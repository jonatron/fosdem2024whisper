{"text": " Yes, good now it is Hello everybody, this is fantastically exciting Look how many people there are, I thought there was going to be like five of us having a lovely time But no, there's far too many of us, great I'm so excited, I'm going to take a photo Just so I can prove this happened Does everybody smile? Wonderful, thank you so much I'm ecstatic, so hello, I'm Louis, I'm the creator of the Gleam programming language If you want to talk to me, do so here I'm here to talk about Gleam, which is, you've just seen a new programming language for the Erlang virtual machine And it feels like we've had milestone, because the language has really matured especially over the last year And so I want to have a little bit of an indulgent look into the past, sort of where did it come from and how did it get started A little bit of a celebration of where we are now and look at some really cool projects And then I want to look into the future and say, what's coming next for Gleam, what can we bring to the beam? So, this slide is ever so slightly irrelevant after that last talk But I just want to stop by saying, what is Gleam, to get everybody on the same page It is a new functional programming language, it doesn't look like Ruby, it doesn't look like Prolog It kind of looks like Rust, C, JavaScript, that sort of thing perhaps And it runs on the Erlang VM, so it is a sibling of Elixir and Erlang But it is a bit different in that it is statically typed, unlike the other two dynamically typed languages, and most of the other ones And that means that it brings a new style of programming to the beam, and hopefully can draw in more beamy people It aims to be very small and consistent, and the point of that is that we want to make it as easy as possible to read code We want it as easy as possible to learn the language and to get productive with it And productivity is not just about having a good language, these days you often have really good tooling Gone are the days when you can just give someone a compiler and then you say, ok well everything else is up to you, you figure it out So we also have a really nice build tool that comes with a formatter and package management and a language server and all those sort of things you probably expect And also it can pass a JavaScript, which is probably less exciting to this room than most But maybe you don't have to write JavaScript if you do in your front-end, so maybe that's a cool thing So first up, the past, what did I mean? Yes good, ok, the past, the past, how did we get here? So this is a history of Gleam according to GitHub, and in the very beginning there was a little tiny little blip of activity and then nothing For absolutely ages, so what was that? What was the very first Gleam? It was this, this hideous thing, this is the very first Gleam syntax People keep saying that the first Gleam syntax was like a Haskell rip-off, it was not, it was this You see it's sort of C-style, it's got braces, but it has the Erlang thing of multiple function clauses, so your top level flow control is done that way And it looks like nothing and nobody's familiar with it and nobody really likes it And it has this perhaps cool idea of having the tests for functions actually be part of the function So maybe you could show that in documentation, and I thought this was great, this is the thing that the language is going to be all about But it looks kind of rubbish to me now, because you can't do any test setup, the only thing you can really do is give an input and an output Well maybe that's good if you're reversing a list, but other than that what can you really do with it? What else can it do? Nothing, it didn't have a type system, it didn't really have a design, I wasn't working in any direction You could return strings and maybe call a function, but that's kind of about it And it was just a really bad layer on top of Erlang, which asked the question, why? Why did this exist? Well it's kind of like today, I wanted to do a conference talk So there I am, looking at younger, Elixir London 2017 And I did a talk on how to write a compiler, how to write a compiler that targeted the Beam virtual machine And it went really well, people liked the talk, I got to hang out with loads of my peers and then I took that project and threw it away And I didn't think about it ever again, sort of Because during this empty period where no work was being done really, I was doing my job, doing open source stuff And I kept thinking, I kept thinking back to that project and wondering, is there actually a point in making another Beam language? And this was spurred on further because I was writing all these really wonderful languages And every time I was writing one of them, I was thinking, oh I really wish I was using one of the other ones Every time I'm writing Elms, it's really difficult to do this IO thing in Elm I wish I was, oh there's no concurrency, I wish I was using Elixir, or I was writing JavaScript I really wish I had Rusts tooling And I sort of figured, maybe it's possible to take all the things I like from all of these languages and merge them into one Because I've sort of accepted the language that I wanted to be writing didn't exist, I felt like I tried them all at this point And so can I make that thing that brings it all together? And so after about a year and a half, the start-up I was working for was bought and trashed And suddenly I had a lot of free time on my hands And so I thought, this is the perfect time to resurrect this project So I remade the whole thing and this is the syntax people keep telling me is the very first Gloom syntax, but it's not It looks a little bit more like OCaml with bits of Elixir mixed in I think And this is in February 2018, okay, so maybe like a year and a half after that previous one And so I kept working on it an awful lot and then fast forward a year and a bit later to April 2019 We've sadly scrapped all of the nice ML syntax and we've got a much more sort of JavaScript syntax And this is version 0.1 which I'm really excited about because it did something You could use it to write some small program whatsoever, which is really cool And it started to look a lot more like Moddingling Fast forward another half year We basically got the syntax as it is today, we did a little bit more, but that's kind of it You notice the differences here are, we've got one of those little pipes And if you look between the IO and the print line, we've got rid of that colon So that's the last of the little Erlang things, sorry Erlang fans What else happened? We used our first class modules as a feature that people love People absolutely love first class modules, that's something that you find in OCaml And really we do it a lot in Elixir and Erlang as well Because if you think about when we pass around an atom that is a reference to the module Well that's a first class module, we're passing it around, we don't have module functors But we do use them an awful lot in our APIs Good, I am actually on the right side And we also have row type records, which is a really cool way of A really cool type system feature that enables you to do these really interesting sorts of polymorphism With objects and variants that sort of looks like interfaces in an OO land But doesn't have that same sort of subtype thing, so these are two fantastically cool features And we also had a more complicated way of declaring types and data structures That was much more akin to what you find in Haskell So we got rid of all these really cool things and replaced them with a string concatenation operator The ability to use callbacks in a slightly nicer way and the ability to give names to arguments So we've swapped really sexy awesome functional programming stuff for things that are actually quite useful But not very exciting And this has kind of been the whole journey of Glim, this has been It's very easy when making something to get excited and distracted by all these things And it could be, we could do this, we could do that But what is actually the most useful thing? And it turns out just removing things and honing in on that call, that most useful, that most productive thing Is the most, hopefully, is the best thing to do And I think we've got a really nice place because of that One thing that we have added that is quite big actually is that JavaScript compilation So that wasn't in there originally, that sort of exploded after Which does make the ecosystem more complicated, but the language not so much We also got a build tool, as I mentioned earlier The idea is to have a really good batteries included one Originally we were using Rebar 3, which is the Erlang build tool And it's really good and it worked quite well for us But you could tell that we were using a tool that wasn't made for us The user experience wasn't as good as I wanted it to be And I didn't just want to match Erlang's developer experience Or even Elixir's developer experience I wanted to even best it in some fashions And I've been writing a lot of Rust and Go And they've got some really amazing tool And I thought, wow, let's take all this goodness that you find in these other ecosystems And let's pull them into the Beam ecosystem, make it grow even better We've integrated with the Hex package management We're all beamers together, it doesn't really matter what language you're writing We want to be able to all share the same code And all depend upon each other's projects and share and give back So we've integrated with Hex So rather than just having a few hundred packages written in Gleam We've also got the 20,000 packages that are written in Elixir and Erlang as well And then we've got a code formatter and a language server And lots of goodies like that So I said there's 20,000, a bit more than that packages on Hex On the package manager And about 200, a bit more than 200 of them are Gleam That makes it extremely difficult to find anything written in Gleam If you want to make a Gleam project So after a while we made the Gleam package index And what that is, that's a little window Just a little view that looks into Hex And allows you to see just the ones that are Gleam So if you want to find a library for HTML in this case You can type in HTML I didn't, I didn't, you're making, we'll talk about that later Anyway, and it will give you elicit packages that have the word HTML In the description or the name That somebody's library does not have HTML in the name or the description And then if you find something suitable you can use that in your project And if you don't then you can then make a decision about Whether you want to perhaps make something new Or if you want to pull something in from the wider ecosystem Internet points, everybody loves internet points So I know that Stiles on GitHub mean absolutely nothing But it's been really uplifting and really wonderful And I feel like a really good sign that loads of people have Have taken that two seconds to say, yeah this seems right This is kind of cool I've been doing this for an awful long time And I think I probably would have stopped by now If it wasn't for loads of lovely people Sharing their support in some small way Whether it be a Stiles on GitHub or a kind message on Discord Or absolutely loads of you turning up into this room today And so it's been absolutely lovely to see that line go up and up and up And I find it wild, I've plotted it here against two quite similar languages Microsoft's F-Sharp and O'Cammill And at some point in the last year or two We've ever taken both of them in terms of number of stars Which is absolutely incredible I'm really excited about ML types And also people really love the Beam I think So this is a really good sign for the future of the Beam What else have we got? Has anyone heard of Exism? Anyone a fan? Fantastic, for those who haven't, it's your lucky day This is a really wonderful website and project Where you can go to learn new programming languages And they've got tens and tens and tens of different languages on there And for a few years we've had a Gleam track And they give you an exercise, some instructions Maybe some hints, and then they give you a series of tests And you can solve it there in your browser Or you can use the command line and download it and use your favourite editor And then when you're happy with your solution You can submit it off and they do a bunch of automatic grading So they've gone some tests and they might do a bit of static analysis Like oh you've done this, maybe you didn't want to do that And then if you're feeling super brave, which is where the real value comes from You can submit it to get some mentoring from an experienced programmer There's loads of lovely people who are just sitting there Helping strangers improve their Erlang or Java or Gleam or whatever There's a really wonderful project And last year, with some help from the wonderful Erlang Ecosystem Foundation Who sponsored this work We went from not just having a set of challenges That you can use to practice your Gleam, but an entire course So you can start by not really knowing any Gleam And by going through this whole thing You can be taught individually all the different concepts And so they give you a concept Then they give you a little challenge that's focused on just that concept And then they will unlock all of the exercises that they think you should be able to do now Using those skills So it's a really fantastic resource and it's absolutely amazing that it's free So do check it out And it's been really well People have really taken to it this course So you can see in the middle Can you see where we launched the new syllabus? Suddenly the uptake went absolutely skyward, which is fantastic And this is not the number of people on the course There are about a thousand, just under a thousand This is how many solutions people are submitting So this is actually the activity It's absolutely wonderful 30,000 submissions Which is a lot of learning, a lot of wasted time Who knows? So Exism is really cool And I really like that idea of being taught The individual concepts in a way that enables you to get somewhere And become productive And off the back of that And also inspired by the wonderful tutorial that Go has So we decided to take that idea of teaching the Breaking the language into concepts And teaching them in an incremental fashion Where each concept builds upon the last one And distilled it, minus all the exercises Into a sort of whistle-stopped tour of Gleam So if you go to the Gleam website today And at the very top there's that hero image That's got the tagline saying Gleam is great tour I don't think it says exactly that, but you get the idea And there's a big button that says Get started or try it or something like that And if you do that it will point you straight It will point you straight onto that first lesson And you can go from This looks kind of interesting Maybe I'll try it to Oh wow, I'm writing and learning Gleam All in your browser without having to Work at how to install Erlang And realizing that App has an Alte Deck package So you can't actually install it properly And oh how do I install Rebar And how do I do these things No, you just go straight in and you can start learning So hopefully people from other ecosystems Or people who are writing election Erlang Can turn up and go Oh I want to give this Gleam thing a try And then very quickly Get whisked into being a Gleam They can be hooked They can start working on the beam And this comes because A, the compiler is written in Rust So if you have Rust you can compile to WebAssembly WebAssembly is a very cool project And we can also compile to JavaScript So if you have those two things together You can run the compiler inside the browser And you can also execute the code inside the browser So we don't have to run any servers So even I can afford this And we don't have to worry about any security stuff Everything is just on the person's computer And it also means it's super fast You can get your feedback immediately So Gleam present, I'm going a bit slow I'm going to speed up a bit Where are we now? I want to look at some projects in the community That are really cool My original version of this The talk ended up being about an hour and a half long So I've had to go loads out So if you're not mentioned, very sorry First thing I want to say is that The Gleam Discord is wonderful I'm super lucky to have loads of lovely people Hang out there I can see some of them here today And there's just people helping each other And sharing cool projects And talking about the news Or talking about coffee or keyboards Or anything really It's a really lovely place to Either get help or to talk to people So do join The community is absolutely wonderful And delightful And I'm super lucky to have Working with them be my job these days So thank you so much everyone But now on to the things they've made The first thing I want to talk and boast about Is MIST And MIST is a pure Gleam HB1.1 server That sports HBHBS It has web sockets I believe Server-centered events are coming in the next version And they're working on HB2 So the cool thing about this Is that it doesn't wrap an Erlang web server It is pure Gleam And it doesn't even use Erlang's OTP It uses Gleam's OTP It's an entirely new implementation And what's really cool Is that it's not just proving that you can use Gleam To make sophisticated things You know, implementing a fast HBHBS server Is quite challenging But you can also get really good performance Out of the ever end So here we've got a bunch of different web servers Graphed The ones at the top are MIST and Bandit Bandit being Elixir's new one Bandit has had a new version Since this benchmark was done So I think it's actually slightly faster now But they're about the same You'll notice we're even beating Go And everyone talks about how Go is super fast But no, we in the Erlang world can do better And we're obviously beating JavaScript But the thing I think is really cool Is that we are really beating Cowboy We are really building the one That we as the community have said This is the best fastest web server It shows that we have further that we can do And it shows that Gleam can be just as performance As Erlang So this really proves the language I think So I mentioned OTP Gleam has gone a different way for OTP Then shared out to Fred and his squid there Gleam has gone a different way with OTP With most of the other languages So Elixir and PureRail and other languages If they want to use OTP They put a very thin layer on top of Erlang OTP Well, Gleam doesn't do that Instead, Gleam takes the core concurrency primitives That you get from the Erlang runtime system And has made type safe versions of all of those And it's the same things like link, sport, monitor Send, receive And then it looks at the protocols that are implemented OTP says you've got to implement certain messages Like system messages And there's certain ways of sending Of doing synchronous requests and all that sort of stuff And we've implemented those same things From the ground up in a type safe way And what's really cool is that we've discovered it's possible For a long time people have said You can't have typed OTP Well, if you get the same If you get that same core primitives that you get inside Erlang You can build the same thing from the ground up So that's been really cool And the fact that it's been used to make miss Shows that it can work And it could be practical and useful in performance So it's all very good having a web server But you kind of need a... Probably need a web framework Unless you want to spend all your time Writing a parser for multi-part form bodies So we have Wisp Wisp is a really lovely little framework I can call it lovely because I made it So if you want to do a web thing That's a good place to start Databases are pretty handy as well We've got bindings for these sort And probably some others that I haven't found The first two, Postgres and SQLite They wrap Erlang projects All the SQLite one can even work on JavaScript If you're using Deno But the bottom two, they're really cool Because they're, again, written in pure Glean Using Glean OTP Now, this is a really cool one This isn't quite so beamy But so Glean can compile to JavaScript Okay, so how do I do a front-end in Glean? I don't want to be writing all this JavaScript For my Beam application If I can avoid it So Lustre is this really lovely library That's sort of quite similar to Elm Or perhaps some React State management systems That gives you a way to make a declarative DOM And then all you need to do is talk about What messages you're going to emit And then how you update the state Every time one of those messages come in And as an Erlanger, I look at this And I see a GenServer I think that the Elm architecture Is basically exactly the same as an Erlang GenServer Instead of calling it call, we're calling it Handlework, we're calling it updates And then we've got this HTML thing on the side Which I don't, who knows But what about live view? People like live view, right? That's the hotness at the moment So live view, in case you don't know Which I find that you almost certainly Do know in this room That's when you have that same sort of idea You get a declarative DOM that is on your front end But all your state updating Where you hold everything is on your back end And then they talk to each other over WebSockets And this results in a really lovely develop experience And you can do all sort of things that you can't Practically do if all the state is on the front end Well, us too can do that as well That last component I showed you There's nothing that says that has to run on the front end It could also run on the back end Just rendering it to HTML Or you could put it on both So you could just by saying Hey, start an actor with this And then here's WebSockets You can have live view with Luster And what's really cool is that you can now pick Which parts of your application is going to use Which architecture? You know, there's a criticism of live view That it means that certain actions That should be really snappy are quite slow And if you lose network connectivity Your whole application stops working Well, then maybe put those bits About making it be resilient to network failures Put those on the clients You can pick exactly what you want So we've got loads of servers and clients And API clients and middleware That are all part of this wider HDP ecosystem And one of the things that's really cool about this Is that there is a Gleam core library Called Gleam HDP that defines a few types for Requests and responses and headers and all these things And so all of these libraries Even though they've been made independently By different people, they can all work together They all share the same primitives And you can say, well I want that API client With that HDP client on the front end And that HDP client on the back end And I'm going to handle it with that server in my tests Fantastic, and it all just nits together Enough about Web There's lots of other cool places we can run code One of them, we probably will do an awful lot Is on the command line And there's this really lovely project called T-Shop Where you can It's a similar sort of Elm updated type thing But rather than being events coming from a DOM It's events coming from a terminal So you can make these really lovely interactive Tuis in Gleam Sadly at the moment you can't run this code on the Beam Because there's a few There's a few quirks of how The Beam handles standard input But hopefully we can make a proposal to The OTP team and they can expose A couple of functions that you can't get to And then we can have exactly the same thing In Elixir and Erlang and all sorts of other languages as well And because I've showed lots of libraries Let's look at an application I think this is really cool This is, I'm going to butcher the name Electrophonie, maybe Which is a music streaming app Similar to Spotify or such And it is written in Gleam Part of JavaScript using Luster And then because we've got this really excellent FFI So we can call into So we can call into other languages And we can use all these web APIs And do things like use the media keys Be on the lock screen of a phone Be in that little bit of the top of your computer Where the music thing is I don't know what it's called And, yeah, the ecosystem is really growing I think there's a name for that kind of curve I'm not sure what it is But we are now 1.2% of hex Which is a tiny number, but bear in mind We're not at version one yet And Elixir's been at version one for 10 years Something like that I think that's really impressive And I really hope that that is going to keep going So, where are we going? What comes next? So, Gleam isn't done A lot of things are very mature, but there are still things to work on And the thing I really want to focus on for the next year is the language server So, what is a language server? Just to make sure everybody's on the same page So, traditionally, if you are making a text editor, an IDE And you want to support a language or a plugin So that they can support a language You need to then work at how to learn all those things about the code layer Oh, how do I know if there's an error? How do I know what I can auto-complete with? How do I know what snippets would expand? How do I know what refactoring is I can do? You'd have to individually implement all those things But some clever clogs, I think at Microsoft, came up with this idea of We're going to have a language server, we're going to define a protocol That all the editors can speak and all these backends can speak And all you need to do is implement the protocol And then suddenly we can have one brain of an editor And that can talk to Elix and Vim and Emacs and VS Code and Zed And all these other cool ones And so we've got one of those Built into the binary that you get when you download Glim Excuse me And it works, but it doesn't work as well as I wanted to It's definitely the least mature part of the whole GLEE ecosystem And a big part of that is my fault I've been developing it entirely on Visual Studio Code And it means the protocol is a little ambiguous in places In a way that I find quite irritating but apparently is fine So all of the editors do slightly different things when you give it certain data So we need to spend more time working on the other editors And making sure that it's rock solid and works exactly the same And all the other ones And I switched a knee over them now so it's not going to be a problem anymore So first step, we're going to get it all working super reliably for everybody And then we're going to flesh it out to have everything We want to have the same experience that you're going to get with Rust Analyzer Or maybe even try and get close to what a JetBrains IDE might give you We want it to be a really excellent experience of all these different things Find references, renaming things, all sorts of refactorings And also code generators, I think are really cool There's loads of bits of trivial code that we bash out every single day about thinking about Well, if it's that easy, just press a button and have the tooling spit out for you And then you can choose to edit it in whatever way you want So breaking changes Over the last year we've had an awful lot of breaking changes Because there was a design and then suddenly a bunch of ULOT turned up and now we had users And then we realised that, oh, actually that original thing that I made up five years ago While I was sitting in my room wasn't the best idea There are problems, so we've made a load of breaking changes in order to refine them What breaking changes are coming next? Hopefully nothing, I think we're there I think we basically have the language to work exactly as it should Which is wonderful And that kind of begs the question Does that mean we can work towards a version one? Yeah, we're working towards a version one So what does that mean? When we get there, what's going to be the points of version one? And I think there are two pillars to this The first one is productivity for people who are using Gleam So that's going to be no breaking changes You can't build on top of foundation that's constantly changing on you We won't have no language bloat I'd be really proud of how we've really honed in on what makes Gleam good And by having a very small, concise, consistent surface area It makes it easy to work with And I want to keep that property I think it's very tempting for languages to hit version one and then go Oh, maybe we need this feature Or maybe we need typeplosses, maybe we need these things No, we're going to keep it super focused And it's going to say exactly that same language that you really love Or don't, you know, whatever it is, it's not going to change And we're going to keep working on improving the developer experience So more tooling, keep improving that If there's something that's annoying to do that everyone has to do Let's make a library for that You know, just keep solving those problems And document everything You know, we want to have cookbooks and guides and tutorials and examples And just make it really easy for you to go How do I do this in Gleam? Oh, look, it says here, here's how I do it Now I can get on And the next thing is sustainability I am not Microsoft I do not have 50 developers working on this I have me And some lovely people who are very kind enough to agree to join the core team Which means they're just called the core team and they do free work for me It's fantastic Thank you very much So we want to make sure that every bit of work that we're doing is as impactful as possible You know, it needs to be... Everything needs to be meaningful And if we can't justify it as being impactful for a large amount of people We just shouldn't do it We've got to make sure everything is efficient as possible Not just in the code, but in our practices as well We're going to document everything internal We're doing really well with this But I think we can do even better I would like people to go, oh, there's something... There's a quirk with the build tool I think this is a bug Okay, I'm going to look inside and see what it is And then just see loads of comments, loads of docs And then they can hopefully work out, oh, that's doing this, that's doing that I can make a contribution to this And the last two things are about funding the project So I work on this full-time And I work on this full-time thanks to GitHub sponsors primarily I really want to... So here, charted in the pink That's how much income we have for the project I'm super happy that it stayed super stable And up there in blue, that is the median For a lead developer in London, which is the city I live I really want to get that up to the blue line For obvious reasons But I'd like to do further than that I'd really like if we could afford to have like one... Two pizza team, is that too old? I want to have that core development team To be able to afford to work on this thing That I think is useful and important and productive And be able to work full-time And be rewarded appropriately It shouldn't be charity, I think, for these people They're doing this really useful work for the ecosystem And then if that stable foundation is there That means other people feel more confident Building their businesses and their projects and so on top of that So if you want to help out, do join the... Do start sponsoring or get your employer to So about half of that previous income comes from one place And that's from Fly, that's our big corporate sponsor They're the really wonderful deployment platform And the other half comes from people donating like five, ten, twenty dollars And they're both wonderful But it means there's quite a lot of... There's quite a lot of weights on one organisation I'd really like to spread that out So if we could have a bunch of smaller corporate sponsors I think that would be much better for the long-term health of the project And if you've got ideas for other things we can do So I know Elixir has a sort of quasi-support thing That you can sign up for If you've got some other ideas, get in touch with me I'd love to hear what your thoughts are So when is Glean version one? How much more have you got to do? Well the answer is now We're there, like we're completely ready And depending on how much you lot distract me For the next few days I hope to get a release candidate out today, tomorrow At some point in the immediate future So this is a really exciting time Good, so questions? Any questions? Thank you very much for creating Glean Could you elaborate more on what happens when we keep target minus JS? When we're targeting to JavaScript Repeat the question Yes, so the question is Can I explain what happens when we target compile to JavaScript? Okay, so we compile to... What can I say about it? So we compile to JavaScript source codes We don't add a runtime We keep very close to JavaScript So like your scripts end up being very small Suitable for use at a browser But because we don't have a runtime It means we don't have an implementation Of say like the Erlang concurrency inside JavaScript So you'll be using a different concurrency pattern If you're using Glean JavaScript If you're using Glean Erlang And that means there's certain incompatibilities Between the Erlang and JavaScript target You can't write a library that easily abstracts over both If it does file IO for it Well, that's a bad example If it does like HTTP requests, for example But it means, you know, that's the trade-off But then it means you can work very well with the Erlang... Sorry, with the JavaScript world We can run Glean in browser through... So again, sorry? Can we run Glean in browser through WebAssembly? Can you run Glean in browser through WebAssembly? No, but that's something we want to explore in future Not because we particularly want to do WebAssembly Sorry, not because we want to do it in the browser Because we could already do that with JavaScript But there's loads of other places you can use WebAssembly And I wanted to talk about this, but I didn't have enough time I think it would be really exciting If we had a good way of executing Glean inside the compiler Because there's loads of optimizations we can do We could start looking at certain kinds of like code generation Meta programming stuff that you can do in Alexa, for example You can't do in Glean But we can't do that because we don't have a copy of the beam This massive thing inside the Glean compiler So if we had like a little VM, maybe we could do that And WebAssembly is a really good little VM for this whole thing Thank you Any other questions? Yeah, I do have a question that you might use to point to I think it's a great question I think it was in the last year during the episode of code And it's a really great project But as you know, I think one of the main parts that draw me to the language Was the vibrant, pink color Is there a story behind it? Is it the color? Why is Glean pink? Great question Great question This was, what is this handle, K-Tec I think is And he just threw this idea it should be pink And I was like, oh really, why? That's really odd And I liked it because it's different You know, you see this pink and you don't go You know, if you see a blue you're like, is that TypeScript? Is it Python? You know, it's visually very different And the other thing is, I think it's quite friendly And hopefully it's welcoming to different people I hope that if someone sees a bright pink thing they go Oh that's cool, you know, maybe there's not going to be And it also says like, you know, be nice to each other No Nazis on the website, you know I'm hoping people will see that and get an idea of what we're about We're about being supportive and friendly And looking after each other So it's, look different and hopefully say something About the kind of vibe we want inside the community Well you work, thank you I mean, it's probably the best thing about Glean I think Currently you target both Glean and then Javister What do you plan to do to introduce other targets like WebAssembly? So I don't like to look at targets as well as, you know I think there's a problem and when people make in languages It's very easy for them to do things that are cool For a language maker to do So for example, it would be cool if I could target WebAssembly It would be cool if I had type classes I don't want to do it for those reasons I want to drive changes by them being impactful to the community And as I said with WebAssembly That can be a nice VM that you can embed in the compiler To enable compile time code execution You could use that to do like Glean script So you could just have just the binary on your server And you can use that to execute tiny little scripts When you don't want to have like a whole virtual machine installed On that computer for example All sorts of little things like that And so I think there is a good Argument in favour of having WebAssembly And so it's something and I would quite enjoy it So I'd like to explore it in future But it's not as high priority as like getting the language server Working really well, getting the documentation fantastic Making sure we've got like a really lovely Like Elixir Phoenix like experience To do web development in Glean So I would like it Maybe one day, don't hold your breath When you do message passing in Glean Does the messages support function cloners as well And if so, how does your type system handle it? As in you're asking When you're doing type OTP Can you send a function to another process? Yeah, function cloners Yes, okay, so So, it's quite tricky You can't, how much context do I give this Because I've thought about this for years And it's quite hard Yes, we can, you can pass any data to another function The key difference between message passing In typed Glean OTP and Erlang OTP Is that you need to have more than just a PID To send a message or something If you've used languages that have channels So for example, Go or Rust You don't just have like the handle for the thread And pass a message to it You've got to have a channel And you send a message via the channel So it's the same idea So we have this idea of a subject We don't call it a channel Because it would be confusing Because it still goes to a process inbox You can't give a channel to a different process And they start pulling from it And every channel is the thing that's typed Not the PID It looks like you should be able to do the PID But then you suddenly realize If you build from the ground up You can't implement synchronous You can't implement call, synchronous message passing If you have typed PIDs Because the type of the return Doesn't match the type of the PID So you need to have something more flexible So we have this thing And if you look under the hood in Erlang OTP They have the same abstraction We've got 14 seconds left And it's used to implement GenServit.co So they have this from thing So it's the same as the from field in GenServit.co That's the thing that you send messages around with I have three seconds left Thank you very much everybody Thank you very much", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 9.0, "text": " Yes, good now it is", "tokens": [50364, 1079, 11, 665, 586, 309, 307, 50814], "temperature": 0.0, "avg_logprob": -0.2466421127319336, "compression_ratio": 1.3725490196078431, "no_speech_prob": 0.40992477536201477}, {"id": 1, "seek": 0, "start": 18.0, "end": 21.0, "text": " Hello everybody, this is fantastically exciting", "tokens": [51264, 2425, 2201, 11, 341, 307, 4115, 22808, 4670, 51414], "temperature": 0.0, "avg_logprob": -0.2466421127319336, "compression_ratio": 1.3725490196078431, "no_speech_prob": 0.40992477536201477}, {"id": 2, "seek": 0, "start": 21.0, "end": 25.0, "text": " Look how many people there are, I thought there was going to be like five of us having a lovely time", "tokens": [51414, 2053, 577, 867, 561, 456, 366, 11, 286, 1194, 456, 390, 516, 281, 312, 411, 1732, 295, 505, 1419, 257, 7496, 565, 51614], "temperature": 0.0, "avg_logprob": -0.2466421127319336, "compression_ratio": 1.3725490196078431, "no_speech_prob": 0.40992477536201477}, {"id": 3, "seek": 0, "start": 25.0, "end": 28.0, "text": " But no, there's far too many of us, great", "tokens": [51614, 583, 572, 11, 456, 311, 1400, 886, 867, 295, 505, 11, 869, 51764], "temperature": 0.0, "avg_logprob": -0.2466421127319336, "compression_ratio": 1.3725490196078431, "no_speech_prob": 0.40992477536201477}, {"id": 4, "seek": 2800, "start": 28.0, "end": 30.0, "text": " I'm so excited, I'm going to take a photo", "tokens": [50364, 286, 478, 370, 2919, 11, 286, 478, 516, 281, 747, 257, 5052, 50464], "temperature": 0.0, "avg_logprob": -0.15787139028873085, "compression_ratio": 1.6177777777777778, "no_speech_prob": 0.30517593026161194}, {"id": 5, "seek": 2800, "start": 31.0, "end": 33.0, "text": " Just so I can prove this happened", "tokens": [50514, 1449, 370, 286, 393, 7081, 341, 2011, 50614], "temperature": 0.0, "avg_logprob": -0.15787139028873085, "compression_ratio": 1.6177777777777778, "no_speech_prob": 0.30517593026161194}, {"id": 6, "seek": 2800, "start": 34.0, "end": 35.0, "text": " Does everybody smile?", "tokens": [50664, 4402, 2201, 7563, 30, 50714], "temperature": 0.0, "avg_logprob": -0.15787139028873085, "compression_ratio": 1.6177777777777778, "no_speech_prob": 0.30517593026161194}, {"id": 7, "seek": 2800, "start": 37.0, "end": 39.0, "text": " Wonderful, thank you so much", "tokens": [50814, 22768, 11, 1309, 291, 370, 709, 50914], "temperature": 0.0, "avg_logprob": -0.15787139028873085, "compression_ratio": 1.6177777777777778, "no_speech_prob": 0.30517593026161194}, {"id": 8, "seek": 2800, "start": 39.0, "end": 44.0, "text": " I'm ecstatic, so hello, I'm Louis, I'm the creator of the Gleam programming language", "tokens": [50914, 286, 478, 11437, 34632, 11, 370, 7751, 11, 286, 478, 9763, 11, 286, 478, 264, 14181, 295, 264, 460, 306, 335, 9410, 2856, 51164], "temperature": 0.0, "avg_logprob": -0.15787139028873085, "compression_ratio": 1.6177777777777778, "no_speech_prob": 0.30517593026161194}, {"id": 9, "seek": 2800, "start": 44.0, "end": 47.0, "text": " If you want to talk to me, do so here", "tokens": [51164, 759, 291, 528, 281, 751, 281, 385, 11, 360, 370, 510, 51314], "temperature": 0.0, "avg_logprob": -0.15787139028873085, "compression_ratio": 1.6177777777777778, "no_speech_prob": 0.30517593026161194}, {"id": 10, "seek": 2800, "start": 47.0, "end": 54.0, "text": " I'm here to talk about Gleam, which is, you've just seen a new programming language for the Erlang virtual machine", "tokens": [51314, 286, 478, 510, 281, 751, 466, 460, 306, 335, 11, 597, 307, 11, 291, 600, 445, 1612, 257, 777, 9410, 2856, 337, 264, 3300, 25241, 6374, 3479, 51664], "temperature": 0.0, "avg_logprob": -0.15787139028873085, "compression_ratio": 1.6177777777777778, "no_speech_prob": 0.30517593026161194}, {"id": 11, "seek": 5400, "start": 54.0, "end": 59.0, "text": " And it feels like we've had milestone, because the language has really matured especially over the last year", "tokens": [50364, 400, 309, 3417, 411, 321, 600, 632, 28048, 11, 570, 264, 2856, 575, 534, 14442, 67, 2318, 670, 264, 1036, 1064, 50614], "temperature": 0.0, "avg_logprob": -0.09827669205204133, "compression_ratio": 1.7370242214532872, "no_speech_prob": 0.22165323793888092}, {"id": 12, "seek": 5400, "start": 59.0, "end": 65.0, "text": " And so I want to have a little bit of an indulgent look into the past, sort of where did it come from and how did it get started", "tokens": [50614, 400, 370, 286, 528, 281, 362, 257, 707, 857, 295, 364, 28626, 6930, 574, 666, 264, 1791, 11, 1333, 295, 689, 630, 309, 808, 490, 293, 577, 630, 309, 483, 1409, 50914], "temperature": 0.0, "avg_logprob": -0.09827669205204133, "compression_ratio": 1.7370242214532872, "no_speech_prob": 0.22165323793888092}, {"id": 13, "seek": 5400, "start": 65.0, "end": 69.0, "text": " A little bit of a celebration of where we are now and look at some really cool projects", "tokens": [50914, 316, 707, 857, 295, 257, 14184, 295, 689, 321, 366, 586, 293, 574, 412, 512, 534, 1627, 4455, 51114], "temperature": 0.0, "avg_logprob": -0.09827669205204133, "compression_ratio": 1.7370242214532872, "no_speech_prob": 0.22165323793888092}, {"id": 14, "seek": 5400, "start": 69.0, "end": 76.0, "text": " And then I want to look into the future and say, what's coming next for Gleam, what can we bring to the beam?", "tokens": [51114, 400, 550, 286, 528, 281, 574, 666, 264, 2027, 293, 584, 11, 437, 311, 1348, 958, 337, 460, 306, 335, 11, 437, 393, 321, 1565, 281, 264, 14269, 30, 51464], "temperature": 0.0, "avg_logprob": -0.09827669205204133, "compression_ratio": 1.7370242214532872, "no_speech_prob": 0.22165323793888092}, {"id": 15, "seek": 5400, "start": 76.0, "end": 81.0, "text": " So, this slide is ever so slightly irrelevant after that last talk", "tokens": [51464, 407, 11, 341, 4137, 307, 1562, 370, 4748, 28682, 934, 300, 1036, 751, 51714], "temperature": 0.0, "avg_logprob": -0.09827669205204133, "compression_ratio": 1.7370242214532872, "no_speech_prob": 0.22165323793888092}, {"id": 16, "seek": 8100, "start": 81.0, "end": 85.0, "text": " But I just want to stop by saying, what is Gleam, to get everybody on the same page", "tokens": [50364, 583, 286, 445, 528, 281, 1590, 538, 1566, 11, 437, 307, 460, 306, 335, 11, 281, 483, 2201, 322, 264, 912, 3028, 50564], "temperature": 0.0, "avg_logprob": -0.08972846575019773, "compression_ratio": 1.6962962962962962, "no_speech_prob": 0.23299594223499298}, {"id": 17, "seek": 8100, "start": 85.0, "end": 90.0, "text": " It is a new functional programming language, it doesn't look like Ruby, it doesn't look like Prolog", "tokens": [50564, 467, 307, 257, 777, 11745, 9410, 2856, 11, 309, 1177, 380, 574, 411, 19907, 11, 309, 1177, 380, 574, 411, 1705, 4987, 50814], "temperature": 0.0, "avg_logprob": -0.08972846575019773, "compression_ratio": 1.6962962962962962, "no_speech_prob": 0.23299594223499298}, {"id": 18, "seek": 8100, "start": 90.0, "end": 95.0, "text": " It kind of looks like Rust, C, JavaScript, that sort of thing perhaps", "tokens": [50814, 467, 733, 295, 1542, 411, 34952, 11, 383, 11, 15778, 11, 300, 1333, 295, 551, 4317, 51064], "temperature": 0.0, "avg_logprob": -0.08972846575019773, "compression_ratio": 1.6962962962962962, "no_speech_prob": 0.23299594223499298}, {"id": 19, "seek": 8100, "start": 95.0, "end": 102.0, "text": " And it runs on the Erlang VM, so it is a sibling of Elixir and Erlang", "tokens": [51064, 400, 309, 6676, 322, 264, 3300, 25241, 18038, 11, 370, 309, 307, 257, 39409, 295, 2699, 970, 347, 293, 3300, 25241, 51414], "temperature": 0.0, "avg_logprob": -0.08972846575019773, "compression_ratio": 1.6962962962962962, "no_speech_prob": 0.23299594223499298}, {"id": 20, "seek": 8100, "start": 102.0, "end": 110.0, "text": " But it is a bit different in that it is statically typed, unlike the other two dynamically typed languages, and most of the other ones", "tokens": [51414, 583, 309, 307, 257, 857, 819, 294, 300, 309, 307, 2219, 984, 33941, 11, 8343, 264, 661, 732, 43492, 33941, 8650, 11, 293, 881, 295, 264, 661, 2306, 51814], "temperature": 0.0, "avg_logprob": -0.08972846575019773, "compression_ratio": 1.6962962962962962, "no_speech_prob": 0.23299594223499298}, {"id": 21, "seek": 11000, "start": 110.0, "end": 117.0, "text": " And that means that it brings a new style of programming to the beam, and hopefully can draw in more beamy people", "tokens": [50364, 400, 300, 1355, 300, 309, 5607, 257, 777, 3758, 295, 9410, 281, 264, 14269, 11, 293, 4696, 393, 2642, 294, 544, 312, 7804, 561, 50714], "temperature": 0.0, "avg_logprob": -0.09685616590538804, "compression_ratio": 1.7740585774058577, "no_speech_prob": 0.06419981271028519}, {"id": 22, "seek": 11000, "start": 117.0, "end": 126.0, "text": " It aims to be very small and consistent, and the point of that is that we want to make it as easy as possible to read code", "tokens": [50714, 467, 24683, 281, 312, 588, 1359, 293, 8398, 11, 293, 264, 935, 295, 300, 307, 300, 321, 528, 281, 652, 309, 382, 1858, 382, 1944, 281, 1401, 3089, 51164], "temperature": 0.0, "avg_logprob": -0.09685616590538804, "compression_ratio": 1.7740585774058577, "no_speech_prob": 0.06419981271028519}, {"id": 23, "seek": 11000, "start": 126.0, "end": 131.0, "text": " We want it as easy as possible to learn the language and to get productive with it", "tokens": [51164, 492, 528, 309, 382, 1858, 382, 1944, 281, 1466, 264, 2856, 293, 281, 483, 13304, 365, 309, 51414], "temperature": 0.0, "avg_logprob": -0.09685616590538804, "compression_ratio": 1.7740585774058577, "no_speech_prob": 0.06419981271028519}, {"id": 24, "seek": 11000, "start": 131.0, "end": 137.0, "text": " And productivity is not just about having a good language, these days you often have really good tooling", "tokens": [51414, 400, 15604, 307, 406, 445, 466, 1419, 257, 665, 2856, 11, 613, 1708, 291, 2049, 362, 534, 665, 46593, 51714], "temperature": 0.0, "avg_logprob": -0.09685616590538804, "compression_ratio": 1.7740585774058577, "no_speech_prob": 0.06419981271028519}, {"id": 25, "seek": 13700, "start": 137.0, "end": 142.0, "text": " Gone are the days when you can just give someone a compiler and then you say, ok well everything else is up to you, you figure it out", "tokens": [50364, 39068, 366, 264, 1708, 562, 291, 393, 445, 976, 1580, 257, 31958, 293, 550, 291, 584, 11, 3133, 731, 1203, 1646, 307, 493, 281, 291, 11, 291, 2573, 309, 484, 50614], "temperature": 0.0, "avg_logprob": -0.16219731381064967, "compression_ratio": 1.6804123711340206, "no_speech_prob": 0.3029616177082062}, {"id": 26, "seek": 13700, "start": 142.0, "end": 152.0, "text": " So we also have a really nice build tool that comes with a formatter and package management and a language server and all those sort of things you probably expect", "tokens": [50614, 407, 321, 611, 362, 257, 534, 1481, 1322, 2290, 300, 1487, 365, 257, 1254, 1161, 293, 7372, 4592, 293, 257, 2856, 7154, 293, 439, 729, 1333, 295, 721, 291, 1391, 2066, 51114], "temperature": 0.0, "avg_logprob": -0.16219731381064967, "compression_ratio": 1.6804123711340206, "no_speech_prob": 0.3029616177082062}, {"id": 27, "seek": 13700, "start": 152.0, "end": 158.0, "text": " And also it can pass a JavaScript, which is probably less exciting to this room than most", "tokens": [51114, 400, 611, 309, 393, 1320, 257, 15778, 11, 597, 307, 1391, 1570, 4670, 281, 341, 1808, 813, 881, 51414], "temperature": 0.0, "avg_logprob": -0.16219731381064967, "compression_ratio": 1.6804123711340206, "no_speech_prob": 0.3029616177082062}, {"id": 28, "seek": 13700, "start": 158.0, "end": 164.0, "text": " But maybe you don't have to write JavaScript if you do in your front-end, so maybe that's a cool thing", "tokens": [51414, 583, 1310, 291, 500, 380, 362, 281, 2464, 15778, 498, 291, 360, 294, 428, 1868, 12, 521, 11, 370, 1310, 300, 311, 257, 1627, 551, 51714], "temperature": 0.0, "avg_logprob": -0.16219731381064967, "compression_ratio": 1.6804123711340206, "no_speech_prob": 0.3029616177082062}, {"id": 29, "seek": 16400, "start": 164.0, "end": 174.0, "text": " So first up, the past, what did I mean? Yes good, ok, the past, the past, how did we get here?", "tokens": [50364, 407, 700, 493, 11, 264, 1791, 11, 437, 630, 286, 914, 30, 1079, 665, 11, 3133, 11, 264, 1791, 11, 264, 1791, 11, 577, 630, 321, 483, 510, 30, 50864], "temperature": 0.0, "avg_logprob": -0.23247936160065408, "compression_ratio": 1.59375, "no_speech_prob": 0.2131355106830597}, {"id": 30, "seek": 16400, "start": 174.0, "end": 185.0, "text": " So this is a history of Gleam according to GitHub, and in the very beginning there was a little tiny little blip of activity and then nothing", "tokens": [50864, 407, 341, 307, 257, 2503, 295, 460, 306, 335, 4650, 281, 23331, 11, 293, 294, 264, 588, 2863, 456, 390, 257, 707, 5870, 707, 888, 647, 295, 5191, 293, 550, 1825, 51414], "temperature": 0.0, "avg_logprob": -0.23247936160065408, "compression_ratio": 1.59375, "no_speech_prob": 0.2131355106830597}, {"id": 31, "seek": 16400, "start": 185.0, "end": 190.0, "text": " For absolutely ages, so what was that? What was the very first Gleam?", "tokens": [51414, 1171, 3122, 12357, 11, 370, 437, 390, 300, 30, 708, 390, 264, 588, 700, 460, 306, 335, 30, 51664], "temperature": 0.0, "avg_logprob": -0.23247936160065408, "compression_ratio": 1.59375, "no_speech_prob": 0.2131355106830597}, {"id": 32, "seek": 19000, "start": 190.0, "end": 195.0, "text": " It was this, this hideous thing, this is the very first Gleam syntax", "tokens": [50364, 467, 390, 341, 11, 341, 6479, 563, 551, 11, 341, 307, 264, 588, 700, 460, 306, 335, 28431, 50614], "temperature": 0.0, "avg_logprob": -0.10438463621050398, "compression_ratio": 1.6791666666666667, "no_speech_prob": 0.35815665125846863}, {"id": 33, "seek": 19000, "start": 195.0, "end": 201.0, "text": " People keep saying that the first Gleam syntax was like a Haskell rip-off, it was not, it was this", "tokens": [50614, 3432, 1066, 1566, 300, 264, 700, 460, 306, 335, 28431, 390, 411, 257, 8646, 43723, 12782, 12, 4506, 11, 309, 390, 406, 11, 309, 390, 341, 50914], "temperature": 0.0, "avg_logprob": -0.10438463621050398, "compression_ratio": 1.6791666666666667, "no_speech_prob": 0.35815665125846863}, {"id": 34, "seek": 19000, "start": 201.0, "end": 211.0, "text": " You see it's sort of C-style, it's got braces, but it has the Erlang thing of multiple function clauses, so your top level flow control is done that way", "tokens": [50914, 509, 536, 309, 311, 1333, 295, 383, 12, 15014, 11, 309, 311, 658, 41537, 11, 457, 309, 575, 264, 3300, 25241, 551, 295, 3866, 2445, 49072, 11, 370, 428, 1192, 1496, 3095, 1969, 307, 1096, 300, 636, 51414], "temperature": 0.0, "avg_logprob": -0.10438463621050398, "compression_ratio": 1.6791666666666667, "no_speech_prob": 0.35815665125846863}, {"id": 35, "seek": 19000, "start": 211.0, "end": 215.0, "text": " And it looks like nothing and nobody's familiar with it and nobody really likes it", "tokens": [51414, 400, 309, 1542, 411, 1825, 293, 5079, 311, 4963, 365, 309, 293, 5079, 534, 5902, 309, 51614], "temperature": 0.0, "avg_logprob": -0.10438463621050398, "compression_ratio": 1.6791666666666667, "no_speech_prob": 0.35815665125846863}, {"id": 36, "seek": 21500, "start": 215.0, "end": 221.0, "text": " And it has this perhaps cool idea of having the tests for functions actually be part of the function", "tokens": [50364, 400, 309, 575, 341, 4317, 1627, 1558, 295, 1419, 264, 6921, 337, 6828, 767, 312, 644, 295, 264, 2445, 50664], "temperature": 0.0, "avg_logprob": -0.09767136080511685, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.6081894636154175}, {"id": 37, "seek": 21500, "start": 221.0, "end": 227.0, "text": " So maybe you could show that in documentation, and I thought this was great, this is the thing that the language is going to be all about", "tokens": [50664, 407, 1310, 291, 727, 855, 300, 294, 14333, 11, 293, 286, 1194, 341, 390, 869, 11, 341, 307, 264, 551, 300, 264, 2856, 307, 516, 281, 312, 439, 466, 50964], "temperature": 0.0, "avg_logprob": -0.09767136080511685, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.6081894636154175}, {"id": 38, "seek": 21500, "start": 227.0, "end": 234.0, "text": " But it looks kind of rubbish to me now, because you can't do any test setup, the only thing you can really do is give an input and an output", "tokens": [50964, 583, 309, 1542, 733, 295, 29978, 281, 385, 586, 11, 570, 291, 393, 380, 360, 604, 1500, 8657, 11, 264, 787, 551, 291, 393, 534, 360, 307, 976, 364, 4846, 293, 364, 5598, 51314], "temperature": 0.0, "avg_logprob": -0.09767136080511685, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.6081894636154175}, {"id": 39, "seek": 21500, "start": 234.0, "end": 239.0, "text": " Well maybe that's good if you're reversing a list, but other than that what can you really do with it?", "tokens": [51314, 1042, 1310, 300, 311, 665, 498, 291, 434, 14582, 278, 257, 1329, 11, 457, 661, 813, 300, 437, 393, 291, 534, 360, 365, 309, 30, 51564], "temperature": 0.0, "avg_logprob": -0.09767136080511685, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.6081894636154175}, {"id": 40, "seek": 23900, "start": 239.0, "end": 246.0, "text": " What else can it do? Nothing, it didn't have a type system, it didn't really have a design, I wasn't working in any direction", "tokens": [50364, 708, 1646, 393, 309, 360, 30, 6693, 11, 309, 994, 380, 362, 257, 2010, 1185, 11, 309, 994, 380, 534, 362, 257, 1715, 11, 286, 2067, 380, 1364, 294, 604, 3513, 50714], "temperature": 0.0, "avg_logprob": -0.11785476376311947, "compression_ratio": 1.576271186440678, "no_speech_prob": 0.09459507465362549}, {"id": 41, "seek": 23900, "start": 246.0, "end": 252.0, "text": " You could return strings and maybe call a function, but that's kind of about it", "tokens": [50714, 509, 727, 2736, 13985, 293, 1310, 818, 257, 2445, 11, 457, 300, 311, 733, 295, 466, 309, 51014], "temperature": 0.0, "avg_logprob": -0.11785476376311947, "compression_ratio": 1.576271186440678, "no_speech_prob": 0.09459507465362549}, {"id": 42, "seek": 23900, "start": 252.0, "end": 259.0, "text": " And it was just a really bad layer on top of Erlang, which asked the question, why? Why did this exist?", "tokens": [51014, 400, 309, 390, 445, 257, 534, 1578, 4583, 322, 1192, 295, 3300, 25241, 11, 597, 2351, 264, 1168, 11, 983, 30, 1545, 630, 341, 2514, 30, 51364], "temperature": 0.0, "avg_logprob": -0.11785476376311947, "compression_ratio": 1.576271186440678, "no_speech_prob": 0.09459507465362549}, {"id": 43, "seek": 23900, "start": 259.0, "end": 262.0, "text": " Well it's kind of like today, I wanted to do a conference talk", "tokens": [51364, 1042, 309, 311, 733, 295, 411, 965, 11, 286, 1415, 281, 360, 257, 7586, 751, 51514], "temperature": 0.0, "avg_logprob": -0.11785476376311947, "compression_ratio": 1.576271186440678, "no_speech_prob": 0.09459507465362549}, {"id": 44, "seek": 26200, "start": 263.0, "end": 269.0, "text": " So there I am, looking at younger, Elixir London 2017", "tokens": [50414, 407, 456, 286, 669, 11, 1237, 412, 7037, 11, 2699, 970, 347, 7042, 6591, 50714], "temperature": 0.0, "avg_logprob": -0.1140351931254069, "compression_ratio": 1.5753424657534247, "no_speech_prob": 0.2613414227962494}, {"id": 45, "seek": 26200, "start": 269.0, "end": 275.0, "text": " And I did a talk on how to write a compiler, how to write a compiler that targeted the Beam virtual machine", "tokens": [50714, 400, 286, 630, 257, 751, 322, 577, 281, 2464, 257, 31958, 11, 577, 281, 2464, 257, 31958, 300, 15045, 264, 40916, 6374, 3479, 51014], "temperature": 0.0, "avg_logprob": -0.1140351931254069, "compression_ratio": 1.5753424657534247, "no_speech_prob": 0.2613414227962494}, {"id": 46, "seek": 26200, "start": 275.0, "end": 281.0, "text": " And it went really well, people liked the talk, I got to hang out with loads of my peers and then I took that project and threw it away", "tokens": [51014, 400, 309, 1437, 534, 731, 11, 561, 4501, 264, 751, 11, 286, 658, 281, 3967, 484, 365, 12668, 295, 452, 16739, 293, 550, 286, 1890, 300, 1716, 293, 11918, 309, 1314, 51314], "temperature": 0.0, "avg_logprob": -0.1140351931254069, "compression_ratio": 1.5753424657534247, "no_speech_prob": 0.2613414227962494}, {"id": 47, "seek": 26200, "start": 281.0, "end": 285.0, "text": " And I didn't think about it ever again, sort of", "tokens": [51314, 400, 286, 994, 380, 519, 466, 309, 1562, 797, 11, 1333, 295, 51514], "temperature": 0.0, "avg_logprob": -0.1140351931254069, "compression_ratio": 1.5753424657534247, "no_speech_prob": 0.2613414227962494}, {"id": 48, "seek": 28500, "start": 285.0, "end": 295.0, "text": " Because during this empty period where no work was being done really, I was doing my job, doing open source stuff", "tokens": [50364, 1436, 1830, 341, 6707, 2896, 689, 572, 589, 390, 885, 1096, 534, 11, 286, 390, 884, 452, 1691, 11, 884, 1269, 4009, 1507, 50864], "temperature": 0.0, "avg_logprob": -0.08269332659126509, "compression_ratio": 1.8936170212765957, "no_speech_prob": 0.6774460673332214}, {"id": 49, "seek": 28500, "start": 295.0, "end": 303.0, "text": " And I kept thinking, I kept thinking back to that project and wondering, is there actually a point in making another Beam language?", "tokens": [50864, 400, 286, 4305, 1953, 11, 286, 4305, 1953, 646, 281, 300, 1716, 293, 6359, 11, 307, 456, 767, 257, 935, 294, 1455, 1071, 40916, 2856, 30, 51264], "temperature": 0.0, "avg_logprob": -0.08269332659126509, "compression_ratio": 1.8936170212765957, "no_speech_prob": 0.6774460673332214}, {"id": 50, "seek": 28500, "start": 303.0, "end": 308.0, "text": " And this was spurred on further because I was writing all these really wonderful languages", "tokens": [51264, 400, 341, 390, 35657, 986, 322, 3052, 570, 286, 390, 3579, 439, 613, 534, 3715, 8650, 51514], "temperature": 0.0, "avg_logprob": -0.08269332659126509, "compression_ratio": 1.8936170212765957, "no_speech_prob": 0.6774460673332214}, {"id": 51, "seek": 28500, "start": 308.0, "end": 314.0, "text": " And every time I was writing one of them, I was thinking, oh I really wish I was using one of the other ones", "tokens": [51514, 400, 633, 565, 286, 390, 3579, 472, 295, 552, 11, 286, 390, 1953, 11, 1954, 286, 534, 3172, 286, 390, 1228, 472, 295, 264, 661, 2306, 51814], "temperature": 0.0, "avg_logprob": -0.08269332659126509, "compression_ratio": 1.8936170212765957, "no_speech_prob": 0.6774460673332214}, {"id": 52, "seek": 31400, "start": 314.0, "end": 319.0, "text": " Every time I'm writing Elms, it's really difficult to do this IO thing in Elm", "tokens": [50364, 2048, 565, 286, 478, 3579, 2699, 2592, 11, 309, 311, 534, 2252, 281, 360, 341, 39839, 551, 294, 2699, 76, 50614], "temperature": 0.0, "avg_logprob": -0.11630036550409653, "compression_ratio": 1.738255033557047, "no_speech_prob": 0.021895507350564003}, {"id": 53, "seek": 31400, "start": 319.0, "end": 323.0, "text": " I wish I was, oh there's no concurrency, I wish I was using Elixir, or I was writing JavaScript", "tokens": [50614, 286, 3172, 286, 390, 11, 1954, 456, 311, 572, 23702, 10457, 11, 286, 3172, 286, 390, 1228, 2699, 970, 347, 11, 420, 286, 390, 3579, 15778, 50814], "temperature": 0.0, "avg_logprob": -0.11630036550409653, "compression_ratio": 1.738255033557047, "no_speech_prob": 0.021895507350564003}, {"id": 54, "seek": 31400, "start": 323.0, "end": 326.0, "text": " I really wish I had Rusts tooling", "tokens": [50814, 286, 534, 3172, 286, 632, 34952, 82, 46593, 50964], "temperature": 0.0, "avg_logprob": -0.11630036550409653, "compression_ratio": 1.738255033557047, "no_speech_prob": 0.021895507350564003}, {"id": 55, "seek": 31400, "start": 326.0, "end": 333.0, "text": " And I sort of figured, maybe it's possible to take all the things I like from all of these languages and merge them into one", "tokens": [50964, 400, 286, 1333, 295, 8932, 11, 1310, 309, 311, 1944, 281, 747, 439, 264, 721, 286, 411, 490, 439, 295, 613, 8650, 293, 22183, 552, 666, 472, 51314], "temperature": 0.0, "avg_logprob": -0.11630036550409653, "compression_ratio": 1.738255033557047, "no_speech_prob": 0.021895507350564003}, {"id": 56, "seek": 31400, "start": 333.0, "end": 338.0, "text": " Because I've sort of accepted the language that I wanted to be writing didn't exist, I felt like I tried them all at this point", "tokens": [51314, 1436, 286, 600, 1333, 295, 9035, 264, 2856, 300, 286, 1415, 281, 312, 3579, 994, 380, 2514, 11, 286, 2762, 411, 286, 3031, 552, 439, 412, 341, 935, 51564], "temperature": 0.0, "avg_logprob": -0.11630036550409653, "compression_ratio": 1.738255033557047, "no_speech_prob": 0.021895507350564003}, {"id": 57, "seek": 31400, "start": 338.0, "end": 343.0, "text": " And so can I make that thing that brings it all together?", "tokens": [51564, 400, 370, 393, 286, 652, 300, 551, 300, 5607, 309, 439, 1214, 30, 51814], "temperature": 0.0, "avg_logprob": -0.11630036550409653, "compression_ratio": 1.738255033557047, "no_speech_prob": 0.021895507350564003}, {"id": 58, "seek": 34300, "start": 343.0, "end": 349.0, "text": " And so after about a year and a half, the start-up I was working for was bought and trashed", "tokens": [50364, 400, 370, 934, 466, 257, 1064, 293, 257, 1922, 11, 264, 722, 12, 1010, 286, 390, 1364, 337, 390, 4243, 293, 11321, 292, 50664], "temperature": 0.0, "avg_logprob": -0.11811582757792341, "compression_ratio": 1.616, "no_speech_prob": 0.010724176652729511}, {"id": 59, "seek": 34300, "start": 349.0, "end": 352.0, "text": " And suddenly I had a lot of free time on my hands", "tokens": [50664, 400, 5800, 286, 632, 257, 688, 295, 1737, 565, 322, 452, 2377, 50814], "temperature": 0.0, "avg_logprob": -0.11811582757792341, "compression_ratio": 1.616, "no_speech_prob": 0.010724176652729511}, {"id": 60, "seek": 34300, "start": 352.0, "end": 357.0, "text": " And so I thought, this is the perfect time to resurrect this project", "tokens": [50814, 400, 370, 286, 1194, 11, 341, 307, 264, 2176, 565, 281, 34338, 341, 1716, 51064], "temperature": 0.0, "avg_logprob": -0.11811582757792341, "compression_ratio": 1.616, "no_speech_prob": 0.010724176652729511}, {"id": 61, "seek": 34300, "start": 357.0, "end": 363.0, "text": " So I remade the whole thing and this is the syntax people keep telling me is the very first Gloom syntax, but it's not", "tokens": [51064, 407, 286, 890, 762, 264, 1379, 551, 293, 341, 307, 264, 28431, 561, 1066, 3585, 385, 307, 264, 588, 700, 10786, 298, 28431, 11, 457, 309, 311, 406, 51364], "temperature": 0.0, "avg_logprob": -0.11811582757792341, "compression_ratio": 1.616, "no_speech_prob": 0.010724176652729511}, {"id": 62, "seek": 34300, "start": 363.0, "end": 368.0, "text": " It looks a little bit more like OCaml with bits of Elixir mixed in I think", "tokens": [51364, 467, 1542, 257, 707, 857, 544, 411, 422, 31030, 75, 365, 9239, 295, 2699, 970, 347, 7467, 294, 286, 519, 51614], "temperature": 0.0, "avg_logprob": -0.11811582757792341, "compression_ratio": 1.616, "no_speech_prob": 0.010724176652729511}, {"id": 63, "seek": 36800, "start": 368.0, "end": 375.0, "text": " And this is in February 2018, okay, so maybe like a year and a half after that previous one", "tokens": [50364, 400, 341, 307, 294, 8711, 6096, 11, 1392, 11, 370, 1310, 411, 257, 1064, 293, 257, 1922, 934, 300, 3894, 472, 50714], "temperature": 0.0, "avg_logprob": -0.10776083686135032, "compression_ratio": 1.5830388692579505, "no_speech_prob": 0.13361583650112152}, {"id": 64, "seek": 36800, "start": 375.0, "end": 382.0, "text": " And so I kept working on it an awful lot and then fast forward a year and a bit later to April 2019", "tokens": [50714, 400, 370, 286, 4305, 1364, 322, 309, 364, 11232, 688, 293, 550, 2370, 2128, 257, 1064, 293, 257, 857, 1780, 281, 6929, 6071, 51064], "temperature": 0.0, "avg_logprob": -0.10776083686135032, "compression_ratio": 1.5830388692579505, "no_speech_prob": 0.13361583650112152}, {"id": 65, "seek": 36800, "start": 382.0, "end": 389.0, "text": " We've sadly scrapped all of the nice ML syntax and we've got a much more sort of JavaScript syntax", "tokens": [51064, 492, 600, 22023, 13943, 3320, 439, 295, 264, 1481, 21601, 28431, 293, 321, 600, 658, 257, 709, 544, 1333, 295, 15778, 28431, 51414], "temperature": 0.0, "avg_logprob": -0.10776083686135032, "compression_ratio": 1.5830388692579505, "no_speech_prob": 0.13361583650112152}, {"id": 66, "seek": 36800, "start": 389.0, "end": 394.0, "text": " And this is version 0.1 which I'm really excited about because it did something", "tokens": [51414, 400, 341, 307, 3037, 1958, 13, 16, 597, 286, 478, 534, 2919, 466, 570, 309, 630, 746, 51664], "temperature": 0.0, "avg_logprob": -0.10776083686135032, "compression_ratio": 1.5830388692579505, "no_speech_prob": 0.13361583650112152}, {"id": 67, "seek": 36800, "start": 394.0, "end": 397.0, "text": " You could use it to write some small program whatsoever, which is really cool", "tokens": [51664, 509, 727, 764, 309, 281, 2464, 512, 1359, 1461, 17076, 11, 597, 307, 534, 1627, 51814], "temperature": 0.0, "avg_logprob": -0.10776083686135032, "compression_ratio": 1.5830388692579505, "no_speech_prob": 0.13361583650112152}, {"id": 68, "seek": 39700, "start": 397.0, "end": 400.0, "text": " And it started to look a lot more like Moddingling", "tokens": [50364, 400, 309, 1409, 281, 574, 257, 688, 544, 411, 6583, 3584, 1688, 50514], "temperature": 0.0, "avg_logprob": -0.17572562808082218, "compression_ratio": 1.6224066390041494, "no_speech_prob": 0.03541683405637741}, {"id": 69, "seek": 39700, "start": 400.0, "end": 403.0, "text": " Fast forward another half year", "tokens": [50514, 15968, 2128, 1071, 1922, 1064, 50664], "temperature": 0.0, "avg_logprob": -0.17572562808082218, "compression_ratio": 1.6224066390041494, "no_speech_prob": 0.03541683405637741}, {"id": 70, "seek": 39700, "start": 403.0, "end": 407.0, "text": " We basically got the syntax as it is today, we did a little bit more, but that's kind of it", "tokens": [50664, 492, 1936, 658, 264, 28431, 382, 309, 307, 965, 11, 321, 630, 257, 707, 857, 544, 11, 457, 300, 311, 733, 295, 309, 50864], "temperature": 0.0, "avg_logprob": -0.17572562808082218, "compression_ratio": 1.6224066390041494, "no_speech_prob": 0.03541683405637741}, {"id": 71, "seek": 39700, "start": 407.0, "end": 412.0, "text": " You notice the differences here are, we've got one of those little pipes", "tokens": [50864, 509, 3449, 264, 7300, 510, 366, 11, 321, 600, 658, 472, 295, 729, 707, 21882, 51114], "temperature": 0.0, "avg_logprob": -0.17572562808082218, "compression_ratio": 1.6224066390041494, "no_speech_prob": 0.03541683405637741}, {"id": 72, "seek": 39700, "start": 412.0, "end": 417.0, "text": " And if you look between the IO and the print line, we've got rid of that colon", "tokens": [51114, 400, 498, 291, 574, 1296, 264, 286, 46, 293, 264, 4482, 1622, 11, 321, 600, 658, 3973, 295, 300, 8255, 51364], "temperature": 0.0, "avg_logprob": -0.17572562808082218, "compression_ratio": 1.6224066390041494, "no_speech_prob": 0.03541683405637741}, {"id": 73, "seek": 39700, "start": 417.0, "end": 422.0, "text": " So that's the last of the little Erlang things, sorry Erlang fans", "tokens": [51364, 407, 300, 311, 264, 1036, 295, 264, 707, 3300, 25241, 721, 11, 2597, 3300, 25241, 4499, 51614], "temperature": 0.0, "avg_logprob": -0.17572562808082218, "compression_ratio": 1.6224066390041494, "no_speech_prob": 0.03541683405637741}, {"id": 74, "seek": 42200, "start": 423.0, "end": 429.0, "text": " What else happened? We used our first class modules as a feature that people love", "tokens": [50414, 708, 1646, 2011, 30, 492, 1143, 527, 700, 1508, 16679, 382, 257, 4111, 300, 561, 959, 50714], "temperature": 0.0, "avg_logprob": -0.12074888137079054, "compression_ratio": 1.7391304347826086, "no_speech_prob": 0.1794808954000473}, {"id": 75, "seek": 42200, "start": 429.0, "end": 433.0, "text": " People absolutely love first class modules, that's something that you find in OCaml", "tokens": [50714, 3432, 3122, 959, 700, 1508, 16679, 11, 300, 311, 746, 300, 291, 915, 294, 422, 31030, 75, 50914], "temperature": 0.0, "avg_logprob": -0.12074888137079054, "compression_ratio": 1.7391304347826086, "no_speech_prob": 0.1794808954000473}, {"id": 76, "seek": 42200, "start": 433.0, "end": 436.0, "text": " And really we do it a lot in Elixir and Erlang as well", "tokens": [50914, 400, 534, 321, 360, 309, 257, 688, 294, 2699, 970, 347, 293, 3300, 25241, 382, 731, 51064], "temperature": 0.0, "avg_logprob": -0.12074888137079054, "compression_ratio": 1.7391304347826086, "no_speech_prob": 0.1794808954000473}, {"id": 77, "seek": 42200, "start": 436.0, "end": 440.0, "text": " Because if you think about when we pass around an atom that is a reference to the module", "tokens": [51064, 1436, 498, 291, 519, 466, 562, 321, 1320, 926, 364, 12018, 300, 307, 257, 6408, 281, 264, 10088, 51264], "temperature": 0.0, "avg_logprob": -0.12074888137079054, "compression_ratio": 1.7391304347826086, "no_speech_prob": 0.1794808954000473}, {"id": 78, "seek": 42200, "start": 440.0, "end": 443.0, "text": " Well that's a first class module, we're passing it around, we don't have module functors", "tokens": [51264, 1042, 300, 311, 257, 700, 1508, 10088, 11, 321, 434, 8437, 309, 926, 11, 321, 500, 380, 362, 10088, 1019, 5547, 51414], "temperature": 0.0, "avg_logprob": -0.12074888137079054, "compression_ratio": 1.7391304347826086, "no_speech_prob": 0.1794808954000473}, {"id": 79, "seek": 42200, "start": 443.0, "end": 446.0, "text": " But we do use them an awful lot in our APIs", "tokens": [51414, 583, 321, 360, 764, 552, 364, 11232, 688, 294, 527, 21445, 51564], "temperature": 0.0, "avg_logprob": -0.12074888137079054, "compression_ratio": 1.7391304347826086, "no_speech_prob": 0.1794808954000473}, {"id": 80, "seek": 42200, "start": 446.0, "end": 448.0, "text": " Good, I am actually on the right side", "tokens": [51564, 2205, 11, 286, 669, 767, 322, 264, 558, 1252, 51664], "temperature": 0.0, "avg_logprob": -0.12074888137079054, "compression_ratio": 1.7391304347826086, "no_speech_prob": 0.1794808954000473}, {"id": 81, "seek": 44800, "start": 449.0, "end": 453.0, "text": " And we also have row type records, which is a really cool way of", "tokens": [50414, 400, 321, 611, 362, 5386, 2010, 7724, 11, 597, 307, 257, 534, 1627, 636, 295, 50614], "temperature": 0.0, "avg_logprob": -0.13026821613311768, "compression_ratio": 1.7405857740585775, "no_speech_prob": 0.02707870677113533}, {"id": 82, "seek": 44800, "start": 453.0, "end": 458.0, "text": " A really cool type system feature that enables you to do these really interesting sorts of polymorphism", "tokens": [50614, 316, 534, 1627, 2010, 1185, 4111, 300, 17077, 291, 281, 360, 613, 534, 1880, 7527, 295, 6754, 76, 18191, 1434, 50864], "temperature": 0.0, "avg_logprob": -0.13026821613311768, "compression_ratio": 1.7405857740585775, "no_speech_prob": 0.02707870677113533}, {"id": 83, "seek": 44800, "start": 458.0, "end": 466.0, "text": " With objects and variants that sort of looks like interfaces in an OO land", "tokens": [50864, 2022, 6565, 293, 21669, 300, 1333, 295, 1542, 411, 28416, 294, 364, 422, 46, 2117, 51264], "temperature": 0.0, "avg_logprob": -0.13026821613311768, "compression_ratio": 1.7405857740585775, "no_speech_prob": 0.02707870677113533}, {"id": 84, "seek": 44800, "start": 466.0, "end": 470.0, "text": " But doesn't have that same sort of subtype thing, so these are two fantastically cool features", "tokens": [51264, 583, 1177, 380, 362, 300, 912, 1333, 295, 1422, 20467, 551, 11, 370, 613, 366, 732, 4115, 22808, 1627, 4122, 51464], "temperature": 0.0, "avg_logprob": -0.13026821613311768, "compression_ratio": 1.7405857740585775, "no_speech_prob": 0.02707870677113533}, {"id": 85, "seek": 44800, "start": 470.0, "end": 474.0, "text": " And we also had a more complicated way of declaring types and data structures", "tokens": [51464, 400, 321, 611, 632, 257, 544, 6179, 636, 295, 40374, 3467, 293, 1412, 9227, 51664], "temperature": 0.0, "avg_logprob": -0.13026821613311768, "compression_ratio": 1.7405857740585775, "no_speech_prob": 0.02707870677113533}, {"id": 86, "seek": 47400, "start": 474.0, "end": 478.0, "text": " That was much more akin to what you find in Haskell", "tokens": [50364, 663, 390, 709, 544, 47540, 281, 437, 291, 915, 294, 8646, 43723, 50564], "temperature": 0.0, "avg_logprob": -0.09160215714398552, "compression_ratio": 1.63003663003663, "no_speech_prob": 0.18063291907310486}, {"id": 87, "seek": 47400, "start": 478.0, "end": 484.0, "text": " So we got rid of all these really cool things and replaced them with a string concatenation operator", "tokens": [50564, 407, 321, 658, 3973, 295, 439, 613, 534, 1627, 721, 293, 10772, 552, 365, 257, 6798, 1588, 7186, 399, 12973, 50864], "temperature": 0.0, "avg_logprob": -0.09160215714398552, "compression_ratio": 1.63003663003663, "no_speech_prob": 0.18063291907310486}, {"id": 88, "seek": 47400, "start": 484.0, "end": 490.0, "text": " The ability to use callbacks in a slightly nicer way and the ability to give names to arguments", "tokens": [50864, 440, 3485, 281, 764, 818, 17758, 294, 257, 4748, 22842, 636, 293, 264, 3485, 281, 976, 5288, 281, 12869, 51164], "temperature": 0.0, "avg_logprob": -0.09160215714398552, "compression_ratio": 1.63003663003663, "no_speech_prob": 0.18063291907310486}, {"id": 89, "seek": 47400, "start": 490.0, "end": 497.0, "text": " So we've swapped really sexy awesome functional programming stuff for things that are actually quite useful", "tokens": [51164, 407, 321, 600, 50011, 534, 13701, 3476, 11745, 9410, 1507, 337, 721, 300, 366, 767, 1596, 4420, 51514], "temperature": 0.0, "avg_logprob": -0.09160215714398552, "compression_ratio": 1.63003663003663, "no_speech_prob": 0.18063291907310486}, {"id": 90, "seek": 47400, "start": 497.0, "end": 499.0, "text": " But not very exciting", "tokens": [51514, 583, 406, 588, 4670, 51614], "temperature": 0.0, "avg_logprob": -0.09160215714398552, "compression_ratio": 1.63003663003663, "no_speech_prob": 0.18063291907310486}, {"id": 91, "seek": 47400, "start": 499.0, "end": 503.0, "text": " And this has kind of been the whole journey of Glim, this has been", "tokens": [51614, 400, 341, 575, 733, 295, 668, 264, 1379, 4671, 295, 460, 4197, 11, 341, 575, 668, 51814], "temperature": 0.0, "avg_logprob": -0.09160215714398552, "compression_ratio": 1.63003663003663, "no_speech_prob": 0.18063291907310486}, {"id": 92, "seek": 50300, "start": 503.0, "end": 507.0, "text": " It's very easy when making something to get excited and distracted by all these things", "tokens": [50364, 467, 311, 588, 1858, 562, 1455, 746, 281, 483, 2919, 293, 21658, 538, 439, 613, 721, 50564], "temperature": 0.0, "avg_logprob": -0.09195686282968163, "compression_ratio": 1.839464882943144, "no_speech_prob": 0.0711834654211998}, {"id": 93, "seek": 50300, "start": 507.0, "end": 509.0, "text": " And it could be, we could do this, we could do that", "tokens": [50564, 400, 309, 727, 312, 11, 321, 727, 360, 341, 11, 321, 727, 360, 300, 50664], "temperature": 0.0, "avg_logprob": -0.09195686282968163, "compression_ratio": 1.839464882943144, "no_speech_prob": 0.0711834654211998}, {"id": 94, "seek": 50300, "start": 509.0, "end": 511.0, "text": " But what is actually the most useful thing?", "tokens": [50664, 583, 437, 307, 767, 264, 881, 4420, 551, 30, 50764], "temperature": 0.0, "avg_logprob": -0.09195686282968163, "compression_ratio": 1.839464882943144, "no_speech_prob": 0.0711834654211998}, {"id": 95, "seek": 50300, "start": 511.0, "end": 518.0, "text": " And it turns out just removing things and honing in on that call, that most useful, that most productive thing", "tokens": [50764, 400, 309, 4523, 484, 445, 12720, 721, 293, 2157, 278, 294, 322, 300, 818, 11, 300, 881, 4420, 11, 300, 881, 13304, 551, 51114], "temperature": 0.0, "avg_logprob": -0.09195686282968163, "compression_ratio": 1.839464882943144, "no_speech_prob": 0.0711834654211998}, {"id": 96, "seek": 50300, "start": 518.0, "end": 521.0, "text": " Is the most, hopefully, is the best thing to do", "tokens": [51114, 1119, 264, 881, 11, 4696, 11, 307, 264, 1151, 551, 281, 360, 51264], "temperature": 0.0, "avg_logprob": -0.09195686282968163, "compression_ratio": 1.839464882943144, "no_speech_prob": 0.0711834654211998}, {"id": 97, "seek": 50300, "start": 521.0, "end": 524.0, "text": " And I think we've got a really nice place because of that", "tokens": [51264, 400, 286, 519, 321, 600, 658, 257, 534, 1481, 1081, 570, 295, 300, 51414], "temperature": 0.0, "avg_logprob": -0.09195686282968163, "compression_ratio": 1.839464882943144, "no_speech_prob": 0.0711834654211998}, {"id": 98, "seek": 50300, "start": 524.0, "end": 529.0, "text": " One thing that we have added that is quite big actually is that JavaScript compilation", "tokens": [51414, 1485, 551, 300, 321, 362, 3869, 300, 307, 1596, 955, 767, 307, 300, 15778, 40261, 51664], "temperature": 0.0, "avg_logprob": -0.09195686282968163, "compression_ratio": 1.839464882943144, "no_speech_prob": 0.0711834654211998}, {"id": 99, "seek": 50300, "start": 529.0, "end": 532.0, "text": " So that wasn't in there originally, that sort of exploded after", "tokens": [51664, 407, 300, 2067, 380, 294, 456, 7993, 11, 300, 1333, 295, 27049, 934, 51814], "temperature": 0.0, "avg_logprob": -0.09195686282968163, "compression_ratio": 1.839464882943144, "no_speech_prob": 0.0711834654211998}, {"id": 100, "seek": 53200, "start": 532.0, "end": 537.0, "text": " Which does make the ecosystem more complicated, but the language not so much", "tokens": [50364, 3013, 775, 652, 264, 11311, 544, 6179, 11, 457, 264, 2856, 406, 370, 709, 50614], "temperature": 0.0, "avg_logprob": -0.09273241184375904, "compression_ratio": 1.6472868217054264, "no_speech_prob": 0.06694874167442322}, {"id": 101, "seek": 53200, "start": 539.0, "end": 541.0, "text": " We also got a build tool, as I mentioned earlier", "tokens": [50714, 492, 611, 658, 257, 1322, 2290, 11, 382, 286, 2835, 3071, 50814], "temperature": 0.0, "avg_logprob": -0.09273241184375904, "compression_ratio": 1.6472868217054264, "no_speech_prob": 0.06694874167442322}, {"id": 102, "seek": 53200, "start": 541.0, "end": 544.0, "text": " The idea is to have a really good batteries included one", "tokens": [50814, 440, 1558, 307, 281, 362, 257, 534, 665, 13070, 5556, 472, 50964], "temperature": 0.0, "avg_logprob": -0.09273241184375904, "compression_ratio": 1.6472868217054264, "no_speech_prob": 0.06694874167442322}, {"id": 103, "seek": 53200, "start": 544.0, "end": 548.0, "text": " Originally we were using Rebar 3, which is the Erlang build tool", "tokens": [50964, 28696, 321, 645, 1228, 1300, 5356, 805, 11, 597, 307, 264, 3300, 25241, 1322, 2290, 51164], "temperature": 0.0, "avg_logprob": -0.09273241184375904, "compression_ratio": 1.6472868217054264, "no_speech_prob": 0.06694874167442322}, {"id": 104, "seek": 53200, "start": 548.0, "end": 550.0, "text": " And it's really good and it worked quite well for us", "tokens": [51164, 400, 309, 311, 534, 665, 293, 309, 2732, 1596, 731, 337, 505, 51264], "temperature": 0.0, "avg_logprob": -0.09273241184375904, "compression_ratio": 1.6472868217054264, "no_speech_prob": 0.06694874167442322}, {"id": 105, "seek": 53200, "start": 550.0, "end": 555.0, "text": " But you could tell that we were using a tool that wasn't made for us", "tokens": [51264, 583, 291, 727, 980, 300, 321, 645, 1228, 257, 2290, 300, 2067, 380, 1027, 337, 505, 51514], "temperature": 0.0, "avg_logprob": -0.09273241184375904, "compression_ratio": 1.6472868217054264, "no_speech_prob": 0.06694874167442322}, {"id": 106, "seek": 53200, "start": 555.0, "end": 559.0, "text": " The user experience wasn't as good as I wanted it to be", "tokens": [51514, 440, 4195, 1752, 2067, 380, 382, 665, 382, 286, 1415, 309, 281, 312, 51714], "temperature": 0.0, "avg_logprob": -0.09273241184375904, "compression_ratio": 1.6472868217054264, "no_speech_prob": 0.06694874167442322}, {"id": 107, "seek": 55900, "start": 559.0, "end": 563.0, "text": " And I didn't just want to match Erlang's developer experience", "tokens": [50364, 400, 286, 994, 380, 445, 528, 281, 2995, 3300, 25241, 311, 10754, 1752, 50564], "temperature": 0.0, "avg_logprob": -0.09192111275412819, "compression_ratio": 1.7166666666666666, "no_speech_prob": 0.06301383674144745}, {"id": 108, "seek": 55900, "start": 563.0, "end": 565.0, "text": " Or even Elixir's developer experience", "tokens": [50564, 1610, 754, 2699, 970, 347, 311, 10754, 1752, 50664], "temperature": 0.0, "avg_logprob": -0.09192111275412819, "compression_ratio": 1.7166666666666666, "no_speech_prob": 0.06301383674144745}, {"id": 109, "seek": 55900, "start": 565.0, "end": 567.0, "text": " I wanted to even best it in some fashions", "tokens": [50664, 286, 1415, 281, 754, 1151, 309, 294, 512, 283, 1299, 626, 50764], "temperature": 0.0, "avg_logprob": -0.09192111275412819, "compression_ratio": 1.7166666666666666, "no_speech_prob": 0.06301383674144745}, {"id": 110, "seek": 55900, "start": 567.0, "end": 571.0, "text": " And I've been writing a lot of Rust and Go", "tokens": [50764, 400, 286, 600, 668, 3579, 257, 688, 295, 34952, 293, 1037, 50964], "temperature": 0.0, "avg_logprob": -0.09192111275412819, "compression_ratio": 1.7166666666666666, "no_speech_prob": 0.06301383674144745}, {"id": 111, "seek": 55900, "start": 571.0, "end": 573.0, "text": " And they've got some really amazing tool", "tokens": [50964, 400, 436, 600, 658, 512, 534, 2243, 2290, 51064], "temperature": 0.0, "avg_logprob": -0.09192111275412819, "compression_ratio": 1.7166666666666666, "no_speech_prob": 0.06301383674144745}, {"id": 112, "seek": 55900, "start": 573.0, "end": 577.0, "text": " And I thought, wow, let's take all this goodness that you find in these other ecosystems", "tokens": [51064, 400, 286, 1194, 11, 6076, 11, 718, 311, 747, 439, 341, 8387, 300, 291, 915, 294, 613, 661, 32647, 51264], "temperature": 0.0, "avg_logprob": -0.09192111275412819, "compression_ratio": 1.7166666666666666, "no_speech_prob": 0.06301383674144745}, {"id": 113, "seek": 55900, "start": 577.0, "end": 581.0, "text": " And let's pull them into the Beam ecosystem, make it grow even better", "tokens": [51264, 400, 718, 311, 2235, 552, 666, 264, 40916, 11311, 11, 652, 309, 1852, 754, 1101, 51464], "temperature": 0.0, "avg_logprob": -0.09192111275412819, "compression_ratio": 1.7166666666666666, "no_speech_prob": 0.06301383674144745}, {"id": 114, "seek": 55900, "start": 581.0, "end": 585.0, "text": " We've integrated with the Hex package management", "tokens": [51464, 492, 600, 10919, 365, 264, 634, 87, 7372, 4592, 51664], "temperature": 0.0, "avg_logprob": -0.09192111275412819, "compression_ratio": 1.7166666666666666, "no_speech_prob": 0.06301383674144745}, {"id": 115, "seek": 55900, "start": 585.0, "end": 588.0, "text": " We're all beamers together, it doesn't really matter what language you're writing", "tokens": [51664, 492, 434, 439, 312, 335, 433, 1214, 11, 309, 1177, 380, 534, 1871, 437, 2856, 291, 434, 3579, 51814], "temperature": 0.0, "avg_logprob": -0.09192111275412819, "compression_ratio": 1.7166666666666666, "no_speech_prob": 0.06301383674144745}, {"id": 116, "seek": 58800, "start": 588.0, "end": 590.0, "text": " We want to be able to all share the same code", "tokens": [50364, 492, 528, 281, 312, 1075, 281, 439, 2073, 264, 912, 3089, 50464], "temperature": 0.0, "avg_logprob": -0.10591786755017998, "compression_ratio": 1.6628787878787878, "no_speech_prob": 0.015966540202498436}, {"id": 117, "seek": 58800, "start": 590.0, "end": 593.0, "text": " And all depend upon each other's projects and share and give back", "tokens": [50464, 400, 439, 5672, 3564, 1184, 661, 311, 4455, 293, 2073, 293, 976, 646, 50614], "temperature": 0.0, "avg_logprob": -0.10591786755017998, "compression_ratio": 1.6628787878787878, "no_speech_prob": 0.015966540202498436}, {"id": 118, "seek": 58800, "start": 593.0, "end": 595.0, "text": " So we've integrated with Hex", "tokens": [50614, 407, 321, 600, 10919, 365, 634, 87, 50714], "temperature": 0.0, "avg_logprob": -0.10591786755017998, "compression_ratio": 1.6628787878787878, "no_speech_prob": 0.015966540202498436}, {"id": 119, "seek": 58800, "start": 595.0, "end": 598.0, "text": " So rather than just having a few hundred packages written in Gleam", "tokens": [50714, 407, 2831, 813, 445, 1419, 257, 1326, 3262, 17401, 3720, 294, 460, 306, 335, 50864], "temperature": 0.0, "avg_logprob": -0.10591786755017998, "compression_ratio": 1.6628787878787878, "no_speech_prob": 0.015966540202498436}, {"id": 120, "seek": 58800, "start": 598.0, "end": 602.0, "text": " We've also got the 20,000 packages that are written in Elixir and Erlang as well", "tokens": [50864, 492, 600, 611, 658, 264, 945, 11, 1360, 17401, 300, 366, 3720, 294, 2699, 970, 347, 293, 3300, 25241, 382, 731, 51064], "temperature": 0.0, "avg_logprob": -0.10591786755017998, "compression_ratio": 1.6628787878787878, "no_speech_prob": 0.015966540202498436}, {"id": 121, "seek": 58800, "start": 602.0, "end": 606.0, "text": " And then we've got a code formatter and a language server", "tokens": [51064, 400, 550, 321, 600, 658, 257, 3089, 1254, 1161, 293, 257, 2856, 7154, 51264], "temperature": 0.0, "avg_logprob": -0.10591786755017998, "compression_ratio": 1.6628787878787878, "no_speech_prob": 0.015966540202498436}, {"id": 122, "seek": 58800, "start": 606.0, "end": 608.0, "text": " And lots of goodies like that", "tokens": [51264, 400, 3195, 295, 44072, 411, 300, 51364], "temperature": 0.0, "avg_logprob": -0.10591786755017998, "compression_ratio": 1.6628787878787878, "no_speech_prob": 0.015966540202498436}, {"id": 123, "seek": 58800, "start": 610.0, "end": 616.0, "text": " So I said there's 20,000, a bit more than that packages on Hex", "tokens": [51464, 407, 286, 848, 456, 311, 945, 11, 1360, 11, 257, 857, 544, 813, 300, 17401, 322, 634, 87, 51764], "temperature": 0.0, "avg_logprob": -0.10591786755017998, "compression_ratio": 1.6628787878787878, "no_speech_prob": 0.015966540202498436}, {"id": 124, "seek": 61600, "start": 616.0, "end": 618.0, "text": " On the package manager", "tokens": [50364, 1282, 264, 7372, 6598, 50464], "temperature": 0.0, "avg_logprob": -0.062000639298382926, "compression_ratio": 1.656, "no_speech_prob": 0.10865338146686554}, {"id": 125, "seek": 61600, "start": 618.0, "end": 622.0, "text": " And about 200, a bit more than 200 of them are Gleam", "tokens": [50464, 400, 466, 2331, 11, 257, 857, 544, 813, 2331, 295, 552, 366, 460, 306, 335, 50664], "temperature": 0.0, "avg_logprob": -0.062000639298382926, "compression_ratio": 1.656, "no_speech_prob": 0.10865338146686554}, {"id": 126, "seek": 61600, "start": 622.0, "end": 625.0, "text": " That makes it extremely difficult to find anything written in Gleam", "tokens": [50664, 663, 1669, 309, 4664, 2252, 281, 915, 1340, 3720, 294, 460, 306, 335, 50814], "temperature": 0.0, "avg_logprob": -0.062000639298382926, "compression_ratio": 1.656, "no_speech_prob": 0.10865338146686554}, {"id": 127, "seek": 61600, "start": 625.0, "end": 627.0, "text": " If you want to make a Gleam project", "tokens": [50814, 759, 291, 528, 281, 652, 257, 460, 306, 335, 1716, 50914], "temperature": 0.0, "avg_logprob": -0.062000639298382926, "compression_ratio": 1.656, "no_speech_prob": 0.10865338146686554}, {"id": 128, "seek": 61600, "start": 627.0, "end": 631.0, "text": " So after a while we made the Gleam package index", "tokens": [50914, 407, 934, 257, 1339, 321, 1027, 264, 460, 306, 335, 7372, 8186, 51114], "temperature": 0.0, "avg_logprob": -0.062000639298382926, "compression_ratio": 1.656, "no_speech_prob": 0.10865338146686554}, {"id": 129, "seek": 61600, "start": 631.0, "end": 633.0, "text": " And what that is, that's a little window", "tokens": [51114, 400, 437, 300, 307, 11, 300, 311, 257, 707, 4910, 51214], "temperature": 0.0, "avg_logprob": -0.062000639298382926, "compression_ratio": 1.656, "no_speech_prob": 0.10865338146686554}, {"id": 130, "seek": 61600, "start": 633.0, "end": 635.0, "text": " Just a little view that looks into Hex", "tokens": [51214, 1449, 257, 707, 1910, 300, 1542, 666, 634, 87, 51314], "temperature": 0.0, "avg_logprob": -0.062000639298382926, "compression_ratio": 1.656, "no_speech_prob": 0.10865338146686554}, {"id": 131, "seek": 61600, "start": 635.0, "end": 639.0, "text": " And allows you to see just the ones that are Gleam", "tokens": [51314, 400, 4045, 291, 281, 536, 445, 264, 2306, 300, 366, 460, 306, 335, 51514], "temperature": 0.0, "avg_logprob": -0.062000639298382926, "compression_ratio": 1.656, "no_speech_prob": 0.10865338146686554}, {"id": 132, "seek": 61600, "start": 639.0, "end": 644.0, "text": " So if you want to find a library for HTML in this case", "tokens": [51514, 407, 498, 291, 528, 281, 915, 257, 6405, 337, 17995, 294, 341, 1389, 51764], "temperature": 0.0, "avg_logprob": -0.062000639298382926, "compression_ratio": 1.656, "no_speech_prob": 0.10865338146686554}, {"id": 133, "seek": 64400, "start": 644.0, "end": 646.0, "text": " You can type in HTML", "tokens": [50364, 509, 393, 2010, 294, 17995, 50464], "temperature": 0.0, "avg_logprob": -0.13798099948513892, "compression_ratio": 1.7934782608695652, "no_speech_prob": 0.024798646569252014}, {"id": 134, "seek": 64400, "start": 646.0, "end": 650.0, "text": " I didn't, I didn't, you're making, we'll talk about that later", "tokens": [50464, 286, 994, 380, 11, 286, 994, 380, 11, 291, 434, 1455, 11, 321, 603, 751, 466, 300, 1780, 50664], "temperature": 0.0, "avg_logprob": -0.13798099948513892, "compression_ratio": 1.7934782608695652, "no_speech_prob": 0.024798646569252014}, {"id": 135, "seek": 64400, "start": 650.0, "end": 654.0, "text": " Anyway, and it will give you elicit packages that have the word HTML", "tokens": [50664, 5684, 11, 293, 309, 486, 976, 291, 806, 8876, 17401, 300, 362, 264, 1349, 17995, 50864], "temperature": 0.0, "avg_logprob": -0.13798099948513892, "compression_ratio": 1.7934782608695652, "no_speech_prob": 0.024798646569252014}, {"id": 136, "seek": 64400, "start": 654.0, "end": 656.0, "text": " In the description or the name", "tokens": [50864, 682, 264, 3855, 420, 264, 1315, 50964], "temperature": 0.0, "avg_logprob": -0.13798099948513892, "compression_ratio": 1.7934782608695652, "no_speech_prob": 0.024798646569252014}, {"id": 137, "seek": 64400, "start": 656.0, "end": 660.0, "text": " That somebody's library does not have HTML in the name or the description", "tokens": [50964, 663, 2618, 311, 6405, 775, 406, 362, 17995, 294, 264, 1315, 420, 264, 3855, 51164], "temperature": 0.0, "avg_logprob": -0.13798099948513892, "compression_ratio": 1.7934782608695652, "no_speech_prob": 0.024798646569252014}, {"id": 138, "seek": 64400, "start": 660.0, "end": 664.0, "text": " And then if you find something suitable you can use that in your project", "tokens": [51164, 400, 550, 498, 291, 915, 746, 12873, 291, 393, 764, 300, 294, 428, 1716, 51364], "temperature": 0.0, "avg_logprob": -0.13798099948513892, "compression_ratio": 1.7934782608695652, "no_speech_prob": 0.024798646569252014}, {"id": 139, "seek": 64400, "start": 664.0, "end": 667.0, "text": " And if you don't then you can then make a decision about", "tokens": [51364, 400, 498, 291, 500, 380, 550, 291, 393, 550, 652, 257, 3537, 466, 51514], "temperature": 0.0, "avg_logprob": -0.13798099948513892, "compression_ratio": 1.7934782608695652, "no_speech_prob": 0.024798646569252014}, {"id": 140, "seek": 64400, "start": 667.0, "end": 669.0, "text": " Whether you want to perhaps make something new", "tokens": [51514, 8503, 291, 528, 281, 4317, 652, 746, 777, 51614], "temperature": 0.0, "avg_logprob": -0.13798099948513892, "compression_ratio": 1.7934782608695652, "no_speech_prob": 0.024798646569252014}, {"id": 141, "seek": 64400, "start": 669.0, "end": 672.0, "text": " Or if you want to pull something in from the wider ecosystem", "tokens": [51614, 1610, 498, 291, 528, 281, 2235, 746, 294, 490, 264, 11842, 11311, 51764], "temperature": 0.0, "avg_logprob": -0.13798099948513892, "compression_ratio": 1.7934782608695652, "no_speech_prob": 0.024798646569252014}, {"id": 142, "seek": 67400, "start": 675.0, "end": 679.0, "text": " Internet points, everybody loves internet points", "tokens": [50414, 7703, 2793, 11, 2201, 6752, 4705, 2793, 50614], "temperature": 0.0, "avg_logprob": -0.10747356058281159, "compression_ratio": 1.65, "no_speech_prob": 0.07503271102905273}, {"id": 143, "seek": 67400, "start": 679.0, "end": 683.0, "text": " So I know that Stiles on GitHub mean absolutely nothing", "tokens": [50614, 407, 286, 458, 300, 745, 4680, 322, 23331, 914, 3122, 1825, 50814], "temperature": 0.0, "avg_logprob": -0.10747356058281159, "compression_ratio": 1.65, "no_speech_prob": 0.07503271102905273}, {"id": 144, "seek": 67400, "start": 683.0, "end": 686.0, "text": " But it's been really uplifting and really wonderful", "tokens": [50814, 583, 309, 311, 668, 534, 493, 34724, 293, 534, 3715, 50964], "temperature": 0.0, "avg_logprob": -0.10747356058281159, "compression_ratio": 1.65, "no_speech_prob": 0.07503271102905273}, {"id": 145, "seek": 67400, "start": 686.0, "end": 690.0, "text": " And I feel like a really good sign that loads of people have", "tokens": [50964, 400, 286, 841, 411, 257, 534, 665, 1465, 300, 12668, 295, 561, 362, 51164], "temperature": 0.0, "avg_logprob": -0.10747356058281159, "compression_ratio": 1.65, "no_speech_prob": 0.07503271102905273}, {"id": 146, "seek": 67400, "start": 690.0, "end": 693.0, "text": " Have taken that two seconds to say, yeah this seems right", "tokens": [51164, 3560, 2726, 300, 732, 3949, 281, 584, 11, 1338, 341, 2544, 558, 51314], "temperature": 0.0, "avg_logprob": -0.10747356058281159, "compression_ratio": 1.65, "no_speech_prob": 0.07503271102905273}, {"id": 147, "seek": 67400, "start": 693.0, "end": 695.0, "text": " This is kind of cool", "tokens": [51314, 639, 307, 733, 295, 1627, 51414], "temperature": 0.0, "avg_logprob": -0.10747356058281159, "compression_ratio": 1.65, "no_speech_prob": 0.07503271102905273}, {"id": 148, "seek": 67400, "start": 695.0, "end": 698.0, "text": " I've been doing this for an awful long time", "tokens": [51414, 286, 600, 668, 884, 341, 337, 364, 11232, 938, 565, 51564], "temperature": 0.0, "avg_logprob": -0.10747356058281159, "compression_ratio": 1.65, "no_speech_prob": 0.07503271102905273}, {"id": 149, "seek": 67400, "start": 698.0, "end": 700.0, "text": " And I think I probably would have stopped by now", "tokens": [51564, 400, 286, 519, 286, 1391, 576, 362, 5936, 538, 586, 51664], "temperature": 0.0, "avg_logprob": -0.10747356058281159, "compression_ratio": 1.65, "no_speech_prob": 0.07503271102905273}, {"id": 150, "seek": 67400, "start": 700.0, "end": 702.0, "text": " If it wasn't for loads of lovely people", "tokens": [51664, 759, 309, 2067, 380, 337, 12668, 295, 7496, 561, 51764], "temperature": 0.0, "avg_logprob": -0.10747356058281159, "compression_ratio": 1.65, "no_speech_prob": 0.07503271102905273}, {"id": 151, "seek": 70200, "start": 702.0, "end": 705.0, "text": " Sharing their support in some small way", "tokens": [50364, 49060, 641, 1406, 294, 512, 1359, 636, 50514], "temperature": 0.0, "avg_logprob": -0.10836006164550781, "compression_ratio": 1.6013513513513513, "no_speech_prob": 0.03559771925210953}, {"id": 152, "seek": 70200, "start": 705.0, "end": 708.0, "text": " Whether it be a Stiles on GitHub or a kind message on Discord", "tokens": [50514, 8503, 309, 312, 257, 745, 4680, 322, 23331, 420, 257, 733, 3636, 322, 32623, 50664], "temperature": 0.0, "avg_logprob": -0.10836006164550781, "compression_ratio": 1.6013513513513513, "no_speech_prob": 0.03559771925210953}, {"id": 153, "seek": 70200, "start": 708.0, "end": 711.0, "text": " Or absolutely loads of you turning up into this room today", "tokens": [50664, 1610, 3122, 12668, 295, 291, 6246, 493, 666, 341, 1808, 965, 50814], "temperature": 0.0, "avg_logprob": -0.10836006164550781, "compression_ratio": 1.6013513513513513, "no_speech_prob": 0.03559771925210953}, {"id": 154, "seek": 70200, "start": 711.0, "end": 716.0, "text": " And so it's been absolutely lovely to see that line go up and up and up", "tokens": [50814, 400, 370, 309, 311, 668, 3122, 7496, 281, 536, 300, 1622, 352, 493, 293, 493, 293, 493, 51064], "temperature": 0.0, "avg_logprob": -0.10836006164550781, "compression_ratio": 1.6013513513513513, "no_speech_prob": 0.03559771925210953}, {"id": 155, "seek": 70200, "start": 716.0, "end": 721.0, "text": " And I find it wild, I've plotted it here against two quite similar languages", "tokens": [51064, 400, 286, 915, 309, 4868, 11, 286, 600, 43288, 309, 510, 1970, 732, 1596, 2531, 8650, 51314], "temperature": 0.0, "avg_logprob": -0.10836006164550781, "compression_ratio": 1.6013513513513513, "no_speech_prob": 0.03559771925210953}, {"id": 156, "seek": 70200, "start": 721.0, "end": 723.0, "text": " Microsoft's F-Sharp and O'Cammill", "tokens": [51314, 8116, 311, 479, 12, 50, 5854, 79, 293, 422, 6, 34, 5136, 373, 51414], "temperature": 0.0, "avg_logprob": -0.10836006164550781, "compression_ratio": 1.6013513513513513, "no_speech_prob": 0.03559771925210953}, {"id": 157, "seek": 70200, "start": 723.0, "end": 726.0, "text": " And at some point in the last year or two", "tokens": [51414, 400, 412, 512, 935, 294, 264, 1036, 1064, 420, 732, 51564], "temperature": 0.0, "avg_logprob": -0.10836006164550781, "compression_ratio": 1.6013513513513513, "no_speech_prob": 0.03559771925210953}, {"id": 158, "seek": 70200, "start": 726.0, "end": 729.0, "text": " We've ever taken both of them in terms of number of stars", "tokens": [51564, 492, 600, 1562, 2726, 1293, 295, 552, 294, 2115, 295, 1230, 295, 6105, 51714], "temperature": 0.0, "avg_logprob": -0.10836006164550781, "compression_ratio": 1.6013513513513513, "no_speech_prob": 0.03559771925210953}, {"id": 159, "seek": 70200, "start": 729.0, "end": 731.0, "text": " Which is absolutely incredible", "tokens": [51714, 3013, 307, 3122, 4651, 51814], "temperature": 0.0, "avg_logprob": -0.10836006164550781, "compression_ratio": 1.6013513513513513, "no_speech_prob": 0.03559771925210953}, {"id": 160, "seek": 73100, "start": 731.0, "end": 733.0, "text": " I'm really excited about ML types", "tokens": [50364, 286, 478, 534, 2919, 466, 21601, 3467, 50464], "temperature": 0.0, "avg_logprob": -0.13637703115289862, "compression_ratio": 1.6395348837209303, "no_speech_prob": 0.05185398459434509}, {"id": 161, "seek": 73100, "start": 733.0, "end": 735.0, "text": " And also people really love the Beam I think", "tokens": [50464, 400, 611, 561, 534, 959, 264, 40916, 286, 519, 50564], "temperature": 0.0, "avg_logprob": -0.13637703115289862, "compression_ratio": 1.6395348837209303, "no_speech_prob": 0.05185398459434509}, {"id": 162, "seek": 73100, "start": 735.0, "end": 738.0, "text": " So this is a really good sign for the future of the Beam", "tokens": [50564, 407, 341, 307, 257, 534, 665, 1465, 337, 264, 2027, 295, 264, 40916, 50714], "temperature": 0.0, "avg_logprob": -0.13637703115289862, "compression_ratio": 1.6395348837209303, "no_speech_prob": 0.05185398459434509}, {"id": 163, "seek": 73100, "start": 739.0, "end": 741.0, "text": " What else have we got?", "tokens": [50764, 708, 1646, 362, 321, 658, 30, 50864], "temperature": 0.0, "avg_logprob": -0.13637703115289862, "compression_ratio": 1.6395348837209303, "no_speech_prob": 0.05185398459434509}, {"id": 164, "seek": 73100, "start": 741.0, "end": 743.0, "text": " Has anyone heard of Exism? Anyone a fan?", "tokens": [50864, 8646, 2878, 2198, 295, 2111, 1434, 30, 14643, 257, 3429, 30, 50964], "temperature": 0.0, "avg_logprob": -0.13637703115289862, "compression_ratio": 1.6395348837209303, "no_speech_prob": 0.05185398459434509}, {"id": 165, "seek": 73100, "start": 743.0, "end": 746.0, "text": " Fantastic, for those who haven't, it's your lucky day", "tokens": [50964, 21320, 11, 337, 729, 567, 2378, 380, 11, 309, 311, 428, 6356, 786, 51114], "temperature": 0.0, "avg_logprob": -0.13637703115289862, "compression_ratio": 1.6395348837209303, "no_speech_prob": 0.05185398459434509}, {"id": 166, "seek": 73100, "start": 746.0, "end": 752.0, "text": " This is a really wonderful website and project", "tokens": [51114, 639, 307, 257, 534, 3715, 3144, 293, 1716, 51414], "temperature": 0.0, "avg_logprob": -0.13637703115289862, "compression_ratio": 1.6395348837209303, "no_speech_prob": 0.05185398459434509}, {"id": 167, "seek": 73100, "start": 752.0, "end": 754.0, "text": " Where you can go to learn new programming languages", "tokens": [51414, 2305, 291, 393, 352, 281, 1466, 777, 9410, 8650, 51514], "temperature": 0.0, "avg_logprob": -0.13637703115289862, "compression_ratio": 1.6395348837209303, "no_speech_prob": 0.05185398459434509}, {"id": 168, "seek": 73100, "start": 754.0, "end": 757.0, "text": " And they've got tens and tens and tens of different languages on there", "tokens": [51514, 400, 436, 600, 658, 10688, 293, 10688, 293, 10688, 295, 819, 8650, 322, 456, 51664], "temperature": 0.0, "avg_logprob": -0.13637703115289862, "compression_ratio": 1.6395348837209303, "no_speech_prob": 0.05185398459434509}, {"id": 169, "seek": 75700, "start": 757.0, "end": 762.0, "text": " And for a few years we've had a Gleam track", "tokens": [50364, 400, 337, 257, 1326, 924, 321, 600, 632, 257, 460, 306, 335, 2837, 50614], "temperature": 0.0, "avg_logprob": -0.09894185393821192, "compression_ratio": 1.7406143344709897, "no_speech_prob": 0.13969823718070984}, {"id": 170, "seek": 75700, "start": 762.0, "end": 765.0, "text": " And they give you an exercise, some instructions", "tokens": [50614, 400, 436, 976, 291, 364, 5380, 11, 512, 9415, 50764], "temperature": 0.0, "avg_logprob": -0.09894185393821192, "compression_ratio": 1.7406143344709897, "no_speech_prob": 0.13969823718070984}, {"id": 171, "seek": 75700, "start": 765.0, "end": 768.0, "text": " Maybe some hints, and then they give you a series of tests", "tokens": [50764, 2704, 512, 27271, 11, 293, 550, 436, 976, 291, 257, 2638, 295, 6921, 50914], "temperature": 0.0, "avg_logprob": -0.09894185393821192, "compression_ratio": 1.7406143344709897, "no_speech_prob": 0.13969823718070984}, {"id": 172, "seek": 75700, "start": 768.0, "end": 770.0, "text": " And you can solve it there in your browser", "tokens": [50914, 400, 291, 393, 5039, 309, 456, 294, 428, 11185, 51014], "temperature": 0.0, "avg_logprob": -0.09894185393821192, "compression_ratio": 1.7406143344709897, "no_speech_prob": 0.13969823718070984}, {"id": 173, "seek": 75700, "start": 770.0, "end": 773.0, "text": " Or you can use the command line and download it and use your favourite editor", "tokens": [51014, 1610, 291, 393, 764, 264, 5622, 1622, 293, 5484, 309, 293, 764, 428, 10696, 9839, 51164], "temperature": 0.0, "avg_logprob": -0.09894185393821192, "compression_ratio": 1.7406143344709897, "no_speech_prob": 0.13969823718070984}, {"id": 174, "seek": 75700, "start": 773.0, "end": 775.0, "text": " And then when you're happy with your solution", "tokens": [51164, 400, 550, 562, 291, 434, 2055, 365, 428, 3827, 51264], "temperature": 0.0, "avg_logprob": -0.09894185393821192, "compression_ratio": 1.7406143344709897, "no_speech_prob": 0.13969823718070984}, {"id": 175, "seek": 75700, "start": 775.0, "end": 778.0, "text": " You can submit it off and they do a bunch of automatic grading", "tokens": [51264, 509, 393, 10315, 309, 766, 293, 436, 360, 257, 3840, 295, 12509, 35540, 51414], "temperature": 0.0, "avg_logprob": -0.09894185393821192, "compression_ratio": 1.7406143344709897, "no_speech_prob": 0.13969823718070984}, {"id": 176, "seek": 75700, "start": 778.0, "end": 782.0, "text": " So they've gone some tests and they might do a bit of static analysis", "tokens": [51414, 407, 436, 600, 2780, 512, 6921, 293, 436, 1062, 360, 257, 857, 295, 13437, 5215, 51614], "temperature": 0.0, "avg_logprob": -0.09894185393821192, "compression_ratio": 1.7406143344709897, "no_speech_prob": 0.13969823718070984}, {"id": 177, "seek": 75700, "start": 782.0, "end": 784.0, "text": " Like oh you've done this, maybe you didn't want to do that", "tokens": [51614, 1743, 1954, 291, 600, 1096, 341, 11, 1310, 291, 994, 380, 528, 281, 360, 300, 51714], "temperature": 0.0, "avg_logprob": -0.09894185393821192, "compression_ratio": 1.7406143344709897, "no_speech_prob": 0.13969823718070984}, {"id": 178, "seek": 78400, "start": 785.0, "end": 788.0, "text": " And then if you're feeling super brave, which is where the real value comes from", "tokens": [50414, 400, 550, 498, 291, 434, 2633, 1687, 12653, 11, 597, 307, 689, 264, 957, 2158, 1487, 490, 50564], "temperature": 0.0, "avg_logprob": -0.09009469758479967, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.0132265230640769}, {"id": 179, "seek": 78400, "start": 788.0, "end": 793.0, "text": " You can submit it to get some mentoring from an experienced programmer", "tokens": [50564, 509, 393, 10315, 309, 281, 483, 512, 30257, 490, 364, 6751, 32116, 50814], "temperature": 0.0, "avg_logprob": -0.09009469758479967, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.0132265230640769}, {"id": 180, "seek": 78400, "start": 793.0, "end": 796.0, "text": " There's loads of lovely people who are just sitting there", "tokens": [50814, 821, 311, 12668, 295, 7496, 561, 567, 366, 445, 3798, 456, 50964], "temperature": 0.0, "avg_logprob": -0.09009469758479967, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.0132265230640769}, {"id": 181, "seek": 78400, "start": 796.0, "end": 801.0, "text": " Helping strangers improve their Erlang or Java or Gleam or whatever", "tokens": [50964, 6128, 3381, 22724, 3470, 641, 3300, 25241, 420, 10745, 420, 460, 306, 335, 420, 2035, 51214], "temperature": 0.0, "avg_logprob": -0.09009469758479967, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.0132265230640769}, {"id": 182, "seek": 78400, "start": 801.0, "end": 803.0, "text": " There's a really wonderful project", "tokens": [51214, 821, 311, 257, 534, 3715, 1716, 51314], "temperature": 0.0, "avg_logprob": -0.09009469758479967, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.0132265230640769}, {"id": 183, "seek": 78400, "start": 803.0, "end": 808.0, "text": " And last year, with some help from the wonderful Erlang Ecosystem Foundation", "tokens": [51314, 400, 1036, 1064, 11, 365, 512, 854, 490, 264, 3715, 3300, 25241, 462, 6877, 9321, 10335, 51564], "temperature": 0.0, "avg_logprob": -0.09009469758479967, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.0132265230640769}, {"id": 184, "seek": 78400, "start": 808.0, "end": 810.0, "text": " Who sponsored this work", "tokens": [51564, 2102, 16621, 341, 589, 51664], "temperature": 0.0, "avg_logprob": -0.09009469758479967, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.0132265230640769}, {"id": 185, "seek": 78400, "start": 810.0, "end": 813.0, "text": " We went from not just having a set of challenges", "tokens": [51664, 492, 1437, 490, 406, 445, 1419, 257, 992, 295, 4759, 51814], "temperature": 0.0, "avg_logprob": -0.09009469758479967, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.0132265230640769}, {"id": 186, "seek": 81300, "start": 813.0, "end": 816.0, "text": " That you can use to practice your Gleam, but an entire course", "tokens": [50364, 663, 291, 393, 764, 281, 3124, 428, 460, 306, 335, 11, 457, 364, 2302, 1164, 50514], "temperature": 0.0, "avg_logprob": -0.08776259422302246, "compression_ratio": 1.7808219178082192, "no_speech_prob": 0.05469686910510063}, {"id": 187, "seek": 81300, "start": 816.0, "end": 819.0, "text": " So you can start by not really knowing any Gleam", "tokens": [50514, 407, 291, 393, 722, 538, 406, 534, 5276, 604, 460, 306, 335, 50664], "temperature": 0.0, "avg_logprob": -0.08776259422302246, "compression_ratio": 1.7808219178082192, "no_speech_prob": 0.05469686910510063}, {"id": 188, "seek": 81300, "start": 819.0, "end": 821.0, "text": " And by going through this whole thing", "tokens": [50664, 400, 538, 516, 807, 341, 1379, 551, 50764], "temperature": 0.0, "avg_logprob": -0.08776259422302246, "compression_ratio": 1.7808219178082192, "no_speech_prob": 0.05469686910510063}, {"id": 189, "seek": 81300, "start": 821.0, "end": 824.0, "text": " You can be taught individually all the different concepts", "tokens": [50764, 509, 393, 312, 5928, 16652, 439, 264, 819, 10392, 50914], "temperature": 0.0, "avg_logprob": -0.08776259422302246, "compression_ratio": 1.7808219178082192, "no_speech_prob": 0.05469686910510063}, {"id": 190, "seek": 81300, "start": 824.0, "end": 827.0, "text": " And so they give you a concept", "tokens": [50914, 400, 370, 436, 976, 291, 257, 3410, 51064], "temperature": 0.0, "avg_logprob": -0.08776259422302246, "compression_ratio": 1.7808219178082192, "no_speech_prob": 0.05469686910510063}, {"id": 191, "seek": 81300, "start": 827.0, "end": 830.0, "text": " Then they give you a little challenge that's focused on just that concept", "tokens": [51064, 1396, 436, 976, 291, 257, 707, 3430, 300, 311, 5178, 322, 445, 300, 3410, 51214], "temperature": 0.0, "avg_logprob": -0.08776259422302246, "compression_ratio": 1.7808219178082192, "no_speech_prob": 0.05469686910510063}, {"id": 192, "seek": 81300, "start": 830.0, "end": 835.0, "text": " And then they will unlock all of the exercises that they think you should be able to do now", "tokens": [51214, 400, 550, 436, 486, 11634, 439, 295, 264, 11900, 300, 436, 519, 291, 820, 312, 1075, 281, 360, 586, 51464], "temperature": 0.0, "avg_logprob": -0.08776259422302246, "compression_ratio": 1.7808219178082192, "no_speech_prob": 0.05469686910510063}, {"id": 193, "seek": 81300, "start": 835.0, "end": 837.0, "text": " Using those skills", "tokens": [51464, 11142, 729, 3942, 51564], "temperature": 0.0, "avg_logprob": -0.08776259422302246, "compression_ratio": 1.7808219178082192, "no_speech_prob": 0.05469686910510063}, {"id": 194, "seek": 81300, "start": 837.0, "end": 840.0, "text": " So it's a really fantastic resource and it's absolutely amazing that it's free", "tokens": [51564, 407, 309, 311, 257, 534, 5456, 7684, 293, 309, 311, 3122, 2243, 300, 309, 311, 1737, 51714], "temperature": 0.0, "avg_logprob": -0.08776259422302246, "compression_ratio": 1.7808219178082192, "no_speech_prob": 0.05469686910510063}, {"id": 195, "seek": 81300, "start": 840.0, "end": 842.0, "text": " So do check it out", "tokens": [51714, 407, 360, 1520, 309, 484, 51814], "temperature": 0.0, "avg_logprob": -0.08776259422302246, "compression_ratio": 1.7808219178082192, "no_speech_prob": 0.05469686910510063}, {"id": 196, "seek": 84300, "start": 844.0, "end": 847.0, "text": " And it's been really well", "tokens": [50414, 400, 309, 311, 668, 534, 731, 50564], "temperature": 0.0, "avg_logprob": -0.13926092459231007, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.018485313281416893}, {"id": 197, "seek": 84300, "start": 847.0, "end": 851.0, "text": " People have really taken to it this course", "tokens": [50564, 3432, 362, 534, 2726, 281, 309, 341, 1164, 50764], "temperature": 0.0, "avg_logprob": -0.13926092459231007, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.018485313281416893}, {"id": 198, "seek": 84300, "start": 851.0, "end": 853.0, "text": " So you can see in the middle", "tokens": [50764, 407, 291, 393, 536, 294, 264, 2808, 50864], "temperature": 0.0, "avg_logprob": -0.13926092459231007, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.018485313281416893}, {"id": 199, "seek": 84300, "start": 853.0, "end": 857.0, "text": " Can you see where we launched the new syllabus?", "tokens": [50864, 1664, 291, 536, 689, 321, 8730, 264, 777, 48077, 30, 51064], "temperature": 0.0, "avg_logprob": -0.13926092459231007, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.018485313281416893}, {"id": 200, "seek": 84300, "start": 857.0, "end": 860.0, "text": " Suddenly the uptake went absolutely skyward, which is fantastic", "tokens": [51064, 21194, 264, 493, 27612, 1437, 3122, 5443, 1007, 11, 597, 307, 5456, 51214], "temperature": 0.0, "avg_logprob": -0.13926092459231007, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.018485313281416893}, {"id": 201, "seek": 84300, "start": 860.0, "end": 863.0, "text": " And this is not the number of people on the course", "tokens": [51214, 400, 341, 307, 406, 264, 1230, 295, 561, 322, 264, 1164, 51364], "temperature": 0.0, "avg_logprob": -0.13926092459231007, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.018485313281416893}, {"id": 202, "seek": 84300, "start": 863.0, "end": 866.0, "text": " There are about a thousand, just under a thousand", "tokens": [51364, 821, 366, 466, 257, 4714, 11, 445, 833, 257, 4714, 51514], "temperature": 0.0, "avg_logprob": -0.13926092459231007, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.018485313281416893}, {"id": 203, "seek": 84300, "start": 866.0, "end": 869.0, "text": " This is how many solutions people are submitting", "tokens": [51514, 639, 307, 577, 867, 6547, 561, 366, 31836, 51664], "temperature": 0.0, "avg_logprob": -0.13926092459231007, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.018485313281416893}, {"id": 204, "seek": 84300, "start": 869.0, "end": 871.0, "text": " So this is actually the activity", "tokens": [51664, 407, 341, 307, 767, 264, 5191, 51764], "temperature": 0.0, "avg_logprob": -0.13926092459231007, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.018485313281416893}, {"id": 205, "seek": 87100, "start": 871.0, "end": 873.0, "text": " It's absolutely wonderful", "tokens": [50364, 467, 311, 3122, 3715, 50464], "temperature": 0.0, "avg_logprob": -0.16282369802286337, "compression_ratio": 1.5132743362831858, "no_speech_prob": 0.01821696013212204}, {"id": 206, "seek": 87100, "start": 873.0, "end": 876.0, "text": " 30,000 submissions", "tokens": [50464, 2217, 11, 1360, 40429, 50614], "temperature": 0.0, "avg_logprob": -0.16282369802286337, "compression_ratio": 1.5132743362831858, "no_speech_prob": 0.01821696013212204}, {"id": 207, "seek": 87100, "start": 876.0, "end": 879.0, "text": " Which is a lot of learning, a lot of wasted time", "tokens": [50614, 3013, 307, 257, 688, 295, 2539, 11, 257, 688, 295, 19496, 565, 50764], "temperature": 0.0, "avg_logprob": -0.16282369802286337, "compression_ratio": 1.5132743362831858, "no_speech_prob": 0.01821696013212204}, {"id": 208, "seek": 87100, "start": 879.0, "end": 881.0, "text": " Who knows?", "tokens": [50764, 2102, 3255, 30, 50864], "temperature": 0.0, "avg_logprob": -0.16282369802286337, "compression_ratio": 1.5132743362831858, "no_speech_prob": 0.01821696013212204}, {"id": 209, "seek": 87100, "start": 882.0, "end": 884.0, "text": " So Exism is really cool", "tokens": [50914, 407, 2111, 1434, 307, 534, 1627, 51014], "temperature": 0.0, "avg_logprob": -0.16282369802286337, "compression_ratio": 1.5132743362831858, "no_speech_prob": 0.01821696013212204}, {"id": 210, "seek": 87100, "start": 884.0, "end": 886.0, "text": " And I really like that idea of being taught", "tokens": [51014, 400, 286, 534, 411, 300, 1558, 295, 885, 5928, 51114], "temperature": 0.0, "avg_logprob": -0.16282369802286337, "compression_ratio": 1.5132743362831858, "no_speech_prob": 0.01821696013212204}, {"id": 211, "seek": 87100, "start": 886.0, "end": 890.0, "text": " The individual concepts in a way that enables you to get somewhere", "tokens": [51114, 440, 2609, 10392, 294, 257, 636, 300, 17077, 291, 281, 483, 4079, 51314], "temperature": 0.0, "avg_logprob": -0.16282369802286337, "compression_ratio": 1.5132743362831858, "no_speech_prob": 0.01821696013212204}, {"id": 212, "seek": 87100, "start": 890.0, "end": 892.0, "text": " And become productive", "tokens": [51314, 400, 1813, 13304, 51414], "temperature": 0.0, "avg_logprob": -0.16282369802286337, "compression_ratio": 1.5132743362831858, "no_speech_prob": 0.01821696013212204}, {"id": 213, "seek": 87100, "start": 892.0, "end": 894.0, "text": " And off the back of that", "tokens": [51414, 400, 766, 264, 646, 295, 300, 51514], "temperature": 0.0, "avg_logprob": -0.16282369802286337, "compression_ratio": 1.5132743362831858, "no_speech_prob": 0.01821696013212204}, {"id": 214, "seek": 87100, "start": 894.0, "end": 899.0, "text": " And also inspired by the wonderful tutorial that Go has", "tokens": [51514, 400, 611, 7547, 538, 264, 3715, 7073, 300, 1037, 575, 51764], "temperature": 0.0, "avg_logprob": -0.16282369802286337, "compression_ratio": 1.5132743362831858, "no_speech_prob": 0.01821696013212204}, {"id": 215, "seek": 89900, "start": 899.0, "end": 901.0, "text": " So we decided to take that idea of teaching the", "tokens": [50364, 407, 321, 3047, 281, 747, 300, 1558, 295, 4571, 264, 50464], "temperature": 0.0, "avg_logprob": -0.11234031357131638, "compression_ratio": 1.7516556291390728, "no_speech_prob": 0.05563236027956009}, {"id": 216, "seek": 89900, "start": 901.0, "end": 903.0, "text": " Breaking the language into concepts", "tokens": [50464, 36715, 264, 2856, 666, 10392, 50564], "temperature": 0.0, "avg_logprob": -0.11234031357131638, "compression_ratio": 1.7516556291390728, "no_speech_prob": 0.05563236027956009}, {"id": 217, "seek": 89900, "start": 903.0, "end": 905.0, "text": " And teaching them in an incremental fashion", "tokens": [50564, 400, 4571, 552, 294, 364, 35759, 6700, 50664], "temperature": 0.0, "avg_logprob": -0.11234031357131638, "compression_ratio": 1.7516556291390728, "no_speech_prob": 0.05563236027956009}, {"id": 218, "seek": 89900, "start": 905.0, "end": 908.0, "text": " Where each concept builds upon the last one", "tokens": [50664, 2305, 1184, 3410, 15182, 3564, 264, 1036, 472, 50814], "temperature": 0.0, "avg_logprob": -0.11234031357131638, "compression_ratio": 1.7516556291390728, "no_speech_prob": 0.05563236027956009}, {"id": 219, "seek": 89900, "start": 908.0, "end": 911.0, "text": " And distilled it, minus all the exercises", "tokens": [50814, 400, 1483, 6261, 309, 11, 3175, 439, 264, 11900, 50964], "temperature": 0.0, "avg_logprob": -0.11234031357131638, "compression_ratio": 1.7516556291390728, "no_speech_prob": 0.05563236027956009}, {"id": 220, "seek": 89900, "start": 911.0, "end": 914.0, "text": " Into a sort of whistle-stopped tour of Gleam", "tokens": [50964, 23373, 257, 1333, 295, 23470, 12, 13559, 3452, 3512, 295, 460, 306, 335, 51114], "temperature": 0.0, "avg_logprob": -0.11234031357131638, "compression_ratio": 1.7516556291390728, "no_speech_prob": 0.05563236027956009}, {"id": 221, "seek": 89900, "start": 914.0, "end": 916.0, "text": " So if you go to the Gleam website today", "tokens": [51114, 407, 498, 291, 352, 281, 264, 460, 306, 335, 3144, 965, 51214], "temperature": 0.0, "avg_logprob": -0.11234031357131638, "compression_ratio": 1.7516556291390728, "no_speech_prob": 0.05563236027956009}, {"id": 222, "seek": 89900, "start": 916.0, "end": 918.0, "text": " And at the very top there's that hero image", "tokens": [51214, 400, 412, 264, 588, 1192, 456, 311, 300, 5316, 3256, 51314], "temperature": 0.0, "avg_logprob": -0.11234031357131638, "compression_ratio": 1.7516556291390728, "no_speech_prob": 0.05563236027956009}, {"id": 223, "seek": 89900, "start": 918.0, "end": 920.0, "text": " That's got the tagline saying Gleam is great tour", "tokens": [51314, 663, 311, 658, 264, 6162, 1889, 1566, 460, 306, 335, 307, 869, 3512, 51414], "temperature": 0.0, "avg_logprob": -0.11234031357131638, "compression_ratio": 1.7516556291390728, "no_speech_prob": 0.05563236027956009}, {"id": 224, "seek": 89900, "start": 920.0, "end": 922.0, "text": " I don't think it says exactly that, but you get the idea", "tokens": [51414, 286, 500, 380, 519, 309, 1619, 2293, 300, 11, 457, 291, 483, 264, 1558, 51514], "temperature": 0.0, "avg_logprob": -0.11234031357131638, "compression_ratio": 1.7516556291390728, "no_speech_prob": 0.05563236027956009}, {"id": 225, "seek": 89900, "start": 922.0, "end": 924.0, "text": " And there's a big button that says", "tokens": [51514, 400, 456, 311, 257, 955, 2960, 300, 1619, 51614], "temperature": 0.0, "avg_logprob": -0.11234031357131638, "compression_ratio": 1.7516556291390728, "no_speech_prob": 0.05563236027956009}, {"id": 226, "seek": 89900, "start": 924.0, "end": 926.0, "text": " Get started or try it or something like that", "tokens": [51614, 3240, 1409, 420, 853, 309, 420, 746, 411, 300, 51714], "temperature": 0.0, "avg_logprob": -0.11234031357131638, "compression_ratio": 1.7516556291390728, "no_speech_prob": 0.05563236027956009}, {"id": 227, "seek": 92600, "start": 926.0, "end": 928.0, "text": " And if you do that it will point you straight", "tokens": [50364, 400, 498, 291, 360, 300, 309, 486, 935, 291, 2997, 50464], "temperature": 0.0, "avg_logprob": -0.11295850226219664, "compression_ratio": 1.7508417508417509, "no_speech_prob": 0.08318045735359192}, {"id": 228, "seek": 92600, "start": 928.0, "end": 930.0, "text": " It will point you straight onto that first lesson", "tokens": [50464, 467, 486, 935, 291, 2997, 3911, 300, 700, 6898, 50564], "temperature": 0.0, "avg_logprob": -0.11295850226219664, "compression_ratio": 1.7508417508417509, "no_speech_prob": 0.08318045735359192}, {"id": 229, "seek": 92600, "start": 930.0, "end": 932.0, "text": " And you can go from", "tokens": [50564, 400, 291, 393, 352, 490, 50664], "temperature": 0.0, "avg_logprob": -0.11295850226219664, "compression_ratio": 1.7508417508417509, "no_speech_prob": 0.08318045735359192}, {"id": 230, "seek": 92600, "start": 932.0, "end": 934.0, "text": " This looks kind of interesting", "tokens": [50664, 639, 1542, 733, 295, 1880, 50764], "temperature": 0.0, "avg_logprob": -0.11295850226219664, "compression_ratio": 1.7508417508417509, "no_speech_prob": 0.08318045735359192}, {"id": 231, "seek": 92600, "start": 934.0, "end": 935.0, "text": " Maybe I'll try it to", "tokens": [50764, 2704, 286, 603, 853, 309, 281, 50814], "temperature": 0.0, "avg_logprob": -0.11295850226219664, "compression_ratio": 1.7508417508417509, "no_speech_prob": 0.08318045735359192}, {"id": 232, "seek": 92600, "start": 935.0, "end": 937.0, "text": " Oh wow, I'm writing and learning Gleam", "tokens": [50814, 876, 6076, 11, 286, 478, 3579, 293, 2539, 460, 306, 335, 50914], "temperature": 0.0, "avg_logprob": -0.11295850226219664, "compression_ratio": 1.7508417508417509, "no_speech_prob": 0.08318045735359192}, {"id": 233, "seek": 92600, "start": 937.0, "end": 939.0, "text": " All in your browser without having to", "tokens": [50914, 1057, 294, 428, 11185, 1553, 1419, 281, 51014], "temperature": 0.0, "avg_logprob": -0.11295850226219664, "compression_ratio": 1.7508417508417509, "no_speech_prob": 0.08318045735359192}, {"id": 234, "seek": 92600, "start": 939.0, "end": 941.0, "text": " Work at how to install Erlang", "tokens": [51014, 6603, 412, 577, 281, 3625, 3300, 25241, 51114], "temperature": 0.0, "avg_logprob": -0.11295850226219664, "compression_ratio": 1.7508417508417509, "no_speech_prob": 0.08318045735359192}, {"id": 235, "seek": 92600, "start": 941.0, "end": 943.0, "text": " And realizing that App has an Alte Deck package", "tokens": [51114, 400, 16734, 300, 3132, 575, 364, 967, 975, 38196, 7372, 51214], "temperature": 0.0, "avg_logprob": -0.11295850226219664, "compression_ratio": 1.7508417508417509, "no_speech_prob": 0.08318045735359192}, {"id": 236, "seek": 92600, "start": 943.0, "end": 945.0, "text": " So you can't actually install it properly", "tokens": [51214, 407, 291, 393, 380, 767, 3625, 309, 6108, 51314], "temperature": 0.0, "avg_logprob": -0.11295850226219664, "compression_ratio": 1.7508417508417509, "no_speech_prob": 0.08318045735359192}, {"id": 237, "seek": 92600, "start": 945.0, "end": 947.0, "text": " And oh how do I install Rebar", "tokens": [51314, 400, 1954, 577, 360, 286, 3625, 1300, 5356, 51414], "temperature": 0.0, "avg_logprob": -0.11295850226219664, "compression_ratio": 1.7508417508417509, "no_speech_prob": 0.08318045735359192}, {"id": 238, "seek": 92600, "start": 947.0, "end": 949.0, "text": " And how do I do these things", "tokens": [51414, 400, 577, 360, 286, 360, 613, 721, 51514], "temperature": 0.0, "avg_logprob": -0.11295850226219664, "compression_ratio": 1.7508417508417509, "no_speech_prob": 0.08318045735359192}, {"id": 239, "seek": 92600, "start": 949.0, "end": 951.0, "text": " No, you just go straight in and you can start learning", "tokens": [51514, 883, 11, 291, 445, 352, 2997, 294, 293, 291, 393, 722, 2539, 51614], "temperature": 0.0, "avg_logprob": -0.11295850226219664, "compression_ratio": 1.7508417508417509, "no_speech_prob": 0.08318045735359192}, {"id": 240, "seek": 92600, "start": 951.0, "end": 954.0, "text": " So hopefully people from other ecosystems", "tokens": [51614, 407, 4696, 561, 490, 661, 32647, 51764], "temperature": 0.0, "avg_logprob": -0.11295850226219664, "compression_ratio": 1.7508417508417509, "no_speech_prob": 0.08318045735359192}, {"id": 241, "seek": 95400, "start": 954.0, "end": 956.0, "text": " Or people who are writing election Erlang", "tokens": [50364, 1610, 561, 567, 366, 3579, 6618, 3300, 25241, 50464], "temperature": 0.0, "avg_logprob": -0.14884744371686662, "compression_ratio": 1.5784753363228698, "no_speech_prob": 0.048548776656389236}, {"id": 242, "seek": 95400, "start": 956.0, "end": 958.0, "text": " Can turn up and go", "tokens": [50464, 1664, 1261, 493, 293, 352, 50564], "temperature": 0.0, "avg_logprob": -0.14884744371686662, "compression_ratio": 1.5784753363228698, "no_speech_prob": 0.048548776656389236}, {"id": 243, "seek": 95400, "start": 958.0, "end": 962.0, "text": " Oh I want to give this Gleam thing a try", "tokens": [50564, 876, 286, 528, 281, 976, 341, 460, 306, 335, 551, 257, 853, 50764], "temperature": 0.0, "avg_logprob": -0.14884744371686662, "compression_ratio": 1.5784753363228698, "no_speech_prob": 0.048548776656389236}, {"id": 244, "seek": 95400, "start": 962.0, "end": 964.0, "text": " And then very quickly", "tokens": [50764, 400, 550, 588, 2661, 50864], "temperature": 0.0, "avg_logprob": -0.14884744371686662, "compression_ratio": 1.5784753363228698, "no_speech_prob": 0.048548776656389236}, {"id": 245, "seek": 95400, "start": 964.0, "end": 967.0, "text": " Get whisked into being a Gleam", "tokens": [50864, 3240, 24485, 292, 666, 885, 257, 460, 306, 335, 51014], "temperature": 0.0, "avg_logprob": -0.14884744371686662, "compression_ratio": 1.5784753363228698, "no_speech_prob": 0.048548776656389236}, {"id": 246, "seek": 95400, "start": 967.0, "end": 968.0, "text": " They can be hooked", "tokens": [51014, 814, 393, 312, 20410, 51064], "temperature": 0.0, "avg_logprob": -0.14884744371686662, "compression_ratio": 1.5784753363228698, "no_speech_prob": 0.048548776656389236}, {"id": 247, "seek": 95400, "start": 968.0, "end": 970.0, "text": " They can start working on the beam", "tokens": [51064, 814, 393, 722, 1364, 322, 264, 14269, 51164], "temperature": 0.0, "avg_logprob": -0.14884744371686662, "compression_ratio": 1.5784753363228698, "no_speech_prob": 0.048548776656389236}, {"id": 248, "seek": 95400, "start": 971.0, "end": 974.0, "text": " And this comes because", "tokens": [51214, 400, 341, 1487, 570, 51364], "temperature": 0.0, "avg_logprob": -0.14884744371686662, "compression_ratio": 1.5784753363228698, "no_speech_prob": 0.048548776656389236}, {"id": 249, "seek": 95400, "start": 974.0, "end": 976.0, "text": " A, the compiler is written in Rust", "tokens": [51364, 316, 11, 264, 31958, 307, 3720, 294, 34952, 51464], "temperature": 0.0, "avg_logprob": -0.14884744371686662, "compression_ratio": 1.5784753363228698, "no_speech_prob": 0.048548776656389236}, {"id": 250, "seek": 95400, "start": 976.0, "end": 979.0, "text": " So if you have Rust you can compile to WebAssembly", "tokens": [51464, 407, 498, 291, 362, 34952, 291, 393, 31413, 281, 9573, 10884, 19160, 51614], "temperature": 0.0, "avg_logprob": -0.14884744371686662, "compression_ratio": 1.5784753363228698, "no_speech_prob": 0.048548776656389236}, {"id": 251, "seek": 95400, "start": 979.0, "end": 981.0, "text": " WebAssembly is a very cool project", "tokens": [51614, 9573, 10884, 19160, 307, 257, 588, 1627, 1716, 51714], "temperature": 0.0, "avg_logprob": -0.14884744371686662, "compression_ratio": 1.5784753363228698, "no_speech_prob": 0.048548776656389236}, {"id": 252, "seek": 98100, "start": 982.0, "end": 984.0, "text": " And we can also compile to JavaScript", "tokens": [50414, 400, 321, 393, 611, 31413, 281, 15778, 50514], "temperature": 0.0, "avg_logprob": -0.07542280865530683, "compression_ratio": 1.7411764705882353, "no_speech_prob": 0.10932622104883194}, {"id": 253, "seek": 98100, "start": 984.0, "end": 986.0, "text": " So if you have those two things together", "tokens": [50514, 407, 498, 291, 362, 729, 732, 721, 1214, 50614], "temperature": 0.0, "avg_logprob": -0.07542280865530683, "compression_ratio": 1.7411764705882353, "no_speech_prob": 0.10932622104883194}, {"id": 254, "seek": 98100, "start": 986.0, "end": 988.0, "text": " You can run the compiler inside the browser", "tokens": [50614, 509, 393, 1190, 264, 31958, 1854, 264, 11185, 50714], "temperature": 0.0, "avg_logprob": -0.07542280865530683, "compression_ratio": 1.7411764705882353, "no_speech_prob": 0.10932622104883194}, {"id": 255, "seek": 98100, "start": 988.0, "end": 990.0, "text": " And you can also execute the code inside the browser", "tokens": [50714, 400, 291, 393, 611, 14483, 264, 3089, 1854, 264, 11185, 50814], "temperature": 0.0, "avg_logprob": -0.07542280865530683, "compression_ratio": 1.7411764705882353, "no_speech_prob": 0.10932622104883194}, {"id": 256, "seek": 98100, "start": 990.0, "end": 992.0, "text": " So we don't have to run any servers", "tokens": [50814, 407, 321, 500, 380, 362, 281, 1190, 604, 15909, 50914], "temperature": 0.0, "avg_logprob": -0.07542280865530683, "compression_ratio": 1.7411764705882353, "no_speech_prob": 0.10932622104883194}, {"id": 257, "seek": 98100, "start": 992.0, "end": 994.0, "text": " So even I can afford this", "tokens": [50914, 407, 754, 286, 393, 6157, 341, 51014], "temperature": 0.0, "avg_logprob": -0.07542280865530683, "compression_ratio": 1.7411764705882353, "no_speech_prob": 0.10932622104883194}, {"id": 258, "seek": 98100, "start": 994.0, "end": 997.0, "text": " And we don't have to worry about any security stuff", "tokens": [51014, 400, 321, 500, 380, 362, 281, 3292, 466, 604, 3825, 1507, 51164], "temperature": 0.0, "avg_logprob": -0.07542280865530683, "compression_ratio": 1.7411764705882353, "no_speech_prob": 0.10932622104883194}, {"id": 259, "seek": 98100, "start": 997.0, "end": 999.0, "text": " Everything is just on the person's computer", "tokens": [51164, 5471, 307, 445, 322, 264, 954, 311, 3820, 51264], "temperature": 0.0, "avg_logprob": -0.07542280865530683, "compression_ratio": 1.7411764705882353, "no_speech_prob": 0.10932622104883194}, {"id": 260, "seek": 98100, "start": 999.0, "end": 1001.0, "text": " And it also means it's super fast", "tokens": [51264, 400, 309, 611, 1355, 309, 311, 1687, 2370, 51364], "temperature": 0.0, "avg_logprob": -0.07542280865530683, "compression_ratio": 1.7411764705882353, "no_speech_prob": 0.10932622104883194}, {"id": 261, "seek": 98100, "start": 1001.0, "end": 1004.0, "text": " You can get your feedback immediately", "tokens": [51364, 509, 393, 483, 428, 5824, 4258, 51514], "temperature": 0.0, "avg_logprob": -0.07542280865530683, "compression_ratio": 1.7411764705882353, "no_speech_prob": 0.10932622104883194}, {"id": 262, "seek": 98100, "start": 1007.0, "end": 1009.0, "text": " So Gleam present, I'm going a bit slow", "tokens": [51664, 407, 460, 306, 335, 1974, 11, 286, 478, 516, 257, 857, 2964, 51764], "temperature": 0.0, "avg_logprob": -0.07542280865530683, "compression_ratio": 1.7411764705882353, "no_speech_prob": 0.10932622104883194}, {"id": 263, "seek": 100900, "start": 1009.0, "end": 1011.0, "text": " I'm going to speed up a bit", "tokens": [50364, 286, 478, 516, 281, 3073, 493, 257, 857, 50464], "temperature": 0.0, "avg_logprob": -0.13958077607331454, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.25738000869750977}, {"id": 264, "seek": 100900, "start": 1011.0, "end": 1013.0, "text": " Where are we now?", "tokens": [50464, 2305, 366, 321, 586, 30, 50564], "temperature": 0.0, "avg_logprob": -0.13958077607331454, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.25738000869750977}, {"id": 265, "seek": 100900, "start": 1013.0, "end": 1016.0, "text": " I want to look at some projects in the community", "tokens": [50564, 286, 528, 281, 574, 412, 512, 4455, 294, 264, 1768, 50714], "temperature": 0.0, "avg_logprob": -0.13958077607331454, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.25738000869750977}, {"id": 266, "seek": 100900, "start": 1016.0, "end": 1017.0, "text": " That are really cool", "tokens": [50714, 663, 366, 534, 1627, 50764], "temperature": 0.0, "avg_logprob": -0.13958077607331454, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.25738000869750977}, {"id": 267, "seek": 100900, "start": 1017.0, "end": 1019.0, "text": " My original version of this", "tokens": [50764, 1222, 3380, 3037, 295, 341, 50864], "temperature": 0.0, "avg_logprob": -0.13958077607331454, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.25738000869750977}, {"id": 268, "seek": 100900, "start": 1019.0, "end": 1021.0, "text": " The talk ended up being about an hour and a half long", "tokens": [50864, 440, 751, 4590, 493, 885, 466, 364, 1773, 293, 257, 1922, 938, 50964], "temperature": 0.0, "avg_logprob": -0.13958077607331454, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.25738000869750977}, {"id": 269, "seek": 100900, "start": 1021.0, "end": 1023.0, "text": " So I've had to go loads out", "tokens": [50964, 407, 286, 600, 632, 281, 352, 12668, 484, 51064], "temperature": 0.0, "avg_logprob": -0.13958077607331454, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.25738000869750977}, {"id": 270, "seek": 100900, "start": 1023.0, "end": 1025.0, "text": " So if you're not mentioned, very sorry", "tokens": [51064, 407, 498, 291, 434, 406, 2835, 11, 588, 2597, 51164], "temperature": 0.0, "avg_logprob": -0.13958077607331454, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.25738000869750977}, {"id": 271, "seek": 100900, "start": 1025.0, "end": 1027.0, "text": " First thing I want to say is that", "tokens": [51164, 2386, 551, 286, 528, 281, 584, 307, 300, 51264], "temperature": 0.0, "avg_logprob": -0.13958077607331454, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.25738000869750977}, {"id": 272, "seek": 100900, "start": 1027.0, "end": 1029.0, "text": " The Gleam Discord is wonderful", "tokens": [51264, 440, 460, 306, 335, 32623, 307, 3715, 51364], "temperature": 0.0, "avg_logprob": -0.13958077607331454, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.25738000869750977}, {"id": 273, "seek": 100900, "start": 1029.0, "end": 1032.0, "text": " I'm super lucky to have loads of lovely people", "tokens": [51364, 286, 478, 1687, 6356, 281, 362, 12668, 295, 7496, 561, 51514], "temperature": 0.0, "avg_logprob": -0.13958077607331454, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.25738000869750977}, {"id": 274, "seek": 100900, "start": 1032.0, "end": 1033.0, "text": " Hang out there", "tokens": [51514, 14070, 484, 456, 51564], "temperature": 0.0, "avg_logprob": -0.13958077607331454, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.25738000869750977}, {"id": 275, "seek": 100900, "start": 1033.0, "end": 1035.0, "text": " I can see some of them here today", "tokens": [51564, 286, 393, 536, 512, 295, 552, 510, 965, 51664], "temperature": 0.0, "avg_logprob": -0.13958077607331454, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.25738000869750977}, {"id": 276, "seek": 100900, "start": 1035.0, "end": 1038.0, "text": " And there's just people helping each other", "tokens": [51664, 400, 456, 311, 445, 561, 4315, 1184, 661, 51814], "temperature": 0.0, "avg_logprob": -0.13958077607331454, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.25738000869750977}, {"id": 277, "seek": 103800, "start": 1038.0, "end": 1039.0, "text": " And sharing cool projects", "tokens": [50364, 400, 5414, 1627, 4455, 50414], "temperature": 0.0, "avg_logprob": -0.112762451171875, "compression_ratio": 1.625, "no_speech_prob": 0.06759197264909744}, {"id": 278, "seek": 103800, "start": 1039.0, "end": 1040.0, "text": " And talking about the news", "tokens": [50414, 400, 1417, 466, 264, 2583, 50464], "temperature": 0.0, "avg_logprob": -0.112762451171875, "compression_ratio": 1.625, "no_speech_prob": 0.06759197264909744}, {"id": 279, "seek": 103800, "start": 1040.0, "end": 1042.0, "text": " Or talking about coffee or keyboards", "tokens": [50464, 1610, 1417, 466, 4982, 420, 47808, 50564], "temperature": 0.0, "avg_logprob": -0.112762451171875, "compression_ratio": 1.625, "no_speech_prob": 0.06759197264909744}, {"id": 280, "seek": 103800, "start": 1042.0, "end": 1043.0, "text": " Or anything really", "tokens": [50564, 1610, 1340, 534, 50614], "temperature": 0.0, "avg_logprob": -0.112762451171875, "compression_ratio": 1.625, "no_speech_prob": 0.06759197264909744}, {"id": 281, "seek": 103800, "start": 1043.0, "end": 1045.0, "text": " It's a really lovely place to", "tokens": [50614, 467, 311, 257, 534, 7496, 1081, 281, 50714], "temperature": 0.0, "avg_logprob": -0.112762451171875, "compression_ratio": 1.625, "no_speech_prob": 0.06759197264909744}, {"id": 282, "seek": 103800, "start": 1045.0, "end": 1048.0, "text": " Either get help or to talk to people", "tokens": [50714, 13746, 483, 854, 420, 281, 751, 281, 561, 50864], "temperature": 0.0, "avg_logprob": -0.112762451171875, "compression_ratio": 1.625, "no_speech_prob": 0.06759197264909744}, {"id": 283, "seek": 103800, "start": 1048.0, "end": 1050.0, "text": " So do join", "tokens": [50864, 407, 360, 3917, 50964], "temperature": 0.0, "avg_logprob": -0.112762451171875, "compression_ratio": 1.625, "no_speech_prob": 0.06759197264909744}, {"id": 284, "seek": 103800, "start": 1050.0, "end": 1052.0, "text": " The community is absolutely wonderful", "tokens": [50964, 440, 1768, 307, 3122, 3715, 51064], "temperature": 0.0, "avg_logprob": -0.112762451171875, "compression_ratio": 1.625, "no_speech_prob": 0.06759197264909744}, {"id": 285, "seek": 103800, "start": 1052.0, "end": 1053.0, "text": " And delightful", "tokens": [51064, 400, 35194, 51114], "temperature": 0.0, "avg_logprob": -0.112762451171875, "compression_ratio": 1.625, "no_speech_prob": 0.06759197264909744}, {"id": 286, "seek": 103800, "start": 1053.0, "end": 1056.0, "text": " And I'm super lucky to have", "tokens": [51114, 400, 286, 478, 1687, 6356, 281, 362, 51264], "temperature": 0.0, "avg_logprob": -0.112762451171875, "compression_ratio": 1.625, "no_speech_prob": 0.06759197264909744}, {"id": 287, "seek": 103800, "start": 1056.0, "end": 1058.0, "text": " Working with them be my job these days", "tokens": [51264, 18337, 365, 552, 312, 452, 1691, 613, 1708, 51364], "temperature": 0.0, "avg_logprob": -0.112762451171875, "compression_ratio": 1.625, "no_speech_prob": 0.06759197264909744}, {"id": 288, "seek": 103800, "start": 1058.0, "end": 1060.0, "text": " So thank you so much everyone", "tokens": [51364, 407, 1309, 291, 370, 709, 1518, 51464], "temperature": 0.0, "avg_logprob": -0.112762451171875, "compression_ratio": 1.625, "no_speech_prob": 0.06759197264909744}, {"id": 289, "seek": 103800, "start": 1060.0, "end": 1062.0, "text": " But now on to the things they've made", "tokens": [51464, 583, 586, 322, 281, 264, 721, 436, 600, 1027, 51564], "temperature": 0.0, "avg_logprob": -0.112762451171875, "compression_ratio": 1.625, "no_speech_prob": 0.06759197264909744}, {"id": 290, "seek": 103800, "start": 1062.0, "end": 1065.0, "text": " The first thing I want to talk and boast about", "tokens": [51564, 440, 700, 551, 286, 528, 281, 751, 293, 46988, 466, 51714], "temperature": 0.0, "avg_logprob": -0.112762451171875, "compression_ratio": 1.625, "no_speech_prob": 0.06759197264909744}, {"id": 291, "seek": 103800, "start": 1065.0, "end": 1066.0, "text": " Is MIST", "tokens": [51714, 1119, 376, 19756, 51764], "temperature": 0.0, "avg_logprob": -0.112762451171875, "compression_ratio": 1.625, "no_speech_prob": 0.06759197264909744}, {"id": 292, "seek": 106600, "start": 1066.0, "end": 1068.0, "text": " And MIST is a pure Gleam", "tokens": [50364, 400, 376, 19756, 307, 257, 6075, 460, 306, 335, 50464], "temperature": 0.0, "avg_logprob": -0.15034471556197765, "compression_ratio": 1.5829787234042554, "no_speech_prob": 0.044694241136312485}, {"id": 293, "seek": 106600, "start": 1068.0, "end": 1070.0, "text": " HB1.1 server", "tokens": [50464, 389, 33, 16, 13, 16, 7154, 50564], "temperature": 0.0, "avg_logprob": -0.15034471556197765, "compression_ratio": 1.5829787234042554, "no_speech_prob": 0.044694241136312485}, {"id": 294, "seek": 106600, "start": 1070.0, "end": 1072.0, "text": " That sports HBHBS", "tokens": [50564, 663, 6573, 389, 33, 39, 8176, 50664], "temperature": 0.0, "avg_logprob": -0.15034471556197765, "compression_ratio": 1.5829787234042554, "no_speech_prob": 0.044694241136312485}, {"id": 295, "seek": 106600, "start": 1072.0, "end": 1073.0, "text": " It has web sockets", "tokens": [50664, 467, 575, 3670, 370, 11984, 50714], "temperature": 0.0, "avg_logprob": -0.15034471556197765, "compression_ratio": 1.5829787234042554, "no_speech_prob": 0.044694241136312485}, {"id": 296, "seek": 106600, "start": 1073.0, "end": 1074.0, "text": " I believe", "tokens": [50714, 286, 1697, 50764], "temperature": 0.0, "avg_logprob": -0.15034471556197765, "compression_ratio": 1.5829787234042554, "no_speech_prob": 0.044694241136312485}, {"id": 297, "seek": 106600, "start": 1074.0, "end": 1076.0, "text": " Server-centered events are coming in the next version", "tokens": [50764, 25684, 12, 36814, 3931, 366, 1348, 294, 264, 958, 3037, 50864], "temperature": 0.0, "avg_logprob": -0.15034471556197765, "compression_ratio": 1.5829787234042554, "no_speech_prob": 0.044694241136312485}, {"id": 298, "seek": 106600, "start": 1076.0, "end": 1078.0, "text": " And they're working on HB2", "tokens": [50864, 400, 436, 434, 1364, 322, 389, 33, 17, 50964], "temperature": 0.0, "avg_logprob": -0.15034471556197765, "compression_ratio": 1.5829787234042554, "no_speech_prob": 0.044694241136312485}, {"id": 299, "seek": 106600, "start": 1078.0, "end": 1080.0, "text": " So the cool thing about this", "tokens": [50964, 407, 264, 1627, 551, 466, 341, 51064], "temperature": 0.0, "avg_logprob": -0.15034471556197765, "compression_ratio": 1.5829787234042554, "no_speech_prob": 0.044694241136312485}, {"id": 300, "seek": 106600, "start": 1080.0, "end": 1083.0, "text": " Is that it doesn't wrap an Erlang web server", "tokens": [51064, 1119, 300, 309, 1177, 380, 7019, 364, 3300, 25241, 3670, 7154, 51214], "temperature": 0.0, "avg_logprob": -0.15034471556197765, "compression_ratio": 1.5829787234042554, "no_speech_prob": 0.044694241136312485}, {"id": 301, "seek": 106600, "start": 1083.0, "end": 1085.0, "text": " It is pure Gleam", "tokens": [51214, 467, 307, 6075, 460, 306, 335, 51314], "temperature": 0.0, "avg_logprob": -0.15034471556197765, "compression_ratio": 1.5829787234042554, "no_speech_prob": 0.044694241136312485}, {"id": 302, "seek": 106600, "start": 1085.0, "end": 1087.0, "text": " And it doesn't even use Erlang's OTP", "tokens": [51314, 400, 309, 1177, 380, 754, 764, 3300, 25241, 311, 422, 16804, 51414], "temperature": 0.0, "avg_logprob": -0.15034471556197765, "compression_ratio": 1.5829787234042554, "no_speech_prob": 0.044694241136312485}, {"id": 303, "seek": 106600, "start": 1087.0, "end": 1089.0, "text": " It uses Gleam's OTP", "tokens": [51414, 467, 4960, 460, 306, 335, 311, 422, 16804, 51514], "temperature": 0.0, "avg_logprob": -0.15034471556197765, "compression_ratio": 1.5829787234042554, "no_speech_prob": 0.044694241136312485}, {"id": 304, "seek": 106600, "start": 1089.0, "end": 1091.0, "text": " It's an entirely new implementation", "tokens": [51514, 467, 311, 364, 7696, 777, 11420, 51614], "temperature": 0.0, "avg_logprob": -0.15034471556197765, "compression_ratio": 1.5829787234042554, "no_speech_prob": 0.044694241136312485}, {"id": 305, "seek": 106600, "start": 1091.0, "end": 1094.0, "text": " And what's really cool", "tokens": [51614, 400, 437, 311, 534, 1627, 51764], "temperature": 0.0, "avg_logprob": -0.15034471556197765, "compression_ratio": 1.5829787234042554, "no_speech_prob": 0.044694241136312485}, {"id": 306, "seek": 109400, "start": 1094.0, "end": 1096.0, "text": " Is that it's not just proving that you can use Gleam", "tokens": [50364, 1119, 300, 309, 311, 406, 445, 27221, 300, 291, 393, 764, 460, 306, 335, 50464], "temperature": 0.0, "avg_logprob": -0.13677669182801858, "compression_ratio": 1.6379821958456973, "no_speech_prob": 0.07922831922769547}, {"id": 307, "seek": 109400, "start": 1096.0, "end": 1098.0, "text": " To make sophisticated things", "tokens": [50464, 1407, 652, 16950, 721, 50564], "temperature": 0.0, "avg_logprob": -0.13677669182801858, "compression_ratio": 1.6379821958456973, "no_speech_prob": 0.07922831922769547}, {"id": 308, "seek": 109400, "start": 1098.0, "end": 1101.0, "text": " You know, implementing a fast HBHBS server", "tokens": [50564, 509, 458, 11, 18114, 257, 2370, 389, 33, 39, 8176, 7154, 50714], "temperature": 0.0, "avg_logprob": -0.13677669182801858, "compression_ratio": 1.6379821958456973, "no_speech_prob": 0.07922831922769547}, {"id": 309, "seek": 109400, "start": 1101.0, "end": 1103.0, "text": " Is quite challenging", "tokens": [50714, 1119, 1596, 7595, 50814], "temperature": 0.0, "avg_logprob": -0.13677669182801858, "compression_ratio": 1.6379821958456973, "no_speech_prob": 0.07922831922769547}, {"id": 310, "seek": 109400, "start": 1103.0, "end": 1105.0, "text": " But you can also get really good performance", "tokens": [50814, 583, 291, 393, 611, 483, 534, 665, 3389, 50914], "temperature": 0.0, "avg_logprob": -0.13677669182801858, "compression_ratio": 1.6379821958456973, "no_speech_prob": 0.07922831922769547}, {"id": 311, "seek": 109400, "start": 1105.0, "end": 1106.0, "text": " Out of the ever end", "tokens": [50914, 5925, 295, 264, 1562, 917, 50964], "temperature": 0.0, "avg_logprob": -0.13677669182801858, "compression_ratio": 1.6379821958456973, "no_speech_prob": 0.07922831922769547}, {"id": 312, "seek": 109400, "start": 1106.0, "end": 1107.0, "text": " So here we've got a bunch of different web servers", "tokens": [50964, 407, 510, 321, 600, 658, 257, 3840, 295, 819, 3670, 15909, 51014], "temperature": 0.0, "avg_logprob": -0.13677669182801858, "compression_ratio": 1.6379821958456973, "no_speech_prob": 0.07922831922769547}, {"id": 313, "seek": 109400, "start": 1107.0, "end": 1109.0, "text": " Graphed", "tokens": [51014, 21884, 292, 51114], "temperature": 0.0, "avg_logprob": -0.13677669182801858, "compression_ratio": 1.6379821958456973, "no_speech_prob": 0.07922831922769547}, {"id": 314, "seek": 109400, "start": 1109.0, "end": 1111.0, "text": " The ones at the top are MIST and Bandit", "tokens": [51114, 440, 2306, 412, 264, 1192, 366, 376, 19756, 293, 15462, 270, 51214], "temperature": 0.0, "avg_logprob": -0.13677669182801858, "compression_ratio": 1.6379821958456973, "no_speech_prob": 0.07922831922769547}, {"id": 315, "seek": 109400, "start": 1111.0, "end": 1113.0, "text": " Bandit being Elixir's new one", "tokens": [51214, 15462, 270, 885, 2699, 970, 347, 311, 777, 472, 51314], "temperature": 0.0, "avg_logprob": -0.13677669182801858, "compression_ratio": 1.6379821958456973, "no_speech_prob": 0.07922831922769547}, {"id": 316, "seek": 109400, "start": 1113.0, "end": 1116.0, "text": " Bandit has had a new version", "tokens": [51314, 15462, 270, 575, 632, 257, 777, 3037, 51464], "temperature": 0.0, "avg_logprob": -0.13677669182801858, "compression_ratio": 1.6379821958456973, "no_speech_prob": 0.07922831922769547}, {"id": 317, "seek": 109400, "start": 1116.0, "end": 1117.0, "text": " Since this benchmark was done", "tokens": [51464, 4162, 341, 18927, 390, 1096, 51514], "temperature": 0.0, "avg_logprob": -0.13677669182801858, "compression_ratio": 1.6379821958456973, "no_speech_prob": 0.07922831922769547}, {"id": 318, "seek": 109400, "start": 1117.0, "end": 1119.0, "text": " So I think it's actually slightly faster now", "tokens": [51514, 407, 286, 519, 309, 311, 767, 4748, 4663, 586, 51614], "temperature": 0.0, "avg_logprob": -0.13677669182801858, "compression_ratio": 1.6379821958456973, "no_speech_prob": 0.07922831922769547}, {"id": 319, "seek": 109400, "start": 1119.0, "end": 1120.0, "text": " But they're about the same", "tokens": [51614, 583, 436, 434, 466, 264, 912, 51664], "temperature": 0.0, "avg_logprob": -0.13677669182801858, "compression_ratio": 1.6379821958456973, "no_speech_prob": 0.07922831922769547}, {"id": 320, "seek": 109400, "start": 1120.0, "end": 1122.0, "text": " You'll notice we're even beating Go", "tokens": [51664, 509, 603, 3449, 321, 434, 754, 13497, 1037, 51764], "temperature": 0.0, "avg_logprob": -0.13677669182801858, "compression_ratio": 1.6379821958456973, "no_speech_prob": 0.07922831922769547}, {"id": 321, "seek": 109400, "start": 1122.0, "end": 1123.0, "text": " And everyone talks about how Go is super fast", "tokens": [51764, 400, 1518, 6686, 466, 577, 1037, 307, 1687, 2370, 51814], "temperature": 0.0, "avg_logprob": -0.13677669182801858, "compression_ratio": 1.6379821958456973, "no_speech_prob": 0.07922831922769547}, {"id": 322, "seek": 112300, "start": 1123.0, "end": 1126.0, "text": " But no, we in the Erlang world can do better", "tokens": [50364, 583, 572, 11, 321, 294, 264, 3300, 25241, 1002, 393, 360, 1101, 50514], "temperature": 0.0, "avg_logprob": -0.10234262015073355, "compression_ratio": 1.758490566037736, "no_speech_prob": 0.020563261583447456}, {"id": 323, "seek": 112300, "start": 1126.0, "end": 1128.0, "text": " And we're obviously beating JavaScript", "tokens": [50514, 400, 321, 434, 2745, 13497, 15778, 50614], "temperature": 0.0, "avg_logprob": -0.10234262015073355, "compression_ratio": 1.758490566037736, "no_speech_prob": 0.020563261583447456}, {"id": 324, "seek": 112300, "start": 1128.0, "end": 1130.0, "text": " But the thing I think is really cool", "tokens": [50614, 583, 264, 551, 286, 519, 307, 534, 1627, 50714], "temperature": 0.0, "avg_logprob": -0.10234262015073355, "compression_ratio": 1.758490566037736, "no_speech_prob": 0.020563261583447456}, {"id": 325, "seek": 112300, "start": 1130.0, "end": 1132.0, "text": " Is that we are really beating Cowboy", "tokens": [50714, 1119, 300, 321, 366, 534, 13497, 21933, 12795, 50814], "temperature": 0.0, "avg_logprob": -0.10234262015073355, "compression_ratio": 1.758490566037736, "no_speech_prob": 0.020563261583447456}, {"id": 326, "seek": 112300, "start": 1132.0, "end": 1134.0, "text": " We are really building the one", "tokens": [50814, 492, 366, 534, 2390, 264, 472, 50914], "temperature": 0.0, "avg_logprob": -0.10234262015073355, "compression_ratio": 1.758490566037736, "no_speech_prob": 0.020563261583447456}, {"id": 327, "seek": 112300, "start": 1134.0, "end": 1135.0, "text": " That we as the community have said", "tokens": [50914, 663, 321, 382, 264, 1768, 362, 848, 50964], "temperature": 0.0, "avg_logprob": -0.10234262015073355, "compression_ratio": 1.758490566037736, "no_speech_prob": 0.020563261583447456}, {"id": 328, "seek": 112300, "start": 1135.0, "end": 1137.0, "text": " This is the best fastest web server", "tokens": [50964, 639, 307, 264, 1151, 14573, 3670, 7154, 51064], "temperature": 0.0, "avg_logprob": -0.10234262015073355, "compression_ratio": 1.758490566037736, "no_speech_prob": 0.020563261583447456}, {"id": 329, "seek": 112300, "start": 1137.0, "end": 1140.0, "text": " It shows that we have further that we can do", "tokens": [51064, 467, 3110, 300, 321, 362, 3052, 300, 321, 393, 360, 51214], "temperature": 0.0, "avg_logprob": -0.10234262015073355, "compression_ratio": 1.758490566037736, "no_speech_prob": 0.020563261583447456}, {"id": 330, "seek": 112300, "start": 1140.0, "end": 1143.0, "text": " And it shows that Gleam can be just as performance", "tokens": [51214, 400, 309, 3110, 300, 460, 306, 335, 393, 312, 445, 382, 3389, 51364], "temperature": 0.0, "avg_logprob": -0.10234262015073355, "compression_ratio": 1.758490566037736, "no_speech_prob": 0.020563261583447456}, {"id": 331, "seek": 112300, "start": 1143.0, "end": 1145.0, "text": " As Erlang", "tokens": [51364, 1018, 3300, 25241, 51464], "temperature": 0.0, "avg_logprob": -0.10234262015073355, "compression_ratio": 1.758490566037736, "no_speech_prob": 0.020563261583447456}, {"id": 332, "seek": 112300, "start": 1145.0, "end": 1148.0, "text": " So this really proves the language I think", "tokens": [51464, 407, 341, 534, 25019, 264, 2856, 286, 519, 51614], "temperature": 0.0, "avg_logprob": -0.10234262015073355, "compression_ratio": 1.758490566037736, "no_speech_prob": 0.020563261583447456}, {"id": 333, "seek": 112300, "start": 1148.0, "end": 1150.0, "text": " So I mentioned OTP", "tokens": [51614, 407, 286, 2835, 422, 16804, 51714], "temperature": 0.0, "avg_logprob": -0.10234262015073355, "compression_ratio": 1.758490566037736, "no_speech_prob": 0.020563261583447456}, {"id": 334, "seek": 112300, "start": 1150.0, "end": 1152.0, "text": " Gleam has gone a different way for OTP", "tokens": [51714, 460, 306, 335, 575, 2780, 257, 819, 636, 337, 422, 16804, 51814], "temperature": 0.0, "avg_logprob": -0.10234262015073355, "compression_ratio": 1.758490566037736, "no_speech_prob": 0.020563261583447456}, {"id": 335, "seek": 115200, "start": 1152.0, "end": 1156.0, "text": " Then shared out to Fred and his squid there", "tokens": [50364, 1396, 5507, 484, 281, 10112, 293, 702, 28015, 456, 50564], "temperature": 0.0, "avg_logprob": -0.1445163927580181, "compression_ratio": 1.6485507246376812, "no_speech_prob": 0.03933781385421753}, {"id": 336, "seek": 115200, "start": 1156.0, "end": 1158.0, "text": " Gleam has gone a different way with OTP", "tokens": [50564, 460, 306, 335, 575, 2780, 257, 819, 636, 365, 422, 16804, 50664], "temperature": 0.0, "avg_logprob": -0.1445163927580181, "compression_ratio": 1.6485507246376812, "no_speech_prob": 0.03933781385421753}, {"id": 337, "seek": 115200, "start": 1158.0, "end": 1160.0, "text": " With most of the other languages", "tokens": [50664, 2022, 881, 295, 264, 661, 8650, 50764], "temperature": 0.0, "avg_logprob": -0.1445163927580181, "compression_ratio": 1.6485507246376812, "no_speech_prob": 0.03933781385421753}, {"id": 338, "seek": 115200, "start": 1160.0, "end": 1164.0, "text": " So Elixir and PureRail and other languages", "tokens": [50764, 407, 2699, 970, 347, 293, 29474, 49, 864, 293, 661, 8650, 50964], "temperature": 0.0, "avg_logprob": -0.1445163927580181, "compression_ratio": 1.6485507246376812, "no_speech_prob": 0.03933781385421753}, {"id": 339, "seek": 115200, "start": 1164.0, "end": 1165.0, "text": " If they want to use OTP", "tokens": [50964, 759, 436, 528, 281, 764, 422, 16804, 51014], "temperature": 0.0, "avg_logprob": -0.1445163927580181, "compression_ratio": 1.6485507246376812, "no_speech_prob": 0.03933781385421753}, {"id": 340, "seek": 115200, "start": 1165.0, "end": 1168.0, "text": " They put a very thin layer on top of Erlang OTP", "tokens": [51014, 814, 829, 257, 588, 5862, 4583, 322, 1192, 295, 3300, 25241, 422, 16804, 51164], "temperature": 0.0, "avg_logprob": -0.1445163927580181, "compression_ratio": 1.6485507246376812, "no_speech_prob": 0.03933781385421753}, {"id": 341, "seek": 115200, "start": 1168.0, "end": 1169.0, "text": " Well, Gleam doesn't do that", "tokens": [51164, 1042, 11, 460, 306, 335, 1177, 380, 360, 300, 51214], "temperature": 0.0, "avg_logprob": -0.1445163927580181, "compression_ratio": 1.6485507246376812, "no_speech_prob": 0.03933781385421753}, {"id": 342, "seek": 115200, "start": 1169.0, "end": 1173.0, "text": " Instead, Gleam takes the core concurrency primitives", "tokens": [51214, 7156, 11, 460, 306, 335, 2516, 264, 4965, 23702, 10457, 2886, 38970, 51414], "temperature": 0.0, "avg_logprob": -0.1445163927580181, "compression_ratio": 1.6485507246376812, "no_speech_prob": 0.03933781385421753}, {"id": 343, "seek": 115200, "start": 1173.0, "end": 1175.0, "text": " That you get from the Erlang runtime system", "tokens": [51414, 663, 291, 483, 490, 264, 3300, 25241, 34474, 1185, 51514], "temperature": 0.0, "avg_logprob": -0.1445163927580181, "compression_ratio": 1.6485507246376812, "no_speech_prob": 0.03933781385421753}, {"id": 344, "seek": 115200, "start": 1175.0, "end": 1178.0, "text": " And has made type safe versions of all of those", "tokens": [51514, 400, 575, 1027, 2010, 3273, 9606, 295, 439, 295, 729, 51664], "temperature": 0.0, "avg_logprob": -0.1445163927580181, "compression_ratio": 1.6485507246376812, "no_speech_prob": 0.03933781385421753}, {"id": 345, "seek": 115200, "start": 1178.0, "end": 1181.0, "text": " And it's the same things like link, sport, monitor", "tokens": [51664, 400, 309, 311, 264, 912, 721, 411, 2113, 11, 7282, 11, 6002, 51814], "temperature": 0.0, "avg_logprob": -0.1445163927580181, "compression_ratio": 1.6485507246376812, "no_speech_prob": 0.03933781385421753}, {"id": 346, "seek": 118100, "start": 1181.0, "end": 1183.0, "text": " Send, receive", "tokens": [50364, 17908, 11, 4774, 50464], "temperature": 0.0, "avg_logprob": -0.08416509935932774, "compression_ratio": 1.8282208588957056, "no_speech_prob": 0.01320516038686037}, {"id": 347, "seek": 118100, "start": 1183.0, "end": 1185.0, "text": " And then it looks at the protocols that are implemented", "tokens": [50464, 400, 550, 309, 1542, 412, 264, 20618, 300, 366, 12270, 50564], "temperature": 0.0, "avg_logprob": -0.08416509935932774, "compression_ratio": 1.8282208588957056, "no_speech_prob": 0.01320516038686037}, {"id": 348, "seek": 118100, "start": 1185.0, "end": 1187.0, "text": " OTP says you've got to implement certain messages", "tokens": [50564, 422, 16804, 1619, 291, 600, 658, 281, 4445, 1629, 7897, 50664], "temperature": 0.0, "avg_logprob": -0.08416509935932774, "compression_ratio": 1.8282208588957056, "no_speech_prob": 0.01320516038686037}, {"id": 349, "seek": 118100, "start": 1187.0, "end": 1189.0, "text": " Like system messages", "tokens": [50664, 1743, 1185, 7897, 50764], "temperature": 0.0, "avg_logprob": -0.08416509935932774, "compression_ratio": 1.8282208588957056, "no_speech_prob": 0.01320516038686037}, {"id": 350, "seek": 118100, "start": 1189.0, "end": 1191.0, "text": " And there's certain ways of sending", "tokens": [50764, 400, 456, 311, 1629, 2098, 295, 7750, 50864], "temperature": 0.0, "avg_logprob": -0.08416509935932774, "compression_ratio": 1.8282208588957056, "no_speech_prob": 0.01320516038686037}, {"id": 351, "seek": 118100, "start": 1191.0, "end": 1193.0, "text": " Of doing synchronous requests and all that sort of stuff", "tokens": [50864, 2720, 884, 44743, 12475, 293, 439, 300, 1333, 295, 1507, 50964], "temperature": 0.0, "avg_logprob": -0.08416509935932774, "compression_ratio": 1.8282208588957056, "no_speech_prob": 0.01320516038686037}, {"id": 352, "seek": 118100, "start": 1193.0, "end": 1195.0, "text": " And we've implemented those same things", "tokens": [50964, 400, 321, 600, 12270, 729, 912, 721, 51064], "temperature": 0.0, "avg_logprob": -0.08416509935932774, "compression_ratio": 1.8282208588957056, "no_speech_prob": 0.01320516038686037}, {"id": 353, "seek": 118100, "start": 1195.0, "end": 1197.0, "text": " From the ground up in a type safe way", "tokens": [51064, 3358, 264, 2727, 493, 294, 257, 2010, 3273, 636, 51164], "temperature": 0.0, "avg_logprob": -0.08416509935932774, "compression_ratio": 1.8282208588957056, "no_speech_prob": 0.01320516038686037}, {"id": 354, "seek": 118100, "start": 1197.0, "end": 1199.0, "text": " And what's really cool is that we've discovered it's possible", "tokens": [51164, 400, 437, 311, 534, 1627, 307, 300, 321, 600, 6941, 309, 311, 1944, 51264], "temperature": 0.0, "avg_logprob": -0.08416509935932774, "compression_ratio": 1.8282208588957056, "no_speech_prob": 0.01320516038686037}, {"id": 355, "seek": 118100, "start": 1199.0, "end": 1200.0, "text": " For a long time people have said", "tokens": [51264, 1171, 257, 938, 565, 561, 362, 848, 51314], "temperature": 0.0, "avg_logprob": -0.08416509935932774, "compression_ratio": 1.8282208588957056, "no_speech_prob": 0.01320516038686037}, {"id": 356, "seek": 118100, "start": 1200.0, "end": 1202.0, "text": " You can't have typed OTP", "tokens": [51314, 509, 393, 380, 362, 33941, 422, 16804, 51414], "temperature": 0.0, "avg_logprob": -0.08416509935932774, "compression_ratio": 1.8282208588957056, "no_speech_prob": 0.01320516038686037}, {"id": 357, "seek": 118100, "start": 1202.0, "end": 1204.0, "text": " Well, if you get the same", "tokens": [51414, 1042, 11, 498, 291, 483, 264, 912, 51514], "temperature": 0.0, "avg_logprob": -0.08416509935932774, "compression_ratio": 1.8282208588957056, "no_speech_prob": 0.01320516038686037}, {"id": 358, "seek": 118100, "start": 1204.0, "end": 1207.0, "text": " If you get that same core primitives that you get inside Erlang", "tokens": [51514, 759, 291, 483, 300, 912, 4965, 2886, 38970, 300, 291, 483, 1854, 3300, 25241, 51664], "temperature": 0.0, "avg_logprob": -0.08416509935932774, "compression_ratio": 1.8282208588957056, "no_speech_prob": 0.01320516038686037}, {"id": 359, "seek": 118100, "start": 1207.0, "end": 1209.0, "text": " You can build the same thing from the ground up", "tokens": [51664, 509, 393, 1322, 264, 912, 551, 490, 264, 2727, 493, 51764], "temperature": 0.0, "avg_logprob": -0.08416509935932774, "compression_ratio": 1.8282208588957056, "no_speech_prob": 0.01320516038686037}, {"id": 360, "seek": 118100, "start": 1209.0, "end": 1210.0, "text": " So that's been really cool", "tokens": [51764, 407, 300, 311, 668, 534, 1627, 51814], "temperature": 0.0, "avg_logprob": -0.08416509935932774, "compression_ratio": 1.8282208588957056, "no_speech_prob": 0.01320516038686037}, {"id": 361, "seek": 121000, "start": 1210.0, "end": 1212.0, "text": " And the fact that it's been used to make miss", "tokens": [50364, 400, 264, 1186, 300, 309, 311, 668, 1143, 281, 652, 1713, 50464], "temperature": 0.0, "avg_logprob": -0.097253569474457, "compression_ratio": 1.6689189189189189, "no_speech_prob": 0.01090250350534916}, {"id": 362, "seek": 121000, "start": 1212.0, "end": 1213.0, "text": " Shows that it can work", "tokens": [50464, 1160, 1509, 300, 309, 393, 589, 50514], "temperature": 0.0, "avg_logprob": -0.097253569474457, "compression_ratio": 1.6689189189189189, "no_speech_prob": 0.01090250350534916}, {"id": 363, "seek": 121000, "start": 1213.0, "end": 1217.0, "text": " And it could be practical and useful in performance", "tokens": [50514, 400, 309, 727, 312, 8496, 293, 4420, 294, 3389, 50714], "temperature": 0.0, "avg_logprob": -0.097253569474457, "compression_ratio": 1.6689189189189189, "no_speech_prob": 0.01090250350534916}, {"id": 364, "seek": 121000, "start": 1217.0, "end": 1219.0, "text": " So it's all very good having a web server", "tokens": [50714, 407, 309, 311, 439, 588, 665, 1419, 257, 3670, 7154, 50814], "temperature": 0.0, "avg_logprob": -0.097253569474457, "compression_ratio": 1.6689189189189189, "no_speech_prob": 0.01090250350534916}, {"id": 365, "seek": 121000, "start": 1219.0, "end": 1221.0, "text": " But you kind of need a...", "tokens": [50814, 583, 291, 733, 295, 643, 257, 485, 50914], "temperature": 0.0, "avg_logprob": -0.097253569474457, "compression_ratio": 1.6689189189189189, "no_speech_prob": 0.01090250350534916}, {"id": 366, "seek": 121000, "start": 1221.0, "end": 1222.0, "text": " Probably need a web framework", "tokens": [50914, 9210, 643, 257, 3670, 8388, 50964], "temperature": 0.0, "avg_logprob": -0.097253569474457, "compression_ratio": 1.6689189189189189, "no_speech_prob": 0.01090250350534916}, {"id": 367, "seek": 121000, "start": 1222.0, "end": 1223.0, "text": " Unless you want to spend all your time", "tokens": [50964, 16581, 291, 528, 281, 3496, 439, 428, 565, 51014], "temperature": 0.0, "avg_logprob": -0.097253569474457, "compression_ratio": 1.6689189189189189, "no_speech_prob": 0.01090250350534916}, {"id": 368, "seek": 121000, "start": 1223.0, "end": 1225.0, "text": " Writing a parser for multi-part form bodies", "tokens": [51014, 32774, 257, 21156, 260, 337, 4825, 12, 6971, 1254, 7510, 51114], "temperature": 0.0, "avg_logprob": -0.097253569474457, "compression_ratio": 1.6689189189189189, "no_speech_prob": 0.01090250350534916}, {"id": 369, "seek": 121000, "start": 1225.0, "end": 1227.0, "text": " So we have Wisp", "tokens": [51114, 407, 321, 362, 343, 7631, 51214], "temperature": 0.0, "avg_logprob": -0.097253569474457, "compression_ratio": 1.6689189189189189, "no_speech_prob": 0.01090250350534916}, {"id": 370, "seek": 121000, "start": 1227.0, "end": 1230.0, "text": " Wisp is a really lovely little framework", "tokens": [51214, 343, 7631, 307, 257, 534, 7496, 707, 8388, 51364], "temperature": 0.0, "avg_logprob": -0.097253569474457, "compression_ratio": 1.6689189189189189, "no_speech_prob": 0.01090250350534916}, {"id": 371, "seek": 121000, "start": 1230.0, "end": 1233.0, "text": " I can call it lovely because I made it", "tokens": [51364, 286, 393, 818, 309, 7496, 570, 286, 1027, 309, 51514], "temperature": 0.0, "avg_logprob": -0.097253569474457, "compression_ratio": 1.6689189189189189, "no_speech_prob": 0.01090250350534916}, {"id": 372, "seek": 121000, "start": 1233.0, "end": 1235.0, "text": " So if you want to do a web thing", "tokens": [51514, 407, 498, 291, 528, 281, 360, 257, 3670, 551, 51614], "temperature": 0.0, "avg_logprob": -0.097253569474457, "compression_ratio": 1.6689189189189189, "no_speech_prob": 0.01090250350534916}, {"id": 373, "seek": 121000, "start": 1235.0, "end": 1237.0, "text": " That's a good place to start", "tokens": [51614, 663, 311, 257, 665, 1081, 281, 722, 51714], "temperature": 0.0, "avg_logprob": -0.097253569474457, "compression_ratio": 1.6689189189189189, "no_speech_prob": 0.01090250350534916}, {"id": 374, "seek": 121000, "start": 1237.0, "end": 1239.0, "text": " Databases are pretty handy as well", "tokens": [51714, 40461, 1957, 366, 1238, 13239, 382, 731, 51814], "temperature": 0.0, "avg_logprob": -0.097253569474457, "compression_ratio": 1.6689189189189189, "no_speech_prob": 0.01090250350534916}, {"id": 375, "seek": 123900, "start": 1239.0, "end": 1241.0, "text": " We've got bindings for these sort", "tokens": [50364, 492, 600, 658, 14786, 1109, 337, 613, 1333, 50464], "temperature": 0.0, "avg_logprob": -0.14281892382408962, "compression_ratio": 1.573643410852713, "no_speech_prob": 0.07848135381937027}, {"id": 376, "seek": 123900, "start": 1241.0, "end": 1243.0, "text": " And probably some others that I haven't found", "tokens": [50464, 400, 1391, 512, 2357, 300, 286, 2378, 380, 1352, 50564], "temperature": 0.0, "avg_logprob": -0.14281892382408962, "compression_ratio": 1.573643410852713, "no_speech_prob": 0.07848135381937027}, {"id": 377, "seek": 123900, "start": 1243.0, "end": 1246.0, "text": " The first two, Postgres and SQLite", "tokens": [50564, 440, 700, 732, 11, 10223, 45189, 293, 19200, 642, 50714], "temperature": 0.0, "avg_logprob": -0.14281892382408962, "compression_ratio": 1.573643410852713, "no_speech_prob": 0.07848135381937027}, {"id": 378, "seek": 123900, "start": 1246.0, "end": 1247.0, "text": " They wrap Erlang projects", "tokens": [50714, 814, 7019, 3300, 25241, 4455, 50764], "temperature": 0.0, "avg_logprob": -0.14281892382408962, "compression_ratio": 1.573643410852713, "no_speech_prob": 0.07848135381937027}, {"id": 379, "seek": 123900, "start": 1247.0, "end": 1249.0, "text": " All the SQLite one can even work on JavaScript", "tokens": [50764, 1057, 264, 19200, 642, 472, 393, 754, 589, 322, 15778, 50864], "temperature": 0.0, "avg_logprob": -0.14281892382408962, "compression_ratio": 1.573643410852713, "no_speech_prob": 0.07848135381937027}, {"id": 380, "seek": 123900, "start": 1249.0, "end": 1252.0, "text": " If you're using Deno", "tokens": [50864, 759, 291, 434, 1228, 6458, 78, 51014], "temperature": 0.0, "avg_logprob": -0.14281892382408962, "compression_ratio": 1.573643410852713, "no_speech_prob": 0.07848135381937027}, {"id": 381, "seek": 123900, "start": 1252.0, "end": 1254.0, "text": " But the bottom two, they're really cool", "tokens": [51014, 583, 264, 2767, 732, 11, 436, 434, 534, 1627, 51114], "temperature": 0.0, "avg_logprob": -0.14281892382408962, "compression_ratio": 1.573643410852713, "no_speech_prob": 0.07848135381937027}, {"id": 382, "seek": 123900, "start": 1254.0, "end": 1256.0, "text": " Because they're, again, written in pure Glean", "tokens": [51114, 1436, 436, 434, 11, 797, 11, 3720, 294, 6075, 460, 28499, 51214], "temperature": 0.0, "avg_logprob": -0.14281892382408962, "compression_ratio": 1.573643410852713, "no_speech_prob": 0.07848135381937027}, {"id": 383, "seek": 123900, "start": 1256.0, "end": 1260.0, "text": " Using Glean OTP", "tokens": [51214, 11142, 460, 28499, 422, 16804, 51414], "temperature": 0.0, "avg_logprob": -0.14281892382408962, "compression_ratio": 1.573643410852713, "no_speech_prob": 0.07848135381937027}, {"id": 384, "seek": 123900, "start": 1260.0, "end": 1262.0, "text": " Now, this is a really cool one", "tokens": [51414, 823, 11, 341, 307, 257, 534, 1627, 472, 51514], "temperature": 0.0, "avg_logprob": -0.14281892382408962, "compression_ratio": 1.573643410852713, "no_speech_prob": 0.07848135381937027}, {"id": 385, "seek": 123900, "start": 1262.0, "end": 1263.0, "text": " This isn't quite so beamy", "tokens": [51514, 639, 1943, 380, 1596, 370, 312, 7804, 51564], "temperature": 0.0, "avg_logprob": -0.14281892382408962, "compression_ratio": 1.573643410852713, "no_speech_prob": 0.07848135381937027}, {"id": 386, "seek": 123900, "start": 1263.0, "end": 1266.0, "text": " But so Glean can compile to JavaScript", "tokens": [51564, 583, 370, 460, 28499, 393, 31413, 281, 15778, 51714], "temperature": 0.0, "avg_logprob": -0.14281892382408962, "compression_ratio": 1.573643410852713, "no_speech_prob": 0.07848135381937027}, {"id": 387, "seek": 126600, "start": 1266.0, "end": 1269.0, "text": " Okay, so how do I do a front-end in Glean?", "tokens": [50364, 1033, 11, 370, 577, 360, 286, 360, 257, 1868, 12, 521, 294, 460, 28499, 30, 50514], "temperature": 0.0, "avg_logprob": -0.12142135716286026, "compression_ratio": 1.5091575091575091, "no_speech_prob": 0.09045278280973434}, {"id": 388, "seek": 126600, "start": 1269.0, "end": 1272.0, "text": " I don't want to be writing all this JavaScript", "tokens": [50514, 286, 500, 380, 528, 281, 312, 3579, 439, 341, 15778, 50664], "temperature": 0.0, "avg_logprob": -0.12142135716286026, "compression_ratio": 1.5091575091575091, "no_speech_prob": 0.09045278280973434}, {"id": 389, "seek": 126600, "start": 1272.0, "end": 1275.0, "text": " For my Beam application", "tokens": [50664, 1171, 452, 40916, 3861, 50814], "temperature": 0.0, "avg_logprob": -0.12142135716286026, "compression_ratio": 1.5091575091575091, "no_speech_prob": 0.09045278280973434}, {"id": 390, "seek": 126600, "start": 1275.0, "end": 1276.0, "text": " If I can avoid it", "tokens": [50814, 759, 286, 393, 5042, 309, 50864], "temperature": 0.0, "avg_logprob": -0.12142135716286026, "compression_ratio": 1.5091575091575091, "no_speech_prob": 0.09045278280973434}, {"id": 391, "seek": 126600, "start": 1276.0, "end": 1279.0, "text": " So Lustre is this really lovely library", "tokens": [50864, 407, 45834, 265, 307, 341, 534, 7496, 6405, 51014], "temperature": 0.0, "avg_logprob": -0.12142135716286026, "compression_ratio": 1.5091575091575091, "no_speech_prob": 0.09045278280973434}, {"id": 392, "seek": 126600, "start": 1279.0, "end": 1281.0, "text": " That's sort of quite similar to Elm", "tokens": [51014, 663, 311, 1333, 295, 1596, 2531, 281, 2699, 76, 51114], "temperature": 0.0, "avg_logprob": -0.12142135716286026, "compression_ratio": 1.5091575091575091, "no_speech_prob": 0.09045278280973434}, {"id": 393, "seek": 126600, "start": 1281.0, "end": 1284.0, "text": " Or perhaps some React", "tokens": [51114, 1610, 4317, 512, 30644, 51264], "temperature": 0.0, "avg_logprob": -0.12142135716286026, "compression_ratio": 1.5091575091575091, "no_speech_prob": 0.09045278280973434}, {"id": 394, "seek": 126600, "start": 1284.0, "end": 1286.0, "text": " State management systems", "tokens": [51264, 4533, 4592, 3652, 51364], "temperature": 0.0, "avg_logprob": -0.12142135716286026, "compression_ratio": 1.5091575091575091, "no_speech_prob": 0.09045278280973434}, {"id": 395, "seek": 126600, "start": 1286.0, "end": 1289.0, "text": " That gives you a way to make a declarative DOM", "tokens": [51364, 663, 2709, 291, 257, 636, 281, 652, 257, 16694, 1166, 35727, 51514], "temperature": 0.0, "avg_logprob": -0.12142135716286026, "compression_ratio": 1.5091575091575091, "no_speech_prob": 0.09045278280973434}, {"id": 396, "seek": 126600, "start": 1289.0, "end": 1291.0, "text": " And then all you need to do is talk about", "tokens": [51514, 400, 550, 439, 291, 643, 281, 360, 307, 751, 466, 51614], "temperature": 0.0, "avg_logprob": -0.12142135716286026, "compression_ratio": 1.5091575091575091, "no_speech_prob": 0.09045278280973434}, {"id": 397, "seek": 126600, "start": 1291.0, "end": 1293.0, "text": " What messages you're going to emit", "tokens": [51614, 708, 7897, 291, 434, 516, 281, 32084, 51714], "temperature": 0.0, "avg_logprob": -0.12142135716286026, "compression_ratio": 1.5091575091575091, "no_speech_prob": 0.09045278280973434}, {"id": 398, "seek": 126600, "start": 1293.0, "end": 1294.0, "text": " And then how you update the state", "tokens": [51714, 400, 550, 577, 291, 5623, 264, 1785, 51764], "temperature": 0.0, "avg_logprob": -0.12142135716286026, "compression_ratio": 1.5091575091575091, "no_speech_prob": 0.09045278280973434}, {"id": 399, "seek": 129400, "start": 1294.0, "end": 1296.0, "text": " Every time one of those messages come in", "tokens": [50364, 2048, 565, 472, 295, 729, 7897, 808, 294, 50464], "temperature": 0.0, "avg_logprob": -0.1179775432416588, "compression_ratio": 1.7408637873754154, "no_speech_prob": 0.036065295338630676}, {"id": 400, "seek": 129400, "start": 1296.0, "end": 1298.0, "text": " And as an Erlanger, I look at this", "tokens": [50464, 400, 382, 364, 3300, 75, 3176, 11, 286, 574, 412, 341, 50564], "temperature": 0.0, "avg_logprob": -0.1179775432416588, "compression_ratio": 1.7408637873754154, "no_speech_prob": 0.036065295338630676}, {"id": 401, "seek": 129400, "start": 1298.0, "end": 1300.0, "text": " And I see a GenServer", "tokens": [50564, 400, 286, 536, 257, 3632, 31859, 331, 50664], "temperature": 0.0, "avg_logprob": -0.1179775432416588, "compression_ratio": 1.7408637873754154, "no_speech_prob": 0.036065295338630676}, {"id": 402, "seek": 129400, "start": 1300.0, "end": 1302.0, "text": " I think that the Elm architecture", "tokens": [50664, 286, 519, 300, 264, 2699, 76, 9482, 50764], "temperature": 0.0, "avg_logprob": -0.1179775432416588, "compression_ratio": 1.7408637873754154, "no_speech_prob": 0.036065295338630676}, {"id": 403, "seek": 129400, "start": 1302.0, "end": 1305.0, "text": " Is basically exactly the same as an Erlang GenServer", "tokens": [50764, 1119, 1936, 2293, 264, 912, 382, 364, 3300, 25241, 3632, 31859, 331, 50914], "temperature": 0.0, "avg_logprob": -0.1179775432416588, "compression_ratio": 1.7408637873754154, "no_speech_prob": 0.036065295338630676}, {"id": 404, "seek": 129400, "start": 1305.0, "end": 1307.0, "text": " Instead of calling it call, we're calling it", "tokens": [50914, 7156, 295, 5141, 309, 818, 11, 321, 434, 5141, 309, 51014], "temperature": 0.0, "avg_logprob": -0.1179775432416588, "compression_ratio": 1.7408637873754154, "no_speech_prob": 0.036065295338630676}, {"id": 405, "seek": 129400, "start": 1307.0, "end": 1310.0, "text": " Handlework, we're calling it updates", "tokens": [51014, 8854, 306, 1902, 11, 321, 434, 5141, 309, 9205, 51164], "temperature": 0.0, "avg_logprob": -0.1179775432416588, "compression_ratio": 1.7408637873754154, "no_speech_prob": 0.036065295338630676}, {"id": 406, "seek": 129400, "start": 1310.0, "end": 1312.0, "text": " And then we've got this HTML thing on the side", "tokens": [51164, 400, 550, 321, 600, 658, 341, 17995, 551, 322, 264, 1252, 51264], "temperature": 0.0, "avg_logprob": -0.1179775432416588, "compression_ratio": 1.7408637873754154, "no_speech_prob": 0.036065295338630676}, {"id": 407, "seek": 129400, "start": 1312.0, "end": 1314.0, "text": " Which I don't, who knows", "tokens": [51264, 3013, 286, 500, 380, 11, 567, 3255, 51364], "temperature": 0.0, "avg_logprob": -0.1179775432416588, "compression_ratio": 1.7408637873754154, "no_speech_prob": 0.036065295338630676}, {"id": 408, "seek": 129400, "start": 1314.0, "end": 1316.0, "text": " But what about live view?", "tokens": [51364, 583, 437, 466, 1621, 1910, 30, 51464], "temperature": 0.0, "avg_logprob": -0.1179775432416588, "compression_ratio": 1.7408637873754154, "no_speech_prob": 0.036065295338630676}, {"id": 409, "seek": 129400, "start": 1316.0, "end": 1317.0, "text": " People like live view, right?", "tokens": [51464, 3432, 411, 1621, 1910, 11, 558, 30, 51514], "temperature": 0.0, "avg_logprob": -0.1179775432416588, "compression_ratio": 1.7408637873754154, "no_speech_prob": 0.036065295338630676}, {"id": 410, "seek": 129400, "start": 1317.0, "end": 1318.0, "text": " That's the hotness at the moment", "tokens": [51514, 663, 311, 264, 2368, 1287, 412, 264, 1623, 51564], "temperature": 0.0, "avg_logprob": -0.1179775432416588, "compression_ratio": 1.7408637873754154, "no_speech_prob": 0.036065295338630676}, {"id": 411, "seek": 129400, "start": 1318.0, "end": 1320.0, "text": " So live view, in case you don't know", "tokens": [51564, 407, 1621, 1910, 11, 294, 1389, 291, 500, 380, 458, 51664], "temperature": 0.0, "avg_logprob": -0.1179775432416588, "compression_ratio": 1.7408637873754154, "no_speech_prob": 0.036065295338630676}, {"id": 412, "seek": 129400, "start": 1320.0, "end": 1322.0, "text": " Which I find that you almost certainly", "tokens": [51664, 3013, 286, 915, 300, 291, 1920, 3297, 51764], "temperature": 0.0, "avg_logprob": -0.1179775432416588, "compression_ratio": 1.7408637873754154, "no_speech_prob": 0.036065295338630676}, {"id": 413, "seek": 129400, "start": 1322.0, "end": 1323.0, "text": " Do know in this room", "tokens": [51764, 1144, 458, 294, 341, 1808, 51814], "temperature": 0.0, "avg_logprob": -0.1179775432416588, "compression_ratio": 1.7408637873754154, "no_speech_prob": 0.036065295338630676}, {"id": 414, "seek": 132300, "start": 1323.0, "end": 1325.0, "text": " That's when you have that same sort of idea", "tokens": [50364, 663, 311, 562, 291, 362, 300, 912, 1333, 295, 1558, 50464], "temperature": 0.0, "avg_logprob": -0.10158046722412109, "compression_ratio": 1.809061488673139, "no_speech_prob": 0.011717784218490124}, {"id": 415, "seek": 132300, "start": 1325.0, "end": 1327.0, "text": " You get a declarative DOM that is on your front end", "tokens": [50464, 509, 483, 257, 16694, 1166, 35727, 300, 307, 322, 428, 1868, 917, 50564], "temperature": 0.0, "avg_logprob": -0.10158046722412109, "compression_ratio": 1.809061488673139, "no_speech_prob": 0.011717784218490124}, {"id": 416, "seek": 132300, "start": 1327.0, "end": 1329.0, "text": " But all your state updating", "tokens": [50564, 583, 439, 428, 1785, 25113, 50664], "temperature": 0.0, "avg_logprob": -0.10158046722412109, "compression_ratio": 1.809061488673139, "no_speech_prob": 0.011717784218490124}, {"id": 417, "seek": 132300, "start": 1329.0, "end": 1331.0, "text": " Where you hold everything is on your back end", "tokens": [50664, 2305, 291, 1797, 1203, 307, 322, 428, 646, 917, 50764], "temperature": 0.0, "avg_logprob": -0.10158046722412109, "compression_ratio": 1.809061488673139, "no_speech_prob": 0.011717784218490124}, {"id": 418, "seek": 132300, "start": 1331.0, "end": 1333.0, "text": " And then they talk to each other over WebSockets", "tokens": [50764, 400, 550, 436, 751, 281, 1184, 661, 670, 9573, 50, 1560, 1385, 50864], "temperature": 0.0, "avg_logprob": -0.10158046722412109, "compression_ratio": 1.809061488673139, "no_speech_prob": 0.011717784218490124}, {"id": 419, "seek": 132300, "start": 1333.0, "end": 1335.0, "text": " And this results in a really lovely develop experience", "tokens": [50864, 400, 341, 3542, 294, 257, 534, 7496, 1499, 1752, 50964], "temperature": 0.0, "avg_logprob": -0.10158046722412109, "compression_ratio": 1.809061488673139, "no_speech_prob": 0.011717784218490124}, {"id": 420, "seek": 132300, "start": 1335.0, "end": 1337.0, "text": " And you can do all sort of things that you can't", "tokens": [50964, 400, 291, 393, 360, 439, 1333, 295, 721, 300, 291, 393, 380, 51064], "temperature": 0.0, "avg_logprob": -0.10158046722412109, "compression_ratio": 1.809061488673139, "no_speech_prob": 0.011717784218490124}, {"id": 421, "seek": 132300, "start": 1337.0, "end": 1340.0, "text": " Practically do if all the state is on the front end", "tokens": [51064, 19170, 984, 360, 498, 439, 264, 1785, 307, 322, 264, 1868, 917, 51214], "temperature": 0.0, "avg_logprob": -0.10158046722412109, "compression_ratio": 1.809061488673139, "no_speech_prob": 0.011717784218490124}, {"id": 422, "seek": 132300, "start": 1340.0, "end": 1342.0, "text": " Well, us too can do that as well", "tokens": [51214, 1042, 11, 505, 886, 393, 360, 300, 382, 731, 51314], "temperature": 0.0, "avg_logprob": -0.10158046722412109, "compression_ratio": 1.809061488673139, "no_speech_prob": 0.011717784218490124}, {"id": 423, "seek": 132300, "start": 1342.0, "end": 1344.0, "text": " That last component I showed you", "tokens": [51314, 663, 1036, 6542, 286, 4712, 291, 51414], "temperature": 0.0, "avg_logprob": -0.10158046722412109, "compression_ratio": 1.809061488673139, "no_speech_prob": 0.011717784218490124}, {"id": 424, "seek": 132300, "start": 1344.0, "end": 1346.0, "text": " There's nothing that says that has to run on the front end", "tokens": [51414, 821, 311, 1825, 300, 1619, 300, 575, 281, 1190, 322, 264, 1868, 917, 51514], "temperature": 0.0, "avg_logprob": -0.10158046722412109, "compression_ratio": 1.809061488673139, "no_speech_prob": 0.011717784218490124}, {"id": 425, "seek": 132300, "start": 1346.0, "end": 1349.0, "text": " It could also run on the back end", "tokens": [51514, 467, 727, 611, 1190, 322, 264, 646, 917, 51664], "temperature": 0.0, "avg_logprob": -0.10158046722412109, "compression_ratio": 1.809061488673139, "no_speech_prob": 0.011717784218490124}, {"id": 426, "seek": 132300, "start": 1349.0, "end": 1351.0, "text": " Just rendering it to HTML", "tokens": [51664, 1449, 22407, 309, 281, 17995, 51764], "temperature": 0.0, "avg_logprob": -0.10158046722412109, "compression_ratio": 1.809061488673139, "no_speech_prob": 0.011717784218490124}, {"id": 427, "seek": 135100, "start": 1351.0, "end": 1353.0, "text": " Or you could put it on both", "tokens": [50364, 1610, 291, 727, 829, 309, 322, 1293, 50464], "temperature": 0.0, "avg_logprob": -0.10462130922259706, "compression_ratio": 1.6757679180887373, "no_speech_prob": 0.014822377823293209}, {"id": 428, "seek": 135100, "start": 1353.0, "end": 1355.0, "text": " So you could just by saying", "tokens": [50464, 407, 291, 727, 445, 538, 1566, 50564], "temperature": 0.0, "avg_logprob": -0.10462130922259706, "compression_ratio": 1.6757679180887373, "no_speech_prob": 0.014822377823293209}, {"id": 429, "seek": 135100, "start": 1355.0, "end": 1356.0, "text": " Hey, start an actor with this", "tokens": [50564, 1911, 11, 722, 364, 8747, 365, 341, 50614], "temperature": 0.0, "avg_logprob": -0.10462130922259706, "compression_ratio": 1.6757679180887373, "no_speech_prob": 0.014822377823293209}, {"id": 430, "seek": 135100, "start": 1356.0, "end": 1358.0, "text": " And then here's WebSockets", "tokens": [50614, 400, 550, 510, 311, 9573, 50, 1560, 1385, 50714], "temperature": 0.0, "avg_logprob": -0.10462130922259706, "compression_ratio": 1.6757679180887373, "no_speech_prob": 0.014822377823293209}, {"id": 431, "seek": 135100, "start": 1358.0, "end": 1360.0, "text": " You can have live view with Luster", "tokens": [50714, 509, 393, 362, 1621, 1910, 365, 441, 8393, 50814], "temperature": 0.0, "avg_logprob": -0.10462130922259706, "compression_ratio": 1.6757679180887373, "no_speech_prob": 0.014822377823293209}, {"id": 432, "seek": 135100, "start": 1360.0, "end": 1363.0, "text": " And what's really cool is that you can now pick", "tokens": [50814, 400, 437, 311, 534, 1627, 307, 300, 291, 393, 586, 1888, 50964], "temperature": 0.0, "avg_logprob": -0.10462130922259706, "compression_ratio": 1.6757679180887373, "no_speech_prob": 0.014822377823293209}, {"id": 433, "seek": 135100, "start": 1363.0, "end": 1366.0, "text": " Which parts of your application is going to use", "tokens": [50964, 3013, 3166, 295, 428, 3861, 307, 516, 281, 764, 51114], "temperature": 0.0, "avg_logprob": -0.10462130922259706, "compression_ratio": 1.6757679180887373, "no_speech_prob": 0.014822377823293209}, {"id": 434, "seek": 135100, "start": 1366.0, "end": 1368.0, "text": " Which architecture?", "tokens": [51114, 3013, 9482, 30, 51214], "temperature": 0.0, "avg_logprob": -0.10462130922259706, "compression_ratio": 1.6757679180887373, "no_speech_prob": 0.014822377823293209}, {"id": 435, "seek": 135100, "start": 1368.0, "end": 1369.0, "text": " You know, there's a criticism of live view", "tokens": [51214, 509, 458, 11, 456, 311, 257, 15835, 295, 1621, 1910, 51264], "temperature": 0.0, "avg_logprob": -0.10462130922259706, "compression_ratio": 1.6757679180887373, "no_speech_prob": 0.014822377823293209}, {"id": 436, "seek": 135100, "start": 1369.0, "end": 1371.0, "text": " That it means that certain actions", "tokens": [51264, 663, 309, 1355, 300, 1629, 5909, 51364], "temperature": 0.0, "avg_logprob": -0.10462130922259706, "compression_ratio": 1.6757679180887373, "no_speech_prob": 0.014822377823293209}, {"id": 437, "seek": 135100, "start": 1371.0, "end": 1374.0, "text": " That should be really snappy are quite slow", "tokens": [51364, 663, 820, 312, 534, 14528, 7966, 366, 1596, 2964, 51514], "temperature": 0.0, "avg_logprob": -0.10462130922259706, "compression_ratio": 1.6757679180887373, "no_speech_prob": 0.014822377823293209}, {"id": 438, "seek": 135100, "start": 1374.0, "end": 1376.0, "text": " And if you lose network connectivity", "tokens": [51514, 400, 498, 291, 3624, 3209, 21095, 51614], "temperature": 0.0, "avg_logprob": -0.10462130922259706, "compression_ratio": 1.6757679180887373, "no_speech_prob": 0.014822377823293209}, {"id": 439, "seek": 135100, "start": 1376.0, "end": 1378.0, "text": " Your whole application stops working", "tokens": [51614, 2260, 1379, 3861, 10094, 1364, 51714], "temperature": 0.0, "avg_logprob": -0.10462130922259706, "compression_ratio": 1.6757679180887373, "no_speech_prob": 0.014822377823293209}, {"id": 440, "seek": 135100, "start": 1378.0, "end": 1380.0, "text": " Well, then maybe put those bits", "tokens": [51714, 1042, 11, 550, 1310, 829, 729, 9239, 51814], "temperature": 0.0, "avg_logprob": -0.10462130922259706, "compression_ratio": 1.6757679180887373, "no_speech_prob": 0.014822377823293209}, {"id": 441, "seek": 138000, "start": 1380.0, "end": 1382.0, "text": " About making it be resilient to network failures", "tokens": [50364, 7769, 1455, 309, 312, 23699, 281, 3209, 20774, 50464], "temperature": 0.0, "avg_logprob": -0.11866488699185646, "compression_ratio": 1.7007575757575757, "no_speech_prob": 0.015950776636600494}, {"id": 442, "seek": 138000, "start": 1382.0, "end": 1384.0, "text": " Put those on the clients", "tokens": [50464, 4935, 729, 322, 264, 6982, 50564], "temperature": 0.0, "avg_logprob": -0.11866488699185646, "compression_ratio": 1.7007575757575757, "no_speech_prob": 0.015950776636600494}, {"id": 443, "seek": 138000, "start": 1384.0, "end": 1386.0, "text": " You can pick exactly what you want", "tokens": [50564, 509, 393, 1888, 2293, 437, 291, 528, 50664], "temperature": 0.0, "avg_logprob": -0.11866488699185646, "compression_ratio": 1.7007575757575757, "no_speech_prob": 0.015950776636600494}, {"id": 444, "seek": 138000, "start": 1388.0, "end": 1390.0, "text": " So we've got loads of servers and clients", "tokens": [50764, 407, 321, 600, 658, 12668, 295, 15909, 293, 6982, 50864], "temperature": 0.0, "avg_logprob": -0.11866488699185646, "compression_ratio": 1.7007575757575757, "no_speech_prob": 0.015950776636600494}, {"id": 445, "seek": 138000, "start": 1390.0, "end": 1393.0, "text": " And API clients and middleware", "tokens": [50864, 400, 9362, 6982, 293, 2808, 3039, 51014], "temperature": 0.0, "avg_logprob": -0.11866488699185646, "compression_ratio": 1.7007575757575757, "no_speech_prob": 0.015950776636600494}, {"id": 446, "seek": 138000, "start": 1393.0, "end": 1396.0, "text": " That are all part of this wider HDP ecosystem", "tokens": [51014, 663, 366, 439, 644, 295, 341, 11842, 389, 11373, 11311, 51164], "temperature": 0.0, "avg_logprob": -0.11866488699185646, "compression_ratio": 1.7007575757575757, "no_speech_prob": 0.015950776636600494}, {"id": 447, "seek": 138000, "start": 1396.0, "end": 1398.0, "text": " And one of the things that's really cool about this", "tokens": [51164, 400, 472, 295, 264, 721, 300, 311, 534, 1627, 466, 341, 51264], "temperature": 0.0, "avg_logprob": -0.11866488699185646, "compression_ratio": 1.7007575757575757, "no_speech_prob": 0.015950776636600494}, {"id": 448, "seek": 138000, "start": 1398.0, "end": 1401.0, "text": " Is that there is a Gleam core library", "tokens": [51264, 1119, 300, 456, 307, 257, 460, 306, 335, 4965, 6405, 51414], "temperature": 0.0, "avg_logprob": -0.11866488699185646, "compression_ratio": 1.7007575757575757, "no_speech_prob": 0.015950776636600494}, {"id": 449, "seek": 138000, "start": 1401.0, "end": 1404.0, "text": " Called Gleam HDP that defines a few types for", "tokens": [51414, 45001, 460, 306, 335, 389, 11373, 300, 23122, 257, 1326, 3467, 337, 51564], "temperature": 0.0, "avg_logprob": -0.11866488699185646, "compression_ratio": 1.7007575757575757, "no_speech_prob": 0.015950776636600494}, {"id": 450, "seek": 138000, "start": 1404.0, "end": 1407.0, "text": " Requests and responses and headers and all these things", "tokens": [51564, 42029, 4409, 293, 13019, 293, 45101, 293, 439, 613, 721, 51714], "temperature": 0.0, "avg_logprob": -0.11866488699185646, "compression_ratio": 1.7007575757575757, "no_speech_prob": 0.015950776636600494}, {"id": 451, "seek": 138000, "start": 1407.0, "end": 1409.0, "text": " And so all of these libraries", "tokens": [51714, 400, 370, 439, 295, 613, 15148, 51814], "temperature": 0.0, "avg_logprob": -0.11866488699185646, "compression_ratio": 1.7007575757575757, "no_speech_prob": 0.015950776636600494}, {"id": 452, "seek": 140900, "start": 1409.0, "end": 1411.0, "text": " Even though they've been made independently", "tokens": [50364, 2754, 1673, 436, 600, 668, 1027, 21761, 50464], "temperature": 0.0, "avg_logprob": -0.08801886818625711, "compression_ratio": 1.642570281124498, "no_speech_prob": 0.020548928529024124}, {"id": 453, "seek": 140900, "start": 1411.0, "end": 1413.0, "text": " By different people, they can all work together", "tokens": [50464, 3146, 819, 561, 11, 436, 393, 439, 589, 1214, 50564], "temperature": 0.0, "avg_logprob": -0.08801886818625711, "compression_ratio": 1.642570281124498, "no_speech_prob": 0.020548928529024124}, {"id": 454, "seek": 140900, "start": 1413.0, "end": 1415.0, "text": " They all share the same primitives", "tokens": [50564, 814, 439, 2073, 264, 912, 2886, 38970, 50664], "temperature": 0.0, "avg_logprob": -0.08801886818625711, "compression_ratio": 1.642570281124498, "no_speech_prob": 0.020548928529024124}, {"id": 455, "seek": 140900, "start": 1415.0, "end": 1417.0, "text": " And you can say, well I want that API client", "tokens": [50664, 400, 291, 393, 584, 11, 731, 286, 528, 300, 9362, 6423, 50764], "temperature": 0.0, "avg_logprob": -0.08801886818625711, "compression_ratio": 1.642570281124498, "no_speech_prob": 0.020548928529024124}, {"id": 456, "seek": 140900, "start": 1417.0, "end": 1420.0, "text": " With that HDP client on the front end", "tokens": [50764, 2022, 300, 389, 11373, 6423, 322, 264, 1868, 917, 50914], "temperature": 0.0, "avg_logprob": -0.08801886818625711, "compression_ratio": 1.642570281124498, "no_speech_prob": 0.020548928529024124}, {"id": 457, "seek": 140900, "start": 1420.0, "end": 1422.0, "text": " And that HDP client on the back end", "tokens": [50914, 400, 300, 389, 11373, 6423, 322, 264, 646, 917, 51014], "temperature": 0.0, "avg_logprob": -0.08801886818625711, "compression_ratio": 1.642570281124498, "no_speech_prob": 0.020548928529024124}, {"id": 458, "seek": 140900, "start": 1422.0, "end": 1424.0, "text": " And I'm going to handle it with that server in my tests", "tokens": [51014, 400, 286, 478, 516, 281, 4813, 309, 365, 300, 7154, 294, 452, 6921, 51114], "temperature": 0.0, "avg_logprob": -0.08801886818625711, "compression_ratio": 1.642570281124498, "no_speech_prob": 0.020548928529024124}, {"id": 459, "seek": 140900, "start": 1424.0, "end": 1426.0, "text": " Fantastic, and it all just nits together", "tokens": [51114, 21320, 11, 293, 309, 439, 445, 297, 1208, 1214, 51214], "temperature": 0.0, "avg_logprob": -0.08801886818625711, "compression_ratio": 1.642570281124498, "no_speech_prob": 0.020548928529024124}, {"id": 460, "seek": 140900, "start": 1433.0, "end": 1435.0, "text": " Enough about Web", "tokens": [51564, 19401, 466, 9573, 51664], "temperature": 0.0, "avg_logprob": -0.08801886818625711, "compression_ratio": 1.642570281124498, "no_speech_prob": 0.020548928529024124}, {"id": 461, "seek": 140900, "start": 1435.0, "end": 1437.0, "text": " There's lots of other cool places we can run code", "tokens": [51664, 821, 311, 3195, 295, 661, 1627, 3190, 321, 393, 1190, 3089, 51764], "temperature": 0.0, "avg_logprob": -0.08801886818625711, "compression_ratio": 1.642570281124498, "no_speech_prob": 0.020548928529024124}, {"id": 462, "seek": 143700, "start": 1437.0, "end": 1439.0, "text": " One of them, we probably will do an awful lot", "tokens": [50364, 1485, 295, 552, 11, 321, 1391, 486, 360, 364, 11232, 688, 50464], "temperature": 0.0, "avg_logprob": -0.13710134249206976, "compression_ratio": 1.740484429065744, "no_speech_prob": 0.07256795465946198}, {"id": 463, "seek": 143700, "start": 1439.0, "end": 1441.0, "text": " Is on the command line", "tokens": [50464, 1119, 322, 264, 5622, 1622, 50564], "temperature": 0.0, "avg_logprob": -0.13710134249206976, "compression_ratio": 1.740484429065744, "no_speech_prob": 0.07256795465946198}, {"id": 464, "seek": 143700, "start": 1441.0, "end": 1443.0, "text": " And there's this really lovely project called T-Shop", "tokens": [50564, 400, 456, 311, 341, 534, 7496, 1716, 1219, 314, 12, 7774, 404, 50664], "temperature": 0.0, "avg_logprob": -0.13710134249206976, "compression_ratio": 1.740484429065744, "no_speech_prob": 0.07256795465946198}, {"id": 465, "seek": 143700, "start": 1443.0, "end": 1445.0, "text": " Where you can", "tokens": [50664, 2305, 291, 393, 50764], "temperature": 0.0, "avg_logprob": -0.13710134249206976, "compression_ratio": 1.740484429065744, "no_speech_prob": 0.07256795465946198}, {"id": 466, "seek": 143700, "start": 1445.0, "end": 1448.0, "text": " It's a similar sort of Elm updated type thing", "tokens": [50764, 467, 311, 257, 2531, 1333, 295, 2699, 76, 10588, 2010, 551, 50914], "temperature": 0.0, "avg_logprob": -0.13710134249206976, "compression_ratio": 1.740484429065744, "no_speech_prob": 0.07256795465946198}, {"id": 467, "seek": 143700, "start": 1448.0, "end": 1450.0, "text": " But rather than being events coming from a DOM", "tokens": [50914, 583, 2831, 813, 885, 3931, 1348, 490, 257, 35727, 51014], "temperature": 0.0, "avg_logprob": -0.13710134249206976, "compression_ratio": 1.740484429065744, "no_speech_prob": 0.07256795465946198}, {"id": 468, "seek": 143700, "start": 1450.0, "end": 1452.0, "text": " It's events coming from a terminal", "tokens": [51014, 467, 311, 3931, 1348, 490, 257, 14709, 51114], "temperature": 0.0, "avg_logprob": -0.13710134249206976, "compression_ratio": 1.740484429065744, "no_speech_prob": 0.07256795465946198}, {"id": 469, "seek": 143700, "start": 1452.0, "end": 1454.0, "text": " So you can make these really lovely interactive", "tokens": [51114, 407, 291, 393, 652, 613, 534, 7496, 15141, 51214], "temperature": 0.0, "avg_logprob": -0.13710134249206976, "compression_ratio": 1.740484429065744, "no_speech_prob": 0.07256795465946198}, {"id": 470, "seek": 143700, "start": 1454.0, "end": 1456.0, "text": " Tuis in Gleam", "tokens": [51214, 7836, 271, 294, 460, 306, 335, 51314], "temperature": 0.0, "avg_logprob": -0.13710134249206976, "compression_ratio": 1.740484429065744, "no_speech_prob": 0.07256795465946198}, {"id": 471, "seek": 143700, "start": 1456.0, "end": 1458.0, "text": " Sadly at the moment you can't run this code on the Beam", "tokens": [51314, 29628, 412, 264, 1623, 291, 393, 380, 1190, 341, 3089, 322, 264, 40916, 51414], "temperature": 0.0, "avg_logprob": -0.13710134249206976, "compression_ratio": 1.740484429065744, "no_speech_prob": 0.07256795465946198}, {"id": 472, "seek": 143700, "start": 1458.0, "end": 1460.0, "text": " Because there's a few", "tokens": [51414, 1436, 456, 311, 257, 1326, 51514], "temperature": 0.0, "avg_logprob": -0.13710134249206976, "compression_ratio": 1.740484429065744, "no_speech_prob": 0.07256795465946198}, {"id": 473, "seek": 143700, "start": 1460.0, "end": 1462.0, "text": " There's a few quirks of how", "tokens": [51514, 821, 311, 257, 1326, 35645, 1694, 295, 577, 51614], "temperature": 0.0, "avg_logprob": -0.13710134249206976, "compression_ratio": 1.740484429065744, "no_speech_prob": 0.07256795465946198}, {"id": 474, "seek": 143700, "start": 1462.0, "end": 1464.0, "text": " The Beam handles standard input", "tokens": [51614, 440, 40916, 18722, 3832, 4846, 51714], "temperature": 0.0, "avg_logprob": -0.13710134249206976, "compression_ratio": 1.740484429065744, "no_speech_prob": 0.07256795465946198}, {"id": 475, "seek": 143700, "start": 1464.0, "end": 1466.0, "text": " But hopefully we can make a proposal to", "tokens": [51714, 583, 4696, 321, 393, 652, 257, 11494, 281, 51814], "temperature": 0.0, "avg_logprob": -0.13710134249206976, "compression_ratio": 1.740484429065744, "no_speech_prob": 0.07256795465946198}, {"id": 476, "seek": 146600, "start": 1466.0, "end": 1468.0, "text": " The OTP team and they can expose", "tokens": [50364, 440, 422, 16804, 1469, 293, 436, 393, 19219, 50464], "temperature": 0.0, "avg_logprob": -0.17941992844992538, "compression_ratio": 1.5604395604395604, "no_speech_prob": 0.027349216863512993}, {"id": 477, "seek": 146600, "start": 1468.0, "end": 1470.0, "text": " A couple of functions that you can't get to", "tokens": [50464, 316, 1916, 295, 6828, 300, 291, 393, 380, 483, 281, 50564], "temperature": 0.0, "avg_logprob": -0.17941992844992538, "compression_ratio": 1.5604395604395604, "no_speech_prob": 0.027349216863512993}, {"id": 478, "seek": 146600, "start": 1470.0, "end": 1472.0, "text": " And then we can have exactly the same thing", "tokens": [50564, 400, 550, 321, 393, 362, 2293, 264, 912, 551, 50664], "temperature": 0.0, "avg_logprob": -0.17941992844992538, "compression_ratio": 1.5604395604395604, "no_speech_prob": 0.027349216863512993}, {"id": 479, "seek": 146600, "start": 1472.0, "end": 1475.0, "text": " In Elixir and Erlang and all sorts of other languages as well", "tokens": [50664, 682, 2699, 970, 347, 293, 3300, 25241, 293, 439, 7527, 295, 661, 8650, 382, 731, 50814], "temperature": 0.0, "avg_logprob": -0.17941992844992538, "compression_ratio": 1.5604395604395604, "no_speech_prob": 0.027349216863512993}, {"id": 480, "seek": 146600, "start": 1477.0, "end": 1479.0, "text": " And because I've showed lots of libraries", "tokens": [50914, 400, 570, 286, 600, 4712, 3195, 295, 15148, 51014], "temperature": 0.0, "avg_logprob": -0.17941992844992538, "compression_ratio": 1.5604395604395604, "no_speech_prob": 0.027349216863512993}, {"id": 481, "seek": 146600, "start": 1479.0, "end": 1481.0, "text": " Let's look at an application", "tokens": [51014, 961, 311, 574, 412, 364, 3861, 51114], "temperature": 0.0, "avg_logprob": -0.17941992844992538, "compression_ratio": 1.5604395604395604, "no_speech_prob": 0.027349216863512993}, {"id": 482, "seek": 146600, "start": 1481.0, "end": 1483.0, "text": " I think this is really cool", "tokens": [51114, 286, 519, 341, 307, 534, 1627, 51214], "temperature": 0.0, "avg_logprob": -0.17941992844992538, "compression_ratio": 1.5604395604395604, "no_speech_prob": 0.027349216863512993}, {"id": 483, "seek": 146600, "start": 1483.0, "end": 1485.0, "text": " This is, I'm going to butcher the name", "tokens": [51214, 639, 307, 11, 286, 478, 516, 281, 41579, 264, 1315, 51314], "temperature": 0.0, "avg_logprob": -0.17941992844992538, "compression_ratio": 1.5604395604395604, "no_speech_prob": 0.027349216863512993}, {"id": 484, "seek": 146600, "start": 1485.0, "end": 1487.0, "text": " Electrophonie, maybe", "tokens": [51314, 12575, 11741, 266, 414, 11, 1310, 51414], "temperature": 0.0, "avg_logprob": -0.17941992844992538, "compression_ratio": 1.5604395604395604, "no_speech_prob": 0.027349216863512993}, {"id": 485, "seek": 146600, "start": 1487.0, "end": 1490.0, "text": " Which is a music streaming app", "tokens": [51414, 3013, 307, 257, 1318, 11791, 724, 51564], "temperature": 0.0, "avg_logprob": -0.17941992844992538, "compression_ratio": 1.5604395604395604, "no_speech_prob": 0.027349216863512993}, {"id": 486, "seek": 146600, "start": 1490.0, "end": 1492.0, "text": " Similar to Spotify or such", "tokens": [51564, 10905, 281, 29036, 420, 1270, 51664], "temperature": 0.0, "avg_logprob": -0.17941992844992538, "compression_ratio": 1.5604395604395604, "no_speech_prob": 0.027349216863512993}, {"id": 487, "seek": 146600, "start": 1492.0, "end": 1495.0, "text": " And it is written in Gleam", "tokens": [51664, 400, 309, 307, 3720, 294, 460, 306, 335, 51814], "temperature": 0.0, "avg_logprob": -0.17941992844992538, "compression_ratio": 1.5604395604395604, "no_speech_prob": 0.027349216863512993}, {"id": 488, "seek": 149500, "start": 1495.0, "end": 1497.0, "text": " Part of JavaScript using Luster", "tokens": [50364, 4100, 295, 15778, 1228, 441, 8393, 50464], "temperature": 0.0, "avg_logprob": -0.15945477919145065, "compression_ratio": 1.617283950617284, "no_speech_prob": 0.028885355219244957}, {"id": 489, "seek": 149500, "start": 1497.0, "end": 1500.0, "text": " And then because we've got this really excellent FFI", "tokens": [50464, 400, 550, 570, 321, 600, 658, 341, 534, 7103, 479, 38568, 50614], "temperature": 0.0, "avg_logprob": -0.15945477919145065, "compression_ratio": 1.617283950617284, "no_speech_prob": 0.028885355219244957}, {"id": 490, "seek": 149500, "start": 1500.0, "end": 1502.0, "text": " So we can call into", "tokens": [50614, 407, 321, 393, 818, 666, 50714], "temperature": 0.0, "avg_logprob": -0.15945477919145065, "compression_ratio": 1.617283950617284, "no_speech_prob": 0.028885355219244957}, {"id": 491, "seek": 149500, "start": 1502.0, "end": 1504.0, "text": " So we can call into other languages", "tokens": [50714, 407, 321, 393, 818, 666, 661, 8650, 50814], "temperature": 0.0, "avg_logprob": -0.15945477919145065, "compression_ratio": 1.617283950617284, "no_speech_prob": 0.028885355219244957}, {"id": 492, "seek": 149500, "start": 1504.0, "end": 1507.0, "text": " And we can use all these web APIs", "tokens": [50814, 400, 321, 393, 764, 439, 613, 3670, 21445, 50964], "temperature": 0.0, "avg_logprob": -0.15945477919145065, "compression_ratio": 1.617283950617284, "no_speech_prob": 0.028885355219244957}, {"id": 493, "seek": 149500, "start": 1507.0, "end": 1509.0, "text": " And do things like use the media keys", "tokens": [50964, 400, 360, 721, 411, 764, 264, 3021, 9317, 51064], "temperature": 0.0, "avg_logprob": -0.15945477919145065, "compression_ratio": 1.617283950617284, "no_speech_prob": 0.028885355219244957}, {"id": 494, "seek": 149500, "start": 1509.0, "end": 1511.0, "text": " Be on the lock screen of a phone", "tokens": [51064, 879, 322, 264, 4017, 2568, 295, 257, 2593, 51164], "temperature": 0.0, "avg_logprob": -0.15945477919145065, "compression_ratio": 1.617283950617284, "no_speech_prob": 0.028885355219244957}, {"id": 495, "seek": 149500, "start": 1511.0, "end": 1514.0, "text": " Be in that little bit of the top of your computer", "tokens": [51164, 879, 294, 300, 707, 857, 295, 264, 1192, 295, 428, 3820, 51314], "temperature": 0.0, "avg_logprob": -0.15945477919145065, "compression_ratio": 1.617283950617284, "no_speech_prob": 0.028885355219244957}, {"id": 496, "seek": 149500, "start": 1514.0, "end": 1516.0, "text": " Where the music thing is", "tokens": [51314, 2305, 264, 1318, 551, 307, 51414], "temperature": 0.0, "avg_logprob": -0.15945477919145065, "compression_ratio": 1.617283950617284, "no_speech_prob": 0.028885355219244957}, {"id": 497, "seek": 149500, "start": 1516.0, "end": 1518.0, "text": " I don't know what it's called", "tokens": [51414, 286, 500, 380, 458, 437, 309, 311, 1219, 51514], "temperature": 0.0, "avg_logprob": -0.15945477919145065, "compression_ratio": 1.617283950617284, "no_speech_prob": 0.028885355219244957}, {"id": 498, "seek": 149500, "start": 1519.0, "end": 1522.0, "text": " And, yeah, the ecosystem is really growing", "tokens": [51564, 400, 11, 1338, 11, 264, 11311, 307, 534, 4194, 51714], "temperature": 0.0, "avg_logprob": -0.15945477919145065, "compression_ratio": 1.617283950617284, "no_speech_prob": 0.028885355219244957}, {"id": 499, "seek": 152200, "start": 1523.0, "end": 1525.0, "text": " I think there's a name for that kind of curve", "tokens": [50414, 286, 519, 456, 311, 257, 1315, 337, 300, 733, 295, 7605, 50514], "temperature": 0.0, "avg_logprob": -0.09833272558743836, "compression_ratio": 1.5684647302904564, "no_speech_prob": 0.03652836009860039}, {"id": 500, "seek": 152200, "start": 1525.0, "end": 1527.0, "text": " I'm not sure what it is", "tokens": [50514, 286, 478, 406, 988, 437, 309, 307, 50614], "temperature": 0.0, "avg_logprob": -0.09833272558743836, "compression_ratio": 1.5684647302904564, "no_speech_prob": 0.03652836009860039}, {"id": 501, "seek": 152200, "start": 1528.0, "end": 1530.0, "text": " But we are now 1.2% of hex", "tokens": [50664, 583, 321, 366, 586, 502, 13, 17, 4, 295, 23291, 50764], "temperature": 0.0, "avg_logprob": -0.09833272558743836, "compression_ratio": 1.5684647302904564, "no_speech_prob": 0.03652836009860039}, {"id": 502, "seek": 152200, "start": 1530.0, "end": 1532.0, "text": " Which is a tiny number, but bear in mind", "tokens": [50764, 3013, 307, 257, 5870, 1230, 11, 457, 6155, 294, 1575, 50864], "temperature": 0.0, "avg_logprob": -0.09833272558743836, "compression_ratio": 1.5684647302904564, "no_speech_prob": 0.03652836009860039}, {"id": 503, "seek": 152200, "start": 1532.0, "end": 1534.0, "text": " We're not at version one yet", "tokens": [50864, 492, 434, 406, 412, 3037, 472, 1939, 50964], "temperature": 0.0, "avg_logprob": -0.09833272558743836, "compression_ratio": 1.5684647302904564, "no_speech_prob": 0.03652836009860039}, {"id": 504, "seek": 152200, "start": 1534.0, "end": 1536.0, "text": " And Elixir's been at version one for 10 years", "tokens": [50964, 400, 2699, 970, 347, 311, 668, 412, 3037, 472, 337, 1266, 924, 51064], "temperature": 0.0, "avg_logprob": -0.09833272558743836, "compression_ratio": 1.5684647302904564, "no_speech_prob": 0.03652836009860039}, {"id": 505, "seek": 152200, "start": 1536.0, "end": 1538.0, "text": " Something like that", "tokens": [51064, 6595, 411, 300, 51164], "temperature": 0.0, "avg_logprob": -0.09833272558743836, "compression_ratio": 1.5684647302904564, "no_speech_prob": 0.03652836009860039}, {"id": 506, "seek": 152200, "start": 1538.0, "end": 1540.0, "text": " I think that's really impressive", "tokens": [51164, 286, 519, 300, 311, 534, 8992, 51264], "temperature": 0.0, "avg_logprob": -0.09833272558743836, "compression_ratio": 1.5684647302904564, "no_speech_prob": 0.03652836009860039}, {"id": 507, "seek": 152200, "start": 1540.0, "end": 1542.0, "text": " And I really hope that that is going to keep going", "tokens": [51264, 400, 286, 534, 1454, 300, 300, 307, 516, 281, 1066, 516, 51364], "temperature": 0.0, "avg_logprob": -0.09833272558743836, "compression_ratio": 1.5684647302904564, "no_speech_prob": 0.03652836009860039}, {"id": 508, "seek": 152200, "start": 1543.0, "end": 1546.0, "text": " So, where are we going?", "tokens": [51414, 407, 11, 689, 366, 321, 516, 30, 51564], "temperature": 0.0, "avg_logprob": -0.09833272558743836, "compression_ratio": 1.5684647302904564, "no_speech_prob": 0.03652836009860039}, {"id": 509, "seek": 152200, "start": 1546.0, "end": 1548.0, "text": " What comes next?", "tokens": [51564, 708, 1487, 958, 30, 51664], "temperature": 0.0, "avg_logprob": -0.09833272558743836, "compression_ratio": 1.5684647302904564, "no_speech_prob": 0.03652836009860039}, {"id": 510, "seek": 152200, "start": 1548.0, "end": 1551.0, "text": " So, Gleam isn't done", "tokens": [51664, 407, 11, 460, 306, 335, 1943, 380, 1096, 51814], "temperature": 0.0, "avg_logprob": -0.09833272558743836, "compression_ratio": 1.5684647302904564, "no_speech_prob": 0.03652836009860039}, {"id": 511, "seek": 155100, "start": 1551.0, "end": 1554.0, "text": " A lot of things are very mature, but there are still things to work on", "tokens": [50364, 316, 688, 295, 721, 366, 588, 14442, 11, 457, 456, 366, 920, 721, 281, 589, 322, 50514], "temperature": 0.0, "avg_logprob": -0.13741751992778414, "compression_ratio": 1.842443729903537, "no_speech_prob": 0.03474465385079384}, {"id": 512, "seek": 155100, "start": 1554.0, "end": 1557.0, "text": " And the thing I really want to focus on for the next year is the language server", "tokens": [50514, 400, 264, 551, 286, 534, 528, 281, 1879, 322, 337, 264, 958, 1064, 307, 264, 2856, 7154, 50664], "temperature": 0.0, "avg_logprob": -0.13741751992778414, "compression_ratio": 1.842443729903537, "no_speech_prob": 0.03474465385079384}, {"id": 513, "seek": 155100, "start": 1557.0, "end": 1559.0, "text": " So, what is a language server?", "tokens": [50664, 407, 11, 437, 307, 257, 2856, 7154, 30, 50764], "temperature": 0.0, "avg_logprob": -0.13741751992778414, "compression_ratio": 1.842443729903537, "no_speech_prob": 0.03474465385079384}, {"id": 514, "seek": 155100, "start": 1559.0, "end": 1562.0, "text": " Just to make sure everybody's on the same page", "tokens": [50764, 1449, 281, 652, 988, 2201, 311, 322, 264, 912, 3028, 50914], "temperature": 0.0, "avg_logprob": -0.13741751992778414, "compression_ratio": 1.842443729903537, "no_speech_prob": 0.03474465385079384}, {"id": 515, "seek": 155100, "start": 1562.0, "end": 1566.0, "text": " So, traditionally, if you are making a text editor, an IDE", "tokens": [50914, 407, 11, 19067, 11, 498, 291, 366, 1455, 257, 2487, 9839, 11, 364, 40930, 51114], "temperature": 0.0, "avg_logprob": -0.13741751992778414, "compression_ratio": 1.842443729903537, "no_speech_prob": 0.03474465385079384}, {"id": 516, "seek": 155100, "start": 1566.0, "end": 1568.0, "text": " And you want to support a language or a plugin", "tokens": [51114, 400, 291, 528, 281, 1406, 257, 2856, 420, 257, 23407, 51214], "temperature": 0.0, "avg_logprob": -0.13741751992778414, "compression_ratio": 1.842443729903537, "no_speech_prob": 0.03474465385079384}, {"id": 517, "seek": 155100, "start": 1568.0, "end": 1570.0, "text": " So that they can support a language", "tokens": [51214, 407, 300, 436, 393, 1406, 257, 2856, 51314], "temperature": 0.0, "avg_logprob": -0.13741751992778414, "compression_ratio": 1.842443729903537, "no_speech_prob": 0.03474465385079384}, {"id": 518, "seek": 155100, "start": 1570.0, "end": 1573.0, "text": " You need to then work at how to learn all those things about the code layer", "tokens": [51314, 509, 643, 281, 550, 589, 412, 577, 281, 1466, 439, 729, 721, 466, 264, 3089, 4583, 51464], "temperature": 0.0, "avg_logprob": -0.13741751992778414, "compression_ratio": 1.842443729903537, "no_speech_prob": 0.03474465385079384}, {"id": 519, "seek": 155100, "start": 1573.0, "end": 1575.0, "text": " Oh, how do I know if there's an error?", "tokens": [51464, 876, 11, 577, 360, 286, 458, 498, 456, 311, 364, 6713, 30, 51564], "temperature": 0.0, "avg_logprob": -0.13741751992778414, "compression_ratio": 1.842443729903537, "no_speech_prob": 0.03474465385079384}, {"id": 520, "seek": 155100, "start": 1575.0, "end": 1577.0, "text": " How do I know what I can auto-complete with?", "tokens": [51564, 1012, 360, 286, 458, 437, 286, 393, 8399, 12, 1112, 17220, 365, 30, 51664], "temperature": 0.0, "avg_logprob": -0.13741751992778414, "compression_ratio": 1.842443729903537, "no_speech_prob": 0.03474465385079384}, {"id": 521, "seek": 155100, "start": 1577.0, "end": 1579.0, "text": " How do I know what snippets would expand?", "tokens": [51664, 1012, 360, 286, 458, 437, 35623, 1385, 576, 5268, 30, 51764], "temperature": 0.0, "avg_logprob": -0.13741751992778414, "compression_ratio": 1.842443729903537, "no_speech_prob": 0.03474465385079384}, {"id": 522, "seek": 157900, "start": 1579.0, "end": 1581.0, "text": " How do I know what refactoring is I can do?", "tokens": [50364, 1012, 360, 286, 458, 437, 1895, 578, 3662, 307, 286, 393, 360, 30, 50464], "temperature": 0.0, "avg_logprob": -0.15138216813405356, "compression_ratio": 1.7549668874172186, "no_speech_prob": 0.024395572021603584}, {"id": 523, "seek": 157900, "start": 1581.0, "end": 1583.0, "text": " You'd have to individually implement all those things", "tokens": [50464, 509, 1116, 362, 281, 16652, 4445, 439, 729, 721, 50564], "temperature": 0.0, "avg_logprob": -0.15138216813405356, "compression_ratio": 1.7549668874172186, "no_speech_prob": 0.024395572021603584}, {"id": 524, "seek": 157900, "start": 1583.0, "end": 1587.0, "text": " But some clever clogs, I think at Microsoft, came up with this idea of", "tokens": [50564, 583, 512, 13494, 34455, 82, 11, 286, 519, 412, 8116, 11, 1361, 493, 365, 341, 1558, 295, 50764], "temperature": 0.0, "avg_logprob": -0.15138216813405356, "compression_ratio": 1.7549668874172186, "no_speech_prob": 0.024395572021603584}, {"id": 525, "seek": 157900, "start": 1587.0, "end": 1589.0, "text": " We're going to have a language server, we're going to define a protocol", "tokens": [50764, 492, 434, 516, 281, 362, 257, 2856, 7154, 11, 321, 434, 516, 281, 6964, 257, 10336, 50864], "temperature": 0.0, "avg_logprob": -0.15138216813405356, "compression_ratio": 1.7549668874172186, "no_speech_prob": 0.024395572021603584}, {"id": 526, "seek": 157900, "start": 1589.0, "end": 1592.0, "text": " That all the editors can speak and all these backends can speak", "tokens": [50864, 663, 439, 264, 31446, 393, 1710, 293, 439, 613, 646, 2581, 393, 1710, 51014], "temperature": 0.0, "avg_logprob": -0.15138216813405356, "compression_ratio": 1.7549668874172186, "no_speech_prob": 0.024395572021603584}, {"id": 527, "seek": 157900, "start": 1592.0, "end": 1594.0, "text": " And all you need to do is implement the protocol", "tokens": [51014, 400, 439, 291, 643, 281, 360, 307, 4445, 264, 10336, 51114], "temperature": 0.0, "avg_logprob": -0.15138216813405356, "compression_ratio": 1.7549668874172186, "no_speech_prob": 0.024395572021603584}, {"id": 528, "seek": 157900, "start": 1594.0, "end": 1597.0, "text": " And then suddenly we can have one brain of an editor", "tokens": [51114, 400, 550, 5800, 321, 393, 362, 472, 3567, 295, 364, 9839, 51264], "temperature": 0.0, "avg_logprob": -0.15138216813405356, "compression_ratio": 1.7549668874172186, "no_speech_prob": 0.024395572021603584}, {"id": 529, "seek": 157900, "start": 1597.0, "end": 1604.0, "text": " And that can talk to Elix and Vim and Emacs and VS Code and Zed", "tokens": [51264, 400, 300, 393, 751, 281, 2699, 970, 293, 691, 332, 293, 3968, 44937, 293, 25091, 15549, 293, 1176, 292, 51614], "temperature": 0.0, "avg_logprob": -0.15138216813405356, "compression_ratio": 1.7549668874172186, "no_speech_prob": 0.024395572021603584}, {"id": 530, "seek": 157900, "start": 1604.0, "end": 1606.0, "text": " And all these other cool ones", "tokens": [51614, 400, 439, 613, 661, 1627, 2306, 51714], "temperature": 0.0, "avg_logprob": -0.15138216813405356, "compression_ratio": 1.7549668874172186, "no_speech_prob": 0.024395572021603584}, {"id": 531, "seek": 157900, "start": 1606.0, "end": 1607.0, "text": " And so we've got one of those", "tokens": [51714, 400, 370, 321, 600, 658, 472, 295, 729, 51764], "temperature": 0.0, "avg_logprob": -0.15138216813405356, "compression_ratio": 1.7549668874172186, "no_speech_prob": 0.024395572021603584}, {"id": 532, "seek": 160700, "start": 1607.0, "end": 1611.0, "text": " Built into the binary that you get when you download Glim", "tokens": [50364, 49822, 666, 264, 17434, 300, 291, 483, 562, 291, 5484, 460, 4197, 50564], "temperature": 0.0, "avg_logprob": -0.1388769242370013, "compression_ratio": 1.5525291828793775, "no_speech_prob": 0.0574878491461277}, {"id": 533, "seek": 160700, "start": 1611.0, "end": 1614.0, "text": " Excuse me", "tokens": [50564, 11359, 385, 50714], "temperature": 0.0, "avg_logprob": -0.1388769242370013, "compression_ratio": 1.5525291828793775, "no_speech_prob": 0.0574878491461277}, {"id": 534, "seek": 160700, "start": 1614.0, "end": 1620.0, "text": " And it works, but it doesn't work as well as I wanted to", "tokens": [50714, 400, 309, 1985, 11, 457, 309, 1177, 380, 589, 382, 731, 382, 286, 1415, 281, 51014], "temperature": 0.0, "avg_logprob": -0.1388769242370013, "compression_ratio": 1.5525291828793775, "no_speech_prob": 0.0574878491461277}, {"id": 535, "seek": 160700, "start": 1620.0, "end": 1623.0, "text": " It's definitely the least mature part of the whole GLEE ecosystem", "tokens": [51014, 467, 311, 2138, 264, 1935, 14442, 644, 295, 264, 1379, 460, 2634, 36, 11311, 51164], "temperature": 0.0, "avg_logprob": -0.1388769242370013, "compression_ratio": 1.5525291828793775, "no_speech_prob": 0.0574878491461277}, {"id": 536, "seek": 160700, "start": 1623.0, "end": 1625.0, "text": " And a big part of that is my fault", "tokens": [51164, 400, 257, 955, 644, 295, 300, 307, 452, 7441, 51264], "temperature": 0.0, "avg_logprob": -0.1388769242370013, "compression_ratio": 1.5525291828793775, "no_speech_prob": 0.0574878491461277}, {"id": 537, "seek": 160700, "start": 1625.0, "end": 1628.0, "text": " I've been developing it entirely on Visual Studio Code", "tokens": [51264, 286, 600, 668, 6416, 309, 7696, 322, 23187, 13500, 15549, 51414], "temperature": 0.0, "avg_logprob": -0.1388769242370013, "compression_ratio": 1.5525291828793775, "no_speech_prob": 0.0574878491461277}, {"id": 538, "seek": 160700, "start": 1628.0, "end": 1633.0, "text": " And it means the protocol is a little ambiguous in places", "tokens": [51414, 400, 309, 1355, 264, 10336, 307, 257, 707, 39465, 294, 3190, 51664], "temperature": 0.0, "avg_logprob": -0.1388769242370013, "compression_ratio": 1.5525291828793775, "no_speech_prob": 0.0574878491461277}, {"id": 539, "seek": 160700, "start": 1633.0, "end": 1636.0, "text": " In a way that I find quite irritating but apparently is fine", "tokens": [51664, 682, 257, 636, 300, 286, 915, 1596, 45971, 457, 7970, 307, 2489, 51814], "temperature": 0.0, "avg_logprob": -0.1388769242370013, "compression_ratio": 1.5525291828793775, "no_speech_prob": 0.0574878491461277}, {"id": 540, "seek": 163600, "start": 1636.0, "end": 1640.0, "text": " So all of the editors do slightly different things when you give it certain data", "tokens": [50364, 407, 439, 295, 264, 31446, 360, 4748, 819, 721, 562, 291, 976, 309, 1629, 1412, 50564], "temperature": 0.0, "avg_logprob": -0.09746916000157187, "compression_ratio": 1.7740963855421688, "no_speech_prob": 0.07156940549612045}, {"id": 541, "seek": 163600, "start": 1640.0, "end": 1643.0, "text": " So we need to spend more time working on the other editors", "tokens": [50564, 407, 321, 643, 281, 3496, 544, 565, 1364, 322, 264, 661, 31446, 50714], "temperature": 0.0, "avg_logprob": -0.09746916000157187, "compression_ratio": 1.7740963855421688, "no_speech_prob": 0.07156940549612045}, {"id": 542, "seek": 163600, "start": 1643.0, "end": 1645.0, "text": " And making sure that it's rock solid and works exactly the same", "tokens": [50714, 400, 1455, 988, 300, 309, 311, 3727, 5100, 293, 1985, 2293, 264, 912, 50814], "temperature": 0.0, "avg_logprob": -0.09746916000157187, "compression_ratio": 1.7740963855421688, "no_speech_prob": 0.07156940549612045}, {"id": 543, "seek": 163600, "start": 1645.0, "end": 1646.0, "text": " And all the other ones", "tokens": [50814, 400, 439, 264, 661, 2306, 50864], "temperature": 0.0, "avg_logprob": -0.09746916000157187, "compression_ratio": 1.7740963855421688, "no_speech_prob": 0.07156940549612045}, {"id": 544, "seek": 163600, "start": 1646.0, "end": 1649.0, "text": " And I switched a knee over them now so it's not going to be a problem anymore", "tokens": [50864, 400, 286, 16858, 257, 9434, 670, 552, 586, 370, 309, 311, 406, 516, 281, 312, 257, 1154, 3602, 51014], "temperature": 0.0, "avg_logprob": -0.09746916000157187, "compression_ratio": 1.7740963855421688, "no_speech_prob": 0.07156940549612045}, {"id": 545, "seek": 163600, "start": 1649.0, "end": 1654.0, "text": " So first step, we're going to get it all working super reliably for everybody", "tokens": [51014, 407, 700, 1823, 11, 321, 434, 516, 281, 483, 309, 439, 1364, 1687, 49927, 337, 2201, 51264], "temperature": 0.0, "avg_logprob": -0.09746916000157187, "compression_ratio": 1.7740963855421688, "no_speech_prob": 0.07156940549612045}, {"id": 546, "seek": 163600, "start": 1654.0, "end": 1656.0, "text": " And then we're going to flesh it out to have everything", "tokens": [51264, 400, 550, 321, 434, 516, 281, 12497, 309, 484, 281, 362, 1203, 51364], "temperature": 0.0, "avg_logprob": -0.09746916000157187, "compression_ratio": 1.7740963855421688, "no_speech_prob": 0.07156940549612045}, {"id": 547, "seek": 163600, "start": 1656.0, "end": 1660.0, "text": " We want to have the same experience that you're going to get with Rust Analyzer", "tokens": [51364, 492, 528, 281, 362, 264, 912, 1752, 300, 291, 434, 516, 281, 483, 365, 34952, 1107, 5222, 4527, 51564], "temperature": 0.0, "avg_logprob": -0.09746916000157187, "compression_ratio": 1.7740963855421688, "no_speech_prob": 0.07156940549612045}, {"id": 548, "seek": 163600, "start": 1660.0, "end": 1664.0, "text": " Or maybe even try and get close to what a JetBrains IDE might give you", "tokens": [51564, 1610, 1310, 754, 853, 293, 483, 1998, 281, 437, 257, 28730, 45606, 1292, 40930, 1062, 976, 291, 51764], "temperature": 0.0, "avg_logprob": -0.09746916000157187, "compression_ratio": 1.7740963855421688, "no_speech_prob": 0.07156940549612045}, {"id": 549, "seek": 166400, "start": 1664.0, "end": 1668.0, "text": " We want it to be a really excellent experience of all these different things", "tokens": [50364, 492, 528, 309, 281, 312, 257, 534, 7103, 1752, 295, 439, 613, 819, 721, 50564], "temperature": 0.0, "avg_logprob": -0.10532595681362465, "compression_ratio": 1.7084745762711864, "no_speech_prob": 0.035115886479616165}, {"id": 550, "seek": 166400, "start": 1668.0, "end": 1673.0, "text": " Find references, renaming things, all sorts of refactorings", "tokens": [50564, 11809, 15400, 11, 8124, 5184, 721, 11, 439, 7527, 295, 1895, 15104, 1109, 50814], "temperature": 0.0, "avg_logprob": -0.10532595681362465, "compression_ratio": 1.7084745762711864, "no_speech_prob": 0.035115886479616165}, {"id": 551, "seek": 166400, "start": 1673.0, "end": 1675.0, "text": " And also code generators, I think are really cool", "tokens": [50814, 400, 611, 3089, 38662, 11, 286, 519, 366, 534, 1627, 50914], "temperature": 0.0, "avg_logprob": -0.10532595681362465, "compression_ratio": 1.7084745762711864, "no_speech_prob": 0.035115886479616165}, {"id": 552, "seek": 166400, "start": 1675.0, "end": 1679.0, "text": " There's loads of bits of trivial code that we bash out every single day about thinking about", "tokens": [50914, 821, 311, 12668, 295, 9239, 295, 26703, 3089, 300, 321, 46183, 484, 633, 2167, 786, 466, 1953, 466, 51114], "temperature": 0.0, "avg_logprob": -0.10532595681362465, "compression_ratio": 1.7084745762711864, "no_speech_prob": 0.035115886479616165}, {"id": 553, "seek": 166400, "start": 1679.0, "end": 1684.0, "text": " Well, if it's that easy, just press a button and have the tooling spit out for you", "tokens": [51114, 1042, 11, 498, 309, 311, 300, 1858, 11, 445, 1886, 257, 2960, 293, 362, 264, 46593, 22127, 484, 337, 291, 51364], "temperature": 0.0, "avg_logprob": -0.10532595681362465, "compression_ratio": 1.7084745762711864, "no_speech_prob": 0.035115886479616165}, {"id": 554, "seek": 166400, "start": 1684.0, "end": 1687.0, "text": " And then you can choose to edit it in whatever way you want", "tokens": [51364, 400, 550, 291, 393, 2826, 281, 8129, 309, 294, 2035, 636, 291, 528, 51514], "temperature": 0.0, "avg_logprob": -0.10532595681362465, "compression_ratio": 1.7084745762711864, "no_speech_prob": 0.035115886479616165}, {"id": 555, "seek": 166400, "start": 1687.0, "end": 1689.0, "text": " So breaking changes", "tokens": [51514, 407, 7697, 2962, 51614], "temperature": 0.0, "avg_logprob": -0.10532595681362465, "compression_ratio": 1.7084745762711864, "no_speech_prob": 0.035115886479616165}, {"id": 556, "seek": 166400, "start": 1689.0, "end": 1691.0, "text": " Over the last year we've had an awful lot of breaking changes", "tokens": [51614, 4886, 264, 1036, 1064, 321, 600, 632, 364, 11232, 688, 295, 7697, 2962, 51714], "temperature": 0.0, "avg_logprob": -0.10532595681362465, "compression_ratio": 1.7084745762711864, "no_speech_prob": 0.035115886479616165}, {"id": 557, "seek": 169100, "start": 1691.0, "end": 1697.0, "text": " Because there was a design and then suddenly a bunch of ULOT turned up and now we had users", "tokens": [50364, 1436, 456, 390, 257, 1715, 293, 550, 5800, 257, 3840, 295, 624, 43, 5068, 3574, 493, 293, 586, 321, 632, 5022, 50664], "temperature": 0.0, "avg_logprob": -0.12583258172043232, "compression_ratio": 1.671280276816609, "no_speech_prob": 0.08619670569896698}, {"id": 558, "seek": 169100, "start": 1697.0, "end": 1701.0, "text": " And then we realised that, oh, actually that original thing that I made up five years ago", "tokens": [50664, 400, 550, 321, 21337, 300, 11, 1954, 11, 767, 300, 3380, 551, 300, 286, 1027, 493, 1732, 924, 2057, 50864], "temperature": 0.0, "avg_logprob": -0.12583258172043232, "compression_ratio": 1.671280276816609, "no_speech_prob": 0.08619670569896698}, {"id": 559, "seek": 169100, "start": 1701.0, "end": 1704.0, "text": " While I was sitting in my room wasn't the best idea", "tokens": [50864, 3987, 286, 390, 3798, 294, 452, 1808, 2067, 380, 264, 1151, 1558, 51014], "temperature": 0.0, "avg_logprob": -0.12583258172043232, "compression_ratio": 1.671280276816609, "no_speech_prob": 0.08619670569896698}, {"id": 560, "seek": 169100, "start": 1704.0, "end": 1708.0, "text": " There are problems, so we've made a load of breaking changes in order to refine them", "tokens": [51014, 821, 366, 2740, 11, 370, 321, 600, 1027, 257, 3677, 295, 7697, 2962, 294, 1668, 281, 33906, 552, 51214], "temperature": 0.0, "avg_logprob": -0.12583258172043232, "compression_ratio": 1.671280276816609, "no_speech_prob": 0.08619670569896698}, {"id": 561, "seek": 169100, "start": 1708.0, "end": 1711.0, "text": " What breaking changes are coming next?", "tokens": [51214, 708, 7697, 2962, 366, 1348, 958, 30, 51364], "temperature": 0.0, "avg_logprob": -0.12583258172043232, "compression_ratio": 1.671280276816609, "no_speech_prob": 0.08619670569896698}, {"id": 562, "seek": 169100, "start": 1711.0, "end": 1714.0, "text": " Hopefully nothing, I think we're there", "tokens": [51364, 10429, 1825, 11, 286, 519, 321, 434, 456, 51514], "temperature": 0.0, "avg_logprob": -0.12583258172043232, "compression_ratio": 1.671280276816609, "no_speech_prob": 0.08619670569896698}, {"id": 563, "seek": 169100, "start": 1714.0, "end": 1717.0, "text": " I think we basically have the language to work exactly as it should", "tokens": [51514, 286, 519, 321, 1936, 362, 264, 2856, 281, 589, 2293, 382, 309, 820, 51664], "temperature": 0.0, "avg_logprob": -0.12583258172043232, "compression_ratio": 1.671280276816609, "no_speech_prob": 0.08619670569896698}, {"id": 564, "seek": 169100, "start": 1717.0, "end": 1719.0, "text": " Which is wonderful", "tokens": [51664, 3013, 307, 3715, 51764], "temperature": 0.0, "avg_logprob": -0.12583258172043232, "compression_ratio": 1.671280276816609, "no_speech_prob": 0.08619670569896698}, {"id": 565, "seek": 171900, "start": 1719.0, "end": 1722.0, "text": " And that kind of begs the question", "tokens": [50364, 400, 300, 733, 295, 4612, 82, 264, 1168, 50514], "temperature": 0.0, "avg_logprob": -0.08919316101074219, "compression_ratio": 1.7671755725190839, "no_speech_prob": 0.039224907755851746}, {"id": 566, "seek": 171900, "start": 1722.0, "end": 1724.0, "text": " Does that mean we can work towards a version one?", "tokens": [50514, 4402, 300, 914, 321, 393, 589, 3030, 257, 3037, 472, 30, 50614], "temperature": 0.0, "avg_logprob": -0.08919316101074219, "compression_ratio": 1.7671755725190839, "no_speech_prob": 0.039224907755851746}, {"id": 567, "seek": 171900, "start": 1724.0, "end": 1727.0, "text": " Yeah, we're working towards a version one", "tokens": [50614, 865, 11, 321, 434, 1364, 3030, 257, 3037, 472, 50764], "temperature": 0.0, "avg_logprob": -0.08919316101074219, "compression_ratio": 1.7671755725190839, "no_speech_prob": 0.039224907755851746}, {"id": 568, "seek": 171900, "start": 1727.0, "end": 1728.0, "text": " So what does that mean?", "tokens": [50764, 407, 437, 775, 300, 914, 30, 50814], "temperature": 0.0, "avg_logprob": -0.08919316101074219, "compression_ratio": 1.7671755725190839, "no_speech_prob": 0.039224907755851746}, {"id": 569, "seek": 171900, "start": 1728.0, "end": 1732.0, "text": " When we get there, what's going to be the points of version one?", "tokens": [50814, 1133, 321, 483, 456, 11, 437, 311, 516, 281, 312, 264, 2793, 295, 3037, 472, 30, 51014], "temperature": 0.0, "avg_logprob": -0.08919316101074219, "compression_ratio": 1.7671755725190839, "no_speech_prob": 0.039224907755851746}, {"id": 570, "seek": 171900, "start": 1732.0, "end": 1734.0, "text": " And I think there are two pillars to this", "tokens": [51014, 400, 286, 519, 456, 366, 732, 26729, 281, 341, 51114], "temperature": 0.0, "avg_logprob": -0.08919316101074219, "compression_ratio": 1.7671755725190839, "no_speech_prob": 0.039224907755851746}, {"id": 571, "seek": 171900, "start": 1734.0, "end": 1738.0, "text": " The first one is productivity for people who are using Gleam", "tokens": [51114, 440, 700, 472, 307, 15604, 337, 561, 567, 366, 1228, 460, 306, 335, 51314], "temperature": 0.0, "avg_logprob": -0.08919316101074219, "compression_ratio": 1.7671755725190839, "no_speech_prob": 0.039224907755851746}, {"id": 572, "seek": 171900, "start": 1738.0, "end": 1740.0, "text": " So that's going to be no breaking changes", "tokens": [51314, 407, 300, 311, 516, 281, 312, 572, 7697, 2962, 51414], "temperature": 0.0, "avg_logprob": -0.08919316101074219, "compression_ratio": 1.7671755725190839, "no_speech_prob": 0.039224907755851746}, {"id": 573, "seek": 171900, "start": 1740.0, "end": 1744.0, "text": " You can't build on top of foundation that's constantly changing on you", "tokens": [51414, 509, 393, 380, 1322, 322, 1192, 295, 7030, 300, 311, 6460, 4473, 322, 291, 51614], "temperature": 0.0, "avg_logprob": -0.08919316101074219, "compression_ratio": 1.7671755725190839, "no_speech_prob": 0.039224907755851746}, {"id": 574, "seek": 171900, "start": 1744.0, "end": 1746.0, "text": " We won't have no language bloat", "tokens": [51614, 492, 1582, 380, 362, 572, 2856, 1749, 267, 51714], "temperature": 0.0, "avg_logprob": -0.08919316101074219, "compression_ratio": 1.7671755725190839, "no_speech_prob": 0.039224907755851746}, {"id": 575, "seek": 174600, "start": 1746.0, "end": 1752.0, "text": " I'd be really proud of how we've really honed in on what makes Gleam good", "tokens": [50364, 286, 1116, 312, 534, 4570, 295, 577, 321, 600, 534, 2157, 292, 294, 322, 437, 1669, 460, 306, 335, 665, 50664], "temperature": 0.0, "avg_logprob": -0.10684073217983904, "compression_ratio": 1.8054607508532423, "no_speech_prob": 0.09756047278642654}, {"id": 576, "seek": 174600, "start": 1752.0, "end": 1756.0, "text": " And by having a very small, concise, consistent surface area", "tokens": [50664, 400, 538, 1419, 257, 588, 1359, 11, 44882, 11, 8398, 3753, 1859, 50864], "temperature": 0.0, "avg_logprob": -0.10684073217983904, "compression_ratio": 1.8054607508532423, "no_speech_prob": 0.09756047278642654}, {"id": 577, "seek": 174600, "start": 1756.0, "end": 1758.0, "text": " It makes it easy to work with", "tokens": [50864, 467, 1669, 309, 1858, 281, 589, 365, 50964], "temperature": 0.0, "avg_logprob": -0.10684073217983904, "compression_ratio": 1.8054607508532423, "no_speech_prob": 0.09756047278642654}, {"id": 578, "seek": 174600, "start": 1758.0, "end": 1759.0, "text": " And I want to keep that property", "tokens": [50964, 400, 286, 528, 281, 1066, 300, 4707, 51014], "temperature": 0.0, "avg_logprob": -0.10684073217983904, "compression_ratio": 1.8054607508532423, "no_speech_prob": 0.09756047278642654}, {"id": 579, "seek": 174600, "start": 1759.0, "end": 1762.0, "text": " I think it's very tempting for languages to hit version one and then go", "tokens": [51014, 286, 519, 309, 311, 588, 37900, 337, 8650, 281, 2045, 3037, 472, 293, 550, 352, 51164], "temperature": 0.0, "avg_logprob": -0.10684073217983904, "compression_ratio": 1.8054607508532423, "no_speech_prob": 0.09756047278642654}, {"id": 580, "seek": 174600, "start": 1762.0, "end": 1764.0, "text": " Oh, maybe we need this feature", "tokens": [51164, 876, 11, 1310, 321, 643, 341, 4111, 51264], "temperature": 0.0, "avg_logprob": -0.10684073217983904, "compression_ratio": 1.8054607508532423, "no_speech_prob": 0.09756047278642654}, {"id": 581, "seek": 174600, "start": 1764.0, "end": 1767.0, "text": " Or maybe we need typeplosses, maybe we need these things", "tokens": [51264, 1610, 1310, 321, 643, 2010, 564, 772, 279, 11, 1310, 321, 643, 613, 721, 51414], "temperature": 0.0, "avg_logprob": -0.10684073217983904, "compression_ratio": 1.8054607508532423, "no_speech_prob": 0.09756047278642654}, {"id": 582, "seek": 174600, "start": 1767.0, "end": 1769.0, "text": " No, we're going to keep it super focused", "tokens": [51414, 883, 11, 321, 434, 516, 281, 1066, 309, 1687, 5178, 51514], "temperature": 0.0, "avg_logprob": -0.10684073217983904, "compression_ratio": 1.8054607508532423, "no_speech_prob": 0.09756047278642654}, {"id": 583, "seek": 174600, "start": 1769.0, "end": 1772.0, "text": " And it's going to say exactly that same language that you really love", "tokens": [51514, 400, 309, 311, 516, 281, 584, 2293, 300, 912, 2856, 300, 291, 534, 959, 51664], "temperature": 0.0, "avg_logprob": -0.10684073217983904, "compression_ratio": 1.8054607508532423, "no_speech_prob": 0.09756047278642654}, {"id": 584, "seek": 174600, "start": 1772.0, "end": 1775.0, "text": " Or don't, you know, whatever it is, it's not going to change", "tokens": [51664, 1610, 500, 380, 11, 291, 458, 11, 2035, 309, 307, 11, 309, 311, 406, 516, 281, 1319, 51814], "temperature": 0.0, "avg_logprob": -0.10684073217983904, "compression_ratio": 1.8054607508532423, "no_speech_prob": 0.09756047278642654}, {"id": 585, "seek": 177500, "start": 1775.0, "end": 1778.0, "text": " And we're going to keep working on improving the developer experience", "tokens": [50364, 400, 321, 434, 516, 281, 1066, 1364, 322, 11470, 264, 10754, 1752, 50514], "temperature": 0.0, "avg_logprob": -0.08128556717921348, "compression_ratio": 1.7322033898305085, "no_speech_prob": 0.008402446284890175}, {"id": 586, "seek": 177500, "start": 1778.0, "end": 1780.0, "text": " So more tooling, keep improving that", "tokens": [50514, 407, 544, 46593, 11, 1066, 11470, 300, 50614], "temperature": 0.0, "avg_logprob": -0.08128556717921348, "compression_ratio": 1.7322033898305085, "no_speech_prob": 0.008402446284890175}, {"id": 587, "seek": 177500, "start": 1780.0, "end": 1783.0, "text": " If there's something that's annoying to do that everyone has to do", "tokens": [50614, 759, 456, 311, 746, 300, 311, 11304, 281, 360, 300, 1518, 575, 281, 360, 50764], "temperature": 0.0, "avg_logprob": -0.08128556717921348, "compression_ratio": 1.7322033898305085, "no_speech_prob": 0.008402446284890175}, {"id": 588, "seek": 177500, "start": 1783.0, "end": 1784.0, "text": " Let's make a library for that", "tokens": [50764, 961, 311, 652, 257, 6405, 337, 300, 50814], "temperature": 0.0, "avg_logprob": -0.08128556717921348, "compression_ratio": 1.7322033898305085, "no_speech_prob": 0.008402446284890175}, {"id": 589, "seek": 177500, "start": 1784.0, "end": 1786.0, "text": " You know, just keep solving those problems", "tokens": [50814, 509, 458, 11, 445, 1066, 12606, 729, 2740, 50914], "temperature": 0.0, "avg_logprob": -0.08128556717921348, "compression_ratio": 1.7322033898305085, "no_speech_prob": 0.008402446284890175}, {"id": 590, "seek": 177500, "start": 1786.0, "end": 1788.0, "text": " And document everything", "tokens": [50914, 400, 4166, 1203, 51014], "temperature": 0.0, "avg_logprob": -0.08128556717921348, "compression_ratio": 1.7322033898305085, "no_speech_prob": 0.008402446284890175}, {"id": 591, "seek": 177500, "start": 1788.0, "end": 1792.0, "text": " You know, we want to have cookbooks and guides and tutorials and examples", "tokens": [51014, 509, 458, 11, 321, 528, 281, 362, 2543, 15170, 293, 17007, 293, 17616, 293, 5110, 51214], "temperature": 0.0, "avg_logprob": -0.08128556717921348, "compression_ratio": 1.7322033898305085, "no_speech_prob": 0.008402446284890175}, {"id": 592, "seek": 177500, "start": 1792.0, "end": 1794.0, "text": " And just make it really easy for you to go", "tokens": [51214, 400, 445, 652, 309, 534, 1858, 337, 291, 281, 352, 51314], "temperature": 0.0, "avg_logprob": -0.08128556717921348, "compression_ratio": 1.7322033898305085, "no_speech_prob": 0.008402446284890175}, {"id": 593, "seek": 177500, "start": 1794.0, "end": 1797.0, "text": " How do I do this in Gleam?", "tokens": [51314, 1012, 360, 286, 360, 341, 294, 460, 306, 335, 30, 51464], "temperature": 0.0, "avg_logprob": -0.08128556717921348, "compression_ratio": 1.7322033898305085, "no_speech_prob": 0.008402446284890175}, {"id": 594, "seek": 177500, "start": 1797.0, "end": 1799.0, "text": " Oh, look, it says here, here's how I do it", "tokens": [51464, 876, 11, 574, 11, 309, 1619, 510, 11, 510, 311, 577, 286, 360, 309, 51564], "temperature": 0.0, "avg_logprob": -0.08128556717921348, "compression_ratio": 1.7322033898305085, "no_speech_prob": 0.008402446284890175}, {"id": 595, "seek": 177500, "start": 1799.0, "end": 1801.0, "text": " Now I can get on", "tokens": [51564, 823, 286, 393, 483, 322, 51664], "temperature": 0.0, "avg_logprob": -0.08128556717921348, "compression_ratio": 1.7322033898305085, "no_speech_prob": 0.008402446284890175}, {"id": 596, "seek": 177500, "start": 1801.0, "end": 1804.0, "text": " And the next thing is sustainability", "tokens": [51664, 400, 264, 958, 551, 307, 16360, 51814], "temperature": 0.0, "avg_logprob": -0.08128556717921348, "compression_ratio": 1.7322033898305085, "no_speech_prob": 0.008402446284890175}, {"id": 597, "seek": 180400, "start": 1804.0, "end": 1806.0, "text": " I am not Microsoft", "tokens": [50364, 286, 669, 406, 8116, 50464], "temperature": 0.0, "avg_logprob": -0.07829340555334605, "compression_ratio": 1.568888888888889, "no_speech_prob": 0.005976221989840269}, {"id": 598, "seek": 180400, "start": 1806.0, "end": 1809.0, "text": " I do not have 50 developers working on this", "tokens": [50464, 286, 360, 406, 362, 2625, 8849, 1364, 322, 341, 50614], "temperature": 0.0, "avg_logprob": -0.07829340555334605, "compression_ratio": 1.568888888888889, "no_speech_prob": 0.005976221989840269}, {"id": 599, "seek": 180400, "start": 1809.0, "end": 1811.0, "text": " I have me", "tokens": [50614, 286, 362, 385, 50714], "temperature": 0.0, "avg_logprob": -0.07829340555334605, "compression_ratio": 1.568888888888889, "no_speech_prob": 0.005976221989840269}, {"id": 600, "seek": 180400, "start": 1811.0, "end": 1816.0, "text": " And some lovely people who are very kind enough to agree to join the core team", "tokens": [50714, 400, 512, 7496, 561, 567, 366, 588, 733, 1547, 281, 3986, 281, 3917, 264, 4965, 1469, 50964], "temperature": 0.0, "avg_logprob": -0.07829340555334605, "compression_ratio": 1.568888888888889, "no_speech_prob": 0.005976221989840269}, {"id": 601, "seek": 180400, "start": 1816.0, "end": 1819.0, "text": " Which means they're just called the core team and they do free work for me", "tokens": [50964, 3013, 1355, 436, 434, 445, 1219, 264, 4965, 1469, 293, 436, 360, 1737, 589, 337, 385, 51114], "temperature": 0.0, "avg_logprob": -0.07829340555334605, "compression_ratio": 1.568888888888889, "no_speech_prob": 0.005976221989840269}, {"id": 602, "seek": 180400, "start": 1819.0, "end": 1822.0, "text": " It's fantastic", "tokens": [51114, 467, 311, 5456, 51264], "temperature": 0.0, "avg_logprob": -0.07829340555334605, "compression_ratio": 1.568888888888889, "no_speech_prob": 0.005976221989840269}, {"id": 603, "seek": 180400, "start": 1822.0, "end": 1824.0, "text": " Thank you very much", "tokens": [51264, 1044, 291, 588, 709, 51364], "temperature": 0.0, "avg_logprob": -0.07829340555334605, "compression_ratio": 1.568888888888889, "no_speech_prob": 0.005976221989840269}, {"id": 604, "seek": 180400, "start": 1824.0, "end": 1830.0, "text": " So we want to make sure that every bit of work that we're doing is as impactful as possible", "tokens": [51364, 407, 321, 528, 281, 652, 988, 300, 633, 857, 295, 589, 300, 321, 434, 884, 307, 382, 30842, 382, 1944, 51664], "temperature": 0.0, "avg_logprob": -0.07829340555334605, "compression_ratio": 1.568888888888889, "no_speech_prob": 0.005976221989840269}, {"id": 605, "seek": 183000, "start": 1830.0, "end": 1832.0, "text": " You know, it needs to be...", "tokens": [50364, 509, 458, 11, 309, 2203, 281, 312, 485, 50464], "temperature": 0.0, "avg_logprob": -0.0955042038987947, "compression_ratio": 1.7261146496815287, "no_speech_prob": 0.23051908612251282}, {"id": 606, "seek": 183000, "start": 1832.0, "end": 1836.0, "text": " Everything needs to be meaningful", "tokens": [50464, 5471, 2203, 281, 312, 10995, 50664], "temperature": 0.0, "avg_logprob": -0.0955042038987947, "compression_ratio": 1.7261146496815287, "no_speech_prob": 0.23051908612251282}, {"id": 607, "seek": 183000, "start": 1836.0, "end": 1839.0, "text": " And if we can't justify it as being impactful for a large amount of people", "tokens": [50664, 400, 498, 321, 393, 380, 20833, 309, 382, 885, 30842, 337, 257, 2416, 2372, 295, 561, 50814], "temperature": 0.0, "avg_logprob": -0.0955042038987947, "compression_ratio": 1.7261146496815287, "no_speech_prob": 0.23051908612251282}, {"id": 608, "seek": 183000, "start": 1839.0, "end": 1841.0, "text": " We just shouldn't do it", "tokens": [50814, 492, 445, 4659, 380, 360, 309, 50914], "temperature": 0.0, "avg_logprob": -0.0955042038987947, "compression_ratio": 1.7261146496815287, "no_speech_prob": 0.23051908612251282}, {"id": 609, "seek": 183000, "start": 1841.0, "end": 1844.0, "text": " We've got to make sure everything is efficient as possible", "tokens": [50914, 492, 600, 658, 281, 652, 988, 1203, 307, 7148, 382, 1944, 51064], "temperature": 0.0, "avg_logprob": -0.0955042038987947, "compression_ratio": 1.7261146496815287, "no_speech_prob": 0.23051908612251282}, {"id": 610, "seek": 183000, "start": 1844.0, "end": 1846.0, "text": " Not just in the code, but in our practices as well", "tokens": [51064, 1726, 445, 294, 264, 3089, 11, 457, 294, 527, 7525, 382, 731, 51164], "temperature": 0.0, "avg_logprob": -0.0955042038987947, "compression_ratio": 1.7261146496815287, "no_speech_prob": 0.23051908612251282}, {"id": 611, "seek": 183000, "start": 1846.0, "end": 1848.0, "text": " We're going to document everything internal", "tokens": [51164, 492, 434, 516, 281, 4166, 1203, 6920, 51264], "temperature": 0.0, "avg_logprob": -0.0955042038987947, "compression_ratio": 1.7261146496815287, "no_speech_prob": 0.23051908612251282}, {"id": 612, "seek": 183000, "start": 1848.0, "end": 1850.0, "text": " We're doing really well with this", "tokens": [51264, 492, 434, 884, 534, 731, 365, 341, 51364], "temperature": 0.0, "avg_logprob": -0.0955042038987947, "compression_ratio": 1.7261146496815287, "no_speech_prob": 0.23051908612251282}, {"id": 613, "seek": 183000, "start": 1850.0, "end": 1852.0, "text": " But I think we can do even better", "tokens": [51364, 583, 286, 519, 321, 393, 360, 754, 1101, 51464], "temperature": 0.0, "avg_logprob": -0.0955042038987947, "compression_ratio": 1.7261146496815287, "no_speech_prob": 0.23051908612251282}, {"id": 614, "seek": 183000, "start": 1852.0, "end": 1854.0, "text": " I would like people to go, oh, there's something...", "tokens": [51464, 286, 576, 411, 561, 281, 352, 11, 1954, 11, 456, 311, 746, 485, 51564], "temperature": 0.0, "avg_logprob": -0.0955042038987947, "compression_ratio": 1.7261146496815287, "no_speech_prob": 0.23051908612251282}, {"id": 615, "seek": 183000, "start": 1854.0, "end": 1856.0, "text": " There's a quirk with the build tool", "tokens": [51564, 821, 311, 257, 421, 18610, 365, 264, 1322, 2290, 51664], "temperature": 0.0, "avg_logprob": -0.0955042038987947, "compression_ratio": 1.7261146496815287, "no_speech_prob": 0.23051908612251282}, {"id": 616, "seek": 183000, "start": 1856.0, "end": 1857.0, "text": " I think this is a bug", "tokens": [51664, 286, 519, 341, 307, 257, 7426, 51714], "temperature": 0.0, "avg_logprob": -0.0955042038987947, "compression_ratio": 1.7261146496815287, "no_speech_prob": 0.23051908612251282}, {"id": 617, "seek": 183000, "start": 1857.0, "end": 1859.0, "text": " Okay, I'm going to look inside and see what it is", "tokens": [51714, 1033, 11, 286, 478, 516, 281, 574, 1854, 293, 536, 437, 309, 307, 51814], "temperature": 0.0, "avg_logprob": -0.0955042038987947, "compression_ratio": 1.7261146496815287, "no_speech_prob": 0.23051908612251282}, {"id": 618, "seek": 185900, "start": 1859.0, "end": 1861.0, "text": " And then just see loads of comments, loads of docs", "tokens": [50364, 400, 550, 445, 536, 12668, 295, 3053, 11, 12668, 295, 45623, 50464], "temperature": 0.0, "avg_logprob": -0.10647553303202645, "compression_ratio": 1.7509727626459144, "no_speech_prob": 0.03567349538207054}, {"id": 619, "seek": 185900, "start": 1861.0, "end": 1864.0, "text": " And then they can hopefully work out, oh, that's doing this, that's doing that", "tokens": [50464, 400, 550, 436, 393, 4696, 589, 484, 11, 1954, 11, 300, 311, 884, 341, 11, 300, 311, 884, 300, 50614], "temperature": 0.0, "avg_logprob": -0.10647553303202645, "compression_ratio": 1.7509727626459144, "no_speech_prob": 0.03567349538207054}, {"id": 620, "seek": 185900, "start": 1864.0, "end": 1866.0, "text": " I can make a contribution to this", "tokens": [50614, 286, 393, 652, 257, 13150, 281, 341, 50714], "temperature": 0.0, "avg_logprob": -0.10647553303202645, "compression_ratio": 1.7509727626459144, "no_speech_prob": 0.03567349538207054}, {"id": 621, "seek": 185900, "start": 1866.0, "end": 1870.0, "text": " And the last two things are about funding the project", "tokens": [50714, 400, 264, 1036, 732, 721, 366, 466, 6137, 264, 1716, 50914], "temperature": 0.0, "avg_logprob": -0.10647553303202645, "compression_ratio": 1.7509727626459144, "no_speech_prob": 0.03567349538207054}, {"id": 622, "seek": 185900, "start": 1870.0, "end": 1872.0, "text": " So I work on this full-time", "tokens": [50914, 407, 286, 589, 322, 341, 1577, 12, 3766, 51014], "temperature": 0.0, "avg_logprob": -0.10647553303202645, "compression_ratio": 1.7509727626459144, "no_speech_prob": 0.03567349538207054}, {"id": 623, "seek": 185900, "start": 1872.0, "end": 1877.0, "text": " And I work on this full-time thanks to GitHub sponsors primarily", "tokens": [51014, 400, 286, 589, 322, 341, 1577, 12, 3766, 3231, 281, 23331, 22593, 10029, 51264], "temperature": 0.0, "avg_logprob": -0.10647553303202645, "compression_ratio": 1.7509727626459144, "no_speech_prob": 0.03567349538207054}, {"id": 624, "seek": 185900, "start": 1877.0, "end": 1880.0, "text": " I really want to...", "tokens": [51264, 286, 534, 528, 281, 485, 51414], "temperature": 0.0, "avg_logprob": -0.10647553303202645, "compression_ratio": 1.7509727626459144, "no_speech_prob": 0.03567349538207054}, {"id": 625, "seek": 185900, "start": 1880.0, "end": 1882.0, "text": " So here, charted in the pink", "tokens": [51414, 407, 510, 11, 6927, 292, 294, 264, 7022, 51514], "temperature": 0.0, "avg_logprob": -0.10647553303202645, "compression_ratio": 1.7509727626459144, "no_speech_prob": 0.03567349538207054}, {"id": 626, "seek": 185900, "start": 1882.0, "end": 1884.0, "text": " That's how much income we have for the project", "tokens": [51514, 663, 311, 577, 709, 5742, 321, 362, 337, 264, 1716, 51614], "temperature": 0.0, "avg_logprob": -0.10647553303202645, "compression_ratio": 1.7509727626459144, "no_speech_prob": 0.03567349538207054}, {"id": 627, "seek": 185900, "start": 1884.0, "end": 1887.0, "text": " I'm super happy that it stayed super stable", "tokens": [51614, 286, 478, 1687, 2055, 300, 309, 9181, 1687, 8351, 51764], "temperature": 0.0, "avg_logprob": -0.10647553303202645, "compression_ratio": 1.7509727626459144, "no_speech_prob": 0.03567349538207054}, {"id": 628, "seek": 188700, "start": 1887.0, "end": 1889.0, "text": " And up there in blue, that is the median", "tokens": [50364, 400, 493, 456, 294, 3344, 11, 300, 307, 264, 26779, 50464], "temperature": 0.0, "avg_logprob": -0.10425799932235326, "compression_ratio": 1.6732283464566928, "no_speech_prob": 0.14545874297618866}, {"id": 629, "seek": 188700, "start": 1889.0, "end": 1892.0, "text": " For a lead developer in London, which is the city I live", "tokens": [50464, 1171, 257, 1477, 10754, 294, 7042, 11, 597, 307, 264, 2307, 286, 1621, 50614], "temperature": 0.0, "avg_logprob": -0.10425799932235326, "compression_ratio": 1.6732283464566928, "no_speech_prob": 0.14545874297618866}, {"id": 630, "seek": 188700, "start": 1892.0, "end": 1895.0, "text": " I really want to get that up to the blue line", "tokens": [50614, 286, 534, 528, 281, 483, 300, 493, 281, 264, 3344, 1622, 50764], "temperature": 0.0, "avg_logprob": -0.10425799932235326, "compression_ratio": 1.6732283464566928, "no_speech_prob": 0.14545874297618866}, {"id": 631, "seek": 188700, "start": 1895.0, "end": 1897.0, "text": " For obvious reasons", "tokens": [50764, 1171, 6322, 4112, 50864], "temperature": 0.0, "avg_logprob": -0.10425799932235326, "compression_ratio": 1.6732283464566928, "no_speech_prob": 0.14545874297618866}, {"id": 632, "seek": 188700, "start": 1897.0, "end": 1898.0, "text": " But I'd like to do further than that", "tokens": [50864, 583, 286, 1116, 411, 281, 360, 3052, 813, 300, 50914], "temperature": 0.0, "avg_logprob": -0.10425799932235326, "compression_ratio": 1.6732283464566928, "no_speech_prob": 0.14545874297618866}, {"id": 633, "seek": 188700, "start": 1898.0, "end": 1902.0, "text": " I'd really like if we could afford to have like one...", "tokens": [50914, 286, 1116, 534, 411, 498, 321, 727, 6157, 281, 362, 411, 472, 485, 51114], "temperature": 0.0, "avg_logprob": -0.10425799932235326, "compression_ratio": 1.6732283464566928, "no_speech_prob": 0.14545874297618866}, {"id": 634, "seek": 188700, "start": 1902.0, "end": 1905.0, "text": " Two pizza team, is that too old?", "tokens": [51114, 4453, 8298, 1469, 11, 307, 300, 886, 1331, 30, 51264], "temperature": 0.0, "avg_logprob": -0.10425799932235326, "compression_ratio": 1.6732283464566928, "no_speech_prob": 0.14545874297618866}, {"id": 635, "seek": 188700, "start": 1905.0, "end": 1908.0, "text": " I want to have that core development team", "tokens": [51264, 286, 528, 281, 362, 300, 4965, 3250, 1469, 51414], "temperature": 0.0, "avg_logprob": -0.10425799932235326, "compression_ratio": 1.6732283464566928, "no_speech_prob": 0.14545874297618866}, {"id": 636, "seek": 188700, "start": 1908.0, "end": 1912.0, "text": " To be able to afford to work on this thing", "tokens": [51414, 1407, 312, 1075, 281, 6157, 281, 589, 322, 341, 551, 51614], "temperature": 0.0, "avg_logprob": -0.10425799932235326, "compression_ratio": 1.6732283464566928, "no_speech_prob": 0.14545874297618866}, {"id": 637, "seek": 188700, "start": 1912.0, "end": 1915.0, "text": " That I think is useful and important and productive", "tokens": [51614, 663, 286, 519, 307, 4420, 293, 1021, 293, 13304, 51764], "temperature": 0.0, "avg_logprob": -0.10425799932235326, "compression_ratio": 1.6732283464566928, "no_speech_prob": 0.14545874297618866}, {"id": 638, "seek": 191500, "start": 1915.0, "end": 1917.0, "text": " And be able to work full-time", "tokens": [50364, 400, 312, 1075, 281, 589, 1577, 12, 3766, 50464], "temperature": 0.0, "avg_logprob": -0.1967686101009971, "compression_ratio": 1.632867132867133, "no_speech_prob": 0.04151063412427902}, {"id": 639, "seek": 191500, "start": 1917.0, "end": 1919.0, "text": " And be rewarded appropriately", "tokens": [50464, 400, 312, 29105, 23505, 50564], "temperature": 0.0, "avg_logprob": -0.1967686101009971, "compression_ratio": 1.632867132867133, "no_speech_prob": 0.04151063412427902}, {"id": 640, "seek": 191500, "start": 1919.0, "end": 1921.0, "text": " It shouldn't be charity, I think, for these people", "tokens": [50564, 467, 4659, 380, 312, 16863, 11, 286, 519, 11, 337, 613, 561, 50664], "temperature": 0.0, "avg_logprob": -0.1967686101009971, "compression_ratio": 1.632867132867133, "no_speech_prob": 0.04151063412427902}, {"id": 641, "seek": 191500, "start": 1921.0, "end": 1924.0, "text": " They're doing this really useful work for the ecosystem", "tokens": [50664, 814, 434, 884, 341, 534, 4420, 589, 337, 264, 11311, 50814], "temperature": 0.0, "avg_logprob": -0.1967686101009971, "compression_ratio": 1.632867132867133, "no_speech_prob": 0.04151063412427902}, {"id": 642, "seek": 191500, "start": 1924.0, "end": 1927.0, "text": " And then if that stable foundation is there", "tokens": [50814, 400, 550, 498, 300, 8351, 7030, 307, 456, 50964], "temperature": 0.0, "avg_logprob": -0.1967686101009971, "compression_ratio": 1.632867132867133, "no_speech_prob": 0.04151063412427902}, {"id": 643, "seek": 191500, "start": 1927.0, "end": 1929.0, "text": " That means other people feel more confident", "tokens": [50964, 663, 1355, 661, 561, 841, 544, 6679, 51064], "temperature": 0.0, "avg_logprob": -0.1967686101009971, "compression_ratio": 1.632867132867133, "no_speech_prob": 0.04151063412427902}, {"id": 644, "seek": 191500, "start": 1929.0, "end": 1933.0, "text": " Building their businesses and their projects and so on top of that", "tokens": [51064, 18974, 641, 6011, 293, 641, 4455, 293, 370, 322, 1192, 295, 300, 51264], "temperature": 0.0, "avg_logprob": -0.1967686101009971, "compression_ratio": 1.632867132867133, "no_speech_prob": 0.04151063412427902}, {"id": 645, "seek": 191500, "start": 1933.0, "end": 1936.0, "text": " So if you want to help out, do join the...", "tokens": [51264, 407, 498, 291, 528, 281, 854, 484, 11, 360, 3917, 264, 485, 51414], "temperature": 0.0, "avg_logprob": -0.1967686101009971, "compression_ratio": 1.632867132867133, "no_speech_prob": 0.04151063412427902}, {"id": 646, "seek": 191500, "start": 1936.0, "end": 1939.0, "text": " Do start sponsoring or get your employer to", "tokens": [51414, 1144, 722, 30311, 420, 483, 428, 16205, 281, 51564], "temperature": 0.0, "avg_logprob": -0.1967686101009971, "compression_ratio": 1.632867132867133, "no_speech_prob": 0.04151063412427902}, {"id": 647, "seek": 191500, "start": 1939.0, "end": 1943.0, "text": " So about half of that previous income comes from one place", "tokens": [51564, 407, 466, 1922, 295, 300, 3894, 5742, 1487, 490, 472, 1081, 51764], "temperature": 0.0, "avg_logprob": -0.1967686101009971, "compression_ratio": 1.632867132867133, "no_speech_prob": 0.04151063412427902}, {"id": 648, "seek": 194300, "start": 1943.0, "end": 1945.0, "text": " And that's from Fly, that's our big corporate sponsor", "tokens": [50364, 400, 300, 311, 490, 25294, 11, 300, 311, 527, 955, 10896, 16198, 50464], "temperature": 0.0, "avg_logprob": -0.07187734561020069, "compression_ratio": 1.8116710875331565, "no_speech_prob": 0.04418070241808891}, {"id": 649, "seek": 194300, "start": 1945.0, "end": 1947.0, "text": " They're the really wonderful deployment platform", "tokens": [50464, 814, 434, 264, 534, 3715, 19317, 3663, 50564], "temperature": 0.0, "avg_logprob": -0.07187734561020069, "compression_ratio": 1.8116710875331565, "no_speech_prob": 0.04418070241808891}, {"id": 650, "seek": 194300, "start": 1947.0, "end": 1951.0, "text": " And the other half comes from people donating like five, ten, twenty dollars", "tokens": [50564, 400, 264, 661, 1922, 1487, 490, 561, 36686, 411, 1732, 11, 2064, 11, 7699, 3808, 50764], "temperature": 0.0, "avg_logprob": -0.07187734561020069, "compression_ratio": 1.8116710875331565, "no_speech_prob": 0.04418070241808891}, {"id": 651, "seek": 194300, "start": 1951.0, "end": 1952.0, "text": " And they're both wonderful", "tokens": [50764, 400, 436, 434, 1293, 3715, 50814], "temperature": 0.0, "avg_logprob": -0.07187734561020069, "compression_ratio": 1.8116710875331565, "no_speech_prob": 0.04418070241808891}, {"id": 652, "seek": 194300, "start": 1952.0, "end": 1954.0, "text": " But it means there's quite a lot of...", "tokens": [50814, 583, 309, 1355, 456, 311, 1596, 257, 688, 295, 485, 50914], "temperature": 0.0, "avg_logprob": -0.07187734561020069, "compression_ratio": 1.8116710875331565, "no_speech_prob": 0.04418070241808891}, {"id": 653, "seek": 194300, "start": 1954.0, "end": 1956.0, "text": " There's quite a lot of weights on one organisation", "tokens": [50914, 821, 311, 1596, 257, 688, 295, 17443, 322, 472, 18641, 51014], "temperature": 0.0, "avg_logprob": -0.07187734561020069, "compression_ratio": 1.8116710875331565, "no_speech_prob": 0.04418070241808891}, {"id": 654, "seek": 194300, "start": 1956.0, "end": 1958.0, "text": " I'd really like to spread that out", "tokens": [51014, 286, 1116, 534, 411, 281, 3974, 300, 484, 51114], "temperature": 0.0, "avg_logprob": -0.07187734561020069, "compression_ratio": 1.8116710875331565, "no_speech_prob": 0.04418070241808891}, {"id": 655, "seek": 194300, "start": 1958.0, "end": 1960.0, "text": " So if we could have a bunch of smaller corporate sponsors", "tokens": [51114, 407, 498, 321, 727, 362, 257, 3840, 295, 4356, 10896, 22593, 51214], "temperature": 0.0, "avg_logprob": -0.07187734561020069, "compression_ratio": 1.8116710875331565, "no_speech_prob": 0.04418070241808891}, {"id": 656, "seek": 194300, "start": 1960.0, "end": 1963.0, "text": " I think that would be much better for the long-term health of the project", "tokens": [51214, 286, 519, 300, 576, 312, 709, 1101, 337, 264, 938, 12, 7039, 1585, 295, 264, 1716, 51364], "temperature": 0.0, "avg_logprob": -0.07187734561020069, "compression_ratio": 1.8116710875331565, "no_speech_prob": 0.04418070241808891}, {"id": 657, "seek": 194300, "start": 1963.0, "end": 1965.0, "text": " And if you've got ideas for other things we can do", "tokens": [51364, 400, 498, 291, 600, 658, 3487, 337, 661, 721, 321, 393, 360, 51464], "temperature": 0.0, "avg_logprob": -0.07187734561020069, "compression_ratio": 1.8116710875331565, "no_speech_prob": 0.04418070241808891}, {"id": 658, "seek": 194300, "start": 1965.0, "end": 1967.0, "text": " So I know Elixir has a sort of quasi-support thing", "tokens": [51464, 407, 286, 458, 2699, 970, 347, 575, 257, 1333, 295, 20954, 12, 36622, 477, 551, 51564], "temperature": 0.0, "avg_logprob": -0.07187734561020069, "compression_ratio": 1.8116710875331565, "no_speech_prob": 0.04418070241808891}, {"id": 659, "seek": 194300, "start": 1967.0, "end": 1968.0, "text": " That you can sign up for", "tokens": [51564, 663, 291, 393, 1465, 493, 337, 51614], "temperature": 0.0, "avg_logprob": -0.07187734561020069, "compression_ratio": 1.8116710875331565, "no_speech_prob": 0.04418070241808891}, {"id": 660, "seek": 194300, "start": 1968.0, "end": 1970.0, "text": " If you've got some other ideas, get in touch with me", "tokens": [51614, 759, 291, 600, 658, 512, 661, 3487, 11, 483, 294, 2557, 365, 385, 51714], "temperature": 0.0, "avg_logprob": -0.07187734561020069, "compression_ratio": 1.8116710875331565, "no_speech_prob": 0.04418070241808891}, {"id": 661, "seek": 194300, "start": 1970.0, "end": 1972.0, "text": " I'd love to hear what your thoughts are", "tokens": [51714, 286, 1116, 959, 281, 1568, 437, 428, 4598, 366, 51814], "temperature": 0.0, "avg_logprob": -0.07187734561020069, "compression_ratio": 1.8116710875331565, "no_speech_prob": 0.04418070241808891}, {"id": 662, "seek": 197300, "start": 1973.0, "end": 1978.0, "text": " So when is Glean version one?", "tokens": [50364, 407, 562, 307, 460, 28499, 3037, 472, 30, 50614], "temperature": 0.0, "avg_logprob": -0.14402471118503146, "compression_ratio": 1.4930232558139536, "no_speech_prob": 0.021682009100914}, {"id": 663, "seek": 197300, "start": 1978.0, "end": 1979.0, "text": " How much more have you got to do?", "tokens": [50614, 1012, 709, 544, 362, 291, 658, 281, 360, 30, 50664], "temperature": 0.0, "avg_logprob": -0.14402471118503146, "compression_ratio": 1.4930232558139536, "no_speech_prob": 0.021682009100914}, {"id": 664, "seek": 197300, "start": 1979.0, "end": 1982.0, "text": " Well the answer is now", "tokens": [50664, 1042, 264, 1867, 307, 586, 50814], "temperature": 0.0, "avg_logprob": -0.14402471118503146, "compression_ratio": 1.4930232558139536, "no_speech_prob": 0.021682009100914}, {"id": 665, "seek": 197300, "start": 1982.0, "end": 1985.0, "text": " We're there, like we're completely ready", "tokens": [50814, 492, 434, 456, 11, 411, 321, 434, 2584, 1919, 50964], "temperature": 0.0, "avg_logprob": -0.14402471118503146, "compression_ratio": 1.4930232558139536, "no_speech_prob": 0.021682009100914}, {"id": 666, "seek": 197300, "start": 1985.0, "end": 1987.0, "text": " And depending on how much you lot distract me", "tokens": [50964, 400, 5413, 322, 577, 709, 291, 688, 9945, 385, 51064], "temperature": 0.0, "avg_logprob": -0.14402471118503146, "compression_ratio": 1.4930232558139536, "no_speech_prob": 0.021682009100914}, {"id": 667, "seek": 197300, "start": 1987.0, "end": 1988.0, "text": " For the next few days", "tokens": [51064, 1171, 264, 958, 1326, 1708, 51114], "temperature": 0.0, "avg_logprob": -0.14402471118503146, "compression_ratio": 1.4930232558139536, "no_speech_prob": 0.021682009100914}, {"id": 668, "seek": 197300, "start": 1988.0, "end": 1991.0, "text": " I hope to get a release candidate out today, tomorrow", "tokens": [51114, 286, 1454, 281, 483, 257, 4374, 11532, 484, 965, 11, 4153, 51264], "temperature": 0.0, "avg_logprob": -0.14402471118503146, "compression_ratio": 1.4930232558139536, "no_speech_prob": 0.021682009100914}, {"id": 669, "seek": 197300, "start": 1991.0, "end": 1993.0, "text": " At some point in the immediate future", "tokens": [51264, 1711, 512, 935, 294, 264, 11629, 2027, 51364], "temperature": 0.0, "avg_logprob": -0.14402471118503146, "compression_ratio": 1.4930232558139536, "no_speech_prob": 0.021682009100914}, {"id": 670, "seek": 197300, "start": 1993.0, "end": 1995.0, "text": " So this is a really exciting time", "tokens": [51364, 407, 341, 307, 257, 534, 4670, 565, 51464], "temperature": 0.0, "avg_logprob": -0.14402471118503146, "compression_ratio": 1.4930232558139536, "no_speech_prob": 0.021682009100914}, {"id": 671, "seek": 199500, "start": 1995.0, "end": 2007.0, "text": " Good, so questions? Any questions?", "tokens": [50364, 2205, 11, 370, 1651, 30, 2639, 1651, 30, 50964], "temperature": 0.0, "avg_logprob": -0.38007235059551164, "compression_ratio": 1.3630136986301369, "no_speech_prob": 0.10156711935997009}, {"id": 672, "seek": 199500, "start": 2007.0, "end": 2011.0, "text": " Thank you very much for creating Glean", "tokens": [50964, 1044, 291, 588, 709, 337, 4084, 460, 28499, 51164], "temperature": 0.0, "avg_logprob": -0.38007235059551164, "compression_ratio": 1.3630136986301369, "no_speech_prob": 0.10156711935997009}, {"id": 673, "seek": 199500, "start": 2011.0, "end": 2017.0, "text": " Could you elaborate more on what happens when we keep target minus JS?", "tokens": [51164, 7497, 291, 20945, 544, 322, 437, 2314, 562, 321, 1066, 3779, 3175, 33063, 30, 51464], "temperature": 0.0, "avg_logprob": -0.38007235059551164, "compression_ratio": 1.3630136986301369, "no_speech_prob": 0.10156711935997009}, {"id": 674, "seek": 199500, "start": 2017.0, "end": 2020.0, "text": " When we're targeting to JavaScript", "tokens": [51464, 1133, 321, 434, 17918, 281, 15778, 51614], "temperature": 0.0, "avg_logprob": -0.38007235059551164, "compression_ratio": 1.3630136986301369, "no_speech_prob": 0.10156711935997009}, {"id": 675, "seek": 199500, "start": 2020.0, "end": 2022.0, "text": " Repeat the question", "tokens": [51614, 28523, 264, 1168, 51714], "temperature": 0.0, "avg_logprob": -0.38007235059551164, "compression_ratio": 1.3630136986301369, "no_speech_prob": 0.10156711935997009}, {"id": 676, "seek": 202200, "start": 2022.0, "end": 2024.0, "text": " Yes, so the question is", "tokens": [50364, 1079, 11, 370, 264, 1168, 307, 50464], "temperature": 0.0, "avg_logprob": -0.1435118085555448, "compression_ratio": 1.7634408602150538, "no_speech_prob": 0.11194314807653427}, {"id": 677, "seek": 202200, "start": 2024.0, "end": 2027.0, "text": " Can I explain what happens when we target compile to JavaScript?", "tokens": [50464, 1664, 286, 2903, 437, 2314, 562, 321, 3779, 31413, 281, 15778, 30, 50614], "temperature": 0.0, "avg_logprob": -0.1435118085555448, "compression_ratio": 1.7634408602150538, "no_speech_prob": 0.11194314807653427}, {"id": 678, "seek": 202200, "start": 2027.0, "end": 2030.0, "text": " Okay, so we compile to...", "tokens": [50614, 1033, 11, 370, 321, 31413, 281, 485, 50764], "temperature": 0.0, "avg_logprob": -0.1435118085555448, "compression_ratio": 1.7634408602150538, "no_speech_prob": 0.11194314807653427}, {"id": 679, "seek": 202200, "start": 2030.0, "end": 2031.0, "text": " What can I say about it?", "tokens": [50764, 708, 393, 286, 584, 466, 309, 30, 50814], "temperature": 0.0, "avg_logprob": -0.1435118085555448, "compression_ratio": 1.7634408602150538, "no_speech_prob": 0.11194314807653427}, {"id": 680, "seek": 202200, "start": 2031.0, "end": 2033.0, "text": " So we compile to JavaScript source codes", "tokens": [50814, 407, 321, 31413, 281, 15778, 4009, 14211, 50914], "temperature": 0.0, "avg_logprob": -0.1435118085555448, "compression_ratio": 1.7634408602150538, "no_speech_prob": 0.11194314807653427}, {"id": 681, "seek": 202200, "start": 2033.0, "end": 2035.0, "text": " We don't add a runtime", "tokens": [50914, 492, 500, 380, 909, 257, 34474, 51014], "temperature": 0.0, "avg_logprob": -0.1435118085555448, "compression_ratio": 1.7634408602150538, "no_speech_prob": 0.11194314807653427}, {"id": 682, "seek": 202200, "start": 2035.0, "end": 2037.0, "text": " We keep very close to JavaScript", "tokens": [51014, 492, 1066, 588, 1998, 281, 15778, 51114], "temperature": 0.0, "avg_logprob": -0.1435118085555448, "compression_ratio": 1.7634408602150538, "no_speech_prob": 0.11194314807653427}, {"id": 683, "seek": 202200, "start": 2037.0, "end": 2039.0, "text": " So like your scripts end up being very small", "tokens": [51114, 407, 411, 428, 23294, 917, 493, 885, 588, 1359, 51214], "temperature": 0.0, "avg_logprob": -0.1435118085555448, "compression_ratio": 1.7634408602150538, "no_speech_prob": 0.11194314807653427}, {"id": 684, "seek": 202200, "start": 2039.0, "end": 2041.0, "text": " Suitable for use at a browser", "tokens": [51214, 48854, 712, 337, 764, 412, 257, 11185, 51314], "temperature": 0.0, "avg_logprob": -0.1435118085555448, "compression_ratio": 1.7634408602150538, "no_speech_prob": 0.11194314807653427}, {"id": 685, "seek": 202200, "start": 2041.0, "end": 2042.0, "text": " But because we don't have a runtime", "tokens": [51314, 583, 570, 321, 500, 380, 362, 257, 34474, 51364], "temperature": 0.0, "avg_logprob": -0.1435118085555448, "compression_ratio": 1.7634408602150538, "no_speech_prob": 0.11194314807653427}, {"id": 686, "seek": 202200, "start": 2042.0, "end": 2043.0, "text": " It means we don't have an implementation", "tokens": [51364, 467, 1355, 321, 500, 380, 362, 364, 11420, 51414], "temperature": 0.0, "avg_logprob": -0.1435118085555448, "compression_ratio": 1.7634408602150538, "no_speech_prob": 0.11194314807653427}, {"id": 687, "seek": 202200, "start": 2043.0, "end": 2047.0, "text": " Of say like the Erlang concurrency inside JavaScript", "tokens": [51414, 2720, 584, 411, 264, 3300, 25241, 23702, 10457, 1854, 15778, 51614], "temperature": 0.0, "avg_logprob": -0.1435118085555448, "compression_ratio": 1.7634408602150538, "no_speech_prob": 0.11194314807653427}, {"id": 688, "seek": 202200, "start": 2047.0, "end": 2049.0, "text": " So you'll be using a different concurrency pattern", "tokens": [51614, 407, 291, 603, 312, 1228, 257, 819, 23702, 10457, 5102, 51714], "temperature": 0.0, "avg_logprob": -0.1435118085555448, "compression_ratio": 1.7634408602150538, "no_speech_prob": 0.11194314807653427}, {"id": 689, "seek": 204900, "start": 2049.0, "end": 2051.0, "text": " If you're using Glean JavaScript", "tokens": [50364, 759, 291, 434, 1228, 460, 28499, 15778, 50464], "temperature": 0.0, "avg_logprob": -0.16839939144486232, "compression_ratio": 1.7206896551724138, "no_speech_prob": 0.05860451981425285}, {"id": 690, "seek": 204900, "start": 2051.0, "end": 2052.0, "text": " If you're using Glean Erlang", "tokens": [50464, 759, 291, 434, 1228, 460, 28499, 3300, 25241, 50514], "temperature": 0.0, "avg_logprob": -0.16839939144486232, "compression_ratio": 1.7206896551724138, "no_speech_prob": 0.05860451981425285}, {"id": 691, "seek": 204900, "start": 2052.0, "end": 2054.0, "text": " And that means there's certain incompatibilities", "tokens": [50514, 400, 300, 1355, 456, 311, 1629, 40393, 267, 8261, 50614], "temperature": 0.0, "avg_logprob": -0.16839939144486232, "compression_ratio": 1.7206896551724138, "no_speech_prob": 0.05860451981425285}, {"id": 692, "seek": 204900, "start": 2054.0, "end": 2056.0, "text": " Between the Erlang and JavaScript target", "tokens": [50614, 18967, 264, 3300, 25241, 293, 15778, 3779, 50714], "temperature": 0.0, "avg_logprob": -0.16839939144486232, "compression_ratio": 1.7206896551724138, "no_speech_prob": 0.05860451981425285}, {"id": 693, "seek": 204900, "start": 2056.0, "end": 2058.0, "text": " You can't write a library that easily abstracts over both", "tokens": [50714, 509, 393, 380, 2464, 257, 6405, 300, 3612, 12649, 82, 670, 1293, 50814], "temperature": 0.0, "avg_logprob": -0.16839939144486232, "compression_ratio": 1.7206896551724138, "no_speech_prob": 0.05860451981425285}, {"id": 694, "seek": 204900, "start": 2058.0, "end": 2060.0, "text": " If it does file IO for it", "tokens": [50814, 759, 309, 775, 3991, 39839, 337, 309, 50914], "temperature": 0.0, "avg_logprob": -0.16839939144486232, "compression_ratio": 1.7206896551724138, "no_speech_prob": 0.05860451981425285}, {"id": 695, "seek": 204900, "start": 2060.0, "end": 2061.0, "text": " Well, that's a bad example", "tokens": [50914, 1042, 11, 300, 311, 257, 1578, 1365, 50964], "temperature": 0.0, "avg_logprob": -0.16839939144486232, "compression_ratio": 1.7206896551724138, "no_speech_prob": 0.05860451981425285}, {"id": 696, "seek": 204900, "start": 2061.0, "end": 2066.0, "text": " If it does like HTTP requests, for example", "tokens": [50964, 759, 309, 775, 411, 33283, 12475, 11, 337, 1365, 51214], "temperature": 0.0, "avg_logprob": -0.16839939144486232, "compression_ratio": 1.7206896551724138, "no_speech_prob": 0.05860451981425285}, {"id": 697, "seek": 204900, "start": 2066.0, "end": 2068.0, "text": " But it means, you know, that's the trade-off", "tokens": [51214, 583, 309, 1355, 11, 291, 458, 11, 300, 311, 264, 4923, 12, 4506, 51314], "temperature": 0.0, "avg_logprob": -0.16839939144486232, "compression_ratio": 1.7206896551724138, "no_speech_prob": 0.05860451981425285}, {"id": 698, "seek": 204900, "start": 2068.0, "end": 2071.0, "text": " But then it means you can work very well with the Erlang...", "tokens": [51314, 583, 550, 309, 1355, 291, 393, 589, 588, 731, 365, 264, 3300, 25241, 485, 51464], "temperature": 0.0, "avg_logprob": -0.16839939144486232, "compression_ratio": 1.7206896551724138, "no_speech_prob": 0.05860451981425285}, {"id": 699, "seek": 204900, "start": 2071.0, "end": 2073.0, "text": " Sorry, with the JavaScript world", "tokens": [51464, 4919, 11, 365, 264, 15778, 1002, 51564], "temperature": 0.0, "avg_logprob": -0.16839939144486232, "compression_ratio": 1.7206896551724138, "no_speech_prob": 0.05860451981425285}, {"id": 700, "seek": 204900, "start": 2073.0, "end": 2076.0, "text": " We can run Glean in browser through...", "tokens": [51564, 492, 393, 1190, 460, 28499, 294, 11185, 807, 485, 51714], "temperature": 0.0, "avg_logprob": -0.16839939144486232, "compression_ratio": 1.7206896551724138, "no_speech_prob": 0.05860451981425285}, {"id": 701, "seek": 204900, "start": 2076.0, "end": 2077.0, "text": " So again, sorry?", "tokens": [51714, 407, 797, 11, 2597, 30, 51764], "temperature": 0.0, "avg_logprob": -0.16839939144486232, "compression_ratio": 1.7206896551724138, "no_speech_prob": 0.05860451981425285}, {"id": 702, "seek": 207700, "start": 2077.0, "end": 2080.0, "text": " Can we run Glean in browser through WebAssembly?", "tokens": [50364, 1664, 321, 1190, 460, 28499, 294, 11185, 807, 9573, 10884, 19160, 30, 50514], "temperature": 0.0, "avg_logprob": -0.06264656943243903, "compression_ratio": 1.9030100334448161, "no_speech_prob": 0.024716440588235855}, {"id": 703, "seek": 207700, "start": 2080.0, "end": 2083.0, "text": " Can you run Glean in browser through WebAssembly?", "tokens": [50514, 1664, 291, 1190, 460, 28499, 294, 11185, 807, 9573, 10884, 19160, 30, 50664], "temperature": 0.0, "avg_logprob": -0.06264656943243903, "compression_ratio": 1.9030100334448161, "no_speech_prob": 0.024716440588235855}, {"id": 704, "seek": 207700, "start": 2083.0, "end": 2085.0, "text": " No, but that's something we want to explore in future", "tokens": [50664, 883, 11, 457, 300, 311, 746, 321, 528, 281, 6839, 294, 2027, 50764], "temperature": 0.0, "avg_logprob": -0.06264656943243903, "compression_ratio": 1.9030100334448161, "no_speech_prob": 0.024716440588235855}, {"id": 705, "seek": 207700, "start": 2085.0, "end": 2088.0, "text": " Not because we particularly want to do WebAssembly", "tokens": [50764, 1726, 570, 321, 4098, 528, 281, 360, 9573, 10884, 19160, 50914], "temperature": 0.0, "avg_logprob": -0.06264656943243903, "compression_ratio": 1.9030100334448161, "no_speech_prob": 0.024716440588235855}, {"id": 706, "seek": 207700, "start": 2088.0, "end": 2090.0, "text": " Sorry, not because we want to do it in the browser", "tokens": [50914, 4919, 11, 406, 570, 321, 528, 281, 360, 309, 294, 264, 11185, 51014], "temperature": 0.0, "avg_logprob": -0.06264656943243903, "compression_ratio": 1.9030100334448161, "no_speech_prob": 0.024716440588235855}, {"id": 707, "seek": 207700, "start": 2090.0, "end": 2093.0, "text": " Because we could already do that with JavaScript", "tokens": [51014, 1436, 321, 727, 1217, 360, 300, 365, 15778, 51164], "temperature": 0.0, "avg_logprob": -0.06264656943243903, "compression_ratio": 1.9030100334448161, "no_speech_prob": 0.024716440588235855}, {"id": 708, "seek": 207700, "start": 2093.0, "end": 2096.0, "text": " But there's loads of other places you can use WebAssembly", "tokens": [51164, 583, 456, 311, 12668, 295, 661, 3190, 291, 393, 764, 9573, 10884, 19160, 51314], "temperature": 0.0, "avg_logprob": -0.06264656943243903, "compression_ratio": 1.9030100334448161, "no_speech_prob": 0.024716440588235855}, {"id": 709, "seek": 207700, "start": 2096.0, "end": 2099.0, "text": " And I wanted to talk about this, but I didn't have enough time", "tokens": [51314, 400, 286, 1415, 281, 751, 466, 341, 11, 457, 286, 994, 380, 362, 1547, 565, 51464], "temperature": 0.0, "avg_logprob": -0.06264656943243903, "compression_ratio": 1.9030100334448161, "no_speech_prob": 0.024716440588235855}, {"id": 710, "seek": 207700, "start": 2099.0, "end": 2101.0, "text": " I think it would be really exciting", "tokens": [51464, 286, 519, 309, 576, 312, 534, 4670, 51564], "temperature": 0.0, "avg_logprob": -0.06264656943243903, "compression_ratio": 1.9030100334448161, "no_speech_prob": 0.024716440588235855}, {"id": 711, "seek": 207700, "start": 2101.0, "end": 2104.0, "text": " If we had a good way of executing Glean inside the compiler", "tokens": [51564, 759, 321, 632, 257, 665, 636, 295, 32368, 460, 28499, 1854, 264, 31958, 51714], "temperature": 0.0, "avg_logprob": -0.06264656943243903, "compression_ratio": 1.9030100334448161, "no_speech_prob": 0.024716440588235855}, {"id": 712, "seek": 207700, "start": 2104.0, "end": 2106.0, "text": " Because there's loads of optimizations we can do", "tokens": [51714, 1436, 456, 311, 12668, 295, 5028, 14455, 321, 393, 360, 51814], "temperature": 0.0, "avg_logprob": -0.06264656943243903, "compression_ratio": 1.9030100334448161, "no_speech_prob": 0.024716440588235855}, {"id": 713, "seek": 210600, "start": 2106.0, "end": 2109.0, "text": " We could start looking at certain kinds of like code generation", "tokens": [50364, 492, 727, 722, 1237, 412, 1629, 3685, 295, 411, 3089, 5125, 50514], "temperature": 0.0, "avg_logprob": -0.16864205932617188, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.01607280969619751}, {"id": 714, "seek": 210600, "start": 2109.0, "end": 2112.0, "text": " Meta programming stuff that you can do in Alexa, for example", "tokens": [50514, 6377, 64, 9410, 1507, 300, 291, 393, 360, 294, 22595, 11, 337, 1365, 50664], "temperature": 0.0, "avg_logprob": -0.16864205932617188, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.01607280969619751}, {"id": 715, "seek": 210600, "start": 2112.0, "end": 2114.0, "text": " You can't do in Glean", "tokens": [50664, 509, 393, 380, 360, 294, 460, 28499, 50764], "temperature": 0.0, "avg_logprob": -0.16864205932617188, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.01607280969619751}, {"id": 716, "seek": 210600, "start": 2114.0, "end": 2116.0, "text": " But we can't do that because we don't have a copy of the beam", "tokens": [50764, 583, 321, 393, 380, 360, 300, 570, 321, 500, 380, 362, 257, 5055, 295, 264, 14269, 50864], "temperature": 0.0, "avg_logprob": -0.16864205932617188, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.01607280969619751}, {"id": 717, "seek": 210600, "start": 2116.0, "end": 2119.0, "text": " This massive thing inside the Glean compiler", "tokens": [50864, 639, 5994, 551, 1854, 264, 460, 28499, 31958, 51014], "temperature": 0.0, "avg_logprob": -0.16864205932617188, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.01607280969619751}, {"id": 718, "seek": 210600, "start": 2119.0, "end": 2122.0, "text": " So if we had like a little VM, maybe we could do that", "tokens": [51014, 407, 498, 321, 632, 411, 257, 707, 18038, 11, 1310, 321, 727, 360, 300, 51164], "temperature": 0.0, "avg_logprob": -0.16864205932617188, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.01607280969619751}, {"id": 719, "seek": 210600, "start": 2122.0, "end": 2125.0, "text": " And WebAssembly is a really good little VM for this whole thing", "tokens": [51164, 400, 9573, 10884, 19160, 307, 257, 534, 665, 707, 18038, 337, 341, 1379, 551, 51314], "temperature": 0.0, "avg_logprob": -0.16864205932617188, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.01607280969619751}, {"id": 720, "seek": 210600, "start": 2125.0, "end": 2126.0, "text": " Thank you", "tokens": [51314, 1044, 291, 51364], "temperature": 0.0, "avg_logprob": -0.16864205932617188, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.01607280969619751}, {"id": 721, "seek": 210600, "start": 2128.0, "end": 2129.0, "text": " Any other questions?", "tokens": [51464, 2639, 661, 1651, 30, 51514], "temperature": 0.0, "avg_logprob": -0.16864205932617188, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.01607280969619751}, {"id": 722, "seek": 210600, "start": 2132.0, "end": 2135.0, "text": " Yeah, I do have a question that you might use to point to", "tokens": [51664, 865, 11, 286, 360, 362, 257, 1168, 300, 291, 1062, 764, 281, 935, 281, 51814], "temperature": 0.0, "avg_logprob": -0.16864205932617188, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.01607280969619751}, {"id": 723, "seek": 213500, "start": 2135.0, "end": 2137.0, "text": " I think it's a great question", "tokens": [50364, 286, 519, 309, 311, 257, 869, 1168, 50464], "temperature": 0.0, "avg_logprob": -0.5100299876223329, "compression_ratio": 1.65625, "no_speech_prob": 0.02709805779159069}, {"id": 724, "seek": 213500, "start": 2137.0, "end": 2141.0, "text": " I think it was in the last year during the episode of code", "tokens": [50464, 286, 519, 309, 390, 294, 264, 1036, 1064, 1830, 264, 3500, 295, 3089, 50664], "temperature": 0.0, "avg_logprob": -0.5100299876223329, "compression_ratio": 1.65625, "no_speech_prob": 0.02709805779159069}, {"id": 725, "seek": 213500, "start": 2141.0, "end": 2144.0, "text": " And it's a really great project", "tokens": [50664, 400, 309, 311, 257, 534, 869, 1716, 50814], "temperature": 0.0, "avg_logprob": -0.5100299876223329, "compression_ratio": 1.65625, "no_speech_prob": 0.02709805779159069}, {"id": 726, "seek": 213500, "start": 2144.0, "end": 2150.0, "text": " But as you know, I think one of the main parts that draw me to the language", "tokens": [50814, 583, 382, 291, 458, 11, 286, 519, 472, 295, 264, 2135, 3166, 300, 2642, 385, 281, 264, 2856, 51114], "temperature": 0.0, "avg_logprob": -0.5100299876223329, "compression_ratio": 1.65625, "no_speech_prob": 0.02709805779159069}, {"id": 727, "seek": 213500, "start": 2150.0, "end": 2154.0, "text": " Was the vibrant, pink color", "tokens": [51114, 3027, 264, 21571, 11, 7022, 2017, 51314], "temperature": 0.0, "avg_logprob": -0.5100299876223329, "compression_ratio": 1.65625, "no_speech_prob": 0.02709805779159069}, {"id": 728, "seek": 213500, "start": 2154.0, "end": 2157.0, "text": " Is there a story behind it?", "tokens": [51314, 1119, 456, 257, 1657, 2261, 309, 30, 51464], "temperature": 0.0, "avg_logprob": -0.5100299876223329, "compression_ratio": 1.65625, "no_speech_prob": 0.02709805779159069}, {"id": 729, "seek": 213500, "start": 2157.0, "end": 2158.0, "text": " Is it the color?", "tokens": [51464, 1119, 309, 264, 2017, 30, 51514], "temperature": 0.0, "avg_logprob": -0.5100299876223329, "compression_ratio": 1.65625, "no_speech_prob": 0.02709805779159069}, {"id": 730, "seek": 213500, "start": 2158.0, "end": 2160.0, "text": " Why is Glean pink? Great question", "tokens": [51514, 1545, 307, 460, 28499, 7022, 30, 3769, 1168, 51614], "temperature": 0.0, "avg_logprob": -0.5100299876223329, "compression_ratio": 1.65625, "no_speech_prob": 0.02709805779159069}, {"id": 731, "seek": 213500, "start": 2161.0, "end": 2162.0, "text": " Great question", "tokens": [51664, 3769, 1168, 51714], "temperature": 0.0, "avg_logprob": -0.5100299876223329, "compression_ratio": 1.65625, "no_speech_prob": 0.02709805779159069}, {"id": 732, "seek": 216200, "start": 2163.0, "end": 2167.0, "text": " This was, what is this handle, K-Tec I think is", "tokens": [50414, 639, 390, 11, 437, 307, 341, 4813, 11, 591, 12, 51, 3045, 286, 519, 307, 50614], "temperature": 0.0, "avg_logprob": -0.19010574716917225, "compression_ratio": 1.7813620071684588, "no_speech_prob": 0.18623453378677368}, {"id": 733, "seek": 216200, "start": 2167.0, "end": 2170.0, "text": " And he just threw this idea it should be pink", "tokens": [50614, 400, 415, 445, 11918, 341, 1558, 309, 820, 312, 7022, 50764], "temperature": 0.0, "avg_logprob": -0.19010574716917225, "compression_ratio": 1.7813620071684588, "no_speech_prob": 0.18623453378677368}, {"id": 734, "seek": 216200, "start": 2170.0, "end": 2172.0, "text": " And I was like, oh really, why? That's really odd", "tokens": [50764, 400, 286, 390, 411, 11, 1954, 534, 11, 983, 30, 663, 311, 534, 7401, 50864], "temperature": 0.0, "avg_logprob": -0.19010574716917225, "compression_ratio": 1.7813620071684588, "no_speech_prob": 0.18623453378677368}, {"id": 735, "seek": 216200, "start": 2172.0, "end": 2176.0, "text": " And I liked it because it's different", "tokens": [50864, 400, 286, 4501, 309, 570, 309, 311, 819, 51064], "temperature": 0.0, "avg_logprob": -0.19010574716917225, "compression_ratio": 1.7813620071684588, "no_speech_prob": 0.18623453378677368}, {"id": 736, "seek": 216200, "start": 2176.0, "end": 2178.0, "text": " You know, you see this pink and you don't go", "tokens": [51064, 509, 458, 11, 291, 536, 341, 7022, 293, 291, 500, 380, 352, 51164], "temperature": 0.0, "avg_logprob": -0.19010574716917225, "compression_ratio": 1.7813620071684588, "no_speech_prob": 0.18623453378677368}, {"id": 737, "seek": 216200, "start": 2178.0, "end": 2180.0, "text": " You know, if you see a blue you're like, is that TypeScript?", "tokens": [51164, 509, 458, 11, 498, 291, 536, 257, 3344, 291, 434, 411, 11, 307, 300, 15576, 14237, 30, 51264], "temperature": 0.0, "avg_logprob": -0.19010574716917225, "compression_ratio": 1.7813620071684588, "no_speech_prob": 0.18623453378677368}, {"id": 738, "seek": 216200, "start": 2180.0, "end": 2183.0, "text": " Is it Python? You know, it's visually very different", "tokens": [51264, 1119, 309, 15329, 30, 509, 458, 11, 309, 311, 19622, 588, 819, 51414], "temperature": 0.0, "avg_logprob": -0.19010574716917225, "compression_ratio": 1.7813620071684588, "no_speech_prob": 0.18623453378677368}, {"id": 739, "seek": 216200, "start": 2183.0, "end": 2186.0, "text": " And the other thing is, I think it's quite friendly", "tokens": [51414, 400, 264, 661, 551, 307, 11, 286, 519, 309, 311, 1596, 9208, 51564], "temperature": 0.0, "avg_logprob": -0.19010574716917225, "compression_ratio": 1.7813620071684588, "no_speech_prob": 0.18623453378677368}, {"id": 740, "seek": 216200, "start": 2186.0, "end": 2188.0, "text": " And hopefully it's welcoming to different people", "tokens": [51564, 400, 4696, 309, 311, 17378, 281, 819, 561, 51664], "temperature": 0.0, "avg_logprob": -0.19010574716917225, "compression_ratio": 1.7813620071684588, "no_speech_prob": 0.18623453378677368}, {"id": 741, "seek": 216200, "start": 2188.0, "end": 2190.0, "text": " I hope that if someone sees a bright pink thing they go", "tokens": [51664, 286, 1454, 300, 498, 1580, 8194, 257, 4730, 7022, 551, 436, 352, 51764], "temperature": 0.0, "avg_logprob": -0.19010574716917225, "compression_ratio": 1.7813620071684588, "no_speech_prob": 0.18623453378677368}, {"id": 742, "seek": 219000, "start": 2190.0, "end": 2194.0, "text": " Oh that's cool, you know, maybe there's not going to be", "tokens": [50364, 876, 300, 311, 1627, 11, 291, 458, 11, 1310, 456, 311, 406, 516, 281, 312, 50564], "temperature": 0.0, "avg_logprob": -0.14272620185973153, "compression_ratio": 1.724264705882353, "no_speech_prob": 0.013199958018958569}, {"id": 743, "seek": 219000, "start": 2194.0, "end": 2196.0, "text": " And it also says like, you know, be nice to each other", "tokens": [50564, 400, 309, 611, 1619, 411, 11, 291, 458, 11, 312, 1481, 281, 1184, 661, 50664], "temperature": 0.0, "avg_logprob": -0.14272620185973153, "compression_ratio": 1.724264705882353, "no_speech_prob": 0.013199958018958569}, {"id": 744, "seek": 219000, "start": 2196.0, "end": 2198.0, "text": " No Nazis on the website, you know", "tokens": [50664, 883, 29812, 322, 264, 3144, 11, 291, 458, 50764], "temperature": 0.0, "avg_logprob": -0.14272620185973153, "compression_ratio": 1.724264705882353, "no_speech_prob": 0.013199958018958569}, {"id": 745, "seek": 219000, "start": 2198.0, "end": 2200.0, "text": " I'm hoping people will see that and get an idea of what we're about", "tokens": [50764, 286, 478, 7159, 561, 486, 536, 300, 293, 483, 364, 1558, 295, 437, 321, 434, 466, 50864], "temperature": 0.0, "avg_logprob": -0.14272620185973153, "compression_ratio": 1.724264705882353, "no_speech_prob": 0.013199958018958569}, {"id": 746, "seek": 219000, "start": 2200.0, "end": 2202.0, "text": " We're about being supportive and friendly", "tokens": [50864, 492, 434, 466, 885, 14435, 293, 9208, 50964], "temperature": 0.0, "avg_logprob": -0.14272620185973153, "compression_ratio": 1.724264705882353, "no_speech_prob": 0.013199958018958569}, {"id": 747, "seek": 219000, "start": 2202.0, "end": 2203.0, "text": " And looking after each other", "tokens": [50964, 400, 1237, 934, 1184, 661, 51014], "temperature": 0.0, "avg_logprob": -0.14272620185973153, "compression_ratio": 1.724264705882353, "no_speech_prob": 0.013199958018958569}, {"id": 748, "seek": 219000, "start": 2203.0, "end": 2206.0, "text": " So it's, look different and hopefully say something", "tokens": [51014, 407, 309, 311, 11, 574, 819, 293, 4696, 584, 746, 51164], "temperature": 0.0, "avg_logprob": -0.14272620185973153, "compression_ratio": 1.724264705882353, "no_speech_prob": 0.013199958018958569}, {"id": 749, "seek": 219000, "start": 2206.0, "end": 2208.0, "text": " About the kind of vibe we want inside the community", "tokens": [51164, 7769, 264, 733, 295, 14606, 321, 528, 1854, 264, 1768, 51264], "temperature": 0.0, "avg_logprob": -0.14272620185973153, "compression_ratio": 1.724264705882353, "no_speech_prob": 0.013199958018958569}, {"id": 750, "seek": 219000, "start": 2208.0, "end": 2210.0, "text": " Well you work, thank you", "tokens": [51264, 1042, 291, 589, 11, 1309, 291, 51364], "temperature": 0.0, "avg_logprob": -0.14272620185973153, "compression_ratio": 1.724264705882353, "no_speech_prob": 0.013199958018958569}, {"id": 751, "seek": 219000, "start": 2216.0, "end": 2218.0, "text": " I mean, it's probably the best thing about Glean I think", "tokens": [51664, 286, 914, 11, 309, 311, 1391, 264, 1151, 551, 466, 460, 28499, 286, 519, 51764], "temperature": 0.0, "avg_logprob": -0.14272620185973153, "compression_ratio": 1.724264705882353, "no_speech_prob": 0.013199958018958569}, {"id": 752, "seek": 222000, "start": 2221.0, "end": 2224.0, "text": " Currently you target both Glean and then Javister", "tokens": [50414, 19964, 291, 3779, 1293, 460, 28499, 293, 550, 508, 706, 1964, 50564], "temperature": 0.0, "avg_logprob": -0.15813569641113281, "compression_ratio": 1.735632183908046, "no_speech_prob": 0.03157436102628708}, {"id": 753, "seek": 222000, "start": 2224.0, "end": 2228.0, "text": " What do you plan to do to introduce other targets like WebAssembly?", "tokens": [50564, 708, 360, 291, 1393, 281, 360, 281, 5366, 661, 12911, 411, 9573, 10884, 19160, 30, 50764], "temperature": 0.0, "avg_logprob": -0.15813569641113281, "compression_ratio": 1.735632183908046, "no_speech_prob": 0.03157436102628708}, {"id": 754, "seek": 222000, "start": 2228.0, "end": 2234.0, "text": " So I don't like to look at targets as well as, you know", "tokens": [50764, 407, 286, 500, 380, 411, 281, 574, 412, 12911, 382, 731, 382, 11, 291, 458, 51064], "temperature": 0.0, "avg_logprob": -0.15813569641113281, "compression_ratio": 1.735632183908046, "no_speech_prob": 0.03157436102628708}, {"id": 755, "seek": 222000, "start": 2234.0, "end": 2237.0, "text": " I think there's a problem and when people make in languages", "tokens": [51064, 286, 519, 456, 311, 257, 1154, 293, 562, 561, 652, 294, 8650, 51214], "temperature": 0.0, "avg_logprob": -0.15813569641113281, "compression_ratio": 1.735632183908046, "no_speech_prob": 0.03157436102628708}, {"id": 756, "seek": 222000, "start": 2237.0, "end": 2239.0, "text": " It's very easy for them to do things that are cool", "tokens": [51214, 467, 311, 588, 1858, 337, 552, 281, 360, 721, 300, 366, 1627, 51314], "temperature": 0.0, "avg_logprob": -0.15813569641113281, "compression_ratio": 1.735632183908046, "no_speech_prob": 0.03157436102628708}, {"id": 757, "seek": 222000, "start": 2239.0, "end": 2241.0, "text": " For a language maker to do", "tokens": [51314, 1171, 257, 2856, 17127, 281, 360, 51414], "temperature": 0.0, "avg_logprob": -0.15813569641113281, "compression_ratio": 1.735632183908046, "no_speech_prob": 0.03157436102628708}, {"id": 758, "seek": 222000, "start": 2241.0, "end": 2244.0, "text": " So for example, it would be cool if I could target WebAssembly", "tokens": [51414, 407, 337, 1365, 11, 309, 576, 312, 1627, 498, 286, 727, 3779, 9573, 10884, 19160, 51564], "temperature": 0.0, "avg_logprob": -0.15813569641113281, "compression_ratio": 1.735632183908046, "no_speech_prob": 0.03157436102628708}, {"id": 759, "seek": 222000, "start": 2244.0, "end": 2245.0, "text": " It would be cool if I had type classes", "tokens": [51564, 467, 576, 312, 1627, 498, 286, 632, 2010, 5359, 51614], "temperature": 0.0, "avg_logprob": -0.15813569641113281, "compression_ratio": 1.735632183908046, "no_speech_prob": 0.03157436102628708}, {"id": 760, "seek": 222000, "start": 2245.0, "end": 2247.0, "text": " I don't want to do it for those reasons", "tokens": [51614, 286, 500, 380, 528, 281, 360, 309, 337, 729, 4112, 51714], "temperature": 0.0, "avg_logprob": -0.15813569641113281, "compression_ratio": 1.735632183908046, "no_speech_prob": 0.03157436102628708}, {"id": 761, "seek": 224700, "start": 2247.0, "end": 2250.0, "text": " I want to drive changes by them being impactful to the community", "tokens": [50364, 286, 528, 281, 3332, 2962, 538, 552, 885, 30842, 281, 264, 1768, 50514], "temperature": 0.0, "avg_logprob": -0.10199932789239358, "compression_ratio": 1.7108843537414966, "no_speech_prob": 0.03378312662243843}, {"id": 762, "seek": 224700, "start": 2250.0, "end": 2252.0, "text": " And as I said with WebAssembly", "tokens": [50514, 400, 382, 286, 848, 365, 9573, 10884, 19160, 50614], "temperature": 0.0, "avg_logprob": -0.10199932789239358, "compression_ratio": 1.7108843537414966, "no_speech_prob": 0.03378312662243843}, {"id": 763, "seek": 224700, "start": 2252.0, "end": 2255.0, "text": " That can be a nice VM that you can embed in the compiler", "tokens": [50614, 663, 393, 312, 257, 1481, 18038, 300, 291, 393, 12240, 294, 264, 31958, 50764], "temperature": 0.0, "avg_logprob": -0.10199932789239358, "compression_ratio": 1.7108843537414966, "no_speech_prob": 0.03378312662243843}, {"id": 764, "seek": 224700, "start": 2255.0, "end": 2258.0, "text": " To enable compile time code execution", "tokens": [50764, 1407, 9528, 31413, 565, 3089, 15058, 50914], "temperature": 0.0, "avg_logprob": -0.10199932789239358, "compression_ratio": 1.7108843537414966, "no_speech_prob": 0.03378312662243843}, {"id": 765, "seek": 224700, "start": 2258.0, "end": 2261.0, "text": " You could use that to do like Glean script", "tokens": [50914, 509, 727, 764, 300, 281, 360, 411, 460, 28499, 5755, 51064], "temperature": 0.0, "avg_logprob": -0.10199932789239358, "compression_ratio": 1.7108843537414966, "no_speech_prob": 0.03378312662243843}, {"id": 766, "seek": 224700, "start": 2261.0, "end": 2264.0, "text": " So you could just have just the binary on your server", "tokens": [51064, 407, 291, 727, 445, 362, 445, 264, 17434, 322, 428, 7154, 51214], "temperature": 0.0, "avg_logprob": -0.10199932789239358, "compression_ratio": 1.7108843537414966, "no_speech_prob": 0.03378312662243843}, {"id": 767, "seek": 224700, "start": 2264.0, "end": 2266.0, "text": " And you can use that to execute tiny little scripts", "tokens": [51214, 400, 291, 393, 764, 300, 281, 14483, 5870, 707, 23294, 51314], "temperature": 0.0, "avg_logprob": -0.10199932789239358, "compression_ratio": 1.7108843537414966, "no_speech_prob": 0.03378312662243843}, {"id": 768, "seek": 224700, "start": 2266.0, "end": 2269.0, "text": " When you don't want to have like a whole virtual machine installed", "tokens": [51314, 1133, 291, 500, 380, 528, 281, 362, 411, 257, 1379, 6374, 3479, 8899, 51464], "temperature": 0.0, "avg_logprob": -0.10199932789239358, "compression_ratio": 1.7108843537414966, "no_speech_prob": 0.03378312662243843}, {"id": 769, "seek": 224700, "start": 2269.0, "end": 2270.0, "text": " On that computer for example", "tokens": [51464, 1282, 300, 3820, 337, 1365, 51514], "temperature": 0.0, "avg_logprob": -0.10199932789239358, "compression_ratio": 1.7108843537414966, "no_speech_prob": 0.03378312662243843}, {"id": 770, "seek": 224700, "start": 2270.0, "end": 2272.0, "text": " All sorts of little things like that", "tokens": [51514, 1057, 7527, 295, 707, 721, 411, 300, 51614], "temperature": 0.0, "avg_logprob": -0.10199932789239358, "compression_ratio": 1.7108843537414966, "no_speech_prob": 0.03378312662243843}, {"id": 771, "seek": 224700, "start": 2272.0, "end": 2275.0, "text": " And so I think there is a good", "tokens": [51614, 400, 370, 286, 519, 456, 307, 257, 665, 51764], "temperature": 0.0, "avg_logprob": -0.10199932789239358, "compression_ratio": 1.7108843537414966, "no_speech_prob": 0.03378312662243843}, {"id": 772, "seek": 227500, "start": 2276.0, "end": 2278.0, "text": " Argument in favour of having WebAssembly", "tokens": [50414, 40081, 2206, 294, 8182, 295, 1419, 9573, 10884, 19160, 50514], "temperature": 0.0, "avg_logprob": -0.16369699548791955, "compression_ratio": 1.571969696969697, "no_speech_prob": 0.008433572016656399}, {"id": 773, "seek": 227500, "start": 2278.0, "end": 2280.0, "text": " And so it's something and I would quite enjoy it", "tokens": [50514, 400, 370, 309, 311, 746, 293, 286, 576, 1596, 2103, 309, 50614], "temperature": 0.0, "avg_logprob": -0.16369699548791955, "compression_ratio": 1.571969696969697, "no_speech_prob": 0.008433572016656399}, {"id": 774, "seek": 227500, "start": 2280.0, "end": 2282.0, "text": " So I'd like to explore it in future", "tokens": [50614, 407, 286, 1116, 411, 281, 6839, 309, 294, 2027, 50714], "temperature": 0.0, "avg_logprob": -0.16369699548791955, "compression_ratio": 1.571969696969697, "no_speech_prob": 0.008433572016656399}, {"id": 775, "seek": 227500, "start": 2282.0, "end": 2288.0, "text": " But it's not as high priority as like getting the language server", "tokens": [50714, 583, 309, 311, 406, 382, 1090, 9365, 382, 411, 1242, 264, 2856, 7154, 51014], "temperature": 0.0, "avg_logprob": -0.16369699548791955, "compression_ratio": 1.571969696969697, "no_speech_prob": 0.008433572016656399}, {"id": 776, "seek": 227500, "start": 2288.0, "end": 2291.0, "text": " Working really well, getting the documentation fantastic", "tokens": [51014, 18337, 534, 731, 11, 1242, 264, 14333, 5456, 51164], "temperature": 0.0, "avg_logprob": -0.16369699548791955, "compression_ratio": 1.571969696969697, "no_speech_prob": 0.008433572016656399}, {"id": 777, "seek": 227500, "start": 2291.0, "end": 2293.0, "text": " Making sure we've got like a really lovely", "tokens": [51164, 14595, 988, 321, 600, 658, 411, 257, 534, 7496, 51264], "temperature": 0.0, "avg_logprob": -0.16369699548791955, "compression_ratio": 1.571969696969697, "no_speech_prob": 0.008433572016656399}, {"id": 778, "seek": 227500, "start": 2293.0, "end": 2294.0, "text": " Like Elixir Phoenix like experience", "tokens": [51264, 1743, 2699, 970, 347, 18383, 411, 1752, 51314], "temperature": 0.0, "avg_logprob": -0.16369699548791955, "compression_ratio": 1.571969696969697, "no_speech_prob": 0.008433572016656399}, {"id": 779, "seek": 227500, "start": 2294.0, "end": 2296.0, "text": " To do web development in Glean", "tokens": [51314, 1407, 360, 3670, 3250, 294, 460, 28499, 51414], "temperature": 0.0, "avg_logprob": -0.16369699548791955, "compression_ratio": 1.571969696969697, "no_speech_prob": 0.008433572016656399}, {"id": 780, "seek": 227500, "start": 2296.0, "end": 2298.0, "text": " So I would like it", "tokens": [51414, 407, 286, 576, 411, 309, 51514], "temperature": 0.0, "avg_logprob": -0.16369699548791955, "compression_ratio": 1.571969696969697, "no_speech_prob": 0.008433572016656399}, {"id": 781, "seek": 227500, "start": 2298.0, "end": 2301.0, "text": " Maybe one day, don't hold your breath", "tokens": [51514, 2704, 472, 786, 11, 500, 380, 1797, 428, 6045, 51664], "temperature": 0.0, "avg_logprob": -0.16369699548791955, "compression_ratio": 1.571969696969697, "no_speech_prob": 0.008433572016656399}, {"id": 782, "seek": 230500, "start": 2305.0, "end": 2307.0, "text": " When you do message passing in Glean", "tokens": [50364, 1133, 291, 360, 3636, 8437, 294, 460, 28499, 50464], "temperature": 0.0, "avg_logprob": -0.23284042633331573, "compression_ratio": 1.5481171548117154, "no_speech_prob": 0.025230076164007187}, {"id": 783, "seek": 230500, "start": 2307.0, "end": 2310.0, "text": " Does the messages support function cloners as well", "tokens": [50464, 4402, 264, 7897, 1406, 2445, 596, 266, 433, 382, 731, 50614], "temperature": 0.0, "avg_logprob": -0.23284042633331573, "compression_ratio": 1.5481171548117154, "no_speech_prob": 0.025230076164007187}, {"id": 784, "seek": 230500, "start": 2310.0, "end": 2313.0, "text": " And if so, how does your type system handle it?", "tokens": [50614, 400, 498, 370, 11, 577, 775, 428, 2010, 1185, 4813, 309, 30, 50764], "temperature": 0.0, "avg_logprob": -0.23284042633331573, "compression_ratio": 1.5481171548117154, "no_speech_prob": 0.025230076164007187}, {"id": 785, "seek": 230500, "start": 2313.0, "end": 2315.0, "text": " As in you're asking", "tokens": [50764, 1018, 294, 291, 434, 3365, 50864], "temperature": 0.0, "avg_logprob": -0.23284042633331573, "compression_ratio": 1.5481171548117154, "no_speech_prob": 0.025230076164007187}, {"id": 786, "seek": 230500, "start": 2315.0, "end": 2317.0, "text": " When you're doing type OTP", "tokens": [50864, 1133, 291, 434, 884, 2010, 422, 16804, 50964], "temperature": 0.0, "avg_logprob": -0.23284042633331573, "compression_ratio": 1.5481171548117154, "no_speech_prob": 0.025230076164007187}, {"id": 787, "seek": 230500, "start": 2317.0, "end": 2320.0, "text": " Can you send a function to another process?", "tokens": [50964, 1664, 291, 2845, 257, 2445, 281, 1071, 1399, 30, 51114], "temperature": 0.0, "avg_logprob": -0.23284042633331573, "compression_ratio": 1.5481171548117154, "no_speech_prob": 0.025230076164007187}, {"id": 788, "seek": 230500, "start": 2320.0, "end": 2321.0, "text": " Yeah, function cloners", "tokens": [51114, 865, 11, 2445, 596, 266, 433, 51164], "temperature": 0.0, "avg_logprob": -0.23284042633331573, "compression_ratio": 1.5481171548117154, "no_speech_prob": 0.025230076164007187}, {"id": 789, "seek": 230500, "start": 2321.0, "end": 2323.0, "text": " Yes, okay, so", "tokens": [51164, 1079, 11, 1392, 11, 370, 51264], "temperature": 0.0, "avg_logprob": -0.23284042633331573, "compression_ratio": 1.5481171548117154, "no_speech_prob": 0.025230076164007187}, {"id": 790, "seek": 230500, "start": 2326.0, "end": 2328.0, "text": " So, it's quite tricky", "tokens": [51414, 407, 11, 309, 311, 1596, 12414, 51514], "temperature": 0.0, "avg_logprob": -0.23284042633331573, "compression_ratio": 1.5481171548117154, "no_speech_prob": 0.025230076164007187}, {"id": 791, "seek": 230500, "start": 2328.0, "end": 2331.0, "text": " You can't, how much context do I give this", "tokens": [51514, 509, 393, 380, 11, 577, 709, 4319, 360, 286, 976, 341, 51664], "temperature": 0.0, "avg_logprob": -0.23284042633331573, "compression_ratio": 1.5481171548117154, "no_speech_prob": 0.025230076164007187}, {"id": 792, "seek": 230500, "start": 2331.0, "end": 2333.0, "text": " Because I've thought about this for years", "tokens": [51664, 1436, 286, 600, 1194, 466, 341, 337, 924, 51764], "temperature": 0.0, "avg_logprob": -0.23284042633331573, "compression_ratio": 1.5481171548117154, "no_speech_prob": 0.025230076164007187}, {"id": 793, "seek": 233300, "start": 2333.0, "end": 2334.0, "text": " And it's quite hard", "tokens": [50364, 400, 309, 311, 1596, 1152, 50414], "temperature": 0.0, "avg_logprob": -0.10545673067607576, "compression_ratio": 1.6973180076628354, "no_speech_prob": 0.016363458707928658}, {"id": 794, "seek": 233300, "start": 2334.0, "end": 2337.0, "text": " Yes, we can, you can pass any data to another function", "tokens": [50414, 1079, 11, 321, 393, 11, 291, 393, 1320, 604, 1412, 281, 1071, 2445, 50564], "temperature": 0.0, "avg_logprob": -0.10545673067607576, "compression_ratio": 1.6973180076628354, "no_speech_prob": 0.016363458707928658}, {"id": 795, "seek": 233300, "start": 2337.0, "end": 2341.0, "text": " The key difference between message passing", "tokens": [50564, 440, 2141, 2649, 1296, 3636, 8437, 50764], "temperature": 0.0, "avg_logprob": -0.10545673067607576, "compression_ratio": 1.6973180076628354, "no_speech_prob": 0.016363458707928658}, {"id": 796, "seek": 233300, "start": 2341.0, "end": 2344.0, "text": " In typed Glean OTP and Erlang OTP", "tokens": [50764, 682, 33941, 460, 28499, 422, 16804, 293, 3300, 25241, 422, 16804, 50914], "temperature": 0.0, "avg_logprob": -0.10545673067607576, "compression_ratio": 1.6973180076628354, "no_speech_prob": 0.016363458707928658}, {"id": 797, "seek": 233300, "start": 2344.0, "end": 2348.0, "text": " Is that you need to have more than just a PID", "tokens": [50914, 1119, 300, 291, 643, 281, 362, 544, 813, 445, 257, 430, 2777, 51114], "temperature": 0.0, "avg_logprob": -0.10545673067607576, "compression_ratio": 1.6973180076628354, "no_speech_prob": 0.016363458707928658}, {"id": 798, "seek": 233300, "start": 2348.0, "end": 2350.0, "text": " To send a message or something", "tokens": [51114, 1407, 2845, 257, 3636, 420, 746, 51214], "temperature": 0.0, "avg_logprob": -0.10545673067607576, "compression_ratio": 1.6973180076628354, "no_speech_prob": 0.016363458707928658}, {"id": 799, "seek": 233300, "start": 2350.0, "end": 2352.0, "text": " If you've used languages that have channels", "tokens": [51214, 759, 291, 600, 1143, 8650, 300, 362, 9235, 51314], "temperature": 0.0, "avg_logprob": -0.10545673067607576, "compression_ratio": 1.6973180076628354, "no_speech_prob": 0.016363458707928658}, {"id": 800, "seek": 233300, "start": 2352.0, "end": 2355.0, "text": " So for example, Go or Rust", "tokens": [51314, 407, 337, 1365, 11, 1037, 420, 34952, 51464], "temperature": 0.0, "avg_logprob": -0.10545673067607576, "compression_ratio": 1.6973180076628354, "no_speech_prob": 0.016363458707928658}, {"id": 801, "seek": 233300, "start": 2355.0, "end": 2358.0, "text": " You don't just have like the handle for the thread", "tokens": [51464, 509, 500, 380, 445, 362, 411, 264, 4813, 337, 264, 7207, 51614], "temperature": 0.0, "avg_logprob": -0.10545673067607576, "compression_ratio": 1.6973180076628354, "no_speech_prob": 0.016363458707928658}, {"id": 802, "seek": 233300, "start": 2358.0, "end": 2359.0, "text": " And pass a message to it", "tokens": [51614, 400, 1320, 257, 3636, 281, 309, 51664], "temperature": 0.0, "avg_logprob": -0.10545673067607576, "compression_ratio": 1.6973180076628354, "no_speech_prob": 0.016363458707928658}, {"id": 803, "seek": 233300, "start": 2359.0, "end": 2360.0, "text": " You've got to have a channel", "tokens": [51664, 509, 600, 658, 281, 362, 257, 2269, 51714], "temperature": 0.0, "avg_logprob": -0.10545673067607576, "compression_ratio": 1.6973180076628354, "no_speech_prob": 0.016363458707928658}, {"id": 804, "seek": 233300, "start": 2360.0, "end": 2362.0, "text": " And you send a message via the channel", "tokens": [51714, 400, 291, 2845, 257, 3636, 5766, 264, 2269, 51814], "temperature": 0.0, "avg_logprob": -0.10545673067607576, "compression_ratio": 1.6973180076628354, "no_speech_prob": 0.016363458707928658}, {"id": 805, "seek": 236200, "start": 2362.0, "end": 2363.0, "text": " So it's the same idea", "tokens": [50364, 407, 309, 311, 264, 912, 1558, 50414], "temperature": 0.0, "avg_logprob": -0.05602550506591797, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.05456540361046791}, {"id": 806, "seek": 236200, "start": 2363.0, "end": 2365.0, "text": " So we have this idea of a subject", "tokens": [50414, 407, 321, 362, 341, 1558, 295, 257, 3983, 50514], "temperature": 0.0, "avg_logprob": -0.05602550506591797, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.05456540361046791}, {"id": 807, "seek": 236200, "start": 2365.0, "end": 2366.0, "text": " We don't call it a channel", "tokens": [50514, 492, 500, 380, 818, 309, 257, 2269, 50564], "temperature": 0.0, "avg_logprob": -0.05602550506591797, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.05456540361046791}, {"id": 808, "seek": 236200, "start": 2366.0, "end": 2367.0, "text": " Because it would be confusing", "tokens": [50564, 1436, 309, 576, 312, 13181, 50614], "temperature": 0.0, "avg_logprob": -0.05602550506591797, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.05456540361046791}, {"id": 809, "seek": 236200, "start": 2367.0, "end": 2370.0, "text": " Because it still goes to a process inbox", "tokens": [50614, 1436, 309, 920, 1709, 281, 257, 1399, 35067, 50764], "temperature": 0.0, "avg_logprob": -0.05602550506591797, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.05456540361046791}, {"id": 810, "seek": 236200, "start": 2370.0, "end": 2372.0, "text": " You can't give a channel to a different process", "tokens": [50764, 509, 393, 380, 976, 257, 2269, 281, 257, 819, 1399, 50864], "temperature": 0.0, "avg_logprob": -0.05602550506591797, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.05456540361046791}, {"id": 811, "seek": 236200, "start": 2372.0, "end": 2374.0, "text": " And they start pulling from it", "tokens": [50864, 400, 436, 722, 8407, 490, 309, 50964], "temperature": 0.0, "avg_logprob": -0.05602550506591797, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.05456540361046791}, {"id": 812, "seek": 236200, "start": 2374.0, "end": 2377.0, "text": " And every channel is the thing that's typed", "tokens": [50964, 400, 633, 2269, 307, 264, 551, 300, 311, 33941, 51114], "temperature": 0.0, "avg_logprob": -0.05602550506591797, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.05456540361046791}, {"id": 813, "seek": 236200, "start": 2377.0, "end": 2379.0, "text": " Not the PID", "tokens": [51114, 1726, 264, 430, 2777, 51214], "temperature": 0.0, "avg_logprob": -0.05602550506591797, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.05456540361046791}, {"id": 814, "seek": 236200, "start": 2379.0, "end": 2381.0, "text": " It looks like you should be able to do the PID", "tokens": [51214, 467, 1542, 411, 291, 820, 312, 1075, 281, 360, 264, 430, 2777, 51314], "temperature": 0.0, "avg_logprob": -0.05602550506591797, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.05456540361046791}, {"id": 815, "seek": 236200, "start": 2381.0, "end": 2383.0, "text": " But then you suddenly realize", "tokens": [51314, 583, 550, 291, 5800, 4325, 51414], "temperature": 0.0, "avg_logprob": -0.05602550506591797, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.05456540361046791}, {"id": 816, "seek": 236200, "start": 2383.0, "end": 2384.0, "text": " If you build from the ground up", "tokens": [51414, 759, 291, 1322, 490, 264, 2727, 493, 51464], "temperature": 0.0, "avg_logprob": -0.05602550506591797, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.05456540361046791}, {"id": 817, "seek": 236200, "start": 2384.0, "end": 2386.0, "text": " You can't implement synchronous", "tokens": [51464, 509, 393, 380, 4445, 44743, 51564], "temperature": 0.0, "avg_logprob": -0.05602550506591797, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.05456540361046791}, {"id": 818, "seek": 236200, "start": 2386.0, "end": 2389.0, "text": " You can't implement call, synchronous message passing", "tokens": [51564, 509, 393, 380, 4445, 818, 11, 44743, 3636, 8437, 51714], "temperature": 0.0, "avg_logprob": -0.05602550506591797, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.05456540361046791}, {"id": 819, "seek": 238900, "start": 2389.0, "end": 2392.0, "text": " If you have typed PIDs", "tokens": [50364, 759, 291, 362, 33941, 430, 2777, 82, 50514], "temperature": 0.0, "avg_logprob": -0.10419778420891561, "compression_ratio": 1.788888888888889, "no_speech_prob": 0.12233646959066391}, {"id": 820, "seek": 238900, "start": 2392.0, "end": 2394.0, "text": " Because the type of the return", "tokens": [50514, 1436, 264, 2010, 295, 264, 2736, 50614], "temperature": 0.0, "avg_logprob": -0.10419778420891561, "compression_ratio": 1.788888888888889, "no_speech_prob": 0.12233646959066391}, {"id": 821, "seek": 238900, "start": 2394.0, "end": 2396.0, "text": " Doesn't match the type of the PID", "tokens": [50614, 12955, 380, 2995, 264, 2010, 295, 264, 430, 2777, 50714], "temperature": 0.0, "avg_logprob": -0.10419778420891561, "compression_ratio": 1.788888888888889, "no_speech_prob": 0.12233646959066391}, {"id": 822, "seek": 238900, "start": 2396.0, "end": 2397.0, "text": " So you need to have something more flexible", "tokens": [50714, 407, 291, 643, 281, 362, 746, 544, 11358, 50764], "temperature": 0.0, "avg_logprob": -0.10419778420891561, "compression_ratio": 1.788888888888889, "no_speech_prob": 0.12233646959066391}, {"id": 823, "seek": 238900, "start": 2397.0, "end": 2398.0, "text": " So we have this thing", "tokens": [50764, 407, 321, 362, 341, 551, 50814], "temperature": 0.0, "avg_logprob": -0.10419778420891561, "compression_ratio": 1.788888888888889, "no_speech_prob": 0.12233646959066391}, {"id": 824, "seek": 238900, "start": 2398.0, "end": 2400.0, "text": " And if you look under the hood in Erlang OTP", "tokens": [50814, 400, 498, 291, 574, 833, 264, 13376, 294, 3300, 25241, 422, 16804, 50914], "temperature": 0.0, "avg_logprob": -0.10419778420891561, "compression_ratio": 1.788888888888889, "no_speech_prob": 0.12233646959066391}, {"id": 825, "seek": 238900, "start": 2400.0, "end": 2404.0, "text": " They have the same abstraction", "tokens": [50914, 814, 362, 264, 912, 37765, 51114], "temperature": 0.0, "avg_logprob": -0.10419778420891561, "compression_ratio": 1.788888888888889, "no_speech_prob": 0.12233646959066391}, {"id": 826, "seek": 238900, "start": 2404.0, "end": 2406.0, "text": " We've got 14 seconds left", "tokens": [51114, 492, 600, 658, 3499, 3949, 1411, 51214], "temperature": 0.0, "avg_logprob": -0.10419778420891561, "compression_ratio": 1.788888888888889, "no_speech_prob": 0.12233646959066391}, {"id": 827, "seek": 238900, "start": 2406.0, "end": 2409.0, "text": " And it's used to implement GenServit.co", "tokens": [51214, 400, 309, 311, 1143, 281, 4445, 3632, 50, 1978, 270, 13, 1291, 51364], "temperature": 0.0, "avg_logprob": -0.10419778420891561, "compression_ratio": 1.788888888888889, "no_speech_prob": 0.12233646959066391}, {"id": 828, "seek": 238900, "start": 2409.0, "end": 2410.0, "text": " So they have this from thing", "tokens": [51364, 407, 436, 362, 341, 490, 551, 51414], "temperature": 0.0, "avg_logprob": -0.10419778420891561, "compression_ratio": 1.788888888888889, "no_speech_prob": 0.12233646959066391}, {"id": 829, "seek": 238900, "start": 2410.0, "end": 2413.0, "text": " So it's the same as the from field in GenServit.co", "tokens": [51414, 407, 309, 311, 264, 912, 382, 264, 490, 2519, 294, 3632, 50, 1978, 270, 13, 1291, 51564], "temperature": 0.0, "avg_logprob": -0.10419778420891561, "compression_ratio": 1.788888888888889, "no_speech_prob": 0.12233646959066391}, {"id": 830, "seek": 238900, "start": 2413.0, "end": 2415.0, "text": " That's the thing that you send messages around with", "tokens": [51564, 663, 311, 264, 551, 300, 291, 2845, 7897, 926, 365, 51664], "temperature": 0.0, "avg_logprob": -0.10419778420891561, "compression_ratio": 1.788888888888889, "no_speech_prob": 0.12233646959066391}, {"id": 831, "seek": 238900, "start": 2415.0, "end": 2416.0, "text": " I have three seconds left", "tokens": [51664, 286, 362, 1045, 3949, 1411, 51714], "temperature": 0.0, "avg_logprob": -0.10419778420891561, "compression_ratio": 1.788888888888889, "no_speech_prob": 0.12233646959066391}, {"id": 832, "seek": 238900, "start": 2416.0, "end": 2417.0, "text": " Thank you very much everybody", "tokens": [51714, 1044, 291, 588, 709, 2201, 51764], "temperature": 0.0, "avg_logprob": -0.10419778420891561, "compression_ratio": 1.788888888888889, "no_speech_prob": 0.12233646959066391}, {"id": 833, "seek": 241700, "start": 2417.0, "end": 2419.0, "text": " Thank you very much", "tokens": [50364, 1044, 291, 588, 709, 50464], "temperature": 0.0, "avg_logprob": -0.4098211015973772, "compression_ratio": 0.7037037037037037, "no_speech_prob": 0.7912212014198303}], "language": "en"}