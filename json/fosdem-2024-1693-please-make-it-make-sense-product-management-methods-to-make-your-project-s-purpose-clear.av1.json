{"text": " I think are we good? Okay, so next up we have some product management coverage content by Loria. Hi. Yeah, so I've been a little bit of an AV disaster, so I'm going to have to look at my slides because I can't see them here. But here's the title of my talk today. My goal is to help you get more structure around your open source projects, hopefully save time and ideally do less. Okay, so about me, I'm an American living in Germany since 2015 and I mention this because I came to Germany with a very live to work mindset and now I have a very work to live mindset. And you're going to see that mindset shift in my talks, like the messaging I share with you. Among my many open source activities has been contributing to Kubernetes, particularly SIG release and also more recently the open SSS security scorecard project. I have this link here where I thought I'd highlight it because you can find a lot of management and leadership guidance there. It's a collection of resources, blog posts, videos, templates, things like this, including some things I'll show you today. I've worked in places. I'm not working now. My company shut down at the turn of the year. So if you like what I have to say and think I could be helpful to your organization, let's talk and there's my LinkedIn in the meantime. I'll cover basically two branches in this talk. First is some observations from my time in open source. I'll sprinkle some helpful hints and examples along the way and then I will focus on some tried and true traditional product management methods that work in a company setting. You've probably encountered them in your day jobs, but they also work in open source with a little bit of creativity. So some of those observations, I see contributors taking on so much work. Just lots of issues, many times even multiple leadership roles and it just seems like a sure far way to burn them. Because they're so overstretched, they don't have a lot of time to do a lot of research and gather data. Also, that's a skill set that not everybody has and not everybody needs to have. But the end result is often that a lot of development is based on assumptions instead of data. Another thing I've noticed is that what exists today in a project isn't well-defined or documented or mutually understood by the project team. This represents a pitfall because you maybe don't have the shared understanding of what your project is and does and should be. And lastly, there's often times of vague strategy or even none at all. I would say that the most acute manifestation of this issue is that there's often a boundary between what goes in a project and what stays out that is lacking. This can lead to a lot of work being done and that work just kind of expanding. So if you take away anything from me today, it would be this message which is I really encourage and invite you to do less if you can. I know your manager may not want you to do less. There's always very specific conditions around that relationship, speaking from experience. So I'm happy to talk to any of you after the talk if you would like to have a sound and pour like ways you can manage your manager's expectations around what you can do in open source with your limited time and availability. But if you are the pressure source telling yourself to do all of the things, then I invite you to ask yourself at first like, does anybody even want this? I mean, maybe they do, but maybe if you're the only person or you don't have a very clear sense of how many people might find value in your project, maybe stop and collect more data before you move on. Also keep your personal backlog light. I know some people really enjoy working with them, but they take on so much work that they end up becoming the blocker for other people to make progress. And you don't really want to do that, right? You don't want to impede your fellow project contributors' efforts because you're like the decision maker on 10 different things. So that leads to delegating. Delegating not just to reduce your workload, but also to empower others to gain skills that you have. And I know that's rather time consuming, but oftentimes what I've seen in open source is that a little bit of upfront onboarding and knowledge exchange saves everybody time in the later stages because you have multiple people who can work on something at once. And the last tip is something I've used over the years because I would just take on work too. I love it, like, let's be busy. And then I would find that the work that I took on actually involved a lot more than I bargained for. So I highly encourage you to unpack a task before you say yes to doing that task because you may find that it's going to take you a significant amount of time. Here's an example of that. So this is a project board that I created with collaborators from SIG Release and Kubernetes. The initial idea was to rewrite a tool from scratch. And I looked at that and thought I heard that and I was like, you know, we may not want to do that because that sounds really, really intensive. So what we did is over a couple of sessions we figured out some real things that we didn't know about this particular tool that we wanted to, you know, talking about rewriting. And what we had was a lot of questions, like what is it, what does it do, what do users want. So you may not see all this text, but just the TLDR for you. There's a lot of spikes in decision making and documentation, like proposals to write to get community feedback before even setting to write code. So this is what I mentioned earlier, like the assumptions that we often take into our development plans. We had a lot of assumptions that we just had to rewrite this tool because it's just too broken and, you know, we just do it over. That's often not the case. And so I just want to point out that I didn't come up with the idea of assumption-driven development. I found a term that someone else created, and in my search to find out exactly who, I came upon this blog post, which I found really interesting. It's a developer who basically described his own failure trajectory because he was operating with assumption-driven development. And what he did was he decided to just take on a lot of work on his own. He didn't talk to anybody around him. He also didn't understand what he was working with in that day, like the tooling and all of the different tooling relationships, and also the knock-on effects of making changes. And he kind of went in like, I'm going to do this, say, and like it's going to be done. And that also didn't turn out to be true. There was a lot more work involved that he had expected and planned for. So I thought it was a really great summary from the developer's perspective of why assumption-driven development is often not the best method to use. I'm going to give them a talk, and you can ask questions after. Thanks. So basically, what I'm suggesting here, like a way to conquer assumptions, is oftentimes just listening to your environment. And that starts with the people around you. So there's this thing called active listening, and I found a nice resource from the Center for Creative Leadership, and they give you some behaviors that you can adopt, or adopt rather, to start listening more actively to your colleagues or co-collaborators and others you work with. They say, first of all, pay attention. And we take this as a given, but in our world of smartphones and lots of distractions and multitasking, we often don't really fully pay attention to each other. And one way that we don't do this is that we sometimes can't wait to, we don't wait for the person to finish what they're saying, before we just like, oh, I want to get my point out. We have to go, and then we end up missing the latter half of the sentence, because we're too focused on our own sentence and what we want to say. So active listening means that you don't do that. You actually let somebody finish, and then you ask. And you also can do things like clarify what the person is telling you by asking them questions. Did I think, I think I heard you say this. Is that correct? Or can you tell me more about what you're trying to say to me? And then together, it starts to become a collaboration, because you're inviting them to also clarify their ideas for themselves. And you're also getting higher quality information, because A, you're taking it in, and you're also engaging with it in a team context to work out new ideas. In addition to listening to your colleagues and people around you, you should also listen to your code. So I mentioned a few slides ago about this idea to rewrite a tool from scratch. But if you don't really listen to your own code from the beginning, you may end up doing a lot of work that you could have avoided by just optimizing and selectively choosing what to work on. So having artifacts like docs and diagrams will help you to better reason about the work you truly should do. Optimize, find the points where you can make things better, and also plan accordingly. So here's another example from Sig Release where we applied this principle. We had this tool, right? And we were going to rewrite it. But I said, first of all, let's actually document the flow that the user follows to use this tool, achieve a job, go from point A to point B. And so an engineer in Sig Release did this, and then we gathered around as a group, around his workflow, and talked through every step, figuring out what was really hard, what was taking a lot of time, what wasn't working. And as you can see from the results, the first line there is the overall flow. And then I blew up this section toward the end, where you see a lot of anger, and then there's this little clock, which means it was really time consuming. And you could then see in the full landscape of this project's flow where the pain points truly were. And we were also able to use these posts to document exactly where the code existed that was executing these steps. And so what we walked away with was a much more focused plan for what we needed to do. And we can then start there and then decide after collecting a lot of information about these weaker points what we should do next. Maybe we rewrite parts of this instead of the whole thing. When you have a workflow like that in place, it really helps you to put, it puts you in better control of your project. Now if you have no projects, that's fine too. What we're going to cover next are some tools that you can apply as you start working on a new project. But you can also introduce these even if you have something that's several years old. It doesn't matter. It's never too late to understand your work and then organize yourself to do the highest value work in the future. So I'm going to cover having a strategy with a doc template, doing user research and surveys, including an example of a survey which is the NPS, making a roadmap and giving you a template you can use, and then prioritizing and refining your backlog with some methods and tools you can apply for those activities. So here's a strategy doc template that I just worked with the security scorecard team on to actually fill this out. And I know these little lines here are small and you can't see them. I'll get to that in the next slide. But it basically introduces the concepts of the 5Ws that journalists use typically to write a news story where they need to have the reader know the facts of the story right away and then if the reader wants more detailed information they can read on. But it answers who, what, when, where, and why as well as how. The goal here is that you have an asynchronous tool that you can use so you don't have to have a meeting around this, although I advise it because you'll find that more information comes out when you actually discuss your strategy. But you can at least start with a template like this and people then can contribute their comments and ideas to it. This is Miro by the way. When you actually have this template filled out and you've gone through it with your team then you can dump it into a doc, refine it a bit more and then publish it in your repository for the public to look at. And then of course you can continuously revise as your project develops and you discover new information. So those small questions in that template are here basically. Not all of them but some key questions that are quite useful for getting a sense of where you're going with your work. So who are the users as long as the contributors and the maintainers? But really who are the users? Who are the people deriving value from your project today? And who do you want to derive, who do you want to have value derived in the future? Like who should derive value in the future? What does your project do today? On the flip side what does it not do? I mentioned earlier that boundary about what goes in a project and what stays out. When you can clearly explain what a project is and what it is not and what it shouldn't be then you can get a clearer sense of where that boundary lies. You can also think here about what the UX is like and what quality concerns and constraints you have. It's really just like what is your project essentially? What is your project useful? So what are the conditions to trigger a user actively coming to you, you're solving their problem? Another way to look at when is like how long does a particular stage of your project's workflow take to be completed? Where does your project fit in the ecosystem? So I'm not going to go over the ins and outs of doing a competitor analysis here. There's lots of templates online that you can look at to do one. But I highly recommend it because when you take a look at other projects in the space that are doing similar, solving a similar problem, you can then assess the resources behind those projects. Maybe there are even products, so maybe there's like a company doing what you want to do. So they have a lot of money and they can work quickly and then you can consider like what you actually have in your time budget to actually pursue. You can also see what those projects and products strengths and weaknesses are and then use that information to distinguish and differentiate like what you want to provide. Maybe it's a niche that you want to really get a handle on and provide a really clear good solution for that no one else is providing. Maybe it's just because your project is community-based and other projects and products out there are like for money and so like you're going to be able to serve the community whereas those alternatives will not. So thinking about where your project fits in that landscape is really quite helpful. That leads into why your project exists in the first place. What value does it deliver? Then that puts you in the seat of the user who is actually trying to use your project and solve those problems they face. Another question I like to ask around why is the cost of delay. So if we don't develop this project now or if we don't iterate on it and provide these features of functionality, what bad things happen? What bad things happen to our goals? What bad things happen for users who continue facing this problem without any solution? What happens to innovation in general? There's really a lot of interesting conversations you can have around cost of delay. Then finally how does it work now? This question is also a really nice hook for you to think about the future and where you want to be in 12 months or 24 months with it. How do you want to build this to provide different features? Maybe redesign the architecture to be simpler. How do you want to be and how is a good frame for that? I pointed earlier, we're going to cover some more tools and methods. The next one is user research and surveys. Having as much data as you possibly can really pulls you out of your own biases and what the developer with the assumption driven development blog post was describing. I only listened to me and it didn't work. If you're listening to your prospective users, your current users, other project leaders, you start to get all these different perspectives that can ultimately help you develop the right most valuable thing and not develop a lot of other things that are going to take up a lot of effort but maybe won't have such a payoff for you or for anyone else. Surveys should be kept quick and easy. I tend to use Google forums. I mean, I know it's not open source but it works. I don't ask people to write a lot because you don't want to read at all. You probably don't have time to read lots and lots of survey responses. The survey respondents also probably don't have a lot of time to fill out lots of forms. Using check boxes, multiple choice, rating options from zero to five or whatever you want to set is your endpoints. You have numeric data that you can quickly turn into charts like this one which was from a Google survey and it's just easy to make a chart out of the results. Another thing I like to remind people of is Please Buy by GDPR. Be careful about how you're collecting the data of the people who are filling out your survey. Make sure they offer their consent before you offer them a chance to give them, to give consent for usage of your data before they move on. Another great way to collect user data is through discussions. Like on GitHub, you can post a question and see people respond to it. That can be a little more time consuming because you're going to have to read through all of those answers. But it can be quite useful too because you get broader context. If you're in a hurry and you just say, hey, community, I want to know if you want us to do this thing or not. You can send out an issue and have them give it a plus one or not. You can use emoticons, this like votes. There's other tools out there that product managers use all the time like AHA that offer this kind of voting functionality for feature ideas. And finally, interviews which are really can be quite time consuming. But if you have the time to do them, you can even just do a few. You can learn so much about your own project. You can sit and watch somebody try to use it and see where they get stuck, see what's confusing to them, and collect all of that data and think of ways to optimize and improve. Oh, I forgot. This is a really important point to ask them. With the results, a lot of times when people fill out surveys, it's numbers, so it's all scientific. But it often isn't because our users may be giving their feedback from a limited set of data points themselves because they may not be aware of all the alternatives, all the directions that your project can take. They may not have a full understanding of the functionality because they don't have time or maybe you didn't explain it well. So always be aware that just when somebody tells you what they want, they may not actually want that thing. That may be the best guess that they have that would solve their problem, but actually in the broader context of other types of users, it wouldn't solve the problem in the best way. So just keep that in mind that data can also be a little bit of a trap if not used carefully. I want to give this example of a survey that you can run very quickly. If you don't have time to set up a forum yourself, lots of questions, you can still do an NPS survey. This is used by lots of companies, but it's quite useful in our context because it just consists of two questions. Basically would you recommend my project in this case to a friend or colleague? And then can you please explain why you gave that score? So the number is very easy. You have to put it in some kind of NPS calculator, so I gave you a link to one. It's also the image source. You basically put in all that data and then you come up with your NPS. And then there's different analyses online for like what is a good score, usually it's 20. When you're 50 to 80, you're doing really well. So that's from the way that the score is calculated. It's a pretty low overhead way to collect feedback. Are we on the right track or not? I mentioned also the next type of tool I want to show you and that's explained with this roadmap template which you can adapt to your own needs if you'd like. I cover some of the who, what, when, where, why questions that I covered with the strategy doc template. But the roadmap is more of the short term. What would you like to do in your next, say, three to six months? It's taking a slice of your strategy into getting you more focused around what you want to develop now. My strong recommendation is to keep it to a page or less so that people can actually remember it. Keep the number of deliverables and goals low, like one for three max, using a metric to justify why it's necessary. If you don't have a metric, like a baseline to say like we're doing this deliverable because X number of users want it, then you can also think about the metric that you want to apply to then be able to measure the success of your feature. I always like to include risks, like what is known, what is unknown in a roadmap, just so that with the unknowns you can plan that it might take away time from the future development. So it might be a bit of a distraction, but you at least are aware of it and you're going to have to work it out in the future as you go. And then technical goals. And this is like to make sure that quality, observability, testing doesn't fall by the wayside. I see this happening in a lot of projects and products as well where like all the stuff that actually makes the thing run gets pushed to the end and then the engineering team is stuck with a very patchy problematic system that they want to really fix, but nobody has a lot of time for them to do so. The next last couple of slides are just covering prioritization. So this is a matrix that I like to use because it allows teams to take a stack of issues and then plot them on this matrix. The matrix asks them to assess tasks, ideas based on the amount of effort along with the value that they expect to provide for the user once they do the thing. And then this allows the team to see like if they have a lot of things that are high value but also high effort, then they either need to maybe focus on one of those because they're not going to do like 10 high impact, high effort items at once or break them down into smaller bits so that they can then go into the do it now column which is really where your quick wins and your low hanging fruit should go. It's really important to plan for those quick wins to have them early on so that you can collect momentum and the team doesn't feel like they're just in some long slog that they're never going to see the results of their work. If you have quick turnaround for impact provided then that's nice because they can celebrate those wins early and keep going. There's also this nice, this is my favorite box, the don't do it box because that's where you just like close the issue and forget. Here's where I use this matrix in action. This is also a security scorecard recently. We haven't done this exercise yet but I'm really hoping we do it soon. This is basically all the bugs in the backlog and just putting them in specific buckets like some of them weren't bugs so that was just really categorizing what's a bug what isn't. Then the goal here is the team will plot the bugs on this graph and then we might find out that some of the bugs were solved, maybe some of them are relevant now but it's really to kick stuff out of the backlog and then just have the focus on what is really important, what's really valuable, what are people really being hurt by right now like we should fix right away. That's basically the steps for how you would apply such a matrix. I also encourage using a scoring model. There's a lot of different scoring models and you can find on Google or Ecosia, my favorite search engine personally is Ecosia. You can go in there and see what scoring models can do to help you assess things like reach, impact, excitement, effort and have a weighted scoring option so you can stack rank your backlog items and then do the top items first because you've decided through data and analysis that they're the most valuable ones. This is another template for your strategy. I just found this on Miro. It's by Lou Coleman and basically if you're rolling out an MVP for a new project for the first time, your center of focus is obviously the tree trunk so making the purpose of that really strong and solid and then over time you have more time to build on your tree trunk. This format allows you to plot your plans basically on different bands. So maybe the future band might be something that's high impact and high effort but it's just going to take a lot of time so you don't project that you're going to have it done right away. I just thought it was a nice visual I like trees too. Last slide is probably something that's very familiar to you. It's a standard campaign project board but this really helps with asynchronous collaboration because if you're running your board really well you'll only have high value work in it and then your contributors don't have to have a meeting to figure out what to do. They just pull off from the board knowing that you've clearly vetted your work through the tools that I've shown you so that they know that what they're going to deliver is ready to go and it's going to make a difference. My experience people are really motivated by purpose. They don't want to just do something for busy work. They actually want to know they're making a change. So with your really nicely refined backlog you can help your contributors along by giving them valuable work to do. I suggest making a triage work in group or having some mechanism in your team but just make sure that issues are triaged regularly so they don't pile up and that's a really good way to get non-code contributors involved as well. Making valuable high purpose work. Hopefully I have helped clear your path and helped you clarify your purpose. This is a nice trail in Amsterdam. It's quiet and friendly and inviting so hopefully that your open source development can achieve some similar aesthetics and that's it and that's the links to the resources that I've shared earlier. Not a question. So this goes back to the assumption driven development that made me wonder especially since you pointed out to stake the work first so you know what you're getting yourself into but if I do that, if I had done that then I would have never started any effort at any time because I would have been too intimidated had I known what I would have gotten myself into. So what do I do to still get stuff done? I think it depends on the number of factors. If you have a lot of time to build something out and really focus on it.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 7.4, "text": " I think are we good?", "tokens": [50364, 286, 519, 366, 321, 665, 30, 50734], "temperature": 0.0, "avg_logprob": -0.37317673953962915, "compression_ratio": 1.398936170212766, "no_speech_prob": 0.29692086577415466}, {"id": 1, "seek": 0, "start": 7.4, "end": 15.120000000000001, "text": " Okay, so next up we have some product management coverage content by Loria.", "tokens": [50734, 1033, 11, 370, 958, 493, 321, 362, 512, 1674, 4592, 9645, 2701, 538, 441, 8172, 13, 51120], "temperature": 0.0, "avg_logprob": -0.37317673953962915, "compression_ratio": 1.398936170212766, "no_speech_prob": 0.29692086577415466}, {"id": 2, "seek": 0, "start": 15.120000000000001, "end": 16.12, "text": " Hi.", "tokens": [51120, 2421, 13, 51170], "temperature": 0.0, "avg_logprob": -0.37317673953962915, "compression_ratio": 1.398936170212766, "no_speech_prob": 0.29692086577415466}, {"id": 3, "seek": 0, "start": 16.12, "end": 21.76, "text": " Yeah, so I've been a little bit of an AV disaster, so I'm going to have to look at my slides", "tokens": [51170, 865, 11, 370, 286, 600, 668, 257, 707, 857, 295, 364, 30198, 11293, 11, 370, 286, 478, 516, 281, 362, 281, 574, 412, 452, 9788, 51452], "temperature": 0.0, "avg_logprob": -0.37317673953962915, "compression_ratio": 1.398936170212766, "no_speech_prob": 0.29692086577415466}, {"id": 4, "seek": 0, "start": 21.76, "end": 23.240000000000002, "text": " because I can't see them here.", "tokens": [51452, 570, 286, 393, 380, 536, 552, 510, 13, 51526], "temperature": 0.0, "avg_logprob": -0.37317673953962915, "compression_ratio": 1.398936170212766, "no_speech_prob": 0.29692086577415466}, {"id": 5, "seek": 0, "start": 23.240000000000002, "end": 25.72, "text": " But here's the title of my talk today.", "tokens": [51526, 583, 510, 311, 264, 4876, 295, 452, 751, 965, 13, 51650], "temperature": 0.0, "avg_logprob": -0.37317673953962915, "compression_ratio": 1.398936170212766, "no_speech_prob": 0.29692086577415466}, {"id": 6, "seek": 2572, "start": 26.32, "end": 31.479999999999997, "text": " My goal is to help you get more structure around your open source projects, hopefully", "tokens": [50394, 1222, 3387, 307, 281, 854, 291, 483, 544, 3877, 926, 428, 1269, 4009, 4455, 11, 4696, 50652], "temperature": 0.0, "avg_logprob": -0.24039253534055224, "compression_ratio": 1.5674603174603174, "no_speech_prob": 0.026622243225574493}, {"id": 7, "seek": 2572, "start": 31.479999999999997, "end": 34.239999999999995, "text": " save time and ideally do less.", "tokens": [50652, 3155, 565, 293, 22915, 360, 1570, 13, 50790], "temperature": 0.0, "avg_logprob": -0.24039253534055224, "compression_ratio": 1.5674603174603174, "no_speech_prob": 0.026622243225574493}, {"id": 8, "seek": 2572, "start": 34.239999999999995, "end": 41.6, "text": " Okay, so about me, I'm an American living in Germany since 2015 and I mention this because", "tokens": [50790, 1033, 11, 370, 466, 385, 11, 286, 478, 364, 2665, 2647, 294, 7244, 1670, 7546, 293, 286, 2152, 341, 570, 51158], "temperature": 0.0, "avg_logprob": -0.24039253534055224, "compression_ratio": 1.5674603174603174, "no_speech_prob": 0.026622243225574493}, {"id": 9, "seek": 2572, "start": 41.6, "end": 48.04, "text": " I came to Germany with a very live to work mindset and now I have a very work to live", "tokens": [51158, 286, 1361, 281, 7244, 365, 257, 588, 1621, 281, 589, 12543, 293, 586, 286, 362, 257, 588, 589, 281, 1621, 51480], "temperature": 0.0, "avg_logprob": -0.24039253534055224, "compression_ratio": 1.5674603174603174, "no_speech_prob": 0.026622243225574493}, {"id": 10, "seek": 2572, "start": 48.04, "end": 49.04, "text": " mindset.", "tokens": [51480, 12543, 13, 51530], "temperature": 0.0, "avg_logprob": -0.24039253534055224, "compression_ratio": 1.5674603174603174, "no_speech_prob": 0.026622243225574493}, {"id": 11, "seek": 2572, "start": 49.04, "end": 53.44, "text": " And you're going to see that mindset shift in my talks, like the messaging I share with", "tokens": [51530, 400, 291, 434, 516, 281, 536, 300, 12543, 5513, 294, 452, 6686, 11, 411, 264, 21812, 286, 2073, 365, 51750], "temperature": 0.0, "avg_logprob": -0.24039253534055224, "compression_ratio": 1.5674603174603174, "no_speech_prob": 0.026622243225574493}, {"id": 12, "seek": 2572, "start": 53.44, "end": 54.44, "text": " you.", "tokens": [51750, 291, 13, 51800], "temperature": 0.0, "avg_logprob": -0.24039253534055224, "compression_ratio": 1.5674603174603174, "no_speech_prob": 0.026622243225574493}, {"id": 13, "seek": 5444, "start": 54.919999999999995, "end": 60.4, "text": " Among my many open source activities has been contributing to Kubernetes, particularly", "tokens": [50388, 16119, 452, 867, 1269, 4009, 5354, 575, 668, 19270, 281, 23145, 11, 4098, 50662], "temperature": 0.0, "avg_logprob": -0.19193078805734445, "compression_ratio": 1.570446735395189, "no_speech_prob": 0.002044757828116417}, {"id": 14, "seek": 5444, "start": 60.4, "end": 65.24, "text": " SIG release and also more recently the open SSS security scorecard project.", "tokens": [50662, 318, 10489, 4374, 293, 611, 544, 3938, 264, 1269, 12238, 50, 3825, 6175, 22259, 1716, 13, 50904], "temperature": 0.0, "avg_logprob": -0.19193078805734445, "compression_ratio": 1.570446735395189, "no_speech_prob": 0.002044757828116417}, {"id": 15, "seek": 5444, "start": 65.24, "end": 70.0, "text": " I have this link here where I thought I'd highlight it because you can find a lot of", "tokens": [50904, 286, 362, 341, 2113, 510, 689, 286, 1194, 286, 1116, 5078, 309, 570, 291, 393, 915, 257, 688, 295, 51142], "temperature": 0.0, "avg_logprob": -0.19193078805734445, "compression_ratio": 1.570446735395189, "no_speech_prob": 0.002044757828116417}, {"id": 16, "seek": 5444, "start": 70.0, "end": 72.03999999999999, "text": " management and leadership guidance there.", "tokens": [51142, 4592, 293, 5848, 10056, 456, 13, 51244], "temperature": 0.0, "avg_logprob": -0.19193078805734445, "compression_ratio": 1.570446735395189, "no_speech_prob": 0.002044757828116417}, {"id": 17, "seek": 5444, "start": 72.03999999999999, "end": 77.28, "text": " It's a collection of resources, blog posts, videos, templates, things like this, including", "tokens": [51244, 467, 311, 257, 5765, 295, 3593, 11, 6968, 12300, 11, 2145, 11, 21165, 11, 721, 411, 341, 11, 3009, 51506], "temperature": 0.0, "avg_logprob": -0.19193078805734445, "compression_ratio": 1.570446735395189, "no_speech_prob": 0.002044757828116417}, {"id": 18, "seek": 5444, "start": 77.28, "end": 79.16, "text": " some things I'll show you today.", "tokens": [51506, 512, 721, 286, 603, 855, 291, 965, 13, 51600], "temperature": 0.0, "avg_logprob": -0.19193078805734445, "compression_ratio": 1.570446735395189, "no_speech_prob": 0.002044757828116417}, {"id": 19, "seek": 5444, "start": 79.16, "end": 81.03999999999999, "text": " I've worked in places.", "tokens": [51600, 286, 600, 2732, 294, 3190, 13, 51694], "temperature": 0.0, "avg_logprob": -0.19193078805734445, "compression_ratio": 1.570446735395189, "no_speech_prob": 0.002044757828116417}, {"id": 20, "seek": 5444, "start": 81.03999999999999, "end": 82.75999999999999, "text": " I'm not working now.", "tokens": [51694, 286, 478, 406, 1364, 586, 13, 51780], "temperature": 0.0, "avg_logprob": -0.19193078805734445, "compression_ratio": 1.570446735395189, "no_speech_prob": 0.002044757828116417}, {"id": 21, "seek": 8276, "start": 82.76, "end": 85.72, "text": " My company shut down at the turn of the year.", "tokens": [50364, 1222, 2237, 5309, 760, 412, 264, 1261, 295, 264, 1064, 13, 50512], "temperature": 0.0, "avg_logprob": -0.19169156186215514, "compression_ratio": 1.6559139784946237, "no_speech_prob": 0.000786772754509002}, {"id": 22, "seek": 8276, "start": 85.72, "end": 89.28, "text": " So if you like what I have to say and think I could be helpful to your organization, let's", "tokens": [50512, 407, 498, 291, 411, 437, 286, 362, 281, 584, 293, 519, 286, 727, 312, 4961, 281, 428, 4475, 11, 718, 311, 50690], "temperature": 0.0, "avg_logprob": -0.19169156186215514, "compression_ratio": 1.6559139784946237, "no_speech_prob": 0.000786772754509002}, {"id": 23, "seek": 8276, "start": 89.28, "end": 91.84, "text": " talk and there's my LinkedIn in the meantime.", "tokens": [50690, 751, 293, 456, 311, 452, 20657, 294, 264, 14991, 13, 50818], "temperature": 0.0, "avg_logprob": -0.19169156186215514, "compression_ratio": 1.6559139784946237, "no_speech_prob": 0.000786772754509002}, {"id": 24, "seek": 8276, "start": 91.84, "end": 97.08000000000001, "text": " I'll cover basically two branches in this talk.", "tokens": [50818, 286, 603, 2060, 1936, 732, 14770, 294, 341, 751, 13, 51080], "temperature": 0.0, "avg_logprob": -0.19169156186215514, "compression_ratio": 1.6559139784946237, "no_speech_prob": 0.000786772754509002}, {"id": 25, "seek": 8276, "start": 97.08000000000001, "end": 100.96000000000001, "text": " First is some observations from my time in open source.", "tokens": [51080, 2386, 307, 512, 18163, 490, 452, 565, 294, 1269, 4009, 13, 51274], "temperature": 0.0, "avg_logprob": -0.19169156186215514, "compression_ratio": 1.6559139784946237, "no_speech_prob": 0.000786772754509002}, {"id": 26, "seek": 8276, "start": 100.96000000000001, "end": 106.96000000000001, "text": " I'll sprinkle some helpful hints and examples along the way and then I will focus on some", "tokens": [51274, 286, 603, 24745, 512, 4961, 27271, 293, 5110, 2051, 264, 636, 293, 550, 286, 486, 1879, 322, 512, 51574], "temperature": 0.0, "avg_logprob": -0.19169156186215514, "compression_ratio": 1.6559139784946237, "no_speech_prob": 0.000786772754509002}, {"id": 27, "seek": 8276, "start": 106.96000000000001, "end": 112.08000000000001, "text": " tried and true traditional product management methods that work in a company setting.", "tokens": [51574, 3031, 293, 2074, 5164, 1674, 4592, 7150, 300, 589, 294, 257, 2237, 3287, 13, 51830], "temperature": 0.0, "avg_logprob": -0.19169156186215514, "compression_ratio": 1.6559139784946237, "no_speech_prob": 0.000786772754509002}, {"id": 28, "seek": 11208, "start": 112.08, "end": 116.56, "text": " You've probably encountered them in your day jobs, but they also work in open source", "tokens": [50364, 509, 600, 1391, 20381, 552, 294, 428, 786, 4782, 11, 457, 436, 611, 589, 294, 1269, 4009, 50588], "temperature": 0.0, "avg_logprob": -0.19722078284438777, "compression_ratio": 1.5511811023622046, "no_speech_prob": 0.0010476518655195832}, {"id": 29, "seek": 11208, "start": 116.56, "end": 120.75999999999999, "text": " with a little bit of creativity.", "tokens": [50588, 365, 257, 707, 857, 295, 12915, 13, 50798], "temperature": 0.0, "avg_logprob": -0.19722078284438777, "compression_ratio": 1.5511811023622046, "no_speech_prob": 0.0010476518655195832}, {"id": 30, "seek": 11208, "start": 120.75999999999999, "end": 127.2, "text": " So some of those observations, I see contributors taking on so much work.", "tokens": [50798, 407, 512, 295, 729, 18163, 11, 286, 536, 45627, 1940, 322, 370, 709, 589, 13, 51120], "temperature": 0.0, "avg_logprob": -0.19722078284438777, "compression_ratio": 1.5511811023622046, "no_speech_prob": 0.0010476518655195832}, {"id": 31, "seek": 11208, "start": 127.2, "end": 133.4, "text": " Just lots of issues, many times even multiple leadership roles and it just seems like a sure", "tokens": [51120, 1449, 3195, 295, 2663, 11, 867, 1413, 754, 3866, 5848, 9604, 293, 309, 445, 2544, 411, 257, 988, 51430], "temperature": 0.0, "avg_logprob": -0.19722078284438777, "compression_ratio": 1.5511811023622046, "no_speech_prob": 0.0010476518655195832}, {"id": 32, "seek": 11208, "start": 133.4, "end": 136.04, "text": " far way to burn them.", "tokens": [51430, 1400, 636, 281, 5064, 552, 13, 51562], "temperature": 0.0, "avg_logprob": -0.19722078284438777, "compression_ratio": 1.5511811023622046, "no_speech_prob": 0.0010476518655195832}, {"id": 33, "seek": 11208, "start": 136.04, "end": 140.16, "text": " Because they're so overstretched, they don't have a lot of time to do a lot of research", "tokens": [51562, 1436, 436, 434, 370, 48834, 45928, 11, 436, 500, 380, 362, 257, 688, 295, 565, 281, 360, 257, 688, 295, 2132, 51768], "temperature": 0.0, "avg_logprob": -0.19722078284438777, "compression_ratio": 1.5511811023622046, "no_speech_prob": 0.0010476518655195832}, {"id": 34, "seek": 14016, "start": 140.16, "end": 141.16, "text": " and gather data.", "tokens": [50364, 293, 5448, 1412, 13, 50414], "temperature": 0.0, "avg_logprob": -0.19834661955880648, "compression_ratio": 1.65234375, "no_speech_prob": 0.010614069178700447}, {"id": 35, "seek": 14016, "start": 141.16, "end": 147.04, "text": " Also, that's a skill set that not everybody has and not everybody needs to have.", "tokens": [50414, 2743, 11, 300, 311, 257, 5389, 992, 300, 406, 2201, 575, 293, 406, 2201, 2203, 281, 362, 13, 50708], "temperature": 0.0, "avg_logprob": -0.19834661955880648, "compression_ratio": 1.65234375, "no_speech_prob": 0.010614069178700447}, {"id": 36, "seek": 14016, "start": 147.04, "end": 151.16, "text": " But the end result is often that a lot of development is based on assumptions instead", "tokens": [50708, 583, 264, 917, 1874, 307, 2049, 300, 257, 688, 295, 3250, 307, 2361, 322, 17695, 2602, 50914], "temperature": 0.0, "avg_logprob": -0.19834661955880648, "compression_ratio": 1.65234375, "no_speech_prob": 0.010614069178700447}, {"id": 37, "seek": 14016, "start": 151.16, "end": 153.16, "text": " of data.", "tokens": [50914, 295, 1412, 13, 51014], "temperature": 0.0, "avg_logprob": -0.19834661955880648, "compression_ratio": 1.65234375, "no_speech_prob": 0.010614069178700447}, {"id": 38, "seek": 14016, "start": 153.16, "end": 156.96, "text": " Another thing I've noticed is that what exists today in a project isn't well-defined or", "tokens": [51014, 3996, 551, 286, 600, 5694, 307, 300, 437, 8198, 965, 294, 257, 1716, 1943, 380, 731, 12, 37716, 420, 51204], "temperature": 0.0, "avg_logprob": -0.19834661955880648, "compression_ratio": 1.65234375, "no_speech_prob": 0.010614069178700447}, {"id": 39, "seek": 14016, "start": 156.96, "end": 161.35999999999999, "text": " documented or mutually understood by the project team.", "tokens": [51204, 23007, 420, 39144, 7320, 538, 264, 1716, 1469, 13, 51424], "temperature": 0.0, "avg_logprob": -0.19834661955880648, "compression_ratio": 1.65234375, "no_speech_prob": 0.010614069178700447}, {"id": 40, "seek": 14016, "start": 161.35999999999999, "end": 166.84, "text": " This represents a pitfall because you maybe don't have the shared understanding of what", "tokens": [51424, 639, 8855, 257, 10147, 6691, 570, 291, 1310, 500, 380, 362, 264, 5507, 3701, 295, 437, 51698], "temperature": 0.0, "avg_logprob": -0.19834661955880648, "compression_ratio": 1.65234375, "no_speech_prob": 0.010614069178700447}, {"id": 41, "seek": 16684, "start": 166.84, "end": 170.28, "text": " your project is and does and should be.", "tokens": [50364, 428, 1716, 307, 293, 775, 293, 820, 312, 13, 50536], "temperature": 0.0, "avg_logprob": -0.18484729459916038, "compression_ratio": 1.6203703703703705, "no_speech_prob": 0.04310673102736473}, {"id": 42, "seek": 16684, "start": 170.28, "end": 174.88, "text": " And lastly, there's often times of vague strategy or even none at all.", "tokens": [50536, 400, 16386, 11, 456, 311, 2049, 1413, 295, 24247, 5206, 420, 754, 6022, 412, 439, 13, 50766], "temperature": 0.0, "avg_logprob": -0.18484729459916038, "compression_ratio": 1.6203703703703705, "no_speech_prob": 0.04310673102736473}, {"id": 43, "seek": 16684, "start": 174.88, "end": 179.88, "text": " I would say that the most acute manifestation of this issue is that there's often a boundary", "tokens": [50766, 286, 576, 584, 300, 264, 881, 24390, 29550, 295, 341, 2734, 307, 300, 456, 311, 2049, 257, 12866, 51016], "temperature": 0.0, "avg_logprob": -0.18484729459916038, "compression_ratio": 1.6203703703703705, "no_speech_prob": 0.04310673102736473}, {"id": 44, "seek": 16684, "start": 179.88, "end": 184.68, "text": " between what goes in a project and what stays out that is lacking.", "tokens": [51016, 1296, 437, 1709, 294, 257, 1716, 293, 437, 10834, 484, 300, 307, 20889, 13, 51256], "temperature": 0.0, "avg_logprob": -0.18484729459916038, "compression_ratio": 1.6203703703703705, "no_speech_prob": 0.04310673102736473}, {"id": 45, "seek": 16684, "start": 184.68, "end": 191.92000000000002, "text": " This can lead to a lot of work being done and that work just kind of expanding.", "tokens": [51256, 639, 393, 1477, 281, 257, 688, 295, 589, 885, 1096, 293, 300, 589, 445, 733, 295, 14702, 13, 51618], "temperature": 0.0, "avg_logprob": -0.18484729459916038, "compression_ratio": 1.6203703703703705, "no_speech_prob": 0.04310673102736473}, {"id": 46, "seek": 19192, "start": 191.92, "end": 197.07999999999998, "text": " So if you take away anything from me today, it would be this message which is I really", "tokens": [50364, 407, 498, 291, 747, 1314, 1340, 490, 385, 965, 11, 309, 576, 312, 341, 3636, 597, 307, 286, 534, 50622], "temperature": 0.0, "avg_logprob": -0.2045704727872796, "compression_ratio": 1.779527559055118, "no_speech_prob": 0.302717000246048}, {"id": 47, "seek": 19192, "start": 197.07999999999998, "end": 200.32, "text": " encourage and invite you to do less if you can.", "tokens": [50622, 5373, 293, 7980, 291, 281, 360, 1570, 498, 291, 393, 13, 50784], "temperature": 0.0, "avg_logprob": -0.2045704727872796, "compression_ratio": 1.779527559055118, "no_speech_prob": 0.302717000246048}, {"id": 48, "seek": 19192, "start": 200.32, "end": 203.95999999999998, "text": " I know your manager may not want you to do less.", "tokens": [50784, 286, 458, 428, 6598, 815, 406, 528, 291, 281, 360, 1570, 13, 50966], "temperature": 0.0, "avg_logprob": -0.2045704727872796, "compression_ratio": 1.779527559055118, "no_speech_prob": 0.302717000246048}, {"id": 49, "seek": 19192, "start": 203.95999999999998, "end": 210.11999999999998, "text": " There's always very specific conditions around that relationship, speaking from experience.", "tokens": [50966, 821, 311, 1009, 588, 2685, 4487, 926, 300, 2480, 11, 4124, 490, 1752, 13, 51274], "temperature": 0.0, "avg_logprob": -0.2045704727872796, "compression_ratio": 1.779527559055118, "no_speech_prob": 0.302717000246048}, {"id": 50, "seek": 19192, "start": 210.11999999999998, "end": 213.88, "text": " So I'm happy to talk to any of you after the talk if you would like to have a sound and", "tokens": [51274, 407, 286, 478, 2055, 281, 751, 281, 604, 295, 291, 934, 264, 751, 498, 291, 576, 411, 281, 362, 257, 1626, 293, 51462], "temperature": 0.0, "avg_logprob": -0.2045704727872796, "compression_ratio": 1.779527559055118, "no_speech_prob": 0.302717000246048}, {"id": 51, "seek": 19192, "start": 213.88, "end": 218.07999999999998, "text": " pour like ways you can manage your manager's expectations around what you can do in open", "tokens": [51462, 2016, 411, 2098, 291, 393, 3067, 428, 6598, 311, 9843, 926, 437, 291, 393, 360, 294, 1269, 51672], "temperature": 0.0, "avg_logprob": -0.2045704727872796, "compression_ratio": 1.779527559055118, "no_speech_prob": 0.302717000246048}, {"id": 52, "seek": 21808, "start": 218.08, "end": 222.84, "text": " source with your limited time and availability.", "tokens": [50364, 4009, 365, 428, 5567, 565, 293, 17945, 13, 50602], "temperature": 0.0, "avg_logprob": -0.17413737986347463, "compression_ratio": 1.6356275303643724, "no_speech_prob": 0.09918422996997833}, {"id": 53, "seek": 21808, "start": 222.84, "end": 227.96, "text": " But if you are the pressure source telling yourself to do all of the things, then I invite", "tokens": [50602, 583, 498, 291, 366, 264, 3321, 4009, 3585, 1803, 281, 360, 439, 295, 264, 721, 11, 550, 286, 7980, 50858], "temperature": 0.0, "avg_logprob": -0.17413737986347463, "compression_ratio": 1.6356275303643724, "no_speech_prob": 0.09918422996997833}, {"id": 54, "seek": 21808, "start": 227.96, "end": 232.64000000000001, "text": " you to ask yourself at first like, does anybody even want this?", "tokens": [50858, 291, 281, 1029, 1803, 412, 700, 411, 11, 775, 4472, 754, 528, 341, 30, 51092], "temperature": 0.0, "avg_logprob": -0.17413737986347463, "compression_ratio": 1.6356275303643724, "no_speech_prob": 0.09918422996997833}, {"id": 55, "seek": 21808, "start": 232.64000000000001, "end": 236.92000000000002, "text": " I mean, maybe they do, but maybe if you're the only person or you don't have a very", "tokens": [51092, 286, 914, 11, 1310, 436, 360, 11, 457, 1310, 498, 291, 434, 264, 787, 954, 420, 291, 500, 380, 362, 257, 588, 51306], "temperature": 0.0, "avg_logprob": -0.17413737986347463, "compression_ratio": 1.6356275303643724, "no_speech_prob": 0.09918422996997833}, {"id": 56, "seek": 21808, "start": 236.92000000000002, "end": 242.76000000000002, "text": " clear sense of how many people might find value in your project, maybe stop and collect", "tokens": [51306, 1850, 2020, 295, 577, 867, 561, 1062, 915, 2158, 294, 428, 1716, 11, 1310, 1590, 293, 2500, 51598], "temperature": 0.0, "avg_logprob": -0.17413737986347463, "compression_ratio": 1.6356275303643724, "no_speech_prob": 0.09918422996997833}, {"id": 57, "seek": 21808, "start": 242.76000000000002, "end": 245.96, "text": " more data before you move on.", "tokens": [51598, 544, 1412, 949, 291, 1286, 322, 13, 51758], "temperature": 0.0, "avg_logprob": -0.17413737986347463, "compression_ratio": 1.6356275303643724, "no_speech_prob": 0.09918422996997833}, {"id": 58, "seek": 24596, "start": 245.96, "end": 248.24, "text": " Also keep your personal backlog light.", "tokens": [50364, 2743, 1066, 428, 2973, 47364, 1442, 13, 50478], "temperature": 0.0, "avg_logprob": -0.1793365478515625, "compression_ratio": 1.671280276816609, "no_speech_prob": 0.14355534315109253}, {"id": 59, "seek": 24596, "start": 248.24, "end": 252.96, "text": " I know some people really enjoy working with them, but they take on so much work that they", "tokens": [50478, 286, 458, 512, 561, 534, 2103, 1364, 365, 552, 11, 457, 436, 747, 322, 370, 709, 589, 300, 436, 50714], "temperature": 0.0, "avg_logprob": -0.1793365478515625, "compression_ratio": 1.671280276816609, "no_speech_prob": 0.14355534315109253}, {"id": 60, "seek": 24596, "start": 252.96, "end": 256.40000000000003, "text": " end up becoming the blocker for other people to make progress.", "tokens": [50714, 917, 493, 5617, 264, 3461, 260, 337, 661, 561, 281, 652, 4205, 13, 50886], "temperature": 0.0, "avg_logprob": -0.1793365478515625, "compression_ratio": 1.671280276816609, "no_speech_prob": 0.14355534315109253}, {"id": 61, "seek": 24596, "start": 256.40000000000003, "end": 258.64, "text": " And you don't really want to do that, right?", "tokens": [50886, 400, 291, 500, 380, 534, 528, 281, 360, 300, 11, 558, 30, 50998], "temperature": 0.0, "avg_logprob": -0.1793365478515625, "compression_ratio": 1.671280276816609, "no_speech_prob": 0.14355534315109253}, {"id": 62, "seek": 24596, "start": 258.64, "end": 264.72, "text": " You don't want to impede your fellow project contributors' efforts because you're like", "tokens": [50998, 509, 500, 380, 528, 281, 704, 4858, 428, 7177, 1716, 45627, 6, 6484, 570, 291, 434, 411, 51302], "temperature": 0.0, "avg_logprob": -0.1793365478515625, "compression_ratio": 1.671280276816609, "no_speech_prob": 0.14355534315109253}, {"id": 63, "seek": 24596, "start": 264.72, "end": 267.56, "text": " the decision maker on 10 different things.", "tokens": [51302, 264, 3537, 17127, 322, 1266, 819, 721, 13, 51444], "temperature": 0.0, "avg_logprob": -0.1793365478515625, "compression_ratio": 1.671280276816609, "no_speech_prob": 0.14355534315109253}, {"id": 64, "seek": 24596, "start": 267.56, "end": 270.72, "text": " So that leads to delegating.", "tokens": [51444, 407, 300, 6689, 281, 15824, 990, 13, 51602], "temperature": 0.0, "avg_logprob": -0.1793365478515625, "compression_ratio": 1.671280276816609, "no_speech_prob": 0.14355534315109253}, {"id": 65, "seek": 24596, "start": 270.72, "end": 275.72, "text": " Delegating not just to reduce your workload, but also to empower others to gain skills", "tokens": [51602, 1346, 6363, 990, 406, 445, 281, 5407, 428, 20139, 11, 457, 611, 281, 11071, 2357, 281, 6052, 3942, 51852], "temperature": 0.0, "avg_logprob": -0.1793365478515625, "compression_ratio": 1.671280276816609, "no_speech_prob": 0.14355534315109253}, {"id": 66, "seek": 27572, "start": 275.72, "end": 276.96000000000004, "text": " that you have.", "tokens": [50364, 300, 291, 362, 13, 50426], "temperature": 0.0, "avg_logprob": -0.1542812613553779, "compression_ratio": 1.7344827586206897, "no_speech_prob": 0.014644766226410866}, {"id": 67, "seek": 27572, "start": 276.96000000000004, "end": 280.96000000000004, "text": " And I know that's rather time consuming, but oftentimes what I've seen in open source", "tokens": [50426, 400, 286, 458, 300, 311, 2831, 565, 19867, 11, 457, 18349, 437, 286, 600, 1612, 294, 1269, 4009, 50626], "temperature": 0.0, "avg_logprob": -0.1542812613553779, "compression_ratio": 1.7344827586206897, "no_speech_prob": 0.014644766226410866}, {"id": 68, "seek": 27572, "start": 280.96000000000004, "end": 286.32000000000005, "text": " is that a little bit of upfront onboarding and knowledge exchange saves everybody time", "tokens": [50626, 307, 300, 257, 707, 857, 295, 30264, 24033, 278, 293, 3601, 7742, 19155, 2201, 565, 50894], "temperature": 0.0, "avg_logprob": -0.1542812613553779, "compression_ratio": 1.7344827586206897, "no_speech_prob": 0.014644766226410866}, {"id": 69, "seek": 27572, "start": 286.32000000000005, "end": 293.04, "text": " in the later stages because you have multiple people who can work on something at once.", "tokens": [50894, 294, 264, 1780, 10232, 570, 291, 362, 3866, 561, 567, 393, 589, 322, 746, 412, 1564, 13, 51230], "temperature": 0.0, "avg_logprob": -0.1542812613553779, "compression_ratio": 1.7344827586206897, "no_speech_prob": 0.014644766226410866}, {"id": 70, "seek": 27572, "start": 293.04, "end": 297.08000000000004, "text": " And the last tip is something I've used over the years because I would just take on work", "tokens": [51230, 400, 264, 1036, 4125, 307, 746, 286, 600, 1143, 670, 264, 924, 570, 286, 576, 445, 747, 322, 589, 51432], "temperature": 0.0, "avg_logprob": -0.1542812613553779, "compression_ratio": 1.7344827586206897, "no_speech_prob": 0.014644766226410866}, {"id": 71, "seek": 27572, "start": 297.08000000000004, "end": 298.08000000000004, "text": " too.", "tokens": [51432, 886, 13, 51482], "temperature": 0.0, "avg_logprob": -0.1542812613553779, "compression_ratio": 1.7344827586206897, "no_speech_prob": 0.014644766226410866}, {"id": 72, "seek": 27572, "start": 298.08000000000004, "end": 300.20000000000005, "text": " I love it, like, let's be busy.", "tokens": [51482, 286, 959, 309, 11, 411, 11, 718, 311, 312, 5856, 13, 51588], "temperature": 0.0, "avg_logprob": -0.1542812613553779, "compression_ratio": 1.7344827586206897, "no_speech_prob": 0.014644766226410866}, {"id": 73, "seek": 27572, "start": 300.20000000000005, "end": 304.04, "text": " And then I would find that the work that I took on actually involved a lot more than", "tokens": [51588, 400, 550, 286, 576, 915, 300, 264, 589, 300, 286, 1890, 322, 767, 3288, 257, 688, 544, 813, 51780], "temperature": 0.0, "avg_logprob": -0.1542812613553779, "compression_ratio": 1.7344827586206897, "no_speech_prob": 0.014644766226410866}, {"id": 74, "seek": 27572, "start": 304.04, "end": 305.36, "text": " I bargained for.", "tokens": [51780, 286, 22351, 3563, 337, 13, 51846], "temperature": 0.0, "avg_logprob": -0.1542812613553779, "compression_ratio": 1.7344827586206897, "no_speech_prob": 0.014644766226410866}, {"id": 75, "seek": 30536, "start": 305.36, "end": 311.32, "text": " So I highly encourage you to unpack a task before you say yes to doing that task because", "tokens": [50364, 407, 286, 5405, 5373, 291, 281, 26699, 257, 5633, 949, 291, 584, 2086, 281, 884, 300, 5633, 570, 50662], "temperature": 0.0, "avg_logprob": -0.1865892770155421, "compression_ratio": 1.6068702290076335, "no_speech_prob": 0.0005954867228865623}, {"id": 76, "seek": 30536, "start": 311.32, "end": 316.6, "text": " you may find that it's going to take you a significant amount of time.", "tokens": [50662, 291, 815, 915, 300, 309, 311, 516, 281, 747, 291, 257, 4776, 2372, 295, 565, 13, 50926], "temperature": 0.0, "avg_logprob": -0.1865892770155421, "compression_ratio": 1.6068702290076335, "no_speech_prob": 0.0005954867228865623}, {"id": 77, "seek": 30536, "start": 316.6, "end": 318.16, "text": " Here's an example of that.", "tokens": [50926, 1692, 311, 364, 1365, 295, 300, 13, 51004], "temperature": 0.0, "avg_logprob": -0.1865892770155421, "compression_ratio": 1.6068702290076335, "no_speech_prob": 0.0005954867228865623}, {"id": 78, "seek": 30536, "start": 318.16, "end": 325.6, "text": " So this is a project board that I created with collaborators from SIG Release and Kubernetes.", "tokens": [51004, 407, 341, 307, 257, 1716, 3150, 300, 286, 2942, 365, 39789, 490, 318, 10489, 34278, 293, 23145, 13, 51376], "temperature": 0.0, "avg_logprob": -0.1865892770155421, "compression_ratio": 1.6068702290076335, "no_speech_prob": 0.0005954867228865623}, {"id": 79, "seek": 30536, "start": 325.6, "end": 329.48, "text": " The initial idea was to rewrite a tool from scratch.", "tokens": [51376, 440, 5883, 1558, 390, 281, 28132, 257, 2290, 490, 8459, 13, 51570], "temperature": 0.0, "avg_logprob": -0.1865892770155421, "compression_ratio": 1.6068702290076335, "no_speech_prob": 0.0005954867228865623}, {"id": 80, "seek": 30536, "start": 329.48, "end": 334.12, "text": " And I looked at that and thought I heard that and I was like, you know, we may not want", "tokens": [51570, 400, 286, 2956, 412, 300, 293, 1194, 286, 2198, 300, 293, 286, 390, 411, 11, 291, 458, 11, 321, 815, 406, 528, 51802], "temperature": 0.0, "avg_logprob": -0.1865892770155421, "compression_ratio": 1.6068702290076335, "no_speech_prob": 0.0005954867228865623}, {"id": 81, "seek": 33412, "start": 334.12, "end": 337.24, "text": " to do that because that sounds really, really intensive.", "tokens": [50364, 281, 360, 300, 570, 300, 3263, 534, 11, 534, 18957, 13, 50520], "temperature": 0.0, "avg_logprob": -0.17133720522004414, "compression_ratio": 1.7173913043478262, "no_speech_prob": 0.0662032812833786}, {"id": 82, "seek": 33412, "start": 337.24, "end": 344.28000000000003, "text": " So what we did is over a couple of sessions we figured out some real things that we didn't", "tokens": [50520, 407, 437, 321, 630, 307, 670, 257, 1916, 295, 11081, 321, 8932, 484, 512, 957, 721, 300, 321, 994, 380, 50872], "temperature": 0.0, "avg_logprob": -0.17133720522004414, "compression_ratio": 1.7173913043478262, "no_speech_prob": 0.0662032812833786}, {"id": 83, "seek": 33412, "start": 344.28000000000003, "end": 350.16, "text": " know about this particular tool that we wanted to, you know, talking about rewriting.", "tokens": [50872, 458, 466, 341, 1729, 2290, 300, 321, 1415, 281, 11, 291, 458, 11, 1417, 466, 319, 19868, 13, 51166], "temperature": 0.0, "avg_logprob": -0.17133720522004414, "compression_ratio": 1.7173913043478262, "no_speech_prob": 0.0662032812833786}, {"id": 84, "seek": 33412, "start": 350.16, "end": 354.72, "text": " And what we had was a lot of questions, like what is it, what does it do, what do users", "tokens": [51166, 400, 437, 321, 632, 390, 257, 688, 295, 1651, 11, 411, 437, 307, 309, 11, 437, 775, 309, 360, 11, 437, 360, 5022, 51394], "temperature": 0.0, "avg_logprob": -0.17133720522004414, "compression_ratio": 1.7173913043478262, "no_speech_prob": 0.0662032812833786}, {"id": 85, "seek": 33412, "start": 354.72, "end": 355.72, "text": " want.", "tokens": [51394, 528, 13, 51444], "temperature": 0.0, "avg_logprob": -0.17133720522004414, "compression_ratio": 1.7173913043478262, "no_speech_prob": 0.0662032812833786}, {"id": 86, "seek": 33412, "start": 355.72, "end": 358.72, "text": " So you may not see all this text, but just the TLDR for you.", "tokens": [51444, 407, 291, 815, 406, 536, 439, 341, 2487, 11, 457, 445, 264, 40277, 9301, 337, 291, 13, 51594], "temperature": 0.0, "avg_logprob": -0.17133720522004414, "compression_ratio": 1.7173913043478262, "no_speech_prob": 0.0662032812833786}, {"id": 87, "seek": 33412, "start": 358.72, "end": 363.72, "text": " There's a lot of spikes in decision making and documentation, like proposals to write", "tokens": [51594, 821, 311, 257, 688, 295, 28997, 294, 3537, 1455, 293, 14333, 11, 411, 20198, 281, 2464, 51844], "temperature": 0.0, "avg_logprob": -0.17133720522004414, "compression_ratio": 1.7173913043478262, "no_speech_prob": 0.0662032812833786}, {"id": 88, "seek": 36372, "start": 363.8, "end": 370.72, "text": " to get community feedback before even setting to write code.", "tokens": [50368, 281, 483, 1768, 5824, 949, 754, 3287, 281, 2464, 3089, 13, 50714], "temperature": 0.0, "avg_logprob": -0.14386266361583364, "compression_ratio": 1.6892430278884463, "no_speech_prob": 0.0014461945975199342}, {"id": 89, "seek": 36372, "start": 370.72, "end": 375.16, "text": " So this is what I mentioned earlier, like the assumptions that we often take into our", "tokens": [50714, 407, 341, 307, 437, 286, 2835, 3071, 11, 411, 264, 17695, 300, 321, 2049, 747, 666, 527, 50936], "temperature": 0.0, "avg_logprob": -0.14386266361583364, "compression_ratio": 1.6892430278884463, "no_speech_prob": 0.0014461945975199342}, {"id": 90, "seek": 36372, "start": 375.16, "end": 376.68, "text": " development plans.", "tokens": [50936, 3250, 5482, 13, 51012], "temperature": 0.0, "avg_logprob": -0.14386266361583364, "compression_ratio": 1.6892430278884463, "no_speech_prob": 0.0014461945975199342}, {"id": 91, "seek": 36372, "start": 376.68, "end": 379.8, "text": " We had a lot of assumptions that we just had to rewrite this tool because it's just too", "tokens": [51012, 492, 632, 257, 688, 295, 17695, 300, 321, 445, 632, 281, 28132, 341, 2290, 570, 309, 311, 445, 886, 51168], "temperature": 0.0, "avg_logprob": -0.14386266361583364, "compression_ratio": 1.6892430278884463, "no_speech_prob": 0.0014461945975199342}, {"id": 92, "seek": 36372, "start": 379.8, "end": 383.32000000000005, "text": " broken and, you know, we just do it over.", "tokens": [51168, 5463, 293, 11, 291, 458, 11, 321, 445, 360, 309, 670, 13, 51344], "temperature": 0.0, "avg_logprob": -0.14386266361583364, "compression_ratio": 1.6892430278884463, "no_speech_prob": 0.0014461945975199342}, {"id": 93, "seek": 36372, "start": 383.32000000000005, "end": 386.16, "text": " That's often not the case.", "tokens": [51344, 663, 311, 2049, 406, 264, 1389, 13, 51486], "temperature": 0.0, "avg_logprob": -0.14386266361583364, "compression_ratio": 1.6892430278884463, "no_speech_prob": 0.0014461945975199342}, {"id": 94, "seek": 36372, "start": 386.16, "end": 389.8, "text": " And so I just want to point out that I didn't come up with the idea of assumption-driven", "tokens": [51486, 400, 370, 286, 445, 528, 281, 935, 484, 300, 286, 994, 380, 808, 493, 365, 264, 1558, 295, 15302, 12, 25456, 51668], "temperature": 0.0, "avg_logprob": -0.14386266361583364, "compression_ratio": 1.6892430278884463, "no_speech_prob": 0.0014461945975199342}, {"id": 95, "seek": 36372, "start": 389.8, "end": 390.8, "text": " development.", "tokens": [51668, 3250, 13, 51718], "temperature": 0.0, "avg_logprob": -0.14386266361583364, "compression_ratio": 1.6892430278884463, "no_speech_prob": 0.0014461945975199342}, {"id": 96, "seek": 39080, "start": 390.88, "end": 394.92, "text": " I found a term that someone else created, and in my search to find out exactly who, I came", "tokens": [50368, 286, 1352, 257, 1433, 300, 1580, 1646, 2942, 11, 293, 294, 452, 3164, 281, 915, 484, 2293, 567, 11, 286, 1361, 50570], "temperature": 0.0, "avg_logprob": -0.1875624656677246, "compression_ratio": 1.6690140845070423, "no_speech_prob": 0.0633302628993988}, {"id": 97, "seek": 39080, "start": 394.92, "end": 398.24, "text": " upon this blog post, which I found really interesting.", "tokens": [50570, 3564, 341, 6968, 2183, 11, 597, 286, 1352, 534, 1880, 13, 50736], "temperature": 0.0, "avg_logprob": -0.1875624656677246, "compression_ratio": 1.6690140845070423, "no_speech_prob": 0.0633302628993988}, {"id": 98, "seek": 39080, "start": 398.24, "end": 404.28000000000003, "text": " It's a developer who basically described his own failure trajectory because he was operating", "tokens": [50736, 467, 311, 257, 10754, 567, 1936, 7619, 702, 1065, 7763, 21512, 570, 415, 390, 7447, 51038], "temperature": 0.0, "avg_logprob": -0.1875624656677246, "compression_ratio": 1.6690140845070423, "no_speech_prob": 0.0633302628993988}, {"id": 99, "seek": 39080, "start": 404.28000000000003, "end": 406.36, "text": " with assumption-driven development.", "tokens": [51038, 365, 15302, 12, 25456, 3250, 13, 51142], "temperature": 0.0, "avg_logprob": -0.1875624656677246, "compression_ratio": 1.6690140845070423, "no_speech_prob": 0.0633302628993988}, {"id": 100, "seek": 39080, "start": 406.36, "end": 410.12, "text": " And what he did was he decided to just take on a lot of work on his own.", "tokens": [51142, 400, 437, 415, 630, 390, 415, 3047, 281, 445, 747, 322, 257, 688, 295, 589, 322, 702, 1065, 13, 51330], "temperature": 0.0, "avg_logprob": -0.1875624656677246, "compression_ratio": 1.6690140845070423, "no_speech_prob": 0.0633302628993988}, {"id": 101, "seek": 39080, "start": 410.12, "end": 412.32, "text": " He didn't talk to anybody around him.", "tokens": [51330, 634, 994, 380, 751, 281, 4472, 926, 796, 13, 51440], "temperature": 0.0, "avg_logprob": -0.1875624656677246, "compression_ratio": 1.6690140845070423, "no_speech_prob": 0.0633302628993988}, {"id": 102, "seek": 39080, "start": 412.32, "end": 416.96000000000004, "text": " He also didn't understand what he was working with in that day, like the tooling and all", "tokens": [51440, 634, 611, 994, 380, 1223, 437, 415, 390, 1364, 365, 294, 300, 786, 11, 411, 264, 46593, 293, 439, 51672], "temperature": 0.0, "avg_logprob": -0.1875624656677246, "compression_ratio": 1.6690140845070423, "no_speech_prob": 0.0633302628993988}, {"id": 103, "seek": 41696, "start": 416.96, "end": 424.68, "text": " of the different tooling relationships, and also the knock-on effects of making changes.", "tokens": [50364, 295, 264, 819, 46593, 6159, 11, 293, 611, 264, 6728, 12, 266, 5065, 295, 1455, 2962, 13, 50750], "temperature": 0.0, "avg_logprob": -0.18962744304112025, "compression_ratio": 1.651685393258427, "no_speech_prob": 0.005603785626590252}, {"id": 104, "seek": 41696, "start": 424.68, "end": 428.79999999999995, "text": " And he kind of went in like, I'm going to do this, say, and like it's going to be done.", "tokens": [50750, 400, 415, 733, 295, 1437, 294, 411, 11, 286, 478, 516, 281, 360, 341, 11, 584, 11, 293, 411, 309, 311, 516, 281, 312, 1096, 13, 50956], "temperature": 0.0, "avg_logprob": -0.18962744304112025, "compression_ratio": 1.651685393258427, "no_speech_prob": 0.005603785626590252}, {"id": 105, "seek": 41696, "start": 428.79999999999995, "end": 430.4, "text": " And that also didn't turn out to be true.", "tokens": [50956, 400, 300, 611, 994, 380, 1261, 484, 281, 312, 2074, 13, 51036], "temperature": 0.0, "avg_logprob": -0.18962744304112025, "compression_ratio": 1.651685393258427, "no_speech_prob": 0.005603785626590252}, {"id": 106, "seek": 41696, "start": 430.4, "end": 435.32, "text": " There was a lot more work involved that he had expected and planned for.", "tokens": [51036, 821, 390, 257, 688, 544, 589, 3288, 300, 415, 632, 5176, 293, 8589, 337, 13, 51282], "temperature": 0.0, "avg_logprob": -0.18962744304112025, "compression_ratio": 1.651685393258427, "no_speech_prob": 0.005603785626590252}, {"id": 107, "seek": 41696, "start": 435.32, "end": 439.84, "text": " So I thought it was a really great summary from the developer's perspective of why assumption-driven", "tokens": [51282, 407, 286, 1194, 309, 390, 257, 534, 869, 12691, 490, 264, 10754, 311, 4585, 295, 983, 15302, 12, 25456, 51508], "temperature": 0.0, "avg_logprob": -0.18962744304112025, "compression_ratio": 1.651685393258427, "no_speech_prob": 0.005603785626590252}, {"id": 108, "seek": 41696, "start": 439.84, "end": 445.84, "text": " development is often not the best method to use.", "tokens": [51508, 3250, 307, 2049, 406, 264, 1151, 3170, 281, 764, 13, 51808], "temperature": 0.0, "avg_logprob": -0.18962744304112025, "compression_ratio": 1.651685393258427, "no_speech_prob": 0.005603785626590252}, {"id": 109, "seek": 44584, "start": 445.84, "end": 449.15999999999997, "text": " I'm going to give them a talk, and you can ask questions after.", "tokens": [50364, 286, 478, 516, 281, 976, 552, 257, 751, 11, 293, 291, 393, 1029, 1651, 934, 13, 50530], "temperature": 0.0, "avg_logprob": -0.19977261038387523, "compression_ratio": 1.62015503875969, "no_speech_prob": 0.005985728930681944}, {"id": 110, "seek": 44584, "start": 449.15999999999997, "end": 450.15999999999997, "text": " Thanks.", "tokens": [50530, 2561, 13, 50580], "temperature": 0.0, "avg_logprob": -0.19977261038387523, "compression_ratio": 1.62015503875969, "no_speech_prob": 0.005985728930681944}, {"id": 111, "seek": 44584, "start": 450.15999999999997, "end": 456.15999999999997, "text": " So basically, what I'm suggesting here, like a way to conquer assumptions, is oftentimes", "tokens": [50580, 407, 1936, 11, 437, 286, 478, 18094, 510, 11, 411, 257, 636, 281, 24136, 17695, 11, 307, 18349, 50880], "temperature": 0.0, "avg_logprob": -0.19977261038387523, "compression_ratio": 1.62015503875969, "no_speech_prob": 0.005985728930681944}, {"id": 112, "seek": 44584, "start": 456.15999999999997, "end": 458.32, "text": " just listening to your environment.", "tokens": [50880, 445, 4764, 281, 428, 2823, 13, 50988], "temperature": 0.0, "avg_logprob": -0.19977261038387523, "compression_ratio": 1.62015503875969, "no_speech_prob": 0.005985728930681944}, {"id": 113, "seek": 44584, "start": 458.32, "end": 460.79999999999995, "text": " And that starts with the people around you.", "tokens": [50988, 400, 300, 3719, 365, 264, 561, 926, 291, 13, 51112], "temperature": 0.0, "avg_logprob": -0.19977261038387523, "compression_ratio": 1.62015503875969, "no_speech_prob": 0.005985728930681944}, {"id": 114, "seek": 44584, "start": 460.79999999999995, "end": 465.88, "text": " So there's this thing called active listening, and I found a nice resource from the Center", "tokens": [51112, 407, 456, 311, 341, 551, 1219, 4967, 4764, 11, 293, 286, 1352, 257, 1481, 7684, 490, 264, 5169, 51366], "temperature": 0.0, "avg_logprob": -0.19977261038387523, "compression_ratio": 1.62015503875969, "no_speech_prob": 0.005985728930681944}, {"id": 115, "seek": 44584, "start": 465.88, "end": 471.28, "text": " for Creative Leadership, and they give you some behaviors that you can adopt, or adopt", "tokens": [51366, 337, 26598, 30577, 11, 293, 436, 976, 291, 512, 15501, 300, 291, 393, 6878, 11, 420, 6878, 51636], "temperature": 0.0, "avg_logprob": -0.19977261038387523, "compression_ratio": 1.62015503875969, "no_speech_prob": 0.005985728930681944}, {"id": 116, "seek": 47128, "start": 471.28, "end": 477.59999999999997, "text": " rather, to start listening more actively to your colleagues or co-collaborators and", "tokens": [50364, 2831, 11, 281, 722, 4764, 544, 13022, 281, 428, 7734, 420, 598, 12, 33891, 3816, 3391, 293, 50680], "temperature": 0.0, "avg_logprob": -0.16417289326209147, "compression_ratio": 1.7062937062937062, "no_speech_prob": 0.08115996420383453}, {"id": 117, "seek": 47128, "start": 477.59999999999997, "end": 480.28, "text": " others you work with.", "tokens": [50680, 2357, 291, 589, 365, 13, 50814], "temperature": 0.0, "avg_logprob": -0.16417289326209147, "compression_ratio": 1.7062937062937062, "no_speech_prob": 0.08115996420383453}, {"id": 118, "seek": 47128, "start": 480.28, "end": 482.28, "text": " They say, first of all, pay attention.", "tokens": [50814, 814, 584, 11, 700, 295, 439, 11, 1689, 3202, 13, 50914], "temperature": 0.0, "avg_logprob": -0.16417289326209147, "compression_ratio": 1.7062937062937062, "no_speech_prob": 0.08115996420383453}, {"id": 119, "seek": 47128, "start": 482.28, "end": 486.55999999999995, "text": " And we take this as a given, but in our world of smartphones and lots of distractions and", "tokens": [50914, 400, 321, 747, 341, 382, 257, 2212, 11, 457, 294, 527, 1002, 295, 26782, 293, 3195, 295, 37887, 293, 51128], "temperature": 0.0, "avg_logprob": -0.16417289326209147, "compression_ratio": 1.7062937062937062, "no_speech_prob": 0.08115996420383453}, {"id": 120, "seek": 47128, "start": 486.55999999999995, "end": 490.96, "text": " multitasking, we often don't really fully pay attention to each other.", "tokens": [51128, 42338, 47211, 11, 321, 2049, 500, 380, 534, 4498, 1689, 3202, 281, 1184, 661, 13, 51348], "temperature": 0.0, "avg_logprob": -0.16417289326209147, "compression_ratio": 1.7062937062937062, "no_speech_prob": 0.08115996420383453}, {"id": 121, "seek": 47128, "start": 490.96, "end": 495.91999999999996, "text": " And one way that we don't do this is that we sometimes can't wait to, we don't wait", "tokens": [51348, 400, 472, 636, 300, 321, 500, 380, 360, 341, 307, 300, 321, 2171, 393, 380, 1699, 281, 11, 321, 500, 380, 1699, 51596], "temperature": 0.0, "avg_logprob": -0.16417289326209147, "compression_ratio": 1.7062937062937062, "no_speech_prob": 0.08115996420383453}, {"id": 122, "seek": 47128, "start": 495.91999999999996, "end": 500.0, "text": " for the person to finish what they're saying, before we just like, oh, I want to get my point", "tokens": [51596, 337, 264, 954, 281, 2413, 437, 436, 434, 1566, 11, 949, 321, 445, 411, 11, 1954, 11, 286, 528, 281, 483, 452, 935, 51800], "temperature": 0.0, "avg_logprob": -0.16417289326209147, "compression_ratio": 1.7062937062937062, "no_speech_prob": 0.08115996420383453}, {"id": 123, "seek": 47128, "start": 500.0, "end": 501.0, "text": " out.", "tokens": [51800, 484, 13, 51850], "temperature": 0.0, "avg_logprob": -0.16417289326209147, "compression_ratio": 1.7062937062937062, "no_speech_prob": 0.08115996420383453}, {"id": 124, "seek": 50100, "start": 501.0, "end": 505.08, "text": " We have to go, and then we end up missing the latter half of the sentence, because we're", "tokens": [50364, 492, 362, 281, 352, 11, 293, 550, 321, 917, 493, 5361, 264, 18481, 1922, 295, 264, 8174, 11, 570, 321, 434, 50568], "temperature": 0.0, "avg_logprob": -0.18639500427246095, "compression_ratio": 1.6859205776173285, "no_speech_prob": 0.022577404975891113}, {"id": 125, "seek": 50100, "start": 505.08, "end": 509.44, "text": " too focused on our own sentence and what we want to say.", "tokens": [50568, 886, 5178, 322, 527, 1065, 8174, 293, 437, 321, 528, 281, 584, 13, 50786], "temperature": 0.0, "avg_logprob": -0.18639500427246095, "compression_ratio": 1.6859205776173285, "no_speech_prob": 0.022577404975891113}, {"id": 126, "seek": 50100, "start": 509.44, "end": 511.52, "text": " So active listening means that you don't do that.", "tokens": [50786, 407, 4967, 4764, 1355, 300, 291, 500, 380, 360, 300, 13, 50890], "temperature": 0.0, "avg_logprob": -0.18639500427246095, "compression_ratio": 1.6859205776173285, "no_speech_prob": 0.022577404975891113}, {"id": 127, "seek": 50100, "start": 511.52, "end": 514.64, "text": " You actually let somebody finish, and then you ask.", "tokens": [50890, 509, 767, 718, 2618, 2413, 11, 293, 550, 291, 1029, 13, 51046], "temperature": 0.0, "avg_logprob": -0.18639500427246095, "compression_ratio": 1.6859205776173285, "no_speech_prob": 0.022577404975891113}, {"id": 128, "seek": 50100, "start": 514.64, "end": 520.6, "text": " And you also can do things like clarify what the person is telling you by asking them questions.", "tokens": [51046, 400, 291, 611, 393, 360, 721, 411, 17594, 437, 264, 954, 307, 3585, 291, 538, 3365, 552, 1651, 13, 51344], "temperature": 0.0, "avg_logprob": -0.18639500427246095, "compression_ratio": 1.6859205776173285, "no_speech_prob": 0.022577404975891113}, {"id": 129, "seek": 50100, "start": 520.6, "end": 522.56, "text": " Did I think, I think I heard you say this.", "tokens": [51344, 2589, 286, 519, 11, 286, 519, 286, 2198, 291, 584, 341, 13, 51442], "temperature": 0.0, "avg_logprob": -0.18639500427246095, "compression_ratio": 1.6859205776173285, "no_speech_prob": 0.022577404975891113}, {"id": 130, "seek": 50100, "start": 522.56, "end": 523.56, "text": " Is that correct?", "tokens": [51442, 1119, 300, 3006, 30, 51492], "temperature": 0.0, "avg_logprob": -0.18639500427246095, "compression_ratio": 1.6859205776173285, "no_speech_prob": 0.022577404975891113}, {"id": 131, "seek": 50100, "start": 523.56, "end": 527.24, "text": " Or can you tell me more about what you're trying to say to me?", "tokens": [51492, 1610, 393, 291, 980, 385, 544, 466, 437, 291, 434, 1382, 281, 584, 281, 385, 30, 51676], "temperature": 0.0, "avg_logprob": -0.18639500427246095, "compression_ratio": 1.6859205776173285, "no_speech_prob": 0.022577404975891113}, {"id": 132, "seek": 52724, "start": 527.24, "end": 531.0, "text": " And then together, it starts to become a collaboration, because you're inviting them", "tokens": [50364, 400, 550, 1214, 11, 309, 3719, 281, 1813, 257, 9363, 11, 570, 291, 434, 18202, 552, 50552], "temperature": 0.0, "avg_logprob": -0.14147539649690902, "compression_ratio": 1.7537313432835822, "no_speech_prob": 0.027806933969259262}, {"id": 133, "seek": 52724, "start": 531.0, "end": 534.5600000000001, "text": " to also clarify their ideas for themselves.", "tokens": [50552, 281, 611, 17594, 641, 3487, 337, 2969, 13, 50730], "temperature": 0.0, "avg_logprob": -0.14147539649690902, "compression_ratio": 1.7537313432835822, "no_speech_prob": 0.027806933969259262}, {"id": 134, "seek": 52724, "start": 534.5600000000001, "end": 538.52, "text": " And you're also getting higher quality information, because A, you're taking it in, and you're", "tokens": [50730, 400, 291, 434, 611, 1242, 2946, 3125, 1589, 11, 570, 316, 11, 291, 434, 1940, 309, 294, 11, 293, 291, 434, 50928], "temperature": 0.0, "avg_logprob": -0.14147539649690902, "compression_ratio": 1.7537313432835822, "no_speech_prob": 0.027806933969259262}, {"id": 135, "seek": 52724, "start": 538.52, "end": 546.76, "text": " also engaging with it in a team context to work out new ideas.", "tokens": [50928, 611, 11268, 365, 309, 294, 257, 1469, 4319, 281, 589, 484, 777, 3487, 13, 51340], "temperature": 0.0, "avg_logprob": -0.14147539649690902, "compression_ratio": 1.7537313432835822, "no_speech_prob": 0.027806933969259262}, {"id": 136, "seek": 52724, "start": 546.76, "end": 550.48, "text": " In addition to listening to your colleagues and people around you, you should also listen", "tokens": [51340, 682, 4500, 281, 4764, 281, 428, 7734, 293, 561, 926, 291, 11, 291, 820, 611, 2140, 51526], "temperature": 0.0, "avg_logprob": -0.14147539649690902, "compression_ratio": 1.7537313432835822, "no_speech_prob": 0.027806933969259262}, {"id": 137, "seek": 52724, "start": 550.48, "end": 551.48, "text": " to your code.", "tokens": [51526, 281, 428, 3089, 13, 51576], "temperature": 0.0, "avg_logprob": -0.14147539649690902, "compression_ratio": 1.7537313432835822, "no_speech_prob": 0.027806933969259262}, {"id": 138, "seek": 52724, "start": 551.48, "end": 556.32, "text": " So I mentioned a few slides ago about this idea to rewrite a tool from scratch.", "tokens": [51576, 407, 286, 2835, 257, 1326, 9788, 2057, 466, 341, 1558, 281, 28132, 257, 2290, 490, 8459, 13, 51818], "temperature": 0.0, "avg_logprob": -0.14147539649690902, "compression_ratio": 1.7537313432835822, "no_speech_prob": 0.027806933969259262}, {"id": 139, "seek": 55632, "start": 556.32, "end": 560.32, "text": " But if you don't really listen to your own code from the beginning, you may end up doing", "tokens": [50364, 583, 498, 291, 500, 380, 534, 2140, 281, 428, 1065, 3089, 490, 264, 2863, 11, 291, 815, 917, 493, 884, 50564], "temperature": 0.0, "avg_logprob": -0.13928977479325963, "compression_ratio": 1.603305785123967, "no_speech_prob": 0.007065233774483204}, {"id": 140, "seek": 55632, "start": 560.32, "end": 565.0400000000001, "text": " a lot of work that you could have avoided by just optimizing and selectively choosing", "tokens": [50564, 257, 688, 295, 589, 300, 291, 727, 362, 24890, 538, 445, 40425, 293, 3048, 3413, 10875, 50800], "temperature": 0.0, "avg_logprob": -0.13928977479325963, "compression_ratio": 1.603305785123967, "no_speech_prob": 0.007065233774483204}, {"id": 141, "seek": 55632, "start": 565.0400000000001, "end": 566.72, "text": " what to work on.", "tokens": [50800, 437, 281, 589, 322, 13, 50884], "temperature": 0.0, "avg_logprob": -0.13928977479325963, "compression_ratio": 1.603305785123967, "no_speech_prob": 0.007065233774483204}, {"id": 142, "seek": 55632, "start": 566.72, "end": 572.8000000000001, "text": " So having artifacts like docs and diagrams will help you to better reason about the work", "tokens": [50884, 407, 1419, 24617, 411, 45623, 293, 36709, 486, 854, 291, 281, 1101, 1778, 466, 264, 589, 51188], "temperature": 0.0, "avg_logprob": -0.13928977479325963, "compression_ratio": 1.603305785123967, "no_speech_prob": 0.007065233774483204}, {"id": 143, "seek": 55632, "start": 572.8000000000001, "end": 575.2, "text": " you truly should do.", "tokens": [51188, 291, 4908, 820, 360, 13, 51308], "temperature": 0.0, "avg_logprob": -0.13928977479325963, "compression_ratio": 1.603305785123967, "no_speech_prob": 0.007065233774483204}, {"id": 144, "seek": 55632, "start": 575.2, "end": 581.0, "text": " Optimize, find the points where you can make things better, and also plan accordingly.", "tokens": [51308, 35013, 1125, 11, 915, 264, 2793, 689, 291, 393, 652, 721, 1101, 11, 293, 611, 1393, 19717, 13, 51598], "temperature": 0.0, "avg_logprob": -0.13928977479325963, "compression_ratio": 1.603305785123967, "no_speech_prob": 0.007065233774483204}, {"id": 145, "seek": 58100, "start": 582.0, "end": 586.72, "text": " So here's another example from Sig Release where we applied this principle.", "tokens": [50414, 407, 510, 311, 1071, 1365, 490, 37763, 34278, 689, 321, 6456, 341, 8665, 13, 50650], "temperature": 0.0, "avg_logprob": -0.1682248196359408, "compression_ratio": 1.691449814126394, "no_speech_prob": 0.036485541611909866}, {"id": 146, "seek": 58100, "start": 586.72, "end": 587.72, "text": " We had this tool, right?", "tokens": [50650, 492, 632, 341, 2290, 11, 558, 30, 50700], "temperature": 0.0, "avg_logprob": -0.1682248196359408, "compression_ratio": 1.691449814126394, "no_speech_prob": 0.036485541611909866}, {"id": 147, "seek": 58100, "start": 587.72, "end": 589.36, "text": " And we were going to rewrite it.", "tokens": [50700, 400, 321, 645, 516, 281, 28132, 309, 13, 50782], "temperature": 0.0, "avg_logprob": -0.1682248196359408, "compression_ratio": 1.691449814126394, "no_speech_prob": 0.036485541611909866}, {"id": 148, "seek": 58100, "start": 589.36, "end": 594.48, "text": " But I said, first of all, let's actually document the flow that the user follows to use this", "tokens": [50782, 583, 286, 848, 11, 700, 295, 439, 11, 718, 311, 767, 4166, 264, 3095, 300, 264, 4195, 10002, 281, 764, 341, 51038], "temperature": 0.0, "avg_logprob": -0.1682248196359408, "compression_ratio": 1.691449814126394, "no_speech_prob": 0.036485541611909866}, {"id": 149, "seek": 58100, "start": 594.48, "end": 599.04, "text": " tool, achieve a job, go from point A to point B.", "tokens": [51038, 2290, 11, 4584, 257, 1691, 11, 352, 490, 935, 316, 281, 935, 363, 13, 51266], "temperature": 0.0, "avg_logprob": -0.1682248196359408, "compression_ratio": 1.691449814126394, "no_speech_prob": 0.036485541611909866}, {"id": 150, "seek": 58100, "start": 599.04, "end": 605.44, "text": " And so an engineer in Sig Release did this, and then we gathered around as a group, around", "tokens": [51266, 400, 370, 364, 11403, 294, 37763, 34278, 630, 341, 11, 293, 550, 321, 13032, 926, 382, 257, 1594, 11, 926, 51586], "temperature": 0.0, "avg_logprob": -0.1682248196359408, "compression_ratio": 1.691449814126394, "no_speech_prob": 0.036485541611909866}, {"id": 151, "seek": 58100, "start": 605.44, "end": 610.84, "text": " his workflow, and talked through every step, figuring out what was really hard, what was", "tokens": [51586, 702, 20993, 11, 293, 2825, 807, 633, 1823, 11, 15213, 484, 437, 390, 534, 1152, 11, 437, 390, 51856], "temperature": 0.0, "avg_logprob": -0.1682248196359408, "compression_ratio": 1.691449814126394, "no_speech_prob": 0.036485541611909866}, {"id": 152, "seek": 61084, "start": 610.88, "end": 614.2800000000001, "text": " taking a lot of time, what wasn't working.", "tokens": [50366, 1940, 257, 688, 295, 565, 11, 437, 2067, 380, 1364, 13, 50536], "temperature": 0.0, "avg_logprob": -0.15726469330868478, "compression_ratio": 1.7727272727272727, "no_speech_prob": 0.0014735086588189006}, {"id": 153, "seek": 61084, "start": 614.2800000000001, "end": 618.6, "text": " And as you can see from the results, the first line there is the overall flow.", "tokens": [50536, 400, 382, 291, 393, 536, 490, 264, 3542, 11, 264, 700, 1622, 456, 307, 264, 4787, 3095, 13, 50752], "temperature": 0.0, "avg_logprob": -0.15726469330868478, "compression_ratio": 1.7727272727272727, "no_speech_prob": 0.0014735086588189006}, {"id": 154, "seek": 61084, "start": 618.6, "end": 623.4, "text": " And then I blew up this section toward the end, where you see a lot of anger, and then", "tokens": [50752, 400, 550, 286, 19075, 493, 341, 3541, 7361, 264, 917, 11, 689, 291, 536, 257, 688, 295, 10240, 11, 293, 550, 50992], "temperature": 0.0, "avg_logprob": -0.15726469330868478, "compression_ratio": 1.7727272727272727, "no_speech_prob": 0.0014735086588189006}, {"id": 155, "seek": 61084, "start": 623.4, "end": 626.48, "text": " there's this little clock, which means it was really time consuming.", "tokens": [50992, 456, 311, 341, 707, 7830, 11, 597, 1355, 309, 390, 534, 565, 19867, 13, 51146], "temperature": 0.0, "avg_logprob": -0.15726469330868478, "compression_ratio": 1.7727272727272727, "no_speech_prob": 0.0014735086588189006}, {"id": 156, "seek": 61084, "start": 626.48, "end": 632.4, "text": " And you could then see in the full landscape of this project's flow where the pain points", "tokens": [51146, 400, 291, 727, 550, 536, 294, 264, 1577, 9661, 295, 341, 1716, 311, 3095, 689, 264, 1822, 2793, 51442], "temperature": 0.0, "avg_logprob": -0.15726469330868478, "compression_ratio": 1.7727272727272727, "no_speech_prob": 0.0014735086588189006}, {"id": 157, "seek": 61084, "start": 632.4, "end": 633.4, "text": " truly were.", "tokens": [51442, 4908, 645, 13, 51492], "temperature": 0.0, "avg_logprob": -0.15726469330868478, "compression_ratio": 1.7727272727272727, "no_speech_prob": 0.0014735086588189006}, {"id": 158, "seek": 61084, "start": 633.4, "end": 639.0400000000001, "text": " And we were also able to use these posts to document exactly where the code existed that", "tokens": [51492, 400, 321, 645, 611, 1075, 281, 764, 613, 12300, 281, 4166, 2293, 689, 264, 3089, 13135, 300, 51774], "temperature": 0.0, "avg_logprob": -0.15726469330868478, "compression_ratio": 1.7727272727272727, "no_speech_prob": 0.0014735086588189006}, {"id": 159, "seek": 63904, "start": 639.0799999999999, "end": 641.9599999999999, "text": " was executing these steps.", "tokens": [50366, 390, 32368, 613, 4439, 13, 50510], "temperature": 0.0, "avg_logprob": -0.16957308582423888, "compression_ratio": 1.6401673640167365, "no_speech_prob": 0.00046363245928660035}, {"id": 160, "seek": 63904, "start": 641.9599999999999, "end": 647.56, "text": " And so what we walked away with was a much more focused plan for what we needed to do.", "tokens": [50510, 400, 370, 437, 321, 7628, 1314, 365, 390, 257, 709, 544, 5178, 1393, 337, 437, 321, 2978, 281, 360, 13, 50790], "temperature": 0.0, "avg_logprob": -0.16957308582423888, "compression_ratio": 1.6401673640167365, "no_speech_prob": 0.00046363245928660035}, {"id": 161, "seek": 63904, "start": 647.56, "end": 653.12, "text": " And we can then start there and then decide after collecting a lot of information about", "tokens": [50790, 400, 321, 393, 550, 722, 456, 293, 550, 4536, 934, 12510, 257, 688, 295, 1589, 466, 51068], "temperature": 0.0, "avg_logprob": -0.16957308582423888, "compression_ratio": 1.6401673640167365, "no_speech_prob": 0.00046363245928660035}, {"id": 162, "seek": 63904, "start": 653.12, "end": 656.9599999999999, "text": " these weaker points what we should do next.", "tokens": [51068, 613, 24286, 2793, 437, 321, 820, 360, 958, 13, 51260], "temperature": 0.0, "avg_logprob": -0.16957308582423888, "compression_ratio": 1.6401673640167365, "no_speech_prob": 0.00046363245928660035}, {"id": 163, "seek": 63904, "start": 656.9599999999999, "end": 663.36, "text": " Maybe we rewrite parts of this instead of the whole thing.", "tokens": [51260, 2704, 321, 28132, 3166, 295, 341, 2602, 295, 264, 1379, 551, 13, 51580], "temperature": 0.0, "avg_logprob": -0.16957308582423888, "compression_ratio": 1.6401673640167365, "no_speech_prob": 0.00046363245928660035}, {"id": 164, "seek": 63904, "start": 663.36, "end": 667.92, "text": " When you have a workflow like that in place, it really helps you to put, it puts you in", "tokens": [51580, 1133, 291, 362, 257, 20993, 411, 300, 294, 1081, 11, 309, 534, 3665, 291, 281, 829, 11, 309, 8137, 291, 294, 51808], "temperature": 0.0, "avg_logprob": -0.16957308582423888, "compression_ratio": 1.6401673640167365, "no_speech_prob": 0.00046363245928660035}, {"id": 165, "seek": 66792, "start": 667.9599999999999, "end": 670.0, "text": " better control of your project.", "tokens": [50366, 1101, 1969, 295, 428, 1716, 13, 50468], "temperature": 0.0, "avg_logprob": -0.1746823787689209, "compression_ratio": 1.7210300429184548, "no_speech_prob": 0.004159932490438223}, {"id": 166, "seek": 66792, "start": 670.0, "end": 673.0799999999999, "text": " Now if you have no projects, that's fine too.", "tokens": [50468, 823, 498, 291, 362, 572, 4455, 11, 300, 311, 2489, 886, 13, 50622], "temperature": 0.0, "avg_logprob": -0.1746823787689209, "compression_ratio": 1.7210300429184548, "no_speech_prob": 0.004159932490438223}, {"id": 167, "seek": 66792, "start": 673.0799999999999, "end": 677.52, "text": " What we're going to cover next are some tools that you can apply as you start working on", "tokens": [50622, 708, 321, 434, 516, 281, 2060, 958, 366, 512, 3873, 300, 291, 393, 3079, 382, 291, 722, 1364, 322, 50844], "temperature": 0.0, "avg_logprob": -0.1746823787689209, "compression_ratio": 1.7210300429184548, "no_speech_prob": 0.004159932490438223}, {"id": 168, "seek": 66792, "start": 677.52, "end": 678.52, "text": " a new project.", "tokens": [50844, 257, 777, 1716, 13, 50894], "temperature": 0.0, "avg_logprob": -0.1746823787689209, "compression_ratio": 1.7210300429184548, "no_speech_prob": 0.004159932490438223}, {"id": 169, "seek": 66792, "start": 678.52, "end": 683.7199999999999, "text": " But you can also introduce these even if you have something that's several years old.", "tokens": [50894, 583, 291, 393, 611, 5366, 613, 754, 498, 291, 362, 746, 300, 311, 2940, 924, 1331, 13, 51154], "temperature": 0.0, "avg_logprob": -0.1746823787689209, "compression_ratio": 1.7210300429184548, "no_speech_prob": 0.004159932490438223}, {"id": 170, "seek": 66792, "start": 683.7199999999999, "end": 684.7199999999999, "text": " It doesn't matter.", "tokens": [51154, 467, 1177, 380, 1871, 13, 51204], "temperature": 0.0, "avg_logprob": -0.1746823787689209, "compression_ratio": 1.7210300429184548, "no_speech_prob": 0.004159932490438223}, {"id": 171, "seek": 66792, "start": 684.7199999999999, "end": 692.04, "text": " It's never too late to understand your work and then organize yourself to do the highest", "tokens": [51204, 467, 311, 1128, 886, 3469, 281, 1223, 428, 589, 293, 550, 13859, 1803, 281, 360, 264, 6343, 51570], "temperature": 0.0, "avg_logprob": -0.1746823787689209, "compression_ratio": 1.7210300429184548, "no_speech_prob": 0.004159932490438223}, {"id": 172, "seek": 66792, "start": 692.04, "end": 695.04, "text": " value work in the future.", "tokens": [51570, 2158, 589, 294, 264, 2027, 13, 51720], "temperature": 0.0, "avg_logprob": -0.1746823787689209, "compression_ratio": 1.7210300429184548, "no_speech_prob": 0.004159932490438223}, {"id": 173, "seek": 69504, "start": 695.16, "end": 701.76, "text": " So I'm going to cover having a strategy with a doc template, doing user research and surveys,", "tokens": [50370, 407, 286, 478, 516, 281, 2060, 1419, 257, 5206, 365, 257, 3211, 12379, 11, 884, 4195, 2132, 293, 22711, 11, 50700], "temperature": 0.0, "avg_logprob": -0.19570319166461242, "compression_ratio": 1.6653696498054475, "no_speech_prob": 0.0008017735090106726}, {"id": 174, "seek": 69504, "start": 701.76, "end": 706.5999999999999, "text": " including an example of a survey which is the NPS, making a roadmap and giving you a", "tokens": [50700, 3009, 364, 1365, 295, 257, 8984, 597, 307, 264, 426, 6273, 11, 1455, 257, 35738, 293, 2902, 291, 257, 50942], "temperature": 0.0, "avg_logprob": -0.19570319166461242, "compression_ratio": 1.6653696498054475, "no_speech_prob": 0.0008017735090106726}, {"id": 175, "seek": 69504, "start": 706.5999999999999, "end": 711.8, "text": " template you can use, and then prioritizing and refining your backlog with some methods", "tokens": [50942, 12379, 291, 393, 764, 11, 293, 550, 14846, 3319, 293, 1895, 1760, 428, 47364, 365, 512, 7150, 51202], "temperature": 0.0, "avg_logprob": -0.19570319166461242, "compression_ratio": 1.6653696498054475, "no_speech_prob": 0.0008017735090106726}, {"id": 176, "seek": 69504, "start": 711.8, "end": 716.0799999999999, "text": " and tools you can apply for those activities.", "tokens": [51202, 293, 3873, 291, 393, 3079, 337, 729, 5354, 13, 51416], "temperature": 0.0, "avg_logprob": -0.19570319166461242, "compression_ratio": 1.6653696498054475, "no_speech_prob": 0.0008017735090106726}, {"id": 177, "seek": 69504, "start": 716.0799999999999, "end": 721.92, "text": " So here's a strategy doc template that I just worked with the security scorecard team on", "tokens": [51416, 407, 510, 311, 257, 5206, 3211, 12379, 300, 286, 445, 2732, 365, 264, 3825, 6175, 22259, 1469, 322, 51708], "temperature": 0.0, "avg_logprob": -0.19570319166461242, "compression_ratio": 1.6653696498054475, "no_speech_prob": 0.0008017735090106726}, {"id": 178, "seek": 69504, "start": 721.92, "end": 723.4399999999999, "text": " to actually fill this out.", "tokens": [51708, 281, 767, 2836, 341, 484, 13, 51784], "temperature": 0.0, "avg_logprob": -0.19570319166461242, "compression_ratio": 1.6653696498054475, "no_speech_prob": 0.0008017735090106726}, {"id": 179, "seek": 72344, "start": 723.44, "end": 726.1600000000001, "text": " And I know these little lines here are small and you can't see them.", "tokens": [50364, 400, 286, 458, 613, 707, 3876, 510, 366, 1359, 293, 291, 393, 380, 536, 552, 13, 50500], "temperature": 0.0, "avg_logprob": -0.1523424932198931, "compression_ratio": 1.7612456747404843, "no_speech_prob": 0.003337723668664694}, {"id": 180, "seek": 72344, "start": 726.1600000000001, "end": 728.2800000000001, "text": " I'll get to that in the next slide.", "tokens": [50500, 286, 603, 483, 281, 300, 294, 264, 958, 4137, 13, 50606], "temperature": 0.0, "avg_logprob": -0.1523424932198931, "compression_ratio": 1.7612456747404843, "no_speech_prob": 0.003337723668664694}, {"id": 181, "seek": 72344, "start": 728.2800000000001, "end": 734.72, "text": " But it basically introduces the concepts of the 5Ws that journalists use typically to", "tokens": [50606, 583, 309, 1936, 31472, 264, 10392, 295, 264, 1025, 54, 82, 300, 19535, 764, 5850, 281, 50928], "temperature": 0.0, "avg_logprob": -0.1523424932198931, "compression_ratio": 1.7612456747404843, "no_speech_prob": 0.003337723668664694}, {"id": 182, "seek": 72344, "start": 734.72, "end": 739.0, "text": " write a news story where they need to have the reader know the facts of the story right", "tokens": [50928, 2464, 257, 2583, 1657, 689, 436, 643, 281, 362, 264, 15149, 458, 264, 9130, 295, 264, 1657, 558, 51142], "temperature": 0.0, "avg_logprob": -0.1523424932198931, "compression_ratio": 1.7612456747404843, "no_speech_prob": 0.003337723668664694}, {"id": 183, "seek": 72344, "start": 739.0, "end": 743.6, "text": " away and then if the reader wants more detailed information they can read on.", "tokens": [51142, 1314, 293, 550, 498, 264, 15149, 2738, 544, 9942, 1589, 436, 393, 1401, 322, 13, 51372], "temperature": 0.0, "avg_logprob": -0.1523424932198931, "compression_ratio": 1.7612456747404843, "no_speech_prob": 0.003337723668664694}, {"id": 184, "seek": 72344, "start": 743.6, "end": 747.2, "text": " But it answers who, what, when, where, and why as well as how.", "tokens": [51372, 583, 309, 6338, 567, 11, 437, 11, 562, 11, 689, 11, 293, 983, 382, 731, 382, 577, 13, 51552], "temperature": 0.0, "avg_logprob": -0.1523424932198931, "compression_ratio": 1.7612456747404843, "no_speech_prob": 0.003337723668664694}, {"id": 185, "seek": 72344, "start": 747.2, "end": 751.5600000000001, "text": " The goal here is that you have an asynchronous tool that you can use so you don't have to", "tokens": [51552, 440, 3387, 510, 307, 300, 291, 362, 364, 49174, 2290, 300, 291, 393, 764, 370, 291, 500, 380, 362, 281, 51770], "temperature": 0.0, "avg_logprob": -0.1523424932198931, "compression_ratio": 1.7612456747404843, "no_speech_prob": 0.003337723668664694}, {"id": 186, "seek": 75156, "start": 751.56, "end": 756.56, "text": " have a meeting around this, although I advise it because you'll find that more information", "tokens": [50364, 362, 257, 3440, 926, 341, 11, 4878, 286, 18312, 309, 570, 291, 603, 915, 300, 544, 1589, 50614], "temperature": 0.0, "avg_logprob": -0.11806834281027855, "compression_ratio": 1.7158671586715868, "no_speech_prob": 0.0076462989673018456}, {"id": 187, "seek": 75156, "start": 756.56, "end": 760.16, "text": " comes out when you actually discuss your strategy.", "tokens": [50614, 1487, 484, 562, 291, 767, 2248, 428, 5206, 13, 50794], "temperature": 0.0, "avg_logprob": -0.11806834281027855, "compression_ratio": 1.7158671586715868, "no_speech_prob": 0.0076462989673018456}, {"id": 188, "seek": 75156, "start": 760.16, "end": 765.16, "text": " But you can at least start with a template like this and people then can contribute their", "tokens": [50794, 583, 291, 393, 412, 1935, 722, 365, 257, 12379, 411, 341, 293, 561, 550, 393, 10586, 641, 51044], "temperature": 0.0, "avg_logprob": -0.11806834281027855, "compression_ratio": 1.7158671586715868, "no_speech_prob": 0.0076462989673018456}, {"id": 189, "seek": 75156, "start": 765.16, "end": 767.04, "text": " comments and ideas to it.", "tokens": [51044, 3053, 293, 3487, 281, 309, 13, 51138], "temperature": 0.0, "avg_logprob": -0.11806834281027855, "compression_ratio": 1.7158671586715868, "no_speech_prob": 0.0076462989673018456}, {"id": 190, "seek": 75156, "start": 767.04, "end": 769.68, "text": " This is Miro by the way.", "tokens": [51138, 639, 307, 376, 5182, 538, 264, 636, 13, 51270], "temperature": 0.0, "avg_logprob": -0.11806834281027855, "compression_ratio": 1.7158671586715868, "no_speech_prob": 0.0076462989673018456}, {"id": 191, "seek": 75156, "start": 769.68, "end": 774.04, "text": " When you actually have this template filled out and you've gone through it with your team", "tokens": [51270, 1133, 291, 767, 362, 341, 12379, 6412, 484, 293, 291, 600, 2780, 807, 309, 365, 428, 1469, 51488], "temperature": 0.0, "avg_logprob": -0.11806834281027855, "compression_ratio": 1.7158671586715868, "no_speech_prob": 0.0076462989673018456}, {"id": 192, "seek": 75156, "start": 774.04, "end": 779.76, "text": " then you can dump it into a doc, refine it a bit more and then publish it in your repository", "tokens": [51488, 550, 291, 393, 11430, 309, 666, 257, 3211, 11, 33906, 309, 257, 857, 544, 293, 550, 11374, 309, 294, 428, 25841, 51774], "temperature": 0.0, "avg_logprob": -0.11806834281027855, "compression_ratio": 1.7158671586715868, "no_speech_prob": 0.0076462989673018456}, {"id": 193, "seek": 77976, "start": 779.88, "end": 781.96, "text": " for the public to look at.", "tokens": [50370, 337, 264, 1908, 281, 574, 412, 13, 50474], "temperature": 0.0, "avg_logprob": -0.1967281681476253, "compression_ratio": 1.6454183266932272, "no_speech_prob": 0.01767781563103199}, {"id": 194, "seek": 77976, "start": 781.96, "end": 787.4399999999999, "text": " And then of course you can continuously revise as your project develops and you discover", "tokens": [50474, 400, 550, 295, 1164, 291, 393, 15684, 44252, 382, 428, 1716, 25453, 293, 291, 4411, 50748], "temperature": 0.0, "avg_logprob": -0.1967281681476253, "compression_ratio": 1.6454183266932272, "no_speech_prob": 0.01767781563103199}, {"id": 195, "seek": 77976, "start": 787.4399999999999, "end": 790.4399999999999, "text": " new information.", "tokens": [50748, 777, 1589, 13, 50898], "temperature": 0.0, "avg_logprob": -0.1967281681476253, "compression_ratio": 1.6454183266932272, "no_speech_prob": 0.01767781563103199}, {"id": 196, "seek": 77976, "start": 790.4399999999999, "end": 794.52, "text": " So those small questions in that template are here basically.", "tokens": [50898, 407, 729, 1359, 1651, 294, 300, 12379, 366, 510, 1936, 13, 51102], "temperature": 0.0, "avg_logprob": -0.1967281681476253, "compression_ratio": 1.6454183266932272, "no_speech_prob": 0.01767781563103199}, {"id": 197, "seek": 77976, "start": 794.52, "end": 798.88, "text": " Not all of them but some key questions that are quite useful for getting a sense of where", "tokens": [51102, 1726, 439, 295, 552, 457, 512, 2141, 1651, 300, 366, 1596, 4420, 337, 1242, 257, 2020, 295, 689, 51320], "temperature": 0.0, "avg_logprob": -0.1967281681476253, "compression_ratio": 1.6454183266932272, "no_speech_prob": 0.01767781563103199}, {"id": 198, "seek": 77976, "start": 798.88, "end": 800.92, "text": " you're going with your work.", "tokens": [51320, 291, 434, 516, 365, 428, 589, 13, 51422], "temperature": 0.0, "avg_logprob": -0.1967281681476253, "compression_ratio": 1.6454183266932272, "no_speech_prob": 0.01767781563103199}, {"id": 199, "seek": 77976, "start": 800.92, "end": 805.4, "text": " So who are the users as long as the contributors and the maintainers?", "tokens": [51422, 407, 567, 366, 264, 5022, 382, 938, 382, 264, 45627, 293, 264, 6909, 433, 30, 51646], "temperature": 0.0, "avg_logprob": -0.1967281681476253, "compression_ratio": 1.6454183266932272, "no_speech_prob": 0.01767781563103199}, {"id": 200, "seek": 77976, "start": 805.4, "end": 806.4, "text": " But really who are the users?", "tokens": [51646, 583, 534, 567, 366, 264, 5022, 30, 51696], "temperature": 0.0, "avg_logprob": -0.1967281681476253, "compression_ratio": 1.6454183266932272, "no_speech_prob": 0.01767781563103199}, {"id": 201, "seek": 80640, "start": 806.52, "end": 810.0, "text": " Who are the people deriving value from your project today?", "tokens": [50370, 2102, 366, 264, 561, 1163, 2123, 2158, 490, 428, 1716, 965, 30, 50544], "temperature": 0.0, "avg_logprob": -0.17894697626796338, "compression_ratio": 1.9022222222222223, "no_speech_prob": 0.002802259288728237}, {"id": 202, "seek": 80640, "start": 810.0, "end": 815.1999999999999, "text": " And who do you want to derive, who do you want to have value derived in the future?", "tokens": [50544, 400, 567, 360, 291, 528, 281, 28446, 11, 567, 360, 291, 528, 281, 362, 2158, 18949, 294, 264, 2027, 30, 50804], "temperature": 0.0, "avg_logprob": -0.17894697626796338, "compression_ratio": 1.9022222222222223, "no_speech_prob": 0.002802259288728237}, {"id": 203, "seek": 80640, "start": 815.1999999999999, "end": 818.36, "text": " Like who should derive value in the future?", "tokens": [50804, 1743, 567, 820, 28446, 2158, 294, 264, 2027, 30, 50962], "temperature": 0.0, "avg_logprob": -0.17894697626796338, "compression_ratio": 1.9022222222222223, "no_speech_prob": 0.002802259288728237}, {"id": 204, "seek": 80640, "start": 818.36, "end": 820.84, "text": " What does your project do today?", "tokens": [50962, 708, 775, 428, 1716, 360, 965, 30, 51086], "temperature": 0.0, "avg_logprob": -0.17894697626796338, "compression_ratio": 1.9022222222222223, "no_speech_prob": 0.002802259288728237}, {"id": 205, "seek": 80640, "start": 820.84, "end": 822.88, "text": " On the flip side what does it not do?", "tokens": [51086, 1282, 264, 7929, 1252, 437, 775, 309, 406, 360, 30, 51188], "temperature": 0.0, "avg_logprob": -0.17894697626796338, "compression_ratio": 1.9022222222222223, "no_speech_prob": 0.002802259288728237}, {"id": 206, "seek": 80640, "start": 822.88, "end": 827.24, "text": " I mentioned earlier that boundary about what goes in a project and what stays out.", "tokens": [51188, 286, 2835, 3071, 300, 12866, 466, 437, 1709, 294, 257, 1716, 293, 437, 10834, 484, 13, 51406], "temperature": 0.0, "avg_logprob": -0.17894697626796338, "compression_ratio": 1.9022222222222223, "no_speech_prob": 0.002802259288728237}, {"id": 207, "seek": 80640, "start": 827.24, "end": 831.56, "text": " When you can clearly explain what a project is and what it is not and what it shouldn't", "tokens": [51406, 1133, 291, 393, 4448, 2903, 437, 257, 1716, 307, 293, 437, 309, 307, 406, 293, 437, 309, 4659, 380, 51622], "temperature": 0.0, "avg_logprob": -0.17894697626796338, "compression_ratio": 1.9022222222222223, "no_speech_prob": 0.002802259288728237}, {"id": 208, "seek": 83156, "start": 831.56, "end": 836.68, "text": " be then you can get a clearer sense of where that boundary lies.", "tokens": [50364, 312, 550, 291, 393, 483, 257, 26131, 2020, 295, 689, 300, 12866, 9134, 13, 50620], "temperature": 0.0, "avg_logprob": -0.16991880898163697, "compression_ratio": 1.6807692307692308, "no_speech_prob": 0.012871168553829193}, {"id": 209, "seek": 83156, "start": 836.68, "end": 841.7199999999999, "text": " You can also think here about what the UX is like and what quality concerns and constraints", "tokens": [50620, 509, 393, 611, 519, 510, 466, 437, 264, 40176, 307, 411, 293, 437, 3125, 7389, 293, 18491, 50872], "temperature": 0.0, "avg_logprob": -0.16991880898163697, "compression_ratio": 1.6807692307692308, "no_speech_prob": 0.012871168553829193}, {"id": 210, "seek": 83156, "start": 841.7199999999999, "end": 842.7199999999999, "text": " you have.", "tokens": [50872, 291, 362, 13, 50922], "temperature": 0.0, "avg_logprob": -0.16991880898163697, "compression_ratio": 1.6807692307692308, "no_speech_prob": 0.012871168553829193}, {"id": 211, "seek": 83156, "start": 842.7199999999999, "end": 847.0799999999999, "text": " It's really just like what is your project essentially?", "tokens": [50922, 467, 311, 534, 445, 411, 437, 307, 428, 1716, 4476, 30, 51140], "temperature": 0.0, "avg_logprob": -0.16991880898163697, "compression_ratio": 1.6807692307692308, "no_speech_prob": 0.012871168553829193}, {"id": 212, "seek": 83156, "start": 847.0799999999999, "end": 848.5999999999999, "text": " What is your project useful?", "tokens": [51140, 708, 307, 428, 1716, 4420, 30, 51216], "temperature": 0.0, "avg_logprob": -0.16991880898163697, "compression_ratio": 1.6807692307692308, "no_speech_prob": 0.012871168553829193}, {"id": 213, "seek": 83156, "start": 848.5999999999999, "end": 853.88, "text": " So what are the conditions to trigger a user actively coming to you, you're solving their", "tokens": [51216, 407, 437, 366, 264, 4487, 281, 7875, 257, 4195, 13022, 1348, 281, 291, 11, 291, 434, 12606, 641, 51480], "temperature": 0.0, "avg_logprob": -0.16991880898163697, "compression_ratio": 1.6807692307692308, "no_speech_prob": 0.012871168553829193}, {"id": 214, "seek": 83156, "start": 853.88, "end": 855.56, "text": " problem?", "tokens": [51480, 1154, 30, 51564], "temperature": 0.0, "avg_logprob": -0.16991880898163697, "compression_ratio": 1.6807692307692308, "no_speech_prob": 0.012871168553829193}, {"id": 215, "seek": 83156, "start": 855.56, "end": 860.28, "text": " Another way to look at when is like how long does a particular stage of your project's", "tokens": [51564, 3996, 636, 281, 574, 412, 562, 307, 411, 577, 938, 775, 257, 1729, 3233, 295, 428, 1716, 311, 51800], "temperature": 0.0, "avg_logprob": -0.16991880898163697, "compression_ratio": 1.6807692307692308, "no_speech_prob": 0.012871168553829193}, {"id": 216, "seek": 86028, "start": 860.3199999999999, "end": 864.12, "text": " workflow take to be completed?", "tokens": [50366, 20993, 747, 281, 312, 7365, 30, 50556], "temperature": 0.0, "avg_logprob": -0.1685777364992628, "compression_ratio": 1.6547619047619047, "no_speech_prob": 0.001880920259281993}, {"id": 217, "seek": 86028, "start": 864.12, "end": 867.0799999999999, "text": " Where does your project fit in the ecosystem?", "tokens": [50556, 2305, 775, 428, 1716, 3318, 294, 264, 11311, 30, 50704], "temperature": 0.0, "avg_logprob": -0.1685777364992628, "compression_ratio": 1.6547619047619047, "no_speech_prob": 0.001880920259281993}, {"id": 218, "seek": 86028, "start": 867.0799999999999, "end": 871.4399999999999, "text": " So I'm not going to go over the ins and outs of doing a competitor analysis here.", "tokens": [50704, 407, 286, 478, 406, 516, 281, 352, 670, 264, 1028, 293, 14758, 295, 884, 257, 27266, 5215, 510, 13, 50922], "temperature": 0.0, "avg_logprob": -0.1685777364992628, "compression_ratio": 1.6547619047619047, "no_speech_prob": 0.001880920259281993}, {"id": 219, "seek": 86028, "start": 871.4399999999999, "end": 874.88, "text": " There's lots of templates online that you can look at to do one.", "tokens": [50922, 821, 311, 3195, 295, 21165, 2950, 300, 291, 393, 574, 412, 281, 360, 472, 13, 51094], "temperature": 0.0, "avg_logprob": -0.1685777364992628, "compression_ratio": 1.6547619047619047, "no_speech_prob": 0.001880920259281993}, {"id": 220, "seek": 86028, "start": 874.88, "end": 879.8, "text": " But I highly recommend it because when you take a look at other projects in the space", "tokens": [51094, 583, 286, 5405, 2748, 309, 570, 562, 291, 747, 257, 574, 412, 661, 4455, 294, 264, 1901, 51340], "temperature": 0.0, "avg_logprob": -0.1685777364992628, "compression_ratio": 1.6547619047619047, "no_speech_prob": 0.001880920259281993}, {"id": 221, "seek": 86028, "start": 879.8, "end": 886.8, "text": " that are doing similar, solving a similar problem, you can then assess the resources", "tokens": [51340, 300, 366, 884, 2531, 11, 12606, 257, 2531, 1154, 11, 291, 393, 550, 5877, 264, 3593, 51690], "temperature": 0.0, "avg_logprob": -0.1685777364992628, "compression_ratio": 1.6547619047619047, "no_speech_prob": 0.001880920259281993}, {"id": 222, "seek": 86028, "start": 886.8, "end": 888.8, "text": " behind those projects.", "tokens": [51690, 2261, 729, 4455, 13, 51790], "temperature": 0.0, "avg_logprob": -0.1685777364992628, "compression_ratio": 1.6547619047619047, "no_speech_prob": 0.001880920259281993}, {"id": 223, "seek": 88880, "start": 888.8399999999999, "end": 892.9599999999999, "text": " Maybe there are even products, so maybe there's like a company doing what you want to do.", "tokens": [50366, 2704, 456, 366, 754, 3383, 11, 370, 1310, 456, 311, 411, 257, 2237, 884, 437, 291, 528, 281, 360, 13, 50572], "temperature": 0.0, "avg_logprob": -0.17643773555755615, "compression_ratio": 1.8646616541353382, "no_speech_prob": 0.08381596952676773}, {"id": 224, "seek": 88880, "start": 892.9599999999999, "end": 896.64, "text": " So they have a lot of money and they can work quickly and then you can consider like what", "tokens": [50572, 407, 436, 362, 257, 688, 295, 1460, 293, 436, 393, 589, 2661, 293, 550, 291, 393, 1949, 411, 437, 50756], "temperature": 0.0, "avg_logprob": -0.17643773555755615, "compression_ratio": 1.8646616541353382, "no_speech_prob": 0.08381596952676773}, {"id": 225, "seek": 88880, "start": 896.64, "end": 900.88, "text": " you actually have in your time budget to actually pursue.", "tokens": [50756, 291, 767, 362, 294, 428, 565, 4706, 281, 767, 12392, 13, 50968], "temperature": 0.0, "avg_logprob": -0.17643773555755615, "compression_ratio": 1.8646616541353382, "no_speech_prob": 0.08381596952676773}, {"id": 226, "seek": 88880, "start": 900.88, "end": 906.0799999999999, "text": " You can also see what those projects and products strengths and weaknesses are and then use", "tokens": [50968, 509, 393, 611, 536, 437, 729, 4455, 293, 3383, 16986, 293, 24381, 366, 293, 550, 764, 51228], "temperature": 0.0, "avg_logprob": -0.17643773555755615, "compression_ratio": 1.8646616541353382, "no_speech_prob": 0.08381596952676773}, {"id": 227, "seek": 88880, "start": 906.0799999999999, "end": 910.76, "text": " that information to distinguish and differentiate like what you want to provide.", "tokens": [51228, 300, 1589, 281, 20206, 293, 23203, 411, 437, 291, 528, 281, 2893, 13, 51462], "temperature": 0.0, "avg_logprob": -0.17643773555755615, "compression_ratio": 1.8646616541353382, "no_speech_prob": 0.08381596952676773}, {"id": 228, "seek": 88880, "start": 910.76, "end": 916.3599999999999, "text": " Maybe it's a niche that you want to really get a handle on and provide a really clear", "tokens": [51462, 2704, 309, 311, 257, 19956, 300, 291, 528, 281, 534, 483, 257, 4813, 322, 293, 2893, 257, 534, 1850, 51742], "temperature": 0.0, "avg_logprob": -0.17643773555755615, "compression_ratio": 1.8646616541353382, "no_speech_prob": 0.08381596952676773}, {"id": 229, "seek": 91636, "start": 916.4, "end": 919.52, "text": " good solution for that no one else is providing.", "tokens": [50366, 665, 3827, 337, 300, 572, 472, 1646, 307, 6530, 13, 50522], "temperature": 0.0, "avg_logprob": -0.21539241790771485, "compression_ratio": 1.682170542635659, "no_speech_prob": 0.001198787591420114}, {"id": 230, "seek": 91636, "start": 919.52, "end": 925.04, "text": " Maybe it's just because your project is community-based and other projects and products out there", "tokens": [50522, 2704, 309, 311, 445, 570, 428, 1716, 307, 1768, 12, 6032, 293, 661, 4455, 293, 3383, 484, 456, 50798], "temperature": 0.0, "avg_logprob": -0.21539241790771485, "compression_ratio": 1.682170542635659, "no_speech_prob": 0.001198787591420114}, {"id": 231, "seek": 91636, "start": 925.04, "end": 929.32, "text": " are like for money and so like you're going to be able to serve the community whereas", "tokens": [50798, 366, 411, 337, 1460, 293, 370, 411, 291, 434, 516, 281, 312, 1075, 281, 4596, 264, 1768, 9735, 51012], "temperature": 0.0, "avg_logprob": -0.21539241790771485, "compression_ratio": 1.682170542635659, "no_speech_prob": 0.001198787591420114}, {"id": 232, "seek": 91636, "start": 929.32, "end": 931.8000000000001, "text": " those alternatives will not.", "tokens": [51012, 729, 20478, 486, 406, 13, 51136], "temperature": 0.0, "avg_logprob": -0.21539241790771485, "compression_ratio": 1.682170542635659, "no_speech_prob": 0.001198787591420114}, {"id": 233, "seek": 91636, "start": 931.8000000000001, "end": 938.2, "text": " So thinking about where your project fits in that landscape is really quite helpful.", "tokens": [51136, 407, 1953, 466, 689, 428, 1716, 9001, 294, 300, 9661, 307, 534, 1596, 4961, 13, 51456], "temperature": 0.0, "avg_logprob": -0.21539241790771485, "compression_ratio": 1.682170542635659, "no_speech_prob": 0.001198787591420114}, {"id": 234, "seek": 91636, "start": 938.2, "end": 941.52, "text": " That leads into why your project exists in the first place.", "tokens": [51456, 663, 6689, 666, 983, 428, 1716, 8198, 294, 264, 700, 1081, 13, 51622], "temperature": 0.0, "avg_logprob": -0.21539241790771485, "compression_ratio": 1.682170542635659, "no_speech_prob": 0.001198787591420114}, {"id": 235, "seek": 91636, "start": 941.52, "end": 945.08, "text": " What value does it deliver?", "tokens": [51622, 708, 2158, 775, 309, 4239, 30, 51800], "temperature": 0.0, "avg_logprob": -0.21539241790771485, "compression_ratio": 1.682170542635659, "no_speech_prob": 0.001198787591420114}, {"id": 236, "seek": 94508, "start": 945.12, "end": 950.48, "text": " Then that puts you in the seat of the user who is actually trying to use your project", "tokens": [50366, 1396, 300, 8137, 291, 294, 264, 6121, 295, 264, 4195, 567, 307, 767, 1382, 281, 764, 428, 1716, 50634], "temperature": 0.0, "avg_logprob": -0.1338559177434333, "compression_ratio": 1.75, "no_speech_prob": 0.00036669251858256757}, {"id": 237, "seek": 94508, "start": 950.48, "end": 953.9200000000001, "text": " and solve those problems they face.", "tokens": [50634, 293, 5039, 729, 2740, 436, 1851, 13, 50806], "temperature": 0.0, "avg_logprob": -0.1338559177434333, "compression_ratio": 1.75, "no_speech_prob": 0.00036669251858256757}, {"id": 238, "seek": 94508, "start": 953.9200000000001, "end": 957.88, "text": " Another question I like to ask around why is the cost of delay.", "tokens": [50806, 3996, 1168, 286, 411, 281, 1029, 926, 983, 307, 264, 2063, 295, 8577, 13, 51004], "temperature": 0.0, "avg_logprob": -0.1338559177434333, "compression_ratio": 1.75, "no_speech_prob": 0.00036669251858256757}, {"id": 239, "seek": 94508, "start": 957.88, "end": 962.96, "text": " So if we don't develop this project now or if we don't iterate on it and provide these", "tokens": [51004, 407, 498, 321, 500, 380, 1499, 341, 1716, 586, 420, 498, 321, 500, 380, 44497, 322, 309, 293, 2893, 613, 51258], "temperature": 0.0, "avg_logprob": -0.1338559177434333, "compression_ratio": 1.75, "no_speech_prob": 0.00036669251858256757}, {"id": 240, "seek": 94508, "start": 962.96, "end": 966.5200000000001, "text": " features of functionality, what bad things happen?", "tokens": [51258, 4122, 295, 14980, 11, 437, 1578, 721, 1051, 30, 51436], "temperature": 0.0, "avg_logprob": -0.1338559177434333, "compression_ratio": 1.75, "no_speech_prob": 0.00036669251858256757}, {"id": 241, "seek": 94508, "start": 966.5200000000001, "end": 968.72, "text": " What bad things happen to our goals?", "tokens": [51436, 708, 1578, 721, 1051, 281, 527, 5493, 30, 51546], "temperature": 0.0, "avg_logprob": -0.1338559177434333, "compression_ratio": 1.75, "no_speech_prob": 0.00036669251858256757}, {"id": 242, "seek": 94508, "start": 968.72, "end": 974.2800000000001, "text": " What bad things happen for users who continue facing this problem without any solution?", "tokens": [51546, 708, 1578, 721, 1051, 337, 5022, 567, 2354, 7170, 341, 1154, 1553, 604, 3827, 30, 51824], "temperature": 0.0, "avg_logprob": -0.1338559177434333, "compression_ratio": 1.75, "no_speech_prob": 0.00036669251858256757}, {"id": 243, "seek": 97428, "start": 974.28, "end": 976.64, "text": " What happens to innovation in general?", "tokens": [50364, 708, 2314, 281, 8504, 294, 2674, 30, 50482], "temperature": 0.0, "avg_logprob": -0.18657324486172078, "compression_ratio": 1.604, "no_speech_prob": 0.002052124124020338}, {"id": 244, "seek": 97428, "start": 976.64, "end": 981.92, "text": " There's really a lot of interesting conversations you can have around cost of delay.", "tokens": [50482, 821, 311, 534, 257, 688, 295, 1880, 7315, 291, 393, 362, 926, 2063, 295, 8577, 13, 50746], "temperature": 0.0, "avg_logprob": -0.18657324486172078, "compression_ratio": 1.604, "no_speech_prob": 0.002052124124020338}, {"id": 245, "seek": 97428, "start": 981.92, "end": 984.88, "text": " Then finally how does it work now?", "tokens": [50746, 1396, 2721, 577, 775, 309, 589, 586, 30, 50894], "temperature": 0.0, "avg_logprob": -0.18657324486172078, "compression_ratio": 1.604, "no_speech_prob": 0.002052124124020338}, {"id": 246, "seek": 97428, "start": 984.88, "end": 989.04, "text": " This question is also a really nice hook for you to think about the future and where you", "tokens": [50894, 639, 1168, 307, 611, 257, 534, 1481, 6328, 337, 291, 281, 519, 466, 264, 2027, 293, 689, 291, 51102], "temperature": 0.0, "avg_logprob": -0.18657324486172078, "compression_ratio": 1.604, "no_speech_prob": 0.002052124124020338}, {"id": 247, "seek": 97428, "start": 989.04, "end": 992.4, "text": " want to be in 12 months or 24 months with it.", "tokens": [51102, 528, 281, 312, 294, 2272, 2493, 420, 4022, 2493, 365, 309, 13, 51270], "temperature": 0.0, "avg_logprob": -0.18657324486172078, "compression_ratio": 1.604, "no_speech_prob": 0.002052124124020338}, {"id": 248, "seek": 97428, "start": 992.4, "end": 998.76, "text": " How do you want to build this to provide different features?", "tokens": [51270, 1012, 360, 291, 528, 281, 1322, 341, 281, 2893, 819, 4122, 30, 51588], "temperature": 0.0, "avg_logprob": -0.18657324486172078, "compression_ratio": 1.604, "no_speech_prob": 0.002052124124020338}, {"id": 249, "seek": 97428, "start": 998.76, "end": 1001.36, "text": " Maybe redesign the architecture to be simpler.", "tokens": [51588, 2704, 39853, 264, 9482, 281, 312, 18587, 13, 51718], "temperature": 0.0, "avg_logprob": -0.18657324486172078, "compression_ratio": 1.604, "no_speech_prob": 0.002052124124020338}, {"id": 250, "seek": 100136, "start": 1001.36, "end": 1007.16, "text": " How do you want to be and how is a good frame for that?", "tokens": [50364, 1012, 360, 291, 528, 281, 312, 293, 577, 307, 257, 665, 3920, 337, 300, 30, 50654], "temperature": 0.0, "avg_logprob": -0.2084055352718272, "compression_ratio": 1.5643153526970954, "no_speech_prob": 0.002836644183844328}, {"id": 251, "seek": 100136, "start": 1007.16, "end": 1012.5600000000001, "text": " I pointed earlier, we're going to cover some more tools and methods.", "tokens": [50654, 286, 10932, 3071, 11, 321, 434, 516, 281, 2060, 512, 544, 3873, 293, 7150, 13, 50924], "temperature": 0.0, "avg_logprob": -0.2084055352718272, "compression_ratio": 1.5643153526970954, "no_speech_prob": 0.002836644183844328}, {"id": 252, "seek": 100136, "start": 1012.5600000000001, "end": 1015.96, "text": " The next one is user research and surveys.", "tokens": [50924, 440, 958, 472, 307, 4195, 2132, 293, 22711, 13, 51094], "temperature": 0.0, "avg_logprob": -0.2084055352718272, "compression_ratio": 1.5643153526970954, "no_speech_prob": 0.002836644183844328}, {"id": 253, "seek": 100136, "start": 1015.96, "end": 1021.6800000000001, "text": " Having as much data as you possibly can really pulls you out of your own biases and what", "tokens": [51094, 10222, 382, 709, 1412, 382, 291, 6264, 393, 534, 16982, 291, 484, 295, 428, 1065, 32152, 293, 437, 51380], "temperature": 0.0, "avg_logprob": -0.2084055352718272, "compression_ratio": 1.5643153526970954, "no_speech_prob": 0.002836644183844328}, {"id": 254, "seek": 100136, "start": 1021.6800000000001, "end": 1025.84, "text": " the developer with the assumption driven development blog post was describing.", "tokens": [51380, 264, 10754, 365, 264, 15302, 9555, 3250, 6968, 2183, 390, 16141, 13, 51588], "temperature": 0.0, "avg_logprob": -0.2084055352718272, "compression_ratio": 1.5643153526970954, "no_speech_prob": 0.002836644183844328}, {"id": 255, "seek": 100136, "start": 1025.84, "end": 1029.04, "text": " I only listened to me and it didn't work.", "tokens": [51588, 286, 787, 13207, 281, 385, 293, 309, 994, 380, 589, 13, 51748], "temperature": 0.0, "avg_logprob": -0.2084055352718272, "compression_ratio": 1.5643153526970954, "no_speech_prob": 0.002836644183844328}, {"id": 256, "seek": 102904, "start": 1029.12, "end": 1036.12, "text": " If you're listening to your prospective users, your current users, other project leaders,", "tokens": [50368, 759, 291, 434, 4764, 281, 428, 39377, 5022, 11, 428, 2190, 5022, 11, 661, 1716, 3523, 11, 50718], "temperature": 0.0, "avg_logprob": -0.1793185615539551, "compression_ratio": 1.6814516129032258, "no_speech_prob": 0.014203882776200771}, {"id": 257, "seek": 102904, "start": 1036.12, "end": 1041.92, "text": " you start to get all these different perspectives that can ultimately help you develop the right", "tokens": [50718, 291, 722, 281, 483, 439, 613, 819, 16766, 300, 393, 6284, 854, 291, 1499, 264, 558, 51008], "temperature": 0.0, "avg_logprob": -0.1793185615539551, "compression_ratio": 1.6814516129032258, "no_speech_prob": 0.014203882776200771}, {"id": 258, "seek": 102904, "start": 1041.92, "end": 1045.8799999999999, "text": " most valuable thing and not develop a lot of other things that are going to take up", "tokens": [51008, 881, 8263, 551, 293, 406, 1499, 257, 688, 295, 661, 721, 300, 366, 516, 281, 747, 493, 51206], "temperature": 0.0, "avg_logprob": -0.1793185615539551, "compression_ratio": 1.6814516129032258, "no_speech_prob": 0.014203882776200771}, {"id": 259, "seek": 102904, "start": 1045.8799999999999, "end": 1052.32, "text": " a lot of effort but maybe won't have such a payoff for you or for anyone else.", "tokens": [51206, 257, 688, 295, 4630, 457, 1310, 1582, 380, 362, 1270, 257, 46547, 337, 291, 420, 337, 2878, 1646, 13, 51528], "temperature": 0.0, "avg_logprob": -0.1793185615539551, "compression_ratio": 1.6814516129032258, "no_speech_prob": 0.014203882776200771}, {"id": 260, "seek": 102904, "start": 1052.32, "end": 1055.2, "text": " Surveys should be kept quick and easy.", "tokens": [51528, 6732, 303, 749, 820, 312, 4305, 1702, 293, 1858, 13, 51672], "temperature": 0.0, "avg_logprob": -0.1793185615539551, "compression_ratio": 1.6814516129032258, "no_speech_prob": 0.014203882776200771}, {"id": 261, "seek": 102904, "start": 1055.2, "end": 1056.72, "text": " I tend to use Google forums.", "tokens": [51672, 286, 3928, 281, 764, 3329, 26998, 13, 51748], "temperature": 0.0, "avg_logprob": -0.1793185615539551, "compression_ratio": 1.6814516129032258, "no_speech_prob": 0.014203882776200771}, {"id": 262, "seek": 105672, "start": 1056.8, "end": 1060.0, "text": " I mean, I know it's not open source but it works.", "tokens": [50368, 286, 914, 11, 286, 458, 309, 311, 406, 1269, 4009, 457, 309, 1985, 13, 50528], "temperature": 0.0, "avg_logprob": -0.24633916219075522, "compression_ratio": 1.7124463519313304, "no_speech_prob": 0.001694809296168387}, {"id": 263, "seek": 105672, "start": 1060.0, "end": 1064.64, "text": " I don't ask people to write a lot because you don't want to read at all.", "tokens": [50528, 286, 500, 380, 1029, 561, 281, 2464, 257, 688, 570, 291, 500, 380, 528, 281, 1401, 412, 439, 13, 50760], "temperature": 0.0, "avg_logprob": -0.24633916219075522, "compression_ratio": 1.7124463519313304, "no_speech_prob": 0.001694809296168387}, {"id": 264, "seek": 105672, "start": 1064.64, "end": 1069.72, "text": " You probably don't have time to read lots and lots of survey responses.", "tokens": [50760, 509, 1391, 500, 380, 362, 565, 281, 1401, 3195, 293, 3195, 295, 8984, 13019, 13, 51014], "temperature": 0.0, "avg_logprob": -0.24633916219075522, "compression_ratio": 1.7124463519313304, "no_speech_prob": 0.001694809296168387}, {"id": 265, "seek": 105672, "start": 1069.72, "end": 1074.4, "text": " The survey respondents also probably don't have a lot of time to fill out lots of forms.", "tokens": [51014, 440, 8984, 48275, 611, 1391, 500, 380, 362, 257, 688, 295, 565, 281, 2836, 484, 3195, 295, 6422, 13, 51248], "temperature": 0.0, "avg_logprob": -0.24633916219075522, "compression_ratio": 1.7124463519313304, "no_speech_prob": 0.001694809296168387}, {"id": 266, "seek": 105672, "start": 1074.4, "end": 1082.08, "text": " Using check boxes, multiple choice, rating options from zero to five or whatever you", "tokens": [51248, 11142, 1520, 9002, 11, 3866, 3922, 11, 10990, 3956, 490, 4018, 281, 1732, 420, 2035, 291, 51632], "temperature": 0.0, "avg_logprob": -0.24633916219075522, "compression_ratio": 1.7124463519313304, "no_speech_prob": 0.001694809296168387}, {"id": 267, "seek": 105672, "start": 1082.08, "end": 1085.04, "text": " want to set is your endpoints.", "tokens": [51632, 528, 281, 992, 307, 428, 917, 20552, 13, 51780], "temperature": 0.0, "avg_logprob": -0.24633916219075522, "compression_ratio": 1.7124463519313304, "no_speech_prob": 0.001694809296168387}, {"id": 268, "seek": 108504, "start": 1085.04, "end": 1089.76, "text": " You have numeric data that you can quickly turn into charts like this one which was from", "tokens": [50364, 509, 362, 7866, 299, 1412, 300, 291, 393, 2661, 1261, 666, 17767, 411, 341, 472, 597, 390, 490, 50600], "temperature": 0.0, "avg_logprob": -0.21893404970074645, "compression_ratio": 1.5984251968503937, "no_speech_prob": 0.0027905285824090242}, {"id": 269, "seek": 108504, "start": 1089.76, "end": 1096.08, "text": " a Google survey and it's just easy to make a chart out of the results.", "tokens": [50600, 257, 3329, 8984, 293, 309, 311, 445, 1858, 281, 652, 257, 6927, 484, 295, 264, 3542, 13, 50916], "temperature": 0.0, "avg_logprob": -0.21893404970074645, "compression_ratio": 1.5984251968503937, "no_speech_prob": 0.0027905285824090242}, {"id": 270, "seek": 108504, "start": 1096.08, "end": 1100.24, "text": " Another thing I like to remind people of is Please Buy by GDPR.", "tokens": [50916, 3996, 551, 286, 411, 281, 4160, 561, 295, 307, 2555, 19146, 538, 19599, 49, 13, 51124], "temperature": 0.0, "avg_logprob": -0.21893404970074645, "compression_ratio": 1.5984251968503937, "no_speech_prob": 0.0027905285824090242}, {"id": 271, "seek": 108504, "start": 1100.24, "end": 1104.52, "text": " Be careful about how you're collecting the data of the people who are filling out your", "tokens": [51124, 879, 5026, 466, 577, 291, 434, 12510, 264, 1412, 295, 264, 561, 567, 366, 10623, 484, 428, 51338], "temperature": 0.0, "avg_logprob": -0.21893404970074645, "compression_ratio": 1.5984251968503937, "no_speech_prob": 0.0027905285824090242}, {"id": 272, "seek": 108504, "start": 1104.52, "end": 1105.68, "text": " survey.", "tokens": [51338, 8984, 13, 51396], "temperature": 0.0, "avg_logprob": -0.21893404970074645, "compression_ratio": 1.5984251968503937, "no_speech_prob": 0.0027905285824090242}, {"id": 273, "seek": 108504, "start": 1105.68, "end": 1111.92, "text": " Make sure they offer their consent before you offer them a chance to give them, to give", "tokens": [51396, 4387, 988, 436, 2626, 641, 14546, 949, 291, 2626, 552, 257, 2931, 281, 976, 552, 11, 281, 976, 51708], "temperature": 0.0, "avg_logprob": -0.21893404970074645, "compression_ratio": 1.5984251968503937, "no_speech_prob": 0.0027905285824090242}, {"id": 274, "seek": 111192, "start": 1111.92, "end": 1117.3200000000002, "text": " consent for usage of your data before they move on.", "tokens": [50364, 14546, 337, 14924, 295, 428, 1412, 949, 436, 1286, 322, 13, 50634], "temperature": 0.0, "avg_logprob": -0.1550564253625791, "compression_ratio": 1.6293706293706294, "no_speech_prob": 0.001847619190812111}, {"id": 275, "seek": 111192, "start": 1117.3200000000002, "end": 1120.68, "text": " Another great way to collect user data is through discussions.", "tokens": [50634, 3996, 869, 636, 281, 2500, 4195, 1412, 307, 807, 11088, 13, 50802], "temperature": 0.0, "avg_logprob": -0.1550564253625791, "compression_ratio": 1.6293706293706294, "no_speech_prob": 0.001847619190812111}, {"id": 276, "seek": 111192, "start": 1120.68, "end": 1126.76, "text": " Like on GitHub, you can post a question and see people respond to it.", "tokens": [50802, 1743, 322, 23331, 11, 291, 393, 2183, 257, 1168, 293, 536, 561, 4196, 281, 309, 13, 51106], "temperature": 0.0, "avg_logprob": -0.1550564253625791, "compression_ratio": 1.6293706293706294, "no_speech_prob": 0.001847619190812111}, {"id": 277, "seek": 111192, "start": 1126.76, "end": 1129.72, "text": " That can be a little more time consuming because you're going to have to read through all of", "tokens": [51106, 663, 393, 312, 257, 707, 544, 565, 19867, 570, 291, 434, 516, 281, 362, 281, 1401, 807, 439, 295, 51254], "temperature": 0.0, "avg_logprob": -0.1550564253625791, "compression_ratio": 1.6293706293706294, "no_speech_prob": 0.001847619190812111}, {"id": 278, "seek": 111192, "start": 1129.72, "end": 1131.1200000000001, "text": " those answers.", "tokens": [51254, 729, 6338, 13, 51324], "temperature": 0.0, "avg_logprob": -0.1550564253625791, "compression_ratio": 1.6293706293706294, "no_speech_prob": 0.001847619190812111}, {"id": 279, "seek": 111192, "start": 1131.1200000000001, "end": 1135.68, "text": " But it can be quite useful too because you get broader context.", "tokens": [51324, 583, 309, 393, 312, 1596, 4420, 886, 570, 291, 483, 13227, 4319, 13, 51552], "temperature": 0.0, "avg_logprob": -0.1550564253625791, "compression_ratio": 1.6293706293706294, "no_speech_prob": 0.001847619190812111}, {"id": 280, "seek": 111192, "start": 1135.68, "end": 1139.3200000000002, "text": " If you're in a hurry and you just say, hey, community, I want to know if you want us to", "tokens": [51552, 759, 291, 434, 294, 257, 11025, 293, 291, 445, 584, 11, 4177, 11, 1768, 11, 286, 528, 281, 458, 498, 291, 528, 505, 281, 51734], "temperature": 0.0, "avg_logprob": -0.1550564253625791, "compression_ratio": 1.6293706293706294, "no_speech_prob": 0.001847619190812111}, {"id": 281, "seek": 111192, "start": 1139.3200000000002, "end": 1140.48, "text": " do this thing or not.", "tokens": [51734, 360, 341, 551, 420, 406, 13, 51792], "temperature": 0.0, "avg_logprob": -0.1550564253625791, "compression_ratio": 1.6293706293706294, "no_speech_prob": 0.001847619190812111}, {"id": 282, "seek": 114048, "start": 1140.48, "end": 1144.56, "text": " You can send out an issue and have them give it a plus one or not.", "tokens": [50364, 509, 393, 2845, 484, 364, 2734, 293, 362, 552, 976, 309, 257, 1804, 472, 420, 406, 13, 50568], "temperature": 0.0, "avg_logprob": -0.1984614474432809, "compression_ratio": 1.6436781609195403, "no_speech_prob": 0.016595663502812386}, {"id": 283, "seek": 114048, "start": 1144.56, "end": 1148.0, "text": " You can use emoticons, this like votes.", "tokens": [50568, 509, 393, 764, 3626, 299, 892, 11, 341, 411, 12068, 13, 50740], "temperature": 0.0, "avg_logprob": -0.1984614474432809, "compression_ratio": 1.6436781609195403, "no_speech_prob": 0.016595663502812386}, {"id": 284, "seek": 114048, "start": 1148.0, "end": 1152.64, "text": " There's other tools out there that product managers use all the time like AHA that offer", "tokens": [50740, 821, 311, 661, 3873, 484, 456, 300, 1674, 14084, 764, 439, 264, 565, 411, 316, 4983, 300, 2626, 50972], "temperature": 0.0, "avg_logprob": -0.1984614474432809, "compression_ratio": 1.6436781609195403, "no_speech_prob": 0.016595663502812386}, {"id": 285, "seek": 114048, "start": 1152.64, "end": 1156.72, "text": " this kind of voting functionality for feature ideas.", "tokens": [50972, 341, 733, 295, 10419, 14980, 337, 4111, 3487, 13, 51176], "temperature": 0.0, "avg_logprob": -0.1984614474432809, "compression_ratio": 1.6436781609195403, "no_speech_prob": 0.016595663502812386}, {"id": 286, "seek": 114048, "start": 1156.72, "end": 1161.8, "text": " And finally, interviews which are really can be quite time consuming.", "tokens": [51176, 400, 2721, 11, 12318, 597, 366, 534, 393, 312, 1596, 565, 19867, 13, 51430], "temperature": 0.0, "avg_logprob": -0.1984614474432809, "compression_ratio": 1.6436781609195403, "no_speech_prob": 0.016595663502812386}, {"id": 287, "seek": 114048, "start": 1161.8, "end": 1165.2, "text": " But if you have the time to do them, you can even just do a few.", "tokens": [51430, 583, 498, 291, 362, 264, 565, 281, 360, 552, 11, 291, 393, 754, 445, 360, 257, 1326, 13, 51600], "temperature": 0.0, "avg_logprob": -0.1984614474432809, "compression_ratio": 1.6436781609195403, "no_speech_prob": 0.016595663502812386}, {"id": 288, "seek": 114048, "start": 1165.2, "end": 1168.8, "text": " You can learn so much about your own project.", "tokens": [51600, 509, 393, 1466, 370, 709, 466, 428, 1065, 1716, 13, 51780], "temperature": 0.0, "avg_logprob": -0.1984614474432809, "compression_ratio": 1.6436781609195403, "no_speech_prob": 0.016595663502812386}, {"id": 289, "seek": 116880, "start": 1168.8, "end": 1173.12, "text": " You can sit and watch somebody try to use it and see where they get stuck, see what's", "tokens": [50364, 509, 393, 1394, 293, 1159, 2618, 853, 281, 764, 309, 293, 536, 689, 436, 483, 5541, 11, 536, 437, 311, 50580], "temperature": 0.0, "avg_logprob": -0.21536715395815736, "compression_ratio": 1.5805243445692885, "no_speech_prob": 0.00662565603852272}, {"id": 290, "seek": 116880, "start": 1173.12, "end": 1179.2, "text": " confusing to them, and collect all of that data and think of ways to optimize and improve.", "tokens": [50580, 13181, 281, 552, 11, 293, 2500, 439, 295, 300, 1412, 293, 519, 295, 2098, 281, 19719, 293, 3470, 13, 50884], "temperature": 0.0, "avg_logprob": -0.21536715395815736, "compression_ratio": 1.5805243445692885, "no_speech_prob": 0.00662565603852272}, {"id": 291, "seek": 116880, "start": 1179.2, "end": 1181.32, "text": " Oh, I forgot.", "tokens": [50884, 876, 11, 286, 5298, 13, 50990], "temperature": 0.0, "avg_logprob": -0.21536715395815736, "compression_ratio": 1.5805243445692885, "no_speech_prob": 0.00662565603852272}, {"id": 292, "seek": 116880, "start": 1181.32, "end": 1184.6399999999999, "text": " This is a really important point to ask them.", "tokens": [50990, 639, 307, 257, 534, 1021, 935, 281, 1029, 552, 13, 51156], "temperature": 0.0, "avg_logprob": -0.21536715395815736, "compression_ratio": 1.5805243445692885, "no_speech_prob": 0.00662565603852272}, {"id": 293, "seek": 116880, "start": 1184.6399999999999, "end": 1189.72, "text": " With the results, a lot of times when people fill out surveys, it's numbers, so it's all", "tokens": [51156, 2022, 264, 3542, 11, 257, 688, 295, 1413, 562, 561, 2836, 484, 22711, 11, 309, 311, 3547, 11, 370, 309, 311, 439, 51410], "temperature": 0.0, "avg_logprob": -0.21536715395815736, "compression_ratio": 1.5805243445692885, "no_speech_prob": 0.00662565603852272}, {"id": 294, "seek": 116880, "start": 1189.72, "end": 1190.72, "text": " scientific.", "tokens": [51410, 8134, 13, 51460], "temperature": 0.0, "avg_logprob": -0.21536715395815736, "compression_ratio": 1.5805243445692885, "no_speech_prob": 0.00662565603852272}, {"id": 295, "seek": 116880, "start": 1190.72, "end": 1196.72, "text": " But it often isn't because our users may be giving their feedback from a limited set", "tokens": [51460, 583, 309, 2049, 1943, 380, 570, 527, 5022, 815, 312, 2902, 641, 5824, 490, 257, 5567, 992, 51760], "temperature": 0.0, "avg_logprob": -0.21536715395815736, "compression_ratio": 1.5805243445692885, "no_speech_prob": 0.00662565603852272}, {"id": 296, "seek": 119672, "start": 1196.72, "end": 1200.8, "text": " of data points themselves because they may not be aware of all the alternatives, all", "tokens": [50364, 295, 1412, 2793, 2969, 570, 436, 815, 406, 312, 3650, 295, 439, 264, 20478, 11, 439, 50568], "temperature": 0.0, "avg_logprob": -0.14573521767893144, "compression_ratio": 1.88339222614841, "no_speech_prob": 0.014865417033433914}, {"id": 297, "seek": 119672, "start": 1200.8, "end": 1202.88, "text": " the directions that your project can take.", "tokens": [50568, 264, 11095, 300, 428, 1716, 393, 747, 13, 50672], "temperature": 0.0, "avg_logprob": -0.14573521767893144, "compression_ratio": 1.88339222614841, "no_speech_prob": 0.014865417033433914}, {"id": 298, "seek": 119672, "start": 1202.88, "end": 1206.88, "text": " They may not have a full understanding of the functionality because they don't have", "tokens": [50672, 814, 815, 406, 362, 257, 1577, 3701, 295, 264, 14980, 570, 436, 500, 380, 362, 50872], "temperature": 0.0, "avg_logprob": -0.14573521767893144, "compression_ratio": 1.88339222614841, "no_speech_prob": 0.014865417033433914}, {"id": 299, "seek": 119672, "start": 1206.88, "end": 1209.2, "text": " time or maybe you didn't explain it well.", "tokens": [50872, 565, 420, 1310, 291, 994, 380, 2903, 309, 731, 13, 50988], "temperature": 0.0, "avg_logprob": -0.14573521767893144, "compression_ratio": 1.88339222614841, "no_speech_prob": 0.014865417033433914}, {"id": 300, "seek": 119672, "start": 1209.2, "end": 1214.3600000000001, "text": " So always be aware that just when somebody tells you what they want, they may not actually", "tokens": [50988, 407, 1009, 312, 3650, 300, 445, 562, 2618, 5112, 291, 437, 436, 528, 11, 436, 815, 406, 767, 51246], "temperature": 0.0, "avg_logprob": -0.14573521767893144, "compression_ratio": 1.88339222614841, "no_speech_prob": 0.014865417033433914}, {"id": 301, "seek": 119672, "start": 1214.3600000000001, "end": 1216.84, "text": " want that thing.", "tokens": [51246, 528, 300, 551, 13, 51370], "temperature": 0.0, "avg_logprob": -0.14573521767893144, "compression_ratio": 1.88339222614841, "no_speech_prob": 0.014865417033433914}, {"id": 302, "seek": 119672, "start": 1216.84, "end": 1221.4, "text": " That may be the best guess that they have that would solve their problem, but actually", "tokens": [51370, 663, 815, 312, 264, 1151, 2041, 300, 436, 362, 300, 576, 5039, 641, 1154, 11, 457, 767, 51598], "temperature": 0.0, "avg_logprob": -0.14573521767893144, "compression_ratio": 1.88339222614841, "no_speech_prob": 0.014865417033433914}, {"id": 303, "seek": 119672, "start": 1221.4, "end": 1226.48, "text": " in the broader context of other types of users, it wouldn't solve the problem in the", "tokens": [51598, 294, 264, 13227, 4319, 295, 661, 3467, 295, 5022, 11, 309, 2759, 380, 5039, 264, 1154, 294, 264, 51852], "temperature": 0.0, "avg_logprob": -0.14573521767893144, "compression_ratio": 1.88339222614841, "no_speech_prob": 0.014865417033433914}, {"id": 304, "seek": 122648, "start": 1226.48, "end": 1227.48, "text": " best way.", "tokens": [50364, 1151, 636, 13, 50414], "temperature": 0.0, "avg_logprob": -0.1565789552492516, "compression_ratio": 1.6224066390041494, "no_speech_prob": 0.001464885426685214}, {"id": 305, "seek": 122648, "start": 1227.48, "end": 1235.08, "text": " So just keep that in mind that data can also be a little bit of a trap if not used carefully.", "tokens": [50414, 407, 445, 1066, 300, 294, 1575, 300, 1412, 393, 611, 312, 257, 707, 857, 295, 257, 11487, 498, 406, 1143, 7500, 13, 50794], "temperature": 0.0, "avg_logprob": -0.1565789552492516, "compression_ratio": 1.6224066390041494, "no_speech_prob": 0.001464885426685214}, {"id": 306, "seek": 122648, "start": 1235.08, "end": 1238.8, "text": " I want to give this example of a survey that you can run very quickly.", "tokens": [50794, 286, 528, 281, 976, 341, 1365, 295, 257, 8984, 300, 291, 393, 1190, 588, 2661, 13, 50980], "temperature": 0.0, "avg_logprob": -0.1565789552492516, "compression_ratio": 1.6224066390041494, "no_speech_prob": 0.001464885426685214}, {"id": 307, "seek": 122648, "start": 1238.8, "end": 1244.04, "text": " If you don't have time to set up a forum yourself, lots of questions, you can still", "tokens": [50980, 759, 291, 500, 380, 362, 565, 281, 992, 493, 257, 17542, 1803, 11, 3195, 295, 1651, 11, 291, 393, 920, 51242], "temperature": 0.0, "avg_logprob": -0.1565789552492516, "compression_ratio": 1.6224066390041494, "no_speech_prob": 0.001464885426685214}, {"id": 308, "seek": 122648, "start": 1244.04, "end": 1246.6, "text": " do an NPS survey.", "tokens": [51242, 360, 364, 426, 6273, 8984, 13, 51370], "temperature": 0.0, "avg_logprob": -0.1565789552492516, "compression_ratio": 1.6224066390041494, "no_speech_prob": 0.001464885426685214}, {"id": 309, "seek": 122648, "start": 1246.6, "end": 1250.76, "text": " This is used by lots of companies, but it's quite useful in our context because it just", "tokens": [51370, 639, 307, 1143, 538, 3195, 295, 3431, 11, 457, 309, 311, 1596, 4420, 294, 527, 4319, 570, 309, 445, 51578], "temperature": 0.0, "avg_logprob": -0.1565789552492516, "compression_ratio": 1.6224066390041494, "no_speech_prob": 0.001464885426685214}, {"id": 310, "seek": 122648, "start": 1250.76, "end": 1252.4, "text": " consists of two questions.", "tokens": [51578, 14689, 295, 732, 1651, 13, 51660], "temperature": 0.0, "avg_logprob": -0.1565789552492516, "compression_ratio": 1.6224066390041494, "no_speech_prob": 0.001464885426685214}, {"id": 311, "seek": 125240, "start": 1253.1200000000001, "end": 1257.5600000000002, "text": " Basically would you recommend my project in this case to a friend or colleague?", "tokens": [50400, 8537, 576, 291, 2748, 452, 1716, 294, 341, 1389, 281, 257, 1277, 420, 13532, 30, 50622], "temperature": 0.0, "avg_logprob": -0.21193771039025258, "compression_ratio": 1.5955882352941178, "no_speech_prob": 0.013960709795355797}, {"id": 312, "seek": 125240, "start": 1257.5600000000002, "end": 1261.24, "text": " And then can you please explain why you gave that score?", "tokens": [50622, 400, 550, 393, 291, 1767, 2903, 983, 291, 2729, 300, 6175, 30, 50806], "temperature": 0.0, "avg_logprob": -0.21193771039025258, "compression_ratio": 1.5955882352941178, "no_speech_prob": 0.013960709795355797}, {"id": 313, "seek": 125240, "start": 1261.24, "end": 1263.2, "text": " So the number is very easy.", "tokens": [50806, 407, 264, 1230, 307, 588, 1858, 13, 50904], "temperature": 0.0, "avg_logprob": -0.21193771039025258, "compression_ratio": 1.5955882352941178, "no_speech_prob": 0.013960709795355797}, {"id": 314, "seek": 125240, "start": 1263.2, "end": 1267.68, "text": " You have to put it in some kind of NPS calculator, so I gave you a link to one.", "tokens": [50904, 509, 362, 281, 829, 309, 294, 512, 733, 295, 426, 6273, 24993, 11, 370, 286, 2729, 291, 257, 2113, 281, 472, 13, 51128], "temperature": 0.0, "avg_logprob": -0.21193771039025258, "compression_ratio": 1.5955882352941178, "no_speech_prob": 0.013960709795355797}, {"id": 315, "seek": 125240, "start": 1267.68, "end": 1269.3600000000001, "text": " It's also the image source.", "tokens": [51128, 467, 311, 611, 264, 3256, 4009, 13, 51212], "temperature": 0.0, "avg_logprob": -0.21193771039025258, "compression_ratio": 1.5955882352941178, "no_speech_prob": 0.013960709795355797}, {"id": 316, "seek": 125240, "start": 1269.3600000000001, "end": 1272.5600000000002, "text": " You basically put in all that data and then you come up with your NPS.", "tokens": [51212, 509, 1936, 829, 294, 439, 300, 1412, 293, 550, 291, 808, 493, 365, 428, 426, 6273, 13, 51372], "temperature": 0.0, "avg_logprob": -0.21193771039025258, "compression_ratio": 1.5955882352941178, "no_speech_prob": 0.013960709795355797}, {"id": 317, "seek": 125240, "start": 1272.5600000000002, "end": 1278.0, "text": " And then there's different analyses online for like what is a good score, usually it's", "tokens": [51372, 400, 550, 456, 311, 819, 37560, 2950, 337, 411, 437, 307, 257, 665, 6175, 11, 2673, 309, 311, 51644], "temperature": 0.0, "avg_logprob": -0.21193771039025258, "compression_ratio": 1.5955882352941178, "no_speech_prob": 0.013960709795355797}, {"id": 318, "seek": 125240, "start": 1278.0, "end": 1279.0, "text": " 20.", "tokens": [51644, 945, 13, 51694], "temperature": 0.0, "avg_logprob": -0.21193771039025258, "compression_ratio": 1.5955882352941178, "no_speech_prob": 0.013960709795355797}, {"id": 319, "seek": 127900, "start": 1279.6, "end": 1282.0, "text": " When you're 50 to 80, you're doing really well.", "tokens": [50394, 1133, 291, 434, 2625, 281, 4688, 11, 291, 434, 884, 534, 731, 13, 50514], "temperature": 0.0, "avg_logprob": -0.2411127192999727, "compression_ratio": 1.5265486725663717, "no_speech_prob": 0.0009177451720461249}, {"id": 320, "seek": 127900, "start": 1282.0, "end": 1286.24, "text": " So that's from the way that the score is calculated.", "tokens": [50514, 407, 300, 311, 490, 264, 636, 300, 264, 6175, 307, 15598, 13, 50726], "temperature": 0.0, "avg_logprob": -0.2411127192999727, "compression_ratio": 1.5265486725663717, "no_speech_prob": 0.0009177451720461249}, {"id": 321, "seek": 127900, "start": 1286.24, "end": 1290.28, "text": " It's a pretty low overhead way to collect feedback.", "tokens": [50726, 467, 311, 257, 1238, 2295, 19922, 636, 281, 2500, 5824, 13, 50928], "temperature": 0.0, "avg_logprob": -0.2411127192999727, "compression_ratio": 1.5265486725663717, "no_speech_prob": 0.0009177451720461249}, {"id": 322, "seek": 127900, "start": 1290.28, "end": 1293.96, "text": " Are we on the right track or not?", "tokens": [50928, 2014, 321, 322, 264, 558, 2837, 420, 406, 30, 51112], "temperature": 0.0, "avg_logprob": -0.2411127192999727, "compression_ratio": 1.5265486725663717, "no_speech_prob": 0.0009177451720461249}, {"id": 323, "seek": 127900, "start": 1293.96, "end": 1300.04, "text": " I mentioned also the next type of tool I want to show you and that's explained with this", "tokens": [51112, 286, 2835, 611, 264, 958, 2010, 295, 2290, 286, 528, 281, 855, 291, 293, 300, 311, 8825, 365, 341, 51416], "temperature": 0.0, "avg_logprob": -0.2411127192999727, "compression_ratio": 1.5265486725663717, "no_speech_prob": 0.0009177451720461249}, {"id": 324, "seek": 127900, "start": 1300.04, "end": 1304.12, "text": " roadmap template which you can adapt to your own needs if you'd like.", "tokens": [51416, 35738, 12379, 597, 291, 393, 6231, 281, 428, 1065, 2203, 498, 291, 1116, 411, 13, 51620], "temperature": 0.0, "avg_logprob": -0.2411127192999727, "compression_ratio": 1.5265486725663717, "no_speech_prob": 0.0009177451720461249}, {"id": 325, "seek": 130412, "start": 1304.12, "end": 1309.52, "text": " I cover some of the who, what, when, where, why questions that I covered with the strategy", "tokens": [50364, 286, 2060, 512, 295, 264, 567, 11, 437, 11, 562, 11, 689, 11, 983, 1651, 300, 286, 5343, 365, 264, 5206, 50634], "temperature": 0.0, "avg_logprob": -0.19189224243164063, "compression_ratio": 1.62109375, "no_speech_prob": 0.012656031176447868}, {"id": 326, "seek": 130412, "start": 1309.52, "end": 1310.6799999999998, "text": " doc template.", "tokens": [50634, 3211, 12379, 13, 50692], "temperature": 0.0, "avg_logprob": -0.19189224243164063, "compression_ratio": 1.62109375, "no_speech_prob": 0.012656031176447868}, {"id": 327, "seek": 130412, "start": 1310.6799999999998, "end": 1313.8799999999999, "text": " But the roadmap is more of the short term.", "tokens": [50692, 583, 264, 35738, 307, 544, 295, 264, 2099, 1433, 13, 50852], "temperature": 0.0, "avg_logprob": -0.19189224243164063, "compression_ratio": 1.62109375, "no_speech_prob": 0.012656031176447868}, {"id": 328, "seek": 130412, "start": 1313.8799999999999, "end": 1317.3999999999999, "text": " What would you like to do in your next, say, three to six months?", "tokens": [50852, 708, 576, 291, 411, 281, 360, 294, 428, 958, 11, 584, 11, 1045, 281, 2309, 2493, 30, 51028], "temperature": 0.0, "avg_logprob": -0.19189224243164063, "compression_ratio": 1.62109375, "no_speech_prob": 0.012656031176447868}, {"id": 329, "seek": 130412, "start": 1317.3999999999999, "end": 1322.0, "text": " It's taking a slice of your strategy into getting you more focused around what you want", "tokens": [51028, 467, 311, 1940, 257, 13153, 295, 428, 5206, 666, 1242, 291, 544, 5178, 926, 437, 291, 528, 51258], "temperature": 0.0, "avg_logprob": -0.19189224243164063, "compression_ratio": 1.62109375, "no_speech_prob": 0.012656031176447868}, {"id": 330, "seek": 130412, "start": 1322.0, "end": 1325.1999999999998, "text": " to develop now.", "tokens": [51258, 281, 1499, 586, 13, 51418], "temperature": 0.0, "avg_logprob": -0.19189224243164063, "compression_ratio": 1.62109375, "no_speech_prob": 0.012656031176447868}, {"id": 331, "seek": 130412, "start": 1325.1999999999998, "end": 1329.04, "text": " My strong recommendation is to keep it to a page or less so that people can actually", "tokens": [51418, 1222, 2068, 11879, 307, 281, 1066, 309, 281, 257, 3028, 420, 1570, 370, 300, 561, 393, 767, 51610], "temperature": 0.0, "avg_logprob": -0.19189224243164063, "compression_ratio": 1.62109375, "no_speech_prob": 0.012656031176447868}, {"id": 332, "seek": 130412, "start": 1329.04, "end": 1330.36, "text": " remember it.", "tokens": [51610, 1604, 309, 13, 51676], "temperature": 0.0, "avg_logprob": -0.19189224243164063, "compression_ratio": 1.62109375, "no_speech_prob": 0.012656031176447868}, {"id": 333, "seek": 133036, "start": 1330.36, "end": 1337.6, "text": " Keep the number of deliverables and goals low, like one for three max, using a metric", "tokens": [50364, 5527, 264, 1230, 295, 4239, 2965, 293, 5493, 2295, 11, 411, 472, 337, 1045, 11469, 11, 1228, 257, 20678, 50726], "temperature": 0.0, "avg_logprob": -0.1655485341837118, "compression_ratio": 1.6330275229357798, "no_speech_prob": 0.02668069489300251}, {"id": 334, "seek": 133036, "start": 1337.6, "end": 1340.52, "text": " to justify why it's necessary.", "tokens": [50726, 281, 20833, 983, 309, 311, 4818, 13, 50872], "temperature": 0.0, "avg_logprob": -0.1655485341837118, "compression_ratio": 1.6330275229357798, "no_speech_prob": 0.02668069489300251}, {"id": 335, "seek": 133036, "start": 1340.52, "end": 1345.1999999999998, "text": " If you don't have a metric, like a baseline to say like we're doing this deliverable because", "tokens": [50872, 759, 291, 500, 380, 362, 257, 20678, 11, 411, 257, 20518, 281, 584, 411, 321, 434, 884, 341, 4239, 712, 570, 51106], "temperature": 0.0, "avg_logprob": -0.1655485341837118, "compression_ratio": 1.6330275229357798, "no_speech_prob": 0.02668069489300251}, {"id": 336, "seek": 133036, "start": 1345.1999999999998, "end": 1351.36, "text": " X number of users want it, then you can also think about the metric that you want to apply", "tokens": [51106, 1783, 1230, 295, 5022, 528, 309, 11, 550, 291, 393, 611, 519, 466, 264, 20678, 300, 291, 528, 281, 3079, 51414], "temperature": 0.0, "avg_logprob": -0.1655485341837118, "compression_ratio": 1.6330275229357798, "no_speech_prob": 0.02668069489300251}, {"id": 337, "seek": 133036, "start": 1351.36, "end": 1357.6, "text": " to then be able to measure the success of your feature.", "tokens": [51414, 281, 550, 312, 1075, 281, 3481, 264, 2245, 295, 428, 4111, 13, 51726], "temperature": 0.0, "avg_logprob": -0.1655485341837118, "compression_ratio": 1.6330275229357798, "no_speech_prob": 0.02668069489300251}, {"id": 338, "seek": 135760, "start": 1357.6, "end": 1362.1599999999999, "text": " I always like to include risks, like what is known, what is unknown in a roadmap, just", "tokens": [50364, 286, 1009, 411, 281, 4090, 10888, 11, 411, 437, 307, 2570, 11, 437, 307, 9841, 294, 257, 35738, 11, 445, 50592], "temperature": 0.0, "avg_logprob": -0.16752268102047216, "compression_ratio": 1.760797342192691, "no_speech_prob": 0.022812495008111}, {"id": 339, "seek": 135760, "start": 1362.1599999999999, "end": 1367.6399999999999, "text": " so that with the unknowns you can plan that it might take away time from the future development.", "tokens": [50592, 370, 300, 365, 264, 46048, 291, 393, 1393, 300, 309, 1062, 747, 1314, 565, 490, 264, 2027, 3250, 13, 50866], "temperature": 0.0, "avg_logprob": -0.16752268102047216, "compression_ratio": 1.760797342192691, "no_speech_prob": 0.022812495008111}, {"id": 340, "seek": 135760, "start": 1367.6399999999999, "end": 1371.08, "text": " So it might be a bit of a distraction, but you at least are aware of it and you're going", "tokens": [50866, 407, 309, 1062, 312, 257, 857, 295, 257, 30217, 11, 457, 291, 412, 1935, 366, 3650, 295, 309, 293, 291, 434, 516, 51038], "temperature": 0.0, "avg_logprob": -0.16752268102047216, "compression_ratio": 1.760797342192691, "no_speech_prob": 0.022812495008111}, {"id": 341, "seek": 135760, "start": 1371.08, "end": 1374.48, "text": " to have to work it out in the future as you go.", "tokens": [51038, 281, 362, 281, 589, 309, 484, 294, 264, 2027, 382, 291, 352, 13, 51208], "temperature": 0.0, "avg_logprob": -0.16752268102047216, "compression_ratio": 1.760797342192691, "no_speech_prob": 0.022812495008111}, {"id": 342, "seek": 135760, "start": 1374.48, "end": 1375.48, "text": " And then technical goals.", "tokens": [51208, 400, 550, 6191, 5493, 13, 51258], "temperature": 0.0, "avg_logprob": -0.16752268102047216, "compression_ratio": 1.760797342192691, "no_speech_prob": 0.022812495008111}, {"id": 343, "seek": 135760, "start": 1375.48, "end": 1380.6, "text": " And this is like to make sure that quality, observability, testing doesn't fall by the", "tokens": [51258, 400, 341, 307, 411, 281, 652, 988, 300, 3125, 11, 9951, 2310, 11, 4997, 1177, 380, 2100, 538, 264, 51514], "temperature": 0.0, "avg_logprob": -0.16752268102047216, "compression_ratio": 1.760797342192691, "no_speech_prob": 0.022812495008111}, {"id": 344, "seek": 135760, "start": 1380.6, "end": 1381.6, "text": " wayside.", "tokens": [51514, 636, 1812, 13, 51564], "temperature": 0.0, "avg_logprob": -0.16752268102047216, "compression_ratio": 1.760797342192691, "no_speech_prob": 0.022812495008111}, {"id": 345, "seek": 135760, "start": 1381.6, "end": 1386.1999999999998, "text": " I see this happening in a lot of projects and products as well where like all the stuff", "tokens": [51564, 286, 536, 341, 2737, 294, 257, 688, 295, 4455, 293, 3383, 382, 731, 689, 411, 439, 264, 1507, 51794], "temperature": 0.0, "avg_logprob": -0.16752268102047216, "compression_ratio": 1.760797342192691, "no_speech_prob": 0.022812495008111}, {"id": 346, "seek": 138620, "start": 1386.2, "end": 1390.68, "text": " that actually makes the thing run gets pushed to the end and then the engineering team is", "tokens": [50364, 300, 767, 1669, 264, 551, 1190, 2170, 9152, 281, 264, 917, 293, 550, 264, 7043, 1469, 307, 50588], "temperature": 0.0, "avg_logprob": -0.15214174444025214, "compression_ratio": 1.6326530612244898, "no_speech_prob": 0.0027010508347302675}, {"id": 347, "seek": 138620, "start": 1390.68, "end": 1395.92, "text": " stuck with a very patchy problematic system that they want to really fix, but nobody has", "tokens": [50588, 5541, 365, 257, 588, 9972, 88, 19011, 1185, 300, 436, 528, 281, 534, 3191, 11, 457, 5079, 575, 50850], "temperature": 0.0, "avg_logprob": -0.15214174444025214, "compression_ratio": 1.6326530612244898, "no_speech_prob": 0.0027010508347302675}, {"id": 348, "seek": 138620, "start": 1395.92, "end": 1401.4, "text": " a lot of time for them to do so.", "tokens": [50850, 257, 688, 295, 565, 337, 552, 281, 360, 370, 13, 51124], "temperature": 0.0, "avg_logprob": -0.15214174444025214, "compression_ratio": 1.6326530612244898, "no_speech_prob": 0.0027010508347302675}, {"id": 349, "seek": 138620, "start": 1401.4, "end": 1405.16, "text": " The next last couple of slides are just covering prioritization.", "tokens": [51124, 440, 958, 1036, 1916, 295, 9788, 366, 445, 10322, 14846, 2144, 13, 51312], "temperature": 0.0, "avg_logprob": -0.15214174444025214, "compression_ratio": 1.6326530612244898, "no_speech_prob": 0.0027010508347302675}, {"id": 350, "seek": 138620, "start": 1405.16, "end": 1411.56, "text": " So this is a matrix that I like to use because it allows teams to take a stack of issues", "tokens": [51312, 407, 341, 307, 257, 8141, 300, 286, 411, 281, 764, 570, 309, 4045, 5491, 281, 747, 257, 8630, 295, 2663, 51632], "temperature": 0.0, "avg_logprob": -0.15214174444025214, "compression_ratio": 1.6326530612244898, "no_speech_prob": 0.0027010508347302675}, {"id": 351, "seek": 138620, "start": 1411.56, "end": 1414.4, "text": " and then plot them on this matrix.", "tokens": [51632, 293, 550, 7542, 552, 322, 341, 8141, 13, 51774], "temperature": 0.0, "avg_logprob": -0.15214174444025214, "compression_ratio": 1.6326530612244898, "no_speech_prob": 0.0027010508347302675}, {"id": 352, "seek": 141440, "start": 1414.4, "end": 1422.8400000000001, "text": " The matrix asks them to assess tasks, ideas based on the amount of effort along with the", "tokens": [50364, 440, 8141, 8962, 552, 281, 5877, 9608, 11, 3487, 2361, 322, 264, 2372, 295, 4630, 2051, 365, 264, 50786], "temperature": 0.0, "avg_logprob": -0.16368510676365272, "compression_ratio": 1.726530612244898, "no_speech_prob": 0.0024608501698821783}, {"id": 353, "seek": 141440, "start": 1422.8400000000001, "end": 1427.52, "text": " value that they expect to provide for the user once they do the thing.", "tokens": [50786, 2158, 300, 436, 2066, 281, 2893, 337, 264, 4195, 1564, 436, 360, 264, 551, 13, 51020], "temperature": 0.0, "avg_logprob": -0.16368510676365272, "compression_ratio": 1.726530612244898, "no_speech_prob": 0.0024608501698821783}, {"id": 354, "seek": 141440, "start": 1427.52, "end": 1431.0400000000002, "text": " And then this allows the team to see like if they have a lot of things that are high", "tokens": [51020, 400, 550, 341, 4045, 264, 1469, 281, 536, 411, 498, 436, 362, 257, 688, 295, 721, 300, 366, 1090, 51196], "temperature": 0.0, "avg_logprob": -0.16368510676365272, "compression_ratio": 1.726530612244898, "no_speech_prob": 0.0024608501698821783}, {"id": 355, "seek": 141440, "start": 1431.0400000000002, "end": 1436.52, "text": " value but also high effort, then they either need to maybe focus on one of those because", "tokens": [51196, 2158, 457, 611, 1090, 4630, 11, 550, 436, 2139, 643, 281, 1310, 1879, 322, 472, 295, 729, 570, 51470], "temperature": 0.0, "avg_logprob": -0.16368510676365272, "compression_ratio": 1.726530612244898, "no_speech_prob": 0.0024608501698821783}, {"id": 356, "seek": 141440, "start": 1436.52, "end": 1442.88, "text": " they're not going to do like 10 high impact, high effort items at once or break them down", "tokens": [51470, 436, 434, 406, 516, 281, 360, 411, 1266, 1090, 2712, 11, 1090, 4630, 4754, 412, 1564, 420, 1821, 552, 760, 51788], "temperature": 0.0, "avg_logprob": -0.16368510676365272, "compression_ratio": 1.726530612244898, "no_speech_prob": 0.0024608501698821783}, {"id": 357, "seek": 144288, "start": 1442.88, "end": 1447.64, "text": " into smaller bits so that they can then go into the do it now column which is really", "tokens": [50364, 666, 4356, 9239, 370, 300, 436, 393, 550, 352, 666, 264, 360, 309, 586, 7738, 597, 307, 534, 50602], "temperature": 0.0, "avg_logprob": -0.15436270298101964, "compression_ratio": 1.756183745583039, "no_speech_prob": 0.08684141933917999}, {"id": 358, "seek": 144288, "start": 1447.64, "end": 1451.0800000000002, "text": " where your quick wins and your low hanging fruit should go.", "tokens": [50602, 689, 428, 1702, 10641, 293, 428, 2295, 8345, 6773, 820, 352, 13, 50774], "temperature": 0.0, "avg_logprob": -0.15436270298101964, "compression_ratio": 1.756183745583039, "no_speech_prob": 0.08684141933917999}, {"id": 359, "seek": 144288, "start": 1451.0800000000002, "end": 1456.24, "text": " It's really important to plan for those quick wins to have them early on so that you can", "tokens": [50774, 467, 311, 534, 1021, 281, 1393, 337, 729, 1702, 10641, 281, 362, 552, 2440, 322, 370, 300, 291, 393, 51032], "temperature": 0.0, "avg_logprob": -0.15436270298101964, "compression_ratio": 1.756183745583039, "no_speech_prob": 0.08684141933917999}, {"id": 360, "seek": 144288, "start": 1456.24, "end": 1460.88, "text": " collect momentum and the team doesn't feel like they're just in some long slog that they're", "tokens": [51032, 2500, 11244, 293, 264, 1469, 1177, 380, 841, 411, 436, 434, 445, 294, 512, 938, 49760, 300, 436, 434, 51264], "temperature": 0.0, "avg_logprob": -0.15436270298101964, "compression_ratio": 1.756183745583039, "no_speech_prob": 0.08684141933917999}, {"id": 361, "seek": 144288, "start": 1460.88, "end": 1463.68, "text": " never going to see the results of their work.", "tokens": [51264, 1128, 516, 281, 536, 264, 3542, 295, 641, 589, 13, 51404], "temperature": 0.0, "avg_logprob": -0.15436270298101964, "compression_ratio": 1.756183745583039, "no_speech_prob": 0.08684141933917999}, {"id": 362, "seek": 144288, "start": 1463.68, "end": 1469.0, "text": " If you have quick turnaround for impact provided then that's nice because they can celebrate", "tokens": [51404, 759, 291, 362, 1702, 46114, 337, 2712, 5649, 550, 300, 311, 1481, 570, 436, 393, 8098, 51670], "temperature": 0.0, "avg_logprob": -0.15436270298101964, "compression_ratio": 1.756183745583039, "no_speech_prob": 0.08684141933917999}, {"id": 363, "seek": 144288, "start": 1469.0, "end": 1471.96, "text": " those wins early and keep going.", "tokens": [51670, 729, 10641, 2440, 293, 1066, 516, 13, 51818], "temperature": 0.0, "avg_logprob": -0.15436270298101964, "compression_ratio": 1.756183745583039, "no_speech_prob": 0.08684141933917999}, {"id": 364, "seek": 147196, "start": 1471.96, "end": 1477.08, "text": " There's also this nice, this is my favorite box, the don't do it box because that's where", "tokens": [50364, 821, 311, 611, 341, 1481, 11, 341, 307, 452, 2954, 2424, 11, 264, 500, 380, 360, 309, 2424, 570, 300, 311, 689, 50620], "temperature": 0.0, "avg_logprob": -0.16094003072599086, "compression_ratio": 1.737037037037037, "no_speech_prob": 0.02222345769405365}, {"id": 365, "seek": 147196, "start": 1477.08, "end": 1482.3600000000001, "text": " you just like close the issue and forget.", "tokens": [50620, 291, 445, 411, 1998, 264, 2734, 293, 2870, 13, 50884], "temperature": 0.0, "avg_logprob": -0.16094003072599086, "compression_ratio": 1.737037037037037, "no_speech_prob": 0.02222345769405365}, {"id": 366, "seek": 147196, "start": 1482.3600000000001, "end": 1484.3600000000001, "text": " Here's where I use this matrix in action.", "tokens": [50884, 1692, 311, 689, 286, 764, 341, 8141, 294, 3069, 13, 50984], "temperature": 0.0, "avg_logprob": -0.16094003072599086, "compression_ratio": 1.737037037037037, "no_speech_prob": 0.02222345769405365}, {"id": 367, "seek": 147196, "start": 1484.3600000000001, "end": 1486.88, "text": " This is also a security scorecard recently.", "tokens": [50984, 639, 307, 611, 257, 3825, 6175, 22259, 3938, 13, 51110], "temperature": 0.0, "avg_logprob": -0.16094003072599086, "compression_ratio": 1.737037037037037, "no_speech_prob": 0.02222345769405365}, {"id": 368, "seek": 147196, "start": 1486.88, "end": 1490.8400000000001, "text": " We haven't done this exercise yet but I'm really hoping we do it soon.", "tokens": [51110, 492, 2378, 380, 1096, 341, 5380, 1939, 457, 286, 478, 534, 7159, 321, 360, 309, 2321, 13, 51308], "temperature": 0.0, "avg_logprob": -0.16094003072599086, "compression_ratio": 1.737037037037037, "no_speech_prob": 0.02222345769405365}, {"id": 369, "seek": 147196, "start": 1490.8400000000001, "end": 1496.8, "text": " This is basically all the bugs in the backlog and just putting them in specific buckets", "tokens": [51308, 639, 307, 1936, 439, 264, 15120, 294, 264, 47364, 293, 445, 3372, 552, 294, 2685, 32191, 51606], "temperature": 0.0, "avg_logprob": -0.16094003072599086, "compression_ratio": 1.737037037037037, "no_speech_prob": 0.02222345769405365}, {"id": 370, "seek": 147196, "start": 1496.8, "end": 1500.8, "text": " like some of them weren't bugs so that was just really categorizing what's a bug what", "tokens": [51606, 411, 512, 295, 552, 4999, 380, 15120, 370, 300, 390, 445, 534, 19250, 3319, 437, 311, 257, 7426, 437, 51806], "temperature": 0.0, "avg_logprob": -0.16094003072599086, "compression_ratio": 1.737037037037037, "no_speech_prob": 0.02222345769405365}, {"id": 371, "seek": 147196, "start": 1500.8, "end": 1501.8, "text": " isn't.", "tokens": [51806, 1943, 380, 13, 51856], "temperature": 0.0, "avg_logprob": -0.16094003072599086, "compression_ratio": 1.737037037037037, "no_speech_prob": 0.02222345769405365}, {"id": 372, "seek": 150180, "start": 1501.8, "end": 1507.12, "text": " Then the goal here is the team will plot the bugs on this graph and then we might find", "tokens": [50364, 1396, 264, 3387, 510, 307, 264, 1469, 486, 7542, 264, 15120, 322, 341, 4295, 293, 550, 321, 1062, 915, 50630], "temperature": 0.0, "avg_logprob": -0.18792491488986546, "compression_ratio": 1.762962962962963, "no_speech_prob": 0.0002955262316390872}, {"id": 373, "seek": 150180, "start": 1507.12, "end": 1511.36, "text": " out that some of the bugs were solved, maybe some of them are relevant now but it's really", "tokens": [50630, 484, 300, 512, 295, 264, 15120, 645, 13041, 11, 1310, 512, 295, 552, 366, 7340, 586, 457, 309, 311, 534, 50842], "temperature": 0.0, "avg_logprob": -0.18792491488986546, "compression_ratio": 1.762962962962963, "no_speech_prob": 0.0002955262316390872}, {"id": 374, "seek": 150180, "start": 1511.36, "end": 1515.52, "text": " to kick stuff out of the backlog and then just have the focus on what is really important,", "tokens": [50842, 281, 4437, 1507, 484, 295, 264, 47364, 293, 550, 445, 362, 264, 1879, 322, 437, 307, 534, 1021, 11, 51050], "temperature": 0.0, "avg_logprob": -0.18792491488986546, "compression_ratio": 1.762962962962963, "no_speech_prob": 0.0002955262316390872}, {"id": 375, "seek": 150180, "start": 1515.52, "end": 1520.68, "text": " what's really valuable, what are people really being hurt by right now like we should fix", "tokens": [51050, 437, 311, 534, 8263, 11, 437, 366, 561, 534, 885, 4607, 538, 558, 586, 411, 321, 820, 3191, 51308], "temperature": 0.0, "avg_logprob": -0.18792491488986546, "compression_ratio": 1.762962962962963, "no_speech_prob": 0.0002955262316390872}, {"id": 376, "seek": 150180, "start": 1520.68, "end": 1522.48, "text": " right away.", "tokens": [51308, 558, 1314, 13, 51398], "temperature": 0.0, "avg_logprob": -0.18792491488986546, "compression_ratio": 1.762962962962963, "no_speech_prob": 0.0002955262316390872}, {"id": 377, "seek": 150180, "start": 1522.48, "end": 1525.76, "text": " That's basically the steps for how you would apply such a matrix.", "tokens": [51398, 663, 311, 1936, 264, 4439, 337, 577, 291, 576, 3079, 1270, 257, 8141, 13, 51562], "temperature": 0.0, "avg_logprob": -0.18792491488986546, "compression_ratio": 1.762962962962963, "no_speech_prob": 0.0002955262316390872}, {"id": 378, "seek": 150180, "start": 1525.76, "end": 1528.8, "text": " I also encourage using a scoring model.", "tokens": [51562, 286, 611, 5373, 1228, 257, 22358, 2316, 13, 51714], "temperature": 0.0, "avg_logprob": -0.18792491488986546, "compression_ratio": 1.762962962962963, "no_speech_prob": 0.0002955262316390872}, {"id": 379, "seek": 152880, "start": 1528.8, "end": 1533.8, "text": " There's a lot of different scoring models and you can find on Google or Ecosia, my favorite", "tokens": [50364, 821, 311, 257, 688, 295, 819, 22358, 5245, 293, 291, 393, 915, 322, 3329, 420, 462, 6877, 654, 11, 452, 2954, 50614], "temperature": 0.0, "avg_logprob": -0.1545296623593285, "compression_ratio": 1.683206106870229, "no_speech_prob": 0.020892882719635963}, {"id": 380, "seek": 152880, "start": 1533.8, "end": 1536.24, "text": " search engine personally is Ecosia.", "tokens": [50614, 3164, 2848, 5665, 307, 462, 6877, 654, 13, 50736], "temperature": 0.0, "avg_logprob": -0.1545296623593285, "compression_ratio": 1.683206106870229, "no_speech_prob": 0.020892882719635963}, {"id": 381, "seek": 152880, "start": 1536.24, "end": 1542.84, "text": " You can go in there and see what scoring models can do to help you assess things like reach,", "tokens": [50736, 509, 393, 352, 294, 456, 293, 536, 437, 22358, 5245, 393, 360, 281, 854, 291, 5877, 721, 411, 2524, 11, 51066], "temperature": 0.0, "avg_logprob": -0.1545296623593285, "compression_ratio": 1.683206106870229, "no_speech_prob": 0.020892882719635963}, {"id": 382, "seek": 152880, "start": 1542.84, "end": 1549.28, "text": " impact, excitement, effort and have a weighted scoring option so you can stack rank your", "tokens": [51066, 2712, 11, 14755, 11, 4630, 293, 362, 257, 32807, 22358, 3614, 370, 291, 393, 8630, 6181, 428, 51388], "temperature": 0.0, "avg_logprob": -0.1545296623593285, "compression_ratio": 1.683206106870229, "no_speech_prob": 0.020892882719635963}, {"id": 383, "seek": 152880, "start": 1549.28, "end": 1555.24, "text": " backlog items and then do the top items first because you've decided through data and analysis", "tokens": [51388, 47364, 4754, 293, 550, 360, 264, 1192, 4754, 700, 570, 291, 600, 3047, 807, 1412, 293, 5215, 51686], "temperature": 0.0, "avg_logprob": -0.1545296623593285, "compression_ratio": 1.683206106870229, "no_speech_prob": 0.020892882719635963}, {"id": 384, "seek": 152880, "start": 1555.24, "end": 1558.48, "text": " that they're the most valuable ones.", "tokens": [51686, 300, 436, 434, 264, 881, 8263, 2306, 13, 51848], "temperature": 0.0, "avg_logprob": -0.1545296623593285, "compression_ratio": 1.683206106870229, "no_speech_prob": 0.020892882719635963}, {"id": 385, "seek": 155848, "start": 1558.48, "end": 1560.48, "text": " This is another template for your strategy.", "tokens": [50364, 639, 307, 1071, 12379, 337, 428, 5206, 13, 50464], "temperature": 0.0, "avg_logprob": -0.22903074376723345, "compression_ratio": 1.5291479820627802, "no_speech_prob": 0.03834513947367668}, {"id": 386, "seek": 155848, "start": 1560.48, "end": 1562.68, "text": " I just found this on Miro.", "tokens": [50464, 286, 445, 1352, 341, 322, 376, 5182, 13, 50574], "temperature": 0.0, "avg_logprob": -0.22903074376723345, "compression_ratio": 1.5291479820627802, "no_speech_prob": 0.03834513947367668}, {"id": 387, "seek": 155848, "start": 1562.68, "end": 1568.44, "text": " It's by Lou Coleman and basically if you're rolling out an MVP for a new project for the", "tokens": [50574, 467, 311, 538, 7272, 49930, 293, 1936, 498, 291, 434, 9439, 484, 364, 37151, 337, 257, 777, 1716, 337, 264, 50862], "temperature": 0.0, "avg_logprob": -0.22903074376723345, "compression_ratio": 1.5291479820627802, "no_speech_prob": 0.03834513947367668}, {"id": 388, "seek": 155848, "start": 1568.44, "end": 1574.24, "text": " first time, your center of focus is obviously the tree trunk so making the purpose of that", "tokens": [50862, 700, 565, 11, 428, 3056, 295, 1879, 307, 2745, 264, 4230, 19849, 370, 1455, 264, 4334, 295, 300, 51152], "temperature": 0.0, "avg_logprob": -0.22903074376723345, "compression_ratio": 1.5291479820627802, "no_speech_prob": 0.03834513947367668}, {"id": 389, "seek": 155848, "start": 1574.24, "end": 1581.24, "text": " really strong and solid and then over time you have more time to build on your tree trunk.", "tokens": [51152, 534, 2068, 293, 5100, 293, 550, 670, 565, 291, 362, 544, 565, 281, 1322, 322, 428, 4230, 19849, 13, 51502], "temperature": 0.0, "avg_logprob": -0.22903074376723345, "compression_ratio": 1.5291479820627802, "no_speech_prob": 0.03834513947367668}, {"id": 390, "seek": 158124, "start": 1581.24, "end": 1587.48, "text": " This format allows you to plot your plans basically on different bands.", "tokens": [50364, 639, 7877, 4045, 291, 281, 7542, 428, 5482, 1936, 322, 819, 13543, 13, 50676], "temperature": 0.0, "avg_logprob": -0.19888942799669632, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.012816205620765686}, {"id": 391, "seek": 158124, "start": 1587.48, "end": 1592.4, "text": " So maybe the future band might be something that's high impact and high effort but it's", "tokens": [50676, 407, 1310, 264, 2027, 4116, 1062, 312, 746, 300, 311, 1090, 2712, 293, 1090, 4630, 457, 309, 311, 50922], "temperature": 0.0, "avg_logprob": -0.19888942799669632, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.012816205620765686}, {"id": 392, "seek": 158124, "start": 1592.4, "end": 1596.88, "text": " just going to take a lot of time so you don't project that you're going to have it done", "tokens": [50922, 445, 516, 281, 747, 257, 688, 295, 565, 370, 291, 500, 380, 1716, 300, 291, 434, 516, 281, 362, 309, 1096, 51146], "temperature": 0.0, "avg_logprob": -0.19888942799669632, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.012816205620765686}, {"id": 393, "seek": 158124, "start": 1596.88, "end": 1597.88, "text": " right away.", "tokens": [51146, 558, 1314, 13, 51196], "temperature": 0.0, "avg_logprob": -0.19888942799669632, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.012816205620765686}, {"id": 394, "seek": 158124, "start": 1597.88, "end": 1602.92, "text": " I just thought it was a nice visual I like trees too.", "tokens": [51196, 286, 445, 1194, 309, 390, 257, 1481, 5056, 286, 411, 5852, 886, 13, 51448], "temperature": 0.0, "avg_logprob": -0.19888942799669632, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.012816205620765686}, {"id": 395, "seek": 158124, "start": 1602.92, "end": 1606.4, "text": " Last slide is probably something that's very familiar to you.", "tokens": [51448, 5264, 4137, 307, 1391, 746, 300, 311, 588, 4963, 281, 291, 13, 51622], "temperature": 0.0, "avg_logprob": -0.19888942799669632, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.012816205620765686}, {"id": 396, "seek": 160640, "start": 1606.4, "end": 1612.4, "text": " It's a standard campaign project board but this really helps with asynchronous collaboration", "tokens": [50364, 467, 311, 257, 3832, 5129, 1716, 3150, 457, 341, 534, 3665, 365, 49174, 9363, 50664], "temperature": 0.0, "avg_logprob": -0.1800450086593628, "compression_ratio": 1.7536231884057971, "no_speech_prob": 0.20353488624095917}, {"id": 397, "seek": 160640, "start": 1612.4, "end": 1616.76, "text": " because if you're running your board really well you'll only have high value work in it", "tokens": [50664, 570, 498, 291, 434, 2614, 428, 3150, 534, 731, 291, 603, 787, 362, 1090, 2158, 589, 294, 309, 50882], "temperature": 0.0, "avg_logprob": -0.1800450086593628, "compression_ratio": 1.7536231884057971, "no_speech_prob": 0.20353488624095917}, {"id": 398, "seek": 160640, "start": 1616.76, "end": 1621.0400000000002, "text": " and then your contributors don't have to have a meeting to figure out what to do.", "tokens": [50882, 293, 550, 428, 45627, 500, 380, 362, 281, 362, 257, 3440, 281, 2573, 484, 437, 281, 360, 13, 51096], "temperature": 0.0, "avg_logprob": -0.1800450086593628, "compression_ratio": 1.7536231884057971, "no_speech_prob": 0.20353488624095917}, {"id": 399, "seek": 160640, "start": 1621.0400000000002, "end": 1626.3200000000002, "text": " They just pull off from the board knowing that you've clearly vetted your work through", "tokens": [51096, 814, 445, 2235, 766, 490, 264, 3150, 5276, 300, 291, 600, 4448, 371, 46508, 428, 589, 807, 51360], "temperature": 0.0, "avg_logprob": -0.1800450086593628, "compression_ratio": 1.7536231884057971, "no_speech_prob": 0.20353488624095917}, {"id": 400, "seek": 160640, "start": 1626.3200000000002, "end": 1631.52, "text": " the tools that I've shown you so that they know that what they're going to deliver is", "tokens": [51360, 264, 3873, 300, 286, 600, 4898, 291, 370, 300, 436, 458, 300, 437, 436, 434, 516, 281, 4239, 307, 51620], "temperature": 0.0, "avg_logprob": -0.1800450086593628, "compression_ratio": 1.7536231884057971, "no_speech_prob": 0.20353488624095917}, {"id": 401, "seek": 160640, "start": 1631.52, "end": 1634.76, "text": " ready to go and it's going to make a difference.", "tokens": [51620, 1919, 281, 352, 293, 309, 311, 516, 281, 652, 257, 2649, 13, 51782], "temperature": 0.0, "avg_logprob": -0.1800450086593628, "compression_ratio": 1.7536231884057971, "no_speech_prob": 0.20353488624095917}, {"id": 402, "seek": 163476, "start": 1635.52, "end": 1637.8799999999999, "text": " My experience people are really motivated by purpose.", "tokens": [50402, 1222, 1752, 561, 366, 534, 14515, 538, 4334, 13, 50520], "temperature": 0.0, "avg_logprob": -0.1724454402923584, "compression_ratio": 1.7016949152542373, "no_speech_prob": 0.005804449785500765}, {"id": 403, "seek": 163476, "start": 1637.8799999999999, "end": 1640.08, "text": " They don't want to just do something for busy work.", "tokens": [50520, 814, 500, 380, 528, 281, 445, 360, 746, 337, 5856, 589, 13, 50630], "temperature": 0.0, "avg_logprob": -0.1724454402923584, "compression_ratio": 1.7016949152542373, "no_speech_prob": 0.005804449785500765}, {"id": 404, "seek": 163476, "start": 1640.08, "end": 1642.56, "text": " They actually want to know they're making a change.", "tokens": [50630, 814, 767, 528, 281, 458, 436, 434, 1455, 257, 1319, 13, 50754], "temperature": 0.0, "avg_logprob": -0.1724454402923584, "compression_ratio": 1.7016949152542373, "no_speech_prob": 0.005804449785500765}, {"id": 405, "seek": 163476, "start": 1642.56, "end": 1649.24, "text": " So with your really nicely refined backlog you can help your contributors along by giving", "tokens": [50754, 407, 365, 428, 534, 9594, 26201, 47364, 291, 393, 854, 428, 45627, 2051, 538, 2902, 51088], "temperature": 0.0, "avg_logprob": -0.1724454402923584, "compression_ratio": 1.7016949152542373, "no_speech_prob": 0.005804449785500765}, {"id": 406, "seek": 163476, "start": 1649.24, "end": 1651.04, "text": " them valuable work to do.", "tokens": [51088, 552, 8263, 589, 281, 360, 13, 51178], "temperature": 0.0, "avg_logprob": -0.1724454402923584, "compression_ratio": 1.7016949152542373, "no_speech_prob": 0.005804449785500765}, {"id": 407, "seek": 163476, "start": 1651.04, "end": 1655.84, "text": " I suggest making a triage work in group or having some mechanism in your team but just", "tokens": [51178, 286, 3402, 1455, 257, 1376, 609, 589, 294, 1594, 420, 1419, 512, 7513, 294, 428, 1469, 457, 445, 51418], "temperature": 0.0, "avg_logprob": -0.1724454402923584, "compression_ratio": 1.7016949152542373, "no_speech_prob": 0.005804449785500765}, {"id": 408, "seek": 163476, "start": 1655.84, "end": 1660.64, "text": " make sure that issues are triaged regularly so they don't pile up and that's a really", "tokens": [51418, 652, 988, 300, 2663, 366, 1376, 2980, 11672, 370, 436, 500, 380, 14375, 493, 293, 300, 311, 257, 534, 51658], "temperature": 0.0, "avg_logprob": -0.1724454402923584, "compression_ratio": 1.7016949152542373, "no_speech_prob": 0.005804449785500765}, {"id": 409, "seek": 163476, "start": 1660.64, "end": 1664.28, "text": " good way to get non-code contributors involved as well.", "tokens": [51658, 665, 636, 281, 483, 2107, 12, 22332, 45627, 3288, 382, 731, 13, 51840], "temperature": 0.0, "avg_logprob": -0.1724454402923584, "compression_ratio": 1.7016949152542373, "no_speech_prob": 0.005804449785500765}, {"id": 410, "seek": 166428, "start": 1664.28, "end": 1668.36, "text": " Making valuable high purpose work.", "tokens": [50364, 14595, 8263, 1090, 4334, 589, 13, 50568], "temperature": 0.0, "avg_logprob": -0.26991995787009215, "compression_ratio": 1.6074766355140186, "no_speech_prob": 0.0019466840894892812}, {"id": 411, "seek": 166428, "start": 1668.36, "end": 1672.44, "text": " Hopefully I have helped clear your path and helped you clarify your purpose.", "tokens": [50568, 10429, 286, 362, 4254, 1850, 428, 3100, 293, 4254, 291, 17594, 428, 4334, 13, 50772], "temperature": 0.0, "avg_logprob": -0.26991995787009215, "compression_ratio": 1.6074766355140186, "no_speech_prob": 0.0019466840894892812}, {"id": 412, "seek": 166428, "start": 1672.44, "end": 1675.36, "text": " This is a nice trail in Amsterdam.", "tokens": [50772, 639, 307, 257, 1481, 9924, 294, 28291, 13, 50918], "temperature": 0.0, "avg_logprob": -0.26991995787009215, "compression_ratio": 1.6074766355140186, "no_speech_prob": 0.0019466840894892812}, {"id": 413, "seek": 166428, "start": 1675.36, "end": 1683.16, "text": " It's quiet and friendly and inviting so hopefully that your open source development can achieve", "tokens": [50918, 467, 311, 5677, 293, 9208, 293, 18202, 370, 4696, 300, 428, 1269, 4009, 3250, 393, 4584, 51308], "temperature": 0.0, "avg_logprob": -0.26991995787009215, "compression_ratio": 1.6074766355140186, "no_speech_prob": 0.0019466840894892812}, {"id": 414, "seek": 166428, "start": 1683.16, "end": 1689.0, "text": " some similar aesthetics and that's it and that's the links to the resources that I've", "tokens": [51308, 512, 2531, 35517, 293, 300, 311, 309, 293, 300, 311, 264, 6123, 281, 264, 3593, 300, 286, 600, 51600], "temperature": 0.0, "avg_logprob": -0.26991995787009215, "compression_ratio": 1.6074766355140186, "no_speech_prob": 0.0019466840894892812}, {"id": 415, "seek": 166428, "start": 1689.0, "end": 1690.0, "text": " shared earlier.", "tokens": [51600, 5507, 3071, 13, 51650], "temperature": 0.0, "avg_logprob": -0.26991995787009215, "compression_ratio": 1.6074766355140186, "no_speech_prob": 0.0019466840894892812}, {"id": 416, "seek": 169428, "start": 1694.28, "end": 1704.6, "text": " Not a question.", "tokens": [50364, 1726, 257, 1168, 13, 50880], "temperature": 0.0, "avg_logprob": -0.21652193211797457, "compression_ratio": 1.4893617021276595, "no_speech_prob": 0.02537083998322487}, {"id": 417, "seek": 169428, "start": 1704.6, "end": 1710.16, "text": " So this goes back to the assumption driven development that made me wonder especially", "tokens": [50880, 407, 341, 1709, 646, 281, 264, 15302, 9555, 3250, 300, 1027, 385, 2441, 2318, 51158], "temperature": 0.0, "avg_logprob": -0.21652193211797457, "compression_ratio": 1.4893617021276595, "no_speech_prob": 0.02537083998322487}, {"id": 418, "seek": 169428, "start": 1710.16, "end": 1715.08, "text": " since you pointed out to stake the work first so you know what you're getting yourself into", "tokens": [51158, 1670, 291, 10932, 484, 281, 10407, 264, 589, 700, 370, 291, 458, 437, 291, 434, 1242, 1803, 666, 51404], "temperature": 0.0, "avg_logprob": -0.21652193211797457, "compression_ratio": 1.4893617021276595, "no_speech_prob": 0.02537083998322487}, {"id": 419, "seek": 169428, "start": 1715.08, "end": 1723.6, "text": " but if I do that, if I had done that then I would have never started any effort at any", "tokens": [51404, 457, 498, 286, 360, 300, 11, 498, 286, 632, 1096, 300, 550, 286, 576, 362, 1128, 1409, 604, 4630, 412, 604, 51830], "temperature": 0.0, "avg_logprob": -0.21652193211797457, "compression_ratio": 1.4893617021276595, "no_speech_prob": 0.02537083998322487}, {"id": 420, "seek": 172360, "start": 1723.6, "end": 1728.56, "text": " time because I would have been too intimidated had I known what I would have gotten myself", "tokens": [50364, 565, 570, 286, 576, 362, 668, 886, 40234, 632, 286, 2570, 437, 286, 576, 362, 5768, 2059, 50612], "temperature": 0.0, "avg_logprob": -0.2419138515696806, "compression_ratio": 1.5088757396449703, "no_speech_prob": 0.8256728053092957}, {"id": 421, "seek": 172360, "start": 1728.56, "end": 1729.56, "text": " into.", "tokens": [50612, 666, 13, 50662], "temperature": 0.0, "avg_logprob": -0.2419138515696806, "compression_ratio": 1.5088757396449703, "no_speech_prob": 0.8256728053092957}, {"id": 422, "seek": 172360, "start": 1729.56, "end": 1734.6, "text": " So what do I do to still get stuff done?", "tokens": [50662, 407, 437, 360, 286, 360, 281, 920, 483, 1507, 1096, 30, 50914], "temperature": 0.0, "avg_logprob": -0.2419138515696806, "compression_ratio": 1.5088757396449703, "no_speech_prob": 0.8256728053092957}, {"id": 423, "seek": 172360, "start": 1734.6, "end": 1737.32, "text": " I think it depends on the number of factors.", "tokens": [50914, 286, 519, 309, 5946, 322, 264, 1230, 295, 6771, 13, 51050], "temperature": 0.0, "avg_logprob": -0.2419138515696806, "compression_ratio": 1.5088757396449703, "no_speech_prob": 0.8256728053092957}, {"id": 424, "seek": 172360, "start": 1737.32, "end": 1741.8799999999999, "text": " If you have a lot of time to build something out and really focus on it.", "tokens": [51050, 759, 291, 362, 257, 688, 295, 565, 281, 1322, 746, 484, 293, 534, 1879, 322, 309, 13, 51278], "temperature": 0.0, "avg_logprob": -0.2419138515696806, "compression_ratio": 1.5088757396449703, "no_speech_prob": 0.8256728053092957}], "language": "en"}