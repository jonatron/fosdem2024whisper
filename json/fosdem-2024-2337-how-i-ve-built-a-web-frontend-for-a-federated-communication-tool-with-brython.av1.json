{"text": " Okay, so let's start. Thank you very much for staying for the last session of the day in the Python Dev Room. So we are now going to have J\u00e9r\u00f4me Poisson, who is a free software developer and he's working on a web front end for an XMPP client using Brithon. So give him a warm welcome. Hello everybody, my name is J\u00e9r\u00f4me Poisson, I'm also known as GoFee on Internet, so I'm the lead developer of the Liberia project and in this talk I will explain how I'm using Brithon to do the web interface and why I'm doing that. So if you were on Liberia, in Liberia it's universal communication in the ecosystem. It's goal is to be all in one place, to do everything like chat, blog, audio video calls, etc. There's Gateway to other protocol, I'm working on an XMPP to activity of Gateway, I made a talk about that yesterday. It supports N2 encryption but not in the web front end at the moment, that's one of the reasons when I want to use Python in the web. And so it's multi front end, so you have desktop, command line interface, text interface and even an experimental Android interface made with Kivi. So why using Python in the browser? First, there is no context switching. In my case, several front ends are made in Python, the backend is made in Python and it's enjoyable not to have to switch to another language, another way of thinking, another way to look for documentation, etc. When I'm working on the web development, I'm always staying in Python and feeling at home. Python is famous for being highly readable language, so it's easier to maintain, so the goal is to make something quick to do a new feature and easy to maintain. There is a code reusability. Thanks to Britten, I can use code from other front end or for backend, actually. The thing why I want to use code for backend is for N2 encryption, I will explain that later. And also it's a stable ecosystem. JavaScript is infamous for I think every X month, a new shiny framework that everybody want to move to and you have to learn everything from scratch again. So yeah, JavaScript stack is quite complicated due to that. I think it starts to be a bit better for a few years with React and VGS, but still, yeah, a bit of JavaScript. So just to give you some ideas, I see the screenshot of the chat feature of the, of the library of the front end. So there are a lot of dynamic stuff here which are managed by Britten, so there is reaction when you can add a smiley, you can like, when you have a new message, of course, it will appear on the below. If you put a message, the input will grow and you can send files, you can drag and drop files and everything and all of that is done with Britten. A few words of why Britten has been chosen and not alternatives. So a few years ago, I was using Pijama, which was a part of Google Web 2 kit to pick to Python. So it was doing combination out of time, so you had JavaScript, which was kind of easy. It was, and we were doing the developments in similar way as desktop development. That was reducing at the time because I was doing a lot of desktop development, but at the end it's proved to be a bad idea because we were far away from the HTML, HTML stack, so to HTML to CSS and it was becoming complicated to maintain and adapt things. And anyway, it was supporting only Python 2 and there was no real plan to move to Python 3 and the project is dead due to a sad argument inside the community. Transcript quickly is another transpiler from Python to JavaScript. It's lightweight, it's working, it seems that it's working well, it's performance, but by design it's made to use JavaScript module and not Python, which is a showstopper in our case. Pyo did is part of C Python to WebAssembly with M script 10. It's fully compatible because it's a real C Python which has been part, but the thing is it's quite kind of heavy, but it supports numerous packages. Also it's not really well adapted to work with the DOM and WebStack, but it's really good project if you want to work with a scientific stack on the web. Pyscript is New Killing Town. The decision to use Britain has been made before Pyscript was even start, five and none at least. It's a kind of framework around thing like Pyo did to make it more easy to use and more integrated with WebStack. You can use other Pyo did, but you will have full Python compatibility, but it will be heavy, or you can use micro Python, which is lightweight, but it's Python, but not fully compatible with Python, which is also a showstopper in our case. But anyway, it's a really interesting project and it's nice to keep an eye on this one. Other project was not supporting Python tree, so it was dead and PyPy.js is not maintained anymore anyway, so it was discarded. So here's come Britain. Britain is Python implementation in JavaScript. It transpiles Python to JavaScript, but in the browser. That means that you can do Python in the browser. You can have a Python console in the browser, but the transpiration at some time, but it's cache is in cache for the first time, it's going in the browser WebStorage. That means that the next time you use it, it will be quick. There is a compatibility layer. You are using JavaScript object, but with a compatibility layer, so the object acts the same way as the Python object works. It's aim is to be real Python, and it's really good compatibility. If something is not working, it happens to make a problem. We can just open a ticket. That's another point about Britain, the community, and the lead developer is really nice, welcoming and reactive. So each time I had a problem, it was fixed quickly and in a nice way. Most of the standard is available either by direct transpiration of the CPy version or by re-implementation. Under the comment, you can see what is available, what is not. And it's really well integrated with JavaScript. You can use JavaScript module as well as Python module. And from JavaScript, you can call a code from Britain. So, yeah, it was really a good fit in our case. And the proof that it's real Python, you can check on Britain.info, there is a console, you can do anti-gravity and then you can fly. So, all the front end is working. So basically, blue on the top, you have a backend which is doing all the work, all the X&PP stuff, the profile management, the caching, et cetera. And then you have the various front ends. And the web front end is a bit special because it's split in two. There is an HTTP server which is done with twist ends. And you have the browser part which is done with Britain. So there is a static part and dynamic part which is done with Britain. And it's communicating by Web sockets between them and then HTTP server communicates with the backend with IPC which is usually DBS. And one of the points Britain must be using in the web front end is because anti-gravity is done fully in back end. So for this front end which works on the same device, it's fine. But because on the web front end, it's usually distant user, you need to do the work for anti-gravity again in the browser. So my long goal is to use the code from the backend to be able to do the encryption and decryption directly in the browser and to make real and to an encryption with this front end. So the goal of the web front end is to have progressive announcements by default if you don't have JavaScript to have a static patch for most of features, not every blog. For highly dynamic features like the chat, of course you need to be fully dynamic. So in this case you need JavaScript enabled. It's made to be easy to develop and to maintain and to reuse the code as much as possible from other front end. An important part of this front end is the templating system. I wanted to have templates which work at the same time in the backend, at the same time in the browser dynamically. So I've chosen to use a Jinja 2 which is probably the most famous template engine in Python. And on JavaScript side I'm using Ninjux which is a kind of port of the Jinja 2 to JavaScript which is made by Mozilla. And it's mostly compatible but some filters and directly everything. So I do the implementation of the one I was needing in Britain. And it's working. And there is easy tuning and the fact that I use the same template in the backend as a side effect that I can use also the template in the Cli. So if for instance you want to generate a static website from the same template and the interface you can do it easily. So each feature is organized in what we call page. A leader page is basically a directory which corresponds to a new URL in the web front end. So there is no router like you have in Flask. This might be easy. So one directory, one feature in URL. And in directory you can have a page underscore method.py file which includes a metadata such as the name of the page, is the page public or private, which template to use and you can also use some Python code if you want to get data from the URL or stuff like that or under the post request. And you can have underscore browser directory with Britain part which is what we see now. And then when you send the website, the hierarchy automatically generated so Britain knows where to access the files. So this is a minimal example of the page.page metadata.py file. So the name is used to be able to access the page from somewhere else. So in this case this access profile means that you need to be logged to access this page and the template to use. And here comes the Britain code. So that's what is running in the browser. So you see it's real Python. On the top I'm using the standard JSON to do the parsing of JSON stuff. In the past, the JSON from standard was a bit slow so I was using directly the JavaScript version. So you can do it but no, it's been fixed and it's fully performed so I'm using directly the standard version. The bridge is just a way to communicate with the backend. The browser is an important module. Browser is what is used to manage the DOM. So document if you want to access an element. So Iopart is a Britain version of AsyncIO. AsyncIO is not exactly the same as in Python for reasons I explained in the doc. And Iorg is just a module to show the dialogs. So you see I'm binding the DOM event click to a method. Normally you expect a blocking method but I want to use AsyncIO so I use Iopart. And then you have AsyncIO method. So you see you have the event exactly like in JavaScript. You can call the method exactly like in JavaScript. Then you have the code and I'm parsing the data of the item. And I'm showing a dialog. The feature actually is you have a list for the list feature and if you want to delete a list, you show a marker around the list and you confirm if you want to delete or not. And so you see with Await it's really readable and easy to do it so I can check after if it's confirmed or not and if it's confirmed I send the deletion request or otherwise I just remove the stuff. So this code is doing this. So we just click on the delete showing the dialog and here I'm canceling and it's removing the flag. So yeah, it's working like it will do in JavaScript. About debugging. So when something is going wrong, what is really nice with Britain is you have real Python, Transback, with the line of the source code and everything so it's really easy to debug. Sometimes unfortunately you have JavaScript exception. Usually in this case it's better to report to Breton because it means it's a bug but it's happening less and less often. You can use breakpoint and PDB so your code will be blocking the browser and you will have another box where you can use PDB instruction and there is also an inspector module which in this case your code is running normally but you have a Python console and you can inspect the local variant that you have where you run the inspector. Regarding performances, according to the doc I have a benchmark myself but it's comparable to CPyton because JavaScript is probably one of the most optimized engines in the world in Chrome and Firefox. So it's comparable, sometimes slower, sometimes quicker. Of course it's slower than pure JavaScript because there is a compatibility time and the compatibility layer but the compatibility is done only once after it's cached and for compatibility layer it's working okay. By default you have a world standard lib which is kind of heavy between 4 and 5 megabytes. Normally you don't want to use that. You can either not use at all or you have a small tool which will check your source code and which module you are actually using and make something smaller and totally usable. So the loading time anyway is cached, it's in cached so after it has been used at least once it's quick to learn. So from my experience and I have not yet worked on optimization it's working absolutely fine at least from my use case. So now the roadmap. In the future I want to integrate more Britons, notably in the loading parts because I want to do something more like modern social network experience with reaction and everything. So use kind of the backend, as I say it's really important for end to end encryption. I want to be able to get the stuff which are done the way we format the XMPP standards etc. and do it in the browser so we have real end to end encryption. And I would like to experiment what we can do with the Python in the browser. I'm thinking there are a lot of fields where we can do that. In education we can imagine a chat where we could have Python console, it could be used for instance to learn Python itself or to do mathematics in a school or this kind of things. For science of course it will be super useful. Maybe we can try to use the work done by the PIOD to also try to run some scientific stack. And automation and visualize that it could be possible to do filter in Python when you have a chat message or block message and to see if you want to do something on it or not. So, for my experience, is a robust solution for integrating Python into the web development. The community is nice which is really important part and it's allowed to use the same code in the backend and in the front end which is really time saving and avoid to have people specialize in one language or one other language. So, that's it for this talk. You can check Brithu on this website. You can check my project on Libervia. I have a blog accessible by XMPP, activity pub or Atom. You have Atom field of course. Where I'm talking about project money and stuff I'm doing with Brithu and etc. And you can look for help in the Libervia chat room on XMPP or PINGMI. This is my other activity pub and I hope I give you the test to try Brithu and see what you can do with it. You have a console in the Brithu official website so you can use it right now and just try to play with it and see how it works and what you can do with it. So, thank you very much. If you have any questions. Thank you. Any questions? Yes. Yes. How do you set up the web server? You must serve it somehow, the Brithun code. Do you have to do some kind of special thing to make the Brithu bridge work? Web soket is support directly. I'm using JavaScript code directly and I'm sending, I'm using JSON to work with the bridge also in the back end. So, it's native in JavaScript and with Brithun it's easy to access. And Web soket is straightforward. No problem with it. So, I send the Web soket to the HTTP server which in turn it's also doing the security stuff because of course from the browser you can trust it. So, I check if you have a right to use this method, etc. And then sending from the IPC. IPC can change but usually it's the bus that we use between front end and back end. Thank you. And great that you support the XMPP world. Thank you. Any questions? No one? Okay, then I guess it's a wrap. So, thanks again for the talk.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 7.0, "text": " Okay, so let's start. Thank you very much for staying for the last session of the day", "tokens": [50364, 1033, 11, 370, 718, 311, 722, 13, 1044, 291, 588, 709, 337, 7939, 337, 264, 1036, 5481, 295, 264, 786, 50714], "temperature": 0.0, "avg_logprob": -0.3033830006917318, "compression_ratio": 1.3523316062176165, "no_speech_prob": 0.20500406622886658}, {"id": 1, "seek": 0, "start": 10.8, "end": 17.2, "text": " in the Python Dev Room. So we are now going to have J\u00e9r\u00f4me Poisson, who is a free software", "tokens": [50904, 294, 264, 15329, 9096, 19190, 13, 407, 321, 366, 586, 516, 281, 362, 508, 4198, 2851, 1398, 6165, 30472, 11, 567, 307, 257, 1737, 4722, 51224], "temperature": 0.0, "avg_logprob": -0.3033830006917318, "compression_ratio": 1.3523316062176165, "no_speech_prob": 0.20500406622886658}, {"id": 2, "seek": 0, "start": 17.2, "end": 24.2, "text": " developer and he's working on a web front end for an XMPP client using Brithon. So", "tokens": [51224, 10754, 293, 415, 311, 1364, 322, 257, 3670, 1868, 917, 337, 364, 1783, 12224, 47, 6423, 1228, 1603, 355, 266, 13, 407, 51574], "temperature": 0.0, "avg_logprob": -0.3033830006917318, "compression_ratio": 1.3523316062176165, "no_speech_prob": 0.20500406622886658}, {"id": 3, "seek": 2420, "start": 25.2, "end": 27.2, "text": " give him a warm welcome.", "tokens": [50414, 976, 796, 257, 4561, 2928, 13, 50514], "temperature": 0.0, "avg_logprob": -0.31504524585812593, "compression_ratio": 1.3846153846153846, "no_speech_prob": 0.059672705829143524}, {"id": 4, "seek": 2420, "start": 27.2, "end": 34.2, "text": " Hello everybody, my name is J\u00e9r\u00f4me Poisson, I'm also known as GoFee on Internet, so I'm", "tokens": [50514, 2425, 2201, 11, 452, 1315, 307, 508, 4198, 2851, 1398, 6165, 30472, 11, 286, 478, 611, 2570, 382, 1037, 37, 1653, 322, 7703, 11, 370, 286, 478, 50864], "temperature": 0.0, "avg_logprob": -0.31504524585812593, "compression_ratio": 1.3846153846153846, "no_speech_prob": 0.059672705829143524}, {"id": 5, "seek": 2420, "start": 37.2, "end": 42.2, "text": " the lead developer of the Liberia project and in this talk I will explain how I'm using", "tokens": [51014, 264, 1477, 10754, 295, 264, 14175, 654, 1716, 293, 294, 341, 751, 286, 486, 2903, 577, 286, 478, 1228, 51264], "temperature": 0.0, "avg_logprob": -0.31504524585812593, "compression_ratio": 1.3846153846153846, "no_speech_prob": 0.059672705829143524}, {"id": 6, "seek": 2420, "start": 42.2, "end": 48.2, "text": " Brithon to do the web interface and why I'm doing that. So if you were on Liberia, in", "tokens": [51264, 1603, 355, 266, 281, 360, 264, 3670, 9226, 293, 983, 286, 478, 884, 300, 13, 407, 498, 291, 645, 322, 14175, 654, 11, 294, 51564], "temperature": 0.0, "avg_logprob": -0.31504524585812593, "compression_ratio": 1.3846153846153846, "no_speech_prob": 0.059672705829143524}, {"id": 7, "seek": 4820, "start": 49.2, "end": 54.2, "text": " Liberia it's universal communication in the ecosystem. It's goal is to be all in one place,", "tokens": [50414, 14175, 654, 309, 311, 11455, 6101, 294, 264, 11311, 13, 467, 311, 3387, 307, 281, 312, 439, 294, 472, 1081, 11, 50664], "temperature": 0.0, "avg_logprob": -0.3147175709406535, "compression_ratio": 1.5020408163265306, "no_speech_prob": 0.062153853476047516}, {"id": 8, "seek": 4820, "start": 54.2, "end": 61.2, "text": " to do everything like chat, blog, audio video calls, etc. There's Gateway to other protocol,", "tokens": [50664, 281, 360, 1203, 411, 5081, 11, 6968, 11, 6278, 960, 5498, 11, 5183, 13, 821, 311, 48394, 281, 661, 10336, 11, 51014], "temperature": 0.0, "avg_logprob": -0.3147175709406535, "compression_ratio": 1.5020408163265306, "no_speech_prob": 0.062153853476047516}, {"id": 9, "seek": 4820, "start": 62.2, "end": 68.2, "text": " I'm working on an XMPP to activity of Gateway, I made a talk about that yesterday. It supports", "tokens": [51064, 286, 478, 1364, 322, 364, 1783, 12224, 47, 281, 5191, 295, 48394, 11, 286, 1027, 257, 751, 466, 300, 5186, 13, 467, 9346, 51364], "temperature": 0.0, "avg_logprob": -0.3147175709406535, "compression_ratio": 1.5020408163265306, "no_speech_prob": 0.062153853476047516}, {"id": 10, "seek": 4820, "start": 68.2, "end": 73.2, "text": " N2 encryption but not in the web front end at the moment, that's one of the reasons when", "tokens": [51364, 426, 17, 29575, 457, 406, 294, 264, 3670, 1868, 917, 412, 264, 1623, 11, 300, 311, 472, 295, 264, 4112, 562, 51614], "temperature": 0.0, "avg_logprob": -0.3147175709406535, "compression_ratio": 1.5020408163265306, "no_speech_prob": 0.062153853476047516}, {"id": 11, "seek": 7320, "start": 73.2, "end": 79.2, "text": " I want to use Python in the web. And so it's multi front end, so you have desktop,", "tokens": [50364, 286, 528, 281, 764, 15329, 294, 264, 3670, 13, 400, 370, 309, 311, 4825, 1868, 917, 11, 370, 291, 362, 14502, 11, 50664], "temperature": 0.0, "avg_logprob": -0.2767913475465239, "compression_ratio": 1.6188340807174888, "no_speech_prob": 0.01453670859336853}, {"id": 12, "seek": 7320, "start": 79.2, "end": 84.2, "text": " command line interface, text interface and even an experimental Android interface made with", "tokens": [50664, 5622, 1622, 9226, 11, 2487, 9226, 293, 754, 364, 17069, 8853, 9226, 1027, 365, 50914], "temperature": 0.0, "avg_logprob": -0.2767913475465239, "compression_ratio": 1.6188340807174888, "no_speech_prob": 0.01453670859336853}, {"id": 13, "seek": 7320, "start": 84.2, "end": 90.2, "text": " Kivi. So why using Python in the browser? First, there is no context switching. In my case,", "tokens": [50914, 591, 33448, 13, 407, 983, 1228, 15329, 294, 264, 11185, 30, 2386, 11, 456, 307, 572, 4319, 16493, 13, 682, 452, 1389, 11, 51214], "temperature": 0.0, "avg_logprob": -0.2767913475465239, "compression_ratio": 1.6188340807174888, "no_speech_prob": 0.01453670859336853}, {"id": 14, "seek": 7320, "start": 94.2, "end": 100.2, "text": " several front ends are made in Python, the backend is made in Python and it's enjoyable not to", "tokens": [51414, 2940, 1868, 5314, 366, 1027, 294, 15329, 11, 264, 38087, 307, 1027, 294, 15329, 293, 309, 311, 20305, 406, 281, 51714], "temperature": 0.0, "avg_logprob": -0.2767913475465239, "compression_ratio": 1.6188340807174888, "no_speech_prob": 0.01453670859336853}, {"id": 15, "seek": 10020, "start": 101.2, "end": 106.2, "text": " have to switch to another language, another way of thinking, another way to look for documentation,", "tokens": [50414, 362, 281, 3679, 281, 1071, 2856, 11, 1071, 636, 295, 1953, 11, 1071, 636, 281, 574, 337, 14333, 11, 50664], "temperature": 0.0, "avg_logprob": -0.22659601790181708, "compression_ratio": 1.6726457399103138, "no_speech_prob": 0.01234597060829401}, {"id": 16, "seek": 10020, "start": 106.2, "end": 111.2, "text": " etc. When I'm working on the web development, I'm always staying in Python and feeling at", "tokens": [50664, 5183, 13, 1133, 286, 478, 1364, 322, 264, 3670, 3250, 11, 286, 478, 1009, 7939, 294, 15329, 293, 2633, 412, 50914], "temperature": 0.0, "avg_logprob": -0.22659601790181708, "compression_ratio": 1.6726457399103138, "no_speech_prob": 0.01234597060829401}, {"id": 17, "seek": 10020, "start": 111.2, "end": 118.2, "text": " home. Python is famous for being highly readable language, so it's easier to maintain, so the", "tokens": [50914, 1280, 13, 15329, 307, 4618, 337, 885, 5405, 49857, 2856, 11, 370, 309, 311, 3571, 281, 6909, 11, 370, 264, 51264], "temperature": 0.0, "avg_logprob": -0.22659601790181708, "compression_ratio": 1.6726457399103138, "no_speech_prob": 0.01234597060829401}, {"id": 18, "seek": 10020, "start": 121.2, "end": 127.2, "text": " goal is to make something quick to do a new feature and easy to maintain. There is a code", "tokens": [51414, 3387, 307, 281, 652, 746, 1702, 281, 360, 257, 777, 4111, 293, 1858, 281, 6909, 13, 821, 307, 257, 3089, 51714], "temperature": 0.0, "avg_logprob": -0.22659601790181708, "compression_ratio": 1.6726457399103138, "no_speech_prob": 0.01234597060829401}, {"id": 19, "seek": 12720, "start": 128.2, "end": 134.2, "text": " reusability. Thanks to Britten, I can use code from other front end or for backend, actually. The", "tokens": [50414, 38860, 2310, 13, 2561, 281, 1603, 2987, 11, 286, 393, 764, 3089, 490, 661, 1868, 917, 420, 337, 38087, 11, 767, 13, 440, 50714], "temperature": 0.0, "avg_logprob": -0.28256947507140456, "compression_ratio": 1.5767634854771784, "no_speech_prob": 0.010981017723679543}, {"id": 20, "seek": 12720, "start": 138.2, "end": 143.2, "text": " thing why I want to use code for backend is for N2 encryption, I will explain that later. And", "tokens": [50914, 551, 983, 286, 528, 281, 764, 3089, 337, 38087, 307, 337, 426, 17, 29575, 11, 286, 486, 2903, 300, 1780, 13, 400, 51164], "temperature": 0.0, "avg_logprob": -0.28256947507140456, "compression_ratio": 1.5767634854771784, "no_speech_prob": 0.010981017723679543}, {"id": 21, "seek": 12720, "start": 143.2, "end": 148.2, "text": " also it's a stable ecosystem. JavaScript is infamous for I think every X month, a new shiny", "tokens": [51164, 611, 309, 311, 257, 8351, 11311, 13, 15778, 307, 30769, 337, 286, 519, 633, 1783, 1618, 11, 257, 777, 16997, 51414], "temperature": 0.0, "avg_logprob": -0.28256947507140456, "compression_ratio": 1.5767634854771784, "no_speech_prob": 0.010981017723679543}, {"id": 22, "seek": 12720, "start": 148.2, "end": 154.2, "text": " framework that everybody want to move to and you have to learn everything from scratch again. So", "tokens": [51414, 8388, 300, 2201, 528, 281, 1286, 281, 293, 291, 362, 281, 1466, 1203, 490, 8459, 797, 13, 407, 51714], "temperature": 0.0, "avg_logprob": -0.28256947507140456, "compression_ratio": 1.5767634854771784, "no_speech_prob": 0.010981017723679543}, {"id": 23, "seek": 15420, "start": 154.2, "end": 160.2, "text": " yeah, JavaScript stack is quite complicated due to that. I think it starts to be a bit better for", "tokens": [50364, 1338, 11, 15778, 8630, 307, 1596, 6179, 3462, 281, 300, 13, 286, 519, 309, 3719, 281, 312, 257, 857, 1101, 337, 50664], "temperature": 0.0, "avg_logprob": -0.3664180100566209, "compression_ratio": 1.598326359832636, "no_speech_prob": 0.010808221995830536}, {"id": 24, "seek": 15420, "start": 161.2, "end": 167.2, "text": " a few years with React and VGS, but still, yeah, a bit of JavaScript. So just to give you", "tokens": [50714, 257, 1326, 924, 365, 30644, 293, 691, 24446, 11, 457, 920, 11, 1338, 11, 257, 857, 295, 15778, 13, 407, 445, 281, 976, 291, 51014], "temperature": 0.0, "avg_logprob": -0.3664180100566209, "compression_ratio": 1.598326359832636, "no_speech_prob": 0.010808221995830536}, {"id": 25, "seek": 15420, "start": 169.2, "end": 175.2, "text": " some ideas, I see the screenshot of the chat feature of the, of the library of the front end. So", "tokens": [51114, 512, 3487, 11, 286, 536, 264, 27712, 295, 264, 5081, 4111, 295, 264, 11, 295, 264, 6405, 295, 264, 1868, 917, 13, 407, 51414], "temperature": 0.0, "avg_logprob": -0.3664180100566209, "compression_ratio": 1.598326359832636, "no_speech_prob": 0.010808221995830536}, {"id": 26, "seek": 15420, "start": 177.2, "end": 181.2, "text": " there are a lot of dynamic stuff here which are managed by Britten, so there is reaction when you", "tokens": [51514, 456, 366, 257, 688, 295, 8546, 1507, 510, 597, 366, 6453, 538, 1603, 2987, 11, 370, 456, 307, 5480, 562, 291, 51714], "temperature": 0.0, "avg_logprob": -0.3664180100566209, "compression_ratio": 1.598326359832636, "no_speech_prob": 0.010808221995830536}, {"id": 27, "seek": 18120, "start": 181.2, "end": 187.2, "text": " can add a smiley, you can like, when you have a new message, of course, it will appear on the", "tokens": [50364, 393, 909, 257, 7563, 88, 11, 291, 393, 411, 11, 562, 291, 362, 257, 777, 3636, 11, 295, 1164, 11, 309, 486, 4204, 322, 264, 50664], "temperature": 0.0, "avg_logprob": -0.22124378353941673, "compression_ratio": 1.6244541484716157, "no_speech_prob": 0.008963106200098991}, {"id": 28, "seek": 18120, "start": 188.2, "end": 196.2, "text": " below. If you put a message, the input will grow and you can send files, you can drag and", "tokens": [50714, 2507, 13, 759, 291, 829, 257, 3636, 11, 264, 4846, 486, 1852, 293, 291, 393, 2845, 7098, 11, 291, 393, 5286, 293, 51114], "temperature": 0.0, "avg_logprob": -0.22124378353941673, "compression_ratio": 1.6244541484716157, "no_speech_prob": 0.008963106200098991}, {"id": 29, "seek": 18120, "start": 196.2, "end": 202.2, "text": " drop files and everything and all of that is done with Britten. A few words of why Britten has been", "tokens": [51114, 3270, 7098, 293, 1203, 293, 439, 295, 300, 307, 1096, 365, 1603, 2987, 13, 316, 1326, 2283, 295, 983, 1603, 2987, 575, 668, 51414], "temperature": 0.0, "avg_logprob": -0.22124378353941673, "compression_ratio": 1.6244541484716157, "no_speech_prob": 0.008963106200098991}, {"id": 30, "seek": 18120, "start": 202.2, "end": 210.2, "text": " chosen and not alternatives. So a few years ago, I was using Pijama, which was a part of", "tokens": [51414, 8614, 293, 406, 20478, 13, 407, 257, 1326, 924, 2057, 11, 286, 390, 1228, 430, 1718, 2404, 11, 597, 390, 257, 644, 295, 51814], "temperature": 0.0, "avg_logprob": -0.22124378353941673, "compression_ratio": 1.6244541484716157, "no_speech_prob": 0.008963106200098991}, {"id": 31, "seek": 21120, "start": 211.2, "end": 218.2, "text": " Google Web 2 kit to pick to Python. So it was doing combination out of time, so you had", "tokens": [50364, 3329, 9573, 568, 8260, 281, 1888, 281, 15329, 13, 407, 309, 390, 884, 6562, 484, 295, 565, 11, 370, 291, 632, 50714], "temperature": 0.0, "avg_logprob": -0.35933776640556225, "compression_ratio": 1.5698924731182795, "no_speech_prob": 0.02655845321714878}, {"id": 32, "seek": 21120, "start": 219.2, "end": 229.2, "text": " JavaScript, which was kind of easy. It was, and we were doing the developments in similar way as desktop", "tokens": [50764, 15778, 11, 597, 390, 733, 295, 1858, 13, 467, 390, 11, 293, 321, 645, 884, 264, 20862, 294, 2531, 636, 382, 14502, 51264], "temperature": 0.0, "avg_logprob": -0.35933776640556225, "compression_ratio": 1.5698924731182795, "no_speech_prob": 0.02655845321714878}, {"id": 33, "seek": 21120, "start": 229.2, "end": 235.2, "text": " development. That was reducing at the time because I was doing a lot of desktop development, but at", "tokens": [51264, 3250, 13, 663, 390, 12245, 412, 264, 565, 570, 286, 390, 884, 257, 688, 295, 14502, 3250, 11, 457, 412, 51564], "temperature": 0.0, "avg_logprob": -0.35933776640556225, "compression_ratio": 1.5698924731182795, "no_speech_prob": 0.02655845321714878}, {"id": 34, "seek": 23520, "start": 235.2, "end": 245.2, "text": " the end it's proved to be a bad idea because we were far away from the HTML, HTML stack, so to HTML", "tokens": [50364, 264, 917, 309, 311, 14617, 281, 312, 257, 1578, 1558, 570, 321, 645, 1400, 1314, 490, 264, 17995, 11, 17995, 8630, 11, 370, 281, 17995, 50864], "temperature": 0.0, "avg_logprob": -0.21191825093449773, "compression_ratio": 1.5368421052631578, "no_speech_prob": 0.018108250573277473}, {"id": 35, "seek": 23520, "start": 245.2, "end": 251.2, "text": " to CSS and it was becoming complicated to maintain and adapt things. And anyway, it was supporting", "tokens": [50864, 281, 24387, 293, 309, 390, 5617, 6179, 281, 6909, 293, 6231, 721, 13, 400, 4033, 11, 309, 390, 7231, 51164], "temperature": 0.0, "avg_logprob": -0.21191825093449773, "compression_ratio": 1.5368421052631578, "no_speech_prob": 0.018108250573277473}, {"id": 36, "seek": 23520, "start": 251.2, "end": 257.2, "text": " only Python 2 and there was no real plan to move to Python 3 and the project is dead due to a", "tokens": [51164, 787, 15329, 568, 293, 456, 390, 572, 957, 1393, 281, 1286, 281, 15329, 805, 293, 264, 1716, 307, 3116, 3462, 281, 257, 51464], "temperature": 0.0, "avg_logprob": -0.21191825093449773, "compression_ratio": 1.5368421052631578, "no_speech_prob": 0.018108250573277473}, {"id": 37, "seek": 25720, "start": 257.2, "end": 264.2, "text": " sad argument inside the community. Transcript quickly is another transpiler from Python to", "tokens": [50364, 4227, 6770, 1854, 264, 1768, 13, 6531, 5944, 2661, 307, 1071, 7132, 5441, 490, 15329, 281, 50714], "temperature": 0.0, "avg_logprob": -0.2370164326259068, "compression_ratio": 1.5052631578947369, "no_speech_prob": 0.10020031034946442}, {"id": 38, "seek": 25720, "start": 264.2, "end": 270.2, "text": " JavaScript. It's lightweight, it's working, it seems that it's working well, it's performance, but by", "tokens": [50714, 15778, 13, 467, 311, 22052, 11, 309, 311, 1364, 11, 309, 2544, 300, 309, 311, 1364, 731, 11, 309, 311, 3389, 11, 457, 538, 51014], "temperature": 0.0, "avg_logprob": -0.2370164326259068, "compression_ratio": 1.5052631578947369, "no_speech_prob": 0.10020031034946442}, {"id": 39, "seek": 25720, "start": 270.2, "end": 277.2, "text": " design it's made to use JavaScript module and not Python, which is a showstopper in our case.", "tokens": [51014, 1715, 309, 311, 1027, 281, 764, 15778, 10088, 293, 406, 15329, 11, 597, 307, 257, 855, 13559, 610, 294, 527, 1389, 13, 51364], "temperature": 0.0, "avg_logprob": -0.2370164326259068, "compression_ratio": 1.5052631578947369, "no_speech_prob": 0.10020031034946442}, {"id": 40, "seek": 27720, "start": 277.2, "end": 286.2, "text": " Pyo did is part of C Python to WebAssembly with M script 10. It's fully compatible because it's a", "tokens": [50364, 430, 8308, 630, 307, 644, 295, 383, 15329, 281, 9573, 10884, 19160, 365, 376, 5755, 1266, 13, 467, 311, 4498, 18218, 570, 309, 311, 257, 50814], "temperature": 0.0, "avg_logprob": -0.32056314517290163, "compression_ratio": 1.44, "no_speech_prob": 0.35509708523750305}, {"id": 41, "seek": 27720, "start": 286.2, "end": 294.2, "text": " real C Python which has been part, but the thing is it's quite kind of heavy, but it supports", "tokens": [50814, 957, 383, 15329, 597, 575, 668, 644, 11, 457, 264, 551, 307, 309, 311, 1596, 733, 295, 4676, 11, 457, 309, 9346, 51214], "temperature": 0.0, "avg_logprob": -0.32056314517290163, "compression_ratio": 1.44, "no_speech_prob": 0.35509708523750305}, {"id": 42, "seek": 27720, "start": 294.2, "end": 304.2, "text": " numerous packages. Also it's not really well adapted to work with the DOM and WebStack, but it's", "tokens": [51214, 12546, 17401, 13, 2743, 309, 311, 406, 534, 731, 20871, 281, 589, 365, 264, 35727, 293, 9573, 4520, 501, 11, 457, 309, 311, 51714], "temperature": 0.0, "avg_logprob": -0.32056314517290163, "compression_ratio": 1.44, "no_speech_prob": 0.35509708523750305}, {"id": 43, "seek": 30420, "start": 304.2, "end": 310.2, "text": " really good project if you want to work with a scientific stack on the web. Pyscript is", "tokens": [50364, 534, 665, 1716, 498, 291, 528, 281, 589, 365, 257, 8134, 8630, 322, 264, 3670, 13, 430, 749, 5944, 307, 50664], "temperature": 0.0, "avg_logprob": -0.2678655351911272, "compression_ratio": 1.4171122994652405, "no_speech_prob": 0.00840561743825674}, {"id": 44, "seek": 30420, "start": 310.2, "end": 316.2, "text": " New Killing Town. The decision to use Britain has been made before Pyscript was even", "tokens": [50664, 1873, 591, 7345, 15954, 13, 440, 3537, 281, 764, 12960, 575, 668, 1027, 949, 430, 749, 5944, 390, 754, 50964], "temperature": 0.0, "avg_logprob": -0.2678655351911272, "compression_ratio": 1.4171122994652405, "no_speech_prob": 0.00840561743825674}, {"id": 45, "seek": 30420, "start": 316.2, "end": 325.2, "text": " start, five and none at least. It's a kind of framework around thing like Pyo did to make it", "tokens": [50964, 722, 11, 1732, 293, 6022, 412, 1935, 13, 467, 311, 257, 733, 295, 8388, 926, 551, 411, 430, 8308, 630, 281, 652, 309, 51414], "temperature": 0.0, "avg_logprob": -0.2678655351911272, "compression_ratio": 1.4171122994652405, "no_speech_prob": 0.00840561743825674}, {"id": 46, "seek": 32520, "start": 325.2, "end": 333.2, "text": " more easy to use and more integrated with WebStack. You can use other Pyo did, but you will have", "tokens": [50364, 544, 1858, 281, 764, 293, 544, 10919, 365, 9573, 4520, 501, 13, 509, 393, 764, 661, 430, 8308, 630, 11, 457, 291, 486, 362, 50764], "temperature": 0.0, "avg_logprob": -0.18300195173783737, "compression_ratio": 1.6593886462882097, "no_speech_prob": 0.07858730852603912}, {"id": 47, "seek": 32520, "start": 333.2, "end": 341.2, "text": " full Python compatibility, but it will be heavy, or you can use micro Python, which is", "tokens": [50764, 1577, 15329, 34237, 11, 457, 309, 486, 312, 4676, 11, 420, 291, 393, 764, 4532, 15329, 11, 597, 307, 51164], "temperature": 0.0, "avg_logprob": -0.18300195173783737, "compression_ratio": 1.6593886462882097, "no_speech_prob": 0.07858730852603912}, {"id": 48, "seek": 32520, "start": 341.2, "end": 347.2, "text": " lightweight, but it's Python, but not fully compatible with Python, which is also a showstopper in", "tokens": [51164, 22052, 11, 457, 309, 311, 15329, 11, 457, 406, 4498, 18218, 365, 15329, 11, 597, 307, 611, 257, 855, 13559, 610, 294, 51464], "temperature": 0.0, "avg_logprob": -0.18300195173783737, "compression_ratio": 1.6593886462882097, "no_speech_prob": 0.07858730852603912}, {"id": 49, "seek": 32520, "start": 347.2, "end": 353.2, "text": " our case. But anyway, it's a really interesting project and it's nice to keep an eye on this one.", "tokens": [51464, 527, 1389, 13, 583, 4033, 11, 309, 311, 257, 534, 1880, 1716, 293, 309, 311, 1481, 281, 1066, 364, 3313, 322, 341, 472, 13, 51764], "temperature": 0.0, "avg_logprob": -0.18300195173783737, "compression_ratio": 1.6593886462882097, "no_speech_prob": 0.07858730852603912}, {"id": 50, "seek": 35320, "start": 353.2, "end": 360.2, "text": " Other project was not supporting Python tree, so it was dead and PyPy.js is not maintained anymore", "tokens": [50364, 5358, 1716, 390, 406, 7231, 15329, 4230, 11, 370, 309, 390, 3116, 293, 9953, 47, 88, 13, 25530, 307, 406, 17578, 3602, 50714], "temperature": 0.0, "avg_logprob": -0.2587337904078986, "compression_ratio": 1.775229357798165, "no_speech_prob": 0.023960601538419724}, {"id": 51, "seek": 35320, "start": 360.2, "end": 368.2, "text": " anyway, so it was discarded. So here's come Britain. Britain is Python implementation in", "tokens": [50714, 4033, 11, 370, 309, 390, 45469, 13, 407, 510, 311, 808, 12960, 13, 12960, 307, 15329, 11420, 294, 51114], "temperature": 0.0, "avg_logprob": -0.2587337904078986, "compression_ratio": 1.775229357798165, "no_speech_prob": 0.023960601538419724}, {"id": 52, "seek": 35320, "start": 368.2, "end": 375.2, "text": " JavaScript. It transpiles Python to JavaScript, but in the browser. That means that you can do Python", "tokens": [51114, 15778, 13, 467, 7132, 4680, 15329, 281, 15778, 11, 457, 294, 264, 11185, 13, 663, 1355, 300, 291, 393, 360, 15329, 51464], "temperature": 0.0, "avg_logprob": -0.2587337904078986, "compression_ratio": 1.775229357798165, "no_speech_prob": 0.023960601538419724}, {"id": 53, "seek": 35320, "start": 375.2, "end": 382.2, "text": " in the browser. You can have a Python console in the browser, but the transpiration at some time,", "tokens": [51464, 294, 264, 11185, 13, 509, 393, 362, 257, 15329, 11076, 294, 264, 11185, 11, 457, 264, 7132, 7611, 412, 512, 565, 11, 51814], "temperature": 0.0, "avg_logprob": -0.2587337904078986, "compression_ratio": 1.775229357798165, "no_speech_prob": 0.023960601538419724}, {"id": 54, "seek": 38220, "start": 382.2, "end": 389.2, "text": " but it's cache is in cache for the first time, it's going in the browser WebStorage. That means that", "tokens": [50364, 457, 309, 311, 19459, 307, 294, 19459, 337, 264, 700, 565, 11, 309, 311, 516, 294, 264, 11185, 9573, 4520, 29226, 13, 663, 1355, 300, 50714], "temperature": 0.0, "avg_logprob": -0.19370966541523837, "compression_ratio": 1.6869565217391305, "no_speech_prob": 0.015704132616519928}, {"id": 55, "seek": 38220, "start": 389.2, "end": 395.2, "text": " the next time you use it, it will be quick. There is a compatibility layer. You are using", "tokens": [50714, 264, 958, 565, 291, 764, 309, 11, 309, 486, 312, 1702, 13, 821, 307, 257, 34237, 4583, 13, 509, 366, 1228, 51014], "temperature": 0.0, "avg_logprob": -0.19370966541523837, "compression_ratio": 1.6869565217391305, "no_speech_prob": 0.015704132616519928}, {"id": 56, "seek": 38220, "start": 395.2, "end": 400.2, "text": " JavaScript object, but with a compatibility layer, so the object acts the same way as the Python", "tokens": [51014, 15778, 2657, 11, 457, 365, 257, 34237, 4583, 11, 370, 264, 2657, 10672, 264, 912, 636, 382, 264, 15329, 51264], "temperature": 0.0, "avg_logprob": -0.19370966541523837, "compression_ratio": 1.6869565217391305, "no_speech_prob": 0.015704132616519928}, {"id": 57, "seek": 38220, "start": 400.2, "end": 407.2, "text": " object works. It's aim is to be real Python, and it's really good compatibility. If something is not", "tokens": [51264, 2657, 1985, 13, 467, 311, 5939, 307, 281, 312, 957, 15329, 11, 293, 309, 311, 534, 665, 34237, 13, 759, 746, 307, 406, 51614], "temperature": 0.0, "avg_logprob": -0.19370966541523837, "compression_ratio": 1.6869565217391305, "no_speech_prob": 0.015704132616519928}, {"id": 58, "seek": 40720, "start": 407.2, "end": 413.2, "text": " working, it happens to make a problem. We can just open a ticket. That's another point about Britain,", "tokens": [50364, 1364, 11, 309, 2314, 281, 652, 257, 1154, 13, 492, 393, 445, 1269, 257, 10550, 13, 663, 311, 1071, 935, 466, 12960, 11, 50664], "temperature": 0.0, "avg_logprob": -0.24167234247381036, "compression_ratio": 1.5691699604743083, "no_speech_prob": 0.04185280203819275}, {"id": 59, "seek": 40720, "start": 413.2, "end": 418.2, "text": " the community, and the lead developer is really nice, welcoming and reactive. So each time I had a", "tokens": [50664, 264, 1768, 11, 293, 264, 1477, 10754, 307, 534, 1481, 11, 17378, 293, 28897, 13, 407, 1184, 565, 286, 632, 257, 50914], "temperature": 0.0, "avg_logprob": -0.24167234247381036, "compression_ratio": 1.5691699604743083, "no_speech_prob": 0.04185280203819275}, {"id": 60, "seek": 40720, "start": 418.2, "end": 425.2, "text": " problem, it was fixed quickly and in a nice way. Most of the standard is available either by direct", "tokens": [50914, 1154, 11, 309, 390, 6806, 2661, 293, 294, 257, 1481, 636, 13, 4534, 295, 264, 3832, 307, 2435, 2139, 538, 2047, 51264], "temperature": 0.0, "avg_logprob": -0.24167234247381036, "compression_ratio": 1.5691699604743083, "no_speech_prob": 0.04185280203819275}, {"id": 61, "seek": 40720, "start": 425.2, "end": 434.2, "text": " transpiration of the CPy version or by re-implementation. Under the comment, you can see what is", "tokens": [51264, 7132, 7611, 295, 264, 22431, 88, 3037, 420, 538, 319, 12, 332, 781, 19631, 13, 6974, 264, 2871, 11, 291, 393, 536, 437, 307, 51714], "temperature": 0.0, "avg_logprob": -0.24167234247381036, "compression_ratio": 1.5691699604743083, "no_speech_prob": 0.04185280203819275}, {"id": 62, "seek": 43420, "start": 434.2, "end": 442.2, "text": " available, what is not. And it's really well integrated with JavaScript. You can use JavaScript", "tokens": [50364, 2435, 11, 437, 307, 406, 13, 400, 309, 311, 534, 731, 10919, 365, 15778, 13, 509, 393, 764, 15778, 50764], "temperature": 0.0, "avg_logprob": -0.24824083768404448, "compression_ratio": 1.6797752808988764, "no_speech_prob": 0.029835471883416176}, {"id": 63, "seek": 43420, "start": 442.2, "end": 450.2, "text": " module as well as Python module. And from JavaScript, you can call a code from Britain. So, yeah, it was", "tokens": [50764, 10088, 382, 731, 382, 15329, 10088, 13, 400, 490, 15778, 11, 291, 393, 818, 257, 3089, 490, 12960, 13, 407, 11, 1338, 11, 309, 390, 51164], "temperature": 0.0, "avg_logprob": -0.24824083768404448, "compression_ratio": 1.6797752808988764, "no_speech_prob": 0.029835471883416176}, {"id": 64, "seek": 43420, "start": 450.2, "end": 456.2, "text": " really a good fit in our case. And the proof that it's real Python, you can check on Britain.info,", "tokens": [51164, 534, 257, 665, 3318, 294, 527, 1389, 13, 400, 264, 8177, 300, 309, 311, 957, 15329, 11, 291, 393, 1520, 322, 12960, 13, 259, 16931, 11, 51464], "temperature": 0.0, "avg_logprob": -0.24824083768404448, "compression_ratio": 1.6797752808988764, "no_speech_prob": 0.029835471883416176}, {"id": 65, "seek": 45620, "start": 456.2, "end": 465.2, "text": " there is a console, you can do anti-gravity and then you can fly. So, all the front end is working. So", "tokens": [50364, 456, 307, 257, 11076, 11, 291, 393, 360, 6061, 12, 36418, 507, 293, 550, 291, 393, 3603, 13, 407, 11, 439, 264, 1868, 917, 307, 1364, 13, 407, 50814], "temperature": 0.0, "avg_logprob": -0.2817982491992769, "compression_ratio": 1.639344262295082, "no_speech_prob": 0.16440339386463165}, {"id": 66, "seek": 45620, "start": 465.2, "end": 473.2, "text": " basically, blue on the top, you have a backend which is doing all the work, all the X&PP stuff, the", "tokens": [50814, 1936, 11, 3344, 322, 264, 1192, 11, 291, 362, 257, 38087, 597, 307, 884, 439, 264, 589, 11, 439, 264, 1783, 5, 17755, 1507, 11, 264, 51214], "temperature": 0.0, "avg_logprob": -0.2817982491992769, "compression_ratio": 1.639344262295082, "no_speech_prob": 0.16440339386463165}, {"id": 67, "seek": 45620, "start": 473.2, "end": 480.2, "text": " profile management, the caching, et cetera. And then you have the various front ends. And the web", "tokens": [51214, 7964, 4592, 11, 264, 269, 2834, 11, 1030, 11458, 13, 400, 550, 291, 362, 264, 3683, 1868, 5314, 13, 400, 264, 3670, 51564], "temperature": 0.0, "avg_logprob": -0.2817982491992769, "compression_ratio": 1.639344262295082, "no_speech_prob": 0.16440339386463165}, {"id": 68, "seek": 48020, "start": 480.2, "end": 485.2, "text": " front end is a bit special because it's split in two. There is an HTTP server which is done with", "tokens": [50364, 1868, 917, 307, 257, 857, 2121, 570, 309, 311, 7472, 294, 732, 13, 821, 307, 364, 33283, 7154, 597, 307, 1096, 365, 50614], "temperature": 0.0, "avg_logprob": -0.23675401160057555, "compression_ratio": 1.7906976744186047, "no_speech_prob": 0.07129040360450745}, {"id": 69, "seek": 48020, "start": 485.2, "end": 491.2, "text": " twist ends. And you have the browser part which is done with Britain. So there is a static part and", "tokens": [50614, 8203, 5314, 13, 400, 291, 362, 264, 11185, 644, 597, 307, 1096, 365, 12960, 13, 407, 456, 307, 257, 13437, 644, 293, 50914], "temperature": 0.0, "avg_logprob": -0.23675401160057555, "compression_ratio": 1.7906976744186047, "no_speech_prob": 0.07129040360450745}, {"id": 70, "seek": 48020, "start": 491.2, "end": 496.2, "text": " dynamic part which is done with Britain. And it's communicating by Web sockets between them and", "tokens": [50914, 8546, 644, 597, 307, 1096, 365, 12960, 13, 400, 309, 311, 17559, 538, 9573, 370, 11984, 1296, 552, 293, 51164], "temperature": 0.0, "avg_logprob": -0.23675401160057555, "compression_ratio": 1.7906976744186047, "no_speech_prob": 0.07129040360450745}, {"id": 71, "seek": 48020, "start": 496.2, "end": 504.2, "text": " then HTTP server communicates with the backend with IPC which is usually DBS. And one of the", "tokens": [51164, 550, 33283, 7154, 3363, 1024, 365, 264, 38087, 365, 8671, 34, 597, 307, 2673, 413, 8176, 13, 400, 472, 295, 264, 51564], "temperature": 0.0, "avg_logprob": -0.23675401160057555, "compression_ratio": 1.7906976744186047, "no_speech_prob": 0.07129040360450745}, {"id": 72, "seek": 50420, "start": 505.2, "end": 514.2, "text": " points Britain must be using in the web front end is because anti-gravity is done fully in back end. So", "tokens": [50414, 2793, 12960, 1633, 312, 1228, 294, 264, 3670, 1868, 917, 307, 570, 6061, 12, 36418, 507, 307, 1096, 4498, 294, 646, 917, 13, 407, 50864], "temperature": 0.0, "avg_logprob": -0.23640768527984618, "compression_ratio": 1.6574585635359116, "no_speech_prob": 0.017235858365893364}, {"id": 73, "seek": 50420, "start": 514.2, "end": 521.2, "text": " for this front end which works on the same device, it's fine. But because on the web front end, it's", "tokens": [50864, 337, 341, 1868, 917, 597, 1985, 322, 264, 912, 4302, 11, 309, 311, 2489, 13, 583, 570, 322, 264, 3670, 1868, 917, 11, 309, 311, 51214], "temperature": 0.0, "avg_logprob": -0.23640768527984618, "compression_ratio": 1.6574585635359116, "no_speech_prob": 0.017235858365893364}, {"id": 74, "seek": 50420, "start": 521.2, "end": 530.2, "text": " usually distant user, you need to do the work for anti-gravity again in the browser. So my long", "tokens": [51214, 2673, 17275, 4195, 11, 291, 643, 281, 360, 264, 589, 337, 6061, 12, 36418, 507, 797, 294, 264, 11185, 13, 407, 452, 938, 51664], "temperature": 0.0, "avg_logprob": -0.23640768527984618, "compression_ratio": 1.6574585635359116, "no_speech_prob": 0.017235858365893364}, {"id": 75, "seek": 53020, "start": 530.2, "end": 536.2, "text": " goal is to use the code from the backend to be able to do the encryption and decryption directly in the", "tokens": [50364, 3387, 307, 281, 764, 264, 3089, 490, 264, 38087, 281, 312, 1075, 281, 360, 264, 29575, 293, 979, 627, 1695, 3838, 294, 264, 50664], "temperature": 0.0, "avg_logprob": -0.22556553284327188, "compression_ratio": 1.7041666666666666, "no_speech_prob": 0.01615685597062111}, {"id": 76, "seek": 53020, "start": 536.2, "end": 543.2, "text": " browser and to make real and to an encryption with this front end. So the goal of the web front end is", "tokens": [50664, 11185, 293, 281, 652, 957, 293, 281, 364, 29575, 365, 341, 1868, 917, 13, 407, 264, 3387, 295, 264, 3670, 1868, 917, 307, 51014], "temperature": 0.0, "avg_logprob": -0.22556553284327188, "compression_ratio": 1.7041666666666666, "no_speech_prob": 0.01615685597062111}, {"id": 77, "seek": 53020, "start": 543.2, "end": 551.2, "text": " to have progressive announcements by default if you don't have JavaScript to have a static patch for", "tokens": [51014, 281, 362, 16131, 23785, 538, 7576, 498, 291, 500, 380, 362, 15778, 281, 362, 257, 13437, 9972, 337, 51414], "temperature": 0.0, "avg_logprob": -0.22556553284327188, "compression_ratio": 1.7041666666666666, "no_speech_prob": 0.01615685597062111}, {"id": 78, "seek": 53020, "start": 551.2, "end": 559.2, "text": " most of features, not every blog. For highly dynamic features like the chat, of course you need to be", "tokens": [51414, 881, 295, 4122, 11, 406, 633, 6968, 13, 1171, 5405, 8546, 4122, 411, 264, 5081, 11, 295, 1164, 291, 643, 281, 312, 51814], "temperature": 0.0, "avg_logprob": -0.22556553284327188, "compression_ratio": 1.7041666666666666, "no_speech_prob": 0.01615685597062111}, {"id": 79, "seek": 55920, "start": 559.2, "end": 567.2, "text": " fully dynamic. So in this case you need JavaScript enabled. It's made to be easy to develop and to", "tokens": [50364, 4498, 8546, 13, 407, 294, 341, 1389, 291, 643, 15778, 15172, 13, 467, 311, 1027, 281, 312, 1858, 281, 1499, 293, 281, 50764], "temperature": 0.0, "avg_logprob": -0.19239830017089843, "compression_ratio": 1.6938775510204083, "no_speech_prob": 0.010488778352737427}, {"id": 80, "seek": 55920, "start": 567.2, "end": 575.2, "text": " maintain and to reuse the code as much as possible from other front end. An important part of this front end is", "tokens": [50764, 6909, 293, 281, 26225, 264, 3089, 382, 709, 382, 1944, 490, 661, 1868, 917, 13, 1107, 1021, 644, 295, 341, 1868, 917, 307, 51164], "temperature": 0.0, "avg_logprob": -0.19239830017089843, "compression_ratio": 1.6938775510204083, "no_speech_prob": 0.010488778352737427}, {"id": 81, "seek": 55920, "start": 575.2, "end": 582.2, "text": " the templating system. I wanted to have templates which work at the same time in the backend, at the same", "tokens": [51164, 264, 9100, 990, 1185, 13, 286, 1415, 281, 362, 21165, 597, 589, 412, 264, 912, 565, 294, 264, 38087, 11, 412, 264, 912, 51514], "temperature": 0.0, "avg_logprob": -0.19239830017089843, "compression_ratio": 1.6938775510204083, "no_speech_prob": 0.010488778352737427}, {"id": 82, "seek": 55920, "start": 582.2, "end": 587.2, "text": " time in the browser dynamically. So I've chosen to use a Jinja 2 which is probably the most famous", "tokens": [51514, 565, 294, 264, 11185, 43492, 13, 407, 286, 600, 8614, 281, 764, 257, 10617, 2938, 568, 597, 307, 1391, 264, 881, 4618, 51764], "temperature": 0.0, "avg_logprob": -0.19239830017089843, "compression_ratio": 1.6938775510204083, "no_speech_prob": 0.010488778352737427}, {"id": 83, "seek": 58720, "start": 587.2, "end": 597.2, "text": " template engine in Python. And on JavaScript side I'm using Ninjux which is a kind of port of", "tokens": [50364, 12379, 2848, 294, 15329, 13, 400, 322, 15778, 1252, 286, 478, 1228, 16093, 73, 2449, 597, 307, 257, 733, 295, 2436, 295, 50864], "temperature": 0.0, "avg_logprob": -0.2815079044651341, "compression_ratio": 1.4874371859296482, "no_speech_prob": 0.014194144867360592}, {"id": 84, "seek": 58720, "start": 597.2, "end": 606.2, "text": " the Jinja 2 to JavaScript which is made by Mozilla. And it's mostly compatible but some filters and", "tokens": [50864, 264, 10617, 2938, 568, 281, 15778, 597, 307, 1027, 538, 3335, 26403, 13, 400, 309, 311, 5240, 18218, 457, 512, 15995, 293, 51314], "temperature": 0.0, "avg_logprob": -0.2815079044651341, "compression_ratio": 1.4874371859296482, "no_speech_prob": 0.014194144867360592}, {"id": 85, "seek": 58720, "start": 606.2, "end": 613.2, "text": " directly everything. So I do the implementation of the one I was needing in Britain. And it's working.", "tokens": [51314, 3838, 1203, 13, 407, 286, 360, 264, 11420, 295, 264, 472, 286, 390, 18006, 294, 12960, 13, 400, 309, 311, 1364, 13, 51664], "temperature": 0.0, "avg_logprob": -0.2815079044651341, "compression_ratio": 1.4874371859296482, "no_speech_prob": 0.014194144867360592}, {"id": 86, "seek": 61320, "start": 613.2, "end": 622.2, "text": " And there is easy tuning and the fact that I use the same template in the backend as a side effect that I can", "tokens": [50364, 400, 456, 307, 1858, 15164, 293, 264, 1186, 300, 286, 764, 264, 912, 12379, 294, 264, 38087, 382, 257, 1252, 1802, 300, 286, 393, 50814], "temperature": 0.0, "avg_logprob": -0.29249143600463867, "compression_ratio": 1.6881720430107527, "no_speech_prob": 0.019966617226600647}, {"id": 87, "seek": 61320, "start": 622.2, "end": 629.2, "text": " use also the template in the Cli. So if for instance you want to generate a static website from the same", "tokens": [50814, 764, 611, 264, 12379, 294, 264, 2033, 72, 13, 407, 498, 337, 5197, 291, 528, 281, 8460, 257, 13437, 3144, 490, 264, 912, 51164], "temperature": 0.0, "avg_logprob": -0.29249143600463867, "compression_ratio": 1.6881720430107527, "no_speech_prob": 0.019966617226600647}, {"id": 88, "seek": 61320, "start": 629.2, "end": 638.2, "text": " template and the interface you can do it easily. So each feature is organized in what we call page.", "tokens": [51164, 12379, 293, 264, 9226, 291, 393, 360, 309, 3612, 13, 407, 1184, 4111, 307, 9983, 294, 437, 321, 818, 3028, 13, 51614], "temperature": 0.0, "avg_logprob": -0.29249143600463867, "compression_ratio": 1.6881720430107527, "no_speech_prob": 0.019966617226600647}, {"id": 89, "seek": 63820, "start": 638.2, "end": 645.2, "text": " A leader page is basically a directory which corresponds to a new URL in the web front end. So there is no", "tokens": [50364, 316, 5263, 3028, 307, 1936, 257, 21120, 597, 23249, 281, 257, 777, 12905, 294, 264, 3670, 1868, 917, 13, 407, 456, 307, 572, 50714], "temperature": 0.0, "avg_logprob": -0.27861846120733963, "compression_ratio": 1.54, "no_speech_prob": 0.07131103426218033}, {"id": 90, "seek": 63820, "start": 645.2, "end": 654.2, "text": " router like you have in Flask. This might be easy. So one directory, one feature in URL. And in", "tokens": [50714, 22492, 411, 291, 362, 294, 3235, 3863, 13, 639, 1062, 312, 1858, 13, 407, 472, 21120, 11, 472, 4111, 294, 12905, 13, 400, 294, 51164], "temperature": 0.0, "avg_logprob": -0.27861846120733963, "compression_ratio": 1.54, "no_speech_prob": 0.07131103426218033}, {"id": 91, "seek": 63820, "start": 654.2, "end": 662.2, "text": " directory you can have a page underscore method.py file which includes a metadata such as the name of the", "tokens": [51164, 21120, 291, 393, 362, 257, 3028, 37556, 3170, 13, 8200, 3991, 597, 5974, 257, 26603, 1270, 382, 264, 1315, 295, 264, 51564], "temperature": 0.0, "avg_logprob": -0.27861846120733963, "compression_ratio": 1.54, "no_speech_prob": 0.07131103426218033}, {"id": 92, "seek": 66220, "start": 662.2, "end": 670.2, "text": " page, is the page public or private, which template to use and you can also use some Python code if you want to", "tokens": [50364, 3028, 11, 307, 264, 3028, 1908, 420, 4551, 11, 597, 12379, 281, 764, 293, 291, 393, 611, 764, 512, 15329, 3089, 498, 291, 528, 281, 50764], "temperature": 0.0, "avg_logprob": -0.2537807516149572, "compression_ratio": 1.537313432835821, "no_speech_prob": 0.15305885672569275}, {"id": 93, "seek": 66220, "start": 670.2, "end": 677.2, "text": " get data from the URL or stuff like that or under the post request. And you can have underscore", "tokens": [50764, 483, 1412, 490, 264, 12905, 420, 1507, 411, 300, 420, 833, 264, 2183, 5308, 13, 400, 291, 393, 362, 37556, 51114], "temperature": 0.0, "avg_logprob": -0.2537807516149572, "compression_ratio": 1.537313432835821, "no_speech_prob": 0.15305885672569275}, {"id": 94, "seek": 66220, "start": 677.2, "end": 685.2, "text": " browser directory with Britain part which is what we see now. And then when you send the website, the", "tokens": [51114, 11185, 21120, 365, 12960, 644, 597, 307, 437, 321, 536, 586, 13, 400, 550, 562, 291, 2845, 264, 3144, 11, 264, 51514], "temperature": 0.0, "avg_logprob": -0.2537807516149572, "compression_ratio": 1.537313432835821, "no_speech_prob": 0.15305885672569275}, {"id": 95, "seek": 68520, "start": 685.2, "end": 696.2, "text": " hierarchy automatically generated so Britain knows where to access the files. So this is a minimal", "tokens": [50364, 22333, 6772, 10833, 370, 12960, 3255, 689, 281, 2105, 264, 7098, 13, 407, 341, 307, 257, 13206, 50914], "temperature": 0.0, "avg_logprob": -0.247228158486856, "compression_ratio": 1.6984126984126984, "no_speech_prob": 0.03403768315911293}, {"id": 96, "seek": 68520, "start": 696.2, "end": 706.2, "text": " example of the page.page metadata.py file. So the name is used to be able to access the page from somewhere", "tokens": [50914, 1365, 295, 264, 3028, 13, 15161, 26603, 13, 8200, 3991, 13, 407, 264, 1315, 307, 1143, 281, 312, 1075, 281, 2105, 264, 3028, 490, 4079, 51414], "temperature": 0.0, "avg_logprob": -0.247228158486856, "compression_ratio": 1.6984126984126984, "no_speech_prob": 0.03403768315911293}, {"id": 97, "seek": 68520, "start": 706.2, "end": 712.2, "text": " else. So in this case this access profile means that you need to be logged to access this page and the template to", "tokens": [51414, 1646, 13, 407, 294, 341, 1389, 341, 2105, 7964, 1355, 300, 291, 643, 281, 312, 27231, 281, 2105, 341, 3028, 293, 264, 12379, 281, 51714], "temperature": 0.0, "avg_logprob": -0.247228158486856, "compression_ratio": 1.6984126984126984, "no_speech_prob": 0.03403768315911293}, {"id": 98, "seek": 71220, "start": 712.2, "end": 719.2, "text": " use. And here comes the Britain code. So that's what is running in the browser. So you see it's real Python. On", "tokens": [50364, 764, 13, 400, 510, 1487, 264, 12960, 3089, 13, 407, 300, 311, 437, 307, 2614, 294, 264, 11185, 13, 407, 291, 536, 309, 311, 957, 15329, 13, 1282, 50714], "temperature": 0.0, "avg_logprob": -0.2152421933795334, "compression_ratio": 1.709016393442623, "no_speech_prob": 0.03012154810130596}, {"id": 99, "seek": 71220, "start": 719.2, "end": 727.2, "text": " the top I'm using the standard JSON to do the parsing of JSON stuff. In the past, the JSON from", "tokens": [50714, 264, 1192, 286, 478, 1228, 264, 3832, 31828, 281, 360, 264, 21156, 278, 295, 31828, 1507, 13, 682, 264, 1791, 11, 264, 31828, 490, 51114], "temperature": 0.0, "avg_logprob": -0.2152421933795334, "compression_ratio": 1.709016393442623, "no_speech_prob": 0.03012154810130596}, {"id": 100, "seek": 71220, "start": 727.2, "end": 733.2, "text": " standard was a bit slow so I was using directly the JavaScript version. So you can do it but no, it's been", "tokens": [51114, 3832, 390, 257, 857, 2964, 370, 286, 390, 1228, 3838, 264, 15778, 3037, 13, 407, 291, 393, 360, 309, 457, 572, 11, 309, 311, 668, 51414], "temperature": 0.0, "avg_logprob": -0.2152421933795334, "compression_ratio": 1.709016393442623, "no_speech_prob": 0.03012154810130596}, {"id": 101, "seek": 71220, "start": 733.2, "end": 741.2, "text": " fixed and it's fully performed so I'm using directly the standard version. The bridge is just a way to", "tokens": [51414, 6806, 293, 309, 311, 4498, 10332, 370, 286, 478, 1228, 3838, 264, 3832, 3037, 13, 440, 7283, 307, 445, 257, 636, 281, 51814], "temperature": 0.0, "avg_logprob": -0.2152421933795334, "compression_ratio": 1.709016393442623, "no_speech_prob": 0.03012154810130596}, {"id": 102, "seek": 74120, "start": 741.2, "end": 749.2, "text": " communicate with the backend. The browser is an important module. Browser is what is used to manage the DOM. So", "tokens": [50364, 7890, 365, 264, 38087, 13, 440, 11185, 307, 364, 1021, 10088, 13, 1603, 30947, 307, 437, 307, 1143, 281, 3067, 264, 35727, 13, 407, 50764], "temperature": 0.0, "avg_logprob": -0.3587281920693137, "compression_ratio": 1.544186046511628, "no_speech_prob": 0.05219098925590515}, {"id": 103, "seek": 74120, "start": 749.2, "end": 756.2, "text": " document if you want to access an element. So Iopart is a Britain version of AsyncIO. AsyncIO is not exactly", "tokens": [50764, 4166, 498, 291, 528, 281, 2105, 364, 4478, 13, 407, 286, 404, 446, 307, 257, 12960, 3037, 295, 1018, 34015, 15167, 13, 1018, 34015, 15167, 307, 406, 2293, 51114], "temperature": 0.0, "avg_logprob": -0.3587281920693137, "compression_ratio": 1.544186046511628, "no_speech_prob": 0.05219098925590515}, {"id": 104, "seek": 74120, "start": 756.2, "end": 764.2, "text": " the same as in Python for reasons I explained in the doc. And Iorg is just a module to show the dialogs. So you", "tokens": [51114, 264, 912, 382, 294, 15329, 337, 4112, 286, 8825, 294, 264, 3211, 13, 400, 286, 4646, 307, 445, 257, 10088, 281, 855, 264, 19308, 82, 13, 407, 291, 51514], "temperature": 0.0, "avg_logprob": -0.3587281920693137, "compression_ratio": 1.544186046511628, "no_speech_prob": 0.05219098925590515}, {"id": 105, "seek": 76420, "start": 764.2, "end": 771.2, "text": " see I'm binding the DOM event click to a method. Normally you expect a blocking method but I want to use AsyncIO", "tokens": [50364, 536, 286, 478, 17359, 264, 35727, 2280, 2052, 281, 257, 3170, 13, 17424, 291, 2066, 257, 17776, 3170, 457, 286, 528, 281, 764, 1018, 34015, 15167, 50714], "temperature": 0.0, "avg_logprob": -0.18008391411749872, "compression_ratio": 1.6847290640394088, "no_speech_prob": 0.039631109684705734}, {"id": 106, "seek": 76420, "start": 771.2, "end": 780.2, "text": " so I use Iopart. And then you have AsyncIO method. So you see you have the event exactly like in JavaScript. You can", "tokens": [50714, 370, 286, 764, 286, 404, 446, 13, 400, 550, 291, 362, 1018, 34015, 15167, 3170, 13, 407, 291, 536, 291, 362, 264, 2280, 2293, 411, 294, 15778, 13, 509, 393, 51164], "temperature": 0.0, "avg_logprob": -0.18008391411749872, "compression_ratio": 1.6847290640394088, "no_speech_prob": 0.039631109684705734}, {"id": 107, "seek": 76420, "start": 780.2, "end": 790.2, "text": " call the method exactly like in JavaScript. Then you have the code and I'm parsing the data of the item. And I'm", "tokens": [51164, 818, 264, 3170, 2293, 411, 294, 15778, 13, 1396, 291, 362, 264, 3089, 293, 286, 478, 21156, 278, 264, 1412, 295, 264, 3174, 13, 400, 286, 478, 51664], "temperature": 0.0, "avg_logprob": -0.18008391411749872, "compression_ratio": 1.6847290640394088, "no_speech_prob": 0.039631109684705734}, {"id": 108, "seek": 79020, "start": 790.2, "end": 798.2, "text": " showing a dialog. The feature actually is you have a list for the list feature and if you want to delete a list, you", "tokens": [50364, 4099, 257, 19308, 13, 440, 4111, 767, 307, 291, 362, 257, 1329, 337, 264, 1329, 4111, 293, 498, 291, 528, 281, 12097, 257, 1329, 11, 291, 50764], "temperature": 0.0, "avg_logprob": -0.21676001437874728, "compression_ratio": 1.8064516129032258, "no_speech_prob": 0.010994287207722664}, {"id": 109, "seek": 79020, "start": 798.2, "end": 806.2, "text": " show a marker around the list and you confirm if you want to delete or not. And so you see with Await it's really", "tokens": [50764, 855, 257, 15247, 926, 264, 1329, 293, 291, 9064, 498, 291, 528, 281, 12097, 420, 406, 13, 400, 370, 291, 536, 365, 6381, 1001, 309, 311, 534, 51164], "temperature": 0.0, "avg_logprob": -0.21676001437874728, "compression_ratio": 1.8064516129032258, "no_speech_prob": 0.010994287207722664}, {"id": 110, "seek": 79020, "start": 806.2, "end": 812.2, "text": " readable and easy to do it so I can check after if it's confirmed or not and if it's confirmed I send the", "tokens": [51164, 49857, 293, 1858, 281, 360, 309, 370, 286, 393, 1520, 934, 498, 309, 311, 11341, 420, 406, 293, 498, 309, 311, 11341, 286, 2845, 264, 51464], "temperature": 0.0, "avg_logprob": -0.21676001437874728, "compression_ratio": 1.8064516129032258, "no_speech_prob": 0.010994287207722664}, {"id": 111, "seek": 81220, "start": 812.2, "end": 821.2, "text": " deletion request or otherwise I just remove the stuff. So this code is doing this. So we just click on the", "tokens": [50364, 1103, 302, 313, 5308, 420, 5911, 286, 445, 4159, 264, 1507, 13, 407, 341, 3089, 307, 884, 341, 13, 407, 321, 445, 2052, 322, 264, 50814], "temperature": 0.0, "avg_logprob": -0.2260255698698113, "compression_ratio": 1.5674418604651164, "no_speech_prob": 0.10045693069696426}, {"id": 112, "seek": 81220, "start": 821.2, "end": 828.2, "text": " delete showing the dialog and here I'm canceling and it's removing the flag. So yeah, it's working like it will do in", "tokens": [50814, 12097, 4099, 264, 19308, 293, 510, 286, 478, 10373, 278, 293, 309, 311, 12720, 264, 7166, 13, 407, 1338, 11, 309, 311, 1364, 411, 309, 486, 360, 294, 51164], "temperature": 0.0, "avg_logprob": -0.2260255698698113, "compression_ratio": 1.5674418604651164, "no_speech_prob": 0.10045693069696426}, {"id": 113, "seek": 81220, "start": 828.2, "end": 836.2, "text": " JavaScript. About debugging. So when something is going wrong, what is really nice with Britain is you have real", "tokens": [51164, 15778, 13, 7769, 45592, 13, 407, 562, 746, 307, 516, 2085, 11, 437, 307, 534, 1481, 365, 12960, 307, 291, 362, 957, 51564], "temperature": 0.0, "avg_logprob": -0.2260255698698113, "compression_ratio": 1.5674418604651164, "no_speech_prob": 0.10045693069696426}, {"id": 114, "seek": 83620, "start": 836.2, "end": 843.2, "text": " Python, Transback, with the line of the source code and everything so it's really easy to debug. Sometimes", "tokens": [50364, 15329, 11, 6531, 3207, 11, 365, 264, 1622, 295, 264, 4009, 3089, 293, 1203, 370, 309, 311, 534, 1858, 281, 24083, 13, 4803, 50714], "temperature": 0.0, "avg_logprob": -0.3119052452377126, "compression_ratio": 1.5, "no_speech_prob": 0.06870231032371521}, {"id": 115, "seek": 83620, "start": 843.2, "end": 850.2, "text": " unfortunately you have JavaScript exception. Usually in this case it's better to report to Breton because it means", "tokens": [50714, 7015, 291, 362, 15778, 11183, 13, 11419, 294, 341, 1389, 309, 311, 1101, 281, 2275, 281, 42000, 266, 570, 309, 1355, 51064], "temperature": 0.0, "avg_logprob": -0.3119052452377126, "compression_ratio": 1.5, "no_speech_prob": 0.06870231032371521}, {"id": 116, "seek": 83620, "start": 850.2, "end": 859.2, "text": " it's a bug but it's happening less and less often. You can use breakpoint and PDB so your code will be blocking", "tokens": [51064, 309, 311, 257, 7426, 457, 309, 311, 2737, 1570, 293, 1570, 2049, 13, 509, 393, 764, 1821, 6053, 293, 10464, 33, 370, 428, 3089, 486, 312, 17776, 51514], "temperature": 0.0, "avg_logprob": -0.3119052452377126, "compression_ratio": 1.5, "no_speech_prob": 0.06870231032371521}, {"id": 117, "seek": 85920, "start": 859.2, "end": 867.2, "text": " the browser and you will have another box where you can use PDB instruction and there is also an inspector module", "tokens": [50364, 264, 11185, 293, 291, 486, 362, 1071, 2424, 689, 291, 393, 764, 10464, 33, 10951, 293, 456, 307, 611, 364, 34564, 10088, 50764], "temperature": 0.0, "avg_logprob": -0.1835893086024693, "compression_ratio": 1.6839378238341969, "no_speech_prob": 0.08500278741121292}, {"id": 118, "seek": 85920, "start": 867.2, "end": 874.2, "text": " which in this case your code is running normally but you have a Python console and you can inspect the local", "tokens": [50764, 597, 294, 341, 1389, 428, 3089, 307, 2614, 5646, 457, 291, 362, 257, 15329, 11076, 293, 291, 393, 15018, 264, 2654, 51114], "temperature": 0.0, "avg_logprob": -0.1835893086024693, "compression_ratio": 1.6839378238341969, "no_speech_prob": 0.08500278741121292}, {"id": 119, "seek": 85920, "start": 874.2, "end": 883.2, "text": " variant that you have where you run the inspector. Regarding performances, according to the doc I have", "tokens": [51114, 17501, 300, 291, 362, 689, 291, 1190, 264, 34564, 13, 35523, 16087, 11, 4650, 281, 264, 3211, 286, 362, 51564], "temperature": 0.0, "avg_logprob": -0.1835893086024693, "compression_ratio": 1.6839378238341969, "no_speech_prob": 0.08500278741121292}, {"id": 120, "seek": 88320, "start": 883.2, "end": 892.2, "text": " a benchmark myself but it's comparable to CPyton because JavaScript is probably one of the most optimized", "tokens": [50364, 257, 18927, 2059, 457, 309, 311, 25323, 281, 22431, 88, 1756, 570, 15778, 307, 1391, 472, 295, 264, 881, 26941, 50814], "temperature": 0.0, "avg_logprob": -0.28279487759459254, "compression_ratio": 1.4161490683229814, "no_speech_prob": 0.09556465595960617}, {"id": 121, "seek": 88320, "start": 892.2, "end": 904.2, "text": " engines in the world in Chrome and Firefox. So it's comparable, sometimes slower, sometimes quicker. Of course it's slower", "tokens": [50814, 12982, 294, 264, 1002, 294, 15327, 293, 46613, 13, 407, 309, 311, 25323, 11, 2171, 14009, 11, 2171, 16255, 13, 2720, 1164, 309, 311, 14009, 51414], "temperature": 0.0, "avg_logprob": -0.28279487759459254, "compression_ratio": 1.4161490683229814, "no_speech_prob": 0.09556465595960617}, {"id": 122, "seek": 90420, "start": 904.2, "end": 911.2, "text": " than pure JavaScript because there is a compatibility time and the compatibility layer but the", "tokens": [50364, 813, 6075, 15778, 570, 456, 307, 257, 34237, 565, 293, 264, 34237, 4583, 457, 264, 50714], "temperature": 0.0, "avg_logprob": -0.30352226675373234, "compression_ratio": 1.626865671641791, "no_speech_prob": 0.12038066983222961}, {"id": 123, "seek": 90420, "start": 911.2, "end": 919.2, "text": " compatibility is done only once after it's cached and for compatibility layer it's working okay. By default you have a", "tokens": [50714, 34237, 307, 1096, 787, 1564, 934, 309, 311, 269, 15095, 293, 337, 34237, 4583, 309, 311, 1364, 1392, 13, 3146, 7576, 291, 362, 257, 51114], "temperature": 0.0, "avg_logprob": -0.30352226675373234, "compression_ratio": 1.626865671641791, "no_speech_prob": 0.12038066983222961}, {"id": 124, "seek": 90420, "start": 919.2, "end": 927.2, "text": " world standard lib which is kind of heavy between 4 and 5 megabytes. Normally you don't want to use that. You can", "tokens": [51114, 1002, 3832, 22854, 597, 307, 733, 295, 4676, 1296, 1017, 293, 1025, 10816, 24538, 13, 17424, 291, 500, 380, 528, 281, 764, 300, 13, 509, 393, 51514], "temperature": 0.0, "avg_logprob": -0.30352226675373234, "compression_ratio": 1.626865671641791, "no_speech_prob": 0.12038066983222961}, {"id": 125, "seek": 92720, "start": 927.2, "end": 934.2, "text": " either not use at all or you have a small tool which will check your source code and which module you are actually using", "tokens": [50364, 2139, 406, 764, 412, 439, 420, 291, 362, 257, 1359, 2290, 597, 486, 1520, 428, 4009, 3089, 293, 597, 10088, 291, 366, 767, 1228, 50714], "temperature": 0.0, "avg_logprob": -0.17010295391082764, "compression_ratio": 1.6274509803921569, "no_speech_prob": 0.2027006894350052}, {"id": 126, "seek": 92720, "start": 934.2, "end": 943.2, "text": " and make something smaller and totally usable. So the loading time anyway is cached, it's in cached so after it has been", "tokens": [50714, 293, 652, 746, 4356, 293, 3879, 29975, 13, 407, 264, 15114, 565, 4033, 307, 269, 15095, 11, 309, 311, 294, 269, 15095, 370, 934, 309, 575, 668, 51164], "temperature": 0.0, "avg_logprob": -0.17010295391082764, "compression_ratio": 1.6274509803921569, "no_speech_prob": 0.2027006894350052}, {"id": 127, "seek": 92720, "start": 943.2, "end": 949.2, "text": " used at least once it's quick to learn. So from my experience and I have not yet worked on", "tokens": [51164, 1143, 412, 1935, 1564, 309, 311, 1702, 281, 1466, 13, 407, 490, 452, 1752, 293, 286, 362, 406, 1939, 2732, 322, 51464], "temperature": 0.0, "avg_logprob": -0.17010295391082764, "compression_ratio": 1.6274509803921569, "no_speech_prob": 0.2027006894350052}, {"id": 128, "seek": 94920, "start": 949.2, "end": 958.2, "text": " optimization it's working absolutely fine at least from my use case. So now the roadmap. In the future I want to", "tokens": [50364, 19618, 309, 311, 1364, 3122, 2489, 412, 1935, 490, 452, 764, 1389, 13, 407, 586, 264, 35738, 13, 682, 264, 2027, 286, 528, 281, 50814], "temperature": 0.0, "avg_logprob": -0.25269181387765066, "compression_ratio": 1.559090909090909, "no_speech_prob": 0.47096017003059387}, {"id": 129, "seek": 94920, "start": 958.2, "end": 965.2, "text": " integrate more Britons, notably in the loading parts because I want to do something more like modern social network", "tokens": [50814, 13365, 544, 4760, 892, 11, 31357, 294, 264, 15114, 3166, 570, 286, 528, 281, 360, 746, 544, 411, 4363, 2093, 3209, 51164], "temperature": 0.0, "avg_logprob": -0.25269181387765066, "compression_ratio": 1.559090909090909, "no_speech_prob": 0.47096017003059387}, {"id": 130, "seek": 94920, "start": 965.2, "end": 973.2, "text": " experience with reaction and everything. So use kind of the backend, as I say it's really important for end to end", "tokens": [51164, 1752, 365, 5480, 293, 1203, 13, 407, 764, 733, 295, 264, 38087, 11, 382, 286, 584, 309, 311, 534, 1021, 337, 917, 281, 917, 51564], "temperature": 0.0, "avg_logprob": -0.25269181387765066, "compression_ratio": 1.559090909090909, "no_speech_prob": 0.47096017003059387}, {"id": 131, "seek": 97320, "start": 973.2, "end": 983.2, "text": " encryption. I want to be able to get the stuff which are done the way we format the XMPP standards etc. and do it in the", "tokens": [50364, 29575, 13, 286, 528, 281, 312, 1075, 281, 483, 264, 1507, 597, 366, 1096, 264, 636, 321, 7877, 264, 1783, 12224, 47, 7787, 5183, 13, 293, 360, 309, 294, 264, 50864], "temperature": 0.0, "avg_logprob": -0.20179784562852648, "compression_ratio": 1.6635514018691588, "no_speech_prob": 0.0605744905769825}, {"id": 132, "seek": 97320, "start": 983.2, "end": 991.2, "text": " browser so we have real end to end encryption. And I would like to experiment what we can do with the Python in the", "tokens": [50864, 11185, 370, 321, 362, 957, 917, 281, 917, 29575, 13, 400, 286, 576, 411, 281, 5120, 437, 321, 393, 360, 365, 264, 15329, 294, 264, 51264], "temperature": 0.0, "avg_logprob": -0.20179784562852648, "compression_ratio": 1.6635514018691588, "no_speech_prob": 0.0605744905769825}, {"id": 133, "seek": 97320, "start": 991.2, "end": 999.2, "text": " browser. I'm thinking there are a lot of fields where we can do that. In education we can imagine a chat where we could", "tokens": [51264, 11185, 13, 286, 478, 1953, 456, 366, 257, 688, 295, 7909, 689, 321, 393, 360, 300, 13, 682, 3309, 321, 393, 3811, 257, 5081, 689, 321, 727, 51664], "temperature": 0.0, "avg_logprob": -0.20179784562852648, "compression_ratio": 1.6635514018691588, "no_speech_prob": 0.0605744905769825}, {"id": 134, "seek": 99920, "start": 999.2, "end": 1007.2, "text": " have Python console, it could be used for instance to learn Python itself or to do mathematics in a school or this kind of", "tokens": [50364, 362, 15329, 11076, 11, 309, 727, 312, 1143, 337, 5197, 281, 1466, 15329, 2564, 420, 281, 360, 18666, 294, 257, 1395, 420, 341, 733, 295, 50764], "temperature": 0.0, "avg_logprob": -0.29226778841566764, "compression_ratio": 1.593073593073593, "no_speech_prob": 0.023123348131775856}, {"id": 135, "seek": 99920, "start": 1007.2, "end": 1016.2, "text": " things. For science of course it will be super useful. Maybe we can try to use the work done by the PIOD to also try to run", "tokens": [50764, 721, 13, 1171, 3497, 295, 1164, 309, 486, 312, 1687, 4420, 13, 2704, 321, 393, 853, 281, 764, 264, 589, 1096, 538, 264, 430, 15167, 35, 281, 611, 853, 281, 1190, 51214], "temperature": 0.0, "avg_logprob": -0.29226778841566764, "compression_ratio": 1.593073593073593, "no_speech_prob": 0.023123348131775856}, {"id": 136, "seek": 99920, "start": 1016.2, "end": 1025.2, "text": " some scientific stack. And automation and visualize that it could be possible to do filter in Python when you have a chat", "tokens": [51214, 512, 8134, 8630, 13, 400, 17769, 293, 23273, 300, 309, 727, 312, 1944, 281, 360, 6608, 294, 15329, 562, 291, 362, 257, 5081, 51664], "temperature": 0.0, "avg_logprob": -0.29226778841566764, "compression_ratio": 1.593073593073593, "no_speech_prob": 0.023123348131775856}, {"id": 137, "seek": 102520, "start": 1025.2, "end": 1037.2, "text": " message or block message and to see if you want to do something on it or not. So, for my experience, is a robust solution for", "tokens": [50364, 3636, 420, 3461, 3636, 293, 281, 536, 498, 291, 528, 281, 360, 746, 322, 309, 420, 406, 13, 407, 11, 337, 452, 1752, 11, 307, 257, 13956, 3827, 337, 50964], "temperature": 0.0, "avg_logprob": -0.31559032504841433, "compression_ratio": 1.471264367816092, "no_speech_prob": 0.0348101407289505}, {"id": 138, "seek": 102520, "start": 1037.2, "end": 1046.2, "text": " integrating Python into the web development. The community is nice which is really important part and it's allowed to use the same", "tokens": [50964, 26889, 15329, 666, 264, 3670, 3250, 13, 440, 1768, 307, 1481, 597, 307, 534, 1021, 644, 293, 309, 311, 4350, 281, 764, 264, 912, 51414], "temperature": 0.0, "avg_logprob": -0.31559032504841433, "compression_ratio": 1.471264367816092, "no_speech_prob": 0.0348101407289505}, {"id": 139, "seek": 104620, "start": 1046.2, "end": 1054.2, "text": " code in the backend and in the front end which is really time saving and avoid to have people specialize in one language or one", "tokens": [50364, 3089, 294, 264, 38087, 293, 294, 264, 1868, 917, 597, 307, 534, 565, 6816, 293, 5042, 281, 362, 561, 37938, 294, 472, 2856, 420, 472, 50764], "temperature": 0.0, "avg_logprob": -0.3033309056208684, "compression_ratio": 1.5029239766081872, "no_speech_prob": 0.25736021995544434}, {"id": 140, "seek": 104620, "start": 1054.2, "end": 1065.2, "text": " other language. So, that's it for this talk. You can check Brithu on this website. You can check my project on Libervia. I have a", "tokens": [50764, 661, 2856, 13, 407, 11, 300, 311, 309, 337, 341, 751, 13, 509, 393, 1520, 1603, 355, 84, 322, 341, 3144, 13, 509, 393, 1520, 452, 1716, 322, 14175, 11617, 13, 286, 362, 257, 51314], "temperature": 0.0, "avg_logprob": -0.3033309056208684, "compression_ratio": 1.5029239766081872, "no_speech_prob": 0.25736021995544434}, {"id": 141, "seek": 106520, "start": 1065.2, "end": 1079.2, "text": " blog accessible by XMPP, activity pub or Atom. You have Atom field of course. Where I'm talking about project money and stuff I'm doing with", "tokens": [50364, 6968, 9515, 538, 1783, 12224, 47, 11, 5191, 1535, 420, 1711, 298, 13, 509, 362, 1711, 298, 2519, 295, 1164, 13, 2305, 286, 478, 1417, 466, 1716, 1460, 293, 1507, 286, 478, 884, 365, 51064], "temperature": 0.0, "avg_logprob": -0.40598919517115545, "compression_ratio": 1.1666666666666667, "no_speech_prob": 0.4136717617511749}, {"id": 142, "seek": 107920, "start": 1079.2, "end": 1093.2, "text": " Brithu and etc. And you can look for help in the Libervia chat room on XMPP or PINGMI. This is my other activity pub and I hope I give you the", "tokens": [50364, 1603, 355, 84, 293, 5183, 13, 400, 291, 393, 574, 337, 854, 294, 264, 14175, 11617, 5081, 1808, 322, 1783, 12224, 47, 420, 430, 3017, 13808, 13, 639, 307, 452, 661, 5191, 1535, 293, 286, 1454, 286, 976, 291, 264, 51064], "temperature": 0.0, "avg_logprob": -0.30583763122558594, "compression_ratio": 1.4759358288770053, "no_speech_prob": 0.660416305065155}, {"id": 143, "seek": 107920, "start": 1093.2, "end": 1100.2, "text": " test to try Brithu and see what you can do with it. You have a console in the Brithu official website so you can use it right now and", "tokens": [51064, 1500, 281, 853, 1603, 355, 84, 293, 536, 437, 291, 393, 360, 365, 309, 13, 509, 362, 257, 11076, 294, 264, 1603, 355, 84, 4783, 3144, 370, 291, 393, 764, 309, 558, 586, 293, 51414], "temperature": 0.0, "avg_logprob": -0.30583763122558594, "compression_ratio": 1.4759358288770053, "no_speech_prob": 0.660416305065155}, {"id": 144, "seek": 110020, "start": 1100.2, "end": 1109.2, "text": " just try to play with it and see how it works and what you can do with it. So, thank you very much. If you have any questions.", "tokens": [50364, 445, 853, 281, 862, 365, 309, 293, 536, 577, 309, 1985, 293, 437, 291, 393, 360, 365, 309, 13, 407, 11, 1309, 291, 588, 709, 13, 759, 291, 362, 604, 1651, 13, 50814], "temperature": 0.0, "avg_logprob": -0.19008135795593262, "compression_ratio": 1.26, "no_speech_prob": 0.5285043120384216}, {"id": 145, "seek": 110920, "start": 1109.2, "end": 1111.2, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 50464], "temperature": 0.0, "avg_logprob": -0.9133133888244629, "compression_ratio": 0.7894736842105263, "no_speech_prob": 0.22303421795368195}, {"id": 146, "seek": 110920, "start": 1119.2, "end": 1121.2, "text": " Any questions? Yes.", "tokens": [50864, 2639, 1651, 30, 1079, 13, 50964], "temperature": 0.0, "avg_logprob": -0.9133133888244629, "compression_ratio": 0.7894736842105263, "no_speech_prob": 0.22303421795368195}, {"id": 147, "seek": 112120, "start": 1121.2, "end": 1139.2, "text": " Yes. How do you set up the web server? You must serve it somehow, the Brithun code. Do you have to do some kind of special thing to make the", "tokens": [50364, 1079, 13, 1012, 360, 291, 992, 493, 264, 3670, 7154, 30, 509, 1633, 4596, 309, 6063, 11, 264, 1603, 355, 409, 3089, 13, 1144, 291, 362, 281, 360, 512, 733, 295, 2121, 551, 281, 652, 264, 51264], "temperature": 0.0, "avg_logprob": -0.3121876001358032, "compression_ratio": 1.238938053097345, "no_speech_prob": 0.19299110770225525}, {"id": 148, "seek": 113920, "start": 1139.2, "end": 1152.2, "text": " Brithu bridge work? Web soket is support directly. I'm using JavaScript code directly and I'm sending, I'm using JSON to work with the bridge", "tokens": [50364, 1603, 355, 84, 7283, 589, 30, 9573, 370, 5758, 307, 1406, 3838, 13, 286, 478, 1228, 15778, 3089, 3838, 293, 286, 478, 7750, 11, 286, 478, 1228, 31828, 281, 589, 365, 264, 7283, 51014], "temperature": 0.0, "avg_logprob": -0.3870331827799479, "compression_ratio": 1.574585635359116, "no_speech_prob": 0.44847023487091064}, {"id": 149, "seek": 113920, "start": 1152.2, "end": 1160.2, "text": " also in the back end. So, it's native in JavaScript and with Brithun it's easy to access. And Web soket is straightforward. No problem with it.", "tokens": [51014, 611, 294, 264, 646, 917, 13, 407, 11, 309, 311, 8470, 294, 15778, 293, 365, 1603, 355, 409, 309, 311, 1858, 281, 2105, 13, 400, 9573, 370, 5758, 307, 15325, 13, 883, 1154, 365, 309, 13, 51414], "temperature": 0.0, "avg_logprob": -0.3870331827799479, "compression_ratio": 1.574585635359116, "no_speech_prob": 0.44847023487091064}, {"id": 150, "seek": 116020, "start": 1160.2, "end": 1172.2, "text": " So, I send the Web soket to the HTTP server which in turn it's also doing the security stuff because of course from the browser you can trust it. So, I check if you have a right to use this method, etc.", "tokens": [50364, 407, 11, 286, 2845, 264, 9573, 370, 5758, 281, 264, 33283, 7154, 597, 294, 1261, 309, 311, 611, 884, 264, 3825, 1507, 570, 295, 1164, 490, 264, 11185, 291, 393, 3361, 309, 13, 407, 11, 286, 1520, 498, 291, 362, 257, 558, 281, 764, 341, 3170, 11, 5183, 13, 50964], "temperature": 0.0, "avg_logprob": -0.2355818920824901, "compression_ratio": 1.5167464114832536, "no_speech_prob": 0.2664828896522522}, {"id": 151, "seek": 116020, "start": 1172.2, "end": 1181.2, "text": " And then sending from the IPC. IPC can change but usually it's the bus that we use between front end and back end.", "tokens": [50964, 400, 550, 7750, 490, 264, 8671, 34, 13, 8671, 34, 393, 1319, 457, 2673, 309, 311, 264, 1255, 300, 321, 764, 1296, 1868, 917, 293, 646, 917, 13, 51414], "temperature": 0.0, "avg_logprob": -0.2355818920824901, "compression_ratio": 1.5167464114832536, "no_speech_prob": 0.2664828896522522}, {"id": 152, "seek": 118120, "start": 1181.2, "end": 1186.2, "text": " Thank you. And great that you support the XMPP world.", "tokens": [50364, 1044, 291, 13, 400, 869, 300, 291, 1406, 264, 1783, 12224, 47, 1002, 13, 50614], "temperature": 0.0, "avg_logprob": -0.26015720000633824, "compression_ratio": 1.2195121951219512, "no_speech_prob": 0.20033890008926392}, {"id": 153, "seek": 118120, "start": 1186.2, "end": 1188.2, "text": " Thank you.", "tokens": [50614, 1044, 291, 13, 50714], "temperature": 0.0, "avg_logprob": -0.26015720000633824, "compression_ratio": 1.2195121951219512, "no_speech_prob": 0.20033890008926392}, {"id": 154, "seek": 118120, "start": 1188.2, "end": 1190.2, "text": " Any questions?", "tokens": [50714, 2639, 1651, 30, 50814], "temperature": 0.0, "avg_logprob": -0.26015720000633824, "compression_ratio": 1.2195121951219512, "no_speech_prob": 0.20033890008926392}, {"id": 155, "seek": 118120, "start": 1193.2, "end": 1195.2, "text": " No one?", "tokens": [50964, 883, 472, 30, 51064], "temperature": 0.0, "avg_logprob": -0.26015720000633824, "compression_ratio": 1.2195121951219512, "no_speech_prob": 0.20033890008926392}, {"id": 156, "seek": 118120, "start": 1195.2, "end": 1200.2, "text": " Okay, then I guess it's a wrap. So, thanks again for the talk.", "tokens": [51064, 1033, 11, 550, 286, 2041, 309, 311, 257, 7019, 13, 407, 11, 3231, 797, 337, 264, 751, 13, 51314], "temperature": 0.0, "avg_logprob": -0.26015720000633824, "compression_ratio": 1.2195121951219512, "no_speech_prob": 0.20033890008926392}], "language": "en"}