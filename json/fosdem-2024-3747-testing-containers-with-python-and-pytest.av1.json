{"text": " Okay, next we have Dan Chudamak with testing containers with Python and PyTest. Wow, thanks. You haven't heard the talk yet, but thank you. So, first, the boring part, I'm Dan, I'm a software developer working for SUSE, I do other stuff, but since we only have 15 minutes, I'm just going to jump right into the meet, and that's why should you test containers? I'm not going to answer that, please test your containers if you deploy applications or anything else. And the first question usually people ask is, why don't you use shell scripts? Because I mean, shell scripts, they are super portable, they run everywhere, and shell scripts are also pretty fast. And given that shell scripts run everywhere, and they are so super-duper portable, everyone understands them. Apparently, I'm not everyone. Because in my opinion, shell scripts are very brittle, especially once I have to do string modeling, that's the point where I start to test my tests. And if I need to write tests to test my tests, I think I'm doing it wrong. You can disagree, but so let me give you the short sales pitch, why you should use Python, PyTest, and especially this is about a PyTest plugin that I wrote that's called PyTestContainer. So, what this thing can do for you is, it handles all the boring plumbing part of a test suite for containers, like pulling images, building containers, launching everything, and cleaning up, and not leaving you with terabytes of stale data. It uses the Python test-infra module, in case you know Python, PyTest, this is just another convenience module to just access files, check whether there are open ports, stuff that you can do with the Python standard library, but it's just another convenience layer there. One part that took more time than I care to admit, but that I'm moderately proud about is that the whole test suite is designed, it supports parallel test runs. So, if you use the PyTest X-Test plugin, it allows you to execute all your tests in parallel, so assuming you have 500 cores, you can run 500 tests in parallel. And the whole thing also works if your container images expose ports, provided you don't open a thousand ports on each and run 500 tests in parallel, then you'll run out of three ports. But there's tools for that. If you're using Podman and not just Docker, it can also work with Podman parts. You can also create abstractions to create container volumes and it will clean up after itself. Also, if you're more into the area, I have an application and I want to check whether it works not just on my box, but also on Fedora, CentOS, Debian, Arc Linux, Alpine, and whatever else there is in the world. You can just define a set of tests and you tell the plugin on which container images to execute them and it will do that for you. So, that allows you to have the same set of tests and run that on different containers, which would be, that would be more into the area that you are looking to test an application. It works with Podman and Docker, you just change it by changing environment variable. And if you happen to be in the lucky position to support enterprise-grade software that's very stable, hence very old, it still works with Python 3.6 and on all the important architectures, which took also more time than I care to admit. So, let's just take a look at a very simple example. This would be just a typical Python test file with your imports, then you define your container image. In this case, it's just the open-source-at-umbleweed image. And then you define a very trivial test. And in this case, what you can see here is, so this stuff here, that's really what testing for shines and it just takes a look at the O.S. release there. Very simple test, but you could do more elaborate examples. So, what are possible use cases? Of course, you'll just base images, you could test those, you could do applications inside containers, and another test, another possible use case would be you have an application and you want to check whether the application works on multiple O.S.s, but you don't need virtual machines for that. Then you could use PyTest container for that as well. So, I guess if you're in this talk, you might know a bit about PyTest and as the name suggests, it's a Python testing framework, otherwise the name would be very bad. All it really does is assemble tests, so it's like unit test on steroids, executes all test functions. And one thing that PyTest container uses extensively are fixtures. If you're not known to PyTest, you probably know setup and tear down functions from all other testing frameworks and PyTest fixtures are kind of the thing there. So, a fixture is really just a parameter for a test function and it can return a certain value and before that do some setup, give you something in this very simple example. This is from the PyTest docs, so it would give you, it would for instance create a mock SMTP connection and for the PyTest container, it gives you a connection to the already created container. And another cool thing that PyTest has is test parameterization, where you can just define multiple parameters. So, in this case, you would get your, you would have a test and you want to execute it for all combinations of those values, so it would run your test for all the, for the whole Cartesian product, so all combinations of 0, 1 and 2 and 3. Let's just jump into a few usage examples. So, in case you want to build new containers, you just define yourself the base URL, you have the, you define yourself the docker file and you create the creatively named class derived container and if you didn't already see, I shouldn't be in charge of naming things because I'm terrible at it, but I'm not very creative. But so, what will happen now if you pass this, if you pass this created class into your test function, the plugin will first pull your, pull the space image, it will build the container on top of that, launch it, pass it into this, pass it into the test function and once the test is executed, it will get cleaned up. You can also, so you can also define pass in other already created containers into this as a base, that all works. I have an example for that later. As I mentioned, binding free ports, you might not say, why don't you just add a parameter somewhere, okay, expose port 8000 on the host and that works as long as you only launch, as you don't launch tests in parallel. So, if you want to launch, if you for instance want to test this specific container five times in parallel, you can't bind all of them to the same port and for that, there's a relatively simple abstraction. So, you just create this port forwarding class, pass it into the container and then it will get exposed in the test. There, you will get the host port and this is inferred automatically on launch of the test. If you want to test ports, so this is very apartment specific, works rather like this. So, essentially a port is just a combination of containers and the only really interesting part that you want to use it for is again port forwarding, works exactly the same like with containers. One little catch. So, so far I was telling, I was claiming that your containers would be launched after the test and destroyed after the test and that's not entirely true because most tests don't modify the container and then you can get away with creating your container before all tests and tearing it down after all tests and you save actually a substantial amount of time. But if you decide to do tests like these where you try whether RM minus RF actually works, then any subsequent, any subsequent test will fail and start burning. So, and therefore there's a different fixture that's called just container per test and that will actually ensure that all, that you just get a fresh container for every test but it costs extra. So, but then you can also RM minus RF everything in your container and the subsequent container will still kind of work. For the case where you decide, where you want to run a bunch of tests, but you don't want to do the whole pie test parameterization before that, you can just dump all your containers into a global variable that's called container images and pie test will do the automatic parameterization. So, in this case, these, all the tests in the test module would get executed with all these containers and that's for instance what, what we're doing in, in the, in the, for Kiwi test functions where you just want to ensure, okay, they work on CentroStream, Fedora, DBN, R-Clinux, etc. Pp. What I've, what I hinted on previously that's dependencies between containers which is essentially just you want to build a container based on another one, based on another one, which would essentially be just you, you split up your, you would split up your Docker file. This might sound like maybe a weird idea at first but it can be, it can be relatively useful if you have, if you want to check different base images and then build stuff on top of them or you want to, or you decide to modify your base image. So, we have used this relatively extensively in the BCI test suite and you can, you can simply create containers that derive from others and that derive from others and you can do this relatively extensively, just don't add loops. That, that will not work. In case you want to, want to check whether, for instance, the environment in your container is still, is what you, what you expect or some config and you don't want to mess with the JSON that Docker Inspector, Portman Inspector gives you, that's also to a certain extent implemented. So, you'll get, you'll get a Python usable version of the inspect of a container where you can, for instance, check what's the user in there, what's the CMD of this container, if there's something in the environment and other stuff. Since I'm nearly out of time, I'm going to jump over this since it's not really that interesting actually. One important thing is if you are, so if you create an application in your container, applications usually take time to launch, please use health checks. Health checks are cool. I know they are not part of the OCI spec, that's a bummer, but please use health checks. Because if you start using a test suite and you, and you yourself execute a test manually, you launch your container, you try to curl where the application is there and it all works and then you automate it and it suddenly fails because the machine is much faster than you are. And your application is simply not up there. What PyTest container supports, if your app, if your container image has a health check defined, it will wait until the container is healthy. And as long as it's not healthy, it will not execute your test. If it becomes unhealthy, your test immediately fails. So, if you add a health check into your container file or if it's just in the image, then it will wait and it will start execute the test and you can always be sure that your container will be healthy. And if you don't want that for whatever reason, then you can just say, okay, I don't care about health checks. Then you just define the timeout to be minus one or you comment the health check out, but well. And then you can, then your container might not, might still be starting or it might be unhealthy. As I said, by default, it will use, it will pick Portman, but you can just set use Docker. And what I'm, as I said, moderately proud is you can just run your tests in parallel. That also works with port forwardings. So, that can save you a lot of time unless all your container builds run themselves in parallel. So, then you're not going to save a lot. The thing cleans up very well after itself. So, if you create containers of volumes or parts or temporary directories, all that gets cleaned up, images and intermediate layers are retained because otherwise it would just take forever and ever. There's a few people that use it. Most of them are those that I bullied into that, but maybe you find this useful and you will be on this list. And since I'm out of time, thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 15.0, "text": " Okay, next we have Dan Chudamak with testing containers with Python and PyTest.", "tokens": [50364, 1033, 11, 958, 321, 362, 3394, 761, 532, 335, 514, 365, 4997, 17089, 365, 15329, 293, 9953, 51, 377, 13, 51114], "temperature": 0.0, "avg_logprob": -0.34412899017333987, "compression_ratio": 1.2651515151515151, "no_speech_prob": 0.1331184059381485}, {"id": 1, "seek": 0, "start": 15.0, "end": 26.36, "text": " Wow, thanks. You haven't heard the talk yet, but thank you. So, first, the boring part,", "tokens": [51114, 3153, 11, 3231, 13, 509, 2378, 380, 2198, 264, 751, 1939, 11, 457, 1309, 291, 13, 407, 11, 700, 11, 264, 9989, 644, 11, 51682], "temperature": 0.0, "avg_logprob": -0.34412899017333987, "compression_ratio": 1.2651515151515151, "no_speech_prob": 0.1331184059381485}, {"id": 2, "seek": 2636, "start": 26.36, "end": 32.04, "text": " I'm Dan, I'm a software developer working for SUSE, I do other stuff, but since we only", "tokens": [50364, 286, 478, 3394, 11, 286, 478, 257, 4722, 10754, 1364, 337, 40117, 36, 11, 286, 360, 661, 1507, 11, 457, 1670, 321, 787, 50648], "temperature": 0.0, "avg_logprob": -0.24761110941569012, "compression_ratio": 1.5258620689655173, "no_speech_prob": 0.12674765288829803}, {"id": 3, "seek": 2636, "start": 32.04, "end": 39.56, "text": " have 15 minutes, I'm just going to jump right into the meet, and that's why should you test", "tokens": [50648, 362, 2119, 2077, 11, 286, 478, 445, 516, 281, 3012, 558, 666, 264, 1677, 11, 293, 300, 311, 983, 820, 291, 1500, 51024], "temperature": 0.0, "avg_logprob": -0.24761110941569012, "compression_ratio": 1.5258620689655173, "no_speech_prob": 0.12674765288829803}, {"id": 4, "seek": 2636, "start": 39.56, "end": 43.36, "text": " containers? I'm not going to answer that, please test your containers if you deploy", "tokens": [51024, 17089, 30, 286, 478, 406, 516, 281, 1867, 300, 11, 1767, 1500, 428, 17089, 498, 291, 7274, 51214], "temperature": 0.0, "avg_logprob": -0.24761110941569012, "compression_ratio": 1.5258620689655173, "no_speech_prob": 0.12674765288829803}, {"id": 5, "seek": 2636, "start": 43.36, "end": 50.68, "text": " applications or anything else. And the first question usually people ask is, why don't you", "tokens": [51214, 5821, 420, 1340, 1646, 13, 400, 264, 700, 1168, 2673, 561, 1029, 307, 11, 983, 500, 380, 291, 51580], "temperature": 0.0, "avg_logprob": -0.24761110941569012, "compression_ratio": 1.5258620689655173, "no_speech_prob": 0.12674765288829803}, {"id": 6, "seek": 5068, "start": 50.68, "end": 57.519999999999996, "text": " use shell scripts? Because I mean, shell scripts, they are super portable, they run everywhere,", "tokens": [50364, 764, 8720, 23294, 30, 1436, 286, 914, 11, 8720, 23294, 11, 436, 366, 1687, 21800, 11, 436, 1190, 5315, 11, 50706], "temperature": 0.0, "avg_logprob": -0.21653967464671414, "compression_ratio": 1.8963730569948187, "no_speech_prob": 0.7118412256240845}, {"id": 7, "seek": 5068, "start": 57.519999999999996, "end": 64.24, "text": " and shell scripts are also pretty fast. And given that shell scripts run everywhere, and", "tokens": [50706, 293, 8720, 23294, 366, 611, 1238, 2370, 13, 400, 2212, 300, 8720, 23294, 1190, 5315, 11, 293, 51042], "temperature": 0.0, "avg_logprob": -0.21653967464671414, "compression_ratio": 1.8963730569948187, "no_speech_prob": 0.7118412256240845}, {"id": 8, "seek": 5068, "start": 64.24, "end": 74.08, "text": " they are so super-duper portable, everyone understands them. Apparently, I'm not everyone.", "tokens": [51042, 436, 366, 370, 1687, 12, 769, 610, 21800, 11, 1518, 15146, 552, 13, 16755, 11, 286, 478, 406, 1518, 13, 51534], "temperature": 0.0, "avg_logprob": -0.21653967464671414, "compression_ratio": 1.8963730569948187, "no_speech_prob": 0.7118412256240845}, {"id": 9, "seek": 5068, "start": 74.08, "end": 79.28, "text": " Because in my opinion, shell scripts are very brittle, especially once I have to do string", "tokens": [51534, 1436, 294, 452, 4800, 11, 8720, 23294, 366, 588, 49325, 11, 2318, 1564, 286, 362, 281, 360, 6798, 51794], "temperature": 0.0, "avg_logprob": -0.21653967464671414, "compression_ratio": 1.8963730569948187, "no_speech_prob": 0.7118412256240845}, {"id": 10, "seek": 7928, "start": 79.28, "end": 84.6, "text": " modeling, that's the point where I start to test my tests. And if I need to write tests", "tokens": [50364, 15983, 11, 300, 311, 264, 935, 689, 286, 722, 281, 1500, 452, 6921, 13, 400, 498, 286, 643, 281, 2464, 6921, 50630], "temperature": 0.0, "avg_logprob": -0.1937565069932204, "compression_ratio": 1.5921052631578947, "no_speech_prob": 0.17361120879650116}, {"id": 11, "seek": 7928, "start": 84.6, "end": 91.8, "text": " to test my tests, I think I'm doing it wrong. You can disagree, but so let me give you the", "tokens": [50630, 281, 1500, 452, 6921, 11, 286, 519, 286, 478, 884, 309, 2085, 13, 509, 393, 14091, 11, 457, 370, 718, 385, 976, 291, 264, 50990], "temperature": 0.0, "avg_logprob": -0.1937565069932204, "compression_ratio": 1.5921052631578947, "no_speech_prob": 0.17361120879650116}, {"id": 12, "seek": 7928, "start": 91.8, "end": 97.84, "text": " short sales pitch, why you should use Python, PyTest, and especially this is about a PyTest", "tokens": [50990, 2099, 5763, 7293, 11, 983, 291, 820, 764, 15329, 11, 9953, 51, 377, 11, 293, 2318, 341, 307, 466, 257, 9953, 51, 377, 51292], "temperature": 0.0, "avg_logprob": -0.1937565069932204, "compression_ratio": 1.5921052631578947, "no_speech_prob": 0.17361120879650116}, {"id": 13, "seek": 7928, "start": 97.84, "end": 108.44, "text": " plugin that I wrote that's called PyTestContainer. So, what this thing can do for you is, it", "tokens": [51292, 23407, 300, 286, 4114, 300, 311, 1219, 9953, 51, 377, 29821, 491, 260, 13, 407, 11, 437, 341, 551, 393, 360, 337, 291, 307, 11, 309, 51822], "temperature": 0.0, "avg_logprob": -0.1937565069932204, "compression_ratio": 1.5921052631578947, "no_speech_prob": 0.17361120879650116}, {"id": 14, "seek": 10844, "start": 108.6, "end": 117.36, "text": " handles all the boring plumbing part of a test suite for containers, like pulling images,", "tokens": [50372, 18722, 439, 264, 9989, 39993, 644, 295, 257, 1500, 14205, 337, 17089, 11, 411, 8407, 5267, 11, 50810], "temperature": 0.0, "avg_logprob": -0.2570139567057292, "compression_ratio": 1.5502958579881656, "no_speech_prob": 0.3309001326560974}, {"id": 15, "seek": 10844, "start": 117.36, "end": 122.8, "text": " building containers, launching everything, and cleaning up, and not leaving you with", "tokens": [50810, 2390, 17089, 11, 18354, 1203, 11, 293, 8924, 493, 11, 293, 406, 5012, 291, 365, 51082], "temperature": 0.0, "avg_logprob": -0.2570139567057292, "compression_ratio": 1.5502958579881656, "no_speech_prob": 0.3309001326560974}, {"id": 16, "seek": 10844, "start": 122.8, "end": 133.32, "text": " terabytes of stale data. It uses the Python test-infra module, in case you know Python,", "tokens": [51082, 1796, 24538, 295, 342, 1220, 1412, 13, 467, 4960, 264, 15329, 1500, 12, 19920, 424, 10088, 11, 294, 1389, 291, 458, 15329, 11, 51608], "temperature": 0.0, "avg_logprob": -0.2570139567057292, "compression_ratio": 1.5502958579881656, "no_speech_prob": 0.3309001326560974}, {"id": 17, "seek": 13332, "start": 133.68, "end": 142.76, "text": " PyTest, this is just another convenience module to just access files, check whether there", "tokens": [50382, 9953, 51, 377, 11, 341, 307, 445, 1071, 19283, 10088, 281, 445, 2105, 7098, 11, 1520, 1968, 456, 50836], "temperature": 0.0, "avg_logprob": -0.17816507959940348, "compression_ratio": 1.6308411214953271, "no_speech_prob": 0.009668001905083656}, {"id": 18, "seek": 13332, "start": 142.76, "end": 147.72, "text": " are open ports, stuff that you can do with the Python standard library, but it's just", "tokens": [50836, 366, 1269, 18160, 11, 1507, 300, 291, 393, 360, 365, 264, 15329, 3832, 6405, 11, 457, 309, 311, 445, 51084], "temperature": 0.0, "avg_logprob": -0.17816507959940348, "compression_ratio": 1.6308411214953271, "no_speech_prob": 0.009668001905083656}, {"id": 19, "seek": 13332, "start": 147.72, "end": 155.12, "text": " another convenience layer there. One part that took more time than I care to admit,", "tokens": [51084, 1071, 19283, 4583, 456, 13, 1485, 644, 300, 1890, 544, 565, 813, 286, 1127, 281, 9796, 11, 51454], "temperature": 0.0, "avg_logprob": -0.17816507959940348, "compression_ratio": 1.6308411214953271, "no_speech_prob": 0.009668001905083656}, {"id": 20, "seek": 13332, "start": 155.12, "end": 161.24, "text": " but that I'm moderately proud about is that the whole test suite is designed, it supports", "tokens": [51454, 457, 300, 286, 478, 10494, 1592, 4570, 466, 307, 300, 264, 1379, 1500, 14205, 307, 4761, 11, 309, 9346, 51760], "temperature": 0.0, "avg_logprob": -0.17816507959940348, "compression_ratio": 1.6308411214953271, "no_speech_prob": 0.009668001905083656}, {"id": 21, "seek": 16124, "start": 161.24, "end": 167.04000000000002, "text": " parallel test runs. So, if you use the PyTest X-Test plugin, it allows you to execute all", "tokens": [50364, 8952, 1500, 6676, 13, 407, 11, 498, 291, 764, 264, 9953, 51, 377, 1783, 12, 51, 377, 23407, 11, 309, 4045, 291, 281, 14483, 439, 50654], "temperature": 0.0, "avg_logprob": -0.219494861105214, "compression_ratio": 1.6933962264150944, "no_speech_prob": 0.012537524104118347}, {"id": 22, "seek": 16124, "start": 167.04000000000002, "end": 173.04000000000002, "text": " your tests in parallel, so assuming you have 500 cores, you can run 500 tests in parallel.", "tokens": [50654, 428, 6921, 294, 8952, 11, 370, 11926, 291, 362, 5923, 24826, 11, 291, 393, 1190, 5923, 6921, 294, 8952, 13, 50954], "temperature": 0.0, "avg_logprob": -0.219494861105214, "compression_ratio": 1.6933962264150944, "no_speech_prob": 0.012537524104118347}, {"id": 23, "seek": 16124, "start": 173.04000000000002, "end": 180.48000000000002, "text": " And the whole thing also works if your container images expose ports, provided you don't open", "tokens": [50954, 400, 264, 1379, 551, 611, 1985, 498, 428, 10129, 5267, 19219, 18160, 11, 5649, 291, 500, 380, 1269, 51326], "temperature": 0.0, "avg_logprob": -0.219494861105214, "compression_ratio": 1.6933962264150944, "no_speech_prob": 0.012537524104118347}, {"id": 24, "seek": 16124, "start": 180.48000000000002, "end": 184.4, "text": " a thousand ports on each and run 500 tests in parallel, then you'll run out of three", "tokens": [51326, 257, 4714, 18160, 322, 1184, 293, 1190, 5923, 6921, 294, 8952, 11, 550, 291, 603, 1190, 484, 295, 1045, 51522], "temperature": 0.0, "avg_logprob": -0.219494861105214, "compression_ratio": 1.6933962264150944, "no_speech_prob": 0.012537524104118347}, {"id": 25, "seek": 18440, "start": 184.44, "end": 192.04000000000002, "text": " ports. But there's tools for that. If you're using Podman and not just Docker, it can also work", "tokens": [50366, 18160, 13, 583, 456, 311, 3873, 337, 300, 13, 759, 291, 434, 1228, 12646, 1601, 293, 406, 445, 33772, 11, 309, 393, 611, 589, 50746], "temperature": 0.0, "avg_logprob": -0.21854892936912743, "compression_ratio": 1.4922279792746114, "no_speech_prob": 0.04276471212506294}, {"id": 26, "seek": 18440, "start": 192.04000000000002, "end": 202.44, "text": " with Podman parts. You can also create abstractions to create container volumes and it will clean", "tokens": [50746, 365, 12646, 1601, 3166, 13, 509, 393, 611, 1884, 12649, 626, 281, 1884, 10129, 22219, 293, 309, 486, 2541, 51266], "temperature": 0.0, "avg_logprob": -0.21854892936912743, "compression_ratio": 1.4922279792746114, "no_speech_prob": 0.04276471212506294}, {"id": 27, "seek": 18440, "start": 202.44, "end": 209.68, "text": " up after itself. Also, if you're more into the area, I have an application and I want to check", "tokens": [51266, 493, 934, 2564, 13, 2743, 11, 498, 291, 434, 544, 666, 264, 1859, 11, 286, 362, 364, 3861, 293, 286, 528, 281, 1520, 51628], "temperature": 0.0, "avg_logprob": -0.21854892936912743, "compression_ratio": 1.4922279792746114, "no_speech_prob": 0.04276471212506294}, {"id": 28, "seek": 20968, "start": 209.92000000000002, "end": 216.8, "text": " whether it works not just on my box, but also on Fedora, CentOS, Debian, Arc Linux, Alpine,", "tokens": [50376, 1968, 309, 1985, 406, 445, 322, 452, 2424, 11, 457, 611, 322, 7772, 3252, 11, 3408, 4367, 11, 1346, 20196, 11, 21727, 18734, 11, 967, 40412, 11, 50720], "temperature": 0.0, "avg_logprob": -0.17798142481331874, "compression_ratio": 1.625, "no_speech_prob": 0.015042685903608799}, {"id": 29, "seek": 20968, "start": 216.8, "end": 222.52, "text": " and whatever else there is in the world. You can just define a set of tests and you tell the", "tokens": [50720, 293, 2035, 1646, 456, 307, 294, 264, 1002, 13, 509, 393, 445, 6964, 257, 992, 295, 6921, 293, 291, 980, 264, 51006], "temperature": 0.0, "avg_logprob": -0.17798142481331874, "compression_ratio": 1.625, "no_speech_prob": 0.015042685903608799}, {"id": 30, "seek": 20968, "start": 222.52, "end": 227.76000000000002, "text": " plugin on which container images to execute them and it will do that for you. So, that allows", "tokens": [51006, 23407, 322, 597, 10129, 5267, 281, 14483, 552, 293, 309, 486, 360, 300, 337, 291, 13, 407, 11, 300, 4045, 51268], "temperature": 0.0, "avg_logprob": -0.17798142481331874, "compression_ratio": 1.625, "no_speech_prob": 0.015042685903608799}, {"id": 31, "seek": 20968, "start": 227.76000000000002, "end": 233.8, "text": " you to have the same set of tests and run that on different containers, which would be, that would", "tokens": [51268, 291, 281, 362, 264, 912, 992, 295, 6921, 293, 1190, 300, 322, 819, 17089, 11, 597, 576, 312, 11, 300, 576, 51570], "temperature": 0.0, "avg_logprob": -0.17798142481331874, "compression_ratio": 1.625, "no_speech_prob": 0.015042685903608799}, {"id": 32, "seek": 23380, "start": 233.84, "end": 239.92000000000002, "text": " be more into the area that you are looking to test an application. It works with Podman and Docker,", "tokens": [50366, 312, 544, 666, 264, 1859, 300, 291, 366, 1237, 281, 1500, 364, 3861, 13, 467, 1985, 365, 12646, 1601, 293, 33772, 11, 50670], "temperature": 0.0, "avg_logprob": -0.1497341073969359, "compression_ratio": 1.5725806451612903, "no_speech_prob": 0.012171673588454723}, {"id": 33, "seek": 23380, "start": 239.92000000000002, "end": 246.64000000000001, "text": " you just change it by changing environment variable. And if you happen to be in the lucky", "tokens": [50670, 291, 445, 1319, 309, 538, 4473, 2823, 7006, 13, 400, 498, 291, 1051, 281, 312, 294, 264, 6356, 51006], "temperature": 0.0, "avg_logprob": -0.1497341073969359, "compression_ratio": 1.5725806451612903, "no_speech_prob": 0.012171673588454723}, {"id": 34, "seek": 23380, "start": 246.64000000000001, "end": 252.68, "text": " position to support enterprise-grade software that's very stable, hence very old, it still works", "tokens": [51006, 2535, 281, 1406, 14132, 12, 8692, 4722, 300, 311, 588, 8351, 11, 16678, 588, 1331, 11, 309, 920, 1985, 51308], "temperature": 0.0, "avg_logprob": -0.1497341073969359, "compression_ratio": 1.5725806451612903, "no_speech_prob": 0.012171673588454723}, {"id": 35, "seek": 23380, "start": 252.68, "end": 260.56, "text": " with Python 3.6 and on all the important architectures, which took also more time than I care to admit.", "tokens": [51308, 365, 15329, 805, 13, 21, 293, 322, 439, 264, 1021, 6331, 1303, 11, 597, 1890, 611, 544, 565, 813, 286, 1127, 281, 9796, 13, 51702], "temperature": 0.0, "avg_logprob": -0.1497341073969359, "compression_ratio": 1.5725806451612903, "no_speech_prob": 0.012171673588454723}, {"id": 36, "seek": 26056, "start": 261.56, "end": 267.84, "text": " So, let's just take a look at a very simple example. This would be just a typical Python test", "tokens": [50414, 407, 11, 718, 311, 445, 747, 257, 574, 412, 257, 588, 2199, 1365, 13, 639, 576, 312, 445, 257, 7476, 15329, 1500, 50728], "temperature": 0.0, "avg_logprob": -0.25069082999715997, "compression_ratio": 1.6894977168949772, "no_speech_prob": 0.004382678307592869}, {"id": 37, "seek": 26056, "start": 267.84, "end": 272.68, "text": " file with your imports, then you define your container image. In this case, it's just the", "tokens": [50728, 3991, 365, 428, 41596, 11, 550, 291, 6964, 428, 10129, 3256, 13, 682, 341, 1389, 11, 309, 311, 445, 264, 50970], "temperature": 0.0, "avg_logprob": -0.25069082999715997, "compression_ratio": 1.6894977168949772, "no_speech_prob": 0.004382678307592869}, {"id": 38, "seek": 26056, "start": 272.68, "end": 279.24, "text": " open-source-at-umbleweed image. And then you define a very trivial test. And in this case,", "tokens": [50970, 1269, 12, 41676, 12, 267, 12, 16473, 21272, 3256, 13, 400, 550, 291, 6964, 257, 588, 26703, 1500, 13, 400, 294, 341, 1389, 11, 51298], "temperature": 0.0, "avg_logprob": -0.25069082999715997, "compression_ratio": 1.6894977168949772, "no_speech_prob": 0.004382678307592869}, {"id": 39, "seek": 26056, "start": 279.24, "end": 288.0, "text": " what you can see here is, so this stuff here, that's really what testing for shines and it just", "tokens": [51298, 437, 291, 393, 536, 510, 307, 11, 370, 341, 1507, 510, 11, 300, 311, 534, 437, 4997, 337, 28056, 293, 309, 445, 51736], "temperature": 0.0, "avg_logprob": -0.25069082999715997, "compression_ratio": 1.6894977168949772, "no_speech_prob": 0.004382678307592869}, {"id": 40, "seek": 28800, "start": 288.36, "end": 293.52, "text": " takes a look at the O.S. release there. Very simple test, but you could do more elaborate", "tokens": [50382, 2516, 257, 574, 412, 264, 422, 13, 50, 13, 4374, 456, 13, 4372, 2199, 1500, 11, 457, 291, 727, 360, 544, 20945, 50640], "temperature": 0.0, "avg_logprob": -0.2784167147697286, "compression_ratio": 1.7098214285714286, "no_speech_prob": 0.005790155380964279}, {"id": 41, "seek": 28800, "start": 293.52, "end": 302.04, "text": " examples. So, what are possible use cases? Of course, you'll just base images, you could test", "tokens": [50640, 5110, 13, 407, 11, 437, 366, 1944, 764, 3331, 30, 2720, 1164, 11, 291, 603, 445, 3096, 5267, 11, 291, 727, 1500, 51066], "temperature": 0.0, "avg_logprob": -0.2784167147697286, "compression_ratio": 1.7098214285714286, "no_speech_prob": 0.005790155380964279}, {"id": 42, "seek": 28800, "start": 302.04, "end": 309.56, "text": " those, you could do applications inside containers, and another test, another possible use case would", "tokens": [51066, 729, 11, 291, 727, 360, 5821, 1854, 17089, 11, 293, 1071, 1500, 11, 1071, 1944, 764, 1389, 576, 51442], "temperature": 0.0, "avg_logprob": -0.2784167147697286, "compression_ratio": 1.7098214285714286, "no_speech_prob": 0.005790155380964279}, {"id": 43, "seek": 28800, "start": 309.56, "end": 314.12, "text": " be you have an application and you want to check whether the application works on multiple O.S.s,", "tokens": [51442, 312, 291, 362, 364, 3861, 293, 291, 528, 281, 1520, 1968, 264, 3861, 1985, 322, 3866, 422, 13, 50, 13, 82, 11, 51670], "temperature": 0.0, "avg_logprob": -0.2784167147697286, "compression_ratio": 1.7098214285714286, "no_speech_prob": 0.005790155380964279}, {"id": 44, "seek": 31412, "start": 314.32, "end": 320.8, "text": " but you don't need virtual machines for that. Then you could use PyTest container for that as well.", "tokens": [50374, 457, 291, 500, 380, 643, 6374, 8379, 337, 300, 13, 1396, 291, 727, 764, 9953, 51, 377, 10129, 337, 300, 382, 731, 13, 50698], "temperature": 0.0, "avg_logprob": -0.1714991012422165, "compression_ratio": 1.583673469387755, "no_speech_prob": 0.007877891883254051}, {"id": 45, "seek": 31412, "start": 320.8, "end": 330.12, "text": " So, I guess if you're in this talk, you might know a bit about PyTest and as the name suggests,", "tokens": [50698, 407, 11, 286, 2041, 498, 291, 434, 294, 341, 751, 11, 291, 1062, 458, 257, 857, 466, 9953, 51, 377, 293, 382, 264, 1315, 13409, 11, 51164], "temperature": 0.0, "avg_logprob": -0.1714991012422165, "compression_ratio": 1.583673469387755, "no_speech_prob": 0.007877891883254051}, {"id": 46, "seek": 31412, "start": 330.12, "end": 335.8, "text": " it's a Python testing framework, otherwise the name would be very bad. All it really does is", "tokens": [51164, 309, 311, 257, 15329, 4997, 8388, 11, 5911, 264, 1315, 576, 312, 588, 1578, 13, 1057, 309, 534, 775, 307, 51448], "temperature": 0.0, "avg_logprob": -0.1714991012422165, "compression_ratio": 1.583673469387755, "no_speech_prob": 0.007877891883254051}, {"id": 47, "seek": 31412, "start": 335.8, "end": 342.08, "text": " assemble tests, so it's like unit test on steroids, executes all test functions. And one thing that", "tokens": [51448, 22364, 6921, 11, 370, 309, 311, 411, 4985, 1500, 322, 45717, 11, 4454, 1819, 439, 1500, 6828, 13, 400, 472, 551, 300, 51762], "temperature": 0.0, "avg_logprob": -0.1714991012422165, "compression_ratio": 1.583673469387755, "no_speech_prob": 0.007877891883254051}, {"id": 48, "seek": 34208, "start": 342.2, "end": 348.88, "text": " PyTest container uses extensively are fixtures. If you're not known to PyTest, you probably know", "tokens": [50370, 9953, 51, 377, 10129, 4960, 32636, 366, 15848, 37610, 13, 759, 291, 434, 406, 2570, 281, 9953, 51, 377, 11, 291, 1391, 458, 50704], "temperature": 0.0, "avg_logprob": -0.19780554978743844, "compression_ratio": 1.6437768240343347, "no_speech_prob": 0.0037338673137128353}, {"id": 49, "seek": 34208, "start": 348.88, "end": 355.52, "text": " setup and tear down functions from all other testing frameworks and PyTest fixtures are kind of", "tokens": [50704, 8657, 293, 12556, 760, 6828, 490, 439, 661, 4997, 29834, 293, 9953, 51, 377, 15848, 37610, 366, 733, 295, 51036], "temperature": 0.0, "avg_logprob": -0.19780554978743844, "compression_ratio": 1.6437768240343347, "no_speech_prob": 0.0037338673137128353}, {"id": 50, "seek": 34208, "start": 355.52, "end": 361.84, "text": " the thing there. So, a fixture is really just a parameter for a test function and it can return", "tokens": [51036, 264, 551, 456, 13, 407, 11, 257, 47680, 307, 534, 445, 257, 13075, 337, 257, 1500, 2445, 293, 309, 393, 2736, 51352], "temperature": 0.0, "avg_logprob": -0.19780554978743844, "compression_ratio": 1.6437768240343347, "no_speech_prob": 0.0037338673137128353}, {"id": 51, "seek": 34208, "start": 361.84, "end": 368.52, "text": " a certain value and before that do some setup, give you something in this very simple example.", "tokens": [51352, 257, 1629, 2158, 293, 949, 300, 360, 512, 8657, 11, 976, 291, 746, 294, 341, 588, 2199, 1365, 13, 51686], "temperature": 0.0, "avg_logprob": -0.19780554978743844, "compression_ratio": 1.6437768240343347, "no_speech_prob": 0.0037338673137128353}, {"id": 52, "seek": 36852, "start": 368.84, "end": 375.44, "text": " This is from the PyTest docs, so it would give you, it would for instance create a mock SMTP connection", "tokens": [50380, 639, 307, 490, 264, 9953, 51, 377, 45623, 11, 370, 309, 576, 976, 291, 11, 309, 576, 337, 5197, 1884, 257, 17362, 13115, 16804, 4984, 50710], "temperature": 0.0, "avg_logprob": -0.20868831872940063, "compression_ratio": 1.7557603686635945, "no_speech_prob": 0.0022024456411600113}, {"id": 53, "seek": 36852, "start": 375.44, "end": 381.12, "text": " and for the PyTest container, it gives you a connection to the already created container.", "tokens": [50710, 293, 337, 264, 9953, 51, 377, 10129, 11, 309, 2709, 291, 257, 4984, 281, 264, 1217, 2942, 10129, 13, 50994], "temperature": 0.0, "avg_logprob": -0.20868831872940063, "compression_ratio": 1.7557603686635945, "no_speech_prob": 0.0022024456411600113}, {"id": 54, "seek": 36852, "start": 381.12, "end": 386.88, "text": " And another cool thing that PyTest has is test parameterization, where you can just define", "tokens": [50994, 400, 1071, 1627, 551, 300, 9953, 51, 377, 575, 307, 1500, 13075, 2144, 11, 689, 291, 393, 445, 6964, 51282], "temperature": 0.0, "avg_logprob": -0.20868831872940063, "compression_ratio": 1.7557603686635945, "no_speech_prob": 0.0022024456411600113}, {"id": 55, "seek": 36852, "start": 386.88, "end": 395.4, "text": " multiple parameters. So, in this case, you would get your, you would have a test and you want to", "tokens": [51282, 3866, 9834, 13, 407, 11, 294, 341, 1389, 11, 291, 576, 483, 428, 11, 291, 576, 362, 257, 1500, 293, 291, 528, 281, 51708], "temperature": 0.0, "avg_logprob": -0.20868831872940063, "compression_ratio": 1.7557603686635945, "no_speech_prob": 0.0022024456411600113}, {"id": 56, "seek": 39540, "start": 395.44, "end": 401.88, "text": " execute it for all combinations of those values, so it would run your test for all the, for the whole", "tokens": [50366, 14483, 309, 337, 439, 21267, 295, 729, 4190, 11, 370, 309, 576, 1190, 428, 1500, 337, 439, 264, 11, 337, 264, 1379, 50688], "temperature": 0.0, "avg_logprob": -0.16232659065560118, "compression_ratio": 1.5351351351351352, "no_speech_prob": 0.001616319757886231}, {"id": 57, "seek": 39540, "start": 401.88, "end": 411.23999999999995, "text": " Cartesian product, so all combinations of 0, 1 and 2 and 3. Let's just jump into a few usage", "tokens": [50688, 22478, 42434, 1674, 11, 370, 439, 21267, 295, 1958, 11, 502, 293, 568, 293, 805, 13, 961, 311, 445, 3012, 666, 257, 1326, 14924, 51156], "temperature": 0.0, "avg_logprob": -0.16232659065560118, "compression_ratio": 1.5351351351351352, "no_speech_prob": 0.001616319757886231}, {"id": 58, "seek": 39540, "start": 411.23999999999995, "end": 419.35999999999996, "text": " examples. So, in case you want to build new containers, you just define yourself the base", "tokens": [51156, 5110, 13, 407, 11, 294, 1389, 291, 528, 281, 1322, 777, 17089, 11, 291, 445, 6964, 1803, 264, 3096, 51562], "temperature": 0.0, "avg_logprob": -0.16232659065560118, "compression_ratio": 1.5351351351351352, "no_speech_prob": 0.001616319757886231}, {"id": 59, "seek": 41936, "start": 419.44, "end": 428.36, "text": " URL, you have the, you define yourself the docker file and you create the creatively named class", "tokens": [50368, 12905, 11, 291, 362, 264, 11, 291, 6964, 1803, 264, 360, 9178, 3991, 293, 291, 1884, 264, 43750, 4926, 1508, 50814], "temperature": 0.0, "avg_logprob": -0.21404390465723325, "compression_ratio": 1.529100529100529, "no_speech_prob": 0.007910476066172123}, {"id": 60, "seek": 41936, "start": 428.36, "end": 434.68, "text": " derived container and if you didn't already see, I shouldn't be in charge of naming things because", "tokens": [50814, 18949, 10129, 293, 498, 291, 994, 380, 1217, 536, 11, 286, 4659, 380, 312, 294, 4602, 295, 25290, 721, 570, 51130], "temperature": 0.0, "avg_logprob": -0.21404390465723325, "compression_ratio": 1.529100529100529, "no_speech_prob": 0.007910476066172123}, {"id": 61, "seek": 41936, "start": 434.68, "end": 442.48, "text": " I'm terrible at it, but I'm not very creative. But so, what will happen now if you pass this,", "tokens": [51130, 286, 478, 6237, 412, 309, 11, 457, 286, 478, 406, 588, 5880, 13, 583, 370, 11, 437, 486, 1051, 586, 498, 291, 1320, 341, 11, 51520], "temperature": 0.0, "avg_logprob": -0.21404390465723325, "compression_ratio": 1.529100529100529, "no_speech_prob": 0.007910476066172123}, {"id": 62, "seek": 44248, "start": 443.20000000000005, "end": 451.84000000000003, "text": " if you pass this created class into your test function, the plugin will first pull your, pull", "tokens": [50400, 498, 291, 1320, 341, 2942, 1508, 666, 428, 1500, 2445, 11, 264, 23407, 486, 700, 2235, 428, 11, 2235, 50832], "temperature": 0.0, "avg_logprob": -0.20803242259555393, "compression_ratio": 1.7108433734939759, "no_speech_prob": 0.022185010835528374}, {"id": 63, "seek": 44248, "start": 451.84000000000003, "end": 459.04, "text": " the space image, it will build the container on top of that, launch it, pass it into this, pass it", "tokens": [50832, 264, 1901, 3256, 11, 309, 486, 1322, 264, 10129, 322, 1192, 295, 300, 11, 4025, 309, 11, 1320, 309, 666, 341, 11, 1320, 309, 51192], "temperature": 0.0, "avg_logprob": -0.20803242259555393, "compression_ratio": 1.7108433734939759, "no_speech_prob": 0.022185010835528374}, {"id": 64, "seek": 44248, "start": 459.04, "end": 465.44, "text": " into the test function and once the test is executed, it will get cleaned up. You can also,", "tokens": [51192, 666, 264, 1500, 2445, 293, 1564, 264, 1500, 307, 17577, 11, 309, 486, 483, 16146, 493, 13, 509, 393, 611, 11, 51512], "temperature": 0.0, "avg_logprob": -0.20803242259555393, "compression_ratio": 1.7108433734939759, "no_speech_prob": 0.022185010835528374}, {"id": 65, "seek": 46544, "start": 466.24, "end": 474.08, "text": " so you can also define pass in other already created containers into this as a base, that all", "tokens": [50404, 370, 291, 393, 611, 6964, 1320, 294, 661, 1217, 2942, 17089, 666, 341, 382, 257, 3096, 11, 300, 439, 50796], "temperature": 0.0, "avg_logprob": -0.22112950886765573, "compression_ratio": 1.476923076923077, "no_speech_prob": 0.011583737097680569}, {"id": 66, "seek": 46544, "start": 474.08, "end": 480.24, "text": " works. I have an example for that later. As I mentioned, binding free ports, you might not say,", "tokens": [50796, 1985, 13, 286, 362, 364, 1365, 337, 300, 1780, 13, 1018, 286, 2835, 11, 17359, 1737, 18160, 11, 291, 1062, 406, 584, 11, 51104], "temperature": 0.0, "avg_logprob": -0.22112950886765573, "compression_ratio": 1.476923076923077, "no_speech_prob": 0.011583737097680569}, {"id": 67, "seek": 46544, "start": 480.24, "end": 489.68, "text": " why don't you just add a parameter somewhere, okay, expose port 8000 on the host and that works as", "tokens": [51104, 983, 500, 380, 291, 445, 909, 257, 13075, 4079, 11, 1392, 11, 19219, 2436, 1649, 1360, 322, 264, 3975, 293, 300, 1985, 382, 51576], "temperature": 0.0, "avg_logprob": -0.22112950886765573, "compression_ratio": 1.476923076923077, "no_speech_prob": 0.011583737097680569}, {"id": 68, "seek": 48968, "start": 489.68, "end": 496.64, "text": " long as you only launch, as you don't launch tests in parallel. So, if you want to launch, if you", "tokens": [50364, 938, 382, 291, 787, 4025, 11, 382, 291, 500, 380, 4025, 6921, 294, 8952, 13, 407, 11, 498, 291, 528, 281, 4025, 11, 498, 291, 50712], "temperature": 0.0, "avg_logprob": -0.13297355418302576, "compression_ratio": 1.7433628318584071, "no_speech_prob": 0.01685398630797863}, {"id": 69, "seek": 48968, "start": 496.64, "end": 503.28000000000003, "text": " for instance want to test this specific container five times in parallel, you can't bind all of them", "tokens": [50712, 337, 5197, 528, 281, 1500, 341, 2685, 10129, 1732, 1413, 294, 8952, 11, 291, 393, 380, 14786, 439, 295, 552, 51044], "temperature": 0.0, "avg_logprob": -0.13297355418302576, "compression_ratio": 1.7433628318584071, "no_speech_prob": 0.01685398630797863}, {"id": 70, "seek": 48968, "start": 503.28000000000003, "end": 509.36, "text": " to the same port and for that, there's a relatively simple abstraction. So, you just create this", "tokens": [51044, 281, 264, 912, 2436, 293, 337, 300, 11, 456, 311, 257, 7226, 2199, 37765, 13, 407, 11, 291, 445, 1884, 341, 51348], "temperature": 0.0, "avg_logprob": -0.13297355418302576, "compression_ratio": 1.7433628318584071, "no_speech_prob": 0.01685398630797863}, {"id": 71, "seek": 48968, "start": 509.36, "end": 517.92, "text": " port forwarding class, pass it into the container and then it will get exposed in the test. There,", "tokens": [51348, 2436, 2128, 278, 1508, 11, 1320, 309, 666, 264, 10129, 293, 550, 309, 486, 483, 9495, 294, 264, 1500, 13, 821, 11, 51776], "temperature": 0.0, "avg_logprob": -0.13297355418302576, "compression_ratio": 1.7433628318584071, "no_speech_prob": 0.01685398630797863}, {"id": 72, "seek": 51792, "start": 517.92, "end": 525.52, "text": " you will get the host port and this is inferred automatically on launch of the test.", "tokens": [50364, 291, 486, 483, 264, 3975, 2436, 293, 341, 307, 13596, 986, 6772, 322, 4025, 295, 264, 1500, 13, 50744], "temperature": 0.0, "avg_logprob": -0.16893490025254546, "compression_ratio": 1.5232558139534884, "no_speech_prob": 0.004038801416754723}, {"id": 73, "seek": 51792, "start": 529.8399999999999, "end": 538.9599999999999, "text": " If you want to test ports, so this is very apartment specific, works rather like this. So,", "tokens": [50960, 759, 291, 528, 281, 1500, 18160, 11, 370, 341, 307, 588, 9587, 2685, 11, 1985, 2831, 411, 341, 13, 407, 11, 51416], "temperature": 0.0, "avg_logprob": -0.16893490025254546, "compression_ratio": 1.5232558139534884, "no_speech_prob": 0.004038801416754723}, {"id": 74, "seek": 51792, "start": 539.8399999999999, "end": 544.24, "text": " essentially a port is just a combination of containers and the only really interesting", "tokens": [51460, 4476, 257, 2436, 307, 445, 257, 6562, 295, 17089, 293, 264, 787, 534, 1880, 51680], "temperature": 0.0, "avg_logprob": -0.16893490025254546, "compression_ratio": 1.5232558139534884, "no_speech_prob": 0.004038801416754723}, {"id": 75, "seek": 54424, "start": 544.24, "end": 549.84, "text": " part that you want to use it for is again port forwarding, works exactly the same like with", "tokens": [50364, 644, 300, 291, 528, 281, 764, 309, 337, 307, 797, 2436, 2128, 278, 11, 1985, 2293, 264, 912, 411, 365, 50644], "temperature": 0.0, "avg_logprob": -0.16410241198183886, "compression_ratio": 1.5944444444444446, "no_speech_prob": 0.003263900987803936}, {"id": 76, "seek": 54424, "start": 550.96, "end": 564.64, "text": " containers. One little catch. So, so far I was telling, I was claiming that your containers would be", "tokens": [50700, 17089, 13, 1485, 707, 3745, 13, 407, 11, 370, 1400, 286, 390, 3585, 11, 286, 390, 19232, 300, 428, 17089, 576, 312, 51384], "temperature": 0.0, "avg_logprob": -0.16410241198183886, "compression_ratio": 1.5944444444444446, "no_speech_prob": 0.003263900987803936}, {"id": 77, "seek": 54424, "start": 565.44, "end": 571.52, "text": " launched after the test and destroyed after the test and that's not entirely true because most", "tokens": [51424, 8730, 934, 264, 1500, 293, 8937, 934, 264, 1500, 293, 300, 311, 406, 7696, 2074, 570, 881, 51728], "temperature": 0.0, "avg_logprob": -0.16410241198183886, "compression_ratio": 1.5944444444444446, "no_speech_prob": 0.003263900987803936}, {"id": 78, "seek": 57152, "start": 571.52, "end": 578.16, "text": " tests don't modify the container and then you can get away with creating your container before", "tokens": [50364, 6921, 500, 380, 16927, 264, 10129, 293, 550, 291, 393, 483, 1314, 365, 4084, 428, 10129, 949, 50696], "temperature": 0.0, "avg_logprob": -0.10641404320211971, "compression_ratio": 1.7085201793721974, "no_speech_prob": 0.007544677704572678}, {"id": 79, "seek": 57152, "start": 578.16, "end": 584.56, "text": " all tests and tearing it down after all tests and you save actually a substantial amount of time.", "tokens": [50696, 439, 6921, 293, 29401, 309, 760, 934, 439, 6921, 293, 291, 3155, 767, 257, 16726, 2372, 295, 565, 13, 51016], "temperature": 0.0, "avg_logprob": -0.10641404320211971, "compression_ratio": 1.7085201793721974, "no_speech_prob": 0.007544677704572678}, {"id": 80, "seek": 57152, "start": 585.28, "end": 592.56, "text": " But if you decide to do tests like these where you try whether RM minus RF actually works,", "tokens": [51052, 583, 498, 291, 4536, 281, 360, 6921, 411, 613, 689, 291, 853, 1968, 23790, 3175, 26204, 767, 1985, 11, 51416], "temperature": 0.0, "avg_logprob": -0.10641404320211971, "compression_ratio": 1.7085201793721974, "no_speech_prob": 0.007544677704572678}, {"id": 81, "seek": 57152, "start": 592.56, "end": 599.52, "text": " then any subsequent, any subsequent test will fail and start burning. So, and therefore there's a", "tokens": [51416, 550, 604, 19962, 11, 604, 19962, 1500, 486, 3061, 293, 722, 9488, 13, 407, 11, 293, 4412, 456, 311, 257, 51764], "temperature": 0.0, "avg_logprob": -0.10641404320211971, "compression_ratio": 1.7085201793721974, "no_speech_prob": 0.007544677704572678}, {"id": 82, "seek": 59952, "start": 599.52, "end": 606.24, "text": " different fixture that's called just container per test and that will actually ensure that all,", "tokens": [50364, 819, 47680, 300, 311, 1219, 445, 10129, 680, 1500, 293, 300, 486, 767, 5586, 300, 439, 11, 50700], "temperature": 0.0, "avg_logprob": -0.10232664590858552, "compression_ratio": 1.6886792452830188, "no_speech_prob": 0.002108158078044653}, {"id": 83, "seek": 59952, "start": 606.24, "end": 613.6, "text": " that you just get a fresh container for every test but it costs extra. So, but then you can also", "tokens": [50700, 300, 291, 445, 483, 257, 4451, 10129, 337, 633, 1500, 457, 309, 5497, 2857, 13, 407, 11, 457, 550, 291, 393, 611, 51068], "temperature": 0.0, "avg_logprob": -0.10232664590858552, "compression_ratio": 1.6886792452830188, "no_speech_prob": 0.002108158078044653}, {"id": 84, "seek": 59952, "start": 613.6, "end": 619.84, "text": " RM minus RF everything in your container and the subsequent container will still kind of work.", "tokens": [51068, 23790, 3175, 26204, 1203, 294, 428, 10129, 293, 264, 19962, 10129, 486, 920, 733, 295, 589, 13, 51380], "temperature": 0.0, "avg_logprob": -0.10232664590858552, "compression_ratio": 1.6886792452830188, "no_speech_prob": 0.002108158078044653}, {"id": 85, "seek": 59952, "start": 621.6, "end": 625.76, "text": " For the case where you decide, where you want to run a bunch of tests,", "tokens": [51468, 1171, 264, 1389, 689, 291, 4536, 11, 689, 291, 528, 281, 1190, 257, 3840, 295, 6921, 11, 51676], "temperature": 0.0, "avg_logprob": -0.10232664590858552, "compression_ratio": 1.6886792452830188, "no_speech_prob": 0.002108158078044653}, {"id": 86, "seek": 62576, "start": 626.56, "end": 632.88, "text": " but you don't want to do the whole pie test parameterization before that, you can just dump all", "tokens": [50404, 457, 291, 500, 380, 528, 281, 360, 264, 1379, 1730, 1500, 13075, 2144, 949, 300, 11, 291, 393, 445, 11430, 439, 50720], "temperature": 0.0, "avg_logprob": -0.227792231241862, "compression_ratio": 1.7511520737327189, "no_speech_prob": 0.004636821802705526}, {"id": 87, "seek": 62576, "start": 632.88, "end": 640.16, "text": " your containers into a global variable that's called container images and pie test will do the", "tokens": [50720, 428, 17089, 666, 257, 4338, 7006, 300, 311, 1219, 10129, 5267, 293, 1730, 1500, 486, 360, 264, 51084], "temperature": 0.0, "avg_logprob": -0.227792231241862, "compression_ratio": 1.7511520737327189, "no_speech_prob": 0.004636821802705526}, {"id": 88, "seek": 62576, "start": 640.16, "end": 646.48, "text": " automatic parameterization. So, in this case, these, all the tests in the test module would get", "tokens": [51084, 12509, 13075, 2144, 13, 407, 11, 294, 341, 1389, 11, 613, 11, 439, 264, 6921, 294, 264, 1500, 10088, 576, 483, 51400], "temperature": 0.0, "avg_logprob": -0.227792231241862, "compression_ratio": 1.7511520737327189, "no_speech_prob": 0.004636821802705526}, {"id": 89, "seek": 62576, "start": 646.48, "end": 653.84, "text": " executed with all these containers and that's for instance what, what we're doing in, in the,", "tokens": [51400, 17577, 365, 439, 613, 17089, 293, 300, 311, 337, 5197, 437, 11, 437, 321, 434, 884, 294, 11, 294, 264, 11, 51768], "temperature": 0.0, "avg_logprob": -0.227792231241862, "compression_ratio": 1.7511520737327189, "no_speech_prob": 0.004636821802705526}, {"id": 90, "seek": 65384, "start": 654.48, "end": 660.08, "text": " in the, for Kiwi test functions where you just want to ensure, okay, they work on CentroStream,", "tokens": [50396, 294, 264, 11, 337, 17459, 6253, 1500, 6828, 689, 291, 445, 528, 281, 5586, 11, 1392, 11, 436, 589, 322, 3408, 340, 4520, 1572, 11, 50676], "temperature": 0.0, "avg_logprob": -0.21991159915924072, "compression_ratio": 1.415, "no_speech_prob": 0.0016097234329208732}, {"id": 91, "seek": 65384, "start": 660.08, "end": 669.52, "text": " Fedora, DBN, R-Clinux, etc. Pp. What I've, what I hinted on previously that's dependencies", "tokens": [50676, 7772, 3252, 11, 26754, 45, 11, 497, 12, 34, 5045, 2449, 11, 5183, 13, 430, 79, 13, 708, 286, 600, 11, 437, 286, 12075, 292, 322, 8046, 300, 311, 36606, 51148], "temperature": 0.0, "avg_logprob": -0.21991159915924072, "compression_ratio": 1.415, "no_speech_prob": 0.0016097234329208732}, {"id": 92, "seek": 65384, "start": 669.52, "end": 674.1600000000001, "text": " between containers which is essentially just you want to build a container based on another one,", "tokens": [51148, 1296, 17089, 597, 307, 4476, 445, 291, 528, 281, 1322, 257, 10129, 2361, 322, 1071, 472, 11, 51380], "temperature": 0.0, "avg_logprob": -0.21991159915924072, "compression_ratio": 1.415, "no_speech_prob": 0.0016097234329208732}, {"id": 93, "seek": 67416, "start": 674.16, "end": 683.8399999999999, "text": " based on another one, which would essentially be just you, you split up your, you would split", "tokens": [50364, 2361, 322, 1071, 472, 11, 597, 576, 4476, 312, 445, 291, 11, 291, 7472, 493, 428, 11, 291, 576, 7472, 50848], "temperature": 0.0, "avg_logprob": -0.09529287736494463, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.013153082691133022}, {"id": 94, "seek": 67416, "start": 683.8399999999999, "end": 691.28, "text": " up your Docker file. This might sound like maybe a weird idea at first but it can be,", "tokens": [50848, 493, 428, 33772, 3991, 13, 639, 1062, 1626, 411, 1310, 257, 3657, 1558, 412, 700, 457, 309, 393, 312, 11, 51220], "temperature": 0.0, "avg_logprob": -0.09529287736494463, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.013153082691133022}, {"id": 95, "seek": 67416, "start": 691.28, "end": 697.52, "text": " it can be relatively useful if you have, if you want to check different base images and then", "tokens": [51220, 309, 393, 312, 7226, 4420, 498, 291, 362, 11, 498, 291, 528, 281, 1520, 819, 3096, 5267, 293, 550, 51532], "temperature": 0.0, "avg_logprob": -0.09529287736494463, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.013153082691133022}, {"id": 96, "seek": 67416, "start": 698.3199999999999, "end": 703.68, "text": " build stuff on top of them or you want to, or you decide to modify your base image. So,", "tokens": [51572, 1322, 1507, 322, 1192, 295, 552, 420, 291, 528, 281, 11, 420, 291, 4536, 281, 16927, 428, 3096, 3256, 13, 407, 11, 51840], "temperature": 0.0, "avg_logprob": -0.09529287736494463, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.013153082691133022}, {"id": 97, "seek": 70368, "start": 703.68, "end": 712.9599999999999, "text": " we have used this relatively extensively in the BCI test suite and you can, you can simply create", "tokens": [50364, 321, 362, 1143, 341, 7226, 32636, 294, 264, 14359, 40, 1500, 14205, 293, 291, 393, 11, 291, 393, 2935, 1884, 50828], "temperature": 0.0, "avg_logprob": -0.12439443043300084, "compression_ratio": 1.783132530120482, "no_speech_prob": 0.0015369565226137638}, {"id": 98, "seek": 70368, "start": 712.9599999999999, "end": 720.64, "text": " containers that derive from others and that derive from others and you can do this relatively", "tokens": [50828, 17089, 300, 28446, 490, 2357, 293, 300, 28446, 490, 2357, 293, 291, 393, 360, 341, 7226, 51212], "temperature": 0.0, "avg_logprob": -0.12439443043300084, "compression_ratio": 1.783132530120482, "no_speech_prob": 0.0015369565226137638}, {"id": 99, "seek": 70368, "start": 720.64, "end": 731.04, "text": " extensively, just don't add loops. That, that will not work. In case you want to, want to check whether,", "tokens": [51212, 32636, 11, 445, 500, 380, 909, 16121, 13, 663, 11, 300, 486, 406, 589, 13, 682, 1389, 291, 528, 281, 11, 528, 281, 1520, 1968, 11, 51732], "temperature": 0.0, "avg_logprob": -0.12439443043300084, "compression_ratio": 1.783132530120482, "no_speech_prob": 0.0015369565226137638}, {"id": 100, "seek": 73104, "start": 731.68, "end": 737.4399999999999, "text": " for instance, the environment in your container is still, is what you, what you expect or some", "tokens": [50396, 337, 5197, 11, 264, 2823, 294, 428, 10129, 307, 920, 11, 307, 437, 291, 11, 437, 291, 2066, 420, 512, 50684], "temperature": 0.0, "avg_logprob": -0.13347430939370014, "compression_ratio": 1.6784140969162995, "no_speech_prob": 0.012545560486614704}, {"id": 101, "seek": 73104, "start": 737.4399999999999, "end": 743.1999999999999, "text": " config and you don't want to mess with the JSON that Docker Inspector, Portman Inspector gives you,", "tokens": [50684, 6662, 293, 291, 500, 380, 528, 281, 2082, 365, 264, 31828, 300, 33772, 33402, 11, 6733, 1601, 33402, 2709, 291, 11, 50972], "temperature": 0.0, "avg_logprob": -0.13347430939370014, "compression_ratio": 1.6784140969162995, "no_speech_prob": 0.012545560486614704}, {"id": 102, "seek": 73104, "start": 744.64, "end": 751.12, "text": " that's also to a certain extent implemented. So, you'll get, you'll get a Python usable", "tokens": [51044, 300, 311, 611, 281, 257, 1629, 8396, 12270, 13, 407, 11, 291, 603, 483, 11, 291, 603, 483, 257, 15329, 29975, 51368], "temperature": 0.0, "avg_logprob": -0.13347430939370014, "compression_ratio": 1.6784140969162995, "no_speech_prob": 0.012545560486614704}, {"id": 103, "seek": 73104, "start": 751.12, "end": 757.04, "text": " version of the inspect of a container where you can, for instance, check what's the user in there,", "tokens": [51368, 3037, 295, 264, 15018, 295, 257, 10129, 689, 291, 393, 11, 337, 5197, 11, 1520, 437, 311, 264, 4195, 294, 456, 11, 51664], "temperature": 0.0, "avg_logprob": -0.13347430939370014, "compression_ratio": 1.6784140969162995, "no_speech_prob": 0.012545560486614704}, {"id": 104, "seek": 75704, "start": 757.04, "end": 762.3199999999999, "text": " what's the CMD of this container, if there's something in the environment and other stuff.", "tokens": [50364, 437, 311, 264, 20424, 35, 295, 341, 10129, 11, 498, 456, 311, 746, 294, 264, 2823, 293, 661, 1507, 13, 50628], "temperature": 0.0, "avg_logprob": -0.09299074581691197, "compression_ratio": 1.5380434782608696, "no_speech_prob": 0.0014748454559594393}, {"id": 105, "seek": 75704, "start": 765.68, "end": 770.9599999999999, "text": " Since I'm nearly out of time, I'm going to jump over this since it's not really that interesting", "tokens": [50796, 4162, 286, 478, 6217, 484, 295, 565, 11, 286, 478, 516, 281, 3012, 670, 341, 1670, 309, 311, 406, 534, 300, 1880, 51060], "temperature": 0.0, "avg_logprob": -0.09299074581691197, "compression_ratio": 1.5380434782608696, "no_speech_prob": 0.0014748454559594393}, {"id": 106, "seek": 75704, "start": 770.9599999999999, "end": 780.3199999999999, "text": " actually. One important thing is if you are, so if you create an application in your container,", "tokens": [51060, 767, 13, 1485, 1021, 551, 307, 498, 291, 366, 11, 370, 498, 291, 1884, 364, 3861, 294, 428, 10129, 11, 51528], "temperature": 0.0, "avg_logprob": -0.09299074581691197, "compression_ratio": 1.5380434782608696, "no_speech_prob": 0.0014748454559594393}, {"id": 107, "seek": 78032, "start": 781.0400000000001, "end": 787.2800000000001, "text": " applications usually take time to launch, please use health checks. Health checks are cool. I know", "tokens": [50400, 5821, 2673, 747, 565, 281, 4025, 11, 1767, 764, 1585, 13834, 13, 5912, 13834, 366, 1627, 13, 286, 458, 50712], "temperature": 0.0, "avg_logprob": -0.12482111077559621, "compression_ratio": 1.7433628318584071, "no_speech_prob": 0.006884112488478422}, {"id": 108, "seek": 78032, "start": 787.2800000000001, "end": 793.9200000000001, "text": " they are not part of the OCI spec, that's a bummer, but please use health checks. Because if you start", "tokens": [50712, 436, 366, 406, 644, 295, 264, 422, 25240, 1608, 11, 300, 311, 257, 13309, 936, 11, 457, 1767, 764, 1585, 13834, 13, 1436, 498, 291, 722, 51044], "temperature": 0.0, "avg_logprob": -0.12482111077559621, "compression_ratio": 1.7433628318584071, "no_speech_prob": 0.006884112488478422}, {"id": 109, "seek": 78032, "start": 793.9200000000001, "end": 799.6800000000001, "text": " using a test suite and you, and you yourself execute a test manually, you launch your container,", "tokens": [51044, 1228, 257, 1500, 14205, 293, 291, 11, 293, 291, 1803, 14483, 257, 1500, 16945, 11, 291, 4025, 428, 10129, 11, 51332], "temperature": 0.0, "avg_logprob": -0.12482111077559621, "compression_ratio": 1.7433628318584071, "no_speech_prob": 0.006884112488478422}, {"id": 110, "seek": 78032, "start": 799.6800000000001, "end": 804.48, "text": " you try to curl where the application is there and it all works and then you automate it and it", "tokens": [51332, 291, 853, 281, 22591, 689, 264, 3861, 307, 456, 293, 309, 439, 1985, 293, 550, 291, 31605, 309, 293, 309, 51572], "temperature": 0.0, "avg_logprob": -0.12482111077559621, "compression_ratio": 1.7433628318584071, "no_speech_prob": 0.006884112488478422}, {"id": 111, "seek": 80448, "start": 804.48, "end": 811.6, "text": " suddenly fails because the machine is much faster than you are. And your application is simply not", "tokens": [50364, 5800, 18199, 570, 264, 3479, 307, 709, 4663, 813, 291, 366, 13, 400, 428, 3861, 307, 2935, 406, 50720], "temperature": 0.0, "avg_logprob": -0.12612810636821545, "compression_ratio": 1.7927927927927927, "no_speech_prob": 0.005354435183107853}, {"id": 112, "seek": 80448, "start": 811.6, "end": 818.24, "text": " up there. What PyTest container supports, if your app, if your container image has a health check", "tokens": [50720, 493, 456, 13, 708, 9953, 51, 377, 10129, 9346, 11, 498, 428, 724, 11, 498, 428, 10129, 3256, 575, 257, 1585, 1520, 51052], "temperature": 0.0, "avg_logprob": -0.12612810636821545, "compression_ratio": 1.7927927927927927, "no_speech_prob": 0.005354435183107853}, {"id": 113, "seek": 80448, "start": 818.24, "end": 824.96, "text": " defined, it will wait until the container is healthy. And as long as it's not healthy, it will not", "tokens": [51052, 7642, 11, 309, 486, 1699, 1826, 264, 10129, 307, 4627, 13, 400, 382, 938, 382, 309, 311, 406, 4627, 11, 309, 486, 406, 51388], "temperature": 0.0, "avg_logprob": -0.12612810636821545, "compression_ratio": 1.7927927927927927, "no_speech_prob": 0.005354435183107853}, {"id": 114, "seek": 80448, "start": 824.96, "end": 830.96, "text": " execute your test. If it becomes unhealthy, your test immediately fails. So, if you add a health check", "tokens": [51388, 14483, 428, 1500, 13, 759, 309, 3643, 29147, 11, 428, 1500, 4258, 18199, 13, 407, 11, 498, 291, 909, 257, 1585, 1520, 51688], "temperature": 0.0, "avg_logprob": -0.12612810636821545, "compression_ratio": 1.7927927927927927, "no_speech_prob": 0.005354435183107853}, {"id": 115, "seek": 83096, "start": 831.0400000000001, "end": 838.64, "text": " into your container file or if it's just in the image, then it will wait and it will start", "tokens": [50368, 666, 428, 10129, 3991, 420, 498, 309, 311, 445, 294, 264, 3256, 11, 550, 309, 486, 1699, 293, 309, 486, 722, 50748], "temperature": 0.0, "avg_logprob": -0.17607612999118105, "compression_ratio": 1.7671232876712328, "no_speech_prob": 0.006647453643381596}, {"id": 116, "seek": 83096, "start": 838.64, "end": 843.6800000000001, "text": " execute the test and you can always be sure that your container will be healthy. And if you don't", "tokens": [50748, 14483, 264, 1500, 293, 291, 393, 1009, 312, 988, 300, 428, 10129, 486, 312, 4627, 13, 400, 498, 291, 500, 380, 51000], "temperature": 0.0, "avg_logprob": -0.17607612999118105, "compression_ratio": 1.7671232876712328, "no_speech_prob": 0.006647453643381596}, {"id": 117, "seek": 83096, "start": 843.6800000000001, "end": 850.32, "text": " want that for whatever reason, then you can just say, okay, I don't care about health checks. Then", "tokens": [51000, 528, 300, 337, 2035, 1778, 11, 550, 291, 393, 445, 584, 11, 1392, 11, 286, 500, 380, 1127, 466, 1585, 13834, 13, 1396, 51332], "temperature": 0.0, "avg_logprob": -0.17607612999118105, "compression_ratio": 1.7671232876712328, "no_speech_prob": 0.006647453643381596}, {"id": 118, "seek": 83096, "start": 850.32, "end": 858.32, "text": " you just define the timeout to be minus one or you comment the health check out, but well. And then", "tokens": [51332, 291, 445, 6964, 264, 565, 346, 281, 312, 3175, 472, 420, 291, 2871, 264, 1585, 1520, 484, 11, 457, 731, 13, 400, 550, 51732], "temperature": 0.0, "avg_logprob": -0.17607612999118105, "compression_ratio": 1.7671232876712328, "no_speech_prob": 0.006647453643381596}, {"id": 119, "seek": 85832, "start": 858.96, "end": 864.24, "text": " you can, then your container might not, might still be starting or it might be unhealthy.", "tokens": [50396, 291, 393, 11, 550, 428, 10129, 1062, 406, 11, 1062, 920, 312, 2891, 420, 309, 1062, 312, 29147, 13, 50660], "temperature": 0.0, "avg_logprob": -0.12806439399719238, "compression_ratio": 1.5248618784530388, "no_speech_prob": 0.0034454064443707466}, {"id": 120, "seek": 85832, "start": 865.6, "end": 872.5600000000001, "text": " As I said, by default, it will use, it will pick Portman, but you can just set use Docker.", "tokens": [50728, 1018, 286, 848, 11, 538, 7576, 11, 309, 486, 764, 11, 309, 486, 1888, 6733, 1601, 11, 457, 291, 393, 445, 992, 764, 33772, 13, 51076], "temperature": 0.0, "avg_logprob": -0.12806439399719238, "compression_ratio": 1.5248618784530388, "no_speech_prob": 0.0034454064443707466}, {"id": 121, "seek": 85832, "start": 875.36, "end": 881.84, "text": " And what I'm, as I said, moderately proud is you can just run your tests in parallel. That also", "tokens": [51216, 400, 437, 286, 478, 11, 382, 286, 848, 11, 10494, 1592, 4570, 307, 291, 393, 445, 1190, 428, 6921, 294, 8952, 13, 663, 611, 51540], "temperature": 0.0, "avg_logprob": -0.12806439399719238, "compression_ratio": 1.5248618784530388, "no_speech_prob": 0.0034454064443707466}, {"id": 122, "seek": 88184, "start": 881.84, "end": 890.72, "text": " works with port forwardings. So, that can save you a lot of time unless all your container builds", "tokens": [50364, 1985, 365, 2436, 2128, 1109, 13, 407, 11, 300, 393, 3155, 291, 257, 688, 295, 565, 5969, 439, 428, 10129, 15182, 50808], "temperature": 0.0, "avg_logprob": -0.1386473070491444, "compression_ratio": 1.6324786324786325, "no_speech_prob": 0.003842498641461134}, {"id": 123, "seek": 88184, "start": 890.72, "end": 897.84, "text": " run themselves in parallel. So, then you're not going to save a lot. The thing cleans up very", "tokens": [50808, 1190, 2969, 294, 8952, 13, 407, 11, 550, 291, 434, 406, 516, 281, 3155, 257, 688, 13, 440, 551, 16912, 493, 588, 51164], "temperature": 0.0, "avg_logprob": -0.1386473070491444, "compression_ratio": 1.6324786324786325, "no_speech_prob": 0.003842498641461134}, {"id": 124, "seek": 88184, "start": 897.84, "end": 903.2, "text": " well after itself. So, if you create containers of volumes or parts or temporary directories,", "tokens": [51164, 731, 934, 2564, 13, 407, 11, 498, 291, 1884, 17089, 295, 22219, 420, 3166, 420, 13413, 5391, 530, 11, 51432], "temperature": 0.0, "avg_logprob": -0.1386473070491444, "compression_ratio": 1.6324786324786325, "no_speech_prob": 0.003842498641461134}, {"id": 125, "seek": 88184, "start": 903.2, "end": 908.64, "text": " all that gets cleaned up, images and intermediate layers are retained because otherwise it would", "tokens": [51432, 439, 300, 2170, 16146, 493, 11, 5267, 293, 19376, 7914, 366, 33438, 570, 5911, 309, 576, 51704], "temperature": 0.0, "avg_logprob": -0.1386473070491444, "compression_ratio": 1.6324786324786325, "no_speech_prob": 0.003842498641461134}, {"id": 126, "seek": 90864, "start": 908.64, "end": 916.72, "text": " just take forever and ever. There's a few people that use it. Most of them are those that I bullied", "tokens": [50364, 445, 747, 5680, 293, 1562, 13, 821, 311, 257, 1326, 561, 300, 764, 309, 13, 4534, 295, 552, 366, 729, 300, 286, 33603, 50768], "temperature": 0.0, "avg_logprob": -0.11406964269177668, "compression_ratio": 1.4217687074829932, "no_speech_prob": 0.009749576449394226}, {"id": 127, "seek": 90864, "start": 916.72, "end": 924.0, "text": " into that, but maybe you find this useful and you will be on this list. And since I'm out of time,", "tokens": [50768, 666, 300, 11, 457, 1310, 291, 915, 341, 4420, 293, 291, 486, 312, 322, 341, 1329, 13, 400, 1670, 286, 478, 484, 295, 565, 11, 51132], "temperature": 0.0, "avg_logprob": -0.11406964269177668, "compression_ratio": 1.4217687074829932, "no_speech_prob": 0.009749576449394226}, {"id": 128, "seek": 90864, "start": 924.0, "end": 928.48, "text": " thank you.", "tokens": [51132, 1309, 291, 13, 51356], "temperature": 0.0, "avg_logprob": -0.11406964269177668, "compression_ratio": 1.4217687074829932, "no_speech_prob": 0.009749576449394226}], "language": "en"}