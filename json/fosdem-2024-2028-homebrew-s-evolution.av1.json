{"text": " That's a very nice soothing start to the talk of just people saying shh. As some of you may know, I really like to start talks with raising hands. So put your hand in the air if you use Humbrew. Lots of people, cool. Put your hand in the air if you've contributed to Humbrew. This clump over here will make sense for the next question. Put your hand in the air if you maintain Humbrew. Put your hand in the air if you're concerned about what happens if there's a CV during this talk and no one is able to march a critical PR to fix open SSL. Because all the maintainers are here. Yes, good. Thank you. Yeah, so a little bit of background for you folks. Let's see if this is working. There we go. Oh, sorry. No, this is a Humbrew. We're Mac people here. Okay, there we go. So I forgot, Humbrew doesn't actually support this version anymore. No, back to that one. Oh, there we go. Okay, that's fine. Humbrew supports this one. Sorry, the jokes don't get any better from here. They're only worse. Hi, I'm Mike McQuade. This is my almost becoming yearly tradition at this point. Sort of state of Humbrew talk at FOSDEM. The distribution's ruined kindly. Let's me come and do this here, even though Humbrew isn't really a distribution, but it feels like the least square round peg hold situation at the conference here. You can find me at various places on the internet if you want to talk or ask me things during or after or whatever. I'm currently the CTO of a startup called Workbrew, which is trying to do some interesting stuff around Humbrew. I'll talk incredibly briefly about that at the end with two former GitHub people. I spent 10 years at GitHub, which I left as a principal engineer last year, and I'm Humbrew's project leader, which is something I have to get elected to do every year. No one has ever run against me, so please, someone do that and set me free from my life of enslavement to an open source project that I suffer for. And I've maintained Humbrew for apparently 15 years this year, which is a little bit worrying. So I'm going to talk through some stuff we've done in the last year or so. Some of it may be new to you, some of it will not be. None of it will be used to any of the maintainers. I don't know why they're here, but hopefully they will just laugh at my jokes and stuff like that anyway. The first major thing, I don't know if any of you noticed how many of you run Brew Update or noticed updating Humbrew. Lots of people complain at me about how Humbrew does this automatically without being prompted. You can opt out, but please don't. This should have got, for most people, most of the time, a lot faster than the last year. And the main reason is that we have stopped using Humbrew's GitHub repositories as the main data source for Humbrew. So when Humbrew was first created in 2009, one of the relatively innovative things it did was to use Git and put essentially all the data on a GitHub repo and then instead of building some complex update information system which is going to pull from some server somewhere that someone would have to host, it's like, no, we'll just do essentially just run Git fetch in the background. And Humbrew has kind of had a long-going battle with... Like a little bit of a battle with GitHub and more of a battle with the performance characteristics of this. So Humbrew Core, the main kind of Humbrew repository for all our formula, for all our packages, has kind of grown and grown over the years. Like we've had over, I think, 11,000 contributors, like millions of commits, hundreds of thousands of pull requests at this point. And as a result, it is very, very, very, very, very, very, very, very slow to do almost anything related to Git. And particularly with Git fetch, like a no-op Git fetch was probably at its worst, taking about 30 seconds just to be like, no, actually, you don't have any updates or anything required at all. So when I was lucky enough to be simultaneously working on Humbrew and GitHub, I added a call to the GitHub API that was there specifically to try and make Brut update a bit faster. So you could go to the GitHub API and it could quickly respond like, hey, don't run Git fetch, you don't need to, it's going to be really slow, and you don't have any changes anyway. A few other package managers use that now as well, which makes me happy. But over the years, lots of people at GitHub have kind of grumbled about using a Git repo as a CDN that's kind of nicely global. Globally distributed, and I believe at our peak, we had a couple of GitHub servers that were essentially dedicated purely to people fetching from Humbrew Core. So eventually, after leaving the company, it's kind of weird that it took me to leave the company to actually make my coworker sloppy. We, like with a bunch of work from other maintainers, we kind of moved over to essentially just curling a JSON file off the internet now. So instead, we have like a 15 meg-ish, I think, compressed file for Humbrew Core, for Humbrew Cask. When there's an update, we don't have any sort of clever binary diffing or anything, unfortunately, so we just download the whole thing again. But that seems to be a lot faster for most of the people, most of the time. And we still, optimistically, will be able to make it faster in future. So in case you didn't know, Humbrew has like a JSON API. This is basically the kind of the basis of what we're using. We've had to kind of add some bits and pieces and modify, move things around. And one of our maintainers here added like nice signing to this and stuff like that so that we could meet the kind of security requirements, the performance requirements we wanted for this new API way of downloading. It's actually, our API is really, really fast because it's posted on GitHub pages. So if you've had an idea of like statically building your API, it's incredibly painful in some respects, but also kind of fun in other ways. But yeah, don't dig too deep on how that's implemented because it's pretty disgusting. Another thing, somewhat relatedly, if you have set any of these variables in the past, like commonly people will set these things because Humbrew was updating too often and it was too slow and annoyed them, or shortly after we rolled out the API stuff, a bunch of people opted out because it was a little bit buggy and stuff like that, or it also updates too often considering un-setting them for a little bit. And then if things are still annoying for you, feel free to set them again, but you might have a better time without these than you used to. Similarly, if you still have these reports on your disk, you can now un-tap them and then you will get much more space back and just generally your updating could be potentially a little bit faster and happier and all this type of stuff. The other relatively big thing we did in the last year, not super exciting for everyone, but our analytics were hosted by Google for a very long time. We had a lot of people who didn't like us having analytics at all and I chose to ignore those people because we need them to be able to do our job, unfortunately. But I guess a concern we did hear again and again from people was like, hey, we don't mind you having analytics, but we're a bit concerned with all this data going to Google and if you look at the analytics docs, you can opt out of certain data collection, but that's kind of a line on trusting Google to do what they say, which I kind of do, but I understand not everyone does. So we've kind of now moved to kind of a nice cloud-hosted like EU instance of inflex DB, which means that we're gathering essentially the same data we had before, but we're not kind of tying it to individual users. We don't have the ability to kind of do stuff like capture IP addresses even if we wanted to and that makes everything a little bit nicer. So we've now destroyed all of our existing Google Analytics data and this means that if you want to know what Hummoo was doing or what user accounts were like two years ago, tough luck, but we do have this new analytics system automatically kind of deletes data after 365 days, so this should get us a nicer, slightly more privacy-focused approach in future. And the other thing that has been kind of principal with our analytics is trying to have it. So if people may not trust us with Gather Analytics, I understand that like it's a touchy point in the tech industry with privacy and all this stuff nowadays, but we do try and make all the information we gather public, so we've got these pages like under formula brudo sh slash analytics, various pages of the analytics we gather. We've got a few more things there than we used to be able to have and you can kind of see the download counts, percentage counts, all this type of stuff. And basically maintainers don't have access really to any more information than you do. Like we have a couple, a handful of people can access our InfluxDB console directly, but like the data in there is in such a kind of messy, horrible format that no one is querying that directly. They're all just using the same web pages as you and I might use, which feels like again, from a privacy perspective, we're all kind of on the same page, whether you're a user of Hummoo or people maintaining it. So also, again, another thing to stick your hand in the air for, who considers Hummoo to be slow? Yeah, a few people. Put your hand in the air if you feel like it got faster in the last year. Mostly just maintainers who made it faster, so... It's all right, you still count iValue. So this is a relatively common critique we hear about Hummoo, is it's slow or why does it upgrade all my things all the times and things like that. So we are working on this, this is kind of a background, medium priority thing for us that we kind of considered for quite a while. So in the last year, hopefully, brew update, that's mainly got faster from the API stuff we mentioned before. Hopefully brew upgrades, we've now made it a lot, in certain cases at least, we can now upgrade fewer of your dependencies than we used to. This is a little bit of a hack, but I'm going to talk later on about how we might be able to make this better going forward. And then similarly around brew fetch, some of our maintainers noticed that there was a bunch of work happening there that didn't need to happen. So I guess if you do find Hummoo to be a little bit too slow, then be relatively confident that we do feel your pain and we are trying to make things faster most of the time. A really weird performance optimization we decided to do, considering everything I've said before, is I don't know if anyone who's not a maintainer ever went and clicked around on the repo pages on GitHub, but due to the Git issues I mentioned earlier, a lot of these pages were time out and stuff like that. And another thing that Git and GitHub people who knew a lot about Git have said to us for a while is due to some complicated Git internal stuff that I don't really understand, you have structured the Hummoo repo in pretty much the worst possible way for Git performance. Git apparently really does not like having directories with thousands of files in them, and we had, I think, a directory with 8,000 files and it was something like that, which means you can see it on the GitHub interface because all these operations list in the directory, if you did a Git blame or Git log on this directory, all of those were time out, which meant increasing amounts of the GitHub user interface was just not useful for when you were using Hummoo, and that also contributed to why Git fetch was so slow Git GC was so slow, like opening PRs, like the pushes and the pulls and all this stuff involved, which is like getting really slow and getting slower and slower and slower. We were also seeing more instance with GitHub that GitHub didn't seem to think we're related to this, but I kind of did. So we've now like sharded our repos, so essentially like everything is split into directories based on name, and because we have quite a lot of libraries, so Lib gets its own special directory, it doesn't get bundled in under L, we've done the same thing for Hummoo Cask as well, like again, as I say, GitHub would be wanting us to do this for ages, but we've finally actually done this now, and that now means that on these pages, you can actually finally now see the commit information and timestamps and all this type of stuff, and it makes it a bit more useful for people when it wasn't before. So a more exciting thing for us is, we moved to like using Ruby 3.1, Hummoo, who knew that Hummoo was written in Ruby? It's this widely known thing, yeah, cool. And so Hummoo originally I think was on Mac OS, 10.5 I think the first version, and back then Apple provided like loads of stuff with the OS, including Ruby, 1.8 or whatever I think it was at the time, and Hummoo kind of particularly in the early days tried to use as much stuff from the system as possible and not pull in its own kind of libraries. We still try and do that where we can, but Ruby was an example where Apple said a few years ago that like, okay, we're kind of deprecating the system version of Ruby and Python and I think Perl and stuff like that, and for Apple kind of deprecating this stuff, we've sort of been playing chicken and being like, well, you say it's deprecated, but you keep upgrading it for us, so we're gonna just keep using your version as long as we can, and like eventually kind of went to some Apple people for the last release and were like, hey, the Ruby you supply is 2.6, that's really old, when are we gonna get a new one? And they were like, did you not read when we told you it was deprecated? And we were like, yeah, but, yeah, but please. And they said, no, this time we mean it. So like finally we've kind of, we've always had our own kind of thing we call portable Ruby, which allowed us a way to distribute a kind of a Ruby that you could install anywhere in your system. So it worked regardless of where your homebrew is, and it would work on a variety of Mac OS versions and stuff like that. And that was now moved to Ruby 3.1, so now we have a system where essentially everyone on Mac OS at least, on Linux, there's some configurations where you don't need this, but everyone has portable Ruby now and supplies kind of a nice, relatively new version of Ruby. So this is nice for us, it probably has some, it's had some mild performance increases, and it lets us use like newer language features, makes homebrew easier to kind of maintain, makes it easier for homebrew like Ruby users to kind of not be used to this kind of ancient version of Ruby, and then there's stuff like Surabay and Rubikop and all these other libraries we kind of depend on that were kind of creeping towards deprecating Ruby 2.6, or had already done so. So let's just kind of keep more up to date and stuff like that as well, which is very nice. We've also released a official like homebrew Mac OS package. This is another thing that's been kind of requested for a long time, people have a love-hate relationship. I think homebrew was one of the first projects to do the whole curl this bash script into your terminal, and then we'll install it that way. Who has security concerns about that approach? Almost everyone, good. We're gonna keep doing it, so yeah. All right. But if you don't like that, then you can use this instead. So this is kind of the more standard installation process you would expect, where you get a nice installer and you kind of click through these things and stuff like that. And you should end up at the end with essentially the same stuff, and it prints the same messages for you and all this type of stuff as the bash installer, but you can do this through like MDM tools and things like that. But as I mentioned earlier, I've actually been working on a few little bits which are kind of not strictly homebrew related. So I've been working on workbrew, which is this thing where we're building kind of some close source stuff on top of work, on top of homebrew to try and kind of find this balance where there's been a bunch of things where like the package is an example of one where people have asked for it over the years, some people wanted to get involved and built that, and that's all fine. Whereas on workbrew, there's been a bunch of stuff that people have asked for over the years and I've asked for it, it's homebrew volunteers and they don't want to do it, say okay, well fine, we can do some of this stuff for you for money. So we have our own package here now, which does a few more things than the homebrew one does and stuff like that. Not going to go on about workbrew too much, but if you are interested, go and have a look at our website and there's a little demo of like what we're doing and we're kind of recruiting people who we want to work with on this stuff. So get in touch. But on homebrew stuff, that's looking forward to the next year. So we meet together as kind of a homebrew group each year, so I'm not entirely sure what our roadmap is, we're going to kind of try and decide some things tomorrow, maybe as a group, kind of figure out like what we see as the most important things, but some ideas kind of I've seen flipping around and things that I have and kind of have currently open issues for them or stuff around like handling conflicts better. So there's this kind of ability for packages and homebrew to conflict with each other, that means you can't have either of them installed, sorry, you can't have both of them installed at the same time. That's kind of a pain in the ass, it doesn't really work very nicely, so we're hoping to improve some of that. There's also kind of inherent conflicts between CASCs and formulae. Who feels like they understand the difference between CASCs and formulae? Okay, only the homebrew maintainers, great. So homebrew had this kind of somewhat alternate approach, like the kind of integrated with homebrew, but was kind of its own separate ecosystem a few years ago that kind of merged into homebrew proper a few years ago called homebrew CASC. So homebrew, at least in the official kind of repo, is all about taking open source software. We build it from source, we give you binary packages, and then we ship that to you. Homebrew CASC is a little bit different, that's for distributing proprietary software where the upstream package, well, the upstream supplier of the software provides the binaries for you, and then we download that and install it for you. So for example, Wget might be a formula, because we can download the sources and build that from scratch, or something like Google Chrome, or Zoom, or whatever would be a CASC. So there's some cases in which there are CASC and formula for the same thing, like Docker, for example, is both an open source project that kind of, you get some nice binaries, you can build from source, but also there's like all the gooey stuff and whatever. And if you do, if you install the Docker formula and the Docker CASC at the same time, things get angry and start shouting at you, and it doesn't work very nicely. So that's something that we're probably gonna try and make better this year. Another thing is we're continuing to work on our API stuff, we're trying to make it smaller and faster and consider ways that we can do that to again make that updating experience more pleasant for people to use. The other, also the API, as someone who's kind of been consuming the Humbrew API a lot recently, it's pretty crap. It was originally kind of created in the relatively early days of like, I don't know, 2013 or something like that. And we've just kind of bolted on bits at this point where it's got like six arms and three legs and they're all the wrong shape and it's, yeah, yuck. So hopefully we can have something that's a little bit nicer for people who are kind of trying to integrate with Humbrew to use, release this year as well. And the stuff I mentioned earlier about upgrades. So part of the reason Humbrew is often upgrading everything all the time and people get grumpy because that's really slow, is because we don't have a good way of figuring out what upgrades are needed and when. So historically we had the kind of conservative approach of, well, if there's anything else that's new, that's in your kind of dependency tree, we will always try and upgrade everything every time just to be safe. But then we realized like, well, you upgrade a ton of stuff all the time and then that makes people sad and angry on the internet and all this type of stuff. So then what I mentioned we did last year was we basically said, well, we can kind of infer a little bit from the way the binary packages were built. The binary package was built with OpenSL 1.1.1 and now we have OpenSL 1.1.2. We know that this package doesn't need 1.1.2 so we don't have to upgrade it, yada, yada, yada. But hopefully we actually have like, there's a lot of the kind of bigger, proper package managers and distributions have like actual like ABI which stands for application binary interface, essentially like what libraries you can link again and change the versions without breaking things. They have a lot of tooling around that stuff that we could kind of adopt and similarly like we can have a way, even with our existing tooling to kind of make this stuff a little bit more explicit, which would mean that we don't need to upgrade as much stuff as much of the time. But because we're an OpenSL project, maybe what we do in the last year will be something that we haven't thought of yet, that we think of because someone in this room has a good idea in a pull request or you file a bug report and then that makes us think of something that's smart and then we go and do something in a clever way or you file a really well written feature request that then inspires us to do something cool. So I really encourage you, even if you've never been involved in an OpenSource project before, we're generally, myself excluded, a fairly friendly bunch and we will all try and help you get involved with Homebrew and help you along the way, particularly with something like a pull request, like if you have an idea and you think you can kind of make it happen and you can write some code in some sort of form, even if it's only like 10% of the way to working, feel free to open a pull request and then just say, hey, like this is what I tried, this is what I need help with, and then we can kind of help you along the way. It's often much easier to talk about the code than it is to talk about the ideas about the code beforehand. We're not the type of project where every pull request needs an issue open to beforehand, like we believe in discussing the code whenever you can rather than kind of discussing some abstract conception of what the code might look like when someone decides to write it. So I think we've got a little bit of time for questions now and also if you don't feel comfortable asking any questions in this format, then feel free to ask me anything privately. I'm on Mastodon and Twitter and you can email me and stuff as well. And yeah, thank you very much for having me. APPLAUSE Are there any questions? Oh, all right. Just going to ask, where's the... Oh, the beer costume. OK, so anyone who was here last year, I was wearing a head to toe beer costume because I love my Uber maintainer friends, but they're not always the most organized bunch. And someone posted a picture before Fosdame last year saying, like, here's a beer costume. Wouldn't it be funny we can make Mike wear this lol? And I was like, yeah, basically like challenge accepted. You're not organized enough to make that happen. And unfortunately they were and I had to wear a beer costume. There are pictures on the Internet. Don't look for them. Thankfully they were not organized enough to bring it this year, so that is why I'm not wearing the beer costume. And shame on you, sir, for reminding people that it exists. LAUGHTER Any more questions? Awesome. Thank you, Mike. APPLAUSE You", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 14.68, "text": " That's a very nice soothing start to the talk of just people saying shh.", "tokens": [50364, 663, 311, 257, 588, 1481, 40704, 722, 281, 264, 751, 295, 445, 561, 1566, 402, 71, 13, 51098], "temperature": 0.0, "avg_logprob": -0.3072647283106674, "compression_ratio": 1.5988372093023255, "no_speech_prob": 0.6254209280014038}, {"id": 1, "seek": 0, "start": 14.68, "end": 18.72, "text": " As some of you may know, I really like to start talks with raising hands.", "tokens": [51098, 1018, 512, 295, 291, 815, 458, 11, 286, 534, 411, 281, 722, 6686, 365, 11225, 2377, 13, 51300], "temperature": 0.0, "avg_logprob": -0.3072647283106674, "compression_ratio": 1.5988372093023255, "no_speech_prob": 0.6254209280014038}, {"id": 2, "seek": 0, "start": 18.72, "end": 21.48, "text": " So put your hand in the air if you use Humbrew.", "tokens": [51300, 407, 829, 428, 1011, 294, 264, 1988, 498, 291, 764, 389, 2860, 2236, 13, 51438], "temperature": 0.0, "avg_logprob": -0.3072647283106674, "compression_ratio": 1.5988372093023255, "no_speech_prob": 0.6254209280014038}, {"id": 3, "seek": 0, "start": 21.48, "end": 23.98, "text": " Lots of people, cool.", "tokens": [51438, 15908, 295, 561, 11, 1627, 13, 51563], "temperature": 0.0, "avg_logprob": -0.3072647283106674, "compression_ratio": 1.5988372093023255, "no_speech_prob": 0.6254209280014038}, {"id": 4, "seek": 0, "start": 23.98, "end": 28.28, "text": " Put your hand in the air if you've contributed to Humbrew.", "tokens": [51563, 4935, 428, 1011, 294, 264, 1988, 498, 291, 600, 18434, 281, 389, 2860, 2236, 13, 51778], "temperature": 0.0, "avg_logprob": -0.3072647283106674, "compression_ratio": 1.5988372093023255, "no_speech_prob": 0.6254209280014038}, {"id": 5, "seek": 2828, "start": 29.040000000000003, "end": 31.560000000000002, "text": " This clump over here will make sense for the next question.", "tokens": [50402, 639, 596, 1420, 670, 510, 486, 652, 2020, 337, 264, 958, 1168, 13, 50528], "temperature": 0.0, "avg_logprob": -0.32810033600905847, "compression_ratio": 1.592156862745098, "no_speech_prob": 0.024226466193795204}, {"id": 6, "seek": 2828, "start": 31.560000000000002, "end": 33.92, "text": " Put your hand in the air if you maintain Humbrew.", "tokens": [50528, 4935, 428, 1011, 294, 264, 1988, 498, 291, 6909, 389, 2860, 2236, 13, 50646], "temperature": 0.0, "avg_logprob": -0.32810033600905847, "compression_ratio": 1.592156862745098, "no_speech_prob": 0.024226466193795204}, {"id": 7, "seek": 2828, "start": 33.92, "end": 41.64, "text": " Put your hand in the air if you're concerned about what happens if there's a CV during this talk", "tokens": [50646, 4935, 428, 1011, 294, 264, 1988, 498, 291, 434, 5922, 466, 437, 2314, 498, 456, 311, 257, 22995, 1830, 341, 751, 51032], "temperature": 0.0, "avg_logprob": -0.32810033600905847, "compression_ratio": 1.592156862745098, "no_speech_prob": 0.024226466193795204}, {"id": 8, "seek": 2828, "start": 41.64, "end": 45.400000000000006, "text": " and no one is able to march a critical PR to fix open SSL.", "tokens": [51032, 293, 572, 472, 307, 1075, 281, 8368, 257, 4924, 11568, 281, 3191, 1269, 12238, 43, 13, 51220], "temperature": 0.0, "avg_logprob": -0.32810033600905847, "compression_ratio": 1.592156862745098, "no_speech_prob": 0.024226466193795204}, {"id": 9, "seek": 2828, "start": 45.400000000000006, "end": 47.120000000000005, "text": " Because all the maintainers are here.", "tokens": [51220, 1436, 439, 264, 6909, 433, 366, 510, 13, 51306], "temperature": 0.0, "avg_logprob": -0.32810033600905847, "compression_ratio": 1.592156862745098, "no_speech_prob": 0.024226466193795204}, {"id": 10, "seek": 2828, "start": 47.120000000000005, "end": 48.72, "text": " Yes, good. Thank you.", "tokens": [51306, 1079, 11, 665, 13, 1044, 291, 13, 51386], "temperature": 0.0, "avg_logprob": -0.32810033600905847, "compression_ratio": 1.592156862745098, "no_speech_prob": 0.024226466193795204}, {"id": 11, "seek": 2828, "start": 48.72, "end": 53.32, "text": " Yeah, so a little bit of background for you folks.", "tokens": [51386, 865, 11, 370, 257, 707, 857, 295, 3678, 337, 291, 4024, 13, 51616], "temperature": 0.0, "avg_logprob": -0.32810033600905847, "compression_ratio": 1.592156862745098, "no_speech_prob": 0.024226466193795204}, {"id": 12, "seek": 2828, "start": 53.32, "end": 56.0, "text": " Let's see if this is working.", "tokens": [51616, 961, 311, 536, 498, 341, 307, 1364, 13, 51750], "temperature": 0.0, "avg_logprob": -0.32810033600905847, "compression_ratio": 1.592156862745098, "no_speech_prob": 0.024226466193795204}, {"id": 13, "seek": 5600, "start": 56.72, "end": 58.16, "text": " There we go.", "tokens": [50400, 821, 321, 352, 13, 50472], "temperature": 0.0, "avg_logprob": -0.33490016542632006, "compression_ratio": 1.6809338521400778, "no_speech_prob": 0.05136917158961296}, {"id": 14, "seek": 5600, "start": 58.16, "end": 61.6, "text": " Oh, sorry. No, this is a Humbrew. We're Mac people here.", "tokens": [50472, 876, 11, 2597, 13, 883, 11, 341, 307, 257, 389, 2860, 2236, 13, 492, 434, 5707, 561, 510, 13, 50644], "temperature": 0.0, "avg_logprob": -0.33490016542632006, "compression_ratio": 1.6809338521400778, "no_speech_prob": 0.05136917158961296}, {"id": 15, "seek": 5600, "start": 61.6, "end": 63.36, "text": " Okay, there we go.", "tokens": [50644, 1033, 11, 456, 321, 352, 13, 50732], "temperature": 0.0, "avg_logprob": -0.33490016542632006, "compression_ratio": 1.6809338521400778, "no_speech_prob": 0.05136917158961296}, {"id": 16, "seek": 5600, "start": 63.36, "end": 67.92, "text": " So I forgot, Humbrew doesn't actually support this version anymore.", "tokens": [50732, 407, 286, 5298, 11, 389, 2860, 2236, 1177, 380, 767, 1406, 341, 3037, 3602, 13, 50960], "temperature": 0.0, "avg_logprob": -0.33490016542632006, "compression_ratio": 1.6809338521400778, "no_speech_prob": 0.05136917158961296}, {"id": 17, "seek": 5600, "start": 67.92, "end": 69.52, "text": " No, back to that one.", "tokens": [50960, 883, 11, 646, 281, 300, 472, 13, 51040], "temperature": 0.0, "avg_logprob": -0.33490016542632006, "compression_ratio": 1.6809338521400778, "no_speech_prob": 0.05136917158961296}, {"id": 18, "seek": 5600, "start": 69.52, "end": 71.88, "text": " Oh, there we go. Okay, that's fine. Humbrew supports this one.", "tokens": [51040, 876, 11, 456, 321, 352, 13, 1033, 11, 300, 311, 2489, 13, 389, 2860, 2236, 9346, 341, 472, 13, 51158], "temperature": 0.0, "avg_logprob": -0.33490016542632006, "compression_ratio": 1.6809338521400778, "no_speech_prob": 0.05136917158961296}, {"id": 19, "seek": 5600, "start": 71.88, "end": 74.2, "text": " Sorry, the jokes don't get any better from here.", "tokens": [51158, 4919, 11, 264, 14439, 500, 380, 483, 604, 1101, 490, 510, 13, 51274], "temperature": 0.0, "avg_logprob": -0.33490016542632006, "compression_ratio": 1.6809338521400778, "no_speech_prob": 0.05136917158961296}, {"id": 20, "seek": 5600, "start": 74.2, "end": 75.84, "text": " They're only worse.", "tokens": [51274, 814, 434, 787, 5324, 13, 51356], "temperature": 0.0, "avg_logprob": -0.33490016542632006, "compression_ratio": 1.6809338521400778, "no_speech_prob": 0.05136917158961296}, {"id": 21, "seek": 5600, "start": 75.84, "end": 78.28, "text": " Hi, I'm Mike McQuade.", "tokens": [51356, 2421, 11, 286, 478, 6602, 4050, 8547, 762, 13, 51478], "temperature": 0.0, "avg_logprob": -0.33490016542632006, "compression_ratio": 1.6809338521400778, "no_speech_prob": 0.05136917158961296}, {"id": 22, "seek": 5600, "start": 78.28, "end": 82.4, "text": " This is my almost becoming yearly tradition at this point.", "tokens": [51478, 639, 307, 452, 1920, 5617, 39102, 6994, 412, 341, 935, 13, 51684], "temperature": 0.0, "avg_logprob": -0.33490016542632006, "compression_ratio": 1.6809338521400778, "no_speech_prob": 0.05136917158961296}, {"id": 23, "seek": 5600, "start": 82.4, "end": 85.03999999999999, "text": " Sort of state of Humbrew talk at FOSDEM.", "tokens": [51684, 26149, 295, 1785, 295, 389, 2860, 2236, 751, 412, 479, 4367, 35, 6683, 13, 51816], "temperature": 0.0, "avg_logprob": -0.33490016542632006, "compression_ratio": 1.6809338521400778, "no_speech_prob": 0.05136917158961296}, {"id": 24, "seek": 8504, "start": 85.08000000000001, "end": 86.92, "text": " The distribution's ruined kindly.", "tokens": [50366, 440, 7316, 311, 17013, 29736, 13, 50458], "temperature": 0.0, "avg_logprob": -0.21222472581707064, "compression_ratio": 1.604026845637584, "no_speech_prob": 0.05617939680814743}, {"id": 25, "seek": 8504, "start": 86.92, "end": 89.72, "text": " Let's me come and do this here, even though Humbrew isn't really a distribution,", "tokens": [50458, 961, 311, 385, 808, 293, 360, 341, 510, 11, 754, 1673, 389, 2860, 2236, 1943, 380, 534, 257, 7316, 11, 50598], "temperature": 0.0, "avg_logprob": -0.21222472581707064, "compression_ratio": 1.604026845637584, "no_speech_prob": 0.05617939680814743}, {"id": 26, "seek": 8504, "start": 89.72, "end": 96.4, "text": " but it feels like the least square round peg hold situation at the conference here.", "tokens": [50598, 457, 309, 3417, 411, 264, 1935, 3732, 3098, 17199, 1797, 2590, 412, 264, 7586, 510, 13, 50932], "temperature": 0.0, "avg_logprob": -0.21222472581707064, "compression_ratio": 1.604026845637584, "no_speech_prob": 0.05617939680814743}, {"id": 27, "seek": 8504, "start": 96.4, "end": 99.12, "text": " You can find me at various places on the internet", "tokens": [50932, 509, 393, 915, 385, 412, 3683, 3190, 322, 264, 4705, 51068], "temperature": 0.0, "avg_logprob": -0.21222472581707064, "compression_ratio": 1.604026845637584, "no_speech_prob": 0.05617939680814743}, {"id": 28, "seek": 8504, "start": 99.12, "end": 103.36000000000001, "text": " if you want to talk or ask me things during or after or whatever.", "tokens": [51068, 498, 291, 528, 281, 751, 420, 1029, 385, 721, 1830, 420, 934, 420, 2035, 13, 51280], "temperature": 0.0, "avg_logprob": -0.21222472581707064, "compression_ratio": 1.604026845637584, "no_speech_prob": 0.05617939680814743}, {"id": 29, "seek": 8504, "start": 103.36000000000001, "end": 106.80000000000001, "text": " I'm currently the CTO of a startup called Workbrew,", "tokens": [51280, 286, 478, 4362, 264, 383, 15427, 295, 257, 18578, 1219, 6603, 65, 2236, 11, 51452], "temperature": 0.0, "avg_logprob": -0.21222472581707064, "compression_ratio": 1.604026845637584, "no_speech_prob": 0.05617939680814743}, {"id": 30, "seek": 8504, "start": 106.80000000000001, "end": 110.16000000000001, "text": " which is trying to do some interesting stuff around Humbrew.", "tokens": [51452, 597, 307, 1382, 281, 360, 512, 1880, 1507, 926, 389, 2860, 2236, 13, 51620], "temperature": 0.0, "avg_logprob": -0.21222472581707064, "compression_ratio": 1.604026845637584, "no_speech_prob": 0.05617939680814743}, {"id": 31, "seek": 8504, "start": 110.16000000000001, "end": 112.88000000000001, "text": " I'll talk incredibly briefly about that at the end", "tokens": [51620, 286, 603, 751, 6252, 10515, 466, 300, 412, 264, 917, 51756], "temperature": 0.0, "avg_logprob": -0.21222472581707064, "compression_ratio": 1.604026845637584, "no_speech_prob": 0.05617939680814743}, {"id": 32, "seek": 11288, "start": 112.92, "end": 114.83999999999999, "text": " with two former GitHub people.", "tokens": [50366, 365, 732, 5819, 23331, 561, 13, 50462], "temperature": 0.0, "avg_logprob": -0.16105985641479492, "compression_ratio": 1.625, "no_speech_prob": 0.04297727346420288}, {"id": 33, "seek": 11288, "start": 114.83999999999999, "end": 119.03999999999999, "text": " I spent 10 years at GitHub, which I left as a principal engineer last year,", "tokens": [50462, 286, 4418, 1266, 924, 412, 23331, 11, 597, 286, 1411, 382, 257, 9716, 11403, 1036, 1064, 11, 50672], "temperature": 0.0, "avg_logprob": -0.16105985641479492, "compression_ratio": 1.625, "no_speech_prob": 0.04297727346420288}, {"id": 34, "seek": 11288, "start": 119.03999999999999, "end": 120.44, "text": " and I'm Humbrew's project leader,", "tokens": [50672, 293, 286, 478, 389, 2860, 2236, 311, 1716, 5263, 11, 50742], "temperature": 0.0, "avg_logprob": -0.16105985641479492, "compression_ratio": 1.625, "no_speech_prob": 0.04297727346420288}, {"id": 35, "seek": 11288, "start": 120.44, "end": 123.44, "text": " which is something I have to get elected to do every year.", "tokens": [50742, 597, 307, 746, 286, 362, 281, 483, 11776, 281, 360, 633, 1064, 13, 50892], "temperature": 0.0, "avg_logprob": -0.16105985641479492, "compression_ratio": 1.625, "no_speech_prob": 0.04297727346420288}, {"id": 36, "seek": 11288, "start": 123.44, "end": 126.92, "text": " No one has ever run against me, so please, someone do that", "tokens": [50892, 883, 472, 575, 1562, 1190, 1970, 385, 11, 370, 1767, 11, 1580, 360, 300, 51066], "temperature": 0.0, "avg_logprob": -0.16105985641479492, "compression_ratio": 1.625, "no_speech_prob": 0.04297727346420288}, {"id": 37, "seek": 11288, "start": 126.92, "end": 132.56, "text": " and set me free from my life of enslavement to an open source project that I suffer for.", "tokens": [51066, 293, 992, 385, 1737, 490, 452, 993, 295, 3489, 27995, 518, 281, 364, 1269, 4009, 1716, 300, 286, 9753, 337, 13, 51348], "temperature": 0.0, "avg_logprob": -0.16105985641479492, "compression_ratio": 1.625, "no_speech_prob": 0.04297727346420288}, {"id": 38, "seek": 11288, "start": 132.56, "end": 135.72, "text": " And I've maintained Humbrew for apparently 15 years this year,", "tokens": [51348, 400, 286, 600, 17578, 389, 2860, 2236, 337, 7970, 2119, 924, 341, 1064, 11, 51506], "temperature": 0.0, "avg_logprob": -0.16105985641479492, "compression_ratio": 1.625, "no_speech_prob": 0.04297727346420288}, {"id": 39, "seek": 11288, "start": 135.72, "end": 139.12, "text": " which is a little bit worrying.", "tokens": [51506, 597, 307, 257, 707, 857, 18788, 13, 51676], "temperature": 0.0, "avg_logprob": -0.16105985641479492, "compression_ratio": 1.625, "no_speech_prob": 0.04297727346420288}, {"id": 40, "seek": 13912, "start": 139.20000000000002, "end": 143.84, "text": " So I'm going to talk through some stuff we've done in the last year or so.", "tokens": [50368, 407, 286, 478, 516, 281, 751, 807, 512, 1507, 321, 600, 1096, 294, 264, 1036, 1064, 420, 370, 13, 50600], "temperature": 0.0, "avg_logprob": -0.18297871907552082, "compression_ratio": 1.720257234726688, "no_speech_prob": 0.04081632196903229}, {"id": 41, "seek": 13912, "start": 143.84, "end": 146.0, "text": " Some of it may be new to you, some of it will not be.", "tokens": [50600, 2188, 295, 309, 815, 312, 777, 281, 291, 11, 512, 295, 309, 486, 406, 312, 13, 50708], "temperature": 0.0, "avg_logprob": -0.18297871907552082, "compression_ratio": 1.720257234726688, "no_speech_prob": 0.04081632196903229}, {"id": 42, "seek": 13912, "start": 146.0, "end": 147.64000000000001, "text": " None of it will be used to any of the maintainers.", "tokens": [50708, 14492, 295, 309, 486, 312, 1143, 281, 604, 295, 264, 6909, 433, 13, 50790], "temperature": 0.0, "avg_logprob": -0.18297871907552082, "compression_ratio": 1.720257234726688, "no_speech_prob": 0.04081632196903229}, {"id": 43, "seek": 13912, "start": 147.64000000000001, "end": 149.08, "text": " I don't know why they're here,", "tokens": [50790, 286, 500, 380, 458, 983, 436, 434, 510, 11, 50862], "temperature": 0.0, "avg_logprob": -0.18297871907552082, "compression_ratio": 1.720257234726688, "no_speech_prob": 0.04081632196903229}, {"id": 44, "seek": 13912, "start": 149.08, "end": 152.88, "text": " but hopefully they will just laugh at my jokes and stuff like that anyway.", "tokens": [50862, 457, 4696, 436, 486, 445, 5801, 412, 452, 14439, 293, 1507, 411, 300, 4033, 13, 51052], "temperature": 0.0, "avg_logprob": -0.18297871907552082, "compression_ratio": 1.720257234726688, "no_speech_prob": 0.04081632196903229}, {"id": 45, "seek": 13912, "start": 152.88, "end": 156.36, "text": " The first major thing, I don't know if any of you noticed", "tokens": [51052, 440, 700, 2563, 551, 11, 286, 500, 380, 458, 498, 604, 295, 291, 5694, 51226], "temperature": 0.0, "avg_logprob": -0.18297871907552082, "compression_ratio": 1.720257234726688, "no_speech_prob": 0.04081632196903229}, {"id": 46, "seek": 13912, "start": 156.36, "end": 160.16, "text": " how many of you run Brew Update or noticed updating Humbrew.", "tokens": [51226, 577, 867, 295, 291, 1190, 42906, 28923, 420, 5694, 25113, 389, 2860, 2236, 13, 51416], "temperature": 0.0, "avg_logprob": -0.18297871907552082, "compression_ratio": 1.720257234726688, "no_speech_prob": 0.04081632196903229}, {"id": 47, "seek": 13912, "start": 160.16, "end": 163.08, "text": " Lots of people complain at me about how Humbrew does this automatically", "tokens": [51416, 15908, 295, 561, 11024, 412, 385, 466, 577, 389, 2860, 2236, 775, 341, 6772, 51562], "temperature": 0.0, "avg_logprob": -0.18297871907552082, "compression_ratio": 1.720257234726688, "no_speech_prob": 0.04081632196903229}, {"id": 48, "seek": 13912, "start": 163.08, "end": 164.6, "text": " without being prompted.", "tokens": [51562, 1553, 885, 31042, 13, 51638], "temperature": 0.0, "avg_logprob": -0.18297871907552082, "compression_ratio": 1.720257234726688, "no_speech_prob": 0.04081632196903229}, {"id": 49, "seek": 13912, "start": 164.6, "end": 166.88, "text": " You can opt out, but please don't.", "tokens": [51638, 509, 393, 2427, 484, 11, 457, 1767, 500, 380, 13, 51752], "temperature": 0.0, "avg_logprob": -0.18297871907552082, "compression_ratio": 1.720257234726688, "no_speech_prob": 0.04081632196903229}, {"id": 50, "seek": 16688, "start": 166.92, "end": 171.72, "text": " This should have got, for most people, most of the time, a lot faster than the last year.", "tokens": [50366, 639, 820, 362, 658, 11, 337, 881, 561, 11, 881, 295, 264, 565, 11, 257, 688, 4663, 813, 264, 1036, 1064, 13, 50606], "temperature": 0.0, "avg_logprob": -0.15856137099089446, "compression_ratio": 1.6436781609195403, "no_speech_prob": 0.008467729203402996}, {"id": 51, "seek": 16688, "start": 171.72, "end": 178.32, "text": " And the main reason is that we have stopped using Humbrew's GitHub repositories", "tokens": [50606, 400, 264, 2135, 1778, 307, 300, 321, 362, 5936, 1228, 389, 2860, 2236, 311, 23331, 22283, 2083, 50936], "temperature": 0.0, "avg_logprob": -0.15856137099089446, "compression_ratio": 1.6436781609195403, "no_speech_prob": 0.008467729203402996}, {"id": 52, "seek": 16688, "start": 178.32, "end": 181.44, "text": " as the main data source for Humbrew.", "tokens": [50936, 382, 264, 2135, 1412, 4009, 337, 389, 2860, 2236, 13, 51092], "temperature": 0.0, "avg_logprob": -0.15856137099089446, "compression_ratio": 1.6436781609195403, "no_speech_prob": 0.008467729203402996}, {"id": 53, "seek": 16688, "start": 181.44, "end": 183.4, "text": " So when Humbrew was first created in 2009,", "tokens": [51092, 407, 562, 389, 2860, 2236, 390, 700, 2942, 294, 11453, 11, 51190], "temperature": 0.0, "avg_logprob": -0.15856137099089446, "compression_ratio": 1.6436781609195403, "no_speech_prob": 0.008467729203402996}, {"id": 54, "seek": 16688, "start": 183.4, "end": 187.84, "text": " one of the relatively innovative things it did was to use Git", "tokens": [51190, 472, 295, 264, 7226, 12999, 721, 309, 630, 390, 281, 764, 16939, 51412], "temperature": 0.0, "avg_logprob": -0.15856137099089446, "compression_ratio": 1.6436781609195403, "no_speech_prob": 0.008467729203402996}, {"id": 55, "seek": 16688, "start": 187.84, "end": 191.44, "text": " and put essentially all the data on a GitHub repo", "tokens": [51412, 293, 829, 4476, 439, 264, 1412, 322, 257, 23331, 49040, 51592], "temperature": 0.0, "avg_logprob": -0.15856137099089446, "compression_ratio": 1.6436781609195403, "no_speech_prob": 0.008467729203402996}, {"id": 56, "seek": 16688, "start": 191.44, "end": 195.4, "text": " and then instead of building some complex update information system", "tokens": [51592, 293, 550, 2602, 295, 2390, 512, 3997, 5623, 1589, 1185, 51790], "temperature": 0.0, "avg_logprob": -0.15856137099089446, "compression_ratio": 1.6436781609195403, "no_speech_prob": 0.008467729203402996}, {"id": 57, "seek": 19540, "start": 195.44, "end": 199.52, "text": " which is going to pull from some server somewhere that someone would have to host,", "tokens": [50366, 597, 307, 516, 281, 2235, 490, 512, 7154, 4079, 300, 1580, 576, 362, 281, 3975, 11, 50570], "temperature": 0.0, "avg_logprob": -0.1704057425506844, "compression_ratio": 1.713235294117647, "no_speech_prob": 0.0010903737274929881}, {"id": 58, "seek": 19540, "start": 199.52, "end": 204.08, "text": " it's like, no, we'll just do essentially just run Git fetch in the background.", "tokens": [50570, 309, 311, 411, 11, 572, 11, 321, 603, 445, 360, 4476, 445, 1190, 16939, 23673, 294, 264, 3678, 13, 50798], "temperature": 0.0, "avg_logprob": -0.1704057425506844, "compression_ratio": 1.713235294117647, "no_speech_prob": 0.0010903737274929881}, {"id": 59, "seek": 19540, "start": 204.08, "end": 209.88, "text": " And Humbrew has kind of had a long-going battle with...", "tokens": [50798, 400, 389, 2860, 2236, 575, 733, 295, 632, 257, 938, 12, 8102, 4635, 365, 485, 51088], "temperature": 0.0, "avg_logprob": -0.1704057425506844, "compression_ratio": 1.713235294117647, "no_speech_prob": 0.0010903737274929881}, {"id": 60, "seek": 19540, "start": 209.88, "end": 211.6, "text": " Like a little bit of a battle with GitHub", "tokens": [51088, 1743, 257, 707, 857, 295, 257, 4635, 365, 23331, 51174], "temperature": 0.0, "avg_logprob": -0.1704057425506844, "compression_ratio": 1.713235294117647, "no_speech_prob": 0.0010903737274929881}, {"id": 61, "seek": 19540, "start": 211.6, "end": 215.56, "text": " and more of a battle with the performance characteristics of this.", "tokens": [51174, 293, 544, 295, 257, 4635, 365, 264, 3389, 10891, 295, 341, 13, 51372], "temperature": 0.0, "avg_logprob": -0.1704057425506844, "compression_ratio": 1.713235294117647, "no_speech_prob": 0.0010903737274929881}, {"id": 62, "seek": 19540, "start": 215.56, "end": 219.32, "text": " So Humbrew Core, the main kind of Humbrew repository for all our formula,", "tokens": [51372, 407, 389, 2860, 2236, 14798, 11, 264, 2135, 733, 295, 389, 2860, 2236, 25841, 337, 439, 527, 8513, 11, 51560], "temperature": 0.0, "avg_logprob": -0.1704057425506844, "compression_ratio": 1.713235294117647, "no_speech_prob": 0.0010903737274929881}, {"id": 63, "seek": 19540, "start": 219.32, "end": 223.08, "text": " for all our packages, has kind of grown and grown over the years.", "tokens": [51560, 337, 439, 527, 17401, 11, 575, 733, 295, 7709, 293, 7709, 670, 264, 924, 13, 51748], "temperature": 0.0, "avg_logprob": -0.1704057425506844, "compression_ratio": 1.713235294117647, "no_speech_prob": 0.0010903737274929881}, {"id": 64, "seek": 22308, "start": 223.12, "end": 226.92000000000002, "text": " Like we've had over, I think, 11,000 contributors,", "tokens": [50366, 1743, 321, 600, 632, 670, 11, 286, 519, 11, 2975, 11, 1360, 45627, 11, 50556], "temperature": 0.0, "avg_logprob": -0.1395833174387614, "compression_ratio": 1.6807692307692308, "no_speech_prob": 0.022924330085515976}, {"id": 65, "seek": 22308, "start": 226.92000000000002, "end": 231.60000000000002, "text": " like millions of commits, hundreds of thousands of pull requests at this point.", "tokens": [50556, 411, 6803, 295, 48311, 11, 6779, 295, 5383, 295, 2235, 12475, 412, 341, 935, 13, 50790], "temperature": 0.0, "avg_logprob": -0.1395833174387614, "compression_ratio": 1.6807692307692308, "no_speech_prob": 0.022924330085515976}, {"id": 66, "seek": 22308, "start": 231.60000000000002, "end": 237.0, "text": " And as a result, it is very, very, very, very, very, very, very, very slow", "tokens": [50790, 400, 382, 257, 1874, 11, 309, 307, 588, 11, 588, 11, 588, 11, 588, 11, 588, 11, 588, 11, 588, 11, 588, 2964, 51060], "temperature": 0.0, "avg_logprob": -0.1395833174387614, "compression_ratio": 1.6807692307692308, "no_speech_prob": 0.022924330085515976}, {"id": 67, "seek": 22308, "start": 237.0, "end": 239.16000000000003, "text": " to do almost anything related to Git.", "tokens": [51060, 281, 360, 1920, 1340, 4077, 281, 16939, 13, 51168], "temperature": 0.0, "avg_logprob": -0.1395833174387614, "compression_ratio": 1.6807692307692308, "no_speech_prob": 0.022924330085515976}, {"id": 68, "seek": 22308, "start": 239.16000000000003, "end": 245.16000000000003, "text": " And particularly with Git fetch, like a no-op Git fetch was probably at its worst,", "tokens": [51168, 400, 4098, 365, 16939, 23673, 11, 411, 257, 572, 12, 404, 16939, 23673, 390, 1391, 412, 1080, 5855, 11, 51468], "temperature": 0.0, "avg_logprob": -0.1395833174387614, "compression_ratio": 1.6807692307692308, "no_speech_prob": 0.022924330085515976}, {"id": 69, "seek": 22308, "start": 245.16000000000003, "end": 247.52, "text": " taking about 30 seconds just to be like,", "tokens": [51468, 1940, 466, 2217, 3949, 445, 281, 312, 411, 11, 51586], "temperature": 0.0, "avg_logprob": -0.1395833174387614, "compression_ratio": 1.6807692307692308, "no_speech_prob": 0.022924330085515976}, {"id": 70, "seek": 22308, "start": 247.52, "end": 250.68, "text": " no, actually, you don't have any updates or anything required at all.", "tokens": [51586, 572, 11, 767, 11, 291, 500, 380, 362, 604, 9205, 420, 1340, 4739, 412, 439, 13, 51744], "temperature": 0.0, "avg_logprob": -0.1395833174387614, "compression_ratio": 1.6807692307692308, "no_speech_prob": 0.022924330085515976}, {"id": 71, "seek": 25068, "start": 250.68, "end": 254.6, "text": " So when I was lucky enough to be simultaneously working on Humbrew and GitHub,", "tokens": [50364, 407, 562, 286, 390, 6356, 1547, 281, 312, 16561, 1364, 322, 389, 2860, 2236, 293, 23331, 11, 50560], "temperature": 0.0, "avg_logprob": -0.162770464529399, "compression_ratio": 1.6696165191740413, "no_speech_prob": 0.0033502415753901005}, {"id": 72, "seek": 25068, "start": 254.6, "end": 259.56, "text": " I added a call to the GitHub API that was there specifically", "tokens": [50560, 286, 3869, 257, 818, 281, 264, 23331, 9362, 300, 390, 456, 4682, 50808], "temperature": 0.0, "avg_logprob": -0.162770464529399, "compression_ratio": 1.6696165191740413, "no_speech_prob": 0.0033502415753901005}, {"id": 73, "seek": 25068, "start": 259.56, "end": 261.8, "text": " to try and make Brut update a bit faster.", "tokens": [50808, 281, 853, 293, 652, 1603, 325, 5623, 257, 857, 4663, 13, 50920], "temperature": 0.0, "avg_logprob": -0.162770464529399, "compression_ratio": 1.6696165191740413, "no_speech_prob": 0.0033502415753901005}, {"id": 74, "seek": 25068, "start": 261.8, "end": 264.40000000000003, "text": " So you could go to the GitHub API and it could quickly respond like,", "tokens": [50920, 407, 291, 727, 352, 281, 264, 23331, 9362, 293, 309, 727, 2661, 4196, 411, 11, 51050], "temperature": 0.0, "avg_logprob": -0.162770464529399, "compression_ratio": 1.6696165191740413, "no_speech_prob": 0.0033502415753901005}, {"id": 75, "seek": 25068, "start": 264.40000000000003, "end": 267.68, "text": " hey, don't run Git fetch, you don't need to, it's going to be really slow,", "tokens": [51050, 4177, 11, 500, 380, 1190, 16939, 23673, 11, 291, 500, 380, 643, 281, 11, 309, 311, 516, 281, 312, 534, 2964, 11, 51214], "temperature": 0.0, "avg_logprob": -0.162770464529399, "compression_ratio": 1.6696165191740413, "no_speech_prob": 0.0033502415753901005}, {"id": 76, "seek": 25068, "start": 267.68, "end": 270.0, "text": " and you don't have any changes anyway.", "tokens": [51214, 293, 291, 500, 380, 362, 604, 2962, 4033, 13, 51330], "temperature": 0.0, "avg_logprob": -0.162770464529399, "compression_ratio": 1.6696165191740413, "no_speech_prob": 0.0033502415753901005}, {"id": 77, "seek": 25068, "start": 270.0, "end": 273.36, "text": " A few other package managers use that now as well, which makes me happy.", "tokens": [51330, 316, 1326, 661, 7372, 14084, 764, 300, 586, 382, 731, 11, 597, 1669, 385, 2055, 13, 51498], "temperature": 0.0, "avg_logprob": -0.162770464529399, "compression_ratio": 1.6696165191740413, "no_speech_prob": 0.0033502415753901005}, {"id": 78, "seek": 25068, "start": 273.36, "end": 276.48, "text": " But over the years, lots of people at GitHub have kind of grumbled", "tokens": [51498, 583, 670, 264, 924, 11, 3195, 295, 561, 412, 23331, 362, 733, 295, 677, 19928, 51654], "temperature": 0.0, "avg_logprob": -0.162770464529399, "compression_ratio": 1.6696165191740413, "no_speech_prob": 0.0033502415753901005}, {"id": 79, "seek": 25068, "start": 276.48, "end": 280.56, "text": " about using a Git repo as a CDN that's kind of nicely global.", "tokens": [51654, 466, 1228, 257, 16939, 49040, 382, 257, 6743, 45, 300, 311, 733, 295, 9594, 4338, 13, 51858], "temperature": 0.0, "avg_logprob": -0.162770464529399, "compression_ratio": 1.6696165191740413, "no_speech_prob": 0.0033502415753901005}, {"id": 80, "seek": 28056, "start": 281.32, "end": 283.96, "text": " Globally distributed, and I believe at our peak,", "tokens": [50402, 10786, 65, 379, 12631, 11, 293, 286, 1697, 412, 527, 10651, 11, 50534], "temperature": 0.0, "avg_logprob": -0.20908737182617188, "compression_ratio": 1.6474358974358974, "no_speech_prob": 0.0010447879321873188}, {"id": 81, "seek": 28056, "start": 283.96, "end": 287.88, "text": " we had a couple of GitHub servers that were essentially dedicated purely", "tokens": [50534, 321, 632, 257, 1916, 295, 23331, 15909, 300, 645, 4476, 8374, 17491, 50730], "temperature": 0.0, "avg_logprob": -0.20908737182617188, "compression_ratio": 1.6474358974358974, "no_speech_prob": 0.0010447879321873188}, {"id": 82, "seek": 28056, "start": 287.88, "end": 289.96, "text": " to people fetching from Humbrew Core.", "tokens": [50730, 281, 561, 23673, 278, 490, 389, 2860, 2236, 14798, 13, 50834], "temperature": 0.0, "avg_logprob": -0.20908737182617188, "compression_ratio": 1.6474358974358974, "no_speech_prob": 0.0010447879321873188}, {"id": 83, "seek": 28056, "start": 289.96, "end": 293.92, "text": " So eventually, after leaving the company, it's kind of weird that it took me", "tokens": [50834, 407, 4728, 11, 934, 5012, 264, 2237, 11, 309, 311, 733, 295, 3657, 300, 309, 1890, 385, 51032], "temperature": 0.0, "avg_logprob": -0.20908737182617188, "compression_ratio": 1.6474358974358974, "no_speech_prob": 0.0010447879321873188}, {"id": 84, "seek": 28056, "start": 293.92, "end": 296.84000000000003, "text": " to leave the company to actually make my coworker sloppy.", "tokens": [51032, 281, 1856, 264, 2237, 281, 767, 652, 452, 31998, 260, 43684, 13, 51178], "temperature": 0.0, "avg_logprob": -0.20908737182617188, "compression_ratio": 1.6474358974358974, "no_speech_prob": 0.0010447879321873188}, {"id": 85, "seek": 28056, "start": 296.84000000000003, "end": 300.72, "text": " We, like with a bunch of work from other maintainers,", "tokens": [51178, 492, 11, 411, 365, 257, 3840, 295, 589, 490, 661, 6909, 433, 11, 51372], "temperature": 0.0, "avg_logprob": -0.20908737182617188, "compression_ratio": 1.6474358974358974, "no_speech_prob": 0.0010447879321873188}, {"id": 86, "seek": 28056, "start": 300.72, "end": 304.92, "text": " we kind of moved over to essentially just curling a JSON file off the internet now.", "tokens": [51372, 321, 733, 295, 4259, 670, 281, 4476, 445, 45085, 257, 31828, 3991, 766, 264, 4705, 586, 13, 51582], "temperature": 0.0, "avg_logprob": -0.20908737182617188, "compression_ratio": 1.6474358974358974, "no_speech_prob": 0.0010447879321873188}, {"id": 87, "seek": 28056, "start": 304.92, "end": 310.28, "text": " So instead, we have like a 15 meg-ish, I think, compressed file for Humbrew Core,", "tokens": [51582, 407, 2602, 11, 321, 362, 411, 257, 2119, 10816, 12, 742, 11, 286, 519, 11, 30353, 3991, 337, 389, 2860, 2236, 14798, 11, 51850], "temperature": 0.0, "avg_logprob": -0.20908737182617188, "compression_ratio": 1.6474358974358974, "no_speech_prob": 0.0010447879321873188}, {"id": 88, "seek": 31028, "start": 310.28, "end": 311.47999999999996, "text": " for Humbrew Cask.", "tokens": [50364, 337, 389, 2860, 2236, 383, 3863, 13, 50424], "temperature": 0.0, "avg_logprob": -0.15864042043685914, "compression_ratio": 1.6704545454545454, "no_speech_prob": 0.001216333475895226}, {"id": 89, "seek": 31028, "start": 311.47999999999996, "end": 314.47999999999996, "text": " When there's an update, we don't have any sort of clever binary diffing", "tokens": [50424, 1133, 456, 311, 364, 5623, 11, 321, 500, 380, 362, 604, 1333, 295, 13494, 17434, 7593, 278, 50574], "temperature": 0.0, "avg_logprob": -0.15864042043685914, "compression_ratio": 1.6704545454545454, "no_speech_prob": 0.001216333475895226}, {"id": 90, "seek": 31028, "start": 314.47999999999996, "end": 317.08, "text": " or anything, unfortunately, so we just download the whole thing again.", "tokens": [50574, 420, 1340, 11, 7015, 11, 370, 321, 445, 5484, 264, 1379, 551, 797, 13, 50704], "temperature": 0.0, "avg_logprob": -0.15864042043685914, "compression_ratio": 1.6704545454545454, "no_speech_prob": 0.001216333475895226}, {"id": 91, "seek": 31028, "start": 317.08, "end": 320.67999999999995, "text": " But that seems to be a lot faster for most of the people, most of the time.", "tokens": [50704, 583, 300, 2544, 281, 312, 257, 688, 4663, 337, 881, 295, 264, 561, 11, 881, 295, 264, 565, 13, 50884], "temperature": 0.0, "avg_logprob": -0.15864042043685914, "compression_ratio": 1.6704545454545454, "no_speech_prob": 0.001216333475895226}, {"id": 92, "seek": 31028, "start": 320.67999999999995, "end": 324.84, "text": " And we still, optimistically, will be able to make it faster in future.", "tokens": [50884, 400, 321, 920, 11, 5028, 20458, 11, 486, 312, 1075, 281, 652, 309, 4663, 294, 2027, 13, 51092], "temperature": 0.0, "avg_logprob": -0.15864042043685914, "compression_ratio": 1.6704545454545454, "no_speech_prob": 0.001216333475895226}, {"id": 93, "seek": 31028, "start": 324.84, "end": 328.08, "text": " So in case you didn't know, Humbrew has like a JSON API.", "tokens": [51092, 407, 294, 1389, 291, 994, 380, 458, 11, 389, 2860, 2236, 575, 411, 257, 31828, 9362, 13, 51254], "temperature": 0.0, "avg_logprob": -0.15864042043685914, "compression_ratio": 1.6704545454545454, "no_speech_prob": 0.001216333475895226}, {"id": 94, "seek": 31028, "start": 328.08, "end": 332.0, "text": " This is basically the kind of the basis of what we're using.", "tokens": [51254, 639, 307, 1936, 264, 733, 295, 264, 5143, 295, 437, 321, 434, 1228, 13, 51450], "temperature": 0.0, "avg_logprob": -0.15864042043685914, "compression_ratio": 1.6704545454545454, "no_speech_prob": 0.001216333475895226}, {"id": 95, "seek": 31028, "start": 332.0, "end": 335.0, "text": " We've had to kind of add some bits and pieces and modify, move things around.", "tokens": [51450, 492, 600, 632, 281, 733, 295, 909, 512, 9239, 293, 3755, 293, 16927, 11, 1286, 721, 926, 13, 51600], "temperature": 0.0, "avg_logprob": -0.15864042043685914, "compression_ratio": 1.6704545454545454, "no_speech_prob": 0.001216333475895226}, {"id": 96, "seek": 31028, "start": 335.0, "end": 339.4, "text": " And one of our maintainers here added like nice signing to this and stuff like that", "tokens": [51600, 400, 472, 295, 527, 6909, 433, 510, 3869, 411, 1481, 13393, 281, 341, 293, 1507, 411, 300, 51820], "temperature": 0.0, "avg_logprob": -0.15864042043685914, "compression_ratio": 1.6704545454545454, "no_speech_prob": 0.001216333475895226}, {"id": 97, "seek": 33940, "start": 339.4, "end": 342.0, "text": " so that we could meet the kind of security requirements,", "tokens": [50364, 370, 300, 321, 727, 1677, 264, 733, 295, 3825, 7728, 11, 50494], "temperature": 0.0, "avg_logprob": -0.14859046936035156, "compression_ratio": 1.6407407407407408, "no_speech_prob": 0.003605116391554475}, {"id": 98, "seek": 33940, "start": 342.0, "end": 346.4, "text": " the performance requirements we wanted for this new API way of downloading.", "tokens": [50494, 264, 3389, 7728, 321, 1415, 337, 341, 777, 9362, 636, 295, 32529, 13, 50714], "temperature": 0.0, "avg_logprob": -0.14859046936035156, "compression_ratio": 1.6407407407407408, "no_speech_prob": 0.003605116391554475}, {"id": 99, "seek": 33940, "start": 346.4, "end": 351.88, "text": " It's actually, our API is really, really fast because it's posted on GitHub pages.", "tokens": [50714, 467, 311, 767, 11, 527, 9362, 307, 534, 11, 534, 2370, 570, 309, 311, 9437, 322, 23331, 7183, 13, 50988], "temperature": 0.0, "avg_logprob": -0.14859046936035156, "compression_ratio": 1.6407407407407408, "no_speech_prob": 0.003605116391554475}, {"id": 100, "seek": 33940, "start": 351.88, "end": 356.91999999999996, "text": " So if you've had an idea of like statically building your API,", "tokens": [50988, 407, 498, 291, 600, 632, 364, 1558, 295, 411, 2219, 984, 2390, 428, 9362, 11, 51240], "temperature": 0.0, "avg_logprob": -0.14859046936035156, "compression_ratio": 1.6407407407407408, "no_speech_prob": 0.003605116391554475}, {"id": 101, "seek": 33940, "start": 356.91999999999996, "end": 360.2, "text": " it's incredibly painful in some respects, but also kind of fun in other ways.", "tokens": [51240, 309, 311, 6252, 11697, 294, 512, 24126, 11, 457, 611, 733, 295, 1019, 294, 661, 2098, 13, 51404], "temperature": 0.0, "avg_logprob": -0.14859046936035156, "compression_ratio": 1.6407407407407408, "no_speech_prob": 0.003605116391554475}, {"id": 102, "seek": 33940, "start": 360.2, "end": 363.56, "text": " But yeah, don't dig too deep on how that's implemented", "tokens": [51404, 583, 1338, 11, 500, 380, 2528, 886, 2452, 322, 577, 300, 311, 12270, 51572], "temperature": 0.0, "avg_logprob": -0.14859046936035156, "compression_ratio": 1.6407407407407408, "no_speech_prob": 0.003605116391554475}, {"id": 103, "seek": 33940, "start": 363.56, "end": 367.79999999999995, "text": " because it's pretty disgusting.", "tokens": [51572, 570, 309, 311, 1238, 17552, 13, 51784], "temperature": 0.0, "avg_logprob": -0.14859046936035156, "compression_ratio": 1.6407407407407408, "no_speech_prob": 0.003605116391554475}, {"id": 104, "seek": 36780, "start": 367.8, "end": 372.52000000000004, "text": " Another thing, somewhat relatedly, if you have set any of these variables in the past,", "tokens": [50364, 3996, 551, 11, 8344, 4077, 356, 11, 498, 291, 362, 992, 604, 295, 613, 9102, 294, 264, 1791, 11, 50600], "temperature": 0.0, "avg_logprob": -0.17468649442078638, "compression_ratio": 1.7608695652173914, "no_speech_prob": 0.0185671616345644}, {"id": 105, "seek": 36780, "start": 372.52000000000004, "end": 379.40000000000003, "text": " like commonly people will set these things because Humbrew was updating too often", "tokens": [50600, 411, 12719, 561, 486, 992, 613, 721, 570, 389, 2860, 2236, 390, 25113, 886, 2049, 50944], "temperature": 0.0, "avg_logprob": -0.17468649442078638, "compression_ratio": 1.7608695652173914, "no_speech_prob": 0.0185671616345644}, {"id": 106, "seek": 36780, "start": 379.40000000000003, "end": 380.92, "text": " and it was too slow and annoyed them,", "tokens": [50944, 293, 309, 390, 886, 2964, 293, 25921, 552, 11, 51020], "temperature": 0.0, "avg_logprob": -0.17468649442078638, "compression_ratio": 1.7608695652173914, "no_speech_prob": 0.0185671616345644}, {"id": 107, "seek": 36780, "start": 380.92, "end": 384.68, "text": " or shortly after we rolled out the API stuff, a bunch of people opted out", "tokens": [51020, 420, 13392, 934, 321, 14306, 484, 264, 9362, 1507, 11, 257, 3840, 295, 561, 40768, 484, 51208], "temperature": 0.0, "avg_logprob": -0.17468649442078638, "compression_ratio": 1.7608695652173914, "no_speech_prob": 0.0185671616345644}, {"id": 108, "seek": 36780, "start": 384.68, "end": 386.68, "text": " because it was a little bit buggy and stuff like that,", "tokens": [51208, 570, 309, 390, 257, 707, 857, 7426, 1480, 293, 1507, 411, 300, 11, 51308], "temperature": 0.0, "avg_logprob": -0.17468649442078638, "compression_ratio": 1.7608695652173914, "no_speech_prob": 0.0185671616345644}, {"id": 109, "seek": 36780, "start": 386.68, "end": 392.0, "text": " or it also updates too often considering un-setting them for a little bit.", "tokens": [51308, 420, 309, 611, 9205, 886, 2049, 8079, 517, 12, 3854, 783, 552, 337, 257, 707, 857, 13, 51574], "temperature": 0.0, "avg_logprob": -0.17468649442078638, "compression_ratio": 1.7608695652173914, "no_speech_prob": 0.0185671616345644}, {"id": 110, "seek": 36780, "start": 392.0, "end": 395.6, "text": " And then if things are still annoying for you, feel free to set them again,", "tokens": [51574, 400, 550, 498, 721, 366, 920, 11304, 337, 291, 11, 841, 1737, 281, 992, 552, 797, 11, 51754], "temperature": 0.0, "avg_logprob": -0.17468649442078638, "compression_ratio": 1.7608695652173914, "no_speech_prob": 0.0185671616345644}, {"id": 111, "seek": 39560, "start": 395.6, "end": 399.32000000000005, "text": " but you might have a better time without these than you used to.", "tokens": [50364, 457, 291, 1062, 362, 257, 1101, 565, 1553, 613, 813, 291, 1143, 281, 13, 50550], "temperature": 0.0, "avg_logprob": -0.18128884805215373, "compression_ratio": 1.641304347826087, "no_speech_prob": 0.01593979261815548}, {"id": 112, "seek": 39560, "start": 399.32000000000005, "end": 403.64000000000004, "text": " Similarly, if you still have these reports on your disk, you can now un-tap them", "tokens": [50550, 13157, 11, 498, 291, 920, 362, 613, 7122, 322, 428, 12355, 11, 291, 393, 586, 517, 12, 83, 569, 552, 50766], "temperature": 0.0, "avg_logprob": -0.18128884805215373, "compression_ratio": 1.641304347826087, "no_speech_prob": 0.01593979261815548}, {"id": 113, "seek": 39560, "start": 403.64000000000004, "end": 405.88, "text": " and then you will get much more space back", "tokens": [50766, 293, 550, 291, 486, 483, 709, 544, 1901, 646, 50878], "temperature": 0.0, "avg_logprob": -0.18128884805215373, "compression_ratio": 1.641304347826087, "no_speech_prob": 0.01593979261815548}, {"id": 114, "seek": 39560, "start": 405.88, "end": 410.88, "text": " and just generally your updating could be potentially a little bit faster", "tokens": [50878, 293, 445, 5101, 428, 25113, 727, 312, 7263, 257, 707, 857, 4663, 51128], "temperature": 0.0, "avg_logprob": -0.18128884805215373, "compression_ratio": 1.641304347826087, "no_speech_prob": 0.01593979261815548}, {"id": 115, "seek": 39560, "start": 410.88, "end": 413.6, "text": " and happier and all this type of stuff.", "tokens": [51128, 293, 20423, 293, 439, 341, 2010, 295, 1507, 13, 51264], "temperature": 0.0, "avg_logprob": -0.18128884805215373, "compression_ratio": 1.641304347826087, "no_speech_prob": 0.01593979261815548}, {"id": 116, "seek": 39560, "start": 413.6, "end": 416.04, "text": " The other relatively big thing we did in the last year,", "tokens": [51264, 440, 661, 7226, 955, 551, 321, 630, 294, 264, 1036, 1064, 11, 51386], "temperature": 0.0, "avg_logprob": -0.18128884805215373, "compression_ratio": 1.641304347826087, "no_speech_prob": 0.01593979261815548}, {"id": 117, "seek": 39560, "start": 416.04, "end": 422.28000000000003, "text": " not super exciting for everyone, but our analytics were hosted by Google for a very long time.", "tokens": [51386, 406, 1687, 4670, 337, 1518, 11, 457, 527, 15370, 645, 19204, 538, 3329, 337, 257, 588, 938, 565, 13, 51698], "temperature": 0.0, "avg_logprob": -0.18128884805215373, "compression_ratio": 1.641304347826087, "no_speech_prob": 0.01593979261815548}, {"id": 118, "seek": 42228, "start": 422.32, "end": 425.96, "text": " We had a lot of people who didn't like us having analytics at all", "tokens": [50366, 492, 632, 257, 688, 295, 561, 567, 994, 380, 411, 505, 1419, 15370, 412, 439, 50548], "temperature": 0.0, "avg_logprob": -0.1312985692705427, "compression_ratio": 1.7679738562091503, "no_speech_prob": 0.07849304378032684}, {"id": 119, "seek": 42228, "start": 425.96, "end": 431.15999999999997, "text": " and I chose to ignore those people because we need them to be able to do our job, unfortunately.", "tokens": [50548, 293, 286, 5111, 281, 11200, 729, 561, 570, 321, 643, 552, 281, 312, 1075, 281, 360, 527, 1691, 11, 7015, 13, 50808], "temperature": 0.0, "avg_logprob": -0.1312985692705427, "compression_ratio": 1.7679738562091503, "no_speech_prob": 0.07849304378032684}, {"id": 120, "seek": 42228, "start": 431.15999999999997, "end": 435.15999999999997, "text": " But I guess a concern we did hear again and again from people was like,", "tokens": [50808, 583, 286, 2041, 257, 3136, 321, 630, 1568, 797, 293, 797, 490, 561, 390, 411, 11, 51008], "temperature": 0.0, "avg_logprob": -0.1312985692705427, "compression_ratio": 1.7679738562091503, "no_speech_prob": 0.07849304378032684}, {"id": 121, "seek": 42228, "start": 435.15999999999997, "end": 436.76, "text": " hey, we don't mind you having analytics,", "tokens": [51008, 4177, 11, 321, 500, 380, 1575, 291, 1419, 15370, 11, 51088], "temperature": 0.0, "avg_logprob": -0.1312985692705427, "compression_ratio": 1.7679738562091503, "no_speech_prob": 0.07849304378032684}, {"id": 122, "seek": 42228, "start": 436.76, "end": 439.67999999999995, "text": " but we're a bit concerned with all this data going to Google", "tokens": [51088, 457, 321, 434, 257, 857, 5922, 365, 439, 341, 1412, 516, 281, 3329, 51234], "temperature": 0.0, "avg_logprob": -0.1312985692705427, "compression_ratio": 1.7679738562091503, "no_speech_prob": 0.07849304378032684}, {"id": 123, "seek": 42228, "start": 439.67999999999995, "end": 444.11999999999995, "text": " and if you look at the analytics docs, you can opt out of certain data collection,", "tokens": [51234, 293, 498, 291, 574, 412, 264, 15370, 45623, 11, 291, 393, 2427, 484, 295, 1629, 1412, 5765, 11, 51456], "temperature": 0.0, "avg_logprob": -0.1312985692705427, "compression_ratio": 1.7679738562091503, "no_speech_prob": 0.07849304378032684}, {"id": 124, "seek": 42228, "start": 444.11999999999995, "end": 447.84, "text": " but that's kind of a line on trusting Google to do what they say,", "tokens": [51456, 457, 300, 311, 733, 295, 257, 1622, 322, 28235, 3329, 281, 360, 437, 436, 584, 11, 51642], "temperature": 0.0, "avg_logprob": -0.1312985692705427, "compression_ratio": 1.7679738562091503, "no_speech_prob": 0.07849304378032684}, {"id": 125, "seek": 42228, "start": 447.84, "end": 451.23999999999995, "text": " which I kind of do, but I understand not everyone does.", "tokens": [51642, 597, 286, 733, 295, 360, 11, 457, 286, 1223, 406, 1518, 775, 13, 51812], "temperature": 0.0, "avg_logprob": -0.1312985692705427, "compression_ratio": 1.7679738562091503, "no_speech_prob": 0.07849304378032684}, {"id": 126, "seek": 45124, "start": 451.28000000000003, "end": 460.2, "text": " So we've kind of now moved to kind of a nice cloud-hosted like EU instance of inflex DB,", "tokens": [50366, 407, 321, 600, 733, 295, 586, 4259, 281, 733, 295, 257, 1481, 4588, 12, 6037, 292, 411, 10887, 5197, 295, 1536, 2021, 26754, 11, 50812], "temperature": 0.0, "avg_logprob": -0.14489830562046596, "compression_ratio": 1.5954198473282444, "no_speech_prob": 0.0007729995995759964}, {"id": 127, "seek": 45124, "start": 460.2, "end": 463.56, "text": " which means that we're gathering essentially the same data we had before,", "tokens": [50812, 597, 1355, 300, 321, 434, 13519, 4476, 264, 912, 1412, 321, 632, 949, 11, 50980], "temperature": 0.0, "avg_logprob": -0.14489830562046596, "compression_ratio": 1.5954198473282444, "no_speech_prob": 0.0007729995995759964}, {"id": 128, "seek": 45124, "start": 463.56, "end": 465.96000000000004, "text": " but we're not kind of tying it to individual users.", "tokens": [50980, 457, 321, 434, 406, 733, 295, 32405, 309, 281, 2609, 5022, 13, 51100], "temperature": 0.0, "avg_logprob": -0.14489830562046596, "compression_ratio": 1.5954198473282444, "no_speech_prob": 0.0007729995995759964}, {"id": 129, "seek": 45124, "start": 465.96000000000004, "end": 470.12, "text": " We don't have the ability to kind of do stuff like capture IP addresses even if we wanted to", "tokens": [51100, 492, 500, 380, 362, 264, 3485, 281, 733, 295, 360, 1507, 411, 7983, 8671, 16862, 754, 498, 321, 1415, 281, 51308], "temperature": 0.0, "avg_logprob": -0.14489830562046596, "compression_ratio": 1.5954198473282444, "no_speech_prob": 0.0007729995995759964}, {"id": 130, "seek": 45124, "start": 470.12, "end": 472.44, "text": " and that makes everything a little bit nicer.", "tokens": [51308, 293, 300, 1669, 1203, 257, 707, 857, 22842, 13, 51424], "temperature": 0.0, "avg_logprob": -0.14489830562046596, "compression_ratio": 1.5954198473282444, "no_speech_prob": 0.0007729995995759964}, {"id": 131, "seek": 45124, "start": 472.44, "end": 476.6, "text": " So we've now destroyed all of our existing Google Analytics data", "tokens": [51424, 407, 321, 600, 586, 8937, 439, 295, 527, 6741, 3329, 25944, 1412, 51632], "temperature": 0.0, "avg_logprob": -0.14489830562046596, "compression_ratio": 1.5954198473282444, "no_speech_prob": 0.0007729995995759964}, {"id": 132, "seek": 47660, "start": 476.6, "end": 480.8, "text": " and this means that if you want to know what Hummoo was doing", "tokens": [50364, 293, 341, 1355, 300, 498, 291, 528, 281, 458, 437, 12877, 76, 1986, 390, 884, 50574], "temperature": 0.0, "avg_logprob": -0.18683153554933882, "compression_ratio": 1.6139705882352942, "no_speech_prob": 0.0007806500070728362}, {"id": 133, "seek": 47660, "start": 480.8, "end": 485.12, "text": " or what user accounts were like two years ago, tough luck,", "tokens": [50574, 420, 437, 4195, 9402, 645, 411, 732, 924, 2057, 11, 4930, 3668, 11, 50790], "temperature": 0.0, "avg_logprob": -0.18683153554933882, "compression_ratio": 1.6139705882352942, "no_speech_prob": 0.0007806500070728362}, {"id": 134, "seek": 47660, "start": 485.12, "end": 487.64000000000004, "text": " but we do have this new analytics system", "tokens": [50790, 457, 321, 360, 362, 341, 777, 15370, 1185, 50916], "temperature": 0.0, "avg_logprob": -0.18683153554933882, "compression_ratio": 1.6139705882352942, "no_speech_prob": 0.0007806500070728362}, {"id": 135, "seek": 47660, "start": 487.64000000000004, "end": 491.20000000000005, "text": " automatically kind of deletes data after 365 days,", "tokens": [50916, 6772, 733, 295, 1103, 37996, 1412, 934, 22046, 1708, 11, 51094], "temperature": 0.0, "avg_logprob": -0.18683153554933882, "compression_ratio": 1.6139705882352942, "no_speech_prob": 0.0007806500070728362}, {"id": 136, "seek": 47660, "start": 491.20000000000005, "end": 496.04, "text": " so this should get us a nicer, slightly more privacy-focused approach in future.", "tokens": [51094, 370, 341, 820, 483, 505, 257, 22842, 11, 4748, 544, 11427, 12, 44062, 3109, 294, 2027, 13, 51336], "temperature": 0.0, "avg_logprob": -0.18683153554933882, "compression_ratio": 1.6139705882352942, "no_speech_prob": 0.0007806500070728362}, {"id": 137, "seek": 47660, "start": 496.04, "end": 500.64000000000004, "text": " And the other thing that has been kind of principal with our analytics is trying to have it.", "tokens": [51336, 400, 264, 661, 551, 300, 575, 668, 733, 295, 9716, 365, 527, 15370, 307, 1382, 281, 362, 309, 13, 51566], "temperature": 0.0, "avg_logprob": -0.18683153554933882, "compression_ratio": 1.6139705882352942, "no_speech_prob": 0.0007806500070728362}, {"id": 138, "seek": 47660, "start": 500.64000000000004, "end": 504.44, "text": " So if people may not trust us with Gather Analytics,", "tokens": [51566, 407, 498, 561, 815, 406, 3361, 505, 365, 39841, 25944, 11, 51756], "temperature": 0.0, "avg_logprob": -0.18683153554933882, "compression_ratio": 1.6139705882352942, "no_speech_prob": 0.0007806500070728362}, {"id": 139, "seek": 50444, "start": 504.48, "end": 508.84, "text": " I understand that like it's a touchy point in the tech industry with privacy and all this stuff nowadays,", "tokens": [50366, 286, 1223, 300, 411, 309, 311, 257, 2557, 88, 935, 294, 264, 7553, 3518, 365, 11427, 293, 439, 341, 1507, 13434, 11, 50584], "temperature": 0.0, "avg_logprob": -0.18248060014512804, "compression_ratio": 1.7687074829931972, "no_speech_prob": 0.07029592245817184}, {"id": 140, "seek": 50444, "start": 508.84, "end": 511.28, "text": " but we do try and make all the information we gather public,", "tokens": [50584, 457, 321, 360, 853, 293, 652, 439, 264, 1589, 321, 5448, 1908, 11, 50706], "temperature": 0.0, "avg_logprob": -0.18248060014512804, "compression_ratio": 1.7687074829931972, "no_speech_prob": 0.07029592245817184}, {"id": 141, "seek": 50444, "start": 511.28, "end": 516.08, "text": " so we've got these pages like under formula brudo sh slash analytics,", "tokens": [50706, 370, 321, 600, 658, 613, 7183, 411, 833, 8513, 738, 6207, 402, 17330, 15370, 11, 50946], "temperature": 0.0, "avg_logprob": -0.18248060014512804, "compression_ratio": 1.7687074829931972, "no_speech_prob": 0.07029592245817184}, {"id": 142, "seek": 50444, "start": 516.08, "end": 517.96, "text": " various pages of the analytics we gather.", "tokens": [50946, 3683, 7183, 295, 264, 15370, 321, 5448, 13, 51040], "temperature": 0.0, "avg_logprob": -0.18248060014512804, "compression_ratio": 1.7687074829931972, "no_speech_prob": 0.07029592245817184}, {"id": 143, "seek": 50444, "start": 517.96, "end": 520.56, "text": " We've got a few more things there than we used to be able to have", "tokens": [51040, 492, 600, 658, 257, 1326, 544, 721, 456, 813, 321, 1143, 281, 312, 1075, 281, 362, 51170], "temperature": 0.0, "avg_logprob": -0.18248060014512804, "compression_ratio": 1.7687074829931972, "no_speech_prob": 0.07029592245817184}, {"id": 144, "seek": 50444, "start": 520.56, "end": 525.28, "text": " and you can kind of see the download counts, percentage counts, all this type of stuff.", "tokens": [51170, 293, 291, 393, 733, 295, 536, 264, 5484, 14893, 11, 9668, 14893, 11, 439, 341, 2010, 295, 1507, 13, 51406], "temperature": 0.0, "avg_logprob": -0.18248060014512804, "compression_ratio": 1.7687074829931972, "no_speech_prob": 0.07029592245817184}, {"id": 145, "seek": 50444, "start": 525.28, "end": 529.48, "text": " And basically maintainers don't have access really to any more information than you do.", "tokens": [51406, 400, 1936, 6909, 433, 500, 380, 362, 2105, 534, 281, 604, 544, 1589, 813, 291, 360, 13, 51616], "temperature": 0.0, "avg_logprob": -0.18248060014512804, "compression_ratio": 1.7687074829931972, "no_speech_prob": 0.07029592245817184}, {"id": 146, "seek": 52948, "start": 529.52, "end": 534.6800000000001, "text": " Like we have a couple, a handful of people can access our InfluxDB console directly,", "tokens": [50366, 1743, 321, 362, 257, 1916, 11, 257, 16458, 295, 561, 393, 2105, 527, 682, 3423, 2449, 27735, 11076, 3838, 11, 50624], "temperature": 0.0, "avg_logprob": -0.17508222925381398, "compression_ratio": 1.6702127659574468, "no_speech_prob": 0.007167713716626167}, {"id": 147, "seek": 52948, "start": 534.6800000000001, "end": 538.5600000000001, "text": " but like the data in there is in such a kind of messy, horrible format", "tokens": [50624, 457, 411, 264, 1412, 294, 456, 307, 294, 1270, 257, 733, 295, 16191, 11, 9263, 7877, 50818], "temperature": 0.0, "avg_logprob": -0.17508222925381398, "compression_ratio": 1.6702127659574468, "no_speech_prob": 0.007167713716626167}, {"id": 148, "seek": 52948, "start": 538.5600000000001, "end": 540.12, "text": " that no one is querying that directly.", "tokens": [50818, 300, 572, 472, 307, 7083, 1840, 300, 3838, 13, 50896], "temperature": 0.0, "avg_logprob": -0.17508222925381398, "compression_ratio": 1.6702127659574468, "no_speech_prob": 0.007167713716626167}, {"id": 149, "seek": 52948, "start": 540.12, "end": 544.04, "text": " They're all just using the same web pages as you and I might use,", "tokens": [50896, 814, 434, 439, 445, 1228, 264, 912, 3670, 7183, 382, 291, 293, 286, 1062, 764, 11, 51092], "temperature": 0.0, "avg_logprob": -0.17508222925381398, "compression_ratio": 1.6702127659574468, "no_speech_prob": 0.007167713716626167}, {"id": 150, "seek": 52948, "start": 544.04, "end": 546.4, "text": " which feels like again, from a privacy perspective,", "tokens": [51092, 597, 3417, 411, 797, 11, 490, 257, 11427, 4585, 11, 51210], "temperature": 0.0, "avg_logprob": -0.17508222925381398, "compression_ratio": 1.6702127659574468, "no_speech_prob": 0.007167713716626167}, {"id": 151, "seek": 52948, "start": 546.4, "end": 550.76, "text": " we're all kind of on the same page, whether you're a user of Hummoo or people maintaining it.", "tokens": [51210, 321, 434, 439, 733, 295, 322, 264, 912, 3028, 11, 1968, 291, 434, 257, 4195, 295, 12877, 76, 1986, 420, 561, 14916, 309, 13, 51428], "temperature": 0.0, "avg_logprob": -0.17508222925381398, "compression_ratio": 1.6702127659574468, "no_speech_prob": 0.007167713716626167}, {"id": 152, "seek": 52948, "start": 550.76, "end": 556.9200000000001, "text": " So also, again, another thing to stick your hand in the air for,", "tokens": [51428, 407, 611, 11, 797, 11, 1071, 551, 281, 2897, 428, 1011, 294, 264, 1988, 337, 11, 51736], "temperature": 0.0, "avg_logprob": -0.17508222925381398, "compression_ratio": 1.6702127659574468, "no_speech_prob": 0.007167713716626167}, {"id": 153, "seek": 55692, "start": 556.9599999999999, "end": 559.36, "text": " who considers Hummoo to be slow?", "tokens": [50366, 567, 33095, 12877, 76, 1986, 281, 312, 2964, 30, 50486], "temperature": 0.0, "avg_logprob": -0.29323392493702544, "compression_ratio": 1.5358649789029535, "no_speech_prob": 0.0031957533210515976}, {"id": 154, "seek": 55692, "start": 561.16, "end": 562.52, "text": " Yeah, a few people.", "tokens": [50576, 865, 11, 257, 1326, 561, 13, 50644], "temperature": 0.0, "avg_logprob": -0.29323392493702544, "compression_ratio": 1.5358649789029535, "no_speech_prob": 0.0031957533210515976}, {"id": 155, "seek": 55692, "start": 563.8399999999999, "end": 567.12, "text": " Put your hand in the air if you feel like it got faster in the last year.", "tokens": [50710, 4935, 428, 1011, 294, 264, 1988, 498, 291, 841, 411, 309, 658, 4663, 294, 264, 1036, 1064, 13, 50874], "temperature": 0.0, "avg_logprob": -0.29323392493702544, "compression_ratio": 1.5358649789029535, "no_speech_prob": 0.0031957533210515976}, {"id": 156, "seek": 55692, "start": 568.52, "end": 571.52, "text": " Mostly just maintainers who made it faster, so...", "tokens": [50944, 29035, 445, 6909, 433, 567, 1027, 309, 4663, 11, 370, 485, 51094], "temperature": 0.0, "avg_logprob": -0.29323392493702544, "compression_ratio": 1.5358649789029535, "no_speech_prob": 0.0031957533210515976}, {"id": 157, "seek": 55692, "start": 572.52, "end": 574.52, "text": " It's all right, you still count iValue.", "tokens": [51144, 467, 311, 439, 558, 11, 291, 920, 1207, 741, 53, 304, 622, 13, 51244], "temperature": 0.0, "avg_logprob": -0.29323392493702544, "compression_ratio": 1.5358649789029535, "no_speech_prob": 0.0031957533210515976}, {"id": 158, "seek": 55692, "start": 575.52, "end": 578.92, "text": " So this is a relatively common critique we hear about Hummoo,", "tokens": [51294, 407, 341, 307, 257, 7226, 2689, 25673, 321, 1568, 466, 12877, 76, 1986, 11, 51464], "temperature": 0.0, "avg_logprob": -0.29323392493702544, "compression_ratio": 1.5358649789029535, "no_speech_prob": 0.0031957533210515976}, {"id": 159, "seek": 55692, "start": 578.92, "end": 585.4, "text": " is it's slow or why does it upgrade all my things all the times and things like that.", "tokens": [51464, 307, 309, 311, 2964, 420, 983, 775, 309, 11484, 439, 452, 721, 439, 264, 1413, 293, 721, 411, 300, 13, 51788], "temperature": 0.0, "avg_logprob": -0.29323392493702544, "compression_ratio": 1.5358649789029535, "no_speech_prob": 0.0031957533210515976}, {"id": 160, "seek": 58540, "start": 585.4, "end": 592.0799999999999, "text": " So we are working on this, this is kind of a background, medium priority thing", "tokens": [50364, 407, 321, 366, 1364, 322, 341, 11, 341, 307, 733, 295, 257, 3678, 11, 6399, 9365, 551, 50698], "temperature": 0.0, "avg_logprob": -0.20364403925022156, "compression_ratio": 1.6323529411764706, "no_speech_prob": 0.0005121482536196709}, {"id": 161, "seek": 58540, "start": 592.0799999999999, "end": 594.6, "text": " for us that we kind of considered for quite a while.", "tokens": [50698, 337, 505, 300, 321, 733, 295, 4888, 337, 1596, 257, 1339, 13, 50824], "temperature": 0.0, "avg_logprob": -0.20364403925022156, "compression_ratio": 1.6323529411764706, "no_speech_prob": 0.0005121482536196709}, {"id": 162, "seek": 58540, "start": 594.6, "end": 596.68, "text": " So in the last year, hopefully,", "tokens": [50824, 407, 294, 264, 1036, 1064, 11, 4696, 11, 50928], "temperature": 0.0, "avg_logprob": -0.20364403925022156, "compression_ratio": 1.6323529411764706, "no_speech_prob": 0.0005121482536196709}, {"id": 163, "seek": 58540, "start": 596.68, "end": 602.16, "text": " brew update, that's mainly got faster from the API stuff we mentioned before.", "tokens": [50928, 34619, 5623, 11, 300, 311, 8704, 658, 4663, 490, 264, 9362, 1507, 321, 2835, 949, 13, 51202], "temperature": 0.0, "avg_logprob": -0.20364403925022156, "compression_ratio": 1.6323529411764706, "no_speech_prob": 0.0005121482536196709}, {"id": 164, "seek": 58540, "start": 602.16, "end": 606.1999999999999, "text": " Hopefully brew upgrades, we've now made it a lot,", "tokens": [51202, 10429, 34619, 24868, 11, 321, 600, 586, 1027, 309, 257, 688, 11, 51404], "temperature": 0.0, "avg_logprob": -0.20364403925022156, "compression_ratio": 1.6323529411764706, "no_speech_prob": 0.0005121482536196709}, {"id": 165, "seek": 58540, "start": 606.1999999999999, "end": 609.0799999999999, "text": " in certain cases at least, we can now upgrade", "tokens": [51404, 294, 1629, 3331, 412, 1935, 11, 321, 393, 586, 11484, 51548], "temperature": 0.0, "avg_logprob": -0.20364403925022156, "compression_ratio": 1.6323529411764706, "no_speech_prob": 0.0005121482536196709}, {"id": 166, "seek": 58540, "start": 609.0799999999999, "end": 611.52, "text": " fewer of your dependencies than we used to.", "tokens": [51548, 13366, 295, 428, 36606, 813, 321, 1143, 281, 13, 51670], "temperature": 0.0, "avg_logprob": -0.20364403925022156, "compression_ratio": 1.6323529411764706, "no_speech_prob": 0.0005121482536196709}, {"id": 167, "seek": 58540, "start": 611.52, "end": 613.56, "text": " This is a little bit of a hack, but I'm going to talk later on", "tokens": [51670, 639, 307, 257, 707, 857, 295, 257, 10339, 11, 457, 286, 478, 516, 281, 751, 1780, 322, 51772], "temperature": 0.0, "avg_logprob": -0.20364403925022156, "compression_ratio": 1.6323529411764706, "no_speech_prob": 0.0005121482536196709}, {"id": 168, "seek": 61356, "start": 613.56, "end": 616.3599999999999, "text": " about how we might be able to make this better going forward.", "tokens": [50364, 466, 577, 321, 1062, 312, 1075, 281, 652, 341, 1101, 516, 2128, 13, 50504], "temperature": 0.0, "avg_logprob": -0.17675913174947103, "compression_ratio": 1.6326530612244898, "no_speech_prob": 0.002211350714787841}, {"id": 169, "seek": 61356, "start": 616.3599999999999, "end": 618.16, "text": " And then similarly around brew fetch,", "tokens": [50504, 400, 550, 14138, 926, 34619, 23673, 11, 50594], "temperature": 0.0, "avg_logprob": -0.17675913174947103, "compression_ratio": 1.6326530612244898, "no_speech_prob": 0.002211350714787841}, {"id": 170, "seek": 61356, "start": 618.16, "end": 620.4, "text": " some of our maintainers noticed that there was a bunch of work", "tokens": [50594, 512, 295, 527, 6909, 433, 5694, 300, 456, 390, 257, 3840, 295, 589, 50706], "temperature": 0.0, "avg_logprob": -0.17675913174947103, "compression_ratio": 1.6326530612244898, "no_speech_prob": 0.002211350714787841}, {"id": 171, "seek": 61356, "start": 620.4, "end": 622.56, "text": " happening there that didn't need to happen.", "tokens": [50706, 2737, 456, 300, 994, 380, 643, 281, 1051, 13, 50814], "temperature": 0.0, "avg_logprob": -0.17675913174947103, "compression_ratio": 1.6326530612244898, "no_speech_prob": 0.002211350714787841}, {"id": 172, "seek": 61356, "start": 622.56, "end": 626.28, "text": " So I guess if you do find Hummoo to be a little bit too slow,", "tokens": [50814, 407, 286, 2041, 498, 291, 360, 915, 12877, 76, 1986, 281, 312, 257, 707, 857, 886, 2964, 11, 51000], "temperature": 0.0, "avg_logprob": -0.17675913174947103, "compression_ratio": 1.6326530612244898, "no_speech_prob": 0.002211350714787841}, {"id": 173, "seek": 61356, "start": 626.28, "end": 630.8399999999999, "text": " then be relatively confident that we do feel your pain", "tokens": [51000, 550, 312, 7226, 6679, 300, 321, 360, 841, 428, 1822, 51228], "temperature": 0.0, "avg_logprob": -0.17675913174947103, "compression_ratio": 1.6326530612244898, "no_speech_prob": 0.002211350714787841}, {"id": 174, "seek": 61356, "start": 630.8399999999999, "end": 633.56, "text": " and we are trying to make things faster most of the time.", "tokens": [51228, 293, 321, 366, 1382, 281, 652, 721, 4663, 881, 295, 264, 565, 13, 51364], "temperature": 0.0, "avg_logprob": -0.17675913174947103, "compression_ratio": 1.6326530612244898, "no_speech_prob": 0.002211350714787841}, {"id": 175, "seek": 61356, "start": 634.4, "end": 637.76, "text": " A really weird performance optimization we decided to do,", "tokens": [51406, 316, 534, 3657, 3389, 19618, 321, 3047, 281, 360, 11, 51574], "temperature": 0.0, "avg_logprob": -0.17675913174947103, "compression_ratio": 1.6326530612244898, "no_speech_prob": 0.002211350714787841}, {"id": 176, "seek": 61356, "start": 637.76, "end": 639.56, "text": " considering everything I've said before,", "tokens": [51574, 8079, 1203, 286, 600, 848, 949, 11, 51664], "temperature": 0.0, "avg_logprob": -0.17675913174947103, "compression_ratio": 1.6326530612244898, "no_speech_prob": 0.002211350714787841}, {"id": 177, "seek": 63956, "start": 640.56, "end": 643.9599999999999, "text": " is I don't know if anyone who's not a maintainer ever went", "tokens": [50414, 307, 286, 500, 380, 458, 498, 2878, 567, 311, 406, 257, 6909, 260, 1562, 1437, 50584], "temperature": 0.0, "avg_logprob": -0.25735403442382815, "compression_ratio": 1.6901408450704225, "no_speech_prob": 0.0028207895811647177}, {"id": 178, "seek": 63956, "start": 643.9599999999999, "end": 647.4799999999999, "text": " and clicked around on the repo pages on GitHub,", "tokens": [50584, 293, 23370, 926, 322, 264, 49040, 7183, 322, 23331, 11, 50760], "temperature": 0.0, "avg_logprob": -0.25735403442382815, "compression_ratio": 1.6901408450704225, "no_speech_prob": 0.0028207895811647177}, {"id": 179, "seek": 63956, "start": 647.4799999999999, "end": 650.8399999999999, "text": " but due to the Git issues I mentioned earlier,", "tokens": [50760, 457, 3462, 281, 264, 16939, 2663, 286, 2835, 3071, 11, 50928], "temperature": 0.0, "avg_logprob": -0.25735403442382815, "compression_ratio": 1.6901408450704225, "no_speech_prob": 0.0028207895811647177}, {"id": 180, "seek": 63956, "start": 650.8399999999999, "end": 653.68, "text": " a lot of these pages were time out and stuff like that.", "tokens": [50928, 257, 688, 295, 613, 7183, 645, 565, 484, 293, 1507, 411, 300, 13, 51070], "temperature": 0.0, "avg_logprob": -0.25735403442382815, "compression_ratio": 1.6901408450704225, "no_speech_prob": 0.0028207895811647177}, {"id": 181, "seek": 63956, "start": 653.68, "end": 656.92, "text": " And another thing that Git and GitHub people", "tokens": [51070, 400, 1071, 551, 300, 16939, 293, 23331, 561, 51232], "temperature": 0.0, "avg_logprob": -0.25735403442382815, "compression_ratio": 1.6901408450704225, "no_speech_prob": 0.0028207895811647177}, {"id": 182, "seek": 63956, "start": 656.92, "end": 659.28, "text": " who knew a lot about Git have said to us for a while", "tokens": [51232, 567, 2586, 257, 688, 466, 16939, 362, 848, 281, 505, 337, 257, 1339, 51350], "temperature": 0.0, "avg_logprob": -0.25735403442382815, "compression_ratio": 1.6901408450704225, "no_speech_prob": 0.0028207895811647177}, {"id": 183, "seek": 63956, "start": 659.28, "end": 662.56, "text": " is due to some complicated Git internal stuff", "tokens": [51350, 307, 3462, 281, 512, 6179, 16939, 6920, 1507, 51514], "temperature": 0.0, "avg_logprob": -0.25735403442382815, "compression_ratio": 1.6901408450704225, "no_speech_prob": 0.0028207895811647177}, {"id": 184, "seek": 63956, "start": 662.56, "end": 664.1199999999999, "text": " that I don't really understand,", "tokens": [51514, 300, 286, 500, 380, 534, 1223, 11, 51592], "temperature": 0.0, "avg_logprob": -0.25735403442382815, "compression_ratio": 1.6901408450704225, "no_speech_prob": 0.0028207895811647177}, {"id": 185, "seek": 63956, "start": 664.1199999999999, "end": 666.0799999999999, "text": " you have structured the Hummoo repo in pretty much", "tokens": [51592, 291, 362, 18519, 264, 12877, 76, 1986, 49040, 294, 1238, 709, 51690], "temperature": 0.0, "avg_logprob": -0.25735403442382815, "compression_ratio": 1.6901408450704225, "no_speech_prob": 0.0028207895811647177}, {"id": 186, "seek": 63956, "start": 666.0799999999999, "end": 668.2399999999999, "text": " the worst possible way for Git performance.", "tokens": [51690, 264, 5855, 1944, 636, 337, 16939, 3389, 13, 51798], "temperature": 0.0, "avg_logprob": -0.25735403442382815, "compression_ratio": 1.6901408450704225, "no_speech_prob": 0.0028207895811647177}, {"id": 187, "seek": 66824, "start": 669.24, "end": 671.96, "text": " Git apparently really does not like having directories", "tokens": [50414, 16939, 7970, 534, 775, 406, 411, 1419, 5391, 530, 50550], "temperature": 0.0, "avg_logprob": -0.26111918284480734, "compression_ratio": 1.7993079584775087, "no_speech_prob": 0.0026066224090754986}, {"id": 188, "seek": 66824, "start": 671.96, "end": 674.96, "text": " with thousands of files in them,", "tokens": [50550, 365, 5383, 295, 7098, 294, 552, 11, 50700], "temperature": 0.0, "avg_logprob": -0.26111918284480734, "compression_ratio": 1.7993079584775087, "no_speech_prob": 0.0026066224090754986}, {"id": 189, "seek": 66824, "start": 674.96, "end": 678.44, "text": " and we had, I think, a directory with 8,000 files", "tokens": [50700, 293, 321, 632, 11, 286, 519, 11, 257, 21120, 365, 1649, 11, 1360, 7098, 50874], "temperature": 0.0, "avg_logprob": -0.26111918284480734, "compression_ratio": 1.7993079584775087, "no_speech_prob": 0.0026066224090754986}, {"id": 190, "seek": 66824, "start": 678.44, "end": 679.76, "text": " and it was something like that,", "tokens": [50874, 293, 309, 390, 746, 411, 300, 11, 50940], "temperature": 0.0, "avg_logprob": -0.26111918284480734, "compression_ratio": 1.7993079584775087, "no_speech_prob": 0.0026066224090754986}, {"id": 191, "seek": 66824, "start": 679.76, "end": 682.16, "text": " which means you can see it on the GitHub interface", "tokens": [50940, 597, 1355, 291, 393, 536, 309, 322, 264, 23331, 9226, 51060], "temperature": 0.0, "avg_logprob": -0.26111918284480734, "compression_ratio": 1.7993079584775087, "no_speech_prob": 0.0026066224090754986}, {"id": 192, "seek": 66824, "start": 682.16, "end": 684.76, "text": " because all these operations list in the directory,", "tokens": [51060, 570, 439, 613, 7705, 1329, 294, 264, 21120, 11, 51190], "temperature": 0.0, "avg_logprob": -0.26111918284480734, "compression_ratio": 1.7993079584775087, "no_speech_prob": 0.0026066224090754986}, {"id": 193, "seek": 66824, "start": 684.76, "end": 687.5600000000001, "text": " if you did a Git blame or Git log on this directory,", "tokens": [51190, 498, 291, 630, 257, 16939, 10127, 420, 16939, 3565, 322, 341, 21120, 11, 51330], "temperature": 0.0, "avg_logprob": -0.26111918284480734, "compression_ratio": 1.7993079584775087, "no_speech_prob": 0.0026066224090754986}, {"id": 194, "seek": 66824, "start": 687.5600000000001, "end": 689.04, "text": " all of those were time out,", "tokens": [51330, 439, 295, 729, 645, 565, 484, 11, 51404], "temperature": 0.0, "avg_logprob": -0.26111918284480734, "compression_ratio": 1.7993079584775087, "no_speech_prob": 0.0026066224090754986}, {"id": 195, "seek": 66824, "start": 689.04, "end": 691.5600000000001, "text": " which meant increasing amounts of the GitHub user interface", "tokens": [51404, 597, 4140, 5662, 11663, 295, 264, 23331, 4195, 9226, 51530], "temperature": 0.0, "avg_logprob": -0.26111918284480734, "compression_ratio": 1.7993079584775087, "no_speech_prob": 0.0026066224090754986}, {"id": 196, "seek": 66824, "start": 691.5600000000001, "end": 695.16, "text": " was just not useful for when you were using Hummoo,", "tokens": [51530, 390, 445, 406, 4420, 337, 562, 291, 645, 1228, 12877, 76, 1986, 11, 51710], "temperature": 0.0, "avg_logprob": -0.26111918284480734, "compression_ratio": 1.7993079584775087, "no_speech_prob": 0.0026066224090754986}, {"id": 197, "seek": 66824, "start": 695.16, "end": 697.96, "text": " and that also contributed to why Git fetch was so slow", "tokens": [51710, 293, 300, 611, 18434, 281, 983, 16939, 23673, 390, 370, 2964, 51850], "temperature": 0.0, "avg_logprob": -0.26111918284480734, "compression_ratio": 1.7993079584775087, "no_speech_prob": 0.0026066224090754986}, {"id": 198, "seek": 69796, "start": 698.6800000000001, "end": 701.6, "text": " Git GC was so slow, like opening PRs,", "tokens": [50400, 16939, 29435, 390, 370, 2964, 11, 411, 5193, 11568, 82, 11, 50546], "temperature": 0.0, "avg_logprob": -0.19191546440124513, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.001099547604098916}, {"id": 199, "seek": 69796, "start": 701.6, "end": 704.0400000000001, "text": " like the pushes and the pulls and all this stuff involved,", "tokens": [50546, 411, 264, 21020, 293, 264, 16982, 293, 439, 341, 1507, 3288, 11, 50668], "temperature": 0.0, "avg_logprob": -0.19191546440124513, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.001099547604098916}, {"id": 200, "seek": 69796, "start": 704.0400000000001, "end": 705.8000000000001, "text": " which is like getting really slow", "tokens": [50668, 597, 307, 411, 1242, 534, 2964, 50756], "temperature": 0.0, "avg_logprob": -0.19191546440124513, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.001099547604098916}, {"id": 201, "seek": 69796, "start": 705.8000000000001, "end": 707.84, "text": " and getting slower and slower and slower.", "tokens": [50756, 293, 1242, 14009, 293, 14009, 293, 14009, 13, 50858], "temperature": 0.0, "avg_logprob": -0.19191546440124513, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.001099547604098916}, {"id": 202, "seek": 69796, "start": 707.84, "end": 710.6800000000001, "text": " We were also seeing more instance with GitHub", "tokens": [50858, 492, 645, 611, 2577, 544, 5197, 365, 23331, 51000], "temperature": 0.0, "avg_logprob": -0.19191546440124513, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.001099547604098916}, {"id": 203, "seek": 69796, "start": 710.6800000000001, "end": 713.36, "text": " that GitHub didn't seem to think we're related to this,", "tokens": [51000, 300, 23331, 994, 380, 1643, 281, 519, 321, 434, 4077, 281, 341, 11, 51134], "temperature": 0.0, "avg_logprob": -0.19191546440124513, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.001099547604098916}, {"id": 204, "seek": 69796, "start": 713.36, "end": 715.36, "text": " but I kind of did.", "tokens": [51134, 457, 286, 733, 295, 630, 13, 51234], "temperature": 0.0, "avg_logprob": -0.19191546440124513, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.001099547604098916}, {"id": 205, "seek": 69796, "start": 715.36, "end": 717.96, "text": " So we've now like sharded our repos,", "tokens": [51234, 407, 321, 600, 586, 411, 402, 22803, 527, 1085, 329, 11, 51364], "temperature": 0.0, "avg_logprob": -0.19191546440124513, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.001099547604098916}, {"id": 206, "seek": 69796, "start": 717.96, "end": 720.9200000000001, "text": " so essentially like everything is split into directories", "tokens": [51364, 370, 4476, 411, 1203, 307, 7472, 666, 5391, 530, 51512], "temperature": 0.0, "avg_logprob": -0.19191546440124513, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.001099547604098916}, {"id": 207, "seek": 69796, "start": 720.9200000000001, "end": 725.9200000000001, "text": " based on name, and because we have quite a lot of libraries,", "tokens": [51512, 2361, 322, 1315, 11, 293, 570, 321, 362, 1596, 257, 688, 295, 15148, 11, 51762], "temperature": 0.0, "avg_logprob": -0.19191546440124513, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.001099547604098916}, {"id": 208, "seek": 72592, "start": 725.92, "end": 728.1999999999999, "text": " so Lib gets its own special directory,", "tokens": [50364, 370, 15834, 2170, 1080, 1065, 2121, 21120, 11, 50478], "temperature": 0.0, "avg_logprob": -0.18847172465545453, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.00206402107141912}, {"id": 209, "seek": 72592, "start": 728.1999999999999, "end": 729.9599999999999, "text": " it doesn't get bundled in under L,", "tokens": [50478, 309, 1177, 380, 483, 13882, 1493, 294, 833, 441, 11, 50566], "temperature": 0.0, "avg_logprob": -0.18847172465545453, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.00206402107141912}, {"id": 210, "seek": 72592, "start": 729.9599999999999, "end": 732.5999999999999, "text": " we've done the same thing for Hummoo Cask as well,", "tokens": [50566, 321, 600, 1096, 264, 912, 551, 337, 12877, 76, 1986, 383, 3863, 382, 731, 11, 50698], "temperature": 0.0, "avg_logprob": -0.18847172465545453, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.00206402107141912}, {"id": 211, "seek": 72592, "start": 732.5999999999999, "end": 733.64, "text": " like again, as I say,", "tokens": [50698, 411, 797, 11, 382, 286, 584, 11, 50750], "temperature": 0.0, "avg_logprob": -0.18847172465545453, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.00206402107141912}, {"id": 212, "seek": 72592, "start": 733.64, "end": 735.0799999999999, "text": " GitHub would be wanting us to do this for ages,", "tokens": [50750, 23331, 576, 312, 7935, 505, 281, 360, 341, 337, 12357, 11, 50822], "temperature": 0.0, "avg_logprob": -0.18847172465545453, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.00206402107141912}, {"id": 213, "seek": 72592, "start": 735.0799999999999, "end": 737.8, "text": " but we've finally actually done this now,", "tokens": [50822, 457, 321, 600, 2721, 767, 1096, 341, 586, 11, 50958], "temperature": 0.0, "avg_logprob": -0.18847172465545453, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.00206402107141912}, {"id": 214, "seek": 72592, "start": 737.8, "end": 739.56, "text": " and that now means that on these pages,", "tokens": [50958, 293, 300, 586, 1355, 300, 322, 613, 7183, 11, 51046], "temperature": 0.0, "avg_logprob": -0.18847172465545453, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.00206402107141912}, {"id": 215, "seek": 72592, "start": 739.56, "end": 742.36, "text": " you can actually finally now see the commit information", "tokens": [51046, 291, 393, 767, 2721, 586, 536, 264, 5599, 1589, 51186], "temperature": 0.0, "avg_logprob": -0.18847172465545453, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.00206402107141912}, {"id": 216, "seek": 72592, "start": 742.36, "end": 744.56, "text": " and timestamps and all this type of stuff,", "tokens": [51186, 293, 49108, 23150, 293, 439, 341, 2010, 295, 1507, 11, 51296], "temperature": 0.0, "avg_logprob": -0.18847172465545453, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.00206402107141912}, {"id": 217, "seek": 72592, "start": 744.56, "end": 746.4399999999999, "text": " and it makes it a bit more useful for people", "tokens": [51296, 293, 309, 1669, 309, 257, 857, 544, 4420, 337, 561, 51390], "temperature": 0.0, "avg_logprob": -0.18847172465545453, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.00206402107141912}, {"id": 218, "seek": 72592, "start": 746.4399999999999, "end": 748.0, "text": " when it wasn't before.", "tokens": [51390, 562, 309, 2067, 380, 949, 13, 51468], "temperature": 0.0, "avg_logprob": -0.18847172465545453, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.00206402107141912}, {"id": 219, "seek": 72592, "start": 748.0, "end": 750.24, "text": " So a more exciting thing for us is,", "tokens": [51468, 407, 257, 544, 4670, 551, 337, 505, 307, 11, 51580], "temperature": 0.0, "avg_logprob": -0.18847172465545453, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.00206402107141912}, {"id": 220, "seek": 72592, "start": 750.24, "end": 752.92, "text": " we moved to like using Ruby 3.1,", "tokens": [51580, 321, 4259, 281, 411, 1228, 19907, 805, 13, 16, 11, 51714], "temperature": 0.0, "avg_logprob": -0.18847172465545453, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.00206402107141912}, {"id": 221, "seek": 75292, "start": 752.92, "end": 756.0799999999999, "text": " Hummoo, who knew that Hummoo was written in Ruby?", "tokens": [50364, 12877, 76, 1986, 11, 567, 2586, 300, 12877, 76, 1986, 390, 3720, 294, 19907, 30, 50522], "temperature": 0.0, "avg_logprob": -0.16666492196016533, "compression_ratio": 1.5978260869565217, "no_speech_prob": 0.0009494443656876683}, {"id": 222, "seek": 75292, "start": 756.0799999999999, "end": 758.68, "text": " It's this widely known thing, yeah, cool.", "tokens": [50522, 467, 311, 341, 13371, 2570, 551, 11, 1338, 11, 1627, 13, 50652], "temperature": 0.0, "avg_logprob": -0.16666492196016533, "compression_ratio": 1.5978260869565217, "no_speech_prob": 0.0009494443656876683}, {"id": 223, "seek": 75292, "start": 758.68, "end": 763.68, "text": " And so Hummoo originally I think was on Mac OS,", "tokens": [50652, 400, 370, 12877, 76, 1986, 7993, 286, 519, 390, 322, 5707, 12731, 11, 50902], "temperature": 0.0, "avg_logprob": -0.16666492196016533, "compression_ratio": 1.5978260869565217, "no_speech_prob": 0.0009494443656876683}, {"id": 224, "seek": 75292, "start": 763.8, "end": 766.8, "text": " 10.5 I think the first version,", "tokens": [50908, 1266, 13, 20, 286, 519, 264, 700, 3037, 11, 51058], "temperature": 0.0, "avg_logprob": -0.16666492196016533, "compression_ratio": 1.5978260869565217, "no_speech_prob": 0.0009494443656876683}, {"id": 225, "seek": 75292, "start": 766.8, "end": 770.36, "text": " and back then Apple provided like loads of stuff with the OS,", "tokens": [51058, 293, 646, 550, 6373, 5649, 411, 12668, 295, 1507, 365, 264, 12731, 11, 51236], "temperature": 0.0, "avg_logprob": -0.16666492196016533, "compression_ratio": 1.5978260869565217, "no_speech_prob": 0.0009494443656876683}, {"id": 226, "seek": 75292, "start": 770.36, "end": 773.88, "text": " including Ruby, 1.8 or whatever I think it was at the time,", "tokens": [51236, 3009, 19907, 11, 502, 13, 23, 420, 2035, 286, 519, 309, 390, 412, 264, 565, 11, 51412], "temperature": 0.0, "avg_logprob": -0.16666492196016533, "compression_ratio": 1.5978260869565217, "no_speech_prob": 0.0009494443656876683}, {"id": 227, "seek": 75292, "start": 773.88, "end": 775.9599999999999, "text": " and Hummoo kind of particularly in the early days", "tokens": [51412, 293, 12877, 76, 1986, 733, 295, 4098, 294, 264, 2440, 1708, 51516], "temperature": 0.0, "avg_logprob": -0.16666492196016533, "compression_ratio": 1.5978260869565217, "no_speech_prob": 0.0009494443656876683}, {"id": 228, "seek": 75292, "start": 775.9599999999999, "end": 778.1999999999999, "text": " tried to use as much stuff from the system as possible", "tokens": [51516, 3031, 281, 764, 382, 709, 1507, 490, 264, 1185, 382, 1944, 51628], "temperature": 0.0, "avg_logprob": -0.16666492196016533, "compression_ratio": 1.5978260869565217, "no_speech_prob": 0.0009494443656876683}, {"id": 229, "seek": 75292, "start": 778.1999999999999, "end": 780.64, "text": " and not pull in its own kind of libraries.", "tokens": [51628, 293, 406, 2235, 294, 1080, 1065, 733, 295, 15148, 13, 51750], "temperature": 0.0, "avg_logprob": -0.16666492196016533, "compression_ratio": 1.5978260869565217, "no_speech_prob": 0.0009494443656876683}, {"id": 230, "seek": 78064, "start": 781.64, "end": 784.04, "text": " We still try and do that where we can,", "tokens": [50414, 492, 920, 853, 293, 360, 300, 689, 321, 393, 11, 50534], "temperature": 0.0, "avg_logprob": -0.1229862746070413, "compression_ratio": 1.8015267175572518, "no_speech_prob": 0.0009208520641550422}, {"id": 231, "seek": 78064, "start": 784.04, "end": 789.04, "text": " but Ruby was an example where Apple said a few years ago", "tokens": [50534, 457, 19907, 390, 364, 1365, 689, 6373, 848, 257, 1326, 924, 2057, 50784], "temperature": 0.0, "avg_logprob": -0.1229862746070413, "compression_ratio": 1.8015267175572518, "no_speech_prob": 0.0009208520641550422}, {"id": 232, "seek": 78064, "start": 789.36, "end": 791.6, "text": " that like, okay, we're kind of deprecating", "tokens": [50800, 300, 411, 11, 1392, 11, 321, 434, 733, 295, 1367, 13867, 990, 50912], "temperature": 0.0, "avg_logprob": -0.1229862746070413, "compression_ratio": 1.8015267175572518, "no_speech_prob": 0.0009208520641550422}, {"id": 233, "seek": 78064, "start": 791.6, "end": 793.92, "text": " the system version of Ruby and Python", "tokens": [50912, 264, 1185, 3037, 295, 19907, 293, 15329, 51028], "temperature": 0.0, "avg_logprob": -0.1229862746070413, "compression_ratio": 1.8015267175572518, "no_speech_prob": 0.0009208520641550422}, {"id": 234, "seek": 78064, "start": 793.92, "end": 796.36, "text": " and I think Perl and stuff like that,", "tokens": [51028, 293, 286, 519, 3026, 75, 293, 1507, 411, 300, 11, 51150], "temperature": 0.0, "avg_logprob": -0.1229862746070413, "compression_ratio": 1.8015267175572518, "no_speech_prob": 0.0009208520641550422}, {"id": 235, "seek": 78064, "start": 796.36, "end": 799.48, "text": " and for Apple kind of deprecating this stuff,", "tokens": [51150, 293, 337, 6373, 733, 295, 1367, 13867, 990, 341, 1507, 11, 51306], "temperature": 0.0, "avg_logprob": -0.1229862746070413, "compression_ratio": 1.8015267175572518, "no_speech_prob": 0.0009208520641550422}, {"id": 236, "seek": 78064, "start": 799.48, "end": 801.0, "text": " we've sort of been playing chicken and being like,", "tokens": [51306, 321, 600, 1333, 295, 668, 2433, 4662, 293, 885, 411, 11, 51382], "temperature": 0.0, "avg_logprob": -0.1229862746070413, "compression_ratio": 1.8015267175572518, "no_speech_prob": 0.0009208520641550422}, {"id": 237, "seek": 78064, "start": 801.0, "end": 802.88, "text": " well, you say it's deprecated,", "tokens": [51382, 731, 11, 291, 584, 309, 311, 1367, 13867, 770, 11, 51476], "temperature": 0.0, "avg_logprob": -0.1229862746070413, "compression_ratio": 1.8015267175572518, "no_speech_prob": 0.0009208520641550422}, {"id": 238, "seek": 78064, "start": 802.88, "end": 804.16, "text": " but you keep upgrading it for us,", "tokens": [51476, 457, 291, 1066, 36249, 309, 337, 505, 11, 51540], "temperature": 0.0, "avg_logprob": -0.1229862746070413, "compression_ratio": 1.8015267175572518, "no_speech_prob": 0.0009208520641550422}, {"id": 239, "seek": 78064, "start": 804.16, "end": 806.4, "text": " so we're gonna just keep using your version", "tokens": [51540, 370, 321, 434, 799, 445, 1066, 1228, 428, 3037, 51652], "temperature": 0.0, "avg_logprob": -0.1229862746070413, "compression_ratio": 1.8015267175572518, "no_speech_prob": 0.0009208520641550422}, {"id": 240, "seek": 78064, "start": 806.4, "end": 810.0, "text": " as long as we can, and like eventually kind of went", "tokens": [51652, 382, 938, 382, 321, 393, 11, 293, 411, 4728, 733, 295, 1437, 51832], "temperature": 0.0, "avg_logprob": -0.1229862746070413, "compression_ratio": 1.8015267175572518, "no_speech_prob": 0.0009208520641550422}, {"id": 241, "seek": 81000, "start": 810.04, "end": 811.72, "text": " to some Apple people for the last release", "tokens": [50366, 281, 512, 6373, 561, 337, 264, 1036, 4374, 50450], "temperature": 0.0, "avg_logprob": -0.14599100748697916, "compression_ratio": 1.7620578778135048, "no_speech_prob": 0.0023956201039254665}, {"id": 242, "seek": 81000, "start": 811.72, "end": 814.32, "text": " and were like, hey, the Ruby you supply is 2.6,", "tokens": [50450, 293, 645, 411, 11, 4177, 11, 264, 19907, 291, 5847, 307, 568, 13, 21, 11, 50580], "temperature": 0.0, "avg_logprob": -0.14599100748697916, "compression_ratio": 1.7620578778135048, "no_speech_prob": 0.0023956201039254665}, {"id": 243, "seek": 81000, "start": 814.32, "end": 816.0, "text": " that's really old, when are we gonna get a new one?", "tokens": [50580, 300, 311, 534, 1331, 11, 562, 366, 321, 799, 483, 257, 777, 472, 30, 50664], "temperature": 0.0, "avg_logprob": -0.14599100748697916, "compression_ratio": 1.7620578778135048, "no_speech_prob": 0.0023956201039254665}, {"id": 244, "seek": 81000, "start": 816.0, "end": 817.92, "text": " And they were like, did you not read", "tokens": [50664, 400, 436, 645, 411, 11, 630, 291, 406, 1401, 50760], "temperature": 0.0, "avg_logprob": -0.14599100748697916, "compression_ratio": 1.7620578778135048, "no_speech_prob": 0.0023956201039254665}, {"id": 245, "seek": 81000, "start": 817.92, "end": 819.2, "text": " when we told you it was deprecated?", "tokens": [50760, 562, 321, 1907, 291, 309, 390, 1367, 13867, 770, 30, 50824], "temperature": 0.0, "avg_logprob": -0.14599100748697916, "compression_ratio": 1.7620578778135048, "no_speech_prob": 0.0023956201039254665}, {"id": 246, "seek": 81000, "start": 819.2, "end": 821.72, "text": " And we were like, yeah, but, yeah, but please.", "tokens": [50824, 400, 321, 645, 411, 11, 1338, 11, 457, 11, 1338, 11, 457, 1767, 13, 50950], "temperature": 0.0, "avg_logprob": -0.14599100748697916, "compression_ratio": 1.7620578778135048, "no_speech_prob": 0.0023956201039254665}, {"id": 247, "seek": 81000, "start": 821.72, "end": 824.04, "text": " And they said, no, this time we mean it.", "tokens": [50950, 400, 436, 848, 11, 572, 11, 341, 565, 321, 914, 309, 13, 51066], "temperature": 0.0, "avg_logprob": -0.14599100748697916, "compression_ratio": 1.7620578778135048, "no_speech_prob": 0.0023956201039254665}, {"id": 248, "seek": 81000, "start": 824.04, "end": 826.48, "text": " So like finally we've kind of,", "tokens": [51066, 407, 411, 2721, 321, 600, 733, 295, 11, 51188], "temperature": 0.0, "avg_logprob": -0.14599100748697916, "compression_ratio": 1.7620578778135048, "no_speech_prob": 0.0023956201039254665}, {"id": 249, "seek": 81000, "start": 826.48, "end": 828.08, "text": " we've always had our own kind of thing", "tokens": [51188, 321, 600, 1009, 632, 527, 1065, 733, 295, 551, 51268], "temperature": 0.0, "avg_logprob": -0.14599100748697916, "compression_ratio": 1.7620578778135048, "no_speech_prob": 0.0023956201039254665}, {"id": 250, "seek": 81000, "start": 828.08, "end": 831.92, "text": " we call portable Ruby, which allowed us a way", "tokens": [51268, 321, 818, 21800, 19907, 11, 597, 4350, 505, 257, 636, 51460], "temperature": 0.0, "avg_logprob": -0.14599100748697916, "compression_ratio": 1.7620578778135048, "no_speech_prob": 0.0023956201039254665}, {"id": 251, "seek": 81000, "start": 831.92, "end": 834.0, "text": " to distribute a kind of a Ruby", "tokens": [51460, 281, 20594, 257, 733, 295, 257, 19907, 51564], "temperature": 0.0, "avg_logprob": -0.14599100748697916, "compression_ratio": 1.7620578778135048, "no_speech_prob": 0.0023956201039254665}, {"id": 252, "seek": 81000, "start": 834.0, "end": 836.28, "text": " that you could install anywhere in your system.", "tokens": [51564, 300, 291, 727, 3625, 4992, 294, 428, 1185, 13, 51678], "temperature": 0.0, "avg_logprob": -0.14599100748697916, "compression_ratio": 1.7620578778135048, "no_speech_prob": 0.0023956201039254665}, {"id": 253, "seek": 81000, "start": 836.28, "end": 838.96, "text": " So it worked regardless of where your homebrew is,", "tokens": [51678, 407, 309, 2732, 10060, 295, 689, 428, 1280, 65, 2236, 307, 11, 51812], "temperature": 0.0, "avg_logprob": -0.14599100748697916, "compression_ratio": 1.7620578778135048, "no_speech_prob": 0.0023956201039254665}, {"id": 254, "seek": 83896, "start": 838.96, "end": 841.36, "text": " and it would work on a variety of Mac OS versions", "tokens": [50364, 293, 309, 576, 589, 322, 257, 5673, 295, 5707, 12731, 9606, 50484], "temperature": 0.0, "avg_logprob": -0.1329422663975429, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.00039164148620329797}, {"id": 255, "seek": 83896, "start": 841.36, "end": 842.8000000000001, "text": " and stuff like that.", "tokens": [50484, 293, 1507, 411, 300, 13, 50556], "temperature": 0.0, "avg_logprob": -0.1329422663975429, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.00039164148620329797}, {"id": 256, "seek": 83896, "start": 842.8000000000001, "end": 845.6800000000001, "text": " And that was now moved to Ruby 3.1,", "tokens": [50556, 400, 300, 390, 586, 4259, 281, 19907, 805, 13, 16, 11, 50700], "temperature": 0.0, "avg_logprob": -0.1329422663975429, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.00039164148620329797}, {"id": 257, "seek": 83896, "start": 845.6800000000001, "end": 848.32, "text": " so now we have a system where essentially everyone", "tokens": [50700, 370, 586, 321, 362, 257, 1185, 689, 4476, 1518, 50832], "temperature": 0.0, "avg_logprob": -0.1329422663975429, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.00039164148620329797}, {"id": 258, "seek": 83896, "start": 848.32, "end": 849.9200000000001, "text": " on Mac OS at least, on Linux,", "tokens": [50832, 322, 5707, 12731, 412, 1935, 11, 322, 18734, 11, 50912], "temperature": 0.0, "avg_logprob": -0.1329422663975429, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.00039164148620329797}, {"id": 259, "seek": 83896, "start": 849.9200000000001, "end": 852.6800000000001, "text": " there's some configurations where you don't need this,", "tokens": [50912, 456, 311, 512, 31493, 689, 291, 500, 380, 643, 341, 11, 51050], "temperature": 0.0, "avg_logprob": -0.1329422663975429, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.00039164148620329797}, {"id": 260, "seek": 83896, "start": 852.6800000000001, "end": 854.72, "text": " but everyone has portable Ruby now", "tokens": [51050, 457, 1518, 575, 21800, 19907, 586, 51152], "temperature": 0.0, "avg_logprob": -0.1329422663975429, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.00039164148620329797}, {"id": 261, "seek": 83896, "start": 854.72, "end": 856.52, "text": " and supplies kind of a nice,", "tokens": [51152, 293, 11768, 733, 295, 257, 1481, 11, 51242], "temperature": 0.0, "avg_logprob": -0.1329422663975429, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.00039164148620329797}, {"id": 262, "seek": 83896, "start": 856.52, "end": 858.5600000000001, "text": " relatively new version of Ruby.", "tokens": [51242, 7226, 777, 3037, 295, 19907, 13, 51344], "temperature": 0.0, "avg_logprob": -0.1329422663975429, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.00039164148620329797}, {"id": 263, "seek": 83896, "start": 858.5600000000001, "end": 861.52, "text": " So this is nice for us, it probably has some,", "tokens": [51344, 407, 341, 307, 1481, 337, 505, 11, 309, 1391, 575, 512, 11, 51492], "temperature": 0.0, "avg_logprob": -0.1329422663975429, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.00039164148620329797}, {"id": 264, "seek": 83896, "start": 861.52, "end": 864.44, "text": " it's had some mild performance increases,", "tokens": [51492, 309, 311, 632, 512, 15154, 3389, 8637, 11, 51638], "temperature": 0.0, "avg_logprob": -0.1329422663975429, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.00039164148620329797}, {"id": 265, "seek": 83896, "start": 864.44, "end": 866.48, "text": " and it lets us use like newer language features,", "tokens": [51638, 293, 309, 6653, 505, 764, 411, 17628, 2856, 4122, 11, 51740], "temperature": 0.0, "avg_logprob": -0.1329422663975429, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.00039164148620329797}, {"id": 266, "seek": 83896, "start": 866.48, "end": 868.36, "text": " makes homebrew easier to kind of maintain,", "tokens": [51740, 1669, 1280, 65, 2236, 3571, 281, 733, 295, 6909, 11, 51834], "temperature": 0.0, "avg_logprob": -0.1329422663975429, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.00039164148620329797}, {"id": 267, "seek": 86836, "start": 868.4, "end": 870.72, "text": " makes it easier for homebrew like Ruby users", "tokens": [50366, 1669, 309, 3571, 337, 1280, 65, 2236, 411, 19907, 5022, 50482], "temperature": 0.0, "avg_logprob": -0.2062187544796445, "compression_ratio": 1.6740088105726871, "no_speech_prob": 0.00036672825808636844}, {"id": 268, "seek": 86836, "start": 870.72, "end": 873.96, "text": " to kind of not be used to this kind of ancient version of Ruby,", "tokens": [50482, 281, 733, 295, 406, 312, 1143, 281, 341, 733, 295, 7832, 3037, 295, 19907, 11, 50644], "temperature": 0.0, "avg_logprob": -0.2062187544796445, "compression_ratio": 1.6740088105726871, "no_speech_prob": 0.00036672825808636844}, {"id": 269, "seek": 86836, "start": 873.96, "end": 877.16, "text": " and then there's stuff like Surabay and Rubikop", "tokens": [50644, 293, 550, 456, 311, 1507, 411, 6732, 455, 320, 293, 10518, 1035, 404, 50804], "temperature": 0.0, "avg_logprob": -0.2062187544796445, "compression_ratio": 1.6740088105726871, "no_speech_prob": 0.00036672825808636844}, {"id": 270, "seek": 86836, "start": 877.16, "end": 880.48, "text": " and all these other libraries we kind of depend on", "tokens": [50804, 293, 439, 613, 661, 15148, 321, 733, 295, 5672, 322, 50970], "temperature": 0.0, "avg_logprob": -0.2062187544796445, "compression_ratio": 1.6740088105726871, "no_speech_prob": 0.00036672825808636844}, {"id": 271, "seek": 86836, "start": 884.96, "end": 887.0, "text": " that were kind of creeping towards", "tokens": [51194, 300, 645, 733, 295, 47753, 3030, 51296], "temperature": 0.0, "avg_logprob": -0.2062187544796445, "compression_ratio": 1.6740088105726871, "no_speech_prob": 0.00036672825808636844}, {"id": 272, "seek": 86836, "start": 887.0, "end": 890.52, "text": " deprecating Ruby 2.6, or had already done so.", "tokens": [51296, 1367, 13867, 990, 19907, 568, 13, 21, 11, 420, 632, 1217, 1096, 370, 13, 51472], "temperature": 0.0, "avg_logprob": -0.2062187544796445, "compression_ratio": 1.6740088105726871, "no_speech_prob": 0.00036672825808636844}, {"id": 273, "seek": 86836, "start": 890.52, "end": 892.24, "text": " So let's just kind of keep more up to date", "tokens": [51472, 407, 718, 311, 445, 733, 295, 1066, 544, 493, 281, 4002, 51558], "temperature": 0.0, "avg_logprob": -0.2062187544796445, "compression_ratio": 1.6740088105726871, "no_speech_prob": 0.00036672825808636844}, {"id": 274, "seek": 86836, "start": 892.24, "end": 894.64, "text": " and stuff like that as well, which is very nice.", "tokens": [51558, 293, 1507, 411, 300, 382, 731, 11, 597, 307, 588, 1481, 13, 51678], "temperature": 0.0, "avg_logprob": -0.2062187544796445, "compression_ratio": 1.6740088105726871, "no_speech_prob": 0.00036672825808636844}, {"id": 275, "seek": 89464, "start": 895.64, "end": 899.92, "text": " We've also released a official like homebrew Mac OS package.", "tokens": [50414, 492, 600, 611, 4736, 257, 4783, 411, 1280, 65, 2236, 5707, 12731, 7372, 13, 50628], "temperature": 0.0, "avg_logprob": -0.22566501651190024, "compression_ratio": 1.5164835164835164, "no_speech_prob": 0.0010531629668548703}, {"id": 276, "seek": 89464, "start": 899.92, "end": 901.4399999999999, "text": " This is another thing that's been kind of requested", "tokens": [50628, 639, 307, 1071, 551, 300, 311, 668, 733, 295, 16436, 50704], "temperature": 0.0, "avg_logprob": -0.22566501651190024, "compression_ratio": 1.5164835164835164, "no_speech_prob": 0.0010531629668548703}, {"id": 277, "seek": 89464, "start": 901.4399999999999, "end": 905.24, "text": " for a long time, people have a love-hate relationship.", "tokens": [50704, 337, 257, 938, 565, 11, 561, 362, 257, 959, 12, 71, 473, 2480, 13, 50894], "temperature": 0.0, "avg_logprob": -0.22566501651190024, "compression_ratio": 1.5164835164835164, "no_speech_prob": 0.0010531629668548703}, {"id": 278, "seek": 89464, "start": 905.24, "end": 909.6, "text": " I think homebrew was one of the first projects", "tokens": [50894, 286, 519, 1280, 65, 2236, 390, 472, 295, 264, 700, 4455, 51112], "temperature": 0.0, "avg_logprob": -0.22566501651190024, "compression_ratio": 1.5164835164835164, "no_speech_prob": 0.0010531629668548703}, {"id": 279, "seek": 89464, "start": 909.6, "end": 913.16, "text": " to do the whole curl this bash script into your terminal,", "tokens": [51112, 281, 360, 264, 1379, 22591, 341, 46183, 5755, 666, 428, 14709, 11, 51290], "temperature": 0.0, "avg_logprob": -0.22566501651190024, "compression_ratio": 1.5164835164835164, "no_speech_prob": 0.0010531629668548703}, {"id": 280, "seek": 89464, "start": 913.16, "end": 914.88, "text": " and then we'll install it that way.", "tokens": [51290, 293, 550, 321, 603, 3625, 309, 300, 636, 13, 51376], "temperature": 0.0, "avg_logprob": -0.22566501651190024, "compression_ratio": 1.5164835164835164, "no_speech_prob": 0.0010531629668548703}, {"id": 281, "seek": 89464, "start": 914.88, "end": 917.36, "text": " Who has security concerns about that approach?", "tokens": [51376, 2102, 575, 3825, 7389, 466, 300, 3109, 30, 51500], "temperature": 0.0, "avg_logprob": -0.22566501651190024, "compression_ratio": 1.5164835164835164, "no_speech_prob": 0.0010531629668548703}, {"id": 282, "seek": 89464, "start": 918.92, "end": 920.4399999999999, "text": " Almost everyone, good.", "tokens": [51578, 12627, 1518, 11, 665, 13, 51654], "temperature": 0.0, "avg_logprob": -0.22566501651190024, "compression_ratio": 1.5164835164835164, "no_speech_prob": 0.0010531629668548703}, {"id": 283, "seek": 89464, "start": 920.4399999999999, "end": 922.3199999999999, "text": " We're gonna keep doing it, so yeah.", "tokens": [51654, 492, 434, 799, 1066, 884, 309, 11, 370, 1338, 13, 51748], "temperature": 0.0, "avg_logprob": -0.22566501651190024, "compression_ratio": 1.5164835164835164, "no_speech_prob": 0.0010531629668548703}, {"id": 284, "seek": 92232, "start": 922.5600000000001, "end": 923.4000000000001, "text": " All right.", "tokens": [50376, 1057, 558, 13, 50418], "temperature": 0.0, "avg_logprob": -0.2546738111055814, "compression_ratio": 1.7837837837837838, "no_speech_prob": 0.0014784663217142224}, {"id": 285, "seek": 92232, "start": 923.4000000000001, "end": 928.4000000000001, "text": " But if you don't like that, then you can use this instead.", "tokens": [50418, 583, 498, 291, 500, 380, 411, 300, 11, 550, 291, 393, 764, 341, 2602, 13, 50668], "temperature": 0.0, "avg_logprob": -0.2546738111055814, "compression_ratio": 1.7837837837837838, "no_speech_prob": 0.0014784663217142224}, {"id": 286, "seek": 92232, "start": 930.12, "end": 933.1600000000001, "text": " So this is kind of the more standard installation process", "tokens": [50754, 407, 341, 307, 733, 295, 264, 544, 3832, 13260, 1399, 50906], "temperature": 0.0, "avg_logprob": -0.2546738111055814, "compression_ratio": 1.7837837837837838, "no_speech_prob": 0.0014784663217142224}, {"id": 287, "seek": 92232, "start": 933.1600000000001, "end": 935.88, "text": " you would expect, where you get a nice installer", "tokens": [50906, 291, 576, 2066, 11, 689, 291, 483, 257, 1481, 46620, 51042], "temperature": 0.0, "avg_logprob": -0.2546738111055814, "compression_ratio": 1.7837837837837838, "no_speech_prob": 0.0014784663217142224}, {"id": 288, "seek": 92232, "start": 935.88, "end": 937.24, "text": " and you kind of click through these things", "tokens": [51042, 293, 291, 733, 295, 2052, 807, 613, 721, 51110], "temperature": 0.0, "avg_logprob": -0.2546738111055814, "compression_ratio": 1.7837837837837838, "no_speech_prob": 0.0014784663217142224}, {"id": 289, "seek": 92232, "start": 937.24, "end": 938.36, "text": " and stuff like that.", "tokens": [51110, 293, 1507, 411, 300, 13, 51166], "temperature": 0.0, "avg_logprob": -0.2546738111055814, "compression_ratio": 1.7837837837837838, "no_speech_prob": 0.0014784663217142224}, {"id": 290, "seek": 92232, "start": 939.6400000000001, "end": 942.44, "text": " And you should end up at the end with essentially", "tokens": [51230, 400, 291, 820, 917, 493, 412, 264, 917, 365, 4476, 51370], "temperature": 0.0, "avg_logprob": -0.2546738111055814, "compression_ratio": 1.7837837837837838, "no_speech_prob": 0.0014784663217142224}, {"id": 291, "seek": 92232, "start": 942.44, "end": 945.0, "text": " the same stuff, and it prints the same messages for you", "tokens": [51370, 264, 912, 1507, 11, 293, 309, 22305, 264, 912, 7897, 337, 291, 51498], "temperature": 0.0, "avg_logprob": -0.2546738111055814, "compression_ratio": 1.7837837837837838, "no_speech_prob": 0.0014784663217142224}, {"id": 292, "seek": 92232, "start": 945.0, "end": 947.6800000000001, "text": " and all this type of stuff as the bash installer,", "tokens": [51498, 293, 439, 341, 2010, 295, 1507, 382, 264, 46183, 46620, 11, 51632], "temperature": 0.0, "avg_logprob": -0.2546738111055814, "compression_ratio": 1.7837837837837838, "no_speech_prob": 0.0014784663217142224}, {"id": 293, "seek": 94768, "start": 948.68, "end": 952.4399999999999, "text": " but you can do this through like MDM tools", "tokens": [50414, 457, 291, 393, 360, 341, 807, 411, 22521, 44, 3873, 50602], "temperature": 0.0, "avg_logprob": -0.13648346887118573, "compression_ratio": 1.7588652482269505, "no_speech_prob": 0.0029812026768922806}, {"id": 294, "seek": 94768, "start": 952.4399999999999, "end": 954.0, "text": " and things like that.", "tokens": [50602, 293, 721, 411, 300, 13, 50680], "temperature": 0.0, "avg_logprob": -0.13648346887118573, "compression_ratio": 1.7588652482269505, "no_speech_prob": 0.0029812026768922806}, {"id": 295, "seek": 94768, "start": 954.0, "end": 955.28, "text": " But as I mentioned earlier,", "tokens": [50680, 583, 382, 286, 2835, 3071, 11, 50744], "temperature": 0.0, "avg_logprob": -0.13648346887118573, "compression_ratio": 1.7588652482269505, "no_speech_prob": 0.0029812026768922806}, {"id": 296, "seek": 94768, "start": 955.28, "end": 956.68, "text": " I've actually been working on a few little bits", "tokens": [50744, 286, 600, 767, 668, 1364, 322, 257, 1326, 707, 9239, 50814], "temperature": 0.0, "avg_logprob": -0.13648346887118573, "compression_ratio": 1.7588652482269505, "no_speech_prob": 0.0029812026768922806}, {"id": 297, "seek": 94768, "start": 956.68, "end": 959.28, "text": " which are kind of not strictly homebrew related.", "tokens": [50814, 597, 366, 733, 295, 406, 20792, 1280, 65, 2236, 4077, 13, 50944], "temperature": 0.0, "avg_logprob": -0.13648346887118573, "compression_ratio": 1.7588652482269505, "no_speech_prob": 0.0029812026768922806}, {"id": 298, "seek": 94768, "start": 959.28, "end": 960.7199999999999, "text": " So I've been working on workbrew,", "tokens": [50944, 407, 286, 600, 668, 1364, 322, 589, 65, 2236, 11, 51016], "temperature": 0.0, "avg_logprob": -0.13648346887118573, "compression_ratio": 1.7588652482269505, "no_speech_prob": 0.0029812026768922806}, {"id": 299, "seek": 94768, "start": 960.7199999999999, "end": 963.92, "text": " which is this thing where we're building kind of", "tokens": [51016, 597, 307, 341, 551, 689, 321, 434, 2390, 733, 295, 51176], "temperature": 0.0, "avg_logprob": -0.13648346887118573, "compression_ratio": 1.7588652482269505, "no_speech_prob": 0.0029812026768922806}, {"id": 300, "seek": 94768, "start": 963.92, "end": 965.92, "text": " some close source stuff on top of work,", "tokens": [51176, 512, 1998, 4009, 1507, 322, 1192, 295, 589, 11, 51276], "temperature": 0.0, "avg_logprob": -0.13648346887118573, "compression_ratio": 1.7588652482269505, "no_speech_prob": 0.0029812026768922806}, {"id": 301, "seek": 94768, "start": 965.92, "end": 970.28, "text": " on top of homebrew to try and kind of find this balance", "tokens": [51276, 322, 1192, 295, 1280, 65, 2236, 281, 853, 293, 733, 295, 915, 341, 4772, 51494], "temperature": 0.0, "avg_logprob": -0.13648346887118573, "compression_ratio": 1.7588652482269505, "no_speech_prob": 0.0029812026768922806}, {"id": 302, "seek": 94768, "start": 970.28, "end": 971.3599999999999, "text": " where there's been a bunch of things", "tokens": [51494, 689, 456, 311, 668, 257, 3840, 295, 721, 51548], "temperature": 0.0, "avg_logprob": -0.13648346887118573, "compression_ratio": 1.7588652482269505, "no_speech_prob": 0.0029812026768922806}, {"id": 303, "seek": 94768, "start": 971.3599999999999, "end": 973.3599999999999, "text": " where like the package is an example of one", "tokens": [51548, 689, 411, 264, 7372, 307, 364, 1365, 295, 472, 51648], "temperature": 0.0, "avg_logprob": -0.13648346887118573, "compression_ratio": 1.7588652482269505, "no_speech_prob": 0.0029812026768922806}, {"id": 304, "seek": 94768, "start": 973.3599999999999, "end": 975.92, "text": " where people have asked for it over the years,", "tokens": [51648, 689, 561, 362, 2351, 337, 309, 670, 264, 924, 11, 51776], "temperature": 0.0, "avg_logprob": -0.13648346887118573, "compression_ratio": 1.7588652482269505, "no_speech_prob": 0.0029812026768922806}, {"id": 305, "seek": 97592, "start": 976.04, "end": 978.0, "text": " some people wanted to get involved and built that,", "tokens": [50370, 512, 561, 1415, 281, 483, 3288, 293, 3094, 300, 11, 50468], "temperature": 0.0, "avg_logprob": -0.14024919240262496, "compression_ratio": 1.845505617977528, "no_speech_prob": 0.0036393525078892708}, {"id": 306, "seek": 97592, "start": 978.0, "end": 979.28, "text": " and that's all fine.", "tokens": [50468, 293, 300, 311, 439, 2489, 13, 50532], "temperature": 0.0, "avg_logprob": -0.14024919240262496, "compression_ratio": 1.845505617977528, "no_speech_prob": 0.0036393525078892708}, {"id": 307, "seek": 97592, "start": 979.28, "end": 981.12, "text": " Whereas on workbrew, there's been a bunch of stuff", "tokens": [50532, 13813, 322, 589, 65, 2236, 11, 456, 311, 668, 257, 3840, 295, 1507, 50624], "temperature": 0.0, "avg_logprob": -0.14024919240262496, "compression_ratio": 1.845505617977528, "no_speech_prob": 0.0036393525078892708}, {"id": 308, "seek": 97592, "start": 981.12, "end": 982.4799999999999, "text": " that people have asked for over the years", "tokens": [50624, 300, 561, 362, 2351, 337, 670, 264, 924, 50692], "temperature": 0.0, "avg_logprob": -0.14024919240262496, "compression_ratio": 1.845505617977528, "no_speech_prob": 0.0036393525078892708}, {"id": 309, "seek": 97592, "start": 982.4799999999999, "end": 985.7199999999999, "text": " and I've asked for it, it's homebrew volunteers", "tokens": [50692, 293, 286, 600, 2351, 337, 309, 11, 309, 311, 1280, 65, 2236, 14352, 50854], "temperature": 0.0, "avg_logprob": -0.14024919240262496, "compression_ratio": 1.845505617977528, "no_speech_prob": 0.0036393525078892708}, {"id": 310, "seek": 97592, "start": 985.7199999999999, "end": 988.4799999999999, "text": " and they don't want to do it, say okay, well fine,", "tokens": [50854, 293, 436, 500, 380, 528, 281, 360, 309, 11, 584, 1392, 11, 731, 2489, 11, 50992], "temperature": 0.0, "avg_logprob": -0.14024919240262496, "compression_ratio": 1.845505617977528, "no_speech_prob": 0.0036393525078892708}, {"id": 311, "seek": 97592, "start": 988.4799999999999, "end": 990.0799999999999, "text": " we can do some of this stuff for you for money.", "tokens": [50992, 321, 393, 360, 512, 295, 341, 1507, 337, 291, 337, 1460, 13, 51072], "temperature": 0.0, "avg_logprob": -0.14024919240262496, "compression_ratio": 1.845505617977528, "no_speech_prob": 0.0036393525078892708}, {"id": 312, "seek": 97592, "start": 990.0799999999999, "end": 991.68, "text": " So we have our own package here now,", "tokens": [51072, 407, 321, 362, 527, 1065, 7372, 510, 586, 11, 51152], "temperature": 0.0, "avg_logprob": -0.14024919240262496, "compression_ratio": 1.845505617977528, "no_speech_prob": 0.0036393525078892708}, {"id": 313, "seek": 97592, "start": 991.68, "end": 994.7199999999999, "text": " which does a few more things than the homebrew one does", "tokens": [51152, 597, 775, 257, 1326, 544, 721, 813, 264, 1280, 65, 2236, 472, 775, 51304], "temperature": 0.0, "avg_logprob": -0.14024919240262496, "compression_ratio": 1.845505617977528, "no_speech_prob": 0.0036393525078892708}, {"id": 314, "seek": 97592, "start": 994.7199999999999, "end": 995.56, "text": " and stuff like that.", "tokens": [51304, 293, 1507, 411, 300, 13, 51346], "temperature": 0.0, "avg_logprob": -0.14024919240262496, "compression_ratio": 1.845505617977528, "no_speech_prob": 0.0036393525078892708}, {"id": 315, "seek": 97592, "start": 995.56, "end": 996.8, "text": " Not going to go on about workbrew too much,", "tokens": [51346, 1726, 516, 281, 352, 322, 466, 589, 65, 2236, 886, 709, 11, 51408], "temperature": 0.0, "avg_logprob": -0.14024919240262496, "compression_ratio": 1.845505617977528, "no_speech_prob": 0.0036393525078892708}, {"id": 316, "seek": 97592, "start": 996.8, "end": 999.8, "text": " but if you are interested, go and have a look at our website", "tokens": [51408, 457, 498, 291, 366, 3102, 11, 352, 293, 362, 257, 574, 412, 527, 3144, 51558], "temperature": 0.0, "avg_logprob": -0.14024919240262496, "compression_ratio": 1.845505617977528, "no_speech_prob": 0.0036393525078892708}, {"id": 317, "seek": 97592, "start": 999.8, "end": 1001.36, "text": " and there's a little demo of like what we're doing", "tokens": [51558, 293, 456, 311, 257, 707, 10723, 295, 411, 437, 321, 434, 884, 51636], "temperature": 0.0, "avg_logprob": -0.14024919240262496, "compression_ratio": 1.845505617977528, "no_speech_prob": 0.0036393525078892708}, {"id": 318, "seek": 97592, "start": 1001.36, "end": 1002.92, "text": " and we're kind of recruiting people", "tokens": [51636, 293, 321, 434, 733, 295, 25987, 561, 51714], "temperature": 0.0, "avg_logprob": -0.14024919240262496, "compression_ratio": 1.845505617977528, "no_speech_prob": 0.0036393525078892708}, {"id": 319, "seek": 97592, "start": 1002.92, "end": 1004.36, "text": " who we want to work with on this stuff.", "tokens": [51714, 567, 321, 528, 281, 589, 365, 322, 341, 1507, 13, 51786], "temperature": 0.0, "avg_logprob": -0.14024919240262496, "compression_ratio": 1.845505617977528, "no_speech_prob": 0.0036393525078892708}, {"id": 320, "seek": 100436, "start": 1004.4, "end": 1005.64, "text": " So get in touch.", "tokens": [50366, 407, 483, 294, 2557, 13, 50428], "temperature": 0.0, "avg_logprob": -0.15913936865590786, "compression_ratio": 1.7377622377622377, "no_speech_prob": 0.0016165971755981445}, {"id": 321, "seek": 100436, "start": 1006.72, "end": 1009.0, "text": " But on homebrew stuff,", "tokens": [50482, 583, 322, 1280, 65, 2236, 1507, 11, 50596], "temperature": 0.0, "avg_logprob": -0.15913936865590786, "compression_ratio": 1.7377622377622377, "no_speech_prob": 0.0016165971755981445}, {"id": 322, "seek": 100436, "start": 1009.0, "end": 1010.4, "text": " that's looking forward to the next year.", "tokens": [50596, 300, 311, 1237, 2128, 281, 264, 958, 1064, 13, 50666], "temperature": 0.0, "avg_logprob": -0.15913936865590786, "compression_ratio": 1.7377622377622377, "no_speech_prob": 0.0016165971755981445}, {"id": 323, "seek": 100436, "start": 1010.4, "end": 1015.4, "text": " So we meet together as kind of a homebrew group each year,", "tokens": [50666, 407, 321, 1677, 1214, 382, 733, 295, 257, 1280, 65, 2236, 1594, 1184, 1064, 11, 50916], "temperature": 0.0, "avg_logprob": -0.15913936865590786, "compression_ratio": 1.7377622377622377, "no_speech_prob": 0.0016165971755981445}, {"id": 324, "seek": 100436, "start": 1015.5600000000001, "end": 1017.52, "text": " so I'm not entirely sure what our roadmap is,", "tokens": [50924, 370, 286, 478, 406, 7696, 988, 437, 527, 35738, 307, 11, 51022], "temperature": 0.0, "avg_logprob": -0.15913936865590786, "compression_ratio": 1.7377622377622377, "no_speech_prob": 0.0016165971755981445}, {"id": 325, "seek": 100436, "start": 1017.52, "end": 1019.6800000000001, "text": " we're going to kind of try and decide some things tomorrow,", "tokens": [51022, 321, 434, 516, 281, 733, 295, 853, 293, 4536, 512, 721, 4153, 11, 51130], "temperature": 0.0, "avg_logprob": -0.15913936865590786, "compression_ratio": 1.7377622377622377, "no_speech_prob": 0.0016165971755981445}, {"id": 326, "seek": 100436, "start": 1019.6800000000001, "end": 1022.6, "text": " maybe as a group, kind of figure out like what we see", "tokens": [51130, 1310, 382, 257, 1594, 11, 733, 295, 2573, 484, 411, 437, 321, 536, 51276], "temperature": 0.0, "avg_logprob": -0.15913936865590786, "compression_ratio": 1.7377622377622377, "no_speech_prob": 0.0016165971755981445}, {"id": 327, "seek": 100436, "start": 1022.6, "end": 1023.5600000000001, "text": " as the most important things,", "tokens": [51276, 382, 264, 881, 1021, 721, 11, 51324], "temperature": 0.0, "avg_logprob": -0.15913936865590786, "compression_ratio": 1.7377622377622377, "no_speech_prob": 0.0016165971755981445}, {"id": 328, "seek": 100436, "start": 1023.5600000000001, "end": 1026.76, "text": " but some ideas kind of I've seen flipping around", "tokens": [51324, 457, 512, 3487, 733, 295, 286, 600, 1612, 26886, 926, 51484], "temperature": 0.0, "avg_logprob": -0.15913936865590786, "compression_ratio": 1.7377622377622377, "no_speech_prob": 0.0016165971755981445}, {"id": 329, "seek": 100436, "start": 1026.76, "end": 1028.4, "text": " and things that I have", "tokens": [51484, 293, 721, 300, 286, 362, 51566], "temperature": 0.0, "avg_logprob": -0.15913936865590786, "compression_ratio": 1.7377622377622377, "no_speech_prob": 0.0016165971755981445}, {"id": 330, "seek": 100436, "start": 1028.4, "end": 1031.32, "text": " and kind of have currently open issues for them", "tokens": [51566, 293, 733, 295, 362, 4362, 1269, 2663, 337, 552, 51712], "temperature": 0.0, "avg_logprob": -0.15913936865590786, "compression_ratio": 1.7377622377622377, "no_speech_prob": 0.0016165971755981445}, {"id": 331, "seek": 100436, "start": 1031.32, "end": 1034.16, "text": " or stuff around like handling conflicts better.", "tokens": [51712, 420, 1507, 926, 411, 13175, 19807, 1101, 13, 51854], "temperature": 0.0, "avg_logprob": -0.15913936865590786, "compression_ratio": 1.7377622377622377, "no_speech_prob": 0.0016165971755981445}, {"id": 332, "seek": 103416, "start": 1034.2, "end": 1038.44, "text": " So there's this kind of ability for packages", "tokens": [50366, 407, 456, 311, 341, 733, 295, 3485, 337, 17401, 50578], "temperature": 0.0, "avg_logprob": -0.1561541996949108, "compression_ratio": 1.7597173144876326, "no_speech_prob": 0.00019791640806943178}, {"id": 333, "seek": 103416, "start": 1038.44, "end": 1039.8400000000001, "text": " and homebrew to conflict with each other,", "tokens": [50578, 293, 1280, 65, 2236, 281, 6596, 365, 1184, 661, 11, 50648], "temperature": 0.0, "avg_logprob": -0.1561541996949108, "compression_ratio": 1.7597173144876326, "no_speech_prob": 0.00019791640806943178}, {"id": 334, "seek": 103416, "start": 1039.8400000000001, "end": 1041.8000000000002, "text": " that means you can't have either of them installed,", "tokens": [50648, 300, 1355, 291, 393, 380, 362, 2139, 295, 552, 8899, 11, 50746], "temperature": 0.0, "avg_logprob": -0.1561541996949108, "compression_ratio": 1.7597173144876326, "no_speech_prob": 0.00019791640806943178}, {"id": 335, "seek": 103416, "start": 1041.8000000000002, "end": 1043.0800000000002, "text": " sorry, you can't have both of them installed", "tokens": [50746, 2597, 11, 291, 393, 380, 362, 1293, 295, 552, 8899, 50810], "temperature": 0.0, "avg_logprob": -0.1561541996949108, "compression_ratio": 1.7597173144876326, "no_speech_prob": 0.00019791640806943178}, {"id": 336, "seek": 103416, "start": 1043.0800000000002, "end": 1044.16, "text": " at the same time.", "tokens": [50810, 412, 264, 912, 565, 13, 50864], "temperature": 0.0, "avg_logprob": -0.1561541996949108, "compression_ratio": 1.7597173144876326, "no_speech_prob": 0.00019791640806943178}, {"id": 337, "seek": 103416, "start": 1044.16, "end": 1045.1200000000001, "text": " That's kind of a pain in the ass,", "tokens": [50864, 663, 311, 733, 295, 257, 1822, 294, 264, 1256, 11, 50912], "temperature": 0.0, "avg_logprob": -0.1561541996949108, "compression_ratio": 1.7597173144876326, "no_speech_prob": 0.00019791640806943178}, {"id": 338, "seek": 103416, "start": 1045.1200000000001, "end": 1046.24, "text": " it doesn't really work very nicely,", "tokens": [50912, 309, 1177, 380, 534, 589, 588, 9594, 11, 50968], "temperature": 0.0, "avg_logprob": -0.1561541996949108, "compression_ratio": 1.7597173144876326, "no_speech_prob": 0.00019791640806943178}, {"id": 339, "seek": 103416, "start": 1046.24, "end": 1047.88, "text": " so we're hoping to improve some of that.", "tokens": [50968, 370, 321, 434, 7159, 281, 3470, 512, 295, 300, 13, 51050], "temperature": 0.0, "avg_logprob": -0.1561541996949108, "compression_ratio": 1.7597173144876326, "no_speech_prob": 0.00019791640806943178}, {"id": 340, "seek": 103416, "start": 1047.88, "end": 1050.8400000000001, "text": " There's also kind of inherent conflicts", "tokens": [51050, 821, 311, 611, 733, 295, 26387, 19807, 51198], "temperature": 0.0, "avg_logprob": -0.1561541996949108, "compression_ratio": 1.7597173144876326, "no_speech_prob": 0.00019791640806943178}, {"id": 341, "seek": 103416, "start": 1050.8400000000001, "end": 1053.3600000000001, "text": " between CASCs and formulae.", "tokens": [51198, 1296, 43268, 33290, 293, 8513, 68, 13, 51324], "temperature": 0.0, "avg_logprob": -0.1561541996949108, "compression_ratio": 1.7597173144876326, "no_speech_prob": 0.00019791640806943178}, {"id": 342, "seek": 103416, "start": 1053.3600000000001, "end": 1054.72, "text": " Who feels like they understand", "tokens": [51324, 2102, 3417, 411, 436, 1223, 51392], "temperature": 0.0, "avg_logprob": -0.1561541996949108, "compression_ratio": 1.7597173144876326, "no_speech_prob": 0.00019791640806943178}, {"id": 343, "seek": 103416, "start": 1054.72, "end": 1057.52, "text": " the difference between CASCs and formulae?", "tokens": [51392, 264, 2649, 1296, 43268, 33290, 293, 8513, 68, 30, 51532], "temperature": 0.0, "avg_logprob": -0.1561541996949108, "compression_ratio": 1.7597173144876326, "no_speech_prob": 0.00019791640806943178}, {"id": 344, "seek": 103416, "start": 1057.52, "end": 1060.28, "text": " Okay, only the homebrew maintainers, great.", "tokens": [51532, 1033, 11, 787, 264, 1280, 65, 2236, 6909, 433, 11, 869, 13, 51670], "temperature": 0.0, "avg_logprob": -0.1561541996949108, "compression_ratio": 1.7597173144876326, "no_speech_prob": 0.00019791640806943178}, {"id": 345, "seek": 106028, "start": 1060.32, "end": 1065.32, "text": " So homebrew had this kind of somewhat alternate approach,", "tokens": [50366, 407, 1280, 65, 2236, 632, 341, 733, 295, 8344, 18873, 3109, 11, 50616], "temperature": 0.0, "avg_logprob": -0.11081240995086893, "compression_ratio": 1.792857142857143, "no_speech_prob": 0.00038687605410814285}, {"id": 346, "seek": 106028, "start": 1067.2, "end": 1069.76, "text": " like the kind of integrated with homebrew,", "tokens": [50710, 411, 264, 733, 295, 10919, 365, 1280, 65, 2236, 11, 50838], "temperature": 0.0, "avg_logprob": -0.11081240995086893, "compression_ratio": 1.792857142857143, "no_speech_prob": 0.00038687605410814285}, {"id": 347, "seek": 106028, "start": 1069.76, "end": 1072.24, "text": " but was kind of its own separate ecosystem a few years ago", "tokens": [50838, 457, 390, 733, 295, 1080, 1065, 4994, 11311, 257, 1326, 924, 2057, 50962], "temperature": 0.0, "avg_logprob": -0.11081240995086893, "compression_ratio": 1.792857142857143, "no_speech_prob": 0.00038687605410814285}, {"id": 348, "seek": 106028, "start": 1072.24, "end": 1074.44, "text": " that kind of merged into homebrew proper a few years ago", "tokens": [50962, 300, 733, 295, 36427, 666, 1280, 65, 2236, 2296, 257, 1326, 924, 2057, 51072], "temperature": 0.0, "avg_logprob": -0.11081240995086893, "compression_ratio": 1.792857142857143, "no_speech_prob": 0.00038687605410814285}, {"id": 349, "seek": 106028, "start": 1074.44, "end": 1075.92, "text": " called homebrew CASC.", "tokens": [51072, 1219, 1280, 65, 2236, 43268, 34, 13, 51146], "temperature": 0.0, "avg_logprob": -0.11081240995086893, "compression_ratio": 1.792857142857143, "no_speech_prob": 0.00038687605410814285}, {"id": 350, "seek": 106028, "start": 1075.92, "end": 1080.16, "text": " So homebrew, at least in the official kind of repo,", "tokens": [51146, 407, 1280, 65, 2236, 11, 412, 1935, 294, 264, 4783, 733, 295, 49040, 11, 51358], "temperature": 0.0, "avg_logprob": -0.11081240995086893, "compression_ratio": 1.792857142857143, "no_speech_prob": 0.00038687605410814285}, {"id": 351, "seek": 106028, "start": 1080.16, "end": 1082.0, "text": " is all about taking open source software.", "tokens": [51358, 307, 439, 466, 1940, 1269, 4009, 4722, 13, 51450], "temperature": 0.0, "avg_logprob": -0.11081240995086893, "compression_ratio": 1.792857142857143, "no_speech_prob": 0.00038687605410814285}, {"id": 352, "seek": 106028, "start": 1082.0, "end": 1083.36, "text": " We build it from source,", "tokens": [51450, 492, 1322, 309, 490, 4009, 11, 51518], "temperature": 0.0, "avg_logprob": -0.11081240995086893, "compression_ratio": 1.792857142857143, "no_speech_prob": 0.00038687605410814285}, {"id": 353, "seek": 106028, "start": 1083.36, "end": 1086.0, "text": " we give you binary packages, and then we ship that to you.", "tokens": [51518, 321, 976, 291, 17434, 17401, 11, 293, 550, 321, 5374, 300, 281, 291, 13, 51650], "temperature": 0.0, "avg_logprob": -0.11081240995086893, "compression_ratio": 1.792857142857143, "no_speech_prob": 0.00038687605410814285}, {"id": 354, "seek": 106028, "start": 1086.0, "end": 1087.44, "text": " Homebrew CASC is a little bit different,", "tokens": [51650, 8719, 65, 2236, 43268, 34, 307, 257, 707, 857, 819, 11, 51722], "temperature": 0.0, "avg_logprob": -0.11081240995086893, "compression_ratio": 1.792857142857143, "no_speech_prob": 0.00038687605410814285}, {"id": 355, "seek": 106028, "start": 1087.44, "end": 1089.48, "text": " that's for distributing proprietary software", "tokens": [51722, 300, 311, 337, 41406, 38992, 4722, 51824], "temperature": 0.0, "avg_logprob": -0.11081240995086893, "compression_ratio": 1.792857142857143, "no_speech_prob": 0.00038687605410814285}, {"id": 356, "seek": 108948, "start": 1089.52, "end": 1092.32, "text": " where the upstream package,", "tokens": [50366, 689, 264, 33915, 7372, 11, 50506], "temperature": 0.0, "avg_logprob": -0.17527417878846865, "compression_ratio": 1.7885906040268456, "no_speech_prob": 0.0005900078103877604}, {"id": 357, "seek": 108948, "start": 1092.32, "end": 1094.32, "text": " well, the upstream supplier of the software", "tokens": [50506, 731, 11, 264, 33915, 31909, 295, 264, 4722, 50606], "temperature": 0.0, "avg_logprob": -0.17527417878846865, "compression_ratio": 1.7885906040268456, "no_speech_prob": 0.0005900078103877604}, {"id": 358, "seek": 108948, "start": 1094.32, "end": 1096.16, "text": " provides the binaries for you,", "tokens": [50606, 6417, 264, 5171, 4889, 337, 291, 11, 50698], "temperature": 0.0, "avg_logprob": -0.17527417878846865, "compression_ratio": 1.7885906040268456, "no_speech_prob": 0.0005900078103877604}, {"id": 359, "seek": 108948, "start": 1096.16, "end": 1098.44, "text": " and then we download that and install it for you.", "tokens": [50698, 293, 550, 321, 5484, 300, 293, 3625, 309, 337, 291, 13, 50812], "temperature": 0.0, "avg_logprob": -0.17527417878846865, "compression_ratio": 1.7885906040268456, "no_speech_prob": 0.0005900078103877604}, {"id": 360, "seek": 108948, "start": 1098.44, "end": 1101.52, "text": " So for example, Wget might be a formula,", "tokens": [50812, 407, 337, 1365, 11, 343, 847, 1062, 312, 257, 8513, 11, 50966], "temperature": 0.0, "avg_logprob": -0.17527417878846865, "compression_ratio": 1.7885906040268456, "no_speech_prob": 0.0005900078103877604}, {"id": 361, "seek": 108948, "start": 1101.52, "end": 1102.64, "text": " because we can download the sources", "tokens": [50966, 570, 321, 393, 5484, 264, 7139, 51022], "temperature": 0.0, "avg_logprob": -0.17527417878846865, "compression_ratio": 1.7885906040268456, "no_speech_prob": 0.0005900078103877604}, {"id": 362, "seek": 108948, "start": 1102.64, "end": 1104.04, "text": " and build that from scratch,", "tokens": [51022, 293, 1322, 300, 490, 8459, 11, 51092], "temperature": 0.0, "avg_logprob": -0.17527417878846865, "compression_ratio": 1.7885906040268456, "no_speech_prob": 0.0005900078103877604}, {"id": 363, "seek": 108948, "start": 1104.04, "end": 1106.6, "text": " or something like Google Chrome, or Zoom,", "tokens": [51092, 420, 746, 411, 3329, 15327, 11, 420, 13453, 11, 51220], "temperature": 0.0, "avg_logprob": -0.17527417878846865, "compression_ratio": 1.7885906040268456, "no_speech_prob": 0.0005900078103877604}, {"id": 364, "seek": 108948, "start": 1106.6, "end": 1108.44, "text": " or whatever would be a CASC.", "tokens": [51220, 420, 2035, 576, 312, 257, 43268, 34, 13, 51312], "temperature": 0.0, "avg_logprob": -0.17527417878846865, "compression_ratio": 1.7885906040268456, "no_speech_prob": 0.0005900078103877604}, {"id": 365, "seek": 108948, "start": 1109.72, "end": 1112.92, "text": " So there's some cases in which there are CASC and formula", "tokens": [51376, 407, 456, 311, 512, 3331, 294, 597, 456, 366, 43268, 34, 293, 8513, 51536], "temperature": 0.0, "avg_logprob": -0.17527417878846865, "compression_ratio": 1.7885906040268456, "no_speech_prob": 0.0005900078103877604}, {"id": 366, "seek": 108948, "start": 1112.92, "end": 1115.08, "text": " for the same thing, like Docker, for example,", "tokens": [51536, 337, 264, 912, 551, 11, 411, 33772, 11, 337, 1365, 11, 51644], "temperature": 0.0, "avg_logprob": -0.17527417878846865, "compression_ratio": 1.7885906040268456, "no_speech_prob": 0.0005900078103877604}, {"id": 367, "seek": 108948, "start": 1115.08, "end": 1116.64, "text": " is both an open source project", "tokens": [51644, 307, 1293, 364, 1269, 4009, 1716, 51722], "temperature": 0.0, "avg_logprob": -0.17527417878846865, "compression_ratio": 1.7885906040268456, "no_speech_prob": 0.0005900078103877604}, {"id": 368, "seek": 108948, "start": 1116.64, "end": 1118.0, "text": " that kind of, you get some nice binaries,", "tokens": [51722, 300, 733, 295, 11, 291, 483, 512, 1481, 5171, 4889, 11, 51790], "temperature": 0.0, "avg_logprob": -0.17527417878846865, "compression_ratio": 1.7885906040268456, "no_speech_prob": 0.0005900078103877604}, {"id": 369, "seek": 108948, "start": 1118.0, "end": 1119.2, "text": " you can build from source,", "tokens": [51790, 291, 393, 1322, 490, 4009, 11, 51850], "temperature": 0.0, "avg_logprob": -0.17527417878846865, "compression_ratio": 1.7885906040268456, "no_speech_prob": 0.0005900078103877604}, {"id": 370, "seek": 111920, "start": 1119.2, "end": 1121.68, "text": " but also there's like all the gooey stuff and whatever.", "tokens": [50364, 457, 611, 456, 311, 411, 439, 264, 33192, 2030, 1507, 293, 2035, 13, 50488], "temperature": 0.0, "avg_logprob": -0.12035661585190717, "compression_ratio": 1.7551724137931035, "no_speech_prob": 0.0011229331139475107}, {"id": 371, "seek": 111920, "start": 1121.68, "end": 1124.56, "text": " And if you do, if you install the Docker formula", "tokens": [50488, 400, 498, 291, 360, 11, 498, 291, 3625, 264, 33772, 8513, 50632], "temperature": 0.0, "avg_logprob": -0.12035661585190717, "compression_ratio": 1.7551724137931035, "no_speech_prob": 0.0011229331139475107}, {"id": 372, "seek": 111920, "start": 1124.56, "end": 1127.1200000000001, "text": " and the Docker CASC at the same time,", "tokens": [50632, 293, 264, 33772, 43268, 34, 412, 264, 912, 565, 11, 50760], "temperature": 0.0, "avg_logprob": -0.12035661585190717, "compression_ratio": 1.7551724137931035, "no_speech_prob": 0.0011229331139475107}, {"id": 373, "seek": 111920, "start": 1127.1200000000001, "end": 1129.8, "text": " things get angry and start shouting at you,", "tokens": [50760, 721, 483, 6884, 293, 722, 20382, 412, 291, 11, 50894], "temperature": 0.0, "avg_logprob": -0.12035661585190717, "compression_ratio": 1.7551724137931035, "no_speech_prob": 0.0011229331139475107}, {"id": 374, "seek": 111920, "start": 1129.8, "end": 1131.88, "text": " and it doesn't work very nicely.", "tokens": [50894, 293, 309, 1177, 380, 589, 588, 9594, 13, 50998], "temperature": 0.0, "avg_logprob": -0.12035661585190717, "compression_ratio": 1.7551724137931035, "no_speech_prob": 0.0011229331139475107}, {"id": 375, "seek": 111920, "start": 1131.88, "end": 1133.72, "text": " So that's something that we're probably", "tokens": [50998, 407, 300, 311, 746, 300, 321, 434, 1391, 51090], "temperature": 0.0, "avg_logprob": -0.12035661585190717, "compression_ratio": 1.7551724137931035, "no_speech_prob": 0.0011229331139475107}, {"id": 376, "seek": 111920, "start": 1133.72, "end": 1135.32, "text": " gonna try and make better this year.", "tokens": [51090, 799, 853, 293, 652, 1101, 341, 1064, 13, 51170], "temperature": 0.0, "avg_logprob": -0.12035661585190717, "compression_ratio": 1.7551724137931035, "no_speech_prob": 0.0011229331139475107}, {"id": 377, "seek": 111920, "start": 1135.32, "end": 1138.0, "text": " Another thing is we're continuing to work on our API stuff,", "tokens": [51170, 3996, 551, 307, 321, 434, 9289, 281, 589, 322, 527, 9362, 1507, 11, 51304], "temperature": 0.0, "avg_logprob": -0.12035661585190717, "compression_ratio": 1.7551724137931035, "no_speech_prob": 0.0011229331139475107}, {"id": 378, "seek": 111920, "start": 1138.0, "end": 1140.28, "text": " we're trying to make it smaller and faster", "tokens": [51304, 321, 434, 1382, 281, 652, 309, 4356, 293, 4663, 51418], "temperature": 0.0, "avg_logprob": -0.12035661585190717, "compression_ratio": 1.7551724137931035, "no_speech_prob": 0.0011229331139475107}, {"id": 379, "seek": 111920, "start": 1140.28, "end": 1142.44, "text": " and consider ways that we can do that", "tokens": [51418, 293, 1949, 2098, 300, 321, 393, 360, 300, 51526], "temperature": 0.0, "avg_logprob": -0.12035661585190717, "compression_ratio": 1.7551724137931035, "no_speech_prob": 0.0011229331139475107}, {"id": 380, "seek": 111920, "start": 1142.44, "end": 1145.0, "text": " to again make that updating experience", "tokens": [51526, 281, 797, 652, 300, 25113, 1752, 51654], "temperature": 0.0, "avg_logprob": -0.12035661585190717, "compression_ratio": 1.7551724137931035, "no_speech_prob": 0.0011229331139475107}, {"id": 381, "seek": 111920, "start": 1145.0, "end": 1146.68, "text": " more pleasant for people to use.", "tokens": [51654, 544, 16232, 337, 561, 281, 764, 13, 51738], "temperature": 0.0, "avg_logprob": -0.12035661585190717, "compression_ratio": 1.7551724137931035, "no_speech_prob": 0.0011229331139475107}, {"id": 382, "seek": 114668, "start": 1147.48, "end": 1148.88, "text": " The other, also the API,", "tokens": [50404, 440, 661, 11, 611, 264, 9362, 11, 50474], "temperature": 0.0, "avg_logprob": -0.16073331698565416, "compression_ratio": 1.644736842105263, "no_speech_prob": 0.0015716308262199163}, {"id": 383, "seek": 114668, "start": 1148.88, "end": 1150.3200000000002, "text": " as someone who's kind of been consuming", "tokens": [50474, 382, 1580, 567, 311, 733, 295, 668, 19867, 50546], "temperature": 0.0, "avg_logprob": -0.16073331698565416, "compression_ratio": 1.644736842105263, "no_speech_prob": 0.0015716308262199163}, {"id": 384, "seek": 114668, "start": 1150.3200000000002, "end": 1153.64, "text": " the Humbrew API a lot recently, it's pretty crap.", "tokens": [50546, 264, 389, 2860, 2236, 9362, 257, 688, 3938, 11, 309, 311, 1238, 12426, 13, 50712], "temperature": 0.0, "avg_logprob": -0.16073331698565416, "compression_ratio": 1.644736842105263, "no_speech_prob": 0.0015716308262199163}, {"id": 385, "seek": 114668, "start": 1153.64, "end": 1157.0, "text": " It was originally kind of created", "tokens": [50712, 467, 390, 7993, 733, 295, 2942, 50880], "temperature": 0.0, "avg_logprob": -0.16073331698565416, "compression_ratio": 1.644736842105263, "no_speech_prob": 0.0015716308262199163}, {"id": 386, "seek": 114668, "start": 1157.0, "end": 1159.4, "text": " in the relatively early days of like,", "tokens": [50880, 294, 264, 7226, 2440, 1708, 295, 411, 11, 51000], "temperature": 0.0, "avg_logprob": -0.16073331698565416, "compression_ratio": 1.644736842105263, "no_speech_prob": 0.0015716308262199163}, {"id": 387, "seek": 114668, "start": 1159.4, "end": 1161.8, "text": " I don't know, 2013 or something like that.", "tokens": [51000, 286, 500, 380, 458, 11, 9012, 420, 746, 411, 300, 13, 51120], "temperature": 0.0, "avg_logprob": -0.16073331698565416, "compression_ratio": 1.644736842105263, "no_speech_prob": 0.0015716308262199163}, {"id": 388, "seek": 114668, "start": 1161.8, "end": 1164.1200000000001, "text": " And we've just kind of bolted on bits at this point", "tokens": [51120, 400, 321, 600, 445, 733, 295, 13436, 292, 322, 9239, 412, 341, 935, 51236], "temperature": 0.0, "avg_logprob": -0.16073331698565416, "compression_ratio": 1.644736842105263, "no_speech_prob": 0.0015716308262199163}, {"id": 389, "seek": 114668, "start": 1164.1200000000001, "end": 1166.6000000000001, "text": " where it's got like six arms and three legs", "tokens": [51236, 689, 309, 311, 658, 411, 2309, 5812, 293, 1045, 5668, 51360], "temperature": 0.0, "avg_logprob": -0.16073331698565416, "compression_ratio": 1.644736842105263, "no_speech_prob": 0.0015716308262199163}, {"id": 390, "seek": 114668, "start": 1166.6000000000001, "end": 1169.64, "text": " and they're all the wrong shape and it's, yeah, yuck.", "tokens": [51360, 293, 436, 434, 439, 264, 2085, 3909, 293, 309, 311, 11, 1338, 11, 288, 1134, 13, 51512], "temperature": 0.0, "avg_logprob": -0.16073331698565416, "compression_ratio": 1.644736842105263, "no_speech_prob": 0.0015716308262199163}, {"id": 391, "seek": 114668, "start": 1169.64, "end": 1172.16, "text": " So hopefully we can have something that's a little bit nicer", "tokens": [51512, 407, 4696, 321, 393, 362, 746, 300, 311, 257, 707, 857, 22842, 51638], "temperature": 0.0, "avg_logprob": -0.16073331698565416, "compression_ratio": 1.644736842105263, "no_speech_prob": 0.0015716308262199163}, {"id": 392, "seek": 114668, "start": 1172.16, "end": 1174.8400000000001, "text": " for people who are kind of trying to integrate with Humbrew", "tokens": [51638, 337, 561, 567, 366, 733, 295, 1382, 281, 13365, 365, 389, 2860, 2236, 51772], "temperature": 0.0, "avg_logprob": -0.16073331698565416, "compression_ratio": 1.644736842105263, "no_speech_prob": 0.0015716308262199163}, {"id": 393, "seek": 117484, "start": 1174.8799999999999, "end": 1177.52, "text": " to use, release this year as well.", "tokens": [50366, 281, 764, 11, 4374, 341, 1064, 382, 731, 13, 50498], "temperature": 0.0, "avg_logprob": -0.11405240955637462, "compression_ratio": 1.745704467353952, "no_speech_prob": 0.002113744616508484}, {"id": 394, "seek": 117484, "start": 1177.52, "end": 1179.6399999999999, "text": " And the stuff I mentioned earlier about upgrades.", "tokens": [50498, 400, 264, 1507, 286, 2835, 3071, 466, 24868, 13, 50604], "temperature": 0.0, "avg_logprob": -0.11405240955637462, "compression_ratio": 1.745704467353952, "no_speech_prob": 0.002113744616508484}, {"id": 395, "seek": 117484, "start": 1179.6399999999999, "end": 1183.28, "text": " So part of the reason Humbrew is often upgrading", "tokens": [50604, 407, 644, 295, 264, 1778, 389, 2860, 2236, 307, 2049, 36249, 50786], "temperature": 0.0, "avg_logprob": -0.11405240955637462, "compression_ratio": 1.745704467353952, "no_speech_prob": 0.002113744616508484}, {"id": 396, "seek": 117484, "start": 1183.28, "end": 1184.84, "text": " everything all the time and people get grumpy", "tokens": [50786, 1203, 439, 264, 565, 293, 561, 483, 677, 36142, 50864], "temperature": 0.0, "avg_logprob": -0.11405240955637462, "compression_ratio": 1.745704467353952, "no_speech_prob": 0.002113744616508484}, {"id": 397, "seek": 117484, "start": 1184.84, "end": 1186.0, "text": " because that's really slow,", "tokens": [50864, 570, 300, 311, 534, 2964, 11, 50922], "temperature": 0.0, "avg_logprob": -0.11405240955637462, "compression_ratio": 1.745704467353952, "no_speech_prob": 0.002113744616508484}, {"id": 398, "seek": 117484, "start": 1186.0, "end": 1187.72, "text": " is because we don't have a good way", "tokens": [50922, 307, 570, 321, 500, 380, 362, 257, 665, 636, 51008], "temperature": 0.0, "avg_logprob": -0.11405240955637462, "compression_ratio": 1.745704467353952, "no_speech_prob": 0.002113744616508484}, {"id": 399, "seek": 117484, "start": 1187.72, "end": 1191.6399999999999, "text": " of figuring out what upgrades are needed and when.", "tokens": [51008, 295, 15213, 484, 437, 24868, 366, 2978, 293, 562, 13, 51204], "temperature": 0.0, "avg_logprob": -0.11405240955637462, "compression_ratio": 1.745704467353952, "no_speech_prob": 0.002113744616508484}, {"id": 400, "seek": 117484, "start": 1191.6399999999999, "end": 1194.9599999999998, "text": " So historically we had the kind of conservative approach", "tokens": [51204, 407, 16180, 321, 632, 264, 733, 295, 13780, 3109, 51370], "temperature": 0.0, "avg_logprob": -0.11405240955637462, "compression_ratio": 1.745704467353952, "no_speech_prob": 0.002113744616508484}, {"id": 401, "seek": 117484, "start": 1194.9599999999998, "end": 1199.28, "text": " of, well, if there's anything else that's new,", "tokens": [51370, 295, 11, 731, 11, 498, 456, 311, 1340, 1646, 300, 311, 777, 11, 51586], "temperature": 0.0, "avg_logprob": -0.11405240955637462, "compression_ratio": 1.745704467353952, "no_speech_prob": 0.002113744616508484}, {"id": 402, "seek": 117484, "start": 1199.28, "end": 1200.76, "text": " that's in your kind of dependency tree,", "tokens": [51586, 300, 311, 294, 428, 733, 295, 33621, 4230, 11, 51660], "temperature": 0.0, "avg_logprob": -0.11405240955637462, "compression_ratio": 1.745704467353952, "no_speech_prob": 0.002113744616508484}, {"id": 403, "seek": 117484, "start": 1200.76, "end": 1203.04, "text": " we will always try and upgrade everything every time", "tokens": [51660, 321, 486, 1009, 853, 293, 11484, 1203, 633, 565, 51774], "temperature": 0.0, "avg_logprob": -0.11405240955637462, "compression_ratio": 1.745704467353952, "no_speech_prob": 0.002113744616508484}, {"id": 404, "seek": 117484, "start": 1203.04, "end": 1204.1999999999998, "text": " just to be safe.", "tokens": [51774, 445, 281, 312, 3273, 13, 51832], "temperature": 0.0, "avg_logprob": -0.11405240955637462, "compression_ratio": 1.745704467353952, "no_speech_prob": 0.002113744616508484}, {"id": 405, "seek": 120420, "start": 1204.2, "end": 1205.76, "text": " But then we realized like, well,", "tokens": [50364, 583, 550, 321, 5334, 411, 11, 731, 11, 50442], "temperature": 0.0, "avg_logprob": -0.12311866177115471, "compression_ratio": 1.7731958762886597, "no_speech_prob": 0.00046222424134612083}, {"id": 406, "seek": 120420, "start": 1205.76, "end": 1207.44, "text": " you upgrade a ton of stuff all the time", "tokens": [50442, 291, 11484, 257, 2952, 295, 1507, 439, 264, 565, 50526], "temperature": 0.0, "avg_logprob": -0.12311866177115471, "compression_ratio": 1.7731958762886597, "no_speech_prob": 0.00046222424134612083}, {"id": 407, "seek": 120420, "start": 1207.44, "end": 1210.56, "text": " and then that makes people sad and angry on the internet", "tokens": [50526, 293, 550, 300, 1669, 561, 4227, 293, 6884, 322, 264, 4705, 50682], "temperature": 0.0, "avg_logprob": -0.12311866177115471, "compression_ratio": 1.7731958762886597, "no_speech_prob": 0.00046222424134612083}, {"id": 408, "seek": 120420, "start": 1210.56, "end": 1211.96, "text": " and all this type of stuff.", "tokens": [50682, 293, 439, 341, 2010, 295, 1507, 13, 50752], "temperature": 0.0, "avg_logprob": -0.12311866177115471, "compression_ratio": 1.7731958762886597, "no_speech_prob": 0.00046222424134612083}, {"id": 409, "seek": 120420, "start": 1211.96, "end": 1214.28, "text": " So then what I mentioned we did last year", "tokens": [50752, 407, 550, 437, 286, 2835, 321, 630, 1036, 1064, 50868], "temperature": 0.0, "avg_logprob": -0.12311866177115471, "compression_ratio": 1.7731958762886597, "no_speech_prob": 0.00046222424134612083}, {"id": 410, "seek": 120420, "start": 1214.28, "end": 1217.4, "text": " was we basically said, well, we can kind of infer a little bit", "tokens": [50868, 390, 321, 1936, 848, 11, 731, 11, 321, 393, 733, 295, 13596, 257, 707, 857, 51024], "temperature": 0.0, "avg_logprob": -0.12311866177115471, "compression_ratio": 1.7731958762886597, "no_speech_prob": 0.00046222424134612083}, {"id": 411, "seek": 120420, "start": 1217.4, "end": 1219.76, "text": " from the way the binary packages were built.", "tokens": [51024, 490, 264, 636, 264, 17434, 17401, 645, 3094, 13, 51142], "temperature": 0.0, "avg_logprob": -0.12311866177115471, "compression_ratio": 1.7731958762886597, "no_speech_prob": 0.00046222424134612083}, {"id": 412, "seek": 120420, "start": 1219.76, "end": 1223.72, "text": " The binary package was built with OpenSL 1.1.1", "tokens": [51142, 440, 17434, 7372, 390, 3094, 365, 7238, 47012, 502, 13, 16, 13, 16, 51340], "temperature": 0.0, "avg_logprob": -0.12311866177115471, "compression_ratio": 1.7731958762886597, "no_speech_prob": 0.00046222424134612083}, {"id": 413, "seek": 120420, "start": 1223.72, "end": 1225.96, "text": " and now we have OpenSL 1.1.2.", "tokens": [51340, 293, 586, 321, 362, 7238, 47012, 502, 13, 16, 13, 17, 13, 51452], "temperature": 0.0, "avg_logprob": -0.12311866177115471, "compression_ratio": 1.7731958762886597, "no_speech_prob": 0.00046222424134612083}, {"id": 414, "seek": 120420, "start": 1225.96, "end": 1228.52, "text": " We know that this package doesn't need 1.1.2", "tokens": [51452, 492, 458, 300, 341, 7372, 1177, 380, 643, 502, 13, 16, 13, 17, 51580], "temperature": 0.0, "avg_logprob": -0.12311866177115471, "compression_ratio": 1.7731958762886597, "no_speech_prob": 0.00046222424134612083}, {"id": 415, "seek": 120420, "start": 1228.52, "end": 1230.56, "text": " so we don't have to upgrade it, yada, yada, yada.", "tokens": [51580, 370, 321, 500, 380, 362, 281, 11484, 309, 11, 288, 1538, 11, 288, 1538, 11, 288, 1538, 13, 51682], "temperature": 0.0, "avg_logprob": -0.12311866177115471, "compression_ratio": 1.7731958762886597, "no_speech_prob": 0.00046222424134612083}, {"id": 416, "seek": 120420, "start": 1230.56, "end": 1232.68, "text": " But hopefully we actually have like,", "tokens": [51682, 583, 4696, 321, 767, 362, 411, 11, 51788], "temperature": 0.0, "avg_logprob": -0.12311866177115471, "compression_ratio": 1.7731958762886597, "no_speech_prob": 0.00046222424134612083}, {"id": 417, "seek": 123268, "start": 1232.68, "end": 1235.5600000000002, "text": " there's a lot of the kind of bigger, proper package managers", "tokens": [50364, 456, 311, 257, 688, 295, 264, 733, 295, 3801, 11, 2296, 7372, 14084, 50508], "temperature": 0.0, "avg_logprob": -0.1781016562482436, "compression_ratio": 1.728658536585366, "no_speech_prob": 0.00136978377122432}, {"id": 418, "seek": 123268, "start": 1235.5600000000002, "end": 1239.0, "text": " and distributions have like actual like ABI", "tokens": [50508, 293, 37870, 362, 411, 3539, 411, 316, 11291, 50680], "temperature": 0.0, "avg_logprob": -0.1781016562482436, "compression_ratio": 1.728658536585366, "no_speech_prob": 0.00136978377122432}, {"id": 419, "seek": 123268, "start": 1239.0, "end": 1241.28, "text": " which stands for application binary interface,", "tokens": [50680, 597, 7382, 337, 3861, 17434, 9226, 11, 50794], "temperature": 0.0, "avg_logprob": -0.1781016562482436, "compression_ratio": 1.728658536585366, "no_speech_prob": 0.00136978377122432}, {"id": 420, "seek": 123268, "start": 1241.28, "end": 1244.16, "text": " essentially like what libraries you can link again", "tokens": [50794, 4476, 411, 437, 15148, 291, 393, 2113, 797, 50938], "temperature": 0.0, "avg_logprob": -0.1781016562482436, "compression_ratio": 1.728658536585366, "no_speech_prob": 0.00136978377122432}, {"id": 421, "seek": 123268, "start": 1244.16, "end": 1246.68, "text": " and change the versions without breaking things.", "tokens": [50938, 293, 1319, 264, 9606, 1553, 7697, 721, 13, 51064], "temperature": 0.0, "avg_logprob": -0.1781016562482436, "compression_ratio": 1.728658536585366, "no_speech_prob": 0.00136978377122432}, {"id": 422, "seek": 123268, "start": 1246.68, "end": 1248.24, "text": " They have a lot of tooling around that stuff", "tokens": [51064, 814, 362, 257, 688, 295, 46593, 926, 300, 1507, 51142], "temperature": 0.0, "avg_logprob": -0.1781016562482436, "compression_ratio": 1.728658536585366, "no_speech_prob": 0.00136978377122432}, {"id": 423, "seek": 123268, "start": 1248.24, "end": 1250.92, "text": " that we could kind of adopt and similarly like we can have a way,", "tokens": [51142, 300, 321, 727, 733, 295, 6878, 293, 14138, 411, 321, 393, 362, 257, 636, 11, 51276], "temperature": 0.0, "avg_logprob": -0.1781016562482436, "compression_ratio": 1.728658536585366, "no_speech_prob": 0.00136978377122432}, {"id": 424, "seek": 123268, "start": 1250.92, "end": 1252.76, "text": " even with our existing tooling to kind of make this stuff", "tokens": [51276, 754, 365, 527, 6741, 46593, 281, 733, 295, 652, 341, 1507, 51368], "temperature": 0.0, "avg_logprob": -0.1781016562482436, "compression_ratio": 1.728658536585366, "no_speech_prob": 0.00136978377122432}, {"id": 425, "seek": 123268, "start": 1252.76, "end": 1254.68, "text": " a little bit more explicit, which would mean", "tokens": [51368, 257, 707, 857, 544, 13691, 11, 597, 576, 914, 51464], "temperature": 0.0, "avg_logprob": -0.1781016562482436, "compression_ratio": 1.728658536585366, "no_speech_prob": 0.00136978377122432}, {"id": 426, "seek": 123268, "start": 1254.68, "end": 1256.6000000000001, "text": " that we don't need to upgrade as much stuff", "tokens": [51464, 300, 321, 500, 380, 643, 281, 11484, 382, 709, 1507, 51560], "temperature": 0.0, "avg_logprob": -0.1781016562482436, "compression_ratio": 1.728658536585366, "no_speech_prob": 0.00136978377122432}, {"id": 427, "seek": 123268, "start": 1256.6000000000001, "end": 1257.6000000000001, "text": " as much of the time.", "tokens": [51560, 382, 709, 295, 264, 565, 13, 51610], "temperature": 0.0, "avg_logprob": -0.1781016562482436, "compression_ratio": 1.728658536585366, "no_speech_prob": 0.00136978377122432}, {"id": 428, "seek": 123268, "start": 1258.8400000000001, "end": 1260.92, "text": " But because we're an OpenSL project,", "tokens": [51672, 583, 570, 321, 434, 364, 7238, 47012, 1716, 11, 51776], "temperature": 0.0, "avg_logprob": -0.1781016562482436, "compression_ratio": 1.728658536585366, "no_speech_prob": 0.00136978377122432}, {"id": 429, "seek": 126092, "start": 1260.96, "end": 1262.68, "text": " maybe what we do in the last year", "tokens": [50366, 1310, 437, 321, 360, 294, 264, 1036, 1064, 50452], "temperature": 0.0, "avg_logprob": -0.13883668354579382, "compression_ratio": 1.8424657534246576, "no_speech_prob": 0.0029413029551506042}, {"id": 430, "seek": 126092, "start": 1262.68, "end": 1264.52, "text": " will be something that we haven't thought of yet,", "tokens": [50452, 486, 312, 746, 300, 321, 2378, 380, 1194, 295, 1939, 11, 50544], "temperature": 0.0, "avg_logprob": -0.13883668354579382, "compression_ratio": 1.8424657534246576, "no_speech_prob": 0.0029413029551506042}, {"id": 431, "seek": 126092, "start": 1264.52, "end": 1267.44, "text": " that we think of because someone in this room", "tokens": [50544, 300, 321, 519, 295, 570, 1580, 294, 341, 1808, 50690], "temperature": 0.0, "avg_logprob": -0.13883668354579382, "compression_ratio": 1.8424657534246576, "no_speech_prob": 0.0029413029551506042}, {"id": 432, "seek": 126092, "start": 1267.44, "end": 1271.16, "text": " has a good idea in a pull request or you file a bug report", "tokens": [50690, 575, 257, 665, 1558, 294, 257, 2235, 5308, 420, 291, 3991, 257, 7426, 2275, 50876], "temperature": 0.0, "avg_logprob": -0.13883668354579382, "compression_ratio": 1.8424657534246576, "no_speech_prob": 0.0029413029551506042}, {"id": 433, "seek": 126092, "start": 1271.16, "end": 1273.96, "text": " and then that makes us think of something that's smart", "tokens": [50876, 293, 550, 300, 1669, 505, 519, 295, 746, 300, 311, 4069, 51016], "temperature": 0.0, "avg_logprob": -0.13883668354579382, "compression_ratio": 1.8424657534246576, "no_speech_prob": 0.0029413029551506042}, {"id": 434, "seek": 126092, "start": 1273.96, "end": 1275.3600000000001, "text": " and then we go and do something in a clever way", "tokens": [51016, 293, 550, 321, 352, 293, 360, 746, 294, 257, 13494, 636, 51086], "temperature": 0.0, "avg_logprob": -0.13883668354579382, "compression_ratio": 1.8424657534246576, "no_speech_prob": 0.0029413029551506042}, {"id": 435, "seek": 126092, "start": 1275.3600000000001, "end": 1278.2, "text": " or you file a really well written feature request", "tokens": [51086, 420, 291, 3991, 257, 534, 731, 3720, 4111, 5308, 51228], "temperature": 0.0, "avg_logprob": -0.13883668354579382, "compression_ratio": 1.8424657534246576, "no_speech_prob": 0.0029413029551506042}, {"id": 436, "seek": 126092, "start": 1278.2, "end": 1279.8000000000002, "text": " that then inspires us to do something cool.", "tokens": [51228, 300, 550, 32566, 505, 281, 360, 746, 1627, 13, 51308], "temperature": 0.0, "avg_logprob": -0.13883668354579382, "compression_ratio": 1.8424657534246576, "no_speech_prob": 0.0029413029551506042}, {"id": 437, "seek": 126092, "start": 1279.8000000000002, "end": 1282.16, "text": " So I really encourage you,", "tokens": [51308, 407, 286, 534, 5373, 291, 11, 51426], "temperature": 0.0, "avg_logprob": -0.13883668354579382, "compression_ratio": 1.8424657534246576, "no_speech_prob": 0.0029413029551506042}, {"id": 438, "seek": 126092, "start": 1282.16, "end": 1283.1200000000001, "text": " even if you've never been involved", "tokens": [51426, 754, 498, 291, 600, 1128, 668, 3288, 51474], "temperature": 0.0, "avg_logprob": -0.13883668354579382, "compression_ratio": 1.8424657534246576, "no_speech_prob": 0.0029413029551506042}, {"id": 439, "seek": 126092, "start": 1283.1200000000001, "end": 1284.6000000000001, "text": " in an OpenSource project before,", "tokens": [51474, 294, 364, 7238, 50, 2948, 1716, 949, 11, 51548], "temperature": 0.0, "avg_logprob": -0.13883668354579382, "compression_ratio": 1.8424657534246576, "no_speech_prob": 0.0029413029551506042}, {"id": 440, "seek": 126092, "start": 1284.6000000000001, "end": 1288.1200000000001, "text": " we're generally, myself excluded, a fairly friendly bunch", "tokens": [51548, 321, 434, 5101, 11, 2059, 29486, 11, 257, 6457, 9208, 3840, 51724], "temperature": 0.0, "avg_logprob": -0.13883668354579382, "compression_ratio": 1.8424657534246576, "no_speech_prob": 0.0029413029551506042}, {"id": 441, "seek": 128812, "start": 1288.36, "end": 1291.9199999999998, "text": " and we will all try and help you get involved with Homebrew", "tokens": [50376, 293, 321, 486, 439, 853, 293, 854, 291, 483, 3288, 365, 8719, 65, 2236, 50554], "temperature": 0.0, "avg_logprob": -0.09853216087293325, "compression_ratio": 1.976027397260274, "no_speech_prob": 0.0035884047392755747}, {"id": 442, "seek": 128812, "start": 1291.9199999999998, "end": 1294.08, "text": " and help you along the way,", "tokens": [50554, 293, 854, 291, 2051, 264, 636, 11, 50662], "temperature": 0.0, "avg_logprob": -0.09853216087293325, "compression_ratio": 1.976027397260274, "no_speech_prob": 0.0035884047392755747}, {"id": 443, "seek": 128812, "start": 1294.08, "end": 1295.6399999999999, "text": " particularly with something like a pull request,", "tokens": [50662, 4098, 365, 746, 411, 257, 2235, 5308, 11, 50740], "temperature": 0.0, "avg_logprob": -0.09853216087293325, "compression_ratio": 1.976027397260274, "no_speech_prob": 0.0035884047392755747}, {"id": 444, "seek": 128812, "start": 1295.6399999999999, "end": 1299.2399999999998, "text": " like if you have an idea and you think you can kind of make it happen", "tokens": [50740, 411, 498, 291, 362, 364, 1558, 293, 291, 519, 291, 393, 733, 295, 652, 309, 1051, 50920], "temperature": 0.0, "avg_logprob": -0.09853216087293325, "compression_ratio": 1.976027397260274, "no_speech_prob": 0.0035884047392755747}, {"id": 445, "seek": 128812, "start": 1299.2399999999998, "end": 1302.52, "text": " and you can write some code in some sort of form,", "tokens": [50920, 293, 291, 393, 2464, 512, 3089, 294, 512, 1333, 295, 1254, 11, 51084], "temperature": 0.0, "avg_logprob": -0.09853216087293325, "compression_ratio": 1.976027397260274, "no_speech_prob": 0.0035884047392755747}, {"id": 446, "seek": 128812, "start": 1302.52, "end": 1305.04, "text": " even if it's only like 10% of the way to working,", "tokens": [51084, 754, 498, 309, 311, 787, 411, 1266, 4, 295, 264, 636, 281, 1364, 11, 51210], "temperature": 0.0, "avg_logprob": -0.09853216087293325, "compression_ratio": 1.976027397260274, "no_speech_prob": 0.0035884047392755747}, {"id": 447, "seek": 128812, "start": 1305.04, "end": 1307.0, "text": " feel free to open a pull request and then just say,", "tokens": [51210, 841, 1737, 281, 1269, 257, 2235, 5308, 293, 550, 445, 584, 11, 51308], "temperature": 0.0, "avg_logprob": -0.09853216087293325, "compression_ratio": 1.976027397260274, "no_speech_prob": 0.0035884047392755747}, {"id": 448, "seek": 128812, "start": 1307.0, "end": 1310.2399999999998, "text": " hey, like this is what I tried, this is what I need help with,", "tokens": [51308, 4177, 11, 411, 341, 307, 437, 286, 3031, 11, 341, 307, 437, 286, 643, 854, 365, 11, 51470], "temperature": 0.0, "avg_logprob": -0.09853216087293325, "compression_ratio": 1.976027397260274, "no_speech_prob": 0.0035884047392755747}, {"id": 449, "seek": 128812, "start": 1310.2399999999998, "end": 1311.76, "text": " and then we can kind of help you along the way.", "tokens": [51470, 293, 550, 321, 393, 733, 295, 854, 291, 2051, 264, 636, 13, 51546], "temperature": 0.0, "avg_logprob": -0.09853216087293325, "compression_ratio": 1.976027397260274, "no_speech_prob": 0.0035884047392755747}, {"id": 450, "seek": 128812, "start": 1311.76, "end": 1314.4399999999998, "text": " It's often much easier to talk about the code", "tokens": [51546, 467, 311, 2049, 709, 3571, 281, 751, 466, 264, 3089, 51680], "temperature": 0.0, "avg_logprob": -0.09853216087293325, "compression_ratio": 1.976027397260274, "no_speech_prob": 0.0035884047392755747}, {"id": 451, "seek": 128812, "start": 1314.4399999999998, "end": 1317.76, "text": " than it is to talk about the ideas about the code beforehand.", "tokens": [51680, 813, 309, 307, 281, 751, 466, 264, 3487, 466, 264, 3089, 22893, 13, 51846], "temperature": 0.0, "avg_logprob": -0.09853216087293325, "compression_ratio": 1.976027397260274, "no_speech_prob": 0.0035884047392755747}, {"id": 452, "seek": 131776, "start": 1317.8, "end": 1321.68, "text": " We're not the type of project where every pull request needs an issue", "tokens": [50366, 492, 434, 406, 264, 2010, 295, 1716, 689, 633, 2235, 5308, 2203, 364, 2734, 50560], "temperature": 0.0, "avg_logprob": -0.16391968381577643, "compression_ratio": 1.6876876876876876, "no_speech_prob": 0.00029982897103764117}, {"id": 453, "seek": 131776, "start": 1321.68, "end": 1325.84, "text": " open to beforehand, like we believe in discussing the code whenever you can", "tokens": [50560, 1269, 281, 22893, 11, 411, 321, 1697, 294, 10850, 264, 3089, 5699, 291, 393, 50768], "temperature": 0.0, "avg_logprob": -0.16391968381577643, "compression_ratio": 1.6876876876876876, "no_speech_prob": 0.00029982897103764117}, {"id": 454, "seek": 131776, "start": 1325.84, "end": 1328.72, "text": " rather than kind of discussing some abstract conception", "tokens": [50768, 2831, 813, 733, 295, 10850, 512, 12649, 30698, 50912], "temperature": 0.0, "avg_logprob": -0.16391968381577643, "compression_ratio": 1.6876876876876876, "no_speech_prob": 0.00029982897103764117}, {"id": 455, "seek": 131776, "start": 1328.72, "end": 1332.64, "text": " of what the code might look like when someone decides to write it.", "tokens": [50912, 295, 437, 264, 3089, 1062, 574, 411, 562, 1580, 14898, 281, 2464, 309, 13, 51108], "temperature": 0.0, "avg_logprob": -0.16391968381577643, "compression_ratio": 1.6876876876876876, "no_speech_prob": 0.00029982897103764117}, {"id": 456, "seek": 131776, "start": 1332.64, "end": 1335.0, "text": " So I think we've got a little bit of time for questions now", "tokens": [51108, 407, 286, 519, 321, 600, 658, 257, 707, 857, 295, 565, 337, 1651, 586, 51226], "temperature": 0.0, "avg_logprob": -0.16391968381577643, "compression_ratio": 1.6876876876876876, "no_speech_prob": 0.00029982897103764117}, {"id": 457, "seek": 131776, "start": 1335.0, "end": 1338.96, "text": " and also if you don't feel comfortable asking any questions in this format,", "tokens": [51226, 293, 611, 498, 291, 500, 380, 841, 4619, 3365, 604, 1651, 294, 341, 7877, 11, 51424], "temperature": 0.0, "avg_logprob": -0.16391968381577643, "compression_ratio": 1.6876876876876876, "no_speech_prob": 0.00029982897103764117}, {"id": 458, "seek": 131776, "start": 1338.96, "end": 1340.6, "text": " then feel free to ask me anything privately.", "tokens": [51424, 550, 841, 1737, 281, 1029, 385, 1340, 31919, 13, 51506], "temperature": 0.0, "avg_logprob": -0.16391968381577643, "compression_ratio": 1.6876876876876876, "no_speech_prob": 0.00029982897103764117}, {"id": 459, "seek": 131776, "start": 1340.6, "end": 1343.84, "text": " I'm on Mastodon and Twitter and you can email me and stuff as well.", "tokens": [51506, 286, 478, 322, 376, 525, 378, 266, 293, 5794, 293, 291, 393, 3796, 385, 293, 1507, 382, 731, 13, 51668], "temperature": 0.0, "avg_logprob": -0.16391968381577643, "compression_ratio": 1.6876876876876876, "no_speech_prob": 0.00029982897103764117}, {"id": 460, "seek": 131776, "start": 1343.84, "end": 1345.64, "text": " And yeah, thank you very much for having me.", "tokens": [51668, 400, 1338, 11, 1309, 291, 588, 709, 337, 1419, 385, 13, 51758], "temperature": 0.0, "avg_logprob": -0.16391968381577643, "compression_ratio": 1.6876876876876876, "no_speech_prob": 0.00029982897103764117}, {"id": 461, "seek": 134564, "start": 1345.64, "end": 1352.64, "text": " APPLAUSE", "tokens": [50364, 35298, 50714], "temperature": 0.0, "avg_logprob": -0.5157913366953532, "compression_ratio": 1.1639344262295082, "no_speech_prob": 0.009665243327617645}, {"id": 462, "seek": 134564, "start": 1356.64, "end": 1358.64, "text": " Are there any questions? Oh, all right.", "tokens": [50914, 2014, 456, 604, 1651, 30, 876, 11, 439, 558, 13, 51014], "temperature": 0.0, "avg_logprob": -0.5157913366953532, "compression_ratio": 1.1639344262295082, "no_speech_prob": 0.009665243327617645}, {"id": 463, "seek": 134564, "start": 1367.1200000000001, "end": 1369.4, "text": " Just going to ask, where's the...", "tokens": [51438, 1449, 516, 281, 1029, 11, 689, 311, 264, 485, 51552], "temperature": 0.0, "avg_logprob": -0.5157913366953532, "compression_ratio": 1.1639344262295082, "no_speech_prob": 0.009665243327617645}, {"id": 464, "seek": 134564, "start": 1369.4, "end": 1371.2, "text": " Oh, the beer costume.", "tokens": [51552, 876, 11, 264, 8795, 14850, 13, 51642], "temperature": 0.0, "avg_logprob": -0.5157913366953532, "compression_ratio": 1.1639344262295082, "no_speech_prob": 0.009665243327617645}, {"id": 465, "seek": 134564, "start": 1371.2, "end": 1374.68, "text": " OK, so anyone who was here last year,", "tokens": [51642, 2264, 11, 370, 2878, 567, 390, 510, 1036, 1064, 11, 51816], "temperature": 0.0, "avg_logprob": -0.5157913366953532, "compression_ratio": 1.1639344262295082, "no_speech_prob": 0.009665243327617645}, {"id": 466, "seek": 137468, "start": 1374.68, "end": 1377.92, "text": " I was wearing a head to toe beer costume", "tokens": [50364, 286, 390, 4769, 257, 1378, 281, 13976, 8795, 14850, 50526], "temperature": 0.0, "avg_logprob": -0.28603973962310564, "compression_ratio": 1.6534653465346534, "no_speech_prob": 0.07411077618598938}, {"id": 467, "seek": 137468, "start": 1377.92, "end": 1380.8400000000001, "text": " because I love my Uber maintainer friends,", "tokens": [50526, 570, 286, 959, 452, 21839, 6909, 260, 1855, 11, 50672], "temperature": 0.0, "avg_logprob": -0.28603973962310564, "compression_ratio": 1.6534653465346534, "no_speech_prob": 0.07411077618598938}, {"id": 468, "seek": 137468, "start": 1380.8400000000001, "end": 1383.6000000000001, "text": " but they're not always the most organized bunch.", "tokens": [50672, 457, 436, 434, 406, 1009, 264, 881, 9983, 3840, 13, 50810], "temperature": 0.0, "avg_logprob": -0.28603973962310564, "compression_ratio": 1.6534653465346534, "no_speech_prob": 0.07411077618598938}, {"id": 469, "seek": 137468, "start": 1383.6000000000001, "end": 1388.28, "text": " And someone posted a picture before Fosdame last year saying,", "tokens": [50810, 400, 1580, 9437, 257, 3036, 949, 479, 329, 67, 529, 1036, 1064, 1566, 11, 51044], "temperature": 0.0, "avg_logprob": -0.28603973962310564, "compression_ratio": 1.6534653465346534, "no_speech_prob": 0.07411077618598938}, {"id": 470, "seek": 137468, "start": 1388.28, "end": 1390.24, "text": " like, here's a beer costume.", "tokens": [51044, 411, 11, 510, 311, 257, 8795, 14850, 13, 51142], "temperature": 0.0, "avg_logprob": -0.28603973962310564, "compression_ratio": 1.6534653465346534, "no_speech_prob": 0.07411077618598938}, {"id": 471, "seek": 137468, "start": 1390.24, "end": 1392.4, "text": " Wouldn't it be funny we can make Mike wear this lol?", "tokens": [51142, 26291, 380, 309, 312, 4074, 321, 393, 652, 6602, 3728, 341, 10065, 30, 51250], "temperature": 0.0, "avg_logprob": -0.28603973962310564, "compression_ratio": 1.6534653465346534, "no_speech_prob": 0.07411077618598938}, {"id": 472, "seek": 137468, "start": 1392.4, "end": 1395.8, "text": " And I was like, yeah, basically like challenge accepted.", "tokens": [51250, 400, 286, 390, 411, 11, 1338, 11, 1936, 411, 3430, 9035, 13, 51420], "temperature": 0.0, "avg_logprob": -0.28603973962310564, "compression_ratio": 1.6534653465346534, "no_speech_prob": 0.07411077618598938}, {"id": 473, "seek": 137468, "start": 1395.8, "end": 1397.88, "text": " You're not organized enough to make that happen.", "tokens": [51420, 509, 434, 406, 9983, 1547, 281, 652, 300, 1051, 13, 51524], "temperature": 0.0, "avg_logprob": -0.28603973962310564, "compression_ratio": 1.6534653465346534, "no_speech_prob": 0.07411077618598938}, {"id": 474, "seek": 137468, "start": 1397.88, "end": 1402.1200000000001, "text": " And unfortunately they were and I had to wear a beer costume.", "tokens": [51524, 400, 7015, 436, 645, 293, 286, 632, 281, 3728, 257, 8795, 14850, 13, 51736], "temperature": 0.0, "avg_logprob": -0.28603973962310564, "compression_ratio": 1.6534653465346534, "no_speech_prob": 0.07411077618598938}, {"id": 475, "seek": 137468, "start": 1402.1200000000001, "end": 1404.52, "text": " There are pictures on the Internet. Don't look for them.", "tokens": [51736, 821, 366, 5242, 322, 264, 7703, 13, 1468, 380, 574, 337, 552, 13, 51856], "temperature": 0.0, "avg_logprob": -0.28603973962310564, "compression_ratio": 1.6534653465346534, "no_speech_prob": 0.07411077618598938}, {"id": 476, "seek": 140452, "start": 1405.36, "end": 1407.96, "text": " Thankfully they were not organized enough to bring it this year,", "tokens": [50406, 28344, 436, 645, 406, 9983, 1547, 281, 1565, 309, 341, 1064, 11, 50536], "temperature": 0.0, "avg_logprob": -0.3457265044703628, "compression_ratio": 1.3093922651933703, "no_speech_prob": 0.0008781434735283256}, {"id": 477, "seek": 140452, "start": 1407.96, "end": 1410.24, "text": " so that is why I'm not wearing the beer costume.", "tokens": [50536, 370, 300, 307, 983, 286, 478, 406, 4769, 264, 8795, 14850, 13, 50650], "temperature": 0.0, "avg_logprob": -0.3457265044703628, "compression_ratio": 1.3093922651933703, "no_speech_prob": 0.0008781434735283256}, {"id": 478, "seek": 140452, "start": 1410.24, "end": 1413.6399999999999, "text": " And shame on you, sir, for reminding people that it exists.", "tokens": [50650, 400, 10069, 322, 291, 11, 4735, 11, 337, 27639, 561, 300, 309, 8198, 13, 50820], "temperature": 0.0, "avg_logprob": -0.3457265044703628, "compression_ratio": 1.3093922651933703, "no_speech_prob": 0.0008781434735283256}, {"id": 479, "seek": 140452, "start": 1413.6399999999999, "end": 1415.6399999999999, "text": " LAUGHTER", "tokens": [50820, 46760, 50920], "temperature": 0.0, "avg_logprob": -0.3457265044703628, "compression_ratio": 1.3093922651933703, "no_speech_prob": 0.0008781434735283256}, {"id": 480, "seek": 140452, "start": 1417.52, "end": 1419.52, "text": " Any more questions?", "tokens": [51014, 2639, 544, 1651, 30, 51114], "temperature": 0.0, "avg_logprob": -0.3457265044703628, "compression_ratio": 1.3093922651933703, "no_speech_prob": 0.0008781434735283256}, {"id": 481, "seek": 140452, "start": 1420.52, "end": 1422.52, "text": " Awesome. Thank you, Mike.", "tokens": [51164, 10391, 13, 1044, 291, 11, 6602, 13, 51264], "temperature": 0.0, "avg_logprob": -0.3457265044703628, "compression_ratio": 1.3093922651933703, "no_speech_prob": 0.0008781434735283256}, {"id": 482, "seek": 140452, "start": 1422.52, "end": 1425.52, "text": " APPLAUSE", "tokens": [51264, 35298, 51414], "temperature": 0.0, "avg_logprob": -0.3457265044703628, "compression_ratio": 1.3093922651933703, "no_speech_prob": 0.0008781434735283256}, {"id": 483, "seek": 143452, "start": 1434.52, "end": 1437.52, "text": " You", "tokens": [50414, 509, 50514], "temperature": 0.0, "avg_logprob": -0.7803918719291687, "compression_ratio": 0.2727272727272727, "no_speech_prob": 0.9345036745071411}], "language": "en"}