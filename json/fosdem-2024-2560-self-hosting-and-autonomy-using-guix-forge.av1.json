{"text": " So, good morning everyone. This is talk about Geeksforge. So, first let me explain what Geeksforge is about. So, Geeksforge is a Geeks channel that has services that will allow you to run a complete GitHub like software forge, but fully on free software and using existing free software components like Seagate and Git, of course, the laminar continuous integration system, something like public inbox and so on. So, usually when we try to build GitHub alternatives, we have monolithic systems like GitLab or GitE, Gox and so on. What Geeksforge tries to do different is use old and existing very stable components like Seagate and assemble it all together into a system that resembles a software forge. And it is assembled together using Geeks. So, you have a nice declarative configuration that you can just deploy practically anywhere. So, in a sense, it's like million a box if you have heard of the project, million a box, they set up complete mail server on a system using by integrating many different components. It's like that, but for software forges and using Geeks. So, first I'll start with a quick demo of the Geeks system containers. This is quite widely used as a package manager, but as a means to deploy Geeks, a full operating system and operating system containers, it's not so widely used. So, I just want to quickly show you a demo of how it works. So, this is a really simple operating system configuration. It just has an engine service that listens on 8080 and serves static directory. So, let me build that. So, the static directory has a simple HTML file that I just wrote up. So, first let's build the container. You build it using Geeks system container. And the hyphen capital N is to enable network access. And the container is completely stateless, something like Docker where you have attached storage somehow. So, you have to mount all storage, all state into the container. And that's why we have the expose here. So, you have this script that has been returned. So, if you open it, it's really just a guy's script that sets up the container and has all the dependencies built into the store itself. So, let me now run it. So, pseudo... Yeah. It says that my Geeks is two worlds, older than 30 days. So, I have started up the container. Let's just go to localhost 8080. And it works. So, this is just the static HTML page. Now, let's try to set up a container that actually uses the Geeks 4 channel. So, this is a more complicated configuration, operating system configuration. Here, I want to show you the Seagate service that Geeks 4 provides. So, it's really simple and it just takes a server name, which is the domain name. And then the repository directory where all the gate repositories are stored. And then you have something called a Forge engine X service, which is similar to the basic engine X service that you have in Geeks upstream. But it automatically handles things like HTTPS, acquiring a TLS certificate, setting up a crown job to periodically renew the certificate, automatic redirection from HTTP to HTTPS and so on. So, it does a lot of things in a very turnkey, fully automated way. You just push the button and you get it essentially. And this is the Acme service configuration. So, Acme is the protocol behind the Let's Encrypt. You have to register an email ID of that. So, that's my email ID. So, in this configuration, I'm currently using the staging URL. It's good for testing because you won't run into any rate limits. So, I'll actually take the risk and delete that. We'll try to build with a real Acme server. So, here again, I'll build a container and run it. I'm mounting a couple of state directories, Acme directory and the GitR Poster directory. So, there it is. It started. So, I'll go to git.demo.system.rego.net. So, initially, the container set up with a self-signed certificate. So, it doesn't work. So, let's actually get real certificates. So, find the shepherd. So, the PID of the container is 19.262. I drop into a shell. Get some source and profile. So, GitX4 sets up a script under user bin. Acme is any... Yeah, I'm inside the container. Yeah. So, around the script. And the script has been automatically configured with all the domain names that need certificates. And now it is actually getting certificates from Let's Encrypt. If you can see the logs, it's telling you what it's doing. Yeah, that it has a certificate and it has restarted the Nginx service as well. Now, if I reload this, it should work with proper certificates. Let's try. Yeah, there you go. So, this is Git. And you can browse some repositories that I put in there. So, Git is really simple, but it doesn't come with all features properly enabled by default. And you have to do a lot of manual tinkering to get it to work. For example, by default, it only serves the dumb HTTP transport protocol for Git. So, but the C Git Nginx 4G is set up with the smart HTTP protocol. That's one. And then you have things like... So, this C Git can render org mode readme files, which the basics it can't do. So, this is actually an org mode readme file in this repo. Then you have things like syntax highlighting that is automatically set up again. So, let's just look at the make file maybe. Yeah, so, yeah, you see the syntax highlighting. So, for that it uses Python pigments. So, my point is that Gitx 4G tries to do all this for you and doesn't expose all this complexity to the administrator. And all you're really saying here in this configuration is domain name and the directory where the repositories are. So, it handles a lot of things with very sensible defaults behind your back. So, that's that. Yeah. How much time do I have? Okay. Okay. So, the philosophy behind Gitx 4G is that it has to be really minimalistic. I don't want to be running a full database server just to publish a few GitHub postries and run a small project. And it should be as stateless as possible. Of course, you need a little bit of state for if you need a mailing list or if you need to backup your Git reports, of course. But it should not have hard to backup state like a database that you have to be that takes a lot of cognitive overhead to keep working successfully. As to, should be as donkey as possible, but it should still be able to inspect it and fit it in your head. It should not be something that is so complex that you cannot hold it in your head. And effectively, what the, what Geeks 4 and the, the Geeks 4 channel is doing is that it's, it's crowdsourcing server management in some sense. So, the regular server which you are always, which have, for which you have to mutate configuration files, you are the only one who's in charge of the server. But when you have Geeks 4 doing a lot of things for you, you're essentially getting a community to help you with managing your server. And so hopefully that will reduce configuration errors and let you run a polished server setup without putting in too much work. So that's it. Thank you. Nobody complains when the speaker is too quick, right? Is this a replacement from GitHub? Yeah, it's meant to be. What about the fast pushing process and we having these things? Can we support them with this Geeks 4? Do you mean the email workflow? Yeah. Yeah, so I don't mean to support public inbox based mailing list. Instead of pull request based model. I think that's easy to set up using existing tools and personally I think it's better than the pull request based model. Questions? Yeah. So I think you mentioned it's in a separate channel. Yeah. And are you planning to upstream it and what would be needed for that? So, can we repeat the question? Yes. Yes. Yes. Sorry. So I'm planning to upstream it into Geeks upstream instead of having a separate channel. So certainly there are some parts that can be upstream. For example, the automatic HTTPS that I demo it can certainly it should be upstreamed. But the all the other services I'm not really sure. So I'm not sure how much of this fits into Geeks upstream itself. We already have a Seagate service in Geeks upstream that doesn't do as much as the Seagate service in Geeks 4. So upstreaming this will essentially break the old service. Maybe it should be called something else now. So that's a difficult conversation to have. Could you have a Meta service? Sorry? Do you have a service with all your special services? I do have a 4 service. It's not fully integrated but it aims to be a full Meta service. Yeah. Can you show Laminar? Oh yes. I can show it in the browser. So this is Laminar which is a continuous integration system. So this is a system that we are already running. It's not running on this laptop. It's running on a different server. And it's a really simple continuous integration system that is very easy to set up. Like most continuous integration systems are so complex that they read the very enterpracy projects that are not meant for a single person to set up. But Laminar is really easy and you should have a look at the documentation itself. It's just a single page of documentation and you can set it up. So we use that in Geeks 4. And it fits in with the philosophy of using very minimal tools. We also have class in Geeks 4. Class is another Git reviewer which is written in Python. So you have even a choice for... If you don't like CGIT you can use class and maybe you can support Git delay and other Git viewers too. Sure. So these are the Git logs. Maybe... Yeah, make file again. So class is just a Git reviewer. It doesn't do anything else. Yeah, it supports the Smart HTTP protocol. Yeah. So you mentioned that the TLS stuff is automated as well. But with the demo there was something that seemed kind of manual? Oh yeah. So the manual step that I showed you is only the first time. And after that that same script is ran as a cron job. I need to get rid of the first manual step but I think I need to patch something in Geeks upstream for it to happen. So yeah. Question. Would it be easy to use this process to set up your own channel and then auto build your packages and then deliver that as a substitute? Yeah. Yeah. Get them to end the flow? Yeah. So we already do that in my Geeks 4 instance. And we also have the... So that is the Geeks bioinformatics channel which Pewter runs. And we already do that for all the packages in Geeks bioinformatics. For example, here you see names of many packages. Some of them build, some of them fail. And I think it's... Using laminar and Geeks 4 is simpler than something as complicated as... As Geeks is quicker as CIS. And I really don't want to be running Postgres to have... To just provide substitutes for my channel. So we have a replacement here for many things, right? Yeah. Including GitHub CI. We don't use GitHub CI anymore. Yeah, we don't use GitHub CI anymore. Alright. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 21.400000000000002, "text": " So, good morning everyone. This is talk about Geeksforge. So, first let me explain what", "tokens": [50364, 407, 11, 665, 2446, 1518, 13, 639, 307, 751, 466, 2876, 24785, 2994, 432, 13, 407, 11, 700, 718, 385, 2903, 437, 51434], "temperature": 0.0, "avg_logprob": -0.2194505654848539, "compression_ratio": 1.4666666666666666, "no_speech_prob": 0.5808894634246826}, {"id": 1, "seek": 0, "start": 21.400000000000002, "end": 27.560000000000002, "text": " Geeksforge is about. So, Geeksforge is a Geeks channel that has services that will allow", "tokens": [51434, 2876, 24785, 2994, 432, 307, 466, 13, 407, 11, 2876, 24785, 2994, 432, 307, 257, 2876, 24785, 2269, 300, 575, 3328, 300, 486, 2089, 51742], "temperature": 0.0, "avg_logprob": -0.2194505654848539, "compression_ratio": 1.4666666666666666, "no_speech_prob": 0.5808894634246826}, {"id": 2, "seek": 2756, "start": 27.56, "end": 34.12, "text": " you to run a complete GitHub like software forge, but fully on free software and using", "tokens": [50364, 291, 281, 1190, 257, 3566, 23331, 411, 4722, 337, 432, 11, 457, 4498, 322, 1737, 4722, 293, 1228, 50692], "temperature": 0.0, "avg_logprob": -0.32950833786365596, "compression_ratio": 1.644859813084112, "no_speech_prob": 0.060769930481910706}, {"id": 3, "seek": 2756, "start": 34.12, "end": 42.72, "text": " existing free software components like Seagate and Git, of course, the laminar continuous", "tokens": [50692, 6741, 1737, 4722, 6677, 411, 1100, 559, 473, 293, 16939, 11, 295, 1164, 11, 264, 24688, 6470, 10957, 51122], "temperature": 0.0, "avg_logprob": -0.32950833786365596, "compression_ratio": 1.644859813084112, "no_speech_prob": 0.060769930481910706}, {"id": 4, "seek": 2756, "start": 42.72, "end": 50.68, "text": " integration system, something like public inbox and so on. So, usually when we try to", "tokens": [51122, 10980, 1185, 11, 746, 411, 1908, 35067, 293, 370, 322, 13, 407, 11, 2673, 562, 321, 853, 281, 51520], "temperature": 0.0, "avg_logprob": -0.32950833786365596, "compression_ratio": 1.644859813084112, "no_speech_prob": 0.060769930481910706}, {"id": 5, "seek": 2756, "start": 50.68, "end": 57.519999999999996, "text": " build GitHub alternatives, we have monolithic systems like GitLab or GitE, Gox and so on.", "tokens": [51520, 1322, 23331, 20478, 11, 321, 362, 1108, 42878, 3652, 411, 16939, 37880, 420, 16939, 36, 11, 1037, 87, 293, 370, 322, 13, 51862], "temperature": 0.0, "avg_logprob": -0.32950833786365596, "compression_ratio": 1.644859813084112, "no_speech_prob": 0.060769930481910706}, {"id": 6, "seek": 5752, "start": 57.52, "end": 66.76, "text": " What Geeksforge tries to do different is use old and existing very stable components like", "tokens": [50364, 708, 2876, 24785, 2994, 432, 9898, 281, 360, 819, 307, 764, 1331, 293, 6741, 588, 8351, 6677, 411, 50826], "temperature": 0.0, "avg_logprob": -0.20293574613683363, "compression_ratio": 1.5810810810810811, "no_speech_prob": 0.019558047875761986}, {"id": 7, "seek": 5752, "start": 66.76, "end": 73.96000000000001, "text": " Seagate and assemble it all together into a system that resembles a software forge. And", "tokens": [50826, 1100, 559, 473, 293, 22364, 309, 439, 1214, 666, 257, 1185, 300, 34433, 257, 4722, 337, 432, 13, 400, 51186], "temperature": 0.0, "avg_logprob": -0.20293574613683363, "compression_ratio": 1.5810810810810811, "no_speech_prob": 0.019558047875761986}, {"id": 8, "seek": 5752, "start": 73.96000000000001, "end": 80.2, "text": " it is assembled together using Geeks. So, you have a nice declarative configuration that", "tokens": [51186, 309, 307, 24204, 1214, 1228, 2876, 24785, 13, 407, 11, 291, 362, 257, 1481, 16694, 1166, 11694, 300, 51498], "temperature": 0.0, "avg_logprob": -0.20293574613683363, "compression_ratio": 1.5810810810810811, "no_speech_prob": 0.019558047875761986}, {"id": 9, "seek": 5752, "start": 80.2, "end": 85.16, "text": " you can just deploy practically anywhere. So, in a sense, it's like million a box if", "tokens": [51498, 291, 393, 445, 7274, 15667, 4992, 13, 407, 11, 294, 257, 2020, 11, 309, 311, 411, 2459, 257, 2424, 498, 51746], "temperature": 0.0, "avg_logprob": -0.20293574613683363, "compression_ratio": 1.5810810810810811, "no_speech_prob": 0.019558047875761986}, {"id": 10, "seek": 8516, "start": 85.16, "end": 90.64, "text": " you have heard of the project, million a box, they set up complete mail server on a", "tokens": [50364, 291, 362, 2198, 295, 264, 1716, 11, 2459, 257, 2424, 11, 436, 992, 493, 3566, 10071, 7154, 322, 257, 50638], "temperature": 0.0, "avg_logprob": -0.2952943773411993, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.021801771596074104}, {"id": 11, "seek": 8516, "start": 90.64, "end": 96.88, "text": " system using by integrating many different components. It's like that, but for software", "tokens": [50638, 1185, 1228, 538, 26889, 867, 819, 6677, 13, 467, 311, 411, 300, 11, 457, 337, 4722, 50950], "temperature": 0.0, "avg_logprob": -0.2952943773411993, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.021801771596074104}, {"id": 12, "seek": 8516, "start": 96.88, "end": 111.36, "text": " forges and using Geeks. So, first I'll start with a quick demo of the Geeks system containers.", "tokens": [50950, 337, 2880, 293, 1228, 2876, 24785, 13, 407, 11, 700, 286, 603, 722, 365, 257, 1702, 10723, 295, 264, 2876, 24785, 1185, 17089, 13, 51674], "temperature": 0.0, "avg_logprob": -0.2952943773411993, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.021801771596074104}, {"id": 13, "seek": 11136, "start": 111.36, "end": 119.16, "text": " This is quite widely used as a package manager, but as a means to deploy Geeks, a full operating", "tokens": [50364, 639, 307, 1596, 13371, 1143, 382, 257, 7372, 6598, 11, 457, 382, 257, 1355, 281, 7274, 2876, 24785, 11, 257, 1577, 7447, 50754], "temperature": 0.0, "avg_logprob": -0.19262266159057617, "compression_ratio": 1.6149425287356323, "no_speech_prob": 0.3121778666973114}, {"id": 14, "seek": 11136, "start": 119.16, "end": 127.72, "text": " system and operating system containers, it's not so widely used. So, I just want to quickly", "tokens": [50754, 1185, 293, 7447, 1185, 17089, 11, 309, 311, 406, 370, 13371, 1143, 13, 407, 11, 286, 445, 528, 281, 2661, 51182], "temperature": 0.0, "avg_logprob": -0.19262266159057617, "compression_ratio": 1.6149425287356323, "no_speech_prob": 0.3121778666973114}, {"id": 15, "seek": 11136, "start": 127.72, "end": 133.48, "text": " show you a demo of how it works. So, this is a really simple operating system configuration.", "tokens": [51182, 855, 291, 257, 10723, 295, 577, 309, 1985, 13, 407, 11, 341, 307, 257, 534, 2199, 7447, 1185, 11694, 13, 51470], "temperature": 0.0, "avg_logprob": -0.19262266159057617, "compression_ratio": 1.6149425287356323, "no_speech_prob": 0.3121778666973114}, {"id": 16, "seek": 13348, "start": 133.48, "end": 143.44, "text": " It just has an engine service that listens on 8080 and serves static directory. So, let", "tokens": [50364, 467, 445, 575, 364, 2848, 2643, 300, 35959, 322, 4688, 4702, 293, 13451, 13437, 21120, 13, 407, 11, 718, 50862], "temperature": 0.0, "avg_logprob": -0.2661394036334494, "compression_ratio": 1.5614035087719298, "no_speech_prob": 0.15965743362903595}, {"id": 17, "seek": 13348, "start": 143.44, "end": 155.35999999999999, "text": " me build that. So, the static directory has a simple HTML file that I just wrote up. So,", "tokens": [50862, 385, 1322, 300, 13, 407, 11, 264, 13437, 21120, 575, 257, 2199, 17995, 3991, 300, 286, 445, 4114, 493, 13, 407, 11, 51458], "temperature": 0.0, "avg_logprob": -0.2661394036334494, "compression_ratio": 1.5614035087719298, "no_speech_prob": 0.15965743362903595}, {"id": 18, "seek": 13348, "start": 155.35999999999999, "end": 163.12, "text": " first let's build the container. You build it using Geeks system container. And the hyphen", "tokens": [51458, 700, 718, 311, 1322, 264, 10129, 13, 509, 1322, 309, 1228, 2876, 24785, 1185, 10129, 13, 400, 264, 2477, 47059, 51846], "temperature": 0.0, "avg_logprob": -0.2661394036334494, "compression_ratio": 1.5614035087719298, "no_speech_prob": 0.15965743362903595}, {"id": 19, "seek": 16312, "start": 163.16, "end": 169.08, "text": " capital N is to enable network access. And the container is completely stateless, something", "tokens": [50366, 4238, 426, 307, 281, 9528, 3209, 2105, 13, 400, 264, 10129, 307, 2584, 2219, 4272, 11, 746, 50662], "temperature": 0.0, "avg_logprob": -0.2734646499156952, "compression_ratio": 1.608433734939759, "no_speech_prob": 0.02925463393330574}, {"id": 20, "seek": 16312, "start": 169.08, "end": 175.96, "text": " like Docker where you have attached storage somehow. So, you have to mount all storage,", "tokens": [50662, 411, 33772, 689, 291, 362, 8570, 6725, 6063, 13, 407, 11, 291, 362, 281, 3746, 439, 6725, 11, 51006], "temperature": 0.0, "avg_logprob": -0.2734646499156952, "compression_ratio": 1.608433734939759, "no_speech_prob": 0.02925463393330574}, {"id": 21, "seek": 16312, "start": 175.96, "end": 184.84, "text": " all state into the container. And that's why we have the expose here. So, you have this", "tokens": [51006, 439, 1785, 666, 264, 10129, 13, 400, 300, 311, 983, 321, 362, 264, 19219, 510, 13, 407, 11, 291, 362, 341, 51450], "temperature": 0.0, "avg_logprob": -0.2734646499156952, "compression_ratio": 1.608433734939759, "no_speech_prob": 0.02925463393330574}, {"id": 22, "seek": 18484, "start": 184.84, "end": 191.76, "text": " script that has been returned. So, if you open it, it's really just a guy's script that", "tokens": [50364, 5755, 300, 575, 668, 8752, 13, 407, 11, 498, 291, 1269, 309, 11, 309, 311, 534, 445, 257, 2146, 311, 5755, 300, 50710], "temperature": 0.0, "avg_logprob": -0.2574737270673116, "compression_ratio": 1.421875, "no_speech_prob": 0.1872253715991974}, {"id": 23, "seek": 18484, "start": 191.76, "end": 199.24, "text": " sets up the container and has all the dependencies built into the store itself. So, let me now", "tokens": [50710, 6352, 493, 264, 10129, 293, 575, 439, 264, 36606, 3094, 666, 264, 3531, 2564, 13, 407, 11, 718, 385, 586, 51084], "temperature": 0.0, "avg_logprob": -0.2574737270673116, "compression_ratio": 1.421875, "no_speech_prob": 0.1872253715991974}, {"id": 24, "seek": 19924, "start": 199.24, "end": 227.12, "text": " run it. So, pseudo... Yeah. It says that my Geeks is two worlds, older than 30 days. So, I have started", "tokens": [50364, 1190, 309, 13, 407, 11, 35899, 485, 865, 13, 467, 1619, 300, 452, 2876, 24785, 307, 732, 13401, 11, 4906, 813, 2217, 1708, 13, 407, 11, 286, 362, 1409, 51758], "temperature": 0.0, "avg_logprob": -0.41164256587173, "compression_ratio": 1.0957446808510638, "no_speech_prob": 0.1456785798072815}, {"id": 25, "seek": 22712, "start": 227.12, "end": 235.08, "text": " up the container. Let's just go to localhost 8080. And it works. So, this is just the static", "tokens": [50364, 493, 264, 10129, 13, 961, 311, 445, 352, 281, 2654, 6037, 4688, 4702, 13, 400, 309, 1985, 13, 407, 11, 341, 307, 445, 264, 13437, 50762], "temperature": 0.0, "avg_logprob": -0.17786413828531902, "compression_ratio": 1.4816753926701571, "no_speech_prob": 0.059616584330797195}, {"id": 26, "seek": 22712, "start": 235.08, "end": 244.52, "text": " HTML page. Now, let's try to set up a container that actually uses the Geeks 4 channel. So, this", "tokens": [50762, 17995, 3028, 13, 823, 11, 718, 311, 853, 281, 992, 493, 257, 10129, 300, 767, 4960, 264, 2876, 24785, 1017, 2269, 13, 407, 11, 341, 51234], "temperature": 0.0, "avg_logprob": -0.17786413828531902, "compression_ratio": 1.4816753926701571, "no_speech_prob": 0.059616584330797195}, {"id": 27, "seek": 22712, "start": 244.52, "end": 251.32, "text": " is a more complicated configuration, operating system configuration. Here, I want to show you", "tokens": [51234, 307, 257, 544, 6179, 11694, 11, 7447, 1185, 11694, 13, 1692, 11, 286, 528, 281, 855, 291, 51574], "temperature": 0.0, "avg_logprob": -0.17786413828531902, "compression_ratio": 1.4816753926701571, "no_speech_prob": 0.059616584330797195}, {"id": 28, "seek": 25132, "start": 251.95999999999998, "end": 259.32, "text": " the Seagate service that Geeks 4 provides. So, it's really simple and it just takes a server name,", "tokens": [50396, 264, 1100, 559, 473, 2643, 300, 2876, 24785, 1017, 6417, 13, 407, 11, 309, 311, 534, 2199, 293, 309, 445, 2516, 257, 7154, 1315, 11, 50764], "temperature": 0.0, "avg_logprob": -0.26742619408501517, "compression_ratio": 1.6844444444444444, "no_speech_prob": 0.04665137082338333}, {"id": 29, "seek": 25132, "start": 259.32, "end": 263.15999999999997, "text": " which is the domain name. And then the repository directory where all the gate repositories are", "tokens": [50764, 597, 307, 264, 9274, 1315, 13, 400, 550, 264, 25841, 21120, 689, 439, 264, 8539, 22283, 2083, 366, 50956], "temperature": 0.0, "avg_logprob": -0.26742619408501517, "compression_ratio": 1.6844444444444444, "no_speech_prob": 0.04665137082338333}, {"id": 30, "seek": 25132, "start": 263.15999999999997, "end": 268.03999999999996, "text": " stored. And then you have something called a Forge engine X service, which is similar to the", "tokens": [50956, 12187, 13, 400, 550, 291, 362, 746, 1219, 257, 1171, 432, 2848, 1783, 2643, 11, 597, 307, 2531, 281, 264, 51200], "temperature": 0.0, "avg_logprob": -0.26742619408501517, "compression_ratio": 1.6844444444444444, "no_speech_prob": 0.04665137082338333}, {"id": 31, "seek": 25132, "start": 268.03999999999996, "end": 275.6, "text": " basic engine X service that you have in Geeks upstream. But it automatically handles things", "tokens": [51200, 3875, 2848, 1783, 2643, 300, 291, 362, 294, 2876, 24785, 33915, 13, 583, 309, 6772, 18722, 721, 51578], "temperature": 0.0, "avg_logprob": -0.26742619408501517, "compression_ratio": 1.6844444444444444, "no_speech_prob": 0.04665137082338333}, {"id": 32, "seek": 27560, "start": 275.6, "end": 283.40000000000003, "text": " like HTTPS, acquiring a TLS certificate, setting up a crown job to periodically renew the certificate,", "tokens": [50364, 411, 11751, 51, 6273, 11, 37374, 257, 314, 19198, 15953, 11, 3287, 493, 257, 11841, 1691, 281, 38916, 10162, 264, 15953, 11, 50754], "temperature": 0.0, "avg_logprob": -0.17493388232062845, "compression_ratio": 1.5591836734693878, "no_speech_prob": 0.039921924471855164}, {"id": 33, "seek": 27560, "start": 283.40000000000003, "end": 289.88, "text": " automatic redirection from HTTP to HTTPS and so on. So, it does a lot of things in a very", "tokens": [50754, 12509, 2182, 621, 882, 490, 33283, 281, 11751, 51, 6273, 293, 370, 322, 13, 407, 11, 309, 775, 257, 688, 295, 721, 294, 257, 588, 51078], "temperature": 0.0, "avg_logprob": -0.17493388232062845, "compression_ratio": 1.5591836734693878, "no_speech_prob": 0.039921924471855164}, {"id": 34, "seek": 27560, "start": 289.88, "end": 296.04, "text": " turnkey, fully automated way. You just push the button and you get it essentially. And this is", "tokens": [51078, 1261, 4119, 11, 4498, 18473, 636, 13, 509, 445, 2944, 264, 2960, 293, 291, 483, 309, 4476, 13, 400, 341, 307, 51386], "temperature": 0.0, "avg_logprob": -0.17493388232062845, "compression_ratio": 1.5591836734693878, "no_speech_prob": 0.039921924471855164}, {"id": 35, "seek": 27560, "start": 296.04, "end": 301.68, "text": " the Acme service configuration. So, Acme is the protocol behind the Let's Encrypt. You have to", "tokens": [51386, 264, 5097, 1398, 2643, 11694, 13, 407, 11, 5097, 1398, 307, 264, 10336, 2261, 264, 961, 311, 29584, 627, 662, 13, 509, 362, 281, 51668], "temperature": 0.0, "avg_logprob": -0.17493388232062845, "compression_ratio": 1.5591836734693878, "no_speech_prob": 0.039921924471855164}, {"id": 36, "seek": 30168, "start": 302.56, "end": 308.76, "text": " register an email ID of that. So, that's my email ID. So, in this configuration, I'm currently", "tokens": [50408, 7280, 364, 3796, 7348, 295, 300, 13, 407, 11, 300, 311, 452, 3796, 7348, 13, 407, 11, 294, 341, 11694, 11, 286, 478, 4362, 50718], "temperature": 0.0, "avg_logprob": -0.15344719793282302, "compression_ratio": 1.578723404255319, "no_speech_prob": 0.01789129711687565}, {"id": 37, "seek": 30168, "start": 308.76, "end": 312.92, "text": " using the staging URL. It's good for testing because you won't run into any rate limits.", "tokens": [50718, 1228, 264, 41085, 12905, 13, 467, 311, 665, 337, 4997, 570, 291, 1582, 380, 1190, 666, 604, 3314, 10406, 13, 50926], "temperature": 0.0, "avg_logprob": -0.15344719793282302, "compression_ratio": 1.578723404255319, "no_speech_prob": 0.01789129711687565}, {"id": 38, "seek": 30168, "start": 312.92, "end": 324.16, "text": " So, I'll actually take the risk and delete that. We'll try to build with a real Acme server. So,", "tokens": [50926, 407, 11, 286, 603, 767, 747, 264, 3148, 293, 12097, 300, 13, 492, 603, 853, 281, 1322, 365, 257, 957, 5097, 1398, 7154, 13, 407, 11, 51488], "temperature": 0.0, "avg_logprob": -0.15344719793282302, "compression_ratio": 1.578723404255319, "no_speech_prob": 0.01789129711687565}, {"id": 39, "seek": 30168, "start": 324.16, "end": 329.92, "text": " here again, I'll build a container and run it. I'm mounting a couple of state directories,", "tokens": [51488, 510, 797, 11, 286, 603, 1322, 257, 10129, 293, 1190, 309, 13, 286, 478, 22986, 257, 1916, 295, 1785, 5391, 530, 11, 51776], "temperature": 0.0, "avg_logprob": -0.15344719793282302, "compression_ratio": 1.578723404255319, "no_speech_prob": 0.01789129711687565}, {"id": 40, "seek": 32992, "start": 330.24, "end": 337.92, "text": " Acme directory and the GitR Poster directory. So, there it is. It started. So, I'll go to", "tokens": [50380, 5097, 1398, 21120, 293, 264, 16939, 49, 430, 7096, 21120, 13, 407, 11, 456, 309, 307, 13, 467, 1409, 13, 407, 11, 286, 603, 352, 281, 50764], "temperature": 0.0, "avg_logprob": -0.39535083770751955, "compression_ratio": 1.3455882352941178, "no_speech_prob": 0.00978176575154066}, {"id": 41, "seek": 32992, "start": 337.92, "end": 344.32, "text": " git.demo.system.rego.net. So, initially, the container set up with a self-signed certificate.", "tokens": [50764, 18331, 13, 10730, 78, 13, 28215, 13, 265, 1571, 13, 7129, 13, 407, 11, 9105, 11, 264, 10129, 992, 493, 365, 257, 2698, 12, 82, 16690, 15953, 13, 51084], "temperature": 0.0, "avg_logprob": -0.39535083770751955, "compression_ratio": 1.3455882352941178, "no_speech_prob": 0.00978176575154066}, {"id": 42, "seek": 34432, "start": 344.32, "end": 359.68, "text": " So, it doesn't work. So, let's actually get real certificates. So, find the shepherd.", "tokens": [50364, 407, 11, 309, 1177, 380, 589, 13, 407, 11, 718, 311, 767, 483, 957, 32941, 13, 407, 11, 915, 264, 40317, 13, 51132], "temperature": 0.0, "avg_logprob": -0.2692460830395038, "compression_ratio": 1.0625, "no_speech_prob": 0.07030479609966278}, {"id": 43, "seek": 35968, "start": 359.68, "end": 376.0, "text": " So, the PID of the container is 19.262. I drop into a shell. Get some source and profile. So,", "tokens": [50364, 407, 11, 264, 430, 2777, 295, 264, 10129, 307, 1294, 13, 10880, 17, 13, 286, 3270, 666, 257, 8720, 13, 3240, 512, 4009, 293, 7964, 13, 407, 11, 51180], "temperature": 0.0, "avg_logprob": -0.3474997858847341, "compression_ratio": 1.2857142857142858, "no_speech_prob": 0.06276796758174896}, {"id": 44, "seek": 35968, "start": 376.0, "end": 386.36, "text": " GitX4 sets up a script under user bin. Acme is any... Yeah, I'm inside the container. Yeah. So,", "tokens": [51180, 16939, 55, 19, 6352, 493, 257, 5755, 833, 4195, 5171, 13, 5097, 1398, 307, 604, 485, 865, 11, 286, 478, 1854, 264, 10129, 13, 865, 13, 407, 11, 51698], "temperature": 0.0, "avg_logprob": -0.3474997858847341, "compression_ratio": 1.2857142857142858, "no_speech_prob": 0.06276796758174896}, {"id": 45, "seek": 38636, "start": 387.24, "end": 392.44, "text": " around the script. And the script has been automatically configured with all the domain", "tokens": [50408, 926, 264, 5755, 13, 400, 264, 5755, 575, 668, 6772, 30538, 365, 439, 264, 9274, 50668], "temperature": 0.0, "avg_logprob": -0.21391006226235248, "compression_ratio": 1.6991150442477876, "no_speech_prob": 0.02095084637403488}, {"id": 46, "seek": 38636, "start": 392.44, "end": 400.44, "text": " names that need certificates. And now it is actually getting certificates from Let's Encrypt. If you", "tokens": [50668, 5288, 300, 643, 32941, 13, 400, 586, 309, 307, 767, 1242, 32941, 490, 961, 311, 29584, 627, 662, 13, 759, 291, 51068], "temperature": 0.0, "avg_logprob": -0.21391006226235248, "compression_ratio": 1.6991150442477876, "no_speech_prob": 0.02095084637403488}, {"id": 47, "seek": 38636, "start": 401.24, "end": 407.08000000000004, "text": " can see the logs, it's telling you what it's doing. Yeah, that it has a certificate and it has", "tokens": [51108, 393, 536, 264, 20820, 11, 309, 311, 3585, 291, 437, 309, 311, 884, 13, 865, 11, 300, 309, 575, 257, 15953, 293, 309, 575, 51400], "temperature": 0.0, "avg_logprob": -0.21391006226235248, "compression_ratio": 1.6991150442477876, "no_speech_prob": 0.02095084637403488}, {"id": 48, "seek": 38636, "start": 407.08000000000004, "end": 414.84000000000003, "text": " restarted the Nginx service as well. Now, if I reload this, it should work with proper certificates.", "tokens": [51400, 21022, 292, 264, 426, 1494, 87, 2643, 382, 731, 13, 823, 11, 498, 286, 25628, 341, 11, 309, 820, 589, 365, 2296, 32941, 13, 51788], "temperature": 0.0, "avg_logprob": -0.21391006226235248, "compression_ratio": 1.6991150442477876, "no_speech_prob": 0.02095084637403488}, {"id": 49, "seek": 41484, "start": 414.84, "end": 430.12, "text": " Let's try. Yeah, there you go. So, this is Git. And you can browse some repositories that I put in", "tokens": [50364, 961, 311, 853, 13, 865, 11, 456, 291, 352, 13, 407, 11, 341, 307, 16939, 13, 400, 291, 393, 31442, 512, 22283, 2083, 300, 286, 829, 294, 51128], "temperature": 0.0, "avg_logprob": -0.21042296669699928, "compression_ratio": 1.346938775510204, "no_speech_prob": 0.017564477398991585}, {"id": 50, "seek": 41484, "start": 430.12, "end": 440.52, "text": " there. So, Git is really simple, but it doesn't come with all features properly enabled by default.", "tokens": [51128, 456, 13, 407, 11, 16939, 307, 534, 2199, 11, 457, 309, 1177, 380, 808, 365, 439, 4122, 6108, 15172, 538, 7576, 13, 51648], "temperature": 0.0, "avg_logprob": -0.21042296669699928, "compression_ratio": 1.346938775510204, "no_speech_prob": 0.017564477398991585}, {"id": 51, "seek": 44052, "start": 440.52, "end": 445.79999999999995, "text": " And you have to do a lot of manual tinkering to get it to work. For example, by default,", "tokens": [50364, 400, 291, 362, 281, 360, 257, 688, 295, 9688, 256, 475, 1794, 281, 483, 309, 281, 589, 13, 1171, 1365, 11, 538, 7576, 11, 50628], "temperature": 0.0, "avg_logprob": -0.18621301651000977, "compression_ratio": 1.5809128630705394, "no_speech_prob": 0.03909172862768173}, {"id": 52, "seek": 44052, "start": 445.79999999999995, "end": 453.88, "text": " it only serves the dumb HTTP transport protocol for Git. So, but the C Git Nginx 4G is set up", "tokens": [50628, 309, 787, 13451, 264, 10316, 33283, 5495, 10336, 337, 16939, 13, 407, 11, 457, 264, 383, 16939, 426, 1494, 87, 1017, 38, 307, 992, 493, 51032], "temperature": 0.0, "avg_logprob": -0.18621301651000977, "compression_ratio": 1.5809128630705394, "no_speech_prob": 0.03909172862768173}, {"id": 53, "seek": 44052, "start": 453.88, "end": 462.84, "text": " with the smart HTTP protocol. That's one. And then you have things like... So, this C Git can render", "tokens": [51032, 365, 264, 4069, 33283, 10336, 13, 663, 311, 472, 13, 400, 550, 291, 362, 721, 411, 485, 407, 11, 341, 383, 16939, 393, 15529, 51480], "temperature": 0.0, "avg_logprob": -0.18621301651000977, "compression_ratio": 1.5809128630705394, "no_speech_prob": 0.03909172862768173}, {"id": 54, "seek": 44052, "start": 462.84, "end": 468.2, "text": " org mode readme files, which the basics it can't do. So, this is actually an org mode readme file", "tokens": [51480, 14045, 4391, 1401, 1398, 7098, 11, 597, 264, 14688, 309, 393, 380, 360, 13, 407, 11, 341, 307, 767, 364, 14045, 4391, 1401, 1398, 3991, 51748], "temperature": 0.0, "avg_logprob": -0.18621301651000977, "compression_ratio": 1.5809128630705394, "no_speech_prob": 0.03909172862768173}, {"id": 55, "seek": 46820, "start": 468.28, "end": 476.84, "text": " in this repo. Then you have things like syntax highlighting that is automatically set up again.", "tokens": [50368, 294, 341, 49040, 13, 1396, 291, 362, 721, 411, 28431, 26551, 300, 307, 6772, 992, 493, 797, 13, 50796], "temperature": 0.0, "avg_logprob": -0.22524508451804137, "compression_ratio": 1.5567567567567568, "no_speech_prob": 0.0297347754240036}, {"id": 56, "seek": 46820, "start": 477.47999999999996, "end": 485.0, "text": " So, let's just look at the make file maybe. Yeah, so, yeah, you see the syntax highlighting.", "tokens": [50828, 407, 11, 718, 311, 445, 574, 412, 264, 652, 3991, 1310, 13, 865, 11, 370, 11, 1338, 11, 291, 536, 264, 28431, 26551, 13, 51204], "temperature": 0.0, "avg_logprob": -0.22524508451804137, "compression_ratio": 1.5567567567567568, "no_speech_prob": 0.0297347754240036}, {"id": 57, "seek": 46820, "start": 486.28, "end": 496.03999999999996, "text": " So, for that it uses Python pigments. So, my point is that Gitx 4G tries to do all this for you and", "tokens": [51268, 407, 11, 337, 300, 309, 4960, 15329, 8120, 1117, 13, 407, 11, 452, 935, 307, 300, 16939, 87, 1017, 38, 9898, 281, 360, 439, 341, 337, 291, 293, 51756], "temperature": 0.0, "avg_logprob": -0.22524508451804137, "compression_ratio": 1.5567567567567568, "no_speech_prob": 0.0297347754240036}, {"id": 58, "seek": 49604, "start": 497.0, "end": 501.96000000000004, "text": " doesn't expose all this complexity to the administrator. And all you're really saying here in this", "tokens": [50412, 1177, 380, 19219, 439, 341, 14024, 281, 264, 25529, 13, 400, 439, 291, 434, 534, 1566, 510, 294, 341, 50660], "temperature": 0.0, "avg_logprob": -0.2270241313510471, "compression_ratio": 1.4825870646766168, "no_speech_prob": 0.02009984664618969}, {"id": 59, "seek": 49604, "start": 501.96000000000004, "end": 507.96000000000004, "text": " configuration is domain name and the directory where the repositories are. So, it handles a lot of", "tokens": [50660, 11694, 307, 9274, 1315, 293, 264, 21120, 689, 264, 22283, 2083, 366, 13, 407, 11, 309, 18722, 257, 688, 295, 50960], "temperature": 0.0, "avg_logprob": -0.2270241313510471, "compression_ratio": 1.4825870646766168, "no_speech_prob": 0.02009984664618969}, {"id": 60, "seek": 49604, "start": 507.96000000000004, "end": 519.16, "text": " things with very sensible defaults behind your back. So, that's that. Yeah. How much time do I have?", "tokens": [50960, 721, 365, 588, 25380, 7576, 82, 2261, 428, 646, 13, 407, 11, 300, 311, 300, 13, 865, 13, 1012, 709, 565, 360, 286, 362, 30, 51520], "temperature": 0.0, "avg_logprob": -0.2270241313510471, "compression_ratio": 1.4825870646766168, "no_speech_prob": 0.02009984664618969}, {"id": 61, "seek": 51916, "start": 519.4, "end": 531.48, "text": " Okay. Okay. So, the philosophy behind Gitx 4G is that it has to be really minimalistic.", "tokens": [50376, 1033, 13, 1033, 13, 407, 11, 264, 10675, 2261, 16939, 87, 1017, 38, 307, 300, 309, 575, 281, 312, 534, 13206, 3142, 13, 50980], "temperature": 0.0, "avg_logprob": -0.20171566009521485, "compression_ratio": 1.4090909090909092, "no_speech_prob": 0.03251199424266815}, {"id": 62, "seek": 51916, "start": 533.0, "end": 540.28, "text": " I don't want to be running a full database server just to publish a few GitHub postries and run a", "tokens": [51056, 286, 500, 380, 528, 281, 312, 2614, 257, 1577, 8149, 7154, 445, 281, 11374, 257, 1326, 23331, 2183, 2244, 293, 1190, 257, 51420], "temperature": 0.0, "avg_logprob": -0.20171566009521485, "compression_ratio": 1.4090909090909092, "no_speech_prob": 0.03251199424266815}, {"id": 63, "seek": 51916, "start": 540.28, "end": 545.8, "text": " small project. And it should be as stateless as possible. Of course, you need a little bit of", "tokens": [51420, 1359, 1716, 13, 400, 309, 820, 312, 382, 2219, 4272, 382, 1944, 13, 2720, 1164, 11, 291, 643, 257, 707, 857, 295, 51696], "temperature": 0.0, "avg_logprob": -0.20171566009521485, "compression_ratio": 1.4090909090909092, "no_speech_prob": 0.03251199424266815}, {"id": 64, "seek": 54580, "start": 545.8, "end": 551.7199999999999, "text": " state for if you need a mailing list or if you need to backup your Git reports, of course.", "tokens": [50364, 1785, 337, 498, 291, 643, 257, 41612, 1329, 420, 498, 291, 643, 281, 14807, 428, 16939, 7122, 11, 295, 1164, 13, 50660], "temperature": 0.0, "avg_logprob": -0.2835887583290658, "compression_ratio": 1.6852791878172588, "no_speech_prob": 0.011995267122983932}, {"id": 65, "seek": 54580, "start": 552.8399999999999, "end": 558.04, "text": " But it should not have hard to backup state like a database that you have to be", "tokens": [50716, 583, 309, 820, 406, 362, 1152, 281, 14807, 1785, 411, 257, 8149, 300, 291, 362, 281, 312, 50976], "temperature": 0.0, "avg_logprob": -0.2835887583290658, "compression_ratio": 1.6852791878172588, "no_speech_prob": 0.011995267122983932}, {"id": 66, "seek": 54580, "start": 560.76, "end": 564.76, "text": " that takes a lot of cognitive overhead to keep working successfully.", "tokens": [51112, 300, 2516, 257, 688, 295, 15605, 19922, 281, 1066, 1364, 10727, 13, 51312], "temperature": 0.0, "avg_logprob": -0.2835887583290658, "compression_ratio": 1.6852791878172588, "no_speech_prob": 0.011995267122983932}, {"id": 67, "seek": 54580, "start": 565.88, "end": 571.16, "text": " As to, should be as donkey as possible, but it should still be able to inspect it and fit it", "tokens": [51368, 1018, 281, 11, 820, 312, 382, 34834, 382, 1944, 11, 457, 309, 820, 920, 312, 1075, 281, 15018, 309, 293, 3318, 309, 51632], "temperature": 0.0, "avg_logprob": -0.2835887583290658, "compression_ratio": 1.6852791878172588, "no_speech_prob": 0.011995267122983932}, {"id": 68, "seek": 57116, "start": 571.16, "end": 577.48, "text": " in your head. It should not be something that is so complex that you cannot hold it in your head.", "tokens": [50364, 294, 428, 1378, 13, 467, 820, 406, 312, 746, 300, 307, 370, 3997, 300, 291, 2644, 1797, 309, 294, 428, 1378, 13, 50680], "temperature": 0.0, "avg_logprob": -0.21250491895173726, "compression_ratio": 1.6849315068493151, "no_speech_prob": 0.010501435026526451}, {"id": 69, "seek": 57116, "start": 578.4399999999999, "end": 586.12, "text": " And effectively, what the, what Geeks 4 and the, the Geeks 4 channel is doing is that it's,", "tokens": [50728, 400, 8659, 11, 437, 264, 11, 437, 2876, 24785, 1017, 293, 264, 11, 264, 2876, 24785, 1017, 2269, 307, 884, 307, 300, 309, 311, 11, 51112], "temperature": 0.0, "avg_logprob": -0.21250491895173726, "compression_ratio": 1.6849315068493151, "no_speech_prob": 0.010501435026526451}, {"id": 70, "seek": 57116, "start": 586.12, "end": 594.1999999999999, "text": " it's crowdsourcing server management in some sense. So, the regular server which you are always,", "tokens": [51112, 309, 311, 26070, 41849, 7154, 4592, 294, 512, 2020, 13, 407, 11, 264, 3890, 7154, 597, 291, 366, 1009, 11, 51516], "temperature": 0.0, "avg_logprob": -0.21250491895173726, "compression_ratio": 1.6849315068493151, "no_speech_prob": 0.010501435026526451}, {"id": 71, "seek": 57116, "start": 594.1999999999999, "end": 597.16, "text": " which have, for which you have to mutate configuration files, you are the only one", "tokens": [51516, 597, 362, 11, 337, 597, 291, 362, 281, 5839, 473, 11694, 7098, 11, 291, 366, 264, 787, 472, 51664], "temperature": 0.0, "avg_logprob": -0.21250491895173726, "compression_ratio": 1.6849315068493151, "no_speech_prob": 0.010501435026526451}, {"id": 72, "seek": 59716, "start": 597.88, "end": 604.28, "text": " who's in charge of the server. But when you have Geeks 4 doing a lot of things for you,", "tokens": [50400, 567, 311, 294, 4602, 295, 264, 7154, 13, 583, 562, 291, 362, 2876, 24785, 1017, 884, 257, 688, 295, 721, 337, 291, 11, 50720], "temperature": 0.0, "avg_logprob": -0.1738393461549437, "compression_ratio": 1.5118483412322274, "no_speech_prob": 0.02752949669957161}, {"id": 73, "seek": 59716, "start": 604.28, "end": 608.76, "text": " you're essentially getting a community to help you with managing your server.", "tokens": [50720, 291, 434, 4476, 1242, 257, 1768, 281, 854, 291, 365, 11642, 428, 7154, 13, 50944], "temperature": 0.0, "avg_logprob": -0.1738393461549437, "compression_ratio": 1.5118483412322274, "no_speech_prob": 0.02752949669957161}, {"id": 74, "seek": 59716, "start": 608.76, "end": 616.36, "text": " And so hopefully that will reduce configuration errors and let you run a polished server setup", "tokens": [50944, 400, 370, 4696, 300, 486, 5407, 11694, 13603, 293, 718, 291, 1190, 257, 29079, 7154, 8657, 51324], "temperature": 0.0, "avg_logprob": -0.1738393461549437, "compression_ratio": 1.5118483412322274, "no_speech_prob": 0.02752949669957161}, {"id": 75, "seek": 59716, "start": 616.36, "end": 620.36, "text": " without putting in too much work. So that's it. Thank you.", "tokens": [51324, 1553, 3372, 294, 886, 709, 589, 13, 407, 300, 311, 309, 13, 1044, 291, 13, 51524], "temperature": 0.0, "avg_logprob": -0.1738393461549437, "compression_ratio": 1.5118483412322274, "no_speech_prob": 0.02752949669957161}, {"id": 76, "seek": 62716, "start": 627.7199999999999, "end": 632.04, "text": " Nobody complains when the speaker is too quick, right?", "tokens": [50392, 9297, 1209, 2315, 562, 264, 8145, 307, 886, 1702, 11, 558, 30, 50608], "temperature": 0.0, "avg_logprob": -0.4014951369341682, "compression_ratio": 1.4814814814814814, "no_speech_prob": 0.07771553099155426}, {"id": 77, "seek": 62716, "start": 635.24, "end": 639.4, "text": " Is this a replacement from GitHub? Yeah, it's meant to be.", "tokens": [50768, 1119, 341, 257, 14419, 490, 23331, 30, 865, 11, 309, 311, 4140, 281, 312, 13, 50976], "temperature": 0.0, "avg_logprob": -0.4014951369341682, "compression_ratio": 1.4814814814814814, "no_speech_prob": 0.07771553099155426}, {"id": 78, "seek": 62716, "start": 641.8, "end": 645.24, "text": " What about the fast pushing process and we having these things?", "tokens": [51096, 708, 466, 264, 2370, 7380, 1399, 293, 321, 1419, 613, 721, 30, 51268], "temperature": 0.0, "avg_logprob": -0.4014951369341682, "compression_ratio": 1.4814814814814814, "no_speech_prob": 0.07771553099155426}, {"id": 79, "seek": 62716, "start": 645.24, "end": 649.88, "text": " Can we support them with this Geeks 4? Do you mean the email workflow?", "tokens": [51268, 1664, 321, 1406, 552, 365, 341, 2876, 24785, 1017, 30, 1144, 291, 914, 264, 3796, 20993, 30, 51500], "temperature": 0.0, "avg_logprob": -0.4014951369341682, "compression_ratio": 1.4814814814814814, "no_speech_prob": 0.07771553099155426}, {"id": 80, "seek": 62716, "start": 649.88, "end": 655.4, "text": " Yeah. Yeah, so I don't mean to support public inbox based mailing list.", "tokens": [51500, 865, 13, 865, 11, 370, 286, 500, 380, 914, 281, 1406, 1908, 35067, 2361, 41612, 1329, 13, 51776], "temperature": 0.0, "avg_logprob": -0.4014951369341682, "compression_ratio": 1.4814814814814814, "no_speech_prob": 0.07771553099155426}, {"id": 81, "seek": 65540, "start": 655.64, "end": 662.68, "text": " Instead of pull request based model. I think that's easy to set up using existing tools and", "tokens": [50376, 7156, 295, 2235, 5308, 2361, 2316, 13, 286, 519, 300, 311, 1858, 281, 992, 493, 1228, 6741, 3873, 293, 50728], "temperature": 0.0, "avg_logprob": -0.3304310473766956, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.02961333468556404}, {"id": 82, "seek": 65540, "start": 663.64, "end": 667.16, "text": " personally I think it's better than the pull request based model.", "tokens": [50776, 5665, 286, 519, 309, 311, 1101, 813, 264, 2235, 5308, 2361, 2316, 13, 50952], "temperature": 0.0, "avg_logprob": -0.3304310473766956, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.02961333468556404}, {"id": 83, "seek": 65540, "start": 669.16, "end": 669.64, "text": " Questions?", "tokens": [51052, 27738, 30, 51076], "temperature": 0.0, "avg_logprob": -0.3304310473766956, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.02961333468556404}, {"id": 84, "seek": 65540, "start": 672.1999999999999, "end": 672.6, "text": " Yeah.", "tokens": [51204, 865, 13, 51224], "temperature": 0.0, "avg_logprob": -0.3304310473766956, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.02961333468556404}, {"id": 85, "seek": 65540, "start": 672.6, "end": 675.0, "text": " So I think you mentioned it's in a separate channel.", "tokens": [51224, 407, 286, 519, 291, 2835, 309, 311, 294, 257, 4994, 2269, 13, 51344], "temperature": 0.0, "avg_logprob": -0.3304310473766956, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.02961333468556404}, {"id": 86, "seek": 65540, "start": 675.0, "end": 675.64, "text": " Yeah.", "tokens": [51344, 865, 13, 51376], "temperature": 0.0, "avg_logprob": -0.3304310473766956, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.02961333468556404}, {"id": 87, "seek": 65540, "start": 675.64, "end": 679.64, "text": " And are you planning to upstream it and what would be needed for that?", "tokens": [51376, 400, 366, 291, 5038, 281, 33915, 309, 293, 437, 576, 312, 2978, 337, 300, 30, 51576], "temperature": 0.0, "avg_logprob": -0.3304310473766956, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.02961333468556404}, {"id": 88, "seek": 65540, "start": 680.4399999999999, "end": 683.64, "text": " So, can we repeat the question?", "tokens": [51616, 407, 11, 393, 321, 7149, 264, 1168, 30, 51776], "temperature": 0.0, "avg_logprob": -0.3304310473766956, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.02961333468556404}, {"id": 89, "seek": 68364, "start": 683.72, "end": 685.16, "text": " Yes. Yes. Yes. Sorry.", "tokens": [50368, 1079, 13, 1079, 13, 1079, 13, 4919, 13, 50440], "temperature": 0.0, "avg_logprob": -0.20629828867286143, "compression_ratio": 1.6940639269406392, "no_speech_prob": 0.007118096575140953}, {"id": 90, "seek": 68364, "start": 685.16, "end": 690.6, "text": " So I'm planning to upstream it into Geeks upstream instead of having a separate channel.", "tokens": [50440, 407, 286, 478, 5038, 281, 33915, 309, 666, 2876, 24785, 33915, 2602, 295, 1419, 257, 4994, 2269, 13, 50712], "temperature": 0.0, "avg_logprob": -0.20629828867286143, "compression_ratio": 1.6940639269406392, "no_speech_prob": 0.007118096575140953}, {"id": 91, "seek": 68364, "start": 690.6, "end": 693.72, "text": " So certainly there are some parts that can be upstream.", "tokens": [50712, 407, 3297, 456, 366, 512, 3166, 300, 393, 312, 33915, 13, 50868], "temperature": 0.0, "avg_logprob": -0.20629828867286143, "compression_ratio": 1.6940639269406392, "no_speech_prob": 0.007118096575140953}, {"id": 92, "seek": 68364, "start": 693.72, "end": 699.3199999999999, "text": " For example, the automatic HTTPS that I demo it can certainly it should be upstreamed.", "tokens": [50868, 1171, 1365, 11, 264, 12509, 11751, 51, 6273, 300, 286, 10723, 309, 393, 3297, 309, 820, 312, 33915, 292, 13, 51148], "temperature": 0.0, "avg_logprob": -0.20629828867286143, "compression_ratio": 1.6940639269406392, "no_speech_prob": 0.007118096575140953}, {"id": 93, "seek": 68364, "start": 700.12, "end": 703.0, "text": " But the all the other services I'm not really sure.", "tokens": [51188, 583, 264, 439, 264, 661, 3328, 286, 478, 406, 534, 988, 13, 51332], "temperature": 0.0, "avg_logprob": -0.20629828867286143, "compression_ratio": 1.6940639269406392, "no_speech_prob": 0.007118096575140953}, {"id": 94, "seek": 68364, "start": 703.0, "end": 710.76, "text": " So I'm not sure how much of this fits into Geeks upstream itself.", "tokens": [51332, 407, 286, 478, 406, 988, 577, 709, 295, 341, 9001, 666, 2876, 24785, 33915, 2564, 13, 51720], "temperature": 0.0, "avg_logprob": -0.20629828867286143, "compression_ratio": 1.6940639269406392, "no_speech_prob": 0.007118096575140953}, {"id": 95, "seek": 71076, "start": 711.0, "end": 715.64, "text": " We already have a Seagate service in Geeks upstream that doesn't do as much as the Seagate", "tokens": [50376, 492, 1217, 362, 257, 1100, 559, 473, 2643, 294, 2876, 24785, 33915, 300, 1177, 380, 360, 382, 709, 382, 264, 1100, 559, 473, 50608], "temperature": 0.0, "avg_logprob": -0.25389222175844256, "compression_ratio": 1.7628458498023716, "no_speech_prob": 0.011143707670271397}, {"id": 96, "seek": 71076, "start": 715.64, "end": 720.2, "text": " service in Geeks 4. So upstreaming this will essentially break the old service.", "tokens": [50608, 2643, 294, 2876, 24785, 1017, 13, 407, 33915, 278, 341, 486, 4476, 1821, 264, 1331, 2643, 13, 50836], "temperature": 0.0, "avg_logprob": -0.25389222175844256, "compression_ratio": 1.7628458498023716, "no_speech_prob": 0.011143707670271397}, {"id": 97, "seek": 71076, "start": 720.2, "end": 722.2, "text": " Maybe it should be called something else now.", "tokens": [50836, 2704, 309, 820, 312, 1219, 746, 1646, 586, 13, 50936], "temperature": 0.0, "avg_logprob": -0.25389222175844256, "compression_ratio": 1.7628458498023716, "no_speech_prob": 0.011143707670271397}, {"id": 98, "seek": 71076, "start": 722.2, "end": 725.4, "text": " So that's a difficult conversation to have.", "tokens": [50936, 407, 300, 311, 257, 2252, 3761, 281, 362, 13, 51096], "temperature": 0.0, "avg_logprob": -0.25389222175844256, "compression_ratio": 1.7628458498023716, "no_speech_prob": 0.011143707670271397}, {"id": 99, "seek": 71076, "start": 725.4, "end": 727.48, "text": " Could you have a Meta service?", "tokens": [51096, 7497, 291, 362, 257, 6377, 64, 2643, 30, 51200], "temperature": 0.0, "avg_logprob": -0.25389222175844256, "compression_ratio": 1.7628458498023716, "no_speech_prob": 0.011143707670271397}, {"id": 100, "seek": 71076, "start": 729.0, "end": 729.24, "text": " Sorry?", "tokens": [51276, 4919, 30, 51288], "temperature": 0.0, "avg_logprob": -0.25389222175844256, "compression_ratio": 1.7628458498023716, "no_speech_prob": 0.011143707670271397}, {"id": 101, "seek": 71076, "start": 729.24, "end": 731.56, "text": " Do you have a service with all your special services?", "tokens": [51288, 1144, 291, 362, 257, 2643, 365, 439, 428, 2121, 3328, 30, 51404], "temperature": 0.0, "avg_logprob": -0.25389222175844256, "compression_ratio": 1.7628458498023716, "no_speech_prob": 0.011143707670271397}, {"id": 102, "seek": 71076, "start": 731.56, "end": 738.2, "text": " I do have a 4 service. It's not fully integrated but it aims to be a full Meta service.", "tokens": [51404, 286, 360, 362, 257, 1017, 2643, 13, 467, 311, 406, 4498, 10919, 457, 309, 24683, 281, 312, 257, 1577, 6377, 64, 2643, 13, 51736], "temperature": 0.0, "avg_logprob": -0.25389222175844256, "compression_ratio": 1.7628458498023716, "no_speech_prob": 0.011143707670271397}, {"id": 103, "seek": 71076, "start": 738.2, "end": 738.68, "text": " Yeah.", "tokens": [51736, 865, 13, 51760], "temperature": 0.0, "avg_logprob": -0.25389222175844256, "compression_ratio": 1.7628458498023716, "no_speech_prob": 0.011143707670271397}, {"id": 104, "seek": 73868, "start": 739.4, "end": 740.68, "text": " Can you show Laminar?", "tokens": [50400, 1664, 291, 855, 18825, 6470, 30, 50464], "temperature": 0.0, "avg_logprob": -0.17639208948889443, "compression_ratio": 1.6858638743455496, "no_speech_prob": 0.008032910525798798}, {"id": 105, "seek": 73868, "start": 741.2399999999999, "end": 743.2399999999999, "text": " Oh yes. I can show it in the browser.", "tokens": [50492, 876, 2086, 13, 286, 393, 855, 309, 294, 264, 11185, 13, 50592], "temperature": 0.0, "avg_logprob": -0.17639208948889443, "compression_ratio": 1.6858638743455496, "no_speech_prob": 0.008032910525798798}, {"id": 106, "seek": 73868, "start": 744.68, "end": 754.12, "text": " So this is Laminar which is a continuous integration system.", "tokens": [50664, 407, 341, 307, 18825, 6470, 597, 307, 257, 10957, 10980, 1185, 13, 51136], "temperature": 0.0, "avg_logprob": -0.17639208948889443, "compression_ratio": 1.6858638743455496, "no_speech_prob": 0.008032910525798798}, {"id": 107, "seek": 73868, "start": 754.12, "end": 756.4399999999999, "text": " So this is a system that we are already running.", "tokens": [51136, 407, 341, 307, 257, 1185, 300, 321, 366, 1217, 2614, 13, 51252], "temperature": 0.0, "avg_logprob": -0.17639208948889443, "compression_ratio": 1.6858638743455496, "no_speech_prob": 0.008032910525798798}, {"id": 108, "seek": 73868, "start": 758.4399999999999, "end": 760.68, "text": " It's not running on this laptop. It's running on a different server.", "tokens": [51352, 467, 311, 406, 2614, 322, 341, 10732, 13, 467, 311, 2614, 322, 257, 819, 7154, 13, 51464], "temperature": 0.0, "avg_logprob": -0.17639208948889443, "compression_ratio": 1.6858638743455496, "no_speech_prob": 0.008032910525798798}, {"id": 109, "seek": 73868, "start": 761.9599999999999, "end": 767.8, "text": " And it's a really simple continuous integration system that is very easy to set up.", "tokens": [51528, 400, 309, 311, 257, 534, 2199, 10957, 10980, 1185, 300, 307, 588, 1858, 281, 992, 493, 13, 51820], "temperature": 0.0, "avg_logprob": -0.17639208948889443, "compression_ratio": 1.6858638743455496, "no_speech_prob": 0.008032910525798798}, {"id": 110, "seek": 76868, "start": 769.56, "end": 775.9599999999999, "text": " Like most continuous integration systems are so complex that they read the very", "tokens": [50408, 1743, 881, 10957, 10980, 3652, 366, 370, 3997, 300, 436, 1401, 264, 588, 50728], "temperature": 0.0, "avg_logprob": -0.17470359802246094, "compression_ratio": 1.6058091286307055, "no_speech_prob": 0.003814786672592163}, {"id": 111, "seek": 76868, "start": 775.9599999999999, "end": 779.56, "text": " enterpracy projects that are not meant for a single person to set up.", "tokens": [50728, 3242, 1424, 2551, 4455, 300, 366, 406, 4140, 337, 257, 2167, 954, 281, 992, 493, 13, 50908], "temperature": 0.0, "avg_logprob": -0.17470359802246094, "compression_ratio": 1.6058091286307055, "no_speech_prob": 0.003814786672592163}, {"id": 112, "seek": 76868, "start": 780.52, "end": 785.16, "text": " But Laminar is really easy and you should have a look at the documentation itself.", "tokens": [50956, 583, 18825, 6470, 307, 534, 1858, 293, 291, 820, 362, 257, 574, 412, 264, 14333, 2564, 13, 51188], "temperature": 0.0, "avg_logprob": -0.17470359802246094, "compression_ratio": 1.6058091286307055, "no_speech_prob": 0.003814786672592163}, {"id": 113, "seek": 76868, "start": 785.16, "end": 789.56, "text": " It's just a single page of documentation and you can set it up.", "tokens": [51188, 467, 311, 445, 257, 2167, 3028, 295, 14333, 293, 291, 393, 992, 309, 493, 13, 51408], "temperature": 0.0, "avg_logprob": -0.17470359802246094, "compression_ratio": 1.6058091286307055, "no_speech_prob": 0.003814786672592163}, {"id": 114, "seek": 76868, "start": 789.56, "end": 791.16, "text": " So we use that in Geeks 4.", "tokens": [51408, 407, 321, 764, 300, 294, 2876, 24785, 1017, 13, 51488], "temperature": 0.0, "avg_logprob": -0.17470359802246094, "compression_ratio": 1.6058091286307055, "no_speech_prob": 0.003814786672592163}, {"id": 115, "seek": 76868, "start": 791.16, "end": 794.92, "text": " And it fits in with the philosophy of using very minimal tools.", "tokens": [51488, 400, 309, 9001, 294, 365, 264, 10675, 295, 1228, 588, 13206, 3873, 13, 51676], "temperature": 0.0, "avg_logprob": -0.17470359802246094, "compression_ratio": 1.6058091286307055, "no_speech_prob": 0.003814786672592163}, {"id": 116, "seek": 79492, "start": 795.24, "end": 799.64, "text": " We also have class in Geeks 4.", "tokens": [50380, 492, 611, 362, 1508, 294, 2876, 24785, 1017, 13, 50600], "temperature": 0.0, "avg_logprob": -0.47937920514275045, "compression_ratio": 1.4620253164556962, "no_speech_prob": 0.014239382930099964}, {"id": 117, "seek": 79492, "start": 799.64, "end": 804.92, "text": " Class is another Git reviewer which is written in Python.", "tokens": [50600, 9471, 307, 1071, 16939, 3131, 260, 597, 307, 3720, 294, 15329, 13, 50864], "temperature": 0.0, "avg_logprob": -0.47937920514275045, "compression_ratio": 1.4620253164556962, "no_speech_prob": 0.014239382930099964}, {"id": 118, "seek": 79492, "start": 804.92, "end": 808.4399999999999, "text": " So you have even a choice for...", "tokens": [50864, 407, 291, 362, 754, 257, 3922, 337, 485, 51040], "temperature": 0.0, "avg_logprob": -0.47937920514275045, "compression_ratio": 1.4620253164556962, "no_speech_prob": 0.014239382930099964}, {"id": 119, "seek": 79492, "start": 808.4399999999999, "end": 815.4, "text": " If you don't like CGIT you can use class and maybe you can support Git delay and other Git viewers too.", "tokens": [51040, 759, 291, 500, 380, 411, 383, 38, 3927, 291, 393, 764, 1508, 293, 1310, 291, 393, 1406, 16939, 8577, 293, 661, 16939, 8499, 886, 13, 51388], "temperature": 0.0, "avg_logprob": -0.47937920514275045, "compression_ratio": 1.4620253164556962, "no_speech_prob": 0.014239382930099964}, {"id": 120, "seek": 79492, "start": 817.9599999999999, "end": 818.68, "text": " Sure.", "tokens": [51516, 4894, 13, 51552], "temperature": 0.0, "avg_logprob": -0.47937920514275045, "compression_ratio": 1.4620253164556962, "no_speech_prob": 0.014239382930099964}, {"id": 121, "seek": 81868, "start": 819.4, "end": 826.5999999999999, "text": " So these are the Git logs. Maybe... Yeah, make file again.", "tokens": [50400, 407, 613, 366, 264, 16939, 20820, 13, 2704, 485, 865, 11, 652, 3991, 797, 13, 50760], "temperature": 0.0, "avg_logprob": -0.42743929227193195, "compression_ratio": 1.2442748091603053, "no_speech_prob": 0.015096670016646385}, {"id": 122, "seek": 81868, "start": 829.56, "end": 834.12, "text": " So class is just a Git reviewer. It doesn't do anything else.", "tokens": [50908, 407, 1508, 307, 445, 257, 16939, 3131, 260, 13, 467, 1177, 380, 360, 1340, 1646, 13, 51136], "temperature": 0.0, "avg_logprob": -0.42743929227193195, "compression_ratio": 1.2442748091603053, "no_speech_prob": 0.015096670016646385}, {"id": 123, "seek": 81868, "start": 836.28, "end": 838.4399999999999, "text": " Yeah, it supports the Smart HTTP protocol.", "tokens": [51244, 865, 11, 309, 9346, 264, 12923, 33283, 10336, 13, 51352], "temperature": 0.0, "avg_logprob": -0.42743929227193195, "compression_ratio": 1.2442748091603053, "no_speech_prob": 0.015096670016646385}, {"id": 124, "seek": 83844, "start": 838.5200000000001, "end": 839.1600000000001, "text": " Yeah.", "tokens": [50368, 865, 13, 50400], "temperature": 0.0, "avg_logprob": -0.35638416290283204, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.028571398928761482}, {"id": 125, "seek": 83844, "start": 844.6800000000001, "end": 847.4000000000001, "text": " So you mentioned that the TLS stuff is automated as well.", "tokens": [50676, 407, 291, 2835, 300, 264, 314, 19198, 1507, 307, 18473, 382, 731, 13, 50812], "temperature": 0.0, "avg_logprob": -0.35638416290283204, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.028571398928761482}, {"id": 126, "seek": 83844, "start": 847.4000000000001, "end": 851.5600000000001, "text": " But with the demo there was something that seemed kind of manual?", "tokens": [50812, 583, 365, 264, 10723, 456, 390, 746, 300, 6576, 733, 295, 9688, 30, 51020], "temperature": 0.0, "avg_logprob": -0.35638416290283204, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.028571398928761482}, {"id": 127, "seek": 83844, "start": 852.2800000000001, "end": 856.36, "text": " Oh yeah. So the manual step that I showed you is only the first time.", "tokens": [51056, 876, 1338, 13, 407, 264, 9688, 1823, 300, 286, 4712, 291, 307, 787, 264, 700, 565, 13, 51260], "temperature": 0.0, "avg_logprob": -0.35638416290283204, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.028571398928761482}, {"id": 128, "seek": 83844, "start": 857.96, "end": 860.5200000000001, "text": " And after that that same script is ran as a cron job.", "tokens": [51340, 400, 934, 300, 300, 912, 5755, 307, 5872, 382, 257, 941, 266, 1691, 13, 51468], "temperature": 0.0, "avg_logprob": -0.35638416290283204, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.028571398928761482}, {"id": 129, "seek": 83844, "start": 861.5600000000001, "end": 866.44, "text": " I need to get rid of the first manual step but I think I need to patch something in Geeks upstream for it to happen.", "tokens": [51520, 286, 643, 281, 483, 3973, 295, 264, 700, 9688, 1823, 457, 286, 519, 286, 643, 281, 9972, 746, 294, 2876, 24785, 33915, 337, 309, 281, 1051, 13, 51764], "temperature": 0.0, "avg_logprob": -0.35638416290283204, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.028571398928761482}, {"id": 130, "seek": 86644, "start": 866.7600000000001, "end": 868.0400000000001, "text": " So yeah.", "tokens": [50380, 407, 1338, 13, 50444], "temperature": 0.0, "avg_logprob": -0.45371194787927577, "compression_ratio": 1.467065868263473, "no_speech_prob": 0.02115536853671074}, {"id": 131, "seek": 86644, "start": 870.2, "end": 870.6800000000001, "text": " Question.", "tokens": [50552, 14464, 13, 50576], "temperature": 0.0, "avg_logprob": -0.45371194787927577, "compression_ratio": 1.467065868263473, "no_speech_prob": 0.02115536853671074}, {"id": 132, "seek": 86644, "start": 870.6800000000001, "end": 881.1600000000001, "text": " Would it be easy to use this process to set up your own channel and then auto build your packages and then deliver that as a substitute?", "tokens": [50576, 6068, 309, 312, 1858, 281, 764, 341, 1399, 281, 992, 493, 428, 1065, 2269, 293, 550, 8399, 1322, 428, 17401, 293, 550, 4239, 300, 382, 257, 15802, 30, 51100], "temperature": 0.0, "avg_logprob": -0.45371194787927577, "compression_ratio": 1.467065868263473, "no_speech_prob": 0.02115536853671074}, {"id": 133, "seek": 86644, "start": 881.1600000000001, "end": 881.6400000000001, "text": " Yeah.", "tokens": [51100, 865, 13, 51124], "temperature": 0.0, "avg_logprob": -0.45371194787927577, "compression_ratio": 1.467065868263473, "no_speech_prob": 0.02115536853671074}, {"id": 134, "seek": 86644, "start": 881.6400000000001, "end": 882.12, "text": " Yeah.", "tokens": [51124, 865, 13, 51148], "temperature": 0.0, "avg_logprob": -0.45371194787927577, "compression_ratio": 1.467065868263473, "no_speech_prob": 0.02115536853671074}, {"id": 135, "seek": 86644, "start": 882.12, "end": 883.4000000000001, "text": " Get them to end the flow?", "tokens": [51148, 3240, 552, 281, 917, 264, 3095, 30, 51212], "temperature": 0.0, "avg_logprob": -0.45371194787927577, "compression_ratio": 1.467065868263473, "no_speech_prob": 0.02115536853671074}, {"id": 136, "seek": 86644, "start": 883.4000000000001, "end": 889.72, "text": " Yeah. So we already do that in my Geeks 4 instance.", "tokens": [51212, 865, 13, 407, 321, 1217, 360, 300, 294, 452, 2876, 24785, 1017, 5197, 13, 51528], "temperature": 0.0, "avg_logprob": -0.45371194787927577, "compression_ratio": 1.467065868263473, "no_speech_prob": 0.02115536853671074}, {"id": 137, "seek": 88972, "start": 890.0400000000001, "end": 892.44, "text": " And we also have the...", "tokens": [50380, 400, 321, 611, 362, 264, 485, 50500], "temperature": 0.0, "avg_logprob": -0.24877872872859874, "compression_ratio": 1.6047619047619048, "no_speech_prob": 0.023920617997646332}, {"id": 138, "seek": 88972, "start": 895.4, "end": 899.24, "text": " So that is the Geeks bioinformatics channel which Pewter runs.", "tokens": [50648, 407, 300, 307, 264, 2876, 24785, 12198, 37811, 30292, 2269, 597, 30638, 391, 6676, 13, 50840], "temperature": 0.0, "avg_logprob": -0.24877872872859874, "compression_ratio": 1.6047619047619048, "no_speech_prob": 0.023920617997646332}, {"id": 139, "seek": 88972, "start": 899.24, "end": 903.24, "text": " And we already do that for all the packages in Geeks bioinformatics.", "tokens": [50840, 400, 321, 1217, 360, 300, 337, 439, 264, 17401, 294, 2876, 24785, 12198, 37811, 30292, 13, 51040], "temperature": 0.0, "avg_logprob": -0.24877872872859874, "compression_ratio": 1.6047619047619048, "no_speech_prob": 0.023920617997646332}, {"id": 140, "seek": 88972, "start": 903.24, "end": 908.36, "text": " For example, here you see names of many packages.", "tokens": [51040, 1171, 1365, 11, 510, 291, 536, 5288, 295, 867, 17401, 13, 51296], "temperature": 0.0, "avg_logprob": -0.24877872872859874, "compression_ratio": 1.6047619047619048, "no_speech_prob": 0.023920617997646332}, {"id": 141, "seek": 88972, "start": 908.36, "end": 909.72, "text": " Some of them build, some of them fail.", "tokens": [51296, 2188, 295, 552, 1322, 11, 512, 295, 552, 3061, 13, 51364], "temperature": 0.0, "avg_logprob": -0.24877872872859874, "compression_ratio": 1.6047619047619048, "no_speech_prob": 0.023920617997646332}, {"id": 142, "seek": 88972, "start": 909.72, "end": 912.6800000000001, "text": " And I think it's...", "tokens": [51364, 400, 286, 519, 309, 311, 485, 51512], "temperature": 0.0, "avg_logprob": -0.24877872872859874, "compression_ratio": 1.6047619047619048, "no_speech_prob": 0.023920617997646332}, {"id": 143, "seek": 88972, "start": 914.28, "end": 918.76, "text": " Using laminar and Geeks 4 is simpler than something as complicated as...", "tokens": [51592, 11142, 24688, 6470, 293, 2876, 24785, 1017, 307, 18587, 813, 746, 382, 6179, 382, 485, 51816], "temperature": 0.0, "avg_logprob": -0.24877872872859874, "compression_ratio": 1.6047619047619048, "no_speech_prob": 0.023920617997646332}, {"id": 144, "seek": 91972, "start": 919.88, "end": 922.12, "text": " As Geeks is quicker as CIS.", "tokens": [50372, 1018, 2876, 24785, 307, 16255, 382, 383, 2343, 13, 50484], "temperature": 0.0, "avg_logprob": -0.3785512613695721, "compression_ratio": 1.4814814814814814, "no_speech_prob": 0.019333332777023315}, {"id": 145, "seek": 91972, "start": 922.12, "end": 926.0400000000001, "text": " And I really don't want to be running Postgres to have...", "tokens": [50484, 400, 286, 534, 500, 380, 528, 281, 312, 2614, 10223, 45189, 281, 362, 485, 50680], "temperature": 0.0, "avg_logprob": -0.3785512613695721, "compression_ratio": 1.4814814814814814, "no_speech_prob": 0.019333332777023315}, {"id": 146, "seek": 91972, "start": 927.5600000000001, "end": 929.96, "text": " To just provide substitutes for my channel.", "tokens": [50756, 1407, 445, 2893, 26441, 1819, 337, 452, 2269, 13, 50876], "temperature": 0.0, "avg_logprob": -0.3785512613695721, "compression_ratio": 1.4814814814814814, "no_speech_prob": 0.019333332777023315}, {"id": 147, "seek": 91972, "start": 935.48, "end": 938.36, "text": " So we have a replacement here for many things, right?", "tokens": [51152, 407, 321, 362, 257, 14419, 510, 337, 867, 721, 11, 558, 30, 51296], "temperature": 0.0, "avg_logprob": -0.3785512613695721, "compression_ratio": 1.4814814814814814, "no_speech_prob": 0.019333332777023315}, {"id": 148, "seek": 91972, "start": 938.36, "end": 938.84, "text": " Yeah.", "tokens": [51296, 865, 13, 51320], "temperature": 0.0, "avg_logprob": -0.3785512613695721, "compression_ratio": 1.4814814814814814, "no_speech_prob": 0.019333332777023315}, {"id": 149, "seek": 91972, "start": 938.84, "end": 939.8000000000001, "text": " Including GitHub CI.", "tokens": [51320, 27137, 23331, 37777, 13, 51368], "temperature": 0.0, "avg_logprob": -0.3785512613695721, "compression_ratio": 1.4814814814814814, "no_speech_prob": 0.019333332777023315}, {"id": 150, "seek": 91972, "start": 941.48, "end": 942.6800000000001, "text": " We don't use GitHub CI anymore.", "tokens": [51452, 492, 500, 380, 764, 23331, 37777, 3602, 13, 51512], "temperature": 0.0, "avg_logprob": -0.3785512613695721, "compression_ratio": 1.4814814814814814, "no_speech_prob": 0.019333332777023315}, {"id": 151, "seek": 91972, "start": 943.5600000000001, "end": 944.84, "text": " Yeah, we don't use GitHub CI anymore.", "tokens": [51556, 865, 11, 321, 500, 380, 764, 23331, 37777, 3602, 13, 51620], "temperature": 0.0, "avg_logprob": -0.3785512613695721, "compression_ratio": 1.4814814814814814, "no_speech_prob": 0.019333332777023315}, {"id": 152, "seek": 94484, "start": 945.1600000000001, "end": 949.64, "text": " Alright.", "tokens": [50380, 2798, 13, 50604], "temperature": 1.0, "avg_logprob": -2.052871513366699, "compression_ratio": 0.7037037037037037, "no_speech_prob": 0.01697865128517151}, {"id": 153, "seek": 94484, "start": 949.64, "end": 957.98, "text": " Thank you.", "tokens": [50604, 1044, 291, 13, 51021], "temperature": 1.0, "avg_logprob": -2.052871513366699, "compression_ratio": 0.7037037037037037, "no_speech_prob": 0.01697865128517151}], "language": "en"}