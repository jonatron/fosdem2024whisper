{"text": " We're here with Dennis Luxald to present annotated type hinge you can use at runtime. Dennis is a Python developer working for the label on post-gres infrastructure and automation. And he's been a long time free software hacker. Thank you very much for being here with us, Dennis. Thank you. Thank you. So annotated type hinge you can use at runtime. First of you want to learn me, I work at Delibos with a small French company doing post-gres service. And they are do database infrastructure automation and also trying to contribute to process ecosystem. Most notably recently the psychophagy database adapter in Python. And last but not least, Python project at SciPy or Macro. So why talking about annotated? Perhaps we have seen this kind of code in the wild recently or less recently. It's taken from Python documentation. Python is a well-known and famous nowadays data modeling and validation library in Python. And you can see from their documentation, especially recently since the version of library, that's this annotated pattern kind of spread everywhere in the library. Another example is here a code sample from Fast API, which is another famous library useful for doing web API in Python. And there is also this annotated pattern here. When I stumbled upon this last year when doing a migration to Python in V2, I was kind of disappointed because this syntax looks well in Python. It's verbose, it's not really usual in Python. So I wanted to talk about it and why. First, let's see how it works because it's not very intuitive to me. Then I wondered how can I use and define my annotation in order to use the annotated syntax using my annotation to when I would define not just the one that would be provided by the library and for which use cases. So the line of the talk is threefold. First I'll introduce typing.annotated, which is defined in a PEP, 593. And then we'll walk through a few of these cases involving data-centric models and doing validation, serialization, and user interface, all using annotated. And first and third I'll discuss what the adoption in the community and ecosystem of this annotated construct. So let's start with PEP 593. So when it is defined in the typing module, it's in the standard library, but in my opinion it's not really a typing similar to others. It's more like an annotation. Maybe more in the spirit of the initial idea of function annotation defined in a pre-old PEP now in which you can attach an annotation to an identifier using the colon symbol. And then it was used for typing, but really here we have the ability to annotate identifiers. Identifiers are for example class attributes, function parameters, or anything in the name space like a module or something. It's here since Python 3.9 or in typing instruction if you have a Python installation. And the PEP is named flexible function and variable annotations. What does it tell? It tells that you can annotate a variable named veer with the type int annotated, which takes at least two arguments. The first one is a valid type, could be a built-in type or custom type you define. And then it takes at least one metadata or annotation. I would use the metadata or annotation in an interchangeable manner in the following. And you need to pass only one annotation, but you can pass many of them. The key idea of this is that this metadata can be used for static analysis and also at runtime, which is pretty new in the typing ecosystem. And it opens for pretty interesting use case in my opinion, although syntax is a bit well. I think it's also interesting because it's designed to be composable, meaning I'm quoting the PEP here, but basically it means that when a tool analyses the code base, the data static analysis or at runtime, and it encounters an annotation it does not know, it should ignore it. And if it encounters an annotation it owns, typically because it defines it, it should handle it. So it means that if you use annotated to combine many annotations from different source, you can expect them to play well together. How to consume annotations? Because once you have defined annotated values you will need to consume them. In the typing module, still in the standard library, you have a couple of utility functions I will introduce here. The first one is getTypins, which can be used for any kind of object like a class, even an instance of a class or functions, any three terms, a mapping from attribute names to their typings. So if we have this point at a class with two attributes, the second one being annotated, we can see that the int value, which is dictionary, returns x and y, and x is simply the integer class, and y is the annotated construct. You can also use annotations and gender attributes, but getTypins is more powerful in general. From there, you need to inspect individual annotations, and you have two functions, you have getOrigin and getAx, still from the typing module. If you use getOrigin on the typings, it allows to discriminate between all the typing constructs that are in the typing module, and especially in the defying in your case, which one are annotated types. So you can compare these results with the ease operator, for instance. Then you can extract the arguments of the annotated value, which means here in our example, in our y example, getting the type and annotations as a list here. So that's how you consume annotation. And in general, thanks to the composability principle I exposed before, once you have extracted all the annotations, you would ignore the ones that you are not interested in. Here we only endow the label annotation which we own, and we ignore the others. So we typically check this with an instant check. To wrap this up, I'll introduce this simple helper. It's not full proof, but it works for our examples. Basically, it uses getTypings, getOrigin, and getArgs in order to work through the annotation of an object and find the one matching the specified type here. So we to illustrate it, if we use getAnnotation on the point class introduced before and trying to match the label annotation, we get these results. So the y attribute, the y name, the annotation, and the type bound to the attribute. So I'll reuse this function here later on. So that's all for the presentation of annotated from the PEP and how to consume them. I will now introduce some use cases in order to illustrate why you would want to use annotated or why not, maybe. I'll use this simple model which is a calendar event model. It uses pyidentic as a base model. So again, pyidentic is a famous library for doing data modeling and validation or stylization. It's similar in scope to data class. And here we have an event model with a few fields, a summary description, and two dates defining the duration of the event. And the following will do three things. The first one will do validation of the daytime fields. We'll do this using pyidentic built-ins annotation. So we'll see how to use third-party annotations. Then we'll do high-calendar stylization. High-calendar is a simple format for XMG calendar data, text format. But we'll see how to implement our own annotation in order to perform stylization. And the third one will be console rendering. We'll build some kind of user interface in the console in order to print and display calendar events. So again, this will illustrate how to define our own annotation. So starting with daytime validation. We define, we use here the built-in annotation from pyidentic. And namely, it's the aftervalidator, which is some kind of annotation factory, because it takes a function here tzware, which as its name suggests, would validate that the daytime value is not naive. Meaning it has a time zone defined. So here, you can simply define tzware type by combining the daytime field with the pyidentic shipped annotation construct and your own validation logic. Here, I'm defining an event with a naive time zone. And we can see that pyidentic produced a validation error, which under the hood is triggered by our value error with the expecting a tzware daytime message. So it works. As a side step, I would like to mention that before using annotated in pyidentic, in all the versions of pyidentic, the pattern for doing validation was through using class methods and decorators, namely the field validator decorator, in which you have to define custom method in your model classes, and you have to bind the attributes you want to validate to the method using the field validator decorator. So that's another way to define validation in pyidentic, not using the annotation. And why, in my opinion, the annotated pattern was adopted in pyidentic is for the following reason, I would say. Because the validation method, the class method is loosely bound to the attributes. You can see that there is no direct relationship between the start art and end art field definition and the validation, whereas in the previous example, with the annotation, you have inline combination of type and annotations. Then if you have different classes using the same validation because validating a non-native daytime is quite usual, you would have to repeat the method in all your model classes. And similar for all use cases, less like serialization. So that's why I think the annotated patterns has taken adoption in this kind of library. Here we simply introduce an alias, tzdatetime, which is the annotated daytime with or validator in order to make or code less variables. So that's one idea of annotated, despite being verbose, you can use aliases. And you can define your base model class just using the aliases. Next, next you see is ICANN under serialization. Here, obviously, I'm using, I'm adding another annotation. These annotations are defined in the ICANN module, which I will introduce later. And there are serializer instances. An ICANN under serialization just takes a label name, which would be used to serialize the data. So here you can see that we have combined different annotations in the same annotated construct, because here our tzdatetime is already in an annotated value and it's again wrapped in another annotated construct with another annotation. All this is flattened at runtime. In the ICANN module I mentioned earlier, we have this serializer class. Here it's a data class. We have the label field. And we have a simple serialization method, which does some transformation between the value, which would be the field value, and specify it. So if it's a date, we need to remove the time zone and change to ETC and use this kind of format. Then we use this function, which takes the object events, walks through the annotation using the get annotation function introduced later and it calls the serial's value. And we join the result using this. So an example here, we still define our event model. We get the date and we can print the serialization in the 9-calendar format. I'm going to work up to define and consume an annotation. The first thing you do is to define annotation, typically as classes, the data class is quite handy for this. You can define options and you would typically implement an underline method in order to process the value. Then you add and take your data type using annotated, obviously. And then you consume your object using the get annotation patterns I would annotate a bit earlier. The third use case, here we are stacking another layer of annotations from the UI module, the UI module I will introduce later. We are adding UI annotation in order to define all the fields of our event model will be serialized in the console. We have a text annotation, a margithon field for the description and we have data serializer for description. Here we will be using the rich library, which is a pretty nice library for doing console rendering and building terminal user interfaces. The widgets, which are the annotations we have used in the previous example are defined here using classes, following the pattern I introduced before. And they basically delegate to rich to do the rendering of a field and then do the running on the type of the field. Here it's another way to process the annotation instead of introducing a custom function for processing the object. We introduce a mixing class, which follows the rich protocol. It's defined in documentation. You need to define a Dunder rich console method. And there, again, we used our get annotation function looking for the widget class, widget annotations. And if we found some, we call the render method of our widgets, get the value and we need the text value. We use this as a mixing, so we extend our class events. If we take another example, we added a description with some margithon formats. The dates field here are the same. Simply, they will be colored depending on whether the events are started or not. So if you reach, print, or events, we get this. We can see that we have margithon interpreted things in the description and the start date is green. So that's all for use cases. I hope I've demonstrated why you would want to use annotated or why not, maybe. Then I will discuss about the adoption of this pattern in the ecosystem and community. First, we have adopters, like I mentioned before, by the antique, fast API, or typo. So you have this kind of code in the wild. And you might want to get used to this because I think it's here to stay in this library. I hope I've demystified the pattern so that you can understand what it does it mean to have this kind of code in the documentation and if you copy-paste it, for example. There's an interesting project in annotated type, which provides reusable constraint type to be used with annotated so that you don't have to define your quite classic annotation. It's also adopted in a SQL alchemy, although it's a bit more involved because you have to use the mapped type annotated file. And obviously, in a project with less coupling with the typing system, there is less enthusiasm. It's obvious. This brings me to some skepticism I've seen in the community. First of all, I've used in annotated is quite verbose. The symbol is already in uncultured and if you stack different kind of annotation in the same type, it's getting verbose so you have to take care about this. It's us, readability. Then it's kind of awkward because annotations are not necessarily typing, although most consumers do use typing information. But if you don't want to use typing, you cannot really use the annotation as provided by annotated at the moment. Also, consuming annotation is a bit tedious as we have seen. You have to write some bullet-plate code. And there is more coming. Here, there is a pep I would like to mention, 724.27, which would introduce a doc construct in the typing module, which would be used through document fields. So again, it's not typed, but it's in the typing module. So this brings us to the typing topic, which as you may know, in the Python community is quite divisive because there are some fans of the typing and some are not. And this, I think Python is growing with its features because they bring user value. The example I've shown in Fast API are a lot more expressive, in my opinion, than the one that you would typically use in other metaprogramming patterns, like decorators and so on. And if you want to deep dive more in this topic, I encourage you to read this LWNN article, which was published recently, and it provides quite a nice overview of the typing issue or topic in the ecosystem and community. Thank you for your attention. I'm done. And if you have some questions or some thoughts to share, but annotated, I'm happy to discuss. Thank you very much, Tennis. Do we have any questions? Let's see. Now is your chance to raise your hand. I can see one question there. Don't be shy. Raise high, please. Hello. Thanks for your talk. It was very cool. Could you go into a little bit more detail of how I could use annotated on my own class? Because like I saw it in Pydantic and I was like, oh, cool. But I didn't quite get how I could use that in my own... Sorry, can you repeat? No, okay. Could you tell me how I could use that annotated trick on my own class instead of it being like a Pydantic base model thing? Yeah, that's what I illustrated. So here you have this cellulizer, which is a class I just defined for the example. And then you annotate your attribute with your cellulizer instances. Here it takes an option, which is the label of the cellulization value. And then you need to write this kind of function in order to consume the annotation of the instance of your event class. Yeah, but the event was inheriting from base model, which was a Pydantic thing. So if I'm in my own project... You don't need to do this Pydantic for this. You can take a built-in class or a data class, or... It's not related to Pydantic. The Pydantic thing was just for the first example, validating the time. Apart from that, you don't need Pydantic at all. Okay, thank you very much. Thank you. Do we have any more questions? One more. One more. The session is still being recorded. So please be silent there. How can we reach you? I'm not sure if it's okay to ask that. Is it possible to use that in Django, REST, and WorkSphere Realizer? Have you tried or have you seen anyone try that using this one? Is it Django, REST, and WorkSphere Realizer? In Django? Yes, Django, REST, and WorkSphere Realizer. I don't know. I don't know Django, REST, and WorkSphere Realizer. In fact, you can use it as long as you define your own way of consuming the annotation. So if you want this kind of helper function, you can use it, definitely. Okay. It's not bound to a particular framework, in fact. It's in the standard pattern. Thank you very much. Another round of applause for Dennis.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 13.68, "text": " We're here with Dennis Luxald to present annotated type hinge you can use at runtime.", "tokens": [50364, 492, 434, 510, 365, 23376, 25767, 3976, 281, 1974, 25339, 770, 2010, 28822, 291, 393, 764, 412, 34474, 13, 51048], "temperature": 0.0, "avg_logprob": -0.41348559614540875, "compression_ratio": 1.435897435897436, "no_speech_prob": 0.4542396068572998}, {"id": 1, "seek": 0, "start": 13.68, "end": 20.080000000000002, "text": " Dennis is a Python developer working for the label on post-gres infrastructure and automation.", "tokens": [51048, 23376, 307, 257, 15329, 10754, 1364, 337, 264, 7645, 322, 2183, 12, 45189, 6896, 293, 17769, 13, 51368], "temperature": 0.0, "avg_logprob": -0.41348559614540875, "compression_ratio": 1.435897435897436, "no_speech_prob": 0.4542396068572998}, {"id": 2, "seek": 0, "start": 20.080000000000002, "end": 24.28, "text": " And he's been a long time free software hacker.", "tokens": [51368, 400, 415, 311, 668, 257, 938, 565, 1737, 4722, 38155, 13, 51578], "temperature": 0.0, "avg_logprob": -0.41348559614540875, "compression_ratio": 1.435897435897436, "no_speech_prob": 0.4542396068572998}, {"id": 3, "seek": 0, "start": 24.28, "end": 27.88, "text": " Thank you very much for being here with us, Dennis.", "tokens": [51578, 1044, 291, 588, 709, 337, 885, 510, 365, 505, 11, 23376, 13, 51758], "temperature": 0.0, "avg_logprob": -0.41348559614540875, "compression_ratio": 1.435897435897436, "no_speech_prob": 0.4542396068572998}, {"id": 4, "seek": 2788, "start": 27.88, "end": 33.879999999999995, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 50664], "temperature": 0.0, "avg_logprob": -0.4315065590732069, "compression_ratio": 1.497797356828194, "no_speech_prob": 0.028394557535648346}, {"id": 5, "seek": 2788, "start": 33.879999999999995, "end": 37.879999999999995, "text": " Thank you. So annotated type hinge you can use at runtime.", "tokens": [50664, 1044, 291, 13, 407, 25339, 770, 2010, 28822, 291, 393, 764, 412, 34474, 13, 50864], "temperature": 0.0, "avg_logprob": -0.4315065590732069, "compression_ratio": 1.497797356828194, "no_speech_prob": 0.028394557535648346}, {"id": 6, "seek": 2788, "start": 37.879999999999995, "end": 43.879999999999995, "text": " First of you want to learn me, I work at Delibos with a small French company doing post-gres service.", "tokens": [50864, 2386, 295, 291, 528, 281, 1466, 385, 11, 286, 589, 412, 5831, 897, 329, 365, 257, 1359, 5522, 2237, 884, 2183, 12, 45189, 2643, 13, 51164], "temperature": 0.0, "avg_logprob": -0.4315065590732069, "compression_ratio": 1.497797356828194, "no_speech_prob": 0.028394557535648346}, {"id": 7, "seek": 2788, "start": 43.879999999999995, "end": 50.879999999999995, "text": " And they are do database infrastructure automation and also trying to contribute to process ecosystem.", "tokens": [51164, 400, 436, 366, 360, 8149, 6896, 17769, 293, 611, 1382, 281, 10586, 281, 1399, 11311, 13, 51514], "temperature": 0.0, "avg_logprob": -0.4315065590732069, "compression_ratio": 1.497797356828194, "no_speech_prob": 0.028394557535648346}, {"id": 8, "seek": 2788, "start": 50.879999999999995, "end": 55.879999999999995, "text": " Most notably recently the psychophagy database adapter in Python.", "tokens": [51514, 4534, 31357, 3938, 264, 4681, 5317, 559, 88, 8149, 22860, 294, 15329, 13, 51764], "temperature": 0.0, "avg_logprob": -0.4315065590732069, "compression_ratio": 1.497797356828194, "no_speech_prob": 0.028394557535648346}, {"id": 9, "seek": 5588, "start": 55.88, "end": 60.88, "text": " And last but not least, Python project at SciPy or Macro.", "tokens": [50364, 400, 1036, 457, 406, 1935, 11, 15329, 1716, 412, 16942, 47, 88, 420, 5707, 340, 13, 50614], "temperature": 0.0, "avg_logprob": -0.28152453104654945, "compression_ratio": 1.472636815920398, "no_speech_prob": 0.03938397020101547}, {"id": 10, "seek": 5588, "start": 60.88, "end": 63.88, "text": " So why talking about annotated?", "tokens": [50614, 407, 983, 1417, 466, 25339, 770, 30, 50764], "temperature": 0.0, "avg_logprob": -0.28152453104654945, "compression_ratio": 1.472636815920398, "no_speech_prob": 0.03938397020101547}, {"id": 11, "seek": 5588, "start": 63.88, "end": 68.88, "text": " Perhaps we have seen this kind of code in the wild recently or less recently.", "tokens": [50764, 10517, 321, 362, 1612, 341, 733, 295, 3089, 294, 264, 4868, 3938, 420, 1570, 3938, 13, 51014], "temperature": 0.0, "avg_logprob": -0.28152453104654945, "compression_ratio": 1.472636815920398, "no_speech_prob": 0.03938397020101547}, {"id": 12, "seek": 5588, "start": 68.88, "end": 72.88, "text": " It's taken from Python documentation.", "tokens": [51014, 467, 311, 2726, 490, 15329, 14333, 13, 51214], "temperature": 0.0, "avg_logprob": -0.28152453104654945, "compression_ratio": 1.472636815920398, "no_speech_prob": 0.03938397020101547}, {"id": 13, "seek": 5588, "start": 72.88, "end": 78.88, "text": " Python is a well-known and famous nowadays data modeling and validation library in Python.", "tokens": [51214, 15329, 307, 257, 731, 12, 6861, 293, 4618, 13434, 1412, 15983, 293, 24071, 6405, 294, 15329, 13, 51514], "temperature": 0.0, "avg_logprob": -0.28152453104654945, "compression_ratio": 1.472636815920398, "no_speech_prob": 0.03938397020101547}, {"id": 14, "seek": 7888, "start": 78.88, "end": 84.88, "text": " And you can see from their documentation, especially recently since the version of library,", "tokens": [50364, 400, 291, 393, 536, 490, 641, 14333, 11, 2318, 3938, 1670, 264, 3037, 295, 6405, 11, 50664], "temperature": 0.0, "avg_logprob": -0.21967150035657382, "compression_ratio": 1.6146341463414635, "no_speech_prob": 0.040866415947675705}, {"id": 15, "seek": 7888, "start": 84.88, "end": 91.88, "text": " that's this annotated pattern kind of spread everywhere in the library.", "tokens": [50664, 300, 311, 341, 25339, 770, 5102, 733, 295, 3974, 5315, 294, 264, 6405, 13, 51014], "temperature": 0.0, "avg_logprob": -0.21967150035657382, "compression_ratio": 1.6146341463414635, "no_speech_prob": 0.040866415947675705}, {"id": 16, "seek": 7888, "start": 91.88, "end": 99.88, "text": " Another example is here a code sample from Fast API, which is another famous library", "tokens": [51014, 3996, 1365, 307, 510, 257, 3089, 6889, 490, 15968, 9362, 11, 597, 307, 1071, 4618, 6405, 51414], "temperature": 0.0, "avg_logprob": -0.21967150035657382, "compression_ratio": 1.6146341463414635, "no_speech_prob": 0.040866415947675705}, {"id": 17, "seek": 7888, "start": 99.88, "end": 103.88, "text": " useful for doing web API in Python.", "tokens": [51414, 4420, 337, 884, 3670, 9362, 294, 15329, 13, 51614], "temperature": 0.0, "avg_logprob": -0.21967150035657382, "compression_ratio": 1.6146341463414635, "no_speech_prob": 0.040866415947675705}, {"id": 18, "seek": 7888, "start": 103.88, "end": 107.88, "text": " And there is also this annotated pattern here.", "tokens": [51614, 400, 456, 307, 611, 341, 25339, 770, 5102, 510, 13, 51814], "temperature": 0.0, "avg_logprob": -0.21967150035657382, "compression_ratio": 1.6146341463414635, "no_speech_prob": 0.040866415947675705}, {"id": 19, "seek": 10788, "start": 107.88, "end": 115.88, "text": " When I stumbled upon this last year when doing a migration to Python in V2,", "tokens": [50364, 1133, 286, 36668, 3564, 341, 1036, 1064, 562, 884, 257, 17011, 281, 15329, 294, 691, 17, 11, 50764], "temperature": 0.0, "avg_logprob": -0.17451891084996665, "compression_ratio": 1.5126903553299493, "no_speech_prob": 0.009440950118005276}, {"id": 20, "seek": 10788, "start": 115.88, "end": 120.88, "text": " I was kind of disappointed because this syntax looks well in Python.", "tokens": [50764, 286, 390, 733, 295, 13856, 570, 341, 28431, 1542, 731, 294, 15329, 13, 51014], "temperature": 0.0, "avg_logprob": -0.17451891084996665, "compression_ratio": 1.5126903553299493, "no_speech_prob": 0.009440950118005276}, {"id": 21, "seek": 10788, "start": 120.88, "end": 124.88, "text": " It's verbose, it's not really usual in Python.", "tokens": [51014, 467, 311, 9595, 541, 11, 309, 311, 406, 534, 7713, 294, 15329, 13, 51214], "temperature": 0.0, "avg_logprob": -0.17451891084996665, "compression_ratio": 1.5126903553299493, "no_speech_prob": 0.009440950118005276}, {"id": 22, "seek": 10788, "start": 124.88, "end": 127.88, "text": " So I wanted to talk about it and why.", "tokens": [51214, 407, 286, 1415, 281, 751, 466, 309, 293, 983, 13, 51364], "temperature": 0.0, "avg_logprob": -0.17451891084996665, "compression_ratio": 1.5126903553299493, "no_speech_prob": 0.009440950118005276}, {"id": 23, "seek": 10788, "start": 127.88, "end": 134.88, "text": " First, let's see how it works because it's not very intuitive to me.", "tokens": [51364, 2386, 11, 718, 311, 536, 577, 309, 1985, 570, 309, 311, 406, 588, 21769, 281, 385, 13, 51714], "temperature": 0.0, "avg_logprob": -0.17451891084996665, "compression_ratio": 1.5126903553299493, "no_speech_prob": 0.009440950118005276}, {"id": 24, "seek": 13488, "start": 134.88, "end": 141.88, "text": " Then I wondered how can I use and define my annotation in order to use the annotated syntax", "tokens": [50364, 1396, 286, 17055, 577, 393, 286, 764, 293, 6964, 452, 48654, 294, 1668, 281, 764, 264, 25339, 770, 28431, 50714], "temperature": 0.0, "avg_logprob": -0.2198298004851944, "compression_ratio": 1.599009900990099, "no_speech_prob": 0.003616641741245985}, {"id": 25, "seek": 13488, "start": 141.88, "end": 147.88, "text": " using my annotation to when I would define not just the one that would be provided by the library", "tokens": [50714, 1228, 452, 48654, 281, 562, 286, 576, 6964, 406, 445, 264, 472, 300, 576, 312, 5649, 538, 264, 6405, 51014], "temperature": 0.0, "avg_logprob": -0.2198298004851944, "compression_ratio": 1.599009900990099, "no_speech_prob": 0.003616641741245985}, {"id": 26, "seek": 13488, "start": 147.88, "end": 150.88, "text": " and for which use cases.", "tokens": [51014, 293, 337, 597, 764, 3331, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2198298004851944, "compression_ratio": 1.599009900990099, "no_speech_prob": 0.003616641741245985}, {"id": 27, "seek": 13488, "start": 150.88, "end": 153.88, "text": " So the line of the talk is threefold.", "tokens": [51164, 407, 264, 1622, 295, 264, 751, 307, 1045, 18353, 13, 51314], "temperature": 0.0, "avg_logprob": -0.2198298004851944, "compression_ratio": 1.599009900990099, "no_speech_prob": 0.003616641741245985}, {"id": 28, "seek": 13488, "start": 153.88, "end": 159.88, "text": " First I'll introduce typing.annotated, which is defined in a PEP, 593.", "tokens": [51314, 2386, 286, 603, 5366, 18444, 13, 969, 310, 770, 11, 597, 307, 7642, 294, 257, 430, 8929, 11, 1025, 26372, 13, 51614], "temperature": 0.0, "avg_logprob": -0.2198298004851944, "compression_ratio": 1.599009900990099, "no_speech_prob": 0.003616641741245985}, {"id": 29, "seek": 15988, "start": 159.88, "end": 166.88, "text": " And then we'll walk through a few of these cases involving data-centric models", "tokens": [50364, 400, 550, 321, 603, 1792, 807, 257, 1326, 295, 613, 3331, 17030, 1412, 12, 45300, 5245, 50714], "temperature": 0.0, "avg_logprob": -0.17840290069580078, "compression_ratio": 1.458128078817734, "no_speech_prob": 0.0032071785535663366}, {"id": 30, "seek": 15988, "start": 166.88, "end": 172.88, "text": " and doing validation, serialization, and user interface, all using annotated.", "tokens": [50714, 293, 884, 24071, 11, 17436, 2144, 11, 293, 4195, 9226, 11, 439, 1228, 25339, 770, 13, 51014], "temperature": 0.0, "avg_logprob": -0.17840290069580078, "compression_ratio": 1.458128078817734, "no_speech_prob": 0.0032071785535663366}, {"id": 31, "seek": 15988, "start": 172.88, "end": 180.88, "text": " And first and third I'll discuss what the adoption in the community and ecosystem of this annotated construct.", "tokens": [51014, 400, 700, 293, 2636, 286, 603, 2248, 437, 264, 19215, 294, 264, 1768, 293, 11311, 295, 341, 25339, 770, 7690, 13, 51414], "temperature": 0.0, "avg_logprob": -0.17840290069580078, "compression_ratio": 1.458128078817734, "no_speech_prob": 0.0032071785535663366}, {"id": 32, "seek": 15988, "start": 180.88, "end": 185.88, "text": " So let's start with PEP 593.", "tokens": [51414, 407, 718, 311, 722, 365, 430, 8929, 1025, 26372, 13, 51664], "temperature": 0.0, "avg_logprob": -0.17840290069580078, "compression_ratio": 1.458128078817734, "no_speech_prob": 0.0032071785535663366}, {"id": 33, "seek": 18588, "start": 186.88, "end": 192.88, "text": " So when it is defined in the typing module, it's in the standard library,", "tokens": [50414, 407, 562, 309, 307, 7642, 294, 264, 18444, 10088, 11, 309, 311, 294, 264, 3832, 6405, 11, 50714], "temperature": 0.0, "avg_logprob": -0.21980368572732675, "compression_ratio": 1.5595238095238095, "no_speech_prob": 0.001045814249664545}, {"id": 34, "seek": 18588, "start": 192.88, "end": 198.88, "text": " but in my opinion it's not really a typing similar to others.", "tokens": [50714, 457, 294, 452, 4800, 309, 311, 406, 534, 257, 18444, 2531, 281, 2357, 13, 51014], "temperature": 0.0, "avg_logprob": -0.21980368572732675, "compression_ratio": 1.5595238095238095, "no_speech_prob": 0.001045814249664545}, {"id": 35, "seek": 18588, "start": 198.88, "end": 202.88, "text": " It's more like an annotation.", "tokens": [51014, 467, 311, 544, 411, 364, 48654, 13, 51214], "temperature": 0.0, "avg_logprob": -0.21980368572732675, "compression_ratio": 1.5595238095238095, "no_speech_prob": 0.001045814249664545}, {"id": 36, "seek": 18588, "start": 202.88, "end": 210.88, "text": " Maybe more in the spirit of the initial idea of function annotation defined in a pre-old PEP now", "tokens": [51214, 2704, 544, 294, 264, 3797, 295, 264, 5883, 1558, 295, 2445, 48654, 7642, 294, 257, 659, 12, 2641, 430, 8929, 586, 51614], "temperature": 0.0, "avg_logprob": -0.21980368572732675, "compression_ratio": 1.5595238095238095, "no_speech_prob": 0.001045814249664545}, {"id": 37, "seek": 21088, "start": 210.88, "end": 219.88, "text": " in which you can attach an annotation to an identifier using the colon symbol.", "tokens": [50364, 294, 597, 291, 393, 5085, 364, 48654, 281, 364, 45690, 1228, 264, 8255, 5986, 13, 50814], "temperature": 0.0, "avg_logprob": -0.16728159207016674, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.003229717258363962}, {"id": 38, "seek": 21088, "start": 219.88, "end": 229.88, "text": " And then it was used for typing, but really here we have the ability to annotate identifiers.", "tokens": [50814, 400, 550, 309, 390, 1143, 337, 18444, 11, 457, 534, 510, 321, 362, 264, 3485, 281, 25339, 473, 2473, 23463, 13, 51314], "temperature": 0.0, "avg_logprob": -0.16728159207016674, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.003229717258363962}, {"id": 39, "seek": 21088, "start": 229.88, "end": 239.88, "text": " Identifiers are for example class attributes, function parameters, or anything in the name space like a module or something.", "tokens": [51314, 25905, 23463, 366, 337, 1365, 1508, 17212, 11, 2445, 9834, 11, 420, 1340, 294, 264, 1315, 1901, 411, 257, 10088, 420, 746, 13, 51814], "temperature": 0.0, "avg_logprob": -0.16728159207016674, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.003229717258363962}, {"id": 40, "seek": 23988, "start": 240.88, "end": 250.88, "text": " It's here since Python 3.9 or in typing instruction if you have a Python installation.", "tokens": [50414, 467, 311, 510, 1670, 15329, 805, 13, 24, 420, 294, 18444, 10951, 498, 291, 362, 257, 15329, 13260, 13, 50914], "temperature": 0.0, "avg_logprob": -0.1723080403877027, "compression_ratio": 1.5089820359281436, "no_speech_prob": 0.003079329151660204}, {"id": 41, "seek": 23988, "start": 250.88, "end": 255.88, "text": " And the PEP is named flexible function and variable annotations.", "tokens": [50914, 400, 264, 430, 8929, 307, 4926, 11358, 2445, 293, 7006, 25339, 763, 13, 51164], "temperature": 0.0, "avg_logprob": -0.1723080403877027, "compression_ratio": 1.5089820359281436, "no_speech_prob": 0.003079329151660204}, {"id": 42, "seek": 23988, "start": 255.88, "end": 257.88, "text": " What does it tell?", "tokens": [51164, 708, 775, 309, 980, 30, 51264], "temperature": 0.0, "avg_logprob": -0.1723080403877027, "compression_ratio": 1.5089820359281436, "no_speech_prob": 0.003079329151660204}, {"id": 43, "seek": 23988, "start": 257.88, "end": 265.88, "text": " It tells that you can annotate a variable named veer with the type int annotated,", "tokens": [51264, 467, 5112, 300, 291, 393, 25339, 473, 257, 7006, 4926, 1241, 260, 365, 264, 2010, 560, 25339, 770, 11, 51664], "temperature": 0.0, "avg_logprob": -0.1723080403877027, "compression_ratio": 1.5089820359281436, "no_speech_prob": 0.003079329151660204}, {"id": 44, "seek": 26588, "start": 265.88, "end": 267.88, "text": " which takes at least two arguments.", "tokens": [50364, 597, 2516, 412, 1935, 732, 12869, 13, 50464], "temperature": 0.0, "avg_logprob": -0.12225053423926943, "compression_ratio": 1.6852791878172588, "no_speech_prob": 0.004296510014683008}, {"id": 45, "seek": 26588, "start": 267.88, "end": 272.88, "text": " The first one is a valid type, could be a built-in type or custom type you define.", "tokens": [50464, 440, 700, 472, 307, 257, 7363, 2010, 11, 727, 312, 257, 3094, 12, 259, 2010, 420, 2375, 2010, 291, 6964, 13, 50714], "temperature": 0.0, "avg_logprob": -0.12225053423926943, "compression_ratio": 1.6852791878172588, "no_speech_prob": 0.004296510014683008}, {"id": 46, "seek": 26588, "start": 272.88, "end": 276.88, "text": " And then it takes at least one metadata or annotation.", "tokens": [50714, 400, 550, 309, 2516, 412, 1935, 472, 26603, 420, 48654, 13, 50914], "temperature": 0.0, "avg_logprob": -0.12225053423926943, "compression_ratio": 1.6852791878172588, "no_speech_prob": 0.004296510014683008}, {"id": 47, "seek": 26588, "start": 276.88, "end": 284.88, "text": " I would use the metadata or annotation in an interchangeable manner in the following.", "tokens": [50914, 286, 576, 764, 264, 26603, 420, 48654, 294, 364, 30358, 712, 9060, 294, 264, 3480, 13, 51314], "temperature": 0.0, "avg_logprob": -0.12225053423926943, "compression_ratio": 1.6852791878172588, "no_speech_prob": 0.004296510014683008}, {"id": 48, "seek": 26588, "start": 284.88, "end": 289.88, "text": " And you need to pass only one annotation, but you can pass many of them.", "tokens": [51314, 400, 291, 643, 281, 1320, 787, 472, 48654, 11, 457, 291, 393, 1320, 867, 295, 552, 13, 51564], "temperature": 0.0, "avg_logprob": -0.12225053423926943, "compression_ratio": 1.6852791878172588, "no_speech_prob": 0.004296510014683008}, {"id": 49, "seek": 28988, "start": 289.88, "end": 295.88, "text": " The key idea of this is that this metadata can be used for static analysis and also at runtime,", "tokens": [50364, 440, 2141, 1558, 295, 341, 307, 300, 341, 26603, 393, 312, 1143, 337, 13437, 5215, 293, 611, 412, 34474, 11, 50664], "temperature": 0.0, "avg_logprob": -0.1407654692487019, "compression_ratio": 1.5296803652968036, "no_speech_prob": 0.01773545891046524}, {"id": 50, "seek": 28988, "start": 295.88, "end": 298.88, "text": " which is pretty new in the typing ecosystem.", "tokens": [50664, 597, 307, 1238, 777, 294, 264, 18444, 11311, 13, 50814], "temperature": 0.0, "avg_logprob": -0.1407654692487019, "compression_ratio": 1.5296803652968036, "no_speech_prob": 0.01773545891046524}, {"id": 51, "seek": 28988, "start": 298.88, "end": 306.88, "text": " And it opens for pretty interesting use case in my opinion, although syntax is a bit well.", "tokens": [50814, 400, 309, 9870, 337, 1238, 1880, 764, 1389, 294, 452, 4800, 11, 4878, 28431, 307, 257, 857, 731, 13, 51214], "temperature": 0.0, "avg_logprob": -0.1407654692487019, "compression_ratio": 1.5296803652968036, "no_speech_prob": 0.01773545891046524}, {"id": 52, "seek": 28988, "start": 306.88, "end": 313.88, "text": " I think it's also interesting because it's designed to be composable, meaning I'm quoting the PEP here,", "tokens": [51214, 286, 519, 309, 311, 611, 1880, 570, 309, 311, 4761, 281, 312, 10199, 712, 11, 3620, 286, 478, 41552, 264, 430, 8929, 510, 11, 51564], "temperature": 0.0, "avg_logprob": -0.1407654692487019, "compression_ratio": 1.5296803652968036, "no_speech_prob": 0.01773545891046524}, {"id": 53, "seek": 31388, "start": 313.88, "end": 318.88, "text": " but basically it means that when a tool analyses the code base,", "tokens": [50364, 457, 1936, 309, 1355, 300, 562, 257, 2290, 37560, 264, 3089, 3096, 11, 50614], "temperature": 0.0, "avg_logprob": -0.17777660281159158, "compression_ratio": 1.805, "no_speech_prob": 0.010969765484333038}, {"id": 54, "seek": 31388, "start": 318.88, "end": 325.88, "text": " the data static analysis or at runtime, and it encounters an annotation it does not know,", "tokens": [50614, 264, 1412, 13437, 5215, 420, 412, 34474, 11, 293, 309, 26310, 364, 48654, 309, 775, 406, 458, 11, 50964], "temperature": 0.0, "avg_logprob": -0.17777660281159158, "compression_ratio": 1.805, "no_speech_prob": 0.010969765484333038}, {"id": 55, "seek": 31388, "start": 325.88, "end": 327.88, "text": " it should ignore it.", "tokens": [50964, 309, 820, 11200, 309, 13, 51064], "temperature": 0.0, "avg_logprob": -0.17777660281159158, "compression_ratio": 1.805, "no_speech_prob": 0.010969765484333038}, {"id": 56, "seek": 31388, "start": 327.88, "end": 334.88, "text": " And if it encounters an annotation it owns, typically because it defines it, it should handle it.", "tokens": [51064, 400, 498, 309, 26310, 364, 48654, 309, 19143, 11, 5850, 570, 309, 23122, 309, 11, 309, 820, 4813, 309, 13, 51414], "temperature": 0.0, "avg_logprob": -0.17777660281159158, "compression_ratio": 1.805, "no_speech_prob": 0.010969765484333038}, {"id": 57, "seek": 31388, "start": 334.88, "end": 339.88, "text": " So it means that if you use annotated to combine many annotations from different source,", "tokens": [51414, 407, 309, 1355, 300, 498, 291, 764, 25339, 770, 281, 10432, 867, 25339, 763, 490, 819, 4009, 11, 51664], "temperature": 0.0, "avg_logprob": -0.17777660281159158, "compression_ratio": 1.805, "no_speech_prob": 0.010969765484333038}, {"id": 58, "seek": 33988, "start": 339.88, "end": 345.88, "text": " you can expect them to play well together.", "tokens": [50364, 291, 393, 2066, 552, 281, 862, 731, 1214, 13, 50664], "temperature": 0.0, "avg_logprob": -0.14318494948129806, "compression_ratio": 1.5290697674418605, "no_speech_prob": 0.005987241398543119}, {"id": 59, "seek": 33988, "start": 345.88, "end": 348.88, "text": " How to consume annotations?", "tokens": [50664, 1012, 281, 14732, 25339, 763, 30, 50814], "temperature": 0.0, "avg_logprob": -0.14318494948129806, "compression_ratio": 1.5290697674418605, "no_speech_prob": 0.005987241398543119}, {"id": 60, "seek": 33988, "start": 348.88, "end": 353.88, "text": " Because once you have defined annotated values you will need to consume them.", "tokens": [50814, 1436, 1564, 291, 362, 7642, 25339, 770, 4190, 291, 486, 643, 281, 14732, 552, 13, 51064], "temperature": 0.0, "avg_logprob": -0.14318494948129806, "compression_ratio": 1.5290697674418605, "no_speech_prob": 0.005987241398543119}, {"id": 61, "seek": 33988, "start": 353.88, "end": 360.88, "text": " In the typing module, still in the standard library, you have a couple of utility functions I will introduce here.", "tokens": [51064, 682, 264, 18444, 10088, 11, 920, 294, 264, 3832, 6405, 11, 291, 362, 257, 1916, 295, 14877, 6828, 286, 486, 5366, 510, 13, 51414], "temperature": 0.0, "avg_logprob": -0.14318494948129806, "compression_ratio": 1.5290697674418605, "no_speech_prob": 0.005987241398543119}, {"id": 62, "seek": 36088, "start": 360.88, "end": 368.88, "text": " The first one is getTypins, which can be used for any kind of object like a class,", "tokens": [50364, 440, 700, 472, 307, 483, 22464, 79, 1292, 11, 597, 393, 312, 1143, 337, 604, 733, 295, 2657, 411, 257, 1508, 11, 50764], "temperature": 0.0, "avg_logprob": -0.21879322888099983, "compression_ratio": 1.55, "no_speech_prob": 0.049178946763277054}, {"id": 63, "seek": 36088, "start": 368.88, "end": 377.88, "text": " even an instance of a class or functions, any three terms, a mapping from attribute names to their typings.", "tokens": [50764, 754, 364, 5197, 295, 257, 1508, 420, 6828, 11, 604, 1045, 2115, 11, 257, 18350, 490, 19667, 5288, 281, 641, 2125, 1109, 13, 51214], "temperature": 0.0, "avg_logprob": -0.21879322888099983, "compression_ratio": 1.55, "no_speech_prob": 0.049178946763277054}, {"id": 64, "seek": 36088, "start": 377.88, "end": 385.88, "text": " So if we have this point at a class with two attributes, the second one being annotated,", "tokens": [51214, 407, 498, 321, 362, 341, 935, 412, 257, 1508, 365, 732, 17212, 11, 264, 1150, 472, 885, 25339, 770, 11, 51614], "temperature": 0.0, "avg_logprob": -0.21879322888099983, "compression_ratio": 1.55, "no_speech_prob": 0.049178946763277054}, {"id": 65, "seek": 38588, "start": 385.88, "end": 391.88, "text": " we can see that the int value, which is dictionary, returns x and y,", "tokens": [50364, 321, 393, 536, 300, 264, 560, 2158, 11, 597, 307, 25890, 11, 11247, 2031, 293, 288, 11, 50664], "temperature": 0.0, "avg_logprob": -0.14738792419433594, "compression_ratio": 1.5483870967741935, "no_speech_prob": 0.002994006499648094}, {"id": 66, "seek": 38588, "start": 391.88, "end": 399.88, "text": " and x is simply the integer class, and y is the annotated construct.", "tokens": [50664, 293, 2031, 307, 2935, 264, 24922, 1508, 11, 293, 288, 307, 264, 25339, 770, 7690, 13, 51064], "temperature": 0.0, "avg_logprob": -0.14738792419433594, "compression_ratio": 1.5483870967741935, "no_speech_prob": 0.002994006499648094}, {"id": 67, "seek": 38588, "start": 399.88, "end": 407.88, "text": " You can also use annotations and gender attributes, but getTypins is more powerful in general.", "tokens": [51064, 509, 393, 611, 764, 25339, 763, 293, 7898, 17212, 11, 457, 483, 22464, 79, 1292, 307, 544, 4005, 294, 2674, 13, 51464], "temperature": 0.0, "avg_logprob": -0.14738792419433594, "compression_ratio": 1.5483870967741935, "no_speech_prob": 0.002994006499648094}, {"id": 68, "seek": 38588, "start": 407.88, "end": 411.88, "text": " From there, you need to inspect individual annotations,", "tokens": [51464, 3358, 456, 11, 291, 643, 281, 15018, 2609, 25339, 763, 11, 51664], "temperature": 0.0, "avg_logprob": -0.14738792419433594, "compression_ratio": 1.5483870967741935, "no_speech_prob": 0.002994006499648094}, {"id": 69, "seek": 41188, "start": 411.88, "end": 417.88, "text": " and you have two functions, you have getOrigin and getAx, still from the typing module.", "tokens": [50364, 293, 291, 362, 732, 6828, 11, 291, 362, 483, 46, 7065, 259, 293, 483, 32, 87, 11, 920, 490, 264, 18444, 10088, 13, 50664], "temperature": 0.0, "avg_logprob": -0.21743405249810988, "compression_ratio": 1.7028301886792452, "no_speech_prob": 0.0045184483751654625}, {"id": 70, "seek": 41188, "start": 417.88, "end": 427.88, "text": " If you use getOrigin on the typings, it allows to discriminate between all the typing constructs that are in the typing module,", "tokens": [50664, 759, 291, 764, 483, 46, 7065, 259, 322, 264, 2125, 1109, 11, 309, 4045, 281, 47833, 1296, 439, 264, 18444, 7690, 82, 300, 366, 294, 264, 18444, 10088, 11, 51164], "temperature": 0.0, "avg_logprob": -0.21743405249810988, "compression_ratio": 1.7028301886792452, "no_speech_prob": 0.0045184483751654625}, {"id": 71, "seek": 41188, "start": 427.88, "end": 432.88, "text": " and especially in the defying in your case, which one are annotated types.", "tokens": [51164, 293, 2318, 294, 264, 1060, 1840, 294, 428, 1389, 11, 597, 472, 366, 25339, 770, 3467, 13, 51414], "temperature": 0.0, "avg_logprob": -0.21743405249810988, "compression_ratio": 1.7028301886792452, "no_speech_prob": 0.0045184483751654625}, {"id": 72, "seek": 41188, "start": 432.88, "end": 437.88, "text": " So you can compare these results with the ease operator, for instance.", "tokens": [51414, 407, 291, 393, 6794, 613, 3542, 365, 264, 12708, 12973, 11, 337, 5197, 13, 51664], "temperature": 0.0, "avg_logprob": -0.21743405249810988, "compression_ratio": 1.7028301886792452, "no_speech_prob": 0.0045184483751654625}, {"id": 73, "seek": 43788, "start": 437.88, "end": 442.88, "text": " Then you can extract the arguments of the annotated value,", "tokens": [50364, 1396, 291, 393, 8947, 264, 12869, 295, 264, 25339, 770, 2158, 11, 50614], "temperature": 0.0, "avg_logprob": -0.15124255507739623, "compression_ratio": 1.5314285714285714, "no_speech_prob": 0.004947789944708347}, {"id": 74, "seek": 43788, "start": 442.88, "end": 452.88, "text": " which means here in our example, in our y example, getting the type and annotations as a list here.", "tokens": [50614, 597, 1355, 510, 294, 527, 1365, 11, 294, 527, 288, 1365, 11, 1242, 264, 2010, 293, 25339, 763, 382, 257, 1329, 510, 13, 51114], "temperature": 0.0, "avg_logprob": -0.15124255507739623, "compression_ratio": 1.5314285714285714, "no_speech_prob": 0.004947789944708347}, {"id": 75, "seek": 43788, "start": 452.88, "end": 456.88, "text": " So that's how you consume annotation.", "tokens": [51114, 407, 300, 311, 577, 291, 14732, 48654, 13, 51314], "temperature": 0.0, "avg_logprob": -0.15124255507739623, "compression_ratio": 1.5314285714285714, "no_speech_prob": 0.004947789944708347}, {"id": 76, "seek": 43788, "start": 456.88, "end": 462.88, "text": " And in general, thanks to the composability principle I exposed before,", "tokens": [51314, 400, 294, 2674, 11, 3231, 281, 264, 10199, 2310, 8665, 286, 9495, 949, 11, 51614], "temperature": 0.0, "avg_logprob": -0.15124255507739623, "compression_ratio": 1.5314285714285714, "no_speech_prob": 0.004947789944708347}, {"id": 77, "seek": 46288, "start": 462.88, "end": 469.88, "text": " once you have extracted all the annotations, you would ignore the ones that you are not interested in.", "tokens": [50364, 1564, 291, 362, 34086, 439, 264, 25339, 763, 11, 291, 576, 11200, 264, 2306, 300, 291, 366, 406, 3102, 294, 13, 50714], "temperature": 0.0, "avg_logprob": -0.16929304876992868, "compression_ratio": 1.5924170616113744, "no_speech_prob": 0.006494579836726189}, {"id": 78, "seek": 46288, "start": 469.88, "end": 475.88, "text": " Here we only endow the label annotation which we own, and we ignore the others.", "tokens": [50714, 1692, 321, 787, 917, 305, 264, 7645, 48654, 597, 321, 1065, 11, 293, 321, 11200, 264, 2357, 13, 51014], "temperature": 0.0, "avg_logprob": -0.16929304876992868, "compression_ratio": 1.5924170616113744, "no_speech_prob": 0.006494579836726189}, {"id": 79, "seek": 46288, "start": 475.88, "end": 481.88, "text": " So we typically check this with an instant check.", "tokens": [51014, 407, 321, 5850, 1520, 341, 365, 364, 9836, 1520, 13, 51314], "temperature": 0.0, "avg_logprob": -0.16929304876992868, "compression_ratio": 1.5924170616113744, "no_speech_prob": 0.006494579836726189}, {"id": 80, "seek": 46288, "start": 481.88, "end": 486.88, "text": " To wrap this up, I'll introduce this simple helper.", "tokens": [51314, 1407, 7019, 341, 493, 11, 286, 603, 5366, 341, 2199, 36133, 13, 51564], "temperature": 0.0, "avg_logprob": -0.16929304876992868, "compression_ratio": 1.5924170616113744, "no_speech_prob": 0.006494579836726189}, {"id": 81, "seek": 46288, "start": 486.88, "end": 490.88, "text": " It's not full proof, but it works for our examples.", "tokens": [51564, 467, 311, 406, 1577, 8177, 11, 457, 309, 1985, 337, 527, 5110, 13, 51764], "temperature": 0.0, "avg_logprob": -0.16929304876992868, "compression_ratio": 1.5924170616113744, "no_speech_prob": 0.006494579836726189}, {"id": 82, "seek": 49088, "start": 490.88, "end": 500.88, "text": " Basically, it uses getTypings, getOrigin, and getArgs in order to work through the annotation of an object", "tokens": [50364, 8537, 11, 309, 4960, 483, 22464, 79, 1109, 11, 483, 46, 7065, 259, 11, 293, 483, 10683, 21559, 294, 1668, 281, 589, 807, 264, 48654, 295, 364, 2657, 50864], "temperature": 0.0, "avg_logprob": -0.18963760962853066, "compression_ratio": 1.4666666666666666, "no_speech_prob": 0.0029354053549468517}, {"id": 83, "seek": 49088, "start": 500.88, "end": 506.88, "text": " and find the one matching the specified type here.", "tokens": [50864, 293, 915, 264, 472, 14324, 264, 22206, 2010, 510, 13, 51164], "temperature": 0.0, "avg_logprob": -0.18963760962853066, "compression_ratio": 1.4666666666666666, "no_speech_prob": 0.0029354053549468517}, {"id": 84, "seek": 49088, "start": 506.88, "end": 515.88, "text": " So we to illustrate it, if we use getAnnotation on the point class introduced before", "tokens": [51164, 407, 321, 281, 23221, 309, 11, 498, 321, 764, 483, 7828, 2247, 399, 322, 264, 935, 1508, 7268, 949, 51614], "temperature": 0.0, "avg_logprob": -0.18963760962853066, "compression_ratio": 1.4666666666666666, "no_speech_prob": 0.0029354053549468517}, {"id": 85, "seek": 51588, "start": 515.88, "end": 520.88, "text": " and trying to match the label annotation, we get these results.", "tokens": [50364, 293, 1382, 281, 2995, 264, 7645, 48654, 11, 321, 483, 613, 3542, 13, 50614], "temperature": 0.0, "avg_logprob": -0.13150019188449807, "compression_ratio": 1.6294117647058823, "no_speech_prob": 0.002409314038231969}, {"id": 86, "seek": 51588, "start": 520.88, "end": 528.88, "text": " So the y attribute, the y name, the annotation, and the type bound to the attribute.", "tokens": [50614, 407, 264, 288, 19667, 11, 264, 288, 1315, 11, 264, 48654, 11, 293, 264, 2010, 5472, 281, 264, 19667, 13, 51014], "temperature": 0.0, "avg_logprob": -0.13150019188449807, "compression_ratio": 1.6294117647058823, "no_speech_prob": 0.002409314038231969}, {"id": 87, "seek": 51588, "start": 528.88, "end": 532.88, "text": " So I'll reuse this function here later on.", "tokens": [51014, 407, 286, 603, 26225, 341, 2445, 510, 1780, 322, 13, 51214], "temperature": 0.0, "avg_logprob": -0.13150019188449807, "compression_ratio": 1.6294117647058823, "no_speech_prob": 0.002409314038231969}, {"id": 88, "seek": 51588, "start": 532.88, "end": 537.88, "text": " So that's all for the presentation of annotated from the PEP and how to consume them.", "tokens": [51214, 407, 300, 311, 439, 337, 264, 5860, 295, 25339, 770, 490, 264, 430, 8929, 293, 577, 281, 14732, 552, 13, 51464], "temperature": 0.0, "avg_logprob": -0.13150019188449807, "compression_ratio": 1.6294117647058823, "no_speech_prob": 0.002409314038231969}, {"id": 89, "seek": 53788, "start": 537.88, "end": 546.88, "text": " I will now introduce some use cases in order to illustrate why you would want to use annotated or why not, maybe.", "tokens": [50364, 286, 486, 586, 5366, 512, 764, 3331, 294, 1668, 281, 23221, 983, 291, 576, 528, 281, 764, 25339, 770, 420, 983, 406, 11, 1310, 13, 50814], "temperature": 0.0, "avg_logprob": -0.19125276201226737, "compression_ratio": 1.6037735849056605, "no_speech_prob": 0.01755337044596672}, {"id": 90, "seek": 53788, "start": 546.88, "end": 551.88, "text": " I'll use this simple model which is a calendar event model.", "tokens": [50814, 286, 603, 764, 341, 2199, 2316, 597, 307, 257, 12183, 2280, 2316, 13, 51064], "temperature": 0.0, "avg_logprob": -0.19125276201226737, "compression_ratio": 1.6037735849056605, "no_speech_prob": 0.01755337044596672}, {"id": 91, "seek": 53788, "start": 551.88, "end": 553.88, "text": " It uses pyidentic as a base model.", "tokens": [51064, 467, 4960, 10664, 1078, 299, 382, 257, 3096, 2316, 13, 51164], "temperature": 0.0, "avg_logprob": -0.19125276201226737, "compression_ratio": 1.6037735849056605, "no_speech_prob": 0.01755337044596672}, {"id": 92, "seek": 53788, "start": 553.88, "end": 560.88, "text": " So again, pyidentic is a famous library for doing data modeling and validation or stylization.", "tokens": [51164, 407, 797, 11, 10664, 1078, 299, 307, 257, 4618, 6405, 337, 884, 1412, 15983, 293, 24071, 420, 23736, 2144, 13, 51514], "temperature": 0.0, "avg_logprob": -0.19125276201226737, "compression_ratio": 1.6037735849056605, "no_speech_prob": 0.01755337044596672}, {"id": 93, "seek": 53788, "start": 560.88, "end": 563.88, "text": " It's similar in scope to data class.", "tokens": [51514, 467, 311, 2531, 294, 11923, 281, 1412, 1508, 13, 51664], "temperature": 0.0, "avg_logprob": -0.19125276201226737, "compression_ratio": 1.6037735849056605, "no_speech_prob": 0.01755337044596672}, {"id": 94, "seek": 56388, "start": 563.88, "end": 573.88, "text": " And here we have an event model with a few fields, a summary description, and two dates defining the duration of the event.", "tokens": [50364, 400, 510, 321, 362, 364, 2280, 2316, 365, 257, 1326, 7909, 11, 257, 12691, 3855, 11, 293, 732, 11691, 17827, 264, 16365, 295, 264, 2280, 13, 50864], "temperature": 0.0, "avg_logprob": -0.1656986872355143, "compression_ratio": 1.6484018264840183, "no_speech_prob": 0.0029874248430132866}, {"id": 95, "seek": 56388, "start": 573.88, "end": 575.88, "text": " And the following will do three things.", "tokens": [50864, 400, 264, 3480, 486, 360, 1045, 721, 13, 50964], "temperature": 0.0, "avg_logprob": -0.1656986872355143, "compression_ratio": 1.6484018264840183, "no_speech_prob": 0.0029874248430132866}, {"id": 96, "seek": 56388, "start": 575.88, "end": 579.88, "text": " The first one will do validation of the daytime fields.", "tokens": [50964, 440, 700, 472, 486, 360, 24071, 295, 264, 31908, 7909, 13, 51164], "temperature": 0.0, "avg_logprob": -0.1656986872355143, "compression_ratio": 1.6484018264840183, "no_speech_prob": 0.0029874248430132866}, {"id": 97, "seek": 56388, "start": 579.88, "end": 584.88, "text": " We'll do this using pyidentic built-ins annotation.", "tokens": [51164, 492, 603, 360, 341, 1228, 10664, 1078, 299, 3094, 12, 1292, 48654, 13, 51414], "temperature": 0.0, "avg_logprob": -0.1656986872355143, "compression_ratio": 1.6484018264840183, "no_speech_prob": 0.0029874248430132866}, {"id": 98, "seek": 56388, "start": 584.88, "end": 587.88, "text": " So we'll see how to use third-party annotations.", "tokens": [51414, 407, 321, 603, 536, 577, 281, 764, 2636, 12, 23409, 25339, 763, 13, 51564], "temperature": 0.0, "avg_logprob": -0.1656986872355143, "compression_ratio": 1.6484018264840183, "no_speech_prob": 0.0029874248430132866}, {"id": 99, "seek": 56388, "start": 587.88, "end": 590.88, "text": " Then we'll do high-calendar stylization.", "tokens": [51564, 1396, 321, 603, 360, 1090, 12, 9895, 10292, 23736, 2144, 13, 51714], "temperature": 0.0, "avg_logprob": -0.1656986872355143, "compression_ratio": 1.6484018264840183, "no_speech_prob": 0.0029874248430132866}, {"id": 100, "seek": 59088, "start": 590.88, "end": 595.88, "text": " High-calendar is a simple format for XMG calendar data, text format.", "tokens": [50364, 5229, 12, 9895, 10292, 307, 257, 2199, 7877, 337, 1783, 44, 38, 12183, 1412, 11, 2487, 7877, 13, 50614], "temperature": 0.0, "avg_logprob": -0.15059165740281008, "compression_ratio": 1.65, "no_speech_prob": 0.005018565803766251}, {"id": 101, "seek": 59088, "start": 595.88, "end": 602.88, "text": " But we'll see how to implement our own annotation in order to perform stylization.", "tokens": [50614, 583, 321, 603, 536, 577, 281, 4445, 527, 1065, 48654, 294, 1668, 281, 2042, 23736, 2144, 13, 50964], "temperature": 0.0, "avg_logprob": -0.15059165740281008, "compression_ratio": 1.65, "no_speech_prob": 0.005018565803766251}, {"id": 102, "seek": 59088, "start": 602.88, "end": 605.88, "text": " And the third one will be console rendering.", "tokens": [50964, 400, 264, 2636, 472, 486, 312, 11076, 22407, 13, 51114], "temperature": 0.0, "avg_logprob": -0.15059165740281008, "compression_ratio": 1.65, "no_speech_prob": 0.005018565803766251}, {"id": 103, "seek": 59088, "start": 605.88, "end": 611.88, "text": " We'll build some kind of user interface in the console in order to print and display calendar events.", "tokens": [51114, 492, 603, 1322, 512, 733, 295, 4195, 9226, 294, 264, 11076, 294, 1668, 281, 4482, 293, 4674, 12183, 3931, 13, 51414], "temperature": 0.0, "avg_logprob": -0.15059165740281008, "compression_ratio": 1.65, "no_speech_prob": 0.005018565803766251}, {"id": 104, "seek": 59088, "start": 611.88, "end": 616.88, "text": " So again, this will illustrate how to define our own annotation.", "tokens": [51414, 407, 797, 11, 341, 486, 23221, 577, 281, 6964, 527, 1065, 48654, 13, 51664], "temperature": 0.0, "avg_logprob": -0.15059165740281008, "compression_ratio": 1.65, "no_speech_prob": 0.005018565803766251}, {"id": 105, "seek": 61688, "start": 616.88, "end": 620.88, "text": " So starting with daytime validation.", "tokens": [50364, 407, 2891, 365, 31908, 24071, 13, 50564], "temperature": 0.0, "avg_logprob": -0.2228533332027606, "compression_ratio": 1.5060975609756098, "no_speech_prob": 0.00429509999230504}, {"id": 106, "seek": 61688, "start": 620.88, "end": 628.88, "text": " We define, we use here the built-in annotation from pyidentic.", "tokens": [50564, 492, 6964, 11, 321, 764, 510, 264, 3094, 12, 259, 48654, 490, 10664, 1078, 299, 13, 50964], "temperature": 0.0, "avg_logprob": -0.2228533332027606, "compression_ratio": 1.5060975609756098, "no_speech_prob": 0.00429509999230504}, {"id": 107, "seek": 61688, "start": 628.88, "end": 635.88, "text": " And namely, it's the aftervalidator, which is some kind of annotation factory,", "tokens": [50964, 400, 20926, 11, 309, 311, 264, 934, 3337, 327, 1639, 11, 597, 307, 512, 733, 295, 48654, 9265, 11, 51314], "temperature": 0.0, "avg_logprob": -0.2228533332027606, "compression_ratio": 1.5060975609756098, "no_speech_prob": 0.00429509999230504}, {"id": 108, "seek": 61688, "start": 635.88, "end": 642.88, "text": " because it takes a function here tzware, which as its name suggests,", "tokens": [51314, 570, 309, 2516, 257, 2445, 510, 256, 89, 3039, 11, 597, 382, 1080, 1315, 13409, 11, 51664], "temperature": 0.0, "avg_logprob": -0.2228533332027606, "compression_ratio": 1.5060975609756098, "no_speech_prob": 0.00429509999230504}, {"id": 109, "seek": 64288, "start": 642.88, "end": 647.88, "text": " would validate that the daytime value is not naive.", "tokens": [50364, 576, 29562, 300, 264, 31908, 2158, 307, 406, 29052, 13, 50614], "temperature": 0.0, "avg_logprob": -0.1680788829408843, "compression_ratio": 1.4906832298136645, "no_speech_prob": 0.0014917274238541722}, {"id": 110, "seek": 64288, "start": 647.88, "end": 652.88, "text": " Meaning it has a time zone defined.", "tokens": [50614, 19948, 309, 575, 257, 565, 6668, 7642, 13, 50864], "temperature": 0.0, "avg_logprob": -0.1680788829408843, "compression_ratio": 1.4906832298136645, "no_speech_prob": 0.0014917274238541722}, {"id": 111, "seek": 64288, "start": 652.88, "end": 661.88, "text": " So here, you can simply define tzware type by combining the daytime field", "tokens": [50864, 407, 510, 11, 291, 393, 2935, 6964, 256, 89, 3039, 2010, 538, 21928, 264, 31908, 2519, 51314], "temperature": 0.0, "avg_logprob": -0.1680788829408843, "compression_ratio": 1.4906832298136645, "no_speech_prob": 0.0014917274238541722}, {"id": 112, "seek": 64288, "start": 661.88, "end": 671.88, "text": " with the pyidentic shipped annotation construct and your own validation logic.", "tokens": [51314, 365, 264, 10664, 1078, 299, 25312, 48654, 7690, 293, 428, 1065, 24071, 9952, 13, 51814], "temperature": 0.0, "avg_logprob": -0.1680788829408843, "compression_ratio": 1.4906832298136645, "no_speech_prob": 0.0014917274238541722}, {"id": 113, "seek": 67188, "start": 671.88, "end": 676.88, "text": " Here, I'm defining an event with a naive time zone.", "tokens": [50364, 1692, 11, 286, 478, 17827, 364, 2280, 365, 257, 29052, 565, 6668, 13, 50614], "temperature": 0.0, "avg_logprob": -0.12925175922672924, "compression_ratio": 1.515, "no_speech_prob": 0.0005167408962734044}, {"id": 114, "seek": 67188, "start": 676.88, "end": 680.88, "text": " And we can see that pyidentic produced a validation error,", "tokens": [50614, 400, 321, 393, 536, 300, 10664, 1078, 299, 7126, 257, 24071, 6713, 11, 50814], "temperature": 0.0, "avg_logprob": -0.12925175922672924, "compression_ratio": 1.515, "no_speech_prob": 0.0005167408962734044}, {"id": 115, "seek": 67188, "start": 680.88, "end": 688.88, "text": " which under the hood is triggered by our value error with the expecting a tzware daytime message.", "tokens": [50814, 597, 833, 264, 13376, 307, 21710, 538, 527, 2158, 6713, 365, 264, 9650, 257, 256, 89, 3039, 31908, 3636, 13, 51214], "temperature": 0.0, "avg_logprob": -0.12925175922672924, "compression_ratio": 1.515, "no_speech_prob": 0.0005167408962734044}, {"id": 116, "seek": 67188, "start": 688.88, "end": 691.88, "text": " So it works.", "tokens": [51214, 407, 309, 1985, 13, 51364], "temperature": 0.0, "avg_logprob": -0.12925175922672924, "compression_ratio": 1.515, "no_speech_prob": 0.0005167408962734044}, {"id": 117, "seek": 67188, "start": 691.88, "end": 697.88, "text": " As a side step, I would like to mention that before using annotated in pyidentic,", "tokens": [51364, 1018, 257, 1252, 1823, 11, 286, 576, 411, 281, 2152, 300, 949, 1228, 25339, 770, 294, 10664, 1078, 299, 11, 51664], "temperature": 0.0, "avg_logprob": -0.12925175922672924, "compression_ratio": 1.515, "no_speech_prob": 0.0005167408962734044}, {"id": 118, "seek": 69788, "start": 697.88, "end": 701.88, "text": " in all the versions of pyidentic, the pattern for doing validation", "tokens": [50364, 294, 439, 264, 9606, 295, 10664, 1078, 299, 11, 264, 5102, 337, 884, 24071, 50564], "temperature": 0.0, "avg_logprob": -0.13868167400360107, "compression_ratio": 1.8361581920903955, "no_speech_prob": 0.005118700675666332}, {"id": 119, "seek": 69788, "start": 701.88, "end": 706.88, "text": " was through using class methods and decorators,", "tokens": [50564, 390, 807, 1228, 1508, 7150, 293, 7919, 3391, 11, 50814], "temperature": 0.0, "avg_logprob": -0.13868167400360107, "compression_ratio": 1.8361581920903955, "no_speech_prob": 0.005118700675666332}, {"id": 120, "seek": 69788, "start": 706.88, "end": 709.88, "text": " namely the field validator decorator,", "tokens": [50814, 20926, 264, 2519, 7363, 1639, 7919, 1639, 11, 50964], "temperature": 0.0, "avg_logprob": -0.13868167400360107, "compression_ratio": 1.8361581920903955, "no_speech_prob": 0.005118700675666332}, {"id": 121, "seek": 69788, "start": 709.88, "end": 715.88, "text": " in which you have to define custom method in your model classes,", "tokens": [50964, 294, 597, 291, 362, 281, 6964, 2375, 3170, 294, 428, 2316, 5359, 11, 51264], "temperature": 0.0, "avg_logprob": -0.13868167400360107, "compression_ratio": 1.8361581920903955, "no_speech_prob": 0.005118700675666332}, {"id": 122, "seek": 69788, "start": 715.88, "end": 721.88, "text": " and you have to bind the attributes you want to validate to the method", "tokens": [51264, 293, 291, 362, 281, 14786, 264, 17212, 291, 528, 281, 29562, 281, 264, 3170, 51564], "temperature": 0.0, "avg_logprob": -0.13868167400360107, "compression_ratio": 1.8361581920903955, "no_speech_prob": 0.005118700675666332}, {"id": 123, "seek": 69788, "start": 721.88, "end": 724.88, "text": " using the field validator decorator.", "tokens": [51564, 1228, 264, 2519, 7363, 1639, 7919, 1639, 13, 51714], "temperature": 0.0, "avg_logprob": -0.13868167400360107, "compression_ratio": 1.8361581920903955, "no_speech_prob": 0.005118700675666332}, {"id": 124, "seek": 72488, "start": 724.88, "end": 729.88, "text": " So that's another way to define validation in pyidentic, not using the annotation.", "tokens": [50364, 407, 300, 311, 1071, 636, 281, 6964, 24071, 294, 10664, 1078, 299, 11, 406, 1228, 264, 48654, 13, 50614], "temperature": 0.0, "avg_logprob": -0.1179184155030684, "compression_ratio": 1.6605504587155964, "no_speech_prob": 0.005132430698722601}, {"id": 125, "seek": 72488, "start": 729.88, "end": 735.88, "text": " And why, in my opinion, the annotated pattern was adopted in pyidentic", "tokens": [50614, 400, 983, 11, 294, 452, 4800, 11, 264, 25339, 770, 5102, 390, 12175, 294, 10664, 1078, 299, 50914], "temperature": 0.0, "avg_logprob": -0.1179184155030684, "compression_ratio": 1.6605504587155964, "no_speech_prob": 0.005132430698722601}, {"id": 126, "seek": 72488, "start": 735.88, "end": 738.88, "text": " is for the following reason, I would say.", "tokens": [50914, 307, 337, 264, 3480, 1778, 11, 286, 576, 584, 13, 51064], "temperature": 0.0, "avg_logprob": -0.1179184155030684, "compression_ratio": 1.6605504587155964, "no_speech_prob": 0.005132430698722601}, {"id": 127, "seek": 72488, "start": 738.88, "end": 744.88, "text": " Because the validation method, the class method is loosely bound to the attributes.", "tokens": [51064, 1436, 264, 24071, 3170, 11, 264, 1508, 3170, 307, 37966, 5472, 281, 264, 17212, 13, 51364], "temperature": 0.0, "avg_logprob": -0.1179184155030684, "compression_ratio": 1.6605504587155964, "no_speech_prob": 0.005132430698722601}, {"id": 128, "seek": 72488, "start": 744.88, "end": 750.88, "text": " You can see that there is no direct relationship between the start art and end art", "tokens": [51364, 509, 393, 536, 300, 456, 307, 572, 2047, 2480, 1296, 264, 722, 1523, 293, 917, 1523, 51664], "temperature": 0.0, "avg_logprob": -0.1179184155030684, "compression_ratio": 1.6605504587155964, "no_speech_prob": 0.005132430698722601}, {"id": 129, "seek": 75088, "start": 750.88, "end": 755.88, "text": " field definition and the validation, whereas in the previous example,", "tokens": [50364, 2519, 7123, 293, 264, 24071, 11, 9735, 294, 264, 3894, 1365, 11, 50614], "temperature": 0.0, "avg_logprob": -0.1590304183959961, "compression_ratio": 1.708994708994709, "no_speech_prob": 0.0009966522920876741}, {"id": 130, "seek": 75088, "start": 755.88, "end": 763.88, "text": " with the annotation, you have inline combination of type and annotations.", "tokens": [50614, 365, 264, 48654, 11, 291, 362, 294, 1889, 6562, 295, 2010, 293, 25339, 763, 13, 51014], "temperature": 0.0, "avg_logprob": -0.1590304183959961, "compression_ratio": 1.708994708994709, "no_speech_prob": 0.0009966522920876741}, {"id": 131, "seek": 75088, "start": 763.88, "end": 767.88, "text": " Then if you have different classes using the same validation", "tokens": [51014, 1396, 498, 291, 362, 819, 5359, 1228, 264, 912, 24071, 51214], "temperature": 0.0, "avg_logprob": -0.1590304183959961, "compression_ratio": 1.708994708994709, "no_speech_prob": 0.0009966522920876741}, {"id": 132, "seek": 75088, "start": 767.88, "end": 772.88, "text": " because validating a non-native daytime is quite usual,", "tokens": [51214, 570, 7363, 990, 257, 2107, 12, 77, 1166, 31908, 307, 1596, 7713, 11, 51464], "temperature": 0.0, "avg_logprob": -0.1590304183959961, "compression_ratio": 1.708994708994709, "no_speech_prob": 0.0009966522920876741}, {"id": 133, "seek": 75088, "start": 772.88, "end": 777.88, "text": " you would have to repeat the method in all your model classes.", "tokens": [51464, 291, 576, 362, 281, 7149, 264, 3170, 294, 439, 428, 2316, 5359, 13, 51714], "temperature": 0.0, "avg_logprob": -0.1590304183959961, "compression_ratio": 1.708994708994709, "no_speech_prob": 0.0009966522920876741}, {"id": 134, "seek": 77788, "start": 777.88, "end": 782.88, "text": " And similar for all use cases, less like serialization.", "tokens": [50364, 400, 2531, 337, 439, 764, 3331, 11, 1570, 411, 17436, 2144, 13, 50614], "temperature": 0.0, "avg_logprob": -0.23076075236002605, "compression_ratio": 1.4867724867724867, "no_speech_prob": 0.005617780145257711}, {"id": 135, "seek": 77788, "start": 782.88, "end": 785.88, "text": " So that's why I think the annotated patterns", "tokens": [50614, 407, 300, 311, 983, 286, 519, 264, 25339, 770, 8294, 50764], "temperature": 0.0, "avg_logprob": -0.23076075236002605, "compression_ratio": 1.4867724867724867, "no_speech_prob": 0.005617780145257711}, {"id": 136, "seek": 77788, "start": 785.88, "end": 789.88, "text": " has taken adoption in this kind of library.", "tokens": [50764, 575, 2726, 19215, 294, 341, 733, 295, 6405, 13, 50964], "temperature": 0.0, "avg_logprob": -0.23076075236002605, "compression_ratio": 1.4867724867724867, "no_speech_prob": 0.005617780145257711}, {"id": 137, "seek": 77788, "start": 793.88, "end": 797.88, "text": " Here we simply introduce an alias, tzdatetime,", "tokens": [51164, 1692, 321, 2935, 5366, 364, 419, 4609, 11, 256, 89, 20367, 9764, 11, 51364], "temperature": 0.0, "avg_logprob": -0.23076075236002605, "compression_ratio": 1.4867724867724867, "no_speech_prob": 0.005617780145257711}, {"id": 138, "seek": 77788, "start": 797.88, "end": 803.88, "text": " which is the annotated daytime with or validator in order to make or code less variables.", "tokens": [51364, 597, 307, 264, 25339, 770, 31908, 365, 420, 7363, 1639, 294, 1668, 281, 652, 420, 3089, 1570, 9102, 13, 51664], "temperature": 0.0, "avg_logprob": -0.23076075236002605, "compression_ratio": 1.4867724867724867, "no_speech_prob": 0.005617780145257711}, {"id": 139, "seek": 80388, "start": 803.88, "end": 809.88, "text": " So that's one idea of annotated, despite being verbose, you can use aliases.", "tokens": [50364, 407, 300, 311, 472, 1558, 295, 25339, 770, 11, 7228, 885, 9595, 541, 11, 291, 393, 764, 10198, 1957, 13, 50664], "temperature": 0.0, "avg_logprob": -0.2311541798350575, "compression_ratio": 1.5420560747663552, "no_speech_prob": 0.0015679762000218034}, {"id": 140, "seek": 80388, "start": 809.88, "end": 815.88, "text": " And you can define your base model class just using the aliases.", "tokens": [50664, 400, 291, 393, 6964, 428, 3096, 2316, 1508, 445, 1228, 264, 10198, 1957, 13, 50964], "temperature": 0.0, "avg_logprob": -0.2311541798350575, "compression_ratio": 1.5420560747663552, "no_speech_prob": 0.0015679762000218034}, {"id": 141, "seek": 80388, "start": 817.88, "end": 821.88, "text": " Next, next you see is ICANN under serialization.", "tokens": [51064, 3087, 11, 958, 291, 536, 307, 14360, 1770, 45, 833, 17436, 2144, 13, 51264], "temperature": 0.0, "avg_logprob": -0.2311541798350575, "compression_ratio": 1.5420560747663552, "no_speech_prob": 0.0015679762000218034}, {"id": 142, "seek": 80388, "start": 821.88, "end": 826.88, "text": " Here, obviously, I'm using, I'm adding another annotation.", "tokens": [51264, 1692, 11, 2745, 11, 286, 478, 1228, 11, 286, 478, 5127, 1071, 48654, 13, 51514], "temperature": 0.0, "avg_logprob": -0.2311541798350575, "compression_ratio": 1.5420560747663552, "no_speech_prob": 0.0015679762000218034}, {"id": 143, "seek": 80388, "start": 826.88, "end": 831.88, "text": " These annotations are defined in the ICANN module, which I will introduce later.", "tokens": [51514, 1981, 25339, 763, 366, 7642, 294, 264, 14360, 1770, 45, 10088, 11, 597, 286, 486, 5366, 1780, 13, 51764], "temperature": 0.0, "avg_logprob": -0.2311541798350575, "compression_ratio": 1.5420560747663552, "no_speech_prob": 0.0015679762000218034}, {"id": 144, "seek": 83188, "start": 831.88, "end": 834.88, "text": " And there are serializer instances.", "tokens": [50364, 400, 456, 366, 17436, 6545, 14519, 13, 50514], "temperature": 0.0, "avg_logprob": -0.10897856886668872, "compression_ratio": 1.6926605504587156, "no_speech_prob": 0.0014482407132163644}, {"id": 145, "seek": 83188, "start": 834.88, "end": 838.88, "text": " An ICANN under serialization just takes a label name,", "tokens": [50514, 1107, 14360, 1770, 45, 833, 17436, 2144, 445, 2516, 257, 7645, 1315, 11, 50714], "temperature": 0.0, "avg_logprob": -0.10897856886668872, "compression_ratio": 1.6926605504587156, "no_speech_prob": 0.0014482407132163644}, {"id": 146, "seek": 83188, "start": 838.88, "end": 843.88, "text": " which would be used to serialize the data.", "tokens": [50714, 597, 576, 312, 1143, 281, 17436, 1125, 264, 1412, 13, 50964], "temperature": 0.0, "avg_logprob": -0.10897856886668872, "compression_ratio": 1.6926605504587156, "no_speech_prob": 0.0014482407132163644}, {"id": 147, "seek": 83188, "start": 843.88, "end": 846.88, "text": " So here you can see that we have combined different annotations", "tokens": [50964, 407, 510, 291, 393, 536, 300, 321, 362, 9354, 819, 25339, 763, 51114], "temperature": 0.0, "avg_logprob": -0.10897856886668872, "compression_ratio": 1.6926605504587156, "no_speech_prob": 0.0014482407132163644}, {"id": 148, "seek": 83188, "start": 846.88, "end": 849.88, "text": " in the same annotated construct,", "tokens": [51114, 294, 264, 912, 25339, 770, 7690, 11, 51264], "temperature": 0.0, "avg_logprob": -0.10897856886668872, "compression_ratio": 1.6926605504587156, "no_speech_prob": 0.0014482407132163644}, {"id": 149, "seek": 83188, "start": 849.88, "end": 854.88, "text": " because here our tzdatetime is already in an annotated value", "tokens": [51264, 570, 510, 527, 256, 89, 20367, 9764, 307, 1217, 294, 364, 25339, 770, 2158, 51514], "temperature": 0.0, "avg_logprob": -0.10897856886668872, "compression_ratio": 1.6926605504587156, "no_speech_prob": 0.0014482407132163644}, {"id": 150, "seek": 83188, "start": 854.88, "end": 859.88, "text": " and it's again wrapped in another annotated construct with another annotation.", "tokens": [51514, 293, 309, 311, 797, 14226, 294, 1071, 25339, 770, 7690, 365, 1071, 48654, 13, 51764], "temperature": 0.0, "avg_logprob": -0.10897856886668872, "compression_ratio": 1.6926605504587156, "no_speech_prob": 0.0014482407132163644}, {"id": 151, "seek": 85988, "start": 859.88, "end": 863.88, "text": " All this is flattened at runtime.", "tokens": [50364, 1057, 341, 307, 24183, 292, 412, 34474, 13, 50564], "temperature": 0.0, "avg_logprob": -0.1828147774875754, "compression_ratio": 1.6322869955156951, "no_speech_prob": 0.0013344305334612727}, {"id": 152, "seek": 85988, "start": 863.88, "end": 868.88, "text": " In the ICANN module I mentioned earlier, we have this serializer class.", "tokens": [50564, 682, 264, 14360, 1770, 45, 10088, 286, 2835, 3071, 11, 321, 362, 341, 17436, 6545, 1508, 13, 50814], "temperature": 0.0, "avg_logprob": -0.1828147774875754, "compression_ratio": 1.6322869955156951, "no_speech_prob": 0.0013344305334612727}, {"id": 153, "seek": 85988, "start": 868.88, "end": 871.88, "text": " Here it's a data class. We have the label field.", "tokens": [50814, 1692, 309, 311, 257, 1412, 1508, 13, 492, 362, 264, 7645, 2519, 13, 50964], "temperature": 0.0, "avg_logprob": -0.1828147774875754, "compression_ratio": 1.6322869955156951, "no_speech_prob": 0.0013344305334612727}, {"id": 154, "seek": 85988, "start": 871.88, "end": 874.88, "text": " And we have a simple serialization method,", "tokens": [50964, 400, 321, 362, 257, 2199, 17436, 2144, 3170, 11, 51114], "temperature": 0.0, "avg_logprob": -0.1828147774875754, "compression_ratio": 1.6322869955156951, "no_speech_prob": 0.0013344305334612727}, {"id": 155, "seek": 85988, "start": 874.88, "end": 880.88, "text": " which does some transformation between the value, which would be the field value,", "tokens": [51114, 597, 775, 512, 9887, 1296, 264, 2158, 11, 597, 576, 312, 264, 2519, 2158, 11, 51414], "temperature": 0.0, "avg_logprob": -0.1828147774875754, "compression_ratio": 1.6322869955156951, "no_speech_prob": 0.0013344305334612727}, {"id": 156, "seek": 85988, "start": 880.88, "end": 882.88, "text": " and specify it.", "tokens": [51414, 293, 16500, 309, 13, 51514], "temperature": 0.0, "avg_logprob": -0.1828147774875754, "compression_ratio": 1.6322869955156951, "no_speech_prob": 0.0013344305334612727}, {"id": 157, "seek": 85988, "start": 882.88, "end": 886.88, "text": " So if it's a date, we need to remove the time zone and change to ETC", "tokens": [51514, 407, 498, 309, 311, 257, 4002, 11, 321, 643, 281, 4159, 264, 565, 6668, 293, 1319, 281, 462, 18238, 51714], "temperature": 0.0, "avg_logprob": -0.1828147774875754, "compression_ratio": 1.6322869955156951, "no_speech_prob": 0.0013344305334612727}, {"id": 158, "seek": 88688, "start": 886.88, "end": 892.88, "text": " and use this kind of format.", "tokens": [50364, 293, 764, 341, 733, 295, 7877, 13, 50664], "temperature": 0.0, "avg_logprob": -0.17731771797969423, "compression_ratio": 1.5496688741721854, "no_speech_prob": 0.0020965184085071087}, {"id": 159, "seek": 88688, "start": 892.88, "end": 898.88, "text": " Then we use this function, which takes the object events,", "tokens": [50664, 1396, 321, 764, 341, 2445, 11, 597, 2516, 264, 2657, 3931, 11, 50964], "temperature": 0.0, "avg_logprob": -0.17731771797969423, "compression_ratio": 1.5496688741721854, "no_speech_prob": 0.0020965184085071087}, {"id": 160, "seek": 88688, "start": 898.88, "end": 904.88, "text": " walks through the annotation using the get annotation function introduced later", "tokens": [50964, 12896, 807, 264, 48654, 1228, 264, 483, 48654, 2445, 7268, 1780, 51264], "temperature": 0.0, "avg_logprob": -0.17731771797969423, "compression_ratio": 1.5496688741721854, "no_speech_prob": 0.0020965184085071087}, {"id": 161, "seek": 88688, "start": 904.88, "end": 908.88, "text": " and it calls the serial's value.", "tokens": [51264, 293, 309, 5498, 264, 17436, 311, 2158, 13, 51464], "temperature": 0.0, "avg_logprob": -0.17731771797969423, "compression_ratio": 1.5496688741721854, "no_speech_prob": 0.0020965184085071087}, {"id": 162, "seek": 88688, "start": 908.88, "end": 911.88, "text": " And we join the result using this.", "tokens": [51464, 400, 321, 3917, 264, 1874, 1228, 341, 13, 51614], "temperature": 0.0, "avg_logprob": -0.17731771797969423, "compression_ratio": 1.5496688741721854, "no_speech_prob": 0.0020965184085071087}, {"id": 163, "seek": 91188, "start": 911.88, "end": 916.88, "text": " So an example here, we still define our event model.", "tokens": [50364, 407, 364, 1365, 510, 11, 321, 920, 6964, 527, 2280, 2316, 13, 50614], "temperature": 0.0, "avg_logprob": -0.20702110966549644, "compression_ratio": 1.538860103626943, "no_speech_prob": 0.0017674231203272939}, {"id": 164, "seek": 91188, "start": 916.88, "end": 924.88, "text": " We get the date and we can print the serialization in the 9-calendar format.", "tokens": [50614, 492, 483, 264, 4002, 293, 321, 393, 4482, 264, 17436, 2144, 294, 264, 1722, 12, 9895, 10292, 7877, 13, 51014], "temperature": 0.0, "avg_logprob": -0.20702110966549644, "compression_ratio": 1.538860103626943, "no_speech_prob": 0.0017674231203272939}, {"id": 165, "seek": 91188, "start": 924.88, "end": 929.88, "text": " I'm going to work up to define and consume an annotation.", "tokens": [51014, 286, 478, 516, 281, 589, 493, 281, 6964, 293, 14732, 364, 48654, 13, 51264], "temperature": 0.0, "avg_logprob": -0.20702110966549644, "compression_ratio": 1.538860103626943, "no_speech_prob": 0.0017674231203272939}, {"id": 166, "seek": 91188, "start": 929.88, "end": 933.88, "text": " The first thing you do is to define annotation, typically as classes,", "tokens": [51264, 440, 700, 551, 291, 360, 307, 281, 6964, 48654, 11, 5850, 382, 5359, 11, 51464], "temperature": 0.0, "avg_logprob": -0.20702110966549644, "compression_ratio": 1.538860103626943, "no_speech_prob": 0.0017674231203272939}, {"id": 167, "seek": 91188, "start": 933.88, "end": 935.88, "text": " the data class is quite handy for this.", "tokens": [51464, 264, 1412, 1508, 307, 1596, 13239, 337, 341, 13, 51564], "temperature": 0.0, "avg_logprob": -0.20702110966549644, "compression_ratio": 1.538860103626943, "no_speech_prob": 0.0017674231203272939}, {"id": 168, "seek": 93588, "start": 935.88, "end": 942.88, "text": " You can define options and you would typically implement an underline method", "tokens": [50364, 509, 393, 6964, 3956, 293, 291, 576, 5850, 4445, 364, 833, 1889, 3170, 50714], "temperature": 0.0, "avg_logprob": -0.28726617789562836, "compression_ratio": 1.6084905660377358, "no_speech_prob": 0.0015658765332773328}, {"id": 169, "seek": 93588, "start": 942.88, "end": 944.88, "text": " in order to process the value.", "tokens": [50714, 294, 1668, 281, 1399, 264, 2158, 13, 50814], "temperature": 0.0, "avg_logprob": -0.28726617789562836, "compression_ratio": 1.6084905660377358, "no_speech_prob": 0.0015658765332773328}, {"id": 170, "seek": 93588, "start": 944.88, "end": 948.88, "text": " Then you add and take your data type using annotated, obviously.", "tokens": [50814, 1396, 291, 909, 293, 747, 428, 1412, 2010, 1228, 25339, 770, 11, 2745, 13, 51014], "temperature": 0.0, "avg_logprob": -0.28726617789562836, "compression_ratio": 1.6084905660377358, "no_speech_prob": 0.0015658765332773328}, {"id": 171, "seek": 93588, "start": 948.88, "end": 951.88, "text": " And then you consume your object using the get annotation patterns", "tokens": [51014, 400, 550, 291, 14732, 428, 2657, 1228, 264, 483, 48654, 8294, 51164], "temperature": 0.0, "avg_logprob": -0.28726617789562836, "compression_ratio": 1.6084905660377358, "no_speech_prob": 0.0015658765332773328}, {"id": 172, "seek": 93588, "start": 951.88, "end": 956.88, "text": " I would annotate a bit earlier.", "tokens": [51164, 286, 576, 25339, 473, 257, 857, 3071, 13, 51414], "temperature": 0.0, "avg_logprob": -0.28726617789562836, "compression_ratio": 1.6084905660377358, "no_speech_prob": 0.0015658765332773328}, {"id": 173, "seek": 93588, "start": 956.88, "end": 961.88, "text": " The third use case, here we are stacking another layer of annotations", "tokens": [51414, 440, 2636, 764, 1389, 11, 510, 321, 366, 41376, 1071, 4583, 295, 25339, 763, 51664], "temperature": 0.0, "avg_logprob": -0.28726617789562836, "compression_ratio": 1.6084905660377358, "no_speech_prob": 0.0015658765332773328}, {"id": 174, "seek": 96188, "start": 961.88, "end": 964.88, "text": " from the UI module, the UI module I will introduce later.", "tokens": [50364, 490, 264, 15682, 10088, 11, 264, 15682, 10088, 286, 486, 5366, 1780, 13, 50514], "temperature": 0.0, "avg_logprob": -0.25544488694932727, "compression_ratio": 1.7019230769230769, "no_speech_prob": 0.0023887420538812876}, {"id": 175, "seek": 96188, "start": 964.88, "end": 973.88, "text": " We are adding UI annotation in order to define all the fields of our event model", "tokens": [50514, 492, 366, 5127, 15682, 48654, 294, 1668, 281, 6964, 439, 264, 7909, 295, 527, 2280, 2316, 50964], "temperature": 0.0, "avg_logprob": -0.25544488694932727, "compression_ratio": 1.7019230769230769, "no_speech_prob": 0.0023887420538812876}, {"id": 176, "seek": 96188, "start": 973.88, "end": 976.88, "text": " will be serialized in the console.", "tokens": [50964, 486, 312, 17436, 1602, 294, 264, 11076, 13, 51114], "temperature": 0.0, "avg_logprob": -0.25544488694932727, "compression_ratio": 1.7019230769230769, "no_speech_prob": 0.0023887420538812876}, {"id": 177, "seek": 96188, "start": 976.88, "end": 981.88, "text": " We have a text annotation, a margithon field for the description", "tokens": [51114, 492, 362, 257, 2487, 48654, 11, 257, 1849, 70, 355, 266, 2519, 337, 264, 3855, 51364], "temperature": 0.0, "avg_logprob": -0.25544488694932727, "compression_ratio": 1.7019230769230769, "no_speech_prob": 0.0023887420538812876}, {"id": 178, "seek": 96188, "start": 981.88, "end": 983.88, "text": " and we have data serializer for description.", "tokens": [51364, 293, 321, 362, 1412, 17436, 6545, 337, 3855, 13, 51464], "temperature": 0.0, "avg_logprob": -0.25544488694932727, "compression_ratio": 1.7019230769230769, "no_speech_prob": 0.0023887420538812876}, {"id": 179, "seek": 96188, "start": 983.88, "end": 988.88, "text": " Here we will be using the rich library, which is a pretty nice library", "tokens": [51464, 1692, 321, 486, 312, 1228, 264, 4593, 6405, 11, 597, 307, 257, 1238, 1481, 6405, 51714], "temperature": 0.0, "avg_logprob": -0.25544488694932727, "compression_ratio": 1.7019230769230769, "no_speech_prob": 0.0023887420538812876}, {"id": 180, "seek": 98888, "start": 988.88, "end": 996.88, "text": " for doing console rendering and building terminal user interfaces.", "tokens": [50364, 337, 884, 11076, 22407, 293, 2390, 14709, 4195, 28416, 13, 50764], "temperature": 0.0, "avg_logprob": -0.1546678855770924, "compression_ratio": 1.518716577540107, "no_speech_prob": 0.0031998734921216965}, {"id": 181, "seek": 98888, "start": 996.88, "end": 1001.88, "text": " The widgets, which are the annotations we have used in the previous example", "tokens": [50764, 440, 43355, 11, 597, 366, 264, 25339, 763, 321, 362, 1143, 294, 264, 3894, 1365, 51014], "temperature": 0.0, "avg_logprob": -0.1546678855770924, "compression_ratio": 1.518716577540107, "no_speech_prob": 0.0031998734921216965}, {"id": 182, "seek": 98888, "start": 1001.88, "end": 1007.88, "text": " are defined here using classes, following the pattern I introduced before.", "tokens": [51014, 366, 7642, 510, 1228, 5359, 11, 3480, 264, 5102, 286, 7268, 949, 13, 51314], "temperature": 0.0, "avg_logprob": -0.1546678855770924, "compression_ratio": 1.518716577540107, "no_speech_prob": 0.0031998734921216965}, {"id": 183, "seek": 98888, "start": 1007.88, "end": 1012.88, "text": " And they basically delegate to rich to do the rendering of a field", "tokens": [51314, 400, 436, 1936, 40999, 281, 4593, 281, 360, 264, 22407, 295, 257, 2519, 51564], "temperature": 0.0, "avg_logprob": -0.1546678855770924, "compression_ratio": 1.518716577540107, "no_speech_prob": 0.0031998734921216965}, {"id": 184, "seek": 101288, "start": 1012.88, "end": 1019.88, "text": " and then do the running on the type of the field.", "tokens": [50364, 293, 550, 360, 264, 2614, 322, 264, 2010, 295, 264, 2519, 13, 50714], "temperature": 0.0, "avg_logprob": -0.29382171630859377, "compression_ratio": 1.5583756345177664, "no_speech_prob": 0.004266100004315376}, {"id": 185, "seek": 101288, "start": 1019.88, "end": 1026.88, "text": " Here it's another way to process the annotation instead of introducing a custom function", "tokens": [50714, 1692, 309, 311, 1071, 636, 281, 1399, 264, 48654, 2602, 295, 15424, 257, 2375, 2445, 51064], "temperature": 0.0, "avg_logprob": -0.29382171630859377, "compression_ratio": 1.5583756345177664, "no_speech_prob": 0.004266100004315376}, {"id": 186, "seek": 101288, "start": 1026.88, "end": 1028.88, "text": " for processing the object.", "tokens": [51064, 337, 9007, 264, 2657, 13, 51164], "temperature": 0.0, "avg_logprob": -0.29382171630859377, "compression_ratio": 1.5583756345177664, "no_speech_prob": 0.004266100004315376}, {"id": 187, "seek": 101288, "start": 1028.88, "end": 1033.88, "text": " We introduce a mixing class, which follows the rich protocol.", "tokens": [51164, 492, 5366, 257, 11983, 1508, 11, 597, 10002, 264, 4593, 10336, 13, 51414], "temperature": 0.0, "avg_logprob": -0.29382171630859377, "compression_ratio": 1.5583756345177664, "no_speech_prob": 0.004266100004315376}, {"id": 188, "seek": 101288, "start": 1033.88, "end": 1035.88, "text": " It's defined in documentation.", "tokens": [51414, 467, 311, 7642, 294, 14333, 13, 51514], "temperature": 0.0, "avg_logprob": -0.29382171630859377, "compression_ratio": 1.5583756345177664, "no_speech_prob": 0.004266100004315376}, {"id": 189, "seek": 101288, "start": 1035.88, "end": 1038.88, "text": " You need to define a Dunder rich console method.", "tokens": [51514, 509, 643, 281, 6964, 257, 413, 6617, 4593, 11076, 3170, 13, 51664], "temperature": 0.0, "avg_logprob": -0.29382171630859377, "compression_ratio": 1.5583756345177664, "no_speech_prob": 0.004266100004315376}, {"id": 190, "seek": 103888, "start": 1038.88, "end": 1042.88, "text": " And there, again, we used our get annotation function", "tokens": [50364, 400, 456, 11, 797, 11, 321, 1143, 527, 483, 48654, 2445, 50564], "temperature": 0.0, "avg_logprob": -0.16667798291081967, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0021392900962382555}, {"id": 191, "seek": 103888, "start": 1042.88, "end": 1046.88, "text": " looking for the widget class, widget annotations.", "tokens": [50564, 1237, 337, 264, 34047, 1508, 11, 34047, 25339, 763, 13, 50764], "temperature": 0.0, "avg_logprob": -0.16667798291081967, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0021392900962382555}, {"id": 192, "seek": 103888, "start": 1046.88, "end": 1052.88, "text": " And if we found some, we call the render method of our widgets, get the value", "tokens": [50764, 400, 498, 321, 1352, 512, 11, 321, 818, 264, 15529, 3170, 295, 527, 43355, 11, 483, 264, 2158, 51064], "temperature": 0.0, "avg_logprob": -0.16667798291081967, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0021392900962382555}, {"id": 193, "seek": 103888, "start": 1052.88, "end": 1057.88, "text": " and we need the text value.", "tokens": [51064, 293, 321, 643, 264, 2487, 2158, 13, 51314], "temperature": 0.0, "avg_logprob": -0.16667798291081967, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0021392900962382555}, {"id": 194, "seek": 103888, "start": 1057.88, "end": 1062.88, "text": " We use this as a mixing, so we extend our class events.", "tokens": [51314, 492, 764, 341, 382, 257, 11983, 11, 370, 321, 10101, 527, 1508, 3931, 13, 51564], "temperature": 0.0, "avg_logprob": -0.16667798291081967, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0021392900962382555}, {"id": 195, "seek": 103888, "start": 1062.88, "end": 1067.88, "text": " If we take another example, we added a description with some margithon formats.", "tokens": [51564, 759, 321, 747, 1071, 1365, 11, 321, 3869, 257, 3855, 365, 512, 1849, 70, 355, 266, 25879, 13, 51814], "temperature": 0.0, "avg_logprob": -0.16667798291081967, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0021392900962382555}, {"id": 196, "seek": 106788, "start": 1067.88, "end": 1069.88, "text": " The dates field here are the same.", "tokens": [50364, 440, 11691, 2519, 510, 366, 264, 912, 13, 50464], "temperature": 0.0, "avg_logprob": -0.13103193449742587, "compression_ratio": 1.5872340425531914, "no_speech_prob": 0.0018551849061623216}, {"id": 197, "seek": 106788, "start": 1069.88, "end": 1075.88, "text": " Simply, they will be colored depending on whether the events are started or not.", "tokens": [50464, 19596, 11, 436, 486, 312, 14332, 5413, 322, 1968, 264, 3931, 366, 1409, 420, 406, 13, 50764], "temperature": 0.0, "avg_logprob": -0.13103193449742587, "compression_ratio": 1.5872340425531914, "no_speech_prob": 0.0018551849061623216}, {"id": 198, "seek": 106788, "start": 1075.88, "end": 1079.88, "text": " So if you reach, print, or events, we get this.", "tokens": [50764, 407, 498, 291, 2524, 11, 4482, 11, 420, 3931, 11, 321, 483, 341, 13, 50964], "temperature": 0.0, "avg_logprob": -0.13103193449742587, "compression_ratio": 1.5872340425531914, "no_speech_prob": 0.0018551849061623216}, {"id": 199, "seek": 106788, "start": 1079.88, "end": 1084.88, "text": " We can see that we have margithon interpreted things in the description", "tokens": [50964, 492, 393, 536, 300, 321, 362, 1849, 70, 355, 266, 26749, 721, 294, 264, 3855, 51214], "temperature": 0.0, "avg_logprob": -0.13103193449742587, "compression_ratio": 1.5872340425531914, "no_speech_prob": 0.0018551849061623216}, {"id": 200, "seek": 106788, "start": 1084.88, "end": 1088.88, "text": " and the start date is green.", "tokens": [51214, 293, 264, 722, 4002, 307, 3092, 13, 51414], "temperature": 0.0, "avg_logprob": -0.13103193449742587, "compression_ratio": 1.5872340425531914, "no_speech_prob": 0.0018551849061623216}, {"id": 201, "seek": 106788, "start": 1088.88, "end": 1090.88, "text": " So that's all for use cases.", "tokens": [51414, 407, 300, 311, 439, 337, 764, 3331, 13, 51514], "temperature": 0.0, "avg_logprob": -0.13103193449742587, "compression_ratio": 1.5872340425531914, "no_speech_prob": 0.0018551849061623216}, {"id": 202, "seek": 106788, "start": 1090.88, "end": 1095.88, "text": " I hope I've demonstrated why you would want to use annotated or why not, maybe.", "tokens": [51514, 286, 1454, 286, 600, 18772, 983, 291, 576, 528, 281, 764, 25339, 770, 420, 983, 406, 11, 1310, 13, 51764], "temperature": 0.0, "avg_logprob": -0.13103193449742587, "compression_ratio": 1.5872340425531914, "no_speech_prob": 0.0018551849061623216}, {"id": 203, "seek": 109588, "start": 1095.88, "end": 1100.88, "text": " Then I will discuss about the adoption of this pattern in the ecosystem and community.", "tokens": [50364, 1396, 286, 486, 2248, 466, 264, 19215, 295, 341, 5102, 294, 264, 11311, 293, 1768, 13, 50614], "temperature": 0.0, "avg_logprob": -0.20912986203848596, "compression_ratio": 1.4901960784313726, "no_speech_prob": 0.0064242128282785416}, {"id": 204, "seek": 109588, "start": 1100.88, "end": 1104.88, "text": " First, we have adopters, like I mentioned before,", "tokens": [50614, 2386, 11, 321, 362, 22486, 1559, 11, 411, 286, 2835, 949, 11, 50814], "temperature": 0.0, "avg_logprob": -0.20912986203848596, "compression_ratio": 1.4901960784313726, "no_speech_prob": 0.0064242128282785416}, {"id": 205, "seek": 109588, "start": 1104.88, "end": 1107.88, "text": " by the antique, fast API, or typo.", "tokens": [50814, 538, 264, 41220, 11, 2370, 9362, 11, 420, 2125, 78, 13, 50964], "temperature": 0.0, "avg_logprob": -0.20912986203848596, "compression_ratio": 1.4901960784313726, "no_speech_prob": 0.0064242128282785416}, {"id": 206, "seek": 109588, "start": 1107.88, "end": 1110.88, "text": " So you have this kind of code in the wild.", "tokens": [50964, 407, 291, 362, 341, 733, 295, 3089, 294, 264, 4868, 13, 51114], "temperature": 0.0, "avg_logprob": -0.20912986203848596, "compression_ratio": 1.4901960784313726, "no_speech_prob": 0.0064242128282785416}, {"id": 207, "seek": 109588, "start": 1110.88, "end": 1119.88, "text": " And you might want to get used to this because I think it's here to stay in this library.", "tokens": [51114, 400, 291, 1062, 528, 281, 483, 1143, 281, 341, 570, 286, 519, 309, 311, 510, 281, 1754, 294, 341, 6405, 13, 51564], "temperature": 0.0, "avg_logprob": -0.20912986203848596, "compression_ratio": 1.4901960784313726, "no_speech_prob": 0.0064242128282785416}, {"id": 208, "seek": 111988, "start": 1120.88, "end": 1125.88, "text": " I hope I've demystified the pattern so that you can understand what it does it mean", "tokens": [50414, 286, 1454, 286, 600, 1371, 38593, 2587, 264, 5102, 370, 300, 291, 393, 1223, 437, 309, 775, 309, 914, 50664], "temperature": 0.0, "avg_logprob": -0.1459122480348099, "compression_ratio": 1.5936073059360731, "no_speech_prob": 0.005122521426528692}, {"id": 209, "seek": 111988, "start": 1125.88, "end": 1130.88, "text": " to have this kind of code in the documentation and if you copy-paste it, for example.", "tokens": [50664, 281, 362, 341, 733, 295, 3089, 294, 264, 14333, 293, 498, 291, 5055, 12, 79, 9079, 309, 11, 337, 1365, 13, 50914], "temperature": 0.0, "avg_logprob": -0.1459122480348099, "compression_ratio": 1.5936073059360731, "no_speech_prob": 0.005122521426528692}, {"id": 210, "seek": 111988, "start": 1130.88, "end": 1134.88, "text": " There's an interesting project in annotated type,", "tokens": [50914, 821, 311, 364, 1880, 1716, 294, 25339, 770, 2010, 11, 51114], "temperature": 0.0, "avg_logprob": -0.1459122480348099, "compression_ratio": 1.5936073059360731, "no_speech_prob": 0.005122521426528692}, {"id": 211, "seek": 111988, "start": 1134.88, "end": 1140.88, "text": " which provides reusable constraint type to be used with annotated", "tokens": [51114, 597, 6417, 41807, 25534, 2010, 281, 312, 1143, 365, 25339, 770, 51414], "temperature": 0.0, "avg_logprob": -0.1459122480348099, "compression_ratio": 1.5936073059360731, "no_speech_prob": 0.005122521426528692}, {"id": 212, "seek": 111988, "start": 1140.88, "end": 1148.88, "text": " so that you don't have to define your quite classic annotation.", "tokens": [51414, 370, 300, 291, 500, 380, 362, 281, 6964, 428, 1596, 7230, 48654, 13, 51814], "temperature": 0.0, "avg_logprob": -0.1459122480348099, "compression_ratio": 1.5936073059360731, "no_speech_prob": 0.005122521426528692}, {"id": 213, "seek": 114888, "start": 1148.88, "end": 1152.88, "text": " It's also adopted in a SQL alchemy,", "tokens": [50364, 467, 311, 611, 12175, 294, 257, 19200, 419, 339, 3633, 11, 50564], "temperature": 0.0, "avg_logprob": -0.20090944555741322, "compression_ratio": 1.4825870646766168, "no_speech_prob": 0.0021727641578763723}, {"id": 214, "seek": 114888, "start": 1152.88, "end": 1161.88, "text": " although it's a bit more involved because you have to use the mapped type annotated file.", "tokens": [50564, 4878, 309, 311, 257, 857, 544, 3288, 570, 291, 362, 281, 764, 264, 33318, 2010, 25339, 770, 3991, 13, 51014], "temperature": 0.0, "avg_logprob": -0.20090944555741322, "compression_ratio": 1.4825870646766168, "no_speech_prob": 0.0021727641578763723}, {"id": 215, "seek": 114888, "start": 1161.88, "end": 1168.88, "text": " And obviously, in a project with less coupling with the typing system, there is less enthusiasm.", "tokens": [51014, 400, 2745, 11, 294, 257, 1716, 365, 1570, 37447, 365, 264, 18444, 1185, 11, 456, 307, 1570, 23417, 13, 51364], "temperature": 0.0, "avg_logprob": -0.20090944555741322, "compression_ratio": 1.4825870646766168, "no_speech_prob": 0.0021727641578763723}, {"id": 216, "seek": 114888, "start": 1168.88, "end": 1170.88, "text": " It's obvious.", "tokens": [51364, 467, 311, 6322, 13, 51464], "temperature": 0.0, "avg_logprob": -0.20090944555741322, "compression_ratio": 1.4825870646766168, "no_speech_prob": 0.0021727641578763723}, {"id": 217, "seek": 114888, "start": 1170.88, "end": 1176.88, "text": " This brings me to some skepticism I've seen in the community.", "tokens": [51464, 639, 5607, 385, 281, 512, 19128, 26356, 286, 600, 1612, 294, 264, 1768, 13, 51764], "temperature": 0.0, "avg_logprob": -0.20090944555741322, "compression_ratio": 1.4825870646766168, "no_speech_prob": 0.0021727641578763723}, {"id": 218, "seek": 117688, "start": 1176.88, "end": 1180.88, "text": " First of all, I've used in annotated is quite verbose.", "tokens": [50364, 2386, 295, 439, 11, 286, 600, 1143, 294, 25339, 770, 307, 1596, 9595, 541, 13, 50564], "temperature": 0.0, "avg_logprob": -0.21333025860530075, "compression_ratio": 1.5884955752212389, "no_speech_prob": 0.003180017462000251}, {"id": 219, "seek": 117688, "start": 1180.88, "end": 1189.88, "text": " The symbol is already in uncultured and if you stack different kind of annotation in the same type,", "tokens": [50564, 440, 5986, 307, 1217, 294, 6219, 723, 3831, 293, 498, 291, 8630, 819, 733, 295, 48654, 294, 264, 912, 2010, 11, 51014], "temperature": 0.0, "avg_logprob": -0.21333025860530075, "compression_ratio": 1.5884955752212389, "no_speech_prob": 0.003180017462000251}, {"id": 220, "seek": 117688, "start": 1189.88, "end": 1192.88, "text": " it's getting verbose so you have to take care about this.", "tokens": [51014, 309, 311, 1242, 9595, 541, 370, 291, 362, 281, 747, 1127, 466, 341, 13, 51164], "temperature": 0.0, "avg_logprob": -0.21333025860530075, "compression_ratio": 1.5884955752212389, "no_speech_prob": 0.003180017462000251}, {"id": 221, "seek": 117688, "start": 1192.88, "end": 1194.88, "text": " It's us, readability.", "tokens": [51164, 467, 311, 505, 11, 1401, 2310, 13, 51264], "temperature": 0.0, "avg_logprob": -0.21333025860530075, "compression_ratio": 1.5884955752212389, "no_speech_prob": 0.003180017462000251}, {"id": 222, "seek": 117688, "start": 1194.88, "end": 1200.88, "text": " Then it's kind of awkward because annotations are not necessarily typing,", "tokens": [51264, 1396, 309, 311, 733, 295, 11411, 570, 25339, 763, 366, 406, 4725, 18444, 11, 51564], "temperature": 0.0, "avg_logprob": -0.21333025860530075, "compression_ratio": 1.5884955752212389, "no_speech_prob": 0.003180017462000251}, {"id": 223, "seek": 117688, "start": 1200.88, "end": 1203.88, "text": " although most consumers do use typing information.", "tokens": [51564, 4878, 881, 11883, 360, 764, 18444, 1589, 13, 51714], "temperature": 0.0, "avg_logprob": -0.21333025860530075, "compression_ratio": 1.5884955752212389, "no_speech_prob": 0.003180017462000251}, {"id": 224, "seek": 120388, "start": 1203.88, "end": 1208.88, "text": " But if you don't want to use typing, you cannot really use the annotation", "tokens": [50364, 583, 498, 291, 500, 380, 528, 281, 764, 18444, 11, 291, 2644, 534, 764, 264, 48654, 50614], "temperature": 0.0, "avg_logprob": -0.18816379585651435, "compression_ratio": 1.5822222222222222, "no_speech_prob": 0.0026652684900909662}, {"id": 225, "seek": 120388, "start": 1208.88, "end": 1213.88, "text": " as provided by annotated at the moment.", "tokens": [50614, 382, 5649, 538, 25339, 770, 412, 264, 1623, 13, 50864], "temperature": 0.0, "avg_logprob": -0.18816379585651435, "compression_ratio": 1.5822222222222222, "no_speech_prob": 0.0026652684900909662}, {"id": 226, "seek": 120388, "start": 1213.88, "end": 1216.88, "text": " Also, consuming annotation is a bit tedious as we have seen.", "tokens": [50864, 2743, 11, 19867, 48654, 307, 257, 857, 38284, 382, 321, 362, 1612, 13, 51014], "temperature": 0.0, "avg_logprob": -0.18816379585651435, "compression_ratio": 1.5822222222222222, "no_speech_prob": 0.0026652684900909662}, {"id": 227, "seek": 120388, "start": 1216.88, "end": 1220.88, "text": " You have to write some bullet-plate code.", "tokens": [51014, 509, 362, 281, 2464, 512, 11632, 12, 37008, 3089, 13, 51214], "temperature": 0.0, "avg_logprob": -0.18816379585651435, "compression_ratio": 1.5822222222222222, "no_speech_prob": 0.0026652684900909662}, {"id": 228, "seek": 120388, "start": 1220.88, "end": 1221.88, "text": " And there is more coming.", "tokens": [51214, 400, 456, 307, 544, 1348, 13, 51264], "temperature": 0.0, "avg_logprob": -0.18816379585651435, "compression_ratio": 1.5822222222222222, "no_speech_prob": 0.0026652684900909662}, {"id": 229, "seek": 120388, "start": 1221.88, "end": 1225.88, "text": " Here, there is a pep I would like to mention, 724.27,", "tokens": [51264, 1692, 11, 456, 307, 257, 520, 79, 286, 576, 411, 281, 2152, 11, 1614, 7911, 13, 10076, 11, 51464], "temperature": 0.0, "avg_logprob": -0.18816379585651435, "compression_ratio": 1.5822222222222222, "no_speech_prob": 0.0026652684900909662}, {"id": 230, "seek": 120388, "start": 1225.88, "end": 1229.88, "text": " which would introduce a doc construct in the typing module,", "tokens": [51464, 597, 576, 5366, 257, 3211, 7690, 294, 264, 18444, 10088, 11, 51664], "temperature": 0.0, "avg_logprob": -0.18816379585651435, "compression_ratio": 1.5822222222222222, "no_speech_prob": 0.0026652684900909662}, {"id": 231, "seek": 122988, "start": 1229.88, "end": 1233.88, "text": " which would be used through document fields.", "tokens": [50364, 597, 576, 312, 1143, 807, 4166, 7909, 13, 50564], "temperature": 0.0, "avg_logprob": -0.17532452174595425, "compression_ratio": 1.5406976744186047, "no_speech_prob": 0.015729190781712532}, {"id": 232, "seek": 122988, "start": 1233.88, "end": 1239.88, "text": " So again, it's not typed, but it's in the typing module.", "tokens": [50564, 407, 797, 11, 309, 311, 406, 33941, 11, 457, 309, 311, 294, 264, 18444, 10088, 13, 50864], "temperature": 0.0, "avg_logprob": -0.17532452174595425, "compression_ratio": 1.5406976744186047, "no_speech_prob": 0.015729190781712532}, {"id": 233, "seek": 122988, "start": 1239.88, "end": 1245.88, "text": " So this brings us to the typing topic, which as you may know,", "tokens": [50864, 407, 341, 5607, 505, 281, 264, 18444, 4829, 11, 597, 382, 291, 815, 458, 11, 51164], "temperature": 0.0, "avg_logprob": -0.17532452174595425, "compression_ratio": 1.5406976744186047, "no_speech_prob": 0.015729190781712532}, {"id": 234, "seek": 122988, "start": 1245.88, "end": 1255.88, "text": " in the Python community is quite divisive because there are some fans of the typing and some are not.", "tokens": [51164, 294, 264, 15329, 1768, 307, 1596, 25974, 488, 570, 456, 366, 512, 4499, 295, 264, 18444, 293, 512, 366, 406, 13, 51664], "temperature": 0.0, "avg_logprob": -0.17532452174595425, "compression_ratio": 1.5406976744186047, "no_speech_prob": 0.015729190781712532}, {"id": 235, "seek": 125588, "start": 1255.88, "end": 1261.88, "text": " And this, I think Python is growing with its features because they bring user value.", "tokens": [50364, 400, 341, 11, 286, 519, 15329, 307, 4194, 365, 1080, 4122, 570, 436, 1565, 4195, 2158, 13, 50664], "temperature": 0.0, "avg_logprob": -0.19016512702493107, "compression_ratio": 1.5176470588235293, "no_speech_prob": 0.021441811695694923}, {"id": 236, "seek": 125588, "start": 1261.88, "end": 1268.88, "text": " The example I've shown in Fast API are a lot more expressive, in my opinion,", "tokens": [50664, 440, 1365, 286, 600, 4898, 294, 15968, 9362, 366, 257, 688, 544, 40189, 11, 294, 452, 4800, 11, 51014], "temperature": 0.0, "avg_logprob": -0.19016512702493107, "compression_ratio": 1.5176470588235293, "no_speech_prob": 0.021441811695694923}, {"id": 237, "seek": 125588, "start": 1268.88, "end": 1272.88, "text": " than the one that you would typically use in other metaprogramming patterns,", "tokens": [51014, 813, 264, 472, 300, 291, 576, 5850, 764, 294, 661, 1131, 569, 340, 1342, 2810, 8294, 11, 51214], "temperature": 0.0, "avg_logprob": -0.19016512702493107, "compression_ratio": 1.5176470588235293, "no_speech_prob": 0.021441811695694923}, {"id": 238, "seek": 125588, "start": 1272.88, "end": 1274.88, "text": " like decorators and so on.", "tokens": [51214, 411, 7919, 3391, 293, 370, 322, 13, 51314], "temperature": 0.0, "avg_logprob": -0.19016512702493107, "compression_ratio": 1.5176470588235293, "no_speech_prob": 0.021441811695694923}, {"id": 239, "seek": 125588, "start": 1274.88, "end": 1278.88, "text": " And if you want to deep dive more in this topic,", "tokens": [51314, 400, 498, 291, 528, 281, 2452, 9192, 544, 294, 341, 4829, 11, 51514], "temperature": 0.0, "avg_logprob": -0.19016512702493107, "compression_ratio": 1.5176470588235293, "no_speech_prob": 0.021441811695694923}, {"id": 240, "seek": 125588, "start": 1278.88, "end": 1283.88, "text": " I encourage you to read this LWNN article, which was published recently,", "tokens": [51514, 286, 5373, 291, 281, 1401, 341, 441, 54, 45, 45, 7222, 11, 597, 390, 6572, 3938, 11, 51764], "temperature": 0.0, "avg_logprob": -0.19016512702493107, "compression_ratio": 1.5176470588235293, "no_speech_prob": 0.021441811695694923}, {"id": 241, "seek": 128388, "start": 1283.88, "end": 1293.88, "text": " and it provides quite a nice overview of the typing issue or topic in the ecosystem and community.", "tokens": [50364, 293, 309, 6417, 1596, 257, 1481, 12492, 295, 264, 18444, 2734, 420, 4829, 294, 264, 11311, 293, 1768, 13, 50864], "temperature": 0.0, "avg_logprob": -0.19999247691670402, "compression_ratio": 1.412121212121212, "no_speech_prob": 0.02163047157227993}, {"id": 242, "seek": 128388, "start": 1293.88, "end": 1295.88, "text": " Thank you for your attention.", "tokens": [50864, 1044, 291, 337, 428, 3202, 13, 50964], "temperature": 0.0, "avg_logprob": -0.19999247691670402, "compression_ratio": 1.412121212121212, "no_speech_prob": 0.02163047157227993}, {"id": 243, "seek": 128388, "start": 1295.88, "end": 1296.88, "text": " I'm done.", "tokens": [50964, 286, 478, 1096, 13, 51014], "temperature": 0.0, "avg_logprob": -0.19999247691670402, "compression_ratio": 1.412121212121212, "no_speech_prob": 0.02163047157227993}, {"id": 244, "seek": 128388, "start": 1296.88, "end": 1302.88, "text": " And if you have some questions or some thoughts to share, but annotated, I'm happy to discuss.", "tokens": [51014, 400, 498, 291, 362, 512, 1651, 420, 512, 4598, 281, 2073, 11, 457, 25339, 770, 11, 286, 478, 2055, 281, 2248, 13, 51314], "temperature": 0.0, "avg_logprob": -0.19999247691670402, "compression_ratio": 1.412121212121212, "no_speech_prob": 0.02163047157227993}, {"id": 245, "seek": 130288, "start": 1302.88, "end": 1314.88, "text": " Thank you very much, Tennis. Do we have any questions?", "tokens": [50364, 1044, 291, 588, 709, 11, 314, 11307, 13, 1144, 321, 362, 604, 1651, 30, 50964], "temperature": 0.0, "avg_logprob": -0.17063289218478733, "compression_ratio": 1.282442748091603, "no_speech_prob": 0.14650999009609222}, {"id": 246, "seek": 130288, "start": 1314.88, "end": 1317.88, "text": " Let's see. Now is your chance to raise your hand.", "tokens": [50964, 961, 311, 536, 13, 823, 307, 428, 2931, 281, 5300, 428, 1011, 13, 51114], "temperature": 0.0, "avg_logprob": -0.17063289218478733, "compression_ratio": 1.282442748091603, "no_speech_prob": 0.14650999009609222}, {"id": 247, "seek": 130288, "start": 1317.88, "end": 1319.88, "text": " I can see one question there.", "tokens": [51114, 286, 393, 536, 472, 1168, 456, 13, 51214], "temperature": 0.0, "avg_logprob": -0.17063289218478733, "compression_ratio": 1.282442748091603, "no_speech_prob": 0.14650999009609222}, {"id": 248, "seek": 130288, "start": 1319.88, "end": 1331.88, "text": " Don't be shy. Raise high, please.", "tokens": [51214, 1468, 380, 312, 12685, 13, 30062, 1090, 11, 1767, 13, 51814], "temperature": 0.0, "avg_logprob": -0.17063289218478733, "compression_ratio": 1.282442748091603, "no_speech_prob": 0.14650999009609222}, {"id": 249, "seek": 133188, "start": 1331.88, "end": 1332.88, "text": " Hello.", "tokens": [50364, 2425, 13, 50414], "temperature": 0.0, "avg_logprob": -0.15528488159179688, "compression_ratio": 1.729957805907173, "no_speech_prob": 0.3440733551979065}, {"id": 250, "seek": 133188, "start": 1332.88, "end": 1334.88, "text": " Thanks for your talk. It was very cool.", "tokens": [50414, 2561, 337, 428, 751, 13, 467, 390, 588, 1627, 13, 50514], "temperature": 0.0, "avg_logprob": -0.15528488159179688, "compression_ratio": 1.729957805907173, "no_speech_prob": 0.3440733551979065}, {"id": 251, "seek": 133188, "start": 1334.88, "end": 1339.88, "text": " Could you go into a little bit more detail of how I could use annotated on my own class?", "tokens": [50514, 7497, 291, 352, 666, 257, 707, 857, 544, 2607, 295, 577, 286, 727, 764, 25339, 770, 322, 452, 1065, 1508, 30, 50764], "temperature": 0.0, "avg_logprob": -0.15528488159179688, "compression_ratio": 1.729957805907173, "no_speech_prob": 0.3440733551979065}, {"id": 252, "seek": 133188, "start": 1339.88, "end": 1342.88, "text": " Because like I saw it in Pydantic and I was like, oh, cool.", "tokens": [50764, 1436, 411, 286, 1866, 309, 294, 430, 6655, 7128, 293, 286, 390, 411, 11, 1954, 11, 1627, 13, 50914], "temperature": 0.0, "avg_logprob": -0.15528488159179688, "compression_ratio": 1.729957805907173, "no_speech_prob": 0.3440733551979065}, {"id": 253, "seek": 133188, "start": 1342.88, "end": 1346.88, "text": " But I didn't quite get how I could use that in my own...", "tokens": [50914, 583, 286, 994, 380, 1596, 483, 577, 286, 727, 764, 300, 294, 452, 1065, 485, 51114], "temperature": 0.0, "avg_logprob": -0.15528488159179688, "compression_ratio": 1.729957805907173, "no_speech_prob": 0.3440733551979065}, {"id": 254, "seek": 133188, "start": 1346.88, "end": 1351.88, "text": " Sorry, can you repeat?", "tokens": [51114, 4919, 11, 393, 291, 7149, 30, 51364], "temperature": 0.0, "avg_logprob": -0.15528488159179688, "compression_ratio": 1.729957805907173, "no_speech_prob": 0.3440733551979065}, {"id": 255, "seek": 133188, "start": 1351.88, "end": 1356.88, "text": " No, okay. Could you tell me how I could use that annotated trick on my own class", "tokens": [51364, 883, 11, 1392, 13, 7497, 291, 980, 385, 577, 286, 727, 764, 300, 25339, 770, 4282, 322, 452, 1065, 1508, 51614], "temperature": 0.0, "avg_logprob": -0.15528488159179688, "compression_ratio": 1.729957805907173, "no_speech_prob": 0.3440733551979065}, {"id": 256, "seek": 133188, "start": 1356.88, "end": 1359.88, "text": " instead of it being like a Pydantic base model thing?", "tokens": [51614, 2602, 295, 309, 885, 411, 257, 430, 6655, 7128, 3096, 2316, 551, 30, 51764], "temperature": 0.0, "avg_logprob": -0.15528488159179688, "compression_ratio": 1.729957805907173, "no_speech_prob": 0.3440733551979065}, {"id": 257, "seek": 135988, "start": 1359.88, "end": 1372.88, "text": " Yeah, that's what I illustrated.", "tokens": [50364, 865, 11, 300, 311, 437, 286, 33875, 13, 51014], "temperature": 0.0, "avg_logprob": -0.1635609245300293, "compression_ratio": 1.3529411764705883, "no_speech_prob": 0.2348642796278}, {"id": 258, "seek": 135988, "start": 1372.88, "end": 1379.88, "text": " So here you have this cellulizer, which is a class I just defined for the example.", "tokens": [51014, 407, 510, 291, 362, 341, 2815, 425, 6545, 11, 597, 307, 257, 1508, 286, 445, 7642, 337, 264, 1365, 13, 51364], "temperature": 0.0, "avg_logprob": -0.1635609245300293, "compression_ratio": 1.3529411764705883, "no_speech_prob": 0.2348642796278}, {"id": 259, "seek": 135988, "start": 1379.88, "end": 1387.88, "text": " And then you annotate your attribute with your cellulizer instances.", "tokens": [51364, 400, 550, 291, 25339, 473, 428, 19667, 365, 428, 2815, 425, 6545, 14519, 13, 51764], "temperature": 0.0, "avg_logprob": -0.1635609245300293, "compression_ratio": 1.3529411764705883, "no_speech_prob": 0.2348642796278}, {"id": 260, "seek": 138788, "start": 1387.88, "end": 1392.88, "text": " Here it takes an option, which is the label of the cellulization value.", "tokens": [50364, 1692, 309, 2516, 364, 3614, 11, 597, 307, 264, 7645, 295, 264, 2815, 425, 2144, 2158, 13, 50614], "temperature": 0.0, "avg_logprob": -0.1169463877092328, "compression_ratio": 1.6434426229508197, "no_speech_prob": 0.07240840047597885}, {"id": 261, "seek": 138788, "start": 1392.88, "end": 1398.88, "text": " And then you need to write this kind of function in order to consume the annotation", "tokens": [50614, 400, 550, 291, 643, 281, 2464, 341, 733, 295, 2445, 294, 1668, 281, 14732, 264, 48654, 50914], "temperature": 0.0, "avg_logprob": -0.1169463877092328, "compression_ratio": 1.6434426229508197, "no_speech_prob": 0.07240840047597885}, {"id": 262, "seek": 138788, "start": 1398.88, "end": 1402.88, "text": " of the instance of your event class.", "tokens": [50914, 295, 264, 5197, 295, 428, 2280, 1508, 13, 51114], "temperature": 0.0, "avg_logprob": -0.1169463877092328, "compression_ratio": 1.6434426229508197, "no_speech_prob": 0.07240840047597885}, {"id": 263, "seek": 138788, "start": 1402.88, "end": 1407.88, "text": " Yeah, but the event was inheriting from base model, which was a Pydantic thing.", "tokens": [51114, 865, 11, 457, 264, 2280, 390, 9484, 1748, 490, 3096, 2316, 11, 597, 390, 257, 430, 6655, 7128, 551, 13, 51364], "temperature": 0.0, "avg_logprob": -0.1169463877092328, "compression_ratio": 1.6434426229508197, "no_speech_prob": 0.07240840047597885}, {"id": 264, "seek": 138788, "start": 1407.88, "end": 1409.88, "text": " So if I'm in my own project...", "tokens": [51364, 407, 498, 286, 478, 294, 452, 1065, 1716, 485, 51464], "temperature": 0.0, "avg_logprob": -0.1169463877092328, "compression_ratio": 1.6434426229508197, "no_speech_prob": 0.07240840047597885}, {"id": 265, "seek": 138788, "start": 1409.88, "end": 1411.88, "text": " You don't need to do this Pydantic for this.", "tokens": [51464, 509, 500, 380, 643, 281, 360, 341, 430, 6655, 7128, 337, 341, 13, 51564], "temperature": 0.0, "avg_logprob": -0.1169463877092328, "compression_ratio": 1.6434426229508197, "no_speech_prob": 0.07240840047597885}, {"id": 266, "seek": 138788, "start": 1411.88, "end": 1414.88, "text": " You can take a built-in class or a data class, or...", "tokens": [51564, 509, 393, 747, 257, 3094, 12, 259, 1508, 420, 257, 1412, 1508, 11, 420, 485, 51714], "temperature": 0.0, "avg_logprob": -0.1169463877092328, "compression_ratio": 1.6434426229508197, "no_speech_prob": 0.07240840047597885}, {"id": 267, "seek": 141488, "start": 1414.88, "end": 1416.88, "text": " It's not related to Pydantic.", "tokens": [50364, 467, 311, 406, 4077, 281, 430, 6655, 7128, 13, 50464], "temperature": 0.0, "avg_logprob": -0.14303349434061252, "compression_ratio": 1.507462686567164, "no_speech_prob": 0.0792178213596344}, {"id": 268, "seek": 141488, "start": 1416.88, "end": 1423.88, "text": " The Pydantic thing was just for the first example, validating the time.", "tokens": [50464, 440, 430, 6655, 7128, 551, 390, 445, 337, 264, 700, 1365, 11, 7363, 990, 264, 565, 13, 50814], "temperature": 0.0, "avg_logprob": -0.14303349434061252, "compression_ratio": 1.507462686567164, "no_speech_prob": 0.0792178213596344}, {"id": 269, "seek": 141488, "start": 1423.88, "end": 1425.88, "text": " Apart from that, you don't need Pydantic at all.", "tokens": [50814, 24111, 490, 300, 11, 291, 500, 380, 643, 430, 6655, 7128, 412, 439, 13, 50914], "temperature": 0.0, "avg_logprob": -0.14303349434061252, "compression_ratio": 1.507462686567164, "no_speech_prob": 0.0792178213596344}, {"id": 270, "seek": 141488, "start": 1425.88, "end": 1430.88, "text": " Okay, thank you very much.", "tokens": [50914, 1033, 11, 1309, 291, 588, 709, 13, 51164], "temperature": 0.0, "avg_logprob": -0.14303349434061252, "compression_ratio": 1.507462686567164, "no_speech_prob": 0.0792178213596344}, {"id": 271, "seek": 141488, "start": 1430.88, "end": 1432.88, "text": " Thank you. Do we have any more questions?", "tokens": [51164, 1044, 291, 13, 1144, 321, 362, 604, 544, 1651, 30, 51264], "temperature": 0.0, "avg_logprob": -0.14303349434061252, "compression_ratio": 1.507462686567164, "no_speech_prob": 0.0792178213596344}, {"id": 272, "seek": 141488, "start": 1432.88, "end": 1435.88, "text": " One more. One more.", "tokens": [51264, 1485, 544, 13, 1485, 544, 13, 51414], "temperature": 0.0, "avg_logprob": -0.14303349434061252, "compression_ratio": 1.507462686567164, "no_speech_prob": 0.0792178213596344}, {"id": 273, "seek": 141488, "start": 1435.88, "end": 1438.88, "text": " The session is still being recorded.", "tokens": [51414, 440, 5481, 307, 920, 885, 8287, 13, 51564], "temperature": 0.0, "avg_logprob": -0.14303349434061252, "compression_ratio": 1.507462686567164, "no_speech_prob": 0.0792178213596344}, {"id": 274, "seek": 141488, "start": 1438.88, "end": 1441.88, "text": " So please be silent there.", "tokens": [51564, 407, 1767, 312, 12784, 456, 13, 51714], "temperature": 0.0, "avg_logprob": -0.14303349434061252, "compression_ratio": 1.507462686567164, "no_speech_prob": 0.0792178213596344}, {"id": 275, "seek": 144188, "start": 1442.88, "end": 1444.88, "text": " How can we reach you?", "tokens": [50414, 1012, 393, 321, 2524, 291, 30, 50514], "temperature": 0.0, "avg_logprob": -0.19833366454593718, "compression_ratio": 2.0168539325842696, "no_speech_prob": 0.1747037172317505}, {"id": 276, "seek": 144188, "start": 1452.88, "end": 1454.88, "text": " I'm not sure if it's okay to ask that.", "tokens": [50914, 286, 478, 406, 988, 498, 309, 311, 1392, 281, 1029, 300, 13, 51014], "temperature": 0.0, "avg_logprob": -0.19833366454593718, "compression_ratio": 2.0168539325842696, "no_speech_prob": 0.1747037172317505}, {"id": 277, "seek": 144188, "start": 1454.88, "end": 1458.88, "text": " Is it possible to use that in Django, REST, and WorkSphere Realizer?", "tokens": [51014, 1119, 309, 1944, 281, 764, 300, 294, 33464, 17150, 11, 497, 14497, 11, 293, 6603, 50, 6605, 8467, 6545, 30, 51214], "temperature": 0.0, "avg_logprob": -0.19833366454593718, "compression_ratio": 2.0168539325842696, "no_speech_prob": 0.1747037172317505}, {"id": 278, "seek": 144188, "start": 1458.88, "end": 1462.88, "text": " Have you tried or have you seen anyone try that using this one?", "tokens": [51214, 3560, 291, 3031, 420, 362, 291, 1612, 2878, 853, 300, 1228, 341, 472, 30, 51414], "temperature": 0.0, "avg_logprob": -0.19833366454593718, "compression_ratio": 2.0168539325842696, "no_speech_prob": 0.1747037172317505}, {"id": 279, "seek": 144188, "start": 1462.88, "end": 1464.88, "text": " Is it Django, REST, and WorkSphere Realizer?", "tokens": [51414, 1119, 309, 33464, 17150, 11, 497, 14497, 11, 293, 6603, 50, 6605, 8467, 6545, 30, 51514], "temperature": 0.0, "avg_logprob": -0.19833366454593718, "compression_ratio": 2.0168539325842696, "no_speech_prob": 0.1747037172317505}, {"id": 280, "seek": 144188, "start": 1464.88, "end": 1465.88, "text": " In Django?", "tokens": [51514, 682, 33464, 17150, 30, 51564], "temperature": 0.0, "avg_logprob": -0.19833366454593718, "compression_ratio": 2.0168539325842696, "no_speech_prob": 0.1747037172317505}, {"id": 281, "seek": 144188, "start": 1465.88, "end": 1467.88, "text": " Yes, Django, REST, and WorkSphere Realizer.", "tokens": [51564, 1079, 11, 33464, 17150, 11, 497, 14497, 11, 293, 6603, 50, 6605, 8467, 6545, 13, 51664], "temperature": 0.0, "avg_logprob": -0.19833366454593718, "compression_ratio": 2.0168539325842696, "no_speech_prob": 0.1747037172317505}, {"id": 282, "seek": 144188, "start": 1467.88, "end": 1470.88, "text": " I don't know. I don't know Django, REST, and WorkSphere Realizer.", "tokens": [51664, 286, 500, 380, 458, 13, 286, 500, 380, 458, 33464, 17150, 11, 497, 14497, 11, 293, 6603, 50, 6605, 8467, 6545, 13, 51814], "temperature": 0.0, "avg_logprob": -0.19833366454593718, "compression_ratio": 2.0168539325842696, "no_speech_prob": 0.1747037172317505}, {"id": 283, "seek": 147088, "start": 1470.88, "end": 1475.88, "text": " In fact, you can use it as long as you define your own way of consuming the annotation.", "tokens": [50364, 682, 1186, 11, 291, 393, 764, 309, 382, 938, 382, 291, 6964, 428, 1065, 636, 295, 19867, 264, 48654, 13, 50614], "temperature": 0.0, "avg_logprob": -0.1311486749088063, "compression_ratio": 1.5223880597014925, "no_speech_prob": 0.2877194285392761}, {"id": 284, "seek": 147088, "start": 1475.88, "end": 1479.88, "text": " So if you want this kind of helper function, you can use it, definitely.", "tokens": [50614, 407, 498, 291, 528, 341, 733, 295, 36133, 2445, 11, 291, 393, 764, 309, 11, 2138, 13, 50814], "temperature": 0.0, "avg_logprob": -0.1311486749088063, "compression_ratio": 1.5223880597014925, "no_speech_prob": 0.2877194285392761}, {"id": 285, "seek": 147088, "start": 1479.88, "end": 1480.88, "text": " Okay.", "tokens": [50814, 1033, 13, 50864], "temperature": 0.0, "avg_logprob": -0.1311486749088063, "compression_ratio": 1.5223880597014925, "no_speech_prob": 0.2877194285392761}, {"id": 286, "seek": 147088, "start": 1480.88, "end": 1483.88, "text": " It's not bound to a particular framework, in fact.", "tokens": [50864, 467, 311, 406, 5472, 281, 257, 1729, 8388, 11, 294, 1186, 13, 51014], "temperature": 0.0, "avg_logprob": -0.1311486749088063, "compression_ratio": 1.5223880597014925, "no_speech_prob": 0.2877194285392761}, {"id": 287, "seek": 147088, "start": 1483.88, "end": 1485.88, "text": " It's in the standard pattern.", "tokens": [51014, 467, 311, 294, 264, 3832, 5102, 13, 51114], "temperature": 0.0, "avg_logprob": -0.1311486749088063, "compression_ratio": 1.5223880597014925, "no_speech_prob": 0.2877194285392761}, {"id": 288, "seek": 147088, "start": 1485.88, "end": 1487.88, "text": " Thank you very much.", "tokens": [51114, 1044, 291, 588, 709, 13, 51214], "temperature": 0.0, "avg_logprob": -0.1311486749088063, "compression_ratio": 1.5223880597014925, "no_speech_prob": 0.2877194285392761}, {"id": 289, "seek": 147088, "start": 1487.88, "end": 1489.88, "text": " Another round of applause for Dennis.", "tokens": [51214, 3996, 3098, 295, 9969, 337, 23376, 13, 51314], "temperature": 0.0, "avg_logprob": -0.1311486749088063, "compression_ratio": 1.5223880597014925, "no_speech_prob": 0.2877194285392761}], "language": "en"}