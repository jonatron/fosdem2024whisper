{"text": " All right. Why can't everyone, while the last people join the room, let me ask a few questions to get an idea of the audience that we have here. So, quick show of hands. Who of you knows AGL Automotive Grid Linux? That's quite a lot. Awesome. Another question. Who of you knows Cooxer? Okay, let us change that because that way, fewer hands than for the AGL. But I think that's a good thing. Last and final question. Who's here still from the beer talk? Like room beer? Okay, I'm glad. We actually came out of these talks. So, as you can already see in the introduction slide, we will talk about vehicular abstraction. So, we talk about Automotive Grid Linux and we talk about Cooxer. So, before that, maybe a bit of context. Who am I? So, I'm not the super automotive developer doing a Canon AutoZer for the last 20 years of my career, also due to age. But I started with really coming from the cloud. I used to keep an E2 working on different projects in Github. And I thought, how can we actually make application development for vehicles more fun and efficient? And one really large essential piece here is one challenge because there are no restandardized signals. You can develop an app for one car and it won't run on another vehicle, even maybe from the same vendor. So, what we often see in the industry is this kind of high end-to-end complexity. So, every application is developed for every specific model, every specific car, and we have a huge pay point for that because you cannot port your applications there. You cannot scale, so if a developer is developing an app for one brand, it won't work on the other brand and also maintenance is just a nightmare because just build it for one car and then you completely forget it. So, as always in computer science, one solution to that is abstraction. That's why we also took a lot of effort in the topic of vehicle abstraction here. So, how can we make a world like this happen? So, where we have tons of applications that develop against the same API, against the same data model and that work just on different cars. While it's the same car, it's the same time. I'm talking a bit too much about cars. We run it on different models, different brands and so on. So, basically how do we get to the world where we ride at once and run it everywhere and to also attract third-party developers because this is how you grow the ecosystem and also make it more attractive to develop the unrealized synergies. So, for this abstraction, I would say we basically need two things. One is a data model to operate on and the other thing is the APIs to interact with the data model. Coming to the first thing, I hope, here we go. When it comes to the data model or you might also call a taxonomy, we decided for the CoVisa Vehicle Signal Specification. So, it's done at an organization called CoVisa, formerly known as GenoVee. Maybe that rings the bell for some. And it was basically does. It creates a tree structure for all kinds of data that might be available in the vehicle. So, for instance, you get the tire pressure. You follow the branch of vehicle, chassis, axle, road, one, wheel, tire and then you get to the pressure signal. The same way you have sensor values in here, you can also have actuator values. So, for instance, when we have a seat position, we could just change this value of the seat position and eventually that seat in the car would move to that position. That's the idea of this whole data model. If you want to play a bit with that, there's also a really cool website called Digital Auto that makes nice visualization of that and also shows some example applications how you interact with VSS. Okay, now we go to the first piece. How about the second? And this is where Cooxa or more specific Cooxa Viara comes into play. So, while in this case, vehicle abstraction layer, so we talk about abstraction, so the idea is to have Cooxa running in the vehicle computer. So, some kind of computer which might run Unix or something similar to that. And we also assume this is a place where we decub the hard from the software in the vehicle. So, the underlying assumption is something you can see on the left. So, we have a lot of deeply embedded layers, can, autos, are, lin, sum, IP, whatever you like or maybe don't like, which is maybe really proprietary in some cases and also the signals and the bits are really specific to the car. So, then people would write something that we call provider or also feeder to translate between these really specific systems and embedded systems towards VSS using the Cooxa API. This is where the API is coming from because we use here Cooxa. If you like more on the abstraction side, we also can say like in the deeply embedded layers, we mostly have data like really 1001 or the bits and we kind of need to interpret those. So, we translate it to VSS, get some information out of that and then by combining this information in different applications, we actually create knowledge. And here Cooxa is a nice building piece for that. So, what is Cooxa in general? So, since we are in the open source conference, obviously it is open source, fully licensed on the APHG 2.0 license and as I just mentioned in the previous slide, it is some kind of digital twin based on VSS. So, it shows the current and the target value of your vehicle. I don't want to go into the definition of digital twins but I guess you kind of get what I am getting at here. And so, you only have the current value which is quite nice but you also have the target value. So, coming back to our seed example, when you would change the value, the current value as an application from a seed, this doesn't meet the seed is actually where I wanted to have. So, I actually will set the target value and then it is up to the deeply embedded layers, so the actual vehicle to move the position of the seed over time. So, that is why you can change both value and hopefully at some point the current value will be the target value because that is the whole idea. So, much about the concepts. Let's get to the code. Or maybe I won't show code here but what it is actually written in. So, we wrote this in Rust. If you steadily compile it, it is less than 4 megabytes, large or small depending on which word you are coming from I guess. Like, these are the cloud words and it is small from the automotive words, maybe large to you. And it is quite language agnostic because the interaction with this is with it because we have a GIPC interface with some basic functions like get, set and subscribe and also a number of client libraries using this. And with that, that is actually the basic of Cooxing and I have to be honest with you, if you have been in this death room last year, you would say where is the news because this has been shown there as well. So, let's get to the news. So, what has happened in the previous year? First and foremost, it was using AGL so Scott will talk a lot about that in the next minutes. But we also have some other news. For instance, we now have a Cooxer Android SDK, we have a mock service and we also did some work with later from our side. So, the Cooxer Android SDK, I mean it is kind of straightforward because in the end of the SDK, that is now available in Maven Central and you can interact with the data broker from an Android application. So, be it Android automotive or maybe your own app on your smartphone. So, assuming you have some kind of Cooxer abstraction in your vehicle, you can use a companion app for instance, which we are about to release to the F2O store. Now, there will be a moment for the releases there. We did support request beginning of the week, but we still wait for F2O to actually show this app in their repository. So, stay with me till Monday, then it might be there hopefully. Another thing is a mock service because the guys in the previous presentation had their robot here. We cannot always have a car on our lab to test the application, but we kind of depend on the behavior of the vehicle. So, we need a way to mox this. So, the community came up with a behavior definition. For instance, whenever the signal of a seed is changed to a certain value, like 1000, then the current value should also change to that value. And this is what you can basically mock or emulate with the mock service to show you just an example. Here we have just an example I mentioned. So, whenever the driver's side position changes, then we create an animation to move to that position or to move the current value to that position, which makes it quite easy and flexible to test whatever you desire with your car. And last but not least, this is just a sneak preview into the lab. So, Cooxer is part of the larger community in the Eclipse Foundation. There's an Eclipse software defined working group, or short Eclipse STV. And there's another distribution called Eclipse Leder, which tries to combine some of the major pieces of the ecosystem there. And this is called Leder. And what we managed to do is actually run the Leder-Yogtu layer on top of an HGL, so that you actually get these pieces, like especially Cooxer, but also some other projects like Cantal, to run on the HGL stack. And I think this is a really good opportunity to learn a bit more about HGL here. Oh, okay. I'll take over then. All right. Thank you, Sven Eric. So, I have done a lot of stuff around HGL, so people might recognize me. I'm Scott Murray. I've done Linux for a long time, and I've been at Linux for a reasonably long time as well. I've been working on HGL on contract for pretty much eight years at this point, and doing all kinds of different things for the project around keeping the Yogtu stuff up to date, and also doing a lot of the demo and integration type of things. So, there was maybe almost half of the people indicating that it would be what HGL was, but I'll do a very quick run-through. So it's a collaborative open source project, basically trying to build a base platform that you can build an automotive product on. So it's about 10 years old. We have a vast array of members now, a lot of the major OEMs, and tier one and two new suppliers. It's pretty much a code first sort of thing, where we are more focused on let's build the distro and get it there for people to try and involve. A lot of work went into that. You might have seen HGL demos for several years doing that type of stuff, but our members were basically saying in 2020 that they weren't interested in maintaining that because they weren't going to use it in product. They all have their own application frameworks, or they buy an application framework, and they like to see HGL focus on lower level, show us how to use open source more than writing new stuff. So we started out, our tech demos, or integration demos are more like taking best of breed open source projects and showing people an automotive. Here's how you use these things. And so this really worked out well, because we weren't connecting. We needed something to show here's how you will do vehicle signaling, and VSS and Cooks of Al basically were starting to come out around the same time that we needed a new thing. So I had started playing with Cooks of Al in 2021. Our first release basically was our spring release in 2022. And it replaced our old signal composer and our can service with basically the original Cooks of Al server. And so since then, basically since spring 2022, we have recipes in our layers for HGL to build the Cooks of Al server, now the data broker. And as well, we actually have some signal customization stuff to sort of access an example of here's how you add some custom signals. And we use their can feeder to basically sort of wire up and show here's how you put all these pieces together. We have our own sort of like mocked up HGL virtual car can definitions. And so that sort of acts as an example for people to use. So that was spring 2022, like I said, and that won't go into all the nitty-gritty there. But originally, we were using the original Web socket API, which is a standard thing with sort of companion to VSS. We actually had can working in our demos. And so through 2022 and into 2023, we were sort of keeping up with the Cooks of Al releases. I started, you know, some nominal updates around switching how we were doing our signal additions and stuff. And then this past summer, our pike release, basically, I started the process of switching over to the data broker, which is the rust based implementation. And so I actually got interesting because we're based on Yachto Kirkstone, which is the LTS release, which at this point is two years old. And it has older rust. So we couldn't actually build the data broker. And so that was the thing where basically, a jail, we contributed upstream, I have a layer that you can get for the Yachto Kirkstone like mix in basically gives you a newer rust to be able to build the data broker, which other people I now are no are using for building other rust projects. So that, you know, we're now starting to look at the data broker, this cop coming release. Basically, we were now using the absolutely latest version of Cooks. And that now I fully have us all switched over everything's data broker using gRPC, all our demos are converted. And that basically acts as a thing. We're trying to see this with the automotive community, because, you know, we see a lot of vendor, you know, or we encode that people open source is all like custom IPC and stuff like that. And it's like, Well, no, there are open source projects that are heavily used that do, you know, gRPC and, you know, interact with cloud providers and stuff, you don't have to reinvent the wheel. So Cooks of Al has been a very good thing for us to sort of try and get that to people. So how exactly are we using an AGL? So there's, you know, the assess applications. As Eric mentioned, the concept of, you know, there's actuators. So there's, you know, apps that basically just listen to sensors. So like dashboards type of, you know, things like that. And then for acting on signals, so basically implement an actuator behavior, we have some example services that do that kind of thing. It's like HVAC sort of stuff. There's also setting an actuator value. So that would be like on a user facing infotainment app would be like HVAC controls or, you know, audio or volume that type of stuff. So in our tree right now, we have two demo services that basically do that actuator side of things. So we have HVAC service that basically listens to all the like signals in the VSS hierarchy around HVAC controls. And then in our demo setup, which unfortunately we won't have the full setup here, actually pushes out to drive some fans and things like that. In the audio side, basically I'm listening into the audio like volume signal that's in VSS and we, you know, have some custom things that I'm working to push upstream. But basically actually drive that down into wire plumber and actually like adjust the, you know, the audio setup. The user facing side are demo applications, the QT demo, which I think we might be showing tomorrow. Basically we're using the SS signals for like everything pretty much. So all the applications in that demo, which are in our source tree, you can grab them, basically are all wired up to do VSS signaling. And the code is sort of in a nice little library now and basically allow you to reuse it. On our newer Flutter demo, which I'm not truthful, actually maybe I think we'll have one setup that'll have that tomorrow. Basically it's, you know, it has a unified sort of home screen. It's doing GRPC from Dart. And right now I don't have that sort of library sort of packaged up yet, but that might happen this year. Or we might move it to native code. Tidder, who are big into Flutter, they tell us that's what they do that for some of their stuff. So, you know, we're pretty much, this is what our newer Flutter demo looks like. And so in this demo, like the tire pressure, all the likes, you know, vehicle speeds and stuff like that, and all the, like the AC controls and the temperature, all of that is going through VSS signaling to driving, you know, demons or whatever you want to do. Or KNData coming in actually gets converted back into a signal update. So, so there's some extra, you know, presentations from Sven and Eric myself. And we're going to be in the AW building tomorrow. We're open bed at work today. We're to have that table tomorrow. We'll have our demos. And this is, you want to do your pitch? Sure. So if this sounds interesting, or even if it doesn't sound interesting, there's a huge chance to engage with the community around coaxa and the larger communities in the automotive sector. So we have something called Bosch Connected Experience. It's hosted by Bosch, but it's basically very large hackathon in Berlin in the end of February. So a bit short notice, but I would be really glad to see some of you there. We have the chance to work with a lot of things like maybe actual seats, maybe actual cars, hopefully. Or and also we plan to have some meetable assimilation of a car which is then connected to a data broker. So I think it will also be cool what you can do with combining these physical and also this cyber physical world, if you will. So I really encourage you to do that. If you want to come there, you normally have to apply. But if you just approach me, I think we'll find a quick way to get you in because being you in this room, I think qualifies as a good hacker for that. So was that maybe you there on another community meeting? So thanks a lot for stating this out and we open for questions. Yeah, I think we have a couple of minutes. Yeah, we'll have to share. Thank you. Great talk. Just wanted to understand a little bit about your testing cycle. So if you you're developing something with this and then you test it in a virtual environment and then you want to test it on a real car, like what do you do in practice when you're developing stuff? Do you have an answer to that? So I wouldn't have a straight answer because here we talk more about implementing that abstraction layer and mostly testing it against things like this mock service or with something like a feeder where we have recorded data. But things that you're touching on a small like a really general topic on how do I actually get my automotive software up and running and into the vehicle. So that's a bit beyond the scope of what just the Cookshead project is doing. So not too much I can comment on here, but I think it's a good topic for the communities, either AGL or Eclipse STB because we have some rounds of meetings where we exactly talk about that. Yeah, I would just say that it's still actually pretty early days for DSS. I mean, I know there's a bunch of OEMs and interior ones that are actively working to product eyes. So I don't think we have visibility yet into how they're actually going about and testing. So I think hopefully in the next year or two we'll see more and we'll maybe get some ideas there. Any more questions? Maybe in two or three words, can you share a little bit about the data broker? Is it something that looked like Debus? Is it something like look like MQTT broker? Something else? What it looks like exactly? Is it something that we can reuse elsewhere or is it specific to Cookshead? I would say the data broker is really specific to VSS data. So it's not like you can put any data in there. So the way it works is you start the data broker and you also give it this VSS data model that you have. So the VSS data model is expressed in a JSON or in a YAML file. Then you put this JSON or YAML file into the data broker and then you can basically do get set and subscribe. That's why I put up this slide again on this kind of data which is expressed in the data model and then the data broker implicitly knows about that. When you talk about MQTT, there's also I have to admit other APIs to interact with VSS. For instance, VIST done in W3C and they also looked a bit into how to do that over MQTT. But again here, the data broker is especially tailored to interact with VSS signals. That's why I cannot generalize it too much. Basically, when I go home, I have a project that our vehicle to cloud, Expert Group in Agile, wants to see basically pushing from VSS up into the cloud. So I'm going to be building a proxy that will basically take a list of signals to listen to from the VSS data broker or cooks a data broker and then basically MQTT them up somewhere. So then talk to us in a better world. I'll have a story for you then. Maybe one final thing to add to that. As there's one slide, I actually removed it from the slide deck but there has been a huge discussion in the VSS community whether VSS is actually fit in the vehicle or whether you should use VSS more on the cloud back end so that you put all the data from the car and whatever form it up to the cloud and then consume it in VSS there. And the data broker is kind of like an answer to yeah, it's also possible to do it in the car in addition to the cloud. So that's kind of the background story as well. Okay, so I think that's all we have time for for the moment. So thank you very much Sven Eric and Scott and round of applause.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 12.26, "text": " All right. Why can't everyone, while the last people join the room, let me ask a few questions", "tokens": [50364, 1057, 558, 13, 1545, 393, 380, 1518, 11, 1339, 264, 1036, 561, 3917, 264, 1808, 11, 718, 385, 1029, 257, 1326, 1651, 50977], "temperature": 0.0, "avg_logprob": -0.2735811697470175, "compression_ratio": 1.4263157894736842, "no_speech_prob": 0.5952090620994568}, {"id": 1, "seek": 0, "start": 12.26, "end": 16.32, "text": " to get an idea of the audience that we have here. So, quick show of hands. Who of you", "tokens": [50977, 281, 483, 364, 1558, 295, 264, 4034, 300, 321, 362, 510, 13, 407, 11, 1702, 855, 295, 2377, 13, 2102, 295, 291, 51180], "temperature": 0.0, "avg_logprob": -0.2735811697470175, "compression_ratio": 1.4263157894736842, "no_speech_prob": 0.5952090620994568}, {"id": 2, "seek": 0, "start": 16.32, "end": 24.400000000000002, "text": " knows AGL Automotive Grid Linux? That's quite a lot. Awesome. Another question. Who of you", "tokens": [51180, 3255, 316, 19440, 24619, 22459, 42905, 18734, 30, 663, 311, 1596, 257, 688, 13, 10391, 13, 3996, 1168, 13, 2102, 295, 291, 51584], "temperature": 0.0, "avg_logprob": -0.2735811697470175, "compression_ratio": 1.4263157894736842, "no_speech_prob": 0.5952090620994568}, {"id": 3, "seek": 2440, "start": 24.4, "end": 31.04, "text": " knows Cooxer? Okay, let us change that because that way, fewer hands than for the AGL. But I", "tokens": [50364, 3255, 383, 1986, 87, 260, 30, 1033, 11, 718, 505, 1319, 300, 570, 300, 636, 11, 13366, 2377, 813, 337, 264, 316, 19440, 13, 583, 286, 50696], "temperature": 0.0, "avg_logprob": -0.34729845383588004, "compression_ratio": 1.5368852459016393, "no_speech_prob": 0.185836061835289}, {"id": 4, "seek": 2440, "start": 31.04, "end": 35.2, "text": " think that's a good thing. Last and final question. Who's here still from the beer talk?", "tokens": [50696, 519, 300, 311, 257, 665, 551, 13, 5264, 293, 2572, 1168, 13, 2102, 311, 510, 920, 490, 264, 8795, 751, 30, 50904], "temperature": 0.0, "avg_logprob": -0.34729845383588004, "compression_ratio": 1.5368852459016393, "no_speech_prob": 0.185836061835289}, {"id": 5, "seek": 2440, "start": 35.2, "end": 43.72, "text": " Like room beer? Okay, I'm glad. We actually came out of these talks. So, as you can already see", "tokens": [50904, 1743, 1808, 8795, 30, 1033, 11, 286, 478, 5404, 13, 492, 767, 1361, 484, 295, 613, 6686, 13, 407, 11, 382, 291, 393, 1217, 536, 51330], "temperature": 0.0, "avg_logprob": -0.34729845383588004, "compression_ratio": 1.5368852459016393, "no_speech_prob": 0.185836061835289}, {"id": 6, "seek": 2440, "start": 43.72, "end": 49.36, "text": " in the introduction slide, we will talk about vehicular abstraction. So, we talk about Automotive", "tokens": [51330, 294, 264, 9339, 4137, 11, 321, 486, 751, 466, 4221, 14646, 37765, 13, 407, 11, 321, 751, 466, 24619, 22459, 51612], "temperature": 0.0, "avg_logprob": -0.34729845383588004, "compression_ratio": 1.5368852459016393, "no_speech_prob": 0.185836061835289}, {"id": 7, "seek": 4936, "start": 49.36, "end": 57.519999999999996, "text": " Grid Linux and we talk about Cooxer. So, before that, maybe a bit of context. Who am I? So, I'm not", "tokens": [50364, 42905, 18734, 293, 321, 751, 466, 383, 1986, 87, 260, 13, 407, 11, 949, 300, 11, 1310, 257, 857, 295, 4319, 13, 2102, 669, 286, 30, 407, 11, 286, 478, 406, 50772], "temperature": 0.0, "avg_logprob": -0.3303950709155482, "compression_ratio": 1.5133333333333334, "no_speech_prob": 0.15546801686286926}, {"id": 8, "seek": 4936, "start": 57.519999999999996, "end": 61.64, "text": " the super automotive developer doing a Canon AutoZer for the last 20 years of my career,", "tokens": [50772, 264, 1687, 32866, 10754, 884, 257, 27666, 13738, 57, 260, 337, 264, 1036, 945, 924, 295, 452, 3988, 11, 50978], "temperature": 0.0, "avg_logprob": -0.3303950709155482, "compression_ratio": 1.5133333333333334, "no_speech_prob": 0.15546801686286926}, {"id": 9, "seek": 4936, "start": 61.64, "end": 66.76, "text": " also due to age. But I started with really coming from the cloud. I used to keep an", "tokens": [50978, 611, 3462, 281, 3205, 13, 583, 286, 1409, 365, 534, 1348, 490, 264, 4588, 13, 286, 1143, 281, 1066, 364, 51234], "temperature": 0.0, "avg_logprob": -0.3303950709155482, "compression_ratio": 1.5133333333333334, "no_speech_prob": 0.15546801686286926}, {"id": 10, "seek": 4936, "start": 66.76, "end": 71.0, "text": " E2 working on different projects in Github. And I thought, how can we actually make", "tokens": [51234, 462, 17, 1364, 322, 819, 4455, 294, 460, 355, 836, 13, 400, 286, 1194, 11, 577, 393, 321, 767, 652, 51446], "temperature": 0.0, "avg_logprob": -0.3303950709155482, "compression_ratio": 1.5133333333333334, "no_speech_prob": 0.15546801686286926}, {"id": 11, "seek": 4936, "start": 71.0, "end": 77.92, "text": " application development for vehicles more fun and efficient? And one really large essential piece", "tokens": [51446, 3861, 3250, 337, 8948, 544, 1019, 293, 7148, 30, 400, 472, 534, 2416, 7115, 2522, 51792], "temperature": 0.0, "avg_logprob": -0.3303950709155482, "compression_ratio": 1.5133333333333334, "no_speech_prob": 0.15546801686286926}, {"id": 12, "seek": 7792, "start": 78.04, "end": 82.88, "text": " here is one challenge because there are no restandardized signals. You can develop an app for", "tokens": [50370, 510, 307, 472, 3430, 570, 456, 366, 572, 319, 1115, 515, 1602, 12354, 13, 509, 393, 1499, 364, 724, 337, 50612], "temperature": 0.0, "avg_logprob": -0.1993400242017663, "compression_ratio": 1.7573529411764706, "no_speech_prob": 0.04745565727353096}, {"id": 13, "seek": 7792, "start": 82.88, "end": 89.08, "text": " one car and it won't run on another vehicle, even maybe from the same vendor. So, what we often", "tokens": [50612, 472, 1032, 293, 309, 1582, 380, 1190, 322, 1071, 5864, 11, 754, 1310, 490, 264, 912, 24321, 13, 407, 11, 437, 321, 2049, 50922], "temperature": 0.0, "avg_logprob": -0.1993400242017663, "compression_ratio": 1.7573529411764706, "no_speech_prob": 0.04745565727353096}, {"id": 14, "seek": 7792, "start": 89.08, "end": 94.8, "text": " see in the industry is this kind of high end-to-end complexity. So, every application is developed", "tokens": [50922, 536, 294, 264, 3518, 307, 341, 733, 295, 1090, 917, 12, 1353, 12, 521, 14024, 13, 407, 11, 633, 3861, 307, 4743, 51208], "temperature": 0.0, "avg_logprob": -0.1993400242017663, "compression_ratio": 1.7573529411764706, "no_speech_prob": 0.04745565727353096}, {"id": 15, "seek": 7792, "start": 94.8, "end": 99.76, "text": " for every specific model, every specific car, and we have a huge pay point for that because you", "tokens": [51208, 337, 633, 2685, 2316, 11, 633, 2685, 1032, 11, 293, 321, 362, 257, 2603, 1689, 935, 337, 300, 570, 291, 51456], "temperature": 0.0, "avg_logprob": -0.1993400242017663, "compression_ratio": 1.7573529411764706, "no_speech_prob": 0.04745565727353096}, {"id": 16, "seek": 7792, "start": 99.76, "end": 104.96000000000001, "text": " cannot port your applications there. You cannot scale, so if a developer is developing an app", "tokens": [51456, 2644, 2436, 428, 5821, 456, 13, 509, 2644, 4373, 11, 370, 498, 257, 10754, 307, 6416, 364, 724, 51716], "temperature": 0.0, "avg_logprob": -0.1993400242017663, "compression_ratio": 1.7573529411764706, "no_speech_prob": 0.04745565727353096}, {"id": 17, "seek": 10496, "start": 105.0, "end": 110.44, "text": " for one brand, it won't work on the other brand and also maintenance is just a nightmare because", "tokens": [50366, 337, 472, 3360, 11, 309, 1582, 380, 589, 322, 264, 661, 3360, 293, 611, 11258, 307, 445, 257, 18724, 570, 50638], "temperature": 0.0, "avg_logprob": -0.15065373872455798, "compression_ratio": 1.6367521367521367, "no_speech_prob": 0.005788228940218687}, {"id": 18, "seek": 10496, "start": 110.44, "end": 116.24, "text": " just build it for one car and then you completely forget it. So, as always in computer science,", "tokens": [50638, 445, 1322, 309, 337, 472, 1032, 293, 550, 291, 2584, 2870, 309, 13, 407, 11, 382, 1009, 294, 3820, 3497, 11, 50928], "temperature": 0.0, "avg_logprob": -0.15065373872455798, "compression_ratio": 1.6367521367521367, "no_speech_prob": 0.005788228940218687}, {"id": 19, "seek": 10496, "start": 116.24, "end": 122.96, "text": " one solution to that is abstraction. That's why we also took a lot of effort in the topic of", "tokens": [50928, 472, 3827, 281, 300, 307, 37765, 13, 663, 311, 983, 321, 611, 1890, 257, 688, 295, 4630, 294, 264, 4829, 295, 51264], "temperature": 0.0, "avg_logprob": -0.15065373872455798, "compression_ratio": 1.6367521367521367, "no_speech_prob": 0.005788228940218687}, {"id": 20, "seek": 10496, "start": 122.96, "end": 129.88, "text": " vehicle abstraction here. So, how can we make a world like this happen? So, where we have tons of", "tokens": [51264, 5864, 37765, 510, 13, 407, 11, 577, 393, 321, 652, 257, 1002, 411, 341, 1051, 30, 407, 11, 689, 321, 362, 9131, 295, 51610], "temperature": 0.0, "avg_logprob": -0.15065373872455798, "compression_ratio": 1.6367521367521367, "no_speech_prob": 0.005788228940218687}, {"id": 21, "seek": 12988, "start": 129.92, "end": 134.92, "text": " applications that develop against the same API, against the same data model and that work just", "tokens": [50366, 5821, 300, 1499, 1970, 264, 912, 9362, 11, 1970, 264, 912, 1412, 2316, 293, 300, 589, 445, 50616], "temperature": 0.0, "avg_logprob": -0.19392923338223347, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.015769630670547485}, {"id": 22, "seek": 12988, "start": 134.92, "end": 139.51999999999998, "text": " on different cars. While it's the same car, it's the same time. I'm talking a bit too much about", "tokens": [50616, 322, 819, 5163, 13, 3987, 309, 311, 264, 912, 1032, 11, 309, 311, 264, 912, 565, 13, 286, 478, 1417, 257, 857, 886, 709, 466, 50846], "temperature": 0.0, "avg_logprob": -0.19392923338223347, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.015769630670547485}, {"id": 23, "seek": 12988, "start": 139.51999999999998, "end": 144.92, "text": " cars. We run it on different models, different brands and so on. So, basically how do we get to", "tokens": [50846, 5163, 13, 492, 1190, 309, 322, 819, 5245, 11, 819, 11324, 293, 370, 322, 13, 407, 11, 1936, 577, 360, 321, 483, 281, 51116], "temperature": 0.0, "avg_logprob": -0.19392923338223347, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.015769630670547485}, {"id": 24, "seek": 12988, "start": 144.92, "end": 149.24, "text": " the world where we ride at once and run it everywhere and to also attract third-party developers", "tokens": [51116, 264, 1002, 689, 321, 5077, 412, 1564, 293, 1190, 309, 5315, 293, 281, 611, 5049, 2636, 12, 23409, 8849, 51332], "temperature": 0.0, "avg_logprob": -0.19392923338223347, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.015769630670547485}, {"id": 25, "seek": 12988, "start": 149.24, "end": 153.92, "text": " because this is how you grow the ecosystem and also make it more attractive to develop the", "tokens": [51332, 570, 341, 307, 577, 291, 1852, 264, 11311, 293, 611, 652, 309, 544, 12609, 281, 1499, 264, 51566], "temperature": 0.0, "avg_logprob": -0.19392923338223347, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.015769630670547485}, {"id": 26, "seek": 15392, "start": 153.95999999999998, "end": 161.11999999999998, "text": " unrealized synergies. So, for this abstraction, I would say we basically need two things. One is a", "tokens": [50366, 25754, 1602, 33781, 25480, 13, 407, 11, 337, 341, 37765, 11, 286, 576, 584, 321, 1936, 643, 732, 721, 13, 1485, 307, 257, 50724], "temperature": 0.0, "avg_logprob": -0.17808212953455307, "compression_ratio": 1.5959183673469388, "no_speech_prob": 0.018126817420125008}, {"id": 27, "seek": 15392, "start": 161.11999999999998, "end": 167.04, "text": " data model to operate on and the other thing is the APIs to interact with the data model. Coming", "tokens": [50724, 1412, 2316, 281, 9651, 322, 293, 264, 661, 551, 307, 264, 21445, 281, 4648, 365, 264, 1412, 2316, 13, 12473, 51020], "temperature": 0.0, "avg_logprob": -0.17808212953455307, "compression_ratio": 1.5959183673469388, "no_speech_prob": 0.018126817420125008}, {"id": 28, "seek": 15392, "start": 167.04, "end": 172.95999999999998, "text": " to the first thing, I hope, here we go. When it comes to the data model or you might also call", "tokens": [51020, 281, 264, 700, 551, 11, 286, 1454, 11, 510, 321, 352, 13, 1133, 309, 1487, 281, 264, 1412, 2316, 420, 291, 1062, 611, 818, 51316], "temperature": 0.0, "avg_logprob": -0.17808212953455307, "compression_ratio": 1.5959183673469388, "no_speech_prob": 0.018126817420125008}, {"id": 29, "seek": 15392, "start": 172.95999999999998, "end": 179.67999999999998, "text": " a taxonomy, we decided for the CoVisa Vehicle Signal Specification. So, it's done at an organization", "tokens": [51316, 257, 3366, 23423, 11, 321, 3047, 337, 264, 3066, 53, 3837, 41230, 3520, 43414, 20484, 3774, 13, 407, 11, 309, 311, 1096, 412, 364, 4475, 51652], "temperature": 0.0, "avg_logprob": -0.17808212953455307, "compression_ratio": 1.5959183673469388, "no_speech_prob": 0.018126817420125008}, {"id": 30, "seek": 17968, "start": 179.72, "end": 185.12, "text": " called CoVisa, formerly known as GenoVee. Maybe that rings the bell for some. And it was basically", "tokens": [50366, 1219, 3066, 53, 3837, 11, 34777, 2570, 382, 3632, 78, 53, 1653, 13, 2704, 300, 11136, 264, 4549, 337, 512, 13, 400, 309, 390, 1936, 50636], "temperature": 0.0, "avg_logprob": -0.19908565611351192, "compression_ratio": 1.6920415224913494, "no_speech_prob": 0.006875765509903431}, {"id": 31, "seek": 17968, "start": 185.12, "end": 190.44, "text": " does. It creates a tree structure for all kinds of data that might be available in the vehicle. So,", "tokens": [50636, 775, 13, 467, 7829, 257, 4230, 3877, 337, 439, 3685, 295, 1412, 300, 1062, 312, 2435, 294, 264, 5864, 13, 407, 11, 50902], "temperature": 0.0, "avg_logprob": -0.19908565611351192, "compression_ratio": 1.6920415224913494, "no_speech_prob": 0.006875765509903431}, {"id": 32, "seek": 17968, "start": 190.44, "end": 195.4, "text": " for instance, you get the tire pressure. You follow the branch of vehicle, chassis, axle, road, one,", "tokens": [50902, 337, 5197, 11, 291, 483, 264, 11756, 3321, 13, 509, 1524, 264, 9819, 295, 5864, 11, 28262, 11, 31192, 11, 3060, 11, 472, 11, 51150], "temperature": 0.0, "avg_logprob": -0.19908565611351192, "compression_ratio": 1.6920415224913494, "no_speech_prob": 0.006875765509903431}, {"id": 33, "seek": 17968, "start": 195.4, "end": 201.28, "text": " wheel, tire and then you get to the pressure signal. The same way you have sensor values in", "tokens": [51150, 5589, 11, 11756, 293, 550, 291, 483, 281, 264, 3321, 6358, 13, 440, 912, 636, 291, 362, 10200, 4190, 294, 51444], "temperature": 0.0, "avg_logprob": -0.19908565611351192, "compression_ratio": 1.6920415224913494, "no_speech_prob": 0.006875765509903431}, {"id": 34, "seek": 17968, "start": 201.28, "end": 206.48000000000002, "text": " here, you can also have actuator values. So, for instance, when we have a seat position, we could", "tokens": [51444, 510, 11, 291, 393, 611, 362, 34964, 1639, 4190, 13, 407, 11, 337, 5197, 11, 562, 321, 362, 257, 6121, 2535, 11, 321, 727, 51704], "temperature": 0.0, "avg_logprob": -0.19908565611351192, "compression_ratio": 1.6920415224913494, "no_speech_prob": 0.006875765509903431}, {"id": 35, "seek": 20648, "start": 206.51999999999998, "end": 212.0, "text": " just change this value of the seat position and eventually that seat in the car would move to", "tokens": [50366, 445, 1319, 341, 2158, 295, 264, 6121, 2535, 293, 4728, 300, 6121, 294, 264, 1032, 576, 1286, 281, 50640], "temperature": 0.0, "avg_logprob": -0.23295618358411288, "compression_ratio": 1.6433566433566433, "no_speech_prob": 0.004662262741476297}, {"id": 36, "seek": 20648, "start": 212.0, "end": 216.95999999999998, "text": " that position. That's the idea of this whole data model. If you want to play a bit with that,", "tokens": [50640, 300, 2535, 13, 663, 311, 264, 1558, 295, 341, 1379, 1412, 2316, 13, 759, 291, 528, 281, 862, 257, 857, 365, 300, 11, 50888], "temperature": 0.0, "avg_logprob": -0.23295618358411288, "compression_ratio": 1.6433566433566433, "no_speech_prob": 0.004662262741476297}, {"id": 37, "seek": 20648, "start": 216.95999999999998, "end": 222.32, "text": " there's also a really cool website called Digital Auto that makes nice visualization of that and", "tokens": [50888, 456, 311, 611, 257, 534, 1627, 3144, 1219, 15522, 13738, 300, 1669, 1481, 25801, 295, 300, 293, 51156], "temperature": 0.0, "avg_logprob": -0.23295618358411288, "compression_ratio": 1.6433566433566433, "no_speech_prob": 0.004662262741476297}, {"id": 38, "seek": 20648, "start": 222.32, "end": 228.35999999999999, "text": " also shows some example applications how you interact with VSS. Okay, now we go to the first", "tokens": [51156, 611, 3110, 512, 1365, 5821, 577, 291, 4648, 365, 691, 21929, 13, 1033, 11, 586, 321, 352, 281, 264, 700, 51458], "temperature": 0.0, "avg_logprob": -0.23295618358411288, "compression_ratio": 1.6433566433566433, "no_speech_prob": 0.004662262741476297}, {"id": 39, "seek": 20648, "start": 228.35999999999999, "end": 235.51999999999998, "text": " piece. How about the second? And this is where Cooxa or more specific Cooxa Viara comes into", "tokens": [51458, 2522, 13, 1012, 466, 264, 1150, 30, 400, 341, 307, 689, 383, 1986, 36852, 420, 544, 2685, 383, 1986, 36852, 6626, 2419, 1487, 666, 51816], "temperature": 0.0, "avg_logprob": -0.23295618358411288, "compression_ratio": 1.6433566433566433, "no_speech_prob": 0.004662262741476297}, {"id": 40, "seek": 23552, "start": 235.56, "end": 240.8, "text": " play. So, while in this case, vehicle abstraction layer, so we talk about abstraction, so the idea", "tokens": [50366, 862, 13, 407, 11, 1339, 294, 341, 1389, 11, 5864, 37765, 4583, 11, 370, 321, 751, 466, 37765, 11, 370, 264, 1558, 50628], "temperature": 0.0, "avg_logprob": -0.2675349523150732, "compression_ratio": 1.7311827956989247, "no_speech_prob": 0.007672708481550217}, {"id": 41, "seek": 23552, "start": 240.8, "end": 246.36, "text": " is to have Cooxa running in the vehicle computer. So, some kind of computer which might run Unix or", "tokens": [50628, 307, 281, 362, 383, 1986, 36852, 2614, 294, 264, 5864, 3820, 13, 407, 11, 512, 733, 295, 3820, 597, 1062, 1190, 1156, 970, 420, 50906], "temperature": 0.0, "avg_logprob": -0.2675349523150732, "compression_ratio": 1.7311827956989247, "no_speech_prob": 0.007672708481550217}, {"id": 42, "seek": 23552, "start": 246.36, "end": 251.04000000000002, "text": " something similar to that. And we also assume this is a place where we decub the hard from the", "tokens": [50906, 746, 2531, 281, 300, 13, 400, 321, 611, 6552, 341, 307, 257, 1081, 689, 321, 979, 836, 264, 1152, 490, 264, 51140], "temperature": 0.0, "avg_logprob": -0.2675349523150732, "compression_ratio": 1.7311827956989247, "no_speech_prob": 0.007672708481550217}, {"id": 43, "seek": 23552, "start": 251.04000000000002, "end": 256.16, "text": " software in the vehicle. So, the underlying assumption is something you can see on the left. So,", "tokens": [51140, 4722, 294, 264, 5864, 13, 407, 11, 264, 14217, 15302, 307, 746, 291, 393, 536, 322, 264, 1411, 13, 407, 11, 51396], "temperature": 0.0, "avg_logprob": -0.2675349523150732, "compression_ratio": 1.7311827956989247, "no_speech_prob": 0.007672708481550217}, {"id": 44, "seek": 23552, "start": 256.16, "end": 260.32, "text": " we have a lot of deeply embedded layers, can, autos, are, lin, sum, IP, whatever you like or", "tokens": [51396, 321, 362, 257, 688, 295, 8760, 16741, 7914, 11, 393, 11, 1476, 329, 11, 366, 11, 22896, 11, 2408, 11, 8671, 11, 2035, 291, 411, 420, 51604], "temperature": 0.0, "avg_logprob": -0.2675349523150732, "compression_ratio": 1.7311827956989247, "no_speech_prob": 0.007672708481550217}, {"id": 45, "seek": 26032, "start": 260.36, "end": 265.88, "text": " maybe don't like, which is maybe really proprietary in some cases and also the signals and the bits", "tokens": [50366, 1310, 500, 380, 411, 11, 597, 307, 1310, 534, 38992, 294, 512, 3331, 293, 611, 264, 12354, 293, 264, 9239, 50642], "temperature": 0.0, "avg_logprob": -0.1340265789547482, "compression_ratio": 1.7292418772563176, "no_speech_prob": 0.013397696428000927}, {"id": 46, "seek": 26032, "start": 265.88, "end": 271.68, "text": " are really specific to the car. So, then people would write something that we call provider or", "tokens": [50642, 366, 534, 2685, 281, 264, 1032, 13, 407, 11, 550, 561, 576, 2464, 746, 300, 321, 818, 12398, 420, 50932], "temperature": 0.0, "avg_logprob": -0.1340265789547482, "compression_ratio": 1.7292418772563176, "no_speech_prob": 0.013397696428000927}, {"id": 47, "seek": 26032, "start": 271.68, "end": 277.6, "text": " also feeder to translate between these really specific systems and embedded systems towards", "tokens": [50932, 611, 48778, 281, 13799, 1296, 613, 534, 2685, 3652, 293, 16741, 3652, 3030, 51228], "temperature": 0.0, "avg_logprob": -0.1340265789547482, "compression_ratio": 1.7292418772563176, "no_speech_prob": 0.013397696428000927}, {"id": 48, "seek": 26032, "start": 277.6, "end": 285.4, "text": " VSS using the Cooxa API. This is where the API is coming from because we use here Cooxa. If you", "tokens": [51228, 691, 21929, 1228, 264, 383, 1986, 36852, 9362, 13, 639, 307, 689, 264, 9362, 307, 1348, 490, 570, 321, 764, 510, 383, 1986, 36852, 13, 759, 291, 51618], "temperature": 0.0, "avg_logprob": -0.1340265789547482, "compression_ratio": 1.7292418772563176, "no_speech_prob": 0.013397696428000927}, {"id": 49, "seek": 26032, "start": 285.4, "end": 289.28, "text": " like more on the abstraction side, we also can say like in the deeply embedded layers, we mostly", "tokens": [51618, 411, 544, 322, 264, 37765, 1252, 11, 321, 611, 393, 584, 411, 294, 264, 8760, 16741, 7914, 11, 321, 5240, 51812], "temperature": 0.0, "avg_logprob": -0.1340265789547482, "compression_ratio": 1.7292418772563176, "no_speech_prob": 0.013397696428000927}, {"id": 50, "seek": 28928, "start": 289.32, "end": 295.96, "text": " have data like really 1001 or the bits and we kind of need to interpret those. So, we translate", "tokens": [50366, 362, 1412, 411, 534, 2319, 16, 420, 264, 9239, 293, 321, 733, 295, 643, 281, 7302, 729, 13, 407, 11, 321, 13799, 50698], "temperature": 0.0, "avg_logprob": -0.19551672538121542, "compression_ratio": 1.6, "no_speech_prob": 0.006227821111679077}, {"id": 51, "seek": 28928, "start": 295.96, "end": 301.08, "text": " it to VSS, get some information out of that and then by combining this information in different", "tokens": [50698, 309, 281, 691, 21929, 11, 483, 512, 1589, 484, 295, 300, 293, 550, 538, 21928, 341, 1589, 294, 819, 50954], "temperature": 0.0, "avg_logprob": -0.19551672538121542, "compression_ratio": 1.6, "no_speech_prob": 0.006227821111679077}, {"id": 52, "seek": 28928, "start": 301.08, "end": 309.59999999999997, "text": " applications, we actually create knowledge. And here Cooxa is a nice building piece for that. So,", "tokens": [50954, 5821, 11, 321, 767, 1884, 3601, 13, 400, 510, 383, 1986, 36852, 307, 257, 1481, 2390, 2522, 337, 300, 13, 407, 11, 51380], "temperature": 0.0, "avg_logprob": -0.19551672538121542, "compression_ratio": 1.6, "no_speech_prob": 0.006227821111679077}, {"id": 53, "seek": 28928, "start": 309.59999999999997, "end": 314.2, "text": " what is Cooxa in general? So, since we are in the open source conference, obviously it is open", "tokens": [51380, 437, 307, 383, 1986, 36852, 294, 2674, 30, 407, 11, 1670, 321, 366, 294, 264, 1269, 4009, 7586, 11, 2745, 309, 307, 1269, 51610], "temperature": 0.0, "avg_logprob": -0.19551672538121542, "compression_ratio": 1.6, "no_speech_prob": 0.006227821111679077}, {"id": 54, "seek": 31420, "start": 314.24, "end": 319.36, "text": " source, fully licensed on the APHG 2.0 license and as I just mentioned in the previous slide,", "tokens": [50366, 4009, 11, 4498, 25225, 322, 264, 5372, 39, 38, 568, 13, 15, 10476, 293, 382, 286, 445, 2835, 294, 264, 3894, 4137, 11, 50622], "temperature": 0.0, "avg_logprob": -0.20261102294921876, "compression_ratio": 1.7311827956989247, "no_speech_prob": 0.036277756094932556}, {"id": 55, "seek": 31420, "start": 319.36, "end": 325.24, "text": " it is some kind of digital twin based on VSS. So, it shows the current and the target value of your", "tokens": [50622, 309, 307, 512, 733, 295, 4562, 18397, 2361, 322, 691, 21929, 13, 407, 11, 309, 3110, 264, 2190, 293, 264, 3779, 2158, 295, 428, 50916], "temperature": 0.0, "avg_logprob": -0.20261102294921876, "compression_ratio": 1.7311827956989247, "no_speech_prob": 0.036277756094932556}, {"id": 56, "seek": 31420, "start": 325.24, "end": 330.71999999999997, "text": " vehicle. I don't want to go into the definition of digital twins but I guess you kind of get what", "tokens": [50916, 5864, 13, 286, 500, 380, 528, 281, 352, 666, 264, 7123, 295, 4562, 22555, 457, 286, 2041, 291, 733, 295, 483, 437, 51190], "temperature": 0.0, "avg_logprob": -0.20261102294921876, "compression_ratio": 1.7311827956989247, "no_speech_prob": 0.036277756094932556}, {"id": 57, "seek": 31420, "start": 330.71999999999997, "end": 336.48, "text": " I am getting at here. And so, you only have the current value which is quite nice but you also", "tokens": [51190, 286, 669, 1242, 412, 510, 13, 400, 370, 11, 291, 787, 362, 264, 2190, 2158, 597, 307, 1596, 1481, 457, 291, 611, 51478], "temperature": 0.0, "avg_logprob": -0.20261102294921876, "compression_ratio": 1.7311827956989247, "no_speech_prob": 0.036277756094932556}, {"id": 58, "seek": 31420, "start": 336.48, "end": 341.4, "text": " have the target value. So, coming back to our seed example, when you would change the value, the", "tokens": [51478, 362, 264, 3779, 2158, 13, 407, 11, 1348, 646, 281, 527, 8871, 1365, 11, 562, 291, 576, 1319, 264, 2158, 11, 264, 51724], "temperature": 0.0, "avg_logprob": -0.20261102294921876, "compression_ratio": 1.7311827956989247, "no_speech_prob": 0.036277756094932556}, {"id": 59, "seek": 34140, "start": 341.4, "end": 345.28, "text": " current value as an application from a seed, this doesn't meet the seed is actually where I", "tokens": [50364, 2190, 2158, 382, 364, 3861, 490, 257, 8871, 11, 341, 1177, 380, 1677, 264, 8871, 307, 767, 689, 286, 50558], "temperature": 0.0, "avg_logprob": -0.24309615084999486, "compression_ratio": 1.8228346456692914, "no_speech_prob": 0.005698920227587223}, {"id": 60, "seek": 34140, "start": 345.28, "end": 349.56, "text": " wanted to have. So, I actually will set the target value and then it is up to the deeply", "tokens": [50558, 1415, 281, 362, 13, 407, 11, 286, 767, 486, 992, 264, 3779, 2158, 293, 550, 309, 307, 493, 281, 264, 8760, 50772], "temperature": 0.0, "avg_logprob": -0.24309615084999486, "compression_ratio": 1.8228346456692914, "no_speech_prob": 0.005698920227587223}, {"id": 61, "seek": 34140, "start": 349.56, "end": 354.28, "text": " embedded layers, so the actual vehicle to move the position of the seed over time. So, that is", "tokens": [50772, 16741, 7914, 11, 370, 264, 3539, 5864, 281, 1286, 264, 2535, 295, 264, 8871, 670, 565, 13, 407, 11, 300, 307, 51008], "temperature": 0.0, "avg_logprob": -0.24309615084999486, "compression_ratio": 1.8228346456692914, "no_speech_prob": 0.005698920227587223}, {"id": 62, "seek": 34140, "start": 354.28, "end": 359.03999999999996, "text": " why you can change both value and hopefully at some point the current value will be the target", "tokens": [51008, 983, 291, 393, 1319, 1293, 2158, 293, 4696, 412, 512, 935, 264, 2190, 2158, 486, 312, 264, 3779, 51246], "temperature": 0.0, "avg_logprob": -0.24309615084999486, "compression_ratio": 1.8228346456692914, "no_speech_prob": 0.005698920227587223}, {"id": 63, "seek": 34140, "start": 359.03999999999996, "end": 366.47999999999996, "text": " value because that is the whole idea. So, much about the concepts. Let's get to the code. Or", "tokens": [51246, 2158, 570, 300, 307, 264, 1379, 1558, 13, 407, 11, 709, 466, 264, 10392, 13, 961, 311, 483, 281, 264, 3089, 13, 1610, 51618], "temperature": 0.0, "avg_logprob": -0.24309615084999486, "compression_ratio": 1.8228346456692914, "no_speech_prob": 0.005698920227587223}, {"id": 64, "seek": 36648, "start": 366.52000000000004, "end": 372.16, "text": " maybe I won't show code here but what it is actually written in. So, we wrote this in Rust. If", "tokens": [50366, 1310, 286, 1582, 380, 855, 3089, 510, 457, 437, 309, 307, 767, 3720, 294, 13, 407, 11, 321, 4114, 341, 294, 34952, 13, 759, 50648], "temperature": 0.0, "avg_logprob": -0.27541846902961403, "compression_ratio": 1.6560283687943262, "no_speech_prob": 0.034396179020404816}, {"id": 65, "seek": 36648, "start": 372.16, "end": 376.92, "text": " you steadily compile it, it is less than 4 megabytes, large or small depending on which word", "tokens": [50648, 291, 36129, 31413, 309, 11, 309, 307, 1570, 813, 1017, 10816, 24538, 11, 2416, 420, 1359, 5413, 322, 597, 1349, 50886], "temperature": 0.0, "avg_logprob": -0.27541846902961403, "compression_ratio": 1.6560283687943262, "no_speech_prob": 0.034396179020404816}, {"id": 66, "seek": 36648, "start": 376.92, "end": 380.44, "text": " you are coming from I guess. Like, these are the cloud words and it is small from the automotive", "tokens": [50886, 291, 366, 1348, 490, 286, 2041, 13, 1743, 11, 613, 366, 264, 4588, 2283, 293, 309, 307, 1359, 490, 264, 32866, 51062], "temperature": 0.0, "avg_logprob": -0.27541846902961403, "compression_ratio": 1.6560283687943262, "no_speech_prob": 0.034396179020404816}, {"id": 67, "seek": 36648, "start": 380.44, "end": 386.12, "text": " words, maybe large to you. And it is quite language agnostic because the interaction with", "tokens": [51062, 2283, 11, 1310, 2416, 281, 291, 13, 400, 309, 307, 1596, 2856, 623, 77, 19634, 570, 264, 9285, 365, 51346], "temperature": 0.0, "avg_logprob": -0.27541846902961403, "compression_ratio": 1.6560283687943262, "no_speech_prob": 0.034396179020404816}, {"id": 68, "seek": 36648, "start": 386.12, "end": 390.84000000000003, "text": " this is with it because we have a GIPC interface with some basic functions like get, set and", "tokens": [51346, 341, 307, 365, 309, 570, 321, 362, 257, 460, 9139, 34, 9226, 365, 512, 3875, 6828, 411, 483, 11, 992, 293, 51582], "temperature": 0.0, "avg_logprob": -0.27541846902961403, "compression_ratio": 1.6560283687943262, "no_speech_prob": 0.034396179020404816}, {"id": 69, "seek": 39084, "start": 390.88, "end": 399.88, "text": " subscribe and also a number of client libraries using this. And with that, that is actually the", "tokens": [50366, 3022, 293, 611, 257, 1230, 295, 6423, 15148, 1228, 341, 13, 400, 365, 300, 11, 300, 307, 767, 264, 50816], "temperature": 0.0, "avg_logprob": -0.25769523682633066, "compression_ratio": 1.6643109540636043, "no_speech_prob": 0.019526463001966476}, {"id": 70, "seek": 39084, "start": 399.88, "end": 404.15999999999997, "text": " basic of Cooxing and I have to be honest with you, if you have been in this death room last", "tokens": [50816, 3875, 295, 383, 1986, 87, 278, 293, 286, 362, 281, 312, 3245, 365, 291, 11, 498, 291, 362, 668, 294, 341, 2966, 1808, 1036, 51030], "temperature": 0.0, "avg_logprob": -0.25769523682633066, "compression_ratio": 1.6643109540636043, "no_speech_prob": 0.019526463001966476}, {"id": 71, "seek": 39084, "start": 404.15999999999997, "end": 409.12, "text": " year, you would say where is the news because this has been shown there as well. So, let's get to", "tokens": [51030, 1064, 11, 291, 576, 584, 689, 307, 264, 2583, 570, 341, 575, 668, 4898, 456, 382, 731, 13, 407, 11, 718, 311, 483, 281, 51278], "temperature": 0.0, "avg_logprob": -0.25769523682633066, "compression_ratio": 1.6643109540636043, "no_speech_prob": 0.019526463001966476}, {"id": 72, "seek": 39084, "start": 409.12, "end": 414.71999999999997, "text": " the news. So, what has happened in the previous year? First and foremost, it was using AGL so", "tokens": [51278, 264, 2583, 13, 407, 11, 437, 575, 2011, 294, 264, 3894, 1064, 30, 2386, 293, 18864, 11, 309, 390, 1228, 316, 19440, 370, 51558], "temperature": 0.0, "avg_logprob": -0.25769523682633066, "compression_ratio": 1.6643109540636043, "no_speech_prob": 0.019526463001966476}, {"id": 73, "seek": 39084, "start": 414.71999999999997, "end": 420.44, "text": " Scott will talk a lot about that in the next minutes. But we also have some other news. For", "tokens": [51558, 6659, 486, 751, 257, 688, 466, 300, 294, 264, 958, 2077, 13, 583, 321, 611, 362, 512, 661, 2583, 13, 1171, 51844], "temperature": 0.0, "avg_logprob": -0.25769523682633066, "compression_ratio": 1.6643109540636043, "no_speech_prob": 0.019526463001966476}, {"id": 74, "seek": 42044, "start": 420.48, "end": 425.4, "text": " instance, we now have a Cooxer Android SDK, we have a mock service and we also did some work", "tokens": [50366, 5197, 11, 321, 586, 362, 257, 383, 1986, 87, 260, 8853, 37135, 11, 321, 362, 257, 17362, 2643, 293, 321, 611, 630, 512, 589, 50612], "temperature": 0.0, "avg_logprob": -0.26704743790299923, "compression_ratio": 1.7753164556962024, "no_speech_prob": 0.013666312210261822}, {"id": 75, "seek": 42044, "start": 425.4, "end": 430.56, "text": " with later from our side. So, the Cooxer Android SDK, I mean it is kind of straightforward", "tokens": [50612, 365, 1780, 490, 527, 1252, 13, 407, 11, 264, 383, 1986, 87, 260, 8853, 37135, 11, 286, 914, 309, 307, 733, 295, 15325, 50870], "temperature": 0.0, "avg_logprob": -0.26704743790299923, "compression_ratio": 1.7753164556962024, "no_speech_prob": 0.013666312210261822}, {"id": 76, "seek": 42044, "start": 430.56, "end": 434.36, "text": " because in the end of the SDK, that is now available in Maven Central and you can interact", "tokens": [50870, 570, 294, 264, 917, 295, 264, 37135, 11, 300, 307, 586, 2435, 294, 4042, 553, 9701, 293, 291, 393, 4648, 51060], "temperature": 0.0, "avg_logprob": -0.26704743790299923, "compression_ratio": 1.7753164556962024, "no_speech_prob": 0.013666312210261822}, {"id": 77, "seek": 42044, "start": 434.36, "end": 440.56, "text": " with the data broker from an Android application. So, be it Android automotive or maybe your own", "tokens": [51060, 365, 264, 1412, 26502, 490, 364, 8853, 3861, 13, 407, 11, 312, 309, 8853, 32866, 420, 1310, 428, 1065, 51370], "temperature": 0.0, "avg_logprob": -0.26704743790299923, "compression_ratio": 1.7753164556962024, "no_speech_prob": 0.013666312210261822}, {"id": 78, "seek": 42044, "start": 440.56, "end": 444.72, "text": " app on your smartphone. So, assuming you have some kind of Cooxer abstraction in your vehicle,", "tokens": [51370, 724, 322, 428, 13307, 13, 407, 11, 11926, 291, 362, 512, 733, 295, 383, 1986, 87, 260, 37765, 294, 428, 5864, 11, 51578], "temperature": 0.0, "avg_logprob": -0.26704743790299923, "compression_ratio": 1.7753164556962024, "no_speech_prob": 0.013666312210261822}, {"id": 79, "seek": 42044, "start": 444.72, "end": 450.04, "text": " you can use a companion app for instance, which we are about to release to the F2O store. Now,", "tokens": [51578, 291, 393, 764, 257, 22363, 724, 337, 5197, 11, 597, 321, 366, 466, 281, 4374, 281, 264, 479, 17, 46, 3531, 13, 823, 11, 51844], "temperature": 0.0, "avg_logprob": -0.26704743790299923, "compression_ratio": 1.7753164556962024, "no_speech_prob": 0.013666312210261822}, {"id": 80, "seek": 45004, "start": 450.12, "end": 455.84000000000003, "text": " there will be a moment for the releases there. We did support request beginning of the week, but", "tokens": [50368, 456, 486, 312, 257, 1623, 337, 264, 16952, 456, 13, 492, 630, 1406, 5308, 2863, 295, 264, 1243, 11, 457, 50654], "temperature": 0.0, "avg_logprob": -0.2622407482516381, "compression_ratio": 1.5783132530120483, "no_speech_prob": 0.0034092646092176437}, {"id": 81, "seek": 45004, "start": 455.84000000000003, "end": 460.84000000000003, "text": " we still wait for F2O to actually show this app in their repository. So, stay with me till Monday,", "tokens": [50654, 321, 920, 1699, 337, 479, 17, 46, 281, 767, 855, 341, 724, 294, 641, 25841, 13, 407, 11, 1754, 365, 385, 4288, 8138, 11, 50904], "temperature": 0.0, "avg_logprob": -0.2622407482516381, "compression_ratio": 1.5783132530120483, "no_speech_prob": 0.0034092646092176437}, {"id": 82, "seek": 45004, "start": 460.84000000000003, "end": 468.76, "text": " then it might be there hopefully. Another thing is a mock service because the guys in the previous", "tokens": [50904, 550, 309, 1062, 312, 456, 4696, 13, 3996, 551, 307, 257, 17362, 2643, 570, 264, 1074, 294, 264, 3894, 51300], "temperature": 0.0, "avg_logprob": -0.2622407482516381, "compression_ratio": 1.5783132530120483, "no_speech_prob": 0.0034092646092176437}, {"id": 83, "seek": 45004, "start": 468.76, "end": 474.12, "text": " presentation had their robot here. We cannot always have a car on our lab to test the application,", "tokens": [51300, 5860, 632, 641, 7881, 510, 13, 492, 2644, 1009, 362, 257, 1032, 322, 527, 2715, 281, 1500, 264, 3861, 11, 51568], "temperature": 0.0, "avg_logprob": -0.2622407482516381, "compression_ratio": 1.5783132530120483, "no_speech_prob": 0.0034092646092176437}, {"id": 84, "seek": 47412, "start": 474.2, "end": 479.32, "text": " but we kind of depend on the behavior of the vehicle. So, we need a way to mox this. So,", "tokens": [50368, 457, 321, 733, 295, 5672, 322, 264, 5223, 295, 264, 5864, 13, 407, 11, 321, 643, 257, 636, 281, 705, 87, 341, 13, 407, 11, 50624], "temperature": 0.0, "avg_logprob": -0.21845245361328125, "compression_ratio": 1.6297872340425532, "no_speech_prob": 0.01925719901919365}, {"id": 85, "seek": 47412, "start": 479.32, "end": 486.84000000000003, "text": " the community came up with a behavior definition. For instance, whenever the signal of a seed is", "tokens": [50624, 264, 1768, 1361, 493, 365, 257, 5223, 7123, 13, 1171, 5197, 11, 5699, 264, 6358, 295, 257, 8871, 307, 51000], "temperature": 0.0, "avg_logprob": -0.21845245361328125, "compression_ratio": 1.6297872340425532, "no_speech_prob": 0.01925719901919365}, {"id": 86, "seek": 47412, "start": 486.84000000000003, "end": 493.56, "text": " changed to a certain value, like 1000, then the current value should also change to that value.", "tokens": [51000, 3105, 281, 257, 1629, 2158, 11, 411, 9714, 11, 550, 264, 2190, 2158, 820, 611, 1319, 281, 300, 2158, 13, 51336], "temperature": 0.0, "avg_logprob": -0.21845245361328125, "compression_ratio": 1.6297872340425532, "no_speech_prob": 0.01925719901919365}, {"id": 87, "seek": 47412, "start": 494.28000000000003, "end": 498.76, "text": " And this is what you can basically mock or emulate with the mock service to show you just an example.", "tokens": [51372, 400, 341, 307, 437, 291, 393, 1936, 17362, 420, 45497, 365, 264, 17362, 2643, 281, 855, 291, 445, 364, 1365, 13, 51596], "temperature": 0.0, "avg_logprob": -0.21845245361328125, "compression_ratio": 1.6297872340425532, "no_speech_prob": 0.01925719901919365}, {"id": 88, "seek": 49876, "start": 499.71999999999997, "end": 504.2, "text": " Here we have just an example I mentioned. So, whenever the driver's side position changes,", "tokens": [50412, 1692, 321, 362, 445, 364, 1365, 286, 2835, 13, 407, 11, 5699, 264, 6787, 311, 1252, 2535, 2962, 11, 50636], "temperature": 0.0, "avg_logprob": -0.15519226349151885, "compression_ratio": 1.6487455197132617, "no_speech_prob": 0.004585566930472851}, {"id": 89, "seek": 49876, "start": 504.2, "end": 509.56, "text": " then we create an animation to move to that position or to move the current value to that", "tokens": [50636, 550, 321, 1884, 364, 9603, 281, 1286, 281, 300, 2535, 420, 281, 1286, 264, 2190, 2158, 281, 300, 50904], "temperature": 0.0, "avg_logprob": -0.15519226349151885, "compression_ratio": 1.6487455197132617, "no_speech_prob": 0.004585566930472851}, {"id": 90, "seek": 49876, "start": 509.56, "end": 515.08, "text": " position, which makes it quite easy and flexible to test whatever you desire with your car.", "tokens": [50904, 2535, 11, 597, 1669, 309, 1596, 1858, 293, 11358, 281, 1500, 2035, 291, 7516, 365, 428, 1032, 13, 51180], "temperature": 0.0, "avg_logprob": -0.15519226349151885, "compression_ratio": 1.6487455197132617, "no_speech_prob": 0.004585566930472851}, {"id": 91, "seek": 49876, "start": 517.08, "end": 522.4399999999999, "text": " And last but not least, this is just a sneak preview into the lab. So, Cooxer is part of the", "tokens": [51280, 400, 1036, 457, 406, 1935, 11, 341, 307, 445, 257, 13164, 14281, 666, 264, 2715, 13, 407, 11, 383, 1986, 87, 260, 307, 644, 295, 264, 51548], "temperature": 0.0, "avg_logprob": -0.15519226349151885, "compression_ratio": 1.6487455197132617, "no_speech_prob": 0.004585566930472851}, {"id": 92, "seek": 49876, "start": 522.4399999999999, "end": 526.92, "text": " larger community in the Eclipse Foundation. There's an Eclipse software defined working group,", "tokens": [51548, 4833, 1768, 294, 264, 462, 27197, 10335, 13, 821, 311, 364, 462, 27197, 4722, 7642, 1364, 1594, 11, 51772], "temperature": 0.0, "avg_logprob": -0.15519226349151885, "compression_ratio": 1.6487455197132617, "no_speech_prob": 0.004585566930472851}, {"id": 93, "seek": 52692, "start": 526.92, "end": 532.28, "text": " or short Eclipse STV. And there's another distribution called Eclipse Leder, which tries to", "tokens": [50364, 420, 2099, 462, 27197, 4904, 53, 13, 400, 456, 311, 1071, 7316, 1219, 462, 27197, 441, 10020, 11, 597, 9898, 281, 50632], "temperature": 0.0, "avg_logprob": -0.18351018996465773, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.02174735628068447}, {"id": 94, "seek": 52692, "start": 532.28, "end": 538.28, "text": " combine some of the major pieces of the ecosystem there. And this is called Leder. And what we", "tokens": [50632, 10432, 512, 295, 264, 2563, 3755, 295, 264, 11311, 456, 13, 400, 341, 307, 1219, 441, 10020, 13, 400, 437, 321, 50932], "temperature": 0.0, "avg_logprob": -0.18351018996465773, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.02174735628068447}, {"id": 95, "seek": 52692, "start": 538.28, "end": 543.4, "text": " managed to do is actually run the Leder-Yogtu layer on top of an HGL, so that you actually get these", "tokens": [50932, 6453, 281, 360, 307, 767, 1190, 264, 441, 10020, 12, 56, 664, 9179, 4583, 322, 1192, 295, 364, 389, 19440, 11, 370, 300, 291, 767, 483, 613, 51188], "temperature": 0.0, "avg_logprob": -0.18351018996465773, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.02174735628068447}, {"id": 96, "seek": 52692, "start": 543.4, "end": 550.8399999999999, "text": " pieces, like especially Cooxer, but also some other projects like Cantal, to run on the HGL stack.", "tokens": [51188, 3755, 11, 411, 2318, 383, 1986, 87, 260, 11, 457, 611, 512, 661, 4455, 411, 26697, 304, 11, 281, 1190, 322, 264, 389, 19440, 8630, 13, 51560], "temperature": 0.0, "avg_logprob": -0.18351018996465773, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.02174735628068447}, {"id": 97, "seek": 52692, "start": 551.56, "end": 555.4, "text": " And I think this is a really good opportunity to learn a bit more about HGL here.", "tokens": [51596, 400, 286, 519, 341, 307, 257, 534, 665, 2650, 281, 1466, 257, 857, 544, 466, 389, 19440, 510, 13, 51788], "temperature": 0.0, "avg_logprob": -0.18351018996465773, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.02174735628068447}, {"id": 98, "seek": 55540, "start": 555.4, "end": 565.24, "text": " Oh, okay. I'll take over then. All right. Thank you, Sven Eric. So, I have done a lot of stuff", "tokens": [50364, 876, 11, 1392, 13, 286, 603, 747, 670, 550, 13, 1057, 558, 13, 1044, 291, 11, 49787, 9336, 13, 407, 11, 286, 362, 1096, 257, 688, 295, 1507, 50856], "temperature": 0.0, "avg_logprob": -0.14836931682768323, "compression_ratio": 1.5748987854251013, "no_speech_prob": 0.004824698902666569}, {"id": 99, "seek": 55540, "start": 565.24, "end": 571.9599999999999, "text": " around HGL, so people might recognize me. I'm Scott Murray. I've done Linux for a long time,", "tokens": [50856, 926, 389, 19440, 11, 370, 561, 1062, 5521, 385, 13, 286, 478, 6659, 27291, 13, 286, 600, 1096, 18734, 337, 257, 938, 565, 11, 51192], "temperature": 0.0, "avg_logprob": -0.14836931682768323, "compression_ratio": 1.5748987854251013, "no_speech_prob": 0.004824698902666569}, {"id": 100, "seek": 55540, "start": 571.9599999999999, "end": 577.4, "text": " and I've been at Linux for a reasonably long time as well. I've been working on HGL on contract for", "tokens": [51192, 293, 286, 600, 668, 412, 18734, 337, 257, 23551, 938, 565, 382, 731, 13, 286, 600, 668, 1364, 322, 389, 19440, 322, 4364, 337, 51464], "temperature": 0.0, "avg_logprob": -0.14836931682768323, "compression_ratio": 1.5748987854251013, "no_speech_prob": 0.004824698902666569}, {"id": 101, "seek": 55540, "start": 578.1999999999999, "end": 583.0, "text": " pretty much eight years at this point, and doing all kinds of different things for the project around", "tokens": [51504, 1238, 709, 3180, 924, 412, 341, 935, 11, 293, 884, 439, 3685, 295, 819, 721, 337, 264, 1716, 926, 51744], "temperature": 0.0, "avg_logprob": -0.14836931682768323, "compression_ratio": 1.5748987854251013, "no_speech_prob": 0.004824698902666569}, {"id": 102, "seek": 58300, "start": 583.88, "end": 590.12, "text": " keeping the Yogtu stuff up to date, and also doing a lot of the demo and integration type of things.", "tokens": [50408, 5145, 264, 398, 664, 9179, 1507, 493, 281, 4002, 11, 293, 611, 884, 257, 688, 295, 264, 10723, 293, 10980, 2010, 295, 721, 13, 50720], "temperature": 0.0, "avg_logprob": -0.14576838811238607, "compression_ratio": 1.5497835497835497, "no_speech_prob": 0.0037615078035742044}, {"id": 103, "seek": 58300, "start": 591.72, "end": 597.08, "text": " So, there was maybe almost half of the people indicating that it would be what HGL was, but", "tokens": [50800, 407, 11, 456, 390, 1310, 1920, 1922, 295, 264, 561, 25604, 300, 309, 576, 312, 437, 389, 19440, 390, 11, 457, 51068], "temperature": 0.0, "avg_logprob": -0.14576838811238607, "compression_ratio": 1.5497835497835497, "no_speech_prob": 0.0037615078035742044}, {"id": 104, "seek": 58300, "start": 597.08, "end": 601.64, "text": " I'll do a very quick run-through. So it's a collaborative open source project,", "tokens": [51068, 286, 603, 360, 257, 588, 1702, 1190, 12, 11529, 13, 407, 309, 311, 257, 16555, 1269, 4009, 1716, 11, 51296], "temperature": 0.0, "avg_logprob": -0.14576838811238607, "compression_ratio": 1.5497835497835497, "no_speech_prob": 0.0037615078035742044}, {"id": 105, "seek": 58300, "start": 602.68, "end": 608.52, "text": " basically trying to build a base platform that you can build an automotive product on.", "tokens": [51348, 1936, 1382, 281, 1322, 257, 3096, 3663, 300, 291, 393, 1322, 364, 32866, 1674, 322, 13, 51640], "temperature": 0.0, "avg_logprob": -0.14576838811238607, "compression_ratio": 1.5497835497835497, "no_speech_prob": 0.0037615078035742044}, {"id": 106, "seek": 60852, "start": 609.4, "end": 615.24, "text": " So it's about 10 years old. We have a vast array of members now, a lot of the major OEMs,", "tokens": [50408, 407, 309, 311, 466, 1266, 924, 1331, 13, 492, 362, 257, 8369, 10225, 295, 2679, 586, 11, 257, 688, 295, 264, 2563, 422, 6683, 82, 11, 50700], "temperature": 0.0, "avg_logprob": -0.16401483498367608, "compression_ratio": 1.526530612244898, "no_speech_prob": 0.010809969156980515}, {"id": 107, "seek": 60852, "start": 615.24, "end": 621.72, "text": " and tier one and two new suppliers. It's pretty much a code first sort of thing, where we are", "tokens": [50700, 293, 12362, 472, 293, 732, 777, 29467, 13, 467, 311, 1238, 709, 257, 3089, 700, 1333, 295, 551, 11, 689, 321, 366, 51024], "temperature": 0.0, "avg_logprob": -0.16401483498367608, "compression_ratio": 1.526530612244898, "no_speech_prob": 0.010809969156980515}, {"id": 108, "seek": 60852, "start": 621.72, "end": 626.12, "text": " more focused on let's build the distro and get it there for people to try and involve. A lot of", "tokens": [51024, 544, 5178, 322, 718, 311, 1322, 264, 1483, 340, 293, 483, 309, 456, 337, 561, 281, 853, 293, 9494, 13, 316, 688, 295, 51244], "temperature": 0.0, "avg_logprob": -0.16401483498367608, "compression_ratio": 1.526530612244898, "no_speech_prob": 0.010809969156980515}, {"id": 109, "seek": 60852, "start": 626.12, "end": 630.76, "text": " work went into that. You might have seen HGL demos for several years doing that type of stuff,", "tokens": [51244, 589, 1437, 666, 300, 13, 509, 1062, 362, 1612, 389, 19440, 33788, 337, 2940, 924, 884, 300, 2010, 295, 1507, 11, 51476], "temperature": 0.0, "avg_logprob": -0.16401483498367608, "compression_ratio": 1.526530612244898, "no_speech_prob": 0.010809969156980515}, {"id": 110, "seek": 63076, "start": 631.24, "end": 638.04, "text": " but our members were basically saying in 2020 that they weren't interested in maintaining that", "tokens": [50388, 457, 527, 2679, 645, 1936, 1566, 294, 4808, 300, 436, 4999, 380, 3102, 294, 14916, 300, 50728], "temperature": 0.0, "avg_logprob": -0.23247142170750817, "compression_ratio": 1.6343612334801763, "no_speech_prob": 0.07914506644010544}, {"id": 111, "seek": 63076, "start": 638.04, "end": 642.76, "text": " because they weren't going to use it in product. They all have their own application frameworks,", "tokens": [50728, 570, 436, 4999, 380, 516, 281, 764, 309, 294, 1674, 13, 814, 439, 362, 641, 1065, 3861, 29834, 11, 50964], "temperature": 0.0, "avg_logprob": -0.23247142170750817, "compression_ratio": 1.6343612334801763, "no_speech_prob": 0.07914506644010544}, {"id": 112, "seek": 63076, "start": 642.76, "end": 648.4399999999999, "text": " or they buy an application framework, and they like to see HGL focus on lower level,", "tokens": [50964, 420, 436, 2256, 364, 3861, 8388, 11, 293, 436, 411, 281, 536, 389, 19440, 1879, 322, 3126, 1496, 11, 51248], "temperature": 0.0, "avg_logprob": -0.23247142170750817, "compression_ratio": 1.6343612334801763, "no_speech_prob": 0.07914506644010544}, {"id": 113, "seek": 63076, "start": 648.4399999999999, "end": 655.88, "text": " show us how to use open source more than writing new stuff. So we started out, our tech demos,", "tokens": [51248, 855, 505, 577, 281, 764, 1269, 4009, 544, 813, 3579, 777, 1507, 13, 407, 321, 1409, 484, 11, 527, 7553, 33788, 11, 51620], "temperature": 0.0, "avg_logprob": -0.23247142170750817, "compression_ratio": 1.6343612334801763, "no_speech_prob": 0.07914506644010544}, {"id": 114, "seek": 65588, "start": 655.88, "end": 661.56, "text": " or integration demos are more like taking best of breed open source projects and showing people", "tokens": [50364, 420, 10980, 33788, 366, 544, 411, 1940, 1151, 295, 18971, 1269, 4009, 4455, 293, 4099, 561, 50648], "temperature": 0.0, "avg_logprob": -0.31406331062316895, "compression_ratio": 1.6050420168067228, "no_speech_prob": 0.009553183801472187}, {"id": 115, "seek": 65588, "start": 661.56, "end": 666.84, "text": " an automotive. Here's how you use these things. And so this really worked out well, because we", "tokens": [50648, 364, 32866, 13, 1692, 311, 577, 291, 764, 613, 721, 13, 400, 370, 341, 534, 2732, 484, 731, 11, 570, 321, 50912], "temperature": 0.0, "avg_logprob": -0.31406331062316895, "compression_ratio": 1.6050420168067228, "no_speech_prob": 0.009553183801472187}, {"id": 116, "seek": 65588, "start": 666.84, "end": 672.28, "text": " weren't connecting. We needed something to show here's how you will do vehicle signaling, and", "tokens": [50912, 4999, 380, 11015, 13, 492, 2978, 746, 281, 855, 510, 311, 577, 291, 486, 360, 5864, 38639, 11, 293, 51184], "temperature": 0.0, "avg_logprob": -0.31406331062316895, "compression_ratio": 1.6050420168067228, "no_speech_prob": 0.009553183801472187}, {"id": 117, "seek": 65588, "start": 672.28, "end": 677.72, "text": " VSS and Cooks of Al basically were starting to come out around the same time that we needed a new", "tokens": [51184, 691, 21929, 293, 12259, 82, 295, 967, 1936, 645, 2891, 281, 808, 484, 926, 264, 912, 565, 300, 321, 2978, 257, 777, 51456], "temperature": 0.0, "avg_logprob": -0.31406331062316895, "compression_ratio": 1.6050420168067228, "no_speech_prob": 0.009553183801472187}, {"id": 118, "seek": 67772, "start": 678.52, "end": 689.72, "text": " thing. So I had started playing with Cooks of Al in 2021. Our first release basically was our", "tokens": [50404, 551, 13, 407, 286, 632, 1409, 2433, 365, 12259, 82, 295, 967, 294, 7201, 13, 2621, 700, 4374, 1936, 390, 527, 50964], "temperature": 0.0, "avg_logprob": -0.19092085741568302, "compression_ratio": 1.6132596685082874, "no_speech_prob": 0.0694286972284317}, {"id": 119, "seek": 67772, "start": 689.72, "end": 697.96, "text": " spring release in 2022. And it replaced our old signal composer and our can service with basically", "tokens": [50964, 5587, 4374, 294, 20229, 13, 400, 309, 10772, 527, 1331, 6358, 26003, 293, 527, 393, 2643, 365, 1936, 51376], "temperature": 0.0, "avg_logprob": -0.19092085741568302, "compression_ratio": 1.6132596685082874, "no_speech_prob": 0.0694286972284317}, {"id": 120, "seek": 67772, "start": 697.96, "end": 706.76, "text": " the original Cooks of Al server. And so since then, basically since spring 2022, we have recipes in", "tokens": [51376, 264, 3380, 12259, 82, 295, 967, 7154, 13, 400, 370, 1670, 550, 11, 1936, 1670, 5587, 20229, 11, 321, 362, 13035, 294, 51816], "temperature": 0.0, "avg_logprob": -0.19092085741568302, "compression_ratio": 1.6132596685082874, "no_speech_prob": 0.0694286972284317}, {"id": 121, "seek": 70676, "start": 706.76, "end": 714.36, "text": " our layers for HGL to build the Cooks of Al server, now the data broker. And as well, we actually", "tokens": [50364, 527, 7914, 337, 389, 19440, 281, 1322, 264, 12259, 82, 295, 967, 7154, 11, 586, 264, 1412, 26502, 13, 400, 382, 731, 11, 321, 767, 50744], "temperature": 0.0, "avg_logprob": -0.09218151053202521, "compression_ratio": 1.625, "no_speech_prob": 0.0027966953348368406}, {"id": 122, "seek": 70676, "start": 714.36, "end": 719.56, "text": " have some signal customization stuff to sort of access an example of here's how you add some custom", "tokens": [50744, 362, 512, 6358, 39387, 1507, 281, 1333, 295, 2105, 364, 1365, 295, 510, 311, 577, 291, 909, 512, 2375, 51004], "temperature": 0.0, "avg_logprob": -0.09218151053202521, "compression_ratio": 1.625, "no_speech_prob": 0.0027966953348368406}, {"id": 123, "seek": 70676, "start": 719.56, "end": 724.92, "text": " signals. And we use their can feeder to basically sort of wire up and show here's how you put all", "tokens": [51004, 12354, 13, 400, 321, 764, 641, 393, 48778, 281, 1936, 1333, 295, 6234, 493, 293, 855, 510, 311, 577, 291, 829, 439, 51272], "temperature": 0.0, "avg_logprob": -0.09218151053202521, "compression_ratio": 1.625, "no_speech_prob": 0.0027966953348368406}, {"id": 124, "seek": 70676, "start": 724.92, "end": 732.28, "text": " these pieces together. We have our own sort of like mocked up HGL virtual car can definitions.", "tokens": [51272, 613, 3755, 1214, 13, 492, 362, 527, 1065, 1333, 295, 411, 17362, 292, 493, 389, 19440, 6374, 1032, 393, 21988, 13, 51640], "temperature": 0.0, "avg_logprob": -0.09218151053202521, "compression_ratio": 1.625, "no_speech_prob": 0.0027966953348368406}, {"id": 125, "seek": 73228, "start": 732.28, "end": 740.04, "text": " And so that sort of acts as an example for people to use. So that was spring 2022, like I said,", "tokens": [50364, 400, 370, 300, 1333, 295, 10672, 382, 364, 1365, 337, 561, 281, 764, 13, 407, 300, 390, 5587, 20229, 11, 411, 286, 848, 11, 50752], "temperature": 0.0, "avg_logprob": -0.13579371369000778, "compression_ratio": 1.6058091286307055, "no_speech_prob": 0.011320240795612335}, {"id": 126, "seek": 73228, "start": 740.04, "end": 745.9599999999999, "text": " and that won't go into all the nitty-gritty there. But originally, we were using the original Web", "tokens": [50752, 293, 300, 1582, 380, 352, 666, 439, 264, 297, 10016, 12, 861, 10016, 456, 13, 583, 7993, 11, 321, 645, 1228, 264, 3380, 9573, 51048], "temperature": 0.0, "avg_logprob": -0.13579371369000778, "compression_ratio": 1.6058091286307055, "no_speech_prob": 0.011320240795612335}, {"id": 127, "seek": 73228, "start": 745.9599999999999, "end": 755.16, "text": " socket API, which is a standard thing with sort of companion to VSS. We actually had can working", "tokens": [51048, 19741, 9362, 11, 597, 307, 257, 3832, 551, 365, 1333, 295, 22363, 281, 691, 21929, 13, 492, 767, 632, 393, 1364, 51508], "temperature": 0.0, "avg_logprob": -0.13579371369000778, "compression_ratio": 1.6058091286307055, "no_speech_prob": 0.011320240795612335}, {"id": 128, "seek": 73228, "start": 755.16, "end": 761.56, "text": " in our demos. And so through 2022 and into 2023, we were sort of keeping up with the Cooks of Al", "tokens": [51508, 294, 527, 33788, 13, 400, 370, 807, 20229, 293, 666, 44377, 11, 321, 645, 1333, 295, 5145, 493, 365, 264, 12259, 82, 295, 967, 51828], "temperature": 0.0, "avg_logprob": -0.13579371369000778, "compression_ratio": 1.6058091286307055, "no_speech_prob": 0.011320240795612335}, {"id": 129, "seek": 76156, "start": 761.56, "end": 766.68, "text": " releases. I started, you know, some nominal updates around switching how we were doing our", "tokens": [50364, 16952, 13, 286, 1409, 11, 291, 458, 11, 512, 41641, 9205, 926, 16493, 577, 321, 645, 884, 527, 50620], "temperature": 0.0, "avg_logprob": -0.12550226279667445, "compression_ratio": 1.7028985507246377, "no_speech_prob": 0.0027108765207231045}, {"id": 130, "seek": 76156, "start": 766.68, "end": 775.4799999999999, "text": " signal additions and stuff. And then this past summer, our pike release, basically, I started", "tokens": [50620, 6358, 35113, 293, 1507, 13, 400, 550, 341, 1791, 4266, 11, 527, 36242, 4374, 11, 1936, 11, 286, 1409, 51060], "temperature": 0.0, "avg_logprob": -0.12550226279667445, "compression_ratio": 1.7028985507246377, "no_speech_prob": 0.0027108765207231045}, {"id": 131, "seek": 76156, "start": 775.4799999999999, "end": 780.8399999999999, "text": " the process of switching over to the data broker, which is the rust based implementation. And so", "tokens": [51060, 264, 1399, 295, 16493, 670, 281, 264, 1412, 26502, 11, 597, 307, 264, 15259, 2361, 11420, 13, 400, 370, 51328], "temperature": 0.0, "avg_logprob": -0.12550226279667445, "compression_ratio": 1.7028985507246377, "no_speech_prob": 0.0027108765207231045}, {"id": 132, "seek": 76156, "start": 780.8399999999999, "end": 786.28, "text": " I actually got interesting because we're based on Yachto Kirkstone, which is the LTS release,", "tokens": [51328, 286, 767, 658, 1880, 570, 321, 434, 2361, 322, 398, 3589, 78, 27834, 11243, 11, 597, 307, 264, 441, 7327, 4374, 11, 51600], "temperature": 0.0, "avg_logprob": -0.12550226279667445, "compression_ratio": 1.7028985507246377, "no_speech_prob": 0.0027108765207231045}, {"id": 133, "seek": 76156, "start": 786.28, "end": 791.0, "text": " which at this point is two years old. And it has older rust. So we couldn't actually build the", "tokens": [51600, 597, 412, 341, 935, 307, 732, 924, 1331, 13, 400, 309, 575, 4906, 15259, 13, 407, 321, 2809, 380, 767, 1322, 264, 51836], "temperature": 0.0, "avg_logprob": -0.12550226279667445, "compression_ratio": 1.7028985507246377, "no_speech_prob": 0.0027108765207231045}, {"id": 134, "seek": 79100, "start": 791.0, "end": 796.36, "text": " data broker. And so that was the thing where basically, a jail, we contributed upstream, I have", "tokens": [50364, 1412, 26502, 13, 400, 370, 300, 390, 264, 551, 689, 1936, 11, 257, 10511, 11, 321, 18434, 33915, 11, 286, 362, 50632], "temperature": 0.0, "avg_logprob": -0.1880852807428419, "compression_ratio": 1.6382978723404256, "no_speech_prob": 0.002471538260579109}, {"id": 135, "seek": 79100, "start": 796.36, "end": 802.76, "text": " a layer that you can get for the Yachto Kirkstone like mix in basically gives you a newer rust to", "tokens": [50632, 257, 4583, 300, 291, 393, 483, 337, 264, 398, 3589, 78, 27834, 11243, 411, 2890, 294, 1936, 2709, 291, 257, 17628, 15259, 281, 50952], "temperature": 0.0, "avg_logprob": -0.1880852807428419, "compression_ratio": 1.6382978723404256, "no_speech_prob": 0.002471538260579109}, {"id": 136, "seek": 79100, "start": 802.76, "end": 807.8, "text": " be able to build the data broker, which other people I now are no are using for building other", "tokens": [50952, 312, 1075, 281, 1322, 264, 1412, 26502, 11, 597, 661, 561, 286, 586, 366, 572, 366, 1228, 337, 2390, 661, 51204], "temperature": 0.0, "avg_logprob": -0.1880852807428419, "compression_ratio": 1.6382978723404256, "no_speech_prob": 0.002471538260579109}, {"id": 137, "seek": 79100, "start": 807.8, "end": 814.04, "text": " rust projects. So that, you know, we're now starting to look at the data broker, this cop coming", "tokens": [51204, 15259, 4455, 13, 407, 300, 11, 291, 458, 11, 321, 434, 586, 2891, 281, 574, 412, 264, 1412, 26502, 11, 341, 2971, 1348, 51516], "temperature": 0.0, "avg_logprob": -0.1880852807428419, "compression_ratio": 1.6382978723404256, "no_speech_prob": 0.002471538260579109}, {"id": 138, "seek": 81404, "start": 814.12, "end": 820.8399999999999, "text": " release. Basically, we were now using the absolutely latest version of Cooks. And that now I fully", "tokens": [50368, 4374, 13, 8537, 11, 321, 645, 586, 1228, 264, 3122, 6792, 3037, 295, 12259, 82, 13, 400, 300, 586, 286, 4498, 50704], "temperature": 0.0, "avg_logprob": -0.18294769036965292, "compression_ratio": 1.7056737588652482, "no_speech_prob": 0.2223028838634491}, {"id": 139, "seek": 81404, "start": 820.8399999999999, "end": 826.5999999999999, "text": " have us all switched over everything's data broker using gRPC, all our demos are converted.", "tokens": [50704, 362, 505, 439, 16858, 670, 1203, 311, 1412, 26502, 1228, 290, 49, 12986, 11, 439, 527, 33788, 366, 16424, 13, 50992], "temperature": 0.0, "avg_logprob": -0.18294769036965292, "compression_ratio": 1.7056737588652482, "no_speech_prob": 0.2223028838634491}, {"id": 140, "seek": 81404, "start": 826.5999999999999, "end": 831.3199999999999, "text": " And that basically acts as a thing. We're trying to see this with the automotive community, because,", "tokens": [50992, 400, 300, 1936, 10672, 382, 257, 551, 13, 492, 434, 1382, 281, 536, 341, 365, 264, 32866, 1768, 11, 570, 11, 51228], "temperature": 0.0, "avg_logprob": -0.18294769036965292, "compression_ratio": 1.7056737588652482, "no_speech_prob": 0.2223028838634491}, {"id": 141, "seek": 81404, "start": 831.9599999999999, "end": 836.68, "text": " you know, we see a lot of vendor, you know, or we encode that people open source is all like", "tokens": [51260, 291, 458, 11, 321, 536, 257, 688, 295, 24321, 11, 291, 458, 11, 420, 321, 2058, 1429, 300, 561, 1269, 4009, 307, 439, 411, 51496], "temperature": 0.0, "avg_logprob": -0.18294769036965292, "compression_ratio": 1.7056737588652482, "no_speech_prob": 0.2223028838634491}, {"id": 142, "seek": 81404, "start": 836.68, "end": 841.7199999999999, "text": " custom IPC and stuff like that. And it's like, Well, no, there are open source projects that are", "tokens": [51496, 2375, 8671, 34, 293, 1507, 411, 300, 13, 400, 309, 311, 411, 11, 1042, 11, 572, 11, 456, 366, 1269, 4009, 4455, 300, 366, 51748], "temperature": 0.0, "avg_logprob": -0.18294769036965292, "compression_ratio": 1.7056737588652482, "no_speech_prob": 0.2223028838634491}, {"id": 143, "seek": 84172, "start": 841.72, "end": 847.72, "text": " heavily used that do, you know, gRPC and, you know, interact with cloud providers and stuff,", "tokens": [50364, 10950, 1143, 300, 360, 11, 291, 458, 11, 290, 49, 12986, 293, 11, 291, 458, 11, 4648, 365, 4588, 11330, 293, 1507, 11, 50664], "temperature": 0.0, "avg_logprob": -0.21258913386951794, "compression_ratio": 1.7581227436823104, "no_speech_prob": 0.0015707705169916153}, {"id": 144, "seek": 84172, "start": 847.72, "end": 852.6800000000001, "text": " you don't have to reinvent the wheel. So Cooks of Al has been a very good thing for us to sort of", "tokens": [50664, 291, 500, 380, 362, 281, 33477, 264, 5589, 13, 407, 12259, 82, 295, 967, 575, 668, 257, 588, 665, 551, 337, 505, 281, 1333, 295, 50912], "temperature": 0.0, "avg_logprob": -0.21258913386951794, "compression_ratio": 1.7581227436823104, "no_speech_prob": 0.0015707705169916153}, {"id": 145, "seek": 84172, "start": 852.6800000000001, "end": 860.0400000000001, "text": " try and get that to people. So how exactly are we using an AGL? So there's, you know, the assess", "tokens": [50912, 853, 293, 483, 300, 281, 561, 13, 407, 577, 2293, 366, 321, 1228, 364, 316, 19440, 30, 407, 456, 311, 11, 291, 458, 11, 264, 5877, 51280], "temperature": 0.0, "avg_logprob": -0.21258913386951794, "compression_ratio": 1.7581227436823104, "no_speech_prob": 0.0015707705169916153}, {"id": 146, "seek": 84172, "start": 860.0400000000001, "end": 865.48, "text": " applications. As Eric mentioned, the concept of, you know, there's actuators. So there's, you know,", "tokens": [51280, 5821, 13, 1018, 9336, 2835, 11, 264, 3410, 295, 11, 291, 458, 11, 456, 311, 34964, 3391, 13, 407, 456, 311, 11, 291, 458, 11, 51552], "temperature": 0.0, "avg_logprob": -0.21258913386951794, "compression_ratio": 1.7581227436823104, "no_speech_prob": 0.0015707705169916153}, {"id": 147, "seek": 84172, "start": 865.48, "end": 870.84, "text": " apps that basically just listen to sensors. So like dashboards type of, you know, things like that.", "tokens": [51552, 7733, 300, 1936, 445, 2140, 281, 14840, 13, 407, 411, 8240, 17228, 2010, 295, 11, 291, 458, 11, 721, 411, 300, 13, 51820], "temperature": 0.0, "avg_logprob": -0.21258913386951794, "compression_ratio": 1.7581227436823104, "no_speech_prob": 0.0015707705169916153}, {"id": 148, "seek": 87172, "start": 871.72, "end": 877.96, "text": " And then for acting on signals, so basically implement an actuator behavior, we have some example", "tokens": [50364, 400, 550, 337, 6577, 322, 12354, 11, 370, 1936, 4445, 364, 34964, 1639, 5223, 11, 321, 362, 512, 1365, 50676], "temperature": 0.0, "avg_logprob": -0.10709498910342946, "compression_ratio": 1.652542372881356, "no_speech_prob": 0.0006982237682677805}, {"id": 149, "seek": 87172, "start": 877.96, "end": 884.84, "text": " services that do that kind of thing. It's like HVAC sort of stuff. There's also setting an actuator", "tokens": [50676, 3328, 300, 360, 300, 733, 295, 551, 13, 467, 311, 411, 389, 53, 4378, 1333, 295, 1507, 13, 821, 311, 611, 3287, 364, 34964, 1639, 51020], "temperature": 0.0, "avg_logprob": -0.10709498910342946, "compression_ratio": 1.652542372881356, "no_speech_prob": 0.0006982237682677805}, {"id": 150, "seek": 87172, "start": 884.84, "end": 890.2, "text": " value. So that would be like on a user facing infotainment app would be like HVAC controls or,", "tokens": [51020, 2158, 13, 407, 300, 576, 312, 411, 322, 257, 4195, 7170, 1536, 310, 491, 518, 724, 576, 312, 411, 389, 53, 4378, 9003, 420, 11, 51288], "temperature": 0.0, "avg_logprob": -0.10709498910342946, "compression_ratio": 1.652542372881356, "no_speech_prob": 0.0006982237682677805}, {"id": 151, "seek": 87172, "start": 890.2, "end": 898.12, "text": " you know, audio or volume that type of stuff. So in our tree right now, we have two demo services", "tokens": [51288, 291, 458, 11, 6278, 420, 5523, 300, 2010, 295, 1507, 13, 407, 294, 527, 4230, 558, 586, 11, 321, 362, 732, 10723, 3328, 51684], "temperature": 0.0, "avg_logprob": -0.10709498910342946, "compression_ratio": 1.652542372881356, "no_speech_prob": 0.0006982237682677805}, {"id": 152, "seek": 89812, "start": 898.12, "end": 903.32, "text": " that basically do that actuator side of things. So we have HVAC service that basically listens to", "tokens": [50364, 300, 1936, 360, 300, 34964, 1639, 1252, 295, 721, 13, 407, 321, 362, 389, 53, 4378, 2643, 300, 1936, 35959, 281, 50624], "temperature": 0.0, "avg_logprob": -0.08820516780271369, "compression_ratio": 1.7581227436823104, "no_speech_prob": 0.013832204975187778}, {"id": 153, "seek": 89812, "start": 903.32, "end": 910.36, "text": " all the like signals in the VSS hierarchy around HVAC controls. And then in our demo setup, which", "tokens": [50624, 439, 264, 411, 12354, 294, 264, 691, 21929, 22333, 926, 389, 53, 4378, 9003, 13, 400, 550, 294, 527, 10723, 8657, 11, 597, 50976], "temperature": 0.0, "avg_logprob": -0.08820516780271369, "compression_ratio": 1.7581227436823104, "no_speech_prob": 0.013832204975187778}, {"id": 154, "seek": 89812, "start": 910.36, "end": 914.84, "text": " unfortunately we won't have the full setup here, actually pushes out to drive some fans and things", "tokens": [50976, 7015, 321, 1582, 380, 362, 264, 1577, 8657, 510, 11, 767, 21020, 484, 281, 3332, 512, 4499, 293, 721, 51200], "temperature": 0.0, "avg_logprob": -0.08820516780271369, "compression_ratio": 1.7581227436823104, "no_speech_prob": 0.013832204975187778}, {"id": 155, "seek": 89812, "start": 914.84, "end": 921.16, "text": " like that. In the audio side, basically I'm listening into the audio like volume signal that's in", "tokens": [51200, 411, 300, 13, 682, 264, 6278, 1252, 11, 1936, 286, 478, 4764, 666, 264, 6278, 411, 5523, 6358, 300, 311, 294, 51516], "temperature": 0.0, "avg_logprob": -0.08820516780271369, "compression_ratio": 1.7581227436823104, "no_speech_prob": 0.013832204975187778}, {"id": 156, "seek": 89812, "start": 921.16, "end": 927.24, "text": " VSS and we, you know, have some custom things that I'm working to push upstream. But basically", "tokens": [51516, 691, 21929, 293, 321, 11, 291, 458, 11, 362, 512, 2375, 721, 300, 286, 478, 1364, 281, 2944, 33915, 13, 583, 1936, 51820], "temperature": 0.0, "avg_logprob": -0.08820516780271369, "compression_ratio": 1.7581227436823104, "no_speech_prob": 0.013832204975187778}, {"id": 157, "seek": 92724, "start": 927.24, "end": 932.84, "text": " actually drive that down into wire plumber and actually like adjust the, you know, the audio setup.", "tokens": [50364, 767, 3332, 300, 760, 666, 6234, 499, 4182, 293, 767, 411, 4369, 264, 11, 291, 458, 11, 264, 6278, 8657, 13, 50644], "temperature": 0.0, "avg_logprob": -0.14492035971747505, "compression_ratio": 1.6075949367088607, "no_speech_prob": 0.0002779013884719461}, {"id": 158, "seek": 92724, "start": 935.48, "end": 940.2, "text": " The user facing side are demo applications, the QT demo, which I think we might be showing", "tokens": [50776, 440, 4195, 7170, 1252, 366, 10723, 5821, 11, 264, 1249, 51, 10723, 11, 597, 286, 519, 321, 1062, 312, 4099, 51012], "temperature": 0.0, "avg_logprob": -0.14492035971747505, "compression_ratio": 1.6075949367088607, "no_speech_prob": 0.0002779013884719461}, {"id": 159, "seek": 92724, "start": 940.2, "end": 946.44, "text": " tomorrow. Basically we're using the SS signals for like everything pretty much. So all the", "tokens": [51012, 4153, 13, 8537, 321, 434, 1228, 264, 12238, 12354, 337, 411, 1203, 1238, 709, 13, 407, 439, 264, 51324], "temperature": 0.0, "avg_logprob": -0.14492035971747505, "compression_ratio": 1.6075949367088607, "no_speech_prob": 0.0002779013884719461}, {"id": 160, "seek": 92724, "start": 946.44, "end": 951.88, "text": " applications in that demo, which are in our source tree, you can grab them, basically are all wired", "tokens": [51324, 5821, 294, 300, 10723, 11, 597, 366, 294, 527, 4009, 4230, 11, 291, 393, 4444, 552, 11, 1936, 366, 439, 27415, 51596], "temperature": 0.0, "avg_logprob": -0.14492035971747505, "compression_ratio": 1.6075949367088607, "no_speech_prob": 0.0002779013884719461}, {"id": 161, "seek": 95188, "start": 951.88, "end": 957.72, "text": " up to do VSS signaling. And the code is sort of in a nice little library now and basically allow you", "tokens": [50364, 493, 281, 360, 691, 21929, 38639, 13, 400, 264, 3089, 307, 1333, 295, 294, 257, 1481, 707, 6405, 586, 293, 1936, 2089, 291, 50656], "temperature": 0.0, "avg_logprob": -0.1814516895222214, "compression_ratio": 1.5873015873015872, "no_speech_prob": 0.023312678560614586}, {"id": 162, "seek": 95188, "start": 957.72, "end": 963.32, "text": " to reuse it. On our newer Flutter demo, which I'm not truthful, actually maybe I think we'll have", "tokens": [50656, 281, 26225, 309, 13, 1282, 527, 17628, 3235, 9947, 10723, 11, 597, 286, 478, 406, 44669, 11, 767, 1310, 286, 519, 321, 603, 362, 50936], "temperature": 0.0, "avg_logprob": -0.1814516895222214, "compression_ratio": 1.5873015873015872, "no_speech_prob": 0.023312678560614586}, {"id": 163, "seek": 95188, "start": 963.32, "end": 969.64, "text": " one setup that'll have that tomorrow. Basically it's, you know, it has a unified sort of home screen.", "tokens": [50936, 472, 8657, 300, 603, 362, 300, 4153, 13, 8537, 309, 311, 11, 291, 458, 11, 309, 575, 257, 26787, 1333, 295, 1280, 2568, 13, 51252], "temperature": 0.0, "avg_logprob": -0.1814516895222214, "compression_ratio": 1.5873015873015872, "no_speech_prob": 0.023312678560614586}, {"id": 164, "seek": 95188, "start": 969.64, "end": 976.12, "text": " It's doing GRPC from Dart. And right now I don't have that sort of library sort of packaged up yet,", "tokens": [51252, 467, 311, 884, 10903, 12986, 490, 30271, 13, 400, 558, 586, 286, 500, 380, 362, 300, 1333, 295, 6405, 1333, 295, 38162, 493, 1939, 11, 51576], "temperature": 0.0, "avg_logprob": -0.1814516895222214, "compression_ratio": 1.5873015873015872, "no_speech_prob": 0.023312678560614586}, {"id": 165, "seek": 97612, "start": 976.12, "end": 982.04, "text": " but that might happen this year. Or we might move it to native code. Tidder, who are big into Flutter,", "tokens": [50364, 457, 300, 1062, 1051, 341, 1064, 13, 1610, 321, 1062, 1286, 309, 281, 8470, 3089, 13, 314, 327, 1068, 11, 567, 366, 955, 666, 3235, 9947, 11, 50660], "temperature": 0.0, "avg_logprob": -0.19449979341947116, "compression_ratio": 1.7661870503597121, "no_speech_prob": 0.02367173135280609}, {"id": 166, "seek": 97612, "start": 982.04, "end": 987.08, "text": " they tell us that's what they do that for some of their stuff. So, you know, we're pretty much,", "tokens": [50660, 436, 980, 505, 300, 311, 437, 436, 360, 300, 337, 512, 295, 641, 1507, 13, 407, 11, 291, 458, 11, 321, 434, 1238, 709, 11, 50912], "temperature": 0.0, "avg_logprob": -0.19449979341947116, "compression_ratio": 1.7661870503597121, "no_speech_prob": 0.02367173135280609}, {"id": 167, "seek": 97612, "start": 987.08, "end": 992.76, "text": " this is what our newer Flutter demo looks like. And so in this demo, like the tire pressure,", "tokens": [50912, 341, 307, 437, 527, 17628, 3235, 9947, 10723, 1542, 411, 13, 400, 370, 294, 341, 10723, 11, 411, 264, 11756, 3321, 11, 51196], "temperature": 0.0, "avg_logprob": -0.19449979341947116, "compression_ratio": 1.7661870503597121, "no_speech_prob": 0.02367173135280609}, {"id": 168, "seek": 97612, "start": 993.72, "end": 999.4, "text": " all the likes, you know, vehicle speeds and stuff like that, and all the, like the AC controls and", "tokens": [51244, 439, 264, 5902, 11, 291, 458, 11, 5864, 16411, 293, 1507, 411, 300, 11, 293, 439, 264, 11, 411, 264, 8157, 9003, 293, 51528], "temperature": 0.0, "avg_logprob": -0.19449979341947116, "compression_ratio": 1.7661870503597121, "no_speech_prob": 0.02367173135280609}, {"id": 169, "seek": 97612, "start": 999.4, "end": 1005.24, "text": " the temperature, all of that is going through VSS signaling to driving, you know, demons or whatever", "tokens": [51528, 264, 4292, 11, 439, 295, 300, 307, 516, 807, 691, 21929, 38639, 281, 4840, 11, 291, 458, 11, 19733, 420, 2035, 51820], "temperature": 0.0, "avg_logprob": -0.19449979341947116, "compression_ratio": 1.7661870503597121, "no_speech_prob": 0.02367173135280609}, {"id": 170, "seek": 100524, "start": 1005.24, "end": 1010.28, "text": " you want to do. Or KNData coming in actually gets converted back into a signal update. So,", "tokens": [50364, 291, 528, 281, 360, 13, 1610, 591, 13360, 3274, 1348, 294, 767, 2170, 16424, 646, 666, 257, 6358, 5623, 13, 407, 11, 50616], "temperature": 0.0, "avg_logprob": -0.20985271861252275, "compression_ratio": 1.5542168674698795, "no_speech_prob": 0.004193430300801992}, {"id": 171, "seek": 100524, "start": 1012.6800000000001, "end": 1018.28, "text": " so there's some extra, you know, presentations from Sven and Eric myself. And we're going to be in the", "tokens": [50736, 370, 456, 311, 512, 2857, 11, 291, 458, 11, 18964, 490, 49787, 293, 9336, 2059, 13, 400, 321, 434, 516, 281, 312, 294, 264, 51016], "temperature": 0.0, "avg_logprob": -0.20985271861252275, "compression_ratio": 1.5542168674698795, "no_speech_prob": 0.004193430300801992}, {"id": 172, "seek": 100524, "start": 1018.28, "end": 1024.52, "text": " AW building tomorrow. We're open bed at work today. We're to have that table tomorrow. We'll have our", "tokens": [51016, 25815, 2390, 4153, 13, 492, 434, 1269, 2901, 412, 589, 965, 13, 492, 434, 281, 362, 300, 3199, 4153, 13, 492, 603, 362, 527, 51328], "temperature": 0.0, "avg_logprob": -0.20985271861252275, "compression_ratio": 1.5542168674698795, "no_speech_prob": 0.004193430300801992}, {"id": 173, "seek": 100524, "start": 1024.52, "end": 1033.32, "text": " demos. And this is, you want to do your pitch? Sure. So if this sounds interesting, or even", "tokens": [51328, 33788, 13, 400, 341, 307, 11, 291, 528, 281, 360, 428, 7293, 30, 4894, 13, 407, 498, 341, 3263, 1880, 11, 420, 754, 51768], "temperature": 0.0, "avg_logprob": -0.20985271861252275, "compression_ratio": 1.5542168674698795, "no_speech_prob": 0.004193430300801992}, {"id": 174, "seek": 103332, "start": 1033.3999999999999, "end": 1037.3999999999999, "text": " if it doesn't sound interesting, there's a huge chance to engage with the community around", "tokens": [50368, 498, 309, 1177, 380, 1626, 1880, 11, 456, 311, 257, 2603, 2931, 281, 4683, 365, 264, 1768, 926, 50568], "temperature": 0.0, "avg_logprob": -0.1317715968115855, "compression_ratio": 1.671280276816609, "no_speech_prob": 0.004240948706865311}, {"id": 175, "seek": 103332, "start": 1037.3999999999999, "end": 1042.4399999999998, "text": " coaxa and the larger communities in the automotive sector. So we have something called Bosch Connected", "tokens": [50568, 598, 2797, 64, 293, 264, 4833, 4456, 294, 264, 32866, 6977, 13, 407, 321, 362, 746, 1219, 22264, 339, 11653, 292, 50820], "temperature": 0.0, "avg_logprob": -0.1317715968115855, "compression_ratio": 1.671280276816609, "no_speech_prob": 0.004240948706865311}, {"id": 176, "seek": 103332, "start": 1042.4399999999998, "end": 1047.1599999999999, "text": " Experience. It's hosted by Bosch, but it's basically very large hackathon in Berlin in the end of", "tokens": [50820, 28503, 13, 467, 311, 19204, 538, 22264, 339, 11, 457, 309, 311, 1936, 588, 2416, 10339, 18660, 294, 13848, 294, 264, 917, 295, 51056], "temperature": 0.0, "avg_logprob": -0.1317715968115855, "compression_ratio": 1.671280276816609, "no_speech_prob": 0.004240948706865311}, {"id": 177, "seek": 103332, "start": 1047.1599999999999, "end": 1052.12, "text": " February. So a bit short notice, but I would be really glad to see some of you there. We have the", "tokens": [51056, 8711, 13, 407, 257, 857, 2099, 3449, 11, 457, 286, 576, 312, 534, 5404, 281, 536, 512, 295, 291, 456, 13, 492, 362, 264, 51304], "temperature": 0.0, "avg_logprob": -0.1317715968115855, "compression_ratio": 1.671280276816609, "no_speech_prob": 0.004240948706865311}, {"id": 178, "seek": 103332, "start": 1052.12, "end": 1057.96, "text": " chance to work with a lot of things like maybe actual seats, maybe actual cars, hopefully. Or", "tokens": [51304, 2931, 281, 589, 365, 257, 688, 295, 721, 411, 1310, 3539, 11069, 11, 1310, 3539, 5163, 11, 4696, 13, 1610, 51596], "temperature": 0.0, "avg_logprob": -0.1317715968115855, "compression_ratio": 1.671280276816609, "no_speech_prob": 0.004240948706865311}, {"id": 179, "seek": 105796, "start": 1057.96, "end": 1062.92, "text": " and also we plan to have some meetable assimilation of a car which is then connected to a data", "tokens": [50364, 293, 611, 321, 1393, 281, 362, 512, 1677, 712, 8249, 16067, 295, 257, 1032, 597, 307, 550, 4582, 281, 257, 1412, 50612], "temperature": 0.0, "avg_logprob": -0.1819560089111328, "compression_ratio": 1.7288732394366197, "no_speech_prob": 0.03429389372467995}, {"id": 180, "seek": 105796, "start": 1062.92, "end": 1067.96, "text": " broker. So I think it will also be cool what you can do with combining these physical and also this", "tokens": [50612, 26502, 13, 407, 286, 519, 309, 486, 611, 312, 1627, 437, 291, 393, 360, 365, 21928, 613, 4001, 293, 611, 341, 50864], "temperature": 0.0, "avg_logprob": -0.1819560089111328, "compression_ratio": 1.7288732394366197, "no_speech_prob": 0.03429389372467995}, {"id": 181, "seek": 105796, "start": 1067.96, "end": 1072.8400000000001, "text": " cyber physical world, if you will. So I really encourage you to do that. If you want to come there,", "tokens": [50864, 13411, 4001, 1002, 11, 498, 291, 486, 13, 407, 286, 534, 5373, 291, 281, 360, 300, 13, 759, 291, 528, 281, 808, 456, 11, 51108], "temperature": 0.0, "avg_logprob": -0.1819560089111328, "compression_ratio": 1.7288732394366197, "no_speech_prob": 0.03429389372467995}, {"id": 182, "seek": 105796, "start": 1072.8400000000001, "end": 1078.04, "text": " you normally have to apply. But if you just approach me, I think we'll find a quick way to get you in", "tokens": [51108, 291, 5646, 362, 281, 3079, 13, 583, 498, 291, 445, 3109, 385, 11, 286, 519, 321, 603, 915, 257, 1702, 636, 281, 483, 291, 294, 51368], "temperature": 0.0, "avg_logprob": -0.1819560089111328, "compression_ratio": 1.7288732394366197, "no_speech_prob": 0.03429389372467995}, {"id": 183, "seek": 105796, "start": 1078.04, "end": 1083.96, "text": " because being you in this room, I think qualifies as a good hacker for that. So was that maybe", "tokens": [51368, 570, 885, 291, 294, 341, 1808, 11, 286, 519, 4101, 11221, 382, 257, 665, 38155, 337, 300, 13, 407, 390, 300, 1310, 51664], "temperature": 0.0, "avg_logprob": -0.1819560089111328, "compression_ratio": 1.7288732394366197, "no_speech_prob": 0.03429389372467995}, {"id": 184, "seek": 108396, "start": 1084.04, "end": 1089.4, "text": " you there on another community meeting? So thanks a lot for stating this out and we open for questions.", "tokens": [50368, 291, 456, 322, 1071, 1768, 3440, 30, 407, 3231, 257, 688, 337, 26688, 341, 484, 293, 321, 1269, 337, 1651, 13, 50636], "temperature": 0.0, "avg_logprob": -0.31960633397102356, "compression_ratio": 1.4385964912280702, "no_speech_prob": 0.022184962406754494}, {"id": 185, "seek": 108396, "start": 1089.4, "end": 1090.76, "text": " Yeah, I think we have a couple of minutes.", "tokens": [50636, 865, 11, 286, 519, 321, 362, 257, 1916, 295, 2077, 13, 50704], "temperature": 0.0, "avg_logprob": -0.31960633397102356, "compression_ratio": 1.4385964912280702, "no_speech_prob": 0.022184962406754494}, {"id": 186, "seek": 108396, "start": 1103.64, "end": 1104.68, "text": " Yeah, we'll have to share.", "tokens": [51348, 865, 11, 321, 603, 362, 281, 2073, 13, 51400], "temperature": 0.0, "avg_logprob": -0.31960633397102356, "compression_ratio": 1.4385964912280702, "no_speech_prob": 0.022184962406754494}, {"id": 187, "seek": 108396, "start": 1109.64, "end": 1112.76, "text": " Thank you. Great talk. Just wanted to understand a little bit about your", "tokens": [51648, 1044, 291, 13, 3769, 751, 13, 1449, 1415, 281, 1223, 257, 707, 857, 466, 428, 51804], "temperature": 0.0, "avg_logprob": -0.31960633397102356, "compression_ratio": 1.4385964912280702, "no_speech_prob": 0.022184962406754494}, {"id": 188, "seek": 111396, "start": 1113.96, "end": 1119.56, "text": " testing cycle. So if you you're developing something with this and then you test it in a", "tokens": [50364, 4997, 6586, 13, 407, 498, 291, 291, 434, 6416, 746, 365, 341, 293, 550, 291, 1500, 309, 294, 257, 50644], "temperature": 0.0, "avg_logprob": -0.10366598765055339, "compression_ratio": 1.6780487804878048, "no_speech_prob": 0.008275098167359829}, {"id": 189, "seek": 111396, "start": 1119.56, "end": 1125.0, "text": " virtual environment and then you want to test it on a real car, like what do you do in practice", "tokens": [50644, 6374, 2823, 293, 550, 291, 528, 281, 1500, 309, 322, 257, 957, 1032, 11, 411, 437, 360, 291, 360, 294, 3124, 50916], "temperature": 0.0, "avg_logprob": -0.10366598765055339, "compression_ratio": 1.6780487804878048, "no_speech_prob": 0.008275098167359829}, {"id": 190, "seek": 111396, "start": 1125.0, "end": 1129.8, "text": " when you're developing stuff? Do you have an answer to that?", "tokens": [50916, 562, 291, 434, 6416, 1507, 30, 1144, 291, 362, 364, 1867, 281, 300, 30, 51156], "temperature": 0.0, "avg_logprob": -0.10366598765055339, "compression_ratio": 1.6780487804878048, "no_speech_prob": 0.008275098167359829}, {"id": 191, "seek": 111396, "start": 1135.0, "end": 1140.68, "text": " So I wouldn't have a straight answer because here we talk more about implementing that abstraction", "tokens": [51416, 407, 286, 2759, 380, 362, 257, 2997, 1867, 570, 510, 321, 751, 544, 466, 18114, 300, 37765, 51700], "temperature": 0.0, "avg_logprob": -0.10366598765055339, "compression_ratio": 1.6780487804878048, "no_speech_prob": 0.008275098167359829}, {"id": 192, "seek": 114068, "start": 1140.68, "end": 1145.64, "text": " layer and mostly testing it against things like this mock service or with something like a feeder", "tokens": [50364, 4583, 293, 5240, 4997, 309, 1970, 721, 411, 341, 17362, 2643, 420, 365, 746, 411, 257, 48778, 50612], "temperature": 0.0, "avg_logprob": -0.24172249515499689, "compression_ratio": 1.6109215017064846, "no_speech_prob": 0.029330171644687653}, {"id": 193, "seek": 114068, "start": 1145.64, "end": 1151.5600000000002, "text": " where we have recorded data. But things that you're touching on a small like a really general", "tokens": [50612, 689, 321, 362, 8287, 1412, 13, 583, 721, 300, 291, 434, 11175, 322, 257, 1359, 411, 257, 534, 2674, 50908], "temperature": 0.0, "avg_logprob": -0.24172249515499689, "compression_ratio": 1.6109215017064846, "no_speech_prob": 0.029330171644687653}, {"id": 194, "seek": 114068, "start": 1152.28, "end": 1157.0, "text": " topic on how do I actually get my automotive software up and running and into the vehicle. So", "tokens": [50944, 4829, 322, 577, 360, 286, 767, 483, 452, 32866, 4722, 493, 293, 2614, 293, 666, 264, 5864, 13, 407, 51180], "temperature": 0.0, "avg_logprob": -0.24172249515499689, "compression_ratio": 1.6109215017064846, "no_speech_prob": 0.029330171644687653}, {"id": 195, "seek": 114068, "start": 1158.8400000000001, "end": 1163.0, "text": " that's a bit beyond the scope of what just the Cookshead project is doing. So not too much I", "tokens": [51272, 300, 311, 257, 857, 4399, 264, 11923, 295, 437, 445, 264, 12259, 82, 1934, 1716, 307, 884, 13, 407, 406, 886, 709, 286, 51480], "temperature": 0.0, "avg_logprob": -0.24172249515499689, "compression_ratio": 1.6109215017064846, "no_speech_prob": 0.029330171644687653}, {"id": 196, "seek": 114068, "start": 1163.0, "end": 1167.3200000000002, "text": " can comment on here, but I think it's a good topic for the communities, either AGL or Eclipse", "tokens": [51480, 393, 2871, 322, 510, 11, 457, 286, 519, 309, 311, 257, 665, 4829, 337, 264, 4456, 11, 2139, 316, 19440, 420, 462, 27197, 51696], "temperature": 0.0, "avg_logprob": -0.24172249515499689, "compression_ratio": 1.6109215017064846, "no_speech_prob": 0.029330171644687653}, {"id": 197, "seek": 116732, "start": 1167.3999999999999, "end": 1170.9199999999998, "text": " STB because we have some rounds of meetings where we exactly talk about that.", "tokens": [50368, 4904, 33, 570, 321, 362, 512, 13757, 295, 8410, 689, 321, 2293, 751, 466, 300, 13, 50544], "temperature": 0.0, "avg_logprob": -0.13807222005483266, "compression_ratio": 1.6036363636363635, "no_speech_prob": 0.007063920143991709}, {"id": 198, "seek": 116732, "start": 1173.6399999999999, "end": 1177.56, "text": " Yeah, I would just say that it's still actually pretty early days for", "tokens": [50680, 865, 11, 286, 576, 445, 584, 300, 309, 311, 920, 767, 1238, 2440, 1708, 337, 50876], "temperature": 0.0, "avg_logprob": -0.13807222005483266, "compression_ratio": 1.6036363636363635, "no_speech_prob": 0.007063920143991709}, {"id": 199, "seek": 116732, "start": 1177.56, "end": 1183.56, "text": " DSS. I mean, I know there's a bunch of OEMs and interior ones that are actively working to product", "tokens": [50876, 15816, 50, 13, 286, 914, 11, 286, 458, 456, 311, 257, 3840, 295, 422, 6683, 82, 293, 10636, 2306, 300, 366, 13022, 1364, 281, 1674, 51176], "temperature": 0.0, "avg_logprob": -0.13807222005483266, "compression_ratio": 1.6036363636363635, "no_speech_prob": 0.007063920143991709}, {"id": 200, "seek": 116732, "start": 1183.56, "end": 1189.32, "text": " eyes. So I don't think we have visibility yet into how they're actually going about and testing.", "tokens": [51176, 2575, 13, 407, 286, 500, 380, 519, 321, 362, 19883, 1939, 666, 577, 436, 434, 767, 516, 466, 293, 4997, 13, 51464], "temperature": 0.0, "avg_logprob": -0.13807222005483266, "compression_ratio": 1.6036363636363635, "no_speech_prob": 0.007063920143991709}, {"id": 201, "seek": 116732, "start": 1189.32, "end": 1194.12, "text": " So I think hopefully in the next year or two we'll see more and we'll maybe get some ideas there.", "tokens": [51464, 407, 286, 519, 4696, 294, 264, 958, 1064, 420, 732, 321, 603, 536, 544, 293, 321, 603, 1310, 483, 512, 3487, 456, 13, 51704], "temperature": 0.0, "avg_logprob": -0.13807222005483266, "compression_ratio": 1.6036363636363635, "no_speech_prob": 0.007063920143991709}, {"id": 202, "seek": 119732, "start": 1197.8799999999999, "end": 1199.8799999999999, "text": " Any more questions?", "tokens": [50392, 2639, 544, 1651, 30, 50492], "temperature": 0.0, "avg_logprob": -0.31007311636941476, "compression_ratio": 1.4965517241379311, "no_speech_prob": 0.020853400230407715}, {"id": 203, "seek": 119732, "start": 1210.76, "end": 1215.96, "text": " Maybe in two or three words, can you share a little bit about the data broker? Is it something that", "tokens": [51036, 2704, 294, 732, 420, 1045, 2283, 11, 393, 291, 2073, 257, 707, 857, 466, 264, 1412, 26502, 30, 1119, 309, 746, 300, 51296], "temperature": 0.0, "avg_logprob": -0.31007311636941476, "compression_ratio": 1.4965517241379311, "no_speech_prob": 0.020853400230407715}, {"id": 204, "seek": 119732, "start": 1215.96, "end": 1222.4399999999998, "text": " looked like Debus? Is it something like look like MQTT broker? Something else? What it looks like", "tokens": [51296, 2956, 411, 1346, 21441, 30, 1119, 309, 746, 411, 574, 411, 376, 48, 28178, 26502, 30, 6595, 1646, 30, 708, 309, 1542, 411, 51620], "temperature": 0.0, "avg_logprob": -0.31007311636941476, "compression_ratio": 1.4965517241379311, "no_speech_prob": 0.020853400230407715}, {"id": 205, "seek": 122244, "start": 1222.44, "end": 1227.72, "text": " exactly? Is it something that we can reuse elsewhere or is it specific to Cookshead?", "tokens": [50364, 2293, 30, 1119, 309, 746, 300, 321, 393, 26225, 14517, 420, 307, 309, 2685, 281, 12259, 82, 1934, 30, 50628], "temperature": 0.0, "avg_logprob": -0.13562472343444823, "compression_ratio": 1.6559633027522935, "no_speech_prob": 0.027223538607358932}, {"id": 206, "seek": 122244, "start": 1230.2, "end": 1235.48, "text": " I would say the data broker is really specific to VSS data. So it's not like you can", "tokens": [50752, 286, 576, 584, 264, 1412, 26502, 307, 534, 2685, 281, 691, 21929, 1412, 13, 407, 309, 311, 406, 411, 291, 393, 51016], "temperature": 0.0, "avg_logprob": -0.13562472343444823, "compression_ratio": 1.6559633027522935, "no_speech_prob": 0.027223538607358932}, {"id": 207, "seek": 122244, "start": 1236.76, "end": 1242.04, "text": " put any data in there. So the way it works is you start the data broker and you also give it this", "tokens": [51080, 829, 604, 1412, 294, 456, 13, 407, 264, 636, 309, 1985, 307, 291, 722, 264, 1412, 26502, 293, 291, 611, 976, 309, 341, 51344], "temperature": 0.0, "avg_logprob": -0.13562472343444823, "compression_ratio": 1.6559633027522935, "no_speech_prob": 0.027223538607358932}, {"id": 208, "seek": 122244, "start": 1242.04, "end": 1247.4, "text": " VSS data model that you have. So the VSS data model is expressed in a JSON or in a YAML file.", "tokens": [51344, 691, 21929, 1412, 2316, 300, 291, 362, 13, 407, 264, 691, 21929, 1412, 2316, 307, 12675, 294, 257, 31828, 420, 294, 257, 398, 2865, 43, 3991, 13, 51612], "temperature": 0.0, "avg_logprob": -0.13562472343444823, "compression_ratio": 1.6559633027522935, "no_speech_prob": 0.027223538607358932}, {"id": 209, "seek": 124740, "start": 1248.2800000000002, "end": 1253.3200000000002, "text": " Then you put this JSON or YAML file into the data broker and then you can basically do get set", "tokens": [50408, 1396, 291, 829, 341, 31828, 420, 398, 2865, 43, 3991, 666, 264, 1412, 26502, 293, 550, 291, 393, 1936, 360, 483, 992, 50660], "temperature": 0.0, "avg_logprob": -0.16094196319580079, "compression_ratio": 1.5201612903225807, "no_speech_prob": 0.034997012466192245}, {"id": 210, "seek": 124740, "start": 1253.3200000000002, "end": 1258.6000000000001, "text": " and subscribe. That's why I put up this slide again on this kind of data which is expressed in the", "tokens": [50660, 293, 3022, 13, 663, 311, 983, 286, 829, 493, 341, 4137, 797, 322, 341, 733, 295, 1412, 597, 307, 12675, 294, 264, 50924], "temperature": 0.0, "avg_logprob": -0.16094196319580079, "compression_ratio": 1.5201612903225807, "no_speech_prob": 0.034997012466192245}, {"id": 211, "seek": 124740, "start": 1258.6000000000001, "end": 1264.92, "text": " data model and then the data broker implicitly knows about that. When you talk about MQTT,", "tokens": [50924, 1412, 2316, 293, 550, 264, 1412, 26502, 26947, 356, 3255, 466, 300, 13, 1133, 291, 751, 466, 376, 48, 28178, 11, 51240], "temperature": 0.0, "avg_logprob": -0.16094196319580079, "compression_ratio": 1.5201612903225807, "no_speech_prob": 0.034997012466192245}, {"id": 212, "seek": 124740, "start": 1264.92, "end": 1271.16, "text": " there's also I have to admit other APIs to interact with VSS. For instance, VIST done in W3C", "tokens": [51240, 456, 311, 611, 286, 362, 281, 9796, 661, 21445, 281, 4648, 365, 691, 21929, 13, 1171, 5197, 11, 691, 19756, 1096, 294, 343, 18, 34, 51552], "temperature": 0.0, "avg_logprob": -0.16094196319580079, "compression_ratio": 1.5201612903225807, "no_speech_prob": 0.034997012466192245}, {"id": 213, "seek": 127116, "start": 1271.8000000000002, "end": 1277.0, "text": " and they also looked a bit into how to do that over MQTT. But again here,", "tokens": [50396, 293, 436, 611, 2956, 257, 857, 666, 577, 281, 360, 300, 670, 376, 48, 28178, 13, 583, 797, 510, 11, 50656], "temperature": 0.0, "avg_logprob": -0.1776140902904754, "compression_ratio": 1.4789915966386555, "no_speech_prob": 0.01563381962478161}, {"id": 214, "seek": 127116, "start": 1278.92, "end": 1283.64, "text": " the data broker is especially tailored to interact with VSS signals. That's why I cannot", "tokens": [50752, 264, 1412, 26502, 307, 2318, 34858, 281, 4648, 365, 691, 21929, 12354, 13, 663, 311, 983, 286, 2644, 50988], "temperature": 0.0, "avg_logprob": -0.1776140902904754, "compression_ratio": 1.4789915966386555, "no_speech_prob": 0.01563381962478161}, {"id": 215, "seek": 127116, "start": 1283.64, "end": 1291.0, "text": " generalize it too much. Basically, when I go home, I have a project that our vehicle to cloud,", "tokens": [50988, 2674, 1125, 309, 886, 709, 13, 8537, 11, 562, 286, 352, 1280, 11, 286, 362, 257, 1716, 300, 527, 5864, 281, 4588, 11, 51356], "temperature": 0.0, "avg_logprob": -0.1776140902904754, "compression_ratio": 1.4789915966386555, "no_speech_prob": 0.01563381962478161}, {"id": 216, "seek": 127116, "start": 1291.0, "end": 1298.1200000000001, "text": " Expert Group in Agile, wants to see basically pushing from VSS up into the cloud. So I'm going", "tokens": [51356, 41255, 10500, 294, 2725, 794, 11, 2738, 281, 536, 1936, 7380, 490, 691, 21929, 493, 666, 264, 4588, 13, 407, 286, 478, 516, 51712], "temperature": 0.0, "avg_logprob": -0.1776140902904754, "compression_ratio": 1.4789915966386555, "no_speech_prob": 0.01563381962478161}, {"id": 217, "seek": 129812, "start": 1298.1999999999998, "end": 1305.2399999999998, "text": " to be building a proxy that will basically take a list of signals to listen to from the VSS", "tokens": [50368, 281, 312, 2390, 257, 29690, 300, 486, 1936, 747, 257, 1329, 295, 12354, 281, 2140, 281, 490, 264, 691, 21929, 50720], "temperature": 0.0, "avg_logprob": -0.1771977523277546, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.005379855632781982}, {"id": 218, "seek": 129812, "start": 1305.2399999999998, "end": 1312.1999999999998, "text": " data broker or cooks a data broker and then basically MQTT them up somewhere. So then talk to", "tokens": [50720, 1412, 26502, 420, 30709, 257, 1412, 26502, 293, 550, 1936, 376, 48, 28178, 552, 493, 4079, 13, 407, 550, 751, 281, 51068], "temperature": 0.0, "avg_logprob": -0.1771977523277546, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.005379855632781982}, {"id": 219, "seek": 129812, "start": 1312.1999999999998, "end": 1318.6, "text": " us in a better world. I'll have a story for you then. Maybe one final thing to add to that.", "tokens": [51068, 505, 294, 257, 1101, 1002, 13, 286, 603, 362, 257, 1657, 337, 291, 550, 13, 2704, 472, 2572, 551, 281, 909, 281, 300, 13, 51388], "temperature": 0.0, "avg_logprob": -0.1771977523277546, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.005379855632781982}, {"id": 220, "seek": 129812, "start": 1318.6, "end": 1322.04, "text": " As there's one slide, I actually removed it from the slide deck but there has been a huge", "tokens": [51388, 1018, 456, 311, 472, 4137, 11, 286, 767, 7261, 309, 490, 264, 4137, 9341, 457, 456, 575, 668, 257, 2603, 51560], "temperature": 0.0, "avg_logprob": -0.1771977523277546, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.005379855632781982}, {"id": 221, "seek": 129812, "start": 1322.04, "end": 1326.84, "text": " discussion in the VSS community whether VSS is actually fit in the vehicle or whether you should", "tokens": [51560, 5017, 294, 264, 691, 21929, 1768, 1968, 691, 21929, 307, 767, 3318, 294, 264, 5864, 420, 1968, 291, 820, 51800], "temperature": 0.0, "avg_logprob": -0.1771977523277546, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.005379855632781982}, {"id": 222, "seek": 132684, "start": 1326.84, "end": 1331.32, "text": " use VSS more on the cloud back end so that you put all the data from the car and whatever form it", "tokens": [50364, 764, 691, 21929, 544, 322, 264, 4588, 646, 917, 370, 300, 291, 829, 439, 264, 1412, 490, 264, 1032, 293, 2035, 1254, 309, 50588], "temperature": 0.0, "avg_logprob": -0.10947736104329427, "compression_ratio": 1.691304347826087, "no_speech_prob": 0.008250602521002293}, {"id": 223, "seek": 132684, "start": 1331.32, "end": 1335.8, "text": " up to the cloud and then consume it in VSS there. And the data broker is kind of like an answer to", "tokens": [50588, 493, 281, 264, 4588, 293, 550, 14732, 309, 294, 691, 21929, 456, 13, 400, 264, 1412, 26502, 307, 733, 295, 411, 364, 1867, 281, 50812], "temperature": 0.0, "avg_logprob": -0.10947736104329427, "compression_ratio": 1.691304347826087, "no_speech_prob": 0.008250602521002293}, {"id": 224, "seek": 132684, "start": 1335.8, "end": 1340.52, "text": " yeah, it's also possible to do it in the car in addition to the cloud. So that's kind of the", "tokens": [50812, 1338, 11, 309, 311, 611, 1944, 281, 360, 309, 294, 264, 1032, 294, 4500, 281, 264, 4588, 13, 407, 300, 311, 733, 295, 264, 51048], "temperature": 0.0, "avg_logprob": -0.10947736104329427, "compression_ratio": 1.691304347826087, "no_speech_prob": 0.008250602521002293}, {"id": 225, "seek": 132684, "start": 1340.52, "end": 1348.9199999999998, "text": " background story as well. Okay, so I think that's all we have time for for the moment. So thank you", "tokens": [51048, 3678, 1657, 382, 731, 13, 1033, 11, 370, 286, 519, 300, 311, 439, 321, 362, 565, 337, 337, 264, 1623, 13, 407, 1309, 291, 51468], "temperature": 0.0, "avg_logprob": -0.10947736104329427, "compression_ratio": 1.691304347826087, "no_speech_prob": 0.008250602521002293}, {"id": 226, "seek": 134892, "start": 1348.92, "end": 1359.0, "text": " very much Sven Eric and Scott and round of applause.", "tokens": [50364, 588, 709, 49787, 9336, 293, 6659, 293, 3098, 295, 9969, 13, 50868], "temperature": 0.0, "avg_logprob": -0.46000402314322336, "compression_ratio": 0.9454545454545454, "no_speech_prob": 0.17318454384803772}], "language": "en"}