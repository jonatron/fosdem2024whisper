{"text": " So there may or may not be time for questions. There's a lot of detail. This is a 60 minute talk compressed down to hopefully 22ish minutes. So we will see how we go. But yeah, I'm here to talk about the technical details of interoperability. I'm also Travis. If you don't know me, I'm the director for standards development at matrix.org. I'm also on the spec core team. I run T2Bot and I work at element for trust and safety. I have a few jobs. But good news, there's already more that we can talk about. So Matthew had the talk this morning. If you haven't seen that or seen the recap of it about 10 minutes ago, covers DMA and the timelines in a lot more detail. To recap though, the DMA requires gatekeepers or large messaging providers to open up their APIs and their systems for interoperability. Encryption must be maintained between those providers. So you cannot break encryption for the sake of interoperating. You have to maintain it. These messengers have three options. You can become multi-headed similar to Beeper Mini where you have all the networks available in your one client. And you just kind of switch between them. You can create a bridge app where the user downloads a third thing and then you bridge locally on the device. That works. It's not great. Or you can speak a common protocol. We've been doing that for the last year. Probably longer. And oh yeah, they have to do this all by March 7th this year. So with that in mind, there are many projects involved as well. There is the more instant messaging, interoperability working group or MIMI at the IETF. They are trying to specify a standard that does this stuff. We are very frequent there. We are a direct contributor to this. I have written a MIMI protocol document in association with a few other people on the design team to try and simplify a lot of the components, particularly what linearized matrix is. Also, linearized matrix was originally created as this simplified version of matrix because it turns out that you don't necessarily need a ton of the fully compatible DAG stuff or even messaging history for interoperability. A lot of the existing providers just kind of want to throw messages around the place. They don't necessarily want to just kind of keep these things around. Obviously, of course, we have matrix. Hopefully, everybody here is familiar with that. But it is the decentralized and fully featured version of an interoperable protocol. What parts of interoperability do we have to worry about? A few. There is encryption. This kind of fits into a weird L shape. You have content format within that. But the encryption, we have to make sure that all the messages are secure. We have to make sure that everything is the same. Of course, we have to make sure that it is consistent across the providers. The content format, what do messages actually look like? We have to make sure that that is the same because the servers can't help us here. The clients have to agree on this. That is more of a challenge. We also need an authorization policy so people can be banned because they need to. Then we also have messages that people might not be allowed to send in certain rooms. Of course, we also have transport. The transport is just how the servers communicate because we have a room model that looks something like this. The room model is a combination of the encryption authorization policy and transport. We also have a definition of membership or participation, a little bit more on that in a minute. And also how the messages are found out themselves. In the very simplest scenario, we have clients talking to servers, servers talking to each other, and encrypted messages flowing between clients effectively. It gets more complicated when you add a third server, so we will do that later. Some of these problems are easier than others. Namely, transport. Super easy to solve. Pretty much everybody uses some form of HTTPS. Mimi wants to use MTLS. Linearized Matrix uses the same system that Matrix already does where you have a signed or a signing key that kind of gets thrown around a bit. It is unclear what the actual format over HTTP would be. Matrix uses JSON. Mimi wants to use some form of binary. Unclear what that actually is. We are also considering a binary event format specifically for this kind of thing. Protobuf and Seabor are kind of on the top. But to be determined, clients would not be expected to consume that binary format yet. I should probably just add that in. But yeah, we will end up using some sort of binary over HTTPS mechanism authorization exactly to be determined later. The other easy thing is authorization policy. Mimi does not define one. We have been working without one. We have just been assuming that people are able to send messages. Matrix obviously has one. Role-based access control is super popular amongst a lot of these discussions. There is those two MSCs there. 4056 covers the decentralization part of RBAC. Then you also have 2812 where it basically rolls as state events. It is an early form of RBAC. Linearized Matrix uses the existing authorization rules. Matrix authorization rules clearly already work. People have been using them for almost a decade now. They should be fined. We will figure out what Mimi ends up with eventually, hopefully. The harder parts are encryption. Most messaging providers use lib signal or something that is a double ratchet. We also have a double ratchet-like implementation called OM. It was not previously interoperable with lib signal up until about 2 a.m. tonight. We now have inter-OM, which has that X3DH support as well as some of the other delts you need to be able to support that sort of interoperability. Megalom is what we use in group chats to try and alleviate the load. Otherwise, with OM, you have to send a number of events for the number of devices in the room, which obviously causes problems when you have multiple devices per user or multiple users in a room. Matrix HQ would be a nightmare. The double ratchet does rely on existing infrastructure in order to send keys. It has no concept of membership. It does not know who to send the keys to on its own. You have to tell it who to encrypt to and then also send those keys yourself. Some messaging providers, namely Google, have announced that they will be using MLS. We also obviously want to use MLS. REMLST.com is where we're tracking that progress. MLS does have a concept of built-in membership, so it does know who it needs to send messages to. It obviously doesn't send the messages itself, but more on that in a second, namely this slide. RFC 942.0, that is where the IETF has specified this. I have a really awful crash course guide because I am not a cryptographer, but there it is. But yeah, there is a binary tree, so you have a root key and you have multiple nodes underneath that. With that concept, you end up with a concept of membership where only users or members that have certain keys can see other keys. That is how you get to know who to send the keys to, particularly the decryption keys. Mimi has refused to implement any other encryption other than MLS. They are obviously considering it as part of double ratchet because we do need an onramp. But with the IETF, they tend to get a little bit stuck in the RFCs. We are also considering MLS, obviously, and so we want to extend it. Decentralized environments, namely matrix, will have to use DMLS or similar. Membership. As part of the discussions with Mimi, we have been having some arguments, we will say, about what it actually means to define membership. We have decided that users join rooms and clients encrypt messages. Both MLS and double ratchet deal with clients. When a user joins the room, all of their clients join as well. This is hopefully not a novel thing that is here, but it is written in stone now. So we need to synchronize these two concepts. We call users to have a participation state or exist on a participation list. And then clients have membership. So users, participation, clients, membership. We also have to make sure that these are atomic operations because otherwise somebody joins the crypto state, but they are not part of the actual user state. That causes issues. So Mimi has started proposing a bunch of MLS extensions to persist application state within an MLS group. Because MLS has those extensions that you can just store arbitrary things, making the blob even larger so you must store it in the media repo. These are new as of like a week and a half ago, but it is called AppSync. It is a generic mechanism. Conveniently, it would basically be mapped to state events in matrix. So you can just add arbitrary information to the group, namely with a key and some sort of content. And then there are some operations that apply where you can add, remove, update, that sort of stuff. But yeah, it is visible to servers, but servers can't see the actual encrypted messages part of MLS. They can just see that state changes are happening and potentially what's inside those state changes, which is why they would map to state events in matrix. Double ratchet and participation is a bit harder. Because double ratchet, again, doesn't have a concept of membership. It's not terribly difficult to map these. It's a little complicated sometimes. So there's a couple of MSCs there that list this sort of information, namely the crypto IDs Matthew was just talking about. And then yeah, we translate these concepts to Mroom member state events as well as device lists on matrix. But regardless of the protocol, we want to make sure that people currently on double ratchet have a way up to MLS. So it's a natural evolution of the application rather than forcing somebody to effectively fork their own client, which brings us a little bit into content format. So clients need to end up encrypting and decrypting the same thing. Otherwise, there's going to be issues. Because if you send a text message to somebody and they just don't know what to expect, then there's not going to see anything. So we need some form of extensibility because messaging also has a ton of features. And it's constantly evolving. Servers can't help with this because it's already encrypted. And of course, it should be as small as possible. It should require minimal processing power because not every client is a laptop. Or sometimes the laptop is a bit slow. So Mimi has worked on their own TLS encoded multi part MIME format. It looks a lot like multi part email. It's not the greatest, but it is a notional format while we try and work out the exact things. But matrix already has events and you can already define your own custom event types. And you can already add arbitrary content. But what if we made that way more extensible? So we introduce extensible events or MSC 1767. We use content blocks to persist information inside of an event. We specify the course blocks there. And then we also try to make sure that the client can render arbitrary event types that they don't know about. So we lose a little bit of richness in the sense that if a client does encounter an unknown event, that they have to figure out how to render that. And it might not render in the same way for everybody, but at least render the same information for everybody. And that's the critical part. So an extensible event looks a little bit like this. This is just a basic text message saying hello world. So if your client supports HTML, it picks the HTML format. If it doesn't support HTML, supports the basic format. But critically, you have a type of m dot message and you have a content block of m dot text. So if we add a little bit more richness to that and create a fake schema for polls that definitely doesn't exist, please see the MSC for a real schema. You have an unknown event type for some clients, namely org matrix poll start. So you still have that text content block. And then you also have this poll content block, which gives you a little bit more information about how to render these events. So if your client knows what that event type is, I can go into the content, pull out the org matrix poll content block, render that in its UI, and then the client can interact with it normally. Otherwise, you end up with just the text and it is suitably okay. It's not great. But you still have the same information from the poll. And so yeah, currently extensible events are JSON. But again, you could make this a binary format in the future. More events get rendered by more clients, which is great. You can create more custom event types. You can do all sorts of fun stuff to be determined exactly what all of this looks like. We're still in the process of specifying all of the pieces, particularly the core content blocks, and also a registry so you can actually implement a client that understands all of these things. So a little bit on room models. The Mimi room model looks like this. So when you add the third server, there's obviously a little bit more complexity. Mimi primarily uses a hub and spoke fan out. So you have one central server per conversation, not for the entire global network, that is responsible for distributing messages. So server B and C try to avoid talking to each other if they absolutely can. And they talk through server A instead. So server A is responsible for sequencing, which is important for MLS. It has those characteristics in play. And then yeah, the follower servers, as they're called, go through that. And encrypted messages still flow between the clients as normal. The servers can't see those messages. So then we have the question of what does linearized matrix look like? It's exactly the same thing, just different objects, which is particularly interesting when it comes to the fact that it was rejected. Because it uses just regular matrix events. It's the same room state. It's the same matrix event stuff. It's a stripped down version of the server to server API because you don't need all the DAG resolution stuff if you don't have a DAG. Also, your DAG is now a linked list. So you don't have any state resolution to do. You have the same authorization rules. You can use the same extensible algorithms for encryption. You can use MLS, double ratchet, your own thing if you're insane enough to do that. And then you have all of the same capabilities of matrix. And you have the history and all of that. But critically, you can support having a DAG capable server in the room. You don't need to give up your decentralization. You can end up with a hub server that basically acts as that linearization algorithm or does linearization algorithm. And it also still persists the events, still distributes them. So when you get into decentralization, namely how matrix works, you use a DAG. You have full mesh fan out where each server contacts every other server instead of going through a central hub. Conflicts of the DAG are used or done through state resolution. So if two people try to do the same thing, somebody has to win. And the good news is state resolution can also be used to linearize the DAG. So through use of a protocol converter, which may or may not be a dual stack server, you can then bring these centralized systems, even linearized matrix into matrix to just further route them. So protocol conversion, they aren't bridges. Bridges somewhat necessar- they're necessarily break the encryption because when you're converting to signal to matrix prior to our existing or to our new interoperability capabilities, you end up decrypting the network on both sides of the bridge and re-encrypting. So you're only really encrypting to the bridge and not beyond it. So protocol converter doesn't decrypt messages. It just converts the envelope format to another format. So that way you can just keep sending your messages. This may also include translating some of the concepts. For matrix, we have two device events, some other protocols, namely Mimi, just send everything over what they call events. So we would have to translate those concepts into the appropriate matrix APIs. Again, you can make this either with an app service or as a dual stack home server. So instead of having a multi-head messenger, you have a multi-head server. And then, yeah, use msc3983 or 3984 to bridge the particular crypto concepts if your server doesn't necessarily support those key formats. So this is what it looks like. You may have recognized it. I stole it from Matthew's slides. So if you have a gatekeeper on the left there, you can do a protocol conversion. And that might be attached to a single server. It runs through matrix. And then you run another protocol conversion to bring it into linearized matrix or Mimi, where you have that hub and spoke, namely that the bottom two servers there aren't talking to each other directly. So those two nodes might be the same physical server, just running dual stack and not doing protocol conversion. But that's all right. So there are a few missing pieces. We haven't talked about anything to do with identity. How do you convert a phone number or a name or an email address into something routable? Who knows? That needs to be defined. We currently have identity servers in matrix. They're a bit centralized. We're hoping that somebody in Mimi can actually solve this problem for us. We also have an interesting idea around consent. Presumably, you don't want to receive spam. So how do you make sure that the person that is messaging you is allowed to message you? We also have anti-abuse. How do you report these messages over federations or over servers? How do you make sure that the servers can implement their own anti-abuse measures using whatever identifiers they can? Mimi also is not necessarily defined the exact identifiers that they want to use. Matrix already has user IDs, room IDs, aliases, that sort of stuff. But who knows? Maybe something different would work. So room metadata. Again, where does the room name go? Who knows? We'll have to figure that out. Matrix state events would probably be fine. Same thing with ordering. MLS requires ordering. There's a discussion around whether or not the clients also need that ordering. So what's next? We have no idea. As Matthew has mentioned, again, I'm just stealing from his slides. So linearized matrix will probably get updated as an MSC because currently the MSC is one version behind from the IETF draft. And the gatekeepers will have to publish their plans by March 7th. We'll see what happens there. The protocol converter concept will continue to be refined, of course. Mimi will also make some form of progress, hopefully get refined as well. And yeah, funding the foundation is the best way to make this work. So, questions. Yes. What are the stakeholders in the Mimi and why are so different stakeholders, like, not using the matrix approach? And what are the different interests here? Yeah, so the question is what are the different stakeholders and why are we going after certain approaches, I believe. So there are several players in the Mimi space. So we have obviously ourselves. We also have wire. There's Google and I'm forgetting all of the other ones, but there's... Yeah, Cisco, Wicker, Phoenix, and a few others. There's a few hundred people in the Mimi working group. You can see their company association as part of the membership list. I would suggest going there. As for the different approaches, everybody wants everybody to use their thing. We're no exception. We just think that ours is better. But yeah, we've been doing this for a while. Matrix was originally built as an interoperable protocol. And here we are with a legal requirement to have interoperability. So, surely Matrix is designed for that, is kind of our thought. We used to rely heavily on canonical JSON to maintain the technicality of the company. How does that translate to the Mimi particular and get the intracorrel? Yeah, so the question is how... Like we've previously relied on canonical JSON. How does that translate to Mimi and just general approaches with interoperability? So, canonical JSON has all sorts of interesting issues with it. What happens if you have multiple keys? What happens if the keys use a weird former of UTF-8? That sort of stuff. It's a very complicated set of rules that can realistically never be fully defined. So with a binary format, namely, that's what Mimi's interested in, you don't necessarily need a canonicalization, because if you keep the signature for the event next to the event, rather than in the event, like we currently have in Matrix, you are able to just sign the series of bytes. And the bytes can be in whatever order. You can deserialize them, see them more easily, and then check the signature much faster. So that's kind of where the Mimi direction is going, is we want to avoid a canonicalization algorithm, but we do need the more specific standard for what's contained in those bytes. This is something to be supported either throughout the chain, yes, we are going to be pushing more towards keeping the, instead of trying to make everybody use the existing matrix thing, I would suggest that matrix kind of adopt more of that binary event signing instead. Yes. You had a slide with things you didn't talk about? Yes. In many places, primarily in the Mimi working group, that's where a lot of these conversations are happening, as well as on the design team for Mimi. But if you are interested in them, or you have ideas, feel free to pop by the Matrix spec room on Matrix, and we'll be happy to engage. Do I have time for one more question? All right. Yes. All right. So how do we avoid, basically if you have two protocol converters, say they're both talking to the same network, how do you avoid message duplication? Good question. We'll have to experiment with it. We will be trying to figure out exactly what that looks like. We kind of have to wait until March 7th to see what the actual gatekeepers, namely WhatsApp and Facebook Messenger, have to offer for that certain capability. Thank you, Travis. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 11.52, "text": " So there may or may not be time for questions. There's a lot of detail. This is a 60 minute", "tokens": [50364, 407, 456, 815, 420, 815, 406, 312, 565, 337, 1651, 13, 821, 311, 257, 688, 295, 2607, 13, 639, 307, 257, 4060, 3456, 50940], "temperature": 0.0, "avg_logprob": -0.20063446044921876, "compression_ratio": 1.5330578512396693, "no_speech_prob": 0.38637346029281616}, {"id": 1, "seek": 0, "start": 11.52, "end": 20.52, "text": " talk compressed down to hopefully 22ish minutes. So we will see how we go. But yeah, I'm here", "tokens": [50940, 751, 30353, 760, 281, 4696, 5853, 742, 2077, 13, 407, 321, 486, 536, 577, 321, 352, 13, 583, 1338, 11, 286, 478, 510, 51390], "temperature": 0.0, "avg_logprob": -0.20063446044921876, "compression_ratio": 1.5330578512396693, "no_speech_prob": 0.38637346029281616}, {"id": 2, "seek": 0, "start": 20.52, "end": 24.88, "text": " to talk about the technical details of interoperability. I'm also Travis. If you don't know me, I'm", "tokens": [51390, 281, 751, 466, 264, 6191, 4365, 295, 728, 7192, 2310, 13, 286, 478, 611, 24430, 13, 759, 291, 500, 380, 458, 385, 11, 286, 478, 51608], "temperature": 0.0, "avg_logprob": -0.20063446044921876, "compression_ratio": 1.5330578512396693, "no_speech_prob": 0.38637346029281616}, {"id": 3, "seek": 0, "start": 24.88, "end": 28.68, "text": " the director for standards development at matrix.org. I'm also on the spec core team.", "tokens": [51608, 264, 5391, 337, 7787, 3250, 412, 8141, 13, 4646, 13, 286, 478, 611, 322, 264, 1608, 4965, 1469, 13, 51798], "temperature": 0.0, "avg_logprob": -0.20063446044921876, "compression_ratio": 1.5330578512396693, "no_speech_prob": 0.38637346029281616}, {"id": 4, "seek": 2868, "start": 28.68, "end": 35.6, "text": " I run T2Bot and I work at element for trust and safety. I have a few jobs. But good news,", "tokens": [50364, 286, 1190, 314, 17, 33, 310, 293, 286, 589, 412, 4478, 337, 3361, 293, 4514, 13, 286, 362, 257, 1326, 4782, 13, 583, 665, 2583, 11, 50710], "temperature": 0.0, "avg_logprob": -0.1551904759855352, "compression_ratio": 1.5625, "no_speech_prob": 0.0933963730931282}, {"id": 5, "seek": 2868, "start": 35.6, "end": 40.519999999999996, "text": " there's already more that we can talk about. So Matthew had the talk this morning. If you", "tokens": [50710, 456, 311, 1217, 544, 300, 321, 393, 751, 466, 13, 407, 12434, 632, 264, 751, 341, 2446, 13, 759, 291, 50956], "temperature": 0.0, "avg_logprob": -0.1551904759855352, "compression_ratio": 1.5625, "no_speech_prob": 0.0933963730931282}, {"id": 6, "seek": 2868, "start": 40.519999999999996, "end": 46.8, "text": " haven't seen that or seen the recap of it about 10 minutes ago, covers DMA and the timelines", "tokens": [50956, 2378, 380, 1612, 300, 420, 1612, 264, 20928, 295, 309, 466, 1266, 2077, 2057, 11, 10538, 413, 9998, 293, 264, 45886, 51270], "temperature": 0.0, "avg_logprob": -0.1551904759855352, "compression_ratio": 1.5625, "no_speech_prob": 0.0933963730931282}, {"id": 7, "seek": 2868, "start": 46.8, "end": 52.6, "text": " in a lot more detail. To recap though, the DMA requires gatekeepers or large messaging", "tokens": [51270, 294, 257, 688, 544, 2607, 13, 1407, 20928, 1673, 11, 264, 413, 9998, 7029, 8539, 43153, 420, 2416, 21812, 51560], "temperature": 0.0, "avg_logprob": -0.1551904759855352, "compression_ratio": 1.5625, "no_speech_prob": 0.0933963730931282}, {"id": 8, "seek": 2868, "start": 52.6, "end": 57.68, "text": " providers to open up their APIs and their systems for interoperability. Encryption must be", "tokens": [51560, 11330, 281, 1269, 493, 641, 21445, 293, 641, 3652, 337, 728, 7192, 2310, 13, 29584, 627, 1695, 1633, 312, 51814], "temperature": 0.0, "avg_logprob": -0.1551904759855352, "compression_ratio": 1.5625, "no_speech_prob": 0.0933963730931282}, {"id": 9, "seek": 5768, "start": 57.68, "end": 63.64, "text": " maintained between those providers. So you cannot break encryption for the sake of interoperating.", "tokens": [50364, 17578, 1296, 729, 11330, 13, 407, 291, 2644, 1821, 29575, 337, 264, 9717, 295, 728, 7192, 990, 13, 50662], "temperature": 0.0, "avg_logprob": -0.17673443991040427, "compression_ratio": 1.6772151898734178, "no_speech_prob": 0.17686614394187927}, {"id": 10, "seek": 5768, "start": 63.64, "end": 67.68, "text": " You have to maintain it. These messengers have three options. You can become multi-headed", "tokens": [50662, 509, 362, 281, 6909, 309, 13, 1981, 2082, 15315, 362, 1045, 3956, 13, 509, 393, 1813, 4825, 12, 28409, 50864], "temperature": 0.0, "avg_logprob": -0.17673443991040427, "compression_ratio": 1.6772151898734178, "no_speech_prob": 0.17686614394187927}, {"id": 11, "seek": 5768, "start": 67.68, "end": 72.24, "text": " similar to Beeper Mini where you have all the networks available in your one client.", "tokens": [50864, 2531, 281, 879, 595, 260, 18239, 689, 291, 362, 439, 264, 9590, 2435, 294, 428, 472, 6423, 13, 51092], "temperature": 0.0, "avg_logprob": -0.17673443991040427, "compression_ratio": 1.6772151898734178, "no_speech_prob": 0.17686614394187927}, {"id": 12, "seek": 5768, "start": 72.24, "end": 75.96000000000001, "text": " And you just kind of switch between them. You can create a bridge app where the user", "tokens": [51092, 400, 291, 445, 733, 295, 3679, 1296, 552, 13, 509, 393, 1884, 257, 7283, 724, 689, 264, 4195, 51278], "temperature": 0.0, "avg_logprob": -0.17673443991040427, "compression_ratio": 1.6772151898734178, "no_speech_prob": 0.17686614394187927}, {"id": 13, "seek": 5768, "start": 75.96000000000001, "end": 80.44, "text": " downloads a third thing and then you bridge locally on the device. That works. It's not", "tokens": [51278, 36553, 257, 2636, 551, 293, 550, 291, 7283, 16143, 322, 264, 4302, 13, 663, 1985, 13, 467, 311, 406, 51502], "temperature": 0.0, "avg_logprob": -0.17673443991040427, "compression_ratio": 1.6772151898734178, "no_speech_prob": 0.17686614394187927}, {"id": 14, "seek": 5768, "start": 80.44, "end": 86.84, "text": " great. Or you can speak a common protocol. We've been doing that for the last year.", "tokens": [51502, 869, 13, 1610, 291, 393, 1710, 257, 2689, 10336, 13, 492, 600, 668, 884, 300, 337, 264, 1036, 1064, 13, 51822], "temperature": 0.0, "avg_logprob": -0.17673443991040427, "compression_ratio": 1.6772151898734178, "no_speech_prob": 0.17686614394187927}, {"id": 15, "seek": 8684, "start": 87.84, "end": 95.16, "text": " Probably longer. And oh yeah, they have to do this all by March 7th this year. So with", "tokens": [50414, 9210, 2854, 13, 400, 1954, 1338, 11, 436, 362, 281, 360, 341, 439, 538, 6129, 1614, 392, 341, 1064, 13, 407, 365, 50780], "temperature": 0.0, "avg_logprob": -0.16654719625200545, "compression_ratio": 1.589928057553957, "no_speech_prob": 0.011891168542206287}, {"id": 16, "seek": 8684, "start": 95.16, "end": 99.96000000000001, "text": " that in mind, there are many projects involved as well. There is the more instant messaging,", "tokens": [50780, 300, 294, 1575, 11, 456, 366, 867, 4455, 3288, 382, 731, 13, 821, 307, 264, 544, 9836, 21812, 11, 51020], "temperature": 0.0, "avg_logprob": -0.16654719625200545, "compression_ratio": 1.589928057553957, "no_speech_prob": 0.011891168542206287}, {"id": 17, "seek": 8684, "start": 99.96000000000001, "end": 105.0, "text": " interoperability working group or MIMI at the IETF. They are trying to specify a standard", "tokens": [51020, 728, 7192, 2310, 1364, 1594, 420, 376, 6324, 40, 412, 264, 286, 4850, 37, 13, 814, 366, 1382, 281, 16500, 257, 3832, 51272], "temperature": 0.0, "avg_logprob": -0.16654719625200545, "compression_ratio": 1.589928057553957, "no_speech_prob": 0.011891168542206287}, {"id": 18, "seek": 8684, "start": 105.0, "end": 111.36, "text": " that does this stuff. We are very frequent there. We are a direct contributor to this.", "tokens": [51272, 300, 775, 341, 1507, 13, 492, 366, 588, 18004, 456, 13, 492, 366, 257, 2047, 42859, 281, 341, 13, 51590], "temperature": 0.0, "avg_logprob": -0.16654719625200545, "compression_ratio": 1.589928057553957, "no_speech_prob": 0.011891168542206287}, {"id": 19, "seek": 8684, "start": 111.36, "end": 116.82000000000001, "text": " I have written a MIMI protocol document in association with a few other people on the", "tokens": [51590, 286, 362, 3720, 257, 376, 6324, 40, 10336, 4166, 294, 14598, 365, 257, 1326, 661, 561, 322, 264, 51863], "temperature": 0.0, "avg_logprob": -0.16654719625200545, "compression_ratio": 1.589928057553957, "no_speech_prob": 0.011891168542206287}, {"id": 20, "seek": 11682, "start": 116.82, "end": 122.46, "text": " design team to try and simplify a lot of the components, particularly what linearized matrix", "tokens": [50364, 1715, 1469, 281, 853, 293, 20460, 257, 688, 295, 264, 6677, 11, 4098, 437, 8213, 1602, 8141, 50646], "temperature": 0.0, "avg_logprob": -0.1788155198097229, "compression_ratio": 1.605263157894737, "no_speech_prob": 0.002674211747944355}, {"id": 21, "seek": 11682, "start": 122.46, "end": 128.01999999999998, "text": " is. Also, linearized matrix was originally created as this simplified version of matrix", "tokens": [50646, 307, 13, 2743, 11, 8213, 1602, 8141, 390, 7993, 2942, 382, 341, 26335, 3037, 295, 8141, 50924], "temperature": 0.0, "avg_logprob": -0.1788155198097229, "compression_ratio": 1.605263157894737, "no_speech_prob": 0.002674211747944355}, {"id": 22, "seek": 11682, "start": 128.01999999999998, "end": 135.78, "text": " because it turns out that you don't necessarily need a ton of the fully compatible DAG stuff", "tokens": [50924, 570, 309, 4523, 484, 300, 291, 500, 380, 4725, 643, 257, 2952, 295, 264, 4498, 18218, 9578, 38, 1507, 51312], "temperature": 0.0, "avg_logprob": -0.1788155198097229, "compression_ratio": 1.605263157894737, "no_speech_prob": 0.002674211747944355}, {"id": 23, "seek": 11682, "start": 135.78, "end": 142.29999999999998, "text": " or even messaging history for interoperability. A lot of the existing providers just kind of", "tokens": [51312, 420, 754, 21812, 2503, 337, 728, 7192, 2310, 13, 316, 688, 295, 264, 6741, 11330, 445, 733, 295, 51638], "temperature": 0.0, "avg_logprob": -0.1788155198097229, "compression_ratio": 1.605263157894737, "no_speech_prob": 0.002674211747944355}, {"id": 24, "seek": 14230, "start": 142.38000000000002, "end": 147.58, "text": " want to throw messages around the place. They don't necessarily want to just kind of keep", "tokens": [50368, 528, 281, 3507, 7897, 926, 264, 1081, 13, 814, 500, 380, 4725, 528, 281, 445, 733, 295, 1066, 50628], "temperature": 0.0, "avg_logprob": -0.16364652301193378, "compression_ratio": 1.648936170212766, "no_speech_prob": 0.024129856377840042}, {"id": 25, "seek": 14230, "start": 147.58, "end": 151.9, "text": " these things around. Obviously, of course, we have matrix. Hopefully, everybody here is familiar", "tokens": [50628, 613, 721, 926, 13, 7580, 11, 295, 1164, 11, 321, 362, 8141, 13, 10429, 11, 2201, 510, 307, 4963, 50844], "temperature": 0.0, "avg_logprob": -0.16364652301193378, "compression_ratio": 1.648936170212766, "no_speech_prob": 0.024129856377840042}, {"id": 26, "seek": 14230, "start": 151.9, "end": 158.42000000000002, "text": " with that. But it is the decentralized and fully featured version of an interoperable protocol.", "tokens": [50844, 365, 300, 13, 583, 309, 307, 264, 32870, 293, 4498, 13822, 3037, 295, 364, 728, 7192, 712, 10336, 13, 51170], "temperature": 0.0, "avg_logprob": -0.16364652301193378, "compression_ratio": 1.648936170212766, "no_speech_prob": 0.024129856377840042}, {"id": 27, "seek": 14230, "start": 160.42000000000002, "end": 166.5, "text": " What parts of interoperability do we have to worry about? A few. There is encryption. This", "tokens": [51270, 708, 3166, 295, 728, 7192, 2310, 360, 321, 362, 281, 3292, 466, 30, 316, 1326, 13, 821, 307, 29575, 13, 639, 51574], "temperature": 0.0, "avg_logprob": -0.16364652301193378, "compression_ratio": 1.648936170212766, "no_speech_prob": 0.024129856377840042}, {"id": 28, "seek": 14230, "start": 166.5, "end": 170.58, "text": " kind of fits into a weird L shape. You have content format within that. But the encryption,", "tokens": [51574, 733, 295, 9001, 666, 257, 3657, 441, 3909, 13, 509, 362, 2701, 7877, 1951, 300, 13, 583, 264, 29575, 11, 51778], "temperature": 0.0, "avg_logprob": -0.16364652301193378, "compression_ratio": 1.648936170212766, "no_speech_prob": 0.024129856377840042}, {"id": 29, "seek": 17058, "start": 170.78, "end": 174.38000000000002, "text": " we have to make sure that all the messages are secure. We have to make sure that everything is", "tokens": [50374, 321, 362, 281, 652, 988, 300, 439, 264, 7897, 366, 7144, 13, 492, 362, 281, 652, 988, 300, 1203, 307, 50554], "temperature": 0.0, "avg_logprob": -0.1617173899774966, "compression_ratio": 1.927710843373494, "no_speech_prob": 0.0050967419520020485}, {"id": 30, "seek": 17058, "start": 174.38000000000002, "end": 179.18, "text": " the same. Of course, we have to make sure that it is consistent across the providers. The content", "tokens": [50554, 264, 912, 13, 2720, 1164, 11, 321, 362, 281, 652, 988, 300, 309, 307, 8398, 2108, 264, 11330, 13, 440, 2701, 50794], "temperature": 0.0, "avg_logprob": -0.1617173899774966, "compression_ratio": 1.927710843373494, "no_speech_prob": 0.0050967419520020485}, {"id": 31, "seek": 17058, "start": 179.18, "end": 184.46, "text": " format, what do messages actually look like? We have to make sure that that is the same because", "tokens": [50794, 7877, 11, 437, 360, 7897, 767, 574, 411, 30, 492, 362, 281, 652, 988, 300, 300, 307, 264, 912, 570, 51058], "temperature": 0.0, "avg_logprob": -0.1617173899774966, "compression_ratio": 1.927710843373494, "no_speech_prob": 0.0050967419520020485}, {"id": 32, "seek": 17058, "start": 184.46, "end": 189.34, "text": " the servers can't help us here. The clients have to agree on this. That is more of a challenge.", "tokens": [51058, 264, 15909, 393, 380, 854, 505, 510, 13, 440, 6982, 362, 281, 3986, 322, 341, 13, 663, 307, 544, 295, 257, 3430, 13, 51302], "temperature": 0.0, "avg_logprob": -0.1617173899774966, "compression_ratio": 1.927710843373494, "no_speech_prob": 0.0050967419520020485}, {"id": 33, "seek": 17058, "start": 189.34, "end": 194.9, "text": " We also need an authorization policy so people can be banned because they need to. Then we also", "tokens": [51302, 492, 611, 643, 364, 33697, 3897, 370, 561, 393, 312, 19564, 570, 436, 643, 281, 13, 1396, 321, 611, 51580], "temperature": 0.0, "avg_logprob": -0.1617173899774966, "compression_ratio": 1.927710843373494, "no_speech_prob": 0.0050967419520020485}, {"id": 34, "seek": 19490, "start": 195.02, "end": 201.22, "text": " have messages that people might not be allowed to send in certain rooms. Of course, we also have", "tokens": [50370, 362, 7897, 300, 561, 1062, 406, 312, 4350, 281, 2845, 294, 1629, 9396, 13, 2720, 1164, 11, 321, 611, 362, 50680], "temperature": 0.0, "avg_logprob": -0.12775102853775025, "compression_ratio": 1.6888888888888889, "no_speech_prob": 0.035010926425457}, {"id": 35, "seek": 19490, "start": 201.22, "end": 207.94, "text": " transport. The transport is just how the servers communicate because we have a room model that", "tokens": [50680, 5495, 13, 440, 5495, 307, 445, 577, 264, 15909, 7890, 570, 321, 362, 257, 1808, 2316, 300, 51016], "temperature": 0.0, "avg_logprob": -0.12775102853775025, "compression_ratio": 1.6888888888888889, "no_speech_prob": 0.035010926425457}, {"id": 36, "seek": 19490, "start": 207.94, "end": 213.58, "text": " looks something like this. The room model is a combination of the encryption authorization", "tokens": [51016, 1542, 746, 411, 341, 13, 440, 1808, 2316, 307, 257, 6562, 295, 264, 29575, 33697, 51298], "temperature": 0.0, "avg_logprob": -0.12775102853775025, "compression_ratio": 1.6888888888888889, "no_speech_prob": 0.035010926425457}, {"id": 37, "seek": 19490, "start": 213.58, "end": 220.38, "text": " policy and transport. We also have a definition of membership or participation, a little bit more", "tokens": [51298, 3897, 293, 5495, 13, 492, 611, 362, 257, 7123, 295, 16560, 420, 13487, 11, 257, 707, 857, 544, 51638], "temperature": 0.0, "avg_logprob": -0.12775102853775025, "compression_ratio": 1.6888888888888889, "no_speech_prob": 0.035010926425457}, {"id": 38, "seek": 22038, "start": 220.46, "end": 226.22, "text": " on that in a minute. And also how the messages are found out themselves. In the very simplest", "tokens": [50368, 322, 300, 294, 257, 3456, 13, 400, 611, 577, 264, 7897, 366, 1352, 484, 2969, 13, 682, 264, 588, 22811, 50656], "temperature": 0.0, "avg_logprob": -0.18329548281292582, "compression_ratio": 1.6118143459915613, "no_speech_prob": 0.016058072447776794}, {"id": 39, "seek": 22038, "start": 226.22, "end": 230.46, "text": " scenario, we have clients talking to servers, servers talking to each other, and encrypted", "tokens": [50656, 9005, 11, 321, 362, 6982, 1417, 281, 15909, 11, 15909, 1417, 281, 1184, 661, 11, 293, 36663, 50868], "temperature": 0.0, "avg_logprob": -0.18329548281292582, "compression_ratio": 1.6118143459915613, "no_speech_prob": 0.016058072447776794}, {"id": 40, "seek": 22038, "start": 230.46, "end": 235.85999999999999, "text": " messages flowing between clients effectively. It gets more complicated when you add a third server,", "tokens": [50868, 7897, 13974, 1296, 6982, 8659, 13, 467, 2170, 544, 6179, 562, 291, 909, 257, 2636, 7154, 11, 51138], "temperature": 0.0, "avg_logprob": -0.18329548281292582, "compression_ratio": 1.6118143459915613, "no_speech_prob": 0.016058072447776794}, {"id": 41, "seek": 22038, "start": 235.85999999999999, "end": 242.7, "text": " so we will do that later. Some of these problems are easier than others. Namely, transport. Super", "tokens": [51138, 370, 321, 486, 360, 300, 1780, 13, 2188, 295, 613, 2740, 366, 3571, 813, 2357, 13, 10684, 736, 11, 5495, 13, 4548, 51480], "temperature": 0.0, "avg_logprob": -0.18329548281292582, "compression_ratio": 1.6118143459915613, "no_speech_prob": 0.016058072447776794}, {"id": 42, "seek": 24270, "start": 242.78, "end": 250.78, "text": " easy to solve. Pretty much everybody uses some form of HTTPS. Mimi wants to use MTLS. Linearized", "tokens": [50368, 1858, 281, 5039, 13, 10693, 709, 2201, 4960, 512, 1254, 295, 11751, 51, 6273, 13, 46709, 2738, 281, 764, 37333, 19198, 13, 14670, 289, 1602, 50768], "temperature": 0.0, "avg_logprob": -0.1998040307428419, "compression_ratio": 1.6495726495726495, "no_speech_prob": 0.5048307776451111}, {"id": 43, "seek": 24270, "start": 250.78, "end": 255.7, "text": " Matrix uses the same system that Matrix already does where you have a signed or a signing key that", "tokens": [50768, 36274, 4960, 264, 912, 1185, 300, 36274, 1217, 775, 689, 291, 362, 257, 8175, 420, 257, 13393, 2141, 300, 51014], "temperature": 0.0, "avg_logprob": -0.1998040307428419, "compression_ratio": 1.6495726495726495, "no_speech_prob": 0.5048307776451111}, {"id": 44, "seek": 24270, "start": 255.7, "end": 262.26, "text": " kind of gets thrown around a bit. It is unclear what the actual format over HTTP would be. Matrix", "tokens": [51014, 733, 295, 2170, 11732, 926, 257, 857, 13, 467, 307, 25636, 437, 264, 3539, 7877, 670, 33283, 576, 312, 13, 36274, 51342], "temperature": 0.0, "avg_logprob": -0.1998040307428419, "compression_ratio": 1.6495726495726495, "no_speech_prob": 0.5048307776451111}, {"id": 45, "seek": 24270, "start": 262.26, "end": 268.53999999999996, "text": " uses JSON. Mimi wants to use some form of binary. Unclear what that actually is. We are also", "tokens": [51342, 4960, 31828, 13, 46709, 2738, 281, 764, 512, 1254, 295, 17434, 13, 1156, 43679, 437, 300, 767, 307, 13, 492, 366, 611, 51656], "temperature": 0.0, "avg_logprob": -0.1998040307428419, "compression_ratio": 1.6495726495726495, "no_speech_prob": 0.5048307776451111}, {"id": 46, "seek": 26854, "start": 268.58000000000004, "end": 273.54, "text": " considering a binary event format specifically for this kind of thing. Protobuf and Seabor are", "tokens": [50366, 8079, 257, 17434, 2280, 7877, 4682, 337, 341, 733, 295, 551, 13, 10019, 996, 2947, 293, 1100, 3816, 366, 50614], "temperature": 0.0, "avg_logprob": -0.2107861258766868, "compression_ratio": 1.674911660777385, "no_speech_prob": 0.014914467930793762}, {"id": 47, "seek": 26854, "start": 273.54, "end": 281.22, "text": " kind of on the top. But to be determined, clients would not be expected to consume that binary", "tokens": [50614, 733, 295, 322, 264, 1192, 13, 583, 281, 312, 9540, 11, 6982, 576, 406, 312, 5176, 281, 14732, 300, 17434, 50998], "temperature": 0.0, "avg_logprob": -0.2107861258766868, "compression_ratio": 1.674911660777385, "no_speech_prob": 0.014914467930793762}, {"id": 48, "seek": 26854, "start": 281.22, "end": 288.54, "text": " format yet. I should probably just add that in. But yeah, we will end up using some sort of binary", "tokens": [50998, 7877, 1939, 13, 286, 820, 1391, 445, 909, 300, 294, 13, 583, 1338, 11, 321, 486, 917, 493, 1228, 512, 1333, 295, 17434, 51364], "temperature": 0.0, "avg_logprob": -0.2107861258766868, "compression_ratio": 1.674911660777385, "no_speech_prob": 0.014914467930793762}, {"id": 49, "seek": 26854, "start": 288.54, "end": 294.14000000000004, "text": " over HTTPS mechanism authorization exactly to be determined later. The other easy thing is", "tokens": [51364, 670, 11751, 51, 6273, 7513, 33697, 2293, 281, 312, 9540, 1780, 13, 440, 661, 1858, 551, 307, 51644], "temperature": 0.0, "avg_logprob": -0.2107861258766868, "compression_ratio": 1.674911660777385, "no_speech_prob": 0.014914467930793762}, {"id": 50, "seek": 26854, "start": 294.14000000000004, "end": 298.22, "text": " authorization policy. Mimi does not define one. We have been working without one. We have just", "tokens": [51644, 33697, 3897, 13, 46709, 775, 406, 6964, 472, 13, 492, 362, 668, 1364, 1553, 472, 13, 492, 362, 445, 51848], "temperature": 0.0, "avg_logprob": -0.2107861258766868, "compression_ratio": 1.674911660777385, "no_speech_prob": 0.014914467930793762}, {"id": 51, "seek": 29822, "start": 298.3, "end": 304.34000000000003, "text": " been assuming that people are able to send messages. Matrix obviously has one. Role-based access", "tokens": [50368, 668, 11926, 300, 561, 366, 1075, 281, 2845, 7897, 13, 36274, 2745, 575, 472, 13, 3101, 306, 12, 6032, 2105, 50670], "temperature": 0.0, "avg_logprob": -0.20798460642496744, "compression_ratio": 1.4698795180722892, "no_speech_prob": 0.004223288036882877}, {"id": 52, "seek": 29822, "start": 304.34000000000003, "end": 311.70000000000005, "text": " control is super popular amongst a lot of these discussions. There is those two MSCs there.", "tokens": [50670, 1969, 307, 1687, 3743, 12918, 257, 688, 295, 613, 11088, 13, 821, 307, 729, 732, 7395, 33290, 456, 13, 51038], "temperature": 0.0, "avg_logprob": -0.20798460642496744, "compression_ratio": 1.4698795180722892, "no_speech_prob": 0.004223288036882877}, {"id": 53, "seek": 29822, "start": 311.70000000000005, "end": 319.34000000000003, "text": " 4056 covers the decentralization part of RBAC. Then you also have 2812 where it basically", "tokens": [51038, 3356, 18317, 10538, 264, 26515, 2144, 644, 295, 40302, 4378, 13, 1396, 291, 611, 362, 7562, 4762, 689, 309, 1936, 51420], "temperature": 0.0, "avg_logprob": -0.20798460642496744, "compression_ratio": 1.4698795180722892, "no_speech_prob": 0.004223288036882877}, {"id": 54, "seek": 29822, "start": 319.34000000000003, "end": 326.5, "text": " rolls as state events. It is an early form of RBAC. Linearized Matrix uses the existing", "tokens": [51420, 15767, 382, 1785, 3931, 13, 467, 307, 364, 2440, 1254, 295, 40302, 4378, 13, 14670, 289, 1602, 36274, 4960, 264, 6741, 51778], "temperature": 0.0, "avg_logprob": -0.20798460642496744, "compression_ratio": 1.4698795180722892, "no_speech_prob": 0.004223288036882877}, {"id": 55, "seek": 32650, "start": 327.26, "end": 332.3, "text": " authorization rules. Matrix authorization rules clearly already work. People have been using them", "tokens": [50402, 33697, 4474, 13, 36274, 33697, 4474, 4448, 1217, 589, 13, 3432, 362, 668, 1228, 552, 50654], "temperature": 0.0, "avg_logprob": -0.2187057688266416, "compression_ratio": 1.592274678111588, "no_speech_prob": 0.0039311060681939125}, {"id": 56, "seek": 32650, "start": 332.3, "end": 337.98, "text": " for almost a decade now. They should be fined. We will figure out what Mimi ends up with", "tokens": [50654, 337, 1920, 257, 10378, 586, 13, 814, 820, 312, 962, 292, 13, 492, 486, 2573, 484, 437, 46709, 5314, 493, 365, 50938], "temperature": 0.0, "avg_logprob": -0.2187057688266416, "compression_ratio": 1.592274678111588, "no_speech_prob": 0.0039311060681939125}, {"id": 57, "seek": 32650, "start": 337.98, "end": 344.94, "text": " eventually, hopefully. The harder parts are encryption. Most messaging providers use lib", "tokens": [50938, 4728, 11, 4696, 13, 440, 6081, 3166, 366, 29575, 13, 4534, 21812, 11330, 764, 22854, 51286], "temperature": 0.0, "avg_logprob": -0.2187057688266416, "compression_ratio": 1.592274678111588, "no_speech_prob": 0.0039311060681939125}, {"id": 58, "seek": 32650, "start": 344.94, "end": 351.58, "text": " signal or something that is a double ratchet. We also have a double ratchet-like implementation", "tokens": [51286, 6358, 420, 746, 300, 307, 257, 3834, 45885, 13, 492, 611, 362, 257, 3834, 45885, 12, 4092, 11420, 51618], "temperature": 0.0, "avg_logprob": -0.2187057688266416, "compression_ratio": 1.592274678111588, "no_speech_prob": 0.0039311060681939125}, {"id": 59, "seek": 35158, "start": 351.62, "end": 361.06, "text": " called OM. It was not previously interoperable with lib signal up until about 2 a.m. tonight. We", "tokens": [50366, 1219, 16954, 13, 467, 390, 406, 8046, 728, 7192, 712, 365, 22854, 6358, 493, 1826, 466, 568, 257, 13, 76, 13, 4440, 13, 492, 50838], "temperature": 0.0, "avg_logprob": -0.3007002416646706, "compression_ratio": 1.589430894308943, "no_speech_prob": 0.05622173845767975}, {"id": 60, "seek": 35158, "start": 361.06, "end": 365.58, "text": " now have inter-OM, which has that X3DH support as well as some of the other delts you need to be", "tokens": [50838, 586, 362, 728, 12, 5251, 11, 597, 575, 300, 1783, 18, 35, 39, 1406, 382, 731, 382, 512, 295, 264, 661, 1103, 1373, 291, 643, 281, 312, 51064], "temperature": 0.0, "avg_logprob": -0.3007002416646706, "compression_ratio": 1.589430894308943, "no_speech_prob": 0.05622173845767975}, {"id": 61, "seek": 35158, "start": 365.58, "end": 370.78, "text": " able to support that sort of interoperability. Megalom is what we use in group chats to try and", "tokens": [51064, 1075, 281, 1406, 300, 1333, 295, 728, 7192, 2310, 13, 9986, 304, 298, 307, 437, 321, 764, 294, 1594, 38057, 281, 853, 293, 51324], "temperature": 0.0, "avg_logprob": -0.3007002416646706, "compression_ratio": 1.589430894308943, "no_speech_prob": 0.05622173845767975}, {"id": 62, "seek": 35158, "start": 370.78, "end": 376.7, "text": " alleviate the load. Otherwise, with OM, you have to send a number of events for the number of devices", "tokens": [51324, 42701, 264, 3677, 13, 10328, 11, 365, 16954, 11, 291, 362, 281, 2845, 257, 1230, 295, 3931, 337, 264, 1230, 295, 5759, 51620], "temperature": 0.0, "avg_logprob": -0.3007002416646706, "compression_ratio": 1.589430894308943, "no_speech_prob": 0.05622173845767975}, {"id": 63, "seek": 37670, "start": 376.78, "end": 382.26, "text": " in the room, which obviously causes problems when you have multiple devices per user or multiple", "tokens": [50368, 294, 264, 1808, 11, 597, 2745, 7700, 2740, 562, 291, 362, 3866, 5759, 680, 4195, 420, 3866, 50642], "temperature": 0.0, "avg_logprob": -0.11273197597927517, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.12713459134101868}, {"id": 64, "seek": 37670, "start": 382.26, "end": 391.06, "text": " users in a room. Matrix HQ would be a nightmare. The double ratchet does rely on existing", "tokens": [50642, 5022, 294, 257, 1808, 13, 36274, 43209, 576, 312, 257, 18724, 13, 440, 3834, 45885, 775, 10687, 322, 6741, 51082], "temperature": 0.0, "avg_logprob": -0.11273197597927517, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.12713459134101868}, {"id": 65, "seek": 37670, "start": 391.06, "end": 397.86, "text": " infrastructure in order to send keys. It has no concept of membership. It does not know who to", "tokens": [51082, 6896, 294, 1668, 281, 2845, 9317, 13, 467, 575, 572, 3410, 295, 16560, 13, 467, 775, 406, 458, 567, 281, 51422], "temperature": 0.0, "avg_logprob": -0.11273197597927517, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.12713459134101868}, {"id": 66, "seek": 37670, "start": 397.86, "end": 403.74, "text": " send the keys to on its own. You have to tell it who to encrypt to and then also send those keys", "tokens": [51422, 2845, 264, 9317, 281, 322, 1080, 1065, 13, 509, 362, 281, 980, 309, 567, 281, 17972, 662, 281, 293, 550, 611, 2845, 729, 9317, 51716], "temperature": 0.0, "avg_logprob": -0.11273197597927517, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.12713459134101868}, {"id": 67, "seek": 40374, "start": 403.82, "end": 409.5, "text": " yourself. Some messaging providers, namely Google, have announced that they will be using MLS. We", "tokens": [50368, 1803, 13, 2188, 21812, 11330, 11, 20926, 3329, 11, 362, 7548, 300, 436, 486, 312, 1228, 376, 19198, 13, 492, 50652], "temperature": 0.0, "avg_logprob": -0.24045271139878494, "compression_ratio": 1.536, "no_speech_prob": 0.12551912665367126}, {"id": 68, "seek": 40374, "start": 409.5, "end": 416.06, "text": " also obviously want to use MLS. REMLST.com is where we're tracking that progress. MLS does have", "tokens": [50652, 611, 2745, 528, 281, 764, 376, 19198, 13, 497, 6683, 43, 6840, 13, 1112, 307, 689, 321, 434, 11603, 300, 4205, 13, 376, 19198, 775, 362, 50980], "temperature": 0.0, "avg_logprob": -0.24045271139878494, "compression_ratio": 1.536, "no_speech_prob": 0.12551912665367126}, {"id": 69, "seek": 40374, "start": 416.06, "end": 421.86, "text": " a concept of built-in membership, so it does know who it needs to send messages to. It obviously", "tokens": [50980, 257, 3410, 295, 3094, 12, 259, 16560, 11, 370, 309, 775, 458, 567, 309, 2203, 281, 2845, 7897, 281, 13, 467, 2745, 51270], "temperature": 0.0, "avg_logprob": -0.24045271139878494, "compression_ratio": 1.536, "no_speech_prob": 0.12551912665367126}, {"id": 70, "seek": 40374, "start": 421.86, "end": 429.98, "text": " doesn't send the messages itself, but more on that in a second, namely this slide. RFC 942.0,", "tokens": [51270, 1177, 380, 2845, 264, 7897, 2564, 11, 457, 544, 322, 300, 294, 257, 1150, 11, 20926, 341, 4137, 13, 497, 18671, 1722, 15628, 13, 15, 11, 51676], "temperature": 0.0, "avg_logprob": -0.24045271139878494, "compression_ratio": 1.536, "no_speech_prob": 0.12551912665367126}, {"id": 71, "seek": 42998, "start": 430.06, "end": 436.62, "text": " that is where the IETF has specified this. I have a really awful crash course guide because I am not", "tokens": [50368, 300, 307, 689, 264, 286, 4850, 37, 575, 22206, 341, 13, 286, 362, 257, 534, 11232, 8252, 1164, 5934, 570, 286, 669, 406, 50696], "temperature": 0.0, "avg_logprob": -0.14503747304280598, "compression_ratio": 1.528497409326425, "no_speech_prob": 0.022740939632058144}, {"id": 72, "seek": 42998, "start": 436.62, "end": 445.82, "text": " a cryptographer, but there it is. But yeah, there is a binary tree, so you have a root key and you", "tokens": [50696, 257, 9844, 13624, 11, 457, 456, 309, 307, 13, 583, 1338, 11, 456, 307, 257, 17434, 4230, 11, 370, 291, 362, 257, 5593, 2141, 293, 291, 51156], "temperature": 0.0, "avg_logprob": -0.14503747304280598, "compression_ratio": 1.528497409326425, "no_speech_prob": 0.022740939632058144}, {"id": 73, "seek": 42998, "start": 445.82, "end": 455.74, "text": " have multiple nodes underneath that. With that concept, you end up with a concept of membership", "tokens": [51156, 362, 3866, 13891, 7223, 300, 13, 2022, 300, 3410, 11, 291, 917, 493, 365, 257, 3410, 295, 16560, 51652], "temperature": 0.0, "avg_logprob": -0.14503747304280598, "compression_ratio": 1.528497409326425, "no_speech_prob": 0.022740939632058144}, {"id": 74, "seek": 45574, "start": 455.82, "end": 463.98, "text": " where only users or members that have certain keys can see other keys. That is how you get to", "tokens": [50368, 689, 787, 5022, 420, 2679, 300, 362, 1629, 9317, 393, 536, 661, 9317, 13, 663, 307, 577, 291, 483, 281, 50776], "temperature": 0.0, "avg_logprob": -0.12215020579676475, "compression_ratio": 1.5630252100840336, "no_speech_prob": 0.003908833488821983}, {"id": 75, "seek": 45574, "start": 463.98, "end": 470.7, "text": " know who to send the keys to, particularly the decryption keys. Mimi has refused to implement", "tokens": [50776, 458, 567, 281, 2845, 264, 9317, 281, 11, 4098, 264, 979, 627, 1695, 9317, 13, 46709, 575, 14654, 281, 4445, 51112], "temperature": 0.0, "avg_logprob": -0.12215020579676475, "compression_ratio": 1.5630252100840336, "no_speech_prob": 0.003908833488821983}, {"id": 76, "seek": 45574, "start": 470.7, "end": 476.22, "text": " any other encryption other than MLS. They are obviously considering it as part of double", "tokens": [51112, 604, 661, 29575, 661, 813, 376, 19198, 13, 814, 366, 2745, 8079, 309, 382, 644, 295, 3834, 51388], "temperature": 0.0, "avg_logprob": -0.12215020579676475, "compression_ratio": 1.5630252100840336, "no_speech_prob": 0.003908833488821983}, {"id": 77, "seek": 45574, "start": 476.22, "end": 483.58, "text": " ratchet because we do need an onramp. But with the IETF, they tend to get a little bit stuck in", "tokens": [51388, 45885, 570, 321, 360, 643, 364, 322, 81, 1215, 13, 583, 365, 264, 286, 4850, 37, 11, 436, 3928, 281, 483, 257, 707, 857, 5541, 294, 51756], "temperature": 0.0, "avg_logprob": -0.12215020579676475, "compression_ratio": 1.5630252100840336, "no_speech_prob": 0.003908833488821983}, {"id": 78, "seek": 48358, "start": 483.97999999999996, "end": 491.82, "text": " the RFCs. We are also considering MLS, obviously, and so we want to extend it. Decentralized", "tokens": [50384, 264, 497, 18671, 82, 13, 492, 366, 611, 8079, 376, 19198, 11, 2745, 11, 293, 370, 321, 528, 281, 10101, 309, 13, 1346, 2207, 2155, 1602, 50776], "temperature": 0.0, "avg_logprob": -0.13643239406829186, "compression_ratio": 1.5040322580645162, "no_speech_prob": 0.00277593987993896}, {"id": 79, "seek": 48358, "start": 491.82, "end": 499.65999999999997, "text": " environments, namely matrix, will have to use DMLS or similar. Membership. As part of the", "tokens": [50776, 12388, 11, 20926, 8141, 11, 486, 362, 281, 764, 413, 12683, 50, 420, 2531, 13, 21495, 1210, 13, 1018, 644, 295, 264, 51168], "temperature": 0.0, "avg_logprob": -0.13643239406829186, "compression_ratio": 1.5040322580645162, "no_speech_prob": 0.00277593987993896}, {"id": 80, "seek": 48358, "start": 499.65999999999997, "end": 504.62, "text": " discussions with Mimi, we have been having some arguments, we will say, about what it actually", "tokens": [51168, 11088, 365, 46709, 11, 321, 362, 668, 1419, 512, 12869, 11, 321, 486, 584, 11, 466, 437, 309, 767, 51416], "temperature": 0.0, "avg_logprob": -0.13643239406829186, "compression_ratio": 1.5040322580645162, "no_speech_prob": 0.00277593987993896}, {"id": 81, "seek": 48358, "start": 504.62, "end": 512.22, "text": " means to define membership. We have decided that users join rooms and clients encrypt messages.", "tokens": [51416, 1355, 281, 6964, 16560, 13, 492, 362, 3047, 300, 5022, 3917, 9396, 293, 6982, 17972, 662, 7897, 13, 51796], "temperature": 0.0, "avg_logprob": -0.13643239406829186, "compression_ratio": 1.5040322580645162, "no_speech_prob": 0.00277593987993896}, {"id": 82, "seek": 51358, "start": 514.5400000000001, "end": 520.94, "text": " Both MLS and double ratchet deal with clients. When a user joins the room, all of their clients", "tokens": [50412, 6767, 376, 19198, 293, 3834, 45885, 2028, 365, 6982, 13, 1133, 257, 4195, 24397, 264, 1808, 11, 439, 295, 641, 6982, 50732], "temperature": 0.0, "avg_logprob": -0.14509839071354397, "compression_ratio": 1.4791666666666667, "no_speech_prob": 0.004581477493047714}, {"id": 83, "seek": 51358, "start": 520.94, "end": 528.86, "text": " join as well. This is hopefully not a novel thing that is here, but it is written in stone now.", "tokens": [50732, 3917, 382, 731, 13, 639, 307, 4696, 406, 257, 7613, 551, 300, 307, 510, 11, 457, 309, 307, 3720, 294, 7581, 586, 13, 51128], "temperature": 0.0, "avg_logprob": -0.14509839071354397, "compression_ratio": 1.4791666666666667, "no_speech_prob": 0.004581477493047714}, {"id": 84, "seek": 51358, "start": 530.46, "end": 536.7800000000001, "text": " So we need to synchronize these two concepts. We call users to have a participation state or", "tokens": [51208, 407, 321, 643, 281, 19331, 1125, 613, 732, 10392, 13, 492, 818, 5022, 281, 362, 257, 13487, 1785, 420, 51524], "temperature": 0.0, "avg_logprob": -0.14509839071354397, "compression_ratio": 1.4791666666666667, "no_speech_prob": 0.004581477493047714}, {"id": 85, "seek": 53678, "start": 537.26, "end": 543.3399999999999, "text": " exist on a participation list. And then clients have membership. So users, participation,", "tokens": [50388, 2514, 322, 257, 13487, 1329, 13, 400, 550, 6982, 362, 16560, 13, 407, 5022, 11, 13487, 11, 50692], "temperature": 0.0, "avg_logprob": -0.1385130214691162, "compression_ratio": 1.7330827067669172, "no_speech_prob": 0.03289598971605301}, {"id": 86, "seek": 53678, "start": 543.3399999999999, "end": 548.22, "text": " clients, membership. We also have to make sure that these are atomic operations because otherwise", "tokens": [50692, 6982, 11, 16560, 13, 492, 611, 362, 281, 652, 988, 300, 613, 366, 22275, 7705, 570, 5911, 50936], "temperature": 0.0, "avg_logprob": -0.1385130214691162, "compression_ratio": 1.7330827067669172, "no_speech_prob": 0.03289598971605301}, {"id": 87, "seek": 53678, "start": 548.22, "end": 553.26, "text": " somebody joins the crypto state, but they are not part of the actual user state. That causes issues.", "tokens": [50936, 2618, 24397, 264, 17240, 1785, 11, 457, 436, 366, 406, 644, 295, 264, 3539, 4195, 1785, 13, 663, 7700, 2663, 13, 51188], "temperature": 0.0, "avg_logprob": -0.1385130214691162, "compression_ratio": 1.7330827067669172, "no_speech_prob": 0.03289598971605301}, {"id": 88, "seek": 53678, "start": 555.5, "end": 561.5, "text": " So Mimi has started proposing a bunch of MLS extensions to persist application", "tokens": [51300, 407, 46709, 575, 1409, 29939, 257, 3840, 295, 376, 19198, 25129, 281, 13233, 3861, 51600], "temperature": 0.0, "avg_logprob": -0.1385130214691162, "compression_ratio": 1.7330827067669172, "no_speech_prob": 0.03289598971605301}, {"id": 89, "seek": 53678, "start": 561.5, "end": 566.38, "text": " state within an MLS group. Because MLS has those extensions that you can just store arbitrary", "tokens": [51600, 1785, 1951, 364, 376, 19198, 1594, 13, 1436, 376, 19198, 575, 729, 25129, 300, 291, 393, 445, 3531, 23211, 51844], "temperature": 0.0, "avg_logprob": -0.1385130214691162, "compression_ratio": 1.7330827067669172, "no_speech_prob": 0.03289598971605301}, {"id": 90, "seek": 56638, "start": 566.38, "end": 573.98, "text": " things, making the blob even larger so you must store it in the media repo. These are new as of", "tokens": [50364, 721, 11, 1455, 264, 46115, 754, 4833, 370, 291, 1633, 3531, 309, 294, 264, 3021, 49040, 13, 1981, 366, 777, 382, 295, 50744], "temperature": 0.0, "avg_logprob": -0.13377640644709268, "compression_ratio": 1.5551020408163265, "no_speech_prob": 0.005185420159250498}, {"id": 91, "seek": 56638, "start": 573.98, "end": 580.78, "text": " like a week and a half ago, but it is called AppSync. It is a generic mechanism. Conveniently,", "tokens": [50744, 411, 257, 1243, 293, 257, 1922, 2057, 11, 457, 309, 307, 1219, 3132, 50, 34015, 13, 467, 307, 257, 19577, 7513, 13, 45992, 1196, 356, 11, 51084], "temperature": 0.0, "avg_logprob": -0.13377640644709268, "compression_ratio": 1.5551020408163265, "no_speech_prob": 0.005185420159250498}, {"id": 92, "seek": 56638, "start": 580.78, "end": 587.18, "text": " it would basically be mapped to state events in matrix. So you can just add arbitrary information", "tokens": [51084, 309, 576, 1936, 312, 33318, 281, 1785, 3931, 294, 8141, 13, 407, 291, 393, 445, 909, 23211, 1589, 51404], "temperature": 0.0, "avg_logprob": -0.13377640644709268, "compression_ratio": 1.5551020408163265, "no_speech_prob": 0.005185420159250498}, {"id": 93, "seek": 56638, "start": 587.18, "end": 593.18, "text": " to the group, namely with a key and some sort of content. And then there are some operations", "tokens": [51404, 281, 264, 1594, 11, 20926, 365, 257, 2141, 293, 512, 1333, 295, 2701, 13, 400, 550, 456, 366, 512, 7705, 51704], "temperature": 0.0, "avg_logprob": -0.13377640644709268, "compression_ratio": 1.5551020408163265, "no_speech_prob": 0.005185420159250498}, {"id": 94, "seek": 59318, "start": 593.18, "end": 602.78, "text": " that apply where you can add, remove, update, that sort of stuff. But yeah, it is visible to servers,", "tokens": [50364, 300, 3079, 689, 291, 393, 909, 11, 4159, 11, 5623, 11, 300, 1333, 295, 1507, 13, 583, 1338, 11, 309, 307, 8974, 281, 15909, 11, 50844], "temperature": 0.0, "avg_logprob": -0.1011550643227317, "compression_ratio": 1.5805084745762712, "no_speech_prob": 0.0030596803408116102}, {"id": 95, "seek": 59318, "start": 602.78, "end": 609.18, "text": " but servers can't see the actual encrypted messages part of MLS. They can just see that", "tokens": [50844, 457, 15909, 393, 380, 536, 264, 3539, 36663, 7897, 644, 295, 376, 19198, 13, 814, 393, 445, 536, 300, 51164], "temperature": 0.0, "avg_logprob": -0.1011550643227317, "compression_ratio": 1.5805084745762712, "no_speech_prob": 0.0030596803408116102}, {"id": 96, "seek": 59318, "start": 609.18, "end": 612.8599999999999, "text": " state changes are happening and potentially what's inside those state changes, which is why they", "tokens": [51164, 1785, 2962, 366, 2737, 293, 7263, 437, 311, 1854, 729, 1785, 2962, 11, 597, 307, 983, 436, 51348], "temperature": 0.0, "avg_logprob": -0.1011550643227317, "compression_ratio": 1.5805084745762712, "no_speech_prob": 0.0030596803408116102}, {"id": 97, "seek": 59318, "start": 612.8599999999999, "end": 618.62, "text": " would map to state events in matrix. Double ratchet and participation is a bit harder.", "tokens": [51348, 576, 4471, 281, 1785, 3931, 294, 8141, 13, 16633, 45885, 293, 13487, 307, 257, 857, 6081, 13, 51636], "temperature": 0.0, "avg_logprob": -0.1011550643227317, "compression_ratio": 1.5805084745762712, "no_speech_prob": 0.0030596803408116102}, {"id": 98, "seek": 61862, "start": 619.18, "end": 625.74, "text": " Because double ratchet, again, doesn't have a concept of membership. It's not terribly difficult", "tokens": [50392, 1436, 3834, 45885, 11, 797, 11, 1177, 380, 362, 257, 3410, 295, 16560, 13, 467, 311, 406, 22903, 2252, 50720], "temperature": 0.0, "avg_logprob": -0.15795719964163643, "compression_ratio": 1.4375, "no_speech_prob": 0.0034108420368283987}, {"id": 99, "seek": 61862, "start": 625.74, "end": 632.94, "text": " to map these. It's a little complicated sometimes. So there's a couple of MSCs there that list this", "tokens": [50720, 281, 4471, 613, 13, 467, 311, 257, 707, 6179, 2171, 13, 407, 456, 311, 257, 1916, 295, 7395, 33290, 456, 300, 1329, 341, 51080], "temperature": 0.0, "avg_logprob": -0.15795719964163643, "compression_ratio": 1.4375, "no_speech_prob": 0.0034108420368283987}, {"id": 100, "seek": 61862, "start": 632.94, "end": 642.3, "text": " sort of information, namely the crypto IDs Matthew was just talking about. And then yeah, we translate", "tokens": [51080, 1333, 295, 1589, 11, 20926, 264, 17240, 48212, 12434, 390, 445, 1417, 466, 13, 400, 550, 1338, 11, 321, 13799, 51548], "temperature": 0.0, "avg_logprob": -0.15795719964163643, "compression_ratio": 1.4375, "no_speech_prob": 0.0034108420368283987}, {"id": 101, "seek": 64230, "start": 642.38, "end": 650.3, "text": " these concepts to Mroom member state events as well as device lists on matrix. But regardless of", "tokens": [50368, 613, 10392, 281, 376, 2861, 4006, 1785, 3931, 382, 731, 382, 4302, 14511, 322, 8141, 13, 583, 10060, 295, 50764], "temperature": 0.0, "avg_logprob": -0.11307584828343885, "compression_ratio": 1.5506072874493928, "no_speech_prob": 0.0163007490336895}, {"id": 102, "seek": 64230, "start": 650.3, "end": 656.14, "text": " the protocol, we want to make sure that people currently on double ratchet have a way up to MLS.", "tokens": [50764, 264, 10336, 11, 321, 528, 281, 652, 988, 300, 561, 4362, 322, 3834, 45885, 362, 257, 636, 493, 281, 376, 19198, 13, 51056], "temperature": 0.0, "avg_logprob": -0.11307584828343885, "compression_ratio": 1.5506072874493928, "no_speech_prob": 0.0163007490336895}, {"id": 103, "seek": 64230, "start": 657.5, "end": 663.26, "text": " So it's a natural evolution of the application rather than forcing somebody to effectively fork", "tokens": [51124, 407, 309, 311, 257, 3303, 9303, 295, 264, 3861, 2831, 813, 19030, 2618, 281, 8659, 17716, 51412], "temperature": 0.0, "avg_logprob": -0.11307584828343885, "compression_ratio": 1.5506072874493928, "no_speech_prob": 0.0163007490336895}, {"id": 104, "seek": 64230, "start": 663.26, "end": 670.38, "text": " their own client, which brings us a little bit into content format. So clients need to end up", "tokens": [51412, 641, 1065, 6423, 11, 597, 5607, 505, 257, 707, 857, 666, 2701, 7877, 13, 407, 6982, 643, 281, 917, 493, 51768], "temperature": 0.0, "avg_logprob": -0.11307584828343885, "compression_ratio": 1.5506072874493928, "no_speech_prob": 0.0163007490336895}, {"id": 105, "seek": 67038, "start": 670.46, "end": 675.26, "text": " encrypting and decrypting the same thing. Otherwise, there's going to be issues. Because", "tokens": [50368, 17972, 662, 278, 293, 979, 627, 662, 278, 264, 912, 551, 13, 10328, 11, 456, 311, 516, 281, 312, 2663, 13, 1436, 50608], "temperature": 0.0, "avg_logprob": -0.09835634145650778, "compression_ratio": 1.689922480620155, "no_speech_prob": 0.00817310530692339}, {"id": 106, "seek": 67038, "start": 675.82, "end": 679.1, "text": " if you send a text message to somebody and they just don't know what to expect,", "tokens": [50636, 498, 291, 2845, 257, 2487, 3636, 281, 2618, 293, 436, 445, 500, 380, 458, 437, 281, 2066, 11, 50800], "temperature": 0.0, "avg_logprob": -0.09835634145650778, "compression_ratio": 1.689922480620155, "no_speech_prob": 0.00817310530692339}, {"id": 107, "seek": 67038, "start": 680.06, "end": 684.62, "text": " then there's not going to see anything. So we need some form of extensibility because", "tokens": [50848, 550, 456, 311, 406, 516, 281, 536, 1340, 13, 407, 321, 643, 512, 1254, 295, 1279, 694, 2841, 570, 51076], "temperature": 0.0, "avg_logprob": -0.09835634145650778, "compression_ratio": 1.689922480620155, "no_speech_prob": 0.00817310530692339}, {"id": 108, "seek": 67038, "start": 685.18, "end": 689.66, "text": " messaging also has a ton of features. And it's constantly evolving. Servers can't help with", "tokens": [51104, 21812, 611, 575, 257, 2952, 295, 4122, 13, 400, 309, 311, 6460, 21085, 13, 4210, 840, 393, 380, 854, 365, 51328], "temperature": 0.0, "avg_logprob": -0.09835634145650778, "compression_ratio": 1.689922480620155, "no_speech_prob": 0.00817310530692339}, {"id": 109, "seek": 67038, "start": 689.66, "end": 695.02, "text": " this because it's already encrypted. And of course, it should be as small as possible. It", "tokens": [51328, 341, 570, 309, 311, 1217, 36663, 13, 400, 295, 1164, 11, 309, 820, 312, 382, 1359, 382, 1944, 13, 467, 51596], "temperature": 0.0, "avg_logprob": -0.09835634145650778, "compression_ratio": 1.689922480620155, "no_speech_prob": 0.00817310530692339}, {"id": 110, "seek": 69502, "start": 695.02, "end": 702.22, "text": " should require minimal processing power because not every client is a laptop. Or sometimes the", "tokens": [50364, 820, 3651, 13206, 9007, 1347, 570, 406, 633, 6423, 307, 257, 10732, 13, 1610, 2171, 264, 50724], "temperature": 0.0, "avg_logprob": -0.12064428130785625, "compression_ratio": 1.5903614457831325, "no_speech_prob": 0.021886330097913742}, {"id": 111, "seek": 69502, "start": 702.22, "end": 709.9, "text": " laptop is a bit slow. So Mimi has worked on their own TLS encoded multi part MIME format. It looks", "tokens": [50724, 10732, 307, 257, 857, 2964, 13, 407, 46709, 575, 2732, 322, 641, 1065, 314, 19198, 2058, 12340, 4825, 644, 376, 6324, 36, 7877, 13, 467, 1542, 51108], "temperature": 0.0, "avg_logprob": -0.12064428130785625, "compression_ratio": 1.5903614457831325, "no_speech_prob": 0.021886330097913742}, {"id": 112, "seek": 69502, "start": 709.9, "end": 717.1, "text": " a lot like multi part email. It's not the greatest, but it is a notional format while we try and work", "tokens": [51108, 257, 688, 411, 4825, 644, 3796, 13, 467, 311, 406, 264, 6636, 11, 457, 309, 307, 257, 406, 1966, 7877, 1339, 321, 853, 293, 589, 51468], "temperature": 0.0, "avg_logprob": -0.12064428130785625, "compression_ratio": 1.5903614457831325, "no_speech_prob": 0.021886330097913742}, {"id": 113, "seek": 69502, "start": 717.1, "end": 722.3, "text": " out the exact things. But matrix already has events and you can already define your own custom event", "tokens": [51468, 484, 264, 1900, 721, 13, 583, 8141, 1217, 575, 3931, 293, 291, 393, 1217, 6964, 428, 1065, 2375, 2280, 51728], "temperature": 0.0, "avg_logprob": -0.12064428130785625, "compression_ratio": 1.5903614457831325, "no_speech_prob": 0.021886330097913742}, {"id": 114, "seek": 72230, "start": 722.3, "end": 732.54, "text": " types. And you can already add arbitrary content. But what if we made that way more extensible?", "tokens": [50364, 3467, 13, 400, 291, 393, 1217, 909, 23211, 2701, 13, 583, 437, 498, 321, 1027, 300, 636, 544, 1279, 30633, 30, 50876], "temperature": 0.0, "avg_logprob": -0.10277911594935826, "compression_ratio": 1.4895833333333333, "no_speech_prob": 0.00677063362672925}, {"id": 115, "seek": 72230, "start": 732.54, "end": 739.3399999999999, "text": " So we introduce extensible events or MSC 1767. We use content blocks to persist information inside", "tokens": [50876, 407, 321, 5366, 1279, 30633, 3931, 420, 7395, 34, 3282, 22452, 13, 492, 764, 2701, 8474, 281, 13233, 1589, 1854, 51216], "temperature": 0.0, "avg_logprob": -0.10277911594935826, "compression_ratio": 1.4895833333333333, "no_speech_prob": 0.00677063362672925}, {"id": 116, "seek": 72230, "start": 739.3399999999999, "end": 746.62, "text": " of an event. We specify the course blocks there. And then we also try to make sure that the", "tokens": [51216, 295, 364, 2280, 13, 492, 16500, 264, 1164, 8474, 456, 13, 400, 550, 321, 611, 853, 281, 652, 988, 300, 264, 51580], "temperature": 0.0, "avg_logprob": -0.10277911594935826, "compression_ratio": 1.4895833333333333, "no_speech_prob": 0.00677063362672925}, {"id": 117, "seek": 74662, "start": 747.58, "end": 754.0600000000001, "text": " client can render arbitrary event types that they don't know about. So we lose a little bit of", "tokens": [50412, 6423, 393, 15529, 23211, 2280, 3467, 300, 436, 500, 380, 458, 466, 13, 407, 321, 3624, 257, 707, 857, 295, 50736], "temperature": 0.0, "avg_logprob": -0.08643719097515484, "compression_ratio": 1.75, "no_speech_prob": 0.0041303085163235664}, {"id": 118, "seek": 74662, "start": 754.0600000000001, "end": 759.66, "text": " richness in the sense that if a client does encounter an unknown event, that they have to", "tokens": [50736, 44506, 294, 264, 2020, 300, 498, 257, 6423, 775, 8593, 364, 9841, 2280, 11, 300, 436, 362, 281, 51016], "temperature": 0.0, "avg_logprob": -0.08643719097515484, "compression_ratio": 1.75, "no_speech_prob": 0.0041303085163235664}, {"id": 119, "seek": 74662, "start": 759.66, "end": 764.14, "text": " figure out how to render that. And it might not render in the same way for everybody, but at", "tokens": [51016, 2573, 484, 577, 281, 15529, 300, 13, 400, 309, 1062, 406, 15529, 294, 264, 912, 636, 337, 2201, 11, 457, 412, 51240], "temperature": 0.0, "avg_logprob": -0.08643719097515484, "compression_ratio": 1.75, "no_speech_prob": 0.0041303085163235664}, {"id": 120, "seek": 74662, "start": 764.14, "end": 769.1, "text": " least render the same information for everybody. And that's the critical part. So an extensible", "tokens": [51240, 1935, 15529, 264, 912, 1589, 337, 2201, 13, 400, 300, 311, 264, 4924, 644, 13, 407, 364, 1279, 30633, 51488], "temperature": 0.0, "avg_logprob": -0.08643719097515484, "compression_ratio": 1.75, "no_speech_prob": 0.0041303085163235664}, {"id": 121, "seek": 74662, "start": 769.1, "end": 774.94, "text": " event looks a little bit like this. This is just a basic text message saying hello world. So if", "tokens": [51488, 2280, 1542, 257, 707, 857, 411, 341, 13, 639, 307, 445, 257, 3875, 2487, 3636, 1566, 7751, 1002, 13, 407, 498, 51780], "temperature": 0.0, "avg_logprob": -0.08643719097515484, "compression_ratio": 1.75, "no_speech_prob": 0.0041303085163235664}, {"id": 122, "seek": 77494, "start": 774.94, "end": 779.82, "text": " your client supports HTML, it picks the HTML format. If it doesn't support HTML, supports the", "tokens": [50364, 428, 6423, 9346, 17995, 11, 309, 16137, 264, 17995, 7877, 13, 759, 309, 1177, 380, 1406, 17995, 11, 9346, 264, 50608], "temperature": 0.0, "avg_logprob": -0.10271098250049655, "compression_ratio": 1.7563636363636363, "no_speech_prob": 0.0005351200234144926}, {"id": 123, "seek": 77494, "start": 779.82, "end": 785.82, "text": " basic format. But critically, you have a type of m dot message and you have a content block of m dot", "tokens": [50608, 3875, 7877, 13, 583, 22797, 11, 291, 362, 257, 2010, 295, 275, 5893, 3636, 293, 291, 362, 257, 2701, 3461, 295, 275, 5893, 50908], "temperature": 0.0, "avg_logprob": -0.10271098250049655, "compression_ratio": 1.7563636363636363, "no_speech_prob": 0.0005351200234144926}, {"id": 124, "seek": 77494, "start": 785.82, "end": 792.94, "text": " text. So if we add a little bit more richness to that and create a fake schema for polls that", "tokens": [50908, 2487, 13, 407, 498, 321, 909, 257, 707, 857, 544, 44506, 281, 300, 293, 1884, 257, 7592, 34078, 337, 24264, 300, 51264], "temperature": 0.0, "avg_logprob": -0.10271098250049655, "compression_ratio": 1.7563636363636363, "no_speech_prob": 0.0005351200234144926}, {"id": 125, "seek": 77494, "start": 792.94, "end": 798.3800000000001, "text": " definitely doesn't exist, please see the MSC for a real schema. You have an unknown event type for", "tokens": [51264, 2138, 1177, 380, 2514, 11, 1767, 536, 264, 7395, 34, 337, 257, 957, 34078, 13, 509, 362, 364, 9841, 2280, 2010, 337, 51536], "temperature": 0.0, "avg_logprob": -0.10271098250049655, "compression_ratio": 1.7563636363636363, "no_speech_prob": 0.0005351200234144926}, {"id": 126, "seek": 77494, "start": 798.3800000000001, "end": 803.82, "text": " some clients, namely org matrix poll start. So you still have that text content block. And then", "tokens": [51536, 512, 6982, 11, 20926, 14045, 8141, 6418, 722, 13, 407, 291, 920, 362, 300, 2487, 2701, 3461, 13, 400, 550, 51808], "temperature": 0.0, "avg_logprob": -0.10271098250049655, "compression_ratio": 1.7563636363636363, "no_speech_prob": 0.0005351200234144926}, {"id": 127, "seek": 80382, "start": 803.82, "end": 807.58, "text": " you also have this poll content block, which gives you a little bit more information about how to", "tokens": [50364, 291, 611, 362, 341, 6418, 2701, 3461, 11, 597, 2709, 291, 257, 707, 857, 544, 1589, 466, 577, 281, 50552], "temperature": 0.0, "avg_logprob": -0.07394652896457249, "compression_ratio": 1.694736842105263, "no_speech_prob": 0.0005606285994872451}, {"id": 128, "seek": 80382, "start": 807.58, "end": 813.34, "text": " render these events. So if your client knows what that event type is, I can go into the content,", "tokens": [50552, 15529, 613, 3931, 13, 407, 498, 428, 6423, 3255, 437, 300, 2280, 2010, 307, 11, 286, 393, 352, 666, 264, 2701, 11, 50840], "temperature": 0.0, "avg_logprob": -0.07394652896457249, "compression_ratio": 1.694736842105263, "no_speech_prob": 0.0005606285994872451}, {"id": 129, "seek": 80382, "start": 813.34, "end": 818.62, "text": " pull out the org matrix poll content block, render that in its UI, and then the client can", "tokens": [50840, 2235, 484, 264, 14045, 8141, 6418, 2701, 3461, 11, 15529, 300, 294, 1080, 15682, 11, 293, 550, 264, 6423, 393, 51104], "temperature": 0.0, "avg_logprob": -0.07394652896457249, "compression_ratio": 1.694736842105263, "no_speech_prob": 0.0005606285994872451}, {"id": 130, "seek": 80382, "start": 818.62, "end": 824.94, "text": " interact with it normally. Otherwise, you end up with just the text and it is suitably okay. It's", "tokens": [51104, 4648, 365, 309, 5646, 13, 10328, 11, 291, 917, 493, 365, 445, 264, 2487, 293, 309, 307, 5722, 1188, 1392, 13, 467, 311, 51420], "temperature": 0.0, "avg_logprob": -0.07394652896457249, "compression_ratio": 1.694736842105263, "no_speech_prob": 0.0005606285994872451}, {"id": 131, "seek": 80382, "start": 824.94, "end": 833.58, "text": " not great. But you still have the same information from the poll. And so yeah, currently extensible", "tokens": [51420, 406, 869, 13, 583, 291, 920, 362, 264, 912, 1589, 490, 264, 6418, 13, 400, 370, 1338, 11, 4362, 1279, 30633, 51852], "temperature": 0.0, "avg_logprob": -0.07394652896457249, "compression_ratio": 1.694736842105263, "no_speech_prob": 0.0005606285994872451}, {"id": 132, "seek": 83358, "start": 833.58, "end": 839.82, "text": " events are JSON. But again, you could make this a binary format in the future. More events get", "tokens": [50364, 3931, 366, 31828, 13, 583, 797, 11, 291, 727, 652, 341, 257, 17434, 7877, 294, 264, 2027, 13, 5048, 3931, 483, 50676], "temperature": 0.0, "avg_logprob": -0.10101983880483976, "compression_ratio": 1.5748987854251013, "no_speech_prob": 0.001696234568953514}, {"id": 133, "seek": 83358, "start": 839.82, "end": 844.0600000000001, "text": " rendered by more clients, which is great. You can create more custom event types. You can do all", "tokens": [50676, 28748, 538, 544, 6982, 11, 597, 307, 869, 13, 509, 393, 1884, 544, 2375, 2280, 3467, 13, 509, 393, 360, 439, 50888], "temperature": 0.0, "avg_logprob": -0.10101983880483976, "compression_ratio": 1.5748987854251013, "no_speech_prob": 0.001696234568953514}, {"id": 134, "seek": 83358, "start": 844.0600000000001, "end": 850.0600000000001, "text": " sorts of fun stuff to be determined exactly what all of this looks like. We're still in the process", "tokens": [50888, 7527, 295, 1019, 1507, 281, 312, 9540, 2293, 437, 439, 295, 341, 1542, 411, 13, 492, 434, 920, 294, 264, 1399, 51188], "temperature": 0.0, "avg_logprob": -0.10101983880483976, "compression_ratio": 1.5748987854251013, "no_speech_prob": 0.001696234568953514}, {"id": 135, "seek": 83358, "start": 850.0600000000001, "end": 858.94, "text": " of specifying all of the pieces, particularly the core content blocks, and also a registry so you", "tokens": [51188, 295, 1608, 5489, 439, 295, 264, 3755, 11, 4098, 264, 4965, 2701, 8474, 11, 293, 611, 257, 36468, 370, 291, 51632], "temperature": 0.0, "avg_logprob": -0.10101983880483976, "compression_ratio": 1.5748987854251013, "no_speech_prob": 0.001696234568953514}, {"id": 136, "seek": 85894, "start": 858.94, "end": 864.7800000000001, "text": " can actually implement a client that understands all of these things. So a little bit on room models.", "tokens": [50364, 393, 767, 4445, 257, 6423, 300, 15146, 439, 295, 613, 721, 13, 407, 257, 707, 857, 322, 1808, 5245, 13, 50656], "temperature": 0.0, "avg_logprob": -0.1040809764418491, "compression_ratio": 1.6218487394957983, "no_speech_prob": 0.022243183106184006}, {"id": 137, "seek": 85894, "start": 865.6600000000001, "end": 870.0600000000001, "text": " The Mimi room model looks like this. So when you add the third server, there's obviously a little", "tokens": [50700, 440, 46709, 1808, 2316, 1542, 411, 341, 13, 407, 562, 291, 909, 264, 2636, 7154, 11, 456, 311, 2745, 257, 707, 50920], "temperature": 0.0, "avg_logprob": -0.1040809764418491, "compression_ratio": 1.6218487394957983, "no_speech_prob": 0.022243183106184006}, {"id": 138, "seek": 85894, "start": 870.0600000000001, "end": 877.2600000000001, "text": " bit more complexity. Mimi primarily uses a hub and spoke fan out. So you have one central server", "tokens": [50920, 857, 544, 14024, 13, 46709, 10029, 4960, 257, 11838, 293, 7179, 3429, 484, 13, 407, 291, 362, 472, 5777, 7154, 51280], "temperature": 0.0, "avg_logprob": -0.1040809764418491, "compression_ratio": 1.6218487394957983, "no_speech_prob": 0.022243183106184006}, {"id": 139, "seek": 85894, "start": 877.2600000000001, "end": 883.6600000000001, "text": " per conversation, not for the entire global network, that is responsible for distributing", "tokens": [51280, 680, 3761, 11, 406, 337, 264, 2302, 4338, 3209, 11, 300, 307, 6250, 337, 41406, 51600], "temperature": 0.0, "avg_logprob": -0.1040809764418491, "compression_ratio": 1.6218487394957983, "no_speech_prob": 0.022243183106184006}, {"id": 140, "seek": 88366, "start": 883.66, "end": 889.5799999999999, "text": " messages. So server B and C try to avoid talking to each other if they absolutely can. And they", "tokens": [50364, 7897, 13, 407, 7154, 363, 293, 383, 853, 281, 5042, 1417, 281, 1184, 661, 498, 436, 3122, 393, 13, 400, 436, 50660], "temperature": 0.0, "avg_logprob": -0.10073568991252355, "compression_ratio": 1.6678200692041523, "no_speech_prob": 0.16842900216579437}, {"id": 141, "seek": 88366, "start": 889.5799999999999, "end": 893.98, "text": " talk through server A instead. So server A is responsible for sequencing, which is important", "tokens": [50660, 751, 807, 7154, 316, 2602, 13, 407, 7154, 316, 307, 6250, 337, 32693, 11, 597, 307, 1021, 50880], "temperature": 0.0, "avg_logprob": -0.10073568991252355, "compression_ratio": 1.6678200692041523, "no_speech_prob": 0.16842900216579437}, {"id": 142, "seek": 88366, "start": 893.98, "end": 901.18, "text": " for MLS. It has those characteristics in play. And then yeah, the follower servers, as they're", "tokens": [50880, 337, 376, 19198, 13, 467, 575, 729, 10891, 294, 862, 13, 400, 550, 1338, 11, 264, 35413, 15909, 11, 382, 436, 434, 51240], "temperature": 0.0, "avg_logprob": -0.10073568991252355, "compression_ratio": 1.6678200692041523, "no_speech_prob": 0.16842900216579437}, {"id": 143, "seek": 88366, "start": 901.18, "end": 905.8199999999999, "text": " called, go through that. And encrypted messages still flow between the clients as normal. The servers", "tokens": [51240, 1219, 11, 352, 807, 300, 13, 400, 36663, 7897, 920, 3095, 1296, 264, 6982, 382, 2710, 13, 440, 15909, 51472], "temperature": 0.0, "avg_logprob": -0.10073568991252355, "compression_ratio": 1.6678200692041523, "no_speech_prob": 0.16842900216579437}, {"id": 144, "seek": 88366, "start": 905.8199999999999, "end": 910.22, "text": " can't see those messages. So then we have the question of what does linearized matrix look like?", "tokens": [51472, 393, 380, 536, 729, 7897, 13, 407, 550, 321, 362, 264, 1168, 295, 437, 775, 8213, 1602, 8141, 574, 411, 30, 51692], "temperature": 0.0, "avg_logprob": -0.10073568991252355, "compression_ratio": 1.6678200692041523, "no_speech_prob": 0.16842900216579437}, {"id": 145, "seek": 91022, "start": 910.86, "end": 916.62, "text": " It's exactly the same thing, just different objects, which is particularly interesting when it comes", "tokens": [50396, 467, 311, 2293, 264, 912, 551, 11, 445, 819, 6565, 11, 597, 307, 4098, 1880, 562, 309, 1487, 50684], "temperature": 0.0, "avg_logprob": -0.11364445090293884, "compression_ratio": 1.7048458149779735, "no_speech_prob": 0.0012605325318872929}, {"id": 146, "seek": 91022, "start": 916.62, "end": 925.34, "text": " to the fact that it was rejected. Because it uses just regular matrix events. It's the same room", "tokens": [50684, 281, 264, 1186, 300, 309, 390, 15749, 13, 1436, 309, 4960, 445, 3890, 8141, 3931, 13, 467, 311, 264, 912, 1808, 51120], "temperature": 0.0, "avg_logprob": -0.11364445090293884, "compression_ratio": 1.7048458149779735, "no_speech_prob": 0.0012605325318872929}, {"id": 147, "seek": 91022, "start": 925.34, "end": 929.6600000000001, "text": " state. It's the same matrix event stuff. It's a stripped down version of the server to server", "tokens": [51120, 1785, 13, 467, 311, 264, 912, 8141, 2280, 1507, 13, 467, 311, 257, 33221, 760, 3037, 295, 264, 7154, 281, 7154, 51336], "temperature": 0.0, "avg_logprob": -0.11364445090293884, "compression_ratio": 1.7048458149779735, "no_speech_prob": 0.0012605325318872929}, {"id": 148, "seek": 91022, "start": 929.6600000000001, "end": 935.4200000000001, "text": " API because you don't need all the DAG resolution stuff if you don't have a DAG. Also, your DAG", "tokens": [51336, 9362, 570, 291, 500, 380, 643, 439, 264, 9578, 38, 8669, 1507, 498, 291, 500, 380, 362, 257, 9578, 38, 13, 2743, 11, 428, 9578, 38, 51624], "temperature": 0.0, "avg_logprob": -0.11364445090293884, "compression_ratio": 1.7048458149779735, "no_speech_prob": 0.0012605325318872929}, {"id": 149, "seek": 93542, "start": 935.42, "end": 940.3, "text": " is now a linked list. So you don't have any state resolution to do. You have the same authorization", "tokens": [50364, 307, 586, 257, 9408, 1329, 13, 407, 291, 500, 380, 362, 604, 1785, 8669, 281, 360, 13, 509, 362, 264, 912, 33697, 50608], "temperature": 0.0, "avg_logprob": -0.07486565426142529, "compression_ratio": 1.675, "no_speech_prob": 0.09386080503463745}, {"id": 150, "seek": 93542, "start": 940.3, "end": 945.9, "text": " rules. You can use the same extensible algorithms for encryption. You can use MLS, double ratchet,", "tokens": [50608, 4474, 13, 509, 393, 764, 264, 912, 1279, 30633, 14642, 337, 29575, 13, 509, 393, 764, 376, 19198, 11, 3834, 45885, 11, 50888], "temperature": 0.0, "avg_logprob": -0.07486565426142529, "compression_ratio": 1.675, "no_speech_prob": 0.09386080503463745}, {"id": 151, "seek": 93542, "start": 945.9, "end": 950.78, "text": " your own thing if you're insane enough to do that. And then you have all of the same capabilities of", "tokens": [50888, 428, 1065, 551, 498, 291, 434, 10838, 1547, 281, 360, 300, 13, 400, 550, 291, 362, 439, 295, 264, 912, 10862, 295, 51132], "temperature": 0.0, "avg_logprob": -0.07486565426142529, "compression_ratio": 1.675, "no_speech_prob": 0.09386080503463745}, {"id": 152, "seek": 93542, "start": 950.78, "end": 957.26, "text": " matrix. And you have the history and all of that. But critically, you can support having a DAG capable", "tokens": [51132, 8141, 13, 400, 291, 362, 264, 2503, 293, 439, 295, 300, 13, 583, 22797, 11, 291, 393, 1406, 1419, 257, 9578, 38, 8189, 51456], "temperature": 0.0, "avg_logprob": -0.07486565426142529, "compression_ratio": 1.675, "no_speech_prob": 0.09386080503463745}, {"id": 153, "seek": 95726, "start": 957.26, "end": 965.74, "text": " server in the room. You don't need to give up your decentralization. You can end up with a hub", "tokens": [50364, 7154, 294, 264, 1808, 13, 509, 500, 380, 643, 281, 976, 493, 428, 26515, 2144, 13, 509, 393, 917, 493, 365, 257, 11838, 50788], "temperature": 0.0, "avg_logprob": -0.10168182148652918, "compression_ratio": 1.6457142857142857, "no_speech_prob": 0.1707136034965515}, {"id": 154, "seek": 95726, "start": 965.74, "end": 974.46, "text": " server that basically acts as that linearization algorithm or does linearization algorithm. And", "tokens": [50788, 7154, 300, 1936, 10672, 382, 300, 8213, 2144, 9284, 420, 775, 8213, 2144, 9284, 13, 400, 51224], "temperature": 0.0, "avg_logprob": -0.10168182148652918, "compression_ratio": 1.6457142857142857, "no_speech_prob": 0.1707136034965515}, {"id": 155, "seek": 95726, "start": 974.46, "end": 981.42, "text": " it also still persists the events, still distributes them. So when you get into decentralization,", "tokens": [51224, 309, 611, 920, 868, 1751, 264, 3931, 11, 920, 4400, 1819, 552, 13, 407, 562, 291, 483, 666, 26515, 2144, 11, 51572], "temperature": 0.0, "avg_logprob": -0.10168182148652918, "compression_ratio": 1.6457142857142857, "no_speech_prob": 0.1707136034965515}, {"id": 156, "seek": 98142, "start": 981.42, "end": 987.9, "text": " namely how matrix works, you use a DAG. You have full mesh fan out where each server contacts", "tokens": [50364, 20926, 577, 8141, 1985, 11, 291, 764, 257, 9578, 38, 13, 509, 362, 1577, 17407, 3429, 484, 689, 1184, 7154, 15836, 50688], "temperature": 0.0, "avg_logprob": -0.09208973166868858, "compression_ratio": 1.6180257510729614, "no_speech_prob": 0.14973938465118408}, {"id": 157, "seek": 98142, "start": 987.9, "end": 993.66, "text": " every other server instead of going through a central hub. Conflicts of the DAG are used or", "tokens": [50688, 633, 661, 7154, 2602, 295, 516, 807, 257, 5777, 11838, 13, 2656, 3423, 985, 82, 295, 264, 9578, 38, 366, 1143, 420, 50976], "temperature": 0.0, "avg_logprob": -0.09208973166868858, "compression_ratio": 1.6180257510729614, "no_speech_prob": 0.14973938465118408}, {"id": 158, "seek": 98142, "start": 993.66, "end": 997.66, "text": " done through state resolution. So if two people try to do the same thing, somebody has to win.", "tokens": [50976, 1096, 807, 1785, 8669, 13, 407, 498, 732, 561, 853, 281, 360, 264, 912, 551, 11, 2618, 575, 281, 1942, 13, 51176], "temperature": 0.0, "avg_logprob": -0.09208973166868858, "compression_ratio": 1.6180257510729614, "no_speech_prob": 0.14973938465118408}, {"id": 159, "seek": 98142, "start": 999.0999999999999, "end": 1005.02, "text": " And the good news is state resolution can also be used to linearize the DAG. So through use of a", "tokens": [51248, 400, 264, 665, 2583, 307, 1785, 8669, 393, 611, 312, 1143, 281, 8213, 1125, 264, 9578, 38, 13, 407, 807, 764, 295, 257, 51544], "temperature": 0.0, "avg_logprob": -0.09208973166868858, "compression_ratio": 1.6180257510729614, "no_speech_prob": 0.14973938465118408}, {"id": 160, "seek": 100502, "start": 1005.02, "end": 1011.26, "text": " protocol converter, which may or may not be a dual stack server, you can then bring these centralized", "tokens": [50364, 10336, 33905, 11, 597, 815, 420, 815, 406, 312, 257, 11848, 8630, 7154, 11, 291, 393, 550, 1565, 613, 32395, 50676], "temperature": 0.0, "avg_logprob": -0.15863142574534697, "compression_ratio": 1.6810344827586208, "no_speech_prob": 0.005354323890060186}, {"id": 161, "seek": 100502, "start": 1011.26, "end": 1019.1, "text": " systems, even linearized matrix into matrix to just further route them. So protocol conversion,", "tokens": [50676, 3652, 11, 754, 8213, 1602, 8141, 666, 8141, 281, 445, 3052, 7955, 552, 13, 407, 10336, 14298, 11, 51068], "temperature": 0.0, "avg_logprob": -0.15863142574534697, "compression_ratio": 1.6810344827586208, "no_speech_prob": 0.005354323890060186}, {"id": 162, "seek": 100502, "start": 1020.14, "end": 1027.34, "text": " they aren't bridges. Bridges somewhat necessar- they're necessarily break the encryption because", "tokens": [51120, 436, 3212, 380, 21114, 13, 30552, 2880, 8344, 2688, 289, 12, 436, 434, 4725, 1821, 264, 29575, 570, 51480], "temperature": 0.0, "avg_logprob": -0.15863142574534697, "compression_ratio": 1.6810344827586208, "no_speech_prob": 0.005354323890060186}, {"id": 163, "seek": 100502, "start": 1027.34, "end": 1033.58, "text": " when you're converting to signal to matrix prior to our existing or to our new interoperability", "tokens": [51480, 562, 291, 434, 29942, 281, 6358, 281, 8141, 4059, 281, 527, 6741, 420, 281, 527, 777, 728, 7192, 2310, 51792], "temperature": 0.0, "avg_logprob": -0.15863142574534697, "compression_ratio": 1.6810344827586208, "no_speech_prob": 0.005354323890060186}, {"id": 164, "seek": 103358, "start": 1033.58, "end": 1039.1799999999998, "text": " capabilities, you end up decrypting the network on both sides of the bridge and re-encrypting. So", "tokens": [50364, 10862, 11, 291, 917, 493, 979, 627, 662, 278, 264, 3209, 322, 1293, 4881, 295, 264, 7283, 293, 319, 12, 22660, 627, 662, 278, 13, 407, 50644], "temperature": 0.0, "avg_logprob": -0.08875075483744123, "compression_ratio": 1.7397769516728625, "no_speech_prob": 0.0025851845275610685}, {"id": 165, "seek": 103358, "start": 1039.1799999999998, "end": 1043.82, "text": " you're only really encrypting to the bridge and not beyond it. So protocol converter doesn't", "tokens": [50644, 291, 434, 787, 534, 17972, 662, 278, 281, 264, 7283, 293, 406, 4399, 309, 13, 407, 10336, 33905, 1177, 380, 50876], "temperature": 0.0, "avg_logprob": -0.08875075483744123, "compression_ratio": 1.7397769516728625, "no_speech_prob": 0.0025851845275610685}, {"id": 166, "seek": 103358, "start": 1043.82, "end": 1049.6599999999999, "text": " decrypt messages. It just converts the envelope format to another format. So that way you can", "tokens": [50876, 979, 627, 662, 7897, 13, 467, 445, 38874, 264, 19989, 7877, 281, 1071, 7877, 13, 407, 300, 636, 291, 393, 51168], "temperature": 0.0, "avg_logprob": -0.08875075483744123, "compression_ratio": 1.7397769516728625, "no_speech_prob": 0.0025851845275610685}, {"id": 167, "seek": 103358, "start": 1050.86, "end": 1055.4199999999998, "text": " just keep sending your messages. This may also include translating some of the concepts. For", "tokens": [51228, 445, 1066, 7750, 428, 7897, 13, 639, 815, 611, 4090, 35030, 512, 295, 264, 10392, 13, 1171, 51456], "temperature": 0.0, "avg_logprob": -0.08875075483744123, "compression_ratio": 1.7397769516728625, "no_speech_prob": 0.0025851845275610685}, {"id": 168, "seek": 103358, "start": 1055.4199999999998, "end": 1059.98, "text": " matrix, we have two device events, some other protocols, namely Mimi, just send everything", "tokens": [51456, 8141, 11, 321, 362, 732, 4302, 3931, 11, 512, 661, 20618, 11, 20926, 46709, 11, 445, 2845, 1203, 51684], "temperature": 0.0, "avg_logprob": -0.08875075483744123, "compression_ratio": 1.7397769516728625, "no_speech_prob": 0.0025851845275610685}, {"id": 169, "seek": 105998, "start": 1059.98, "end": 1066.8600000000001, "text": " over what they call events. So we would have to translate those concepts into the appropriate", "tokens": [50364, 670, 437, 436, 818, 3931, 13, 407, 321, 576, 362, 281, 13799, 729, 10392, 666, 264, 6854, 50708], "temperature": 0.0, "avg_logprob": -0.09205928056136421, "compression_ratio": 1.5643153526970954, "no_speech_prob": 0.0029748028609901667}, {"id": 170, "seek": 105998, "start": 1066.8600000000001, "end": 1072.06, "text": " matrix APIs. Again, you can make this either with an app service or as a dual stack home server.", "tokens": [50708, 8141, 21445, 13, 3764, 11, 291, 393, 652, 341, 2139, 365, 364, 724, 2643, 420, 382, 257, 11848, 8630, 1280, 7154, 13, 50968], "temperature": 0.0, "avg_logprob": -0.09205928056136421, "compression_ratio": 1.5643153526970954, "no_speech_prob": 0.0029748028609901667}, {"id": 171, "seek": 105998, "start": 1072.78, "end": 1077.26, "text": " So instead of having a multi-head messenger, you have a multi-head server. And then, yeah,", "tokens": [51004, 407, 2602, 295, 1419, 257, 4825, 12, 1934, 26599, 11, 291, 362, 257, 4825, 12, 1934, 7154, 13, 400, 550, 11, 1338, 11, 51228], "temperature": 0.0, "avg_logprob": -0.09205928056136421, "compression_ratio": 1.5643153526970954, "no_speech_prob": 0.0029748028609901667}, {"id": 172, "seek": 105998, "start": 1077.26, "end": 1083.5, "text": " use msc3983 or 3984 to bridge the particular crypto concepts if your server doesn't necessarily", "tokens": [51228, 764, 275, 4417, 12493, 31849, 420, 15238, 25494, 281, 7283, 264, 1729, 17240, 10392, 498, 428, 7154, 1177, 380, 4725, 51540], "temperature": 0.0, "avg_logprob": -0.09205928056136421, "compression_ratio": 1.5643153526970954, "no_speech_prob": 0.0029748028609901667}, {"id": 173, "seek": 108350, "start": 1083.5, "end": 1090.62, "text": " support those key formats. So this is what it looks like. You may have recognized it. I stole", "tokens": [50364, 1406, 729, 2141, 25879, 13, 407, 341, 307, 437, 309, 1542, 411, 13, 509, 815, 362, 9823, 309, 13, 286, 16326, 50720], "temperature": 0.0, "avg_logprob": -0.07662370375224523, "compression_ratio": 1.6843971631205674, "no_speech_prob": 0.01906721293926239}, {"id": 174, "seek": 108350, "start": 1090.62, "end": 1098.06, "text": " it from Matthew's slides. So if you have a gatekeeper on the left there, you can do a protocol", "tokens": [50720, 309, 490, 12434, 311, 9788, 13, 407, 498, 291, 362, 257, 8539, 23083, 322, 264, 1411, 456, 11, 291, 393, 360, 257, 10336, 51092], "temperature": 0.0, "avg_logprob": -0.07662370375224523, "compression_ratio": 1.6843971631205674, "no_speech_prob": 0.01906721293926239}, {"id": 175, "seek": 108350, "start": 1098.06, "end": 1103.5, "text": " conversion. And that might be attached to a single server. It runs through matrix. And then you run", "tokens": [51092, 14298, 13, 400, 300, 1062, 312, 8570, 281, 257, 2167, 7154, 13, 467, 6676, 807, 8141, 13, 400, 550, 291, 1190, 51364], "temperature": 0.0, "avg_logprob": -0.07662370375224523, "compression_ratio": 1.6843971631205674, "no_speech_prob": 0.01906721293926239}, {"id": 176, "seek": 108350, "start": 1103.5, "end": 1108.7, "text": " another protocol conversion to bring it into linearized matrix or Mimi, where you have that", "tokens": [51364, 1071, 10336, 14298, 281, 1565, 309, 666, 8213, 1602, 8141, 420, 46709, 11, 689, 291, 362, 300, 51624], "temperature": 0.0, "avg_logprob": -0.07662370375224523, "compression_ratio": 1.6843971631205674, "no_speech_prob": 0.01906721293926239}, {"id": 177, "seek": 108350, "start": 1108.7, "end": 1113.1, "text": " hub and spoke, namely that the bottom two servers there aren't talking to each other directly.", "tokens": [51624, 11838, 293, 7179, 11, 20926, 300, 264, 2767, 732, 15909, 456, 3212, 380, 1417, 281, 1184, 661, 3838, 13, 51844], "temperature": 0.0, "avg_logprob": -0.07662370375224523, "compression_ratio": 1.6843971631205674, "no_speech_prob": 0.01906721293926239}, {"id": 178, "seek": 111350, "start": 1113.82, "end": 1121.1, "text": " So those two nodes might be the same physical server, just running dual stack and not doing", "tokens": [50380, 407, 729, 732, 13891, 1062, 312, 264, 912, 4001, 7154, 11, 445, 2614, 11848, 8630, 293, 406, 884, 50744], "temperature": 0.0, "avg_logprob": -0.06997170142077525, "compression_ratio": 1.5932203389830508, "no_speech_prob": 0.00026095390785485506}, {"id": 179, "seek": 111350, "start": 1121.1, "end": 1127.82, "text": " protocol conversion. But that's all right. So there are a few missing pieces. We haven't talked", "tokens": [50744, 10336, 14298, 13, 583, 300, 311, 439, 558, 13, 407, 456, 366, 257, 1326, 5361, 3755, 13, 492, 2378, 380, 2825, 51080], "temperature": 0.0, "avg_logprob": -0.06997170142077525, "compression_ratio": 1.5932203389830508, "no_speech_prob": 0.00026095390785485506}, {"id": 180, "seek": 111350, "start": 1127.82, "end": 1132.06, "text": " about anything to do with identity. How do you convert a phone number or a name or an email", "tokens": [51080, 466, 1340, 281, 360, 365, 6575, 13, 1012, 360, 291, 7620, 257, 2593, 1230, 420, 257, 1315, 420, 364, 3796, 51292], "temperature": 0.0, "avg_logprob": -0.06997170142077525, "compression_ratio": 1.5932203389830508, "no_speech_prob": 0.00026095390785485506}, {"id": 181, "seek": 111350, "start": 1132.06, "end": 1137.26, "text": " address into something routable? Who knows? That needs to be defined. We currently have identity", "tokens": [51292, 2985, 666, 746, 4020, 712, 30, 2102, 3255, 30, 663, 2203, 281, 312, 7642, 13, 492, 4362, 362, 6575, 51552], "temperature": 0.0, "avg_logprob": -0.06997170142077525, "compression_ratio": 1.5932203389830508, "no_speech_prob": 0.00026095390785485506}, {"id": 182, "seek": 111350, "start": 1137.26, "end": 1141.42, "text": " servers in matrix. They're a bit centralized. We're hoping that somebody in Mimi can actually", "tokens": [51552, 15909, 294, 8141, 13, 814, 434, 257, 857, 32395, 13, 492, 434, 7159, 300, 2618, 294, 46709, 393, 767, 51760], "temperature": 0.0, "avg_logprob": -0.06997170142077525, "compression_ratio": 1.5932203389830508, "no_speech_prob": 0.00026095390785485506}, {"id": 183, "seek": 114142, "start": 1141.42, "end": 1147.66, "text": " solve this problem for us. We also have an interesting idea around consent. Presumably,", "tokens": [50364, 5039, 341, 1154, 337, 505, 13, 492, 611, 362, 364, 1880, 1558, 926, 14546, 13, 2718, 449, 1188, 11, 50676], "temperature": 0.0, "avg_logprob": -0.04459871637060287, "compression_ratio": 1.7442922374429224, "no_speech_prob": 0.0071981558576226234}, {"id": 184, "seek": 114142, "start": 1147.66, "end": 1152.7, "text": " you don't want to receive spam. So how do you make sure that the person that is messaging you", "tokens": [50676, 291, 500, 380, 528, 281, 4774, 24028, 13, 407, 577, 360, 291, 652, 988, 300, 264, 954, 300, 307, 21812, 291, 50928], "temperature": 0.0, "avg_logprob": -0.04459871637060287, "compression_ratio": 1.7442922374429224, "no_speech_prob": 0.0071981558576226234}, {"id": 185, "seek": 114142, "start": 1152.7, "end": 1159.26, "text": " is allowed to message you? We also have anti-abuse. How do you report these messages over federations", "tokens": [50928, 307, 4350, 281, 3636, 291, 30, 492, 611, 362, 6061, 12, 455, 438, 13, 1012, 360, 291, 2275, 613, 7897, 670, 38024, 763, 51256], "temperature": 0.0, "avg_logprob": -0.04459871637060287, "compression_ratio": 1.7442922374429224, "no_speech_prob": 0.0071981558576226234}, {"id": 186, "seek": 114142, "start": 1159.26, "end": 1164.78, "text": " or over servers? How do you make sure that the servers can implement their own anti-abuse measures", "tokens": [51256, 420, 670, 15909, 30, 1012, 360, 291, 652, 988, 300, 264, 15909, 393, 4445, 641, 1065, 6061, 12, 455, 438, 8000, 51532], "temperature": 0.0, "avg_logprob": -0.04459871637060287, "compression_ratio": 1.7442922374429224, "no_speech_prob": 0.0071981558576226234}, {"id": 187, "seek": 116478, "start": 1165.26, "end": 1173.74, "text": " using whatever identifiers they can? Mimi also is not necessarily defined the exact identifiers", "tokens": [50388, 1228, 2035, 2473, 23463, 436, 393, 30, 46709, 611, 307, 406, 4725, 7642, 264, 1900, 2473, 23463, 50812], "temperature": 0.0, "avg_logprob": -0.15046823543051016, "compression_ratio": 1.5726141078838174, "no_speech_prob": 0.27778327465057373}, {"id": 188, "seek": 116478, "start": 1173.74, "end": 1178.78, "text": " that they want to use. Matrix already has user IDs, room IDs, aliases, that sort of stuff. But", "tokens": [50812, 300, 436, 528, 281, 764, 13, 36274, 1217, 575, 4195, 48212, 11, 1808, 48212, 11, 10198, 1957, 11, 300, 1333, 295, 1507, 13, 583, 51064], "temperature": 0.0, "avg_logprob": -0.15046823543051016, "compression_ratio": 1.5726141078838174, "no_speech_prob": 0.27778327465057373}, {"id": 189, "seek": 116478, "start": 1180.22, "end": 1188.54, "text": " who knows? Maybe something different would work. So room metadata. Again, where does the", "tokens": [51136, 567, 3255, 30, 2704, 746, 819, 576, 589, 13, 407, 1808, 26603, 13, 3764, 11, 689, 775, 264, 51552], "temperature": 0.0, "avg_logprob": -0.15046823543051016, "compression_ratio": 1.5726141078838174, "no_speech_prob": 0.27778327465057373}, {"id": 190, "seek": 116478, "start": 1188.54, "end": 1194.22, "text": " room name go? Who knows? We'll have to figure that out. Matrix state events would probably be fine.", "tokens": [51552, 1808, 1315, 352, 30, 2102, 3255, 30, 492, 603, 362, 281, 2573, 300, 484, 13, 36274, 1785, 3931, 576, 1391, 312, 2489, 13, 51836], "temperature": 0.0, "avg_logprob": -0.15046823543051016, "compression_ratio": 1.5726141078838174, "no_speech_prob": 0.27778327465057373}, {"id": 191, "seek": 119422, "start": 1194.3, "end": 1198.14, "text": " Same thing with ordering. MLS requires ordering. There's a discussion around whether or not the", "tokens": [50368, 10635, 551, 365, 21739, 13, 376, 19198, 7029, 21739, 13, 821, 311, 257, 5017, 926, 1968, 420, 406, 264, 50560], "temperature": 0.0, "avg_logprob": -0.06876454146012016, "compression_ratio": 1.5780730897009967, "no_speech_prob": 0.0018336502835154533}, {"id": 192, "seek": 119422, "start": 1198.14, "end": 1204.3, "text": " clients also need that ordering. So what's next? We have no idea. As Matthew has mentioned, again,", "tokens": [50560, 6982, 611, 643, 300, 21739, 13, 407, 437, 311, 958, 30, 492, 362, 572, 1558, 13, 1018, 12434, 575, 2835, 11, 797, 11, 50868], "temperature": 0.0, "avg_logprob": -0.06876454146012016, "compression_ratio": 1.5780730897009967, "no_speech_prob": 0.0018336502835154533}, {"id": 193, "seek": 119422, "start": 1204.3, "end": 1210.3, "text": " I'm just stealing from his slides. So linearized matrix will probably get updated as an MSC", "tokens": [50868, 286, 478, 445, 19757, 490, 702, 9788, 13, 407, 8213, 1602, 8141, 486, 1391, 483, 10588, 382, 364, 7395, 34, 51168], "temperature": 0.0, "avg_logprob": -0.06876454146012016, "compression_ratio": 1.5780730897009967, "no_speech_prob": 0.0018336502835154533}, {"id": 194, "seek": 119422, "start": 1210.3, "end": 1216.38, "text": " because currently the MSC is one version behind from the IETF draft. And the gatekeepers will", "tokens": [51168, 570, 4362, 264, 7395, 34, 307, 472, 3037, 2261, 490, 264, 286, 4850, 37, 11206, 13, 400, 264, 8539, 43153, 486, 51472], "temperature": 0.0, "avg_logprob": -0.06876454146012016, "compression_ratio": 1.5780730897009967, "no_speech_prob": 0.0018336502835154533}, {"id": 195, "seek": 119422, "start": 1216.38, "end": 1221.18, "text": " have to publish their plans by March 7th. We'll see what happens there. The protocol converter", "tokens": [51472, 362, 281, 11374, 641, 5482, 538, 6129, 1614, 392, 13, 492, 603, 536, 437, 2314, 456, 13, 440, 10336, 33905, 51712], "temperature": 0.0, "avg_logprob": -0.06876454146012016, "compression_ratio": 1.5780730897009967, "no_speech_prob": 0.0018336502835154533}, {"id": 196, "seek": 122118, "start": 1221.18, "end": 1227.1000000000001, "text": " concept will continue to be refined, of course. Mimi will also make some form of progress,", "tokens": [50364, 3410, 486, 2354, 281, 312, 26201, 11, 295, 1164, 13, 46709, 486, 611, 652, 512, 1254, 295, 4205, 11, 50660], "temperature": 0.0, "avg_logprob": -0.15463714246396665, "compression_ratio": 1.375, "no_speech_prob": 0.0025312944781035185}, {"id": 197, "seek": 122118, "start": 1227.1000000000001, "end": 1232.22, "text": " hopefully get refined as well. And yeah, funding the foundation is the best way to make this work.", "tokens": [50660, 4696, 483, 26201, 382, 731, 13, 400, 1338, 11, 6137, 264, 7030, 307, 264, 1151, 636, 281, 652, 341, 589, 13, 50916], "temperature": 0.0, "avg_logprob": -0.15463714246396665, "compression_ratio": 1.375, "no_speech_prob": 0.0025312944781035185}, {"id": 198, "seek": 122118, "start": 1232.22, "end": 1246.0600000000002, "text": " So, questions. Yes.", "tokens": [50916, 407, 11, 1651, 13, 1079, 13, 51608], "temperature": 0.0, "avg_logprob": -0.15463714246396665, "compression_ratio": 1.375, "no_speech_prob": 0.0025312944781035185}, {"id": 199, "seek": 124606, "start": 1246.62, "end": 1252.3799999999999, "text": " What are the stakeholders in the Mimi and why are so different stakeholders, like,", "tokens": [50392, 708, 366, 264, 17779, 294, 264, 46709, 293, 983, 366, 370, 819, 17779, 11, 411, 11, 50680], "temperature": 0.0, "avg_logprob": -0.21413107922202662, "compression_ratio": 1.7956989247311828, "no_speech_prob": 0.03092215582728386}, {"id": 200, "seek": 124606, "start": 1252.3799999999999, "end": 1255.6599999999999, "text": " not using the matrix approach? And what are the different interests here?", "tokens": [50680, 406, 1228, 264, 8141, 3109, 30, 400, 437, 366, 264, 819, 8847, 510, 30, 50844], "temperature": 0.0, "avg_logprob": -0.21413107922202662, "compression_ratio": 1.7956989247311828, "no_speech_prob": 0.03092215582728386}, {"id": 201, "seek": 124606, "start": 1256.78, "end": 1263.1799999999998, "text": " Yeah, so the question is what are the different stakeholders and why are we going after", "tokens": [50900, 865, 11, 370, 264, 1168, 307, 437, 366, 264, 819, 17779, 293, 983, 366, 321, 516, 934, 51220], "temperature": 0.0, "avg_logprob": -0.21413107922202662, "compression_ratio": 1.7956989247311828, "no_speech_prob": 0.03092215582728386}, {"id": 202, "seek": 124606, "start": 1263.1799999999998, "end": 1269.98, "text": " certain approaches, I believe. So there are several players in the Mimi space. So we have", "tokens": [51220, 1629, 11587, 11, 286, 1697, 13, 407, 456, 366, 2940, 4150, 294, 264, 46709, 1901, 13, 407, 321, 362, 51560], "temperature": 0.0, "avg_logprob": -0.21413107922202662, "compression_ratio": 1.7956989247311828, "no_speech_prob": 0.03092215582728386}, {"id": 203, "seek": 126998, "start": 1270.06, "end": 1277.98, "text": " obviously ourselves. We also have wire. There's Google and I'm forgetting all of the other ones,", "tokens": [50368, 2745, 4175, 13, 492, 611, 362, 6234, 13, 821, 311, 3329, 293, 286, 478, 25428, 439, 295, 264, 661, 2306, 11, 50764], "temperature": 0.0, "avg_logprob": -0.1398482539437034, "compression_ratio": 1.4938271604938271, "no_speech_prob": 0.062295228242874146}, {"id": 204, "seek": 126998, "start": 1277.98, "end": 1288.22, "text": " but there's... Yeah, Cisco, Wicker, Phoenix, and a few others. There's a few hundred people in", "tokens": [50764, 457, 456, 311, 485, 865, 11, 38528, 11, 343, 33804, 11, 18383, 11, 293, 257, 1326, 2357, 13, 821, 311, 257, 1326, 3262, 561, 294, 51276], "temperature": 0.0, "avg_logprob": -0.1398482539437034, "compression_ratio": 1.4938271604938271, "no_speech_prob": 0.062295228242874146}, {"id": 205, "seek": 126998, "start": 1288.22, "end": 1293.66, "text": " the Mimi working group. You can see their company association as part of the membership list.", "tokens": [51276, 264, 46709, 1364, 1594, 13, 509, 393, 536, 641, 2237, 14598, 382, 644, 295, 264, 16560, 1329, 13, 51548], "temperature": 0.0, "avg_logprob": -0.1398482539437034, "compression_ratio": 1.4938271604938271, "no_speech_prob": 0.062295228242874146}, {"id": 206, "seek": 126998, "start": 1294.94, "end": 1299.42, "text": " I would suggest going there. As for the different approaches, everybody wants", "tokens": [51612, 286, 576, 3402, 516, 456, 13, 1018, 337, 264, 819, 11587, 11, 2201, 2738, 51836], "temperature": 0.0, "avg_logprob": -0.1398482539437034, "compression_ratio": 1.4938271604938271, "no_speech_prob": 0.062295228242874146}, {"id": 207, "seek": 129942, "start": 1299.5, "end": 1305.8200000000002, "text": " everybody to use their thing. We're no exception. We just think that ours is better.", "tokens": [50368, 2201, 281, 764, 641, 551, 13, 492, 434, 572, 11183, 13, 492, 445, 519, 300, 11896, 307, 1101, 13, 50684], "temperature": 0.0, "avg_logprob": -0.13504473368326822, "compression_ratio": 1.4473684210526316, "no_speech_prob": 0.0013328632339835167}, {"id": 208, "seek": 129942, "start": 1308.78, "end": 1316.22, "text": " But yeah, we've been doing this for a while. Matrix was originally built as an interoperable", "tokens": [50832, 583, 1338, 11, 321, 600, 668, 884, 341, 337, 257, 1339, 13, 36274, 390, 7993, 3094, 382, 364, 728, 7192, 712, 51204], "temperature": 0.0, "avg_logprob": -0.13504473368326822, "compression_ratio": 1.4473684210526316, "no_speech_prob": 0.0013328632339835167}, {"id": 209, "seek": 129942, "start": 1316.22, "end": 1323.5800000000002, "text": " protocol. And here we are with a legal requirement to have interoperability. So, surely Matrix is", "tokens": [51204, 10336, 13, 400, 510, 321, 366, 365, 257, 5089, 11695, 281, 362, 728, 7192, 2310, 13, 407, 11, 11468, 36274, 307, 51572], "temperature": 0.0, "avg_logprob": -0.13504473368326822, "compression_ratio": 1.4473684210526316, "no_speech_prob": 0.0013328632339835167}, {"id": 210, "seek": 132358, "start": 1323.58, "end": 1326.1399999999999, "text": " designed for that, is kind of our thought.", "tokens": [50364, 4761, 337, 300, 11, 307, 733, 295, 527, 1194, 13, 50492], "temperature": 0.0, "avg_logprob": -0.31989806038992746, "compression_ratio": 0.875, "no_speech_prob": 0.019393399357795715}, {"id": 211, "seek": 132614, "start": 1326.8600000000001, "end": 1337.0200000000002, "text": " We used to rely heavily on canonical JSON to maintain the", "tokens": [50400, 492, 1143, 281, 10687, 10950, 322, 46491, 31828, 281, 6909, 264, 50908], "temperature": 0.0, "avg_logprob": -0.7634662759715113, "compression_ratio": 1.4251497005988023, "no_speech_prob": 0.09245353192090988}, {"id": 212, "seek": 132614, "start": 1337.0200000000002, "end": 1346.7, "text": " technicality of the company. How does that translate to the Mimi particular and get the", "tokens": [50908, 6191, 507, 295, 264, 2237, 13, 1012, 775, 300, 13799, 281, 264, 46709, 1729, 293, 483, 264, 51392], "temperature": 0.0, "avg_logprob": -0.7634662759715113, "compression_ratio": 1.4251497005988023, "no_speech_prob": 0.09245353192090988}, {"id": 213, "seek": 132614, "start": 1347.8200000000002, "end": 1354.22, "text": " intracorrel? Yeah, so the question is how... Like we've previously relied on canonical JSON.", "tokens": [51448, 560, 12080, 284, 4419, 30, 865, 11, 370, 264, 1168, 307, 577, 485, 1743, 321, 600, 8046, 35463, 322, 46491, 31828, 13, 51768], "temperature": 0.0, "avg_logprob": -0.7634662759715113, "compression_ratio": 1.4251497005988023, "no_speech_prob": 0.09245353192090988}, {"id": 214, "seek": 135422, "start": 1354.22, "end": 1359.82, "text": " How does that translate to Mimi and just general approaches with interoperability? So,", "tokens": [50364, 1012, 775, 300, 13799, 281, 46709, 293, 445, 2674, 11587, 365, 728, 7192, 2310, 30, 407, 11, 50644], "temperature": 0.0, "avg_logprob": -0.1308295748649387, "compression_ratio": 1.624113475177305, "no_speech_prob": 0.004436646122485399}, {"id": 215, "seek": 135422, "start": 1360.6200000000001, "end": 1366.94, "text": " canonical JSON has all sorts of interesting issues with it. What happens if you have multiple", "tokens": [50684, 46491, 31828, 575, 439, 7527, 295, 1880, 2663, 365, 309, 13, 708, 2314, 498, 291, 362, 3866, 51000], "temperature": 0.0, "avg_logprob": -0.1308295748649387, "compression_ratio": 1.624113475177305, "no_speech_prob": 0.004436646122485399}, {"id": 216, "seek": 135422, "start": 1366.94, "end": 1373.34, "text": " keys? What happens if the keys use a weird former of UTF-8? That sort of stuff. It's a very complicated", "tokens": [51000, 9317, 30, 708, 2314, 498, 264, 9317, 764, 257, 3657, 5819, 295, 35514, 37, 12, 23, 30, 663, 1333, 295, 1507, 13, 467, 311, 257, 588, 6179, 51320], "temperature": 0.0, "avg_logprob": -0.1308295748649387, "compression_ratio": 1.624113475177305, "no_speech_prob": 0.004436646122485399}, {"id": 217, "seek": 135422, "start": 1373.34, "end": 1379.1000000000001, "text": " set of rules that can realistically never be fully defined. So with a binary format, namely,", "tokens": [51320, 992, 295, 4474, 300, 393, 40734, 1128, 312, 4498, 7642, 13, 407, 365, 257, 17434, 7877, 11, 20926, 11, 51608], "temperature": 0.0, "avg_logprob": -0.1308295748649387, "compression_ratio": 1.624113475177305, "no_speech_prob": 0.004436646122485399}, {"id": 218, "seek": 135422, "start": 1379.1000000000001, "end": 1383.58, "text": " that's what Mimi's interested in, you don't necessarily need a canonicalization,", "tokens": [51608, 300, 311, 437, 46709, 311, 3102, 294, 11, 291, 500, 380, 4725, 643, 257, 46491, 2144, 11, 51832], "temperature": 0.0, "avg_logprob": -0.1308295748649387, "compression_ratio": 1.624113475177305, "no_speech_prob": 0.004436646122485399}, {"id": 219, "seek": 138358, "start": 1383.58, "end": 1390.1399999999999, "text": " because if you keep the signature for the event next to the event, rather than in the event,", "tokens": [50364, 570, 498, 291, 1066, 264, 13397, 337, 264, 2280, 958, 281, 264, 2280, 11, 2831, 813, 294, 264, 2280, 11, 50692], "temperature": 0.0, "avg_logprob": -0.07906798927151427, "compression_ratio": 1.673728813559322, "no_speech_prob": 0.0021097746212035418}, {"id": 220, "seek": 138358, "start": 1390.1399999999999, "end": 1396.06, "text": " like we currently have in Matrix, you are able to just sign the series of bytes. And the bytes", "tokens": [50692, 411, 321, 4362, 362, 294, 36274, 11, 291, 366, 1075, 281, 445, 1465, 264, 2638, 295, 36088, 13, 400, 264, 36088, 50988], "temperature": 0.0, "avg_logprob": -0.07906798927151427, "compression_ratio": 1.673728813559322, "no_speech_prob": 0.0021097746212035418}, {"id": 221, "seek": 138358, "start": 1396.06, "end": 1403.1799999999998, "text": " can be in whatever order. You can deserialize them, see them more easily, and then check the signature", "tokens": [50988, 393, 312, 294, 2035, 1668, 13, 509, 393, 730, 260, 831, 1125, 552, 11, 536, 552, 544, 3612, 11, 293, 550, 1520, 264, 13397, 51344], "temperature": 0.0, "avg_logprob": -0.07906798927151427, "compression_ratio": 1.673728813559322, "no_speech_prob": 0.0021097746212035418}, {"id": 222, "seek": 138358, "start": 1403.1799999999998, "end": 1410.6999999999998, "text": " much faster. So that's kind of where the Mimi direction is going, is we want to avoid a canonicalization", "tokens": [51344, 709, 4663, 13, 407, 300, 311, 733, 295, 689, 264, 46709, 3513, 307, 516, 11, 307, 321, 528, 281, 5042, 257, 46491, 2144, 51720], "temperature": 0.0, "avg_logprob": -0.07906798927151427, "compression_ratio": 1.673728813559322, "no_speech_prob": 0.0021097746212035418}, {"id": 223, "seek": 141070, "start": 1410.78, "end": 1417.98, "text": " algorithm, but we do need the more specific standard for what's contained in those bytes.", "tokens": [50368, 9284, 11, 457, 321, 360, 643, 264, 544, 2685, 3832, 337, 437, 311, 16212, 294, 729, 36088, 13, 50728], "temperature": 0.0, "avg_logprob": -0.15096944028680975, "compression_ratio": 1.0987654320987654, "no_speech_prob": 0.005159572698175907}, {"id": 224, "seek": 141798, "start": 1418.94, "end": 1422.78, "text": " This is something to be supported either throughout the chain,", "tokens": [50412, 639, 307, 746, 281, 312, 8104, 2139, 3710, 264, 5021, 11, 50604], "temperature": 0.0, "avg_logprob": -0.3138020498710766, "compression_ratio": 1.536144578313253, "no_speech_prob": 0.07926268130540848}, {"id": 225, "seek": 141798, "start": 1433.18, "end": 1441.98, "text": " yes, we are going to be pushing more towards keeping the, instead of trying to make everybody use", "tokens": [51124, 2086, 11, 321, 366, 516, 281, 312, 7380, 544, 3030, 5145, 264, 11, 2602, 295, 1382, 281, 652, 2201, 764, 51564], "temperature": 0.0, "avg_logprob": -0.3138020498710766, "compression_ratio": 1.536144578313253, "no_speech_prob": 0.07926268130540848}, {"id": 226, "seek": 141798, "start": 1441.98, "end": 1447.1, "text": " the existing matrix thing, I would suggest that matrix kind of adopt more of that binary event", "tokens": [51564, 264, 6741, 8141, 551, 11, 286, 576, 3402, 300, 8141, 733, 295, 6878, 544, 295, 300, 17434, 2280, 51820], "temperature": 0.0, "avg_logprob": -0.3138020498710766, "compression_ratio": 1.536144578313253, "no_speech_prob": 0.07926268130540848}, {"id": 227, "seek": 144710, "start": 1447.1799999999998, "end": 1450.54, "text": " signing instead. Yes.", "tokens": [50368, 13393, 2602, 13, 1079, 13, 50536], "temperature": 0.0, "avg_logprob": -0.17133107477304887, "compression_ratio": 1.5512820512820513, "no_speech_prob": 0.0039209723472595215}, {"id": 228, "seek": 144710, "start": 1450.54, "end": 1452.86, "text": " You had a slide with things you didn't talk about?", "tokens": [50536, 509, 632, 257, 4137, 365, 721, 291, 994, 380, 751, 466, 30, 50652], "temperature": 0.0, "avg_logprob": -0.17133107477304887, "compression_ratio": 1.5512820512820513, "no_speech_prob": 0.0039209723472595215}, {"id": 229, "seek": 144710, "start": 1452.86, "end": 1453.1, "text": " Yes.", "tokens": [50652, 1079, 13, 50664], "temperature": 0.0, "avg_logprob": -0.17133107477304887, "compression_ratio": 1.5512820512820513, "no_speech_prob": 0.0039209723472595215}, {"id": 230, "seek": 144710, "start": 1455.1, "end": 1460.9399999999998, "text": " In many places, primarily in the Mimi working group, that's where a lot of these conversations", "tokens": [50764, 682, 867, 3190, 11, 10029, 294, 264, 46709, 1364, 1594, 11, 300, 311, 689, 257, 688, 295, 613, 7315, 51056], "temperature": 0.0, "avg_logprob": -0.17133107477304887, "compression_ratio": 1.5512820512820513, "no_speech_prob": 0.0039209723472595215}, {"id": 231, "seek": 144710, "start": 1460.9399999999998, "end": 1465.6599999999999, "text": " are happening, as well as on the design team for Mimi. But if you are interested in them,", "tokens": [51056, 366, 2737, 11, 382, 731, 382, 322, 264, 1715, 1469, 337, 46709, 13, 583, 498, 291, 366, 3102, 294, 552, 11, 51292], "temperature": 0.0, "avg_logprob": -0.17133107477304887, "compression_ratio": 1.5512820512820513, "no_speech_prob": 0.0039209723472595215}, {"id": 232, "seek": 144710, "start": 1465.6599999999999, "end": 1473.74, "text": " or you have ideas, feel free to pop by the Matrix spec room on Matrix, and we'll be happy to engage.", "tokens": [51292, 420, 291, 362, 3487, 11, 841, 1737, 281, 1665, 538, 264, 36274, 1608, 1808, 322, 36274, 11, 293, 321, 603, 312, 2055, 281, 4683, 13, 51696], "temperature": 0.0, "avg_logprob": -0.17133107477304887, "compression_ratio": 1.5512820512820513, "no_speech_prob": 0.0039209723472595215}, {"id": 233, "seek": 147374, "start": 1473.74, "end": 1476.6200000000001, "text": " Do I have time for one more question? All right.", "tokens": [50364, 1144, 286, 362, 565, 337, 472, 544, 1168, 30, 1057, 558, 13, 50508], "temperature": 0.0, "avg_logprob": -0.2132322160821212, "compression_ratio": 1.212962962962963, "no_speech_prob": 0.0424664132297039}, {"id": 234, "seek": 147374, "start": 1491.5, "end": 1499.1, "text": " Yes. All right. So how do we avoid, basically if you have two protocol converters,", "tokens": [51252, 1079, 13, 1057, 558, 13, 407, 577, 360, 321, 5042, 11, 1936, 498, 291, 362, 732, 10336, 9652, 1559, 11, 51632], "temperature": 0.0, "avg_logprob": -0.2132322160821212, "compression_ratio": 1.212962962962963, "no_speech_prob": 0.0424664132297039}, {"id": 235, "seek": 149910, "start": 1499.1, "end": 1503.1799999999998, "text": " say they're both talking to the same network, how do you avoid message duplication?", "tokens": [50364, 584, 436, 434, 1293, 1417, 281, 264, 912, 3209, 11, 577, 360, 291, 5042, 3636, 17154, 399, 30, 50568], "temperature": 0.0, "avg_logprob": -0.10628183388415678, "compression_ratio": 1.506787330316742, "no_speech_prob": 0.02613404020667076}, {"id": 236, "seek": 149910, "start": 1506.3, "end": 1513.02, "text": " Good question. We'll have to experiment with it. We will be trying to", "tokens": [50724, 2205, 1168, 13, 492, 603, 362, 281, 5120, 365, 309, 13, 492, 486, 312, 1382, 281, 51060], "temperature": 0.0, "avg_logprob": -0.10628183388415678, "compression_ratio": 1.506787330316742, "no_speech_prob": 0.02613404020667076}, {"id": 237, "seek": 149910, "start": 1513.98, "end": 1519.82, "text": " figure out exactly what that looks like. We kind of have to wait until March 7th to see", "tokens": [51108, 2573, 484, 2293, 437, 300, 1542, 411, 13, 492, 733, 295, 362, 281, 1699, 1826, 6129, 1614, 392, 281, 536, 51400], "temperature": 0.0, "avg_logprob": -0.10628183388415678, "compression_ratio": 1.506787330316742, "no_speech_prob": 0.02613404020667076}, {"id": 238, "seek": 149910, "start": 1520.6999999999998, "end": 1527.74, "text": " what the actual gatekeepers, namely WhatsApp and Facebook Messenger, have to offer for that", "tokens": [51444, 437, 264, 3539, 8539, 43153, 11, 20926, 30513, 293, 4384, 34226, 11, 362, 281, 2626, 337, 300, 51796], "temperature": 0.0, "avg_logprob": -0.10628183388415678, "compression_ratio": 1.506787330316742, "no_speech_prob": 0.02613404020667076}, {"id": 239, "seek": 152774, "start": 1527.74, "end": 1536.86, "text": " certain capability. Thank you, Travis. Thank you.", "tokens": [50368, 1629, 13759, 13, 1044, 291, 11, 24430, 13, 1044, 291, 13, 50820], "temperature": 0.0, "avg_logprob": -0.3944465432848249, "compression_ratio": 1.0208333333333333, "no_speech_prob": 0.0012971562100574374}], "language": "en"}