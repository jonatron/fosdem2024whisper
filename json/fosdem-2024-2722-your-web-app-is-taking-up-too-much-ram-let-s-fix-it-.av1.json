{"text": " Hello everyone. Can you guys hear me properly? Nice, perfect. Yeah, today I wanted to start your presentation with quite a bold claim. I would say that your web app is taking up too much RAM and we could fix it. And this like comes from a thing that I noticed recently and is that if you look at your Chrome browser, you can see that if you hover over the tab, you will see that the Chrome is now starting, at least in a while, to tell users the memory usage of your app. Which like, if you look at most applications such as for example g-tub even while looking at a pretty big diff, the memory usage is not that bad. Yeah, like I mean, 122 megabytes were a lot in the 2000 but like now it's not as much. But if you look at other websites that maybe are a bit more expensive such as Airbnb, you can see that if we load a pretty big page, the memory usage goes way up. Like we're talking about half a gig of RAM being used by the browser. And what I was wondering like is it our fault? Is it the browser? What's in that memory that is being used? And we can find out how much of that is actually used by the JavaScript virtual machine, by our variables, our functions and our code. And the way of doing that, it's by opening the DevTools and there is a special tab called memory and you can see for each JavaScript virtual machine that is running, you can see how much memory is it taking up right now. Which in case of Airbnb, it was like 111 megabytes which is like, it's not much but it starts to be quite a bit especially when GitHub was like 10 megabytes compared to that. And then maybe you look at some more extreme examples such as here I propose fully stress test notion by loading a quite big table and we went into 1.5 gigabytes of RAM used just by JavaScript variables and that was quite wild because if you think about it, that's a lot. That's a lot for a web page. And also there are even worse examples or I would say more difficult examples like the product that I'm currently building and I'm building this web-based tool called the flux which is a tool for designing electronics on your browser and it is quite complicated because electronics is made up by a lot of different parts and it's built using typeskipped React, 3JS, React refiber so we use a bunch of technologies and also a bunch of abstractions to make our life easier and that had an effect on us. In fact because we wanted to be able to render very complicated documents with a lot of different shapes and text and everything has to run at 60 FPS, you can see how holding a big project can take a lot of RAM and that's something that backfired a bit. Why? Well because originally we focused a lot on performance, we wanted to have everything load very quickly, we wanted the scroll to be fast and originally we just optimized for performance, we were like yeah memory is cheap, let's just use whatever all the memory that we have so we just optimized what the profiler said, not what the memory profiler said and actually we did this because there was this article that from a while ago that was talking about yeah if you're building React apps just memorize everything, just cache everything that you can because that is not going to be an issue in most cases. People did we know that we were one of those cases and yeah and in fact you can see how like if you load a pretty big document at least before this talk the app will take too much RAM but they can really hear someone says well okay I have 16, 32 weeks of RAM on my desktop on my computer, why do I care about memory users, we're not in 1999 anymore. Well there are still a couple of reasons why we really care about this now and one of the reasons is out-of-memory crashes. If you're not optimizing memory usage the browser will limit you. In most cases for example in Chrome if you go over four gigabytes you will get this, you will get an old snap error code 5 which is an out-of-memory and there is no way to catch it, no way to solve it, the only thing that you can do is just prevent this from happening in the first place because here you will need to refresh the page to fix it. And on iOS it's even worse because on iOS sometimes the limit goes down and no one is really clear about what the limit is. For example if you are on Safari UIOS sometimes the limit can go as low as 300 megabytes and this is what you get, you get your browser loading up the page, trying to load the page then going out of memory, refreshing the page and going in an infinite refresh loop which you will see your user report and that's when your product manager will come screaming into your office why is the application not loading on my phone and because you're using too much RAM, so yeah clients might have a lot of RAM but your browser doesn't care, it will not let you use it. And another thing is that we also care about the garbage collection performance, if the more that you allocate the more that you will need to deallocate later and that's a thing that you have to care about because in some cases the garbage collection connection times can really hurt your performance. This is a bit of an extreme case that's like one minute of garbage collection but like this is something that is a bit more realistic. We were debugging an event handler that was supposed to run on mouse move so something that was totally off path and the major garbage collector took 0.5 seconds which means that there was a sharp drop in the frame per second just because the garbage collector had to kick in and so that's another thing that you want to care if you care about performance. Also memory is part of your performance optimization strategy and another thing is that as I showed before now Chrome is showing the memory usage of your website to your users so if your users are using like 12 tabs or if you are insane like in my case you have 10 browser's opens with a thousand tabs each, yeah that should start closing them maybe tomorrow. The users will be able to see that it's your website that is taking up their entire RAM and they will not be happy with you so now they will know which one it is and so yeah we're into a situation and for example my situation how do we solve this like how we approach this problem in flux? Well first of all it's important to figure out what is occupying memory and once you do that like there are multiple strategies that you can use to kill it with fire and then we also want to make sure we're not doing the same mistake aka we can set up some checks in CI or we can set up some monitoring even with remote users to check that the memory usage is not that bad right now. Of course in the talk of today I wanted to focus more on the first point because that's already a lot of things to talk about. So before going into the tooling I wanted to introduce some ideas about memory usage so that we know what we're talking about. I like to have those distinctions while talking about memory usage this is something that I made up in my analysis and like I noticed that there is a pattern of having either static or transient memory usage. What are we talking about here? Static memory usage it's when you have variables that are taking up a lot of RAM but they are long lived, they are global variables, they are state that is staying there and it's not really changing throughout the run of your application and that's basically what you would find in a heap snapshot and it is that the easy thing for example the document that loads and it is taking up a lot of RAM but you don't necessarily have a situation like that sometimes you could have a transient peak of memory usage which means that for example the user clicks a button and that button triggers a very quick operation which allocates an array with one million elements you can see it as a peak in the memory usage at that point and that sometimes can be a bit more hard to the bug because you want to find that on a heap snapshot because a heap snapshot is just taking an image of what's in your RAM at that moment and a peak of memory that would be de-allocated immediately won't show up in that so there are different strategies depending if we have the first or the second type of memory problem. Another thing that I like to consider is the count and the size of stuff. Why? Because you might have a very happy situation the kind of analysis wise in which you're locating a 500 megabyte string or a 500 megabytes array that's very different than allocating millions of small objects and if you have the first or the second situation you need to use completely different approach to analyze that because while if you have a giant object it would just show up in the memory profiler immediately as a very big object if you have millions of small elements it would be much harder to analyze them because you will need to check what's inside those those four bytes objects and another thing that I like to bring up is the difference between shallow and retained size and these are things those are two terms that you will see in the memory profiler and the reason for that is because in JavaScript everything is a pointer so if you have an array of strings it's actually an array of pointers to strings so the array itself could be very small like in order of bytes but the stuff that is pointing to could be giant like it could be pointing to a lot of one megabyte strings so when we talk about shallow size we talk about the size of that allocation itself such as the array which is small but that array it's causing other memory to stay allocated because it's referring to those one megabyte string so the retained size is instead the total amount of memory that that object or that array is forcing to stay and that is preventing from being deallocated and there's another last topic that is also quite complicated which are allocation types and which means that in JavaScript there are multiple things that you can allocate you have different other types you have code you have strings just array you have typed arrays you have also closures and each one of those behaves differently in memory and one cool thing that you can get from this is that for example also functions are something that can take up memory if you're not careful enough because functions need to save all the variables that are around them so technically that a function is an object as well in javascript and this means that even for example if you are creating functions in a loop that could become a memory problem because it's the same thing as creating an array of objects so like sometimes you can just look up the v8 in Chrome documentation and find a lot of interesting things about how memory is used internally but that's another topic for another talk I would say I wanted to instead look into tooling like if we are in a situation in which we have a lot of memory usage what are some tools that we can use to try to start to analyze what is going on and how to solve the problem well the most famous one is the common memory compiler which is that memory tab that you probably saw next to performance in the Chrome DevTools and it's quite powerful because it can work in three different modes I think the most interesting ones are the heap snapshot and the allocation sampling which works in very different ways for different purposes but it is that with the heap snapshot you can take a big snapshot of everything that it's in your RAM everything that javascript is working with and like imagine that you created a lot of variables in your code with this you can just save all of them and look at what's inside of them which is really cool because you can even see the values that you have there and for each one of those for each allocation that you have you can also see what is the retainer that means what why is this being a memory who created it and who is holding references to it and that's useful to determine who is the thing like what is the function that caused that thing to stay in memory and the heap snapshot are very useful if you want to check stuff like static memory usage because it takes a snapshot in time if instead you're more interested into transient memory peaks as I said before there is this other tool called the allocation sampling which works by accumulating every allocation that happens this means that everything that is allocated is saved here but you don't get the allocations so which is you can't really measure how much RAM you're using you can just measure who is creating that RAM that's objects we had not too many of them but some of them were taking a lot of RAM like 89 megabytes that's a lot and we had one specific object that was taking a giant amount of memory like 80 megabytes and which is then by looking at the retainers we were able to immediately figure out what was the function that was allocating that stuff that was retaining that stuff and that was one of the very first optimization that we managed to do because this way we went into the code into that function and realized how we were basically creating a bunch of functions this is react code and a bunch of string UIDs and saving all of them in a map and apparently that's incredibly inefficient that's probably not code that you look at the first at the first glance that it seems inefficient but if you call it thousands of times this is apparently sticking up 80 megs of RAM and so how did we solve this we refactored it a bit by using a set instead of a map and so it's very experiment based and with this we were able to have like a 50 percent improvement of memory usage which was huge and this really made the difference between being able to load some project at all or projects that would just crush your browser like documents and so that was one of the first big wins that we had so we were like yeah okay let's continue this eventually we will reach zero megs of memory use right no immediately after that we hit pretty much a brick wall in which we were taking hit snapshots and we were seeing that we had two million objects that were taking a lot of space and it's not that that like we had one big object to optimize each one of them was a couple of bytes and the heat profiler really doesn't help you in those cases and that's interesting because that's pretty much the same situation that you will find if you try to profile that same notion that I've tested it before or even Airbnb as it's actually the same problem and unfortunately the answer is the problem is react kind of and like we are in the same situation also with notion we have is it two geeks of ground no that can't be that is just being occupied by a lot of small objects so yeah we hit a brick wall but what we do now like the heat profiler is very bad and analyzing those kind of stuff thankfully we can export from it we can export a giant five gigabytes json from from chrome and then we look at the json and we see that the json it's in a format that is pretty much unreadable but thankfully there is someone that did work for us the guys at meta and it is beautiful tool called memelab which it's a toolkit for exploring memory usage which is very focused on finding memory leaks it has like an entire automation for that but I think this is even more it's even cooler because it provides you a very powerful API for opening snapshots from chrome and analyzing them what you can do is that basically you can read the objects in memory and perform analytics on them for example we wanted to answer this question which type of objects are taking up the most space out of the two millions that we found in a snapshot well this is a some code that we wrote I think that we don't have time to go too much into it but I can publish it the idea is that we can load the snapshot so load the current state of memory and find all the object types like what are what is the like the type skip type of the object computed total shallow size for each type and then sort and print results and from these the results were very cool because the um which is we had the for each object type even including like the the keys of the object how much memory they were occupying and which is we were able to see that on the top two we have one object that is called fiber node which is from react and another node another object that had base q base state memo state what the next q what is that that is not something that came from our application that's react again that's the data structure that is used internally for keeping tracks of hooks and so like we went into react to me so that there was exactly that other structure which in most websites that are using react heavily nowadays is pretty much the thing that is occupying the most memory with enough so it is we figured out that keeping tracks of hooks is expensive and but are we supposed to just tear down the 400 000 lines of react that we have in our app right now like that's a bit too far into the development so we wanted to know precisely what we need to optimize so we use memlum again this time we uh we see like even more uh by looking at this fiber node data structure that is used by reactor and we need a lot of statistics on it to try to figure out what is the react component that is taking up the most memory so that we can optimize that specific component first and we managed to do this because this way we were able to divide the odd memory uses by react component and see each hook how much memory it was using and with this we were able to find out a specific react component that was using a lot of memory and we cut the memory users down again by 60 percent which was pretty nice so that's like memlum saved us with this because we were able to make our app properly working and it also made us possible to answer other questions like as out of all the strings that we have in our app how many of those are uids should we start optimizing uids and make them numbers well no because we used memlum to find all the uids and we found out it was like two megabytes in total so who cares so that's also nice to know what to not prematurely optimize so just to sum up everything that i said i think that we can all agree that memory analysis is actually difficult especially because it varies so much between application between framework between browsers but it's important even if even in a world like nowadays in which we have a lot of a lot of round because for some apps it really makes a difference it makes the difference between you being able to use the notion on your phone or the app constantly crashing and never loading your data and that thing is that the chrome profiler is cool but sometimes it's not enough but thankfully it can export so that at least you can perform your own analysis externally so thank you for listening to representation thank you are there any questions i see a question here yes you were talking about the shallow size versus retained size yeah when would you ever be interested in looking at the shallow size sounds like the more interesting one yeah he asked about when do we care about shallow size when we also have the retained size well i yeah we care a lot about shallow size in our case it was all about shallow size where to write our own custom plugging for memblab to just analyze shallow size why because if you are analyzing like very big objects there are thousands of lines and in that case you have to use tricks like even virtual scrolling if you know that you can have like instead of allocating all the DOM elements you keep reusing the same ones and you think about that that's like ejecting from react because you are creating something just with javascript and the DOM and then you are creating a reactive wrapper for it so that's another thing that it shows that yeah react is good at orchestrating stuff but when it comes to the performance critical things that you want to have inside your application then you need to start optimizing it differently just a small mark or we continue with the questions so please if there are spaces please try to squeeze and not leave spaces in the middle as you could see we have hundreds of people waiting outside and here as well and we cannot have that many people on the sides so please try to squeeze don't let free seats for your jackets or something put it on your lap thank you and since we're starting to be quite a lot if you're going to go out please try to go out from the right side and avoid going out from the left side so that it's easier for everyone thank you we have a question here first i've got more more as a comment instead of a question so the thing is that with this limitation of four gigabytes for memory this comes from the fact that like chrome like compresses pointers so that small objects take less space basically that's one thing second thing is that is this is like a security mitigation so that when there is some like back in v8 it's harder to exploit it but also i've read on like a chromium box tracker that there is for example 16 gigabytes limit for fixed arrays so there may be different limitations for different things like web assembly also has a different limitation and also supposedly like electron abs doesn't have limits so yeah yeah that that's very cool thank you i think that firefox has pretty much the same limitations oh ask me if we're also trying with other browser yeah i'm mostly working on firefox actually and firefox has very similar limitation and sometimes it's even worse because sometimes we notice that the upper randomly sometimes takes more memory in firefox for some reason or some things are more optimized in firefox other things are more optimized in chrome so that that's very complicated to answer unfortunately because it seems like that the answer is either you look deeply into the source code of the browsers which is i still haven't reached that point unfortunately or you do try an error ah no the tooling um you know firefox also has tooling around it which is actually if i remember correctly more focused around analyzing the memory users of the DOM elements and it also has some facilities for for analyzing ip snapshots but since like memlab users works with chrome ip snapshots we went with that immediately and how do you go about running this in ci? oh um yeah that's a complicated thing because running in ci it's pure pain like you can use memlab and run it in ci because it uses playwright i don't remember if it uses playwright or puppeteer i think puppeteer and with it you can like orchestrate some some tests that open a page it can even like use some machine learning algorithm to find memory leaks the problem with doing that is that it's fine if your app is small if your app starts to become bigger then uh you will need to have a ci machine that is powerful enough to be able to run your app and the profiler on top of it which for us it meant that the the ci time went like in 30 minutes which was unacceptable so eventually we removed it but you can do it are there questions as your question there so from the browser or something like that? yeah that's another complicated thing because if you are using chrome i don't think that firefox allows you that but chrome does you have a specific performance or memory i think variable that you can use and you can check both the maximum heap allowed size and you can also read an estimate of the current family usage in our case once we do that we are constantly like giving data to segment then we analyze in amplitude with which we can like keep track of memory usage and we are also doing that for like the performance timing the problem is that we notice that that data who very quickly becomes bogus because it depends a lot on what the user is doing and when the garbage collector kicks in because the garbage collector sometimes is like it goes up to four gigabytes and then no problem goes down to 500 megabytes so it's extremely difficult to capture memory usage because you don't have a precise memory a precise measure on how much of the total retained memory is active and how much is actually inactive and going to be garbage collected soon so we try to do it and we have some charts showing how much memory is being used but it's very hard to make sense of them unfortunately any other questions you still have around five minutes for questions", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 11.64, "text": " Hello everyone. Can you guys hear me properly? Nice, perfect. Yeah, today I wanted to start", "tokens": [50364, 2425, 1518, 13, 1664, 291, 1074, 1568, 385, 6108, 30, 5490, 11, 2176, 13, 865, 11, 965, 286, 1415, 281, 722, 50946], "temperature": 0.0, "avg_logprob": -0.24126841416999475, "compression_ratio": 1.38860103626943, "no_speech_prob": 0.14137141406536102}, {"id": 1, "seek": 0, "start": 11.64, "end": 17.400000000000002, "text": " your presentation with quite a bold claim. I would say that your web app is taking up", "tokens": [50946, 428, 5860, 365, 1596, 257, 11928, 3932, 13, 286, 576, 584, 300, 428, 3670, 724, 307, 1940, 493, 51234], "temperature": 0.0, "avg_logprob": -0.24126841416999475, "compression_ratio": 1.38860103626943, "no_speech_prob": 0.14137141406536102}, {"id": 2, "seek": 0, "start": 17.400000000000002, "end": 26.48, "text": " too much RAM and we could fix it. And this like comes from a thing that I noticed recently", "tokens": [51234, 886, 709, 14561, 293, 321, 727, 3191, 309, 13, 400, 341, 411, 1487, 490, 257, 551, 300, 286, 5694, 3938, 51688], "temperature": 0.0, "avg_logprob": -0.24126841416999475, "compression_ratio": 1.38860103626943, "no_speech_prob": 0.14137141406536102}, {"id": 3, "seek": 2648, "start": 26.48, "end": 31.8, "text": " and is that if you look at your Chrome browser, you can see that if you hover over the tab,", "tokens": [50364, 293, 307, 300, 498, 291, 574, 412, 428, 15327, 11185, 11, 291, 393, 536, 300, 498, 291, 20076, 670, 264, 4421, 11, 50630], "temperature": 0.0, "avg_logprob": -0.21266867717107138, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.22923947870731354}, {"id": 4, "seek": 2648, "start": 31.8, "end": 39.28, "text": " you will see that the Chrome is now starting, at least in a while, to tell users the memory", "tokens": [50630, 291, 486, 536, 300, 264, 15327, 307, 586, 2891, 11, 412, 1935, 294, 257, 1339, 11, 281, 980, 5022, 264, 4675, 51004], "temperature": 0.0, "avg_logprob": -0.21266867717107138, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.22923947870731354}, {"id": 5, "seek": 2648, "start": 39.28, "end": 45.88, "text": " usage of your app. Which like, if you look at most applications such as for example g-tub", "tokens": [51004, 14924, 295, 428, 724, 13, 3013, 411, 11, 498, 291, 574, 412, 881, 5821, 1270, 382, 337, 1365, 290, 12, 83, 836, 51334], "temperature": 0.0, "avg_logprob": -0.21266867717107138, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.22923947870731354}, {"id": 6, "seek": 2648, "start": 45.88, "end": 50.760000000000005, "text": " even while looking at a pretty big diff, the memory usage is not that bad. Yeah, like I", "tokens": [51334, 754, 1339, 1237, 412, 257, 1238, 955, 7593, 11, 264, 4675, 14924, 307, 406, 300, 1578, 13, 865, 11, 411, 286, 51578], "temperature": 0.0, "avg_logprob": -0.21266867717107138, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.22923947870731354}, {"id": 7, "seek": 5076, "start": 50.76, "end": 58.72, "text": " mean, 122 megabytes were a lot in the 2000 but like now it's not as much. But if you look at", "tokens": [50364, 914, 11, 2272, 17, 10816, 24538, 645, 257, 688, 294, 264, 8132, 457, 411, 586, 309, 311, 406, 382, 709, 13, 583, 498, 291, 574, 412, 50762], "temperature": 0.0, "avg_logprob": -0.21488539377848306, "compression_ratio": 1.516, "no_speech_prob": 0.01110350526869297}, {"id": 8, "seek": 5076, "start": 58.72, "end": 66.75999999999999, "text": " other websites that maybe are a bit more expensive such as Airbnb, you can see that if we load a", "tokens": [50762, 661, 12891, 300, 1310, 366, 257, 857, 544, 5124, 1270, 382, 38232, 11, 291, 393, 536, 300, 498, 321, 3677, 257, 51164], "temperature": 0.0, "avg_logprob": -0.21488539377848306, "compression_ratio": 1.516, "no_speech_prob": 0.01110350526869297}, {"id": 9, "seek": 5076, "start": 66.75999999999999, "end": 72.96, "text": " pretty big page, the memory usage goes way up. Like we're talking about half a gig of RAM being", "tokens": [51164, 1238, 955, 3028, 11, 264, 4675, 14924, 1709, 636, 493, 13, 1743, 321, 434, 1417, 466, 1922, 257, 8741, 295, 14561, 885, 51474], "temperature": 0.0, "avg_logprob": -0.21488539377848306, "compression_ratio": 1.516, "no_speech_prob": 0.01110350526869297}, {"id": 10, "seek": 5076, "start": 72.96, "end": 79.92, "text": " used by the browser. And what I was wondering like is it our fault? Is it the browser? What's", "tokens": [51474, 1143, 538, 264, 11185, 13, 400, 437, 286, 390, 6359, 411, 307, 309, 527, 7441, 30, 1119, 309, 264, 11185, 30, 708, 311, 51822], "temperature": 0.0, "avg_logprob": -0.21488539377848306, "compression_ratio": 1.516, "no_speech_prob": 0.01110350526869297}, {"id": 11, "seek": 7992, "start": 80.08, "end": 88.6, "text": " in that memory that is being used? And we can find out how much of that is actually used by the", "tokens": [50372, 294, 300, 4675, 300, 307, 885, 1143, 30, 400, 321, 393, 915, 484, 577, 709, 295, 300, 307, 767, 1143, 538, 264, 50798], "temperature": 0.0, "avg_logprob": -0.18325274477722825, "compression_ratio": 1.7579908675799087, "no_speech_prob": 0.03688614070415497}, {"id": 12, "seek": 7992, "start": 88.6, "end": 94.72, "text": " JavaScript virtual machine, by our variables, our functions and our code. And the way of doing that,", "tokens": [50798, 15778, 6374, 3479, 11, 538, 527, 9102, 11, 527, 6828, 293, 527, 3089, 13, 400, 264, 636, 295, 884, 300, 11, 51104], "temperature": 0.0, "avg_logprob": -0.18325274477722825, "compression_ratio": 1.7579908675799087, "no_speech_prob": 0.03688614070415497}, {"id": 13, "seek": 7992, "start": 94.72, "end": 99.68, "text": " it's by opening the DevTools and there is a special tab called memory and you can see for", "tokens": [51104, 309, 311, 538, 5193, 264, 9096, 51, 29298, 293, 456, 307, 257, 2121, 4421, 1219, 4675, 293, 291, 393, 536, 337, 51352], "temperature": 0.0, "avg_logprob": -0.18325274477722825, "compression_ratio": 1.7579908675799087, "no_speech_prob": 0.03688614070415497}, {"id": 14, "seek": 7992, "start": 99.68, "end": 104.96000000000001, "text": " each JavaScript virtual machine that is running, you can see how much memory is it taking up right", "tokens": [51352, 1184, 15778, 6374, 3479, 300, 307, 2614, 11, 291, 393, 536, 577, 709, 4675, 307, 309, 1940, 493, 558, 51616], "temperature": 0.0, "avg_logprob": -0.18325274477722825, "compression_ratio": 1.7579908675799087, "no_speech_prob": 0.03688614070415497}, {"id": 15, "seek": 10496, "start": 104.96, "end": 112.55999999999999, "text": " now. Which in case of Airbnb, it was like 111 megabytes which is like, it's not much but it", "tokens": [50364, 586, 13, 3013, 294, 1389, 295, 38232, 11, 309, 390, 411, 2975, 16, 10816, 24538, 597, 307, 411, 11, 309, 311, 406, 709, 457, 309, 50744], "temperature": 0.0, "avg_logprob": -0.25958877885845344, "compression_ratio": 1.5106382978723405, "no_speech_prob": 0.00635708449408412}, {"id": 16, "seek": 10496, "start": 112.55999999999999, "end": 119.11999999999999, "text": " starts to be quite a bit especially when GitHub was like 10 megabytes compared to that. And then", "tokens": [50744, 3719, 281, 312, 1596, 257, 857, 2318, 562, 23331, 390, 411, 1266, 10816, 24538, 5347, 281, 300, 13, 400, 550, 51072], "temperature": 0.0, "avg_logprob": -0.25958877885845344, "compression_ratio": 1.5106382978723405, "no_speech_prob": 0.00635708449408412}, {"id": 17, "seek": 10496, "start": 119.11999999999999, "end": 126.0, "text": " maybe you look at some more extreme examples such as here I propose fully stress test notion by", "tokens": [51072, 1310, 291, 574, 412, 512, 544, 8084, 5110, 1270, 382, 510, 286, 17421, 4498, 4244, 1500, 10710, 538, 51416], "temperature": 0.0, "avg_logprob": -0.25958877885845344, "compression_ratio": 1.5106382978723405, "no_speech_prob": 0.00635708449408412}, {"id": 18, "seek": 12600, "start": 126.08, "end": 135.36, "text": " loading a quite big table and we went into 1.5 gigabytes of RAM used just by", "tokens": [50368, 15114, 257, 1596, 955, 3199, 293, 321, 1437, 666, 502, 13, 20, 42741, 295, 14561, 1143, 445, 538, 50832], "temperature": 0.0, "avg_logprob": -0.191796839922324, "compression_ratio": 1.517094017094017, "no_speech_prob": 0.03602242469787598}, {"id": 19, "seek": 12600, "start": 135.36, "end": 141.2, "text": " JavaScript variables and that was quite wild because if you think about it, that's a lot. That's", "tokens": [50832, 15778, 9102, 293, 300, 390, 1596, 4868, 570, 498, 291, 519, 466, 309, 11, 300, 311, 257, 688, 13, 663, 311, 51124], "temperature": 0.0, "avg_logprob": -0.191796839922324, "compression_ratio": 1.517094017094017, "no_speech_prob": 0.03602242469787598}, {"id": 20, "seek": 12600, "start": 141.2, "end": 148.56, "text": " a lot for a web page. And also there are even worse examples or I would say more difficult", "tokens": [51124, 257, 688, 337, 257, 3670, 3028, 13, 400, 611, 456, 366, 754, 5324, 5110, 420, 286, 576, 584, 544, 2252, 51492], "temperature": 0.0, "avg_logprob": -0.191796839922324, "compression_ratio": 1.517094017094017, "no_speech_prob": 0.03602242469787598}, {"id": 21, "seek": 12600, "start": 148.56, "end": 154.72, "text": " examples like the product that I'm currently building and I'm building this web-based tool", "tokens": [51492, 5110, 411, 264, 1674, 300, 286, 478, 4362, 2390, 293, 286, 478, 2390, 341, 3670, 12, 6032, 2290, 51800], "temperature": 0.0, "avg_logprob": -0.191796839922324, "compression_ratio": 1.517094017094017, "no_speech_prob": 0.03602242469787598}, {"id": 22, "seek": 15472, "start": 154.72, "end": 161.84, "text": " called the flux which is a tool for designing electronics on your browser and it is quite", "tokens": [50364, 1219, 264, 19298, 597, 307, 257, 2290, 337, 14685, 20611, 322, 428, 11185, 293, 309, 307, 1596, 50720], "temperature": 0.0, "avg_logprob": -0.23384818163785068, "compression_ratio": 1.5, "no_speech_prob": 0.0016569100553169847}, {"id": 23, "seek": 15472, "start": 161.84, "end": 169.68, "text": " complicated because electronics is made up by a lot of different parts and it's built using", "tokens": [50720, 6179, 570, 20611, 307, 1027, 493, 538, 257, 688, 295, 819, 3166, 293, 309, 311, 3094, 1228, 51112], "temperature": 0.0, "avg_logprob": -0.23384818163785068, "compression_ratio": 1.5, "no_speech_prob": 0.0016569100553169847}, {"id": 24, "seek": 15472, "start": 171.44, "end": 178.72, "text": " typeskipped React, 3JS, React refiber so we use a bunch of technologies and also a bunch of", "tokens": [51200, 3467, 74, 5529, 30644, 11, 805, 41, 50, 11, 30644, 1895, 5331, 370, 321, 764, 257, 3840, 295, 7943, 293, 611, 257, 3840, 295, 51564], "temperature": 0.0, "avg_logprob": -0.23384818163785068, "compression_ratio": 1.5, "no_speech_prob": 0.0016569100553169847}, {"id": 25, "seek": 17872, "start": 178.72, "end": 186.16, "text": " abstractions to make our life easier and that had an effect on us. In fact because we wanted to", "tokens": [50364, 12649, 626, 281, 652, 527, 993, 3571, 293, 300, 632, 364, 1802, 322, 505, 13, 682, 1186, 570, 321, 1415, 281, 50736], "temperature": 0.0, "avg_logprob": -0.13472163336617607, "compression_ratio": 1.4545454545454546, "no_speech_prob": 0.009343696758151054}, {"id": 26, "seek": 17872, "start": 186.16, "end": 193.68, "text": " be able to render very complicated documents with a lot of different shapes and text and everything", "tokens": [50736, 312, 1075, 281, 15529, 588, 6179, 8512, 365, 257, 688, 295, 819, 10854, 293, 2487, 293, 1203, 51112], "temperature": 0.0, "avg_logprob": -0.13472163336617607, "compression_ratio": 1.4545454545454546, "no_speech_prob": 0.009343696758151054}, {"id": 27, "seek": 17872, "start": 193.68, "end": 204.24, "text": " has to run at 60 FPS, you can see how holding a big project can take a lot of RAM and that's", "tokens": [51112, 575, 281, 1190, 412, 4060, 26429, 11, 291, 393, 536, 577, 5061, 257, 955, 1716, 393, 747, 257, 688, 295, 14561, 293, 300, 311, 51640], "temperature": 0.0, "avg_logprob": -0.13472163336617607, "compression_ratio": 1.4545454545454546, "no_speech_prob": 0.009343696758151054}, {"id": 28, "seek": 20424, "start": 204.32000000000002, "end": 211.36, "text": " something that backfired a bit. Why? Well because originally we focused a lot on performance,", "tokens": [50368, 746, 300, 646, 69, 1824, 257, 857, 13, 1545, 30, 1042, 570, 7993, 321, 5178, 257, 688, 322, 3389, 11, 50720], "temperature": 0.0, "avg_logprob": -0.16299323821335696, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.010702075436711311}, {"id": 29, "seek": 20424, "start": 211.36, "end": 217.84, "text": " we wanted to have everything load very quickly, we wanted the scroll to be fast and originally", "tokens": [50720, 321, 1415, 281, 362, 1203, 3677, 588, 2661, 11, 321, 1415, 264, 11369, 281, 312, 2370, 293, 7993, 51044], "temperature": 0.0, "avg_logprob": -0.16299323821335696, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.010702075436711311}, {"id": 30, "seek": 20424, "start": 217.84, "end": 223.44, "text": " we just optimized for performance, we were like yeah memory is cheap, let's just use whatever", "tokens": [51044, 321, 445, 26941, 337, 3389, 11, 321, 645, 411, 1338, 4675, 307, 7084, 11, 718, 311, 445, 764, 2035, 51324], "temperature": 0.0, "avg_logprob": -0.16299323821335696, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.010702075436711311}, {"id": 31, "seek": 20424, "start": 223.44, "end": 231.52, "text": " all the memory that we have so we just optimized what the profiler said, not what the memory profiler", "tokens": [51324, 439, 264, 4675, 300, 321, 362, 370, 321, 445, 26941, 437, 264, 1740, 5441, 848, 11, 406, 437, 264, 4675, 1740, 5441, 51728], "temperature": 0.0, "avg_logprob": -0.16299323821335696, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.010702075436711311}, {"id": 32, "seek": 23152, "start": 231.52, "end": 241.84, "text": " said and actually we did this because there was this article that from a while ago that was", "tokens": [50364, 848, 293, 767, 321, 630, 341, 570, 456, 390, 341, 7222, 300, 490, 257, 1339, 2057, 300, 390, 50880], "temperature": 0.0, "avg_logprob": -0.1255938857793808, "compression_ratio": 1.6136363636363635, "no_speech_prob": 0.006455329246819019}, {"id": 33, "seek": 23152, "start": 241.84, "end": 247.84, "text": " talking about yeah if you're building React apps just memorize everything, just cache everything", "tokens": [50880, 1417, 466, 1338, 498, 291, 434, 2390, 30644, 7733, 445, 27478, 1203, 11, 445, 19459, 1203, 51180], "temperature": 0.0, "avg_logprob": -0.1255938857793808, "compression_ratio": 1.6136363636363635, "no_speech_prob": 0.006455329246819019}, {"id": 34, "seek": 23152, "start": 247.84, "end": 255.20000000000002, "text": " that you can because that is not going to be an issue in most cases. People did we know that we", "tokens": [51180, 300, 291, 393, 570, 300, 307, 406, 516, 281, 312, 364, 2734, 294, 881, 3331, 13, 3432, 630, 321, 458, 300, 321, 51548], "temperature": 0.0, "avg_logprob": -0.1255938857793808, "compression_ratio": 1.6136363636363635, "no_speech_prob": 0.006455329246819019}, {"id": 35, "seek": 25520, "start": 255.2, "end": 261.92, "text": " were one of those cases and yeah and in fact you can see how like if you load a pretty big", "tokens": [50364, 645, 472, 295, 729, 3331, 293, 1338, 293, 294, 1186, 291, 393, 536, 577, 411, 498, 291, 3677, 257, 1238, 955, 50700], "temperature": 0.0, "avg_logprob": -0.1500002766998721, "compression_ratio": 1.4484536082474226, "no_speech_prob": 0.011441781185567379}, {"id": 36, "seek": 25520, "start": 261.92, "end": 271.84, "text": " document at least before this talk the app will take too much RAM but they can really hear someone", "tokens": [50700, 4166, 412, 1935, 949, 341, 751, 264, 724, 486, 747, 886, 709, 14561, 457, 436, 393, 534, 1568, 1580, 51196], "temperature": 0.0, "avg_logprob": -0.1500002766998721, "compression_ratio": 1.4484536082474226, "no_speech_prob": 0.011441781185567379}, {"id": 37, "seek": 25520, "start": 271.84, "end": 279.36, "text": " says well okay I have 16, 32 weeks of RAM on my desktop on my computer, why do I care about", "tokens": [51196, 1619, 731, 1392, 286, 362, 3165, 11, 8858, 3259, 295, 14561, 322, 452, 14502, 322, 452, 3820, 11, 983, 360, 286, 1127, 466, 51572], "temperature": 0.0, "avg_logprob": -0.1500002766998721, "compression_ratio": 1.4484536082474226, "no_speech_prob": 0.011441781185567379}, {"id": 38, "seek": 27936, "start": 279.36, "end": 286.48, "text": " memory users, we're not in 1999 anymore. Well there are still a couple of reasons why we really care", "tokens": [50364, 4675, 5022, 11, 321, 434, 406, 294, 19952, 3602, 13, 1042, 456, 366, 920, 257, 1916, 295, 4112, 983, 321, 534, 1127, 50720], "temperature": 0.0, "avg_logprob": -0.1437831766465131, "compression_ratio": 1.6458333333333333, "no_speech_prob": 0.044466838240623474}, {"id": 39, "seek": 27936, "start": 286.48, "end": 294.16, "text": " about this now and one of the reasons is out-of-memory crashes. If you're not optimizing memory usage", "tokens": [50720, 466, 341, 586, 293, 472, 295, 264, 4112, 307, 484, 12, 2670, 12, 17886, 827, 28642, 13, 759, 291, 434, 406, 40425, 4675, 14924, 51104], "temperature": 0.0, "avg_logprob": -0.1437831766465131, "compression_ratio": 1.6458333333333333, "no_speech_prob": 0.044466838240623474}, {"id": 40, "seek": 27936, "start": 294.16, "end": 299.44, "text": " the browser will limit you. In most cases for example in Chrome if you go over four gigabytes", "tokens": [51104, 264, 11185, 486, 4948, 291, 13, 682, 881, 3331, 337, 1365, 294, 15327, 498, 291, 352, 670, 1451, 42741, 51368], "temperature": 0.0, "avg_logprob": -0.1437831766465131, "compression_ratio": 1.6458333333333333, "no_speech_prob": 0.044466838240623474}, {"id": 41, "seek": 27936, "start": 300.32, "end": 306.16, "text": " you will get this, you will get an old snap error code 5 which is an out-of-memory and there is no", "tokens": [51412, 291, 486, 483, 341, 11, 291, 486, 483, 364, 1331, 13650, 6713, 3089, 1025, 597, 307, 364, 484, 12, 2670, 12, 17886, 827, 293, 456, 307, 572, 51704], "temperature": 0.0, "avg_logprob": -0.1437831766465131, "compression_ratio": 1.6458333333333333, "no_speech_prob": 0.044466838240623474}, {"id": 42, "seek": 30616, "start": 306.16, "end": 311.36, "text": " way to catch it, no way to solve it, the only thing that you can do is just prevent this from", "tokens": [50364, 636, 281, 3745, 309, 11, 572, 636, 281, 5039, 309, 11, 264, 787, 551, 300, 291, 393, 360, 307, 445, 4871, 341, 490, 50624], "temperature": 0.0, "avg_logprob": -0.1050065223206865, "compression_ratio": 1.6563876651982379, "no_speech_prob": 0.010066546499729156}, {"id": 43, "seek": 30616, "start": 311.36, "end": 315.68, "text": " happening in the first place because here you will need to refresh the page to fix it.", "tokens": [50624, 2737, 294, 264, 700, 1081, 570, 510, 291, 486, 643, 281, 15134, 264, 3028, 281, 3191, 309, 13, 50840], "temperature": 0.0, "avg_logprob": -0.1050065223206865, "compression_ratio": 1.6563876651982379, "no_speech_prob": 0.010066546499729156}, {"id": 44, "seek": 30616, "start": 316.48, "end": 322.88, "text": " And on iOS it's even worse because on iOS sometimes the limit goes down and no one is really clear", "tokens": [50880, 400, 322, 17430, 309, 311, 754, 5324, 570, 322, 17430, 2171, 264, 4948, 1709, 760, 293, 572, 472, 307, 534, 1850, 51200], "temperature": 0.0, "avg_logprob": -0.1050065223206865, "compression_ratio": 1.6563876651982379, "no_speech_prob": 0.010066546499729156}, {"id": 45, "seek": 30616, "start": 322.88, "end": 331.20000000000005, "text": " about what the limit is. For example if you are on Safari UIOS sometimes the limit can go as low", "tokens": [51200, 466, 437, 264, 4948, 307, 13, 1171, 1365, 498, 291, 366, 322, 43820, 15682, 4367, 2171, 264, 4948, 393, 352, 382, 2295, 51616], "temperature": 0.0, "avg_logprob": -0.1050065223206865, "compression_ratio": 1.6563876651982379, "no_speech_prob": 0.010066546499729156}, {"id": 46, "seek": 33120, "start": 331.2, "end": 338.88, "text": " as 300 megabytes and this is what you get, you get your browser loading up the page, trying to load", "tokens": [50364, 382, 6641, 10816, 24538, 293, 341, 307, 437, 291, 483, 11, 291, 483, 428, 11185, 15114, 493, 264, 3028, 11, 1382, 281, 3677, 50748], "temperature": 0.0, "avg_logprob": -0.12148405996601233, "compression_ratio": 1.7017543859649122, "no_speech_prob": 0.02317667193710804}, {"id": 47, "seek": 33120, "start": 338.88, "end": 343.2, "text": " the page then going out of memory, refreshing the page and going in an infinite refresh loop", "tokens": [50748, 264, 3028, 550, 516, 484, 295, 4675, 11, 19772, 264, 3028, 293, 516, 294, 364, 13785, 15134, 6367, 50964], "temperature": 0.0, "avg_logprob": -0.12148405996601233, "compression_ratio": 1.7017543859649122, "no_speech_prob": 0.02317667193710804}, {"id": 48, "seek": 33120, "start": 344.4, "end": 351.76, "text": " which you will see your user report and that's when your product manager will come screaming into", "tokens": [51024, 597, 291, 486, 536, 428, 4195, 2275, 293, 300, 311, 562, 428, 1674, 6598, 486, 808, 12636, 666, 51392], "temperature": 0.0, "avg_logprob": -0.12148405996601233, "compression_ratio": 1.7017543859649122, "no_speech_prob": 0.02317667193710804}, {"id": 49, "seek": 33120, "start": 351.76, "end": 356.71999999999997, "text": " your office why is the application not loading on my phone and because you're using too much RAM,", "tokens": [51392, 428, 3398, 983, 307, 264, 3861, 406, 15114, 322, 452, 2593, 293, 570, 291, 434, 1228, 886, 709, 14561, 11, 51640], "temperature": 0.0, "avg_logprob": -0.12148405996601233, "compression_ratio": 1.7017543859649122, "no_speech_prob": 0.02317667193710804}, {"id": 50, "seek": 35672, "start": 356.72, "end": 363.12, "text": " so yeah clients might have a lot of RAM but your browser doesn't care, it will not let you use it.", "tokens": [50364, 370, 1338, 6982, 1062, 362, 257, 688, 295, 14561, 457, 428, 11185, 1177, 380, 1127, 11, 309, 486, 406, 718, 291, 764, 309, 13, 50684], "temperature": 0.0, "avg_logprob": -0.11531167619683769, "compression_ratio": 1.7916666666666667, "no_speech_prob": 0.0017043808475136757}, {"id": 51, "seek": 35672, "start": 364.08000000000004, "end": 370.64000000000004, "text": " And another thing is that we also care about the garbage collection performance, if the more that", "tokens": [50732, 400, 1071, 551, 307, 300, 321, 611, 1127, 466, 264, 14150, 5765, 3389, 11, 498, 264, 544, 300, 51060], "temperature": 0.0, "avg_logprob": -0.11531167619683769, "compression_ratio": 1.7916666666666667, "no_speech_prob": 0.0017043808475136757}, {"id": 52, "seek": 35672, "start": 370.64000000000004, "end": 376.64000000000004, "text": " you allocate the more that you will need to deallocate later and that's a thing that you have to", "tokens": [51060, 291, 35713, 264, 544, 300, 291, 486, 643, 281, 368, 336, 42869, 1780, 293, 300, 311, 257, 551, 300, 291, 362, 281, 51360], "temperature": 0.0, "avg_logprob": -0.11531167619683769, "compression_ratio": 1.7916666666666667, "no_speech_prob": 0.0017043808475136757}, {"id": 53, "seek": 35672, "start": 376.64000000000004, "end": 381.6, "text": " care about because in some cases the garbage collection connection times can really hurt your", "tokens": [51360, 1127, 466, 570, 294, 512, 3331, 264, 14150, 5765, 4984, 1413, 393, 534, 4607, 428, 51608], "temperature": 0.0, "avg_logprob": -0.11531167619683769, "compression_ratio": 1.7916666666666667, "no_speech_prob": 0.0017043808475136757}, {"id": 54, "seek": 38160, "start": 381.6, "end": 386.32000000000005, "text": " performance. This is a bit of an extreme case that's like one minute of garbage collection", "tokens": [50364, 3389, 13, 639, 307, 257, 857, 295, 364, 8084, 1389, 300, 311, 411, 472, 3456, 295, 14150, 5765, 50600], "temperature": 0.0, "avg_logprob": -0.1574098362642176, "compression_ratio": 1.6651982378854626, "no_speech_prob": 0.022955333814024925}, {"id": 55, "seek": 38160, "start": 386.32000000000005, "end": 393.44, "text": " but like this is something that is a bit more realistic. We were debugging an event handler that", "tokens": [50600, 457, 411, 341, 307, 746, 300, 307, 257, 857, 544, 12465, 13, 492, 645, 45592, 364, 2280, 41967, 300, 50956], "temperature": 0.0, "avg_logprob": -0.1574098362642176, "compression_ratio": 1.6651982378854626, "no_speech_prob": 0.022955333814024925}, {"id": 56, "seek": 38160, "start": 393.44, "end": 401.28000000000003, "text": " was supposed to run on mouse move so something that was totally off path and the major garbage", "tokens": [50956, 390, 3442, 281, 1190, 322, 9719, 1286, 370, 746, 300, 390, 3879, 766, 3100, 293, 264, 2563, 14150, 51348], "temperature": 0.0, "avg_logprob": -0.1574098362642176, "compression_ratio": 1.6651982378854626, "no_speech_prob": 0.022955333814024925}, {"id": 57, "seek": 38160, "start": 401.28000000000003, "end": 409.36, "text": " collector took 0.5 seconds which means that there was a sharp drop in the frame per second just", "tokens": [51348, 23960, 1890, 1958, 13, 20, 3949, 597, 1355, 300, 456, 390, 257, 8199, 3270, 294, 264, 3920, 680, 1150, 445, 51752], "temperature": 0.0, "avg_logprob": -0.1574098362642176, "compression_ratio": 1.6651982378854626, "no_speech_prob": 0.022955333814024925}, {"id": 58, "seek": 40936, "start": 409.36, "end": 416.08000000000004, "text": " because the garbage collector had to kick in and so that's another thing that you want to care", "tokens": [50364, 570, 264, 14150, 23960, 632, 281, 4437, 294, 293, 370, 300, 311, 1071, 551, 300, 291, 528, 281, 1127, 50700], "temperature": 0.0, "avg_logprob": -0.1304871468316941, "compression_ratio": 1.726027397260274, "no_speech_prob": 0.005006921011954546}, {"id": 59, "seek": 40936, "start": 416.08000000000004, "end": 422.16, "text": " if you care about performance. Also memory is part of your performance optimization strategy", "tokens": [50700, 498, 291, 1127, 466, 3389, 13, 2743, 4675, 307, 644, 295, 428, 3389, 19618, 5206, 51004], "temperature": 0.0, "avg_logprob": -0.1304871468316941, "compression_ratio": 1.726027397260274, "no_speech_prob": 0.005006921011954546}, {"id": 60, "seek": 40936, "start": 423.6, "end": 430.0, "text": " and another thing is that as I showed before now Chrome is showing the memory usage of your", "tokens": [51076, 293, 1071, 551, 307, 300, 382, 286, 4712, 949, 586, 15327, 307, 4099, 264, 4675, 14924, 295, 428, 51396], "temperature": 0.0, "avg_logprob": -0.1304871468316941, "compression_ratio": 1.726027397260274, "no_speech_prob": 0.005006921011954546}, {"id": 61, "seek": 40936, "start": 430.0, "end": 438.96000000000004, "text": " website to your users so if your users are using like 12 tabs or if you are insane like in my case", "tokens": [51396, 3144, 281, 428, 5022, 370, 498, 428, 5022, 366, 1228, 411, 2272, 20743, 420, 498, 291, 366, 10838, 411, 294, 452, 1389, 51844], "temperature": 0.0, "avg_logprob": -0.1304871468316941, "compression_ratio": 1.726027397260274, "no_speech_prob": 0.005006921011954546}, {"id": 62, "seek": 43896, "start": 438.96, "end": 444.71999999999997, "text": " you have 10 browser's opens with a thousand tabs each, yeah that should start closing them maybe", "tokens": [50364, 291, 362, 1266, 11185, 311, 9870, 365, 257, 4714, 20743, 1184, 11, 1338, 300, 820, 722, 10377, 552, 1310, 50652], "temperature": 0.0, "avg_logprob": -0.20909258524576824, "compression_ratio": 1.6406926406926408, "no_speech_prob": 0.005116134881973267}, {"id": 63, "seek": 43896, "start": 444.71999999999997, "end": 452.88, "text": " tomorrow. The users will be able to see that it's your website that is taking up their entire", "tokens": [50652, 4153, 13, 440, 5022, 486, 312, 1075, 281, 536, 300, 309, 311, 428, 3144, 300, 307, 1940, 493, 641, 2302, 51060], "temperature": 0.0, "avg_logprob": -0.20909258524576824, "compression_ratio": 1.6406926406926408, "no_speech_prob": 0.005116134881973267}, {"id": 64, "seek": 43896, "start": 452.88, "end": 461.28, "text": " RAM and they will not be happy with you so now they will know which one it is and so yeah we're", "tokens": [51060, 14561, 293, 436, 486, 406, 312, 2055, 365, 291, 370, 586, 436, 486, 458, 597, 472, 309, 307, 293, 370, 1338, 321, 434, 51480], "temperature": 0.0, "avg_logprob": -0.20909258524576824, "compression_ratio": 1.6406926406926408, "no_speech_prob": 0.005116134881973267}, {"id": 65, "seek": 43896, "start": 461.28, "end": 466.64, "text": " into a situation and for example my situation how do we solve this like how we approach this", "tokens": [51480, 666, 257, 2590, 293, 337, 1365, 452, 2590, 577, 360, 321, 5039, 341, 411, 577, 321, 3109, 341, 51748], "temperature": 0.0, "avg_logprob": -0.20909258524576824, "compression_ratio": 1.6406926406926408, "no_speech_prob": 0.005116134881973267}, {"id": 66, "seek": 46664, "start": 466.64, "end": 473.2, "text": " problem in flux? Well first of all it's important to figure out what is occupying memory and once", "tokens": [50364, 1154, 294, 19298, 30, 1042, 700, 295, 439, 309, 311, 1021, 281, 2573, 484, 437, 307, 8073, 1840, 4675, 293, 1564, 50692], "temperature": 0.0, "avg_logprob": -0.08854951461156209, "compression_ratio": 1.680672268907563, "no_speech_prob": 0.006221150979399681}, {"id": 67, "seek": 46664, "start": 473.2, "end": 481.52, "text": " you do that like there are multiple strategies that you can use to kill it with fire and then we also", "tokens": [50692, 291, 360, 300, 411, 456, 366, 3866, 9029, 300, 291, 393, 764, 281, 1961, 309, 365, 2610, 293, 550, 321, 611, 51108], "temperature": 0.0, "avg_logprob": -0.08854951461156209, "compression_ratio": 1.680672268907563, "no_speech_prob": 0.006221150979399681}, {"id": 68, "seek": 46664, "start": 481.52, "end": 487.91999999999996, "text": " want to make sure we're not doing the same mistake aka we can set up some checks in CI or we can set", "tokens": [51108, 528, 281, 652, 988, 321, 434, 406, 884, 264, 912, 6146, 28042, 321, 393, 992, 493, 512, 13834, 294, 37777, 420, 321, 393, 992, 51428], "temperature": 0.0, "avg_logprob": -0.08854951461156209, "compression_ratio": 1.680672268907563, "no_speech_prob": 0.006221150979399681}, {"id": 69, "seek": 46664, "start": 487.91999999999996, "end": 493.36, "text": " up some monitoring even with remote users to check that the memory usage is not that bad right now.", "tokens": [51428, 493, 512, 11028, 754, 365, 8607, 5022, 281, 1520, 300, 264, 4675, 14924, 307, 406, 300, 1578, 558, 586, 13, 51700], "temperature": 0.0, "avg_logprob": -0.08854951461156209, "compression_ratio": 1.680672268907563, "no_speech_prob": 0.006221150979399681}, {"id": 70, "seek": 49336, "start": 494.0, "end": 500.24, "text": " Of course in the talk of today I wanted to focus more on the first point because that's already", "tokens": [50396, 2720, 1164, 294, 264, 751, 295, 965, 286, 1415, 281, 1879, 544, 322, 264, 700, 935, 570, 300, 311, 1217, 50708], "temperature": 0.0, "avg_logprob": -0.09705625562106862, "compression_ratio": 1.5856353591160222, "no_speech_prob": 0.003533444833010435}, {"id": 71, "seek": 49336, "start": 501.84000000000003, "end": 508.64, "text": " a lot of things to talk about. So before going into the tooling I wanted to introduce some", "tokens": [50788, 257, 688, 295, 721, 281, 751, 466, 13, 407, 949, 516, 666, 264, 46593, 286, 1415, 281, 5366, 512, 51128], "temperature": 0.0, "avg_logprob": -0.09705625562106862, "compression_ratio": 1.5856353591160222, "no_speech_prob": 0.003533444833010435}, {"id": 72, "seek": 49336, "start": 510.88, "end": 517.6800000000001, "text": " ideas about memory usage so that we know what we're talking about. I like to have those distinctions", "tokens": [51240, 3487, 466, 4675, 14924, 370, 300, 321, 458, 437, 321, 434, 1417, 466, 13, 286, 411, 281, 362, 729, 1483, 49798, 51580], "temperature": 0.0, "avg_logprob": -0.09705625562106862, "compression_ratio": 1.5856353591160222, "no_speech_prob": 0.003533444833010435}, {"id": 73, "seek": 51768, "start": 517.68, "end": 524.2399999999999, "text": " while talking about memory usage this is something that I made up in my analysis and like I noticed", "tokens": [50364, 1339, 1417, 466, 4675, 14924, 341, 307, 746, 300, 286, 1027, 493, 294, 452, 5215, 293, 411, 286, 5694, 50692], "temperature": 0.0, "avg_logprob": -0.12005468515249398, "compression_ratio": 1.7678571428571428, "no_speech_prob": 0.022270211949944496}, {"id": 74, "seek": 51768, "start": 524.2399999999999, "end": 530.2399999999999, "text": " that there is a pattern of having either static or transient memory usage. What are we talking about", "tokens": [50692, 300, 456, 307, 257, 5102, 295, 1419, 2139, 13437, 420, 41998, 4675, 14924, 13, 708, 366, 321, 1417, 466, 50992], "temperature": 0.0, "avg_logprob": -0.12005468515249398, "compression_ratio": 1.7678571428571428, "no_speech_prob": 0.022270211949944496}, {"id": 75, "seek": 51768, "start": 530.2399999999999, "end": 536.0799999999999, "text": " here? Static memory usage it's when you have variables that are taking up a lot of RAM but they", "tokens": [50992, 510, 30, 745, 2399, 4675, 14924, 309, 311, 562, 291, 362, 9102, 300, 366, 1940, 493, 257, 688, 295, 14561, 457, 436, 51284], "temperature": 0.0, "avg_logprob": -0.12005468515249398, "compression_ratio": 1.7678571428571428, "no_speech_prob": 0.022270211949944496}, {"id": 76, "seek": 51768, "start": 536.0799999999999, "end": 542.7199999999999, "text": " are long lived, they are global variables, they are state that is staying there and it's not really", "tokens": [51284, 366, 938, 5152, 11, 436, 366, 4338, 9102, 11, 436, 366, 1785, 300, 307, 7939, 456, 293, 309, 311, 406, 534, 51616], "temperature": 0.0, "avg_logprob": -0.12005468515249398, "compression_ratio": 1.7678571428571428, "no_speech_prob": 0.022270211949944496}, {"id": 77, "seek": 54272, "start": 542.72, "end": 549.0400000000001, "text": " changing throughout the run of your application and that's basically what you would find in a", "tokens": [50364, 4473, 3710, 264, 1190, 295, 428, 3861, 293, 300, 311, 1936, 437, 291, 576, 915, 294, 257, 50680], "temperature": 0.0, "avg_logprob": -0.13124856604150978, "compression_ratio": 1.7117117117117118, "no_speech_prob": 0.0011015563504770398}, {"id": 78, "seek": 54272, "start": 549.0400000000001, "end": 556.4, "text": " heap snapshot and it is that the easy thing for example the document that loads and it is taking", "tokens": [50680, 33591, 30163, 293, 309, 307, 300, 264, 1858, 551, 337, 1365, 264, 4166, 300, 12668, 293, 309, 307, 1940, 51048], "temperature": 0.0, "avg_logprob": -0.13124856604150978, "compression_ratio": 1.7117117117117118, "no_speech_prob": 0.0011015563504770398}, {"id": 79, "seek": 54272, "start": 556.4, "end": 562.48, "text": " up a lot of RAM but you don't necessarily have a situation like that sometimes you could have a", "tokens": [51048, 493, 257, 688, 295, 14561, 457, 291, 500, 380, 4725, 362, 257, 2590, 411, 300, 2171, 291, 727, 362, 257, 51352], "temperature": 0.0, "avg_logprob": -0.13124856604150978, "compression_ratio": 1.7117117117117118, "no_speech_prob": 0.0011015563504770398}, {"id": 80, "seek": 54272, "start": 562.48, "end": 568.5600000000001, "text": " transient peak of memory usage which means that for example the user clicks a button and that", "tokens": [51352, 41998, 10651, 295, 4675, 14924, 597, 1355, 300, 337, 1365, 264, 4195, 18521, 257, 2960, 293, 300, 51656], "temperature": 0.0, "avg_logprob": -0.13124856604150978, "compression_ratio": 1.7117117117117118, "no_speech_prob": 0.0011015563504770398}, {"id": 81, "seek": 56856, "start": 568.56, "end": 573.76, "text": " button triggers a very quick operation which allocates an array with one million elements", "tokens": [50364, 2960, 22827, 257, 588, 1702, 6916, 597, 12660, 1024, 364, 10225, 365, 472, 2459, 4959, 50624], "temperature": 0.0, "avg_logprob": -0.08275206335659685, "compression_ratio": 1.6818181818181819, "no_speech_prob": 0.0015576774021610618}, {"id": 82, "seek": 56856, "start": 574.8, "end": 581.28, "text": " you can see it as a peak in the memory usage at that point and that sometimes can be a bit more", "tokens": [50676, 291, 393, 536, 309, 382, 257, 10651, 294, 264, 4675, 14924, 412, 300, 935, 293, 300, 2171, 393, 312, 257, 857, 544, 51000], "temperature": 0.0, "avg_logprob": -0.08275206335659685, "compression_ratio": 1.6818181818181819, "no_speech_prob": 0.0015576774021610618}, {"id": 83, "seek": 56856, "start": 581.28, "end": 586.88, "text": " hard to the bug because you want to find that on a heap snapshot because a heap snapshot is just", "tokens": [51000, 1152, 281, 264, 7426, 570, 291, 528, 281, 915, 300, 322, 257, 33591, 30163, 570, 257, 33591, 30163, 307, 445, 51280], "temperature": 0.0, "avg_logprob": -0.08275206335659685, "compression_ratio": 1.6818181818181819, "no_speech_prob": 0.0015576774021610618}, {"id": 84, "seek": 56856, "start": 587.4399999999999, "end": 593.4399999999999, "text": " taking an image of what's in your RAM at that moment and a peak of memory that would be", "tokens": [51308, 1940, 364, 3256, 295, 437, 311, 294, 428, 14561, 412, 300, 1623, 293, 257, 10651, 295, 4675, 300, 576, 312, 51608], "temperature": 0.0, "avg_logprob": -0.08275206335659685, "compression_ratio": 1.6818181818181819, "no_speech_prob": 0.0015576774021610618}, {"id": 85, "seek": 59344, "start": 593.5200000000001, "end": 598.72, "text": " de-allocated immediately won't show up in that so there are different strategies depending if we", "tokens": [50368, 368, 12, 336, 905, 770, 4258, 1582, 380, 855, 493, 294, 300, 370, 456, 366, 819, 9029, 5413, 498, 321, 50628], "temperature": 0.0, "avg_logprob": -0.1451139347527617, "compression_ratio": 1.5896414342629481, "no_speech_prob": 0.00547720305621624}, {"id": 86, "seek": 59344, "start": 598.72, "end": 607.2, "text": " have the first or the second type of memory problem. Another thing that I like to consider is the count", "tokens": [50628, 362, 264, 700, 420, 264, 1150, 2010, 295, 4675, 1154, 13, 3996, 551, 300, 286, 411, 281, 1949, 307, 264, 1207, 51052], "temperature": 0.0, "avg_logprob": -0.1451139347527617, "compression_ratio": 1.5896414342629481, "no_speech_prob": 0.00547720305621624}, {"id": 87, "seek": 59344, "start": 608.08, "end": 615.6, "text": " and the size of stuff. Why? Because you might have a very happy situation the kind of analysis wise", "tokens": [51096, 293, 264, 2744, 295, 1507, 13, 1545, 30, 1436, 291, 1062, 362, 257, 588, 2055, 2590, 264, 733, 295, 5215, 10829, 51472], "temperature": 0.0, "avg_logprob": -0.1451139347527617, "compression_ratio": 1.5896414342629481, "no_speech_prob": 0.00547720305621624}, {"id": 88, "seek": 59344, "start": 615.6, "end": 622.8800000000001, "text": " in which you're locating a 500 megabyte string or a 500 megabytes array that's very different than", "tokens": [51472, 294, 597, 291, 434, 1628, 990, 257, 5923, 10816, 34529, 6798, 420, 257, 5923, 10816, 24538, 10225, 300, 311, 588, 819, 813, 51836], "temperature": 0.0, "avg_logprob": -0.1451139347527617, "compression_ratio": 1.5896414342629481, "no_speech_prob": 0.00547720305621624}, {"id": 89, "seek": 62344, "start": 623.7600000000001, "end": 631.2800000000001, "text": " allocating millions of small objects and if you have the first or the second situation you need to", "tokens": [50380, 12660, 990, 6803, 295, 1359, 6565, 293, 498, 291, 362, 264, 700, 420, 264, 1150, 2590, 291, 643, 281, 50756], "temperature": 0.0, "avg_logprob": -0.0931155709659352, "compression_ratio": 1.8211009174311927, "no_speech_prob": 0.0017629603389650583}, {"id": 90, "seek": 62344, "start": 631.2800000000001, "end": 637.2, "text": " use completely different approach to analyze that because while if you have a giant object it would", "tokens": [50756, 764, 2584, 819, 3109, 281, 12477, 300, 570, 1339, 498, 291, 362, 257, 7410, 2657, 309, 576, 51052], "temperature": 0.0, "avg_logprob": -0.0931155709659352, "compression_ratio": 1.8211009174311927, "no_speech_prob": 0.0017629603389650583}, {"id": 91, "seek": 62344, "start": 637.2, "end": 643.44, "text": " just show up in the memory profiler immediately as a very big object if you have millions of small", "tokens": [51052, 445, 855, 493, 294, 264, 4675, 1740, 5441, 4258, 382, 257, 588, 955, 2657, 498, 291, 362, 6803, 295, 1359, 51364], "temperature": 0.0, "avg_logprob": -0.0931155709659352, "compression_ratio": 1.8211009174311927, "no_speech_prob": 0.0017629603389650583}, {"id": 92, "seek": 62344, "start": 643.44, "end": 648.5600000000001, "text": " elements it would be much harder to analyze them because you will need to check what's inside those", "tokens": [51364, 4959, 309, 576, 312, 709, 6081, 281, 12477, 552, 570, 291, 486, 643, 281, 1520, 437, 311, 1854, 729, 51620], "temperature": 0.0, "avg_logprob": -0.0931155709659352, "compression_ratio": 1.8211009174311927, "no_speech_prob": 0.0017629603389650583}, {"id": 93, "seek": 64856, "start": 649.1199999999999, "end": 656.3199999999999, "text": " those four bytes objects and another thing that I like to bring up is the difference between", "tokens": [50392, 729, 1451, 36088, 6565, 293, 1071, 551, 300, 286, 411, 281, 1565, 493, 307, 264, 2649, 1296, 50752], "temperature": 0.0, "avg_logprob": -0.1090540885925293, "compression_ratio": 1.7098214285714286, "no_speech_prob": 0.0006647455156780779}, {"id": 94, "seek": 64856, "start": 656.3199999999999, "end": 661.3599999999999, "text": " shallow and retained size and these are things those are two terms that you will see in the memory", "tokens": [50752, 20488, 293, 33438, 2744, 293, 613, 366, 721, 729, 366, 732, 2115, 300, 291, 486, 536, 294, 264, 4675, 51004], "temperature": 0.0, "avg_logprob": -0.1090540885925293, "compression_ratio": 1.7098214285714286, "no_speech_prob": 0.0006647455156780779}, {"id": 95, "seek": 64856, "start": 661.3599999999999, "end": 670.3199999999999, "text": " profiler and the reason for that is because in JavaScript everything is a pointer so if you", "tokens": [51004, 1740, 5441, 293, 264, 1778, 337, 300, 307, 570, 294, 15778, 1203, 307, 257, 23918, 370, 498, 291, 51452], "temperature": 0.0, "avg_logprob": -0.1090540885925293, "compression_ratio": 1.7098214285714286, "no_speech_prob": 0.0006647455156780779}, {"id": 96, "seek": 64856, "start": 671.04, "end": 677.4399999999999, "text": " have an array of strings it's actually an array of pointers to strings so the array itself could be", "tokens": [51488, 362, 364, 10225, 295, 13985, 309, 311, 767, 364, 10225, 295, 44548, 281, 13985, 370, 264, 10225, 2564, 727, 312, 51808], "temperature": 0.0, "avg_logprob": -0.1090540885925293, "compression_ratio": 1.7098214285714286, "no_speech_prob": 0.0006647455156780779}, {"id": 97, "seek": 67744, "start": 677.44, "end": 683.2, "text": " very small like in order of bytes but the stuff that is pointing to could be giant like it could", "tokens": [50364, 588, 1359, 411, 294, 1668, 295, 36088, 457, 264, 1507, 300, 307, 12166, 281, 727, 312, 7410, 411, 309, 727, 50652], "temperature": 0.0, "avg_logprob": -0.06050026151869032, "compression_ratio": 1.8738317757009346, "no_speech_prob": 0.0021543463226407766}, {"id": 98, "seek": 67744, "start": 683.2, "end": 690.24, "text": " be pointing to a lot of one megabyte strings so when we talk about shallow size we talk about the size", "tokens": [50652, 312, 12166, 281, 257, 688, 295, 472, 10816, 34529, 13985, 370, 562, 321, 751, 466, 20488, 2744, 321, 751, 466, 264, 2744, 51004], "temperature": 0.0, "avg_logprob": -0.06050026151869032, "compression_ratio": 1.8738317757009346, "no_speech_prob": 0.0021543463226407766}, {"id": 99, "seek": 67744, "start": 690.24, "end": 697.9200000000001, "text": " of that allocation itself such as the array which is small but that array it's causing other memory", "tokens": [51004, 295, 300, 27599, 2564, 1270, 382, 264, 10225, 597, 307, 1359, 457, 300, 10225, 309, 311, 9853, 661, 4675, 51388], "temperature": 0.0, "avg_logprob": -0.06050026151869032, "compression_ratio": 1.8738317757009346, "no_speech_prob": 0.0021543463226407766}, {"id": 100, "seek": 67744, "start": 697.9200000000001, "end": 706.08, "text": " to stay allocated because it's referring to those one megabyte string so the retained size is instead", "tokens": [51388, 281, 1754, 29772, 570, 309, 311, 13761, 281, 729, 472, 10816, 34529, 6798, 370, 264, 33438, 2744, 307, 2602, 51796], "temperature": 0.0, "avg_logprob": -0.06050026151869032, "compression_ratio": 1.8738317757009346, "no_speech_prob": 0.0021543463226407766}, {"id": 101, "seek": 70608, "start": 706.64, "end": 715.5200000000001, "text": " the total amount of memory that that object or that array is forcing to stay and that is preventing", "tokens": [50392, 264, 3217, 2372, 295, 4675, 300, 300, 2657, 420, 300, 10225, 307, 19030, 281, 1754, 293, 300, 307, 19965, 50836], "temperature": 0.0, "avg_logprob": -0.10031671058840869, "compression_ratio": 1.8537735849056605, "no_speech_prob": 0.0010737372795119882}, {"id": 102, "seek": 70608, "start": 715.5200000000001, "end": 721.0400000000001, "text": " from being deallocated and there's another last topic that is also quite complicated which are", "tokens": [50836, 490, 885, 368, 336, 905, 770, 293, 456, 311, 1071, 1036, 4829, 300, 307, 611, 1596, 6179, 597, 366, 51112], "temperature": 0.0, "avg_logprob": -0.10031671058840869, "compression_ratio": 1.8537735849056605, "no_speech_prob": 0.0010737372795119882}, {"id": 103, "seek": 70608, "start": 721.0400000000001, "end": 728.8000000000001, "text": " allocation types and which means that in JavaScript there are multiple things that you can allocate", "tokens": [51112, 27599, 3467, 293, 597, 1355, 300, 294, 15778, 456, 366, 3866, 721, 300, 291, 393, 35713, 51500], "temperature": 0.0, "avg_logprob": -0.10031671058840869, "compression_ratio": 1.8537735849056605, "no_speech_prob": 0.0010737372795119882}, {"id": 104, "seek": 70608, "start": 728.8000000000001, "end": 733.6800000000001, "text": " you have different other types you have code you have strings just array you have typed arrays you", "tokens": [51500, 291, 362, 819, 661, 3467, 291, 362, 3089, 291, 362, 13985, 445, 10225, 291, 362, 33941, 41011, 291, 51744], "temperature": 0.0, "avg_logprob": -0.10031671058840869, "compression_ratio": 1.8537735849056605, "no_speech_prob": 0.0010737372795119882}, {"id": 105, "seek": 73368, "start": 733.68, "end": 742.2399999999999, "text": " have also closures and each one of those behaves differently in memory and one cool thing that you", "tokens": [50364, 362, 611, 2611, 1303, 293, 1184, 472, 295, 729, 36896, 7614, 294, 4675, 293, 472, 1627, 551, 300, 291, 50792], "temperature": 0.0, "avg_logprob": -0.09437291324138641, "compression_ratio": 1.6740331491712708, "no_speech_prob": 0.0017266453942283988}, {"id": 106, "seek": 73368, "start": 742.2399999999999, "end": 748.88, "text": " can get from this is that for example also functions are something that can take up memory if you're", "tokens": [50792, 393, 483, 490, 341, 307, 300, 337, 1365, 611, 6828, 366, 746, 300, 393, 747, 493, 4675, 498, 291, 434, 51124], "temperature": 0.0, "avg_logprob": -0.09437291324138641, "compression_ratio": 1.6740331491712708, "no_speech_prob": 0.0017266453942283988}, {"id": 107, "seek": 73368, "start": 748.88, "end": 756.2399999999999, "text": " not careful enough because functions need to save all the variables that are around them so technically", "tokens": [51124, 406, 5026, 1547, 570, 6828, 643, 281, 3155, 439, 264, 9102, 300, 366, 926, 552, 370, 12120, 51492], "temperature": 0.0, "avg_logprob": -0.09437291324138641, "compression_ratio": 1.6740331491712708, "no_speech_prob": 0.0017266453942283988}, {"id": 108, "seek": 75624, "start": 756.8, "end": 763.84, "text": " that a function is an object as well in javascript and this means that even for example if you are", "tokens": [50392, 300, 257, 2445, 307, 364, 2657, 382, 731, 294, 361, 37331, 5944, 293, 341, 1355, 300, 754, 337, 1365, 498, 291, 366, 50744], "temperature": 0.0, "avg_logprob": -0.06587922295858693, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.00675964867696166}, {"id": 109, "seek": 75624, "start": 763.84, "end": 768.48, "text": " creating functions in a loop that could become a memory problem because it's the same thing as", "tokens": [50744, 4084, 6828, 294, 257, 6367, 300, 727, 1813, 257, 4675, 1154, 570, 309, 311, 264, 912, 551, 382, 50976], "temperature": 0.0, "avg_logprob": -0.06587922295858693, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.00675964867696166}, {"id": 110, "seek": 75624, "start": 768.48, "end": 777.44, "text": " creating an array of objects so like sometimes you can just look up the v8 in Chrome documentation", "tokens": [50976, 4084, 364, 10225, 295, 6565, 370, 411, 2171, 291, 393, 445, 574, 493, 264, 371, 23, 294, 15327, 14333, 51424], "temperature": 0.0, "avg_logprob": -0.06587922295858693, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.00675964867696166}, {"id": 111, "seek": 75624, "start": 777.44, "end": 783.04, "text": " and find a lot of interesting things about how memory is used internally but that's another", "tokens": [51424, 293, 915, 257, 688, 295, 1880, 721, 466, 577, 4675, 307, 1143, 19501, 457, 300, 311, 1071, 51704], "temperature": 0.0, "avg_logprob": -0.06587922295858693, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.00675964867696166}, {"id": 112, "seek": 78304, "start": 783.04, "end": 788.4, "text": " topic for another talk I would say I wanted to instead look into tooling like if we are in a", "tokens": [50364, 4829, 337, 1071, 751, 286, 576, 584, 286, 1415, 281, 2602, 574, 666, 46593, 411, 498, 321, 366, 294, 257, 50632], "temperature": 0.0, "avg_logprob": -0.11185876713242641, "compression_ratio": 1.7222222222222223, "no_speech_prob": 0.003681981936097145}, {"id": 113, "seek": 78304, "start": 788.4, "end": 795.68, "text": " situation in which we have a lot of memory usage what are some tools that we can use to try to", "tokens": [50632, 2590, 294, 597, 321, 362, 257, 688, 295, 4675, 14924, 437, 366, 512, 3873, 300, 321, 393, 764, 281, 853, 281, 50996], "temperature": 0.0, "avg_logprob": -0.11185876713242641, "compression_ratio": 1.7222222222222223, "no_speech_prob": 0.003681981936097145}, {"id": 114, "seek": 78304, "start": 795.68, "end": 802.88, "text": " start to analyze what is going on and how to solve the problem well the most famous one is the", "tokens": [50996, 722, 281, 12477, 437, 307, 516, 322, 293, 577, 281, 5039, 264, 1154, 731, 264, 881, 4618, 472, 307, 264, 51356], "temperature": 0.0, "avg_logprob": -0.11185876713242641, "compression_ratio": 1.7222222222222223, "no_speech_prob": 0.003681981936097145}, {"id": 115, "seek": 78304, "start": 802.88, "end": 807.92, "text": " common memory compiler which is that memory tab that you probably saw next to performance", "tokens": [51356, 2689, 4675, 31958, 597, 307, 300, 4675, 4421, 300, 291, 1391, 1866, 958, 281, 3389, 51608], "temperature": 0.0, "avg_logprob": -0.11185876713242641, "compression_ratio": 1.7222222222222223, "no_speech_prob": 0.003681981936097145}, {"id": 116, "seek": 80792, "start": 808.88, "end": 814.4799999999999, "text": " in the Chrome DevTools and it's quite powerful because it can work in three different modes I", "tokens": [50412, 294, 264, 15327, 9096, 51, 29298, 293, 309, 311, 1596, 4005, 570, 309, 393, 589, 294, 1045, 819, 14068, 286, 50692], "temperature": 0.0, "avg_logprob": -0.1452798728483269, "compression_ratio": 1.7363636363636363, "no_speech_prob": 0.002167305676266551}, {"id": 117, "seek": 80792, "start": 814.4799999999999, "end": 820.88, "text": " think the most interesting ones are the heap snapshot and the allocation sampling which works in", "tokens": [50692, 519, 264, 881, 1880, 2306, 366, 264, 33591, 30163, 293, 264, 27599, 21179, 597, 1985, 294, 51012], "temperature": 0.0, "avg_logprob": -0.1452798728483269, "compression_ratio": 1.7363636363636363, "no_speech_prob": 0.002167305676266551}, {"id": 118, "seek": 80792, "start": 820.88, "end": 827.68, "text": " very different ways for different purposes but it is that with the heap snapshot you can take a big", "tokens": [51012, 588, 819, 2098, 337, 819, 9932, 457, 309, 307, 300, 365, 264, 33591, 30163, 291, 393, 747, 257, 955, 51352], "temperature": 0.0, "avg_logprob": -0.1452798728483269, "compression_ratio": 1.7363636363636363, "no_speech_prob": 0.002167305676266551}, {"id": 119, "seek": 80792, "start": 827.68, "end": 834.7199999999999, "text": " snapshot of everything that it's in your RAM everything that javascript is working with and", "tokens": [51352, 30163, 295, 1203, 300, 309, 311, 294, 428, 14561, 1203, 300, 361, 37331, 5944, 307, 1364, 365, 293, 51704], "temperature": 0.0, "avg_logprob": -0.1452798728483269, "compression_ratio": 1.7363636363636363, "no_speech_prob": 0.002167305676266551}, {"id": 120, "seek": 83472, "start": 834.72, "end": 840.8000000000001, "text": " like imagine that you created a lot of variables in your code with this you can just save all of them", "tokens": [50364, 411, 3811, 300, 291, 2942, 257, 688, 295, 9102, 294, 428, 3089, 365, 341, 291, 393, 445, 3155, 439, 295, 552, 50668], "temperature": 0.0, "avg_logprob": -0.06839968083979009, "compression_ratio": 1.8341232227488151, "no_speech_prob": 0.006002296693623066}, {"id": 121, "seek": 83472, "start": 840.8000000000001, "end": 846.72, "text": " and look at what's inside of them which is really cool because you can even see the values that you", "tokens": [50668, 293, 574, 412, 437, 311, 1854, 295, 552, 597, 307, 534, 1627, 570, 291, 393, 754, 536, 264, 4190, 300, 291, 50964], "temperature": 0.0, "avg_logprob": -0.06839968083979009, "compression_ratio": 1.8341232227488151, "no_speech_prob": 0.006002296693623066}, {"id": 122, "seek": 83472, "start": 846.72, "end": 853.44, "text": " have there and for each one of those for each allocation that you have you can also see what", "tokens": [50964, 362, 456, 293, 337, 1184, 472, 295, 729, 337, 1184, 27599, 300, 291, 362, 291, 393, 611, 536, 437, 51300], "temperature": 0.0, "avg_logprob": -0.06839968083979009, "compression_ratio": 1.8341232227488151, "no_speech_prob": 0.006002296693623066}, {"id": 123, "seek": 83472, "start": 853.44, "end": 861.2, "text": " is the retainer that means what why is this being a memory who created it and who is holding", "tokens": [51300, 307, 264, 18340, 260, 300, 1355, 437, 983, 307, 341, 885, 257, 4675, 567, 2942, 309, 293, 567, 307, 5061, 51688], "temperature": 0.0, "avg_logprob": -0.06839968083979009, "compression_ratio": 1.8341232227488151, "no_speech_prob": 0.006002296693623066}, {"id": 124, "seek": 86120, "start": 861.2800000000001, "end": 867.76, "text": " references to it and that's useful to determine who is the thing like what is the function that", "tokens": [50368, 15400, 281, 309, 293, 300, 311, 4420, 281, 6997, 567, 307, 264, 551, 411, 437, 307, 264, 2445, 300, 50692], "temperature": 0.0, "avg_logprob": -0.09239224353468561, "compression_ratio": 1.75, "no_speech_prob": 0.0019649548921734095}, {"id": 125, "seek": 86120, "start": 869.44, "end": 875.6800000000001, "text": " caused that thing to stay in memory and the heap snapshot are very useful if you want to check", "tokens": [50776, 7008, 300, 551, 281, 1754, 294, 4675, 293, 264, 33591, 30163, 366, 588, 4420, 498, 291, 528, 281, 1520, 51088], "temperature": 0.0, "avg_logprob": -0.09239224353468561, "compression_ratio": 1.75, "no_speech_prob": 0.0019649548921734095}, {"id": 126, "seek": 86120, "start": 876.5600000000001, "end": 882.1600000000001, "text": " stuff like static memory usage because it takes a snapshot in time if instead you're more interested", "tokens": [51132, 1507, 411, 13437, 4675, 14924, 570, 309, 2516, 257, 30163, 294, 565, 498, 2602, 291, 434, 544, 3102, 51412], "temperature": 0.0, "avg_logprob": -0.09239224353468561, "compression_ratio": 1.75, "no_speech_prob": 0.0019649548921734095}, {"id": 127, "seek": 86120, "start": 882.1600000000001, "end": 888.08, "text": " into transient memory peaks as I said before there is this other tool called the allocation sampling", "tokens": [51412, 666, 41998, 4675, 26897, 382, 286, 848, 949, 456, 307, 341, 661, 2290, 1219, 264, 27599, 21179, 51708], "temperature": 0.0, "avg_logprob": -0.09239224353468561, "compression_ratio": 1.75, "no_speech_prob": 0.0019649548921734095}, {"id": 128, "seek": 88808, "start": 888.08, "end": 896.72, "text": " which works by accumulating every allocation that happens this means that everything that", "tokens": [50364, 597, 1985, 538, 12989, 12162, 633, 27599, 300, 2314, 341, 1355, 300, 1203, 300, 50796], "temperature": 0.0, "avg_logprob": -0.10410718312339177, "compression_ratio": 1.6627218934911243, "no_speech_prob": 0.002378451405093074}, {"id": 129, "seek": 88808, "start": 897.9200000000001, "end": 904.32, "text": " is allocated is saved here but you don't get the allocations so which is you can't really measure", "tokens": [50856, 307, 29772, 307, 6624, 510, 457, 291, 500, 380, 483, 264, 12660, 763, 370, 597, 307, 291, 393, 380, 534, 3481, 51176], "temperature": 0.0, "avg_logprob": -0.10410718312339177, "compression_ratio": 1.6627218934911243, "no_speech_prob": 0.002378451405093074}, {"id": 130, "seek": 88808, "start": 904.32, "end": 913.5200000000001, "text": " how much RAM you're using you can just measure who is creating that RAM that's objects we had", "tokens": [51176, 577, 709, 14561, 291, 434, 1228, 291, 393, 445, 3481, 567, 307, 4084, 300, 14561, 300, 311, 6565, 321, 632, 51636], "temperature": 0.0, "avg_logprob": -0.10410718312339177, "compression_ratio": 1.6627218934911243, "no_speech_prob": 0.002378451405093074}, {"id": 131, "seek": 91352, "start": 913.52, "end": 919.4399999999999, "text": " not too many of them but some of them were taking a lot of RAM like 89 megabytes that's a lot and", "tokens": [50364, 406, 886, 867, 295, 552, 457, 512, 295, 552, 645, 1940, 257, 688, 295, 14561, 411, 31877, 10816, 24538, 300, 311, 257, 688, 293, 50660], "temperature": 0.0, "avg_logprob": -0.06125175035916842, "compression_ratio": 1.820754716981132, "no_speech_prob": 0.004565434996038675}, {"id": 132, "seek": 91352, "start": 919.4399999999999, "end": 925.68, "text": " we had one specific object that was taking a giant amount of memory like 80 megabytes and", "tokens": [50660, 321, 632, 472, 2685, 2657, 300, 390, 1940, 257, 7410, 2372, 295, 4675, 411, 4688, 10816, 24538, 293, 50972], "temperature": 0.0, "avg_logprob": -0.06125175035916842, "compression_ratio": 1.820754716981132, "no_speech_prob": 0.004565434996038675}, {"id": 133, "seek": 91352, "start": 926.64, "end": 932.56, "text": " which is then by looking at the retainers we were able to immediately figure out what was the function", "tokens": [51020, 597, 307, 550, 538, 1237, 412, 264, 18340, 433, 321, 645, 1075, 281, 4258, 2573, 484, 437, 390, 264, 2445, 51316], "temperature": 0.0, "avg_logprob": -0.06125175035916842, "compression_ratio": 1.820754716981132, "no_speech_prob": 0.004565434996038675}, {"id": 134, "seek": 91352, "start": 933.12, "end": 939.84, "text": " that was allocating that stuff that was retaining that stuff and that was one of the very first", "tokens": [51344, 300, 390, 12660, 990, 300, 1507, 300, 390, 34936, 300, 1507, 293, 300, 390, 472, 295, 264, 588, 700, 51680], "temperature": 0.0, "avg_logprob": -0.06125175035916842, "compression_ratio": 1.820754716981132, "no_speech_prob": 0.004565434996038675}, {"id": 135, "seek": 93984, "start": 939.84, "end": 946.4, "text": " optimization that we managed to do because this way we went into the code into that function", "tokens": [50364, 19618, 300, 321, 6453, 281, 360, 570, 341, 636, 321, 1437, 666, 264, 3089, 666, 300, 2445, 50692], "temperature": 0.0, "avg_logprob": -0.08912967794081744, "compression_ratio": 1.7906976744186047, "no_speech_prob": 0.0047898790799081326}, {"id": 136, "seek": 93984, "start": 946.4, "end": 954.8000000000001, "text": " and realized how we were basically creating a bunch of functions this is react code and a bunch of", "tokens": [50692, 293, 5334, 577, 321, 645, 1936, 4084, 257, 3840, 295, 6828, 341, 307, 4515, 3089, 293, 257, 3840, 295, 51112], "temperature": 0.0, "avg_logprob": -0.08912967794081744, "compression_ratio": 1.7906976744186047, "no_speech_prob": 0.0047898790799081326}, {"id": 137, "seek": 93984, "start": 954.8000000000001, "end": 960.88, "text": " string UIDs and saving all of them in a map and apparently that's incredibly inefficient that's", "tokens": [51112, 6798, 624, 2777, 82, 293, 6816, 439, 295, 552, 294, 257, 4471, 293, 7970, 300, 311, 6252, 43495, 300, 311, 51416], "temperature": 0.0, "avg_logprob": -0.08912967794081744, "compression_ratio": 1.7906976744186047, "no_speech_prob": 0.0047898790799081326}, {"id": 138, "seek": 93984, "start": 960.88, "end": 965.9200000000001, "text": " probably not code that you look at the first at the first glance that it seems inefficient but if", "tokens": [51416, 1391, 406, 3089, 300, 291, 574, 412, 264, 700, 412, 264, 700, 21094, 300, 309, 2544, 43495, 457, 498, 51668], "temperature": 0.0, "avg_logprob": -0.08912967794081744, "compression_ratio": 1.7906976744186047, "no_speech_prob": 0.0047898790799081326}, {"id": 139, "seek": 96592, "start": 965.92, "end": 973.8399999999999, "text": " you call it thousands of times this is apparently sticking up 80 megs of RAM and so how did we solve", "tokens": [50364, 291, 818, 309, 5383, 295, 1413, 341, 307, 7970, 13465, 493, 4688, 10816, 82, 295, 14561, 293, 370, 577, 630, 321, 5039, 50760], "temperature": 0.0, "avg_logprob": -0.10527866180628946, "compression_ratio": 1.5, "no_speech_prob": 0.0034961726050823927}, {"id": 140, "seek": 96592, "start": 973.8399999999999, "end": 984.16, "text": " this we refactored it a bit by using a set instead of a map and so it's very experiment based and", "tokens": [50760, 341, 321, 1895, 578, 2769, 309, 257, 857, 538, 1228, 257, 992, 2602, 295, 257, 4471, 293, 370, 309, 311, 588, 5120, 2361, 293, 51276], "temperature": 0.0, "avg_logprob": -0.10527866180628946, "compression_ratio": 1.5, "no_speech_prob": 0.0034961726050823927}, {"id": 141, "seek": 96592, "start": 984.16, "end": 989.76, "text": " with this we were able to have like a 50 percent improvement of memory usage which was huge and", "tokens": [51276, 365, 341, 321, 645, 1075, 281, 362, 411, 257, 2625, 3043, 10444, 295, 4675, 14924, 597, 390, 2603, 293, 51556], "temperature": 0.0, "avg_logprob": -0.10527866180628946, "compression_ratio": 1.5, "no_speech_prob": 0.0034961726050823927}, {"id": 142, "seek": 98976, "start": 989.76, "end": 996.0, "text": " this really made the difference between being able to load some project at all or projects that", "tokens": [50364, 341, 534, 1027, 264, 2649, 1296, 885, 1075, 281, 3677, 512, 1716, 412, 439, 420, 4455, 300, 50676], "temperature": 0.0, "avg_logprob": -0.15553371205049402, "compression_ratio": 1.6637554585152838, "no_speech_prob": 0.0017419994110241532}, {"id": 143, "seek": 98976, "start": 996.0, "end": 1001.76, "text": " would just crush your browser like documents and so that was one of the first big wins that we had", "tokens": [50676, 576, 445, 10321, 428, 11185, 411, 8512, 293, 370, 300, 390, 472, 295, 264, 700, 955, 10641, 300, 321, 632, 50964], "temperature": 0.0, "avg_logprob": -0.15553371205049402, "compression_ratio": 1.6637554585152838, "no_speech_prob": 0.0017419994110241532}, {"id": 144, "seek": 98976, "start": 1002.72, "end": 1008.3199999999999, "text": " so we were like yeah okay let's continue this eventually we will reach zero megs of memory", "tokens": [51012, 370, 321, 645, 411, 1338, 1392, 718, 311, 2354, 341, 4728, 321, 486, 2524, 4018, 10816, 82, 295, 4675, 51292], "temperature": 0.0, "avg_logprob": -0.15553371205049402, "compression_ratio": 1.6637554585152838, "no_speech_prob": 0.0017419994110241532}, {"id": 145, "seek": 98976, "start": 1008.3199999999999, "end": 1016.88, "text": " use right no immediately after that we hit pretty much a brick wall in which we were taking hit", "tokens": [51292, 764, 558, 572, 4258, 934, 300, 321, 2045, 1238, 709, 257, 16725, 2929, 294, 597, 321, 645, 1940, 2045, 51720], "temperature": 0.0, "avg_logprob": -0.15553371205049402, "compression_ratio": 1.6637554585152838, "no_speech_prob": 0.0017419994110241532}, {"id": 146, "seek": 101688, "start": 1016.88, "end": 1023.6, "text": " snapshots and we were seeing that we had two million objects that were taking a lot of space", "tokens": [50364, 19206, 27495, 293, 321, 645, 2577, 300, 321, 632, 732, 2459, 6565, 300, 645, 1940, 257, 688, 295, 1901, 50700], "temperature": 0.0, "avg_logprob": -0.07477964979878972, "compression_ratio": 1.7638888888888888, "no_speech_prob": 0.002685914281755686}, {"id": 147, "seek": 101688, "start": 1023.6, "end": 1030.0, "text": " and it's not that that like we had one big object to optimize each one of them was a couple of bytes", "tokens": [50700, 293, 309, 311, 406, 300, 300, 411, 321, 632, 472, 955, 2657, 281, 19719, 1184, 472, 295, 552, 390, 257, 1916, 295, 36088, 51020], "temperature": 0.0, "avg_logprob": -0.07477964979878972, "compression_ratio": 1.7638888888888888, "no_speech_prob": 0.002685914281755686}, {"id": 148, "seek": 101688, "start": 1030.0, "end": 1036.88, "text": " and the heat profiler really doesn't help you in those cases and that's interesting because", "tokens": [51020, 293, 264, 3738, 1740, 5441, 534, 1177, 380, 854, 291, 294, 729, 3331, 293, 300, 311, 1880, 570, 51364], "temperature": 0.0, "avg_logprob": -0.07477964979878972, "compression_ratio": 1.7638888888888888, "no_speech_prob": 0.002685914281755686}, {"id": 149, "seek": 101688, "start": 1036.88, "end": 1042.24, "text": " that's pretty much the same situation that you will find if you try to profile that same notion", "tokens": [51364, 300, 311, 1238, 709, 264, 912, 2590, 300, 291, 486, 915, 498, 291, 853, 281, 7964, 300, 912, 10710, 51632], "temperature": 0.0, "avg_logprob": -0.07477964979878972, "compression_ratio": 1.7638888888888888, "no_speech_prob": 0.002685914281755686}, {"id": 150, "seek": 104224, "start": 1042.56, "end": 1048.8, "text": " that I've tested it before or even Airbnb as it's actually the same problem and unfortunately the", "tokens": [50380, 300, 286, 600, 8246, 309, 949, 420, 754, 38232, 382, 309, 311, 767, 264, 912, 1154, 293, 7015, 264, 50692], "temperature": 0.0, "avg_logprob": -0.2820417645951392, "compression_ratio": 1.5828877005347595, "no_speech_prob": 0.005248360335826874}, {"id": 151, "seek": 104224, "start": 1048.8, "end": 1058.64, "text": " answer is the problem is react kind of and like we are in the same situation also with notion we have", "tokens": [50692, 1867, 307, 264, 1154, 307, 4515, 733, 295, 293, 411, 321, 366, 294, 264, 912, 2590, 611, 365, 10710, 321, 362, 51184], "temperature": 0.0, "avg_logprob": -0.2820417645951392, "compression_ratio": 1.5828877005347595, "no_speech_prob": 0.005248360335826874}, {"id": 152, "seek": 104224, "start": 1061.04, "end": 1069.36, "text": " is it two geeks of ground no that can't be that is just being occupied by a lot of small objects", "tokens": [51304, 307, 309, 732, 1519, 24785, 295, 2727, 572, 300, 393, 380, 312, 300, 307, 445, 885, 19629, 538, 257, 688, 295, 1359, 6565, 51720], "temperature": 0.0, "avg_logprob": -0.2820417645951392, "compression_ratio": 1.5828877005347595, "no_speech_prob": 0.005248360335826874}, {"id": 153, "seek": 106936, "start": 1069.4399999999998, "end": 1076.3999999999999, "text": " so yeah we hit a brick wall but what we do now like the heat profiler is very bad and analyzing", "tokens": [50368, 370, 1338, 321, 2045, 257, 16725, 2929, 457, 437, 321, 360, 586, 411, 264, 3738, 1740, 5441, 307, 588, 1578, 293, 23663, 50716], "temperature": 0.0, "avg_logprob": -0.2536571269132653, "compression_ratio": 1.760180995475113, "no_speech_prob": 0.0021059836726635695}, {"id": 154, "seek": 106936, "start": 1076.3999999999999, "end": 1084.24, "text": " those kind of stuff thankfully we can export from it we can export a giant five gigabytes json from", "tokens": [50716, 729, 733, 295, 1507, 27352, 321, 393, 10725, 490, 309, 321, 393, 10725, 257, 7410, 1732, 42741, 361, 3015, 490, 51108], "temperature": 0.0, "avg_logprob": -0.2536571269132653, "compression_ratio": 1.760180995475113, "no_speech_prob": 0.0021059836726635695}, {"id": 155, "seek": 106936, "start": 1085.84, "end": 1091.52, "text": " from chrome and then we look at the json and we see that the json it's in a format that is pretty", "tokens": [51188, 490, 33120, 293, 550, 321, 574, 412, 264, 361, 3015, 293, 321, 536, 300, 264, 361, 3015, 309, 311, 294, 257, 7877, 300, 307, 1238, 51472], "temperature": 0.0, "avg_logprob": -0.2536571269132653, "compression_ratio": 1.760180995475113, "no_speech_prob": 0.0021059836726635695}, {"id": 156, "seek": 106936, "start": 1091.52, "end": 1098.1599999999999, "text": " much unreadable but thankfully there is someone that did work for us the guys at meta and it is", "tokens": [51472, 709, 517, 2538, 712, 457, 27352, 456, 307, 1580, 300, 630, 589, 337, 505, 264, 1074, 412, 19616, 293, 309, 307, 51804], "temperature": 0.0, "avg_logprob": -0.2536571269132653, "compression_ratio": 1.760180995475113, "no_speech_prob": 0.0021059836726635695}, {"id": 157, "seek": 109816, "start": 1099.1200000000001, "end": 1105.28, "text": " beautiful tool called memelab which it's a toolkit for exploring memory usage", "tokens": [50412, 2238, 2290, 1219, 1334, 338, 455, 597, 309, 311, 257, 40167, 337, 12736, 4675, 14924, 50720], "temperature": 0.0, "avg_logprob": -0.1246602917894905, "compression_ratio": 1.6140350877192982, "no_speech_prob": 0.001899379538372159}, {"id": 158, "seek": 109816, "start": 1106.24, "end": 1111.92, "text": " which is very focused on finding memory leaks it has like an entire automation for that but I think", "tokens": [50768, 597, 307, 588, 5178, 322, 5006, 4675, 28885, 309, 575, 411, 364, 2302, 17769, 337, 300, 457, 286, 519, 51052], "temperature": 0.0, "avg_logprob": -0.1246602917894905, "compression_ratio": 1.6140350877192982, "no_speech_prob": 0.001899379538372159}, {"id": 159, "seek": 109816, "start": 1111.92, "end": 1118.88, "text": " this is even more it's even cooler because it provides you a very powerful API for opening", "tokens": [51052, 341, 307, 754, 544, 309, 311, 754, 15566, 570, 309, 6417, 291, 257, 588, 4005, 9362, 337, 5193, 51400], "temperature": 0.0, "avg_logprob": -0.1246602917894905, "compression_ratio": 1.6140350877192982, "no_speech_prob": 0.001899379538372159}, {"id": 160, "seek": 109816, "start": 1118.88, "end": 1126.16, "text": " snapshots from chrome and analyzing them what you can do is that basically you can read the objects", "tokens": [51400, 19206, 27495, 490, 33120, 293, 23663, 552, 437, 291, 393, 360, 307, 300, 1936, 291, 393, 1401, 264, 6565, 51764], "temperature": 0.0, "avg_logprob": -0.1246602917894905, "compression_ratio": 1.6140350877192982, "no_speech_prob": 0.001899379538372159}, {"id": 161, "seek": 112616, "start": 1126.16, "end": 1135.6000000000001, "text": " in memory and perform analytics on them for example we wanted to answer this question which type of", "tokens": [50364, 294, 4675, 293, 2042, 15370, 322, 552, 337, 1365, 321, 1415, 281, 1867, 341, 1168, 597, 2010, 295, 50836], "temperature": 0.0, "avg_logprob": -0.10182597977774484, "compression_ratio": 1.5698924731182795, "no_speech_prob": 0.001374606043100357}, {"id": 162, "seek": 112616, "start": 1135.6000000000001, "end": 1142.72, "text": " objects are taking up the most space out of the two millions that we found in a snapshot well", "tokens": [50836, 6565, 366, 1940, 493, 264, 881, 1901, 484, 295, 264, 732, 6803, 300, 321, 1352, 294, 257, 30163, 731, 51192], "temperature": 0.0, "avg_logprob": -0.10182597977774484, "compression_ratio": 1.5698924731182795, "no_speech_prob": 0.001374606043100357}, {"id": 163, "seek": 112616, "start": 1144.5600000000002, "end": 1151.28, "text": " this is a some code that we wrote I think that we don't have time to go too much into it but I can", "tokens": [51284, 341, 307, 257, 512, 3089, 300, 321, 4114, 286, 519, 300, 321, 500, 380, 362, 565, 281, 352, 886, 709, 666, 309, 457, 286, 393, 51620], "temperature": 0.0, "avg_logprob": -0.10182597977774484, "compression_ratio": 1.5698924731182795, "no_speech_prob": 0.001374606043100357}, {"id": 164, "seek": 115128, "start": 1151.28, "end": 1156.8, "text": " publish it the idea is that we can load the snapshot so load the current state of memory", "tokens": [50364, 11374, 309, 264, 1558, 307, 300, 321, 393, 3677, 264, 30163, 370, 3677, 264, 2190, 1785, 295, 4675, 50640], "temperature": 0.0, "avg_logprob": -0.11271336499382467, "compression_ratio": 1.8529411764705883, "no_speech_prob": 0.0056952377781271935}, {"id": 165, "seek": 115128, "start": 1156.8, "end": 1161.76, "text": " and find all the object types like what are what is the like the type skip type of the object", "tokens": [50640, 293, 915, 439, 264, 2657, 3467, 411, 437, 366, 437, 307, 264, 411, 264, 2010, 10023, 2010, 295, 264, 2657, 50888], "temperature": 0.0, "avg_logprob": -0.11271336499382467, "compression_ratio": 1.8529411764705883, "no_speech_prob": 0.0056952377781271935}, {"id": 166, "seek": 115128, "start": 1162.32, "end": 1170.72, "text": " computed total shallow size for each type and then sort and print results and from these the results", "tokens": [50916, 40610, 3217, 20488, 2744, 337, 1184, 2010, 293, 550, 1333, 293, 4482, 3542, 293, 490, 613, 264, 3542, 51336], "temperature": 0.0, "avg_logprob": -0.11271336499382467, "compression_ratio": 1.8529411764705883, "no_speech_prob": 0.0056952377781271935}, {"id": 167, "seek": 115128, "start": 1170.72, "end": 1177.84, "text": " were very cool because the um which is we had the for each object type even including like the", "tokens": [51336, 645, 588, 1627, 570, 264, 1105, 597, 307, 321, 632, 264, 337, 1184, 2657, 2010, 754, 3009, 411, 264, 51692], "temperature": 0.0, "avg_logprob": -0.11271336499382467, "compression_ratio": 1.8529411764705883, "no_speech_prob": 0.0056952377781271935}, {"id": 168, "seek": 117784, "start": 1178.56, "end": 1184.24, "text": " the keys of the object how much memory they were occupying and which is we were able to see that", "tokens": [50400, 264, 9317, 295, 264, 2657, 577, 709, 4675, 436, 645, 8073, 1840, 293, 597, 307, 321, 645, 1075, 281, 536, 300, 50684], "temperature": 0.0, "avg_logprob": -0.13800956986167215, "compression_ratio": 1.886138613861386, "no_speech_prob": 0.0019401147728785872}, {"id": 169, "seek": 117784, "start": 1184.24, "end": 1192.32, "text": " on the top two we have one object that is called fiber node which is from react and another node", "tokens": [50684, 322, 264, 1192, 732, 321, 362, 472, 2657, 300, 307, 1219, 12874, 9984, 597, 307, 490, 4515, 293, 1071, 9984, 51088], "temperature": 0.0, "avg_logprob": -0.13800956986167215, "compression_ratio": 1.886138613861386, "no_speech_prob": 0.0019401147728785872}, {"id": 170, "seek": 117784, "start": 1192.32, "end": 1199.76, "text": " another object that had base q base state memo state what the next q what is that that is not", "tokens": [51088, 1071, 2657, 300, 632, 3096, 9505, 3096, 1785, 35900, 1785, 437, 264, 958, 9505, 437, 307, 300, 300, 307, 406, 51460], "temperature": 0.0, "avg_logprob": -0.13800956986167215, "compression_ratio": 1.886138613861386, "no_speech_prob": 0.0019401147728785872}, {"id": 171, "seek": 117784, "start": 1199.76, "end": 1204.32, "text": " something that came from our application that's react again that's the data structure that is", "tokens": [51460, 746, 300, 1361, 490, 527, 3861, 300, 311, 4515, 797, 300, 311, 264, 1412, 3877, 300, 307, 51688], "temperature": 0.0, "avg_logprob": -0.13800956986167215, "compression_ratio": 1.886138613861386, "no_speech_prob": 0.0019401147728785872}, {"id": 172, "seek": 120432, "start": 1204.32, "end": 1211.36, "text": " used internally for keeping tracks of hooks and so like we went into react to me so that there was", "tokens": [50364, 1143, 19501, 337, 5145, 10218, 295, 26485, 293, 370, 411, 321, 1437, 666, 4515, 281, 385, 370, 300, 456, 390, 50716], "temperature": 0.0, "avg_logprob": -0.14004148595473345, "compression_ratio": 1.7321428571428572, "no_speech_prob": 0.0019473526626825333}, {"id": 173, "seek": 120432, "start": 1211.36, "end": 1217.04, "text": " exactly that other structure which in most websites that are using react heavily nowadays is pretty", "tokens": [50716, 2293, 300, 661, 3877, 597, 294, 881, 12891, 300, 366, 1228, 4515, 10950, 13434, 307, 1238, 51000], "temperature": 0.0, "avg_logprob": -0.14004148595473345, "compression_ratio": 1.7321428571428572, "no_speech_prob": 0.0019473526626825333}, {"id": 174, "seek": 120432, "start": 1217.04, "end": 1223.6799999999998, "text": " much the thing that is occupying the most memory with enough so it is we figured out that keeping", "tokens": [51000, 709, 264, 551, 300, 307, 8073, 1840, 264, 881, 4675, 365, 1547, 370, 309, 307, 321, 8932, 484, 300, 5145, 51332], "temperature": 0.0, "avg_logprob": -0.14004148595473345, "compression_ratio": 1.7321428571428572, "no_speech_prob": 0.0019473526626825333}, {"id": 175, "seek": 120432, "start": 1223.6799999999998, "end": 1232.1599999999999, "text": " tracks of hooks is expensive and but are we supposed to just tear down the 400 000 lines of", "tokens": [51332, 10218, 295, 26485, 307, 5124, 293, 457, 366, 321, 3442, 281, 445, 12556, 760, 264, 8423, 13711, 3876, 295, 51756], "temperature": 0.0, "avg_logprob": -0.14004148595473345, "compression_ratio": 1.7321428571428572, "no_speech_prob": 0.0019473526626825333}, {"id": 176, "seek": 123216, "start": 1232.24, "end": 1239.1200000000001, "text": " react that we have in our app right now like that's a bit too far into the development so we wanted", "tokens": [50368, 4515, 300, 321, 362, 294, 527, 724, 558, 586, 411, 300, 311, 257, 857, 886, 1400, 666, 264, 3250, 370, 321, 1415, 50712], "temperature": 0.0, "avg_logprob": -0.13087225462260998, "compression_ratio": 1.760180995475113, "no_speech_prob": 0.004371266812086105}, {"id": 177, "seek": 123216, "start": 1239.1200000000001, "end": 1247.44, "text": " to know precisely what we need to optimize so we use memlum again this time we uh we see like even", "tokens": [50712, 281, 458, 13402, 437, 321, 643, 281, 19719, 370, 321, 764, 1334, 75, 449, 797, 341, 565, 321, 2232, 321, 536, 411, 754, 51128], "temperature": 0.0, "avg_logprob": -0.13087225462260998, "compression_ratio": 1.760180995475113, "no_speech_prob": 0.004371266812086105}, {"id": 178, "seek": 123216, "start": 1247.44, "end": 1253.76, "text": " more uh by looking at this fiber node data structure that is used by reactor and we need a lot of", "tokens": [51128, 544, 2232, 538, 1237, 412, 341, 12874, 9984, 1412, 3877, 300, 307, 1143, 538, 20628, 293, 321, 643, 257, 688, 295, 51444], "temperature": 0.0, "avg_logprob": -0.13087225462260998, "compression_ratio": 1.760180995475113, "no_speech_prob": 0.004371266812086105}, {"id": 179, "seek": 123216, "start": 1253.76, "end": 1260.0, "text": " statistics on it to try to figure out what is the react component that is taking up the most", "tokens": [51444, 12523, 322, 309, 281, 853, 281, 2573, 484, 437, 307, 264, 4515, 6542, 300, 307, 1940, 493, 264, 881, 51756], "temperature": 0.0, "avg_logprob": -0.13087225462260998, "compression_ratio": 1.760180995475113, "no_speech_prob": 0.004371266812086105}, {"id": 180, "seek": 126000, "start": 1260.08, "end": 1265.44, "text": " memory so that we can optimize that specific component first and we managed to do this because", "tokens": [50368, 4675, 370, 300, 321, 393, 19719, 300, 2685, 6542, 700, 293, 321, 6453, 281, 360, 341, 570, 50636], "temperature": 0.0, "avg_logprob": -0.12685933223990506, "compression_ratio": 1.8916256157635467, "no_speech_prob": 0.015688836574554443}, {"id": 181, "seek": 126000, "start": 1265.44, "end": 1273.04, "text": " this way we were able to divide the odd memory uses by react component and see each hook how much", "tokens": [50636, 341, 636, 321, 645, 1075, 281, 9845, 264, 7401, 4675, 4960, 538, 4515, 6542, 293, 536, 1184, 6328, 577, 709, 51016], "temperature": 0.0, "avg_logprob": -0.12685933223990506, "compression_ratio": 1.8916256157635467, "no_speech_prob": 0.015688836574554443}, {"id": 182, "seek": 126000, "start": 1273.92, "end": 1279.76, "text": " memory it was using and with this we were able to find out a specific react component that", "tokens": [51060, 4675, 309, 390, 1228, 293, 365, 341, 321, 645, 1075, 281, 915, 484, 257, 2685, 4515, 6542, 300, 51352], "temperature": 0.0, "avg_logprob": -0.12685933223990506, "compression_ratio": 1.8916256157635467, "no_speech_prob": 0.015688836574554443}, {"id": 183, "seek": 126000, "start": 1280.64, "end": 1286.4, "text": " was using a lot of memory and we cut the memory users down again by 60 percent which was pretty nice", "tokens": [51396, 390, 1228, 257, 688, 295, 4675, 293, 321, 1723, 264, 4675, 5022, 760, 797, 538, 4060, 3043, 597, 390, 1238, 1481, 51684], "temperature": 0.0, "avg_logprob": -0.12685933223990506, "compression_ratio": 1.8916256157635467, "no_speech_prob": 0.015688836574554443}, {"id": 184, "seek": 128640, "start": 1286.4, "end": 1292.24, "text": " so that's like memlum saved us with this because we were able to make our app properly working", "tokens": [50364, 370, 300, 311, 411, 1334, 75, 449, 6624, 505, 365, 341, 570, 321, 645, 1075, 281, 652, 527, 724, 6108, 1364, 50656], "temperature": 0.0, "avg_logprob": -0.0871156354745229, "compression_ratio": 1.740909090909091, "no_speech_prob": 0.002640540711581707}, {"id": 185, "seek": 128640, "start": 1293.0400000000002, "end": 1302.72, "text": " and it also made us possible to answer other questions like as out of all the strings that we", "tokens": [50696, 293, 309, 611, 1027, 505, 1944, 281, 1867, 661, 1651, 411, 382, 484, 295, 439, 264, 13985, 300, 321, 51180], "temperature": 0.0, "avg_logprob": -0.0871156354745229, "compression_ratio": 1.740909090909091, "no_speech_prob": 0.002640540711581707}, {"id": 186, "seek": 128640, "start": 1302.72, "end": 1309.6000000000001, "text": " have in our app how many of those are uids should we start optimizing uids and make them numbers", "tokens": [51180, 362, 294, 527, 724, 577, 867, 295, 729, 366, 344, 3742, 820, 321, 722, 40425, 344, 3742, 293, 652, 552, 3547, 51524], "temperature": 0.0, "avg_logprob": -0.0871156354745229, "compression_ratio": 1.740909090909091, "no_speech_prob": 0.002640540711581707}, {"id": 187, "seek": 128640, "start": 1309.6000000000001, "end": 1315.3600000000001, "text": " well no because we used memlum to find all the uids and we found out it was like two megabytes in", "tokens": [51524, 731, 572, 570, 321, 1143, 1334, 75, 449, 281, 915, 439, 264, 344, 3742, 293, 321, 1352, 484, 309, 390, 411, 732, 10816, 24538, 294, 51812], "temperature": 0.0, "avg_logprob": -0.0871156354745229, "compression_ratio": 1.740909090909091, "no_speech_prob": 0.002640540711581707}, {"id": 188, "seek": 131536, "start": 1315.36, "end": 1323.1999999999998, "text": " total so who cares so that's also nice to know what to not prematurely optimize so just to sum up", "tokens": [50364, 3217, 370, 567, 12310, 370, 300, 311, 611, 1481, 281, 458, 437, 281, 406, 34877, 356, 19719, 370, 445, 281, 2408, 493, 50756], "temperature": 0.0, "avg_logprob": -0.07946817647843134, "compression_ratio": 1.6872246696035242, "no_speech_prob": 0.001538519631139934}, {"id": 189, "seek": 131536, "start": 1323.1999999999998, "end": 1328.8, "text": " everything that i said i think that we can all agree that memory analysis is actually difficult", "tokens": [50756, 1203, 300, 741, 848, 741, 519, 300, 321, 393, 439, 3986, 300, 4675, 5215, 307, 767, 2252, 51036], "temperature": 0.0, "avg_logprob": -0.07946817647843134, "compression_ratio": 1.6872246696035242, "no_speech_prob": 0.001538519631139934}, {"id": 190, "seek": 131536, "start": 1328.8, "end": 1333.28, "text": " especially because it varies so much between application between framework between browsers", "tokens": [51036, 2318, 570, 309, 21716, 370, 709, 1296, 3861, 1296, 8388, 1296, 36069, 51260], "temperature": 0.0, "avg_logprob": -0.07946817647843134, "compression_ratio": 1.6872246696035242, "no_speech_prob": 0.001538519631139934}, {"id": 191, "seek": 131536, "start": 1334.1599999999999, "end": 1342.6399999999999, "text": " but it's important even if even in a world like nowadays in which we have a lot of a lot of round", "tokens": [51304, 457, 309, 311, 1021, 754, 498, 754, 294, 257, 1002, 411, 13434, 294, 597, 321, 362, 257, 688, 295, 257, 688, 295, 3098, 51728], "temperature": 0.0, "avg_logprob": -0.07946817647843134, "compression_ratio": 1.6872246696035242, "no_speech_prob": 0.001538519631139934}, {"id": 192, "seek": 134264, "start": 1342.64, "end": 1347.3600000000001, "text": " because for some apps it really makes a difference it makes the difference between you being able to", "tokens": [50364, 570, 337, 512, 7733, 309, 534, 1669, 257, 2649, 309, 1669, 264, 2649, 1296, 291, 885, 1075, 281, 50600], "temperature": 0.0, "avg_logprob": -0.13167308899293462, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.004140831530094147}, {"id": 193, "seek": 134264, "start": 1347.3600000000001, "end": 1354.48, "text": " use the notion on your phone or the app constantly crashing and never loading your data and", "tokens": [50600, 764, 264, 10710, 322, 428, 2593, 420, 264, 724, 6460, 26900, 293, 1128, 15114, 428, 1412, 293, 50956], "temperature": 0.0, "avg_logprob": -0.13167308899293462, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.004140831530094147}, {"id": 194, "seek": 134264, "start": 1356.0, "end": 1361.68, "text": " that thing is that the chrome profiler is cool but sometimes it's not enough but thankfully it can", "tokens": [51032, 300, 551, 307, 300, 264, 33120, 1740, 5441, 307, 1627, 457, 2171, 309, 311, 406, 1547, 457, 27352, 309, 393, 51316], "temperature": 0.0, "avg_logprob": -0.13167308899293462, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.004140831530094147}, {"id": 195, "seek": 134264, "start": 1361.68, "end": 1369.0400000000002, "text": " export so that at least you can perform your own analysis externally so thank you for listening to", "tokens": [51316, 10725, 370, 300, 412, 1935, 291, 393, 2042, 428, 1065, 5215, 40899, 370, 1309, 291, 337, 4764, 281, 51684], "temperature": 0.0, "avg_logprob": -0.13167308899293462, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.004140831530094147}, {"id": 196, "seek": 136904, "start": 1369.04, "end": 1373.44, "text": " representation thank you", "tokens": [50364, 10290, 1309, 291, 50584], "temperature": 0.0, "avg_logprob": -0.3430244241441999, "compression_ratio": 1.7583892617449663, "no_speech_prob": 0.04935533553361893}, {"id": 197, "seek": 136904, "start": 1378.0, "end": 1380.32, "text": " are there any questions i see a question here", "tokens": [50812, 366, 456, 604, 1651, 741, 536, 257, 1168, 510, 50928], "temperature": 0.0, "avg_logprob": -0.3430244241441999, "compression_ratio": 1.7583892617449663, "no_speech_prob": 0.04935533553361893}, {"id": 198, "seek": 136904, "start": 1382.8, "end": 1389.44, "text": " yes you were talking about the shallow size versus retained size yeah when would you ever", "tokens": [51052, 2086, 291, 645, 1417, 466, 264, 20488, 2744, 5717, 33438, 2744, 1338, 562, 576, 291, 1562, 51384], "temperature": 0.0, "avg_logprob": -0.3430244241441999, "compression_ratio": 1.7583892617449663, "no_speech_prob": 0.04935533553361893}, {"id": 199, "seek": 136904, "start": 1389.44, "end": 1396.3999999999999, "text": " be interested in looking at the shallow size sounds like the more interesting one yeah he asked about", "tokens": [51384, 312, 3102, 294, 1237, 412, 264, 20488, 2744, 3263, 411, 264, 544, 1880, 472, 1338, 415, 2351, 466, 51732], "temperature": 0.0, "avg_logprob": -0.3430244241441999, "compression_ratio": 1.7583892617449663, "no_speech_prob": 0.04935533553361893}, {"id": 200, "seek": 139640, "start": 1396.4, "end": 1401.2800000000002, "text": " when do we care about shallow size when we also have the retained size well i yeah we care a lot", "tokens": [50364, 562, 360, 321, 1127, 466, 20488, 2744, 562, 321, 611, 362, 264, 33438, 2744, 731, 741, 1338, 321, 1127, 257, 688, 50608], "temperature": 0.0, "avg_logprob": -0.1323753482890579, "compression_ratio": 1.8616600790513833, "no_speech_prob": 0.015048256143927574}, {"id": 201, "seek": 139640, "start": 1401.2800000000002, "end": 1405.3600000000001, "text": " about shallow size in our case it was all about shallow size where to write our own custom", "tokens": [50608, 466, 20488, 2744, 294, 527, 1389, 309, 390, 439, 466, 20488, 2744, 689, 281, 2464, 527, 1065, 2375, 50812], "temperature": 0.0, "avg_logprob": -0.1323753482890579, "compression_ratio": 1.8616600790513833, "no_speech_prob": 0.015048256143927574}, {"id": 202, "seek": 139640, "start": 1405.92, "end": 1412.8000000000002, "text": " plugging for memblab to just analyze shallow size why because if you are analyzing like very big", "tokens": [50840, 42975, 337, 1334, 5199, 455, 281, 445, 12477, 20488, 2744, 983, 570, 498, 291, 366, 23663, 411, 588, 955, 51184], "temperature": 0.0, "avg_logprob": -0.1323753482890579, "compression_ratio": 1.8616600790513833, "no_speech_prob": 0.015048256143927574}, {"id": 203, "seek": 139640, "start": 1412.8000000000002, "end": 1420.24, "text": " objects there are thousands of lines and in that case you have to use tricks like even virtual", "tokens": [51184, 6565, 456, 366, 5383, 295, 3876, 293, 294, 300, 1389, 291, 362, 281, 764, 11733, 411, 754, 6374, 51556], "temperature": 0.0, "avg_logprob": -0.1323753482890579, "compression_ratio": 1.8616600790513833, "no_speech_prob": 0.015048256143927574}, {"id": 204, "seek": 139640, "start": 1420.24, "end": 1424.96, "text": " scrolling if you know that you can have like instead of allocating all the DOM elements you", "tokens": [51556, 29053, 498, 291, 458, 300, 291, 393, 362, 411, 2602, 295, 12660, 990, 439, 264, 35727, 4959, 291, 51792], "temperature": 0.0, "avg_logprob": -0.1323753482890579, "compression_ratio": 1.8616600790513833, "no_speech_prob": 0.015048256143927574}, {"id": 205, "seek": 142496, "start": 1424.96, "end": 1429.76, "text": " keep reusing the same ones and you think about that that's like ejecting from react because you are", "tokens": [50364, 1066, 319, 7981, 264, 912, 2306, 293, 291, 519, 466, 300, 300, 311, 411, 32520, 278, 490, 4515, 570, 291, 366, 50604], "temperature": 0.0, "avg_logprob": -0.11668875638176412, "compression_ratio": 1.7832699619771863, "no_speech_prob": 0.011309493333101273}, {"id": 206, "seek": 142496, "start": 1429.76, "end": 1435.44, "text": " creating something just with javascript and the DOM and then you are creating a reactive", "tokens": [50604, 4084, 746, 445, 365, 361, 37331, 5944, 293, 264, 35727, 293, 550, 291, 366, 4084, 257, 28897, 50888], "temperature": 0.0, "avg_logprob": -0.11668875638176412, "compression_ratio": 1.7832699619771863, "no_speech_prob": 0.011309493333101273}, {"id": 207, "seek": 142496, "start": 1435.44, "end": 1439.28, "text": " wrapper for it so that's another thing that it shows that yeah react is good at orchestrating", "tokens": [50888, 46906, 337, 309, 370, 300, 311, 1071, 551, 300, 309, 3110, 300, 1338, 4515, 307, 665, 412, 14161, 8754, 51080], "temperature": 0.0, "avg_logprob": -0.11668875638176412, "compression_ratio": 1.7832699619771863, "no_speech_prob": 0.011309493333101273}, {"id": 208, "seek": 142496, "start": 1439.28, "end": 1444.64, "text": " stuff but when it comes to the performance critical things that you want to have inside your", "tokens": [51080, 1507, 457, 562, 309, 1487, 281, 264, 3389, 4924, 721, 300, 291, 528, 281, 362, 1854, 428, 51348], "temperature": 0.0, "avg_logprob": -0.11668875638176412, "compression_ratio": 1.7832699619771863, "no_speech_prob": 0.011309493333101273}, {"id": 209, "seek": 142496, "start": 1444.64, "end": 1454.64, "text": " application then you need to start optimizing it differently just a small mark or we continue", "tokens": [51348, 3861, 550, 291, 643, 281, 722, 40425, 309, 7614, 445, 257, 1359, 1491, 420, 321, 2354, 51848], "temperature": 0.0, "avg_logprob": -0.11668875638176412, "compression_ratio": 1.7832699619771863, "no_speech_prob": 0.011309493333101273}, {"id": 210, "seek": 145464, "start": 1454.72, "end": 1461.76, "text": " with the questions so please if there are spaces please try to squeeze and not leave spaces in the", "tokens": [50368, 365, 264, 1651, 370, 1767, 498, 456, 366, 7673, 1767, 853, 281, 13578, 293, 406, 1856, 7673, 294, 264, 50720], "temperature": 0.0, "avg_logprob": -0.10077129904903583, "compression_ratio": 1.736842105263158, "no_speech_prob": 0.08256636559963226}, {"id": 211, "seek": 145464, "start": 1461.76, "end": 1469.92, "text": " middle as you could see we have hundreds of people waiting outside and here as well and we cannot have", "tokens": [50720, 2808, 382, 291, 727, 536, 321, 362, 6779, 295, 561, 3806, 2380, 293, 510, 382, 731, 293, 321, 2644, 362, 51128], "temperature": 0.0, "avg_logprob": -0.10077129904903583, "compression_ratio": 1.736842105263158, "no_speech_prob": 0.08256636559963226}, {"id": 212, "seek": 145464, "start": 1469.92, "end": 1476.8000000000002, "text": " that many people on the sides so please try to squeeze don't let free seats for your jackets or", "tokens": [51128, 300, 867, 561, 322, 264, 4881, 370, 1767, 853, 281, 13578, 500, 380, 718, 1737, 11069, 337, 428, 34612, 420, 51472], "temperature": 0.0, "avg_logprob": -0.10077129904903583, "compression_ratio": 1.736842105263158, "no_speech_prob": 0.08256636559963226}, {"id": 213, "seek": 147680, "start": 1476.8, "end": 1486.08, "text": " something put it on your lap thank you and since we're starting to be quite a lot if you're going", "tokens": [50364, 746, 829, 309, 322, 428, 13214, 1309, 291, 293, 1670, 321, 434, 2891, 281, 312, 1596, 257, 688, 498, 291, 434, 516, 50828], "temperature": 0.0, "avg_logprob": -0.09139874863297973, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.08992414176464081}, {"id": 214, "seek": 147680, "start": 1486.08, "end": 1493.2, "text": " to go out please try to go out from the right side and avoid going out from the left side so that", "tokens": [50828, 281, 352, 484, 1767, 853, 281, 352, 484, 490, 264, 558, 1252, 293, 5042, 516, 484, 490, 264, 1411, 1252, 370, 300, 51184], "temperature": 0.0, "avg_logprob": -0.09139874863297973, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.08992414176464081}, {"id": 215, "seek": 147680, "start": 1493.2, "end": 1502.32, "text": " it's easier for everyone thank you we have a question here first i've got more more as a comment", "tokens": [51184, 309, 311, 3571, 337, 1518, 1309, 291, 321, 362, 257, 1168, 510, 700, 741, 600, 658, 544, 544, 382, 257, 2871, 51640], "temperature": 0.0, "avg_logprob": -0.09139874863297973, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.08992414176464081}, {"id": 216, "seek": 150232, "start": 1502.32, "end": 1506.96, "text": " instead of a question so the thing is that with this limitation of four gigabytes for memory", "tokens": [50364, 2602, 295, 257, 1168, 370, 264, 551, 307, 300, 365, 341, 27432, 295, 1451, 42741, 337, 4675, 50596], "temperature": 0.0, "avg_logprob": -0.0865517999524268, "compression_ratio": 1.8206106870229009, "no_speech_prob": 0.1405426412820816}, {"id": 217, "seek": 150232, "start": 1507.9199999999998, "end": 1514.1599999999999, "text": " this comes from the fact that like chrome like compresses pointers so that small objects take", "tokens": [50644, 341, 1487, 490, 264, 1186, 300, 411, 33120, 411, 14778, 279, 44548, 370, 300, 1359, 6565, 747, 50956], "temperature": 0.0, "avg_logprob": -0.0865517999524268, "compression_ratio": 1.8206106870229009, "no_speech_prob": 0.1405426412820816}, {"id": 218, "seek": 150232, "start": 1514.1599999999999, "end": 1518.96, "text": " less space basically that's one thing second thing is that is this is like a security mitigation so", "tokens": [50956, 1570, 1901, 1936, 300, 311, 472, 551, 1150, 551, 307, 300, 307, 341, 307, 411, 257, 3825, 32649, 370, 51196], "temperature": 0.0, "avg_logprob": -0.0865517999524268, "compression_ratio": 1.8206106870229009, "no_speech_prob": 0.1405426412820816}, {"id": 219, "seek": 150232, "start": 1518.96, "end": 1526.08, "text": " that when there is some like back in v8 it's harder to exploit it but also i've read on like a", "tokens": [51196, 300, 562, 456, 307, 512, 411, 646, 294, 371, 23, 309, 311, 6081, 281, 25924, 309, 457, 611, 741, 600, 1401, 322, 411, 257, 51552], "temperature": 0.0, "avg_logprob": -0.0865517999524268, "compression_ratio": 1.8206106870229009, "no_speech_prob": 0.1405426412820816}, {"id": 220, "seek": 150232, "start": 1526.08, "end": 1532.08, "text": " chromium box tracker that there is for example 16 gigabytes limit for fixed arrays so there may", "tokens": [51552, 16209, 2197, 2424, 37516, 300, 456, 307, 337, 1365, 3165, 42741, 4948, 337, 6806, 41011, 370, 456, 815, 51852], "temperature": 0.0, "avg_logprob": -0.0865517999524268, "compression_ratio": 1.8206106870229009, "no_speech_prob": 0.1405426412820816}, {"id": 221, "seek": 153208, "start": 1532.08, "end": 1537.1999999999998, "text": " be different limitations for different things like web assembly also has a different limitation", "tokens": [50364, 312, 819, 15705, 337, 819, 721, 411, 3670, 12103, 611, 575, 257, 819, 27432, 50620], "temperature": 0.0, "avg_logprob": -0.14089417457580566, "compression_ratio": 1.6097560975609757, "no_speech_prob": 0.005407506600022316}, {"id": 222, "seek": 153208, "start": 1537.1999999999998, "end": 1545.1999999999998, "text": " and also supposedly like electron abs doesn't have limits so yeah yeah that that's very cool thank you", "tokens": [50620, 293, 611, 20581, 411, 6084, 1950, 1177, 380, 362, 10406, 370, 1338, 1338, 300, 300, 311, 588, 1627, 1309, 291, 51020], "temperature": 0.0, "avg_logprob": -0.14089417457580566, "compression_ratio": 1.6097560975609757, "no_speech_prob": 0.005407506600022316}, {"id": 223, "seek": 154520, "start": 1545.52, "end": 1561.2, "text": " i think that firefox has pretty much the same limitations", "tokens": [50380, 741, 519, 300, 2610, 38416, 575, 1238, 709, 264, 912, 15705, 51164], "temperature": 0.0, "avg_logprob": -0.32288762142783717, "compression_ratio": 1.3596491228070176, "no_speech_prob": 0.03593284264206886}, {"id": 224, "seek": 154520, "start": 1562.8, "end": 1569.2, "text": " oh ask me if we're also trying with other browser yeah i'm mostly working on firefox actually and", "tokens": [51244, 1954, 1029, 385, 498, 321, 434, 611, 1382, 365, 661, 11185, 1338, 741, 478, 5240, 1364, 322, 2610, 38416, 767, 293, 51564], "temperature": 0.0, "avg_logprob": -0.32288762142783717, "compression_ratio": 1.3596491228070176, "no_speech_prob": 0.03593284264206886}, {"id": 225, "seek": 156920, "start": 1569.2, "end": 1575.92, "text": " firefox has very similar limitation and sometimes it's even worse because sometimes we notice that", "tokens": [50364, 2610, 38416, 575, 588, 2531, 27432, 293, 2171, 309, 311, 754, 5324, 570, 2171, 321, 3449, 300, 50700], "temperature": 0.0, "avg_logprob": -0.10522740061690168, "compression_ratio": 1.900943396226415, "no_speech_prob": 0.01005964819341898}, {"id": 226, "seek": 156920, "start": 1577.04, "end": 1583.44, "text": " the upper randomly sometimes takes more memory in firefox for some reason or some things are more", "tokens": [50756, 264, 6597, 16979, 2171, 2516, 544, 4675, 294, 2610, 38416, 337, 512, 1778, 420, 512, 721, 366, 544, 51076], "temperature": 0.0, "avg_logprob": -0.10522740061690168, "compression_ratio": 1.900943396226415, "no_speech_prob": 0.01005964819341898}, {"id": 227, "seek": 156920, "start": 1583.44, "end": 1590.16, "text": " optimized in firefox other things are more optimized in chrome so that that's very complicated to answer", "tokens": [51076, 26941, 294, 2610, 38416, 661, 721, 366, 544, 26941, 294, 33120, 370, 300, 300, 311, 588, 6179, 281, 1867, 51412], "temperature": 0.0, "avg_logprob": -0.10522740061690168, "compression_ratio": 1.900943396226415, "no_speech_prob": 0.01005964819341898}, {"id": 228, "seek": 156920, "start": 1590.16, "end": 1595.52, "text": " unfortunately because it seems like that the answer is either you look deeply into the source code of", "tokens": [51412, 7015, 570, 309, 2544, 411, 300, 264, 1867, 307, 2139, 291, 574, 8760, 666, 264, 4009, 3089, 295, 51680], "temperature": 0.0, "avg_logprob": -0.10522740061690168, "compression_ratio": 1.900943396226415, "no_speech_prob": 0.01005964819341898}, {"id": 229, "seek": 159552, "start": 1595.52, "end": 1602.48, "text": " the browsers which is i still haven't reached that point unfortunately or you do try an error", "tokens": [50364, 264, 36069, 597, 307, 741, 920, 2378, 380, 6488, 300, 935, 7015, 420, 291, 360, 853, 364, 6713, 50712], "temperature": 0.0, "avg_logprob": -0.1349160179259285, "compression_ratio": 1.5737704918032787, "no_speech_prob": 0.006433513946831226}, {"id": 230, "seek": 159552, "start": 1607.2, "end": 1613.28, "text": " ah no the tooling um you know firefox also has tooling around it which is actually if i remember", "tokens": [50948, 3716, 572, 264, 46593, 1105, 291, 458, 2610, 38416, 611, 575, 46593, 926, 309, 597, 307, 767, 498, 741, 1604, 51252], "temperature": 0.0, "avg_logprob": -0.1349160179259285, "compression_ratio": 1.5737704918032787, "no_speech_prob": 0.006433513946831226}, {"id": 231, "seek": 159552, "start": 1613.28, "end": 1620.16, "text": " correctly more focused around analyzing the memory users of the DOM elements and it also has some", "tokens": [51252, 8944, 544, 5178, 926, 23663, 264, 4675, 5022, 295, 264, 35727, 4959, 293, 309, 611, 575, 512, 51596], "temperature": 0.0, "avg_logprob": -0.1349160179259285, "compression_ratio": 1.5737704918032787, "no_speech_prob": 0.006433513946831226}, {"id": 232, "seek": 162016, "start": 1620.16, "end": 1629.2, "text": " facilities for for analyzing ip snapshots but since like memlab users works with chrome", "tokens": [50364, 9406, 337, 337, 23663, 28501, 19206, 27495, 457, 1670, 411, 1334, 44990, 5022, 1985, 365, 33120, 50816], "temperature": 0.0, "avg_logprob": -0.34369800129874806, "compression_ratio": 1.546583850931677, "no_speech_prob": 0.014019311405718327}, {"id": 233, "seek": 162016, "start": 1629.2, "end": 1631.6000000000001, "text": " ip snapshots we went with that immediately", "tokens": [50816, 28501, 19206, 27495, 321, 1437, 365, 300, 4258, 50936], "temperature": 0.0, "avg_logprob": -0.34369800129874806, "compression_ratio": 1.546583850931677, "no_speech_prob": 0.014019311405718327}, {"id": 234, "seek": 162016, "start": 1636.88, "end": 1638.8000000000002, "text": " and how do you go about running this in ci?", "tokens": [51200, 293, 577, 360, 291, 352, 466, 2614, 341, 294, 6983, 30, 51296], "temperature": 0.0, "avg_logprob": -0.34369800129874806, "compression_ratio": 1.546583850931677, "no_speech_prob": 0.014019311405718327}, {"id": 235, "seek": 162016, "start": 1639.68, "end": 1645.8400000000001, "text": " oh um yeah that's a complicated thing because running in ci it's pure pain", "tokens": [51340, 1954, 1105, 1338, 300, 311, 257, 6179, 551, 570, 2614, 294, 6983, 309, 311, 6075, 1822, 51648], "temperature": 0.0, "avg_logprob": -0.34369800129874806, "compression_ratio": 1.546583850931677, "no_speech_prob": 0.014019311405718327}, {"id": 236, "seek": 164584, "start": 1646.8, "end": 1653.04, "text": " like you can use memlab and run it in ci because it uses playwright i don't remember if it uses", "tokens": [50412, 411, 291, 393, 764, 1334, 44990, 293, 1190, 309, 294, 6983, 570, 309, 4960, 862, 37752, 741, 500, 380, 1604, 498, 309, 4960, 50724], "temperature": 0.0, "avg_logprob": -0.11737173983925267, "compression_ratio": 1.8177570093457944, "no_speech_prob": 0.023506177589297295}, {"id": 237, "seek": 164584, "start": 1653.04, "end": 1660.48, "text": " playwright or puppeteer i think puppeteer and with it you can like orchestrate some some tests", "tokens": [50724, 862, 37752, 420, 17014, 3498, 260, 741, 519, 17014, 3498, 260, 293, 365, 309, 291, 393, 411, 14161, 4404, 512, 512, 6921, 51096], "temperature": 0.0, "avg_logprob": -0.11737173983925267, "compression_ratio": 1.8177570093457944, "no_speech_prob": 0.023506177589297295}, {"id": 238, "seek": 164584, "start": 1660.48, "end": 1666.8799999999999, "text": " that open a page it can even like use some machine learning algorithm to find memory leaks the problem", "tokens": [51096, 300, 1269, 257, 3028, 309, 393, 754, 411, 764, 512, 3479, 2539, 9284, 281, 915, 4675, 28885, 264, 1154, 51416], "temperature": 0.0, "avg_logprob": -0.11737173983925267, "compression_ratio": 1.8177570093457944, "no_speech_prob": 0.023506177589297295}, {"id": 239, "seek": 164584, "start": 1666.8799999999999, "end": 1672.56, "text": " with doing that is that it's fine if your app is small if your app starts to become bigger then", "tokens": [51416, 365, 884, 300, 307, 300, 309, 311, 2489, 498, 428, 724, 307, 1359, 498, 428, 724, 3719, 281, 1813, 3801, 550, 51700], "temperature": 0.0, "avg_logprob": -0.11737173983925267, "compression_ratio": 1.8177570093457944, "no_speech_prob": 0.023506177589297295}, {"id": 240, "seek": 167256, "start": 1672.6399999999999, "end": 1677.6799999999998, "text": " uh you will need to have a ci machine that is powerful enough to be able to run your app", "tokens": [50368, 2232, 291, 486, 643, 281, 362, 257, 6983, 3479, 300, 307, 4005, 1547, 281, 312, 1075, 281, 1190, 428, 724, 50620], "temperature": 0.0, "avg_logprob": -0.17438105742136636, "compression_ratio": 1.6054054054054054, "no_speech_prob": 0.008965780958533287}, {"id": 241, "seek": 167256, "start": 1678.24, "end": 1687.36, "text": " and the profiler on top of it which for us it meant that the the ci time went like in 30 minutes", "tokens": [50648, 293, 264, 1740, 5441, 322, 1192, 295, 309, 597, 337, 505, 309, 4140, 300, 264, 264, 6983, 565, 1437, 411, 294, 2217, 2077, 51104], "temperature": 0.0, "avg_logprob": -0.17438105742136636, "compression_ratio": 1.6054054054054054, "no_speech_prob": 0.008965780958533287}, {"id": 242, "seek": 167256, "start": 1687.9199999999998, "end": 1691.36, "text": " which was unacceptable so eventually we removed it but you can do it", "tokens": [51132, 597, 390, 31812, 370, 4728, 321, 7261, 309, 457, 291, 393, 360, 309, 51304], "temperature": 0.0, "avg_logprob": -0.17438105742136636, "compression_ratio": 1.6054054054054054, "no_speech_prob": 0.008965780958533287}, {"id": 243, "seek": 167256, "start": 1695.76, "end": 1697.36, "text": " are there questions as your question there", "tokens": [51524, 366, 456, 1651, 382, 428, 1168, 456, 51604], "temperature": 0.0, "avg_logprob": -0.17438105742136636, "compression_ratio": 1.6054054054054054, "no_speech_prob": 0.008965780958533287}, {"id": 244, "seek": 170256, "start": 1703.12, "end": 1706.0, "text": " so from the browser or something like that?", "tokens": [50392, 370, 490, 264, 11185, 420, 746, 411, 300, 30, 50536], "temperature": 0.0, "avg_logprob": -0.3124720785352919, "compression_ratio": 1.6736842105263159, "no_speech_prob": 0.00755151454359293}, {"id": 245, "seek": 170256, "start": 1706.72, "end": 1714.32, "text": " yeah that's another complicated thing because if you are using chrome i don't think that firefox", "tokens": [50572, 1338, 300, 311, 1071, 6179, 551, 570, 498, 291, 366, 1228, 33120, 741, 500, 380, 519, 300, 2610, 38416, 50952], "temperature": 0.0, "avg_logprob": -0.3124720785352919, "compression_ratio": 1.6736842105263159, "no_speech_prob": 0.00755151454359293}, {"id": 246, "seek": 170256, "start": 1714.32, "end": 1719.2, "text": " allows you that but chrome does you have a specific performance or memory i think", "tokens": [50952, 4045, 291, 300, 457, 33120, 775, 291, 362, 257, 2685, 3389, 420, 4675, 741, 519, 51196], "temperature": 0.0, "avg_logprob": -0.3124720785352919, "compression_ratio": 1.6736842105263159, "no_speech_prob": 0.00755151454359293}, {"id": 247, "seek": 170256, "start": 1720.08, "end": 1726.6399999999999, "text": " variable that you can use and you can check both the maximum heap allowed size and you can also", "tokens": [51240, 7006, 300, 291, 393, 764, 293, 291, 393, 1520, 1293, 264, 6674, 33591, 4350, 2744, 293, 291, 393, 611, 51568], "temperature": 0.0, "avg_logprob": -0.3124720785352919, "compression_ratio": 1.6736842105263159, "no_speech_prob": 0.00755151454359293}, {"id": 248, "seek": 172664, "start": 1727.6000000000001, "end": 1734.5600000000002, "text": " read an estimate of the current family usage in our case once we do that we are constantly like", "tokens": [50412, 1401, 364, 12539, 295, 264, 2190, 1605, 14924, 294, 527, 1389, 1564, 321, 360, 300, 321, 366, 6460, 411, 50760], "temperature": 0.0, "avg_logprob": -0.12127017974853516, "compression_ratio": 1.7174887892376682, "no_speech_prob": 0.028850562870502472}, {"id": 249, "seek": 172664, "start": 1735.1200000000001, "end": 1742.8000000000002, "text": " giving data to segment then we analyze in amplitude with which we can like keep track of memory usage", "tokens": [50788, 2902, 1412, 281, 9469, 550, 321, 12477, 294, 27433, 365, 597, 321, 393, 411, 1066, 2837, 295, 4675, 14924, 51172], "temperature": 0.0, "avg_logprob": -0.12127017974853516, "compression_ratio": 1.7174887892376682, "no_speech_prob": 0.028850562870502472}, {"id": 250, "seek": 172664, "start": 1742.8000000000002, "end": 1747.2, "text": " and we are also doing that for like the performance timing the problem is that we notice that", "tokens": [51172, 293, 321, 366, 611, 884, 300, 337, 411, 264, 3389, 10822, 264, 1154, 307, 300, 321, 3449, 300, 51392], "temperature": 0.0, "avg_logprob": -0.12127017974853516, "compression_ratio": 1.7174887892376682, "no_speech_prob": 0.028850562870502472}, {"id": 251, "seek": 172664, "start": 1747.8400000000001, "end": 1756.5600000000002, "text": " that data who very quickly becomes bogus because it depends a lot on what the user is doing", "tokens": [51424, 300, 1412, 567, 588, 2661, 3643, 26132, 301, 570, 309, 5946, 257, 688, 322, 437, 264, 4195, 307, 884, 51860], "temperature": 0.0, "avg_logprob": -0.12127017974853516, "compression_ratio": 1.7174887892376682, "no_speech_prob": 0.028850562870502472}, {"id": 252, "seek": 175656, "start": 1756.56, "end": 1760.8799999999999, "text": " and when the garbage collector kicks in because the garbage collector sometimes is like it goes", "tokens": [50364, 293, 562, 264, 14150, 23960, 21293, 294, 570, 264, 14150, 23960, 2171, 307, 411, 309, 1709, 50580], "temperature": 0.0, "avg_logprob": -0.06678198859805153, "compression_ratio": 1.9051383399209487, "no_speech_prob": 0.007678097579628229}, {"id": 253, "seek": 175656, "start": 1760.8799999999999, "end": 1766.32, "text": " up to four gigabytes and then no problem goes down to 500 megabytes so it's extremely difficult to", "tokens": [50580, 493, 281, 1451, 42741, 293, 550, 572, 1154, 1709, 760, 281, 5923, 10816, 24538, 370, 309, 311, 4664, 2252, 281, 50852], "temperature": 0.0, "avg_logprob": -0.06678198859805153, "compression_ratio": 1.9051383399209487, "no_speech_prob": 0.007678097579628229}, {"id": 254, "seek": 175656, "start": 1766.32, "end": 1771.36, "text": " capture memory usage because you don't have a precise memory a precise measure on how much", "tokens": [50852, 7983, 4675, 14924, 570, 291, 500, 380, 362, 257, 13600, 4675, 257, 13600, 3481, 322, 577, 709, 51104], "temperature": 0.0, "avg_logprob": -0.06678198859805153, "compression_ratio": 1.9051383399209487, "no_speech_prob": 0.007678097579628229}, {"id": 255, "seek": 175656, "start": 1772.48, "end": 1777.04, "text": " of the total retained memory is active and how much is actually inactive and going to be garbage", "tokens": [51160, 295, 264, 3217, 33438, 4675, 307, 4967, 293, 577, 709, 307, 767, 294, 12596, 293, 516, 281, 312, 14150, 51388], "temperature": 0.0, "avg_logprob": -0.06678198859805153, "compression_ratio": 1.9051383399209487, "no_speech_prob": 0.007678097579628229}, {"id": 256, "seek": 175656, "start": 1777.04, "end": 1784.0, "text": " collected soon so we try to do it and we have some charts showing how much memory is being used but", "tokens": [51388, 11087, 2321, 370, 321, 853, 281, 360, 309, 293, 321, 362, 512, 17767, 4099, 577, 709, 4675, 307, 885, 1143, 457, 51736], "temperature": 0.0, "avg_logprob": -0.06678198859805153, "compression_ratio": 1.9051383399209487, "no_speech_prob": 0.007678097579628229}, {"id": 257, "seek": 178400, "start": 1784.56, "end": 1788.08, "text": " it's very hard to make sense of them unfortunately", "tokens": [50392, 309, 311, 588, 1152, 281, 652, 2020, 295, 552, 7015, 50568], "temperature": 0.0, "avg_logprob": -0.34647428072415865, "compression_ratio": 1.2934782608695652, "no_speech_prob": 0.024714218452572823}, {"id": 258, "seek": 178400, "start": 1791.2, "end": 1796.08, "text": " any other questions you still have around five minutes for questions", "tokens": [50724, 604, 661, 1651, 291, 920, 362, 926, 1732, 2077, 337, 1651, 50968], "temperature": 0.0, "avg_logprob": -0.34647428072415865, "compression_ratio": 1.2934782608695652, "no_speech_prob": 0.024714218452572823}], "language": "en"}