{"text": " So, let's start the next talk. Introduction to the Open API, podcast API with Kuhn Glotsman and Karen Einzwort. Sorry for the pronunciation. So the stage is yours. Thank you. All right. Thank you. Thank you, everyone. So, yeah. We are here to present the... Thank you. Thank you. We're here to present the Open Podcast API, which is a new specification that allows users to actually synchronize their podcast listening data, like your subscriptions episodes where you started, where you want to continue, et cetera, et cetera. So why are we actually doing this new API? It's because we have a problem. The problem is that there is actually a defecto standard for synchronizing podcasting data between devices, but it has a couple of challenges, let's say. One of them being that it's no longer actively maintained for the moment. There is a draft for a new version of the API, which is good, but has been still for a while. So that's one issue. But maybe a bigger problem is that there are some technical issues fundamentally in the API and the way it's designed. One of them is about the episode identification, which is basically based on the media URL, which is in the RSS feed. And that thing is not always unique. RSS is a standard, but it's a Wild West at the same time. So we can't really rely too much on that. So that's a problem. And also, the software behind this standard has some issues with feed duplication, which occurs if a podcast changes the RSS feed, they change their URL, then you get the same podcast twice in your subscriptions list. So I said, well, we didn't say that yet, but I'm with Antenna Pot and Kiran is with Funqvill. And in Antenna Pot, what we see is that that service, that software behind the API de facto standard is actually used as a centralized service. So there's a lot of users, which is great, but it's also a restrain on the servers. And so that overload is actually causing end users in Antenna Pot to see errors, and then they come and complain to us and we're like, well, yeah, we don't have too much influence over that. So the solution there to this, these set of problems, is to build that new API standard, which is actually building on the existing standard, but being more extensible, more standards compliant, easier to implement across different projects so that we avoid the centralization aspect. So for users, that means that they can synchronize their subscriptions, listening progress, favorites, cues, etc., etc. That the idea is that they can connect all their different devices. So whether you're on your desktop or mobile, or if you have a work mobile and a private mobile, that all your listening progress, etc., moves from one to the other. And also, this integration with the different apps would allow you as a user to actually switch from Antenna Pot to Cast if you don't like Antenna Pot for some weird reason. And so, that's on the end user side, but we need developers to implement that API, of course. To make that as easy as possible, we want to have clear and comprehensive documentation about the features, but also about the behavior. So if I send this API call, then what is expected to happen? We want to have the specs being reliable and easy to implement. And also, we want them to be feature complete, because different podcasting apps and servers and services all have different features. Some might have multiple queues that you can create. Some like Antenna Pot, we only have one queue that you can create. So we need to make sure that the API covers all these different use cases. So the approach there is to build a new API spec based on the existing standard, which I assume many of you might have guessed, is gpotter.net. Notice that it's a great thing to start from. And there are some issues that we are trying to solve. So we're building on it in a way. We're not building on it. We're taking inspiration from it, I should say. But actually, compatibility with it is not our main focus. We also try to follow the OpenAPI standard specification, because that allows for easier integration into software. With by respecting this standard, we can have CI create libraries, which are always up to date with the latest specifications. And that's our plan also to do that for different languages. And an important aspect there is also that RSS is our single source of truth, meaning that we don't want to synchronize, for example, episode titles, because that's already in the RSS feed. So why would we synchronize data that's already in the RSS feed? But at the same time, we also have already the GUIT of an episode, the unique identifier of an episode in the RSS feed. That's unique, but not really, because of RSS Wild West. So we do actually expect to create and synchronize a true unique identifier for episodes. And then we're also trying to be podcasting to the already, which refers specifically to the GUIT at the podcast level. And there are some technical challenges. One is about the episode identification. Like I said, there's a GUIT in the feed to identify an episode, but that's not always globally unique. So why is it called a GUIT anyway? You have links and you have enclosure URLs. And we thought, okay, to identify an episode in order to sync data between devices, we could do a hash of these three, but they're all changing. They're all optional in the RSS standard. So you might have none of these and then end up with no hash, I guess. So that doesn't really work. So yeah, we are having the solution that the first discover of an episode, whether that's a server, if it pulls RSS feed, the RSS feed, or if it's a client, it creates the GUIT. And then yeah, there's some things that we need to consider. Like first pull the new information from the server and then send it back to avoid race condition, et cetera. And also we expect the client to do the application of episodes. But if you're interested in more technical aspects, there's a link to the notes. Okay, thank you. So building on that sort of quite specific example, there's the more general question of feature compatibility. So clients and servers need to agree in a way on what is compatible. We need to have a way of communicating that. So we can't expect all apps and services to support every single endpoint, every single call because different apps implement different things in different ways. So to sort of get around this, what we've decided is that we should have essentially a core feature set where we say that specific endpoints are considered core and you must support them as a client or as a server in order to be considered open podcast compatible. There is of course then scope to optionally sort of extend this and to add additional endpoints which give us more functionality but are not considered core. So you can then negotiate that between your API, your server and your client. These would be then documented in the specification, what is necessary for compliance, what is an optional extension and then we can sort of work with clients and servers to map that and say what is this, what works for you and what do you need to implement. So what sort of endpoints are we looking to add? Well, we've got a few that we've already been working on. So as Kun has already mentioned, subscriptions is a big one. It's fetching and storing and syncing all of your feeds, all of your subscriptions between devices with the option to update them, change their URL or change their position or whatever it may be and delete them and to manage them across all devices. Versioning this is an important one. If the specification changes and we decide to deprecate something, change an endpoint, we need to express what major versions are supported so that clients are aware of what they are able to get from the server. We are currently discussing episodes but as Kun has already alluded to, this is a very complicated thing. So we already have a pad full of information about how we will synchronize this but the goal is to have that sort of implemented to synchronize status and playback position, how long you've played it, that kind of thing for all episodes across all different feeds. In future, we would also like to be able to synchronize settings or give an optional endpoint for synchronizing settings, search endpoint, discovery for discovering similar podcasts and features and also ratings and reviews which are becoming a big part of a lot of podcast stores. Who's involved? Currently, you've got myself and Kun. We're from Antenapod and Funqwell respectively. We've also been in conversations with casts, pod friend, Gpod Async for NextCloud and Musicpod. The idea is to get as many projects on board as possible from both the client side and the server side. Funqwell acts as both but we're more steering for server side at the moment. If you are involved in a podcast adjacent project, we would love to hear from you and get your buy-in and your advice and feedback. Just to mention on that last point, those are all open source but the idea is that closed source projects could also use this if they wanted to. What are our next steps? As mentioned, we're still discussing episodes. It's a big thing. Something we need to get right and something that we need to finalize before we can consider ourselves at a point where we have a core endpoint. We also need to discuss authentication. This is super important. You should not be able to query somebody else's status and you should not be able to get a hold of anyone else's data. It must be locked down. We need to discuss how we want to do that. It will probably be just a case of OAuth. That is for someone who knows more about OAuth than me to decide. We're currently building a new website. Currently we have a website which is built using Sphinx but we found some limitations with Sphinx in terms of having dynamic content. We're going to be rebuilding that using Astro and Starlight. It's currently just in a pull request somewhere. We're just waiting for that to get deployed somewhere. We're mapping features across apps so we need to get a greater understanding of what different features are available in different applications, how they present that information, and therefore how we can present that in our API specifications. We want to get a beta implementation in a few applications. Client applications specifically. We would like to have at least two maybe more supporting some of those core API endpoints so that we can show that it works. Which of course means we also want to have a reference server implementation which the FunQuel team will be working on just so that people have something to test against, something that they can deploy themselves if they want to. We can check that our client implementations also work as expected and according to the specification. If you want to get in contact with us, contact details are up here. There's a QR code you can scan but basically search for Open Podcast API. It's where we are. We're on Matrix. We have the website which I mentioned we'll be replacing soon. Obviously we have a GitHub organization which is where all of the conversations are currently happening. Get in touch especially if you are interested in podcasting or are currently involved in podcasting we'd really like to hear from you. If you have questions we will be outside I guess and we would love to hear from you. We're very friendly I promise. Thank you very much for listening. I'll just put the contact details up again so that you can all take your time, scan the code. Thank you very much. It was lovely.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 8.64, "text": " So, let's start the next talk.", "tokens": [50364, 407, 11, 718, 311, 722, 264, 958, 751, 13, 50796], "temperature": 0.0, "avg_logprob": -0.4294285292036078, "compression_ratio": 1.4438202247191012, "no_speech_prob": 0.24294643104076385}, {"id": 1, "seek": 0, "start": 8.64, "end": 16.48, "text": " Introduction to the Open API, podcast API with Kuhn Glotsman and Karen Einzwort.", "tokens": [50796, 27193, 882, 281, 264, 7238, 9362, 11, 7367, 9362, 365, 591, 3232, 77, 5209, 1971, 1601, 293, 14834, 6391, 89, 13802, 13, 51188], "temperature": 0.0, "avg_logprob": -0.4294285292036078, "compression_ratio": 1.4438202247191012, "no_speech_prob": 0.24294643104076385}, {"id": 2, "seek": 0, "start": 16.48, "end": 18.080000000000002, "text": " Sorry for the pronunciation.", "tokens": [51188, 4919, 337, 264, 23338, 13, 51268], "temperature": 0.0, "avg_logprob": -0.4294285292036078, "compression_ratio": 1.4438202247191012, "no_speech_prob": 0.24294643104076385}, {"id": 3, "seek": 0, "start": 18.080000000000002, "end": 19.84, "text": " So the stage is yours.", "tokens": [51268, 407, 264, 3233, 307, 6342, 13, 51356], "temperature": 0.0, "avg_logprob": -0.4294285292036078, "compression_ratio": 1.4438202247191012, "no_speech_prob": 0.24294643104076385}, {"id": 4, "seek": 0, "start": 19.84, "end": 20.84, "text": " Thank you.", "tokens": [51356, 1044, 291, 13, 51406], "temperature": 0.0, "avg_logprob": -0.4294285292036078, "compression_ratio": 1.4438202247191012, "no_speech_prob": 0.24294643104076385}, {"id": 5, "seek": 0, "start": 20.84, "end": 21.84, "text": " All right.", "tokens": [51406, 1057, 558, 13, 51456], "temperature": 0.0, "avg_logprob": -0.4294285292036078, "compression_ratio": 1.4438202247191012, "no_speech_prob": 0.24294643104076385}, {"id": 6, "seek": 0, "start": 21.84, "end": 22.84, "text": " Thank you.", "tokens": [51456, 1044, 291, 13, 51506], "temperature": 0.0, "avg_logprob": -0.4294285292036078, "compression_ratio": 1.4438202247191012, "no_speech_prob": 0.24294643104076385}, {"id": 7, "seek": 0, "start": 22.84, "end": 23.84, "text": " Thank you, everyone.", "tokens": [51506, 1044, 291, 11, 1518, 13, 51556], "temperature": 0.0, "avg_logprob": -0.4294285292036078, "compression_ratio": 1.4438202247191012, "no_speech_prob": 0.24294643104076385}, {"id": 8, "seek": 0, "start": 23.84, "end": 24.92, "text": " So, yeah.", "tokens": [51556, 407, 11, 1338, 13, 51610], "temperature": 0.0, "avg_logprob": -0.4294285292036078, "compression_ratio": 1.4438202247191012, "no_speech_prob": 0.24294643104076385}, {"id": 9, "seek": 0, "start": 24.92, "end": 28.240000000000002, "text": " We are here to present the...", "tokens": [51610, 492, 366, 510, 281, 1974, 264, 485, 51776], "temperature": 0.0, "avg_logprob": -0.4294285292036078, "compression_ratio": 1.4438202247191012, "no_speech_prob": 0.24294643104076385}, {"id": 10, "seek": 2824, "start": 28.24, "end": 29.24, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 50414], "temperature": 0.0, "avg_logprob": -0.19284868788445134, "compression_ratio": 1.559090909090909, "no_speech_prob": 0.059527549892663956}, {"id": 11, "seek": 2824, "start": 29.24, "end": 30.24, "text": " Thank you.", "tokens": [50414, 1044, 291, 13, 50464], "temperature": 0.0, "avg_logprob": -0.19284868788445134, "compression_ratio": 1.559090909090909, "no_speech_prob": 0.059527549892663956}, {"id": 12, "seek": 2824, "start": 30.24, "end": 36.16, "text": " We're here to present the Open Podcast API, which is a new specification that allows", "tokens": [50464, 492, 434, 510, 281, 1974, 264, 7238, 29972, 9362, 11, 597, 307, 257, 777, 31256, 300, 4045, 50760], "temperature": 0.0, "avg_logprob": -0.19284868788445134, "compression_ratio": 1.559090909090909, "no_speech_prob": 0.059527549892663956}, {"id": 13, "seek": 2824, "start": 36.16, "end": 43.239999999999995, "text": " users to actually synchronize their podcast listening data, like your subscriptions episodes", "tokens": [50760, 5022, 281, 767, 19331, 1125, 641, 7367, 4764, 1412, 11, 411, 428, 44951, 9313, 51114], "temperature": 0.0, "avg_logprob": -0.19284868788445134, "compression_ratio": 1.559090909090909, "no_speech_prob": 0.059527549892663956}, {"id": 14, "seek": 2824, "start": 43.239999999999995, "end": 47.08, "text": " where you started, where you want to continue, et cetera, et cetera.", "tokens": [51114, 689, 291, 1409, 11, 689, 291, 528, 281, 2354, 11, 1030, 11458, 11, 1030, 11458, 13, 51306], "temperature": 0.0, "avg_logprob": -0.19284868788445134, "compression_ratio": 1.559090909090909, "no_speech_prob": 0.059527549892663956}, {"id": 15, "seek": 2824, "start": 47.08, "end": 51.8, "text": " So why are we actually doing this new API?", "tokens": [51306, 407, 983, 366, 321, 767, 884, 341, 777, 9362, 30, 51542], "temperature": 0.0, "avg_logprob": -0.19284868788445134, "compression_ratio": 1.559090909090909, "no_speech_prob": 0.059527549892663956}, {"id": 16, "seek": 2824, "start": 51.8, "end": 54.879999999999995, "text": " It's because we have a problem.", "tokens": [51542, 467, 311, 570, 321, 362, 257, 1154, 13, 51696], "temperature": 0.0, "avg_logprob": -0.19284868788445134, "compression_ratio": 1.559090909090909, "no_speech_prob": 0.059527549892663956}, {"id": 17, "seek": 5488, "start": 55.56, "end": 61.440000000000005, "text": " The problem is that there is actually a defecto standard for synchronizing podcasting data", "tokens": [50398, 440, 1154, 307, 300, 456, 307, 767, 257, 16445, 78, 3832, 337, 19331, 3319, 7367, 278, 1412, 50692], "temperature": 0.0, "avg_logprob": -0.16191900693453276, "compression_ratio": 1.5545454545454545, "no_speech_prob": 0.041401784867048264}, {"id": 18, "seek": 5488, "start": 61.440000000000005, "end": 70.32000000000001, "text": " between devices, but it has a couple of challenges, let's say.", "tokens": [50692, 1296, 5759, 11, 457, 309, 575, 257, 1916, 295, 4759, 11, 718, 311, 584, 13, 51136], "temperature": 0.0, "avg_logprob": -0.16191900693453276, "compression_ratio": 1.5545454545454545, "no_speech_prob": 0.041401784867048264}, {"id": 19, "seek": 5488, "start": 70.32000000000001, "end": 73.64, "text": " One of them being that it's no longer actively maintained for the moment.", "tokens": [51136, 1485, 295, 552, 885, 300, 309, 311, 572, 2854, 13022, 17578, 337, 264, 1623, 13, 51302], "temperature": 0.0, "avg_logprob": -0.16191900693453276, "compression_ratio": 1.5545454545454545, "no_speech_prob": 0.041401784867048264}, {"id": 20, "seek": 5488, "start": 73.64, "end": 79.80000000000001, "text": " There is a draft for a new version of the API, which is good, but has been still for", "tokens": [51302, 821, 307, 257, 11206, 337, 257, 777, 3037, 295, 264, 9362, 11, 597, 307, 665, 11, 457, 575, 668, 920, 337, 51610], "temperature": 0.0, "avg_logprob": -0.16191900693453276, "compression_ratio": 1.5545454545454545, "no_speech_prob": 0.041401784867048264}, {"id": 21, "seek": 5488, "start": 79.80000000000001, "end": 80.80000000000001, "text": " a while.", "tokens": [51610, 257, 1339, 13, 51660], "temperature": 0.0, "avg_logprob": -0.16191900693453276, "compression_ratio": 1.5545454545454545, "no_speech_prob": 0.041401784867048264}, {"id": 22, "seek": 5488, "start": 80.80000000000001, "end": 83.84, "text": " So that's one issue.", "tokens": [51660, 407, 300, 311, 472, 2734, 13, 51812], "temperature": 0.0, "avg_logprob": -0.16191900693453276, "compression_ratio": 1.5545454545454545, "no_speech_prob": 0.041401784867048264}, {"id": 23, "seek": 8384, "start": 83.84, "end": 89.36, "text": " But maybe a bigger problem is that there are some technical issues fundamentally in the", "tokens": [50364, 583, 1310, 257, 3801, 1154, 307, 300, 456, 366, 512, 6191, 2663, 17879, 294, 264, 50640], "temperature": 0.0, "avg_logprob": -0.16180262782356955, "compression_ratio": 1.5253456221198156, "no_speech_prob": 0.035394761711359024}, {"id": 24, "seek": 8384, "start": 89.36, "end": 94.76, "text": " API and the way it's designed.", "tokens": [50640, 9362, 293, 264, 636, 309, 311, 4761, 13, 50910], "temperature": 0.0, "avg_logprob": -0.16180262782356955, "compression_ratio": 1.5253456221198156, "no_speech_prob": 0.035394761711359024}, {"id": 25, "seek": 8384, "start": 94.76, "end": 101.16, "text": " One of them is about the episode identification, which is basically based on the media URL,", "tokens": [50910, 1485, 295, 552, 307, 466, 264, 3500, 22065, 11, 597, 307, 1936, 2361, 322, 264, 3021, 12905, 11, 51230], "temperature": 0.0, "avg_logprob": -0.16180262782356955, "compression_ratio": 1.5253456221198156, "no_speech_prob": 0.035394761711359024}, {"id": 26, "seek": 8384, "start": 101.16, "end": 103.84, "text": " which is in the RSS feed.", "tokens": [51230, 597, 307, 294, 264, 497, 21929, 3154, 13, 51364], "temperature": 0.0, "avg_logprob": -0.16180262782356955, "compression_ratio": 1.5253456221198156, "no_speech_prob": 0.035394761711359024}, {"id": 27, "seek": 8384, "start": 103.84, "end": 107.64, "text": " And that thing is not always unique.", "tokens": [51364, 400, 300, 551, 307, 406, 1009, 3845, 13, 51554], "temperature": 0.0, "avg_logprob": -0.16180262782356955, "compression_ratio": 1.5253456221198156, "no_speech_prob": 0.035394761711359024}, {"id": 28, "seek": 8384, "start": 107.64, "end": 112.24000000000001, "text": " RSS is a standard, but it's a Wild West at the same time.", "tokens": [51554, 497, 21929, 307, 257, 3832, 11, 457, 309, 311, 257, 10904, 4055, 412, 264, 912, 565, 13, 51784], "temperature": 0.0, "avg_logprob": -0.16180262782356955, "compression_ratio": 1.5253456221198156, "no_speech_prob": 0.035394761711359024}, {"id": 29, "seek": 11224, "start": 112.24, "end": 115.28, "text": " So we can't really rely too much on that.", "tokens": [50364, 407, 321, 393, 380, 534, 10687, 886, 709, 322, 300, 13, 50516], "temperature": 0.0, "avg_logprob": -0.16834483734548908, "compression_ratio": 1.4973262032085561, "no_speech_prob": 0.009518063627183437}, {"id": 30, "seek": 11224, "start": 115.28, "end": 117.03999999999999, "text": " So that's a problem.", "tokens": [50516, 407, 300, 311, 257, 1154, 13, 50604], "temperature": 0.0, "avg_logprob": -0.16834483734548908, "compression_ratio": 1.4973262032085561, "no_speech_prob": 0.009518063627183437}, {"id": 31, "seek": 11224, "start": 117.03999999999999, "end": 126.0, "text": " And also, the software behind this standard has some issues with feed duplication, which", "tokens": [50604, 400, 611, 11, 264, 4722, 2261, 341, 3832, 575, 512, 2663, 365, 3154, 17154, 399, 11, 597, 51052], "temperature": 0.0, "avg_logprob": -0.16834483734548908, "compression_ratio": 1.4973262032085561, "no_speech_prob": 0.009518063627183437}, {"id": 32, "seek": 11224, "start": 126.0, "end": 135.72, "text": " occurs if a podcast changes the RSS feed, they change their URL, then you get the same podcast", "tokens": [51052, 11843, 498, 257, 7367, 2962, 264, 497, 21929, 3154, 11, 436, 1319, 641, 12905, 11, 550, 291, 483, 264, 912, 7367, 51538], "temperature": 0.0, "avg_logprob": -0.16834483734548908, "compression_ratio": 1.4973262032085561, "no_speech_prob": 0.009518063627183437}, {"id": 33, "seek": 11224, "start": 135.72, "end": 139.72, "text": " twice in your subscriptions list.", "tokens": [51538, 6091, 294, 428, 44951, 1329, 13, 51738], "temperature": 0.0, "avg_logprob": -0.16834483734548908, "compression_ratio": 1.4973262032085561, "no_speech_prob": 0.009518063627183437}, {"id": 34, "seek": 13972, "start": 140.4, "end": 147.24, "text": " So I said, well, we didn't say that yet, but I'm with Antenna Pot and Kiran is with Funqvill.", "tokens": [50398, 407, 286, 848, 11, 731, 11, 321, 994, 380, 584, 300, 1939, 11, 457, 286, 478, 365, 5130, 268, 629, 9145, 293, 11305, 282, 307, 365, 11166, 80, 85, 373, 13, 50740], "temperature": 0.0, "avg_logprob": -0.20680030019659745, "compression_ratio": 1.5507246376811594, "no_speech_prob": 0.08609668165445328}, {"id": 35, "seek": 13972, "start": 147.24, "end": 155.16, "text": " And in Antenna Pot, what we see is that that service, that software behind the API de facto", "tokens": [50740, 400, 294, 5130, 268, 629, 9145, 11, 437, 321, 536, 307, 300, 300, 2643, 11, 300, 4722, 2261, 264, 9362, 368, 42225, 51136], "temperature": 0.0, "avg_logprob": -0.20680030019659745, "compression_ratio": 1.5507246376811594, "no_speech_prob": 0.08609668165445328}, {"id": 36, "seek": 13972, "start": 155.16, "end": 158.52, "text": " standard is actually used as a centralized service.", "tokens": [51136, 3832, 307, 767, 1143, 382, 257, 32395, 2643, 13, 51304], "temperature": 0.0, "avg_logprob": -0.20680030019659745, "compression_ratio": 1.5507246376811594, "no_speech_prob": 0.08609668165445328}, {"id": 37, "seek": 13972, "start": 158.52, "end": 166.88, "text": " So there's a lot of users, which is great, but it's also a restrain on the servers.", "tokens": [51304, 407, 456, 311, 257, 688, 295, 5022, 11, 597, 307, 869, 11, 457, 309, 311, 611, 257, 1472, 7146, 322, 264, 15909, 13, 51722], "temperature": 0.0, "avg_logprob": -0.20680030019659745, "compression_ratio": 1.5507246376811594, "no_speech_prob": 0.08609668165445328}, {"id": 38, "seek": 16688, "start": 166.88, "end": 172.76, "text": " And so that overload is actually causing end users in Antenna Pot to see errors, and then", "tokens": [50364, 400, 370, 300, 28777, 307, 767, 9853, 917, 5022, 294, 5130, 268, 629, 9145, 281, 536, 13603, 11, 293, 550, 50658], "temperature": 0.0, "avg_logprob": -0.1452808072490077, "compression_ratio": 1.625, "no_speech_prob": 0.013794834725558758}, {"id": 39, "seek": 16688, "start": 172.76, "end": 177.51999999999998, "text": " they come and complain to us and we're like, well, yeah, we don't have too much influence", "tokens": [50658, 436, 808, 293, 11024, 281, 505, 293, 321, 434, 411, 11, 731, 11, 1338, 11, 321, 500, 380, 362, 886, 709, 6503, 50896], "temperature": 0.0, "avg_logprob": -0.1452808072490077, "compression_ratio": 1.625, "no_speech_prob": 0.013794834725558758}, {"id": 40, "seek": 16688, "start": 177.51999999999998, "end": 178.96, "text": " over that.", "tokens": [50896, 670, 300, 13, 50968], "temperature": 0.0, "avg_logprob": -0.1452808072490077, "compression_ratio": 1.625, "no_speech_prob": 0.013794834725558758}, {"id": 41, "seek": 16688, "start": 178.96, "end": 188.68, "text": " So the solution there to this, these set of problems, is to build that new API standard,", "tokens": [50968, 407, 264, 3827, 456, 281, 341, 11, 613, 992, 295, 2740, 11, 307, 281, 1322, 300, 777, 9362, 3832, 11, 51454], "temperature": 0.0, "avg_logprob": -0.1452808072490077, "compression_ratio": 1.625, "no_speech_prob": 0.013794834725558758}, {"id": 42, "seek": 16688, "start": 188.68, "end": 195.68, "text": " which is actually building on the existing standard, but being more extensible, more", "tokens": [51454, 597, 307, 767, 2390, 322, 264, 6741, 3832, 11, 457, 885, 544, 1279, 30633, 11, 544, 51804], "temperature": 0.0, "avg_logprob": -0.1452808072490077, "compression_ratio": 1.625, "no_speech_prob": 0.013794834725558758}, {"id": 43, "seek": 19568, "start": 195.68, "end": 202.20000000000002, "text": " standards compliant, easier to implement across different projects so that we avoid the centralization", "tokens": [50364, 7787, 36248, 11, 3571, 281, 4445, 2108, 819, 4455, 370, 300, 321, 5042, 264, 5777, 2144, 50690], "temperature": 0.0, "avg_logprob": -0.19965741899278427, "compression_ratio": 1.670995670995671, "no_speech_prob": 0.014798163436353207}, {"id": 44, "seek": 19568, "start": 202.20000000000002, "end": 203.20000000000002, "text": " aspect.", "tokens": [50690, 4171, 13, 50740], "temperature": 0.0, "avg_logprob": -0.19965741899278427, "compression_ratio": 1.670995670995671, "no_speech_prob": 0.014798163436353207}, {"id": 45, "seek": 19568, "start": 203.20000000000002, "end": 209.96, "text": " So for users, that means that they can synchronize their subscriptions, listening progress, favorites,", "tokens": [50740, 407, 337, 5022, 11, 300, 1355, 300, 436, 393, 19331, 1125, 641, 44951, 11, 4764, 4205, 11, 16907, 11, 51078], "temperature": 0.0, "avg_logprob": -0.19965741899278427, "compression_ratio": 1.670995670995671, "no_speech_prob": 0.014798163436353207}, {"id": 46, "seek": 19568, "start": 209.96, "end": 212.92000000000002, "text": " cues, etc., etc.", "tokens": [51078, 32192, 11, 5183, 7933, 5183, 13, 51226], "temperature": 0.0, "avg_logprob": -0.19965741899278427, "compression_ratio": 1.670995670995671, "no_speech_prob": 0.014798163436353207}, {"id": 47, "seek": 19568, "start": 212.92000000000002, "end": 216.64000000000001, "text": " That the idea is that they can connect all their different devices.", "tokens": [51226, 663, 264, 1558, 307, 300, 436, 393, 1745, 439, 641, 819, 5759, 13, 51412], "temperature": 0.0, "avg_logprob": -0.19965741899278427, "compression_ratio": 1.670995670995671, "no_speech_prob": 0.014798163436353207}, {"id": 48, "seek": 19568, "start": 216.64000000000001, "end": 221.64000000000001, "text": " So whether you're on your desktop or mobile, or if you have a work mobile and a private", "tokens": [51412, 407, 1968, 291, 434, 322, 428, 14502, 420, 6013, 11, 420, 498, 291, 362, 257, 589, 6013, 293, 257, 4551, 51662], "temperature": 0.0, "avg_logprob": -0.19965741899278427, "compression_ratio": 1.670995670995671, "no_speech_prob": 0.014798163436353207}, {"id": 49, "seek": 22164, "start": 221.64, "end": 227.6, "text": " mobile, that all your listening progress, etc., moves from one to the other.", "tokens": [50364, 6013, 11, 300, 439, 428, 4764, 4205, 11, 5183, 7933, 6067, 490, 472, 281, 264, 661, 13, 50662], "temperature": 0.0, "avg_logprob": -0.15342479747730298, "compression_ratio": 1.5707762557077625, "no_speech_prob": 0.06695851683616638}, {"id": 50, "seek": 22164, "start": 227.6, "end": 234.32, "text": " And also, this integration with the different apps would allow you as a user to actually", "tokens": [50662, 400, 611, 11, 341, 10980, 365, 264, 819, 7733, 576, 2089, 291, 382, 257, 4195, 281, 767, 50998], "temperature": 0.0, "avg_logprob": -0.15342479747730298, "compression_ratio": 1.5707762557077625, "no_speech_prob": 0.06695851683616638}, {"id": 51, "seek": 22164, "start": 234.32, "end": 241.32, "text": " switch from Antenna Pot to Cast if you don't like Antenna Pot for some weird reason.", "tokens": [50998, 3679, 490, 5130, 268, 629, 9145, 281, 11019, 498, 291, 500, 380, 411, 5130, 268, 629, 9145, 337, 512, 3657, 1778, 13, 51348], "temperature": 0.0, "avg_logprob": -0.15342479747730298, "compression_ratio": 1.5707762557077625, "no_speech_prob": 0.06695851683616638}, {"id": 52, "seek": 22164, "start": 241.32, "end": 246.92, "text": " And so, that's on the end user side, but we need developers to implement that API, of", "tokens": [51348, 400, 370, 11, 300, 311, 322, 264, 917, 4195, 1252, 11, 457, 321, 643, 8849, 281, 4445, 300, 9362, 11, 295, 51628], "temperature": 0.0, "avg_logprob": -0.15342479747730298, "compression_ratio": 1.5707762557077625, "no_speech_prob": 0.06695851683616638}, {"id": 53, "seek": 22164, "start": 246.92, "end": 247.92, "text": " course.", "tokens": [51628, 1164, 13, 51678], "temperature": 0.0, "avg_logprob": -0.15342479747730298, "compression_ratio": 1.5707762557077625, "no_speech_prob": 0.06695851683616638}, {"id": 54, "seek": 24792, "start": 248.28, "end": 254.16, "text": " To make that as easy as possible, we want to have clear and comprehensive documentation", "tokens": [50382, 1407, 652, 300, 382, 1858, 382, 1944, 11, 321, 528, 281, 362, 1850, 293, 13914, 14333, 50676], "temperature": 0.0, "avg_logprob": -0.14313024090182397, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.09134384989738464}, {"id": 55, "seek": 24792, "start": 254.16, "end": 256.32, "text": " about the features, but also about the behavior.", "tokens": [50676, 466, 264, 4122, 11, 457, 611, 466, 264, 5223, 13, 50784], "temperature": 0.0, "avg_logprob": -0.14313024090182397, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.09134384989738464}, {"id": 56, "seek": 24792, "start": 256.32, "end": 262.44, "text": " So if I send this API call, then what is expected to happen?", "tokens": [50784, 407, 498, 286, 2845, 341, 9362, 818, 11, 550, 437, 307, 5176, 281, 1051, 30, 51090], "temperature": 0.0, "avg_logprob": -0.14313024090182397, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.09134384989738464}, {"id": 57, "seek": 24792, "start": 262.44, "end": 267.88, "text": " We want to have the specs being reliable and easy to implement.", "tokens": [51090, 492, 528, 281, 362, 264, 27911, 885, 12924, 293, 1858, 281, 4445, 13, 51362], "temperature": 0.0, "avg_logprob": -0.14313024090182397, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.09134384989738464}, {"id": 58, "seek": 24792, "start": 267.88, "end": 274.56, "text": " And also, we want them to be feature complete, because different podcasting apps and servers", "tokens": [51362, 400, 611, 11, 321, 528, 552, 281, 312, 4111, 3566, 11, 570, 819, 7367, 278, 7733, 293, 15909, 51696], "temperature": 0.0, "avg_logprob": -0.14313024090182397, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.09134384989738464}, {"id": 59, "seek": 24792, "start": 274.56, "end": 277.2, "text": " and services all have different features.", "tokens": [51696, 293, 3328, 439, 362, 819, 4122, 13, 51828], "temperature": 0.0, "avg_logprob": -0.14313024090182397, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.09134384989738464}, {"id": 60, "seek": 27720, "start": 277.2, "end": 280.32, "text": " Some might have multiple queues that you can create.", "tokens": [50364, 2188, 1062, 362, 3866, 631, 1247, 300, 291, 393, 1884, 13, 50520], "temperature": 0.0, "avg_logprob": -0.18744398752848307, "compression_ratio": 1.625, "no_speech_prob": 0.09146599471569061}, {"id": 61, "seek": 27720, "start": 280.32, "end": 284.52, "text": " Some like Antenna Pot, we only have one queue that you can create.", "tokens": [50520, 2188, 411, 5130, 268, 629, 9145, 11, 321, 787, 362, 472, 18639, 300, 291, 393, 1884, 13, 50730], "temperature": 0.0, "avg_logprob": -0.18744398752848307, "compression_ratio": 1.625, "no_speech_prob": 0.09146599471569061}, {"id": 62, "seek": 27720, "start": 284.52, "end": 289.44, "text": " So we need to make sure that the API covers all these different use cases.", "tokens": [50730, 407, 321, 643, 281, 652, 988, 300, 264, 9362, 10538, 439, 613, 819, 764, 3331, 13, 50976], "temperature": 0.0, "avg_logprob": -0.18744398752848307, "compression_ratio": 1.625, "no_speech_prob": 0.09146599471569061}, {"id": 63, "seek": 27720, "start": 289.44, "end": 295.48, "text": " So the approach there is to build a new API spec based on the existing standard, which", "tokens": [50976, 407, 264, 3109, 456, 307, 281, 1322, 257, 777, 9362, 1608, 2361, 322, 264, 6741, 3832, 11, 597, 51278], "temperature": 0.0, "avg_logprob": -0.18744398752848307, "compression_ratio": 1.625, "no_speech_prob": 0.09146599471569061}, {"id": 64, "seek": 27720, "start": 295.48, "end": 302.48, "text": " I assume many of you might have guessed, is gpotter.net.", "tokens": [51278, 286, 6552, 867, 295, 291, 1062, 362, 21852, 11, 307, 290, 17698, 391, 13, 7129, 13, 51628], "temperature": 0.0, "avg_logprob": -0.18744398752848307, "compression_ratio": 1.625, "no_speech_prob": 0.09146599471569061}, {"id": 65, "seek": 30248, "start": 302.48, "end": 308.16, "text": " Notice that it's a great thing to start from.", "tokens": [50364, 13428, 300, 309, 311, 257, 869, 551, 281, 722, 490, 13, 50648], "temperature": 0.0, "avg_logprob": -0.20038784324348746, "compression_ratio": 1.5344827586206897, "no_speech_prob": 0.026886867359280586}, {"id": 66, "seek": 30248, "start": 308.16, "end": 312.04, "text": " And there are some issues that we are trying to solve.", "tokens": [50648, 400, 456, 366, 512, 2663, 300, 321, 366, 1382, 281, 5039, 13, 50842], "temperature": 0.0, "avg_logprob": -0.20038784324348746, "compression_ratio": 1.5344827586206897, "no_speech_prob": 0.026886867359280586}, {"id": 67, "seek": 30248, "start": 312.04, "end": 315.6, "text": " So we're building on it in a way.", "tokens": [50842, 407, 321, 434, 2390, 322, 309, 294, 257, 636, 13, 51020], "temperature": 0.0, "avg_logprob": -0.20038784324348746, "compression_ratio": 1.5344827586206897, "no_speech_prob": 0.026886867359280586}, {"id": 68, "seek": 30248, "start": 315.6, "end": 316.6, "text": " We're not building on it.", "tokens": [51020, 492, 434, 406, 2390, 322, 309, 13, 51070], "temperature": 0.0, "avg_logprob": -0.20038784324348746, "compression_ratio": 1.5344827586206897, "no_speech_prob": 0.026886867359280586}, {"id": 69, "seek": 30248, "start": 316.6, "end": 319.88, "text": " We're taking inspiration from it, I should say.", "tokens": [51070, 492, 434, 1940, 10249, 490, 309, 11, 286, 820, 584, 13, 51234], "temperature": 0.0, "avg_logprob": -0.20038784324348746, "compression_ratio": 1.5344827586206897, "no_speech_prob": 0.026886867359280586}, {"id": 70, "seek": 30248, "start": 319.88, "end": 326.8, "text": " But actually, compatibility with it is not our main focus.", "tokens": [51234, 583, 767, 11, 34237, 365, 309, 307, 406, 527, 2135, 1879, 13, 51580], "temperature": 0.0, "avg_logprob": -0.20038784324348746, "compression_ratio": 1.5344827586206897, "no_speech_prob": 0.026886867359280586}, {"id": 71, "seek": 32680, "start": 326.8, "end": 334.40000000000003, "text": " We also try to follow the OpenAPI standard specification, because that allows for easier", "tokens": [50364, 492, 611, 853, 281, 1524, 264, 7238, 4715, 40, 3832, 31256, 11, 570, 300, 4045, 337, 3571, 50744], "temperature": 0.0, "avg_logprob": -0.13394388471330915, "compression_ratio": 1.515, "no_speech_prob": 0.08000404387712479}, {"id": 72, "seek": 32680, "start": 334.40000000000003, "end": 338.08, "text": " integration into software.", "tokens": [50744, 10980, 666, 4722, 13, 50928], "temperature": 0.0, "avg_logprob": -0.13394388471330915, "compression_ratio": 1.515, "no_speech_prob": 0.08000404387712479}, {"id": 73, "seek": 32680, "start": 338.08, "end": 343.32, "text": " With by respecting this standard, we can have CI create libraries, which are always up to", "tokens": [50928, 2022, 538, 41968, 341, 3832, 11, 321, 393, 362, 37777, 1884, 15148, 11, 597, 366, 1009, 493, 281, 51190], "temperature": 0.0, "avg_logprob": -0.13394388471330915, "compression_ratio": 1.515, "no_speech_prob": 0.08000404387712479}, {"id": 74, "seek": 32680, "start": 343.32, "end": 347.16, "text": " date with the latest specifications.", "tokens": [51190, 4002, 365, 264, 6792, 29448, 13, 51382], "temperature": 0.0, "avg_logprob": -0.13394388471330915, "compression_ratio": 1.515, "no_speech_prob": 0.08000404387712479}, {"id": 75, "seek": 32680, "start": 347.16, "end": 352.72, "text": " And that's our plan also to do that for different languages.", "tokens": [51382, 400, 300, 311, 527, 1393, 611, 281, 360, 300, 337, 819, 8650, 13, 51660], "temperature": 0.0, "avg_logprob": -0.13394388471330915, "compression_ratio": 1.515, "no_speech_prob": 0.08000404387712479}, {"id": 76, "seek": 35272, "start": 352.72, "end": 359.68, "text": " And an important aspect there is also that RSS is our single source of truth, meaning", "tokens": [50364, 400, 364, 1021, 4171, 456, 307, 611, 300, 497, 21929, 307, 527, 2167, 4009, 295, 3494, 11, 3620, 50712], "temperature": 0.0, "avg_logprob": -0.14923693152034984, "compression_ratio": 1.7235023041474655, "no_speech_prob": 0.14495840668678284}, {"id": 77, "seek": 35272, "start": 359.68, "end": 366.12, "text": " that we don't want to synchronize, for example, episode titles, because that's already in", "tokens": [50712, 300, 321, 500, 380, 528, 281, 19331, 1125, 11, 337, 1365, 11, 3500, 12992, 11, 570, 300, 311, 1217, 294, 51034], "temperature": 0.0, "avg_logprob": -0.14923693152034984, "compression_ratio": 1.7235023041474655, "no_speech_prob": 0.14495840668678284}, {"id": 78, "seek": 35272, "start": 366.12, "end": 367.12, "text": " the RSS feed.", "tokens": [51034, 264, 497, 21929, 3154, 13, 51084], "temperature": 0.0, "avg_logprob": -0.14923693152034984, "compression_ratio": 1.7235023041474655, "no_speech_prob": 0.14495840668678284}, {"id": 79, "seek": 35272, "start": 367.12, "end": 371.24, "text": " So why would we synchronize data that's already in the RSS feed?", "tokens": [51084, 407, 983, 576, 321, 19331, 1125, 1412, 300, 311, 1217, 294, 264, 497, 21929, 3154, 30, 51290], "temperature": 0.0, "avg_logprob": -0.14923693152034984, "compression_ratio": 1.7235023041474655, "no_speech_prob": 0.14495840668678284}, {"id": 80, "seek": 35272, "start": 371.24, "end": 375.96000000000004, "text": " But at the same time, we also have already the GUIT of an episode, the unique identifier", "tokens": [51290, 583, 412, 264, 912, 565, 11, 321, 611, 362, 1217, 264, 17917, 3927, 295, 364, 3500, 11, 264, 3845, 45690, 51526], "temperature": 0.0, "avg_logprob": -0.14923693152034984, "compression_ratio": 1.7235023041474655, "no_speech_prob": 0.14495840668678284}, {"id": 81, "seek": 35272, "start": 375.96000000000004, "end": 378.20000000000005, "text": " of an episode in the RSS feed.", "tokens": [51526, 295, 364, 3500, 294, 264, 497, 21929, 3154, 13, 51638], "temperature": 0.0, "avg_logprob": -0.14923693152034984, "compression_ratio": 1.7235023041474655, "no_speech_prob": 0.14495840668678284}, {"id": 82, "seek": 37820, "start": 378.2, "end": 382.71999999999997, "text": " That's unique, but not really, because of RSS Wild West.", "tokens": [50364, 663, 311, 3845, 11, 457, 406, 534, 11, 570, 295, 497, 21929, 10904, 4055, 13, 50590], "temperature": 0.0, "avg_logprob": -0.11938959592348569, "compression_ratio": 1.5123152709359606, "no_speech_prob": 0.15489839017391205}, {"id": 83, "seek": 37820, "start": 382.71999999999997, "end": 393.71999999999997, "text": " So we do actually expect to create and synchronize a true unique identifier for episodes.", "tokens": [50590, 407, 321, 360, 767, 2066, 281, 1884, 293, 19331, 1125, 257, 2074, 3845, 45690, 337, 9313, 13, 51140], "temperature": 0.0, "avg_logprob": -0.11938959592348569, "compression_ratio": 1.5123152709359606, "no_speech_prob": 0.15489839017391205}, {"id": 84, "seek": 37820, "start": 393.71999999999997, "end": 398.44, "text": " And then we're also trying to be podcasting to the already, which refers specifically", "tokens": [51140, 400, 550, 321, 434, 611, 1382, 281, 312, 7367, 278, 281, 264, 1217, 11, 597, 14942, 4682, 51376], "temperature": 0.0, "avg_logprob": -0.11938959592348569, "compression_ratio": 1.5123152709359606, "no_speech_prob": 0.15489839017391205}, {"id": 85, "seek": 37820, "start": 398.44, "end": 401.96, "text": " to the GUIT at the podcast level.", "tokens": [51376, 281, 264, 17917, 3927, 412, 264, 7367, 1496, 13, 51552], "temperature": 0.0, "avg_logprob": -0.11938959592348569, "compression_ratio": 1.5123152709359606, "no_speech_prob": 0.15489839017391205}, {"id": 86, "seek": 37820, "start": 401.96, "end": 404.59999999999997, "text": " And there are some technical challenges.", "tokens": [51552, 400, 456, 366, 512, 6191, 4759, 13, 51684], "temperature": 0.0, "avg_logprob": -0.11938959592348569, "compression_ratio": 1.5123152709359606, "no_speech_prob": 0.15489839017391205}, {"id": 87, "seek": 40460, "start": 404.6, "end": 407.32000000000005, "text": " One is about the episode identification.", "tokens": [50364, 1485, 307, 466, 264, 3500, 22065, 13, 50500], "temperature": 0.0, "avg_logprob": -0.17642099380493165, "compression_ratio": 1.5751072961373391, "no_speech_prob": 0.06476656347513199}, {"id": 88, "seek": 40460, "start": 407.32000000000005, "end": 414.28000000000003, "text": " Like I said, there's a GUIT in the feed to identify an episode, but that's not always", "tokens": [50500, 1743, 286, 848, 11, 456, 311, 257, 17917, 3927, 294, 264, 3154, 281, 5876, 364, 3500, 11, 457, 300, 311, 406, 1009, 50848], "temperature": 0.0, "avg_logprob": -0.17642099380493165, "compression_ratio": 1.5751072961373391, "no_speech_prob": 0.06476656347513199}, {"id": 89, "seek": 40460, "start": 414.28000000000003, "end": 416.96000000000004, "text": " globally unique.", "tokens": [50848, 18958, 3845, 13, 50982], "temperature": 0.0, "avg_logprob": -0.17642099380493165, "compression_ratio": 1.5751072961373391, "no_speech_prob": 0.06476656347513199}, {"id": 90, "seek": 40460, "start": 416.96000000000004, "end": 420.0, "text": " So why is it called a GUIT anyway?", "tokens": [50982, 407, 983, 307, 309, 1219, 257, 17917, 3927, 4033, 30, 51134], "temperature": 0.0, "avg_logprob": -0.17642099380493165, "compression_ratio": 1.5751072961373391, "no_speech_prob": 0.06476656347513199}, {"id": 91, "seek": 40460, "start": 420.0, "end": 423.40000000000003, "text": " You have links and you have enclosure URLs.", "tokens": [51134, 509, 362, 6123, 293, 291, 362, 34093, 43267, 13, 51304], "temperature": 0.0, "avg_logprob": -0.17642099380493165, "compression_ratio": 1.5751072961373391, "no_speech_prob": 0.06476656347513199}, {"id": 92, "seek": 40460, "start": 423.40000000000003, "end": 428.04, "text": " And we thought, okay, to identify an episode in order to sync data between devices, we", "tokens": [51304, 400, 321, 1194, 11, 1392, 11, 281, 5876, 364, 3500, 294, 1668, 281, 20271, 1412, 1296, 5759, 11, 321, 51536], "temperature": 0.0, "avg_logprob": -0.17642099380493165, "compression_ratio": 1.5751072961373391, "no_speech_prob": 0.06476656347513199}, {"id": 93, "seek": 40460, "start": 428.04, "end": 432.76000000000005, "text": " could do a hash of these three, but they're all changing.", "tokens": [51536, 727, 360, 257, 22019, 295, 613, 1045, 11, 457, 436, 434, 439, 4473, 13, 51772], "temperature": 0.0, "avg_logprob": -0.17642099380493165, "compression_ratio": 1.5751072961373391, "no_speech_prob": 0.06476656347513199}, {"id": 94, "seek": 43276, "start": 432.76, "end": 434.64, "text": " They're all optional in the RSS standard.", "tokens": [50364, 814, 434, 439, 17312, 294, 264, 497, 21929, 3832, 13, 50458], "temperature": 0.0, "avg_logprob": -0.15074993480335583, "compression_ratio": 1.6379310344827587, "no_speech_prob": 0.1000833585858345}, {"id": 95, "seek": 43276, "start": 434.64, "end": 439.36, "text": " So you might have none of these and then end up with no hash, I guess.", "tokens": [50458, 407, 291, 1062, 362, 6022, 295, 613, 293, 550, 917, 493, 365, 572, 22019, 11, 286, 2041, 13, 50694], "temperature": 0.0, "avg_logprob": -0.15074993480335583, "compression_ratio": 1.6379310344827587, "no_speech_prob": 0.1000833585858345}, {"id": 96, "seek": 43276, "start": 439.36, "end": 441.84, "text": " So that doesn't really work.", "tokens": [50694, 407, 300, 1177, 380, 534, 589, 13, 50818], "temperature": 0.0, "avg_logprob": -0.15074993480335583, "compression_ratio": 1.6379310344827587, "no_speech_prob": 0.1000833585858345}, {"id": 97, "seek": 43276, "start": 441.84, "end": 447.68, "text": " So yeah, we are having the solution that the first discover of an episode, whether that's", "tokens": [50818, 407, 1338, 11, 321, 366, 1419, 264, 3827, 300, 264, 700, 4411, 295, 364, 3500, 11, 1968, 300, 311, 51110], "temperature": 0.0, "avg_logprob": -0.15074993480335583, "compression_ratio": 1.6379310344827587, "no_speech_prob": 0.1000833585858345}, {"id": 98, "seek": 43276, "start": 447.68, "end": 455.92, "text": " a server, if it pulls RSS feed, the RSS feed, or if it's a client, it creates the GUIT.", "tokens": [51110, 257, 7154, 11, 498, 309, 16982, 497, 21929, 3154, 11, 264, 497, 21929, 3154, 11, 420, 498, 309, 311, 257, 6423, 11, 309, 7829, 264, 17917, 3927, 13, 51522], "temperature": 0.0, "avg_logprob": -0.15074993480335583, "compression_ratio": 1.6379310344827587, "no_speech_prob": 0.1000833585858345}, {"id": 99, "seek": 43276, "start": 455.92, "end": 458.56, "text": " And then yeah, there's some things that we need to consider.", "tokens": [51522, 400, 550, 1338, 11, 456, 311, 512, 721, 300, 321, 643, 281, 1949, 13, 51654], "temperature": 0.0, "avg_logprob": -0.15074993480335583, "compression_ratio": 1.6379310344827587, "no_speech_prob": 0.1000833585858345}, {"id": 100, "seek": 45856, "start": 458.56, "end": 464.32, "text": " Like first pull the new information from the server and then send it back to avoid race", "tokens": [50364, 1743, 700, 2235, 264, 777, 1589, 490, 264, 7154, 293, 550, 2845, 309, 646, 281, 5042, 4569, 50652], "temperature": 0.0, "avg_logprob": -0.17782988446824094, "compression_ratio": 1.5802469135802468, "no_speech_prob": 0.026490358635783195}, {"id": 101, "seek": 45856, "start": 464.32, "end": 466.72, "text": " condition, et cetera.", "tokens": [50652, 4188, 11, 1030, 11458, 13, 50772], "temperature": 0.0, "avg_logprob": -0.17782988446824094, "compression_ratio": 1.5802469135802468, "no_speech_prob": 0.026490358635783195}, {"id": 102, "seek": 45856, "start": 466.72, "end": 470.96, "text": " And also we expect the client to do the application of episodes.", "tokens": [50772, 400, 611, 321, 2066, 264, 6423, 281, 360, 264, 3861, 295, 9313, 13, 50984], "temperature": 0.0, "avg_logprob": -0.17782988446824094, "compression_ratio": 1.5802469135802468, "no_speech_prob": 0.026490358635783195}, {"id": 103, "seek": 45856, "start": 470.96, "end": 476.12, "text": " But if you're interested in more technical aspects, there's a link to the notes.", "tokens": [50984, 583, 498, 291, 434, 3102, 294, 544, 6191, 7270, 11, 456, 311, 257, 2113, 281, 264, 5570, 13, 51242], "temperature": 0.0, "avg_logprob": -0.17782988446824094, "compression_ratio": 1.5802469135802468, "no_speech_prob": 0.026490358635783195}, {"id": 104, "seek": 45856, "start": 476.12, "end": 479.28, "text": " Okay, thank you.", "tokens": [51242, 1033, 11, 1309, 291, 13, 51400], "temperature": 0.0, "avg_logprob": -0.17782988446824094, "compression_ratio": 1.5802469135802468, "no_speech_prob": 0.026490358635783195}, {"id": 105, "seek": 45856, "start": 479.28, "end": 483.36, "text": " So building on that sort of quite specific example, there's the more general question", "tokens": [51400, 407, 2390, 322, 300, 1333, 295, 1596, 2685, 1365, 11, 456, 311, 264, 544, 2674, 1168, 51604], "temperature": 0.0, "avg_logprob": -0.17782988446824094, "compression_ratio": 1.5802469135802468, "no_speech_prob": 0.026490358635783195}, {"id": 106, "seek": 45856, "start": 483.36, "end": 485.68, "text": " of feature compatibility.", "tokens": [51604, 295, 4111, 34237, 13, 51720], "temperature": 0.0, "avg_logprob": -0.17782988446824094, "compression_ratio": 1.5802469135802468, "no_speech_prob": 0.026490358635783195}, {"id": 107, "seek": 48568, "start": 485.68, "end": 490.88, "text": " So clients and servers need to agree in a way on what is compatible.", "tokens": [50364, 407, 6982, 293, 15909, 643, 281, 3986, 294, 257, 636, 322, 437, 307, 18218, 13, 50624], "temperature": 0.0, "avg_logprob": -0.12166131711473652, "compression_ratio": 1.774703557312253, "no_speech_prob": 0.008485493250191212}, {"id": 108, "seek": 48568, "start": 490.88, "end": 493.36, "text": " We need to have a way of communicating that.", "tokens": [50624, 492, 643, 281, 362, 257, 636, 295, 17559, 300, 13, 50748], "temperature": 0.0, "avg_logprob": -0.12166131711473652, "compression_ratio": 1.774703557312253, "no_speech_prob": 0.008485493250191212}, {"id": 109, "seek": 48568, "start": 493.36, "end": 498.08, "text": " So we can't expect all apps and services to support every single endpoint, every single", "tokens": [50748, 407, 321, 393, 380, 2066, 439, 7733, 293, 3328, 281, 1406, 633, 2167, 35795, 11, 633, 2167, 50984], "temperature": 0.0, "avg_logprob": -0.12166131711473652, "compression_ratio": 1.774703557312253, "no_speech_prob": 0.008485493250191212}, {"id": 110, "seek": 48568, "start": 498.08, "end": 502.52, "text": " call because different apps implement different things in different ways.", "tokens": [50984, 818, 570, 819, 7733, 4445, 819, 721, 294, 819, 2098, 13, 51206], "temperature": 0.0, "avg_logprob": -0.12166131711473652, "compression_ratio": 1.774703557312253, "no_speech_prob": 0.008485493250191212}, {"id": 111, "seek": 48568, "start": 502.52, "end": 506.8, "text": " So to sort of get around this, what we've decided is that we should have essentially", "tokens": [51206, 407, 281, 1333, 295, 483, 926, 341, 11, 437, 321, 600, 3047, 307, 300, 321, 820, 362, 4476, 51420], "temperature": 0.0, "avg_logprob": -0.12166131711473652, "compression_ratio": 1.774703557312253, "no_speech_prob": 0.008485493250191212}, {"id": 112, "seek": 48568, "start": 506.8, "end": 512.64, "text": " a core feature set where we say that specific endpoints are considered core and you must", "tokens": [51420, 257, 4965, 4111, 992, 689, 321, 584, 300, 2685, 917, 20552, 366, 4888, 4965, 293, 291, 1633, 51712], "temperature": 0.0, "avg_logprob": -0.12166131711473652, "compression_ratio": 1.774703557312253, "no_speech_prob": 0.008485493250191212}, {"id": 113, "seek": 51264, "start": 512.64, "end": 520.92, "text": " support them as a client or as a server in order to be considered open podcast compatible.", "tokens": [50364, 1406, 552, 382, 257, 6423, 420, 382, 257, 7154, 294, 1668, 281, 312, 4888, 1269, 7367, 18218, 13, 50778], "temperature": 0.0, "avg_logprob": -0.1392710015580461, "compression_ratio": 1.6059113300492611, "no_speech_prob": 0.07077214866876602}, {"id": 114, "seek": 51264, "start": 520.92, "end": 526.8, "text": " There is of course then scope to optionally sort of extend this and to add additional", "tokens": [50778, 821, 307, 295, 1164, 550, 11923, 281, 3614, 379, 1333, 295, 10101, 341, 293, 281, 909, 4497, 51072], "temperature": 0.0, "avg_logprob": -0.1392710015580461, "compression_ratio": 1.6059113300492611, "no_speech_prob": 0.07077214866876602}, {"id": 115, "seek": 51264, "start": 526.8, "end": 533.92, "text": " endpoints which give us more functionality but are not considered core.", "tokens": [51072, 917, 20552, 597, 976, 505, 544, 14980, 457, 366, 406, 4888, 4965, 13, 51428], "temperature": 0.0, "avg_logprob": -0.1392710015580461, "compression_ratio": 1.6059113300492611, "no_speech_prob": 0.07077214866876602}, {"id": 116, "seek": 51264, "start": 533.92, "end": 539.28, "text": " So you can then negotiate that between your API, your server and your client.", "tokens": [51428, 407, 291, 393, 550, 21713, 300, 1296, 428, 9362, 11, 428, 7154, 293, 428, 6423, 13, 51696], "temperature": 0.0, "avg_logprob": -0.1392710015580461, "compression_ratio": 1.6059113300492611, "no_speech_prob": 0.07077214866876602}, {"id": 117, "seek": 53928, "start": 539.28, "end": 544.24, "text": " These would be then documented in the specification, what is necessary for compliance, what is", "tokens": [50364, 1981, 576, 312, 550, 23007, 294, 264, 31256, 11, 437, 307, 4818, 337, 15882, 11, 437, 307, 50612], "temperature": 0.0, "avg_logprob": -0.15900460729059182, "compression_ratio": 1.697211155378486, "no_speech_prob": 0.2005612701177597}, {"id": 118, "seek": 53928, "start": 544.24, "end": 550.88, "text": " an optional extension and then we can sort of work with clients and servers to map that", "tokens": [50612, 364, 17312, 10320, 293, 550, 321, 393, 1333, 295, 589, 365, 6982, 293, 15909, 281, 4471, 300, 50944], "temperature": 0.0, "avg_logprob": -0.15900460729059182, "compression_ratio": 1.697211155378486, "no_speech_prob": 0.2005612701177597}, {"id": 119, "seek": 53928, "start": 550.88, "end": 555.68, "text": " and say what is this, what works for you and what do you need to implement.", "tokens": [50944, 293, 584, 437, 307, 341, 11, 437, 1985, 337, 291, 293, 437, 360, 291, 643, 281, 4445, 13, 51184], "temperature": 0.0, "avg_logprob": -0.15900460729059182, "compression_ratio": 1.697211155378486, "no_speech_prob": 0.2005612701177597}, {"id": 120, "seek": 53928, "start": 555.68, "end": 558.72, "text": " So what sort of endpoints are we looking to add?", "tokens": [51184, 407, 437, 1333, 295, 917, 20552, 366, 321, 1237, 281, 909, 30, 51336], "temperature": 0.0, "avg_logprob": -0.15900460729059182, "compression_ratio": 1.697211155378486, "no_speech_prob": 0.2005612701177597}, {"id": 121, "seek": 53928, "start": 558.72, "end": 561.0, "text": " Well, we've got a few that we've already been working on.", "tokens": [51336, 1042, 11, 321, 600, 658, 257, 1326, 300, 321, 600, 1217, 668, 1364, 322, 13, 51450], "temperature": 0.0, "avg_logprob": -0.15900460729059182, "compression_ratio": 1.697211155378486, "no_speech_prob": 0.2005612701177597}, {"id": 122, "seek": 53928, "start": 561.0, "end": 564.3199999999999, "text": " So as Kun has already mentioned, subscriptions is a big one.", "tokens": [51450, 407, 382, 19089, 575, 1217, 2835, 11, 44951, 307, 257, 955, 472, 13, 51616], "temperature": 0.0, "avg_logprob": -0.15900460729059182, "compression_ratio": 1.697211155378486, "no_speech_prob": 0.2005612701177597}, {"id": 123, "seek": 56432, "start": 564.32, "end": 570.24, "text": " It's fetching and storing and syncing all of your feeds, all of your subscriptions between", "tokens": [50364, 467, 311, 23673, 278, 293, 26085, 293, 5451, 2175, 439, 295, 428, 23712, 11, 439, 295, 428, 44951, 1296, 50660], "temperature": 0.0, "avg_logprob": -0.16518263981260103, "compression_ratio": 1.7110091743119267, "no_speech_prob": 0.5943471193313599}, {"id": 124, "seek": 56432, "start": 570.24, "end": 576.7600000000001, "text": " devices with the option to update them, change their URL or change their position or whatever", "tokens": [50660, 5759, 365, 264, 3614, 281, 5623, 552, 11, 1319, 641, 12905, 420, 1319, 641, 2535, 420, 2035, 50986], "temperature": 0.0, "avg_logprob": -0.16518263981260103, "compression_ratio": 1.7110091743119267, "no_speech_prob": 0.5943471193313599}, {"id": 125, "seek": 56432, "start": 576.7600000000001, "end": 582.0400000000001, "text": " it may be and delete them and to manage them across all devices.", "tokens": [50986, 309, 815, 312, 293, 12097, 552, 293, 281, 3067, 552, 2108, 439, 5759, 13, 51250], "temperature": 0.0, "avg_logprob": -0.16518263981260103, "compression_ratio": 1.7110091743119267, "no_speech_prob": 0.5943471193313599}, {"id": 126, "seek": 56432, "start": 582.0400000000001, "end": 583.6800000000001, "text": " Versioning this is an important one.", "tokens": [51250, 35965, 278, 341, 307, 364, 1021, 472, 13, 51332], "temperature": 0.0, "avg_logprob": -0.16518263981260103, "compression_ratio": 1.7110091743119267, "no_speech_prob": 0.5943471193313599}, {"id": 127, "seek": 56432, "start": 583.6800000000001, "end": 589.8800000000001, "text": " If the specification changes and we decide to deprecate something, change an endpoint,", "tokens": [51332, 759, 264, 31256, 2962, 293, 321, 4536, 281, 1367, 13867, 473, 746, 11, 1319, 364, 35795, 11, 51642], "temperature": 0.0, "avg_logprob": -0.16518263981260103, "compression_ratio": 1.7110091743119267, "no_speech_prob": 0.5943471193313599}, {"id": 128, "seek": 58988, "start": 589.88, "end": 595.92, "text": " we need to express what major versions are supported so that clients are aware of what", "tokens": [50364, 321, 643, 281, 5109, 437, 2563, 9606, 366, 8104, 370, 300, 6982, 366, 3650, 295, 437, 50666], "temperature": 0.0, "avg_logprob": -0.1123963632891255, "compression_ratio": 1.6356275303643724, "no_speech_prob": 0.24335213005542755}, {"id": 129, "seek": 58988, "start": 595.92, "end": 599.32, "text": " they are able to get from the server.", "tokens": [50666, 436, 366, 1075, 281, 483, 490, 264, 7154, 13, 50836], "temperature": 0.0, "avg_logprob": -0.1123963632891255, "compression_ratio": 1.6356275303643724, "no_speech_prob": 0.24335213005542755}, {"id": 130, "seek": 58988, "start": 599.32, "end": 603.2, "text": " We are currently discussing episodes but as Kun has already alluded to, this is a very", "tokens": [50836, 492, 366, 4362, 10850, 9313, 457, 382, 19089, 575, 1217, 33919, 281, 11, 341, 307, 257, 588, 51030], "temperature": 0.0, "avg_logprob": -0.1123963632891255, "compression_ratio": 1.6356275303643724, "no_speech_prob": 0.24335213005542755}, {"id": 131, "seek": 58988, "start": 603.2, "end": 605.32, "text": " complicated thing.", "tokens": [51030, 6179, 551, 13, 51136], "temperature": 0.0, "avg_logprob": -0.1123963632891255, "compression_ratio": 1.6356275303643724, "no_speech_prob": 0.24335213005542755}, {"id": 132, "seek": 58988, "start": 605.32, "end": 611.64, "text": " So we already have a pad full of information about how we will synchronize this but the", "tokens": [51136, 407, 321, 1217, 362, 257, 6887, 1577, 295, 1589, 466, 577, 321, 486, 19331, 1125, 341, 457, 264, 51452], "temperature": 0.0, "avg_logprob": -0.1123963632891255, "compression_ratio": 1.6356275303643724, "no_speech_prob": 0.24335213005542755}, {"id": 133, "seek": 58988, "start": 611.64, "end": 619.08, "text": " goal is to have that sort of implemented to synchronize status and playback position,", "tokens": [51452, 3387, 307, 281, 362, 300, 1333, 295, 12270, 281, 19331, 1125, 6558, 293, 37223, 2535, 11, 51824], "temperature": 0.0, "avg_logprob": -0.1123963632891255, "compression_ratio": 1.6356275303643724, "no_speech_prob": 0.24335213005542755}, {"id": 134, "seek": 61908, "start": 619.08, "end": 626.8000000000001, "text": " how long you've played it, that kind of thing for all episodes across all different feeds.", "tokens": [50364, 577, 938, 291, 600, 3737, 309, 11, 300, 733, 295, 551, 337, 439, 9313, 2108, 439, 819, 23712, 13, 50750], "temperature": 0.0, "avg_logprob": -0.1794255909166838, "compression_ratio": 1.6384976525821595, "no_speech_prob": 0.10384400188922882}, {"id": 135, "seek": 61908, "start": 626.8000000000001, "end": 630.96, "text": " In future, we would also like to be able to synchronize settings or give an optional", "tokens": [50750, 682, 2027, 11, 321, 576, 611, 411, 281, 312, 1075, 281, 19331, 1125, 6257, 420, 976, 364, 17312, 50958], "temperature": 0.0, "avg_logprob": -0.1794255909166838, "compression_ratio": 1.6384976525821595, "no_speech_prob": 0.10384400188922882}, {"id": 136, "seek": 61908, "start": 630.96, "end": 639.32, "text": " endpoint for synchronizing settings, search endpoint, discovery for discovering similar", "tokens": [50958, 35795, 337, 19331, 3319, 6257, 11, 3164, 35795, 11, 12114, 337, 24773, 2531, 51376], "temperature": 0.0, "avg_logprob": -0.1794255909166838, "compression_ratio": 1.6384976525821595, "no_speech_prob": 0.10384400188922882}, {"id": 137, "seek": 61908, "start": 639.32, "end": 644.5600000000001, "text": " podcasts and features and also ratings and reviews which are becoming a big part of a", "tokens": [51376, 24045, 293, 4122, 293, 611, 24603, 293, 10229, 597, 366, 5617, 257, 955, 644, 295, 257, 51638], "temperature": 0.0, "avg_logprob": -0.1794255909166838, "compression_ratio": 1.6384976525821595, "no_speech_prob": 0.10384400188922882}, {"id": 138, "seek": 64456, "start": 644.56, "end": 650.1999999999999, "text": " lot of podcast stores.", "tokens": [50364, 688, 295, 7367, 9512, 13, 50646], "temperature": 0.0, "avg_logprob": -0.32680204936436247, "compression_ratio": 1.5603112840466926, "no_speech_prob": 0.4049067497253418}, {"id": 139, "seek": 64456, "start": 650.1999999999999, "end": 651.1999999999999, "text": " Who's involved?", "tokens": [50646, 2102, 311, 3288, 30, 50696], "temperature": 0.0, "avg_logprob": -0.32680204936436247, "compression_ratio": 1.5603112840466926, "no_speech_prob": 0.4049067497253418}, {"id": 140, "seek": 64456, "start": 651.1999999999999, "end": 653.76, "text": " Currently, you've got myself and Kun.", "tokens": [50696, 19964, 11, 291, 600, 658, 2059, 293, 19089, 13, 50824], "temperature": 0.0, "avg_logprob": -0.32680204936436247, "compression_ratio": 1.5603112840466926, "no_speech_prob": 0.4049067497253418}, {"id": 141, "seek": 64456, "start": 653.76, "end": 656.9599999999999, "text": " We're from Antenapod and Funqwell respectively.", "tokens": [50824, 492, 434, 490, 5130, 268, 569, 378, 293, 11166, 80, 6326, 25009, 13, 50984], "temperature": 0.0, "avg_logprob": -0.32680204936436247, "compression_ratio": 1.5603112840466926, "no_speech_prob": 0.4049067497253418}, {"id": 142, "seek": 64456, "start": 656.9599999999999, "end": 663.0, "text": " We've also been in conversations with casts, pod friend, Gpod Async for NextCloud and Musicpod.", "tokens": [50984, 492, 600, 611, 668, 294, 7315, 365, 41921, 11, 2497, 1277, 11, 460, 43388, 1018, 34015, 337, 3087, 32787, 293, 7609, 43388, 13, 51286], "temperature": 0.0, "avg_logprob": -0.32680204936436247, "compression_ratio": 1.5603112840466926, "no_speech_prob": 0.4049067497253418}, {"id": 143, "seek": 64456, "start": 663.0, "end": 668.3599999999999, "text": " The idea is to get as many projects on board as possible from both the client side and", "tokens": [51286, 440, 1558, 307, 281, 483, 382, 867, 4455, 322, 3150, 382, 1944, 490, 1293, 264, 6423, 1252, 293, 51554], "temperature": 0.0, "avg_logprob": -0.32680204936436247, "compression_ratio": 1.5603112840466926, "no_speech_prob": 0.4049067497253418}, {"id": 144, "seek": 64456, "start": 668.3599999999999, "end": 669.3599999999999, "text": " the server side.", "tokens": [51554, 264, 7154, 1252, 13, 51604], "temperature": 0.0, "avg_logprob": -0.32680204936436247, "compression_ratio": 1.5603112840466926, "no_speech_prob": 0.4049067497253418}, {"id": 145, "seek": 64456, "start": 669.3599999999999, "end": 674.52, "text": " Funqwell acts as both but we're more steering for server side at the moment.", "tokens": [51604, 11166, 80, 6326, 10672, 382, 1293, 457, 321, 434, 544, 14823, 337, 7154, 1252, 412, 264, 1623, 13, 51862], "temperature": 0.0, "avg_logprob": -0.32680204936436247, "compression_ratio": 1.5603112840466926, "no_speech_prob": 0.4049067497253418}, {"id": 146, "seek": 67452, "start": 675.28, "end": 680.0, "text": " If you are involved in a podcast adjacent project, we would love to hear from you and", "tokens": [50402, 759, 291, 366, 3288, 294, 257, 7367, 24441, 1716, 11, 321, 576, 959, 281, 1568, 490, 291, 293, 50638], "temperature": 0.0, "avg_logprob": -0.17543365557988486, "compression_ratio": 1.564102564102564, "no_speech_prob": 0.04634130373597145}, {"id": 147, "seek": 67452, "start": 680.0, "end": 685.64, "text": " get your buy-in and your advice and feedback.", "tokens": [50638, 483, 428, 2256, 12, 259, 293, 428, 5192, 293, 5824, 13, 50920], "temperature": 0.0, "avg_logprob": -0.17543365557988486, "compression_ratio": 1.564102564102564, "no_speech_prob": 0.04634130373597145}, {"id": 148, "seek": 67452, "start": 685.64, "end": 689.52, "text": " Just to mention on that last point, those are all open source but the idea is that closed", "tokens": [50920, 1449, 281, 2152, 322, 300, 1036, 935, 11, 729, 366, 439, 1269, 4009, 457, 264, 1558, 307, 300, 5395, 51114], "temperature": 0.0, "avg_logprob": -0.17543365557988486, "compression_ratio": 1.564102564102564, "no_speech_prob": 0.04634130373597145}, {"id": 149, "seek": 67452, "start": 689.52, "end": 695.0799999999999, "text": " source projects could also use this if they wanted to.", "tokens": [51114, 4009, 4455, 727, 611, 764, 341, 498, 436, 1415, 281, 13, 51392], "temperature": 0.0, "avg_logprob": -0.17543365557988486, "compression_ratio": 1.564102564102564, "no_speech_prob": 0.04634130373597145}, {"id": 150, "seek": 67452, "start": 695.0799999999999, "end": 696.72, "text": " What are our next steps?", "tokens": [51392, 708, 366, 527, 958, 4439, 30, 51474], "temperature": 0.0, "avg_logprob": -0.17543365557988486, "compression_ratio": 1.564102564102564, "no_speech_prob": 0.04634130373597145}, {"id": 151, "seek": 67452, "start": 696.72, "end": 699.64, "text": " As mentioned, we're still discussing episodes.", "tokens": [51474, 1018, 2835, 11, 321, 434, 920, 10850, 9313, 13, 51620], "temperature": 0.0, "avg_logprob": -0.17543365557988486, "compression_ratio": 1.564102564102564, "no_speech_prob": 0.04634130373597145}, {"id": 152, "seek": 67452, "start": 699.64, "end": 700.64, "text": " It's a big thing.", "tokens": [51620, 467, 311, 257, 955, 551, 13, 51670], "temperature": 0.0, "avg_logprob": -0.17543365557988486, "compression_ratio": 1.564102564102564, "no_speech_prob": 0.04634130373597145}, {"id": 153, "seek": 70064, "start": 700.76, "end": 706.84, "text": " Something we need to get right and something that we need to finalize before we can consider", "tokens": [50370, 6595, 321, 643, 281, 483, 558, 293, 746, 300, 321, 643, 281, 2572, 1125, 949, 321, 393, 1949, 50674], "temperature": 0.0, "avg_logprob": -0.17465098150845232, "compression_ratio": 1.748, "no_speech_prob": 0.10724065452814102}, {"id": 154, "seek": 70064, "start": 706.84, "end": 710.84, "text": " ourselves at a point where we have a core endpoint.", "tokens": [50674, 4175, 412, 257, 935, 689, 321, 362, 257, 4965, 35795, 13, 50874], "temperature": 0.0, "avg_logprob": -0.17465098150845232, "compression_ratio": 1.748, "no_speech_prob": 0.10724065452814102}, {"id": 155, "seek": 70064, "start": 710.84, "end": 712.6, "text": " We also need to discuss authentication.", "tokens": [50874, 492, 611, 643, 281, 2248, 26643, 13, 50962], "temperature": 0.0, "avg_logprob": -0.17465098150845232, "compression_ratio": 1.748, "no_speech_prob": 0.10724065452814102}, {"id": 156, "seek": 70064, "start": 712.6, "end": 714.3199999999999, "text": " This is super important.", "tokens": [50962, 639, 307, 1687, 1021, 13, 51048], "temperature": 0.0, "avg_logprob": -0.17465098150845232, "compression_ratio": 1.748, "no_speech_prob": 0.10724065452814102}, {"id": 157, "seek": 70064, "start": 714.3199999999999, "end": 720.04, "text": " You should not be able to query somebody else's status and you should not be able to get a", "tokens": [51048, 509, 820, 406, 312, 1075, 281, 14581, 2618, 1646, 311, 6558, 293, 291, 820, 406, 312, 1075, 281, 483, 257, 51334], "temperature": 0.0, "avg_logprob": -0.17465098150845232, "compression_ratio": 1.748, "no_speech_prob": 0.10724065452814102}, {"id": 158, "seek": 70064, "start": 720.04, "end": 721.28, "text": " hold of anyone else's data.", "tokens": [51334, 1797, 295, 2878, 1646, 311, 1412, 13, 51396], "temperature": 0.0, "avg_logprob": -0.17465098150845232, "compression_ratio": 1.748, "no_speech_prob": 0.10724065452814102}, {"id": 159, "seek": 70064, "start": 721.28, "end": 722.28, "text": " It must be locked down.", "tokens": [51396, 467, 1633, 312, 9376, 760, 13, 51446], "temperature": 0.0, "avg_logprob": -0.17465098150845232, "compression_ratio": 1.748, "no_speech_prob": 0.10724065452814102}, {"id": 160, "seek": 70064, "start": 722.28, "end": 724.24, "text": " We need to discuss how we want to do that.", "tokens": [51446, 492, 643, 281, 2248, 577, 321, 528, 281, 360, 300, 13, 51544], "temperature": 0.0, "avg_logprob": -0.17465098150845232, "compression_ratio": 1.748, "no_speech_prob": 0.10724065452814102}, {"id": 161, "seek": 70064, "start": 724.24, "end": 728.16, "text": " It will probably be just a case of OAuth.", "tokens": [51544, 467, 486, 1391, 312, 445, 257, 1389, 295, 48424, 2910, 13, 51740], "temperature": 0.0, "avg_logprob": -0.17465098150845232, "compression_ratio": 1.748, "no_speech_prob": 0.10724065452814102}, {"id": 162, "seek": 72816, "start": 728.1999999999999, "end": 732.6, "text": " That is for someone who knows more about OAuth than me to decide.", "tokens": [50366, 663, 307, 337, 1580, 567, 3255, 544, 466, 48424, 2910, 813, 385, 281, 4536, 13, 50586], "temperature": 0.0, "avg_logprob": -0.19153860503552006, "compression_ratio": 1.6763485477178424, "no_speech_prob": 0.030007926747202873}, {"id": 163, "seek": 72816, "start": 732.6, "end": 735.0799999999999, "text": " We're currently building a new website.", "tokens": [50586, 492, 434, 4362, 2390, 257, 777, 3144, 13, 50710], "temperature": 0.0, "avg_logprob": -0.19153860503552006, "compression_ratio": 1.6763485477178424, "no_speech_prob": 0.030007926747202873}, {"id": 164, "seek": 72816, "start": 735.0799999999999, "end": 739.52, "text": " Currently we have a website which is built using Sphinx but we found some limitations", "tokens": [50710, 19964, 321, 362, 257, 3144, 597, 307, 3094, 1228, 318, 48522, 87, 457, 321, 1352, 512, 15705, 50932], "temperature": 0.0, "avg_logprob": -0.19153860503552006, "compression_ratio": 1.6763485477178424, "no_speech_prob": 0.030007926747202873}, {"id": 165, "seek": 72816, "start": 739.52, "end": 745.56, "text": " with Sphinx in terms of having dynamic content.", "tokens": [50932, 365, 318, 48522, 87, 294, 2115, 295, 1419, 8546, 2701, 13, 51234], "temperature": 0.0, "avg_logprob": -0.19153860503552006, "compression_ratio": 1.6763485477178424, "no_speech_prob": 0.030007926747202873}, {"id": 166, "seek": 72816, "start": 745.56, "end": 748.88, "text": " We're going to be rebuilding that using Astro and Starlight.", "tokens": [51234, 492, 434, 516, 281, 312, 36717, 300, 1228, 12884, 340, 293, 5705, 2764, 13, 51400], "temperature": 0.0, "avg_logprob": -0.19153860503552006, "compression_ratio": 1.6763485477178424, "no_speech_prob": 0.030007926747202873}, {"id": 167, "seek": 72816, "start": 748.88, "end": 751.8, "text": " It's currently just in a pull request somewhere.", "tokens": [51400, 467, 311, 4362, 445, 294, 257, 2235, 5308, 4079, 13, 51546], "temperature": 0.0, "avg_logprob": -0.19153860503552006, "compression_ratio": 1.6763485477178424, "no_speech_prob": 0.030007926747202873}, {"id": 168, "seek": 72816, "start": 751.8, "end": 757.04, "text": " We're just waiting for that to get deployed somewhere.", "tokens": [51546, 492, 434, 445, 3806, 337, 300, 281, 483, 17826, 4079, 13, 51808], "temperature": 0.0, "avg_logprob": -0.19153860503552006, "compression_ratio": 1.6763485477178424, "no_speech_prob": 0.030007926747202873}, {"id": 169, "seek": 75704, "start": 757.12, "end": 761.76, "text": " We're mapping features across apps so we need to get a greater understanding of what different", "tokens": [50368, 492, 434, 18350, 4122, 2108, 7733, 370, 321, 643, 281, 483, 257, 5044, 3701, 295, 437, 819, 50600], "temperature": 0.0, "avg_logprob": -0.21413212032108517, "compression_ratio": 1.7833333333333334, "no_speech_prob": 0.015546707436442375}, {"id": 170, "seek": 75704, "start": 761.76, "end": 766.36, "text": " features are available in different applications, how they present that information, and therefore", "tokens": [50600, 4122, 366, 2435, 294, 819, 5821, 11, 577, 436, 1974, 300, 1589, 11, 293, 4412, 50830], "temperature": 0.0, "avg_logprob": -0.21413212032108517, "compression_ratio": 1.7833333333333334, "no_speech_prob": 0.015546707436442375}, {"id": 171, "seek": 75704, "start": 766.36, "end": 771.24, "text": " how we can present that in our API specifications.", "tokens": [50830, 577, 321, 393, 1974, 300, 294, 527, 9362, 29448, 13, 51074], "temperature": 0.0, "avg_logprob": -0.21413212032108517, "compression_ratio": 1.7833333333333334, "no_speech_prob": 0.015546707436442375}, {"id": 172, "seek": 75704, "start": 771.24, "end": 776.56, "text": " We want to get a beta implementation in a few applications.", "tokens": [51074, 492, 528, 281, 483, 257, 9861, 11420, 294, 257, 1326, 5821, 13, 51340], "temperature": 0.0, "avg_logprob": -0.21413212032108517, "compression_ratio": 1.7833333333333334, "no_speech_prob": 0.015546707436442375}, {"id": 173, "seek": 75704, "start": 776.56, "end": 779.0, "text": " Client applications specifically.", "tokens": [51340, 2033, 1196, 5821, 4682, 13, 51462], "temperature": 0.0, "avg_logprob": -0.21413212032108517, "compression_ratio": 1.7833333333333334, "no_speech_prob": 0.015546707436442375}, {"id": 174, "seek": 75704, "start": 779.0, "end": 786.48, "text": " We would like to have at least two maybe more supporting some of those core API endpoints", "tokens": [51462, 492, 576, 411, 281, 362, 412, 1935, 732, 1310, 544, 7231, 512, 295, 729, 4965, 9362, 917, 20552, 51836], "temperature": 0.0, "avg_logprob": -0.21413212032108517, "compression_ratio": 1.7833333333333334, "no_speech_prob": 0.015546707436442375}, {"id": 175, "seek": 78648, "start": 786.52, "end": 789.32, "text": " so that we can show that it works.", "tokens": [50366, 370, 300, 321, 393, 855, 300, 309, 1985, 13, 50506], "temperature": 0.0, "avg_logprob": -0.20781474437528444, "compression_ratio": 1.7469879518072289, "no_speech_prob": 0.0023174709640443325}, {"id": 176, "seek": 78648, "start": 789.32, "end": 793.76, "text": " Which of course means we also want to have a reference server implementation which the", "tokens": [50506, 3013, 295, 1164, 1355, 321, 611, 528, 281, 362, 257, 6408, 7154, 11420, 597, 264, 50728], "temperature": 0.0, "avg_logprob": -0.20781474437528444, "compression_ratio": 1.7469879518072289, "no_speech_prob": 0.0023174709640443325}, {"id": 177, "seek": 78648, "start": 793.76, "end": 798.52, "text": " FunQuel team will be working on just so that people have something to test against, something", "tokens": [50728, 11166, 48, 3483, 1469, 486, 312, 1364, 322, 445, 370, 300, 561, 362, 746, 281, 1500, 1970, 11, 746, 50966], "temperature": 0.0, "avg_logprob": -0.20781474437528444, "compression_ratio": 1.7469879518072289, "no_speech_prob": 0.0023174709640443325}, {"id": 178, "seek": 78648, "start": 798.52, "end": 803.04, "text": " that they can deploy themselves if they want to.", "tokens": [50966, 300, 436, 393, 7274, 2969, 498, 436, 528, 281, 13, 51192], "temperature": 0.0, "avg_logprob": -0.20781474437528444, "compression_ratio": 1.7469879518072289, "no_speech_prob": 0.0023174709640443325}, {"id": 179, "seek": 78648, "start": 803.04, "end": 807.8000000000001, "text": " We can check that our client implementations also work as expected and according to the", "tokens": [51192, 492, 393, 1520, 300, 527, 6423, 4445, 763, 611, 589, 382, 5176, 293, 4650, 281, 264, 51430], "temperature": 0.0, "avg_logprob": -0.20781474437528444, "compression_ratio": 1.7469879518072289, "no_speech_prob": 0.0023174709640443325}, {"id": 180, "seek": 78648, "start": 807.8000000000001, "end": 810.12, "text": " specification.", "tokens": [51430, 31256, 13, 51546], "temperature": 0.0, "avg_logprob": -0.20781474437528444, "compression_ratio": 1.7469879518072289, "no_speech_prob": 0.0023174709640443325}, {"id": 181, "seek": 78648, "start": 810.12, "end": 813.04, "text": " If you want to get in contact with us, contact details are up here.", "tokens": [51546, 759, 291, 528, 281, 483, 294, 3385, 365, 505, 11, 3385, 4365, 366, 493, 510, 13, 51692], "temperature": 0.0, "avg_logprob": -0.20781474437528444, "compression_ratio": 1.7469879518072289, "no_speech_prob": 0.0023174709640443325}, {"id": 182, "seek": 81304, "start": 813.0799999999999, "end": 817.8399999999999, "text": " There's a QR code you can scan but basically search for Open Podcast API.", "tokens": [50366, 821, 311, 257, 32784, 3089, 291, 393, 11049, 457, 1936, 3164, 337, 7238, 29972, 9362, 13, 50604], "temperature": 0.0, "avg_logprob": -0.21100193116723037, "compression_ratio": 1.702054794520548, "no_speech_prob": 0.2675926685333252}, {"id": 183, "seek": 81304, "start": 817.8399999999999, "end": 818.8399999999999, "text": " It's where we are.", "tokens": [50604, 467, 311, 689, 321, 366, 13, 50654], "temperature": 0.0, "avg_logprob": -0.21100193116723037, "compression_ratio": 1.702054794520548, "no_speech_prob": 0.2675926685333252}, {"id": 184, "seek": 81304, "start": 818.8399999999999, "end": 819.8399999999999, "text": " We're on Matrix.", "tokens": [50654, 492, 434, 322, 36274, 13, 50704], "temperature": 0.0, "avg_logprob": -0.21100193116723037, "compression_ratio": 1.702054794520548, "no_speech_prob": 0.2675926685333252}, {"id": 185, "seek": 81304, "start": 819.8399999999999, "end": 823.0799999999999, "text": " We have the website which I mentioned we'll be replacing soon.", "tokens": [50704, 492, 362, 264, 3144, 597, 286, 2835, 321, 603, 312, 19139, 2321, 13, 50866], "temperature": 0.0, "avg_logprob": -0.21100193116723037, "compression_ratio": 1.702054794520548, "no_speech_prob": 0.2675926685333252}, {"id": 186, "seek": 81304, "start": 823.0799999999999, "end": 826.5999999999999, "text": " Obviously we have a GitHub organization which is where all of the conversations are currently", "tokens": [50866, 7580, 321, 362, 257, 23331, 4475, 597, 307, 689, 439, 295, 264, 7315, 366, 4362, 51042], "temperature": 0.0, "avg_logprob": -0.21100193116723037, "compression_ratio": 1.702054794520548, "no_speech_prob": 0.2675926685333252}, {"id": 187, "seek": 81304, "start": 826.5999999999999, "end": 829.4399999999999, "text": " happening.", "tokens": [51042, 2737, 13, 51184], "temperature": 0.0, "avg_logprob": -0.21100193116723037, "compression_ratio": 1.702054794520548, "no_speech_prob": 0.2675926685333252}, {"id": 188, "seek": 81304, "start": 829.4399999999999, "end": 833.0, "text": " Get in touch especially if you are interested in podcasting or are currently involved in", "tokens": [51184, 3240, 294, 2557, 2318, 498, 291, 366, 3102, 294, 7367, 278, 420, 366, 4362, 3288, 294, 51362], "temperature": 0.0, "avg_logprob": -0.21100193116723037, "compression_ratio": 1.702054794520548, "no_speech_prob": 0.2675926685333252}, {"id": 189, "seek": 81304, "start": 833.0, "end": 837.0799999999999, "text": " podcasting we'd really like to hear from you.", "tokens": [51362, 7367, 278, 321, 1116, 534, 411, 281, 1568, 490, 291, 13, 51566], "temperature": 0.0, "avg_logprob": -0.21100193116723037, "compression_ratio": 1.702054794520548, "no_speech_prob": 0.2675926685333252}, {"id": 190, "seek": 81304, "start": 837.0799999999999, "end": 843.0, "text": " If you have questions we will be outside I guess and we would love to hear from you.", "tokens": [51566, 759, 291, 362, 1651, 321, 486, 312, 2380, 286, 2041, 293, 321, 576, 959, 281, 1568, 490, 291, 13, 51862], "temperature": 0.0, "avg_logprob": -0.21100193116723037, "compression_ratio": 1.702054794520548, "no_speech_prob": 0.2675926685333252}, {"id": 191, "seek": 84300, "start": 843.96, "end": 847.08, "text": " We're very friendly I promise.", "tokens": [50412, 492, 434, 588, 9208, 286, 6228, 13, 50568], "temperature": 0.0, "avg_logprob": -0.43136080380143793, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.019733557477593422}, {"id": 192, "seek": 84300, "start": 847.08, "end": 848.28, "text": " Thank you very much for listening.", "tokens": [50568, 1044, 291, 588, 709, 337, 4764, 13, 50628], "temperature": 0.0, "avg_logprob": -0.43136080380143793, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.019733557477593422}, {"id": 193, "seek": 84300, "start": 848.28, "end": 852.28, "text": " I'll just put the contact details up again so that you can all take your time, scan the", "tokens": [50628, 286, 603, 445, 829, 264, 3385, 4365, 493, 797, 370, 300, 291, 393, 439, 747, 428, 565, 11, 11049, 264, 50828], "temperature": 0.0, "avg_logprob": -0.43136080380143793, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.019733557477593422}, {"id": 194, "seek": 84300, "start": 852.28, "end": 853.28, "text": " code.", "tokens": [50828, 3089, 13, 50878], "temperature": 0.0, "avg_logprob": -0.43136080380143793, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.019733557477593422}, {"id": 195, "seek": 84300, "start": 853.28, "end": 855.28, "text": " Thank you very much.", "tokens": [50878, 1044, 291, 588, 709, 13, 50978], "temperature": 0.0, "avg_logprob": -0.43136080380143793, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.019733557477593422}, {"id": 196, "seek": 84300, "start": 855.28, "end": 856.36, "text": " It was lovely.", "tokens": [50978, 467, 390, 7496, 13, 51032], "temperature": 0.0, "avg_logprob": -0.43136080380143793, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.019733557477593422}], "language": "en"}