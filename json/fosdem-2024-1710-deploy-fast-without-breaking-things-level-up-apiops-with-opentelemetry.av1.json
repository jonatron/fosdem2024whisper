{"text": " with the topic. It is a very big mouthful of a topic today, but I'm hoping that we're going to break this down for you today and that you're actually going to learn something that you can take home back to actually implement yourselves. I'm here just to be talking about the open telemetry part. Sonya is actually the brains of this operation. She's basically been planning this whole thing, set everything up and just invited me at the end because yeah, because I'm pretty. That's basically all that I'm contributing today. So I am hopeful that a lot of you have had any type of touch with open telemetry and observability in general, but also that you know the basic DevOps principles and how that is going to be connected with API Ops. Just an introduction for both myself and Sonya. I am Adnan. I do developer relations as you obviously might have already figured out. And yeah, Sonya here is a product manager at Tyche and I would like to hand over the microphone. Yeah, hi. I'm a product manager at Tyche. So we do API management. We have an open source API gateway. If you were in the session before that, you have seen it on the screen. It's an API gateway that's written in Go. It's really fast and has lots of capabilities. So do check it out. And now we are happy to talk about the topic. Cool. Just a quick rundown of the agenda for today. We have four main topics for the agenda today. First and foremost, we're going to talk about API Ops, what it is, how you can get started. And then from there, we're going to take a closer look into how to do API Ops hands on. So we're going to start with the Kubernetes cluster. We'll walk you through how to use Argo CD and Tyche for your API gateway and basically just enable very fast flows and very fast deployments and release cycles within your APIs. From there, we're going to move into production environment. So we're going to say, okay, so what do I need to do to get observability, to get insight into my production APIs? And from there, we're going to shift left even more and figure out how to integrate the release cycles and make them have integrated. I'm going to say integration testing as well. So we're shifting left even more using the production data, so the observability data for testing as well. So that's going to be, I'm going to say my most favorite part because I'm here from Trace Test and we do that. But for right now, let's do the API Ops portion first. Yes, so what is API Ops? Thank you. So you might be familiar with API management and I find that sometimes in API management, we have too many manual operation. And as you all know, manual operation, that's a cause for disaster, that's a cause for error, that's a cause for security problems and we need to speed up things. So my interpretation of what is API Ops and you might have heard about API Ops and some vendors will try to push their ideas of what is API Ops. Some would say it's about deploying your API fast. I'd like to bring a bit back the cultural side of DevOps and say that API Ops is the offspring of DevOps and API management. So it's applying the culture of DevOps to your API management lifecycle. And why? Because you want to deliver value fast without disrupting your users. So if we think back about the DevOps culture, the DevOps principle that originally came from before we started to have lots of vendor trying to sell off things that are DevOps applied, it's about fast flow. I want to be able to commit and have it used by user to have feedback. So to have that culture of having feedback loops. And it's also about enabling that culture of learning. I want to understand what's going on. I want to learn fast, fail fast and be able to provide value to my users. And we're here today to tell you that we think that observability is a key enabler for all that in API management or API Ops. So let's take a look at how to implement API Ops in modern Kubernetes environments to have fast flow. So typically you will have a developer that's building a service. You will have things like open API specification along the way. So we had a talk in this room earlier about open API. I'm not going to go more into details, but it's definitely a space, a place that you have to take into your CI, into your continuous integration, making it all automated. Today we're going to talk now a little bit more on the deployment side. That's why we haven't added it, but of course things like linting and generating documentation. All that should be part of your process. So once the developer commits something, it goes to the CI, continuous integration, and the result might be a Docker container. So it gets published. And now we want to deploy that. We want to deploy that new version of that service. We want to deploy it with an API specification. And for that in Kubernetes, the new way of doing continuous deployment is to use GitOps. There are projects like AgroCD or Flux that are able to do GitOps. What does it mean? GitOps? You're lucky you're really pretty. Okay. So the main thing about GitOps is you don't have a continuous pipeline that pushes the things and deploy to your server. That's the Kubernetes cluster with something like Agro. Pull the information and deploy it itself. So how does it look like? You have then at the end of your CI pipeline, you have to make a change into your deployment repository. You have a code artifacts for all your changes, all the configuration. And you might have a new version that is placed into staging. And AgroCD on your Kubernetes cluster can be configured to automatically pick it up and deploy it. So all automated. Now there's another thing that you need is to expose an API is an API gateway. So in that example, we are using tag API gateway to use the authentication, verification, monitoring. So we add an API gateway, open source API gateway to that. And that's going to be interesting also for the observability part later. So an API gateway helps you to centrally manage your APIs to use authentication, authorization, weight limiting, all this capability that you need in operation. How do you add that? The Kubernetes and GitHub way. Typically we focus on resource definition like it's the way in Kubernetes. So you can add things. And that's a very, very simple where you can say which protocol it use. You could define things like weight limiting, like security policy, which service is proxying on your cluster. And again, it's configuration as code. So it's again central repository. And when you make changes to it into your deployment configuration repository, something like ArgosCD will track it and will apply it automatically. So what we see at the end in your ArgosCD application, you see, okay, all my application definitions, all my application are synchronized automatically with whatever I put into my Git repository. So now we have the first step, right? We have automation for fast flow. We are preventing configuration drift. We have enhanced security. All is automated. No manual error. We are more efficient. We also have an audit trail. So we see exactly what was changed in the deployment of your APIs. And we have better collaboration and visibility on what's happening. Wonderful. And obviously, as the slide says, that is not enough. So we're getting the automation part down. What do we do next? Step three in the whole process is to get additional feedback into your feedback loops so you can connect both ops and dev correctly. So what this means is that the ops team needs to enable the dev team to fix issues by exactly knowing what the issue is, so that the dev team doesn't need to spend useless cycles trying to figure out what the problem is. And we do that by using OpenTelemetry and using Yeager, which are observability tools within our API ops pipelines. Now, this is what we exactly don't want. We don't want to see gears turning and hoping it's all fine because it's not really fine. You don't know what your users are seeing. So we don't really know if our users are happy. We just kind of know it works. And then you kind of do prayer driven development, as I like saying, that's not really what we want. We want to use observability to infer the internal state of our system by getting telemetry out of our system to understand what's actually happening. And then we can figure out whether our users are happy. Because this is something that we can see by using observability with distributed tracing. When our API is exposed telemetry, we can actually see, oh, okay, obviously something is wrong because we have breaking APIs. So it's pretty obvious that our users are unhappy because we can obviously see things breaking for them. And this is a particular view that you get by using Jaeger. Now, let's get to the fun part of actually showing you how it all works and how you can set it up yourself. Now, the way you do it is you use CNCF observability tooling. So tooling from the CNCF tracing landscape, more specifically open telemetry and Jaeger. Open telemetry is an incubating project. Jaeger is a graduated project. So they're all fully open source supported by the CNCF. Now, the specifics are that you use open telemetry as the open standard, we're very focused on open standard for the whole dev room today. So once again, it's an open standard to generate, collect and export your telemetry. Remember that part, it's a bunch of libraries and APIs that help you generate, collect and export telemetry. Now, where do you export it to? Well, you export it to Jaeger, which is a tracing backend, which is just like a data store for your distributed tracing. And then you use Jaeger for all of your production monitoring troubleshooting and whatever else you need to do in your production environment. Now, from this, one of the bigger issues is that open telemetry is quite hard to implement if you're new to it. So some vendors like to bake it in into their systems. One such vendor is there was a lot of suspense, right? Yeah. Yeah. So one thing that we did in tech is to add support, native support for open telemetry, because we know that people that works in the API space, they use API's to proxy multiple services, and the developers might not yet have implemented open telemetry. But we know they need one where to report the data on all the APIs have really visibility on what's happening. And so we added support, native support for open telemetry in tech to enable our user to export this data and to capture them automatically for older APIs. So that's need a couple of settings. This is settings for our hand charts. So where do you need to enable it in tech? You need to say where do you want to send the data to an open telemetry collector could be also directly to an observability backend. And this is what you get. So for every API request, you get a distributed trace for what's happening at the gateway and till the upstream service. So you can see, first of all, you can see any error that's happening already at the API gateway level, authentication error, wait limiting. We see sometimes people only monitor what's happening on the service, but they don't realize they're already missing a lot of people having issue with the authorization, authentication, wait limiting. And then you see what's happening in the upstream. So you can very, very quickly catch up errors, understand not only the timing text, the HTTP response code, but really what's happening if there's an error, if something is slow, where is it happening? Is it on the API gateway, is it on the upstream service? What are the details of the transaction that enables a team to better troubleshoot the issue? And with that, we have now achieved feedback from production. So we have healthy development lifecycle with feedback loop between Dev and Ops. If there's an issue, then the Ops team can report it, can take a look. So it's not only an error on a metric that goes up, it's really a trace where you understand where's the problem, you know, which team needs to act on. And it enables you to provide a better user experience, fix the issues earlier. Again, what have achieved, feedback from production, we no longer relying on user reporting feature, no longer somebody that calls support and say, oh, I have a problem, something is done, no, you see it, you see it all, so you can be proactive. You understand the API performance, you understand really what's happening, where the error is happening, and you can solve issues faster. And with that suspendsful mic switch, again, it's not enough. So we need to introduce another layer of, actually this one, no, we need to introduce another layer of protection. Because right now, we want, we're only stopping bugs after our users are seeing them. So we exactly know that a user saw problem that broke our API, and then we're now rotating back to fix it. We need to be more proactive and figure out how to stop the bugs before they even reach our users. Now, so this is a shift left even more approach, but actually for you guys, it's shift left even more approach. Because we want to add observability to our release cycles as well. So not just our production systems. So the way we're going to go through that a bit is by doing this little squiggly in between, as well. So this basically means that you need to implement something called trace-based testing, which is also called observability driven development. If you like honeycomb and their CTO, it's a term that they coined. Okay. Anyway, the way that you use trace-based testing is you quite literally using the distributed tracing that your observability, like open telemetry exposes, and then you're running tests on those actual data points from your infrastructure. So that means that even though we can see that we have our gears turning, that's awesome. But my initial connection to that API gateway is returning 200. But how do I know this is not broken? How do I know if this is on fire or not? This is an external service. I don't like I don't manage this. So this is something that easily breaks and that you don't really have a lot of control over. Now, let me show you how you can actually get to that state where you can do your testing against the distributed trace itself. This is a screenshot from Trace-Test, which is also a CNCF tracing landscape tool. You can build your test by getting the trace itself from Jaeger, and then you're writing your test specs directly against trace data. So you're not using any mocking, you're not using any faking or whatever the word is nowadays with kids use, I don't even know. You're literally getting the actual data back and running your test against that data. Now, the magical part here is that you can quite literally test against anything that's exposing telemetry. It can be an API gateway like TIC, it can be databases like Postgres, it can be caches like Redis, it can be pretty much anything that you have instrumented to export traces. Now, this is a really cool use case for authentication as well, but also for GraphQL. Now, for authentication, you have a very good example. Yeah, something like Off-Flow where you have multiple service taking to each other and getting the request, that's one of the really cool, useful examples. And also something that I've noticed as well is for GraphQL. So one thing for GraphQL is that it often returns a 200, even though it's failing because the actual error is within the response. So you don't really know, it's very intricate to test that. One thing you can do with trace-based testing is you can drill down to the actual middleware that handles that in your API gateway, find the exact error that happened, and then you can run your test spec on that exact value. So with all of this, we're getting step one, which is functional testing. So we can actually functionally validate our behavior of the system by using all of the telemetry that you've implemented in the prior step to make your production environment reliable. Now, but it doesn't really stop there. We also have step two, which is performance testing, because every span has a duration. You can quite literally go in and say, I want my duration for this span to be less than whatever value of 200 milliseconds or something, which means that if you have external services, external APIs, upstream APIs that you're not in charge of, if their performance is bad, you can validate that and you know exactly what part of your system is misbehaving. So this is the performance aspect as well. So you're getting basically two things from one, I'm going to say exercise. Now the way you do it, I'm going to walk you through quickly. You do this shifting left with trace test, which is, as I said, open source part of the CNCF tracing landscape as well. And what it does, it is quite literally giving you the infrastructure by actually the distributed system architecture by looking at the trace data. And then you can both get the overview of what your system is doing, and you can run tests against exactly what's happening in your system. So those are two powerful things because as engineers, it's very hard to know what the system is doing if it's highly distributed with a lot of microservices, especially if you're a new person on a team, it's just, it's a pain to do that. But with trace test, I want to show you how you can implement these integration tests in your Argo CD, like right here. So this is what an integration test in a post sync hook would look like. You have a API that you're deploying, you have your integration test, which basically runs a Kubernetes job from Argos, from the Argo CD sync hook, then it runs a few integration tests. If they, if they're failing, awesome, you know that they're failing, if they're passing, even better, you see that they're passing, but doesn't really stop here. The thing that you get with this is also every test that fails, you have a URL to go to that particular test to actually see precisely which part of that transaction failed within your API, within your API microservices. And I really like that part because this is not just, oh, yo, this failed, this is actually, this failed, here's exactly how, where, and what happened. And with that, we're actually getting to a stage where we're validating our production, but we're also using that effort we put into our production reliability to validate pre-production as well. So you're basically getting the exact same overview graph that Sonya just showed you, but instead of using your end users, you're running tests with trace test against the API Gateway platform, then you're getting the traces back from your Yeager or Grafana or whatever you're using, and then that info goes back to the API developer that can then fix the issues that were found. Now, with this, I'm just going to wrap up everything that we learned from this last section, which is that we got functional testing and we got performance testing. So you can both validate your behavior, or actually the behavior of your system, so all upstream and downstream services, API transactions, both the ones that you manage and don't manage, you can actually test database performance, you can test cache, you can also test the size of an HTTP response and request, but you can also do very intricate performance testing by validating the duration of every part of your API. And with that, I have a saying where I'm from. We say you're swatting two flies with one swing because I think that's more friendly than killing birds with stones. So yeah, with that, I think that this is the closest we can get to be bounty hunters because we're bug hunters. That was very lame. Anyway, so that's a CU space cowboy reference if somebody can. Thank you for making this. So, and just before we close, I want to say if this is a topic that's interesting for you, we're running an online API observability conference in February. It's going to be called LEAP because it's going to be on the LEAP there. So if that's the topic that's interesting to you, make sure to register. We have lots of people from the API space and observability space that will be coming. We also have a GitHub project about all the screenshot that we showed to you today. We were working on it as a GitHub example. We don't have a link for it, but if you're interested, just reach out to us. Those are LinkedIn. Yeah, I don't like Twitter anymore. So make sure to send a connect and we're happy to send you a link to a GitHub project. You can try it all by yourself at this combination of open source projects. Thank you so much. So we have some time for questions. Yeah, there is one over there. Questions down. Questions down. Go ahead with one customer. Yeah. Okay, so the question is, I have to repeat for the video, the question is, if I have a service that can be accessed by multiple customers, do I want to have one to send the data to different places so to split them out or do I want to have just one year, one open telemetry? And as always, it depends. And on what does it depend? It depends on do you want to give access to those data to your customers somewhere? Do you want to have strict regulation on the data of your customer where you may need to split them by location? But yeah. Yeah, yeah. Yeah. Yeah, that's a very, very, very good question. So the question is, how do I monitor the service level for every customer? So typically you have for every customer, they have, they are authenticated. So you have maybe something like a token. Yeah, yeah, but in production, yeah, yeah. So they're authenticated. So when they come to you, you can put a tag on an information on the trace, and tag will do it automatically if you're using the authorization or authentication from tag, tag. The API, yeah, it's tag. Tag. Yeah, no worry. And so on the traces, we put the information on who is going to API. And with open telemetry, you can then use the data to create your own report based on that information. Yeah. So we add that information on the API call so that you can reuse it for your report. Yeah, it's directly exposed. Yeah. That's a very good question. It's really important to monitor per customers because you want to, some customers have different usage, different patterns, and you want to make sure that every one of them is happy and not just like an average where you don't really understand whether problems. Also, the question is whether Trace Test notifies on errors. No, Trace Test is just a testing tool. You would then need something to automate the test, like Argo, and then you need something to alert on failures as well. And then you can pick the alerting tool that you want. Whatever you're using right now, you can automate within your CI, so you can build your CI within Argo or within whatever you can use Tecton. You can do basically whatever CI tool you're using, and then you're sending errors on that. So think just integration testing. You just get works, doesn't work, then you do whatever else you want to do. Yeah. Yeah. Another question. Observability data for APS, I can take that one. So, yeah, so the question is how do you deal with data privacy? And because in the observability data, they can land a lot that could be considered privacy data. So first, you have to be very aware of that, that observability data could potentially have some data that in your country, in your own regulation could have some impact. OpenTelemetry has a lot of tool for that. In the OpenTelemetry collector, there are kind of plugins that you can define using Yamal and say, that arguments, that thing I want to filter out, I don't want to register it. So you're very flexible in your observability pipeline, but that's something that you have to take care of to make sure that your developers haven't added something that you don't want to store. Sorry. I'll go for it. Go for it. Jack, when I use the data to send the data to the OpenTelemetry, this data is made only on HB8. HB8, the status only. So like a 100, 500 message, the status of the response of the HB8 request. Yes. All on another way is to analyze the response of the request. So the question is, what do we track or what kind of data do we expose with tech? So, yeah, so in tag the gateway, when it's being called, you will get the answer, but the traces, it will export using OpenTelemetry will contain all the data, all the steps, the traces that we saw in Yeager. And you can also extend them. So we have a plugin mechanism where you could, that you could load into there and add even more data if that's more open, extend your OpenTelemetry traces. The question is, where is the effort? So tech make it easier for you because it captured the starts up to the call to the upstream service and it tell you how long it took. And but if you want to get even more details, what happens after that, then it's where you need to instrument your services using OpenTelemetry. And then the beauty of it is when all the services speak the same observability language, they all send the data to the same place, then you have the full picture and that's kind of the operational dream. Thank you. Yeah. You suggest to run that on a trade production? It's right. Correct. Correct. So you wouldn't use trace this in this point of view for your production, you would use it in pre production, where you need sampling to be at 100%. Yeah, yeah, we can also just stand. We'll just wait so you can come by and chat with us. So because yeah, we don't have time. Don't follow up on questions. Yeah. So yeah, yeah, we'll be here. Come here. Yeah. Cool. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 10.88, "text": " with the topic. It is a very big mouthful of a topic today, but I'm hoping that we're", "tokens": [50364, 365, 264, 4829, 13, 467, 307, 257, 588, 955, 4525, 906, 295, 257, 4829, 965, 11, 457, 286, 478, 7159, 300, 321, 434, 50908], "temperature": 0.0, "avg_logprob": -0.1475577943780449, "compression_ratio": 1.646788990825688, "no_speech_prob": 0.39095762372016907}, {"id": 1, "seek": 0, "start": 10.88, "end": 14.4, "text": " going to break this down for you today and that you're actually going to learn something", "tokens": [50908, 516, 281, 1821, 341, 760, 337, 291, 965, 293, 300, 291, 434, 767, 516, 281, 1466, 746, 51084], "temperature": 0.0, "avg_logprob": -0.1475577943780449, "compression_ratio": 1.646788990825688, "no_speech_prob": 0.39095762372016907}, {"id": 2, "seek": 0, "start": 14.4, "end": 20.76, "text": " that you can take home back to actually implement yourselves. I'm here just to be talking about", "tokens": [51084, 300, 291, 393, 747, 1280, 646, 281, 767, 4445, 14791, 13, 286, 478, 510, 445, 281, 312, 1417, 466, 51402], "temperature": 0.0, "avg_logprob": -0.1475577943780449, "compression_ratio": 1.646788990825688, "no_speech_prob": 0.39095762372016907}, {"id": 3, "seek": 0, "start": 20.76, "end": 26.46, "text": " the open telemetry part. Sonya is actually the brains of this operation. She's basically", "tokens": [51402, 264, 1269, 4304, 5537, 627, 644, 13, 13575, 64, 307, 767, 264, 15442, 295, 341, 6916, 13, 1240, 311, 1936, 51687], "temperature": 0.0, "avg_logprob": -0.1475577943780449, "compression_ratio": 1.646788990825688, "no_speech_prob": 0.39095762372016907}, {"id": 4, "seek": 2646, "start": 26.46, "end": 30.380000000000003, "text": " been planning this whole thing, set everything up and just invited me at the end because", "tokens": [50364, 668, 5038, 341, 1379, 551, 11, 992, 1203, 493, 293, 445, 9185, 385, 412, 264, 917, 570, 50560], "temperature": 0.0, "avg_logprob": -0.1620030529731143, "compression_ratio": 1.596551724137931, "no_speech_prob": 0.10998624563217163}, {"id": 5, "seek": 2646, "start": 30.380000000000003, "end": 37.2, "text": " yeah, because I'm pretty. That's basically all that I'm contributing today. So I am hopeful", "tokens": [50560, 1338, 11, 570, 286, 478, 1238, 13, 663, 311, 1936, 439, 300, 286, 478, 19270, 965, 13, 407, 286, 669, 20531, 50901], "temperature": 0.0, "avg_logprob": -0.1620030529731143, "compression_ratio": 1.596551724137931, "no_speech_prob": 0.10998624563217163}, {"id": 6, "seek": 2646, "start": 37.2, "end": 43.38, "text": " that a lot of you have had any type of touch with open telemetry and observability in general,", "tokens": [50901, 300, 257, 688, 295, 291, 362, 632, 604, 2010, 295, 2557, 365, 1269, 4304, 5537, 627, 293, 9951, 2310, 294, 2674, 11, 51210], "temperature": 0.0, "avg_logprob": -0.1620030529731143, "compression_ratio": 1.596551724137931, "no_speech_prob": 0.10998624563217163}, {"id": 7, "seek": 2646, "start": 43.38, "end": 48.7, "text": " but also that you know the basic DevOps principles and how that is going to be connected with", "tokens": [51210, 457, 611, 300, 291, 458, 264, 3875, 43051, 9156, 293, 577, 300, 307, 516, 281, 312, 4582, 365, 51476], "temperature": 0.0, "avg_logprob": -0.1620030529731143, "compression_ratio": 1.596551724137931, "no_speech_prob": 0.10998624563217163}, {"id": 8, "seek": 2646, "start": 48.7, "end": 55.28, "text": " API Ops. Just an introduction for both myself and Sonya. I am Adnan. I do developer relations", "tokens": [51476, 9362, 422, 1878, 13, 1449, 364, 9339, 337, 1293, 2059, 293, 13575, 64, 13, 286, 669, 1999, 17622, 13, 286, 360, 10754, 2299, 51805], "temperature": 0.0, "avg_logprob": -0.1620030529731143, "compression_ratio": 1.596551724137931, "no_speech_prob": 0.10998624563217163}, {"id": 9, "seek": 5528, "start": 55.28, "end": 62.28, "text": " as you obviously might have already figured out. And yeah, Sonya here is a product manager", "tokens": [50364, 382, 291, 2745, 1062, 362, 1217, 8932, 484, 13, 400, 1338, 11, 13575, 64, 510, 307, 257, 1674, 6598, 50714], "temperature": 0.0, "avg_logprob": -0.249329965764826, "compression_ratio": 1.6680161943319838, "no_speech_prob": 0.0067552621476352215}, {"id": 10, "seek": 5528, "start": 62.28, "end": 65.0, "text": " at Tyche and I would like to hand over the microphone.", "tokens": [50714, 412, 5569, 1876, 293, 286, 576, 411, 281, 1011, 670, 264, 10952, 13, 50850], "temperature": 0.0, "avg_logprob": -0.249329965764826, "compression_ratio": 1.6680161943319838, "no_speech_prob": 0.0067552621476352215}, {"id": 11, "seek": 5528, "start": 65.0, "end": 71.08, "text": " Yeah, hi. I'm a product manager at Tyche. So we do API management. We have an open source", "tokens": [50850, 865, 11, 4879, 13, 286, 478, 257, 1674, 6598, 412, 5569, 1876, 13, 407, 321, 360, 9362, 4592, 13, 492, 362, 364, 1269, 4009, 51154], "temperature": 0.0, "avg_logprob": -0.249329965764826, "compression_ratio": 1.6680161943319838, "no_speech_prob": 0.0067552621476352215}, {"id": 12, "seek": 5528, "start": 71.08, "end": 75.16, "text": " API gateway. If you were in the session before that, you have seen it on the screen. It's", "tokens": [51154, 9362, 28532, 13, 759, 291, 645, 294, 264, 5481, 949, 300, 11, 291, 362, 1612, 309, 322, 264, 2568, 13, 467, 311, 51358], "temperature": 0.0, "avg_logprob": -0.249329965764826, "compression_ratio": 1.6680161943319838, "no_speech_prob": 0.0067552621476352215}, {"id": 13, "seek": 5528, "start": 75.16, "end": 79.48, "text": " an API gateway that's written in Go. It's really fast and has lots of capabilities. So", "tokens": [51358, 364, 9362, 28532, 300, 311, 3720, 294, 1037, 13, 467, 311, 534, 2370, 293, 575, 3195, 295, 10862, 13, 407, 51574], "temperature": 0.0, "avg_logprob": -0.249329965764826, "compression_ratio": 1.6680161943319838, "no_speech_prob": 0.0067552621476352215}, {"id": 14, "seek": 7948, "start": 79.48, "end": 85.48, "text": " do check it out. And now we are happy to talk about the topic.", "tokens": [50364, 360, 1520, 309, 484, 13, 400, 586, 321, 366, 2055, 281, 751, 466, 264, 4829, 13, 50664], "temperature": 0.0, "avg_logprob": -0.13593834324886925, "compression_ratio": 1.6814516129032258, "no_speech_prob": 0.1456678807735443}, {"id": 15, "seek": 7948, "start": 85.48, "end": 91.4, "text": " Cool. Just a quick rundown of the agenda for today. We have four main topics for the agenda", "tokens": [50664, 8561, 13, 1449, 257, 1702, 23096, 648, 295, 264, 9829, 337, 965, 13, 492, 362, 1451, 2135, 8378, 337, 264, 9829, 50960], "temperature": 0.0, "avg_logprob": -0.13593834324886925, "compression_ratio": 1.6814516129032258, "no_speech_prob": 0.1456678807735443}, {"id": 16, "seek": 7948, "start": 91.4, "end": 95.72, "text": " today. First and foremost, we're going to talk about API Ops, what it is, how you can", "tokens": [50960, 965, 13, 2386, 293, 18864, 11, 321, 434, 516, 281, 751, 466, 9362, 422, 1878, 11, 437, 309, 307, 11, 577, 291, 393, 51176], "temperature": 0.0, "avg_logprob": -0.13593834324886925, "compression_ratio": 1.6814516129032258, "no_speech_prob": 0.1456678807735443}, {"id": 17, "seek": 7948, "start": 95.72, "end": 101.28, "text": " get started. And then from there, we're going to take a closer look into how to do API Ops", "tokens": [51176, 483, 1409, 13, 400, 550, 490, 456, 11, 321, 434, 516, 281, 747, 257, 4966, 574, 666, 577, 281, 360, 9362, 422, 1878, 51454], "temperature": 0.0, "avg_logprob": -0.13593834324886925, "compression_ratio": 1.6814516129032258, "no_speech_prob": 0.1456678807735443}, {"id": 18, "seek": 7948, "start": 101.28, "end": 105.0, "text": " hands on. So we're going to start with the Kubernetes cluster. We'll walk you through", "tokens": [51454, 2377, 322, 13, 407, 321, 434, 516, 281, 722, 365, 264, 23145, 13630, 13, 492, 603, 1792, 291, 807, 51640], "temperature": 0.0, "avg_logprob": -0.13593834324886925, "compression_ratio": 1.6814516129032258, "no_speech_prob": 0.1456678807735443}, {"id": 19, "seek": 10500, "start": 105.0, "end": 111.0, "text": " how to use Argo CD and Tyche for your API gateway and basically just enable very fast", "tokens": [50364, 577, 281, 764, 1587, 1571, 6743, 293, 5569, 1876, 337, 428, 9362, 28532, 293, 1936, 445, 9528, 588, 2370, 50664], "temperature": 0.0, "avg_logprob": -0.12762132397404424, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.4288126528263092}, {"id": 20, "seek": 10500, "start": 111.0, "end": 115.96000000000001, "text": " flows and very fast deployments and release cycles within your APIs. From there, we're", "tokens": [50664, 12867, 293, 588, 2370, 7274, 1117, 293, 4374, 17796, 1951, 428, 21445, 13, 3358, 456, 11, 321, 434, 50912], "temperature": 0.0, "avg_logprob": -0.12762132397404424, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.4288126528263092}, {"id": 21, "seek": 10500, "start": 115.96000000000001, "end": 119.64, "text": " going to move into production environment. So we're going to say, okay, so what do I", "tokens": [50912, 516, 281, 1286, 666, 4265, 2823, 13, 407, 321, 434, 516, 281, 584, 11, 1392, 11, 370, 437, 360, 286, 51096], "temperature": 0.0, "avg_logprob": -0.12762132397404424, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.4288126528263092}, {"id": 22, "seek": 10500, "start": 119.64, "end": 124.68, "text": " need to do to get observability, to get insight into my production APIs? And from there, we're", "tokens": [51096, 643, 281, 360, 281, 483, 9951, 2310, 11, 281, 483, 11269, 666, 452, 4265, 21445, 30, 400, 490, 456, 11, 321, 434, 51348], "temperature": 0.0, "avg_logprob": -0.12762132397404424, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.4288126528263092}, {"id": 23, "seek": 10500, "start": 124.68, "end": 130.56, "text": " going to shift left even more and figure out how to integrate the release cycles and make", "tokens": [51348, 516, 281, 5513, 1411, 754, 544, 293, 2573, 484, 577, 281, 13365, 264, 4374, 17796, 293, 652, 51642], "temperature": 0.0, "avg_logprob": -0.12762132397404424, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.4288126528263092}, {"id": 24, "seek": 13056, "start": 130.64000000000001, "end": 136.32, "text": " them have integrated. I'm going to say integration testing as well. So we're shifting left even", "tokens": [50368, 552, 362, 10919, 13, 286, 478, 516, 281, 584, 10980, 4997, 382, 731, 13, 407, 321, 434, 17573, 1411, 754, 50652], "temperature": 0.0, "avg_logprob": -0.17435419294569227, "compression_ratio": 1.6585365853658536, "no_speech_prob": 0.03840353339910507}, {"id": 25, "seek": 13056, "start": 136.32, "end": 141.64000000000001, "text": " more using the production data, so the observability data for testing as well. So that's going", "tokens": [50652, 544, 1228, 264, 4265, 1412, 11, 370, 264, 9951, 2310, 1412, 337, 4997, 382, 731, 13, 407, 300, 311, 516, 50918], "temperature": 0.0, "avg_logprob": -0.17435419294569227, "compression_ratio": 1.6585365853658536, "no_speech_prob": 0.03840353339910507}, {"id": 26, "seek": 13056, "start": 141.64000000000001, "end": 147.24, "text": " to be, I'm going to say my most favorite part because I'm here from Trace Test and we do", "tokens": [50918, 281, 312, 11, 286, 478, 516, 281, 584, 452, 881, 2954, 644, 570, 286, 478, 510, 490, 1765, 617, 9279, 293, 321, 360, 51198], "temperature": 0.0, "avg_logprob": -0.17435419294569227, "compression_ratio": 1.6585365853658536, "no_speech_prob": 0.03840353339910507}, {"id": 27, "seek": 13056, "start": 147.24, "end": 153.24, "text": " that. But for right now, let's do the API Ops portion first.", "tokens": [51198, 300, 13, 583, 337, 558, 586, 11, 718, 311, 360, 264, 9362, 422, 1878, 8044, 700, 13, 51498], "temperature": 0.0, "avg_logprob": -0.17435419294569227, "compression_ratio": 1.6585365853658536, "no_speech_prob": 0.03840353339910507}, {"id": 28, "seek": 15324, "start": 154.24, "end": 161.24, "text": " Yes, so what is API Ops? Thank you. So you might be familiar with API management and I find that", "tokens": [50414, 1079, 11, 370, 437, 307, 9362, 422, 1878, 30, 1044, 291, 13, 407, 291, 1062, 312, 4963, 365, 9362, 4592, 293, 286, 915, 300, 50764], "temperature": 0.0, "avg_logprob": -0.19762254268565077, "compression_ratio": 1.7815533980582525, "no_speech_prob": 0.003796576289460063}, {"id": 29, "seek": 15324, "start": 165.4, "end": 170.48000000000002, "text": " sometimes in API management, we have too many manual operation. And as you all know, manual", "tokens": [50972, 2171, 294, 9362, 4592, 11, 321, 362, 886, 867, 9688, 6916, 13, 400, 382, 291, 439, 458, 11, 9688, 51226], "temperature": 0.0, "avg_logprob": -0.19762254268565077, "compression_ratio": 1.7815533980582525, "no_speech_prob": 0.003796576289460063}, {"id": 30, "seek": 15324, "start": 170.48000000000002, "end": 175.28, "text": " operation, that's a cause for disaster, that's a cause for error, that's a cause for security", "tokens": [51226, 6916, 11, 300, 311, 257, 3082, 337, 11293, 11, 300, 311, 257, 3082, 337, 6713, 11, 300, 311, 257, 3082, 337, 3825, 51466], "temperature": 0.0, "avg_logprob": -0.19762254268565077, "compression_ratio": 1.7815533980582525, "no_speech_prob": 0.003796576289460063}, {"id": 31, "seek": 15324, "start": 175.28, "end": 182.28, "text": " problems and we need to speed up things. So my interpretation of what is API Ops and", "tokens": [51466, 2740, 293, 321, 643, 281, 3073, 493, 721, 13, 407, 452, 14174, 295, 437, 307, 9362, 422, 1878, 293, 51816], "temperature": 0.0, "avg_logprob": -0.19762254268565077, "compression_ratio": 1.7815533980582525, "no_speech_prob": 0.003796576289460063}, {"id": 32, "seek": 18228, "start": 182.32, "end": 186.68, "text": " you might have heard about API Ops and some vendors will try to push their ideas of what", "tokens": [50366, 291, 1062, 362, 2198, 466, 9362, 422, 1878, 293, 512, 22056, 486, 853, 281, 2944, 641, 3487, 295, 437, 50584], "temperature": 0.0, "avg_logprob": -0.11645256621497017, "compression_ratio": 1.7683397683397684, "no_speech_prob": 0.00291550625115633}, {"id": 33, "seek": 18228, "start": 186.68, "end": 192.12, "text": " is API Ops. Some would say it's about deploying your API fast. I'd like to bring a bit back", "tokens": [50584, 307, 9362, 422, 1878, 13, 2188, 576, 584, 309, 311, 466, 34198, 428, 9362, 2370, 13, 286, 1116, 411, 281, 1565, 257, 857, 646, 50856], "temperature": 0.0, "avg_logprob": -0.11645256621497017, "compression_ratio": 1.7683397683397684, "no_speech_prob": 0.00291550625115633}, {"id": 34, "seek": 18228, "start": 192.12, "end": 198.12, "text": " the cultural side of DevOps and say that API Ops is the offspring of DevOps and API management.", "tokens": [50856, 264, 6988, 1252, 295, 43051, 293, 584, 300, 9362, 422, 1878, 307, 264, 36857, 295, 43051, 293, 9362, 4592, 13, 51156], "temperature": 0.0, "avg_logprob": -0.11645256621497017, "compression_ratio": 1.7683397683397684, "no_speech_prob": 0.00291550625115633}, {"id": 35, "seek": 18228, "start": 198.12, "end": 204.56, "text": " So it's applying the culture of DevOps to your API management lifecycle. And why? Because", "tokens": [51156, 407, 309, 311, 9275, 264, 3713, 295, 43051, 281, 428, 9362, 4592, 45722, 13, 400, 983, 30, 1436, 51478], "temperature": 0.0, "avg_logprob": -0.11645256621497017, "compression_ratio": 1.7683397683397684, "no_speech_prob": 0.00291550625115633}, {"id": 36, "seek": 18228, "start": 204.56, "end": 211.56, "text": " you want to deliver value fast without disrupting your users. So if we think back about the", "tokens": [51478, 291, 528, 281, 4239, 2158, 2370, 1553, 14124, 278, 428, 5022, 13, 407, 498, 321, 519, 646, 466, 264, 51828], "temperature": 0.0, "avg_logprob": -0.11645256621497017, "compression_ratio": 1.7683397683397684, "no_speech_prob": 0.00291550625115633}, {"id": 37, "seek": 21156, "start": 211.56, "end": 216.0, "text": " DevOps culture, the DevOps principle that originally came from before we started to have", "tokens": [50364, 43051, 3713, 11, 264, 43051, 8665, 300, 7993, 1361, 490, 949, 321, 1409, 281, 362, 50586], "temperature": 0.0, "avg_logprob": -0.13291888866784438, "compression_ratio": 1.7943548387096775, "no_speech_prob": 0.0036979287397116423}, {"id": 38, "seek": 21156, "start": 216.0, "end": 221.44, "text": " lots of vendor trying to sell off things that are DevOps applied, it's about fast flow.", "tokens": [50586, 3195, 295, 24321, 1382, 281, 3607, 766, 721, 300, 366, 43051, 6456, 11, 309, 311, 466, 2370, 3095, 13, 50858], "temperature": 0.0, "avg_logprob": -0.13291888866784438, "compression_ratio": 1.7943548387096775, "no_speech_prob": 0.0036979287397116423}, {"id": 39, "seek": 21156, "start": 221.44, "end": 227.44, "text": " I want to be able to commit and have it used by user to have feedback. So to have that", "tokens": [50858, 286, 528, 281, 312, 1075, 281, 5599, 293, 362, 309, 1143, 538, 4195, 281, 362, 5824, 13, 407, 281, 362, 300, 51158], "temperature": 0.0, "avg_logprob": -0.13291888866784438, "compression_ratio": 1.7943548387096775, "no_speech_prob": 0.0036979287397116423}, {"id": 40, "seek": 21156, "start": 227.44, "end": 232.32, "text": " culture of having feedback loops. And it's also about enabling that culture of learning.", "tokens": [51158, 3713, 295, 1419, 5824, 16121, 13, 400, 309, 311, 611, 466, 23148, 300, 3713, 295, 2539, 13, 51402], "temperature": 0.0, "avg_logprob": -0.13291888866784438, "compression_ratio": 1.7943548387096775, "no_speech_prob": 0.0036979287397116423}, {"id": 41, "seek": 21156, "start": 232.32, "end": 237.04, "text": " I want to understand what's going on. I want to learn fast, fail fast and be able to provide", "tokens": [51402, 286, 528, 281, 1223, 437, 311, 516, 322, 13, 286, 528, 281, 1466, 2370, 11, 3061, 2370, 293, 312, 1075, 281, 2893, 51638], "temperature": 0.0, "avg_logprob": -0.13291888866784438, "compression_ratio": 1.7943548387096775, "no_speech_prob": 0.0036979287397116423}, {"id": 42, "seek": 23704, "start": 237.04, "end": 241.84, "text": " value to my users. And we're here today to tell you that we think that observability is", "tokens": [50364, 2158, 281, 452, 5022, 13, 400, 321, 434, 510, 965, 281, 980, 291, 300, 321, 519, 300, 9951, 2310, 307, 50604], "temperature": 0.0, "avg_logprob": -0.13619120737140097, "compression_ratio": 1.5764192139737991, "no_speech_prob": 0.006697048898786306}, {"id": 43, "seek": 23704, "start": 241.84, "end": 249.2, "text": " a key enabler for all that in API management or API Ops. So let's take a look at how to", "tokens": [50604, 257, 2141, 465, 455, 1918, 337, 439, 300, 294, 9362, 4592, 420, 9362, 422, 1878, 13, 407, 718, 311, 747, 257, 574, 412, 577, 281, 50972], "temperature": 0.0, "avg_logprob": -0.13619120737140097, "compression_ratio": 1.5764192139737991, "no_speech_prob": 0.006697048898786306}, {"id": 44, "seek": 23704, "start": 249.2, "end": 258.15999999999997, "text": " implement API Ops in modern Kubernetes environments to have fast flow. So typically you will have", "tokens": [50972, 4445, 9362, 422, 1878, 294, 4363, 23145, 12388, 281, 362, 2370, 3095, 13, 407, 5850, 291, 486, 362, 51420], "temperature": 0.0, "avg_logprob": -0.13619120737140097, "compression_ratio": 1.5764192139737991, "no_speech_prob": 0.006697048898786306}, {"id": 45, "seek": 23704, "start": 258.15999999999997, "end": 263.28, "text": " a developer that's building a service. You will have things like open API specification", "tokens": [51420, 257, 10754, 300, 311, 2390, 257, 2643, 13, 509, 486, 362, 721, 411, 1269, 9362, 31256, 51676], "temperature": 0.0, "avg_logprob": -0.13619120737140097, "compression_ratio": 1.5764192139737991, "no_speech_prob": 0.006697048898786306}, {"id": 46, "seek": 26328, "start": 263.28, "end": 268.44, "text": " along the way. So we had a talk in this room earlier about open API. I'm not going to go", "tokens": [50364, 2051, 264, 636, 13, 407, 321, 632, 257, 751, 294, 341, 1808, 3071, 466, 1269, 9362, 13, 286, 478, 406, 516, 281, 352, 50622], "temperature": 0.0, "avg_logprob": -0.22443721168919614, "compression_ratio": 1.7088607594936709, "no_speech_prob": 0.02364732138812542}, {"id": 47, "seek": 26328, "start": 268.44, "end": 273.44, "text": " more into details, but it's definitely a space, a place that you have to take into your CI,", "tokens": [50622, 544, 666, 4365, 11, 457, 309, 311, 2138, 257, 1901, 11, 257, 1081, 300, 291, 362, 281, 747, 666, 428, 37777, 11, 50872], "temperature": 0.0, "avg_logprob": -0.22443721168919614, "compression_ratio": 1.7088607594936709, "no_speech_prob": 0.02364732138812542}, {"id": 48, "seek": 26328, "start": 273.44, "end": 277.91999999999996, "text": " into your continuous integration, making it all automated. Today we're going to talk now", "tokens": [50872, 666, 428, 10957, 10980, 11, 1455, 309, 439, 18473, 13, 2692, 321, 434, 516, 281, 751, 586, 51096], "temperature": 0.0, "avg_logprob": -0.22443721168919614, "compression_ratio": 1.7088607594936709, "no_speech_prob": 0.02364732138812542}, {"id": 49, "seek": 26328, "start": 277.91999999999996, "end": 282.0, "text": " a little bit more on the deployment side. That's why we haven't added it, but of course things", "tokens": [51096, 257, 707, 857, 544, 322, 264, 19317, 1252, 13, 663, 311, 983, 321, 2378, 380, 3869, 309, 11, 457, 295, 1164, 721, 51300], "temperature": 0.0, "avg_logprob": -0.22443721168919614, "compression_ratio": 1.7088607594936709, "no_speech_prob": 0.02364732138812542}, {"id": 50, "seek": 26328, "start": 282.0, "end": 287.0, "text": " like linting and generating documentation. All that should be part of your process. So", "tokens": [51300, 411, 287, 686, 278, 293, 17746, 14333, 13, 1057, 300, 820, 312, 644, 295, 428, 1399, 13, 407, 51550], "temperature": 0.0, "avg_logprob": -0.22443721168919614, "compression_ratio": 1.7088607594936709, "no_speech_prob": 0.02364732138812542}, {"id": 51, "seek": 26328, "start": 287.0, "end": 291.91999999999996, "text": " once the developer commits something, it goes to the CI, continuous integration, and the", "tokens": [51550, 1564, 264, 10754, 48311, 746, 11, 309, 1709, 281, 264, 37777, 11, 10957, 10980, 11, 293, 264, 51796], "temperature": 0.0, "avg_logprob": -0.22443721168919614, "compression_ratio": 1.7088607594936709, "no_speech_prob": 0.02364732138812542}, {"id": 52, "seek": 29192, "start": 291.96000000000004, "end": 297.6, "text": " result might be a Docker container. So it gets published. And now we want to deploy that. We", "tokens": [50366, 1874, 1062, 312, 257, 33772, 10129, 13, 407, 309, 2170, 6572, 13, 400, 586, 321, 528, 281, 7274, 300, 13, 492, 50648], "temperature": 0.0, "avg_logprob": -0.18612557649612427, "compression_ratio": 1.617391304347826, "no_speech_prob": 0.0013652872294187546}, {"id": 53, "seek": 29192, "start": 297.6, "end": 302.28000000000003, "text": " want to deploy that new version of that service. We want to deploy it with an API specification.", "tokens": [50648, 528, 281, 7274, 300, 777, 3037, 295, 300, 2643, 13, 492, 528, 281, 7274, 309, 365, 364, 9362, 31256, 13, 50882], "temperature": 0.0, "avg_logprob": -0.18612557649612427, "compression_ratio": 1.617391304347826, "no_speech_prob": 0.0013652872294187546}, {"id": 54, "seek": 29192, "start": 302.28000000000003, "end": 309.84000000000003, "text": " And for that in Kubernetes, the new way of doing continuous deployment is to use GitOps.", "tokens": [50882, 400, 337, 300, 294, 23145, 11, 264, 777, 636, 295, 884, 10957, 19317, 307, 281, 764, 16939, 36179, 13, 51260], "temperature": 0.0, "avg_logprob": -0.18612557649612427, "compression_ratio": 1.617391304347826, "no_speech_prob": 0.0013652872294187546}, {"id": 55, "seek": 29192, "start": 309.84000000000003, "end": 317.96000000000004, "text": " There are projects like AgroCD or Flux that are able to do GitOps. What does it mean? GitOps?", "tokens": [51260, 821, 366, 4455, 411, 2725, 340, 16508, 420, 3235, 2449, 300, 366, 1075, 281, 360, 16939, 36179, 13, 708, 775, 309, 914, 30, 16939, 36179, 30, 51666], "temperature": 0.0, "avg_logprob": -0.18612557649612427, "compression_ratio": 1.617391304347826, "no_speech_prob": 0.0013652872294187546}, {"id": 56, "seek": 31796, "start": 318.0, "end": 330.12, "text": " You're lucky you're really pretty. Okay. So the main thing about GitOps is you don't have a", "tokens": [50366, 509, 434, 6356, 291, 434, 534, 1238, 13, 1033, 13, 407, 264, 2135, 551, 466, 16939, 36179, 307, 291, 500, 380, 362, 257, 50972], "temperature": 0.0, "avg_logprob": -0.23255413903130426, "compression_ratio": 1.5659574468085107, "no_speech_prob": 0.003924158401787281}, {"id": 57, "seek": 31796, "start": 330.12, "end": 334.52, "text": " continuous pipeline that pushes the things and deploy to your server. That's the Kubernetes", "tokens": [50972, 10957, 15517, 300, 21020, 264, 721, 293, 7274, 281, 428, 7154, 13, 663, 311, 264, 23145, 51192], "temperature": 0.0, "avg_logprob": -0.23255413903130426, "compression_ratio": 1.5659574468085107, "no_speech_prob": 0.003924158401787281}, {"id": 58, "seek": 31796, "start": 334.52, "end": 341.12, "text": " cluster with something like Agro. Pull the information and deploy it itself. So how does", "tokens": [51192, 13630, 365, 746, 411, 2725, 340, 13, 15074, 264, 1589, 293, 7274, 309, 2564, 13, 407, 577, 775, 51522], "temperature": 0.0, "avg_logprob": -0.23255413903130426, "compression_ratio": 1.5659574468085107, "no_speech_prob": 0.003924158401787281}, {"id": 59, "seek": 31796, "start": 341.12, "end": 346.84, "text": " it look like? You have then at the end of your CI pipeline, you have to make a change into your", "tokens": [51522, 309, 574, 411, 30, 509, 362, 550, 412, 264, 917, 295, 428, 37777, 15517, 11, 291, 362, 281, 652, 257, 1319, 666, 428, 51808], "temperature": 0.0, "avg_logprob": -0.23255413903130426, "compression_ratio": 1.5659574468085107, "no_speech_prob": 0.003924158401787281}, {"id": 60, "seek": 34684, "start": 346.88, "end": 351.88, "text": " deployment repository. You have a code artifacts for all your changes, all the configuration. And", "tokens": [50366, 19317, 25841, 13, 509, 362, 257, 3089, 24617, 337, 439, 428, 2962, 11, 439, 264, 11694, 13, 400, 50616], "temperature": 0.0, "avg_logprob": -0.19039847056070963, "compression_ratio": 1.5737704918032787, "no_speech_prob": 0.0010336858686059713}, {"id": 61, "seek": 34684, "start": 351.88, "end": 359.0, "text": " you might have a new version that is placed into staging. And AgroCD on your Kubernetes cluster", "tokens": [50616, 291, 1062, 362, 257, 777, 3037, 300, 307, 7074, 666, 41085, 13, 400, 2725, 340, 16508, 322, 428, 23145, 13630, 50972], "temperature": 0.0, "avg_logprob": -0.19039847056070963, "compression_ratio": 1.5737704918032787, "no_speech_prob": 0.0010336858686059713}, {"id": 62, "seek": 34684, "start": 359.0, "end": 365.23999999999995, "text": " can be configured to automatically pick it up and deploy it. So all automated. Now there's", "tokens": [50972, 393, 312, 30538, 281, 6772, 1888, 309, 493, 293, 7274, 309, 13, 407, 439, 18473, 13, 823, 456, 311, 51284], "temperature": 0.0, "avg_logprob": -0.19039847056070963, "compression_ratio": 1.5737704918032787, "no_speech_prob": 0.0010336858686059713}, {"id": 63, "seek": 34684, "start": 365.23999999999995, "end": 371.15999999999997, "text": " another thing that you need is to expose an API is an API gateway. So in that example, we are using", "tokens": [51284, 1071, 551, 300, 291, 643, 307, 281, 19219, 364, 9362, 307, 364, 9362, 28532, 13, 407, 294, 300, 1365, 11, 321, 366, 1228, 51580], "temperature": 0.0, "avg_logprob": -0.19039847056070963, "compression_ratio": 1.5737704918032787, "no_speech_prob": 0.0010336858686059713}, {"id": 64, "seek": 37116, "start": 371.16, "end": 377.64000000000004, "text": " tag API gateway to use the authentication, verification, monitoring. So we add an API", "tokens": [50364, 6162, 9362, 28532, 281, 764, 264, 26643, 11, 30206, 11, 11028, 13, 407, 321, 909, 364, 9362, 50688], "temperature": 0.0, "avg_logprob": -0.17302321210319613, "compression_ratio": 1.7403846153846154, "no_speech_prob": 0.004535485990345478}, {"id": 65, "seek": 37116, "start": 377.64000000000004, "end": 382.44, "text": " gateway, open source API gateway to that. And that's going to be interesting also for the", "tokens": [50688, 28532, 11, 1269, 4009, 9362, 28532, 281, 300, 13, 400, 300, 311, 516, 281, 312, 1880, 611, 337, 264, 50928], "temperature": 0.0, "avg_logprob": -0.17302321210319613, "compression_ratio": 1.7403846153846154, "no_speech_prob": 0.004535485990345478}, {"id": 66, "seek": 37116, "start": 382.44, "end": 389.76000000000005, "text": " observability part later. So an API gateway helps you to centrally manage your APIs to use", "tokens": [50928, 9951, 2310, 644, 1780, 13, 407, 364, 9362, 28532, 3665, 291, 281, 32199, 379, 3067, 428, 21445, 281, 764, 51294], "temperature": 0.0, "avg_logprob": -0.17302321210319613, "compression_ratio": 1.7403846153846154, "no_speech_prob": 0.004535485990345478}, {"id": 67, "seek": 37116, "start": 389.76000000000005, "end": 394.8, "text": " authentication, authorization, weight limiting, all this capability that you need in operation.", "tokens": [51294, 26643, 11, 33697, 11, 3364, 22083, 11, 439, 341, 13759, 300, 291, 643, 294, 6916, 13, 51546], "temperature": 0.0, "avg_logprob": -0.17302321210319613, "compression_ratio": 1.7403846153846154, "no_speech_prob": 0.004535485990345478}, {"id": 68, "seek": 39480, "start": 395.76, "end": 401.72, "text": " How do you add that? The Kubernetes and GitHub way. Typically we focus on resource definition", "tokens": [50412, 1012, 360, 291, 909, 300, 30, 440, 23145, 293, 23331, 636, 13, 23129, 321, 1879, 322, 7684, 7123, 50710], "temperature": 0.0, "avg_logprob": -0.21924213652915142, "compression_ratio": 1.6244725738396624, "no_speech_prob": 0.0048384880647063255}, {"id": 69, "seek": 39480, "start": 401.72, "end": 407.6, "text": " like it's the way in Kubernetes. So you can add things. And that's a very, very simple where you", "tokens": [50710, 411, 309, 311, 264, 636, 294, 23145, 13, 407, 291, 393, 909, 721, 13, 400, 300, 311, 257, 588, 11, 588, 2199, 689, 291, 51004], "temperature": 0.0, "avg_logprob": -0.21924213652915142, "compression_ratio": 1.6244725738396624, "no_speech_prob": 0.0048384880647063255}, {"id": 70, "seek": 39480, "start": 407.6, "end": 412.48, "text": " can say which protocol it use. You could define things like weight limiting, like security policy,", "tokens": [51004, 393, 584, 597, 10336, 309, 764, 13, 509, 727, 6964, 721, 411, 3364, 22083, 11, 411, 3825, 3897, 11, 51248], "temperature": 0.0, "avg_logprob": -0.21924213652915142, "compression_ratio": 1.6244725738396624, "no_speech_prob": 0.0048384880647063255}, {"id": 71, "seek": 39480, "start": 413.36, "end": 419.36, "text": " which service is proxying on your cluster. And again, it's configuration as code. So it's again", "tokens": [51292, 597, 2643, 307, 447, 87, 1840, 322, 428, 13630, 13, 400, 797, 11, 309, 311, 11694, 382, 3089, 13, 407, 309, 311, 797, 51592], "temperature": 0.0, "avg_logprob": -0.21924213652915142, "compression_ratio": 1.6244725738396624, "no_speech_prob": 0.0048384880647063255}, {"id": 72, "seek": 41936, "start": 419.44, "end": 426.84000000000003, "text": " central repository. And when you make changes to it into your deployment configuration", "tokens": [50368, 5777, 25841, 13, 400, 562, 291, 652, 2962, 281, 309, 666, 428, 19317, 11694, 50738], "temperature": 0.0, "avg_logprob": -0.2828943133354187, "compression_ratio": 1.582857142857143, "no_speech_prob": 0.0038244128227233887}, {"id": 73, "seek": 41936, "start": 426.84000000000003, "end": 436.2, "text": " repository, something like ArgosCD will track it and will apply it automatically. So what we see", "tokens": [50738, 25841, 11, 746, 411, 1587, 18674, 16508, 486, 2837, 309, 293, 486, 3079, 309, 6772, 13, 407, 437, 321, 536, 51206], "temperature": 0.0, "avg_logprob": -0.2828943133354187, "compression_ratio": 1.582857142857143, "no_speech_prob": 0.0038244128227233887}, {"id": 74, "seek": 41936, "start": 436.2, "end": 441.56, "text": " at the end in your ArgosCD application, you see, okay, all my application definitions, all my", "tokens": [51206, 412, 264, 917, 294, 428, 1587, 18674, 16508, 3861, 11, 291, 536, 11, 1392, 11, 439, 452, 3861, 21988, 11, 439, 452, 51474], "temperature": 0.0, "avg_logprob": -0.2828943133354187, "compression_ratio": 1.582857142857143, "no_speech_prob": 0.0038244128227233887}, {"id": 75, "seek": 44156, "start": 441.6, "end": 451.72, "text": " application are synchronized automatically with whatever I put into my Git repository. So now we", "tokens": [50366, 3861, 366, 19331, 1602, 6772, 365, 2035, 286, 829, 666, 452, 16939, 25841, 13, 407, 586, 321, 50872], "temperature": 0.0, "avg_logprob": -0.1861483400518244, "compression_ratio": 1.565040650406504, "no_speech_prob": 0.0029530900064855814}, {"id": 76, "seek": 44156, "start": 451.72, "end": 457.04, "text": " have the first step, right? We have automation for fast flow. We are preventing configuration drift.", "tokens": [50872, 362, 264, 700, 1823, 11, 558, 30, 492, 362, 17769, 337, 2370, 3095, 13, 492, 366, 19965, 11694, 19699, 13, 51138], "temperature": 0.0, "avg_logprob": -0.1861483400518244, "compression_ratio": 1.565040650406504, "no_speech_prob": 0.0029530900064855814}, {"id": 77, "seek": 44156, "start": 457.04, "end": 463.52, "text": " We have enhanced security. All is automated. No manual error. We are more efficient. We also", "tokens": [51138, 492, 362, 21191, 3825, 13, 1057, 307, 18473, 13, 883, 9688, 6713, 13, 492, 366, 544, 7148, 13, 492, 611, 51462], "temperature": 0.0, "avg_logprob": -0.1861483400518244, "compression_ratio": 1.565040650406504, "no_speech_prob": 0.0029530900064855814}, {"id": 78, "seek": 44156, "start": 463.52, "end": 468.56, "text": " have an audit trail. So we see exactly what was changed in the deployment of your APIs. And we", "tokens": [51462, 362, 364, 17748, 9924, 13, 407, 321, 536, 2293, 437, 390, 3105, 294, 264, 19317, 295, 428, 21445, 13, 400, 321, 51714], "temperature": 0.0, "avg_logprob": -0.1861483400518244, "compression_ratio": 1.565040650406504, "no_speech_prob": 0.0029530900064855814}, {"id": 79, "seek": 46856, "start": 468.56, "end": 472.0, "text": " have better collaboration and visibility on what's happening.", "tokens": [50364, 362, 1101, 9363, 293, 19883, 322, 437, 311, 2737, 13, 50536], "temperature": 0.0, "avg_logprob": -0.11299419403076172, "compression_ratio": 1.4184782608695652, "no_speech_prob": 0.004120785742998123}, {"id": 80, "seek": 46856, "start": 475.72, "end": 484.48, "text": " Wonderful. And obviously, as the slide says, that is not enough. So we're getting the automation part", "tokens": [50722, 22768, 13, 400, 2745, 11, 382, 264, 4137, 1619, 11, 300, 307, 406, 1547, 13, 407, 321, 434, 1242, 264, 17769, 644, 51160], "temperature": 0.0, "avg_logprob": -0.11299419403076172, "compression_ratio": 1.4184782608695652, "no_speech_prob": 0.004120785742998123}, {"id": 81, "seek": 46856, "start": 484.48, "end": 493.16, "text": " down. What do we do next? Step three in the whole process is to get additional feedback into your", "tokens": [51160, 760, 13, 708, 360, 321, 360, 958, 30, 5470, 1045, 294, 264, 1379, 1399, 307, 281, 483, 4497, 5824, 666, 428, 51594], "temperature": 0.0, "avg_logprob": -0.11299419403076172, "compression_ratio": 1.4184782608695652, "no_speech_prob": 0.004120785742998123}, {"id": 82, "seek": 49316, "start": 493.20000000000005, "end": 500.08000000000004, "text": " feedback loops so you can connect both ops and dev correctly. So what this means is that the ops", "tokens": [50366, 5824, 16121, 370, 291, 393, 1745, 1293, 44663, 293, 1905, 8944, 13, 407, 437, 341, 1355, 307, 300, 264, 44663, 50710], "temperature": 0.0, "avg_logprob": -0.15152501066525778, "compression_ratio": 1.6514522821576763, "no_speech_prob": 0.0158892422914505}, {"id": 83, "seek": 49316, "start": 500.08000000000004, "end": 506.12, "text": " team needs to enable the dev team to fix issues by exactly knowing what the issue is, so that the", "tokens": [50710, 1469, 2203, 281, 9528, 264, 1905, 1469, 281, 3191, 2663, 538, 2293, 5276, 437, 264, 2734, 307, 11, 370, 300, 264, 51012], "temperature": 0.0, "avg_logprob": -0.15152501066525778, "compression_ratio": 1.6514522821576763, "no_speech_prob": 0.0158892422914505}, {"id": 84, "seek": 49316, "start": 506.12, "end": 512.0, "text": " dev team doesn't need to spend useless cycles trying to figure out what the problem is. And we do that", "tokens": [51012, 1905, 1469, 1177, 380, 643, 281, 3496, 14115, 17796, 1382, 281, 2573, 484, 437, 264, 1154, 307, 13, 400, 321, 360, 300, 51306], "temperature": 0.0, "avg_logprob": -0.15152501066525778, "compression_ratio": 1.6514522821576763, "no_speech_prob": 0.0158892422914505}, {"id": 85, "seek": 49316, "start": 512.6800000000001, "end": 518.9200000000001, "text": " by using OpenTelemetry and using Yeager, which are observability tools within our API ops pipelines.", "tokens": [51340, 538, 1228, 7238, 14233, 306, 5537, 627, 293, 1228, 835, 3557, 11, 597, 366, 9951, 2310, 3873, 1951, 527, 9362, 44663, 40168, 13, 51652], "temperature": 0.0, "avg_logprob": -0.15152501066525778, "compression_ratio": 1.6514522821576763, "no_speech_prob": 0.0158892422914505}, {"id": 86, "seek": 51892, "start": 519.8, "end": 529.12, "text": " Now, this is what we exactly don't want. We don't want to see gears turning and hoping it's all fine", "tokens": [50408, 823, 11, 341, 307, 437, 321, 2293, 500, 380, 528, 13, 492, 500, 380, 528, 281, 536, 20915, 6246, 293, 7159, 309, 311, 439, 2489, 50874], "temperature": 0.0, "avg_logprob": -0.10091638119421273, "compression_ratio": 1.7280334728033473, "no_speech_prob": 0.008969281800091267}, {"id": 87, "seek": 51892, "start": 529.1999999999999, "end": 535.04, "text": " because it's not really fine. You don't know what your users are seeing. So we don't really know if our", "tokens": [50878, 570, 309, 311, 406, 534, 2489, 13, 509, 500, 380, 458, 437, 428, 5022, 366, 2577, 13, 407, 321, 500, 380, 534, 458, 498, 527, 51170], "temperature": 0.0, "avg_logprob": -0.10091638119421273, "compression_ratio": 1.7280334728033473, "no_speech_prob": 0.008969281800091267}, {"id": 88, "seek": 51892, "start": 535.04, "end": 539.36, "text": " users are happy. We just kind of know it works. And then you kind of do prayer driven development, as I", "tokens": [51170, 5022, 366, 2055, 13, 492, 445, 733, 295, 458, 309, 1985, 13, 400, 550, 291, 733, 295, 360, 8767, 9555, 3250, 11, 382, 286, 51386], "temperature": 0.0, "avg_logprob": -0.10091638119421273, "compression_ratio": 1.7280334728033473, "no_speech_prob": 0.008969281800091267}, {"id": 89, "seek": 51892, "start": 539.36, "end": 544.8399999999999, "text": " like saying, that's not really what we want. We want to use observability to infer the internal state of", "tokens": [51386, 411, 1566, 11, 300, 311, 406, 534, 437, 321, 528, 13, 492, 528, 281, 764, 9951, 2310, 281, 13596, 264, 6920, 1785, 295, 51660], "temperature": 0.0, "avg_logprob": -0.10091638119421273, "compression_ratio": 1.7280334728033473, "no_speech_prob": 0.008969281800091267}, {"id": 90, "seek": 54484, "start": 544.84, "end": 550.24, "text": " our system by getting telemetry out of our system to understand what's actually happening. And then we", "tokens": [50364, 527, 1185, 538, 1242, 4304, 5537, 627, 484, 295, 527, 1185, 281, 1223, 437, 311, 767, 2737, 13, 400, 550, 321, 50634], "temperature": 0.0, "avg_logprob": -0.10779553128961931, "compression_ratio": 1.8237410071942446, "no_speech_prob": 0.01589186303317547}, {"id": 91, "seek": 54484, "start": 550.24, "end": 554.48, "text": " can figure out whether our users are happy. Because this is something that we can see by using", "tokens": [50634, 393, 2573, 484, 1968, 527, 5022, 366, 2055, 13, 1436, 341, 307, 746, 300, 321, 393, 536, 538, 1228, 50846], "temperature": 0.0, "avg_logprob": -0.10779553128961931, "compression_ratio": 1.8237410071942446, "no_speech_prob": 0.01589186303317547}, {"id": 92, "seek": 54484, "start": 554.52, "end": 560.2, "text": " observability with distributed tracing. When our API is exposed telemetry, we can actually see, oh, okay,", "tokens": [50848, 9951, 2310, 365, 12631, 25262, 13, 1133, 527, 9362, 307, 9495, 4304, 5537, 627, 11, 321, 393, 767, 536, 11, 1954, 11, 1392, 11, 51132], "temperature": 0.0, "avg_logprob": -0.10779553128961931, "compression_ratio": 1.8237410071942446, "no_speech_prob": 0.01589186303317547}, {"id": 93, "seek": 54484, "start": 560.96, "end": 566.1600000000001, "text": " obviously something is wrong because we have breaking APIs. So it's pretty obvious that our users are", "tokens": [51170, 2745, 746, 307, 2085, 570, 321, 362, 7697, 21445, 13, 407, 309, 311, 1238, 6322, 300, 527, 5022, 366, 51430], "temperature": 0.0, "avg_logprob": -0.10779553128961931, "compression_ratio": 1.8237410071942446, "no_speech_prob": 0.01589186303317547}, {"id": 94, "seek": 54484, "start": 566.1600000000001, "end": 571.76, "text": " unhappy because we can obviously see things breaking for them. And this is a particular view that you", "tokens": [51430, 22172, 570, 321, 393, 2745, 536, 721, 7697, 337, 552, 13, 400, 341, 307, 257, 1729, 1910, 300, 291, 51710], "temperature": 0.0, "avg_logprob": -0.10779553128961931, "compression_ratio": 1.8237410071942446, "no_speech_prob": 0.01589186303317547}, {"id": 95, "seek": 57176, "start": 571.76, "end": 577.68, "text": " get by using Jaeger. Now, let's get to the fun part of actually showing you how it all works and how you", "tokens": [50364, 483, 538, 1228, 3530, 30744, 13, 823, 11, 718, 311, 483, 281, 264, 1019, 644, 295, 767, 4099, 291, 577, 309, 439, 1985, 293, 577, 291, 50660], "temperature": 0.0, "avg_logprob": -0.09170832676170147, "compression_ratio": 1.7119341563786008, "no_speech_prob": 0.012232300825417042}, {"id": 96, "seek": 57176, "start": 577.68, "end": 584.6, "text": " can set it up yourself. Now, the way you do it is you use CNCF observability tooling. So tooling from the", "tokens": [50660, 393, 992, 309, 493, 1803, 13, 823, 11, 264, 636, 291, 360, 309, 307, 291, 764, 14589, 34, 37, 9951, 2310, 46593, 13, 407, 46593, 490, 264, 51006], "temperature": 0.0, "avg_logprob": -0.09170832676170147, "compression_ratio": 1.7119341563786008, "no_speech_prob": 0.012232300825417042}, {"id": 97, "seek": 57176, "start": 584.6, "end": 590.4, "text": " CNCF tracing landscape, more specifically open telemetry and Jaeger. Open telemetry is an incubating", "tokens": [51006, 14589, 34, 37, 25262, 9661, 11, 544, 4682, 1269, 4304, 5537, 627, 293, 3530, 30744, 13, 7238, 4304, 5537, 627, 307, 364, 33345, 990, 51296], "temperature": 0.0, "avg_logprob": -0.09170832676170147, "compression_ratio": 1.7119341563786008, "no_speech_prob": 0.012232300825417042}, {"id": 98, "seek": 57176, "start": 590.4, "end": 596.68, "text": " project. Jaeger is a graduated project. So they're all fully open source supported by the CNCF. Now, the", "tokens": [51296, 1716, 13, 3530, 30744, 307, 257, 13693, 1716, 13, 407, 436, 434, 439, 4498, 1269, 4009, 8104, 538, 264, 14589, 34, 37, 13, 823, 11, 264, 51610], "temperature": 0.0, "avg_logprob": -0.09170832676170147, "compression_ratio": 1.7119341563786008, "no_speech_prob": 0.012232300825417042}, {"id": 99, "seek": 59668, "start": 596.68, "end": 603.0799999999999, "text": " specifics are that you use open telemetry as the open standard, we're very focused on open standard for the", "tokens": [50364, 28454, 366, 300, 291, 764, 1269, 4304, 5537, 627, 382, 264, 1269, 3832, 11, 321, 434, 588, 5178, 322, 1269, 3832, 337, 264, 50684], "temperature": 0.0, "avg_logprob": -0.10441131775195782, "compression_ratio": 1.8080357142857142, "no_speech_prob": 0.002115303184837103}, {"id": 100, "seek": 59668, "start": 603.0799999999999, "end": 607.8, "text": " whole dev room today. So once again, it's an open standard to generate, collect and export your", "tokens": [50684, 1379, 1905, 1808, 965, 13, 407, 1564, 797, 11, 309, 311, 364, 1269, 3832, 281, 8460, 11, 2500, 293, 10725, 428, 50920], "temperature": 0.0, "avg_logprob": -0.10441131775195782, "compression_ratio": 1.8080357142857142, "no_speech_prob": 0.002115303184837103}, {"id": 101, "seek": 59668, "start": 607.8, "end": 614.28, "text": " telemetry. Remember that part, it's a bunch of libraries and APIs that help you generate, collect and", "tokens": [50920, 4304, 5537, 627, 13, 5459, 300, 644, 11, 309, 311, 257, 3840, 295, 15148, 293, 21445, 300, 854, 291, 8460, 11, 2500, 293, 51244], "temperature": 0.0, "avg_logprob": -0.10441131775195782, "compression_ratio": 1.8080357142857142, "no_speech_prob": 0.002115303184837103}, {"id": 102, "seek": 59668, "start": 614.28, "end": 621.88, "text": " export telemetry. Now, where do you export it to? Well, you export it to Jaeger, which is a tracing", "tokens": [51244, 10725, 4304, 5537, 627, 13, 823, 11, 689, 360, 291, 10725, 309, 281, 30, 1042, 11, 291, 10725, 309, 281, 3530, 30744, 11, 597, 307, 257, 25262, 51624], "temperature": 0.0, "avg_logprob": -0.10441131775195782, "compression_ratio": 1.8080357142857142, "no_speech_prob": 0.002115303184837103}, {"id": 103, "seek": 62188, "start": 621.96, "end": 629.0, "text": " backend, which is just like a data store for your distributed tracing. And then you use Jaeger for all of", "tokens": [50368, 38087, 11, 597, 307, 445, 411, 257, 1412, 3531, 337, 428, 12631, 25262, 13, 400, 550, 291, 764, 3530, 30744, 337, 439, 295, 50720], "temperature": 0.0, "avg_logprob": -0.12668069203694662, "compression_ratio": 1.6024096385542168, "no_speech_prob": 0.00628297682851553}, {"id": 104, "seek": 62188, "start": 629.0, "end": 633.2, "text": " your production monitoring troubleshooting and whatever else you need to do in your production", "tokens": [50720, 428, 4265, 11028, 15379, 47011, 293, 2035, 1646, 291, 643, 281, 360, 294, 428, 4265, 50930], "temperature": 0.0, "avg_logprob": -0.12668069203694662, "compression_ratio": 1.6024096385542168, "no_speech_prob": 0.00628297682851553}, {"id": 105, "seek": 62188, "start": 633.2, "end": 642.56, "text": " environment. Now, from this, one of the bigger issues is that open telemetry is quite hard to implement if", "tokens": [50930, 2823, 13, 823, 11, 490, 341, 11, 472, 295, 264, 3801, 2663, 307, 300, 1269, 4304, 5537, 627, 307, 1596, 1152, 281, 4445, 498, 51398], "temperature": 0.0, "avg_logprob": -0.12668069203694662, "compression_ratio": 1.6024096385542168, "no_speech_prob": 0.00628297682851553}, {"id": 106, "seek": 62188, "start": 642.56, "end": 649.52, "text": " you're new to it. So some vendors like to bake it in into their systems. One such vendor is", "tokens": [51398, 291, 434, 777, 281, 309, 13, 407, 512, 22056, 411, 281, 16562, 309, 294, 666, 641, 3652, 13, 1485, 1270, 24321, 307, 51746], "temperature": 0.0, "avg_logprob": -0.12668069203694662, "compression_ratio": 1.6024096385542168, "no_speech_prob": 0.00628297682851553}, {"id": 107, "seek": 65188, "start": 652.64, "end": 659.16, "text": " there was a lot of suspense, right? Yeah. Yeah. So one thing that we did in tech is to add support,", "tokens": [50402, 456, 390, 257, 688, 295, 47803, 11, 558, 30, 865, 13, 865, 13, 407, 472, 551, 300, 321, 630, 294, 7553, 307, 281, 909, 1406, 11, 50728], "temperature": 0.0, "avg_logprob": -0.24652251017462348, "compression_ratio": 1.6375, "no_speech_prob": 0.0027184158097952604}, {"id": 108, "seek": 65188, "start": 659.16, "end": 664.52, "text": " native support for open telemetry, because we know that people that works in the API space, they use", "tokens": [50728, 8470, 1406, 337, 1269, 4304, 5537, 627, 11, 570, 321, 458, 300, 561, 300, 1985, 294, 264, 9362, 1901, 11, 436, 764, 50996], "temperature": 0.0, "avg_logprob": -0.24652251017462348, "compression_ratio": 1.6375, "no_speech_prob": 0.0027184158097952604}, {"id": 109, "seek": 65188, "start": 664.52, "end": 669.76, "text": " API's to proxy multiple services, and the developers might not yet have implemented open", "tokens": [50996, 9362, 311, 281, 29690, 3866, 3328, 11, 293, 264, 8849, 1062, 406, 1939, 362, 12270, 1269, 51258], "temperature": 0.0, "avg_logprob": -0.24652251017462348, "compression_ratio": 1.6375, "no_speech_prob": 0.0027184158097952604}, {"id": 110, "seek": 65188, "start": 669.76, "end": 676.2, "text": " telemetry. But we know they need one where to report the data on all the APIs have really visibility on", "tokens": [51258, 4304, 5537, 627, 13, 583, 321, 458, 436, 643, 472, 689, 281, 2275, 264, 1412, 322, 439, 264, 21445, 362, 534, 19883, 322, 51580], "temperature": 0.0, "avg_logprob": -0.24652251017462348, "compression_ratio": 1.6375, "no_speech_prob": 0.0027184158097952604}, {"id": 111, "seek": 67620, "start": 676.2, "end": 682.6800000000001, "text": " what's happening. And so we added support, native support for open telemetry in tech to enable our", "tokens": [50364, 437, 311, 2737, 13, 400, 370, 321, 3869, 1406, 11, 8470, 1406, 337, 1269, 4304, 5537, 627, 294, 7553, 281, 9528, 527, 50688], "temperature": 0.0, "avg_logprob": -0.15656656207460345, "compression_ratio": 1.7478260869565216, "no_speech_prob": 0.0022250977344810963}, {"id": 112, "seek": 67620, "start": 682.6800000000001, "end": 689.4000000000001, "text": " user to export this data and to capture them automatically for older APIs. So that's need a couple", "tokens": [50688, 4195, 281, 10725, 341, 1412, 293, 281, 7983, 552, 6772, 337, 4906, 21445, 13, 407, 300, 311, 643, 257, 1916, 51024], "temperature": 0.0, "avg_logprob": -0.15656656207460345, "compression_ratio": 1.7478260869565216, "no_speech_prob": 0.0022250977344810963}, {"id": 113, "seek": 67620, "start": 689.4000000000001, "end": 694.2800000000001, "text": " of settings. This is settings for our hand charts. So where do you need to enable it in tech? You need", "tokens": [51024, 295, 6257, 13, 639, 307, 6257, 337, 527, 1011, 17767, 13, 407, 689, 360, 291, 643, 281, 9528, 309, 294, 7553, 30, 509, 643, 51268], "temperature": 0.0, "avg_logprob": -0.15656656207460345, "compression_ratio": 1.7478260869565216, "no_speech_prob": 0.0022250977344810963}, {"id": 114, "seek": 67620, "start": 694.2800000000001, "end": 699.4000000000001, "text": " to say where do you want to send the data to an open telemetry collector could be also directly to an", "tokens": [51268, 281, 584, 689, 360, 291, 528, 281, 2845, 264, 1412, 281, 364, 1269, 4304, 5537, 627, 23960, 727, 312, 611, 3838, 281, 364, 51524], "temperature": 0.0, "avg_logprob": -0.15656656207460345, "compression_ratio": 1.7478260869565216, "no_speech_prob": 0.0022250977344810963}, {"id": 115, "seek": 69940, "start": 699.4, "end": 706.6, "text": " observability backend. And this is what you get. So for every API request, you get a distributed", "tokens": [50364, 9951, 2310, 38087, 13, 400, 341, 307, 437, 291, 483, 13, 407, 337, 633, 9362, 5308, 11, 291, 483, 257, 12631, 50724], "temperature": 0.0, "avg_logprob": -0.17210840104936478, "compression_ratio": 1.8265682656826567, "no_speech_prob": 0.01522587426006794}, {"id": 116, "seek": 69940, "start": 706.6, "end": 713.24, "text": " trace for what's happening at the gateway and till the upstream service. So you can see, first of all,", "tokens": [50724, 13508, 337, 437, 311, 2737, 412, 264, 28532, 293, 4288, 264, 33915, 2643, 13, 407, 291, 393, 536, 11, 700, 295, 439, 11, 51056], "temperature": 0.0, "avg_logprob": -0.17210840104936478, "compression_ratio": 1.8265682656826567, "no_speech_prob": 0.01522587426006794}, {"id": 117, "seek": 69940, "start": 713.24, "end": 718.12, "text": " you can see any error that's happening already at the API gateway level, authentication error,", "tokens": [51056, 291, 393, 536, 604, 6713, 300, 311, 2737, 1217, 412, 264, 9362, 28532, 1496, 11, 26643, 6713, 11, 51300], "temperature": 0.0, "avg_logprob": -0.17210840104936478, "compression_ratio": 1.8265682656826567, "no_speech_prob": 0.01522587426006794}, {"id": 118, "seek": 69940, "start": 718.12, "end": 723.24, "text": " wait limiting. We see sometimes people only monitor what's happening on the service, but they don't", "tokens": [51300, 1699, 22083, 13, 492, 536, 2171, 561, 787, 6002, 437, 311, 2737, 322, 264, 2643, 11, 457, 436, 500, 380, 51556], "temperature": 0.0, "avg_logprob": -0.17210840104936478, "compression_ratio": 1.8265682656826567, "no_speech_prob": 0.01522587426006794}, {"id": 119, "seek": 69940, "start": 723.24, "end": 727.4399999999999, "text": " realize they're already missing a lot of people having issue with the authorization, authentication,", "tokens": [51556, 4325, 436, 434, 1217, 5361, 257, 688, 295, 561, 1419, 2734, 365, 264, 33697, 11, 26643, 11, 51766], "temperature": 0.0, "avg_logprob": -0.17210840104936478, "compression_ratio": 1.8265682656826567, "no_speech_prob": 0.01522587426006794}, {"id": 120, "seek": 72744, "start": 727.6800000000001, "end": 733.6800000000001, "text": " wait limiting. And then you see what's happening in the upstream. So you can very, very quickly catch", "tokens": [50376, 1699, 22083, 13, 400, 550, 291, 536, 437, 311, 2737, 294, 264, 33915, 13, 407, 291, 393, 588, 11, 588, 2661, 3745, 50676], "temperature": 0.0, "avg_logprob": -0.11055765446928359, "compression_ratio": 1.6411290322580645, "no_speech_prob": 0.0020576941315084696}, {"id": 121, "seek": 72744, "start": 733.6800000000001, "end": 740.24, "text": " up errors, understand not only the timing text, the HTTP response code, but really what's happening", "tokens": [50676, 493, 13603, 11, 1223, 406, 787, 264, 10822, 2487, 11, 264, 33283, 4134, 3089, 11, 457, 534, 437, 311, 2737, 51004], "temperature": 0.0, "avg_logprob": -0.11055765446928359, "compression_ratio": 1.6411290322580645, "no_speech_prob": 0.0020576941315084696}, {"id": 122, "seek": 72744, "start": 740.24, "end": 745.12, "text": " if there's an error, if something is slow, where is it happening? Is it on the API gateway, is it on", "tokens": [51004, 498, 456, 311, 364, 6713, 11, 498, 746, 307, 2964, 11, 689, 307, 309, 2737, 30, 1119, 309, 322, 264, 9362, 28532, 11, 307, 309, 322, 51248], "temperature": 0.0, "avg_logprob": -0.11055765446928359, "compression_ratio": 1.6411290322580645, "no_speech_prob": 0.0020576941315084696}, {"id": 123, "seek": 72744, "start": 745.12, "end": 751.6, "text": " the upstream service? What are the details of the transaction that enables a team to better troubleshoot", "tokens": [51248, 264, 33915, 2643, 30, 708, 366, 264, 4365, 295, 264, 14425, 300, 17077, 257, 1469, 281, 1101, 15379, 24467, 51572], "temperature": 0.0, "avg_logprob": -0.11055765446928359, "compression_ratio": 1.6411290322580645, "no_speech_prob": 0.0020576941315084696}, {"id": 124, "seek": 75160, "start": 751.6, "end": 760.88, "text": " the issue? And with that, we have now achieved feedback from production. So we have healthy", "tokens": [50364, 264, 2734, 30, 400, 365, 300, 11, 321, 362, 586, 11042, 5824, 490, 4265, 13, 407, 321, 362, 4627, 50828], "temperature": 0.0, "avg_logprob": -0.14645952224731446, "compression_ratio": 1.6024590163934427, "no_speech_prob": 0.002344404114410281}, {"id": 125, "seek": 75160, "start": 760.88, "end": 768.88, "text": " development lifecycle with feedback loop between Dev and Ops. If there's an issue, then the Ops team", "tokens": [50828, 3250, 45722, 365, 5824, 6367, 1296, 9096, 293, 422, 1878, 13, 759, 456, 311, 364, 2734, 11, 550, 264, 422, 1878, 1469, 51228], "temperature": 0.0, "avg_logprob": -0.14645952224731446, "compression_ratio": 1.6024590163934427, "no_speech_prob": 0.002344404114410281}, {"id": 126, "seek": 75160, "start": 768.88, "end": 773.9200000000001, "text": " can report it, can take a look. So it's not only an error on a metric that goes up, it's really a", "tokens": [51228, 393, 2275, 309, 11, 393, 747, 257, 574, 13, 407, 309, 311, 406, 787, 364, 6713, 322, 257, 20678, 300, 1709, 493, 11, 309, 311, 534, 257, 51480], "temperature": 0.0, "avg_logprob": -0.14645952224731446, "compression_ratio": 1.6024590163934427, "no_speech_prob": 0.002344404114410281}, {"id": 127, "seek": 75160, "start": 773.9200000000001, "end": 779.0400000000001, "text": " trace where you understand where's the problem, you know, which team needs to act on. And it enables", "tokens": [51480, 13508, 689, 291, 1223, 689, 311, 264, 1154, 11, 291, 458, 11, 597, 1469, 2203, 281, 605, 322, 13, 400, 309, 17077, 51736], "temperature": 0.0, "avg_logprob": -0.14645952224731446, "compression_ratio": 1.6024590163934427, "no_speech_prob": 0.002344404114410281}, {"id": 128, "seek": 77904, "start": 779.04, "end": 785.92, "text": " you to provide a better user experience, fix the issues earlier. Again, what have achieved, feedback", "tokens": [50364, 291, 281, 2893, 257, 1101, 4195, 1752, 11, 3191, 264, 2663, 3071, 13, 3764, 11, 437, 362, 11042, 11, 5824, 50708], "temperature": 0.0, "avg_logprob": -0.1566146282439536, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.0038477478083223104}, {"id": 129, "seek": 77904, "start": 785.92, "end": 791.5999999999999, "text": " from production, we no longer relying on user reporting feature, no longer somebody that calls", "tokens": [50708, 490, 4265, 11, 321, 572, 2854, 24140, 322, 4195, 10031, 4111, 11, 572, 2854, 2618, 300, 5498, 50992], "temperature": 0.0, "avg_logprob": -0.1566146282439536, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.0038477478083223104}, {"id": 130, "seek": 77904, "start": 791.5999999999999, "end": 795.68, "text": " support and say, oh, I have a problem, something is done, no, you see it, you see it all, so you can", "tokens": [50992, 1406, 293, 584, 11, 1954, 11, 286, 362, 257, 1154, 11, 746, 307, 1096, 11, 572, 11, 291, 536, 309, 11, 291, 536, 309, 439, 11, 370, 291, 393, 51196], "temperature": 0.0, "avg_logprob": -0.1566146282439536, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.0038477478083223104}, {"id": 131, "seek": 77904, "start": 795.68, "end": 801.12, "text": " be proactive. You understand the API performance, you understand really what's happening, where the", "tokens": [51196, 312, 28028, 13, 509, 1223, 264, 9362, 3389, 11, 291, 1223, 534, 437, 311, 2737, 11, 689, 264, 51468], "temperature": 0.0, "avg_logprob": -0.1566146282439536, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.0038477478083223104}, {"id": 132, "seek": 80112, "start": 801.2, "end": 804.08, "text": " error is happening, and you can solve issues faster.", "tokens": [50368, 6713, 307, 2737, 11, 293, 291, 393, 5039, 2663, 4663, 13, 50512], "temperature": 0.0, "avg_logprob": -0.1746880899776112, "compression_ratio": 1.6431924882629108, "no_speech_prob": 0.029713571071624756}, {"id": 133, "seek": 80112, "start": 806.88, "end": 813.76, "text": " And with that suspendsful mic switch, again, it's not enough. So we need to introduce another layer", "tokens": [50652, 400, 365, 300, 6535, 2581, 906, 3123, 3679, 11, 797, 11, 309, 311, 406, 1547, 13, 407, 321, 643, 281, 5366, 1071, 4583, 50996], "temperature": 0.0, "avg_logprob": -0.1746880899776112, "compression_ratio": 1.6431924882629108, "no_speech_prob": 0.029713571071624756}, {"id": 134, "seek": 80112, "start": 814.4, "end": 821.92, "text": " of, actually this one, no, we need to introduce another layer of protection. Because right now,", "tokens": [51028, 295, 11, 767, 341, 472, 11, 572, 11, 321, 643, 281, 5366, 1071, 4583, 295, 6334, 13, 1436, 558, 586, 11, 51404], "temperature": 0.0, "avg_logprob": -0.1746880899776112, "compression_ratio": 1.6431924882629108, "no_speech_prob": 0.029713571071624756}, {"id": 135, "seek": 80112, "start": 822.72, "end": 829.28, "text": " we want, we're only stopping bugs after our users are seeing them. So we exactly know that a user saw", "tokens": [51444, 321, 528, 11, 321, 434, 787, 12767, 15120, 934, 527, 5022, 366, 2577, 552, 13, 407, 321, 2293, 458, 300, 257, 4195, 1866, 51772], "temperature": 0.0, "avg_logprob": -0.1746880899776112, "compression_ratio": 1.6431924882629108, "no_speech_prob": 0.029713571071624756}, {"id": 136, "seek": 82928, "start": 829.28, "end": 834.64, "text": " problem that broke our API, and then we're now rotating back to fix it. We need to be more", "tokens": [50364, 1154, 300, 6902, 527, 9362, 11, 293, 550, 321, 434, 586, 19627, 646, 281, 3191, 309, 13, 492, 643, 281, 312, 544, 50632], "temperature": 0.0, "avg_logprob": -0.09468701306511373, "compression_ratio": 1.657439446366782, "no_speech_prob": 0.008839746005833149}, {"id": 137, "seek": 82928, "start": 834.64, "end": 840.64, "text": " proactive and figure out how to stop the bugs before they even reach our users. Now, so this is a", "tokens": [50632, 28028, 293, 2573, 484, 577, 281, 1590, 264, 15120, 949, 436, 754, 2524, 527, 5022, 13, 823, 11, 370, 341, 307, 257, 50932], "temperature": 0.0, "avg_logprob": -0.09468701306511373, "compression_ratio": 1.657439446366782, "no_speech_prob": 0.008839746005833149}, {"id": 138, "seek": 82928, "start": 840.64, "end": 845.04, "text": " shift left even more approach, but actually for you guys, it's shift left even more approach.", "tokens": [50932, 5513, 1411, 754, 544, 3109, 11, 457, 767, 337, 291, 1074, 11, 309, 311, 5513, 1411, 754, 544, 3109, 13, 51152], "temperature": 0.0, "avg_logprob": -0.09468701306511373, "compression_ratio": 1.657439446366782, "no_speech_prob": 0.008839746005833149}, {"id": 139, "seek": 82928, "start": 846.16, "end": 850.48, "text": " Because we want to add observability to our release cycles as well. So not just our production", "tokens": [51208, 1436, 321, 528, 281, 909, 9951, 2310, 281, 527, 4374, 17796, 382, 731, 13, 407, 406, 445, 527, 4265, 51424], "temperature": 0.0, "avg_logprob": -0.09468701306511373, "compression_ratio": 1.657439446366782, "no_speech_prob": 0.008839746005833149}, {"id": 140, "seek": 82928, "start": 850.48, "end": 858.9599999999999, "text": " systems. So the way we're going to go through that a bit is by doing this little squiggly in between,", "tokens": [51424, 3652, 13, 407, 264, 636, 321, 434, 516, 281, 352, 807, 300, 257, 857, 307, 538, 884, 341, 707, 2339, 46737, 294, 1296, 11, 51848], "temperature": 0.0, "avg_logprob": -0.09468701306511373, "compression_ratio": 1.657439446366782, "no_speech_prob": 0.008839746005833149}, {"id": 141, "seek": 85896, "start": 859.0400000000001, "end": 865.52, "text": " as well. So this basically means that you need to implement something called trace-based testing,", "tokens": [50368, 382, 731, 13, 407, 341, 1936, 1355, 300, 291, 643, 281, 4445, 746, 1219, 13508, 12, 6032, 4997, 11, 50692], "temperature": 0.0, "avg_logprob": -0.1493274900648329, "compression_ratio": 1.6565217391304348, "no_speech_prob": 0.0023936007637530565}, {"id": 142, "seek": 85896, "start": 865.52, "end": 871.84, "text": " which is also called observability driven development. If you like honeycomb and their CTO,", "tokens": [50692, 597, 307, 611, 1219, 9951, 2310, 9555, 3250, 13, 759, 291, 411, 8330, 38763, 293, 641, 383, 15427, 11, 51008], "temperature": 0.0, "avg_logprob": -0.1493274900648329, "compression_ratio": 1.6565217391304348, "no_speech_prob": 0.0023936007637530565}, {"id": 143, "seek": 85896, "start": 871.84, "end": 882.0, "text": " it's a term that they coined. Okay. Anyway, the way that you use trace-based testing is you quite", "tokens": [51008, 309, 311, 257, 1433, 300, 436, 45222, 13, 1033, 13, 5684, 11, 264, 636, 300, 291, 764, 13508, 12, 6032, 4997, 307, 291, 1596, 51516], "temperature": 0.0, "avg_logprob": -0.1493274900648329, "compression_ratio": 1.6565217391304348, "no_speech_prob": 0.0023936007637530565}, {"id": 144, "seek": 85896, "start": 882.0, "end": 886.96, "text": " literally using the distributed tracing that your observability, like open telemetry exposes,", "tokens": [51516, 3736, 1228, 264, 12631, 25262, 300, 428, 9951, 2310, 11, 411, 1269, 4304, 5537, 627, 1278, 4201, 11, 51764], "temperature": 0.0, "avg_logprob": -0.1493274900648329, "compression_ratio": 1.6565217391304348, "no_speech_prob": 0.0023936007637530565}, {"id": 145, "seek": 88696, "start": 886.96, "end": 893.36, "text": " and then you're running tests on those actual data points from your infrastructure. So that", "tokens": [50364, 293, 550, 291, 434, 2614, 6921, 322, 729, 3539, 1412, 2793, 490, 428, 6896, 13, 407, 300, 50684], "temperature": 0.0, "avg_logprob": -0.06711576331374991, "compression_ratio": 1.6953405017921146, "no_speech_prob": 0.0036489409394562244}, {"id": 146, "seek": 88696, "start": 893.36, "end": 898.72, "text": " means that even though we can see that we have our gears turning, that's awesome. But my initial", "tokens": [50684, 1355, 300, 754, 1673, 321, 393, 536, 300, 321, 362, 527, 20915, 6246, 11, 300, 311, 3476, 13, 583, 452, 5883, 50952], "temperature": 0.0, "avg_logprob": -0.06711576331374991, "compression_ratio": 1.6953405017921146, "no_speech_prob": 0.0036489409394562244}, {"id": 147, "seek": 88696, "start": 898.72, "end": 904.8000000000001, "text": " connection to that API gateway is returning 200. But how do I know this is not broken? How do I", "tokens": [50952, 4984, 281, 300, 9362, 28532, 307, 12678, 2331, 13, 583, 577, 360, 286, 458, 341, 307, 406, 5463, 30, 1012, 360, 286, 51256], "temperature": 0.0, "avg_logprob": -0.06711576331374991, "compression_ratio": 1.6953405017921146, "no_speech_prob": 0.0036489409394562244}, {"id": 148, "seek": 88696, "start": 904.8000000000001, "end": 908.88, "text": " know if this is on fire or not? This is an external service. I don't like I don't manage this.", "tokens": [51256, 458, 498, 341, 307, 322, 2610, 420, 406, 30, 639, 307, 364, 8320, 2643, 13, 286, 500, 380, 411, 286, 500, 380, 3067, 341, 13, 51460], "temperature": 0.0, "avg_logprob": -0.06711576331374991, "compression_ratio": 1.6953405017921146, "no_speech_prob": 0.0036489409394562244}, {"id": 149, "seek": 88696, "start": 910.24, "end": 914.64, "text": " So this is something that easily breaks and that you don't really have a lot of control over.", "tokens": [51528, 407, 341, 307, 746, 300, 3612, 9857, 293, 300, 291, 500, 380, 534, 362, 257, 688, 295, 1969, 670, 13, 51748], "temperature": 0.0, "avg_logprob": -0.06711576331374991, "compression_ratio": 1.6953405017921146, "no_speech_prob": 0.0036489409394562244}, {"id": 150, "seek": 91464, "start": 915.28, "end": 919.76, "text": " Now, let me show you how you can actually get to that state where you can do your testing against", "tokens": [50396, 823, 11, 718, 385, 855, 291, 577, 291, 393, 767, 483, 281, 300, 1785, 689, 291, 393, 360, 428, 4997, 1970, 50620], "temperature": 0.0, "avg_logprob": -0.11304324712508763, "compression_ratio": 1.7416974169741697, "no_speech_prob": 0.0029800599440932274}, {"id": 151, "seek": 91464, "start": 919.76, "end": 924.96, "text": " the distributed trace itself. This is a screenshot from Trace-Test, which is also a", "tokens": [50620, 264, 12631, 13508, 2564, 13, 639, 307, 257, 27712, 490, 1765, 617, 12, 51, 377, 11, 597, 307, 611, 257, 50880], "temperature": 0.0, "avg_logprob": -0.11304324712508763, "compression_ratio": 1.7416974169741697, "no_speech_prob": 0.0029800599440932274}, {"id": 152, "seek": 91464, "start": 926.08, "end": 932.16, "text": " CNCF tracing landscape tool. You can build your test by getting the trace itself from Jaeger,", "tokens": [50936, 48714, 37, 25262, 9661, 2290, 13, 509, 393, 1322, 428, 1500, 538, 1242, 264, 13508, 2564, 490, 3530, 30744, 11, 51240], "temperature": 0.0, "avg_logprob": -0.11304324712508763, "compression_ratio": 1.7416974169741697, "no_speech_prob": 0.0029800599440932274}, {"id": 153, "seek": 91464, "start": 932.16, "end": 937.92, "text": " and then you're writing your test specs directly against trace data. So you're not using any mocking,", "tokens": [51240, 293, 550, 291, 434, 3579, 428, 1500, 27911, 3838, 1970, 13508, 1412, 13, 407, 291, 434, 406, 1228, 604, 49792, 11, 51528], "temperature": 0.0, "avg_logprob": -0.11304324712508763, "compression_ratio": 1.7416974169741697, "no_speech_prob": 0.0029800599440932274}, {"id": 154, "seek": 91464, "start": 937.92, "end": 941.92, "text": " you're not using any faking or whatever the word is nowadays with kids use, I don't even know.", "tokens": [51528, 291, 434, 406, 1228, 604, 283, 2456, 420, 2035, 264, 1349, 307, 13434, 365, 2301, 764, 11, 286, 500, 380, 754, 458, 13, 51728], "temperature": 0.0, "avg_logprob": -0.11304324712508763, "compression_ratio": 1.7416974169741697, "no_speech_prob": 0.0029800599440932274}, {"id": 155, "seek": 94192, "start": 942.88, "end": 947.36, "text": " You're literally getting the actual data back and running your test against that data.", "tokens": [50412, 509, 434, 3736, 1242, 264, 3539, 1412, 646, 293, 2614, 428, 1500, 1970, 300, 1412, 13, 50636], "temperature": 0.0, "avg_logprob": -0.10940959475456027, "compression_ratio": 1.7286821705426356, "no_speech_prob": 0.0017272902186959982}, {"id": 156, "seek": 94192, "start": 948.24, "end": 951.92, "text": " Now, the magical part here is that you can quite literally test against anything that's", "tokens": [50680, 823, 11, 264, 12066, 644, 510, 307, 300, 291, 393, 1596, 3736, 1500, 1970, 1340, 300, 311, 50864], "temperature": 0.0, "avg_logprob": -0.10940959475456027, "compression_ratio": 1.7286821705426356, "no_speech_prob": 0.0017272902186959982}, {"id": 157, "seek": 94192, "start": 951.92, "end": 956.16, "text": " exposing telemetry. It can be an API gateway like TIC, it can be databases like Postgres,", "tokens": [50864, 33178, 4304, 5537, 627, 13, 467, 393, 312, 364, 9362, 28532, 411, 314, 2532, 11, 309, 393, 312, 22380, 411, 10223, 45189, 11, 51076], "temperature": 0.0, "avg_logprob": -0.10940959475456027, "compression_ratio": 1.7286821705426356, "no_speech_prob": 0.0017272902186959982}, {"id": 158, "seek": 94192, "start": 956.16, "end": 960.9599999999999, "text": " it can be caches like Redis, it can be pretty much anything that you have instrumented to", "tokens": [51076, 309, 393, 312, 269, 13272, 411, 4477, 271, 11, 309, 393, 312, 1238, 709, 1340, 300, 291, 362, 7198, 292, 281, 51316], "temperature": 0.0, "avg_logprob": -0.10940959475456027, "compression_ratio": 1.7286821705426356, "no_speech_prob": 0.0017272902186959982}, {"id": 159, "seek": 94192, "start": 960.9599999999999, "end": 966.4, "text": " export traces. Now, this is a really cool use case for authentication as well, but also for", "tokens": [51316, 10725, 26076, 13, 823, 11, 341, 307, 257, 534, 1627, 764, 1389, 337, 26643, 382, 731, 11, 457, 611, 337, 51588], "temperature": 0.0, "avg_logprob": -0.10940959475456027, "compression_ratio": 1.7286821705426356, "no_speech_prob": 0.0017272902186959982}, {"id": 160, "seek": 96640, "start": 967.12, "end": 971.12, "text": " GraphQL. Now, for authentication, you have a very good example.", "tokens": [50400, 21884, 13695, 13, 823, 11, 337, 26643, 11, 291, 362, 257, 588, 665, 1365, 13, 50600], "temperature": 0.0, "avg_logprob": -0.16487494302452158, "compression_ratio": 1.6066176470588236, "no_speech_prob": 0.004665724467486143}, {"id": 161, "seek": 96640, "start": 973.4399999999999, "end": 978.0799999999999, "text": " Yeah, something like Off-Flow where you have multiple service taking to each other and getting", "tokens": [50716, 865, 11, 746, 411, 6318, 12, 37, 14107, 689, 291, 362, 3866, 2643, 1940, 281, 1184, 661, 293, 1242, 50948], "temperature": 0.0, "avg_logprob": -0.16487494302452158, "compression_ratio": 1.6066176470588236, "no_speech_prob": 0.004665724467486143}, {"id": 162, "seek": 96640, "start": 978.0799999999999, "end": 984.56, "text": " the request, that's one of the really cool, useful examples. And also something that I've", "tokens": [50948, 264, 5308, 11, 300, 311, 472, 295, 264, 534, 1627, 11, 4420, 5110, 13, 400, 611, 746, 300, 286, 600, 51272], "temperature": 0.0, "avg_logprob": -0.16487494302452158, "compression_ratio": 1.6066176470588236, "no_speech_prob": 0.004665724467486143}, {"id": 163, "seek": 96640, "start": 984.56, "end": 990.56, "text": " noticed as well is for GraphQL. So one thing for GraphQL is that it often returns a 200,", "tokens": [51272, 5694, 382, 731, 307, 337, 21884, 13695, 13, 407, 472, 551, 337, 21884, 13695, 307, 300, 309, 2049, 11247, 257, 2331, 11, 51572], "temperature": 0.0, "avg_logprob": -0.16487494302452158, "compression_ratio": 1.6066176470588236, "no_speech_prob": 0.004665724467486143}, {"id": 164, "seek": 96640, "start": 990.56, "end": 995.68, "text": " even though it's failing because the actual error is within the response. So you don't really know,", "tokens": [51572, 754, 1673, 309, 311, 18223, 570, 264, 3539, 6713, 307, 1951, 264, 4134, 13, 407, 291, 500, 380, 534, 458, 11, 51828], "temperature": 0.0, "avg_logprob": -0.16487494302452158, "compression_ratio": 1.6066176470588236, "no_speech_prob": 0.004665724467486143}, {"id": 165, "seek": 99568, "start": 996.0, "end": 1000.0, "text": " it's very intricate to test that. One thing you can do with trace-based testing is you can drill", "tokens": [50380, 309, 311, 588, 38015, 281, 1500, 300, 13, 1485, 551, 291, 393, 360, 365, 13508, 12, 6032, 4997, 307, 291, 393, 11392, 50580], "temperature": 0.0, "avg_logprob": -0.056882130248206, "compression_ratio": 1.755639097744361, "no_speech_prob": 0.0018372299382463098}, {"id": 166, "seek": 99568, "start": 1000.0, "end": 1006.0, "text": " down to the actual middleware that handles that in your API gateway, find the exact error that", "tokens": [50580, 760, 281, 264, 3539, 2808, 3039, 300, 18722, 300, 294, 428, 9362, 28532, 11, 915, 264, 1900, 6713, 300, 50880], "temperature": 0.0, "avg_logprob": -0.056882130248206, "compression_ratio": 1.755639097744361, "no_speech_prob": 0.0018372299382463098}, {"id": 167, "seek": 99568, "start": 1006.0, "end": 1011.8399999999999, "text": " happened, and then you can run your test spec on that exact value. So with all of this, we're", "tokens": [50880, 2011, 11, 293, 550, 291, 393, 1190, 428, 1500, 1608, 322, 300, 1900, 2158, 13, 407, 365, 439, 295, 341, 11, 321, 434, 51172], "temperature": 0.0, "avg_logprob": -0.056882130248206, "compression_ratio": 1.755639097744361, "no_speech_prob": 0.0018372299382463098}, {"id": 168, "seek": 99568, "start": 1011.8399999999999, "end": 1016.8, "text": " getting step one, which is functional testing. So we can actually functionally validate our", "tokens": [51172, 1242, 1823, 472, 11, 597, 307, 11745, 4997, 13, 407, 321, 393, 767, 2445, 379, 29562, 527, 51420], "temperature": 0.0, "avg_logprob": -0.056882130248206, "compression_ratio": 1.755639097744361, "no_speech_prob": 0.0018372299382463098}, {"id": 169, "seek": 99568, "start": 1016.8, "end": 1021.5999999999999, "text": " behavior of the system by using all of the telemetry that you've implemented in the prior", "tokens": [51420, 5223, 295, 264, 1185, 538, 1228, 439, 295, 264, 4304, 5537, 627, 300, 291, 600, 12270, 294, 264, 4059, 51660], "temperature": 0.0, "avg_logprob": -0.056882130248206, "compression_ratio": 1.755639097744361, "no_speech_prob": 0.0018372299382463098}, {"id": 170, "seek": 102160, "start": 1021.6, "end": 1027.1200000000001, "text": " step to make your production environment reliable. Now, but it doesn't really stop there. We also", "tokens": [50364, 1823, 281, 652, 428, 4265, 2823, 12924, 13, 823, 11, 457, 309, 1177, 380, 534, 1590, 456, 13, 492, 611, 50640], "temperature": 0.0, "avg_logprob": -0.07333796614900641, "compression_ratio": 1.6413793103448275, "no_speech_prob": 0.003820632817223668}, {"id": 171, "seek": 102160, "start": 1027.1200000000001, "end": 1032.56, "text": " have step two, which is performance testing, because every span has a duration. You can quite", "tokens": [50640, 362, 1823, 732, 11, 597, 307, 3389, 4997, 11, 570, 633, 16174, 575, 257, 16365, 13, 509, 393, 1596, 50912], "temperature": 0.0, "avg_logprob": -0.07333796614900641, "compression_ratio": 1.6413793103448275, "no_speech_prob": 0.003820632817223668}, {"id": 172, "seek": 102160, "start": 1032.56, "end": 1037.84, "text": " literally go in and say, I want my duration for this span to be less than whatever value of 200", "tokens": [50912, 3736, 352, 294, 293, 584, 11, 286, 528, 452, 16365, 337, 341, 16174, 281, 312, 1570, 813, 2035, 2158, 295, 2331, 51176], "temperature": 0.0, "avg_logprob": -0.07333796614900641, "compression_ratio": 1.6413793103448275, "no_speech_prob": 0.003820632817223668}, {"id": 173, "seek": 102160, "start": 1037.84, "end": 1042.48, "text": " milliseconds or something, which means that if you have external services, external APIs, upstream", "tokens": [51176, 34184, 420, 746, 11, 597, 1355, 300, 498, 291, 362, 8320, 3328, 11, 8320, 21445, 11, 33915, 51408], "temperature": 0.0, "avg_logprob": -0.07333796614900641, "compression_ratio": 1.6413793103448275, "no_speech_prob": 0.003820632817223668}, {"id": 174, "seek": 102160, "start": 1042.48, "end": 1048.56, "text": " APIs that you're not in charge of, if their performance is bad, you can validate that and", "tokens": [51408, 21445, 300, 291, 434, 406, 294, 4602, 295, 11, 498, 641, 3389, 307, 1578, 11, 291, 393, 29562, 300, 293, 51712], "temperature": 0.0, "avg_logprob": -0.07333796614900641, "compression_ratio": 1.6413793103448275, "no_speech_prob": 0.003820632817223668}, {"id": 175, "seek": 104856, "start": 1048.6399999999999, "end": 1053.28, "text": " you know exactly what part of your system is misbehaving. So this is the performance aspect as", "tokens": [50368, 291, 458, 2293, 437, 644, 295, 428, 1185, 307, 3346, 29437, 6152, 13, 407, 341, 307, 264, 3389, 4171, 382, 50600], "temperature": 0.0, "avg_logprob": -0.1102096443502312, "compression_ratio": 1.6442953020134228, "no_speech_prob": 0.0018958606524392962}, {"id": 176, "seek": 104856, "start": 1053.28, "end": 1060.6399999999999, "text": " well. So you're getting basically two things from one, I'm going to say exercise. Now the way you", "tokens": [50600, 731, 13, 407, 291, 434, 1242, 1936, 732, 721, 490, 472, 11, 286, 478, 516, 281, 584, 5380, 13, 823, 264, 636, 291, 50968], "temperature": 0.0, "avg_logprob": -0.1102096443502312, "compression_ratio": 1.6442953020134228, "no_speech_prob": 0.0018958606524392962}, {"id": 177, "seek": 104856, "start": 1060.6399999999999, "end": 1064.8799999999999, "text": " do it, I'm going to walk you through quickly. You do this shifting left with trace test, which is,", "tokens": [50968, 360, 309, 11, 286, 478, 516, 281, 1792, 291, 807, 2661, 13, 509, 360, 341, 17573, 1411, 365, 13508, 1500, 11, 597, 307, 11, 51180], "temperature": 0.0, "avg_logprob": -0.1102096443502312, "compression_ratio": 1.6442953020134228, "no_speech_prob": 0.0018958606524392962}, {"id": 178, "seek": 104856, "start": 1064.8799999999999, "end": 1070.6399999999999, "text": " as I said, open source part of the CNCF tracing landscape as well. And what it does, it is quite", "tokens": [51180, 382, 286, 848, 11, 1269, 4009, 644, 295, 264, 48714, 37, 25262, 9661, 382, 731, 13, 400, 437, 309, 775, 11, 309, 307, 1596, 51468], "temperature": 0.0, "avg_logprob": -0.1102096443502312, "compression_ratio": 1.6442953020134228, "no_speech_prob": 0.0018958606524392962}, {"id": 179, "seek": 104856, "start": 1070.6399999999999, "end": 1077.36, "text": " literally giving you the infrastructure by actually the distributed system architecture by looking at", "tokens": [51468, 3736, 2902, 291, 264, 6896, 538, 767, 264, 12631, 1185, 9482, 538, 1237, 412, 51804], "temperature": 0.0, "avg_logprob": -0.1102096443502312, "compression_ratio": 1.6442953020134228, "no_speech_prob": 0.0018958606524392962}, {"id": 180, "seek": 107736, "start": 1077.36, "end": 1081.6, "text": " the trace data. And then you can both get the overview of what your system is doing,", "tokens": [50364, 264, 13508, 1412, 13, 400, 550, 291, 393, 1293, 483, 264, 12492, 295, 437, 428, 1185, 307, 884, 11, 50576], "temperature": 0.0, "avg_logprob": -0.06565296338952106, "compression_ratio": 1.6764705882352942, "no_speech_prob": 0.002393371658399701}, {"id": 181, "seek": 107736, "start": 1081.6, "end": 1086.3999999999999, "text": " and you can run tests against exactly what's happening in your system. So those are two", "tokens": [50576, 293, 291, 393, 1190, 6921, 1970, 2293, 437, 311, 2737, 294, 428, 1185, 13, 407, 729, 366, 732, 50816], "temperature": 0.0, "avg_logprob": -0.06565296338952106, "compression_ratio": 1.6764705882352942, "no_speech_prob": 0.002393371658399701}, {"id": 182, "seek": 107736, "start": 1086.3999999999999, "end": 1091.04, "text": " powerful things because as engineers, it's very hard to know what the system is doing if it's", "tokens": [50816, 4005, 721, 570, 382, 11955, 11, 309, 311, 588, 1152, 281, 458, 437, 264, 1185, 307, 884, 498, 309, 311, 51048], "temperature": 0.0, "avg_logprob": -0.06565296338952106, "compression_ratio": 1.6764705882352942, "no_speech_prob": 0.002393371658399701}, {"id": 183, "seek": 107736, "start": 1091.04, "end": 1096.0, "text": " highly distributed with a lot of microservices, especially if you're a new person on a team,", "tokens": [51048, 5405, 12631, 365, 257, 688, 295, 15547, 47480, 11, 2318, 498, 291, 434, 257, 777, 954, 322, 257, 1469, 11, 51296], "temperature": 0.0, "avg_logprob": -0.06565296338952106, "compression_ratio": 1.6764705882352942, "no_speech_prob": 0.002393371658399701}, {"id": 184, "seek": 107736, "start": 1096.0, "end": 1102.4799999999998, "text": " it's just, it's a pain to do that. But with trace test, I want to show you how you can implement", "tokens": [51296, 309, 311, 445, 11, 309, 311, 257, 1822, 281, 360, 300, 13, 583, 365, 13508, 1500, 11, 286, 528, 281, 855, 291, 577, 291, 393, 4445, 51620], "temperature": 0.0, "avg_logprob": -0.06565296338952106, "compression_ratio": 1.6764705882352942, "no_speech_prob": 0.002393371658399701}, {"id": 185, "seek": 110248, "start": 1102.48, "end": 1109.92, "text": " these integration tests in your Argo CD, like right here. So this is what an integration test in a", "tokens": [50364, 613, 10980, 6921, 294, 428, 1587, 1571, 6743, 11, 411, 558, 510, 13, 407, 341, 307, 437, 364, 10980, 1500, 294, 257, 50736], "temperature": 0.0, "avg_logprob": -0.13362074279785155, "compression_ratio": 1.9115384615384616, "no_speech_prob": 0.07248538732528687}, {"id": 186, "seek": 110248, "start": 1109.92, "end": 1116.56, "text": " post sync hook would look like. You have a API that you're deploying, you have your integration test,", "tokens": [50736, 2183, 20271, 6328, 576, 574, 411, 13, 509, 362, 257, 9362, 300, 291, 434, 34198, 11, 291, 362, 428, 10980, 1500, 11, 51068], "temperature": 0.0, "avg_logprob": -0.13362074279785155, "compression_ratio": 1.9115384615384616, "no_speech_prob": 0.07248538732528687}, {"id": 187, "seek": 110248, "start": 1116.56, "end": 1123.6, "text": " which basically runs a Kubernetes job from Argos, from the Argo CD sync hook, then it runs a few", "tokens": [51068, 597, 1936, 6676, 257, 23145, 1691, 490, 1587, 18674, 11, 490, 264, 1587, 1571, 6743, 20271, 6328, 11, 550, 309, 6676, 257, 1326, 51420], "temperature": 0.0, "avg_logprob": -0.13362074279785155, "compression_ratio": 1.9115384615384616, "no_speech_prob": 0.07248538732528687}, {"id": 188, "seek": 110248, "start": 1123.6, "end": 1127.3600000000001, "text": " integration tests. If they, if they're failing, awesome, you know that they're failing, if they're", "tokens": [51420, 10980, 6921, 13, 759, 436, 11, 498, 436, 434, 18223, 11, 3476, 11, 291, 458, 300, 436, 434, 18223, 11, 498, 436, 434, 51608], "temperature": 0.0, "avg_logprob": -0.13362074279785155, "compression_ratio": 1.9115384615384616, "no_speech_prob": 0.07248538732528687}, {"id": 189, "seek": 110248, "start": 1127.3600000000001, "end": 1132.4, "text": " passing, even better, you see that they're passing, but doesn't really stop here. The thing that you", "tokens": [51608, 8437, 11, 754, 1101, 11, 291, 536, 300, 436, 434, 8437, 11, 457, 1177, 380, 534, 1590, 510, 13, 440, 551, 300, 291, 51860], "temperature": 0.0, "avg_logprob": -0.13362074279785155, "compression_ratio": 1.9115384615384616, "no_speech_prob": 0.07248538732528687}, {"id": 190, "seek": 113240, "start": 1132.5600000000002, "end": 1139.3600000000001, "text": " get with this is also every test that fails, you have a URL to go to that particular test", "tokens": [50372, 483, 365, 341, 307, 611, 633, 1500, 300, 18199, 11, 291, 362, 257, 12905, 281, 352, 281, 300, 1729, 1500, 50712], "temperature": 0.0, "avg_logprob": -0.09623771974410134, "compression_ratio": 1.680952380952381, "no_speech_prob": 0.0036459483671933413}, {"id": 191, "seek": 113240, "start": 1139.3600000000001, "end": 1146.0800000000002, "text": " to actually see precisely which part of that transaction failed within your API, within your", "tokens": [50712, 281, 767, 536, 13402, 597, 644, 295, 300, 14425, 7612, 1951, 428, 9362, 11, 1951, 428, 51048], "temperature": 0.0, "avg_logprob": -0.09623771974410134, "compression_ratio": 1.680952380952381, "no_speech_prob": 0.0036459483671933413}, {"id": 192, "seek": 113240, "start": 1146.0800000000002, "end": 1151.68, "text": " API microservices. And I really like that part because this is not just, oh, yo, this failed,", "tokens": [51048, 9362, 15547, 47480, 13, 400, 286, 534, 411, 300, 644, 570, 341, 307, 406, 445, 11, 1954, 11, 5290, 11, 341, 7612, 11, 51328], "temperature": 0.0, "avg_logprob": -0.09623771974410134, "compression_ratio": 1.680952380952381, "no_speech_prob": 0.0036459483671933413}, {"id": 193, "seek": 113240, "start": 1152.4, "end": 1156.4, "text": " this is actually, this failed, here's exactly how, where, and what happened.", "tokens": [51364, 341, 307, 767, 11, 341, 7612, 11, 510, 311, 2293, 577, 11, 689, 11, 293, 437, 2011, 13, 51564], "temperature": 0.0, "avg_logprob": -0.09623771974410134, "compression_ratio": 1.680952380952381, "no_speech_prob": 0.0036459483671933413}, {"id": 194, "seek": 115640, "start": 1156.4, "end": 1163.68, "text": " And with that, we're actually getting to a stage where we're validating our production, but we're", "tokens": [50364, 400, 365, 300, 11, 321, 434, 767, 1242, 281, 257, 3233, 689, 321, 434, 7363, 990, 527, 4265, 11, 457, 321, 434, 50728], "temperature": 0.0, "avg_logprob": -0.09874032853959917, "compression_ratio": 1.7806691449814127, "no_speech_prob": 0.003943752031773329}, {"id": 195, "seek": 115640, "start": 1163.68, "end": 1169.92, "text": " also using that effort we put into our production reliability to validate pre-production as well.", "tokens": [50728, 611, 1228, 300, 4630, 321, 829, 666, 527, 4265, 24550, 281, 29562, 659, 12, 40827, 382, 731, 13, 51040], "temperature": 0.0, "avg_logprob": -0.09874032853959917, "compression_ratio": 1.7806691449814127, "no_speech_prob": 0.003943752031773329}, {"id": 196, "seek": 115640, "start": 1169.92, "end": 1175.68, "text": " So you're basically getting the exact same overview graph that Sonya just showed you, but", "tokens": [51040, 407, 291, 434, 1936, 1242, 264, 1900, 912, 12492, 4295, 300, 13575, 64, 445, 4712, 291, 11, 457, 51328], "temperature": 0.0, "avg_logprob": -0.09874032853959917, "compression_ratio": 1.7806691449814127, "no_speech_prob": 0.003943752031773329}, {"id": 197, "seek": 115640, "start": 1175.68, "end": 1180.5600000000002, "text": " instead of using your end users, you're running tests with trace test against the API Gateway", "tokens": [51328, 2602, 295, 1228, 428, 917, 5022, 11, 291, 434, 2614, 6921, 365, 13508, 1500, 1970, 264, 9362, 48394, 51572], "temperature": 0.0, "avg_logprob": -0.09874032853959917, "compression_ratio": 1.7806691449814127, "no_speech_prob": 0.003943752031773329}, {"id": 198, "seek": 115640, "start": 1180.5600000000002, "end": 1186.0, "text": " platform, then you're getting the traces back from your Yeager or Grafana or whatever you're using,", "tokens": [51572, 3663, 11, 550, 291, 434, 1242, 264, 26076, 646, 490, 428, 835, 3557, 420, 8985, 69, 2095, 420, 2035, 291, 434, 1228, 11, 51844], "temperature": 0.0, "avg_logprob": -0.09874032853959917, "compression_ratio": 1.7806691449814127, "no_speech_prob": 0.003943752031773329}, {"id": 199, "seek": 118600, "start": 1186.08, "end": 1193.12, "text": " and then that info goes back to the API developer that can then fix the issues that were found.", "tokens": [50368, 293, 550, 300, 13614, 1709, 646, 281, 264, 9362, 10754, 300, 393, 550, 3191, 264, 2663, 300, 645, 1352, 13, 50720], "temperature": 0.0, "avg_logprob": -0.07968763623918806, "compression_ratio": 1.7338403041825095, "no_speech_prob": 0.0005610726657323539}, {"id": 200, "seek": 118600, "start": 1194.8, "end": 1200.8, "text": " Now, with this, I'm just going to wrap up everything that we learned from this last section,", "tokens": [50804, 823, 11, 365, 341, 11, 286, 478, 445, 516, 281, 7019, 493, 1203, 300, 321, 3264, 490, 341, 1036, 3541, 11, 51104], "temperature": 0.0, "avg_logprob": -0.07968763623918806, "compression_ratio": 1.7338403041825095, "no_speech_prob": 0.0005610726657323539}, {"id": 201, "seek": 118600, "start": 1200.8, "end": 1205.12, "text": " which is that we got functional testing and we got performance testing. So you can both", "tokens": [51104, 597, 307, 300, 321, 658, 11745, 4997, 293, 321, 658, 3389, 4997, 13, 407, 291, 393, 1293, 51320], "temperature": 0.0, "avg_logprob": -0.07968763623918806, "compression_ratio": 1.7338403041825095, "no_speech_prob": 0.0005610726657323539}, {"id": 202, "seek": 118600, "start": 1205.68, "end": 1210.4, "text": " validate your behavior, or actually the behavior of your system, so all upstream and downstream", "tokens": [51348, 29562, 428, 5223, 11, 420, 767, 264, 5223, 295, 428, 1185, 11, 370, 439, 33915, 293, 30621, 51584], "temperature": 0.0, "avg_logprob": -0.07968763623918806, "compression_ratio": 1.7338403041825095, "no_speech_prob": 0.0005610726657323539}, {"id": 203, "seek": 118600, "start": 1210.4, "end": 1215.68, "text": " services, API transactions, both the ones that you manage and don't manage, you can", "tokens": [51584, 3328, 11, 9362, 16856, 11, 1293, 264, 2306, 300, 291, 3067, 293, 500, 380, 3067, 11, 291, 393, 51848], "temperature": 0.0, "avg_logprob": -0.07968763623918806, "compression_ratio": 1.7338403041825095, "no_speech_prob": 0.0005610726657323539}, {"id": 204, "seek": 121568, "start": 1215.76, "end": 1221.68, "text": " actually test database performance, you can test cache, you can also test the size of an HTTP", "tokens": [50368, 767, 1500, 8149, 3389, 11, 291, 393, 1500, 19459, 11, 291, 393, 611, 1500, 264, 2744, 295, 364, 33283, 50664], "temperature": 0.0, "avg_logprob": -0.07683200329805898, "compression_ratio": 1.7158671586715868, "no_speech_prob": 0.0033720016945153475}, {"id": 205, "seek": 121568, "start": 1221.68, "end": 1226.16, "text": " response and request, but you can also do very intricate performance testing by validating", "tokens": [50664, 4134, 293, 5308, 11, 457, 291, 393, 611, 360, 588, 38015, 3389, 4997, 538, 7363, 990, 50888], "temperature": 0.0, "avg_logprob": -0.07683200329805898, "compression_ratio": 1.7158671586715868, "no_speech_prob": 0.0033720016945153475}, {"id": 206, "seek": 121568, "start": 1226.16, "end": 1233.6000000000001, "text": " the duration of every part of your API. And with that, I have a saying where I'm from. We say", "tokens": [50888, 264, 16365, 295, 633, 644, 295, 428, 9362, 13, 400, 365, 300, 11, 286, 362, 257, 1566, 689, 286, 478, 490, 13, 492, 584, 51260], "temperature": 0.0, "avg_logprob": -0.07683200329805898, "compression_ratio": 1.7158671586715868, "no_speech_prob": 0.0033720016945153475}, {"id": 207, "seek": 121568, "start": 1234.96, "end": 1239.04, "text": " you're swatting two flies with one swing because I think that's more friendly than killing birds", "tokens": [51328, 291, 434, 1693, 267, 783, 732, 17414, 365, 472, 11173, 570, 286, 519, 300, 311, 544, 9208, 813, 8011, 9009, 51532], "temperature": 0.0, "avg_logprob": -0.07683200329805898, "compression_ratio": 1.7158671586715868, "no_speech_prob": 0.0033720016945153475}, {"id": 208, "seek": 121568, "start": 1239.04, "end": 1244.64, "text": " with stones. So yeah, with that, I think that this is the closest we can get to be bounty", "tokens": [51532, 365, 14083, 13, 407, 1338, 11, 365, 300, 11, 286, 519, 300, 341, 307, 264, 13699, 321, 393, 483, 281, 312, 40773, 51812], "temperature": 0.0, "avg_logprob": -0.07683200329805898, "compression_ratio": 1.7158671586715868, "no_speech_prob": 0.0033720016945153475}, {"id": 209, "seek": 124464, "start": 1244.64, "end": 1251.3600000000001, "text": " hunters because we're bug hunters. That was very lame. Anyway, so that's a CU space cowboy reference", "tokens": [50364, 29509, 570, 321, 434, 7426, 29509, 13, 663, 390, 588, 27635, 13, 5684, 11, 370, 300, 311, 257, 29777, 1901, 39174, 6408, 50700], "temperature": 0.0, "avg_logprob": -0.15721097038787546, "compression_ratio": 1.613821138211382, "no_speech_prob": 0.02013394609093666}, {"id": 210, "seek": 124464, "start": 1251.3600000000001, "end": 1262.88, "text": " if somebody can. Thank you for making this. So, and just before we close, I want to say if this is", "tokens": [50700, 498, 2618, 393, 13, 1044, 291, 337, 1455, 341, 13, 407, 11, 293, 445, 949, 321, 1998, 11, 286, 528, 281, 584, 498, 341, 307, 51276], "temperature": 0.0, "avg_logprob": -0.15721097038787546, "compression_ratio": 1.613821138211382, "no_speech_prob": 0.02013394609093666}, {"id": 211, "seek": 124464, "start": 1262.88, "end": 1267.8400000000001, "text": " a topic that's interesting for you, we're running an online API observability conference in February.", "tokens": [51276, 257, 4829, 300, 311, 1880, 337, 291, 11, 321, 434, 2614, 364, 2950, 9362, 9951, 2310, 7586, 294, 8711, 13, 51524], "temperature": 0.0, "avg_logprob": -0.15721097038787546, "compression_ratio": 1.613821138211382, "no_speech_prob": 0.02013394609093666}, {"id": 212, "seek": 124464, "start": 1267.8400000000001, "end": 1272.0800000000002, "text": " It's going to be called LEAP because it's going to be on the LEAP there. So if that's the topic", "tokens": [51524, 467, 311, 516, 281, 312, 1219, 11378, 4715, 570, 309, 311, 516, 281, 312, 322, 264, 11378, 4715, 456, 13, 407, 498, 300, 311, 264, 4829, 51736], "temperature": 0.0, "avg_logprob": -0.15721097038787546, "compression_ratio": 1.613821138211382, "no_speech_prob": 0.02013394609093666}, {"id": 213, "seek": 127208, "start": 1272.08, "end": 1276.32, "text": " that's interesting to you, make sure to register. We have lots of people from the API space and", "tokens": [50364, 300, 311, 1880, 281, 291, 11, 652, 988, 281, 7280, 13, 492, 362, 3195, 295, 561, 490, 264, 9362, 1901, 293, 50576], "temperature": 0.0, "avg_logprob": -0.08580433937811083, "compression_ratio": 1.685121107266436, "no_speech_prob": 0.008183570578694344}, {"id": 214, "seek": 127208, "start": 1276.32, "end": 1281.9199999999998, "text": " observability space that will be coming. We also have a GitHub project about all the screenshot", "tokens": [50576, 9951, 2310, 1901, 300, 486, 312, 1348, 13, 492, 611, 362, 257, 23331, 1716, 466, 439, 264, 27712, 50856], "temperature": 0.0, "avg_logprob": -0.08580433937811083, "compression_ratio": 1.685121107266436, "no_speech_prob": 0.008183570578694344}, {"id": 215, "seek": 127208, "start": 1281.9199999999998, "end": 1286.8, "text": " that we showed to you today. We were working on it as a GitHub example. We don't have a link for", "tokens": [50856, 300, 321, 4712, 281, 291, 965, 13, 492, 645, 1364, 322, 309, 382, 257, 23331, 1365, 13, 492, 500, 380, 362, 257, 2113, 337, 51100], "temperature": 0.0, "avg_logprob": -0.08580433937811083, "compression_ratio": 1.685121107266436, "no_speech_prob": 0.008183570578694344}, {"id": 216, "seek": 127208, "start": 1286.8, "end": 1293.9199999999998, "text": " it, but if you're interested, just reach out to us. Those are LinkedIn. Yeah, I don't like Twitter", "tokens": [51100, 309, 11, 457, 498, 291, 434, 3102, 11, 445, 2524, 484, 281, 505, 13, 3950, 366, 20657, 13, 865, 11, 286, 500, 380, 411, 5794, 51456], "temperature": 0.0, "avg_logprob": -0.08580433937811083, "compression_ratio": 1.685121107266436, "no_speech_prob": 0.008183570578694344}, {"id": 217, "seek": 127208, "start": 1293.9199999999998, "end": 1300.48, "text": " anymore. So make sure to send a connect and we're happy to send you a link to a GitHub project. You", "tokens": [51456, 3602, 13, 407, 652, 988, 281, 2845, 257, 1745, 293, 321, 434, 2055, 281, 2845, 291, 257, 2113, 281, 257, 23331, 1716, 13, 509, 51784], "temperature": 0.0, "avg_logprob": -0.08580433937811083, "compression_ratio": 1.685121107266436, "no_speech_prob": 0.008183570578694344}, {"id": 218, "seek": 130048, "start": 1300.48, "end": 1305.68, "text": " can try it all by yourself at this combination of open source projects. Thank you so much.", "tokens": [50364, 393, 853, 309, 439, 538, 1803, 412, 341, 6562, 295, 1269, 4009, 4455, 13, 1044, 291, 370, 709, 13, 50624], "temperature": 0.0, "avg_logprob": -0.2666020592053731, "compression_ratio": 1.4427480916030535, "no_speech_prob": 0.026768524199724197}, {"id": 219, "seek": 130048, "start": 1317.84, "end": 1320.96, "text": " So we have some time for questions. Yeah, there is one over there.", "tokens": [51232, 407, 321, 362, 512, 565, 337, 1651, 13, 865, 11, 456, 307, 472, 670, 456, 13, 51388], "temperature": 0.0, "avg_logprob": -0.2666020592053731, "compression_ratio": 1.4427480916030535, "no_speech_prob": 0.026768524199724197}, {"id": 220, "seek": 130048, "start": 1323.3600000000001, "end": 1324.64, "text": " Questions down. Questions down.", "tokens": [51508, 27738, 760, 13, 27738, 760, 13, 51572], "temperature": 0.0, "avg_logprob": -0.2666020592053731, "compression_ratio": 1.4427480916030535, "no_speech_prob": 0.026768524199724197}, {"id": 221, "seek": 133048, "start": 1330.48, "end": 1332.64, "text": " Go ahead with one customer. Yeah.", "tokens": [50368, 1037, 2286, 365, 472, 5474, 13, 865, 13, 50472], "temperature": 0.4, "avg_logprob": -0.699450362812389, "compression_ratio": 0.8048780487804879, "no_speech_prob": 0.5135059356689453}, {"id": 222, "seek": 136048, "start": 1360.48, "end": 1378.32, "text": " Okay, so the question is, I have to repeat for the video, the question is, if I have a service that", "tokens": [50364, 1033, 11, 370, 264, 1168, 307, 11, 286, 362, 281, 7149, 337, 264, 960, 11, 264, 1168, 307, 11, 498, 286, 362, 257, 2643, 300, 51256], "temperature": 0.0, "avg_logprob": -0.21095720926920572, "compression_ratio": 1.4924242424242424, "no_speech_prob": 0.04277624562382698}, {"id": 223, "seek": 136048, "start": 1379.1200000000001, "end": 1384.96, "text": " can be accessed by multiple customers, do I want to have one to send the data to different places", "tokens": [51296, 393, 312, 34211, 538, 3866, 4581, 11, 360, 286, 528, 281, 362, 472, 281, 2845, 264, 1412, 281, 819, 3190, 51588], "temperature": 0.0, "avg_logprob": -0.21095720926920572, "compression_ratio": 1.4924242424242424, "no_speech_prob": 0.04277624562382698}, {"id": 224, "seek": 138496, "start": 1384.96, "end": 1390.24, "text": " so to split them out or do I want to have just one year, one open telemetry? And as always,", "tokens": [50364, 370, 281, 7472, 552, 484, 420, 360, 286, 528, 281, 362, 445, 472, 1064, 11, 472, 1269, 4304, 5537, 627, 30, 400, 382, 1009, 11, 50628], "temperature": 0.0, "avg_logprob": -0.19947486088193697, "compression_ratio": 1.7244897959183674, "no_speech_prob": 0.05418805032968521}, {"id": 225, "seek": 138496, "start": 1390.24, "end": 1396.0, "text": " it depends. And on what does it depend? It depends on do you want to give access to those data to", "tokens": [50628, 309, 5946, 13, 400, 322, 437, 775, 309, 5672, 30, 467, 5946, 322, 360, 291, 528, 281, 976, 2105, 281, 729, 1412, 281, 50916], "temperature": 0.0, "avg_logprob": -0.19947486088193697, "compression_ratio": 1.7244897959183674, "no_speech_prob": 0.05418805032968521}, {"id": 226, "seek": 138496, "start": 1396.0, "end": 1401.04, "text": " your customers somewhere? Do you want to have strict regulation on the data of your customer", "tokens": [50916, 428, 4581, 4079, 30, 1144, 291, 528, 281, 362, 10910, 15062, 322, 264, 1412, 295, 428, 5474, 51168], "temperature": 0.0, "avg_logprob": -0.19947486088193697, "compression_ratio": 1.7244897959183674, "no_speech_prob": 0.05418805032968521}, {"id": 227, "seek": 138496, "start": 1401.04, "end": 1404.4, "text": " where you may need to split them by location? But yeah.", "tokens": [51168, 689, 291, 815, 643, 281, 7472, 552, 538, 4914, 30, 583, 1338, 13, 51336], "temperature": 0.0, "avg_logprob": -0.19947486088193697, "compression_ratio": 1.7244897959183674, "no_speech_prob": 0.05418805032968521}, {"id": 228, "seek": 141496, "start": 1414.96, "end": 1420.24, "text": " Yeah, yeah.", "tokens": [50364, 865, 11, 1338, 13, 50628], "temperature": 0.0, "avg_logprob": -0.2970495333616761, "compression_ratio": 1.723756906077348, "no_speech_prob": 0.03389744088053703}, {"id": 229, "seek": 141496, "start": 1424.08, "end": 1424.32, "text": " Yeah.", "tokens": [50820, 865, 13, 50832], "temperature": 0.0, "avg_logprob": -0.2970495333616761, "compression_ratio": 1.723756906077348, "no_speech_prob": 0.03389744088053703}, {"id": 230, "seek": 141496, "start": 1426.4, "end": 1430.96, "text": " Yeah, that's a very, very, very good question. So the question is, how do I monitor the service", "tokens": [50936, 865, 11, 300, 311, 257, 588, 11, 588, 11, 588, 665, 1168, 13, 407, 264, 1168, 307, 11, 577, 360, 286, 6002, 264, 2643, 51164], "temperature": 0.0, "avg_logprob": -0.2970495333616761, "compression_ratio": 1.723756906077348, "no_speech_prob": 0.03389744088053703}, {"id": 231, "seek": 141496, "start": 1430.96, "end": 1436.24, "text": " level for every customer? So typically you have for every customer, they have, they are authenticated.", "tokens": [51164, 1496, 337, 633, 5474, 30, 407, 5850, 291, 362, 337, 633, 5474, 11, 436, 362, 11, 436, 366, 9214, 3587, 13, 51428], "temperature": 0.0, "avg_logprob": -0.2970495333616761, "compression_ratio": 1.723756906077348, "no_speech_prob": 0.03389744088053703}, {"id": 232, "seek": 141496, "start": 1436.24, "end": 1441.92, "text": " So you have maybe something like a token. Yeah, yeah, but in production, yeah, yeah. So they're", "tokens": [51428, 407, 291, 362, 1310, 746, 411, 257, 14862, 13, 865, 11, 1338, 11, 457, 294, 4265, 11, 1338, 11, 1338, 13, 407, 436, 434, 51712], "temperature": 0.0, "avg_logprob": -0.2970495333616761, "compression_ratio": 1.723756906077348, "no_speech_prob": 0.03389744088053703}, {"id": 233, "seek": 144192, "start": 1441.92, "end": 1448.0800000000002, "text": " authenticated. So when they come to you, you can put a tag on an information on the trace,", "tokens": [50364, 9214, 3587, 13, 407, 562, 436, 808, 281, 291, 11, 291, 393, 829, 257, 6162, 322, 364, 1589, 322, 264, 13508, 11, 50672], "temperature": 0.0, "avg_logprob": -0.21764852486404718, "compression_ratio": 1.7207207207207207, "no_speech_prob": 0.02780533768236637}, {"id": 234, "seek": 144192, "start": 1448.0800000000002, "end": 1452.16, "text": " and tag will do it automatically if you're using the authorization or authentication from", "tokens": [50672, 293, 6162, 486, 360, 309, 6772, 498, 291, 434, 1228, 264, 33697, 420, 26643, 490, 50876], "temperature": 0.0, "avg_logprob": -0.21764852486404718, "compression_ratio": 1.7207207207207207, "no_speech_prob": 0.02780533768236637}, {"id": 235, "seek": 144192, "start": 1452.16, "end": 1460.72, "text": " tag, tag. The API, yeah, it's tag. Tag. Yeah, no worry. And so on the traces, we put the information", "tokens": [50876, 6162, 11, 6162, 13, 440, 9362, 11, 1338, 11, 309, 311, 6162, 13, 11204, 13, 865, 11, 572, 3292, 13, 400, 370, 322, 264, 26076, 11, 321, 829, 264, 1589, 51304], "temperature": 0.0, "avg_logprob": -0.21764852486404718, "compression_ratio": 1.7207207207207207, "no_speech_prob": 0.02780533768236637}, {"id": 236, "seek": 144192, "start": 1460.72, "end": 1466.96, "text": " on who is going to API. And with open telemetry, you can then use the data to create your own report", "tokens": [51304, 322, 567, 307, 516, 281, 9362, 13, 400, 365, 1269, 4304, 5537, 627, 11, 291, 393, 550, 764, 264, 1412, 281, 1884, 428, 1065, 2275, 51616], "temperature": 0.0, "avg_logprob": -0.21764852486404718, "compression_ratio": 1.7207207207207207, "no_speech_prob": 0.02780533768236637}, {"id": 237, "seek": 146696, "start": 1466.96, "end": 1473.1200000000001, "text": " based on that information. Yeah. So we add that information on the API call so that you can reuse", "tokens": [50364, 2361, 322, 300, 1589, 13, 865, 13, 407, 321, 909, 300, 1589, 322, 264, 9362, 818, 370, 300, 291, 393, 26225, 50672], "temperature": 0.0, "avg_logprob": -0.11648253772569739, "compression_ratio": 1.7035398230088497, "no_speech_prob": 0.025099778547883034}, {"id": 238, "seek": 146696, "start": 1473.1200000000001, "end": 1480.4, "text": " it for your report. Yeah, it's directly exposed. Yeah. That's a very good question. It's really", "tokens": [50672, 309, 337, 428, 2275, 13, 865, 11, 309, 311, 3838, 9495, 13, 865, 13, 663, 311, 257, 588, 665, 1168, 13, 467, 311, 534, 51036], "temperature": 0.0, "avg_logprob": -0.11648253772569739, "compression_ratio": 1.7035398230088497, "no_speech_prob": 0.025099778547883034}, {"id": 239, "seek": 146696, "start": 1480.4, "end": 1486.0, "text": " important to monitor per customers because you want to, some customers have different usage,", "tokens": [51036, 1021, 281, 6002, 680, 4581, 570, 291, 528, 281, 11, 512, 4581, 362, 819, 14924, 11, 51316], "temperature": 0.0, "avg_logprob": -0.11648253772569739, "compression_ratio": 1.7035398230088497, "no_speech_prob": 0.025099778547883034}, {"id": 240, "seek": 146696, "start": 1486.0, "end": 1491.2, "text": " different patterns, and you want to make sure that every one of them is happy and not just like an", "tokens": [51316, 819, 8294, 11, 293, 291, 528, 281, 652, 988, 300, 633, 472, 295, 552, 307, 2055, 293, 406, 445, 411, 364, 51576], "temperature": 0.0, "avg_logprob": -0.11648253772569739, "compression_ratio": 1.7035398230088497, "no_speech_prob": 0.025099778547883034}, {"id": 241, "seek": 149120, "start": 1491.2, "end": 1493.6000000000001, "text": " average where you don't really understand whether problems.", "tokens": [50364, 4274, 689, 291, 500, 380, 534, 1223, 1968, 2740, 13, 50484], "temperature": 0.0, "avg_logprob": -0.18491135634385147, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.009633511304855347}, {"id": 242, "seek": 149120, "start": 1504.96, "end": 1507.6000000000001, "text": " Also, the question is whether Trace Test notifies on errors.", "tokens": [51052, 2743, 11, 264, 1168, 307, 1968, 1765, 617, 9279, 406, 11221, 322, 13603, 13, 51184], "temperature": 0.0, "avg_logprob": -0.18491135634385147, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.009633511304855347}, {"id": 243, "seek": 149120, "start": 1509.8400000000001, "end": 1515.04, "text": " No, Trace Test is just a testing tool. You would then need something to automate the test,", "tokens": [51296, 883, 11, 1765, 617, 9279, 307, 445, 257, 4997, 2290, 13, 509, 576, 550, 643, 746, 281, 31605, 264, 1500, 11, 51556], "temperature": 0.0, "avg_logprob": -0.18491135634385147, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.009633511304855347}, {"id": 244, "seek": 149120, "start": 1515.04, "end": 1519.8400000000001, "text": " like Argo, and then you need something to alert on failures as well. And then you can pick the", "tokens": [51556, 411, 1587, 1571, 11, 293, 550, 291, 643, 746, 281, 9615, 322, 20774, 382, 731, 13, 400, 550, 291, 393, 1888, 264, 51796], "temperature": 0.0, "avg_logprob": -0.18491135634385147, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.009633511304855347}, {"id": 245, "seek": 151984, "start": 1519.84, "end": 1525.4399999999998, "text": " alerting tool that you want. Whatever you're using right now, you can automate within your CI,", "tokens": [50364, 419, 27187, 2290, 300, 291, 528, 13, 8541, 291, 434, 1228, 558, 586, 11, 291, 393, 31605, 1951, 428, 37777, 11, 50644], "temperature": 0.0, "avg_logprob": -0.1685050885701917, "compression_ratio": 1.8047619047619048, "no_speech_prob": 0.004793678410351276}, {"id": 246, "seek": 151984, "start": 1525.4399999999998, "end": 1530.8799999999999, "text": " so you can build your CI within Argo or within whatever you can use Tecton. You can do basically", "tokens": [50644, 370, 291, 393, 1322, 428, 37777, 1951, 1587, 1571, 420, 1951, 2035, 291, 393, 764, 314, 557, 266, 13, 509, 393, 360, 1936, 50916], "temperature": 0.0, "avg_logprob": -0.1685050885701917, "compression_ratio": 1.8047619047619048, "no_speech_prob": 0.004793678410351276}, {"id": 247, "seek": 151984, "start": 1530.8799999999999, "end": 1536.72, "text": " whatever CI tool you're using, and then you're sending errors on that. So think just integration", "tokens": [50916, 2035, 37777, 2290, 291, 434, 1228, 11, 293, 550, 291, 434, 7750, 13603, 322, 300, 13, 407, 519, 445, 10980, 51208], "temperature": 0.0, "avg_logprob": -0.1685050885701917, "compression_ratio": 1.8047619047619048, "no_speech_prob": 0.004793678410351276}, {"id": 248, "seek": 151984, "start": 1536.72, "end": 1540.9599999999998, "text": " testing. You just get works, doesn't work, then you do whatever else you want to do. Yeah.", "tokens": [51208, 4997, 13, 509, 445, 483, 1985, 11, 1177, 380, 589, 11, 550, 291, 360, 2035, 1646, 291, 528, 281, 360, 13, 865, 13, 51420], "temperature": 0.0, "avg_logprob": -0.1685050885701917, "compression_ratio": 1.8047619047619048, "no_speech_prob": 0.004793678410351276}, {"id": 249, "seek": 154096, "start": 1541.44, "end": 1543.6000000000001, "text": " Yeah. Another question.", "tokens": [50388, 865, 13, 3996, 1168, 13, 50496], "temperature": 0.0, "avg_logprob": -0.32155150175094604, "compression_ratio": 1.310077519379845, "no_speech_prob": 0.011813251301646233}, {"id": 250, "seek": 154096, "start": 1555.6000000000001, "end": 1559.6000000000001, "text": " Observability data for APS, I can take that one. So,", "tokens": [51096, 42547, 2310, 1412, 337, 5372, 50, 11, 286, 393, 747, 300, 472, 13, 407, 11, 51296], "temperature": 0.0, "avg_logprob": -0.32155150175094604, "compression_ratio": 1.310077519379845, "no_speech_prob": 0.011813251301646233}, {"id": 251, "seek": 154096, "start": 1562.08, "end": 1567.44, "text": " yeah, so the question is how do you deal with data privacy? And because in the observability", "tokens": [51420, 1338, 11, 370, 264, 1168, 307, 577, 360, 291, 2028, 365, 1412, 11427, 30, 400, 570, 294, 264, 9951, 2310, 51688], "temperature": 0.0, "avg_logprob": -0.32155150175094604, "compression_ratio": 1.310077519379845, "no_speech_prob": 0.011813251301646233}, {"id": 252, "seek": 156744, "start": 1567.44, "end": 1572.88, "text": " data, they can land a lot that could be considered privacy data. So first, you have to be very", "tokens": [50364, 1412, 11, 436, 393, 2117, 257, 688, 300, 727, 312, 4888, 11427, 1412, 13, 407, 700, 11, 291, 362, 281, 312, 588, 50636], "temperature": 0.0, "avg_logprob": -0.15017157695332511, "compression_ratio": 1.7445255474452555, "no_speech_prob": 0.027668975293636322}, {"id": 253, "seek": 156744, "start": 1572.88, "end": 1577.3600000000001, "text": " aware of that, that observability data could potentially have some data that in your country,", "tokens": [50636, 3650, 295, 300, 11, 300, 9951, 2310, 1412, 727, 7263, 362, 512, 1412, 300, 294, 428, 1941, 11, 50860], "temperature": 0.0, "avg_logprob": -0.15017157695332511, "compression_ratio": 1.7445255474452555, "no_speech_prob": 0.027668975293636322}, {"id": 254, "seek": 156744, "start": 1577.3600000000001, "end": 1583.1200000000001, "text": " in your own regulation could have some impact. OpenTelemetry has a lot of tool for that. In the", "tokens": [50860, 294, 428, 1065, 15062, 727, 362, 512, 2712, 13, 7238, 14233, 306, 5537, 627, 575, 257, 688, 295, 2290, 337, 300, 13, 682, 264, 51148], "temperature": 0.0, "avg_logprob": -0.15017157695332511, "compression_ratio": 1.7445255474452555, "no_speech_prob": 0.027668975293636322}, {"id": 255, "seek": 156744, "start": 1583.1200000000001, "end": 1588.0800000000002, "text": " OpenTelemetry collector, there are kind of plugins that you can define using Yamal and say,", "tokens": [51148, 7238, 14233, 306, 5537, 627, 23960, 11, 456, 366, 733, 295, 33759, 300, 291, 393, 6964, 1228, 18992, 304, 293, 584, 11, 51396], "temperature": 0.0, "avg_logprob": -0.15017157695332511, "compression_ratio": 1.7445255474452555, "no_speech_prob": 0.027668975293636322}, {"id": 256, "seek": 156744, "start": 1588.0800000000002, "end": 1594.3200000000002, "text": " that arguments, that thing I want to filter out, I don't want to register it. So you're very flexible", "tokens": [51396, 300, 12869, 11, 300, 551, 286, 528, 281, 6608, 484, 11, 286, 500, 380, 528, 281, 7280, 309, 13, 407, 291, 434, 588, 11358, 51708], "temperature": 0.0, "avg_logprob": -0.15017157695332511, "compression_ratio": 1.7445255474452555, "no_speech_prob": 0.027668975293636322}, {"id": 257, "seek": 159432, "start": 1594.32, "end": 1598.08, "text": " in your observability pipeline, but that's something that you have to take care of to make", "tokens": [50364, 294, 428, 9951, 2310, 15517, 11, 457, 300, 311, 746, 300, 291, 362, 281, 747, 1127, 295, 281, 652, 50552], "temperature": 0.0, "avg_logprob": -0.22364444732666017, "compression_ratio": 1.511111111111111, "no_speech_prob": 0.035456474870443344}, {"id": 258, "seek": 159432, "start": 1598.08, "end": 1601.84, "text": " sure that your developers haven't added something that you don't want to store.", "tokens": [50552, 988, 300, 428, 8849, 2378, 380, 3869, 746, 300, 291, 500, 380, 528, 281, 3531, 13, 50740], "temperature": 0.0, "avg_logprob": -0.22364444732666017, "compression_ratio": 1.511111111111111, "no_speech_prob": 0.035456474870443344}, {"id": 259, "seek": 159432, "start": 1604.56, "end": 1606.6399999999999, "text": " Sorry. I'll go for it. Go for it.", "tokens": [50876, 4919, 13, 286, 603, 352, 337, 309, 13, 1037, 337, 309, 13, 50980], "temperature": 0.0, "avg_logprob": -0.22364444732666017, "compression_ratio": 1.511111111111111, "no_speech_prob": 0.035456474870443344}, {"id": 260, "seek": 160664, "start": 1606.8000000000002, "end": 1618.96, "text": " Jack, when I use the data to send the data to the OpenTelemetry, this data is made only on HB8.", "tokens": [50372, 4718, 11, 562, 286, 764, 264, 1412, 281, 2845, 264, 1412, 281, 264, 7238, 14233, 306, 5537, 627, 11, 341, 1412, 307, 1027, 787, 322, 389, 33, 23, 13, 50980], "temperature": 0.0, "avg_logprob": -0.7646356640440045, "compression_ratio": 1.1728395061728396, "no_speech_prob": 0.5420747399330139}, {"id": 261, "seek": 161896, "start": 1619.92, "end": 1631.3600000000001, "text": " HB8, the status only. So like a 100, 500 message, the status of the response of the", "tokens": [50412, 389, 33, 23, 11, 264, 6558, 787, 13, 407, 411, 257, 2319, 11, 5923, 3636, 11, 264, 6558, 295, 264, 4134, 295, 264, 50984], "temperature": 0.0, "avg_logprob": -0.5877921435297752, "compression_ratio": 1.4173913043478261, "no_speech_prob": 0.17690281569957733}, {"id": 262, "seek": 161896, "start": 1632.64, "end": 1643.44, "text": " HB8 request. Yes. All on another way is to analyze the response of the request.", "tokens": [51048, 389, 33, 23, 5308, 13, 1079, 13, 1057, 322, 1071, 636, 307, 281, 12477, 264, 4134, 295, 264, 5308, 13, 51588], "temperature": 0.0, "avg_logprob": -0.5877921435297752, "compression_ratio": 1.4173913043478261, "no_speech_prob": 0.17690281569957733}, {"id": 263, "seek": 164344, "start": 1643.44, "end": 1649.92, "text": " So the question is, what do we track or what kind of data do we expose with tech?", "tokens": [50392, 407, 264, 1168, 307, 11, 437, 360, 321, 2837, 420, 437, 733, 295, 1412, 360, 321, 19219, 365, 7553, 30, 50688], "temperature": 0.0, "avg_logprob": -0.2094740452973739, "compression_ratio": 1.08, "no_speech_prob": 0.06154896318912506}, {"id": 264, "seek": 167344, "start": 1674.0800000000002, "end": 1689.52, "text": " So, yeah, so in tag the gateway, when it's being called, you will get the answer, but the traces,", "tokens": [50396, 407, 11, 1338, 11, 370, 294, 6162, 264, 28532, 11, 562, 309, 311, 885, 1219, 11, 291, 486, 483, 264, 1867, 11, 457, 264, 26076, 11, 51168], "temperature": 0.0, "avg_logprob": -0.24049285695522646, "compression_ratio": 1.548913043478261, "no_speech_prob": 0.01268835924565792}, {"id": 265, "seek": 167344, "start": 1689.52, "end": 1694.48, "text": " it will export using OpenTelemetry will contain all the data, all the steps, the traces that we", "tokens": [51168, 309, 486, 10725, 1228, 7238, 14233, 306, 5537, 627, 486, 5304, 439, 264, 1412, 11, 439, 264, 4439, 11, 264, 26076, 300, 321, 51416], "temperature": 0.0, "avg_logprob": -0.24049285695522646, "compression_ratio": 1.548913043478261, "no_speech_prob": 0.01268835924565792}, {"id": 266, "seek": 167344, "start": 1694.48, "end": 1699.44, "text": " saw in Yeager. And you can also extend them. So we have a plugin mechanism where you could,", "tokens": [51416, 1866, 294, 835, 3557, 13, 400, 291, 393, 611, 10101, 552, 13, 407, 321, 362, 257, 23407, 7513, 689, 291, 727, 11, 51664], "temperature": 0.0, "avg_logprob": -0.24049285695522646, "compression_ratio": 1.548913043478261, "no_speech_prob": 0.01268835924565792}, {"id": 267, "seek": 169944, "start": 1699.44, "end": 1704.8, "text": " that you could load into there and add even more data if that's more open, extend your OpenTelemetry", "tokens": [50364, 300, 291, 727, 3677, 666, 456, 293, 909, 754, 544, 1412, 498, 300, 311, 544, 1269, 11, 10101, 428, 7238, 14233, 306, 5537, 627, 50632], "temperature": 0.0, "avg_logprob": -0.19242660120913857, "compression_ratio": 1.617391304347826, "no_speech_prob": 0.006504418328404427}, {"id": 268, "seek": 169944, "start": 1704.8, "end": 1718.48, "text": " traces. The question is, where is the effort? So tech make it easier for you because it captured", "tokens": [50632, 26076, 13, 440, 1168, 307, 11, 689, 307, 264, 4630, 30, 407, 7553, 652, 309, 3571, 337, 291, 570, 309, 11828, 51316], "temperature": 0.0, "avg_logprob": -0.19242660120913857, "compression_ratio": 1.617391304347826, "no_speech_prob": 0.006504418328404427}, {"id": 269, "seek": 169944, "start": 1718.48, "end": 1723.52, "text": " the starts up to the call to the upstream service and it tell you how long it took.", "tokens": [51316, 264, 3719, 493, 281, 264, 818, 281, 264, 33915, 2643, 293, 309, 980, 291, 577, 938, 309, 1890, 13, 51568], "temperature": 0.0, "avg_logprob": -0.19242660120913857, "compression_ratio": 1.617391304347826, "no_speech_prob": 0.006504418328404427}, {"id": 270, "seek": 169944, "start": 1724.24, "end": 1728.4, "text": " And but if you want to get even more details, what happens after that, then it's where you", "tokens": [51604, 400, 457, 498, 291, 528, 281, 483, 754, 544, 4365, 11, 437, 2314, 934, 300, 11, 550, 309, 311, 689, 291, 51812], "temperature": 0.0, "avg_logprob": -0.19242660120913857, "compression_ratio": 1.617391304347826, "no_speech_prob": 0.006504418328404427}, {"id": 271, "seek": 172840, "start": 1728.4, "end": 1734.72, "text": " need to instrument your services using OpenTelemetry. And then the beauty of it is when all the services", "tokens": [50364, 643, 281, 7198, 428, 3328, 1228, 7238, 14233, 306, 5537, 627, 13, 400, 550, 264, 6643, 295, 309, 307, 562, 439, 264, 3328, 50680], "temperature": 0.0, "avg_logprob": -0.21889686584472656, "compression_ratio": 1.5707317073170732, "no_speech_prob": 0.017094949260354042}, {"id": 272, "seek": 172840, "start": 1734.72, "end": 1738.5600000000002, "text": " speak the same observability language, they all send the data to the same place,", "tokens": [50680, 1710, 264, 912, 9951, 2310, 2856, 11, 436, 439, 2845, 264, 1412, 281, 264, 912, 1081, 11, 50872], "temperature": 0.0, "avg_logprob": -0.21889686584472656, "compression_ratio": 1.5707317073170732, "no_speech_prob": 0.017094949260354042}, {"id": 273, "seek": 172840, "start": 1738.5600000000002, "end": 1743.76, "text": " then you have the full picture and that's kind of the operational dream. Thank you.", "tokens": [50872, 550, 291, 362, 264, 1577, 3036, 293, 300, 311, 733, 295, 264, 16607, 3055, 13, 1044, 291, 13, 51132], "temperature": 0.0, "avg_logprob": -0.21889686584472656, "compression_ratio": 1.5707317073170732, "no_speech_prob": 0.017094949260354042}, {"id": 274, "seek": 172840, "start": 1744.4, "end": 1748.72, "text": " Yeah. You suggest to run that on a trade production?", "tokens": [51164, 865, 13, 509, 3402, 281, 1190, 300, 322, 257, 4923, 4265, 30, 51380], "temperature": 0.0, "avg_logprob": -0.21889686584472656, "compression_ratio": 1.5707317073170732, "no_speech_prob": 0.017094949260354042}, {"id": 275, "seek": 174872, "start": 1748.72, "end": 1751.04, "text": " It's right.", "tokens": [50380, 467, 311, 558, 13, 50480], "temperature": 0.0, "avg_logprob": -0.9561937877110073, "compression_ratio": 0.5789473684210527, "no_speech_prob": 0.14706288278102875}, {"id": 276, "seek": 177872, "start": 1779.04, "end": 1792.4, "text": " Correct. Correct. So you wouldn't use trace this in this point of view for your production,", "tokens": [50380, 12753, 13, 12753, 13, 407, 291, 2759, 380, 764, 13508, 341, 294, 341, 935, 295, 1910, 337, 428, 4265, 11, 51048], "temperature": 0.0, "avg_logprob": -0.23036118628273547, "compression_ratio": 1.5113636363636365, "no_speech_prob": 0.030056023970246315}, {"id": 277, "seek": 177872, "start": 1792.4, "end": 1796.16, "text": " you would use it in pre production, where you need sampling to be at 100%.", "tokens": [51048, 291, 576, 764, 309, 294, 659, 4265, 11, 689, 291, 643, 21179, 281, 312, 412, 2319, 6856, 51236], "temperature": 0.0, "avg_logprob": -0.23036118628273547, "compression_ratio": 1.5113636363636365, "no_speech_prob": 0.030056023970246315}, {"id": 278, "seek": 177872, "start": 1800.32, "end": 1807.04, "text": " Yeah, yeah, we can also just stand. We'll just wait so you can come by and chat with us. So because", "tokens": [51444, 865, 11, 1338, 11, 321, 393, 611, 445, 1463, 13, 492, 603, 445, 1699, 370, 291, 393, 808, 538, 293, 5081, 365, 505, 13, 407, 570, 51780], "temperature": 0.0, "avg_logprob": -0.23036118628273547, "compression_ratio": 1.5113636363636365, "no_speech_prob": 0.030056023970246315}, {"id": 279, "seek": 180704, "start": 1807.12, "end": 1814.32, "text": " yeah, we don't have time. Don't follow up on questions. Yeah. So yeah, yeah, we'll be here. Come here. Yeah.", "tokens": [50368, 1338, 11, 321, 500, 380, 362, 565, 13, 1468, 380, 1524, 493, 322, 1651, 13, 865, 13, 407, 1338, 11, 1338, 11, 321, 603, 312, 510, 13, 2492, 510, 13, 865, 13, 50728], "temperature": 0.0, "avg_logprob": -0.3887362253098261, "compression_ratio": 1.2135922330097086, "no_speech_prob": 0.06870231032371521}, {"id": 280, "seek": 180704, "start": 1814.96, "end": 1816.96, "text": " Cool. Thank you.", "tokens": [50760, 8561, 13, 1044, 291, 13, 50860], "temperature": 0.0, "avg_logprob": -0.3887362253098261, "compression_ratio": 1.2135922330097086, "no_speech_prob": 0.06870231032371521}], "language": "en"}