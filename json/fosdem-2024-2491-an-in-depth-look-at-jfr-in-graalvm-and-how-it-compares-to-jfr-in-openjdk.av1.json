{"text": " Hi everyone, my name is Robert Swenaga and I work at Red Hat. Today I'll be talking a little bit about JDK Flight Recorder in Gravium Native Image. And from now on we'll just refer to JDK Flight Recorder as JFR. So as a high level breakdown, I broke in this presentation to two sections. The first section is a high level overview of JFR Native Image and then we'll go into a low level deep dive of JFR Native Image and talk about some comparisons between substrate VM and hotspot. And I want to make note that even if you're not interested in Gravium Native Image at all, you may still be interested in the second half of this presentation because the details of JFR are going to be talking about there extend beyond just native image and also apply to hotspot more generally as well. Okay, so as a very quick refresher, JFR is an event-based monitoring and profiling tool. It's built directly into the JDK and it can give you some really valuable insights into what your application is doing both at a high level and also at the VM level. Okay, so Phoebus already talked about this a little bit, but Gravium Native Image is essentially a technology that allows you to convert your Java applications into binary executables. The appeal of this is you get much faster startup and use less resources and a big reason for that is you don't have to warm up your traditional JVM alongside your application code. And how it works is you compile your Java application to bytecode like you normally would and then you run the native image tool to convert that bytecode into your executable which you can later run. So why is JFR different to native image than in OpenJDK? The reasoning behind this is that a native image executable doesn't require a traditional JVM to run, however it still requires certain runtime components that your Java code expects such as GC and synchronization constructs like monitors, for example, and what's providing that in native images is something called substrate VM, which you can think of as sort of like a scoped down replacement for a hotspot. So it does a lot of the things that your Java code requires, but strips out a lot of the dynamic stuff that hotspot does that we don't really need in this environment. And the key here is that since a lot of the JFR code is embedded within hotspots, when we transfer it over to native image, we're using substrate VM so it has to be re-implemented in that VM instead. So that involves everything from the low-level JFR event instrumentation to the actual infrastructure that varies that JFR data from the point of instrumentation to the point where it's later consumed by a user. Yeah, so in terms of the current state of JFR support in native image, you can do things such as starting and stopping recording from the command line or from within your application code via the recording API. Several events are implemented, especially at the VM level. We have events for threads, monitors, allocations, you see, save points, etc. You can dump, snap, shot, to disk and inspect them with tools such as visual VM or JDK mission control as you normally would. The custom event API is also working, so you can create your own custom application level events. Stack traces and CPU profiling are also possible. Event streaming has recently been added as well. You can also even connect via remote GMX to flight recorder MaxBean, which practically means you can do things like from within the JMCUI, interact with JFR recordings that way, start them and manage them on the fly. How you might first interact with JFR in native image is at build time, you specify that you want the enable monitoring flag, specify you want JFR specifically, and that builds the JFR components into your executable. So then at runtime you can use the normal start recording, start flight recording option and pass all of the normal parameters that you would require, such as specifying a file name to dump the recording to or a duration, etc. There are still quite a few limitations to JFR native image. So not all events are implemented yet. It's an ongoing effort to keep up with open JDK in that area. Specifically, events related to bytecode instrumentation are not yet supported and of course some new JDK events we're trying to keep pace with that as well. Event streaming doesn't yet support stack traces, so that's one limitation of that. And we have a couple things that are in the review pipeline as well and are not yet supported in any release. That said, we've reached the deep dive, which is going to take up the majority of the presentation. And yeah, let's take a deep breath. So this road map essentially represents a very high level zoomed out view of the flow of JFR data through the system. And from now on each slide is going to contain this road map and the highlighted part will indicate the part that we're currently talking about just for convenience and easy reference. So firstly, the point of instrumentation. These are various points where JFR events are made at either an application level code or a VM level. And the screenshot on the slide is just from JDK Mission Control. I'm just using it to show some content that an event may contain. You can see there's a bunch of fields and corresponding values. And this is just one example. It'll vary by event. And you can think of JFR events as the primary thing that we're concerned with really. And the rest of the slides going forth are basically just piping to get that JFR data from the point of instrumentation to the chunk file where it can be consumed later. So yeah, speaking of chunk files, we're jumping all the way to the end of the road map. So chunk files are essentially the resting place of the JFR data as far as we're concerned for this presentation. And they must contain basically the same information, the same format regardless of whether OpenJDK or native images generating them. And they can be dumped to snapshots, the JFR snapshot which is the .JFR file format. And that's usually how people are going to interact with them via JMC or Visual VM or the JFR command line tool. Yeah, so chunk files are self-contained and they have four distinct sections. You can see in the diagram here header which contains pointers and other metadata. There is the event data section which contains the core JFR event data. Then there's the metadata section which describes the format and layout of the events in the event data section. And then we have the constant pools which contain constants which are referenced from the event data section. So the constants, in order to reduce the size of JFR data, we use a referencing ID scheme to increase compactness. And how this works is entries in the event data section of the chunk file will use unique IDs to reference into the constant pool section of the chunk file. And this helps with deduplicating the actual constants that are used by the JFR events. So in this slide you can see there's an example of one event entry which uses the unique ID 12 which is then going to be used to index the thread constant pool and reference the actual thread data residing there. So all this increases the compactness of the JFR data and what that does is it reduces overhead when dealing with it while it's in flight and when writing it to disk. It reduces the overall chunk file size as well. However the downside of this increased compactness in this referencing ID scheme is that we have a tight coupling of the event data and the constant pool data so that if they're ever separated and not found in the same self-contained chunk file then we can't decode the event data section and it's basically unreadable. So that's when down side. Right, so now that we've talked about the very beginning and the end of the road map we'll jump and fill in the middle. So now, so after event emission the JFR data splits. So the event data, the core event data goes to the JFR thread local buffers while the constant data goes to the constant pools. And in both hotspot and substrate VM the JFR thread local buffers essentially have the same purpose and same structure. So their structure in a segment way that allows for concurrent rating and reading of data and there are various pointers which define the sections. So there's the rate position pointer which basically determines where new data is written into the buffer. So when the event rate is in progress that's the pointer that's going to be in use. Then there's the committed position pointer which represents the end of the committed data section. And the committed data section is data that has been fully written so it's not an in-progress rate but it hasn't migrated anywhere else yet. The flush data section is essentially committed data that has been migrated somewhere else so it can be overridden at the earliest convenience. Eventually the buffers will fill up with committed data and will have to be flushed elsewhere and at that point all the pointers reset back to the start position. Hotspot is a little bit different in that it uses buffer pools to recycle buffers. So there's a live list and a free list and when a new thread requires a T.O.B. from JFR one will be taken off of the free list and put on the live list and vice versa when that thread goes away. But in such a threat we have it a little bit simpler. We just allocate a native memory, a thread local buffer when it's required and when the thread goes away we destroy that memory. So we don't really have to manage access to these buffer pools and maintain them. Right, in the case of virtual threads, multiple virtual threads may share the same thread local buffer of the carrier thread and that's not really an issue because each one has exclusive access at any point in time and the JFR data is eventually going to the same place anyways. Right, so after the thread local buffers fill up they are migrated, the data is migrated to a set of global buffers and the global buffers essentially act as a capacity for overflow storage and it's more efficient than increasing the size of all the thread local buffers because not all threads will be equally as busy with respect to JFR events. Right, so constant pools. Previously we mentioned how constant pools use a referencing ID scheme to reduce the size of JFR data and they do this essentially works by deduplicating constants. In a hotspot the deduplication works, one way the deduplication works is by using JFR specific bits and the metaspace data for certain constant types such as class with a K and also methods. So these JFR specific bits act essentially as Boolean toggles so when an event data reference from in a JFR local buffer somewhere references a constant that bit in that constant is flipped to indicate that it's referenced somewhere that way when it's time to actually persist the constants to disk we only have to persist the ones that are actually referenced not all of them. Additionally if multiple events reference the same constant that bit is only flipped once and that's only used to be written once so that's where the deduplication happens. There are some constant types such as stack traces that don't have metaspace data and those cases a lookup table is instead used for the deduplication and tracking and an interesting thing is in substrate VM native image there is no metaspace at all so we have to rely on the lookup table approach for all the various constant types. Right, so after enough JFR data has been generated a chunk rotation must be requested and what this is is essentially the way that JFR data is continually persisted to disk. The current chunk file and disk that's open is sealed and then a new chunk file is opened and in that process all the in-flight and memory data is flushed to that chunk file before it's sealed and the thread that's performing this the chunk rotation must flush the thread local buffers of other threads and to do that safely we have to request a save point. So the order of operations at a chunk rotation save point is as follows on the slide I want to make note that it's pretty similar in open JDK as it is in substrate VM and the space between chunk rotation save points the recording time between is called an epic and you can see in the green save point box that that's where we're actually flushing the JFR buffers both local and global to disk but the most interesting thing here is that we're writing the constant pool to disk outside of the save points when we're already starting epic 2 so what that means is we'll we're simultaneously writing the constants from epic 1 to disk while recording constants for relative to epic 2 so they're kind of mingling inside the constant pools so we need to keep them isolated however because we want to avoid writing constants perspective to epic 2 to disk into chunk file for epic 1 otherwise we'll have that mismatch and we won't be able to decode the data for constant for epic 2 the same issue that I explained a few slides back so how we do this is we tag each constant according to the respective epic to keep them isolated and essentially overall the more of the story is it allows us to reduce save point pause time by writing these constant pools outside of the save point and another way we actually reduce save point pause time is by having a dedicated JFR thread flush the global buffers to disk periodically throughout the epic time so it's not actually happening in the save points so there's less work to actually be done when we are stopping the worlds to flush the buffers to disk right um um one related note on save pointing is the question of can a chunk rotation save point interrupts concurrent event emission that may be happening in other threads so we have a scenario here where the save point actually and save points and epic transition actually interrupts the event emission and separates the constant data and the event data into different epics and different chunk files and then it will be unreadable then so that's a scenario that is in question right now um and in j in open JDK in hotspot the JFR code is written in C++ it's native code so it can actually be interrupted for a save point so it's not really an issue at all however in substrate VM it's Java on Java and the VM code is written in Java so the JFR stuff is Java code and potentially could save point at a very inopportune moment so how do we prevent that stuff from happening in substrate VM um how it's done is we have this annotation called an interruptible and what that does is that build time prevents the insertion of save point checks so that the code that's in the annotated with an interruptible annotation doesn't actually save point at all so you find that a lot of the JFR code is sprinkled with this annotation all over the place in the VM especially dealing with buffers and constant pools and event writes but this has pretty big consequences for the implementation itself because un-interruptible code that can't save point can only call other un-interruptible code that can't save point which means a lot of the JDK code that's written in Java is off limits so we can't use things like the normal hash tables, re-entrant locks, etc. we have to kind of like roll our own versions of that which are un-interruptible another thing is we can't even use manage memory on the Java heap because that can induce a garbage collection which requires save point and that's not un-interruptible so we have to use unmanaged native memory in order to craft room data structures to deal with a lot of these things so it's a little bit of work dealing with that and the last thing I want to talk about and the last difference I want to mention between JFR and substrate VM and hotspot is related to how JFR interfaces from the the Java level JFR code to the VM level JFR code and in open JDK it happens in the JVM class here you can see on the left side of sorry the right side of the slide and these are basically the points where the Java level JFR code and the JDK calls down to hotspot at the VM level using JNI so we reuse that code in native image we reuse that Java level JFR code from the JDK but there's no underlying hotspot implementation to call into so how do we resolve that mismatch what we use is we use substitutions which Feeb has talked about a little bit but I'll mention again but essentially what it does is allows us at build time to specify redirects from these Java methods to our own implementation the JFR VM level code so on the right side you can see mark chunk final is highlighted and that corresponds to the Java level code on the left sorry on the right I keep getting mixed up on the right side of the of the slide so we can see that we're actually grabbing that and then redirecting it to our own substrate VM base implementation of that code so that's how we kind of resolve that mismatch um yeah with that said um that basically concludes my presentation if you're interested there are further links for for more reading there's some documentation and some blog posts as well and you can always approach me as outside as well if you have more questions um yeah how good you are for time Chris okay if there's any questions I'm happy to answer them now you just did such a good job explaining it thanks yeah on on substrate VM is there did you measure impagant time to save point because if is it uninterruptible you know this uninterruptible trade oh time to save points yeah yeah I could imagine yeah um I'm not really sure of the exact figures I can't really give you a number but um I I know what you're saying it it would potentially an issue I haven't not really aware of it um but yeah that that's definitely a concern um but it's not just the jfr code that's marked as interruptible a lot of the gc code as well a lot of the low-level operations they they must also be uninterruptible so it's not just jfr yeah understood thanks yeah actually to tag on to that a lot of jfr code is really just instrumenting other low-level code which is already an uninterruptible so it's like collateral damage it's not really an issue to add a little bit more on to code that's already an intructible such as uh jfr gc event handling and uh slow path allocation stuff that's already you can't save point there anyways thank you okay okay uh thank you for listening", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 9.52, "text": " Hi everyone, my name is Robert Swenaga and I work at Red Hat. Today I'll be talking a", "tokens": [50364, 2421, 1518, 11, 452, 1315, 307, 7977, 3926, 268, 9286, 293, 286, 589, 412, 4477, 15867, 13, 2692, 286, 603, 312, 1417, 257, 50840], "temperature": 0.0, "avg_logprob": -0.2645758599350133, "compression_ratio": 1.5474137931034482, "no_speech_prob": 0.10182065516710281}, {"id": 1, "seek": 0, "start": 9.52, "end": 15.24, "text": " little bit about JDK Flight Recorder in Gravium Native Image. And from now on we'll just refer", "tokens": [50840, 707, 857, 466, 37082, 42, 28954, 9647, 4687, 294, 8985, 85, 2197, 15093, 29903, 13, 400, 490, 586, 322, 321, 603, 445, 2864, 51126], "temperature": 0.0, "avg_logprob": -0.2645758599350133, "compression_ratio": 1.5474137931034482, "no_speech_prob": 0.10182065516710281}, {"id": 2, "seek": 0, "start": 15.24, "end": 21.96, "text": " to JDK Flight Recorder as JFR. So as a high level breakdown, I broke in this presentation", "tokens": [51126, 281, 37082, 42, 28954, 9647, 4687, 382, 508, 34658, 13, 407, 382, 257, 1090, 1496, 18188, 11, 286, 6902, 294, 341, 5860, 51462], "temperature": 0.0, "avg_logprob": -0.2645758599350133, "compression_ratio": 1.5474137931034482, "no_speech_prob": 0.10182065516710281}, {"id": 3, "seek": 0, "start": 21.96, "end": 27.28, "text": " to two sections. The first section is a high level overview of JFR Native Image and then", "tokens": [51462, 281, 732, 10863, 13, 440, 700, 3541, 307, 257, 1090, 1496, 12492, 295, 508, 34658, 15093, 29903, 293, 550, 51728], "temperature": 0.0, "avg_logprob": -0.2645758599350133, "compression_ratio": 1.5474137931034482, "no_speech_prob": 0.10182065516710281}, {"id": 4, "seek": 2728, "start": 27.28, "end": 31.240000000000002, "text": " we'll go into a low level deep dive of JFR Native Image and talk about some comparisons between", "tokens": [50364, 321, 603, 352, 666, 257, 2295, 1496, 2452, 9192, 295, 508, 34658, 15093, 29903, 293, 751, 466, 512, 33157, 1296, 50562], "temperature": 0.0, "avg_logprob": -0.1357358997151003, "compression_ratio": 1.6484641638225257, "no_speech_prob": 0.003372814506292343}, {"id": 5, "seek": 2728, "start": 31.240000000000002, "end": 38.36, "text": " substrate VM and hotspot. And I want to make note that even if you're not interested in Gravium", "tokens": [50562, 27585, 18038, 293, 36121, 17698, 13, 400, 286, 528, 281, 652, 3637, 300, 754, 498, 291, 434, 406, 3102, 294, 8985, 85, 2197, 50918], "temperature": 0.0, "avg_logprob": -0.1357358997151003, "compression_ratio": 1.6484641638225257, "no_speech_prob": 0.003372814506292343}, {"id": 6, "seek": 2728, "start": 38.36, "end": 42.72, "text": " Native Image at all, you may still be interested in the second half of this presentation because the", "tokens": [50918, 15093, 29903, 412, 439, 11, 291, 815, 920, 312, 3102, 294, 264, 1150, 1922, 295, 341, 5860, 570, 264, 51136], "temperature": 0.0, "avg_logprob": -0.1357358997151003, "compression_ratio": 1.6484641638225257, "no_speech_prob": 0.003372814506292343}, {"id": 7, "seek": 2728, "start": 42.72, "end": 47.120000000000005, "text": " details of JFR are going to be talking about there extend beyond just native image and also apply", "tokens": [51136, 4365, 295, 508, 34658, 366, 516, 281, 312, 1417, 466, 456, 10101, 4399, 445, 8470, 3256, 293, 611, 3079, 51356], "temperature": 0.0, "avg_logprob": -0.1357358997151003, "compression_ratio": 1.6484641638225257, "no_speech_prob": 0.003372814506292343}, {"id": 8, "seek": 2728, "start": 47.120000000000005, "end": 55.2, "text": " to hotspot more generally as well. Okay, so as a very quick refresher, JFR is an event-based", "tokens": [51356, 281, 36121, 17698, 544, 5101, 382, 731, 13, 1033, 11, 370, 382, 257, 588, 1702, 17368, 511, 11, 508, 34658, 307, 364, 2280, 12, 6032, 51760], "temperature": 0.0, "avg_logprob": -0.1357358997151003, "compression_ratio": 1.6484641638225257, "no_speech_prob": 0.003372814506292343}, {"id": 9, "seek": 5520, "start": 55.2, "end": 59.96, "text": " monitoring and profiling tool. It's built directly into the JDK and it can give you some really", "tokens": [50364, 11028, 293, 1740, 4883, 2290, 13, 467, 311, 3094, 3838, 666, 264, 37082, 42, 293, 309, 393, 976, 291, 512, 534, 50602], "temperature": 0.0, "avg_logprob": -0.19471643652234757, "compression_ratio": 1.6342281879194631, "no_speech_prob": 0.005215232260525227}, {"id": 10, "seek": 5520, "start": 59.96, "end": 64.84, "text": " valuable insights into what your application is doing both at a high level and also at the VM level.", "tokens": [50602, 8263, 14310, 666, 437, 428, 3861, 307, 884, 1293, 412, 257, 1090, 1496, 293, 611, 412, 264, 18038, 1496, 13, 50846], "temperature": 0.0, "avg_logprob": -0.19471643652234757, "compression_ratio": 1.6342281879194631, "no_speech_prob": 0.005215232260525227}, {"id": 11, "seek": 5520, "start": 64.84, "end": 72.60000000000001, "text": " Okay, so Phoebus already talked about this a little bit, but Gravium Native Image is essentially a", "tokens": [50846, 1033, 11, 370, 14936, 68, 21441, 1217, 2825, 466, 341, 257, 707, 857, 11, 457, 8985, 85, 2197, 15093, 29903, 307, 4476, 257, 51234], "temperature": 0.0, "avg_logprob": -0.19471643652234757, "compression_ratio": 1.6342281879194631, "no_speech_prob": 0.005215232260525227}, {"id": 12, "seek": 5520, "start": 72.60000000000001, "end": 78.76, "text": " technology that allows you to convert your Java applications into binary executables. The appeal", "tokens": [51234, 2899, 300, 4045, 291, 281, 7620, 428, 10745, 5821, 666, 17434, 7568, 2965, 13, 440, 13668, 51542], "temperature": 0.0, "avg_logprob": -0.19471643652234757, "compression_ratio": 1.6342281879194631, "no_speech_prob": 0.005215232260525227}, {"id": 13, "seek": 5520, "start": 78.76, "end": 82.96000000000001, "text": " of this is you get much faster startup and use less resources and a big reason for that is you", "tokens": [51542, 295, 341, 307, 291, 483, 709, 4663, 18578, 293, 764, 1570, 3593, 293, 257, 955, 1778, 337, 300, 307, 291, 51752], "temperature": 0.0, "avg_logprob": -0.19471643652234757, "compression_ratio": 1.6342281879194631, "no_speech_prob": 0.005215232260525227}, {"id": 14, "seek": 8296, "start": 83.0, "end": 88.32, "text": " don't have to warm up your traditional JVM alongside your application code. And how it works is you", "tokens": [50366, 500, 380, 362, 281, 4561, 493, 428, 5164, 508, 53, 44, 12385, 428, 3861, 3089, 13, 400, 577, 309, 1985, 307, 291, 50632], "temperature": 0.0, "avg_logprob": -0.14496415526002318, "compression_ratio": 1.6422413793103448, "no_speech_prob": 0.0005526382010430098}, {"id": 15, "seek": 8296, "start": 88.32, "end": 93.0, "text": " compile your Java application to bytecode like you normally would and then you run the native", "tokens": [50632, 31413, 428, 10745, 3861, 281, 40846, 22332, 411, 291, 5646, 576, 293, 550, 291, 1190, 264, 8470, 50866], "temperature": 0.0, "avg_logprob": -0.14496415526002318, "compression_ratio": 1.6422413793103448, "no_speech_prob": 0.0005526382010430098}, {"id": 16, "seek": 8296, "start": 93.0, "end": 99.72, "text": " image tool to convert that bytecode into your executable which you can later run. So why is", "tokens": [50866, 3256, 2290, 281, 7620, 300, 40846, 22332, 666, 428, 7568, 712, 597, 291, 393, 1780, 1190, 13, 407, 983, 307, 51202], "temperature": 0.0, "avg_logprob": -0.14496415526002318, "compression_ratio": 1.6422413793103448, "no_speech_prob": 0.0005526382010430098}, {"id": 17, "seek": 8296, "start": 99.72, "end": 108.19999999999999, "text": " JFR different to native image than in OpenJDK? The reasoning behind this is that a native image", "tokens": [51202, 508, 34658, 819, 281, 8470, 3256, 813, 294, 7238, 41, 35, 42, 30, 440, 21577, 2261, 341, 307, 300, 257, 8470, 3256, 51626], "temperature": 0.0, "avg_logprob": -0.14496415526002318, "compression_ratio": 1.6422413793103448, "no_speech_prob": 0.0005526382010430098}, {"id": 18, "seek": 10820, "start": 108.24000000000001, "end": 113.96000000000001, "text": " executable doesn't require a traditional JVM to run, however it still requires certain runtime", "tokens": [50366, 7568, 712, 1177, 380, 3651, 257, 5164, 508, 53, 44, 281, 1190, 11, 4461, 309, 920, 7029, 1629, 34474, 50652], "temperature": 0.0, "avg_logprob": -0.17442458759654653, "compression_ratio": 1.6701754385964913, "no_speech_prob": 0.0466763861477375}, {"id": 19, "seek": 10820, "start": 113.96000000000001, "end": 119.84, "text": " components that your Java code expects such as GC and synchronization constructs like monitors,", "tokens": [50652, 6677, 300, 428, 10745, 3089, 33280, 1270, 382, 29435, 293, 19331, 2144, 7690, 82, 411, 26518, 11, 50946], "temperature": 0.0, "avg_logprob": -0.17442458759654653, "compression_ratio": 1.6701754385964913, "no_speech_prob": 0.0466763861477375}, {"id": 20, "seek": 10820, "start": 119.84, "end": 124.32000000000001, "text": " for example, and what's providing that in native images is something called substrate VM, which", "tokens": [50946, 337, 1365, 11, 293, 437, 311, 6530, 300, 294, 8470, 5267, 307, 746, 1219, 27585, 18038, 11, 597, 51170], "temperature": 0.0, "avg_logprob": -0.17442458759654653, "compression_ratio": 1.6701754385964913, "no_speech_prob": 0.0466763861477375}, {"id": 21, "seek": 10820, "start": 124.32000000000001, "end": 128.96, "text": " you can think of as sort of like a scoped down replacement for a hotspot. So it does a lot of", "tokens": [51170, 291, 393, 519, 295, 382, 1333, 295, 411, 257, 795, 27277, 760, 14419, 337, 257, 36121, 17698, 13, 407, 309, 775, 257, 688, 295, 51402], "temperature": 0.0, "avg_logprob": -0.17442458759654653, "compression_ratio": 1.6701754385964913, "no_speech_prob": 0.0466763861477375}, {"id": 22, "seek": 10820, "start": 128.96, "end": 133.28, "text": " the things that your Java code requires, but strips out a lot of the dynamic stuff that hotspot", "tokens": [51402, 264, 721, 300, 428, 10745, 3089, 7029, 11, 457, 19842, 484, 257, 688, 295, 264, 8546, 1507, 300, 36121, 17698, 51618], "temperature": 0.0, "avg_logprob": -0.17442458759654653, "compression_ratio": 1.6701754385964913, "no_speech_prob": 0.0466763861477375}, {"id": 23, "seek": 13328, "start": 133.36, "end": 139.08, "text": " does that we don't really need in this environment. And the key here is that since a lot of the", "tokens": [50368, 775, 300, 321, 500, 380, 534, 643, 294, 341, 2823, 13, 400, 264, 2141, 510, 307, 300, 1670, 257, 688, 295, 264, 50654], "temperature": 0.0, "avg_logprob": -0.14892759161480404, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.006583948619663715}, {"id": 24, "seek": 13328, "start": 139.08, "end": 143.72, "text": " JFR code is embedded within hotspots, when we transfer it over to native image, we're using", "tokens": [50654, 508, 34658, 3089, 307, 16741, 1951, 36121, 79, 1971, 11, 562, 321, 5003, 309, 670, 281, 8470, 3256, 11, 321, 434, 1228, 50886], "temperature": 0.0, "avg_logprob": -0.14892759161480404, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.006583948619663715}, {"id": 25, "seek": 13328, "start": 143.72, "end": 149.56, "text": " substrate VM so it has to be re-implemented in that VM instead. So that involves everything from", "tokens": [50886, 27585, 18038, 370, 309, 575, 281, 312, 319, 12, 332, 781, 14684, 294, 300, 18038, 2602, 13, 407, 300, 11626, 1203, 490, 51178], "temperature": 0.0, "avg_logprob": -0.14892759161480404, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.006583948619663715}, {"id": 26, "seek": 13328, "start": 149.56, "end": 155.44, "text": " the low-level JFR event instrumentation to the actual infrastructure that varies that JFR data", "tokens": [51178, 264, 2295, 12, 12418, 508, 34658, 2280, 7198, 399, 281, 264, 3539, 6896, 300, 21716, 300, 508, 34658, 1412, 51472], "temperature": 0.0, "avg_logprob": -0.14892759161480404, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.006583948619663715}, {"id": 27, "seek": 13328, "start": 155.44, "end": 162.8, "text": " from the point of instrumentation to the point where it's later consumed by a user. Yeah, so", "tokens": [51472, 490, 264, 935, 295, 7198, 399, 281, 264, 935, 689, 309, 311, 1780, 21226, 538, 257, 4195, 13, 865, 11, 370, 51840], "temperature": 0.0, "avg_logprob": -0.14892759161480404, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.006583948619663715}, {"id": 28, "seek": 16280, "start": 162.84, "end": 168.44, "text": " in terms of the current state of JFR support in native image, you can do things such as starting", "tokens": [50366, 294, 2115, 295, 264, 2190, 1785, 295, 508, 34658, 1406, 294, 8470, 3256, 11, 291, 393, 360, 721, 1270, 382, 2891, 50646], "temperature": 0.0, "avg_logprob": -0.21429600034441268, "compression_ratio": 1.6585365853658536, "no_speech_prob": 0.0002570570504758507}, {"id": 29, "seek": 16280, "start": 168.44, "end": 172.92000000000002, "text": " and stopping recording from the command line or from within your application code via the", "tokens": [50646, 293, 12767, 6613, 490, 264, 5622, 1622, 420, 490, 1951, 428, 3861, 3089, 5766, 264, 50870], "temperature": 0.0, "avg_logprob": -0.21429600034441268, "compression_ratio": 1.6585365853658536, "no_speech_prob": 0.0002570570504758507}, {"id": 30, "seek": 16280, "start": 172.92000000000002, "end": 178.92000000000002, "text": " recording API. Several events are implemented, especially at the VM level. We have events for", "tokens": [50870, 6613, 9362, 13, 22246, 3931, 366, 12270, 11, 2318, 412, 264, 18038, 1496, 13, 492, 362, 3931, 337, 51170], "temperature": 0.0, "avg_logprob": -0.21429600034441268, "compression_ratio": 1.6585365853658536, "no_speech_prob": 0.0002570570504758507}, {"id": 31, "seek": 16280, "start": 178.92000000000002, "end": 184.60000000000002, "text": " threads, monitors, allocations, you see, save points, etc. You can dump, snap, shot, to disk and", "tokens": [51170, 19314, 11, 26518, 11, 12660, 763, 11, 291, 536, 11, 3155, 2793, 11, 5183, 13, 509, 393, 11430, 11, 13650, 11, 3347, 11, 281, 12355, 293, 51454], "temperature": 0.0, "avg_logprob": -0.21429600034441268, "compression_ratio": 1.6585365853658536, "no_speech_prob": 0.0002570570504758507}, {"id": 32, "seek": 16280, "start": 184.60000000000002, "end": 190.32000000000002, "text": " inspect them with tools such as visual VM or JDK mission control as you normally would. The custom", "tokens": [51454, 15018, 552, 365, 3873, 1270, 382, 5056, 18038, 420, 37082, 42, 4447, 1969, 382, 291, 5646, 576, 13, 440, 2375, 51740], "temperature": 0.0, "avg_logprob": -0.21429600034441268, "compression_ratio": 1.6585365853658536, "no_speech_prob": 0.0002570570504758507}, {"id": 33, "seek": 19032, "start": 190.35999999999999, "end": 196.56, "text": " event API is also working, so you can create your own custom application level events. Stack traces", "tokens": [50366, 2280, 9362, 307, 611, 1364, 11, 370, 291, 393, 1884, 428, 1065, 2375, 3861, 1496, 3931, 13, 37649, 26076, 50676], "temperature": 0.0, "avg_logprob": -0.23456098768446182, "compression_ratio": 1.5294117647058822, "no_speech_prob": 0.0011331894202157855}, {"id": 34, "seek": 19032, "start": 196.56, "end": 202.4, "text": " and CPU profiling are also possible. Event streaming has recently been added as well. You can also", "tokens": [50676, 293, 13199, 1740, 4883, 366, 611, 1944, 13, 13222, 11791, 575, 3938, 668, 3869, 382, 731, 13, 509, 393, 611, 50968], "temperature": 0.0, "avg_logprob": -0.23456098768446182, "compression_ratio": 1.5294117647058822, "no_speech_prob": 0.0011331894202157855}, {"id": 35, "seek": 19032, "start": 202.4, "end": 206.95999999999998, "text": " even connect via remote GMX to flight recorder MaxBean, which practically means you can do things", "tokens": [50968, 754, 1745, 5766, 8607, 16609, 55, 281, 7018, 37744, 7402, 6524, 282, 11, 597, 15667, 1355, 291, 393, 360, 721, 51196], "temperature": 0.0, "avg_logprob": -0.23456098768446182, "compression_ratio": 1.5294117647058822, "no_speech_prob": 0.0011331894202157855}, {"id": 36, "seek": 19032, "start": 206.95999999999998, "end": 213.35999999999999, "text": " like from within the JMCUI, interact with JFR recordings that way, start them and manage them", "tokens": [51196, 411, 490, 1951, 264, 35162, 25864, 40, 11, 4648, 365, 508, 34658, 25162, 300, 636, 11, 722, 552, 293, 3067, 552, 51516], "temperature": 0.0, "avg_logprob": -0.23456098768446182, "compression_ratio": 1.5294117647058822, "no_speech_prob": 0.0011331894202157855}, {"id": 37, "seek": 21336, "start": 213.4, "end": 221.4, "text": " on the fly. How you might first interact with JFR in native image is at build time, you specify", "tokens": [50366, 322, 264, 3603, 13, 1012, 291, 1062, 700, 4648, 365, 508, 34658, 294, 8470, 3256, 307, 412, 1322, 565, 11, 291, 16500, 50766], "temperature": 0.0, "avg_logprob": -0.2346156473909871, "compression_ratio": 1.6943231441048034, "no_speech_prob": 0.03019699826836586}, {"id": 38, "seek": 21336, "start": 221.4, "end": 227.8, "text": " that you want the enable monitoring flag, specify you want JFR specifically, and that builds the JFR", "tokens": [50766, 300, 291, 528, 264, 9528, 11028, 7166, 11, 16500, 291, 528, 508, 34658, 4682, 11, 293, 300, 15182, 264, 508, 34658, 51086], "temperature": 0.0, "avg_logprob": -0.2346156473909871, "compression_ratio": 1.6943231441048034, "no_speech_prob": 0.03019699826836586}, {"id": 39, "seek": 21336, "start": 227.8, "end": 234.0, "text": " components into your executable. So then at runtime you can use the normal start recording, start", "tokens": [51086, 6677, 666, 428, 7568, 712, 13, 407, 550, 412, 34474, 291, 393, 764, 264, 2710, 722, 6613, 11, 722, 51396], "temperature": 0.0, "avg_logprob": -0.2346156473909871, "compression_ratio": 1.6943231441048034, "no_speech_prob": 0.03019699826836586}, {"id": 40, "seek": 21336, "start": 234.0, "end": 238.64000000000001, "text": " flight recording option and pass all of the normal parameters that you would require, such as", "tokens": [51396, 7018, 6613, 3614, 293, 1320, 439, 295, 264, 2710, 9834, 300, 291, 576, 3651, 11, 1270, 382, 51628], "temperature": 0.0, "avg_logprob": -0.2346156473909871, "compression_ratio": 1.6943231441048034, "no_speech_prob": 0.03019699826836586}, {"id": 41, "seek": 23864, "start": 238.92, "end": 245.83999999999997, "text": " specifying a file name to dump the recording to or a duration, etc. There are still quite a few", "tokens": [50378, 1608, 5489, 257, 3991, 1315, 281, 11430, 264, 6613, 281, 420, 257, 16365, 11, 5183, 13, 821, 366, 920, 1596, 257, 1326, 50724], "temperature": 0.0, "avg_logprob": -0.219395427380578, "compression_ratio": 1.6552901023890785, "no_speech_prob": 0.004397187381982803}, {"id": 42, "seek": 23864, "start": 245.83999999999997, "end": 251.2, "text": " limitations to JFR native image. So not all events are implemented yet. It's an ongoing effort to", "tokens": [50724, 15705, 281, 508, 34658, 8470, 3256, 13, 407, 406, 439, 3931, 366, 12270, 1939, 13, 467, 311, 364, 10452, 4630, 281, 50992], "temperature": 0.0, "avg_logprob": -0.219395427380578, "compression_ratio": 1.6552901023890785, "no_speech_prob": 0.004397187381982803}, {"id": 43, "seek": 23864, "start": 251.2, "end": 256.64, "text": " keep up with open JDK in that area. Specifically, events related to bytecode instrumentation are not", "tokens": [50992, 1066, 493, 365, 1269, 37082, 42, 294, 300, 1859, 13, 26058, 11, 3931, 4077, 281, 40846, 22332, 7198, 399, 366, 406, 51264], "temperature": 0.0, "avg_logprob": -0.219395427380578, "compression_ratio": 1.6552901023890785, "no_speech_prob": 0.004397187381982803}, {"id": 44, "seek": 23864, "start": 256.64, "end": 261.56, "text": " yet supported and of course some new JDK events we're trying to keep pace with that as well.", "tokens": [51264, 1939, 8104, 293, 295, 1164, 512, 777, 37082, 42, 3931, 321, 434, 1382, 281, 1066, 11638, 365, 300, 382, 731, 13, 51510], "temperature": 0.0, "avg_logprob": -0.219395427380578, "compression_ratio": 1.6552901023890785, "no_speech_prob": 0.004397187381982803}, {"id": 45, "seek": 23864, "start": 261.56, "end": 267.28, "text": " Event streaming doesn't yet support stack traces, so that's one limitation of that. And we have a", "tokens": [51510, 13222, 11791, 1177, 380, 1939, 1406, 8630, 26076, 11, 370, 300, 311, 472, 27432, 295, 300, 13, 400, 321, 362, 257, 51796], "temperature": 0.0, "avg_logprob": -0.219395427380578, "compression_ratio": 1.6552901023890785, "no_speech_prob": 0.004397187381982803}, {"id": 46, "seek": 26728, "start": 267.32, "end": 271.0, "text": " couple things that are in the review pipeline as well and are not yet supported in any release.", "tokens": [50366, 1916, 721, 300, 366, 294, 264, 3131, 15517, 382, 731, 293, 366, 406, 1939, 8104, 294, 604, 4374, 13, 50550], "temperature": 0.0, "avg_logprob": -0.18233002110531454, "compression_ratio": 1.603305785123967, "no_speech_prob": 0.0012061753077432513}, {"id": 47, "seek": 26728, "start": 271.0, "end": 278.0, "text": " That said, we've reached the deep dive, which is going to take up the majority of the presentation.", "tokens": [50550, 663, 848, 11, 321, 600, 6488, 264, 2452, 9192, 11, 597, 307, 516, 281, 747, 493, 264, 6286, 295, 264, 5860, 13, 50900], "temperature": 0.0, "avg_logprob": -0.18233002110531454, "compression_ratio": 1.603305785123967, "no_speech_prob": 0.0012061753077432513}, {"id": 48, "seek": 26728, "start": 278.0, "end": 287.59999999999997, "text": " And yeah, let's take a deep breath. So this road map essentially represents a very high level zoomed", "tokens": [50900, 400, 1338, 11, 718, 311, 747, 257, 2452, 6045, 13, 407, 341, 3060, 4471, 4476, 8855, 257, 588, 1090, 1496, 8863, 292, 51380], "temperature": 0.0, "avg_logprob": -0.18233002110531454, "compression_ratio": 1.603305785123967, "no_speech_prob": 0.0012061753077432513}, {"id": 49, "seek": 26728, "start": 287.59999999999997, "end": 292.32, "text": " out view of the flow of JFR data through the system. And from now on each slide is going to", "tokens": [51380, 484, 1910, 295, 264, 3095, 295, 508, 34658, 1412, 807, 264, 1185, 13, 400, 490, 586, 322, 1184, 4137, 307, 516, 281, 51616], "temperature": 0.0, "avg_logprob": -0.18233002110531454, "compression_ratio": 1.603305785123967, "no_speech_prob": 0.0012061753077432513}, {"id": 50, "seek": 29232, "start": 292.32, "end": 297.92, "text": " contain this road map and the highlighted part will indicate the part that we're currently talking", "tokens": [50364, 5304, 341, 3060, 4471, 293, 264, 17173, 644, 486, 13330, 264, 644, 300, 321, 434, 4362, 1417, 50644], "temperature": 0.0, "avg_logprob": -0.1526945446609357, "compression_ratio": 1.6059602649006623, "no_speech_prob": 0.004132347647100687}, {"id": 51, "seek": 29232, "start": 297.92, "end": 305.36, "text": " about just for convenience and easy reference. So firstly, the point of instrumentation. These", "tokens": [50644, 466, 445, 337, 19283, 293, 1858, 6408, 13, 407, 27376, 11, 264, 935, 295, 7198, 399, 13, 1981, 51016], "temperature": 0.0, "avg_logprob": -0.1526945446609357, "compression_ratio": 1.6059602649006623, "no_speech_prob": 0.004132347647100687}, {"id": 52, "seek": 29232, "start": 305.36, "end": 310.36, "text": " are various points where JFR events are made at either an application level code or a VM level.", "tokens": [51016, 366, 3683, 2793, 689, 508, 34658, 3931, 366, 1027, 412, 2139, 364, 3861, 1496, 3089, 420, 257, 18038, 1496, 13, 51266], "temperature": 0.0, "avg_logprob": -0.1526945446609357, "compression_ratio": 1.6059602649006623, "no_speech_prob": 0.004132347647100687}, {"id": 53, "seek": 29232, "start": 310.36, "end": 315.15999999999997, "text": " And the screenshot on the slide is just from JDK Mission Control. I'm just using it to show some", "tokens": [51266, 400, 264, 27712, 322, 264, 4137, 307, 445, 490, 37082, 42, 20170, 12912, 13, 286, 478, 445, 1228, 309, 281, 855, 512, 51506], "temperature": 0.0, "avg_logprob": -0.1526945446609357, "compression_ratio": 1.6059602649006623, "no_speech_prob": 0.004132347647100687}, {"id": 54, "seek": 29232, "start": 315.15999999999997, "end": 319.92, "text": " content that an event may contain. You can see there's a bunch of fields and corresponding values.", "tokens": [51506, 2701, 300, 364, 2280, 815, 5304, 13, 509, 393, 536, 456, 311, 257, 3840, 295, 7909, 293, 11760, 4190, 13, 51744], "temperature": 0.0, "avg_logprob": -0.1526945446609357, "compression_ratio": 1.6059602649006623, "no_speech_prob": 0.004132347647100687}, {"id": 55, "seek": 31992, "start": 320.32, "end": 326.04, "text": " And this is just one example. It'll vary by event. And you can think of JFR events as the primary", "tokens": [50384, 400, 341, 307, 445, 472, 1365, 13, 467, 603, 10559, 538, 2280, 13, 400, 291, 393, 519, 295, 508, 34658, 3931, 382, 264, 6194, 50670], "temperature": 0.0, "avg_logprob": -0.12513151890089533, "compression_ratio": 1.7564575645756457, "no_speech_prob": 0.0003149398835375905}, {"id": 56, "seek": 31992, "start": 326.04, "end": 331.52000000000004, "text": " thing that we're concerned with really. And the rest of the slides going forth are basically just", "tokens": [50670, 551, 300, 321, 434, 5922, 365, 534, 13, 400, 264, 1472, 295, 264, 9788, 516, 5220, 366, 1936, 445, 50944], "temperature": 0.0, "avg_logprob": -0.12513151890089533, "compression_ratio": 1.7564575645756457, "no_speech_prob": 0.0003149398835375905}, {"id": 57, "seek": 31992, "start": 331.52000000000004, "end": 336.56, "text": " piping to get that JFR data from the point of instrumentation to the chunk file where it can", "tokens": [50944, 35204, 281, 483, 300, 508, 34658, 1412, 490, 264, 935, 295, 7198, 399, 281, 264, 16635, 3991, 689, 309, 393, 51196], "temperature": 0.0, "avg_logprob": -0.12513151890089533, "compression_ratio": 1.7564575645756457, "no_speech_prob": 0.0003149398835375905}, {"id": 58, "seek": 31992, "start": 336.56, "end": 341.6, "text": " be consumed later. So yeah, speaking of chunk files, we're jumping all the way to the end of the", "tokens": [51196, 312, 21226, 1780, 13, 407, 1338, 11, 4124, 295, 16635, 7098, 11, 321, 434, 11233, 439, 264, 636, 281, 264, 917, 295, 264, 51448], "temperature": 0.0, "avg_logprob": -0.12513151890089533, "compression_ratio": 1.7564575645756457, "no_speech_prob": 0.0003149398835375905}, {"id": 59, "seek": 31992, "start": 341.6, "end": 349.40000000000003, "text": " road map. So chunk files are essentially the resting place of the JFR data as far as we're", "tokens": [51448, 3060, 4471, 13, 407, 16635, 7098, 366, 4476, 264, 21221, 1081, 295, 264, 508, 34658, 1412, 382, 1400, 382, 321, 434, 51838], "temperature": 0.0, "avg_logprob": -0.12513151890089533, "compression_ratio": 1.7564575645756457, "no_speech_prob": 0.0003149398835375905}, {"id": 60, "seek": 34940, "start": 349.4, "end": 353.59999999999997, "text": " concerned for this presentation. And they must contain basically the same information, the same", "tokens": [50364, 5922, 337, 341, 5860, 13, 400, 436, 1633, 5304, 1936, 264, 912, 1589, 11, 264, 912, 50574], "temperature": 0.0, "avg_logprob": -0.15865672262091385, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.0016477288445457816}, {"id": 61, "seek": 34940, "start": 353.59999999999997, "end": 359.84, "text": " format regardless of whether OpenJDK or native images generating them. And they can be dumped", "tokens": [50574, 7877, 10060, 295, 1968, 7238, 41, 35, 42, 420, 8470, 5267, 17746, 552, 13, 400, 436, 393, 312, 32131, 50886], "temperature": 0.0, "avg_logprob": -0.15865672262091385, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.0016477288445457816}, {"id": 62, "seek": 34940, "start": 359.84, "end": 364.91999999999996, "text": " to snapshots, the JFR snapshot which is the .JFR file format. And that's usually how people are", "tokens": [50886, 281, 19206, 27495, 11, 264, 508, 34658, 30163, 597, 307, 264, 2411, 41, 34658, 3991, 7877, 13, 400, 300, 311, 2673, 577, 561, 366, 51140], "temperature": 0.0, "avg_logprob": -0.15865672262091385, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.0016477288445457816}, {"id": 63, "seek": 34940, "start": 364.91999999999996, "end": 373.08, "text": " going to interact with them via JMC or Visual VM or the JFR command line tool. Yeah, so chunk", "tokens": [51140, 516, 281, 4648, 365, 552, 5766, 35162, 34, 420, 23187, 18038, 420, 264, 508, 34658, 5622, 1622, 2290, 13, 865, 11, 370, 16635, 51548], "temperature": 0.0, "avg_logprob": -0.15865672262091385, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.0016477288445457816}, {"id": 64, "seek": 34940, "start": 373.08, "end": 378.08, "text": " files are self-contained and they have four distinct sections. You can see in the diagram here", "tokens": [51548, 7098, 366, 2698, 12, 9000, 3563, 293, 436, 362, 1451, 10644, 10863, 13, 509, 393, 536, 294, 264, 10686, 510, 51798], "temperature": 0.0, "avg_logprob": -0.15865672262091385, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.0016477288445457816}, {"id": 65, "seek": 37808, "start": 378.12, "end": 384.0, "text": " header which contains pointers and other metadata. There is the event data section which contains the", "tokens": [50366, 23117, 597, 8306, 44548, 293, 661, 26603, 13, 821, 307, 264, 2280, 1412, 3541, 597, 8306, 264, 50660], "temperature": 0.0, "avg_logprob": -0.14398677008492605, "compression_ratio": 2.0414507772020727, "no_speech_prob": 0.0020495213102549314}, {"id": 66, "seek": 37808, "start": 384.0, "end": 388.64, "text": " core JFR event data. Then there's the metadata section which describes the format and layout of", "tokens": [50660, 4965, 508, 34658, 2280, 1412, 13, 1396, 456, 311, 264, 26603, 3541, 597, 15626, 264, 7877, 293, 13333, 295, 50892], "temperature": 0.0, "avg_logprob": -0.14398677008492605, "compression_ratio": 2.0414507772020727, "no_speech_prob": 0.0020495213102549314}, {"id": 67, "seek": 37808, "start": 388.64, "end": 393.71999999999997, "text": " the events in the event data section. And then we have the constant pools which contain constants", "tokens": [50892, 264, 3931, 294, 264, 2280, 1412, 3541, 13, 400, 550, 321, 362, 264, 5754, 28688, 597, 5304, 35870, 51146], "temperature": 0.0, "avg_logprob": -0.14398677008492605, "compression_ratio": 2.0414507772020727, "no_speech_prob": 0.0020495213102549314}, {"id": 68, "seek": 37808, "start": 393.71999999999997, "end": 404.91999999999996, "text": " which are referenced from the event data section. So the constants, in order to reduce the size of", "tokens": [51146, 597, 366, 32734, 490, 264, 2280, 1412, 3541, 13, 407, 264, 35870, 11, 294, 1668, 281, 5407, 264, 2744, 295, 51706], "temperature": 0.0, "avg_logprob": -0.14398677008492605, "compression_ratio": 2.0414507772020727, "no_speech_prob": 0.0020495213102549314}, {"id": 69, "seek": 40492, "start": 404.96000000000004, "end": 416.04, "text": " JFR data, we use a referencing ID scheme to increase compactness. And how this works is entries in", "tokens": [50366, 508, 34658, 1412, 11, 321, 764, 257, 40582, 7348, 12232, 281, 3488, 14679, 1287, 13, 400, 577, 341, 1985, 307, 23041, 294, 50920], "temperature": 0.0, "avg_logprob": -0.15989930489484003, "compression_ratio": 1.6077348066298343, "no_speech_prob": 0.0006874728132970631}, {"id": 70, "seek": 40492, "start": 416.04, "end": 421.40000000000003, "text": " the event data section of the chunk file will use unique IDs to reference into the constant pool", "tokens": [50920, 264, 2280, 1412, 3541, 295, 264, 16635, 3991, 486, 764, 3845, 48212, 281, 6408, 666, 264, 5754, 7005, 51188], "temperature": 0.0, "avg_logprob": -0.15989930489484003, "compression_ratio": 1.6077348066298343, "no_speech_prob": 0.0006874728132970631}, {"id": 71, "seek": 40492, "start": 421.40000000000003, "end": 428.40000000000003, "text": " section of the chunk file. And this helps with deduplicating the actual constants that are used", "tokens": [51188, 3541, 295, 264, 16635, 3991, 13, 400, 341, 3665, 365, 4172, 84, 4770, 990, 264, 3539, 35870, 300, 366, 1143, 51538], "temperature": 0.0, "avg_logprob": -0.15989930489484003, "compression_ratio": 1.6077348066298343, "no_speech_prob": 0.0006874728132970631}, {"id": 72, "seek": 42840, "start": 428.4, "end": 434.71999999999997, "text": " by the JFR events. So in this slide you can see there's an example of one event entry which", "tokens": [50364, 538, 264, 508, 34658, 3931, 13, 407, 294, 341, 4137, 291, 393, 536, 456, 311, 364, 1365, 295, 472, 2280, 8729, 597, 50680], "temperature": 0.0, "avg_logprob": -0.14648514463190446, "compression_ratio": 1.7077464788732395, "no_speech_prob": 0.001244244514964521}, {"id": 73, "seek": 42840, "start": 434.71999999999997, "end": 439.28, "text": " uses the unique ID 12 which is then going to be used to index the thread constant pool and reference", "tokens": [50680, 4960, 264, 3845, 7348, 2272, 597, 307, 550, 516, 281, 312, 1143, 281, 8186, 264, 7207, 5754, 7005, 293, 6408, 50908], "temperature": 0.0, "avg_logprob": -0.14648514463190446, "compression_ratio": 1.7077464788732395, "no_speech_prob": 0.001244244514964521}, {"id": 74, "seek": 42840, "start": 439.28, "end": 446.64, "text": " the actual thread data residing there. So all this increases the compactness of the JFR data and", "tokens": [50908, 264, 3539, 7207, 1412, 725, 2819, 456, 13, 407, 439, 341, 8637, 264, 14679, 1287, 295, 264, 508, 34658, 1412, 293, 51276], "temperature": 0.0, "avg_logprob": -0.14648514463190446, "compression_ratio": 1.7077464788732395, "no_speech_prob": 0.001244244514964521}, {"id": 75, "seek": 42840, "start": 446.64, "end": 451.2, "text": " what that does is it reduces overhead when dealing with it while it's in flight and when writing it", "tokens": [51276, 437, 300, 775, 307, 309, 18081, 19922, 562, 6260, 365, 309, 1339, 309, 311, 294, 7018, 293, 562, 3579, 309, 51504], "temperature": 0.0, "avg_logprob": -0.14648514463190446, "compression_ratio": 1.7077464788732395, "no_speech_prob": 0.001244244514964521}, {"id": 76, "seek": 42840, "start": 451.2, "end": 457.88, "text": " to disk. It reduces the overall chunk file size as well. However the downside of this increased", "tokens": [51504, 281, 12355, 13, 467, 18081, 264, 4787, 16635, 3991, 2744, 382, 731, 13, 2908, 264, 25060, 295, 341, 6505, 51838], "temperature": 0.0, "avg_logprob": -0.14648514463190446, "compression_ratio": 1.7077464788732395, "no_speech_prob": 0.001244244514964521}, {"id": 77, "seek": 45788, "start": 457.92, "end": 464.48, "text": " compactness in this referencing ID scheme is that we have a tight coupling of the event data and the", "tokens": [50366, 14679, 1287, 294, 341, 40582, 7348, 12232, 307, 300, 321, 362, 257, 4524, 37447, 295, 264, 2280, 1412, 293, 264, 50694], "temperature": 0.0, "avg_logprob": -0.14747159679730734, "compression_ratio": 1.649789029535865, "no_speech_prob": 0.0002452088228892535}, {"id": 78, "seek": 45788, "start": 464.48, "end": 468.52, "text": " constant pool data so that if they're ever separated and not found in the same self-contained", "tokens": [50694, 5754, 7005, 1412, 370, 300, 498, 436, 434, 1562, 12005, 293, 406, 1352, 294, 264, 912, 2698, 12, 9000, 3563, 50896], "temperature": 0.0, "avg_logprob": -0.14747159679730734, "compression_ratio": 1.649789029535865, "no_speech_prob": 0.0002452088228892535}, {"id": 79, "seek": 45788, "start": 468.52, "end": 474.12, "text": " chunk file then we can't decode the event data section and it's basically unreadable. So that's", "tokens": [50896, 16635, 3991, 550, 321, 393, 380, 979, 1429, 264, 2280, 1412, 3541, 293, 309, 311, 1936, 517, 2538, 712, 13, 407, 300, 311, 51176], "temperature": 0.0, "avg_logprob": -0.14747159679730734, "compression_ratio": 1.649789029535865, "no_speech_prob": 0.0002452088228892535}, {"id": 80, "seek": 45788, "start": 474.12, "end": 480.48, "text": " when down side. Right, so now that we've talked about the very beginning and the end of the road map", "tokens": [51176, 562, 760, 1252, 13, 1779, 11, 370, 586, 300, 321, 600, 2825, 466, 264, 588, 2863, 293, 264, 917, 295, 264, 3060, 4471, 51494], "temperature": 0.0, "avg_logprob": -0.14747159679730734, "compression_ratio": 1.649789029535865, "no_speech_prob": 0.0002452088228892535}, {"id": 81, "seek": 48048, "start": 480.52000000000004, "end": 490.08000000000004, "text": " we'll jump and fill in the middle. So now, so after event emission the JFR data splits. So the event", "tokens": [50366, 321, 603, 3012, 293, 2836, 294, 264, 2808, 13, 407, 586, 11, 370, 934, 2280, 29513, 264, 508, 34658, 1412, 37741, 13, 407, 264, 2280, 50844], "temperature": 0.0, "avg_logprob": -0.19242601896587172, "compression_ratio": 1.809090909090909, "no_speech_prob": 0.021594179794192314}, {"id": 82, "seek": 48048, "start": 490.08000000000004, "end": 495.92, "text": " data, the core event data goes to the JFR thread local buffers while the constant data goes to the", "tokens": [50844, 1412, 11, 264, 4965, 2280, 1412, 1709, 281, 264, 508, 34658, 7207, 2654, 9204, 433, 1339, 264, 5754, 1412, 1709, 281, 264, 51136], "temperature": 0.0, "avg_logprob": -0.19242601896587172, "compression_ratio": 1.809090909090909, "no_speech_prob": 0.021594179794192314}, {"id": 83, "seek": 48048, "start": 495.92, "end": 502.36, "text": " constant pools. And in both hotspot and substrate VM the JFR thread local buffers essentially have", "tokens": [51136, 5754, 28688, 13, 400, 294, 1293, 36121, 17698, 293, 27585, 18038, 264, 508, 34658, 7207, 2654, 9204, 433, 4476, 362, 51458], "temperature": 0.0, "avg_logprob": -0.19242601896587172, "compression_ratio": 1.809090909090909, "no_speech_prob": 0.021594179794192314}, {"id": 84, "seek": 48048, "start": 502.36, "end": 508.44, "text": " the same purpose and same structure. So their structure in a segment way that allows for concurrent", "tokens": [51458, 264, 912, 4334, 293, 912, 3877, 13, 407, 641, 3877, 294, 257, 9469, 636, 300, 4045, 337, 37702, 51762], "temperature": 0.0, "avg_logprob": -0.19242601896587172, "compression_ratio": 1.809090909090909, "no_speech_prob": 0.021594179794192314}, {"id": 85, "seek": 50844, "start": 508.48, "end": 514.92, "text": " rating and reading of data and there are various pointers which define the sections. So there's", "tokens": [50366, 10990, 293, 3760, 295, 1412, 293, 456, 366, 3683, 44548, 597, 6964, 264, 10863, 13, 407, 456, 311, 50688], "temperature": 0.0, "avg_logprob": -0.1527491077300041, "compression_ratio": 2.0996309963099633, "no_speech_prob": 0.0027131119277328253}, {"id": 86, "seek": 50844, "start": 514.92, "end": 518.68, "text": " the rate position pointer which basically determines where new data is written into the", "tokens": [50688, 264, 3314, 2535, 23918, 597, 1936, 24799, 689, 777, 1412, 307, 3720, 666, 264, 50876], "temperature": 0.0, "avg_logprob": -0.1527491077300041, "compression_ratio": 2.0996309963099633, "no_speech_prob": 0.0027131119277328253}, {"id": 87, "seek": 50844, "start": 518.68, "end": 523.72, "text": " buffer. So when the event rate is in progress that's the pointer that's going to be in use. Then", "tokens": [50876, 21762, 13, 407, 562, 264, 2280, 3314, 307, 294, 4205, 300, 311, 264, 23918, 300, 311, 516, 281, 312, 294, 764, 13, 1396, 51128], "temperature": 0.0, "avg_logprob": -0.1527491077300041, "compression_ratio": 2.0996309963099633, "no_speech_prob": 0.0027131119277328253}, {"id": 88, "seek": 50844, "start": 523.72, "end": 527.24, "text": " there's the committed position pointer which represents the end of the committed data section.", "tokens": [51128, 456, 311, 264, 7784, 2535, 23918, 597, 8855, 264, 917, 295, 264, 7784, 1412, 3541, 13, 51304], "temperature": 0.0, "avg_logprob": -0.1527491077300041, "compression_ratio": 2.0996309963099633, "no_speech_prob": 0.0027131119277328253}, {"id": 89, "seek": 50844, "start": 527.24, "end": 531.16, "text": " And the committed data section is data that has been fully written so it's not an in-progress", "tokens": [51304, 400, 264, 7784, 1412, 3541, 307, 1412, 300, 575, 668, 4498, 3720, 370, 309, 311, 406, 364, 294, 12, 4318, 3091, 51500], "temperature": 0.0, "avg_logprob": -0.1527491077300041, "compression_ratio": 2.0996309963099633, "no_speech_prob": 0.0027131119277328253}, {"id": 90, "seek": 50844, "start": 531.16, "end": 537.56, "text": " rate but it hasn't migrated anywhere else yet. The flush data section is essentially committed data", "tokens": [51500, 3314, 457, 309, 6132, 380, 48329, 4992, 1646, 1939, 13, 440, 19568, 1412, 3541, 307, 4476, 7784, 1412, 51820], "temperature": 0.0, "avg_logprob": -0.1527491077300041, "compression_ratio": 2.0996309963099633, "no_speech_prob": 0.0027131119277328253}, {"id": 91, "seek": 53756, "start": 537.8, "end": 541.2399999999999, "text": " that has been migrated somewhere else so it can be overridden at the earliest convenience.", "tokens": [50376, 300, 575, 668, 48329, 4079, 1646, 370, 309, 393, 312, 670, 81, 6171, 412, 264, 20573, 19283, 13, 50548], "temperature": 0.0, "avg_logprob": -0.1624497815597156, "compression_ratio": 1.725, "no_speech_prob": 0.0002866902214009315}, {"id": 92, "seek": 53756, "start": 541.2399999999999, "end": 548.1199999999999, "text": " Eventually the buffers will fill up with committed data and will have to be flushed elsewhere and", "tokens": [50548, 17586, 264, 9204, 433, 486, 2836, 493, 365, 7784, 1412, 293, 486, 362, 281, 312, 19568, 292, 14517, 293, 50892], "temperature": 0.0, "avg_logprob": -0.1624497815597156, "compression_ratio": 1.725, "no_speech_prob": 0.0002866902214009315}, {"id": 93, "seek": 53756, "start": 548.1199999999999, "end": 553.4799999999999, "text": " at that point all the pointers reset back to the start position. Hotspot is a little bit different", "tokens": [50892, 412, 300, 935, 439, 264, 44548, 14322, 646, 281, 264, 722, 2535, 13, 389, 1971, 17698, 307, 257, 707, 857, 819, 51160], "temperature": 0.0, "avg_logprob": -0.1624497815597156, "compression_ratio": 1.725, "no_speech_prob": 0.0002866902214009315}, {"id": 94, "seek": 53756, "start": 553.4799999999999, "end": 559.88, "text": " in that it uses buffer pools to recycle buffers. So there's a live list and a free list and when a", "tokens": [51160, 294, 300, 309, 4960, 21762, 28688, 281, 32162, 9204, 433, 13, 407, 456, 311, 257, 1621, 1329, 293, 257, 1737, 1329, 293, 562, 257, 51480], "temperature": 0.0, "avg_logprob": -0.1624497815597156, "compression_ratio": 1.725, "no_speech_prob": 0.0002866902214009315}, {"id": 95, "seek": 53756, "start": 559.88, "end": 564.88, "text": " new thread requires a T.O.B. from JFR one will be taken off of the free list and put on the live", "tokens": [51480, 777, 7207, 7029, 257, 314, 13, 46, 13, 33, 13, 490, 508, 34658, 472, 486, 312, 2726, 766, 295, 264, 1737, 1329, 293, 829, 322, 264, 1621, 51730], "temperature": 0.0, "avg_logprob": -0.1624497815597156, "compression_ratio": 1.725, "no_speech_prob": 0.0002866902214009315}, {"id": 96, "seek": 56488, "start": 564.88, "end": 568.56, "text": " list and vice versa when that thread goes away. But in such a threat we have it a little bit", "tokens": [50364, 1329, 293, 11964, 25650, 562, 300, 7207, 1709, 1314, 13, 583, 294, 1270, 257, 4734, 321, 362, 309, 257, 707, 857, 50548], "temperature": 0.0, "avg_logprob": -0.14249398686864354, "compression_ratio": 1.830188679245283, "no_speech_prob": 0.00394393177703023}, {"id": 97, "seek": 56488, "start": 568.56, "end": 573.68, "text": " simpler. We just allocate a native memory, a thread local buffer when it's required and when the", "tokens": [50548, 18587, 13, 492, 445, 35713, 257, 8470, 4675, 11, 257, 7207, 2654, 21762, 562, 309, 311, 4739, 293, 562, 264, 50804], "temperature": 0.0, "avg_logprob": -0.14249398686864354, "compression_ratio": 1.830188679245283, "no_speech_prob": 0.00394393177703023}, {"id": 98, "seek": 56488, "start": 573.68, "end": 579.12, "text": " thread goes away we destroy that memory. So we don't really have to manage access to these buffer", "tokens": [50804, 7207, 1709, 1314, 321, 5293, 300, 4675, 13, 407, 321, 500, 380, 534, 362, 281, 3067, 2105, 281, 613, 21762, 51076], "temperature": 0.0, "avg_logprob": -0.14249398686864354, "compression_ratio": 1.830188679245283, "no_speech_prob": 0.00394393177703023}, {"id": 99, "seek": 56488, "start": 579.12, "end": 587.6, "text": " pools and maintain them. Right, in the case of virtual threads, multiple virtual threads may share", "tokens": [51076, 28688, 293, 6909, 552, 13, 1779, 11, 294, 264, 1389, 295, 6374, 19314, 11, 3866, 6374, 19314, 815, 2073, 51500], "temperature": 0.0, "avg_logprob": -0.14249398686864354, "compression_ratio": 1.830188679245283, "no_speech_prob": 0.00394393177703023}, {"id": 100, "seek": 56488, "start": 587.6, "end": 593.2, "text": " the same thread local buffer of the carrier thread and that's not really an issue because each one", "tokens": [51500, 264, 912, 7207, 2654, 21762, 295, 264, 17574, 7207, 293, 300, 311, 406, 534, 364, 2734, 570, 1184, 472, 51780], "temperature": 0.0, "avg_logprob": -0.14249398686864354, "compression_ratio": 1.830188679245283, "no_speech_prob": 0.00394393177703023}, {"id": 101, "seek": 59320, "start": 593.2, "end": 597.2800000000001, "text": " has exclusive access at any point in time and the JFR data is eventually going to the same place", "tokens": [50364, 575, 13005, 2105, 412, 604, 935, 294, 565, 293, 264, 508, 34658, 1412, 307, 4728, 516, 281, 264, 912, 1081, 50568], "temperature": 0.0, "avg_logprob": -0.09088702731662326, "compression_ratio": 1.7345132743362832, "no_speech_prob": 0.00023026858980301768}, {"id": 102, "seek": 59320, "start": 597.2800000000001, "end": 604.8000000000001, "text": " anyways. Right, so after the thread local buffers fill up they are migrated, the data is migrated", "tokens": [50568, 13448, 13, 1779, 11, 370, 934, 264, 7207, 2654, 9204, 433, 2836, 493, 436, 366, 48329, 11, 264, 1412, 307, 48329, 50944], "temperature": 0.0, "avg_logprob": -0.09088702731662326, "compression_ratio": 1.7345132743362832, "no_speech_prob": 0.00023026858980301768}, {"id": 103, "seek": 59320, "start": 604.8000000000001, "end": 610.88, "text": " to a set of global buffers and the global buffers essentially act as a capacity for overflow storage", "tokens": [50944, 281, 257, 992, 295, 4338, 9204, 433, 293, 264, 4338, 9204, 433, 4476, 605, 382, 257, 6042, 337, 37772, 6725, 51248], "temperature": 0.0, "avg_logprob": -0.09088702731662326, "compression_ratio": 1.7345132743362832, "no_speech_prob": 0.00023026858980301768}, {"id": 104, "seek": 59320, "start": 610.88, "end": 614.32, "text": " and it's more efficient than increasing the size of all the thread local buffers because not all", "tokens": [51248, 293, 309, 311, 544, 7148, 813, 5662, 264, 2744, 295, 439, 264, 7207, 2654, 9204, 433, 570, 406, 439, 51420], "temperature": 0.0, "avg_logprob": -0.09088702731662326, "compression_ratio": 1.7345132743362832, "no_speech_prob": 0.00023026858980301768}, {"id": 105, "seek": 61432, "start": 614.32, "end": 623.6800000000001, "text": " threads will be equally as busy with respect to JFR events. Right, so constant pools. Previously we", "tokens": [50364, 19314, 486, 312, 12309, 382, 5856, 365, 3104, 281, 508, 34658, 3931, 13, 1779, 11, 370, 5754, 28688, 13, 33606, 321, 50832], "temperature": 0.0, "avg_logprob": -0.12018214550214945, "compression_ratio": 1.7094017094017093, "no_speech_prob": 0.003703424008563161}, {"id": 106, "seek": 61432, "start": 623.6800000000001, "end": 629.7600000000001, "text": " mentioned how constant pools use a referencing ID scheme to reduce the size of JFR data and they do", "tokens": [50832, 2835, 577, 5754, 28688, 764, 257, 40582, 7348, 12232, 281, 5407, 264, 2744, 295, 508, 34658, 1412, 293, 436, 360, 51136], "temperature": 0.0, "avg_logprob": -0.12018214550214945, "compression_ratio": 1.7094017094017093, "no_speech_prob": 0.003703424008563161}, {"id": 107, "seek": 61432, "start": 629.7600000000001, "end": 636.72, "text": " this essentially works by deduplicating constants. In a hotspot the deduplication works, one way the", "tokens": [51136, 341, 4476, 1985, 538, 4172, 84, 4770, 990, 35870, 13, 682, 257, 36121, 17698, 264, 4172, 84, 4770, 399, 1985, 11, 472, 636, 264, 51484], "temperature": 0.0, "avg_logprob": -0.12018214550214945, "compression_ratio": 1.7094017094017093, "no_speech_prob": 0.003703424008563161}, {"id": 108, "seek": 61432, "start": 636.72, "end": 642.4000000000001, "text": " deduplication works is by using JFR specific bits and the metaspace data for certain constant types", "tokens": [51484, 4172, 84, 4770, 399, 1985, 307, 538, 1228, 508, 34658, 2685, 9239, 293, 264, 1131, 9375, 617, 1412, 337, 1629, 5754, 3467, 51768], "temperature": 0.0, "avg_logprob": -0.12018214550214945, "compression_ratio": 1.7094017094017093, "no_speech_prob": 0.003703424008563161}, {"id": 109, "seek": 64240, "start": 642.4, "end": 650.16, "text": " such as class with a K and also methods. So these JFR specific bits act essentially as Boolean toggles", "tokens": [50364, 1270, 382, 1508, 365, 257, 591, 293, 611, 7150, 13, 407, 613, 508, 34658, 2685, 9239, 605, 4476, 382, 23351, 28499, 26911, 904, 50752], "temperature": 0.0, "avg_logprob": -0.1233729205085236, "compression_ratio": 1.859922178988327, "no_speech_prob": 0.0007428097887896001}, {"id": 110, "seek": 64240, "start": 650.16, "end": 657.6, "text": " so when an event data reference from in a JFR local buffer somewhere references a constant", "tokens": [50752, 370, 562, 364, 2280, 1412, 6408, 490, 294, 257, 508, 34658, 2654, 21762, 4079, 15400, 257, 5754, 51124], "temperature": 0.0, "avg_logprob": -0.1233729205085236, "compression_ratio": 1.859922178988327, "no_speech_prob": 0.0007428097887896001}, {"id": 111, "seek": 64240, "start": 657.6, "end": 661.84, "text": " that bit in that constant is flipped to indicate that it's referenced somewhere that way when it's", "tokens": [51124, 300, 857, 294, 300, 5754, 307, 26273, 281, 13330, 300, 309, 311, 32734, 4079, 300, 636, 562, 309, 311, 51336], "temperature": 0.0, "avg_logprob": -0.1233729205085236, "compression_ratio": 1.859922178988327, "no_speech_prob": 0.0007428097887896001}, {"id": 112, "seek": 64240, "start": 661.84, "end": 666.16, "text": " time to actually persist the constants to disk we only have to persist the ones that are actually", "tokens": [51336, 565, 281, 767, 13233, 264, 35870, 281, 12355, 321, 787, 362, 281, 13233, 264, 2306, 300, 366, 767, 51552], "temperature": 0.0, "avg_logprob": -0.1233729205085236, "compression_ratio": 1.859922178988327, "no_speech_prob": 0.0007428097887896001}, {"id": 113, "seek": 64240, "start": 666.16, "end": 671.76, "text": " referenced not all of them. Additionally if multiple events reference the same constant", "tokens": [51552, 32734, 406, 439, 295, 552, 13, 19927, 498, 3866, 3931, 6408, 264, 912, 5754, 51832], "temperature": 0.0, "avg_logprob": -0.1233729205085236, "compression_ratio": 1.859922178988327, "no_speech_prob": 0.0007428097887896001}, {"id": 114, "seek": 67176, "start": 671.84, "end": 675.68, "text": " that bit is only flipped once and that's only used to be written once so that's where the deduplication", "tokens": [50368, 300, 857, 307, 787, 26273, 1564, 293, 300, 311, 787, 1143, 281, 312, 3720, 1564, 370, 300, 311, 689, 264, 4172, 84, 4770, 399, 50560], "temperature": 0.0, "avg_logprob": -0.09111669684658531, "compression_ratio": 1.770909090909091, "no_speech_prob": 0.00012728579167742282}, {"id": 115, "seek": 67176, "start": 675.68, "end": 681.12, "text": " happens. There are some constant types such as stack traces that don't have metaspace data", "tokens": [50560, 2314, 13, 821, 366, 512, 5754, 3467, 1270, 382, 8630, 26076, 300, 500, 380, 362, 1131, 9375, 617, 1412, 50832], "temperature": 0.0, "avg_logprob": -0.09111669684658531, "compression_ratio": 1.770909090909091, "no_speech_prob": 0.00012728579167742282}, {"id": 116, "seek": 67176, "start": 681.12, "end": 686.24, "text": " and those cases a lookup table is instead used for the deduplication and tracking and an interesting", "tokens": [50832, 293, 729, 3331, 257, 574, 1010, 3199, 307, 2602, 1143, 337, 264, 4172, 84, 4770, 399, 293, 11603, 293, 364, 1880, 51088], "temperature": 0.0, "avg_logprob": -0.09111669684658531, "compression_ratio": 1.770909090909091, "no_speech_prob": 0.00012728579167742282}, {"id": 117, "seek": 67176, "start": 686.24, "end": 690.56, "text": " thing is in substrate VM native image there is no metaspace at all so we have to rely on the", "tokens": [51088, 551, 307, 294, 27585, 18038, 8470, 3256, 456, 307, 572, 1131, 9375, 617, 412, 439, 370, 321, 362, 281, 10687, 322, 264, 51304], "temperature": 0.0, "avg_logprob": -0.09111669684658531, "compression_ratio": 1.770909090909091, "no_speech_prob": 0.00012728579167742282}, {"id": 118, "seek": 67176, "start": 690.56, "end": 698.72, "text": " lookup table approach for all the various constant types. Right, so after enough JFR data has been", "tokens": [51304, 574, 1010, 3199, 3109, 337, 439, 264, 3683, 5754, 3467, 13, 1779, 11, 370, 934, 1547, 508, 34658, 1412, 575, 668, 51712], "temperature": 0.0, "avg_logprob": -0.09111669684658531, "compression_ratio": 1.770909090909091, "no_speech_prob": 0.00012728579167742282}, {"id": 119, "seek": 69872, "start": 698.72, "end": 704.8000000000001, "text": " generated a chunk rotation must be requested and what this is is essentially the way that JFR", "tokens": [50364, 10833, 257, 16635, 12447, 1633, 312, 16436, 293, 437, 341, 307, 307, 4476, 264, 636, 300, 508, 34658, 50668], "temperature": 0.0, "avg_logprob": -0.10270694417691012, "compression_ratio": 1.9271255060728745, "no_speech_prob": 0.00792998168617487}, {"id": 120, "seek": 69872, "start": 704.8000000000001, "end": 711.6800000000001, "text": " data is continually persisted to disk. The current chunk file and disk that's open is sealed and", "tokens": [50668, 1412, 307, 22277, 13233, 292, 281, 12355, 13, 440, 2190, 16635, 3991, 293, 12355, 300, 311, 1269, 307, 21514, 293, 51012], "temperature": 0.0, "avg_logprob": -0.10270694417691012, "compression_ratio": 1.9271255060728745, "no_speech_prob": 0.00792998168617487}, {"id": 121, "seek": 69872, "start": 711.6800000000001, "end": 717.84, "text": " then a new chunk file is opened and in that process all the in-flight and memory data is flushed", "tokens": [51012, 550, 257, 777, 16635, 3991, 307, 5625, 293, 294, 300, 1399, 439, 264, 294, 12, 43636, 293, 4675, 1412, 307, 19568, 292, 51320], "temperature": 0.0, "avg_logprob": -0.10270694417691012, "compression_ratio": 1.9271255060728745, "no_speech_prob": 0.00792998168617487}, {"id": 122, "seek": 69872, "start": 717.84, "end": 724.1600000000001, "text": " to that chunk file before it's sealed and the thread that's performing this the chunk rotation", "tokens": [51320, 281, 300, 16635, 3991, 949, 309, 311, 21514, 293, 264, 7207, 300, 311, 10205, 341, 264, 16635, 12447, 51636], "temperature": 0.0, "avg_logprob": -0.10270694417691012, "compression_ratio": 1.9271255060728745, "no_speech_prob": 0.00792998168617487}, {"id": 123, "seek": 69872, "start": 724.1600000000001, "end": 728.4, "text": " must flush the thread local buffers of other threads and to do that safely we have to request", "tokens": [51636, 1633, 19568, 264, 7207, 2654, 9204, 433, 295, 661, 19314, 293, 281, 360, 300, 11750, 321, 362, 281, 5308, 51848], "temperature": 0.0, "avg_logprob": -0.10270694417691012, "compression_ratio": 1.9271255060728745, "no_speech_prob": 0.00792998168617487}, {"id": 124, "seek": 72840, "start": 728.48, "end": 736.24, "text": " a save point. So the order of operations at a chunk rotation save point is as follows on the slide", "tokens": [50368, 257, 3155, 935, 13, 407, 264, 1668, 295, 7705, 412, 257, 16635, 12447, 3155, 935, 307, 382, 10002, 322, 264, 4137, 50756], "temperature": 0.0, "avg_logprob": -0.11426162719726562, "compression_ratio": 1.6899563318777293, "no_speech_prob": 0.000335186516167596}, {"id": 125, "seek": 72840, "start": 738.0, "end": 744.4, "text": " I want to make note that it's pretty similar in open JDK as it is in substrate VM and the space", "tokens": [50844, 286, 528, 281, 652, 3637, 300, 309, 311, 1238, 2531, 294, 1269, 37082, 42, 382, 309, 307, 294, 27585, 18038, 293, 264, 1901, 51164], "temperature": 0.0, "avg_logprob": -0.11426162719726562, "compression_ratio": 1.6899563318777293, "no_speech_prob": 0.000335186516167596}, {"id": 126, "seek": 72840, "start": 744.4, "end": 751.76, "text": " between chunk rotation save points the recording time between is called an epic and you can see", "tokens": [51164, 1296, 16635, 12447, 3155, 2793, 264, 6613, 565, 1296, 307, 1219, 364, 13581, 293, 291, 393, 536, 51532], "temperature": 0.0, "avg_logprob": -0.11426162719726562, "compression_ratio": 1.6899563318777293, "no_speech_prob": 0.000335186516167596}, {"id": 127, "seek": 72840, "start": 751.76, "end": 755.76, "text": " in the green save point box that that's where we're actually flushing the JFR buffers both local", "tokens": [51532, 294, 264, 3092, 3155, 935, 2424, 300, 300, 311, 689, 321, 434, 767, 932, 5371, 264, 508, 34658, 9204, 433, 1293, 2654, 51732], "temperature": 0.0, "avg_logprob": -0.11426162719726562, "compression_ratio": 1.6899563318777293, "no_speech_prob": 0.000335186516167596}, {"id": 128, "seek": 75576, "start": 755.84, "end": 761.4399999999999, "text": " and global to disk but the most interesting thing here is that we're writing the constant pool to", "tokens": [50368, 293, 4338, 281, 12355, 457, 264, 881, 1880, 551, 510, 307, 300, 321, 434, 3579, 264, 5754, 7005, 281, 50648], "temperature": 0.0, "avg_logprob": -0.14609007154192244, "compression_ratio": 1.9634146341463414, "no_speech_prob": 0.0008827342535369098}, {"id": 129, "seek": 75576, "start": 761.4399999999999, "end": 766.4, "text": " disk outside of the save points when we're already starting epic 2 so what that means is we'll", "tokens": [50648, 12355, 2380, 295, 264, 3155, 2793, 562, 321, 434, 1217, 2891, 13581, 568, 370, 437, 300, 1355, 307, 321, 603, 50896], "temperature": 0.0, "avg_logprob": -0.14609007154192244, "compression_ratio": 1.9634146341463414, "no_speech_prob": 0.0008827342535369098}, {"id": 130, "seek": 75576, "start": 766.4, "end": 772.0, "text": " we're simultaneously writing the constants from epic 1 to disk while recording constants for", "tokens": [50896, 321, 434, 16561, 3579, 264, 35870, 490, 13581, 502, 281, 12355, 1339, 6613, 35870, 337, 51176], "temperature": 0.0, "avg_logprob": -0.14609007154192244, "compression_ratio": 1.9634146341463414, "no_speech_prob": 0.0008827342535369098}, {"id": 131, "seek": 75576, "start": 772.0, "end": 777.12, "text": " relative to epic 2 so they're kind of mingling inside the constant pools so we need to keep them", "tokens": [51176, 4972, 281, 13581, 568, 370, 436, 434, 733, 295, 275, 278, 1688, 1854, 264, 5754, 28688, 370, 321, 643, 281, 1066, 552, 51432], "temperature": 0.0, "avg_logprob": -0.14609007154192244, "compression_ratio": 1.9634146341463414, "no_speech_prob": 0.0008827342535369098}, {"id": 132, "seek": 75576, "start": 777.12, "end": 782.16, "text": " isolated however because we want to avoid writing constants perspective to epic 2 to disk into chunk", "tokens": [51432, 14621, 4461, 570, 321, 528, 281, 5042, 3579, 35870, 4585, 281, 13581, 568, 281, 12355, 666, 16635, 51684], "temperature": 0.0, "avg_logprob": -0.14609007154192244, "compression_ratio": 1.9634146341463414, "no_speech_prob": 0.0008827342535369098}, {"id": 133, "seek": 78216, "start": 782.64, "end": 789.76, "text": " file for epic 1 otherwise we'll have that mismatch and we won't be able to decode the data for", "tokens": [50388, 3991, 337, 13581, 502, 5911, 321, 603, 362, 300, 23220, 852, 293, 321, 1582, 380, 312, 1075, 281, 979, 1429, 264, 1412, 337, 50744], "temperature": 0.0, "avg_logprob": -0.14944479438696015, "compression_ratio": 1.6609442060085837, "no_speech_prob": 0.0011510089971125126}, {"id": 134, "seek": 78216, "start": 789.76, "end": 795.36, "text": " constant for epic 2 the same issue that I explained a few slides back so how we do this is we tag each", "tokens": [50744, 5754, 337, 13581, 568, 264, 912, 2734, 300, 286, 8825, 257, 1326, 9788, 646, 370, 577, 321, 360, 341, 307, 321, 6162, 1184, 51024], "temperature": 0.0, "avg_logprob": -0.14944479438696015, "compression_ratio": 1.6609442060085837, "no_speech_prob": 0.0011510089971125126}, {"id": 135, "seek": 78216, "start": 795.36, "end": 802.0, "text": " constant according to the respective epic to keep them isolated and essentially overall the", "tokens": [51024, 5754, 4650, 281, 264, 23649, 13581, 281, 1066, 552, 14621, 293, 4476, 4787, 264, 51356], "temperature": 0.0, "avg_logprob": -0.14944479438696015, "compression_ratio": 1.6609442060085837, "no_speech_prob": 0.0011510089971125126}, {"id": 136, "seek": 78216, "start": 802.0, "end": 805.8399999999999, "text": " more of the story is it allows us to reduce save point pause time by writing these constant pools", "tokens": [51356, 544, 295, 264, 1657, 307, 309, 4045, 505, 281, 5407, 3155, 935, 10465, 565, 538, 3579, 613, 5754, 28688, 51548], "temperature": 0.0, "avg_logprob": -0.14944479438696015, "compression_ratio": 1.6609442060085837, "no_speech_prob": 0.0011510089971125126}, {"id": 137, "seek": 80584, "start": 805.84, "end": 810.4, "text": " outside of the save point and another way we actually reduce save point pause time is by", "tokens": [50364, 2380, 295, 264, 3155, 935, 293, 1071, 636, 321, 767, 5407, 3155, 935, 10465, 565, 307, 538, 50592], "temperature": 0.0, "avg_logprob": -0.09560031528714337, "compression_ratio": 1.75, "no_speech_prob": 0.007811227347701788}, {"id": 138, "seek": 80584, "start": 811.52, "end": 817.0400000000001, "text": " having a dedicated JFR thread flush the global buffers to disk periodically throughout the", "tokens": [50648, 1419, 257, 8374, 508, 34658, 7207, 19568, 264, 4338, 9204, 433, 281, 12355, 38916, 3710, 264, 50924], "temperature": 0.0, "avg_logprob": -0.09560031528714337, "compression_ratio": 1.75, "no_speech_prob": 0.007811227347701788}, {"id": 139, "seek": 80584, "start": 817.0400000000001, "end": 821.2800000000001, "text": " epic time so it's not actually happening in the save points so there's less work to actually be done", "tokens": [50924, 13581, 565, 370, 309, 311, 406, 767, 2737, 294, 264, 3155, 2793, 370, 456, 311, 1570, 589, 281, 767, 312, 1096, 51136], "temperature": 0.0, "avg_logprob": -0.09560031528714337, "compression_ratio": 1.75, "no_speech_prob": 0.007811227347701788}, {"id": 140, "seek": 80584, "start": 821.2800000000001, "end": 829.0400000000001, "text": " when we are stopping the worlds to flush the buffers to disk right um", "tokens": [51136, 562, 321, 366, 12767, 264, 13401, 281, 19568, 264, 9204, 433, 281, 12355, 558, 1105, 51524], "temperature": 0.0, "avg_logprob": -0.09560031528714337, "compression_ratio": 1.75, "no_speech_prob": 0.007811227347701788}, {"id": 141, "seek": 82904, "start": 829.52, "end": 830.24, "text": " um", "tokens": [50388, 1105, 50424], "temperature": 0.0, "avg_logprob": -0.14407773561115506, "compression_ratio": 1.9538461538461538, "no_speech_prob": 0.0004302065062802285}, {"id": 142, "seek": 82904, "start": 831.8399999999999, "end": 839.1999999999999, "text": " one related note on save pointing is the question of can a chunk rotation save point interrupts", "tokens": [50504, 472, 4077, 3637, 322, 3155, 12166, 307, 264, 1168, 295, 393, 257, 16635, 12447, 3155, 935, 12729, 82, 50872], "temperature": 0.0, "avg_logprob": -0.14407773561115506, "compression_ratio": 1.9538461538461538, "no_speech_prob": 0.0004302065062802285}, {"id": 143, "seek": 82904, "start": 839.1999999999999, "end": 844.7199999999999, "text": " concurrent event emission that may be happening in other threads so we have a scenario here where", "tokens": [50872, 37702, 2280, 29513, 300, 815, 312, 2737, 294, 661, 19314, 370, 321, 362, 257, 9005, 510, 689, 51148], "temperature": 0.0, "avg_logprob": -0.14407773561115506, "compression_ratio": 1.9538461538461538, "no_speech_prob": 0.0004302065062802285}, {"id": 144, "seek": 82904, "start": 845.28, "end": 850.56, "text": " the save point actually and save points and epic transition actually interrupts the event", "tokens": [51176, 264, 3155, 935, 767, 293, 3155, 2793, 293, 13581, 6034, 767, 12729, 82, 264, 2280, 51440], "temperature": 0.0, "avg_logprob": -0.14407773561115506, "compression_ratio": 1.9538461538461538, "no_speech_prob": 0.0004302065062802285}, {"id": 145, "seek": 82904, "start": 850.56, "end": 856.24, "text": " emission and separates the constant data and the event data into different epics and different", "tokens": [51440, 29513, 293, 34149, 264, 5754, 1412, 293, 264, 2280, 1412, 666, 819, 2388, 1167, 293, 819, 51724], "temperature": 0.0, "avg_logprob": -0.14407773561115506, "compression_ratio": 1.9538461538461538, "no_speech_prob": 0.0004302065062802285}, {"id": 146, "seek": 85624, "start": 856.24, "end": 861.84, "text": " chunk files and then it will be unreadable then so that's a scenario that is in question right now", "tokens": [50364, 16635, 7098, 293, 550, 309, 486, 312, 517, 2538, 712, 550, 370, 300, 311, 257, 9005, 300, 307, 294, 1168, 558, 586, 50644], "temperature": 0.0, "avg_logprob": -0.1304159641265869, "compression_ratio": 1.6696428571428572, "no_speech_prob": 0.001865506055764854}, {"id": 147, "seek": 85624, "start": 863.04, "end": 869.76, "text": " um and in j in open JDK in hotspot the JFR code is written in C++ it's native code so it can", "tokens": [50704, 1105, 293, 294, 361, 294, 1269, 37082, 42, 294, 36121, 17698, 264, 508, 34658, 3089, 307, 3720, 294, 383, 25472, 309, 311, 8470, 3089, 370, 309, 393, 51040], "temperature": 0.0, "avg_logprob": -0.1304159641265869, "compression_ratio": 1.6696428571428572, "no_speech_prob": 0.001865506055764854}, {"id": 148, "seek": 85624, "start": 869.76, "end": 875.12, "text": " actually be interrupted for a save point so it's not really an issue at all however in", "tokens": [51040, 767, 312, 30329, 337, 257, 3155, 935, 370, 309, 311, 406, 534, 364, 2734, 412, 439, 4461, 294, 51308], "temperature": 0.0, "avg_logprob": -0.1304159641265869, "compression_ratio": 1.6696428571428572, "no_speech_prob": 0.001865506055764854}, {"id": 149, "seek": 85624, "start": 875.12, "end": 881.28, "text": " substrate VM it's Java on Java and the VM code is written in Java so the JFR stuff is Java code", "tokens": [51308, 27585, 18038, 309, 311, 10745, 322, 10745, 293, 264, 18038, 3089, 307, 3720, 294, 10745, 370, 264, 508, 34658, 1507, 307, 10745, 3089, 51616], "temperature": 0.0, "avg_logprob": -0.1304159641265869, "compression_ratio": 1.6696428571428572, "no_speech_prob": 0.001865506055764854}, {"id": 150, "seek": 88128, "start": 881.28, "end": 885.92, "text": " and potentially could save point at a very inopportune moment so how do we prevent that", "tokens": [50364, 293, 7263, 727, 3155, 935, 412, 257, 588, 294, 17158, 27172, 1623, 370, 577, 360, 321, 4871, 300, 50596], "temperature": 0.0, "avg_logprob": -0.08242131805419922, "compression_ratio": 1.880952380952381, "no_speech_prob": 0.007809943985193968}, {"id": 151, "seek": 88128, "start": 885.92, "end": 891.52, "text": " stuff from happening in substrate VM um how it's done is we have this annotation called an", "tokens": [50596, 1507, 490, 2737, 294, 27585, 18038, 1105, 577, 309, 311, 1096, 307, 321, 362, 341, 48654, 1219, 364, 50876], "temperature": 0.0, "avg_logprob": -0.08242131805419922, "compression_ratio": 1.880952380952381, "no_speech_prob": 0.007809943985193968}, {"id": 152, "seek": 88128, "start": 891.52, "end": 895.6, "text": " interruptible and what that does is that build time prevents the insertion of save point checks", "tokens": [50876, 12729, 964, 293, 437, 300, 775, 307, 300, 1322, 565, 22367, 264, 8969, 313, 295, 3155, 935, 13834, 51080], "temperature": 0.0, "avg_logprob": -0.08242131805419922, "compression_ratio": 1.880952380952381, "no_speech_prob": 0.007809943985193968}, {"id": 153, "seek": 88128, "start": 895.6, "end": 899.8399999999999, "text": " so that the code that's in the annotated with an interruptible annotation doesn't actually", "tokens": [51080, 370, 300, 264, 3089, 300, 311, 294, 264, 25339, 770, 365, 364, 12729, 964, 48654, 1177, 380, 767, 51292], "temperature": 0.0, "avg_logprob": -0.08242131805419922, "compression_ratio": 1.880952380952381, "no_speech_prob": 0.007809943985193968}, {"id": 154, "seek": 88128, "start": 899.8399999999999, "end": 904.56, "text": " save point at all so you find that a lot of the JFR code is sprinkled with this annotation all over", "tokens": [51292, 3155, 935, 412, 439, 370, 291, 915, 300, 257, 688, 295, 264, 508, 34658, 3089, 307, 30885, 1493, 365, 341, 48654, 439, 670, 51528], "temperature": 0.0, "avg_logprob": -0.08242131805419922, "compression_ratio": 1.880952380952381, "no_speech_prob": 0.007809943985193968}, {"id": 155, "seek": 88128, "start": 904.56, "end": 909.1999999999999, "text": " the place in the VM especially dealing with buffers and constant pools and event writes", "tokens": [51528, 264, 1081, 294, 264, 18038, 2318, 6260, 365, 9204, 433, 293, 5754, 28688, 293, 2280, 13657, 51760], "temperature": 0.0, "avg_logprob": -0.08242131805419922, "compression_ratio": 1.880952380952381, "no_speech_prob": 0.007809943985193968}, {"id": 156, "seek": 90920, "start": 910.1600000000001, "end": 914.32, "text": " but this has pretty big consequences for the implementation itself because", "tokens": [50412, 457, 341, 575, 1238, 955, 10098, 337, 264, 11420, 2564, 570, 50620], "temperature": 0.0, "avg_logprob": -0.11697478117766204, "compression_ratio": 1.8945578231292517, "no_speech_prob": 0.0008293712744489312}, {"id": 157, "seek": 90920, "start": 914.32, "end": 917.84, "text": " un-interruptible code that can't save point can only call other un-interruptible code that can't", "tokens": [50620, 517, 12, 5106, 5428, 964, 3089, 300, 393, 380, 3155, 935, 393, 787, 818, 661, 517, 12, 5106, 5428, 964, 3089, 300, 393, 380, 50796], "temperature": 0.0, "avg_logprob": -0.11697478117766204, "compression_ratio": 1.8945578231292517, "no_speech_prob": 0.0008293712744489312}, {"id": 158, "seek": 90920, "start": 917.84, "end": 922.08, "text": " save point which means a lot of the JDK code that's written in Java is off limits so we can't use", "tokens": [50796, 3155, 935, 597, 1355, 257, 688, 295, 264, 37082, 42, 3089, 300, 311, 3720, 294, 10745, 307, 766, 10406, 370, 321, 393, 380, 764, 51008], "temperature": 0.0, "avg_logprob": -0.11697478117766204, "compression_ratio": 1.8945578231292517, "no_speech_prob": 0.0008293712744489312}, {"id": 159, "seek": 90920, "start": 922.08, "end": 926.96, "text": " things like the normal hash tables, re-entrant locks, etc. we have to kind of like roll our own", "tokens": [51008, 721, 411, 264, 2710, 22019, 8020, 11, 319, 12, 317, 7541, 20703, 11, 5183, 13, 321, 362, 281, 733, 295, 411, 3373, 527, 1065, 51252], "temperature": 0.0, "avg_logprob": -0.11697478117766204, "compression_ratio": 1.8945578231292517, "no_speech_prob": 0.0008293712744489312}, {"id": 160, "seek": 90920, "start": 926.96, "end": 931.84, "text": " versions of that which are un-interruptible another thing is we can't even use manage memory on the", "tokens": [51252, 9606, 295, 300, 597, 366, 517, 12, 5106, 5428, 964, 1071, 551, 307, 321, 393, 380, 754, 764, 3067, 4675, 322, 264, 51496], "temperature": 0.0, "avg_logprob": -0.11697478117766204, "compression_ratio": 1.8945578231292517, "no_speech_prob": 0.0008293712744489312}, {"id": 161, "seek": 90920, "start": 931.84, "end": 936.1600000000001, "text": " Java heap because that can induce a garbage collection which requires save point and that's", "tokens": [51496, 10745, 33591, 570, 300, 393, 41263, 257, 14150, 5765, 597, 7029, 3155, 935, 293, 300, 311, 51712], "temperature": 0.0, "avg_logprob": -0.11697478117766204, "compression_ratio": 1.8945578231292517, "no_speech_prob": 0.0008293712744489312}, {"id": 162, "seek": 93616, "start": 936.9599999999999, "end": 942.0, "text": " not un-interruptible so we have to use unmanaged native memory in order to craft", "tokens": [50404, 406, 517, 12, 5106, 5428, 964, 370, 321, 362, 281, 764, 517, 1601, 2980, 8470, 4675, 294, 1668, 281, 8448, 50656], "temperature": 0.0, "avg_logprob": -0.1482424410906705, "compression_ratio": 1.6221198156682028, "no_speech_prob": 6.013140955474228e-05}, {"id": 163, "seek": 93616, "start": 942.0, "end": 946.64, "text": " room data structures to deal with a lot of these things so it's a little bit of work", "tokens": [50656, 1808, 1412, 9227, 281, 2028, 365, 257, 688, 295, 613, 721, 370, 309, 311, 257, 707, 857, 295, 589, 50888], "temperature": 0.0, "avg_logprob": -0.1482424410906705, "compression_ratio": 1.6221198156682028, "no_speech_prob": 6.013140955474228e-05}, {"id": 164, "seek": 93616, "start": 946.64, "end": 952.7199999999999, "text": " dealing with that and the last thing I want to talk about and the last difference I want to", "tokens": [50888, 6260, 365, 300, 293, 264, 1036, 551, 286, 528, 281, 751, 466, 293, 264, 1036, 2649, 286, 528, 281, 51192], "temperature": 0.0, "avg_logprob": -0.1482424410906705, "compression_ratio": 1.6221198156682028, "no_speech_prob": 6.013140955474228e-05}, {"id": 165, "seek": 93616, "start": 952.7199999999999, "end": 961.68, "text": " mention between JFR and substrate VM and hotspot is related to how JFR interfaces from the the", "tokens": [51192, 2152, 1296, 508, 34658, 293, 27585, 18038, 293, 36121, 17698, 307, 4077, 281, 577, 508, 34658, 28416, 490, 264, 264, 51640], "temperature": 0.0, "avg_logprob": -0.1482424410906705, "compression_ratio": 1.6221198156682028, "no_speech_prob": 6.013140955474228e-05}, {"id": 166, "seek": 96168, "start": 961.76, "end": 969.8399999999999, "text": " Java level JFR code to the VM level JFR code and in open JDK it happens in the JVM class here", "tokens": [50368, 10745, 1496, 508, 34658, 3089, 281, 264, 18038, 1496, 508, 34658, 3089, 293, 294, 1269, 37082, 42, 309, 2314, 294, 264, 508, 53, 44, 1508, 510, 50772], "temperature": 0.0, "avg_logprob": -0.1144853494106195, "compression_ratio": 1.7423312883435582, "no_speech_prob": 0.002796702552586794}, {"id": 167, "seek": 96168, "start": 969.8399999999999, "end": 976.4799999999999, "text": " you can see on the left side of sorry the right side of the slide and these are basically the", "tokens": [50772, 291, 393, 536, 322, 264, 1411, 1252, 295, 2597, 264, 558, 1252, 295, 264, 4137, 293, 613, 366, 1936, 264, 51104], "temperature": 0.0, "avg_logprob": -0.1144853494106195, "compression_ratio": 1.7423312883435582, "no_speech_prob": 0.002796702552586794}, {"id": 168, "seek": 96168, "start": 976.4799999999999, "end": 985.3599999999999, "text": " points where the Java level JFR code and the JDK calls down to hotspot at the VM level using JNI", "tokens": [51104, 2793, 689, 264, 10745, 1496, 508, 34658, 3089, 293, 264, 37082, 42, 5498, 760, 281, 36121, 17698, 412, 264, 18038, 1496, 1228, 508, 42496, 51548], "temperature": 0.0, "avg_logprob": -0.1144853494106195, "compression_ratio": 1.7423312883435582, "no_speech_prob": 0.002796702552586794}, {"id": 169, "seek": 98536, "start": 985.36, "end": 991.92, "text": " so we reuse that code in native image we reuse that Java level JFR code from the JDK", "tokens": [50364, 370, 321, 26225, 300, 3089, 294, 8470, 3256, 321, 26225, 300, 10745, 1496, 508, 34658, 3089, 490, 264, 37082, 42, 50692], "temperature": 0.0, "avg_logprob": -0.14506346456120522, "compression_ratio": 1.64, "no_speech_prob": 0.0016473226714879274}, {"id": 170, "seek": 98536, "start": 992.8000000000001, "end": 997.92, "text": " but there's no underlying hotspot implementation to call into so how do we resolve that mismatch", "tokens": [50736, 457, 456, 311, 572, 14217, 36121, 17698, 11420, 281, 818, 666, 370, 577, 360, 321, 14151, 300, 23220, 852, 50992], "temperature": 0.0, "avg_logprob": -0.14506346456120522, "compression_ratio": 1.64, "no_speech_prob": 0.0016473226714879274}, {"id": 171, "seek": 98536, "start": 999.04, "end": 1004.88, "text": " what we use is we use substitutions which Feeb has talked about a little bit but I'll mention again", "tokens": [51048, 437, 321, 764, 307, 321, 764, 26441, 3666, 597, 479, 1653, 65, 575, 2825, 466, 257, 707, 857, 457, 286, 603, 2152, 797, 51340], "temperature": 0.0, "avg_logprob": -0.14506346456120522, "compression_ratio": 1.64, "no_speech_prob": 0.0016473226714879274}, {"id": 172, "seek": 98536, "start": 1004.88, "end": 1011.52, "text": " but essentially what it does is allows us at build time to specify redirects from these", "tokens": [51340, 457, 4476, 437, 309, 775, 307, 4045, 505, 412, 1322, 565, 281, 16500, 29066, 82, 490, 613, 51672], "temperature": 0.0, "avg_logprob": -0.14506346456120522, "compression_ratio": 1.64, "no_speech_prob": 0.0016473226714879274}, {"id": 173, "seek": 101152, "start": 1012.24, "end": 1017.84, "text": " Java methods to our own implementation the JFR VM level code so on the right side you can see", "tokens": [50400, 10745, 7150, 281, 527, 1065, 11420, 264, 508, 34658, 18038, 1496, 3089, 370, 322, 264, 558, 1252, 291, 393, 536, 50680], "temperature": 0.0, "avg_logprob": -0.12113590801463407, "compression_ratio": 1.825, "no_speech_prob": 0.001621554489247501}, {"id": 174, "seek": 101152, "start": 1018.72, "end": 1022.88, "text": " mark chunk final is highlighted and that corresponds to the Java level code on the left", "tokens": [50724, 1491, 16635, 2572, 307, 17173, 293, 300, 23249, 281, 264, 10745, 1496, 3089, 322, 264, 1411, 50932], "temperature": 0.0, "avg_logprob": -0.12113590801463407, "compression_ratio": 1.825, "no_speech_prob": 0.001621554489247501}, {"id": 175, "seek": 101152, "start": 1023.52, "end": 1029.84, "text": " sorry on the right I keep getting mixed up on the right side of the of the slide so we can see", "tokens": [50964, 2597, 322, 264, 558, 286, 1066, 1242, 7467, 493, 322, 264, 558, 1252, 295, 264, 295, 264, 4137, 370, 321, 393, 536, 51280], "temperature": 0.0, "avg_logprob": -0.12113590801463407, "compression_ratio": 1.825, "no_speech_prob": 0.001621554489247501}, {"id": 176, "seek": 101152, "start": 1029.84, "end": 1033.84, "text": " that we're actually grabbing that and then redirecting it to our own substrate VM base", "tokens": [51280, 300, 321, 434, 767, 23771, 300, 293, 550, 29066, 278, 309, 281, 527, 1065, 27585, 18038, 3096, 51480], "temperature": 0.0, "avg_logprob": -0.12113590801463407, "compression_ratio": 1.825, "no_speech_prob": 0.001621554489247501}, {"id": 177, "seek": 101152, "start": 1033.84, "end": 1038.0, "text": " implementation of that code so that's how we kind of resolve that mismatch", "tokens": [51480, 11420, 295, 300, 3089, 370, 300, 311, 577, 321, 733, 295, 14151, 300, 23220, 852, 51688], "temperature": 0.0, "avg_logprob": -0.12113590801463407, "compression_ratio": 1.825, "no_speech_prob": 0.001621554489247501}, {"id": 178, "seek": 103800, "start": 1038.96, "end": 1044.64, "text": " um yeah with that said um that basically concludes my presentation if you're interested", "tokens": [50412, 1105, 1338, 365, 300, 848, 1105, 300, 1936, 24643, 452, 5860, 498, 291, 434, 3102, 50696], "temperature": 0.0, "avg_logprob": -0.18439764976501466, "compression_ratio": 1.6242774566473988, "no_speech_prob": 0.0013651615008711815}, {"id": 179, "seek": 103800, "start": 1045.52, "end": 1050.64, "text": " there are further links for for more reading there's some documentation and some blog posts as well", "tokens": [50740, 456, 366, 3052, 6123, 337, 337, 544, 3760, 456, 311, 512, 14333, 293, 512, 6968, 12300, 382, 731, 50996], "temperature": 0.0, "avg_logprob": -0.18439764976501466, "compression_ratio": 1.6242774566473988, "no_speech_prob": 0.0013651615008711815}, {"id": 180, "seek": 103800, "start": 1051.28, "end": 1056.72, "text": " and you can always approach me as outside as well if you have more questions um yeah how good", "tokens": [51028, 293, 291, 393, 1009, 3109, 385, 382, 2380, 382, 731, 498, 291, 362, 544, 1651, 1105, 1338, 577, 665, 51300], "temperature": 0.0, "avg_logprob": -0.18439764976501466, "compression_ratio": 1.6242774566473988, "no_speech_prob": 0.0013651615008711815}, {"id": 181, "seek": 105672, "start": 1056.72, "end": 1069.04, "text": " you are for time Chris okay if there's any questions I'm happy to answer them now", "tokens": [50364, 291, 366, 337, 565, 6688, 1392, 498, 456, 311, 604, 1651, 286, 478, 2055, 281, 1867, 552, 586, 50980], "temperature": 0.0, "avg_logprob": -0.6598983244462446, "compression_ratio": 1.0657894736842106, "no_speech_prob": 0.011082753539085388}, {"id": 182, "seek": 106904, "start": 1070.0, "end": 1077.04, "text": " you just did such a good job explaining it", "tokens": [50412, 291, 445, 630, 1270, 257, 665, 1691, 13468, 309, 50764], "temperature": 0.0, "avg_logprob": -0.36429605327668735, "compression_ratio": 1.5844155844155845, "no_speech_prob": 0.0037896204739809036}, {"id": 183, "seek": 106904, "start": 1079.44, "end": 1080.8799999999999, "text": " thanks yeah", "tokens": [50884, 3231, 1338, 50956], "temperature": 0.0, "avg_logprob": -0.36429605327668735, "compression_ratio": 1.5844155844155845, "no_speech_prob": 0.0037896204739809036}, {"id": 184, "seek": 106904, "start": 1084.48, "end": 1090.48, "text": " on on substrate VM is there did you measure impagant time to save point because if is it", "tokens": [51136, 322, 322, 27585, 18038, 307, 456, 630, 291, 3481, 704, 559, 394, 565, 281, 3155, 935, 570, 498, 307, 309, 51436], "temperature": 0.0, "avg_logprob": -0.36429605327668735, "compression_ratio": 1.5844155844155845, "no_speech_prob": 0.0037896204739809036}, {"id": 185, "seek": 106904, "start": 1090.48, "end": 1096.6399999999999, "text": " uninterruptible you know this uninterruptible trade oh time to save points yeah yeah I could imagine", "tokens": [51436, 49234, 5428, 964, 291, 458, 341, 49234, 5428, 964, 4923, 1954, 565, 281, 3155, 2793, 1338, 1338, 286, 727, 3811, 51744], "temperature": 0.0, "avg_logprob": -0.36429605327668735, "compression_ratio": 1.5844155844155845, "no_speech_prob": 0.0037896204739809036}, {"id": 186, "seek": 109664, "start": 1096.64, "end": 1101.8400000000001, "text": " yeah um I'm not really sure of the exact figures I can't really give you a number but um I I know", "tokens": [50364, 1338, 1105, 286, 478, 406, 534, 988, 295, 264, 1900, 9624, 286, 393, 380, 534, 976, 291, 257, 1230, 457, 1105, 286, 286, 458, 50624], "temperature": 0.0, "avg_logprob": -0.1266924258201353, "compression_ratio": 1.8638132295719845, "no_speech_prob": 0.0031163457315415144}, {"id": 187, "seek": 109664, "start": 1101.8400000000001, "end": 1107.44, "text": " what you're saying it it would potentially an issue I haven't not really aware of it um but yeah", "tokens": [50624, 437, 291, 434, 1566, 309, 309, 576, 7263, 364, 2734, 286, 2378, 380, 406, 534, 3650, 295, 309, 1105, 457, 1338, 50904], "temperature": 0.0, "avg_logprob": -0.1266924258201353, "compression_ratio": 1.8638132295719845, "no_speech_prob": 0.0031163457315415144}, {"id": 188, "seek": 109664, "start": 1107.44, "end": 1112.3200000000002, "text": " that that's definitely a concern um but it's not just the jfr code that's marked as interruptible", "tokens": [50904, 300, 300, 311, 2138, 257, 3136, 1105, 457, 309, 311, 406, 445, 264, 361, 5779, 3089, 300, 311, 12658, 382, 12729, 964, 51148], "temperature": 0.0, "avg_logprob": -0.1266924258201353, "compression_ratio": 1.8638132295719845, "no_speech_prob": 0.0031163457315415144}, {"id": 189, "seek": 109664, "start": 1112.3200000000002, "end": 1116.88, "text": " a lot of the gc code as well a lot of the low-level operations they they must also be", "tokens": [51148, 257, 688, 295, 264, 290, 66, 3089, 382, 731, 257, 688, 295, 264, 2295, 12, 12418, 7705, 436, 436, 1633, 611, 312, 51376], "temperature": 0.0, "avg_logprob": -0.1266924258201353, "compression_ratio": 1.8638132295719845, "no_speech_prob": 0.0031163457315415144}, {"id": 190, "seek": 109664, "start": 1116.88, "end": 1123.76, "text": " uninterruptible so it's not just jfr yeah understood thanks yeah actually to tag on to that a lot of", "tokens": [51376, 49234, 5428, 964, 370, 309, 311, 406, 445, 361, 5779, 1338, 7320, 3231, 1338, 767, 281, 6162, 322, 281, 300, 257, 688, 295, 51720], "temperature": 0.0, "avg_logprob": -0.1266924258201353, "compression_ratio": 1.8638132295719845, "no_speech_prob": 0.0031163457315415144}, {"id": 191, "seek": 112376, "start": 1123.76, "end": 1129.36, "text": " jfr code is really just instrumenting other low-level code which is already an", "tokens": [50364, 361, 5779, 3089, 307, 534, 445, 7198, 278, 661, 2295, 12, 12418, 3089, 597, 307, 1217, 364, 50644], "temperature": 0.0, "avg_logprob": -0.19605434642118566, "compression_ratio": 1.6650485436893203, "no_speech_prob": 0.0035356737207621336}, {"id": 192, "seek": 112376, "start": 1129.36, "end": 1134.08, "text": " uninterruptible so it's like collateral damage it's not really an issue to add a little bit more on", "tokens": [50644, 49234, 5428, 964, 370, 309, 311, 411, 41875, 4344, 309, 311, 406, 534, 364, 2734, 281, 909, 257, 707, 857, 544, 322, 50880], "temperature": 0.0, "avg_logprob": -0.19605434642118566, "compression_ratio": 1.6650485436893203, "no_speech_prob": 0.0035356737207621336}, {"id": 193, "seek": 112376, "start": 1134.96, "end": 1142.64, "text": " to code that's already an intructible such as uh jfr gc event handling and uh slow path allocation", "tokens": [50924, 281, 3089, 300, 311, 1217, 364, 560, 1757, 964, 1270, 382, 2232, 361, 5779, 290, 66, 2280, 13175, 293, 2232, 2964, 3100, 27599, 51308], "temperature": 0.0, "avg_logprob": -0.19605434642118566, "compression_ratio": 1.6650485436893203, "no_speech_prob": 0.0035356737207621336}, {"id": 194, "seek": 112376, "start": 1142.64, "end": 1146.48, "text": " stuff that's already you can't save point there anyways thank you", "tokens": [51308, 1507, 300, 311, 1217, 291, 393, 380, 3155, 935, 456, 13448, 1309, 291, 51500], "temperature": 0.0, "avg_logprob": -0.19605434642118566, "compression_ratio": 1.6650485436893203, "no_speech_prob": 0.0035356737207621336}, {"id": 195, "seek": 114648, "start": 1146.56, "end": 1149.68, "text": " okay", "tokens": [50368, 1392, 50524], "temperature": 0.0, "avg_logprob": -0.7253914674123129, "compression_ratio": 0.8780487804878049, "no_speech_prob": 0.005813088268041611}, {"id": 196, "seek": 114648, "start": 1152.64, "end": 1157.68, "text": " okay uh thank you for listening", "tokens": [50672, 1392, 2232, 1309, 291, 337, 4764, 50924], "temperature": 0.0, "avg_logprob": -0.7253914674123129, "compression_ratio": 0.8780487804878049, "no_speech_prob": 0.005813088268041611}], "language": "en"}