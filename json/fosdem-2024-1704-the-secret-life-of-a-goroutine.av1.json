{"text": " It's time for our first actual talk of the day, which is by a very frequent speaker who I didn't have to look up the introduction of, because every time I look at his talk, it's like, wow, I learned something very deep about Go. So, small applause. Okay, just... Hello, everybody. Well, I'm going to talk about the secret life of a Go routine. This comes from my interest about how Go works internally, and I was investigating how the Go routine works internally. So, when I started investigating it, my idea of how Go routines were created and all that stuff was something like this. A caring mother with a baby in her arms, taking care of that beautiful, full of joy baby. It wasn't like that, okay? I started digging into the code and I realized that it's more like this. And necromancer racing the deads. I was like, why? There's a reason for that. But before that, I'm going to talk about something more general, that is the Go scheduler. For understanding how the Go routine works, we need to understand how the scheduler works and how it is shaped. So, let's start with the different pieces of the Go scheduler. One of them is the P extract that is the representation of a virtual CPU. Whenever you say Go Max Prox, what you are saying is the number of pieces that the scheduler has. And a processor, as I said, is a virtual representation of the CPU. It can have a status that can be either running, c-scrolling, or g-stop. It has associated the current M. We are going to see what an M is in a moment. Then it has, each processor has a queue of Go routines that needs to be executed. And a list of free Go routines. We are going to see what free Go routines are later. And, of course, other metadata. This is a very shallow explanation of the scheduler. This is an over simplification. Of course, it's more complex than that. But, well, a lot of other metadata inside the PS track. Let's talk about the M. The M is the self-representation of an operating system thread. It's what is executing your code in the CPU. And it has associated normally the current Go routine that is running in this M, in this machine. And the current processor that is associated to this M, that can be null, actually. There are some cases where the M is not associated to a processor. But, in general, they are associated. And other metadata. Let's talk about, let me, let's talk about the scheduler itself. On top of all these M's and P's, there's a struct that is called a schedule. That is, it has all the, it has a list of all the, all the idle M's, all the M's that are not doing any work, all the idle P's, processors that have not, that are not doing any work. All the, at least of global runnable Go routines, a queue of work that is not associated to any specific processor for now. And a list of global free Go routines. Okay. And the start of our show, the Go routine. There's a struct that is called GStrug. That struct is, represents a Go routine. And a Go routine is composed by, in a lot of the stuff, but mainly you have a stack that is a two kilobytes chunk of memory. The program counter that is similar to the program counter in a thread that is pointing to the next, well, to the current instruction that is executing. The status of the Go routine that can be running, waiting, runnable. There's a lot of different statuses. The current M that is associated to this Go routine is being executed right now. And the wait reason. The wait reason is if the Go routine is waiting, they have to be waiting for something. They have to be a reason for waiting. And that's the way reason. There's a lot of other metadata. But let's take a look at the whole picture. As I said, we have the scheduler at the top left with a list of free Go routines, a list of runnable Go routines, a list of either processors, either machines. And we have running processors with running Go routines associated with machines and all that stuff. Also, another interesting thing is that at global level in the runtime, as global variables, we have a list of all the M's, a list of all the P's, and a list of all the Go routines. That really are three global variables in the runtime. Okay, but how Go routines are created? This is where the necromancer raising the dead's metaphor comes into place. Because whenever you create a Go routine with just Peggy's, you create a spawn a new Go routine and start running things on that. But that's not what is happening. There's two ways of creating a Go routine. One option is to create it from scratch and the other option is to reuse all Go routine that is no longer working. So this is what is happening. Whenever a Go routine finish, it's changed the state to dead. So all that free Go routines, actually they are dead Go routines. So whenever you need a new Go routine, you can reuse one of them. Or the other option, if there's no free Go routine or dead Go routine to reuse, you create a new Go routine full of life, you kill it, and then you raise that from the dead. So that's the process. And actually that is how it works in the source code. It was shocking for me and it was a funny way of representing this. So let's see an example of that. Imagine that I have this Go routine here that wants to create a new Go routine. What it's going to do is pick one of the free Go routines in the free list and raise that from the dead, convert that into a runnable, put that in the queue of the runnable Go routines of the processor, and call the scheduler and the scheduler is going to, well, and the scheduler is going to eventually execute that Go routine. Another option is this Go routine here wants to run a new Go routine, spawn a new Go routine, but there's nothing in the free list of the processor. So it's going to go to the global free list of the scheduler and pick a chunk of them, move them to the processor, and then pick one of them and raise that from the dead and add it to the queue. And finally you have the option of this one is it wants to create a new Go routine, but there's nothing in the global queue. So what it's going to do is create a new Go routine. It's going to kill it and then it's going to raise that from the dead and put in the queue and all that stuff. So that's how Go routines are created. Let's see how Go routines, how is the life of a Go routine. A Go routine can go through a lot of different states, can go to runable to running, from running to waiting, from waiting to runable, from running to preempted, from preempted to waiting. There's a lot of stuff. Let's see how, let's see all these transitions one by one. From runable to running. That happens when you for example have a Go routine have finished the job or a Go routine start waiting for something. So it's going to call the scheduler. So the scheduler is going to try to find another Go routine to execute. The first thing that is going to do is try to find a Go routine in the local processor, in the runable list of the local processor. If there's nothing, it's going to go to the global runable queue and it's going to take some of that, it's going to move that work into the processor, it's going to schedule one of that Go routines to be executed. Then if there's nothing in the global queue, it's going to go to the net pool. The net pool is this system that allows Go to do IO work in an efficient way. And what it does is do the IO work and whenever it's finished, it gets the Go routine runable again. But sometimes what we do is we need to find work to do. So we go to the net pool and check if something is already done and start executing that. If there's nothing in the net pool, we are going to steal work from other processors. And if not, we are going to help the garbage collector in the marked face. Well, once we have found a Go routine in all the process, we are going to mark that as running and we are going to assign the machine, the operating system thread to that Go routine. We are going to mark that as running and we are going to start executing the code. Another option is running, well, another change is running to waiting. One of the interesting part of this is it's exemplifies how Go routines are cooperative entities. So they cooperate to give you the sensation of concurrency. So the Go routine, when the Go routine needs to wait for something, is the own Go routine who parks itself. Whenever I have to write to a channel, for example, if the channel is not buffered and I have to wait for something, what I'm going to do as a Go routine is park myself, stop myself, check my state to waiting, set the wait reason, detach myself from the operating system thread and run the scheduler. It's the Go routine that is marking itself as waiting, the one that is calling the scheduler to schedule the new Go routine. So the scheduler is going to find another task and it's going to start running that. So what are the reasons why we can wait? If you go to the Go source code, and actually there's in the bottom right corner, I usually put some references to the Go source code, but well, if you go to that point in the Go source code, you are going to see the wait reasons and that's the least of all the wait reasons. There's no more, there's no less. That's all the wait reasons. Don't pay too much attention to that. I'm going to summarize that. If you want to take a look, you can go. But the summary is you have GC reasons, garbage collector reasons, mutex reasons, semaphore reasons, channel reasons, sleep reasons, and other reasons. That's mainly why the garbage, why the Go routines waits for something. Okay, from running to Cisco and to running or runable again. Well, the Cisco is an interesting part. The Cisco is basically calling the operating system to do something and that can be fast or can be slow. And for some Cisco, it's kind of obvious, but for some Cisco, it's not so obvious. So what it does is whenever you enter in a Cisco, whenever you try to execute a Cisco, it's going to detach from the processor and it's going to detect if the Cisco is slow or fast. And if it's a fast Cisco, it's going to finish the Cisco and go back directly to running. But if the Cisco is slow, it's going to just stay in Cisco state and it's going to detach the processor. Well, it's going to keep the processor detached so the processor can select another Go routine to execute and it's going to finish the Cisco eventually and whenever it finish, it's going to move the Go routine to runable again and then queue that in a processor and all that stuff. The other thing that is interesting is the copy stack status. Whenever a Go routine needs to grow the stack because it needs more space for the function parameters or for the local variables of the function execution, it's passed through this process that it's going to move from running to copy stack. It's going to reserve the double of the current stack size in memory, copy over all the information from one place to another and change the pointers and then it's going to move back from copy stack to running again. From waiting to runable, this is a very interesting case because, again, as I said, Go routines are cooperative. So normally, a Go routine, it's changed from waiting to runable whenever other Go routine calls go ready. Whenever other Go routines say to my Go routine that it's ready to keep executing, we are going to see examples of that later. So whenever Go ready is called, for example, if a Go routine is sending something to a channel and some other Go routine is waiting, it's going to wake up that Go routine, it's going to mark us ready that Go routine. Then it's going to mark us ready, it's going to add that to the queue of the processor and try to get a processor to execute that. Another way is when you reactivate a list of Go routines that happens, for example, when the garbage collector have to reactivate some of the Go routines and then the garbage collector are waiting for the garbage collector phase, for the mark phase, and when that's finished, it's going to wake up a list of Go routines. Another case, it's when there's a case where it doesn't need to wait. Imagine that you say, hey, I'm going to wait for X, but that X is already fulfilled, so I'm going to go back to runable directly. Another thing is when you are trying to find a Go routine to execute the scheduler, you check the scheduler, sorry, you check the net pool, and the net pool sometimes has these Go routines that in theory they are waiting, but the data is already there or the job is already done. So it just moved that app from waiting to runable. Okay, from running to preempt to waiting or runable. Go has a preemptive garbage collector, has a preemptive runtime, and what it does is when a Go routine is executing for too much time, the system monitor is going to detect that and it's going to send a signal to the operating system thread that is executing the Go routine. That signal is going to mark the Go routine as preempt, so it's going to be moved from running to preempt, and eventually the Go routine itself is going to find the time for moving from preempt to waiting. And after the next garbage collector scan, it's going to move from waiting to runable again. So again, this is the whole life cycle, runable, running, syscall, waiting, preempt, govistak. Now all these states should be more obvious or more clear to everybody. There are some other kind of similar states of parallel states related to garbage collector. This is again a bit of a simplification, but this is in general what is the kind of state that you have in the Go routines. So let's see some examples. Imagine that you have a channel and you want to send data to that channel. The channel is not buffered, and there's nobody else waiting for that. So I try to send the data and because nobody's waiting, I'm going to need to wait for that. So I'm going to park myself, the Go routine is going to park itself, it's going to add itself to a list of Go routines that is inside the extract of the channel, and it's going to wait there. So it's there, it's waiting, and eventually another Go routine comes to read from the channel. What it's going to do is go there, read the data directly from the memory of the other Go routine, and then when it has the data, it's going to call Go ready on that Go routine saying this Go routine is already prepared to keep going. It's going to, and that's going to end in this state, and eventually the scheduler is going to select that Go routine to be run and everything is going to keep going. Yeah, this is the whole picture, trying to send the data, waiting inside the channel, getting the data from the other side, and the other Go routine is the one that is responsible of waking up the Go routine that was waiting in the channel. Let's see another example. Let's talk about the wake groups. For example, I can create a wake group and add three in this case. This is a very common pattern. And then I just found three Go routines that are going to do certain work in parallel. Then I'm going to wait at that point, maybe one Go routine is already running, maybe not, doesn't matter. So I call wait, so I'm now waiting. The Go routines keep going, maybe some of them are executed, maybe some of them have finished already, doesn't matter. Some of them finish and are there. And the last one, the last one is going to call done, the last done, and it's going to see that, hey, the wake group is already zero, so I'm going to call ready on the list of Go routines that are waiting for this wake group. So that end up with this situation where that's a runnable Go routine that is going to eventually be executed by the, well, that is going to be a schedule by the scheduler, and that's it. Again, the whole picture here. Okay, let's talk about how Go routines die. There's a Go routine normally dies when it finished the work. Basically, whenever there's nothing else to execute, it's going to change the state to that, it's going to set most of the data to the zero value, it's going to disconnect the Go routine from the end, add the Go routine to the free list of the processor, the dead Go routine to the free list of the processor, and call the scheduler to find anything else to execute. So, yeah, the whole life of the Go routine. Again, if you see this is the scenario where the Go routines are doing things. If I did my job correctly, you now should understand this better. And also this should sound familiar to. So let me finish with a couple things. One of them is I want to thanks Laura Pareja, the one that did all the illustrations for this talk. All the illustrations are creative common by. And you can see the webpage of Laura Pareja. So you can reuse it that do whatever you want with all that images. Also, I want to, I have a gift from MatterMos that is my company, they're the company that I work for. I have some stickers. I going to left out the stickers there, like Margie said. So that's exactly right there. So feel free to pick as many as you want. But I don't know if, well, I also have some pins too, but they are going to fly probably. Another thing is what is missing. I haven't talked about certain things because in the sake of simplicity, I try to avoid getting too much into the details. One of the things that I removed from the equation and have a lot to do with Go routines is garbage collector. I ignore the garbage collector entirely and it's a big chunk of how the scheduler interacts and how the Go routines are moving from one stage to another and all that stuff. The net pool, I mentioned the net pool, but I haven't entered into the details. There's very good talks about the garbage collector and the net pool out there. I know SIGO. Also, SIGO have certain implications with the Go routines also, but I have ignored them. The mark assist phase that is kind of important is a relevant part of things that Go routine does, assisting the garbage collector in the mark phase. This is the monitor that I have mentioned, but I haven't talked in detail about that. But again, there's talks around system monitor out there. One of the main references is the Go source code. I totally recommend you to go there and explore it. There's an illustrated text of Go runtime scheduler that is a YouTube video there. There's a series of posts from Argonel Labs about the Go scheduler. It's from 2018, so it's not super up today, but the general patterns are still there. Well, I hope this talk, after this talk, you have a better understanding of how the Go routines work, how the Go routines change from one state to another and all that stuff. But I want, what is more important to me, I want to encourage you to go there and explore the Go source code because it's a great source of information. There's a lot of super cool stuff there. And well, and depending on a combination of your passion about learning and your taste in movies, this can be more exciting than a zombie movie. So thank you. If you want to keep in touch with me, feel free to contact me. And the other thing, if you want to have a follow up session, then try this. If you want to have a follow up session, asking questions or whatever, feel free to join there. If you're leaving. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 13.52, "text": " It's time for our first actual talk of the day, which is by a very frequent speaker", "tokens": [50364, 467, 311, 565, 337, 527, 700, 3539, 751, 295, 264, 786, 11, 597, 307, 538, 257, 588, 18004, 8145, 51040], "temperature": 0.0, "avg_logprob": -0.3142156293315272, "compression_ratio": 1.4430379746835442, "no_speech_prob": 0.5617666244506836}, {"id": 1, "seek": 0, "start": 13.52, "end": 18.92, "text": " who I didn't have to look up the introduction of, because every time I look at his talk,", "tokens": [51040, 567, 286, 994, 380, 362, 281, 574, 493, 264, 9339, 295, 11, 570, 633, 565, 286, 574, 412, 702, 751, 11, 51310], "temperature": 0.0, "avg_logprob": -0.3142156293315272, "compression_ratio": 1.4430379746835442, "no_speech_prob": 0.5617666244506836}, {"id": 2, "seek": 0, "start": 18.92, "end": 22.48, "text": " it's like, wow, I learned something very deep about Go.", "tokens": [51310, 309, 311, 411, 11, 6076, 11, 286, 3264, 746, 588, 2452, 466, 1037, 13, 51488], "temperature": 0.0, "avg_logprob": -0.3142156293315272, "compression_ratio": 1.4430379746835442, "no_speech_prob": 0.5617666244506836}, {"id": 3, "seek": 2248, "start": 22.48, "end": 24.48, "text": " So, small applause.", "tokens": [50364, 407, 11, 1359, 9969, 13, 50464], "temperature": 0.0, "avg_logprob": -0.3817360511192909, "compression_ratio": 1.453416149068323, "no_speech_prob": 0.32139790058135986}, {"id": 4, "seek": 2248, "start": 24.48, "end": 26.48, "text": " Okay, just...", "tokens": [50464, 1033, 11, 445, 485, 50564], "temperature": 0.0, "avg_logprob": -0.3817360511192909, "compression_ratio": 1.453416149068323, "no_speech_prob": 0.32139790058135986}, {"id": 5, "seek": 2248, "start": 26.48, "end": 32.480000000000004, "text": " Hello, everybody.", "tokens": [50564, 2425, 11, 2201, 13, 50864], "temperature": 0.0, "avg_logprob": -0.3817360511192909, "compression_ratio": 1.453416149068323, "no_speech_prob": 0.32139790058135986}, {"id": 6, "seek": 2248, "start": 32.480000000000004, "end": 37.480000000000004, "text": " Well, I'm going to talk about the secret life of a Go routine.", "tokens": [50864, 1042, 11, 286, 478, 516, 281, 751, 466, 264, 4054, 993, 295, 257, 1037, 9927, 13, 51114], "temperature": 0.0, "avg_logprob": -0.3817360511192909, "compression_ratio": 1.453416149068323, "no_speech_prob": 0.32139790058135986}, {"id": 7, "seek": 2248, "start": 37.480000000000004, "end": 43.480000000000004, "text": " This comes from my interest about how Go works internally,", "tokens": [51114, 639, 1487, 490, 452, 1179, 466, 577, 1037, 1985, 19501, 11, 51414], "temperature": 0.0, "avg_logprob": -0.3817360511192909, "compression_ratio": 1.453416149068323, "no_speech_prob": 0.32139790058135986}, {"id": 8, "seek": 2248, "start": 43.480000000000004, "end": 47.480000000000004, "text": " and I was investigating how the Go routine works internally.", "tokens": [51414, 293, 286, 390, 22858, 577, 264, 1037, 9927, 1985, 19501, 13, 51614], "temperature": 0.0, "avg_logprob": -0.3817360511192909, "compression_ratio": 1.453416149068323, "no_speech_prob": 0.32139790058135986}, {"id": 9, "seek": 4748, "start": 47.48, "end": 53.48, "text": " So, when I started investigating it, my idea of how Go routines were created", "tokens": [50364, 407, 11, 562, 286, 1409, 22858, 309, 11, 452, 1558, 295, 577, 1037, 33827, 645, 2942, 50664], "temperature": 0.0, "avg_logprob": -0.19092910847765335, "compression_ratio": 1.5707762557077625, "no_speech_prob": 0.044825270771980286}, {"id": 10, "seek": 4748, "start": 53.48, "end": 55.48, "text": " and all that stuff was something like this.", "tokens": [50664, 293, 439, 300, 1507, 390, 746, 411, 341, 13, 50764], "temperature": 0.0, "avg_logprob": -0.19092910847765335, "compression_ratio": 1.5707762557077625, "no_speech_prob": 0.044825270771980286}, {"id": 11, "seek": 4748, "start": 55.48, "end": 63.48, "text": " A caring mother with a baby in her arms, taking care of that beautiful, full of joy baby.", "tokens": [50764, 316, 15365, 2895, 365, 257, 3186, 294, 720, 5812, 11, 1940, 1127, 295, 300, 2238, 11, 1577, 295, 6258, 3186, 13, 51164], "temperature": 0.0, "avg_logprob": -0.19092910847765335, "compression_ratio": 1.5707762557077625, "no_speech_prob": 0.044825270771980286}, {"id": 12, "seek": 4748, "start": 63.48, "end": 66.47999999999999, "text": " It wasn't like that, okay?", "tokens": [51164, 467, 2067, 380, 411, 300, 11, 1392, 30, 51314], "temperature": 0.0, "avg_logprob": -0.19092910847765335, "compression_ratio": 1.5707762557077625, "no_speech_prob": 0.044825270771980286}, {"id": 13, "seek": 4748, "start": 66.47999999999999, "end": 71.47999999999999, "text": " I started digging into the code and I realized that it's more like this.", "tokens": [51314, 286, 1409, 17343, 666, 264, 3089, 293, 286, 5334, 300, 309, 311, 544, 411, 341, 13, 51564], "temperature": 0.0, "avg_logprob": -0.19092910847765335, "compression_ratio": 1.5707762557077625, "no_speech_prob": 0.044825270771980286}, {"id": 14, "seek": 4748, "start": 71.47999999999999, "end": 74.47999999999999, "text": " And necromancer racing the deads.", "tokens": [51564, 400, 408, 10757, 4277, 1776, 12553, 264, 3116, 82, 13, 51714], "temperature": 0.0, "avg_logprob": -0.19092910847765335, "compression_ratio": 1.5707762557077625, "no_speech_prob": 0.044825270771980286}, {"id": 15, "seek": 7448, "start": 74.48, "end": 77.48, "text": " I was like, why? There's a reason for that.", "tokens": [50364, 286, 390, 411, 11, 983, 30, 821, 311, 257, 1778, 337, 300, 13, 50514], "temperature": 0.0, "avg_logprob": -0.1609630210726869, "compression_ratio": 1.6798245614035088, "no_speech_prob": 0.04979544132947922}, {"id": 16, "seek": 7448, "start": 77.48, "end": 82.48, "text": " But before that, I'm going to talk about something more general, that is the Go scheduler.", "tokens": [50514, 583, 949, 300, 11, 286, 478, 516, 281, 751, 466, 746, 544, 2674, 11, 300, 307, 264, 1037, 12000, 260, 13, 50764], "temperature": 0.0, "avg_logprob": -0.1609630210726869, "compression_ratio": 1.6798245614035088, "no_speech_prob": 0.04979544132947922}, {"id": 17, "seek": 7448, "start": 82.48, "end": 88.48, "text": " For understanding how the Go routine works, we need to understand how the scheduler works", "tokens": [50764, 1171, 3701, 577, 264, 1037, 9927, 1985, 11, 321, 643, 281, 1223, 577, 264, 12000, 260, 1985, 51064], "temperature": 0.0, "avg_logprob": -0.1609630210726869, "compression_ratio": 1.6798245614035088, "no_speech_prob": 0.04979544132947922}, {"id": 18, "seek": 7448, "start": 88.48, "end": 92.48, "text": " and how it is shaped.", "tokens": [51064, 293, 577, 309, 307, 13475, 13, 51264], "temperature": 0.0, "avg_logprob": -0.1609630210726869, "compression_ratio": 1.6798245614035088, "no_speech_prob": 0.04979544132947922}, {"id": 19, "seek": 7448, "start": 92.48, "end": 97.48, "text": " So, let's start with the different pieces of the Go scheduler.", "tokens": [51264, 407, 11, 718, 311, 722, 365, 264, 819, 3755, 295, 264, 1037, 12000, 260, 13, 51514], "temperature": 0.0, "avg_logprob": -0.1609630210726869, "compression_ratio": 1.6798245614035088, "no_speech_prob": 0.04979544132947922}, {"id": 20, "seek": 7448, "start": 97.48, "end": 103.48, "text": " One of them is the P extract that is the representation of a virtual CPU.", "tokens": [51514, 1485, 295, 552, 307, 264, 430, 8947, 300, 307, 264, 10290, 295, 257, 6374, 13199, 13, 51814], "temperature": 0.0, "avg_logprob": -0.1609630210726869, "compression_ratio": 1.6798245614035088, "no_speech_prob": 0.04979544132947922}, {"id": 21, "seek": 10348, "start": 103.48, "end": 110.48, "text": " Whenever you say Go Max Prox, what you are saying is the number of pieces that the scheduler has.", "tokens": [50364, 14159, 291, 584, 1037, 7402, 1705, 87, 11, 437, 291, 366, 1566, 307, 264, 1230, 295, 3755, 300, 264, 12000, 260, 575, 13, 50714], "temperature": 0.0, "avg_logprob": -0.20691236427852086, "compression_ratio": 1.5896414342629481, "no_speech_prob": 0.008425814099609852}, {"id": 22, "seek": 10348, "start": 110.48, "end": 115.48, "text": " And a processor, as I said, is a virtual representation of the CPU.", "tokens": [50714, 400, 257, 15321, 11, 382, 286, 848, 11, 307, 257, 6374, 10290, 295, 264, 13199, 13, 50964], "temperature": 0.0, "avg_logprob": -0.20691236427852086, "compression_ratio": 1.5896414342629481, "no_speech_prob": 0.008425814099609852}, {"id": 23, "seek": 10348, "start": 115.48, "end": 119.48, "text": " It can have a status that can be either running, c-scrolling, or g-stop.", "tokens": [50964, 467, 393, 362, 257, 6558, 300, 393, 312, 2139, 2614, 11, 269, 12, 4417, 18688, 11, 420, 290, 12, 13559, 13, 51164], "temperature": 0.0, "avg_logprob": -0.20691236427852086, "compression_ratio": 1.5896414342629481, "no_speech_prob": 0.008425814099609852}, {"id": 24, "seek": 10348, "start": 119.48, "end": 123.48, "text": " It has associated the current M.", "tokens": [51164, 467, 575, 6615, 264, 2190, 376, 13, 51364], "temperature": 0.0, "avg_logprob": -0.20691236427852086, "compression_ratio": 1.5896414342629481, "no_speech_prob": 0.008425814099609852}, {"id": 25, "seek": 10348, "start": 123.48, "end": 126.48, "text": " We are going to see what an M is in a moment.", "tokens": [51364, 492, 366, 516, 281, 536, 437, 364, 376, 307, 294, 257, 1623, 13, 51514], "temperature": 0.0, "avg_logprob": -0.20691236427852086, "compression_ratio": 1.5896414342629481, "no_speech_prob": 0.008425814099609852}, {"id": 26, "seek": 10348, "start": 126.48, "end": 132.48000000000002, "text": " Then it has, each processor has a queue of Go routines that needs to be executed.", "tokens": [51514, 1396, 309, 575, 11, 1184, 15321, 575, 257, 18639, 295, 1037, 33827, 300, 2203, 281, 312, 17577, 13, 51814], "temperature": 0.0, "avg_logprob": -0.20691236427852086, "compression_ratio": 1.5896414342629481, "no_speech_prob": 0.008425814099609852}, {"id": 27, "seek": 13248, "start": 132.48, "end": 135.48, "text": " And a list of free Go routines.", "tokens": [50364, 400, 257, 1329, 295, 1737, 1037, 33827, 13, 50514], "temperature": 0.0, "avg_logprob": -0.10799571446010045, "compression_ratio": 1.6244725738396624, "no_speech_prob": 0.011371249333024025}, {"id": 28, "seek": 13248, "start": 135.48, "end": 138.48, "text": " We are going to see what free Go routines are later.", "tokens": [50514, 492, 366, 516, 281, 536, 437, 1737, 1037, 33827, 366, 1780, 13, 50664], "temperature": 0.0, "avg_logprob": -0.10799571446010045, "compression_ratio": 1.6244725738396624, "no_speech_prob": 0.011371249333024025}, {"id": 29, "seek": 13248, "start": 138.48, "end": 141.48, "text": " And, of course, other metadata.", "tokens": [50664, 400, 11, 295, 1164, 11, 661, 26603, 13, 50814], "temperature": 0.0, "avg_logprob": -0.10799571446010045, "compression_ratio": 1.6244725738396624, "no_speech_prob": 0.011371249333024025}, {"id": 30, "seek": 13248, "start": 141.48, "end": 146.48, "text": " This is a very shallow explanation of the scheduler.", "tokens": [50814, 639, 307, 257, 588, 20488, 10835, 295, 264, 12000, 260, 13, 51064], "temperature": 0.0, "avg_logprob": -0.10799571446010045, "compression_ratio": 1.6244725738396624, "no_speech_prob": 0.011371249333024025}, {"id": 31, "seek": 13248, "start": 146.48, "end": 148.48, "text": " This is an over simplification.", "tokens": [51064, 639, 307, 364, 670, 6883, 3774, 13, 51164], "temperature": 0.0, "avg_logprob": -0.10799571446010045, "compression_ratio": 1.6244725738396624, "no_speech_prob": 0.011371249333024025}, {"id": 32, "seek": 13248, "start": 148.48, "end": 150.48, "text": " Of course, it's more complex than that.", "tokens": [51164, 2720, 1164, 11, 309, 311, 544, 3997, 813, 300, 13, 51264], "temperature": 0.0, "avg_logprob": -0.10799571446010045, "compression_ratio": 1.6244725738396624, "no_speech_prob": 0.011371249333024025}, {"id": 33, "seek": 13248, "start": 150.48, "end": 153.48, "text": " But, well, a lot of other metadata inside the PS track.", "tokens": [51264, 583, 11, 731, 11, 257, 688, 295, 661, 26603, 1854, 264, 8168, 2837, 13, 51414], "temperature": 0.0, "avg_logprob": -0.10799571446010045, "compression_ratio": 1.6244725738396624, "no_speech_prob": 0.011371249333024025}, {"id": 34, "seek": 13248, "start": 153.48, "end": 155.48, "text": " Let's talk about the M.", "tokens": [51414, 961, 311, 751, 466, 264, 376, 13, 51514], "temperature": 0.0, "avg_logprob": -0.10799571446010045, "compression_ratio": 1.6244725738396624, "no_speech_prob": 0.011371249333024025}, {"id": 35, "seek": 13248, "start": 155.48, "end": 160.48, "text": " The M is the self-representation of an operating system thread.", "tokens": [51514, 440, 376, 307, 264, 2698, 12, 19919, 11662, 399, 295, 364, 7447, 1185, 7207, 13, 51764], "temperature": 0.0, "avg_logprob": -0.10799571446010045, "compression_ratio": 1.6244725738396624, "no_speech_prob": 0.011371249333024025}, {"id": 36, "seek": 16048, "start": 160.48, "end": 164.48, "text": " It's what is executing your code in the CPU.", "tokens": [50364, 467, 311, 437, 307, 32368, 428, 3089, 294, 264, 13199, 13, 50564], "temperature": 0.0, "avg_logprob": -0.10418629116482205, "compression_ratio": 1.755, "no_speech_prob": 0.010697070509195328}, {"id": 37, "seek": 16048, "start": 164.48, "end": 170.48, "text": " And it has associated normally the current Go routine that is running in this M, in this machine.", "tokens": [50564, 400, 309, 575, 6615, 5646, 264, 2190, 1037, 9927, 300, 307, 2614, 294, 341, 376, 11, 294, 341, 3479, 13, 50864], "temperature": 0.0, "avg_logprob": -0.10418629116482205, "compression_ratio": 1.755, "no_speech_prob": 0.010697070509195328}, {"id": 38, "seek": 16048, "start": 170.48, "end": 177.48, "text": " And the current processor that is associated to this M, that can be null, actually.", "tokens": [50864, 400, 264, 2190, 15321, 300, 307, 6615, 281, 341, 376, 11, 300, 393, 312, 18184, 11, 767, 13, 51214], "temperature": 0.0, "avg_logprob": -0.10418629116482205, "compression_ratio": 1.755, "no_speech_prob": 0.010697070509195328}, {"id": 39, "seek": 16048, "start": 177.48, "end": 184.48, "text": " There are some cases where the M is not associated to a processor.", "tokens": [51214, 821, 366, 512, 3331, 689, 264, 376, 307, 406, 6615, 281, 257, 15321, 13, 51564], "temperature": 0.0, "avg_logprob": -0.10418629116482205, "compression_ratio": 1.755, "no_speech_prob": 0.010697070509195328}, {"id": 40, "seek": 16048, "start": 184.48, "end": 186.48, "text": " But, in general, they are associated.", "tokens": [51564, 583, 11, 294, 2674, 11, 436, 366, 6615, 13, 51664], "temperature": 0.0, "avg_logprob": -0.10418629116482205, "compression_ratio": 1.755, "no_speech_prob": 0.010697070509195328}, {"id": 41, "seek": 16048, "start": 186.48, "end": 189.48, "text": " And other metadata.", "tokens": [51664, 400, 661, 26603, 13, 51814], "temperature": 0.0, "avg_logprob": -0.10418629116482205, "compression_ratio": 1.755, "no_speech_prob": 0.010697070509195328}, {"id": 42, "seek": 18948, "start": 189.48, "end": 195.48, "text": " Let's talk about, let me, let's talk about the scheduler itself.", "tokens": [50364, 961, 311, 751, 466, 11, 718, 385, 11, 718, 311, 751, 466, 264, 12000, 260, 2564, 13, 50664], "temperature": 0.0, "avg_logprob": -0.18984652981899752, "compression_ratio": 1.9058823529411764, "no_speech_prob": 0.012033345177769661}, {"id": 43, "seek": 18948, "start": 195.48, "end": 200.48, "text": " On top of all these M's and P's, there's a struct that is called a schedule.", "tokens": [50664, 1282, 1192, 295, 439, 613, 376, 311, 293, 430, 311, 11, 456, 311, 257, 6594, 300, 307, 1219, 257, 7567, 13, 50914], "temperature": 0.0, "avg_logprob": -0.18984652981899752, "compression_ratio": 1.9058823529411764, "no_speech_prob": 0.012033345177769661}, {"id": 44, "seek": 18948, "start": 200.48, "end": 207.48, "text": " That is, it has all the, it has a list of all the, all the idle M's,", "tokens": [50914, 663, 307, 11, 309, 575, 439, 264, 11, 309, 575, 257, 1329, 295, 439, 264, 11, 439, 264, 30650, 376, 311, 11, 51264], "temperature": 0.0, "avg_logprob": -0.18984652981899752, "compression_ratio": 1.9058823529411764, "no_speech_prob": 0.012033345177769661}, {"id": 45, "seek": 18948, "start": 207.48, "end": 209.48, "text": " all the M's that are not doing any work,", "tokens": [51264, 439, 264, 376, 311, 300, 366, 406, 884, 604, 589, 11, 51364], "temperature": 0.0, "avg_logprob": -0.18984652981899752, "compression_ratio": 1.9058823529411764, "no_speech_prob": 0.012033345177769661}, {"id": 46, "seek": 18948, "start": 209.48, "end": 214.48, "text": " all the idle P's, processors that have not, that are not doing any work.", "tokens": [51364, 439, 264, 30650, 430, 311, 11, 27751, 300, 362, 406, 11, 300, 366, 406, 884, 604, 589, 13, 51614], "temperature": 0.0, "avg_logprob": -0.18984652981899752, "compression_ratio": 1.9058823529411764, "no_speech_prob": 0.012033345177769661}, {"id": 47, "seek": 21448, "start": 214.48, "end": 224.48, "text": " All the, at least of global runnable Go routines, a queue of work that is not associated to any specific processor for now.", "tokens": [50364, 1057, 264, 11, 412, 1935, 295, 4338, 1190, 77, 712, 1037, 33827, 11, 257, 18639, 295, 589, 300, 307, 406, 6615, 281, 604, 2685, 15321, 337, 586, 13, 50864], "temperature": 0.0, "avg_logprob": -0.19128548117244945, "compression_ratio": 1.6132596685082874, "no_speech_prob": 0.0486639067530632}, {"id": 48, "seek": 21448, "start": 224.48, "end": 228.48, "text": " And a list of global free Go routines.", "tokens": [50864, 400, 257, 1329, 295, 4338, 1737, 1037, 33827, 13, 51064], "temperature": 0.0, "avg_logprob": -0.19128548117244945, "compression_ratio": 1.6132596685082874, "no_speech_prob": 0.0486639067530632}, {"id": 49, "seek": 21448, "start": 228.48, "end": 230.48, "text": " Okay.", "tokens": [51064, 1033, 13, 51164], "temperature": 0.0, "avg_logprob": -0.19128548117244945, "compression_ratio": 1.6132596685082874, "no_speech_prob": 0.0486639067530632}, {"id": 50, "seek": 21448, "start": 230.48, "end": 234.48, "text": " And the start of our show, the Go routine.", "tokens": [51164, 400, 264, 722, 295, 527, 855, 11, 264, 1037, 9927, 13, 51364], "temperature": 0.0, "avg_logprob": -0.19128548117244945, "compression_ratio": 1.6132596685082874, "no_speech_prob": 0.0486639067530632}, {"id": 51, "seek": 21448, "start": 234.48, "end": 237.48, "text": " There's a struct that is called GStrug.", "tokens": [51364, 821, 311, 257, 6594, 300, 307, 1219, 460, 4520, 81, 697, 13, 51514], "temperature": 0.0, "avg_logprob": -0.19128548117244945, "compression_ratio": 1.6132596685082874, "no_speech_prob": 0.0486639067530632}, {"id": 52, "seek": 21448, "start": 237.48, "end": 240.48, "text": " That struct is, represents a Go routine.", "tokens": [51514, 663, 6594, 307, 11, 8855, 257, 1037, 9927, 13, 51664], "temperature": 0.0, "avg_logprob": -0.19128548117244945, "compression_ratio": 1.6132596685082874, "no_speech_prob": 0.0486639067530632}, {"id": 53, "seek": 24048, "start": 240.48, "end": 250.48, "text": " And a Go routine is composed by, in a lot of the stuff, but mainly you have a stack that is a two kilobytes chunk of memory.", "tokens": [50364, 400, 257, 1037, 9927, 307, 18204, 538, 11, 294, 257, 688, 295, 264, 1507, 11, 457, 8704, 291, 362, 257, 8630, 300, 307, 257, 732, 5128, 996, 43673, 16635, 295, 4675, 13, 50864], "temperature": 0.0, "avg_logprob": -0.13730273927961076, "compression_ratio": 1.740909090909091, "no_speech_prob": 0.06271909922361374}, {"id": 54, "seek": 24048, "start": 250.48, "end": 258.48, "text": " The program counter that is similar to the program counter in a thread that is pointing to the next, well, to the current instruction that is executing.", "tokens": [50864, 440, 1461, 5682, 300, 307, 2531, 281, 264, 1461, 5682, 294, 257, 7207, 300, 307, 12166, 281, 264, 958, 11, 731, 11, 281, 264, 2190, 10951, 300, 307, 32368, 13, 51264], "temperature": 0.0, "avg_logprob": -0.13730273927961076, "compression_ratio": 1.740909090909091, "no_speech_prob": 0.06271909922361374}, {"id": 55, "seek": 24048, "start": 258.48, "end": 262.48, "text": " The status of the Go routine that can be running, waiting, runnable.", "tokens": [51264, 440, 6558, 295, 264, 1037, 9927, 300, 393, 312, 2614, 11, 3806, 11, 1190, 77, 712, 13, 51464], "temperature": 0.0, "avg_logprob": -0.13730273927961076, "compression_ratio": 1.740909090909091, "no_speech_prob": 0.06271909922361374}, {"id": 56, "seek": 24048, "start": 262.48, "end": 265.48, "text": " There's a lot of different statuses.", "tokens": [51464, 821, 311, 257, 688, 295, 819, 6558, 279, 13, 51614], "temperature": 0.0, "avg_logprob": -0.13730273927961076, "compression_ratio": 1.740909090909091, "no_speech_prob": 0.06271909922361374}, {"id": 57, "seek": 26548, "start": 265.48, "end": 271.48, "text": " The current M that is associated to this Go routine is being executed right now.", "tokens": [50364, 440, 2190, 376, 300, 307, 6615, 281, 341, 1037, 9927, 307, 885, 17577, 558, 586, 13, 50664], "temperature": 0.0, "avg_logprob": -0.11002600324022901, "compression_ratio": 1.7891891891891891, "no_speech_prob": 0.051963139325380325}, {"id": 58, "seek": 26548, "start": 271.48, "end": 272.48, "text": " And the wait reason.", "tokens": [50664, 400, 264, 1699, 1778, 13, 50714], "temperature": 0.0, "avg_logprob": -0.11002600324022901, "compression_ratio": 1.7891891891891891, "no_speech_prob": 0.051963139325380325}, {"id": 59, "seek": 26548, "start": 272.48, "end": 277.48, "text": " The wait reason is if the Go routine is waiting, they have to be waiting for something.", "tokens": [50714, 440, 1699, 1778, 307, 498, 264, 1037, 9927, 307, 3806, 11, 436, 362, 281, 312, 3806, 337, 746, 13, 50964], "temperature": 0.0, "avg_logprob": -0.11002600324022901, "compression_ratio": 1.7891891891891891, "no_speech_prob": 0.051963139325380325}, {"id": 60, "seek": 26548, "start": 277.48, "end": 279.48, "text": " They have to be a reason for waiting.", "tokens": [50964, 814, 362, 281, 312, 257, 1778, 337, 3806, 13, 51064], "temperature": 0.0, "avg_logprob": -0.11002600324022901, "compression_ratio": 1.7891891891891891, "no_speech_prob": 0.051963139325380325}, {"id": 61, "seek": 26548, "start": 279.48, "end": 281.48, "text": " And that's the way reason.", "tokens": [51064, 400, 300, 311, 264, 636, 1778, 13, 51164], "temperature": 0.0, "avg_logprob": -0.11002600324022901, "compression_ratio": 1.7891891891891891, "no_speech_prob": 0.051963139325380325}, {"id": 62, "seek": 26548, "start": 281.48, "end": 283.48, "text": " There's a lot of other metadata.", "tokens": [51164, 821, 311, 257, 688, 295, 661, 26603, 13, 51264], "temperature": 0.0, "avg_logprob": -0.11002600324022901, "compression_ratio": 1.7891891891891891, "no_speech_prob": 0.051963139325380325}, {"id": 63, "seek": 26548, "start": 283.48, "end": 286.48, "text": " But let's take a look at the whole picture.", "tokens": [51264, 583, 718, 311, 747, 257, 574, 412, 264, 1379, 3036, 13, 51414], "temperature": 0.0, "avg_logprob": -0.11002600324022901, "compression_ratio": 1.7891891891891891, "no_speech_prob": 0.051963139325380325}, {"id": 64, "seek": 28648, "start": 286.48, "end": 297.48, "text": " As I said, we have the scheduler at the top left with a list of free Go routines, a list of runnable Go routines, a list of either processors, either machines.", "tokens": [50364, 1018, 286, 848, 11, 321, 362, 264, 12000, 260, 412, 264, 1192, 1411, 365, 257, 1329, 295, 1737, 1037, 33827, 11, 257, 1329, 295, 1190, 77, 712, 1037, 33827, 11, 257, 1329, 295, 2139, 27751, 11, 2139, 8379, 13, 50914], "temperature": 0.0, "avg_logprob": -0.11414074897766113, "compression_ratio": 1.9289099526066351, "no_speech_prob": 0.23578189313411713}, {"id": 65, "seek": 28648, "start": 297.48, "end": 305.48, "text": " And we have running processors with running Go routines associated with machines and all that stuff.", "tokens": [50914, 400, 321, 362, 2614, 27751, 365, 2614, 1037, 33827, 6615, 365, 8379, 293, 439, 300, 1507, 13, 51314], "temperature": 0.0, "avg_logprob": -0.11414074897766113, "compression_ratio": 1.9289099526066351, "no_speech_prob": 0.23578189313411713}, {"id": 66, "seek": 28648, "start": 305.48, "end": 315.48, "text": " Also, another interesting thing is that at global level in the runtime, as global variables, we have a list of all the M's, a list of all the P's,", "tokens": [51314, 2743, 11, 1071, 1880, 551, 307, 300, 412, 4338, 1496, 294, 264, 34474, 11, 382, 4338, 9102, 11, 321, 362, 257, 1329, 295, 439, 264, 376, 311, 11, 257, 1329, 295, 439, 264, 430, 311, 11, 51814], "temperature": 0.0, "avg_logprob": -0.11414074897766113, "compression_ratio": 1.9289099526066351, "no_speech_prob": 0.23578189313411713}, {"id": 67, "seek": 31548, "start": 315.48, "end": 317.48, "text": " and a list of all the Go routines.", "tokens": [50364, 293, 257, 1329, 295, 439, 264, 1037, 33827, 13, 50464], "temperature": 0.0, "avg_logprob": -0.17608244278851679, "compression_ratio": 1.5904761904761904, "no_speech_prob": 0.01145709678530693}, {"id": 68, "seek": 31548, "start": 317.48, "end": 322.48, "text": " That really are three global variables in the runtime.", "tokens": [50464, 663, 534, 366, 1045, 4338, 9102, 294, 264, 34474, 13, 50714], "temperature": 0.0, "avg_logprob": -0.17608244278851679, "compression_ratio": 1.5904761904761904, "no_speech_prob": 0.01145709678530693}, {"id": 69, "seek": 31548, "start": 322.48, "end": 327.48, "text": " Okay, but how Go routines are created?", "tokens": [50714, 1033, 11, 457, 577, 1037, 33827, 366, 2942, 30, 50964], "temperature": 0.0, "avg_logprob": -0.17608244278851679, "compression_ratio": 1.5904761904761904, "no_speech_prob": 0.01145709678530693}, {"id": 70, "seek": 31548, "start": 327.48, "end": 335.48, "text": " This is where the necromancer raising the dead's metaphor comes into place.", "tokens": [50964, 639, 307, 689, 264, 408, 10757, 4277, 1776, 11225, 264, 3116, 311, 19157, 1487, 666, 1081, 13, 51364], "temperature": 0.0, "avg_logprob": -0.17608244278851679, "compression_ratio": 1.5904761904761904, "no_speech_prob": 0.01145709678530693}, {"id": 71, "seek": 31548, "start": 335.48, "end": 344.48, "text": " Because whenever you create a Go routine with just Peggy's, you create a spawn a new Go routine and start running things on that.", "tokens": [51364, 1436, 5699, 291, 1884, 257, 1037, 9927, 365, 445, 28007, 1480, 311, 11, 291, 1884, 257, 17088, 257, 777, 1037, 9927, 293, 722, 2614, 721, 322, 300, 13, 51814], "temperature": 0.0, "avg_logprob": -0.17608244278851679, "compression_ratio": 1.5904761904761904, "no_speech_prob": 0.01145709678530693}, {"id": 72, "seek": 34448, "start": 344.48, "end": 346.48, "text": " But that's not what is happening.", "tokens": [50364, 583, 300, 311, 406, 437, 307, 2737, 13, 50464], "temperature": 0.0, "avg_logprob": -0.11198473612467448, "compression_ratio": 1.6358381502890174, "no_speech_prob": 0.011796815320849419}, {"id": 73, "seek": 34448, "start": 346.48, "end": 352.48, "text": " There's two ways of creating a Go routine.", "tokens": [50464, 821, 311, 732, 2098, 295, 4084, 257, 1037, 9927, 13, 50764], "temperature": 0.0, "avg_logprob": -0.11198473612467448, "compression_ratio": 1.6358381502890174, "no_speech_prob": 0.011796815320849419}, {"id": 74, "seek": 34448, "start": 352.48, "end": 361.48, "text": " One option is to create it from scratch and the other option is to reuse all Go routine that is no longer working.", "tokens": [50764, 1485, 3614, 307, 281, 1884, 309, 490, 8459, 293, 264, 661, 3614, 307, 281, 26225, 439, 1037, 9927, 300, 307, 572, 2854, 1364, 13, 51214], "temperature": 0.0, "avg_logprob": -0.11198473612467448, "compression_ratio": 1.6358381502890174, "no_speech_prob": 0.011796815320849419}, {"id": 75, "seek": 34448, "start": 361.48, "end": 365.48, "text": " So this is what is happening.", "tokens": [51214, 407, 341, 307, 437, 307, 2737, 13, 51414], "temperature": 0.0, "avg_logprob": -0.11198473612467448, "compression_ratio": 1.6358381502890174, "no_speech_prob": 0.011796815320849419}, {"id": 76, "seek": 34448, "start": 365.48, "end": 371.48, "text": " Whenever a Go routine finish, it's changed the state to dead.", "tokens": [51414, 14159, 257, 1037, 9927, 2413, 11, 309, 311, 3105, 264, 1785, 281, 3116, 13, 51714], "temperature": 0.0, "avg_logprob": -0.11198473612467448, "compression_ratio": 1.6358381502890174, "no_speech_prob": 0.011796815320849419}, {"id": 77, "seek": 37148, "start": 371.48, "end": 376.48, "text": " So all that free Go routines, actually they are dead Go routines.", "tokens": [50364, 407, 439, 300, 1737, 1037, 33827, 11, 767, 436, 366, 3116, 1037, 33827, 13, 50614], "temperature": 0.0, "avg_logprob": -0.11916366277956496, "compression_ratio": 1.8454106280193237, "no_speech_prob": 0.004388405941426754}, {"id": 78, "seek": 37148, "start": 376.48, "end": 381.48, "text": " So whenever you need a new Go routine, you can reuse one of them.", "tokens": [50614, 407, 5699, 291, 643, 257, 777, 1037, 9927, 11, 291, 393, 26225, 472, 295, 552, 13, 50864], "temperature": 0.0, "avg_logprob": -0.11916366277956496, "compression_ratio": 1.8454106280193237, "no_speech_prob": 0.004388405941426754}, {"id": 79, "seek": 37148, "start": 381.48, "end": 392.48, "text": " Or the other option, if there's no free Go routine or dead Go routine to reuse, you create a new Go routine full of life, you kill it, and then you raise that from the dead.", "tokens": [50864, 1610, 264, 661, 3614, 11, 498, 456, 311, 572, 1737, 1037, 9927, 420, 3116, 1037, 9927, 281, 26225, 11, 291, 1884, 257, 777, 1037, 9927, 1577, 295, 993, 11, 291, 1961, 309, 11, 293, 550, 291, 5300, 300, 490, 264, 3116, 13, 51414], "temperature": 0.0, "avg_logprob": -0.11916366277956496, "compression_ratio": 1.8454106280193237, "no_speech_prob": 0.004388405941426754}, {"id": 80, "seek": 37148, "start": 392.48, "end": 394.48, "text": " So that's the process.", "tokens": [51414, 407, 300, 311, 264, 1399, 13, 51514], "temperature": 0.0, "avg_logprob": -0.11916366277956496, "compression_ratio": 1.8454106280193237, "no_speech_prob": 0.004388405941426754}, {"id": 81, "seek": 37148, "start": 394.48, "end": 397.48, "text": " And actually that is how it works in the source code.", "tokens": [51514, 400, 767, 300, 307, 577, 309, 1985, 294, 264, 4009, 3089, 13, 51664], "temperature": 0.0, "avg_logprob": -0.11916366277956496, "compression_ratio": 1.8454106280193237, "no_speech_prob": 0.004388405941426754}, {"id": 82, "seek": 39748, "start": 397.48, "end": 402.48, "text": " It was shocking for me and it was a funny way of representing this.", "tokens": [50364, 467, 390, 18776, 337, 385, 293, 309, 390, 257, 4074, 636, 295, 13460, 341, 13, 50614], "temperature": 0.0, "avg_logprob": -0.11211398124694824, "compression_ratio": 1.7813953488372094, "no_speech_prob": 0.01686251349747181}, {"id": 83, "seek": 39748, "start": 402.48, "end": 404.48, "text": " So let's see an example of that.", "tokens": [50614, 407, 718, 311, 536, 364, 1365, 295, 300, 13, 50714], "temperature": 0.0, "avg_logprob": -0.11211398124694824, "compression_ratio": 1.7813953488372094, "no_speech_prob": 0.01686251349747181}, {"id": 84, "seek": 39748, "start": 404.48, "end": 410.48, "text": " Imagine that I have this Go routine here that wants to create a new Go routine.", "tokens": [50714, 11739, 300, 286, 362, 341, 1037, 9927, 510, 300, 2738, 281, 1884, 257, 777, 1037, 9927, 13, 51014], "temperature": 0.0, "avg_logprob": -0.11211398124694824, "compression_ratio": 1.7813953488372094, "no_speech_prob": 0.01686251349747181}, {"id": 85, "seek": 39748, "start": 410.48, "end": 423.48, "text": " What it's going to do is pick one of the free Go routines in the free list and raise that from the dead, convert that into a runnable, put that in the queue of the runnable Go routines of the processor,", "tokens": [51014, 708, 309, 311, 516, 281, 360, 307, 1888, 472, 295, 264, 1737, 1037, 33827, 294, 264, 1737, 1329, 293, 5300, 300, 490, 264, 3116, 11, 7620, 300, 666, 257, 1190, 77, 712, 11, 829, 300, 294, 264, 18639, 295, 264, 1190, 77, 712, 1037, 33827, 295, 264, 15321, 11, 51664], "temperature": 0.0, "avg_logprob": -0.11211398124694824, "compression_ratio": 1.7813953488372094, "no_speech_prob": 0.01686251349747181}, {"id": 86, "seek": 42348, "start": 423.48, "end": 432.48, "text": " and call the scheduler and the scheduler is going to, well, and the scheduler is going to eventually execute that Go routine.", "tokens": [50364, 293, 818, 264, 12000, 260, 293, 264, 12000, 260, 307, 516, 281, 11, 731, 11, 293, 264, 12000, 260, 307, 516, 281, 4728, 14483, 300, 1037, 9927, 13, 50814], "temperature": 0.0, "avg_logprob": -0.1002677447760283, "compression_ratio": 1.8026315789473684, "no_speech_prob": 0.029041577130556107}, {"id": 87, "seek": 42348, "start": 432.48, "end": 439.48, "text": " Another option is this Go routine here wants to run a new Go routine, spawn a new Go routine, but there's nothing in the free list of the processor.", "tokens": [50814, 3996, 3614, 307, 341, 1037, 9927, 510, 2738, 281, 1190, 257, 777, 1037, 9927, 11, 17088, 257, 777, 1037, 9927, 11, 457, 456, 311, 1825, 294, 264, 1737, 1329, 295, 264, 15321, 13, 51164], "temperature": 0.0, "avg_logprob": -0.1002677447760283, "compression_ratio": 1.8026315789473684, "no_speech_prob": 0.029041577130556107}, {"id": 88, "seek": 43948, "start": 439.48, "end": 453.48, "text": " So it's going to go to the global free list of the scheduler and pick a chunk of them, move them to the processor, and then pick one of them and raise that from the dead and add it to the queue.", "tokens": [50364, 407, 309, 311, 516, 281, 352, 281, 264, 4338, 1737, 1329, 295, 264, 12000, 260, 293, 1888, 257, 16635, 295, 552, 11, 1286, 552, 281, 264, 15321, 11, 293, 550, 1888, 472, 295, 552, 293, 5300, 300, 490, 264, 3116, 293, 909, 309, 281, 264, 18639, 13, 51064], "temperature": 0.0, "avg_logprob": -0.09516048431396484, "compression_ratio": 1.6443298969072164, "no_speech_prob": 0.13347148895263672}, {"id": 89, "seek": 43948, "start": 453.48, "end": 460.48, "text": " And finally you have the option of this one is it wants to create a new Go routine, but there's nothing in the global queue.", "tokens": [51064, 400, 2721, 291, 362, 264, 3614, 295, 341, 472, 307, 309, 2738, 281, 1884, 257, 777, 1037, 9927, 11, 457, 456, 311, 1825, 294, 264, 4338, 18639, 13, 51414], "temperature": 0.0, "avg_logprob": -0.09516048431396484, "compression_ratio": 1.6443298969072164, "no_speech_prob": 0.13347148895263672}, {"id": 90, "seek": 46048, "start": 460.48, "end": 464.48, "text": " So what it's going to do is create a new Go routine.", "tokens": [50364, 407, 437, 309, 311, 516, 281, 360, 307, 1884, 257, 777, 1037, 9927, 13, 50564], "temperature": 0.0, "avg_logprob": -0.11048188962434467, "compression_ratio": 1.7466666666666666, "no_speech_prob": 0.039914388209581375}, {"id": 91, "seek": 46048, "start": 464.48, "end": 472.48, "text": " It's going to kill it and then it's going to raise that from the dead and put in the queue and all that stuff.", "tokens": [50564, 467, 311, 516, 281, 1961, 309, 293, 550, 309, 311, 516, 281, 5300, 300, 490, 264, 3116, 293, 829, 294, 264, 18639, 293, 439, 300, 1507, 13, 50964], "temperature": 0.0, "avg_logprob": -0.11048188962434467, "compression_ratio": 1.7466666666666666, "no_speech_prob": 0.039914388209581375}, {"id": 92, "seek": 46048, "start": 472.48, "end": 475.48, "text": " So that's how Go routines are created.", "tokens": [50964, 407, 300, 311, 577, 1037, 33827, 366, 2942, 13, 51114], "temperature": 0.0, "avg_logprob": -0.11048188962434467, "compression_ratio": 1.7466666666666666, "no_speech_prob": 0.039914388209581375}, {"id": 93, "seek": 46048, "start": 475.48, "end": 481.48, "text": " Let's see how Go routines, how is the life of a Go routine.", "tokens": [51114, 961, 311, 536, 577, 1037, 33827, 11, 577, 307, 264, 993, 295, 257, 1037, 9927, 13, 51414], "temperature": 0.0, "avg_logprob": -0.11048188962434467, "compression_ratio": 1.7466666666666666, "no_speech_prob": 0.039914388209581375}, {"id": 94, "seek": 48148, "start": 481.48, "end": 493.48, "text": " A Go routine can go through a lot of different states, can go to runable to running, from running to waiting, from waiting to runable, from running to preempted, from preempted to waiting.", "tokens": [50364, 316, 1037, 9927, 393, 352, 807, 257, 688, 295, 819, 4368, 11, 393, 352, 281, 1190, 712, 281, 2614, 11, 490, 2614, 281, 3806, 11, 490, 3806, 281, 1190, 712, 11, 490, 2614, 281, 659, 4543, 292, 11, 490, 659, 4543, 292, 281, 3806, 13, 50964], "temperature": 0.0, "avg_logprob": -0.15051723388304195, "compression_ratio": 1.8734177215189873, "no_speech_prob": 0.032963648438453674}, {"id": 95, "seek": 48148, "start": 493.48, "end": 495.48, "text": " There's a lot of stuff.", "tokens": [50964, 821, 311, 257, 688, 295, 1507, 13, 51064], "temperature": 0.0, "avg_logprob": -0.15051723388304195, "compression_ratio": 1.8734177215189873, "no_speech_prob": 0.032963648438453674}, {"id": 96, "seek": 48148, "start": 495.48, "end": 500.48, "text": " Let's see how, let's see all these transitions one by one.", "tokens": [51064, 961, 311, 536, 577, 11, 718, 311, 536, 439, 613, 23767, 472, 538, 472, 13, 51314], "temperature": 0.0, "avg_logprob": -0.15051723388304195, "compression_ratio": 1.8734177215189873, "no_speech_prob": 0.032963648438453674}, {"id": 97, "seek": 48148, "start": 500.48, "end": 503.48, "text": " From runable to running.", "tokens": [51314, 3358, 1190, 712, 281, 2614, 13, 51464], "temperature": 0.0, "avg_logprob": -0.15051723388304195, "compression_ratio": 1.8734177215189873, "no_speech_prob": 0.032963648438453674}, {"id": 98, "seek": 50348, "start": 504.48, "end": 513.48, "text": " That happens when you for example have a Go routine have finished the job or a Go routine start waiting for something.", "tokens": [50414, 663, 2314, 562, 291, 337, 1365, 362, 257, 1037, 9927, 362, 4335, 264, 1691, 420, 257, 1037, 9927, 722, 3806, 337, 746, 13, 50864], "temperature": 0.0, "avg_logprob": -0.08786639738618658, "compression_ratio": 1.8894736842105264, "no_speech_prob": 0.026469381526112556}, {"id": 99, "seek": 50348, "start": 513.48, "end": 515.48, "text": " So it's going to call the scheduler.", "tokens": [50864, 407, 309, 311, 516, 281, 818, 264, 12000, 260, 13, 50964], "temperature": 0.0, "avg_logprob": -0.08786639738618658, "compression_ratio": 1.8894736842105264, "no_speech_prob": 0.026469381526112556}, {"id": 100, "seek": 50348, "start": 515.48, "end": 519.48, "text": " So the scheduler is going to try to find another Go routine to execute.", "tokens": [50964, 407, 264, 12000, 260, 307, 516, 281, 853, 281, 915, 1071, 1037, 9927, 281, 14483, 13, 51164], "temperature": 0.0, "avg_logprob": -0.08786639738618658, "compression_ratio": 1.8894736842105264, "no_speech_prob": 0.026469381526112556}, {"id": 101, "seek": 50348, "start": 519.48, "end": 527.48, "text": " The first thing that is going to do is try to find a Go routine in the local processor, in the runable list of the local processor.", "tokens": [51164, 440, 700, 551, 300, 307, 516, 281, 360, 307, 853, 281, 915, 257, 1037, 9927, 294, 264, 2654, 15321, 11, 294, 264, 1190, 712, 1329, 295, 264, 2654, 15321, 13, 51564], "temperature": 0.0, "avg_logprob": -0.08786639738618658, "compression_ratio": 1.8894736842105264, "no_speech_prob": 0.026469381526112556}, {"id": 102, "seek": 52748, "start": 527.48, "end": 543.48, "text": " If there's nothing, it's going to go to the global runable queue and it's going to take some of that, it's going to move that work into the processor, it's going to schedule one of that Go routines to be executed.", "tokens": [50364, 759, 456, 311, 1825, 11, 309, 311, 516, 281, 352, 281, 264, 4338, 1190, 712, 18639, 293, 309, 311, 516, 281, 747, 512, 295, 300, 11, 309, 311, 516, 281, 1286, 300, 589, 666, 264, 15321, 11, 309, 311, 516, 281, 7567, 472, 295, 300, 1037, 33827, 281, 312, 17577, 13, 51164], "temperature": 0.0, "avg_logprob": -0.09464136103993838, "compression_ratio": 1.8974358974358974, "no_speech_prob": 0.03964276984333992}, {"id": 103, "seek": 52748, "start": 543.48, "end": 548.48, "text": " Then if there's nothing in the global queue, it's going to go to the net pool.", "tokens": [51164, 1396, 498, 456, 311, 1825, 294, 264, 4338, 18639, 11, 309, 311, 516, 281, 352, 281, 264, 2533, 7005, 13, 51414], "temperature": 0.0, "avg_logprob": -0.09464136103993838, "compression_ratio": 1.8974358974358974, "no_speech_prob": 0.03964276984333992}, {"id": 104, "seek": 52748, "start": 548.48, "end": 556.48, "text": " The net pool is this system that allows Go to do IO work in an efficient way.", "tokens": [51414, 440, 2533, 7005, 307, 341, 1185, 300, 4045, 1037, 281, 360, 39839, 589, 294, 364, 7148, 636, 13, 51814], "temperature": 0.0, "avg_logprob": -0.09464136103993838, "compression_ratio": 1.8974358974358974, "no_speech_prob": 0.03964276984333992}, {"id": 105, "seek": 55648, "start": 556.48, "end": 565.48, "text": " And what it does is do the IO work and whenever it's finished, it gets the Go routine runable again.", "tokens": [50364, 400, 437, 309, 775, 307, 360, 264, 39839, 589, 293, 5699, 309, 311, 4335, 11, 309, 2170, 264, 1037, 9927, 1190, 712, 797, 13, 50814], "temperature": 0.0, "avg_logprob": -0.08601711517156557, "compression_ratio": 1.5961538461538463, "no_speech_prob": 0.01662319153547287}, {"id": 106, "seek": 55648, "start": 565.48, "end": 571.48, "text": " But sometimes what we do is we need to find work to do.", "tokens": [50814, 583, 2171, 437, 321, 360, 307, 321, 643, 281, 915, 589, 281, 360, 13, 51114], "temperature": 0.0, "avg_logprob": -0.08601711517156557, "compression_ratio": 1.5961538461538463, "no_speech_prob": 0.01662319153547287}, {"id": 107, "seek": 55648, "start": 571.48, "end": 577.48, "text": " So we go to the net pool and check if something is already done and start executing that.", "tokens": [51114, 407, 321, 352, 281, 264, 2533, 7005, 293, 1520, 498, 746, 307, 1217, 1096, 293, 722, 32368, 300, 13, 51414], "temperature": 0.0, "avg_logprob": -0.08601711517156557, "compression_ratio": 1.5961538461538463, "no_speech_prob": 0.01662319153547287}, {"id": 108, "seek": 55648, "start": 577.48, "end": 583.48, "text": " If there's nothing in the net pool, we are going to steal work from other processors.", "tokens": [51414, 759, 456, 311, 1825, 294, 264, 2533, 7005, 11, 321, 366, 516, 281, 11009, 589, 490, 661, 27751, 13, 51714], "temperature": 0.0, "avg_logprob": -0.08601711517156557, "compression_ratio": 1.5961538461538463, "no_speech_prob": 0.01662319153547287}, {"id": 109, "seek": 58348, "start": 583.48, "end": 591.48, "text": " And if not, we are going to help the garbage collector in the marked face.", "tokens": [50364, 400, 498, 406, 11, 321, 366, 516, 281, 854, 264, 14150, 23960, 294, 264, 12658, 1851, 13, 50764], "temperature": 0.0, "avg_logprob": -0.1252243777355516, "compression_ratio": 1.9540229885057472, "no_speech_prob": 0.021930599585175514}, {"id": 110, "seek": 58348, "start": 591.48, "end": 604.48, "text": " Well, once we have found a Go routine in all the process, we are going to mark that as running and we are going to assign the machine, the operating system thread to that Go routine.", "tokens": [50764, 1042, 11, 1564, 321, 362, 1352, 257, 1037, 9927, 294, 439, 264, 1399, 11, 321, 366, 516, 281, 1491, 300, 382, 2614, 293, 321, 366, 516, 281, 6269, 264, 3479, 11, 264, 7447, 1185, 7207, 281, 300, 1037, 9927, 13, 51414], "temperature": 0.0, "avg_logprob": -0.1252243777355516, "compression_ratio": 1.9540229885057472, "no_speech_prob": 0.021930599585175514}, {"id": 111, "seek": 58348, "start": 604.48, "end": 609.48, "text": " We are going to mark that as running and we are going to start executing the code.", "tokens": [51414, 492, 366, 516, 281, 1491, 300, 382, 2614, 293, 321, 366, 516, 281, 722, 32368, 264, 3089, 13, 51664], "temperature": 0.0, "avg_logprob": -0.1252243777355516, "compression_ratio": 1.9540229885057472, "no_speech_prob": 0.021930599585175514}, {"id": 112, "seek": 60948, "start": 609.48, "end": 615.48, "text": " Another option is running, well, another change is running to waiting.", "tokens": [50364, 3996, 3614, 307, 2614, 11, 731, 11, 1071, 1319, 307, 2614, 281, 3806, 13, 50664], "temperature": 0.0, "avg_logprob": -0.1215146221692049, "compression_ratio": 1.7055837563451777, "no_speech_prob": 0.049554239958524704}, {"id": 113, "seek": 60948, "start": 615.48, "end": 625.48, "text": " One of the interesting part of this is it's exemplifies how Go routines are cooperative entities.", "tokens": [50664, 1485, 295, 264, 1880, 644, 295, 341, 307, 309, 311, 24112, 11221, 577, 1037, 33827, 366, 31772, 16667, 13, 51164], "temperature": 0.0, "avg_logprob": -0.1215146221692049, "compression_ratio": 1.7055837563451777, "no_speech_prob": 0.049554239958524704}, {"id": 114, "seek": 60948, "start": 625.48, "end": 630.48, "text": " So they cooperate to give you the sensation of concurrency.", "tokens": [51164, 407, 436, 26667, 281, 976, 291, 264, 20069, 295, 23702, 10457, 13, 51414], "temperature": 0.0, "avg_logprob": -0.1215146221692049, "compression_ratio": 1.7055837563451777, "no_speech_prob": 0.049554239958524704}, {"id": 115, "seek": 60948, "start": 630.48, "end": 637.48, "text": " So the Go routine, when the Go routine needs to wait for something, is the own Go routine who parks itself.", "tokens": [51414, 407, 264, 1037, 9927, 11, 562, 264, 1037, 9927, 2203, 281, 1699, 337, 746, 11, 307, 264, 1065, 1037, 9927, 567, 16213, 2564, 13, 51764], "temperature": 0.0, "avg_logprob": -0.1215146221692049, "compression_ratio": 1.7055837563451777, "no_speech_prob": 0.049554239958524704}, {"id": 116, "seek": 63748, "start": 637.48, "end": 653.48, "text": " Whenever I have to write to a channel, for example, if the channel is not buffered and I have to wait for something, what I'm going to do as a Go routine is park myself, stop myself, check my state to waiting, set the wait reason,", "tokens": [50364, 14159, 286, 362, 281, 2464, 281, 257, 2269, 11, 337, 1365, 11, 498, 264, 2269, 307, 406, 9204, 4073, 293, 286, 362, 281, 1699, 337, 746, 11, 437, 286, 478, 516, 281, 360, 382, 257, 1037, 9927, 307, 3884, 2059, 11, 1590, 2059, 11, 1520, 452, 1785, 281, 3806, 11, 992, 264, 1699, 1778, 11, 51164], "temperature": 0.0, "avg_logprob": -0.1104873193276895, "compression_ratio": 1.6216216216216217, "no_speech_prob": 0.04866362735629082}, {"id": 117, "seek": 63748, "start": 653.48, "end": 661.48, "text": " detach myself from the operating system thread and run the scheduler.", "tokens": [51164, 43245, 2059, 490, 264, 7447, 1185, 7207, 293, 1190, 264, 12000, 260, 13, 51564], "temperature": 0.0, "avg_logprob": -0.1104873193276895, "compression_ratio": 1.6216216216216217, "no_speech_prob": 0.04866362735629082}, {"id": 118, "seek": 66148, "start": 661.48, "end": 672.48, "text": " It's the Go routine that is marking itself as waiting, the one that is calling the scheduler to schedule the new Go routine.", "tokens": [50364, 467, 311, 264, 1037, 9927, 300, 307, 25482, 2564, 382, 3806, 11, 264, 472, 300, 307, 5141, 264, 12000, 260, 281, 7567, 264, 777, 1037, 9927, 13, 50914], "temperature": 0.0, "avg_logprob": -0.11786747723817825, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.07576620578765869}, {"id": 119, "seek": 66148, "start": 672.48, "end": 679.48, "text": " So the scheduler is going to find another task and it's going to start running that.", "tokens": [50914, 407, 264, 12000, 260, 307, 516, 281, 915, 1071, 5633, 293, 309, 311, 516, 281, 722, 2614, 300, 13, 51264], "temperature": 0.0, "avg_logprob": -0.11786747723817825, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.07576620578765869}, {"id": 120, "seek": 66148, "start": 679.48, "end": 682.48, "text": " So what are the reasons why we can wait?", "tokens": [51264, 407, 437, 366, 264, 4112, 983, 321, 393, 1699, 30, 51414], "temperature": 0.0, "avg_logprob": -0.11786747723817825, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.07576620578765869}, {"id": 121, "seek": 68248, "start": 682.48, "end": 691.48, "text": " If you go to the Go source code, and actually there's in the bottom right corner, I usually put some references to the Go source code,", "tokens": [50364, 759, 291, 352, 281, 264, 1037, 4009, 3089, 11, 293, 767, 456, 311, 294, 264, 2767, 558, 4538, 11, 286, 2673, 829, 512, 15400, 281, 264, 1037, 4009, 3089, 11, 50814], "temperature": 0.0, "avg_logprob": -0.11062718391418457, "compression_ratio": 1.9583333333333333, "no_speech_prob": 0.390023797750473}, {"id": 122, "seek": 68248, "start": 691.48, "end": 701.48, "text": " but well, if you go to that point in the Go source code, you are going to see the wait reasons and that's the least of all the wait reasons.", "tokens": [50814, 457, 731, 11, 498, 291, 352, 281, 300, 935, 294, 264, 1037, 4009, 3089, 11, 291, 366, 516, 281, 536, 264, 1699, 4112, 293, 300, 311, 264, 1935, 295, 439, 264, 1699, 4112, 13, 51314], "temperature": 0.0, "avg_logprob": -0.11062718391418457, "compression_ratio": 1.9583333333333333, "no_speech_prob": 0.390023797750473}, {"id": 123, "seek": 68248, "start": 701.48, "end": 705.48, "text": " There's no more, there's no less. That's all the wait reasons.", "tokens": [51314, 821, 311, 572, 544, 11, 456, 311, 572, 1570, 13, 663, 311, 439, 264, 1699, 4112, 13, 51514], "temperature": 0.0, "avg_logprob": -0.11062718391418457, "compression_ratio": 1.9583333333333333, "no_speech_prob": 0.390023797750473}, {"id": 124, "seek": 68248, "start": 705.48, "end": 707.48, "text": " Don't pay too much attention to that.", "tokens": [51514, 1468, 380, 1689, 886, 709, 3202, 281, 300, 13, 51614], "temperature": 0.0, "avg_logprob": -0.11062718391418457, "compression_ratio": 1.9583333333333333, "no_speech_prob": 0.390023797750473}, {"id": 125, "seek": 70748, "start": 707.48, "end": 710.48, "text": " I'm going to summarize that. If you want to take a look, you can go.", "tokens": [50364, 286, 478, 516, 281, 20858, 300, 13, 759, 291, 528, 281, 747, 257, 574, 11, 291, 393, 352, 13, 50514], "temperature": 0.0, "avg_logprob": -0.16939033632693085, "compression_ratio": 1.680952380952381, "no_speech_prob": 0.019667373970150948}, {"id": 126, "seek": 70748, "start": 710.48, "end": 716.48, "text": " But the summary is you have GC reasons, garbage collector reasons,", "tokens": [50514, 583, 264, 12691, 307, 291, 362, 29435, 4112, 11, 14150, 23960, 4112, 11, 50814], "temperature": 0.0, "avg_logprob": -0.16939033632693085, "compression_ratio": 1.680952380952381, "no_speech_prob": 0.019667373970150948}, {"id": 127, "seek": 70748, "start": 716.48, "end": 721.48, "text": " mutex reasons, semaphore reasons, channel reasons, sleep reasons, and other reasons.", "tokens": [50814, 24523, 87, 4112, 11, 4361, 13957, 418, 4112, 11, 2269, 4112, 11, 2817, 4112, 11, 293, 661, 4112, 13, 51064], "temperature": 0.0, "avg_logprob": -0.16939033632693085, "compression_ratio": 1.680952380952381, "no_speech_prob": 0.019667373970150948}, {"id": 128, "seek": 70748, "start": 721.48, "end": 729.48, "text": " That's mainly why the garbage, why the Go routines waits for something.", "tokens": [51064, 663, 311, 8704, 983, 264, 14150, 11, 983, 264, 1037, 33827, 40597, 337, 746, 13, 51464], "temperature": 0.0, "avg_logprob": -0.16939033632693085, "compression_ratio": 1.680952380952381, "no_speech_prob": 0.019667373970150948}, {"id": 129, "seek": 70748, "start": 729.48, "end": 735.48, "text": " Okay, from running to Cisco and to running or runable again.", "tokens": [51464, 1033, 11, 490, 2614, 281, 38528, 293, 281, 2614, 420, 1190, 712, 797, 13, 51764], "temperature": 0.0, "avg_logprob": -0.16939033632693085, "compression_ratio": 1.680952380952381, "no_speech_prob": 0.019667373970150948}, {"id": 130, "seek": 73548, "start": 735.48, "end": 745.48, "text": " Well, the Cisco is an interesting part. The Cisco is basically calling the operating system to do something and that can be fast or can be slow.", "tokens": [50364, 1042, 11, 264, 38528, 307, 364, 1880, 644, 13, 440, 38528, 307, 1936, 5141, 264, 7447, 1185, 281, 360, 746, 293, 300, 393, 312, 2370, 420, 393, 312, 2964, 13, 50864], "temperature": 0.0, "avg_logprob": -0.1033158844167536, "compression_ratio": 1.7184466019417475, "no_speech_prob": 0.016935735940933228}, {"id": 131, "seek": 73548, "start": 745.48, "end": 750.48, "text": " And for some Cisco, it's kind of obvious, but for some Cisco, it's not so obvious.", "tokens": [50864, 400, 337, 512, 38528, 11, 309, 311, 733, 295, 6322, 11, 457, 337, 512, 38528, 11, 309, 311, 406, 370, 6322, 13, 51114], "temperature": 0.0, "avg_logprob": -0.1033158844167536, "compression_ratio": 1.7184466019417475, "no_speech_prob": 0.016935735940933228}, {"id": 132, "seek": 73548, "start": 750.48, "end": 763.48, "text": " So what it does is whenever you enter in a Cisco, whenever you try to execute a Cisco, it's going to detach from the processor", "tokens": [51114, 407, 437, 309, 775, 307, 5699, 291, 3242, 294, 257, 38528, 11, 5699, 291, 853, 281, 14483, 257, 38528, 11, 309, 311, 516, 281, 43245, 490, 264, 15321, 51764], "temperature": 0.0, "avg_logprob": -0.1033158844167536, "compression_ratio": 1.7184466019417475, "no_speech_prob": 0.016935735940933228}, {"id": 133, "seek": 76348, "start": 763.48, "end": 770.48, "text": " and it's going to detect if the Cisco is slow or fast.", "tokens": [50364, 293, 309, 311, 516, 281, 5531, 498, 264, 38528, 307, 2964, 420, 2370, 13, 50714], "temperature": 0.0, "avg_logprob": -0.08487256815735723, "compression_ratio": 1.8308823529411764, "no_speech_prob": 0.14836061000823975}, {"id": 134, "seek": 76348, "start": 770.48, "end": 776.48, "text": " And if it's a fast Cisco, it's going to finish the Cisco and go back directly to running.", "tokens": [50714, 400, 498, 309, 311, 257, 2370, 38528, 11, 309, 311, 516, 281, 2413, 264, 38528, 293, 352, 646, 3838, 281, 2614, 13, 51014], "temperature": 0.0, "avg_logprob": -0.08487256815735723, "compression_ratio": 1.8308823529411764, "no_speech_prob": 0.14836061000823975}, {"id": 135, "seek": 76348, "start": 776.48, "end": 784.48, "text": " But if the Cisco is slow, it's going to just stay in Cisco state", "tokens": [51014, 583, 498, 264, 38528, 307, 2964, 11, 309, 311, 516, 281, 445, 1754, 294, 38528, 1785, 51414], "temperature": 0.0, "avg_logprob": -0.08487256815735723, "compression_ratio": 1.8308823529411764, "no_speech_prob": 0.14836061000823975}, {"id": 136, "seek": 76348, "start": 784.48, "end": 787.48, "text": " and it's going to detach the processor.", "tokens": [51414, 293, 309, 311, 516, 281, 43245, 264, 15321, 13, 51564], "temperature": 0.0, "avg_logprob": -0.08487256815735723, "compression_ratio": 1.8308823529411764, "no_speech_prob": 0.14836061000823975}, {"id": 137, "seek": 78748, "start": 787.48, "end": 794.48, "text": " Well, it's going to keep the processor detached so the processor can select another Go routine to execute", "tokens": [50364, 1042, 11, 309, 311, 516, 281, 1066, 264, 15321, 42050, 370, 264, 15321, 393, 3048, 1071, 1037, 9927, 281, 14483, 50714], "temperature": 0.0, "avg_logprob": -0.15180327892303466, "compression_ratio": 1.7772020725388602, "no_speech_prob": 0.030624279752373695}, {"id": 138, "seek": 78748, "start": 794.48, "end": 805.48, "text": " and it's going to finish the Cisco eventually and whenever it finish, it's going to move the Go routine to runable again", "tokens": [50714, 293, 309, 311, 516, 281, 2413, 264, 38528, 4728, 293, 5699, 309, 2413, 11, 309, 311, 516, 281, 1286, 264, 1037, 9927, 281, 1190, 712, 797, 51264], "temperature": 0.0, "avg_logprob": -0.15180327892303466, "compression_ratio": 1.7772020725388602, "no_speech_prob": 0.030624279752373695}, {"id": 139, "seek": 78748, "start": 805.48, "end": 810.48, "text": " and then queue that in a processor and all that stuff.", "tokens": [51264, 293, 550, 18639, 300, 294, 257, 15321, 293, 439, 300, 1507, 13, 51514], "temperature": 0.0, "avg_logprob": -0.15180327892303466, "compression_ratio": 1.7772020725388602, "no_speech_prob": 0.030624279752373695}, {"id": 140, "seek": 78748, "start": 810.48, "end": 816.48, "text": " The other thing that is interesting is the copy stack status.", "tokens": [51514, 440, 661, 551, 300, 307, 1880, 307, 264, 5055, 8630, 6558, 13, 51814], "temperature": 0.0, "avg_logprob": -0.15180327892303466, "compression_ratio": 1.7772020725388602, "no_speech_prob": 0.030624279752373695}, {"id": 141, "seek": 81648, "start": 816.48, "end": 823.48, "text": " Whenever a Go routine needs to grow the stack because it needs more space for the function parameters", "tokens": [50364, 14159, 257, 1037, 9927, 2203, 281, 1852, 264, 8630, 570, 309, 2203, 544, 1901, 337, 264, 2445, 9834, 50714], "temperature": 0.0, "avg_logprob": -0.08531699603116966, "compression_ratio": 1.6944444444444444, "no_speech_prob": 0.012835483066737652}, {"id": 142, "seek": 81648, "start": 823.48, "end": 834.48, "text": " or for the local variables of the function execution, it's passed through this process that it's going to move from running to copy stack.", "tokens": [50714, 420, 337, 264, 2654, 9102, 295, 264, 2445, 15058, 11, 309, 311, 4678, 807, 341, 1399, 300, 309, 311, 516, 281, 1286, 490, 2614, 281, 5055, 8630, 13, 51264], "temperature": 0.0, "avg_logprob": -0.08531699603116966, "compression_ratio": 1.6944444444444444, "no_speech_prob": 0.012835483066737652}, {"id": 143, "seek": 81648, "start": 834.48, "end": 845.48, "text": " It's going to reserve the double of the current stack size in memory, copy over all the information from one place to another", "tokens": [51264, 467, 311, 516, 281, 17824, 264, 3834, 295, 264, 2190, 8630, 2744, 294, 4675, 11, 5055, 670, 439, 264, 1589, 490, 472, 1081, 281, 1071, 51814], "temperature": 0.0, "avg_logprob": -0.08531699603116966, "compression_ratio": 1.6944444444444444, "no_speech_prob": 0.012835483066737652}, {"id": 144, "seek": 84548, "start": 845.48, "end": 854.48, "text": " and change the pointers and then it's going to move back from copy stack to running again.", "tokens": [50364, 293, 1319, 264, 44548, 293, 550, 309, 311, 516, 281, 1286, 646, 490, 5055, 8630, 281, 2614, 797, 13, 50814], "temperature": 0.0, "avg_logprob": -0.1460528818766276, "compression_ratio": 1.6349206349206349, "no_speech_prob": 0.0038109077140688896}, {"id": 145, "seek": 84548, "start": 854.48, "end": 862.48, "text": " From waiting to runable, this is a very interesting case because, again, as I said, Go routines are cooperative.", "tokens": [50814, 3358, 3806, 281, 1190, 712, 11, 341, 307, 257, 588, 1880, 1389, 570, 11, 797, 11, 382, 286, 848, 11, 1037, 33827, 366, 31772, 13, 51214], "temperature": 0.0, "avg_logprob": -0.1460528818766276, "compression_ratio": 1.6349206349206349, "no_speech_prob": 0.0038109077140688896}, {"id": 146, "seek": 84548, "start": 862.48, "end": 873.48, "text": " So normally, a Go routine, it's changed from waiting to runable whenever other Go routine calls go ready.", "tokens": [51214, 407, 5646, 11, 257, 1037, 9927, 11, 309, 311, 3105, 490, 3806, 281, 1190, 712, 5699, 661, 1037, 9927, 5498, 352, 1919, 13, 51764], "temperature": 0.0, "avg_logprob": -0.1460528818766276, "compression_ratio": 1.6349206349206349, "no_speech_prob": 0.0038109077140688896}, {"id": 147, "seek": 87348, "start": 873.48, "end": 882.48, "text": " Whenever other Go routines say to my Go routine that it's ready to keep executing, we are going to see examples of that later.", "tokens": [50364, 14159, 661, 1037, 33827, 584, 281, 452, 1037, 9927, 300, 309, 311, 1919, 281, 1066, 32368, 11, 321, 366, 516, 281, 536, 5110, 295, 300, 1780, 13, 50814], "temperature": 0.0, "avg_logprob": -0.09871189934866768, "compression_ratio": 1.9269662921348314, "no_speech_prob": 0.009942969307303429}, {"id": 148, "seek": 87348, "start": 882.48, "end": 893.48, "text": " So whenever Go ready is called, for example, if a Go routine is sending something to a channel and some other Go routine is waiting,", "tokens": [50814, 407, 5699, 1037, 1919, 307, 1219, 11, 337, 1365, 11, 498, 257, 1037, 9927, 307, 7750, 746, 281, 257, 2269, 293, 512, 661, 1037, 9927, 307, 3806, 11, 51364], "temperature": 0.0, "avg_logprob": -0.09871189934866768, "compression_ratio": 1.9269662921348314, "no_speech_prob": 0.009942969307303429}, {"id": 149, "seek": 87348, "start": 893.48, "end": 901.48, "text": " it's going to wake up that Go routine, it's going to mark us ready that Go routine.", "tokens": [51364, 309, 311, 516, 281, 6634, 493, 300, 1037, 9927, 11, 309, 311, 516, 281, 1491, 505, 1919, 300, 1037, 9927, 13, 51764], "temperature": 0.0, "avg_logprob": -0.09871189934866768, "compression_ratio": 1.9269662921348314, "no_speech_prob": 0.009942969307303429}, {"id": 150, "seek": 90148, "start": 901.48, "end": 912.48, "text": " Then it's going to mark us ready, it's going to add that to the queue of the processor and try to get a processor to execute that.", "tokens": [50364, 1396, 309, 311, 516, 281, 1491, 505, 1919, 11, 309, 311, 516, 281, 909, 300, 281, 264, 18639, 295, 264, 15321, 293, 853, 281, 483, 257, 15321, 281, 14483, 300, 13, 50914], "temperature": 0.0, "avg_logprob": -0.10660550253731864, "compression_ratio": 1.6136363636363635, "no_speech_prob": 0.0077116843312978745}, {"id": 151, "seek": 90148, "start": 912.48, "end": 922.48, "text": " Another way is when you reactivate a list of Go routines that happens, for example, when the garbage collector have to reactivate some of the Go routines", "tokens": [50914, 3996, 636, 307, 562, 291, 4515, 592, 473, 257, 1329, 295, 1037, 33827, 300, 2314, 11, 337, 1365, 11, 562, 264, 14150, 23960, 362, 281, 4515, 592, 473, 512, 295, 264, 1037, 33827, 51414], "temperature": 0.0, "avg_logprob": -0.10660550253731864, "compression_ratio": 1.6136363636363635, "no_speech_prob": 0.0077116843312978745}, {"id": 152, "seek": 92248, "start": 922.48, "end": 938.48, "text": " and then the garbage collector are waiting for the garbage collector phase, for the mark phase, and when that's finished, it's going to wake up a list of Go routines.", "tokens": [50364, 293, 550, 264, 14150, 23960, 366, 3806, 337, 264, 14150, 23960, 5574, 11, 337, 264, 1491, 5574, 11, 293, 562, 300, 311, 4335, 11, 309, 311, 516, 281, 6634, 493, 257, 1329, 295, 1037, 33827, 13, 51164], "temperature": 0.0, "avg_logprob": -0.21863555908203125, "compression_ratio": 1.7102803738317758, "no_speech_prob": 0.25863420963287354}, {"id": 153, "seek": 92248, "start": 938.48, "end": 943.48, "text": " Another case, it's when there's a case where it doesn't need to wait.", "tokens": [51164, 3996, 1389, 11, 309, 311, 562, 456, 311, 257, 1389, 689, 309, 1177, 380, 643, 281, 1699, 13, 51414], "temperature": 0.0, "avg_logprob": -0.21863555908203125, "compression_ratio": 1.7102803738317758, "no_speech_prob": 0.25863420963287354}, {"id": 154, "seek": 92248, "start": 943.48, "end": 951.48, "text": " Imagine that you say, hey, I'm going to wait for X, but that X is already fulfilled, so I'm going to go back to runable directly.", "tokens": [51414, 11739, 300, 291, 584, 11, 4177, 11, 286, 478, 516, 281, 1699, 337, 1783, 11, 457, 300, 1783, 307, 1217, 21380, 11, 370, 286, 478, 516, 281, 352, 646, 281, 1190, 712, 3838, 13, 51814], "temperature": 0.0, "avg_logprob": -0.21863555908203125, "compression_ratio": 1.7102803738317758, "no_speech_prob": 0.25863420963287354}, {"id": 155, "seek": 95148, "start": 951.48, "end": 966.48, "text": " Another thing is when you are trying to find a Go routine to execute the scheduler, you check the scheduler, sorry, you check the net pool,", "tokens": [50364, 3996, 551, 307, 562, 291, 366, 1382, 281, 915, 257, 1037, 9927, 281, 14483, 264, 12000, 260, 11, 291, 1520, 264, 12000, 260, 11, 2597, 11, 291, 1520, 264, 2533, 7005, 11, 51114], "temperature": 0.0, "avg_logprob": -0.1719281637846534, "compression_ratio": 1.7770700636942676, "no_speech_prob": 0.016851168125867844}, {"id": 156, "seek": 95148, "start": 966.48, "end": 976.48, "text": " and the net pool sometimes has these Go routines that in theory they are waiting, but the data is already there or the job is already done.", "tokens": [51114, 293, 264, 2533, 7005, 2171, 575, 613, 1037, 33827, 300, 294, 5261, 436, 366, 3806, 11, 457, 264, 1412, 307, 1217, 456, 420, 264, 1691, 307, 1217, 1096, 13, 51614], "temperature": 0.0, "avg_logprob": -0.1719281637846534, "compression_ratio": 1.7770700636942676, "no_speech_prob": 0.016851168125867844}, {"id": 157, "seek": 97648, "start": 976.48, "end": 982.48, "text": " So it just moved that app from waiting to runable.", "tokens": [50364, 407, 309, 445, 4259, 300, 724, 490, 3806, 281, 1190, 712, 13, 50664], "temperature": 0.0, "avg_logprob": -0.27900277351846503, "compression_ratio": 1.4736842105263157, "no_speech_prob": 0.07275085151195526}, {"id": 158, "seek": 97648, "start": 982.48, "end": 989.48, "text": " Okay, from running to preempt to waiting or runable.", "tokens": [50664, 1033, 11, 490, 2614, 281, 659, 4543, 281, 3806, 420, 1190, 712, 13, 51014], "temperature": 0.0, "avg_logprob": -0.27900277351846503, "compression_ratio": 1.4736842105263157, "no_speech_prob": 0.07275085151195526}, {"id": 159, "seek": 97648, "start": 989.48, "end": 997.48, "text": " Go has a preemptive garbage collector, has a preemptive runtime,", "tokens": [51014, 1037, 575, 257, 659, 4543, 488, 14150, 23960, 11, 575, 257, 659, 4543, 488, 34474, 11, 51414], "temperature": 0.0, "avg_logprob": -0.27900277351846503, "compression_ratio": 1.4736842105263157, "no_speech_prob": 0.07275085151195526}, {"id": 160, "seek": 99748, "start": 997.48, "end": 1012.48, "text": " and what it does is when a Go routine is executing for too much time, the system monitor is going to detect that and it's going to send a signal to the operating system thread that is executing the Go routine.", "tokens": [50364, 293, 437, 309, 775, 307, 562, 257, 1037, 9927, 307, 32368, 337, 886, 709, 565, 11, 264, 1185, 6002, 307, 516, 281, 5531, 300, 293, 309, 311, 516, 281, 2845, 257, 6358, 281, 264, 7447, 1185, 7207, 300, 307, 32368, 264, 1037, 9927, 13, 51114], "temperature": 0.0, "avg_logprob": -0.07508607705434163, "compression_ratio": 1.9761904761904763, "no_speech_prob": 0.5463037490844727}, {"id": 161, "seek": 99748, "start": 1012.48, "end": 1026.48, "text": " That signal is going to mark the Go routine as preempt, so it's going to be moved from running to preempt, and eventually the Go routine itself is going to find the time for moving from preempt to waiting.", "tokens": [51114, 663, 6358, 307, 516, 281, 1491, 264, 1037, 9927, 382, 659, 4543, 11, 370, 309, 311, 516, 281, 312, 4259, 490, 2614, 281, 659, 4543, 11, 293, 4728, 264, 1037, 9927, 2564, 307, 516, 281, 915, 264, 565, 337, 2684, 490, 659, 4543, 281, 3806, 13, 51814], "temperature": 0.0, "avg_logprob": -0.07508607705434163, "compression_ratio": 1.9761904761904763, "no_speech_prob": 0.5463037490844727}, {"id": 162, "seek": 102648, "start": 1026.48, "end": 1037.48, "text": " And after the next garbage collector scan, it's going to move from waiting to runable again.", "tokens": [50364, 400, 934, 264, 958, 14150, 23960, 11049, 11, 309, 311, 516, 281, 1286, 490, 3806, 281, 1190, 712, 797, 13, 50914], "temperature": 0.0, "avg_logprob": -0.23415719812566585, "compression_ratio": 1.364963503649635, "no_speech_prob": 0.08048988878726959}, {"id": 163, "seek": 102648, "start": 1037.48, "end": 1044.48, "text": " So again, this is the whole life cycle, runable, running, syscall, waiting, preempt, govistak.", "tokens": [50914, 407, 797, 11, 341, 307, 264, 1379, 993, 6586, 11, 1190, 712, 11, 2614, 11, 262, 749, 45459, 11, 3806, 11, 659, 4543, 11, 352, 85, 468, 514, 13, 51264], "temperature": 0.0, "avg_logprob": -0.23415719812566585, "compression_ratio": 1.364963503649635, "no_speech_prob": 0.08048988878726959}, {"id": 164, "seek": 104448, "start": 1044.48, "end": 1050.48, "text": " Now all these states should be more obvious or more clear to everybody.", "tokens": [50364, 823, 439, 613, 4368, 820, 312, 544, 6322, 420, 544, 1850, 281, 2201, 13, 50664], "temperature": 0.0, "avg_logprob": -0.1500760975168712, "compression_ratio": 1.5483870967741935, "no_speech_prob": 0.6022801399230957}, {"id": 165, "seek": 104448, "start": 1050.48, "end": 1059.48, "text": " There are some other kind of similar states of parallel states related to garbage collector.", "tokens": [50664, 821, 366, 512, 661, 733, 295, 2531, 4368, 295, 8952, 4368, 4077, 281, 14150, 23960, 13, 51114], "temperature": 0.0, "avg_logprob": -0.1500760975168712, "compression_ratio": 1.5483870967741935, "no_speech_prob": 0.6022801399230957}, {"id": 166, "seek": 104448, "start": 1059.48, "end": 1070.48, "text": " This is again a bit of a simplification, but this is in general what is the kind of state that you have in the Go routines.", "tokens": [51114, 639, 307, 797, 257, 857, 295, 257, 6883, 3774, 11, 457, 341, 307, 294, 2674, 437, 307, 264, 733, 295, 1785, 300, 291, 362, 294, 264, 1037, 33827, 13, 51664], "temperature": 0.0, "avg_logprob": -0.1500760975168712, "compression_ratio": 1.5483870967741935, "no_speech_prob": 0.6022801399230957}, {"id": 167, "seek": 107048, "start": 1070.48, "end": 1072.48, "text": " So let's see some examples.", "tokens": [50364, 407, 718, 311, 536, 512, 5110, 13, 50464], "temperature": 0.0, "avg_logprob": -0.12617525789472792, "compression_ratio": 1.6257668711656441, "no_speech_prob": 0.17027218639850616}, {"id": 168, "seek": 107048, "start": 1072.48, "end": 1076.48, "text": " Imagine that you have a channel and you want to send data to that channel.", "tokens": [50464, 11739, 300, 291, 362, 257, 2269, 293, 291, 528, 281, 2845, 1412, 281, 300, 2269, 13, 50664], "temperature": 0.0, "avg_logprob": -0.12617525789472792, "compression_ratio": 1.6257668711656441, "no_speech_prob": 0.17027218639850616}, {"id": 169, "seek": 107048, "start": 1076.48, "end": 1084.48, "text": " The channel is not buffered, and there's nobody else waiting for that.", "tokens": [50664, 440, 2269, 307, 406, 9204, 4073, 11, 293, 456, 311, 5079, 1646, 3806, 337, 300, 13, 51064], "temperature": 0.0, "avg_logprob": -0.12617525789472792, "compression_ratio": 1.6257668711656441, "no_speech_prob": 0.17027218639850616}, {"id": 170, "seek": 107048, "start": 1084.48, "end": 1091.48, "text": " So I try to send the data and because nobody's waiting, I'm going to need to wait for that.", "tokens": [51064, 407, 286, 853, 281, 2845, 264, 1412, 293, 570, 5079, 311, 3806, 11, 286, 478, 516, 281, 643, 281, 1699, 337, 300, 13, 51414], "temperature": 0.0, "avg_logprob": -0.12617525789472792, "compression_ratio": 1.6257668711656441, "no_speech_prob": 0.17027218639850616}, {"id": 171, "seek": 109148, "start": 1091.48, "end": 1103.48, "text": " So I'm going to park myself, the Go routine is going to park itself, it's going to add itself to a list of Go routines that is inside the extract of the channel, and it's going to wait there.", "tokens": [50364, 407, 286, 478, 516, 281, 3884, 2059, 11, 264, 1037, 9927, 307, 516, 281, 3884, 2564, 11, 309, 311, 516, 281, 909, 2564, 281, 257, 1329, 295, 1037, 33827, 300, 307, 1854, 264, 8947, 295, 264, 2269, 11, 293, 309, 311, 516, 281, 1699, 456, 13, 50964], "temperature": 0.0, "avg_logprob": -0.13424828934342894, "compression_ratio": 1.8451612903225807, "no_speech_prob": 0.6093043684959412}, {"id": 172, "seek": 109148, "start": 1103.48, "end": 1110.48, "text": " So it's there, it's waiting, and eventually another Go routine comes to read from the channel.", "tokens": [50964, 407, 309, 311, 456, 11, 309, 311, 3806, 11, 293, 4728, 1071, 1037, 9927, 1487, 281, 1401, 490, 264, 2269, 13, 51314], "temperature": 0.0, "avg_logprob": -0.13424828934342894, "compression_ratio": 1.8451612903225807, "no_speech_prob": 0.6093043684959412}, {"id": 173, "seek": 111048, "start": 1110.48, "end": 1127.48, "text": " What it's going to do is go there, read the data directly from the memory of the other Go routine, and then when it has the data, it's going to call Go ready on that Go routine saying this Go routine is already prepared to keep going.", "tokens": [50364, 708, 309, 311, 516, 281, 360, 307, 352, 456, 11, 1401, 264, 1412, 3838, 490, 264, 4675, 295, 264, 661, 1037, 9927, 11, 293, 550, 562, 309, 575, 264, 1412, 11, 309, 311, 516, 281, 818, 1037, 1919, 322, 300, 1037, 9927, 1566, 341, 1037, 9927, 307, 1217, 4927, 281, 1066, 516, 13, 51214], "temperature": 0.0, "avg_logprob": -0.13041489584404126, "compression_ratio": 1.647887323943662, "no_speech_prob": 0.24577461183071136}, {"id": 174, "seek": 112748, "start": 1127.48, "end": 1140.48, "text": " It's going to, and that's going to end in this state, and eventually the scheduler is going to select that Go routine to be run and everything is going to keep going.", "tokens": [50364, 467, 311, 516, 281, 11, 293, 300, 311, 516, 281, 917, 294, 341, 1785, 11, 293, 4728, 264, 12000, 260, 307, 516, 281, 3048, 300, 1037, 9927, 281, 312, 1190, 293, 1203, 307, 516, 281, 1066, 516, 13, 51014], "temperature": 0.0, "avg_logprob": -0.10223051372327302, "compression_ratio": 1.9473684210526316, "no_speech_prob": 0.12275106459856033}, {"id": 175, "seek": 112748, "start": 1140.48, "end": 1156.48, "text": " Yeah, this is the whole picture, trying to send the data, waiting inside the channel, getting the data from the other side, and the other Go routine is the one that is responsible of waking up the Go routine that was waiting in the channel.", "tokens": [51014, 865, 11, 341, 307, 264, 1379, 3036, 11, 1382, 281, 2845, 264, 1412, 11, 3806, 1854, 264, 2269, 11, 1242, 264, 1412, 490, 264, 661, 1252, 11, 293, 264, 661, 1037, 9927, 307, 264, 472, 300, 307, 6250, 295, 20447, 493, 264, 1037, 9927, 300, 390, 3806, 294, 264, 2269, 13, 51814], "temperature": 0.0, "avg_logprob": -0.10223051372327302, "compression_ratio": 1.9473684210526316, "no_speech_prob": 0.12275106459856033}, {"id": 176, "seek": 115648, "start": 1156.48, "end": 1165.48, "text": " Let's see another example. Let's talk about the wake groups. For example, I can create a wake group and add three in this case. This is a very common pattern.", "tokens": [50364, 961, 311, 536, 1071, 1365, 13, 961, 311, 751, 466, 264, 6634, 3935, 13, 1171, 1365, 11, 286, 393, 1884, 257, 6634, 1594, 293, 909, 1045, 294, 341, 1389, 13, 639, 307, 257, 588, 2689, 5102, 13, 50814], "temperature": 0.0, "avg_logprob": -0.12741961590079373, "compression_ratio": 1.6175115207373272, "no_speech_prob": 0.054391659796237946}, {"id": 177, "seek": 115648, "start": 1165.48, "end": 1177.48, "text": " And then I just found three Go routines that are going to do certain work in parallel. Then I'm going to wait at that point, maybe one Go routine is already running, maybe not, doesn't matter.", "tokens": [50814, 400, 550, 286, 445, 1352, 1045, 1037, 33827, 300, 366, 516, 281, 360, 1629, 589, 294, 8952, 13, 1396, 286, 478, 516, 281, 1699, 412, 300, 935, 11, 1310, 472, 1037, 9927, 307, 1217, 2614, 11, 1310, 406, 11, 1177, 380, 1871, 13, 51414], "temperature": 0.0, "avg_logprob": -0.12741961590079373, "compression_ratio": 1.6175115207373272, "no_speech_prob": 0.054391659796237946}, {"id": 178, "seek": 117748, "start": 1177.48, "end": 1186.48, "text": " So I call wait, so I'm now waiting. The Go routines keep going, maybe some of them are executed, maybe some of them have finished already, doesn't matter.", "tokens": [50364, 407, 286, 818, 1699, 11, 370, 286, 478, 586, 3806, 13, 440, 1037, 33827, 1066, 516, 11, 1310, 512, 295, 552, 366, 17577, 11, 1310, 512, 295, 552, 362, 4335, 1217, 11, 1177, 380, 1871, 13, 50814], "temperature": 0.0, "avg_logprob": -0.1440747728887594, "compression_ratio": 1.9575471698113207, "no_speech_prob": 0.4402981996536255}, {"id": 179, "seek": 117748, "start": 1186.48, "end": 1204.48, "text": " Some of them finish and are there. And the last one, the last one is going to call done, the last done, and it's going to see that, hey, the wake group is already zero, so I'm going to call ready on the list of Go routines that are waiting for this wake group.", "tokens": [50814, 2188, 295, 552, 2413, 293, 366, 456, 13, 400, 264, 1036, 472, 11, 264, 1036, 472, 307, 516, 281, 818, 1096, 11, 264, 1036, 1096, 11, 293, 309, 311, 516, 281, 536, 300, 11, 4177, 11, 264, 6634, 1594, 307, 1217, 4018, 11, 370, 286, 478, 516, 281, 818, 1919, 322, 264, 1329, 295, 1037, 33827, 300, 366, 3806, 337, 341, 6634, 1594, 13, 51714], "temperature": 0.0, "avg_logprob": -0.1440747728887594, "compression_ratio": 1.9575471698113207, "no_speech_prob": 0.4402981996536255}, {"id": 180, "seek": 120448, "start": 1205.48, "end": 1220.48, "text": " So that end up with this situation where that's a runnable Go routine that is going to eventually be executed by the, well, that is going to be a schedule by the scheduler, and that's it.", "tokens": [50414, 407, 300, 917, 493, 365, 341, 2590, 689, 300, 311, 257, 1190, 77, 712, 1037, 9927, 300, 307, 516, 281, 4728, 312, 17577, 538, 264, 11, 731, 11, 300, 307, 516, 281, 312, 257, 7567, 538, 264, 12000, 260, 11, 293, 300, 311, 309, 13, 51164], "temperature": 0.0, "avg_logprob": -0.1575886792150037, "compression_ratio": 1.5138888888888888, "no_speech_prob": 0.08228270709514618}, {"id": 181, "seek": 120448, "start": 1220.48, "end": 1222.48, "text": " Again, the whole picture here.", "tokens": [51164, 3764, 11, 264, 1379, 3036, 510, 13, 51264], "temperature": 0.0, "avg_logprob": -0.1575886792150037, "compression_ratio": 1.5138888888888888, "no_speech_prob": 0.08228270709514618}, {"id": 182, "seek": 122248, "start": 1223.48, "end": 1248.48, "text": " Okay, let's talk about how Go routines die. There's a Go routine normally dies when it finished the work. Basically, whenever there's nothing else to execute, it's going to change the state to that, it's going to set most of the data to the zero value, it's going to disconnect the Go routine from the end,", "tokens": [50414, 1033, 11, 718, 311, 751, 466, 577, 1037, 33827, 978, 13, 821, 311, 257, 1037, 9927, 5646, 2714, 562, 309, 4335, 264, 589, 13, 8537, 11, 5699, 456, 311, 1825, 1646, 281, 14483, 11, 309, 311, 516, 281, 1319, 264, 1785, 281, 300, 11, 309, 311, 516, 281, 992, 881, 295, 264, 1412, 281, 264, 4018, 2158, 11, 309, 311, 516, 281, 14299, 264, 1037, 9927, 490, 264, 917, 11, 51664], "temperature": 0.0, "avg_logprob": -0.20919371939994194, "compression_ratio": 1.6813186813186813, "no_speech_prob": 0.12448152154684067}, {"id": 183, "seek": 124848, "start": 1249.48, "end": 1257.48, "text": " add the Go routine to the free list of the processor, the dead Go routine to the free list of the processor, and call the scheduler to find anything else to execute.", "tokens": [50414, 909, 264, 1037, 9927, 281, 264, 1737, 1329, 295, 264, 15321, 11, 264, 3116, 1037, 9927, 281, 264, 1737, 1329, 295, 264, 15321, 11, 293, 818, 264, 12000, 260, 281, 915, 1340, 1646, 281, 14483, 13, 50814], "temperature": 0.0, "avg_logprob": -0.12551276263068703, "compression_ratio": 1.8153846153846154, "no_speech_prob": 0.014235176146030426}, {"id": 184, "seek": 124848, "start": 1259.48, "end": 1272.48, "text": " So, yeah, the whole life of the Go routine. Again, if you see this is the scenario where the Go routines are doing things. If I did my job correctly, you now should understand this better.", "tokens": [50914, 407, 11, 1338, 11, 264, 1379, 993, 295, 264, 1037, 9927, 13, 3764, 11, 498, 291, 536, 341, 307, 264, 9005, 689, 264, 1037, 33827, 366, 884, 721, 13, 759, 286, 630, 452, 1691, 8944, 11, 291, 586, 820, 1223, 341, 1101, 13, 51564], "temperature": 0.0, "avg_logprob": -0.12551276263068703, "compression_ratio": 1.8153846153846154, "no_speech_prob": 0.014235176146030426}, {"id": 185, "seek": 127248, "start": 1273.48, "end": 1281.48, "text": " And also this should sound familiar to. So let me finish with a couple things.", "tokens": [50414, 400, 611, 341, 820, 1626, 4963, 281, 13, 407, 718, 385, 2413, 365, 257, 1916, 721, 13, 50814], "temperature": 0.0, "avg_logprob": -0.25750626458062065, "compression_ratio": 1.4545454545454546, "no_speech_prob": 0.06889209896326065}, {"id": 186, "seek": 127248, "start": 1282.48, "end": 1292.48, "text": " One of them is I want to thanks Laura Pareja, the one that did all the illustrations for this talk. All the illustrations are creative common by.", "tokens": [50864, 1485, 295, 552, 307, 286, 528, 281, 3231, 13220, 31189, 2938, 11, 264, 472, 300, 630, 439, 264, 34540, 337, 341, 751, 13, 1057, 264, 34540, 366, 5880, 2689, 538, 13, 51364], "temperature": 0.0, "avg_logprob": -0.25750626458062065, "compression_ratio": 1.4545454545454546, "no_speech_prob": 0.06889209896326065}, {"id": 187, "seek": 129248, "start": 1293.48, "end": 1301.48, "text": " And you can see the webpage of Laura Pareja. So you can reuse it that do whatever you want with all that images.", "tokens": [50414, 400, 291, 393, 536, 264, 37852, 295, 13220, 31189, 2938, 13, 407, 291, 393, 26225, 309, 300, 360, 2035, 291, 528, 365, 439, 300, 5267, 13, 50814], "temperature": 0.0, "avg_logprob": -0.24694474135773092, "compression_ratio": 1.560846560846561, "no_speech_prob": 0.34915944933891296}, {"id": 188, "seek": 129248, "start": 1302.48, "end": 1313.48, "text": " Also, I want to, I have a gift from MatterMos that is my company, they're the company that I work for. I have some stickers. I going to left out the stickers there, like Margie said.", "tokens": [50864, 2743, 11, 286, 528, 281, 11, 286, 362, 257, 5306, 490, 20285, 44, 329, 300, 307, 452, 2237, 11, 436, 434, 264, 2237, 300, 286, 589, 337, 13, 286, 362, 512, 21019, 13, 286, 516, 281, 1411, 484, 264, 21019, 456, 11, 411, 2039, 9997, 848, 13, 51414], "temperature": 0.0, "avg_logprob": -0.24694474135773092, "compression_ratio": 1.560846560846561, "no_speech_prob": 0.34915944933891296}, {"id": 189, "seek": 131348, "start": 1313.48, "end": 1318.48, "text": " So that's exactly right there.", "tokens": [50364, 407, 300, 311, 2293, 558, 456, 13, 50614], "temperature": 0.0, "avg_logprob": -0.2604287519293316, "compression_ratio": 1.3243243243243243, "no_speech_prob": 0.18577249348163605}, {"id": 190, "seek": 131348, "start": 1319.48, "end": 1322.48, "text": " So feel free to pick as many as you want.", "tokens": [50664, 407, 841, 1737, 281, 1888, 382, 867, 382, 291, 528, 13, 50814], "temperature": 0.0, "avg_logprob": -0.2604287519293316, "compression_ratio": 1.3243243243243243, "no_speech_prob": 0.18577249348163605}, {"id": 191, "seek": 131348, "start": 1322.48, "end": 1330.48, "text": " But I don't know if, well, I also have some pins too, but they are going to fly probably.", "tokens": [50814, 583, 286, 500, 380, 458, 498, 11, 731, 11, 286, 611, 362, 512, 16392, 886, 11, 457, 436, 366, 516, 281, 3603, 1391, 13, 51214], "temperature": 0.0, "avg_logprob": -0.2604287519293316, "compression_ratio": 1.3243243243243243, "no_speech_prob": 0.18577249348163605}, {"id": 192, "seek": 131348, "start": 1333.48, "end": 1335.48, "text": " Another thing is what is missing.", "tokens": [51364, 3996, 551, 307, 437, 307, 5361, 13, 51464], "temperature": 0.0, "avg_logprob": -0.2604287519293316, "compression_ratio": 1.3243243243243243, "no_speech_prob": 0.18577249348163605}, {"id": 193, "seek": 133548, "start": 1336.48, "end": 1344.48, "text": " I haven't talked about certain things because in the sake of simplicity, I try to avoid getting too much into the details.", "tokens": [50414, 286, 2378, 380, 2825, 466, 1629, 721, 570, 294, 264, 9717, 295, 25632, 11, 286, 853, 281, 5042, 1242, 886, 709, 666, 264, 4365, 13, 50814], "temperature": 0.0, "avg_logprob": -0.08843658765157064, "compression_ratio": 1.698744769874477, "no_speech_prob": 0.10532413423061371}, {"id": 194, "seek": 133548, "start": 1345.48, "end": 1351.48, "text": " One of the things that I removed from the equation and have a lot to do with Go routines is garbage collector.", "tokens": [50864, 1485, 295, 264, 721, 300, 286, 7261, 490, 264, 5367, 293, 362, 257, 688, 281, 360, 365, 1037, 33827, 307, 14150, 23960, 13, 51164], "temperature": 0.0, "avg_logprob": -0.08843658765157064, "compression_ratio": 1.698744769874477, "no_speech_prob": 0.10532413423061371}, {"id": 195, "seek": 133548, "start": 1352.48, "end": 1364.48, "text": " I ignore the garbage collector entirely and it's a big chunk of how the scheduler interacts and how the Go routines are moving from one stage to another and all that stuff.", "tokens": [51214, 286, 11200, 264, 14150, 23960, 7696, 293, 309, 311, 257, 955, 16635, 295, 577, 264, 12000, 260, 43582, 293, 577, 264, 1037, 33827, 366, 2684, 490, 472, 3233, 281, 1071, 293, 439, 300, 1507, 13, 51814], "temperature": 0.0, "avg_logprob": -0.08843658765157064, "compression_ratio": 1.698744769874477, "no_speech_prob": 0.10532413423061371}, {"id": 196, "seek": 136548, "start": 1365.48, "end": 1375.48, "text": " The net pool, I mentioned the net pool, but I haven't entered into the details. There's very good talks about the garbage collector and the net pool out there.", "tokens": [50364, 440, 2533, 7005, 11, 286, 2835, 264, 2533, 7005, 11, 457, 286, 2378, 380, 9065, 666, 264, 4365, 13, 821, 311, 588, 665, 6686, 466, 264, 14150, 23960, 293, 264, 2533, 7005, 484, 456, 13, 50864], "temperature": 0.0, "avg_logprob": -0.19656015902149435, "compression_ratio": 1.7792207792207793, "no_speech_prob": 0.012043571099638939}, {"id": 197, "seek": 136548, "start": 1376.48, "end": 1383.48, "text": " I know SIGO. Also, SIGO have certain implications with the Go routines also, but I have ignored them.", "tokens": [50914, 286, 458, 318, 10489, 46, 13, 2743, 11, 318, 10489, 46, 362, 1629, 16602, 365, 264, 1037, 33827, 611, 11, 457, 286, 362, 19735, 552, 13, 51264], "temperature": 0.0, "avg_logprob": -0.19656015902149435, "compression_ratio": 1.7792207792207793, "no_speech_prob": 0.012043571099638939}, {"id": 198, "seek": 136548, "start": 1384.48, "end": 1392.48, "text": " The mark assist phase that is kind of important is a relevant part of things that Go routine does, assisting the garbage collector in the mark phase.", "tokens": [51314, 440, 1491, 4255, 5574, 300, 307, 733, 295, 1021, 307, 257, 7340, 644, 295, 721, 300, 1037, 9927, 775, 11, 40368, 264, 14150, 23960, 294, 264, 1491, 5574, 13, 51714], "temperature": 0.0, "avg_logprob": -0.19656015902149435, "compression_ratio": 1.7792207792207793, "no_speech_prob": 0.012043571099638939}, {"id": 199, "seek": 139248, "start": 1392.48, "end": 1398.48, "text": " This is the monitor that I have mentioned, but I haven't talked in detail about that.", "tokens": [50364, 639, 307, 264, 6002, 300, 286, 362, 2835, 11, 457, 286, 2378, 380, 2825, 294, 2607, 466, 300, 13, 50664], "temperature": 0.0, "avg_logprob": -0.1365692889104124, "compression_ratio": 1.4939024390243902, "no_speech_prob": 0.012506403960287571}, {"id": 200, "seek": 139248, "start": 1399.48, "end": 1403.48, "text": " But again, there's talks around system monitor out there.", "tokens": [50714, 583, 797, 11, 456, 311, 6686, 926, 1185, 6002, 484, 456, 13, 50914], "temperature": 0.0, "avg_logprob": -0.1365692889104124, "compression_ratio": 1.4939024390243902, "no_speech_prob": 0.012506403960287571}, {"id": 201, "seek": 139248, "start": 1404.48, "end": 1413.48, "text": " One of the main references is the Go source code. I totally recommend you to go there and explore it.", "tokens": [50964, 1485, 295, 264, 2135, 15400, 307, 264, 1037, 4009, 3089, 13, 286, 3879, 2748, 291, 281, 352, 456, 293, 6839, 309, 13, 51414], "temperature": 0.0, "avg_logprob": -0.1365692889104124, "compression_ratio": 1.4939024390243902, "no_speech_prob": 0.012506403960287571}, {"id": 202, "seek": 141348, "start": 1413.48, "end": 1419.48, "text": " There's an illustrated text of Go runtime scheduler that is a YouTube video there.", "tokens": [50364, 821, 311, 364, 33875, 2487, 295, 1037, 34474, 12000, 260, 300, 307, 257, 3088, 960, 456, 13, 50664], "temperature": 0.0, "avg_logprob": -0.2165624743602315, "compression_ratio": 1.4303030303030304, "no_speech_prob": 0.29482534527778625}, {"id": 203, "seek": 141348, "start": 1420.48, "end": 1431.48, "text": " There's a series of posts from Argonel Labs about the Go scheduler. It's from 2018, so it's not super up today, but the general patterns are still there.", "tokens": [50714, 821, 311, 257, 2638, 295, 12300, 490, 1587, 10660, 338, 40047, 466, 264, 1037, 12000, 260, 13, 467, 311, 490, 6096, 11, 370, 309, 311, 406, 1687, 493, 965, 11, 457, 264, 2674, 8294, 366, 920, 456, 13, 51264], "temperature": 0.0, "avg_logprob": -0.2165624743602315, "compression_ratio": 1.4303030303030304, "no_speech_prob": 0.29482534527778625}, {"id": 204, "seek": 143148, "start": 1432.48, "end": 1444.48, "text": " Well, I hope this talk, after this talk, you have a better understanding of how the Go routines work, how the Go routines change from one state to another and all that stuff.", "tokens": [50414, 1042, 11, 286, 1454, 341, 751, 11, 934, 341, 751, 11, 291, 362, 257, 1101, 3701, 295, 577, 264, 1037, 33827, 589, 11, 577, 264, 1037, 33827, 1319, 490, 472, 1785, 281, 1071, 293, 439, 300, 1507, 13, 51014], "temperature": 0.0, "avg_logprob": -0.12017077666062576, "compression_ratio": 1.6108374384236452, "no_speech_prob": 0.1477450430393219}, {"id": 205, "seek": 143148, "start": 1445.48, "end": 1456.48, "text": " But I want, what is more important to me, I want to encourage you to go there and explore the Go source code because it's a great source of information.", "tokens": [51064, 583, 286, 528, 11, 437, 307, 544, 1021, 281, 385, 11, 286, 528, 281, 5373, 291, 281, 352, 456, 293, 6839, 264, 1037, 4009, 3089, 570, 309, 311, 257, 869, 4009, 295, 1589, 13, 51614], "temperature": 0.0, "avg_logprob": -0.12017077666062576, "compression_ratio": 1.6108374384236452, "no_speech_prob": 0.1477450430393219}, {"id": 206, "seek": 145648, "start": 1456.48, "end": 1460.48, "text": " There's a lot of super cool stuff there.", "tokens": [50364, 821, 311, 257, 688, 295, 1687, 1627, 1507, 456, 13, 50564], "temperature": 0.0, "avg_logprob": -0.13830376606361539, "compression_ratio": 1.4014084507042253, "no_speech_prob": 0.19625963270664215}, {"id": 207, "seek": 145648, "start": 1463.48, "end": 1472.48, "text": " And well, and depending on a combination of your passion about learning and your taste in movies, this can be more exciting than a zombie movie.", "tokens": [50714, 400, 731, 11, 293, 5413, 322, 257, 6562, 295, 428, 5418, 466, 2539, 293, 428, 3939, 294, 6233, 11, 341, 393, 312, 544, 4670, 813, 257, 20310, 3169, 13, 51164], "temperature": 0.0, "avg_logprob": -0.13830376606361539, "compression_ratio": 1.4014084507042253, "no_speech_prob": 0.19625963270664215}, {"id": 208, "seek": 145648, "start": 1473.48, "end": 1474.48, "text": " So thank you.", "tokens": [51214, 407, 1309, 291, 13, 51264], "temperature": 0.0, "avg_logprob": -0.13830376606361539, "compression_ratio": 1.4014084507042253, "no_speech_prob": 0.19625963270664215}, {"id": 209, "seek": 147448, "start": 1474.48, "end": 1486.48, "text": " If you want to keep in touch with me, feel free to contact me.", "tokens": [50364, 759, 291, 528, 281, 1066, 294, 2557, 365, 385, 11, 841, 1737, 281, 3385, 385, 13, 50964], "temperature": 0.0, "avg_logprob": -0.17015496662684848, "compression_ratio": 1.727891156462585, "no_speech_prob": 0.46452948451042175}, {"id": 210, "seek": 147448, "start": 1487.48, "end": 1494.48, "text": " And the other thing, if you want to have a follow up session, then try this.", "tokens": [51014, 400, 264, 661, 551, 11, 498, 291, 528, 281, 362, 257, 1524, 493, 5481, 11, 550, 853, 341, 13, 51364], "temperature": 0.0, "avg_logprob": -0.17015496662684848, "compression_ratio": 1.727891156462585, "no_speech_prob": 0.46452948451042175}, {"id": 211, "seek": 147448, "start": 1495.48, "end": 1499.48, "text": " If you want to have a follow up session, asking questions or whatever, feel free to join there.", "tokens": [51414, 759, 291, 528, 281, 362, 257, 1524, 493, 5481, 11, 3365, 1651, 420, 2035, 11, 841, 1737, 281, 3917, 456, 13, 51614], "temperature": 0.0, "avg_logprob": -0.17015496662684848, "compression_ratio": 1.727891156462585, "no_speech_prob": 0.46452948451042175}, {"id": 212, "seek": 147448, "start": 1500.48, "end": 1501.48, "text": " If you're leaving.", "tokens": [51664, 759, 291, 434, 5012, 13, 51714], "temperature": 0.0, "avg_logprob": -0.17015496662684848, "compression_ratio": 1.727891156462585, "no_speech_prob": 0.46452948451042175}, {"id": 213, "seek": 150448, "start": 1504.48, "end": 1505.48, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 50414], "temperature": 0.0, "avg_logprob": -0.5909881194432577, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.9701392650604248}], "language": "en"}