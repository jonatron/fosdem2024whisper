{"text": " Good morning everybody. So I've got too many slides to present, so I'm going to go kind of fast. I think all of you know what SPDX is. Does anybody not know what SPDX is? I'm going to skip up, Axe Troublemaker. Now I'm going to skip through kind of the what is SPDX slide and jump into what are we doing about 3.0. This is really a talk about my kind of more practical journey. I'm one of the maintainers of the tools and I recently went through a process to upgrade the tools for 3.0 and I thought if I shared my experience with you, those of you who are writing tools yourself might gain some of my experience from that and help you out with your tooling. So as far as the agenda, I thought I might start with a little bit of context. Why did we even do 3.0? Because as you'll see there are some breaking changes or some changes you'll have to adapt to in your code. So it's good to know why we're all doing this. I'm going to talk a little bit about the approach to creating the spec because that will give you context to some of the techniques I've used for upgrading the tools and an overview of the changes, the important part. Then I'll talk about my practical experience on the Java libraries itself. So why SPDX 3.0? We've gotten a lot of feedback from the community. By the way, you guys hear me okay? We have no idea. Yeah, we don't know if it's... There we go. Let's see if I can... It is there. I think that'll work. Alright, a little bit easier. So we've got a lot of feedback on the SPDX 2 spec that is just too complicated. There are too many pages in the spec. So we took some steps in 3.0 to simplify it. At the same time, we added a lot more use cases, which actually can make it a little bit more complicated. So we've taken a few approaches. I think the biggest one is the introduction of profiles in SPDX to allow you to focus in on the things that you care about on SPDX and that does create some changes into the specs and impacts the tooling. Another big change that impacts the tooling is we made a lot more flexible. We have some people using SPDX and extremely large deployments, very, very large S-bombs, and they want to be able to basically distribute this S-bomb across many different files, across the network. And so you'll see some structural changes that allow you to do that more easily and of course reliably and in a way that you can authenticate the relationships. There's a lot of interest in SPDX and non-licensing and non-security scenarios now. So product safety is coming up in 3.1 and some of that actually started to kind of come into 3.0 as well. But there is a lot of changes to support that as well. And a big change, there was actually a time when there was yet a third standard. I know many of you are frustrated with two standards. There was actually three for a while and we merged two of them together in SPDX so that also had somewhat of an impact. So I'm not going to go through all this, but just to point out, we've been around for a long time. So don't ask me why we created two standards. We started back in 2010 and we've gone through a lot of evolutions. Most of them adding use cases back in the early 2000s, 2010, 2013. We added security use cases. More recently, we did the merger. And you can see on the top some of the external influences, the NTIA being one of the most significant in terms of accelerators. What's that? And the CRA. Absolutely. I am in Europe. Yes. And we've also done some work on ISO standardization that's on the timeline as well. And of course, this has an impact on how we evolved the SPAC itself. We started off in a very simple PDF. So we'd give tool developers like myself, here's a PDF, go implement it. That kind of created some errors. Some of us read the words a little bit differently. English isn't the most precise way of describing some of the technical features. We moved that over into a markdown file that was a little bit easier and we generated things. And then we went to an ISO SPAC. Have any of you guys ever gone through an ISO specification process? It's interesting. There are a lot of requirements. They're very picky about their format. So we went through that. And then where we ended up is going to more of a model based description of the language and generating actually multiple different schema files. For 3.0, we actually spent quite a bit of time deciding how we want to do the SPAC infrastructure for 3.0. We decided that a lot of us wanted to write directly to schemas. There's a lot of people though that wanted to make it just human readable and human writable more importantly. So we actually took kind of a middle ground. We described everything in a markdown files, but in a very specific format that every time you commit to the repository, it checks to make sure you adhere to that format. And then we take that and we generate an intermediate schema file. And that schema file then generates everything else. So I have a little bit of a diagram to kind of show you what the process is. And this is important if you want to contribute to the SPAC. This kind of gives you a guide on how to do that. We started with a conceptual model. This is kind of temporary. We don't use that anymore, but it's just a picture to get us all on the same page. And then we write the specs and markdown. And this is where you can contribute. You can just commit directly to the SPAC in that specific format. And thanks to Alexios and quite a few other contributors, we have tools and generators that right now is generating a website, an HTML version of the pages. And here's where us tools developers get to actually kind of get a little excited, at least I do. We generate a Shackle Owl schema file. Now, how many of you have never heard of Shackle or Owl? Okay. Oh my gosh. You guys are going to kill me. But there's good news. We translate the Shackle and Owl to something that you do understand. So, you know, just hang in there because we will get you, we're going to be generating certainly JSON schema files, you know, that I think is really popular. But you might be wondering, first you're wondering what the heck is Shackle and Owl. Look it up. It's really interesting. It's very complicated, but it's very complete. Okay. It's very complete. And then this is where we go to, we call it serialization schemas because JSON looks different than XML, looks different from, you know, there may be other schemas that we generate as well. And the way we, the reason we did all this is it ensures consistency. If we agree on what the markdown file is, everything is completely consistent all the way through to the schemas you use to validate your source code. So, it's well worth the effort. Really, Kate, it's worth the effort. So, you might, now after you ask yourself what is Shackle Owl, you might ask yourself, especially if you look at the spec, you're going to wonder why did we pick that. One thing it captures not only the syntax of the data, which all the schemas do well, you know, this is an integer, this is a string, it's got this pattern. It also captures the semantic behind it. So, it goes beyond what you can capture in a simple syntactic schema. And that is the additional information we pull out of the markdown files and we put it into the Shackle file. So, we can say things like, oh, you got a relationship between a file and a license. It can only be of this type and you have to have at least one of those. Whereas in a syntax, all you can really say is there's a relationship and it's got this cardinality and it's got this type. So, you can go beyond, you know, the specifications. And, of course, if you start with that, you can easily generate the simpler schemas, but you can't go from the simpler schemas to the more complex. So, that's why we picked Shackle. Now, the other reason we picked it is just about the reason we picked all the, well, there's a lot of, huh, it's coming, it's coming back. There's tooling for, there's libraries that support Shackle and most eco-language ecosystems like Python and Java, etc. Am I back yet? So, it's not coming back because we don't have slides that being captured on the stream and the HDMI is put through here. So, there's something going on with this machine. You need to go and talk downstairs. Stream is not available, is what they're saying. Oh, dear. Technical difficulties. So, let's, oh, but I keep, is it coming back? You want me to disconnect? Okay. Okay. X2.x, you know, if you cared about security, you cared about licensing, you cared about, whatever you cared about, you had to read the whole spec to find the little field that you're interested in, you know, in supporting. It's kind of hard to navigate that. And if you wanted to conform, you know, what is required, you know, it's like, you know, if you got a, if you're interested in security, you really want to make sure you have the integrity fields. If you're interested in licensing, you want to make sure you have the licensing fields. But, you know, what do you make required for the spec? So, we introduced profiles and we have what, six or seven profiles in total. And there's really three different aspects to a profile. The most important is the conformance requirements. And what that means for us tools developers, that's the most important. What that means is if you are a producer of a spec and you say, I conform to this profile, I'm, I'm meeting the minimum requirements. That's your promise to the consumer. So, you can say, I conform to licensing, security, and AI and data. But I don't conform to the new services profile. And that, that, and that's, you know, of course carried over in the, in the, in the data itself. It's also a namespace. And this is where the simplification comes in, is that you can kind of filter the spec on what you care about by using these namespace. Technically as well. So, there is a technical namespace that goes along with all the classes and properties. And you can filter on that. And within my code, I also use that to help me with some of the verification code that, that's there. And it's also the way we organize within SPDX. We have meetings that are organized by profiles. So, people of like-mind and like concerns get together and actually develop the spec. So, let's talk a little bit about some of the other structural changes. In SPDX2, we, everything was around a document and that was a file basically. And we had a mechanism for reliably linking documents together because you may get many types of S-bombs for many vendors. You may want to bring them together. You may want to compare them. And you may want to link them together. So, we had a mechanism to do that. In 3.0, we still have the ability, this I got to make this really clear because there's this rumor that SPDX documents are dead and 3.0 is not true. They're still there. And you can use them the same way that you've always used them. But you can also link directly from the elements. And an element is a package or a file or you know, something, you know, a unit of something you care about in SPDX. So, now you can go directly. And so, you can put these things out on a network without having to worry about the files that contain them. And so, think about like the World Wide Web, you know, where you have like files and images that are linked together in HTML. You can do that in SPDX documents in the future. So, it's a very, very flexible, powerful mechanism we're introducing. Relationships have changed. In SPDX 2, they were a property of the element. So, you have an element like a package and you say, it has a relationship to another element like a file and that would be a property. There's a problem with that when you go to this distributed environment because you have to have, you have to know about this in advance. You can't introduce a relationship after the fact because it's a property in the element itself. So, we moved the relationship outside. So, now you have a separate object which is the element that does a relationship from one element to the other. And we've put a bunch of properties in there that in a way kind of simplifies the relationships. So, rather than having hundreds of relationships, we can have dozens of relationships and a few properties within the relationships to take care of it. How am I doing on time, by the way? You are at, yeah, 17 minutes. Oh, perfect. Okay. Other, I want to make sure I go through these changes because I think this may be the most interesting part to you guys. The other, there's a few other changes. There's a better model for what we call entities. This is the person organization. In SPDX 2.x, they were just strings and you'd have to parse the string to figure out whether it's a person or an organization. We now have kind of like a whole object hierarchy that describes what these things are. It makes it a little bit easier for parsing. We renamed and removed a lot of confusing properties. Those of you who have built tooling for SPDX 2 will love this because people complained about these properties all the time. And we either renamed them to make them clear or just got rid of them. And, you know, for example, files analyzed. A lot of people don't like files analyzed. Functionality is still there, but it's just a lot clearer how to actually do those use cases. We've added some additional uses, useful classes and properties. So, for example, we elevated package URL from an external identifier to be in a property on package because a lot of people are using that directly for identifying the package metadata. And then we have some additional profile specific classes and properties, of course. And on this, I know you're not going to be able to type this in. Hopefully, you'll get a copy of these slides. There is a Google Doc that I put together. It's a living document, which means it's open for comment from any of you. You find something missing. Please comment on it. But this is kind of a guide to all the detailed changes. And I was writing that as I was doing this, and I know there's some folks that have done the same thing and contributed to this document that describes all the migration. It'll turn into a migration guide once we do the full release, but right now it's more of a living document. So, kind of stepping back at these changes, you know, what's kind of the big picture of this? You know, it'll be a lot more flexible with the profiles. There'll be a new relationship structure in addition to relationships. So, you need to annotations independent as well, so you can do more incremental changes to the S-bomb without having to go back and create a whole new big S-bomb. And then simpler profiles, simpler snippets, more use cases. And then, again, see the migration document for that. So, now I'm going to switch over to my personal experience. I was involved in writing this back, and now I'm going to tell you how fun it was to actually implement it. So, the Java libraries, first to give you context, I wanted to give you an overview of what the current SPDX 2.x library's architecture looks like. You know, it's what you'd expect. There's a model set of classes, and that match exactly the SPDX 2.x model. The only change is really is I had to rename some of the things that conflicted with the Java language. So, Java doesn't like you to call a class package, for example. And then, there's a set of utility classes that has some useful functions like being able to do a comparison of license, little things like that. And because in the very first iteration of this, I started this like 10 years ago as a pretty printer, it was very monolithic, and I got a lot of feedback that, hey, you know, I don't want to have all these RDF library things in there, if all I want to do is generate JSON. So, we introduced a storage interface that lets you create a lot of different model stores. The model stores can represent a very specific serialization of a file, or it can also represent like a database or a triple store if you're into RDF, or the most common is just an N memory store for it. So, this allows you to separate these out into separate jar files. It does add a complexity because there's a storage interface in between that has to adhere so that we can separate these out into different things, but I think it does make it a lot cleaner. So, a couple of breaking changes that I noticed right off. I think one of the ones I did not expect, this change to the namespaces actually caused a change to the storage interface because I was just using the property names, and I knew that I could always map the property to the full URI of what the properties were, or the full string with the namespace because we had a clean mapping. I can't count on that anymore. So, I had to add one extra parameter, which means, oh my goodness, now I got to change all these different libraries to use that. Of course, I put in a compatibility library that made it a little bit easier, but that was a breaking change to all those things that are implementing the storage object, at the storage model below. The model itself created some breaking changes as you'd expect after going through what the changes are. There is, what I did is I took all of the spdx2.x code and moved that over to a compatibility library so that it's all still there. It is though in a different package in Java, so there is a small change to the imports, but it should work pretty much as is. The relationship and annotation structures that definitely impacted the Java code because it moves it out of properties and makes them a little bit more independent. I came up with a trick to help manage the consumers of my libraries, keep them from having breaking changes. I'll come to that in a couple minutes. That might be an interesting tip for some of you. The external document ref structure really changed. That was probably one of the more significant changes. We talked about the agents, the snippet simplifications, and then moving these properties to relationships. Sure. That layer will direct you to the compatible layer or to the new model layer. It basically minimizes the impact to the users of my library. That's this spdx model factory is what does the switching there. This is the little trick that I came up with for relationships. We used to have these as properties and now we moved them over to separate independent relationships. You can imagine what this will do to all the users of the library. It's like, oh, this isn't just like a change of coding or a change of names. I got to restructure my code. I came up with a way to make it look like a property inside the class. I have a special class that says, okay, this is a relationship, but it looks like a property. If you're interested in that technique, let me know. I can show you the code. It really wasn't that hard. It's a very generalized class that I can use for just about any kind of property. I think it's called relationship property or something like that. That makes it a little bit easier. The other thing I was focused on is reducing the errors. You remember in the, how am I doing? I'll see you in five minutes. Thank you. I saw you getting ready. You remember in the specs, we did a lot of things to reduce the translation errors down to the actual schema files. We're taking that further with the coding as well. We're from the OWL Shackle file. I'm generating the Java code. The Java library code, so now you got from the markdown file all the way through to the actual Java code, traceable, reproducible code to make sure it's all done right. I can't tell you how many errors I have personally made or I mistyped something or I didn't read it right, and it got implemented wrong in the Java library. I think the errors that I make now will be much bigger because it'll be in the code generator. It'll happen to everything. Sorry. That's a little bit of a joke, but no. It'll get rid of all those little errors. We'll also be generating, as I mentioned before, the schema files for those of you who would rather see things in JSON schema or XML schema. I also generate the verification code from the Shackle OWL files. If you're into the RDF, it complies with the Shackle OWL. Those are some of the techniques for reducing the errors. I think this is my last slide, the new architecture. One thing I didn't mention is this copy manager in between. It's a little bit of a detail, but it's kind of an important one, is that if you're migrating, if you've got two different SPDX documents with two different versions and you're referencing to each other, that copy manager will let you copy it over to the new version. That kind of does the upgrades. It'll also copy between the different types of model stores. It'll let you convert between tag value and JSON, whatever. Anyway, I think I might have a minute or two for questions. I got three minutes for questions. Did I go so fast? I lose all of you on that? That felt like I was speed presenting. Yes. I recognize that you get a lot of work about the specs so that you can see them easier. That's great work. But also, I would say we need to have a lot of different kind of examples. You know, you write your library, then you want to test it, and then you find out whether you really understood the specs the right way. Yes. Yes. And therefore, more examples of different types. Yes. I don't think I can repeat all of that, but I think the basic comment, and I think it's a really good one, is in addition to the spec, we need to have examples, you know, so that we can work off of those examples. And we do have an examples repo in SPDX today. We plan on, we're going to organize that in the future for 3.0 by profile. So you'll be, if you're interested in security, you can go down and look at, like, the security examples, be able to use those. Excellent point. Thank you. Yes. Now is current code ready to convert a file from SPDX2 to 3.0? Yeah, that's a really good question. So the question was, do we have code today that'll let you convert from 2 to 3? The Java code is not ready to be used yet, unfortunately. It compiles, but not quite ready. Yes, Dolph. Yeah, we have a project that can do that with the 3DUSRC of SPDX3. So Dolph mentioned there is, is that in the presentation later today? Yeah. Okay. So we hear about a tool that can do that later today. It's not the Java library. So it's coming though. It's not quite ready yet. Yes. SPDX3 light coming? SPDX3 light is coming. And that will be, that's one of our profiles. It's got, it's unique in that it skinnies it down, you know, rather than adding things to it, which other ones do. Yeah. Sorry. Yes. Talk about some of the relationship of SPDX to RDF. I was wondering if you'd come up against any requirements, things that RDF doesn't support, stuff that you feel like you need to push back up into RDF. Ah, that's a good question. The question is, is there anything that we ran into in the RDF world that we, that we couldn't satisfy by using like, like the RDF, maybe Shackle Owl specification? I'd have to think about, I have a feeling we have, but I can't think of an example right now. You know, I, I, I, I, let me think about it and then give back to you later. Yeah. Thank you. Yes. What's the view about converting SPDX3 to Cyclone DX and back and forth? Oh, yes. Because they've obviously got things like AI in their model 5. Right. 5, etc. You've got one. Right. And security. So we're looking at compatibility because there's not people to be, what people to be flexible? Yes, we do. And I'm, I'm with you on that. So the question is, what about converting between Cyclone DX and SPDX? We actually had an effort going on in SPDX2 where we had people from Cyclone DX, myself included on the SPDX side collaborating and, and we were doing two things. We were, we were writing libraries to convert, you know, so kind of really testing it hands on. And, and then we were also working on the SPAC where we were like in 2.3. I actually put a number of things in per request of the Cyclone DX team to make it easier to convert. So we're doing both of those. Unfortunately, that collaboration stopped. I am looking for somebody from the Cyclone DX team to work with to do that in 3.0. So if you're on the Cyclone DX team or if any of you in the room are in Cyclone DX and are interested in, in collaborating with SPDX and make it easier for all of our users, let me know. I'd be happy to work with you. Thank you. Yeah. Okay. So I, I'm not sure I completely understand the, oh, time's up. Answer him. Yeah. Why don't you go ahead and shut me down and you can go ahead and close the screen and take that over. Yeah. Yeah. Just. So, sorry. So the, the decision about. These are committee that decide about the changes. Oh, how, okay. Like the governance of how the SPAC has made itself. Yeah. So we do have a formal governance process. We have a technical, we have kind of like a steering committee and then we have different work groups. The real work gets done in the profile work group. Most of it's in the core. There are team leads that are nominated and, you know, the steering committee, this whole process that does that. And then the way that we really try hard to make all the decisions consensus space and it's, it's based on contributions too. So if somebody says, hey, I want to do this, but they don't contribute anything. Yeah, we don't really listen. If they say, hey, I want to do this and here's a poll request. Here's the spec. Here's some tasks. You know, here's what you do to the schema to make it. Then it's like, oh yeah, come on in, you know, we'll work on it. And sometimes there's differences of opinion. We try to work together very rarely. The team leads will have to make a call and we try to do it based on the majority, but you know, it's rare when we do that. We think very carefully before we do that. Yeah. All right. Max, thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 11.88, "text": " Good morning everybody. So I've got too many slides to present, so I'm going to go kind", "tokens": [50364, 2205, 2446, 2201, 13, 407, 286, 600, 658, 886, 867, 9788, 281, 1974, 11, 370, 286, 478, 516, 281, 352, 733, 50958], "temperature": 0.0, "avg_logprob": -0.22354384029612823, "compression_ratio": 1.5898617511520738, "no_speech_prob": 0.12051123380661011}, {"id": 1, "seek": 0, "start": 11.88, "end": 16.92, "text": " of fast. I think all of you know what SPDX is. Does anybody not know what SPDX is? I'm", "tokens": [50958, 295, 2370, 13, 286, 519, 439, 295, 291, 458, 437, 19572, 55, 307, 13, 4402, 4472, 406, 458, 437, 19572, 55, 307, 30, 286, 478, 51210], "temperature": 0.0, "avg_logprob": -0.22354384029612823, "compression_ratio": 1.5898617511520738, "no_speech_prob": 0.12051123380661011}, {"id": 2, "seek": 0, "start": 16.92, "end": 21.68, "text": " going to skip up, Axe Troublemaker. Now I'm going to skip through kind of the what is", "tokens": [51210, 516, 281, 10023, 493, 11, 20118, 68, 1765, 263, 1113, 4003, 13, 823, 286, 478, 516, 281, 10023, 807, 733, 295, 264, 437, 307, 51448], "temperature": 0.0, "avg_logprob": -0.22354384029612823, "compression_ratio": 1.5898617511520738, "no_speech_prob": 0.12051123380661011}, {"id": 3, "seek": 0, "start": 21.68, "end": 27.04, "text": " SPDX slide and jump into what are we doing about 3.0. This is really a talk about my", "tokens": [51448, 19572, 55, 4137, 293, 3012, 666, 437, 366, 321, 884, 466, 805, 13, 15, 13, 639, 307, 534, 257, 751, 466, 452, 51716], "temperature": 0.0, "avg_logprob": -0.22354384029612823, "compression_ratio": 1.5898617511520738, "no_speech_prob": 0.12051123380661011}, {"id": 4, "seek": 2704, "start": 27.08, "end": 31.759999999999998, "text": " kind of more practical journey. I'm one of the maintainers of the tools and I recently", "tokens": [50366, 733, 295, 544, 8496, 4671, 13, 286, 478, 472, 295, 264, 6909, 433, 295, 264, 3873, 293, 286, 3938, 50600], "temperature": 0.0, "avg_logprob": -0.11088751895087105, "compression_ratio": 1.6870229007633588, "no_speech_prob": 0.07803085446357727}, {"id": 5, "seek": 2704, "start": 31.759999999999998, "end": 36.48, "text": " went through a process to upgrade the tools for 3.0 and I thought if I shared my experience", "tokens": [50600, 1437, 807, 257, 1399, 281, 11484, 264, 3873, 337, 805, 13, 15, 293, 286, 1194, 498, 286, 5507, 452, 1752, 50836], "temperature": 0.0, "avg_logprob": -0.11088751895087105, "compression_ratio": 1.6870229007633588, "no_speech_prob": 0.07803085446357727}, {"id": 6, "seek": 2704, "start": 36.48, "end": 42.6, "text": " with you, those of you who are writing tools yourself might gain some of my experience", "tokens": [50836, 365, 291, 11, 729, 295, 291, 567, 366, 3579, 3873, 1803, 1062, 6052, 512, 295, 452, 1752, 51142], "temperature": 0.0, "avg_logprob": -0.11088751895087105, "compression_ratio": 1.6870229007633588, "no_speech_prob": 0.07803085446357727}, {"id": 7, "seek": 2704, "start": 42.6, "end": 48.599999999999994, "text": " from that and help you out with your tooling. So as far as the agenda, I thought I might", "tokens": [51142, 490, 300, 293, 854, 291, 484, 365, 428, 46593, 13, 407, 382, 1400, 382, 264, 9829, 11, 286, 1194, 286, 1062, 51442], "temperature": 0.0, "avg_logprob": -0.11088751895087105, "compression_ratio": 1.6870229007633588, "no_speech_prob": 0.07803085446357727}, {"id": 8, "seek": 2704, "start": 48.599999999999994, "end": 52.879999999999995, "text": " start with a little bit of context. Why did we even do 3.0? Because as you'll see there", "tokens": [51442, 722, 365, 257, 707, 857, 295, 4319, 13, 1545, 630, 321, 754, 360, 805, 13, 15, 30, 1436, 382, 291, 603, 536, 456, 51656], "temperature": 0.0, "avg_logprob": -0.11088751895087105, "compression_ratio": 1.6870229007633588, "no_speech_prob": 0.07803085446357727}, {"id": 9, "seek": 5288, "start": 52.92, "end": 57.160000000000004, "text": " are some breaking changes or some changes you'll have to adapt to in your code. So it's", "tokens": [50366, 366, 512, 7697, 2962, 420, 512, 2962, 291, 603, 362, 281, 6231, 281, 294, 428, 3089, 13, 407, 309, 311, 50578], "temperature": 0.0, "avg_logprob": -0.16781365780429985, "compression_ratio": 1.6012269938650308, "no_speech_prob": 0.0747043713927269}, {"id": 10, "seek": 5288, "start": 57.160000000000004, "end": 61.0, "text": " good to know why we're all doing this. I'm going to talk a little bit about the approach", "tokens": [50578, 665, 281, 458, 983, 321, 434, 439, 884, 341, 13, 286, 478, 516, 281, 751, 257, 707, 857, 466, 264, 3109, 50770], "temperature": 0.0, "avg_logprob": -0.16781365780429985, "compression_ratio": 1.6012269938650308, "no_speech_prob": 0.0747043713927269}, {"id": 11, "seek": 5288, "start": 61.0, "end": 64.4, "text": " to creating the spec because that will give you context to some of the techniques I've", "tokens": [50770, 281, 4084, 264, 1608, 570, 300, 486, 976, 291, 4319, 281, 512, 295, 264, 7512, 286, 600, 50940], "temperature": 0.0, "avg_logprob": -0.16781365780429985, "compression_ratio": 1.6012269938650308, "no_speech_prob": 0.0747043713927269}, {"id": 12, "seek": 5288, "start": 64.4, "end": 70.04, "text": " used for upgrading the tools and an overview of the changes, the important part. Then I'll", "tokens": [50940, 1143, 337, 36249, 264, 3873, 293, 364, 12492, 295, 264, 2962, 11, 264, 1021, 644, 13, 1396, 286, 603, 51222], "temperature": 0.0, "avg_logprob": -0.16781365780429985, "compression_ratio": 1.6012269938650308, "no_speech_prob": 0.0747043713927269}, {"id": 13, "seek": 5288, "start": 70.04, "end": 77.04, "text": " talk about my practical experience on the Java libraries itself. So why SPDX 3.0? We've", "tokens": [51222, 751, 466, 452, 8496, 1752, 322, 264, 10745, 15148, 2564, 13, 407, 983, 19572, 55, 805, 13, 15, 30, 492, 600, 51572], "temperature": 0.0, "avg_logprob": -0.16781365780429985, "compression_ratio": 1.6012269938650308, "no_speech_prob": 0.0747043713927269}, {"id": 14, "seek": 5288, "start": 77.04, "end": 80.84, "text": " gotten a lot of feedback from the community. By the way, you guys hear me okay?", "tokens": [51572, 5768, 257, 688, 295, 5824, 490, 264, 1768, 13, 3146, 264, 636, 11, 291, 1074, 1568, 385, 1392, 30, 51762], "temperature": 0.0, "avg_logprob": -0.16781365780429985, "compression_ratio": 1.6012269938650308, "no_speech_prob": 0.0747043713927269}, {"id": 15, "seek": 8084, "start": 80.84, "end": 87.84, "text": " We have no idea. Yeah, we don't know if it's... There we go. Let's see if I can... It is there.", "tokens": [50364, 492, 362, 572, 1558, 13, 865, 11, 321, 500, 380, 458, 498, 309, 311, 485, 821, 321, 352, 13, 961, 311, 536, 498, 286, 393, 485, 467, 307, 456, 13, 50714], "temperature": 0.0, "avg_logprob": -0.2822077913982112, "compression_ratio": 1.418848167539267, "no_speech_prob": 0.010983056388795376}, {"id": 16, "seek": 8084, "start": 99.76, "end": 104.92, "text": " I think that'll work. Alright, a little bit easier. So we've got a lot of feedback on", "tokens": [51310, 286, 519, 300, 603, 589, 13, 2798, 11, 257, 707, 857, 3571, 13, 407, 321, 600, 658, 257, 688, 295, 5824, 322, 51568], "temperature": 0.0, "avg_logprob": -0.2822077913982112, "compression_ratio": 1.418848167539267, "no_speech_prob": 0.010983056388795376}, {"id": 17, "seek": 8084, "start": 104.92, "end": 109.68, "text": " the SPDX 2 spec that is just too complicated. There are too many pages in the spec. So we", "tokens": [51568, 264, 19572, 55, 568, 1608, 300, 307, 445, 886, 6179, 13, 821, 366, 886, 867, 7183, 294, 264, 1608, 13, 407, 321, 51806], "temperature": 0.0, "avg_logprob": -0.2822077913982112, "compression_ratio": 1.418848167539267, "no_speech_prob": 0.010983056388795376}, {"id": 18, "seek": 10968, "start": 109.72000000000001, "end": 115.0, "text": " took some steps in 3.0 to simplify it. At the same time, we added a lot more use cases,", "tokens": [50366, 1890, 512, 4439, 294, 805, 13, 15, 281, 20460, 309, 13, 1711, 264, 912, 565, 11, 321, 3869, 257, 688, 544, 764, 3331, 11, 50630], "temperature": 0.0, "avg_logprob": -0.13644966372737177, "compression_ratio": 1.6717557251908397, "no_speech_prob": 0.004069330636411905}, {"id": 19, "seek": 10968, "start": 115.0, "end": 119.48, "text": " which actually can make it a little bit more complicated. So we've taken a few approaches.", "tokens": [50630, 597, 767, 393, 652, 309, 257, 707, 857, 544, 6179, 13, 407, 321, 600, 2726, 257, 1326, 11587, 13, 50854], "temperature": 0.0, "avg_logprob": -0.13644966372737177, "compression_ratio": 1.6717557251908397, "no_speech_prob": 0.004069330636411905}, {"id": 20, "seek": 10968, "start": 119.48, "end": 123.60000000000001, "text": " I think the biggest one is the introduction of profiles in SPDX to allow you to focus", "tokens": [50854, 286, 519, 264, 3880, 472, 307, 264, 9339, 295, 23693, 294, 19572, 55, 281, 2089, 291, 281, 1879, 51060], "temperature": 0.0, "avg_logprob": -0.13644966372737177, "compression_ratio": 1.6717557251908397, "no_speech_prob": 0.004069330636411905}, {"id": 21, "seek": 10968, "start": 123.60000000000001, "end": 129.52, "text": " in on the things that you care about on SPDX and that does create some changes into the", "tokens": [51060, 294, 322, 264, 721, 300, 291, 1127, 466, 322, 19572, 55, 293, 300, 775, 1884, 512, 2962, 666, 264, 51356], "temperature": 0.0, "avg_logprob": -0.13644966372737177, "compression_ratio": 1.6717557251908397, "no_speech_prob": 0.004069330636411905}, {"id": 22, "seek": 10968, "start": 129.52, "end": 134.48000000000002, "text": " specs and impacts the tooling. Another big change that impacts the tooling is we made", "tokens": [51356, 27911, 293, 11606, 264, 46593, 13, 3996, 955, 1319, 300, 11606, 264, 46593, 307, 321, 1027, 51604], "temperature": 0.0, "avg_logprob": -0.13644966372737177, "compression_ratio": 1.6717557251908397, "no_speech_prob": 0.004069330636411905}, {"id": 23, "seek": 13448, "start": 134.56, "end": 140.0, "text": " a lot more flexible. We have some people using SPDX and extremely large deployments, very,", "tokens": [50368, 257, 688, 544, 11358, 13, 492, 362, 512, 561, 1228, 19572, 55, 293, 4664, 2416, 7274, 1117, 11, 588, 11, 50640], "temperature": 0.0, "avg_logprob": -0.1625880495123907, "compression_ratio": 1.6217228464419475, "no_speech_prob": 0.40302982926368713}, {"id": 24, "seek": 13448, "start": 140.0, "end": 146.28, "text": " very large S-bombs, and they want to be able to basically distribute this S-bomb across", "tokens": [50640, 588, 2416, 318, 12, 65, 298, 929, 11, 293, 436, 528, 281, 312, 1075, 281, 1936, 20594, 341, 318, 12, 65, 3548, 2108, 50954], "temperature": 0.0, "avg_logprob": -0.1625880495123907, "compression_ratio": 1.6217228464419475, "no_speech_prob": 0.40302982926368713}, {"id": 25, "seek": 13448, "start": 146.28, "end": 150.83999999999997, "text": " many different files, across the network. And so you'll see some structural changes", "tokens": [50954, 867, 819, 7098, 11, 2108, 264, 3209, 13, 400, 370, 291, 603, 536, 512, 15067, 2962, 51182], "temperature": 0.0, "avg_logprob": -0.1625880495123907, "compression_ratio": 1.6217228464419475, "no_speech_prob": 0.40302982926368713}, {"id": 26, "seek": 13448, "start": 150.83999999999997, "end": 155.0, "text": " that allow you to do that more easily and of course reliably and in a way that you can", "tokens": [51182, 300, 2089, 291, 281, 360, 300, 544, 3612, 293, 295, 1164, 49927, 293, 294, 257, 636, 300, 291, 393, 51390], "temperature": 0.0, "avg_logprob": -0.1625880495123907, "compression_ratio": 1.6217228464419475, "no_speech_prob": 0.40302982926368713}, {"id": 27, "seek": 13448, "start": 155.0, "end": 161.16, "text": " authenticate the relationships. There's a lot of interest in SPDX and non-licensing", "tokens": [51390, 9214, 8700, 264, 6159, 13, 821, 311, 257, 688, 295, 1179, 294, 19572, 55, 293, 2107, 12, 1050, 22481, 51698], "temperature": 0.0, "avg_logprob": -0.1625880495123907, "compression_ratio": 1.6217228464419475, "no_speech_prob": 0.40302982926368713}, {"id": 28, "seek": 16116, "start": 161.2, "end": 166.68, "text": " and non-security scenarios now. So product safety is coming up in 3.1 and some of that", "tokens": [50366, 293, 2107, 12, 31004, 15077, 586, 13, 407, 1674, 4514, 307, 1348, 493, 294, 805, 13, 16, 293, 512, 295, 300, 50640], "temperature": 0.0, "avg_logprob": -0.14974704541658101, "compression_ratio": 1.6931818181818181, "no_speech_prob": 0.012818085961043835}, {"id": 29, "seek": 16116, "start": 166.68, "end": 173.16, "text": " actually started to kind of come into 3.0 as well. But there is a lot of changes to support", "tokens": [50640, 767, 1409, 281, 733, 295, 808, 666, 805, 13, 15, 382, 731, 13, 583, 456, 307, 257, 688, 295, 2962, 281, 1406, 50964], "temperature": 0.0, "avg_logprob": -0.14974704541658101, "compression_ratio": 1.6931818181818181, "no_speech_prob": 0.012818085961043835}, {"id": 30, "seek": 16116, "start": 173.16, "end": 178.6, "text": " that as well. And a big change, there was actually a time when there was yet a third standard.", "tokens": [50964, 300, 382, 731, 13, 400, 257, 955, 1319, 11, 456, 390, 767, 257, 565, 562, 456, 390, 1939, 257, 2636, 3832, 13, 51236], "temperature": 0.0, "avg_logprob": -0.14974704541658101, "compression_ratio": 1.6931818181818181, "no_speech_prob": 0.012818085961043835}, {"id": 31, "seek": 16116, "start": 178.6, "end": 182.84, "text": " I know many of you are frustrated with two standards. There was actually three for a", "tokens": [51236, 286, 458, 867, 295, 291, 366, 15751, 365, 732, 7787, 13, 821, 390, 767, 1045, 337, 257, 51448], "temperature": 0.0, "avg_logprob": -0.14974704541658101, "compression_ratio": 1.6931818181818181, "no_speech_prob": 0.012818085961043835}, {"id": 32, "seek": 16116, "start": 182.84, "end": 186.96, "text": " while and we merged two of them together in SPDX so that also had somewhat of an impact.", "tokens": [51448, 1339, 293, 321, 36427, 732, 295, 552, 1214, 294, 19572, 55, 370, 300, 611, 632, 8344, 295, 364, 2712, 13, 51654], "temperature": 0.0, "avg_logprob": -0.14974704541658101, "compression_ratio": 1.6931818181818181, "no_speech_prob": 0.012818085961043835}, {"id": 33, "seek": 18696, "start": 187.0, "end": 192.6, "text": " So I'm not going to go through all this, but just to point out, we've been around for a long time.", "tokens": [50366, 407, 286, 478, 406, 516, 281, 352, 807, 439, 341, 11, 457, 445, 281, 935, 484, 11, 321, 600, 668, 926, 337, 257, 938, 565, 13, 50646], "temperature": 0.0, "avg_logprob": -0.18857081119830793, "compression_ratio": 1.5743801652892562, "no_speech_prob": 0.0023229175712913275}, {"id": 34, "seek": 18696, "start": 192.6, "end": 199.0, "text": " So don't ask me why we created two standards. We started back in 2010 and we've gone through a", "tokens": [50646, 407, 500, 380, 1029, 385, 983, 321, 2942, 732, 7787, 13, 492, 1409, 646, 294, 9657, 293, 321, 600, 2780, 807, 257, 50966], "temperature": 0.0, "avg_logprob": -0.18857081119830793, "compression_ratio": 1.5743801652892562, "no_speech_prob": 0.0023229175712913275}, {"id": 35, "seek": 18696, "start": 199.0, "end": 207.8, "text": " lot of evolutions. Most of them adding use cases back in the early 2000s, 2010, 2013. We added", "tokens": [50966, 688, 295, 1073, 15892, 13, 4534, 295, 552, 5127, 764, 3331, 646, 294, 264, 2440, 8132, 82, 11, 9657, 11, 9012, 13, 492, 3869, 51406], "temperature": 0.0, "avg_logprob": -0.18857081119830793, "compression_ratio": 1.5743801652892562, "no_speech_prob": 0.0023229175712913275}, {"id": 36, "seek": 18696, "start": 207.8, "end": 212.48000000000002, "text": " security use cases. More recently, we did the merger. And you can see on the top some of the", "tokens": [51406, 3825, 764, 3331, 13, 5048, 3938, 11, 321, 630, 264, 48002, 13, 400, 291, 393, 536, 322, 264, 1192, 512, 295, 264, 51640], "temperature": 0.0, "avg_logprob": -0.18857081119830793, "compression_ratio": 1.5743801652892562, "no_speech_prob": 0.0023229175712913275}, {"id": 37, "seek": 21248, "start": 212.51999999999998, "end": 217.32, "text": " external influences, the NTIA being one of the most significant in terms of accelerators.", "tokens": [50366, 8320, 21222, 11, 264, 426, 5422, 32, 885, 472, 295, 264, 881, 4776, 294, 2115, 295, 10172, 3391, 13, 50606], "temperature": 0.0, "avg_logprob": -0.27378093953035315, "compression_ratio": 1.45703125, "no_speech_prob": 0.03458142280578613}, {"id": 38, "seek": 21248, "start": 217.32, "end": 225.76, "text": " What's that? And the CRA. Absolutely. I am in Europe. Yes. And we've also done some work on", "tokens": [50606, 708, 311, 300, 30, 400, 264, 34425, 13, 7021, 13, 286, 669, 294, 3315, 13, 1079, 13, 400, 321, 600, 611, 1096, 512, 589, 322, 51028], "temperature": 0.0, "avg_logprob": -0.27378093953035315, "compression_ratio": 1.45703125, "no_speech_prob": 0.03458142280578613}, {"id": 39, "seek": 21248, "start": 225.76, "end": 233.04, "text": " ISO standardization that's on the timeline as well. And of course, this has an impact on how we", "tokens": [51028, 25042, 3832, 2144, 300, 311, 322, 264, 12933, 382, 731, 13, 400, 295, 1164, 11, 341, 575, 364, 2712, 322, 577, 321, 51392], "temperature": 0.0, "avg_logprob": -0.27378093953035315, "compression_ratio": 1.45703125, "no_speech_prob": 0.03458142280578613}, {"id": 40, "seek": 21248, "start": 233.04, "end": 239.0, "text": " evolved the SPAC itself. We started off in a very simple PDF. So we'd give tool developers like", "tokens": [51392, 14178, 264, 8420, 4378, 2564, 13, 492, 1409, 766, 294, 257, 588, 2199, 17752, 13, 407, 321, 1116, 976, 2290, 8849, 411, 51690], "temperature": 0.0, "avg_logprob": -0.27378093953035315, "compression_ratio": 1.45703125, "no_speech_prob": 0.03458142280578613}, {"id": 41, "seek": 23900, "start": 239.04, "end": 245.36, "text": " myself, here's a PDF, go implement it. That kind of created some errors. Some of us read the words", "tokens": [50366, 2059, 11, 510, 311, 257, 17752, 11, 352, 4445, 309, 13, 663, 733, 295, 2942, 512, 13603, 13, 2188, 295, 505, 1401, 264, 2283, 50682], "temperature": 0.0, "avg_logprob": -0.15809605247096012, "compression_ratio": 1.5372549019607844, "no_speech_prob": 0.022962354123592377}, {"id": 42, "seek": 23900, "start": 245.36, "end": 250.4, "text": " a little bit differently. English isn't the most precise way of describing some of the technical", "tokens": [50682, 257, 707, 857, 7614, 13, 3669, 1943, 380, 264, 881, 13600, 636, 295, 16141, 512, 295, 264, 6191, 50934], "temperature": 0.0, "avg_logprob": -0.15809605247096012, "compression_ratio": 1.5372549019607844, "no_speech_prob": 0.022962354123592377}, {"id": 43, "seek": 23900, "start": 250.4, "end": 257.68, "text": " features. We moved that over into a markdown file that was a little bit easier and we generated", "tokens": [50934, 4122, 13, 492, 4259, 300, 670, 666, 257, 1491, 5093, 3991, 300, 390, 257, 707, 857, 3571, 293, 321, 10833, 51298], "temperature": 0.0, "avg_logprob": -0.15809605247096012, "compression_ratio": 1.5372549019607844, "no_speech_prob": 0.022962354123592377}, {"id": 44, "seek": 23900, "start": 257.68, "end": 263.96, "text": " things. And then we went to an ISO SPAC. Have any of you guys ever gone through an ISO specification", "tokens": [51298, 721, 13, 400, 550, 321, 1437, 281, 364, 25042, 8420, 4378, 13, 3560, 604, 295, 291, 1074, 1562, 2780, 807, 364, 25042, 31256, 51612], "temperature": 0.0, "avg_logprob": -0.15809605247096012, "compression_ratio": 1.5372549019607844, "no_speech_prob": 0.022962354123592377}, {"id": 45, "seek": 26396, "start": 264.0, "end": 270.35999999999996, "text": " process? It's interesting. There are a lot of requirements. They're very picky about their", "tokens": [50366, 1399, 30, 467, 311, 1880, 13, 821, 366, 257, 688, 295, 7728, 13, 814, 434, 588, 41099, 466, 641, 50684], "temperature": 0.0, "avg_logprob": -0.15564430152976905, "compression_ratio": 1.5100401606425702, "no_speech_prob": 0.03257552534341812}, {"id": 46, "seek": 26396, "start": 270.35999999999996, "end": 277.76, "text": " format. So we went through that. And then where we ended up is going to more of a model based", "tokens": [50684, 7877, 13, 407, 321, 1437, 807, 300, 13, 400, 550, 689, 321, 4590, 493, 307, 516, 281, 544, 295, 257, 2316, 2361, 51054], "temperature": 0.0, "avg_logprob": -0.15564430152976905, "compression_ratio": 1.5100401606425702, "no_speech_prob": 0.03257552534341812}, {"id": 47, "seek": 26396, "start": 277.76, "end": 285.67999999999995, "text": " description of the language and generating actually multiple different schema files. For 3.0,", "tokens": [51054, 3855, 295, 264, 2856, 293, 17746, 767, 3866, 819, 34078, 7098, 13, 1171, 805, 13, 15, 11, 51450], "temperature": 0.0, "avg_logprob": -0.15564430152976905, "compression_ratio": 1.5100401606425702, "no_speech_prob": 0.03257552534341812}, {"id": 48, "seek": 26396, "start": 285.67999999999995, "end": 290.44, "text": " we actually spent quite a bit of time deciding how we want to do the SPAC infrastructure for 3.0.", "tokens": [51450, 321, 767, 4418, 1596, 257, 857, 295, 565, 17990, 577, 321, 528, 281, 360, 264, 8420, 4378, 6896, 337, 805, 13, 15, 13, 51688], "temperature": 0.0, "avg_logprob": -0.15564430152976905, "compression_ratio": 1.5100401606425702, "no_speech_prob": 0.03257552534341812}, {"id": 49, "seek": 29044, "start": 291.04, "end": 296.2, "text": " We decided that a lot of us wanted to write directly to schemas. There's a lot of people", "tokens": [50394, 492, 3047, 300, 257, 688, 295, 505, 1415, 281, 2464, 3838, 281, 22627, 296, 13, 821, 311, 257, 688, 295, 561, 50652], "temperature": 0.0, "avg_logprob": -0.19601497134646853, "compression_ratio": 1.7418181818181817, "no_speech_prob": 0.020322905853390694}, {"id": 50, "seek": 29044, "start": 296.2, "end": 301.48, "text": " though that wanted to make it just human readable and human writable more importantly. So we actually", "tokens": [50652, 1673, 300, 1415, 281, 652, 309, 445, 1952, 49857, 293, 1952, 10912, 712, 544, 8906, 13, 407, 321, 767, 50916], "temperature": 0.0, "avg_logprob": -0.19601497134646853, "compression_ratio": 1.7418181818181817, "no_speech_prob": 0.020322905853390694}, {"id": 51, "seek": 29044, "start": 301.48, "end": 307.28, "text": " took kind of a middle ground. We described everything in a markdown files, but in a very", "tokens": [50916, 1890, 733, 295, 257, 2808, 2727, 13, 492, 7619, 1203, 294, 257, 1491, 5093, 7098, 11, 457, 294, 257, 588, 51206], "temperature": 0.0, "avg_logprob": -0.19601497134646853, "compression_ratio": 1.7418181818181817, "no_speech_prob": 0.020322905853390694}, {"id": 52, "seek": 29044, "start": 307.28, "end": 312.64, "text": " specific format that every time you commit to the repository, it checks to make sure you adhere to", "tokens": [51206, 2685, 7877, 300, 633, 565, 291, 5599, 281, 264, 25841, 11, 309, 13834, 281, 652, 988, 291, 33584, 281, 51474], "temperature": 0.0, "avg_logprob": -0.19601497134646853, "compression_ratio": 1.7418181818181817, "no_speech_prob": 0.020322905853390694}, {"id": 53, "seek": 29044, "start": 312.64, "end": 319.64, "text": " that format. And then we take that and we generate an intermediate schema file. And that schema file", "tokens": [51474, 300, 7877, 13, 400, 550, 321, 747, 300, 293, 321, 8460, 364, 19376, 34078, 3991, 13, 400, 300, 34078, 3991, 51824], "temperature": 0.0, "avg_logprob": -0.19601497134646853, "compression_ratio": 1.7418181818181817, "no_speech_prob": 0.020322905853390694}, {"id": 54, "seek": 31964, "start": 319.76, "end": 326.15999999999997, "text": " then generates everything else. So I have a little bit of a diagram to kind of show you what the", "tokens": [50370, 550, 23815, 1203, 1646, 13, 407, 286, 362, 257, 707, 857, 295, 257, 10686, 281, 733, 295, 855, 291, 437, 264, 50690], "temperature": 0.0, "avg_logprob": -0.10055228752818535, "compression_ratio": 1.687719298245614, "no_speech_prob": 0.0023591688368469477}, {"id": 55, "seek": 31964, "start": 326.15999999999997, "end": 330.71999999999997, "text": " process is. And this is important if you want to contribute to the SPAC. This kind of gives you a", "tokens": [50690, 1399, 307, 13, 400, 341, 307, 1021, 498, 291, 528, 281, 10586, 281, 264, 8420, 4378, 13, 639, 733, 295, 2709, 291, 257, 50918], "temperature": 0.0, "avg_logprob": -0.10055228752818535, "compression_ratio": 1.687719298245614, "no_speech_prob": 0.0023591688368469477}, {"id": 56, "seek": 31964, "start": 330.71999999999997, "end": 335.96, "text": " guide on how to do that. We started with a conceptual model. This is kind of temporary. We", "tokens": [50918, 5934, 322, 577, 281, 360, 300, 13, 492, 1409, 365, 257, 24106, 2316, 13, 639, 307, 733, 295, 13413, 13, 492, 51180], "temperature": 0.0, "avg_logprob": -0.10055228752818535, "compression_ratio": 1.687719298245614, "no_speech_prob": 0.0023591688368469477}, {"id": 57, "seek": 31964, "start": 335.96, "end": 340.88, "text": " don't use that anymore, but it's just a picture to get us all on the same page. And then we write", "tokens": [51180, 500, 380, 764, 300, 3602, 11, 457, 309, 311, 445, 257, 3036, 281, 483, 505, 439, 322, 264, 912, 3028, 13, 400, 550, 321, 2464, 51426], "temperature": 0.0, "avg_logprob": -0.10055228752818535, "compression_ratio": 1.687719298245614, "no_speech_prob": 0.0023591688368469477}, {"id": 58, "seek": 31964, "start": 340.88, "end": 345.68, "text": " the specs and markdown. And this is where you can contribute. You can just commit directly to the", "tokens": [51426, 264, 27911, 293, 1491, 5093, 13, 400, 341, 307, 689, 291, 393, 10586, 13, 509, 393, 445, 5599, 3838, 281, 264, 51666], "temperature": 0.0, "avg_logprob": -0.10055228752818535, "compression_ratio": 1.687719298245614, "no_speech_prob": 0.0023591688368469477}, {"id": 59, "seek": 34568, "start": 345.72, "end": 351.44, "text": " SPAC in that specific format. And thanks to Alexios and quite a few other contributors, we have", "tokens": [50366, 8420, 4378, 294, 300, 2685, 7877, 13, 400, 3231, 281, 5202, 2717, 293, 1596, 257, 1326, 661, 45627, 11, 321, 362, 50652], "temperature": 0.0, "avg_logprob": -0.15418880764800724, "compression_ratio": 1.5317460317460319, "no_speech_prob": 0.03513745963573456}, {"id": 60, "seek": 34568, "start": 351.44, "end": 358.48, "text": " tools and generators that right now is generating a website, an HTML version of the pages. And", "tokens": [50652, 3873, 293, 38662, 300, 558, 586, 307, 17746, 257, 3144, 11, 364, 17995, 3037, 295, 264, 7183, 13, 400, 51004], "temperature": 0.0, "avg_logprob": -0.15418880764800724, "compression_ratio": 1.5317460317460319, "no_speech_prob": 0.03513745963573456}, {"id": 61, "seek": 34568, "start": 358.48, "end": 363.88, "text": " here's where us tools developers get to actually kind of get a little excited, at least I do. We", "tokens": [51004, 510, 311, 689, 505, 3873, 8849, 483, 281, 767, 733, 295, 483, 257, 707, 2919, 11, 412, 1935, 286, 360, 13, 492, 51274], "temperature": 0.0, "avg_logprob": -0.15418880764800724, "compression_ratio": 1.5317460317460319, "no_speech_prob": 0.03513745963573456}, {"id": 62, "seek": 34568, "start": 363.88, "end": 371.36, "text": " generate a Shackle Owl schema file. Now, how many of you have never heard of Shackle or Owl? Okay.", "tokens": [51274, 8460, 257, 1160, 501, 306, 12773, 75, 34078, 3991, 13, 823, 11, 577, 867, 295, 291, 362, 1128, 2198, 295, 1160, 501, 306, 420, 12773, 75, 30, 1033, 13, 51648], "temperature": 0.0, "avg_logprob": -0.15418880764800724, "compression_ratio": 1.5317460317460319, "no_speech_prob": 0.03513745963573456}, {"id": 63, "seek": 37136, "start": 371.56, "end": 377.0, "text": " Oh my gosh. You guys are going to kill me. But there's good news. We translate the Shackle and", "tokens": [50374, 876, 452, 6502, 13, 509, 1074, 366, 516, 281, 1961, 385, 13, 583, 456, 311, 665, 2583, 13, 492, 13799, 264, 1160, 501, 306, 293, 50646], "temperature": 0.0, "avg_logprob": -0.16189819801854724, "compression_ratio": 1.7446808510638299, "no_speech_prob": 0.008846152573823929}, {"id": 64, "seek": 37136, "start": 377.0, "end": 381.48, "text": " Owl to something that you do understand. So, you know, just hang in there because we will get you,", "tokens": [50646, 12773, 75, 281, 746, 300, 291, 360, 1223, 13, 407, 11, 291, 458, 11, 445, 3967, 294, 456, 570, 321, 486, 483, 291, 11, 50870], "temperature": 0.0, "avg_logprob": -0.16189819801854724, "compression_ratio": 1.7446808510638299, "no_speech_prob": 0.008846152573823929}, {"id": 65, "seek": 37136, "start": 381.48, "end": 386.44, "text": " we're going to be generating certainly JSON schema files, you know, that I think is really popular.", "tokens": [50870, 321, 434, 516, 281, 312, 17746, 3297, 31828, 34078, 7098, 11, 291, 458, 11, 300, 286, 519, 307, 534, 3743, 13, 51118], "temperature": 0.0, "avg_logprob": -0.16189819801854724, "compression_ratio": 1.7446808510638299, "no_speech_prob": 0.008846152573823929}, {"id": 66, "seek": 37136, "start": 387.44, "end": 391.44, "text": " But you might be wondering, first you're wondering what the heck is Shackle and Owl. Look it up.", "tokens": [51168, 583, 291, 1062, 312, 6359, 11, 700, 291, 434, 6359, 437, 264, 12872, 307, 1160, 501, 306, 293, 12773, 75, 13, 2053, 309, 493, 13, 51368], "temperature": 0.0, "avg_logprob": -0.16189819801854724, "compression_ratio": 1.7446808510638299, "no_speech_prob": 0.008846152573823929}, {"id": 67, "seek": 37136, "start": 391.44, "end": 398.08000000000004, "text": " It's really interesting. It's very complicated, but it's very complete. Okay. It's very complete. And", "tokens": [51368, 467, 311, 534, 1880, 13, 467, 311, 588, 6179, 11, 457, 309, 311, 588, 3566, 13, 1033, 13, 467, 311, 588, 3566, 13, 400, 51700], "temperature": 0.0, "avg_logprob": -0.16189819801854724, "compression_ratio": 1.7446808510638299, "no_speech_prob": 0.008846152573823929}, {"id": 68, "seek": 39808, "start": 398.12, "end": 402.76, "text": " then this is where we go to, we call it serialization schemas because JSON looks different than XML,", "tokens": [50366, 550, 341, 307, 689, 321, 352, 281, 11, 321, 818, 309, 17436, 2144, 22627, 296, 570, 31828, 1542, 819, 813, 43484, 11, 50598], "temperature": 0.0, "avg_logprob": -0.17826020333074755, "compression_ratio": 1.7253521126760563, "no_speech_prob": 0.0016482012579217553}, {"id": 69, "seek": 39808, "start": 402.76, "end": 408.35999999999996, "text": " looks different from, you know, there may be other schemas that we generate as well. And the way we,", "tokens": [50598, 1542, 819, 490, 11, 291, 458, 11, 456, 815, 312, 661, 22627, 296, 300, 321, 8460, 382, 731, 13, 400, 264, 636, 321, 11, 50878], "temperature": 0.0, "avg_logprob": -0.17826020333074755, "compression_ratio": 1.7253521126760563, "no_speech_prob": 0.0016482012579217553}, {"id": 70, "seek": 39808, "start": 408.35999999999996, "end": 413.28, "text": " the reason we did all this is it ensures consistency. If we agree on what the markdown file is,", "tokens": [50878, 264, 1778, 321, 630, 439, 341, 307, 309, 28111, 14416, 13, 759, 321, 3986, 322, 437, 264, 1491, 5093, 3991, 307, 11, 51124], "temperature": 0.0, "avg_logprob": -0.17826020333074755, "compression_ratio": 1.7253521126760563, "no_speech_prob": 0.0016482012579217553}, {"id": 71, "seek": 39808, "start": 413.28, "end": 417.68, "text": " everything is completely consistent all the way through to the schemas you use to validate your", "tokens": [51124, 1203, 307, 2584, 8398, 439, 264, 636, 807, 281, 264, 22627, 296, 291, 764, 281, 29562, 428, 51344], "temperature": 0.0, "avg_logprob": -0.17826020333074755, "compression_ratio": 1.7253521126760563, "no_speech_prob": 0.0016482012579217553}, {"id": 72, "seek": 39808, "start": 417.68, "end": 425.64, "text": " source code. So, it's well worth the effort. Really, Kate, it's worth the effort. So, you might,", "tokens": [51344, 4009, 3089, 13, 407, 11, 309, 311, 731, 3163, 264, 4630, 13, 4083, 11, 16251, 11, 309, 311, 3163, 264, 4630, 13, 407, 11, 291, 1062, 11, 51742], "temperature": 0.0, "avg_logprob": -0.17826020333074755, "compression_ratio": 1.7253521126760563, "no_speech_prob": 0.0016482012579217553}, {"id": 73, "seek": 42564, "start": 425.91999999999996, "end": 430.76, "text": " now after you ask yourself what is Shackle Owl, you might ask yourself, especially if you look at", "tokens": [50378, 586, 934, 291, 1029, 1803, 437, 307, 1160, 501, 306, 12773, 75, 11, 291, 1062, 1029, 1803, 11, 2318, 498, 291, 574, 412, 50620], "temperature": 0.0, "avg_logprob": -0.1785880918425273, "compression_ratio": 1.7318840579710144, "no_speech_prob": 0.0030747682321816683}, {"id": 74, "seek": 42564, "start": 430.76, "end": 435.91999999999996, "text": " the spec, you're going to wonder why did we pick that. One thing it captures not only the syntax", "tokens": [50620, 264, 1608, 11, 291, 434, 516, 281, 2441, 983, 630, 321, 1888, 300, 13, 1485, 551, 309, 27986, 406, 787, 264, 28431, 50878], "temperature": 0.0, "avg_logprob": -0.1785880918425273, "compression_ratio": 1.7318840579710144, "no_speech_prob": 0.0030747682321816683}, {"id": 75, "seek": 42564, "start": 435.91999999999996, "end": 442.76, "text": " of the data, which all the schemas do well, you know, this is an integer, this is a string,", "tokens": [50878, 295, 264, 1412, 11, 597, 439, 264, 22627, 296, 360, 731, 11, 291, 458, 11, 341, 307, 364, 24922, 11, 341, 307, 257, 6798, 11, 51220], "temperature": 0.0, "avg_logprob": -0.1785880918425273, "compression_ratio": 1.7318840579710144, "no_speech_prob": 0.0030747682321816683}, {"id": 76, "seek": 42564, "start": 442.76, "end": 449.36, "text": " it's got this pattern. It also captures the semantic behind it. So, it goes beyond what you can", "tokens": [51220, 309, 311, 658, 341, 5102, 13, 467, 611, 27986, 264, 47982, 2261, 309, 13, 407, 11, 309, 1709, 4399, 437, 291, 393, 51550], "temperature": 0.0, "avg_logprob": -0.1785880918425273, "compression_ratio": 1.7318840579710144, "no_speech_prob": 0.0030747682321816683}, {"id": 77, "seek": 42564, "start": 449.36, "end": 454.91999999999996, "text": " capture in a simple syntactic schema. And that is the additional information we pull out of the", "tokens": [51550, 7983, 294, 257, 2199, 23980, 19892, 34078, 13, 400, 300, 307, 264, 4497, 1589, 321, 2235, 484, 295, 264, 51828], "temperature": 0.0, "avg_logprob": -0.1785880918425273, "compression_ratio": 1.7318840579710144, "no_speech_prob": 0.0030747682321816683}, {"id": 78, "seek": 45492, "start": 454.96000000000004, "end": 459.40000000000003, "text": " markdown files and we put it into the Shackle file. So, we can say things like, oh, you got a", "tokens": [50366, 1491, 5093, 7098, 293, 321, 829, 309, 666, 264, 1160, 501, 306, 3991, 13, 407, 11, 321, 393, 584, 721, 411, 11, 1954, 11, 291, 658, 257, 50588], "temperature": 0.0, "avg_logprob": -0.12335667106675806, "compression_ratio": 1.8639240506329113, "no_speech_prob": 0.0030749111901968718}, {"id": 79, "seek": 45492, "start": 459.40000000000003, "end": 463.92, "text": " relationship between a file and a license. It can only be of this type and you have to have at least", "tokens": [50588, 2480, 1296, 257, 3991, 293, 257, 10476, 13, 467, 393, 787, 312, 295, 341, 2010, 293, 291, 362, 281, 362, 412, 1935, 50814], "temperature": 0.0, "avg_logprob": -0.12335667106675806, "compression_ratio": 1.8639240506329113, "no_speech_prob": 0.0030749111901968718}, {"id": 80, "seek": 45492, "start": 463.92, "end": 468.6, "text": " one of those. Whereas in a syntax, all you can really say is there's a relationship and it's got", "tokens": [50814, 472, 295, 729, 13, 13813, 294, 257, 28431, 11, 439, 291, 393, 534, 584, 307, 456, 311, 257, 2480, 293, 309, 311, 658, 51048], "temperature": 0.0, "avg_logprob": -0.12335667106675806, "compression_ratio": 1.8639240506329113, "no_speech_prob": 0.0030749111901968718}, {"id": 81, "seek": 45492, "start": 468.6, "end": 473.92, "text": " this cardinality and it's got this type. So, you can go beyond, you know, the specifications. And,", "tokens": [51048, 341, 2920, 259, 1860, 293, 309, 311, 658, 341, 2010, 13, 407, 11, 291, 393, 352, 4399, 11, 291, 458, 11, 264, 29448, 13, 400, 11, 51314], "temperature": 0.0, "avg_logprob": -0.12335667106675806, "compression_ratio": 1.8639240506329113, "no_speech_prob": 0.0030749111901968718}, {"id": 82, "seek": 45492, "start": 473.92, "end": 478.64, "text": " of course, if you start with that, you can easily generate the simpler schemas, but you can't go", "tokens": [51314, 295, 1164, 11, 498, 291, 722, 365, 300, 11, 291, 393, 3612, 8460, 264, 18587, 22627, 296, 11, 457, 291, 393, 380, 352, 51550], "temperature": 0.0, "avg_logprob": -0.12335667106675806, "compression_ratio": 1.8639240506329113, "no_speech_prob": 0.0030749111901968718}, {"id": 83, "seek": 45492, "start": 478.64, "end": 484.36, "text": " from the simpler schemas to the more complex. So, that's why we picked Shackle. Now, the other reason", "tokens": [51550, 490, 264, 18587, 22627, 296, 281, 264, 544, 3997, 13, 407, 11, 300, 311, 983, 321, 6183, 1160, 501, 306, 13, 823, 11, 264, 661, 1778, 51836], "temperature": 0.0, "avg_logprob": -0.12335667106675806, "compression_ratio": 1.8639240506329113, "no_speech_prob": 0.0030749111901968718}, {"id": 84, "seek": 48436, "start": 484.40000000000003, "end": 498.2, "text": " we picked it is just about the reason we picked all the, well, there's a lot of, huh, it's coming,", "tokens": [50366, 321, 6183, 309, 307, 445, 466, 264, 1778, 321, 6183, 439, 264, 11, 731, 11, 456, 311, 257, 688, 295, 11, 7020, 11, 309, 311, 1348, 11, 51056], "temperature": 0.0, "avg_logprob": -0.3114924165937636, "compression_ratio": 1.5029940119760479, "no_speech_prob": 0.0012247723061591387}, {"id": 85, "seek": 48436, "start": 498.2, "end": 503.64, "text": " it's coming back. There's tooling for, there's libraries that support Shackle and most", "tokens": [51056, 309, 311, 1348, 646, 13, 821, 311, 46593, 337, 11, 456, 311, 15148, 300, 1406, 1160, 501, 306, 293, 881, 51328], "temperature": 0.0, "avg_logprob": -0.3114924165937636, "compression_ratio": 1.5029940119760479, "no_speech_prob": 0.0012247723061591387}, {"id": 86, "seek": 48436, "start": 503.64, "end": 508.24, "text": " eco-language ecosystems like Python and Java, etc. Am I back yet?", "tokens": [51328, 30226, 12, 25241, 20473, 32647, 411, 15329, 293, 10745, 11, 5183, 13, 2012, 286, 646, 1939, 30, 51558], "temperature": 0.0, "avg_logprob": -0.3114924165937636, "compression_ratio": 1.5029940119760479, "no_speech_prob": 0.0012247723061591387}, {"id": 87, "seek": 50824, "start": 508.24, "end": 512.44, "text": " So, it's not coming back because we don't have slides that being captured on the stream and the", "tokens": [50364, 407, 11, 309, 311, 406, 1348, 646, 570, 321, 500, 380, 362, 9788, 300, 885, 11828, 322, 264, 4309, 293, 264, 50574], "temperature": 0.0, "avg_logprob": -0.27079786381251375, "compression_ratio": 1.4356435643564356, "no_speech_prob": 0.038688186556100845}, {"id": 88, "seek": 50824, "start": 512.44, "end": 517.24, "text": " HDMI is put through here. So, there's something going on with this machine. You need to go and talk", "tokens": [50574, 30811, 307, 829, 807, 510, 13, 407, 11, 456, 311, 746, 516, 322, 365, 341, 3479, 13, 509, 643, 281, 352, 293, 751, 50814], "temperature": 0.0, "avg_logprob": -0.27079786381251375, "compression_ratio": 1.4356435643564356, "no_speech_prob": 0.038688186556100845}, {"id": 89, "seek": 50824, "start": 517.24, "end": 524.16, "text": " downstairs. Stream is not available, is what they're saying. Oh, dear. Technical difficulties.", "tokens": [50814, 20148, 13, 24904, 307, 406, 2435, 11, 307, 437, 436, 434, 1566, 13, 876, 11, 6875, 13, 35512, 14399, 13, 51160], "temperature": 0.0, "avg_logprob": -0.27079786381251375, "compression_ratio": 1.4356435643564356, "no_speech_prob": 0.038688186556100845}, {"id": 90, "seek": 53824, "start": 539.24, "end": 556.76, "text": " So, let's, oh, but I keep, is it coming back? You want me to disconnect? Okay. Okay.", "tokens": [50414, 407, 11, 718, 311, 11, 1954, 11, 457, 286, 1066, 11, 307, 309, 1348, 646, 30, 509, 528, 385, 281, 14299, 30, 1033, 13, 1033, 13, 51290], "temperature": 0.0, "avg_logprob": -0.45932499567667645, "compression_ratio": 1.0120481927710843, "no_speech_prob": 0.06267942488193512}, {"id": 91, "seek": 55676, "start": 556.76, "end": 571.36, "text": " X2.x, you know, if you cared about security, you cared about licensing, you cared about, whatever you", "tokens": [50364, 1783, 17, 13, 87, 11, 291, 458, 11, 498, 291, 19779, 466, 3825, 11, 291, 19779, 466, 29759, 11, 291, 19779, 466, 11, 2035, 291, 51094], "temperature": 0.0, "avg_logprob": -0.14893715268089658, "compression_ratio": 1.9543147208121827, "no_speech_prob": 0.040206797420978546}, {"id": 92, "seek": 55676, "start": 571.36, "end": 575.64, "text": " cared about, you had to read the whole spec to find the little field that you're interested in,", "tokens": [51094, 19779, 466, 11, 291, 632, 281, 1401, 264, 1379, 1608, 281, 915, 264, 707, 2519, 300, 291, 434, 3102, 294, 11, 51308], "temperature": 0.0, "avg_logprob": -0.14893715268089658, "compression_ratio": 1.9543147208121827, "no_speech_prob": 0.040206797420978546}, {"id": 93, "seek": 55676, "start": 575.64, "end": 580.0, "text": " you know, in supporting. It's kind of hard to navigate that. And if you wanted to conform,", "tokens": [51308, 291, 458, 11, 294, 7231, 13, 467, 311, 733, 295, 1152, 281, 12350, 300, 13, 400, 498, 291, 1415, 281, 18975, 11, 51526], "temperature": 0.0, "avg_logprob": -0.14893715268089658, "compression_ratio": 1.9543147208121827, "no_speech_prob": 0.040206797420978546}, {"id": 94, "seek": 55676, "start": 580.0, "end": 584.68, "text": " you know, what is required, you know, it's like, you know, if you got a, if you're interested in", "tokens": [51526, 291, 458, 11, 437, 307, 4739, 11, 291, 458, 11, 309, 311, 411, 11, 291, 458, 11, 498, 291, 658, 257, 11, 498, 291, 434, 3102, 294, 51760], "temperature": 0.0, "avg_logprob": -0.14893715268089658, "compression_ratio": 1.9543147208121827, "no_speech_prob": 0.040206797420978546}, {"id": 95, "seek": 58468, "start": 584.68, "end": 587.88, "text": " security, you really want to make sure you have the integrity fields. If you're interested in", "tokens": [50364, 3825, 11, 291, 534, 528, 281, 652, 988, 291, 362, 264, 16000, 7909, 13, 759, 291, 434, 3102, 294, 50524], "temperature": 0.0, "avg_logprob": -0.15327161336116654, "compression_ratio": 1.9191919191919191, "no_speech_prob": 0.07802803814411163}, {"id": 96, "seek": 58468, "start": 587.88, "end": 591.4799999999999, "text": " licensing, you want to make sure you have the licensing fields. But, you know, what do you make", "tokens": [50524, 29759, 11, 291, 528, 281, 652, 988, 291, 362, 264, 29759, 7909, 13, 583, 11, 291, 458, 11, 437, 360, 291, 652, 50704], "temperature": 0.0, "avg_logprob": -0.15327161336116654, "compression_ratio": 1.9191919191919191, "no_speech_prob": 0.07802803814411163}, {"id": 97, "seek": 58468, "start": 591.4799999999999, "end": 597.3599999999999, "text": " required for the spec? So, we introduced profiles and we have what, six or seven profiles in total.", "tokens": [50704, 4739, 337, 264, 1608, 30, 407, 11, 321, 7268, 23693, 293, 321, 362, 437, 11, 2309, 420, 3407, 23693, 294, 3217, 13, 50998], "temperature": 0.0, "avg_logprob": -0.15327161336116654, "compression_ratio": 1.9191919191919191, "no_speech_prob": 0.07802803814411163}, {"id": 98, "seek": 58468, "start": 597.3599999999999, "end": 602.3599999999999, "text": " And there's really three different aspects to a profile. The most important is the conformance", "tokens": [50998, 400, 456, 311, 534, 1045, 819, 7270, 281, 257, 7964, 13, 440, 881, 1021, 307, 264, 18975, 719, 51248], "temperature": 0.0, "avg_logprob": -0.15327161336116654, "compression_ratio": 1.9191919191919191, "no_speech_prob": 0.07802803814411163}, {"id": 99, "seek": 58468, "start": 602.3599999999999, "end": 607.0, "text": " requirements. And what that means for us tools developers, that's the most important. What", "tokens": [51248, 7728, 13, 400, 437, 300, 1355, 337, 505, 3873, 8849, 11, 300, 311, 264, 881, 1021, 13, 708, 51480], "temperature": 0.0, "avg_logprob": -0.15327161336116654, "compression_ratio": 1.9191919191919191, "no_speech_prob": 0.07802803814411163}, {"id": 100, "seek": 58468, "start": 607.0, "end": 612.04, "text": " that means is if you are a producer of a spec and you say, I conform to this profile, I'm, I'm", "tokens": [51480, 300, 1355, 307, 498, 291, 366, 257, 12314, 295, 257, 1608, 293, 291, 584, 11, 286, 18975, 281, 341, 7964, 11, 286, 478, 11, 286, 478, 51732], "temperature": 0.0, "avg_logprob": -0.15327161336116654, "compression_ratio": 1.9191919191919191, "no_speech_prob": 0.07802803814411163}, {"id": 101, "seek": 61204, "start": 612.0799999999999, "end": 616.5999999999999, "text": " meeting the minimum requirements. That's your promise to the consumer. So, you can say, I conform", "tokens": [50366, 3440, 264, 7285, 7728, 13, 663, 311, 428, 6228, 281, 264, 9711, 13, 407, 11, 291, 393, 584, 11, 286, 18975, 50592], "temperature": 0.0, "avg_logprob": -0.1920933610811008, "compression_ratio": 1.7418181818181817, "no_speech_prob": 0.005554077215492725}, {"id": 102, "seek": 61204, "start": 616.5999999999999, "end": 625.4, "text": " to licensing, security, and AI and data. But I don't conform to the new services profile. And", "tokens": [50592, 281, 29759, 11, 3825, 11, 293, 7318, 293, 1412, 13, 583, 286, 500, 380, 18975, 281, 264, 777, 3328, 7964, 13, 400, 51032], "temperature": 0.0, "avg_logprob": -0.1920933610811008, "compression_ratio": 1.7418181818181817, "no_speech_prob": 0.005554077215492725}, {"id": 103, "seek": 61204, "start": 625.4, "end": 631.0799999999999, "text": " that, that, and that's, you know, of course carried over in the, in the, in the data itself. It's", "tokens": [51032, 300, 11, 300, 11, 293, 300, 311, 11, 291, 458, 11, 295, 1164, 9094, 670, 294, 264, 11, 294, 264, 11, 294, 264, 1412, 2564, 13, 467, 311, 51316], "temperature": 0.0, "avg_logprob": -0.1920933610811008, "compression_ratio": 1.7418181818181817, "no_speech_prob": 0.005554077215492725}, {"id": 104, "seek": 61204, "start": 631.0799999999999, "end": 635.76, "text": " also a namespace. And this is where the simplification comes in, is that you can kind of filter the", "tokens": [51316, 611, 257, 5288, 17940, 13, 400, 341, 307, 689, 264, 6883, 3774, 1487, 294, 11, 307, 300, 291, 393, 733, 295, 6608, 264, 51550], "temperature": 0.0, "avg_logprob": -0.1920933610811008, "compression_ratio": 1.7418181818181817, "no_speech_prob": 0.005554077215492725}, {"id": 105, "seek": 61204, "start": 635.76, "end": 640.92, "text": " spec on what you care about by using these namespace. Technically as well. So, there is a", "tokens": [51550, 1608, 322, 437, 291, 1127, 466, 538, 1228, 613, 5288, 17940, 13, 42494, 382, 731, 13, 407, 11, 456, 307, 257, 51808], "temperature": 0.0, "avg_logprob": -0.1920933610811008, "compression_ratio": 1.7418181818181817, "no_speech_prob": 0.005554077215492725}, {"id": 106, "seek": 64092, "start": 640.9599999999999, "end": 645.7199999999999, "text": " technical namespace that goes along with all the classes and properties. And you can filter on", "tokens": [50366, 6191, 5288, 17940, 300, 1709, 2051, 365, 439, 264, 5359, 293, 7221, 13, 400, 291, 393, 6608, 322, 50604], "temperature": 0.0, "avg_logprob": -0.1355462316739357, "compression_ratio": 1.6725978647686832, "no_speech_prob": 0.0008829530561342835}, {"id": 107, "seek": 64092, "start": 645.7199999999999, "end": 651.0799999999999, "text": " that. And within my code, I also use that to help me with some of the verification code that, that's", "tokens": [50604, 300, 13, 400, 1951, 452, 3089, 11, 286, 611, 764, 300, 281, 854, 385, 365, 512, 295, 264, 30206, 3089, 300, 11, 300, 311, 50872], "temperature": 0.0, "avg_logprob": -0.1355462316739357, "compression_ratio": 1.6725978647686832, "no_speech_prob": 0.0008829530561342835}, {"id": 108, "seek": 64092, "start": 651.0799999999999, "end": 656.0, "text": " there. And it's also the way we organize within SPDX. We have meetings that are organized by", "tokens": [50872, 456, 13, 400, 309, 311, 611, 264, 636, 321, 13859, 1951, 19572, 55, 13, 492, 362, 8410, 300, 366, 9983, 538, 51118], "temperature": 0.0, "avg_logprob": -0.1355462316739357, "compression_ratio": 1.6725978647686832, "no_speech_prob": 0.0008829530561342835}, {"id": 109, "seek": 64092, "start": 656.0, "end": 660.36, "text": " profiles. So, people of like-mind and like concerns get together and actually develop the", "tokens": [51118, 23693, 13, 407, 11, 561, 295, 411, 12, 13733, 293, 411, 7389, 483, 1214, 293, 767, 1499, 264, 51336], "temperature": 0.0, "avg_logprob": -0.1355462316739357, "compression_ratio": 1.6725978647686832, "no_speech_prob": 0.0008829530561342835}, {"id": 110, "seek": 64092, "start": 660.36, "end": 667.04, "text": " spec. So, let's talk a little bit about some of the other structural changes. In SPDX2, we,", "tokens": [51336, 1608, 13, 407, 11, 718, 311, 751, 257, 707, 857, 466, 512, 295, 264, 661, 15067, 2962, 13, 682, 19572, 55, 17, 11, 321, 11, 51670], "temperature": 0.0, "avg_logprob": -0.1355462316739357, "compression_ratio": 1.6725978647686832, "no_speech_prob": 0.0008829530561342835}, {"id": 111, "seek": 66704, "start": 667.48, "end": 673.12, "text": " everything was around a document and that was a file basically. And we had a mechanism for", "tokens": [50386, 1203, 390, 926, 257, 4166, 293, 300, 390, 257, 3991, 1936, 13, 400, 321, 632, 257, 7513, 337, 50668], "temperature": 0.0, "avg_logprob": -0.12871198784815122, "compression_ratio": 1.9063545150501673, "no_speech_prob": 0.01615002565085888}, {"id": 112, "seek": 66704, "start": 673.12, "end": 678.28, "text": " reliably linking documents together because you may get many types of S-bombs for many vendors. You", "tokens": [50668, 49927, 25775, 8512, 1214, 570, 291, 815, 483, 867, 3467, 295, 318, 12, 65, 298, 929, 337, 867, 22056, 13, 509, 50926], "temperature": 0.0, "avg_logprob": -0.12871198784815122, "compression_ratio": 1.9063545150501673, "no_speech_prob": 0.01615002565085888}, {"id": 113, "seek": 66704, "start": 678.28, "end": 682.16, "text": " may want to bring them together. You may want to compare them. And you may want to link them", "tokens": [50926, 815, 528, 281, 1565, 552, 1214, 13, 509, 815, 528, 281, 6794, 552, 13, 400, 291, 815, 528, 281, 2113, 552, 51120], "temperature": 0.0, "avg_logprob": -0.12871198784815122, "compression_ratio": 1.9063545150501673, "no_speech_prob": 0.01615002565085888}, {"id": 114, "seek": 66704, "start": 682.16, "end": 688.56, "text": " together. So, we had a mechanism to do that. In 3.0, we still have the ability, this I got to", "tokens": [51120, 1214, 13, 407, 11, 321, 632, 257, 7513, 281, 360, 300, 13, 682, 805, 13, 15, 11, 321, 920, 362, 264, 3485, 11, 341, 286, 658, 281, 51440], "temperature": 0.0, "avg_logprob": -0.12871198784815122, "compression_ratio": 1.9063545150501673, "no_speech_prob": 0.01615002565085888}, {"id": 115, "seek": 66704, "start": 688.56, "end": 692.76, "text": " make this really clear because there's this rumor that SPDX documents are dead and 3.0 is not true.", "tokens": [51440, 652, 341, 534, 1850, 570, 456, 311, 341, 29639, 300, 19572, 55, 8512, 366, 3116, 293, 805, 13, 15, 307, 406, 2074, 13, 51650], "temperature": 0.0, "avg_logprob": -0.12871198784815122, "compression_ratio": 1.9063545150501673, "no_speech_prob": 0.01615002565085888}, {"id": 116, "seek": 66704, "start": 692.76, "end": 696.64, "text": " They're still there. And you can use them the same way that you've always used them. But you", "tokens": [51650, 814, 434, 920, 456, 13, 400, 291, 393, 764, 552, 264, 912, 636, 300, 291, 600, 1009, 1143, 552, 13, 583, 291, 51844], "temperature": 0.0, "avg_logprob": -0.12871198784815122, "compression_ratio": 1.9063545150501673, "no_speech_prob": 0.01615002565085888}, {"id": 117, "seek": 69664, "start": 696.68, "end": 701.76, "text": " can also link directly from the elements. And an element is a package or a file or you know,", "tokens": [50366, 393, 611, 2113, 3838, 490, 264, 4959, 13, 400, 364, 4478, 307, 257, 7372, 420, 257, 3991, 420, 291, 458, 11, 50620], "temperature": 0.0, "avg_logprob": -0.14653701252407497, "compression_ratio": 1.7788161993769471, "no_speech_prob": 0.0016481694765388966}, {"id": 118, "seek": 69664, "start": 701.76, "end": 706.6, "text": " something, you know, a unit of something you care about in SPDX. So, now you can go directly. And", "tokens": [50620, 746, 11, 291, 458, 11, 257, 4985, 295, 746, 291, 1127, 466, 294, 19572, 55, 13, 407, 11, 586, 291, 393, 352, 3838, 13, 400, 50862], "temperature": 0.0, "avg_logprob": -0.14653701252407497, "compression_ratio": 1.7788161993769471, "no_speech_prob": 0.0016481694765388966}, {"id": 119, "seek": 69664, "start": 706.6, "end": 710.4, "text": " so, you can put these things out on a network without having to worry about the files that", "tokens": [50862, 370, 11, 291, 393, 829, 613, 721, 484, 322, 257, 3209, 1553, 1419, 281, 3292, 466, 264, 7098, 300, 51052], "temperature": 0.0, "avg_logprob": -0.14653701252407497, "compression_ratio": 1.7788161993769471, "no_speech_prob": 0.0016481694765388966}, {"id": 120, "seek": 69664, "start": 710.4, "end": 715.12, "text": " contain them. And so, think about like the World Wide Web, you know, where you have like files and", "tokens": [51052, 5304, 552, 13, 400, 370, 11, 519, 466, 411, 264, 3937, 42543, 9573, 11, 291, 458, 11, 689, 291, 362, 411, 7098, 293, 51288], "temperature": 0.0, "avg_logprob": -0.14653701252407497, "compression_ratio": 1.7788161993769471, "no_speech_prob": 0.0016481694765388966}, {"id": 121, "seek": 69664, "start": 715.12, "end": 719.72, "text": " images that are linked together in HTML. You can do that in SPDX documents in the future. So,", "tokens": [51288, 5267, 300, 366, 9408, 1214, 294, 17995, 13, 509, 393, 360, 300, 294, 19572, 55, 8512, 294, 264, 2027, 13, 407, 11, 51518], "temperature": 0.0, "avg_logprob": -0.14653701252407497, "compression_ratio": 1.7788161993769471, "no_speech_prob": 0.0016481694765388966}, {"id": 122, "seek": 69664, "start": 719.72, "end": 726.16, "text": " it's a very, very flexible, powerful mechanism we're introducing. Relationships have changed. In", "tokens": [51518, 309, 311, 257, 588, 11, 588, 11358, 11, 4005, 7513, 321, 434, 15424, 13, 28663, 7640, 362, 3105, 13, 682, 51840], "temperature": 0.0, "avg_logprob": -0.14653701252407497, "compression_ratio": 1.7788161993769471, "no_speech_prob": 0.0016481694765388966}, {"id": 123, "seek": 72616, "start": 726.4, "end": 731.88, "text": " SPDX 2, they were a property of the element. So, you have an element like a package and you say,", "tokens": [50376, 19572, 55, 568, 11, 436, 645, 257, 4707, 295, 264, 4478, 13, 407, 11, 291, 362, 364, 4478, 411, 257, 7372, 293, 291, 584, 11, 50650], "temperature": 0.0, "avg_logprob": -0.14342423143057986, "compression_ratio": 1.87890625, "no_speech_prob": 0.0006877679261378944}, {"id": 124, "seek": 72616, "start": 731.88, "end": 736.1999999999999, "text": " it has a relationship to another element like a file and that would be a property. There's a", "tokens": [50650, 309, 575, 257, 2480, 281, 1071, 4478, 411, 257, 3991, 293, 300, 576, 312, 257, 4707, 13, 821, 311, 257, 50866], "temperature": 0.0, "avg_logprob": -0.14342423143057986, "compression_ratio": 1.87890625, "no_speech_prob": 0.0006877679261378944}, {"id": 125, "seek": 72616, "start": 736.1999999999999, "end": 740.9599999999999, "text": " problem with that when you go to this distributed environment because you have to have, you have", "tokens": [50866, 1154, 365, 300, 562, 291, 352, 281, 341, 12631, 2823, 570, 291, 362, 281, 362, 11, 291, 362, 51104], "temperature": 0.0, "avg_logprob": -0.14342423143057986, "compression_ratio": 1.87890625, "no_speech_prob": 0.0006877679261378944}, {"id": 126, "seek": 72616, "start": 740.9599999999999, "end": 746.4, "text": " to know about this in advance. You can't introduce a relationship after the fact because it's a", "tokens": [51104, 281, 458, 466, 341, 294, 7295, 13, 509, 393, 380, 5366, 257, 2480, 934, 264, 1186, 570, 309, 311, 257, 51376], "temperature": 0.0, "avg_logprob": -0.14342423143057986, "compression_ratio": 1.87890625, "no_speech_prob": 0.0006877679261378944}, {"id": 127, "seek": 72616, "start": 746.4, "end": 752.6, "text": " property in the element itself. So, we moved the relationship outside. So, now you have a separate", "tokens": [51376, 4707, 294, 264, 4478, 2564, 13, 407, 11, 321, 4259, 264, 2480, 2380, 13, 407, 11, 586, 291, 362, 257, 4994, 51686], "temperature": 0.0, "avg_logprob": -0.14342423143057986, "compression_ratio": 1.87890625, "no_speech_prob": 0.0006877679261378944}, {"id": 128, "seek": 75260, "start": 752.64, "end": 757.8000000000001, "text": " object which is the element that does a relationship from one element to the other. And we've put a", "tokens": [50366, 2657, 597, 307, 264, 4478, 300, 775, 257, 2480, 490, 472, 4478, 281, 264, 661, 13, 400, 321, 600, 829, 257, 50624], "temperature": 0.0, "avg_logprob": -0.19578989998238985, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0031724695581942797}, {"id": 129, "seek": 75260, "start": 757.8000000000001, "end": 762.0, "text": " bunch of properties in there that in a way kind of simplifies the relationships. So, rather than", "tokens": [50624, 3840, 295, 7221, 294, 456, 300, 294, 257, 636, 733, 295, 6883, 11221, 264, 6159, 13, 407, 11, 2831, 813, 50834], "temperature": 0.0, "avg_logprob": -0.19578989998238985, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0031724695581942797}, {"id": 130, "seek": 75260, "start": 762.0, "end": 767.4, "text": " having hundreds of relationships, we can have dozens of relationships and a few properties within", "tokens": [50834, 1419, 6779, 295, 6159, 11, 321, 393, 362, 18431, 295, 6159, 293, 257, 1326, 7221, 1951, 51104], "temperature": 0.0, "avg_logprob": -0.19578989998238985, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0031724695581942797}, {"id": 131, "seek": 75260, "start": 767.4, "end": 771.12, "text": " the relationships to take care of it. How am I doing on time, by the way?", "tokens": [51104, 264, 6159, 281, 747, 1127, 295, 309, 13, 1012, 669, 286, 884, 322, 565, 11, 538, 264, 636, 30, 51290], "temperature": 0.0, "avg_logprob": -0.19578989998238985, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0031724695581942797}, {"id": 132, "seek": 75260, "start": 771.12, "end": 776.6, "text": " You are at, yeah, 17 minutes.", "tokens": [51290, 509, 366, 412, 11, 1338, 11, 3282, 2077, 13, 51564], "temperature": 0.0, "avg_logprob": -0.19578989998238985, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0031724695581942797}, {"id": 133, "seek": 75260, "start": 776.6, "end": 781.9200000000001, "text": " Oh, perfect. Okay. Other, I want to make sure I go through these changes because I think this may", "tokens": [51564, 876, 11, 2176, 13, 1033, 13, 5358, 11, 286, 528, 281, 652, 988, 286, 352, 807, 613, 2962, 570, 286, 519, 341, 815, 51830], "temperature": 0.0, "avg_logprob": -0.19578989998238985, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0031724695581942797}, {"id": 134, "seek": 78192, "start": 781.9599999999999, "end": 787.3199999999999, "text": " be the most interesting part to you guys. The other, there's a few other changes. There's a", "tokens": [50366, 312, 264, 881, 1880, 644, 281, 291, 1074, 13, 440, 661, 11, 456, 311, 257, 1326, 661, 2962, 13, 821, 311, 257, 50634], "temperature": 0.0, "avg_logprob": -0.13939604238301767, "compression_ratio": 1.685121107266436, "no_speech_prob": 0.004753975663334131}, {"id": 135, "seek": 78192, "start": 787.3199999999999, "end": 793.56, "text": " better model for what we call entities. This is the person organization. In SPDX 2.x, they were", "tokens": [50634, 1101, 2316, 337, 437, 321, 818, 16667, 13, 639, 307, 264, 954, 4475, 13, 682, 19572, 55, 568, 13, 87, 11, 436, 645, 50946], "temperature": 0.0, "avg_logprob": -0.13939604238301767, "compression_ratio": 1.685121107266436, "no_speech_prob": 0.004753975663334131}, {"id": 136, "seek": 78192, "start": 793.56, "end": 798.04, "text": " just strings and you'd have to parse the string to figure out whether it's a person or an organization.", "tokens": [50946, 445, 13985, 293, 291, 1116, 362, 281, 48377, 264, 6798, 281, 2573, 484, 1968, 309, 311, 257, 954, 420, 364, 4475, 13, 51170], "temperature": 0.0, "avg_logprob": -0.13939604238301767, "compression_ratio": 1.685121107266436, "no_speech_prob": 0.004753975663334131}, {"id": 137, "seek": 78192, "start": 798.04, "end": 803.0799999999999, "text": " We now have kind of like a whole object hierarchy that describes what these things are. It makes it", "tokens": [51170, 492, 586, 362, 733, 295, 411, 257, 1379, 2657, 22333, 300, 15626, 437, 613, 721, 366, 13, 467, 1669, 309, 51422], "temperature": 0.0, "avg_logprob": -0.13939604238301767, "compression_ratio": 1.685121107266436, "no_speech_prob": 0.004753975663334131}, {"id": 138, "seek": 78192, "start": 803.0799999999999, "end": 809.7199999999999, "text": " a little bit easier for parsing. We renamed and removed a lot of confusing properties. Those of", "tokens": [51422, 257, 707, 857, 3571, 337, 21156, 278, 13, 492, 40949, 293, 7261, 257, 688, 295, 13181, 7221, 13, 3950, 295, 51754], "temperature": 0.0, "avg_logprob": -0.13939604238301767, "compression_ratio": 1.685121107266436, "no_speech_prob": 0.004753975663334131}, {"id": 139, "seek": 80972, "start": 809.76, "end": 814.9200000000001, "text": " you who have built tooling for SPDX 2 will love this because people complained about these properties", "tokens": [50366, 291, 567, 362, 3094, 46593, 337, 19572, 55, 568, 486, 959, 341, 570, 561, 33951, 466, 613, 7221, 50624], "temperature": 0.0, "avg_logprob": -0.13222801990998098, "compression_ratio": 1.6554054054054055, "no_speech_prob": 0.017983414232730865}, {"id": 140, "seek": 80972, "start": 814.9200000000001, "end": 819.96, "text": " all the time. And we either renamed them to make them clear or just got rid of them. And, you know,", "tokens": [50624, 439, 264, 565, 13, 400, 321, 2139, 40949, 552, 281, 652, 552, 1850, 420, 445, 658, 3973, 295, 552, 13, 400, 11, 291, 458, 11, 50876], "temperature": 0.0, "avg_logprob": -0.13222801990998098, "compression_ratio": 1.6554054054054055, "no_speech_prob": 0.017983414232730865}, {"id": 141, "seek": 80972, "start": 819.96, "end": 824.32, "text": " for example, files analyzed. A lot of people don't like files analyzed. Functionality is still there,", "tokens": [50876, 337, 1365, 11, 7098, 28181, 13, 316, 688, 295, 561, 500, 380, 411, 7098, 28181, 13, 11166, 882, 1860, 307, 920, 456, 11, 51094], "temperature": 0.0, "avg_logprob": -0.13222801990998098, "compression_ratio": 1.6554054054054055, "no_speech_prob": 0.017983414232730865}, {"id": 142, "seek": 80972, "start": 824.32, "end": 829.8000000000001, "text": " but it's just a lot clearer how to actually do those use cases. We've added some additional", "tokens": [51094, 457, 309, 311, 445, 257, 688, 26131, 577, 281, 767, 360, 729, 764, 3331, 13, 492, 600, 3869, 512, 4497, 51368], "temperature": 0.0, "avg_logprob": -0.13222801990998098, "compression_ratio": 1.6554054054054055, "no_speech_prob": 0.017983414232730865}, {"id": 143, "seek": 80972, "start": 829.8000000000001, "end": 837.72, "text": " uses, useful classes and properties. So, for example, we elevated package URL from an external", "tokens": [51368, 4960, 11, 4420, 5359, 293, 7221, 13, 407, 11, 337, 1365, 11, 321, 23457, 7372, 12905, 490, 364, 8320, 51764], "temperature": 0.0, "avg_logprob": -0.13222801990998098, "compression_ratio": 1.6554054054054055, "no_speech_prob": 0.017983414232730865}, {"id": 144, "seek": 83772, "start": 837.72, "end": 842.6800000000001, "text": " identifier to be in a property on package because a lot of people are using that directly for", "tokens": [50364, 45690, 281, 312, 294, 257, 4707, 322, 7372, 570, 257, 688, 295, 561, 366, 1228, 300, 3838, 337, 50612], "temperature": 0.0, "avg_logprob": -0.1343296439246794, "compression_ratio": 1.6026936026936027, "no_speech_prob": 0.009124277159571648}, {"id": 145, "seek": 83772, "start": 842.6800000000001, "end": 850.12, "text": " identifying the package metadata. And then we have some additional profile specific classes and", "tokens": [50612, 16696, 264, 7372, 26603, 13, 400, 550, 321, 362, 512, 4497, 7964, 2685, 5359, 293, 50984], "temperature": 0.0, "avg_logprob": -0.1343296439246794, "compression_ratio": 1.6026936026936027, "no_speech_prob": 0.009124277159571648}, {"id": 146, "seek": 83772, "start": 850.12, "end": 854.36, "text": " properties, of course. And on this, I know you're not going to be able to type this in. Hopefully,", "tokens": [50984, 7221, 11, 295, 1164, 13, 400, 322, 341, 11, 286, 458, 291, 434, 406, 516, 281, 312, 1075, 281, 2010, 341, 294, 13, 10429, 11, 51196], "temperature": 0.0, "avg_logprob": -0.1343296439246794, "compression_ratio": 1.6026936026936027, "no_speech_prob": 0.009124277159571648}, {"id": 147, "seek": 83772, "start": 854.36, "end": 860.76, "text": " you'll get a copy of these slides. There is a Google Doc that I put together. It's a living", "tokens": [51196, 291, 603, 483, 257, 5055, 295, 613, 9788, 13, 821, 307, 257, 3329, 16024, 300, 286, 829, 1214, 13, 467, 311, 257, 2647, 51516], "temperature": 0.0, "avg_logprob": -0.1343296439246794, "compression_ratio": 1.6026936026936027, "no_speech_prob": 0.009124277159571648}, {"id": 148, "seek": 83772, "start": 860.76, "end": 866.76, "text": " document, which means it's open for comment from any of you. You find something missing. Please", "tokens": [51516, 4166, 11, 597, 1355, 309, 311, 1269, 337, 2871, 490, 604, 295, 291, 13, 509, 915, 746, 5361, 13, 2555, 51816], "temperature": 0.0, "avg_logprob": -0.1343296439246794, "compression_ratio": 1.6026936026936027, "no_speech_prob": 0.009124277159571648}, {"id": 149, "seek": 86676, "start": 866.84, "end": 872.04, "text": " comment on it. But this is kind of a guide to all the detailed changes. And I was writing that as", "tokens": [50368, 2871, 322, 309, 13, 583, 341, 307, 733, 295, 257, 5934, 281, 439, 264, 9942, 2962, 13, 400, 286, 390, 3579, 300, 382, 50628], "temperature": 0.0, "avg_logprob": -0.09943116095758253, "compression_ratio": 1.7544483985765125, "no_speech_prob": 0.004904571454972029}, {"id": 150, "seek": 86676, "start": 872.04, "end": 876.76, "text": " I was doing this, and I know there's some folks that have done the same thing and contributed to", "tokens": [50628, 286, 390, 884, 341, 11, 293, 286, 458, 456, 311, 512, 4024, 300, 362, 1096, 264, 912, 551, 293, 18434, 281, 50864], "temperature": 0.0, "avg_logprob": -0.09943116095758253, "compression_ratio": 1.7544483985765125, "no_speech_prob": 0.004904571454972029}, {"id": 151, "seek": 86676, "start": 876.76, "end": 881.88, "text": " this document that describes all the migration. It'll turn into a migration guide once we do the", "tokens": [50864, 341, 4166, 300, 15626, 439, 264, 17011, 13, 467, 603, 1261, 666, 257, 17011, 5934, 1564, 321, 360, 264, 51120], "temperature": 0.0, "avg_logprob": -0.09943116095758253, "compression_ratio": 1.7544483985765125, "no_speech_prob": 0.004904571454972029}, {"id": 152, "seek": 86676, "start": 881.88, "end": 887.24, "text": " full release, but right now it's more of a living document. So, kind of stepping back at these changes,", "tokens": [51120, 1577, 4374, 11, 457, 558, 586, 309, 311, 544, 295, 257, 2647, 4166, 13, 407, 11, 733, 295, 16821, 646, 412, 613, 2962, 11, 51388], "temperature": 0.0, "avg_logprob": -0.09943116095758253, "compression_ratio": 1.7544483985765125, "no_speech_prob": 0.004904571454972029}, {"id": 153, "seek": 86676, "start": 887.24, "end": 892.12, "text": " you know, what's kind of the big picture of this? You know, it'll be a lot more flexible with the", "tokens": [51388, 291, 458, 11, 437, 311, 733, 295, 264, 955, 3036, 295, 341, 30, 509, 458, 11, 309, 603, 312, 257, 688, 544, 11358, 365, 264, 51632], "temperature": 0.0, "avg_logprob": -0.09943116095758253, "compression_ratio": 1.7544483985765125, "no_speech_prob": 0.004904571454972029}, {"id": 154, "seek": 89212, "start": 892.12, "end": 897.64, "text": " profiles. There'll be a new relationship structure in addition to relationships. So, you need to", "tokens": [50364, 23693, 13, 821, 603, 312, 257, 777, 2480, 3877, 294, 4500, 281, 6159, 13, 407, 11, 291, 643, 281, 50640], "temperature": 0.0, "avg_logprob": -0.10200509946208355, "compression_ratio": 1.7077464788732395, "no_speech_prob": 0.01384666096419096}, {"id": 155, "seek": 89212, "start": 897.64, "end": 901.96, "text": " annotations independent as well, so you can do more incremental changes to the S-bomb without", "tokens": [50640, 25339, 763, 6695, 382, 731, 11, 370, 291, 393, 360, 544, 35759, 2962, 281, 264, 318, 12, 65, 3548, 1553, 50856], "temperature": 0.0, "avg_logprob": -0.10200509946208355, "compression_ratio": 1.7077464788732395, "no_speech_prob": 0.01384666096419096}, {"id": 156, "seek": 89212, "start": 901.96, "end": 907.96, "text": " having to go back and create a whole new big S-bomb. And then simpler profiles, simpler snippets,", "tokens": [50856, 1419, 281, 352, 646, 293, 1884, 257, 1379, 777, 955, 318, 12, 65, 3548, 13, 400, 550, 18587, 23693, 11, 18587, 35623, 1385, 11, 51156], "temperature": 0.0, "avg_logprob": -0.10200509946208355, "compression_ratio": 1.7077464788732395, "no_speech_prob": 0.01384666096419096}, {"id": 157, "seek": 89212, "start": 907.96, "end": 915.48, "text": " more use cases. And then, again, see the migration document for that. So, now I'm going to switch", "tokens": [51156, 544, 764, 3331, 13, 400, 550, 11, 797, 11, 536, 264, 17011, 4166, 337, 300, 13, 407, 11, 586, 286, 478, 516, 281, 3679, 51532], "temperature": 0.0, "avg_logprob": -0.10200509946208355, "compression_ratio": 1.7077464788732395, "no_speech_prob": 0.01384666096419096}, {"id": 158, "seek": 89212, "start": 915.48, "end": 921.16, "text": " over to my personal experience. I was involved in writing this back, and now I'm going to tell you", "tokens": [51532, 670, 281, 452, 2973, 1752, 13, 286, 390, 3288, 294, 3579, 341, 646, 11, 293, 586, 286, 478, 516, 281, 980, 291, 51816], "temperature": 0.0, "avg_logprob": -0.10200509946208355, "compression_ratio": 1.7077464788732395, "no_speech_prob": 0.01384666096419096}, {"id": 159, "seek": 92116, "start": 921.16, "end": 928.92, "text": " how fun it was to actually implement it. So, the Java libraries, first to give you context,", "tokens": [50364, 577, 1019, 309, 390, 281, 767, 4445, 309, 13, 407, 11, 264, 10745, 15148, 11, 700, 281, 976, 291, 4319, 11, 50752], "temperature": 0.0, "avg_logprob": -0.12580912184007098, "compression_ratio": 1.5655737704918034, "no_speech_prob": 0.0038833001162856817}, {"id": 160, "seek": 92116, "start": 928.92, "end": 935.24, "text": " I wanted to give you an overview of what the current SPDX 2.x library's architecture looks like.", "tokens": [50752, 286, 1415, 281, 976, 291, 364, 12492, 295, 437, 264, 2190, 19572, 55, 568, 13, 87, 6405, 311, 9482, 1542, 411, 13, 51068], "temperature": 0.0, "avg_logprob": -0.12580912184007098, "compression_ratio": 1.5655737704918034, "no_speech_prob": 0.0038833001162856817}, {"id": 161, "seek": 92116, "start": 936.04, "end": 941.0799999999999, "text": " You know, it's what you'd expect. There's a model set of classes, and that match exactly the SPDX", "tokens": [51108, 509, 458, 11, 309, 311, 437, 291, 1116, 2066, 13, 821, 311, 257, 2316, 992, 295, 5359, 11, 293, 300, 2995, 2293, 264, 19572, 55, 51360], "temperature": 0.0, "avg_logprob": -0.12580912184007098, "compression_ratio": 1.5655737704918034, "no_speech_prob": 0.0038833001162856817}, {"id": 162, "seek": 92116, "start": 941.0799999999999, "end": 945.88, "text": " 2.x model. The only change is really is I had to rename some of the things that conflicted with", "tokens": [51360, 568, 13, 87, 2316, 13, 440, 787, 1319, 307, 534, 307, 286, 632, 281, 36741, 512, 295, 264, 721, 300, 6596, 292, 365, 51600], "temperature": 0.0, "avg_logprob": -0.12580912184007098, "compression_ratio": 1.5655737704918034, "no_speech_prob": 0.0038833001162856817}, {"id": 163, "seek": 94588, "start": 945.88, "end": 950.92, "text": " the Java language. So, Java doesn't like you to call a class package, for example. And then,", "tokens": [50364, 264, 10745, 2856, 13, 407, 11, 10745, 1177, 380, 411, 291, 281, 818, 257, 1508, 7372, 11, 337, 1365, 13, 400, 550, 11, 50616], "temperature": 0.0, "avg_logprob": -0.0812301025390625, "compression_ratio": 1.635135135135135, "no_speech_prob": 0.044668182730674744}, {"id": 164, "seek": 94588, "start": 950.92, "end": 955.4, "text": " there's a set of utility classes that has some useful functions like being able to do a comparison", "tokens": [50616, 456, 311, 257, 992, 295, 14877, 5359, 300, 575, 512, 4420, 6828, 411, 885, 1075, 281, 360, 257, 9660, 50840], "temperature": 0.0, "avg_logprob": -0.0812301025390625, "compression_ratio": 1.635135135135135, "no_speech_prob": 0.044668182730674744}, {"id": 165, "seek": 94588, "start": 955.4, "end": 963.24, "text": " of license, little things like that. And because in the very first iteration of this, I started this", "tokens": [50840, 295, 10476, 11, 707, 721, 411, 300, 13, 400, 570, 294, 264, 588, 700, 24784, 295, 341, 11, 286, 1409, 341, 51232], "temperature": 0.0, "avg_logprob": -0.0812301025390625, "compression_ratio": 1.635135135135135, "no_speech_prob": 0.044668182730674744}, {"id": 166, "seek": 94588, "start": 963.24, "end": 968.84, "text": " like 10 years ago as a pretty printer, it was very monolithic, and I got a lot of feedback that,", "tokens": [51232, 411, 1266, 924, 2057, 382, 257, 1238, 16671, 11, 309, 390, 588, 1108, 42878, 11, 293, 286, 658, 257, 688, 295, 5824, 300, 11, 51512], "temperature": 0.0, "avg_logprob": -0.0812301025390625, "compression_ratio": 1.635135135135135, "no_speech_prob": 0.044668182730674744}, {"id": 167, "seek": 94588, "start": 968.84, "end": 974.04, "text": " hey, you know, I don't want to have all these RDF library things in there, if all I want to do", "tokens": [51512, 4177, 11, 291, 458, 11, 286, 500, 380, 528, 281, 362, 439, 613, 49488, 37, 6405, 721, 294, 456, 11, 498, 439, 286, 528, 281, 360, 51772], "temperature": 0.0, "avg_logprob": -0.0812301025390625, "compression_ratio": 1.635135135135135, "no_speech_prob": 0.044668182730674744}, {"id": 168, "seek": 97404, "start": 974.04, "end": 979.48, "text": " is generate JSON. So, we introduced a storage interface that lets you create a lot of different", "tokens": [50364, 307, 8460, 31828, 13, 407, 11, 321, 7268, 257, 6725, 9226, 300, 6653, 291, 1884, 257, 688, 295, 819, 50636], "temperature": 0.0, "avg_logprob": -0.09223438364214602, "compression_ratio": 1.7355072463768115, "no_speech_prob": 0.02930295653641224}, {"id": 169, "seek": 97404, "start": 979.48, "end": 984.68, "text": " model stores. The model stores can represent a very specific serialization of a file, or it can", "tokens": [50636, 2316, 9512, 13, 440, 2316, 9512, 393, 2906, 257, 588, 2685, 17436, 2144, 295, 257, 3991, 11, 420, 309, 393, 50896], "temperature": 0.0, "avg_logprob": -0.09223438364214602, "compression_ratio": 1.7355072463768115, "no_speech_prob": 0.02930295653641224}, {"id": 170, "seek": 97404, "start": 984.68, "end": 990.76, "text": " also represent like a database or a triple store if you're into RDF, or the most common is just an", "tokens": [50896, 611, 2906, 411, 257, 8149, 420, 257, 15508, 3531, 498, 291, 434, 666, 49488, 37, 11, 420, 264, 881, 2689, 307, 445, 364, 51200], "temperature": 0.0, "avg_logprob": -0.09223438364214602, "compression_ratio": 1.7355072463768115, "no_speech_prob": 0.02930295653641224}, {"id": 171, "seek": 97404, "start": 990.76, "end": 996.8399999999999, "text": " N memory store for it. So, this allows you to separate these out into separate jar files. It", "tokens": [51200, 426, 4675, 3531, 337, 309, 13, 407, 11, 341, 4045, 291, 281, 4994, 613, 484, 666, 4994, 15181, 7098, 13, 467, 51504], "temperature": 0.0, "avg_logprob": -0.09223438364214602, "compression_ratio": 1.7355072463768115, "no_speech_prob": 0.02930295653641224}, {"id": 172, "seek": 97404, "start": 996.8399999999999, "end": 1001.0, "text": " does add a complexity because there's a storage interface in between that has to adhere so that", "tokens": [51504, 775, 909, 257, 14024, 570, 456, 311, 257, 6725, 9226, 294, 1296, 300, 575, 281, 33584, 370, 300, 51712], "temperature": 0.0, "avg_logprob": -0.09223438364214602, "compression_ratio": 1.7355072463768115, "no_speech_prob": 0.02930295653641224}, {"id": 173, "seek": 100100, "start": 1001.0, "end": 1005.72, "text": " we can separate these out into different things, but I think it does make it a lot cleaner.", "tokens": [50364, 321, 393, 4994, 613, 484, 666, 819, 721, 11, 457, 286, 519, 309, 775, 652, 309, 257, 688, 16532, 13, 50600], "temperature": 0.0, "avg_logprob": -0.06565966940762703, "compression_ratio": 1.8185328185328185, "no_speech_prob": 0.0057295230217278}, {"id": 174, "seek": 100100, "start": 1006.84, "end": 1012.92, "text": " So, a couple of breaking changes that I noticed right off. I think one of the ones I did not", "tokens": [50656, 407, 11, 257, 1916, 295, 7697, 2962, 300, 286, 5694, 558, 766, 13, 286, 519, 472, 295, 264, 2306, 286, 630, 406, 50960], "temperature": 0.0, "avg_logprob": -0.06565966940762703, "compression_ratio": 1.8185328185328185, "no_speech_prob": 0.0057295230217278}, {"id": 175, "seek": 100100, "start": 1012.92, "end": 1019.48, "text": " expect, this change to the namespaces actually caused a change to the storage interface because I", "tokens": [50960, 2066, 11, 341, 1319, 281, 264, 5288, 79, 2116, 767, 7008, 257, 1319, 281, 264, 6725, 9226, 570, 286, 51288], "temperature": 0.0, "avg_logprob": -0.06565966940762703, "compression_ratio": 1.8185328185328185, "no_speech_prob": 0.0057295230217278}, {"id": 176, "seek": 100100, "start": 1019.48, "end": 1024.84, "text": " was just using the property names, and I knew that I could always map the property to the full", "tokens": [51288, 390, 445, 1228, 264, 4707, 5288, 11, 293, 286, 2586, 300, 286, 727, 1009, 4471, 264, 4707, 281, 264, 1577, 51556], "temperature": 0.0, "avg_logprob": -0.06565966940762703, "compression_ratio": 1.8185328185328185, "no_speech_prob": 0.0057295230217278}, {"id": 177, "seek": 100100, "start": 1024.84, "end": 1029.4, "text": " URI of what the properties were, or the full string with the namespace because we had a clean", "tokens": [51556, 624, 5577, 295, 437, 264, 7221, 645, 11, 420, 264, 1577, 6798, 365, 264, 5288, 17940, 570, 321, 632, 257, 2541, 51784], "temperature": 0.0, "avg_logprob": -0.06565966940762703, "compression_ratio": 1.8185328185328185, "no_speech_prob": 0.0057295230217278}, {"id": 178, "seek": 102940, "start": 1029.4, "end": 1034.2, "text": " mapping. I can't count on that anymore. So, I had to add one extra parameter, which means, oh my", "tokens": [50364, 18350, 13, 286, 393, 380, 1207, 322, 300, 3602, 13, 407, 11, 286, 632, 281, 909, 472, 2857, 13075, 11, 597, 1355, 11, 1954, 452, 50604], "temperature": 0.0, "avg_logprob": -0.10463352890701981, "compression_ratio": 1.7075812274368232, "no_speech_prob": 0.0015486599877476692}, {"id": 179, "seek": 102940, "start": 1034.2, "end": 1037.72, "text": " goodness, now I got to change all these different libraries to use that. Of course, I put in a", "tokens": [50604, 8387, 11, 586, 286, 658, 281, 1319, 439, 613, 819, 15148, 281, 764, 300, 13, 2720, 1164, 11, 286, 829, 294, 257, 50780], "temperature": 0.0, "avg_logprob": -0.10463352890701981, "compression_ratio": 1.7075812274368232, "no_speech_prob": 0.0015486599877476692}, {"id": 180, "seek": 102940, "start": 1037.72, "end": 1042.8400000000001, "text": " compatibility library that made it a little bit easier, but that was a breaking change to all", "tokens": [50780, 34237, 6405, 300, 1027, 309, 257, 707, 857, 3571, 11, 457, 300, 390, 257, 7697, 1319, 281, 439, 51036], "temperature": 0.0, "avg_logprob": -0.10463352890701981, "compression_ratio": 1.7075812274368232, "no_speech_prob": 0.0015486599877476692}, {"id": 181, "seek": 102940, "start": 1042.8400000000001, "end": 1047.4, "text": " those things that are implementing the storage object, at the storage model below. The model", "tokens": [51036, 729, 721, 300, 366, 18114, 264, 6725, 2657, 11, 412, 264, 6725, 2316, 2507, 13, 440, 2316, 51264], "temperature": 0.0, "avg_logprob": -0.10463352890701981, "compression_ratio": 1.7075812274368232, "no_speech_prob": 0.0015486599877476692}, {"id": 182, "seek": 102940, "start": 1047.4, "end": 1053.88, "text": " itself created some breaking changes as you'd expect after going through what the changes are.", "tokens": [51264, 2564, 2942, 512, 7697, 2962, 382, 291, 1116, 2066, 934, 516, 807, 437, 264, 2962, 366, 13, 51588], "temperature": 0.0, "avg_logprob": -0.10463352890701981, "compression_ratio": 1.7075812274368232, "no_speech_prob": 0.0015486599877476692}, {"id": 183, "seek": 105388, "start": 1054.8400000000001, "end": 1061.16, "text": " There is, what I did is I took all of the spdx2.x code and moved that over to a compatibility", "tokens": [50412, 821, 307, 11, 437, 286, 630, 307, 286, 1890, 439, 295, 264, 637, 67, 87, 17, 13, 87, 3089, 293, 4259, 300, 670, 281, 257, 34237, 50728], "temperature": 0.0, "avg_logprob": -0.10515471722217316, "compression_ratio": 1.5991735537190082, "no_speech_prob": 0.014501292258501053}, {"id": 184, "seek": 105388, "start": 1061.16, "end": 1070.1200000000001, "text": " library so that it's all still there. It is though in a different package in Java, so there is a", "tokens": [50728, 6405, 370, 300, 309, 311, 439, 920, 456, 13, 467, 307, 1673, 294, 257, 819, 7372, 294, 10745, 11, 370, 456, 307, 257, 51176], "temperature": 0.0, "avg_logprob": -0.10515471722217316, "compression_ratio": 1.5991735537190082, "no_speech_prob": 0.014501292258501053}, {"id": 185, "seek": 105388, "start": 1070.1200000000001, "end": 1075.96, "text": " small change to the imports, but it should work pretty much as is. The relationship and annotation", "tokens": [51176, 1359, 1319, 281, 264, 41596, 11, 457, 309, 820, 589, 1238, 709, 382, 307, 13, 440, 2480, 293, 48654, 51468], "temperature": 0.0, "avg_logprob": -0.10515471722217316, "compression_ratio": 1.5991735537190082, "no_speech_prob": 0.014501292258501053}, {"id": 186, "seek": 105388, "start": 1075.96, "end": 1081.4, "text": " structures that definitely impacted the Java code because it moves it out of properties and makes", "tokens": [51468, 9227, 300, 2138, 15653, 264, 10745, 3089, 570, 309, 6067, 309, 484, 295, 7221, 293, 1669, 51740], "temperature": 0.0, "avg_logprob": -0.10515471722217316, "compression_ratio": 1.5991735537190082, "no_speech_prob": 0.014501292258501053}, {"id": 187, "seek": 108140, "start": 1081.48, "end": 1086.44, "text": " them a little bit more independent. I came up with a trick to help manage the consumers of my", "tokens": [50368, 552, 257, 707, 857, 544, 6695, 13, 286, 1361, 493, 365, 257, 4282, 281, 854, 3067, 264, 11883, 295, 452, 50616], "temperature": 0.0, "avg_logprob": -0.14496416258580477, "compression_ratio": 1.6272401433691757, "no_speech_prob": 0.0043976581655442715}, {"id": 188, "seek": 108140, "start": 1086.44, "end": 1090.8400000000001, "text": " libraries, keep them from having breaking changes. I'll come to that in a couple minutes. That might", "tokens": [50616, 15148, 11, 1066, 552, 490, 1419, 7697, 2962, 13, 286, 603, 808, 281, 300, 294, 257, 1916, 2077, 13, 663, 1062, 50836], "temperature": 0.0, "avg_logprob": -0.14496416258580477, "compression_ratio": 1.6272401433691757, "no_speech_prob": 0.0043976581655442715}, {"id": 189, "seek": 108140, "start": 1090.8400000000001, "end": 1097.88, "text": " be an interesting tip for some of you. The external document ref structure really changed. That was", "tokens": [50836, 312, 364, 1880, 4125, 337, 512, 295, 291, 13, 440, 8320, 4166, 1895, 3877, 534, 3105, 13, 663, 390, 51188], "temperature": 0.0, "avg_logprob": -0.14496416258580477, "compression_ratio": 1.6272401433691757, "no_speech_prob": 0.0043976581655442715}, {"id": 190, "seek": 108140, "start": 1097.88, "end": 1103.5600000000002, "text": " probably one of the more significant changes. We talked about the agents, the snippet simplifications,", "tokens": [51188, 1391, 472, 295, 264, 544, 4776, 2962, 13, 492, 2825, 466, 264, 12554, 11, 264, 35623, 302, 6883, 7833, 11, 51472], "temperature": 0.0, "avg_logprob": -0.14496416258580477, "compression_ratio": 1.6272401433691757, "no_speech_prob": 0.0043976581655442715}, {"id": 191, "seek": 108140, "start": 1103.5600000000002, "end": 1105.72, "text": " and then moving these properties to relationships.", "tokens": [51472, 293, 550, 2684, 613, 7221, 281, 6159, 13, 51580], "temperature": 0.0, "avg_logprob": -0.14496416258580477, "compression_ratio": 1.6272401433691757, "no_speech_prob": 0.0043976581655442715}, {"id": 192, "seek": 108140, "start": 1108.2800000000002, "end": 1110.2800000000002, "text": " Sure.", "tokens": [51708, 4894, 13, 51808], "temperature": 0.0, "avg_logprob": -0.14496416258580477, "compression_ratio": 1.6272401433691757, "no_speech_prob": 0.0043976581655442715}, {"id": 193, "seek": 111140, "start": 1111.48, "end": 1141.3200000000002, "text": " That layer will direct you to the compatible layer or to the new", "tokens": [50368, 663, 4583, 486, 2047, 291, 281, 264, 18218, 4583, 420, 281, 264, 777, 51860], "temperature": 0.0, "avg_logprob": -0.3517860524794635, "compression_ratio": 1.0491803278688525, "no_speech_prob": 0.526308000087738}, {"id": 194, "seek": 114132, "start": 1141.3999999999999, "end": 1149.32, "text": " model layer. It basically minimizes the impact to the users of my library. That's this spdx", "tokens": [50368, 2316, 4583, 13, 467, 1936, 4464, 5660, 264, 2712, 281, 264, 5022, 295, 452, 6405, 13, 663, 311, 341, 637, 67, 87, 50764], "temperature": 0.0, "avg_logprob": -0.12988745155981032, "compression_ratio": 1.704626334519573, "no_speech_prob": 0.008707680739462376}, {"id": 195, "seek": 114132, "start": 1149.32, "end": 1155.48, "text": " model factory is what does the switching there. This is the little trick that I came up with", "tokens": [50764, 2316, 9265, 307, 437, 775, 264, 16493, 456, 13, 639, 307, 264, 707, 4282, 300, 286, 1361, 493, 365, 51072], "temperature": 0.0, "avg_logprob": -0.12988745155981032, "compression_ratio": 1.704626334519573, "no_speech_prob": 0.008707680739462376}, {"id": 196, "seek": 114132, "start": 1155.48, "end": 1160.2, "text": " for relationships. We used to have these as properties and now we moved them over to separate", "tokens": [51072, 337, 6159, 13, 492, 1143, 281, 362, 613, 382, 7221, 293, 586, 321, 4259, 552, 670, 281, 4994, 51308], "temperature": 0.0, "avg_logprob": -0.12988745155981032, "compression_ratio": 1.704626334519573, "no_speech_prob": 0.008707680739462376}, {"id": 197, "seek": 114132, "start": 1160.2, "end": 1164.4399999999998, "text": " independent relationships. You can imagine what this will do to all the users of the library. It's", "tokens": [51308, 6695, 6159, 13, 509, 393, 3811, 437, 341, 486, 360, 281, 439, 264, 5022, 295, 264, 6405, 13, 467, 311, 51520], "temperature": 0.0, "avg_logprob": -0.12988745155981032, "compression_ratio": 1.704626334519573, "no_speech_prob": 0.008707680739462376}, {"id": 198, "seek": 114132, "start": 1164.4399999999998, "end": 1169.72, "text": " like, oh, this isn't just like a change of coding or a change of names. I got to restructure my code.", "tokens": [51520, 411, 11, 1954, 11, 341, 1943, 380, 445, 411, 257, 1319, 295, 17720, 420, 257, 1319, 295, 5288, 13, 286, 658, 281, 1472, 2885, 452, 3089, 13, 51784], "temperature": 0.0, "avg_logprob": -0.12988745155981032, "compression_ratio": 1.704626334519573, "no_speech_prob": 0.008707680739462376}, {"id": 199, "seek": 116972, "start": 1169.88, "end": 1176.3600000000001, "text": " I came up with a way to make it look like a property inside the class. I have a special", "tokens": [50372, 286, 1361, 493, 365, 257, 636, 281, 652, 309, 574, 411, 257, 4707, 1854, 264, 1508, 13, 286, 362, 257, 2121, 50696], "temperature": 0.0, "avg_logprob": -0.05388045103653617, "compression_ratio": 1.755813953488372, "no_speech_prob": 0.0004728207131847739}, {"id": 200, "seek": 116972, "start": 1176.3600000000001, "end": 1180.6000000000001, "text": " class that says, okay, this is a relationship, but it looks like a property. If you're interested", "tokens": [50696, 1508, 300, 1619, 11, 1392, 11, 341, 307, 257, 2480, 11, 457, 309, 1542, 411, 257, 4707, 13, 759, 291, 434, 3102, 50908], "temperature": 0.0, "avg_logprob": -0.05388045103653617, "compression_ratio": 1.755813953488372, "no_speech_prob": 0.0004728207131847739}, {"id": 201, "seek": 116972, "start": 1180.6000000000001, "end": 1185.4, "text": " in that technique, let me know. I can show you the code. It really wasn't that hard. It's a very", "tokens": [50908, 294, 300, 6532, 11, 718, 385, 458, 13, 286, 393, 855, 291, 264, 3089, 13, 467, 534, 2067, 380, 300, 1152, 13, 467, 311, 257, 588, 51148], "temperature": 0.0, "avg_logprob": -0.05388045103653617, "compression_ratio": 1.755813953488372, "no_speech_prob": 0.0004728207131847739}, {"id": 202, "seek": 116972, "start": 1185.4, "end": 1191.32, "text": " generalized class that I can use for just about any kind of property. I think it's called", "tokens": [51148, 44498, 1508, 300, 286, 393, 764, 337, 445, 466, 604, 733, 295, 4707, 13, 286, 519, 309, 311, 1219, 51444], "temperature": 0.0, "avg_logprob": -0.05388045103653617, "compression_ratio": 1.755813953488372, "no_speech_prob": 0.0004728207131847739}, {"id": 203, "seek": 116972, "start": 1191.32, "end": 1194.3600000000001, "text": " relationship property or something like that. That makes it a little bit easier.", "tokens": [51444, 2480, 4707, 420, 746, 411, 300, 13, 663, 1669, 309, 257, 707, 857, 3571, 13, 51596], "temperature": 0.0, "avg_logprob": -0.05388045103653617, "compression_ratio": 1.755813953488372, "no_speech_prob": 0.0004728207131847739}, {"id": 204, "seek": 119436, "start": 1195.08, "end": 1202.76, "text": " The other thing I was focused on is reducing the errors. You remember in the, how am I doing?", "tokens": [50400, 440, 661, 551, 286, 390, 5178, 322, 307, 12245, 264, 13603, 13, 509, 1604, 294, 264, 11, 577, 669, 286, 884, 30, 50784], "temperature": 0.0, "avg_logprob": -0.1717626205598465, "compression_ratio": 1.6293103448275863, "no_speech_prob": 0.0010321802692487836}, {"id": 205, "seek": 119436, "start": 1202.76, "end": 1210.1999999999998, "text": " I'll see you in five minutes. Thank you. I saw you getting ready. You remember in the specs,", "tokens": [50784, 286, 603, 536, 291, 294, 1732, 2077, 13, 1044, 291, 13, 286, 1866, 291, 1242, 1919, 13, 509, 1604, 294, 264, 27911, 11, 51156], "temperature": 0.0, "avg_logprob": -0.1717626205598465, "compression_ratio": 1.6293103448275863, "no_speech_prob": 0.0010321802692487836}, {"id": 206, "seek": 119436, "start": 1210.1999999999998, "end": 1215.6399999999999, "text": " we did a lot of things to reduce the translation errors down to the actual schema files. We're", "tokens": [51156, 321, 630, 257, 688, 295, 721, 281, 5407, 264, 12853, 13603, 760, 281, 264, 3539, 34078, 7098, 13, 492, 434, 51428], "temperature": 0.0, "avg_logprob": -0.1717626205598465, "compression_ratio": 1.6293103448275863, "no_speech_prob": 0.0010321802692487836}, {"id": 207, "seek": 119436, "start": 1215.6399999999999, "end": 1224.12, "text": " taking that further with the coding as well. We're from the OWL Shackle file. I'm generating the", "tokens": [51428, 1940, 300, 3052, 365, 264, 17720, 382, 731, 13, 492, 434, 490, 264, 38329, 43, 1160, 501, 306, 3991, 13, 286, 478, 17746, 264, 51852], "temperature": 0.0, "avg_logprob": -0.1717626205598465, "compression_ratio": 1.6293103448275863, "no_speech_prob": 0.0010321802692487836}, {"id": 208, "seek": 122412, "start": 1224.1999999999998, "end": 1231.0, "text": " Java code. The Java library code, so now you got from the markdown file all the way through to the", "tokens": [50368, 10745, 3089, 13, 440, 10745, 6405, 3089, 11, 370, 586, 291, 658, 490, 264, 1491, 5093, 3991, 439, 264, 636, 807, 281, 264, 50708], "temperature": 0.0, "avg_logprob": -0.10894697220599064, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.004197896923869848}, {"id": 209, "seek": 122412, "start": 1231.0, "end": 1238.6799999999998, "text": " actual Java code, traceable, reproducible code to make sure it's all done right. I can't tell you", "tokens": [50708, 3539, 10745, 3089, 11, 13508, 712, 11, 11408, 32128, 3089, 281, 652, 988, 309, 311, 439, 1096, 558, 13, 286, 393, 380, 980, 291, 51092], "temperature": 0.0, "avg_logprob": -0.10894697220599064, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.004197896923869848}, {"id": 210, "seek": 122412, "start": 1238.6799999999998, "end": 1243.8799999999999, "text": " how many errors I have personally made or I mistyped something or I didn't read it right,", "tokens": [51092, 577, 867, 13603, 286, 362, 5665, 1027, 420, 286, 3544, 88, 3452, 746, 420, 286, 994, 380, 1401, 309, 558, 11, 51352], "temperature": 0.0, "avg_logprob": -0.10894697220599064, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.004197896923869848}, {"id": 211, "seek": 122412, "start": 1243.8799999999999, "end": 1249.4799999999998, "text": " and it got implemented wrong in the Java library. I think the errors that I make now will be much", "tokens": [51352, 293, 309, 658, 12270, 2085, 294, 264, 10745, 6405, 13, 286, 519, 264, 13603, 300, 286, 652, 586, 486, 312, 709, 51632], "temperature": 0.0, "avg_logprob": -0.10894697220599064, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.004197896923869848}, {"id": 212, "seek": 122412, "start": 1249.4799999999998, "end": 1253.2399999999998, "text": " bigger because it'll be in the code generator. It'll happen to everything. Sorry. That's a", "tokens": [51632, 3801, 570, 309, 603, 312, 294, 264, 3089, 19265, 13, 467, 603, 1051, 281, 1203, 13, 4919, 13, 663, 311, 257, 51820], "temperature": 0.0, "avg_logprob": -0.10894697220599064, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.004197896923869848}, {"id": 213, "seek": 125324, "start": 1253.24, "end": 1260.04, "text": " little bit of a joke, but no. It'll get rid of all those little errors. We'll also be generating,", "tokens": [50364, 707, 857, 295, 257, 7647, 11, 457, 572, 13, 467, 603, 483, 3973, 295, 439, 729, 707, 13603, 13, 492, 603, 611, 312, 17746, 11, 50704], "temperature": 0.0, "avg_logprob": -0.12333066463470459, "compression_ratio": 1.51, "no_speech_prob": 0.0026726815849542618}, {"id": 214, "seek": 125324, "start": 1260.04, "end": 1265.08, "text": " as I mentioned before, the schema files for those of you who would rather see things in JSON schema", "tokens": [50704, 382, 286, 2835, 949, 11, 264, 34078, 7098, 337, 729, 295, 291, 567, 576, 2831, 536, 721, 294, 31828, 34078, 50956], "temperature": 0.0, "avg_logprob": -0.12333066463470459, "compression_ratio": 1.51, "no_speech_prob": 0.0026726815849542618}, {"id": 215, "seek": 125324, "start": 1265.08, "end": 1274.84, "text": " or XML schema. I also generate the verification code from the Shackle OWL files. If you're into the RDF,", "tokens": [50956, 420, 43484, 34078, 13, 286, 611, 8460, 264, 30206, 3089, 490, 264, 1160, 501, 306, 38329, 43, 7098, 13, 759, 291, 434, 666, 264, 49488, 37, 11, 51444], "temperature": 0.0, "avg_logprob": -0.12333066463470459, "compression_ratio": 1.51, "no_speech_prob": 0.0026726815849542618}, {"id": 216, "seek": 127484, "start": 1274.84, "end": 1287.24, "text": " it complies with the Shackle OWL. Those are some of the techniques for reducing the errors.", "tokens": [50364, 309, 1209, 530, 365, 264, 1160, 501, 306, 38329, 43, 13, 3950, 366, 512, 295, 264, 7512, 337, 12245, 264, 13603, 13, 50984], "temperature": 0.0, "avg_logprob": -0.14136484341743666, "compression_ratio": 1.469387755102041, "no_speech_prob": 0.0052187456749379635}, {"id": 217, "seek": 127484, "start": 1287.24, "end": 1294.84, "text": " I think this is my last slide, the new architecture. One thing I didn't mention is this copy manager", "tokens": [50984, 286, 519, 341, 307, 452, 1036, 4137, 11, 264, 777, 9482, 13, 1485, 551, 286, 994, 380, 2152, 307, 341, 5055, 6598, 51364], "temperature": 0.0, "avg_logprob": -0.14136484341743666, "compression_ratio": 1.469387755102041, "no_speech_prob": 0.0052187456749379635}, {"id": 218, "seek": 127484, "start": 1294.84, "end": 1300.6799999999998, "text": " in between. It's a little bit of a detail, but it's kind of an important one, is that if you're", "tokens": [51364, 294, 1296, 13, 467, 311, 257, 707, 857, 295, 257, 2607, 11, 457, 309, 311, 733, 295, 364, 1021, 472, 11, 307, 300, 498, 291, 434, 51656], "temperature": 0.0, "avg_logprob": -0.14136484341743666, "compression_ratio": 1.469387755102041, "no_speech_prob": 0.0052187456749379635}, {"id": 219, "seek": 130068, "start": 1300.68, "end": 1307.48, "text": " migrating, if you've got two different SPDX documents with two different versions and you're", "tokens": [50364, 6186, 8754, 11, 498, 291, 600, 658, 732, 819, 19572, 55, 8512, 365, 732, 819, 9606, 293, 291, 434, 50704], "temperature": 0.0, "avg_logprob": -0.09101284991253863, "compression_ratio": 1.6282051282051282, "no_speech_prob": 0.002980610588565469}, {"id": 220, "seek": 130068, "start": 1307.48, "end": 1312.28, "text": " referencing to each other, that copy manager will let you copy it over to the new version. That", "tokens": [50704, 40582, 281, 1184, 661, 11, 300, 5055, 6598, 486, 718, 291, 5055, 309, 670, 281, 264, 777, 3037, 13, 663, 50944], "temperature": 0.0, "avg_logprob": -0.09101284991253863, "compression_ratio": 1.6282051282051282, "no_speech_prob": 0.002980610588565469}, {"id": 221, "seek": 130068, "start": 1312.28, "end": 1318.68, "text": " kind of does the upgrades. It'll also copy between the different types of model stores. It'll let", "tokens": [50944, 733, 295, 775, 264, 24868, 13, 467, 603, 611, 5055, 1296, 264, 819, 3467, 295, 2316, 9512, 13, 467, 603, 718, 51264], "temperature": 0.0, "avg_logprob": -0.09101284991253863, "compression_ratio": 1.6282051282051282, "no_speech_prob": 0.002980610588565469}, {"id": 222, "seek": 130068, "start": 1318.68, "end": 1326.68, "text": " you convert between tag value and JSON, whatever. Anyway, I think I might have a minute or two", "tokens": [51264, 291, 7620, 1296, 6162, 2158, 293, 31828, 11, 2035, 13, 5684, 11, 286, 519, 286, 1062, 362, 257, 3456, 420, 732, 51664], "temperature": 0.0, "avg_logprob": -0.09101284991253863, "compression_ratio": 1.6282051282051282, "no_speech_prob": 0.002980610588565469}, {"id": 223, "seek": 132668, "start": 1326.68, "end": 1334.28, "text": " for questions. I got three minutes for questions. Did I go so fast? I lose all of you on that?", "tokens": [50364, 337, 1651, 13, 286, 658, 1045, 2077, 337, 1651, 13, 2589, 286, 352, 370, 2370, 30, 286, 3624, 439, 295, 291, 322, 300, 30, 50744], "temperature": 0.0, "avg_logprob": -0.2809641185559725, "compression_ratio": 1.5874439461883407, "no_speech_prob": 0.06181386113166809}, {"id": 224, "seek": 132668, "start": 1334.28, "end": 1336.68, "text": " That felt like I was speed presenting. Yes.", "tokens": [50744, 663, 2762, 411, 286, 390, 3073, 15578, 13, 1079, 13, 50864], "temperature": 0.0, "avg_logprob": -0.2809641185559725, "compression_ratio": 1.5874439461883407, "no_speech_prob": 0.06181386113166809}, {"id": 225, "seek": 132668, "start": 1336.68, "end": 1344.68, "text": " I recognize that you get a lot of work about the specs so that you can see them easier. That's great work.", "tokens": [50864, 286, 5521, 300, 291, 483, 257, 688, 295, 589, 466, 264, 27911, 370, 300, 291, 393, 536, 552, 3571, 13, 663, 311, 869, 589, 13, 51264], "temperature": 0.0, "avg_logprob": -0.2809641185559725, "compression_ratio": 1.5874439461883407, "no_speech_prob": 0.06181386113166809}, {"id": 226, "seek": 132668, "start": 1344.68, "end": 1352.68, "text": " But also, I would say we need to have a lot of different kind of examples. You know, you write your library,", "tokens": [51264, 583, 611, 11, 286, 576, 584, 321, 643, 281, 362, 257, 688, 295, 819, 733, 295, 5110, 13, 509, 458, 11, 291, 2464, 428, 6405, 11, 51664], "temperature": 0.0, "avg_logprob": -0.2809641185559725, "compression_ratio": 1.5874439461883407, "no_speech_prob": 0.06181386113166809}, {"id": 227, "seek": 135268, "start": 1352.68, "end": 1358.68, "text": " then you want to test it, and then you find out whether you really understood the specs the right way.", "tokens": [50364, 550, 291, 528, 281, 1500, 309, 11, 293, 550, 291, 915, 484, 1968, 291, 534, 7320, 264, 27911, 264, 558, 636, 13, 50664], "temperature": 0.0, "avg_logprob": -0.12941635245143776, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.010816168040037155}, {"id": 228, "seek": 135268, "start": 1358.68, "end": 1362.68, "text": " Yes. Yes. And therefore, more examples of different types.", "tokens": [50664, 1079, 13, 1079, 13, 400, 4412, 11, 544, 5110, 295, 819, 3467, 13, 50864], "temperature": 0.0, "avg_logprob": -0.12941635245143776, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.010816168040037155}, {"id": 229, "seek": 135268, "start": 1362.68, "end": 1370.68, "text": " Yes. I don't think I can repeat all of that, but I think the basic comment, and I think it's a really good one,", "tokens": [50864, 1079, 13, 286, 500, 380, 519, 286, 393, 7149, 439, 295, 300, 11, 457, 286, 519, 264, 3875, 2871, 11, 293, 286, 519, 309, 311, 257, 534, 665, 472, 11, 51264], "temperature": 0.0, "avg_logprob": -0.12941635245143776, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.010816168040037155}, {"id": 230, "seek": 135268, "start": 1370.68, "end": 1376.68, "text": " is in addition to the spec, we need to have examples, you know, so that we can work off of those examples.", "tokens": [51264, 307, 294, 4500, 281, 264, 1608, 11, 321, 643, 281, 362, 5110, 11, 291, 458, 11, 370, 300, 321, 393, 589, 766, 295, 729, 5110, 13, 51564], "temperature": 0.0, "avg_logprob": -0.12941635245143776, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.010816168040037155}, {"id": 231, "seek": 137668, "start": 1376.68, "end": 1384.68, "text": " And we do have an examples repo in SPDX today. We plan on, we're going to organize that in the future for 3.0 by profile.", "tokens": [50364, 400, 321, 360, 362, 364, 5110, 49040, 294, 19572, 55, 965, 13, 492, 1393, 322, 11, 321, 434, 516, 281, 13859, 300, 294, 264, 2027, 337, 805, 13, 15, 538, 7964, 13, 50764], "temperature": 0.0, "avg_logprob": -0.1872968292236328, "compression_ratio": 1.4680851063829787, "no_speech_prob": 0.14594313502311707}, {"id": 232, "seek": 137668, "start": 1384.68, "end": 1390.68, "text": " So you'll be, if you're interested in security, you can go down and look at, like, the security examples, be able to use those.", "tokens": [50764, 407, 291, 603, 312, 11, 498, 291, 434, 3102, 294, 3825, 11, 291, 393, 352, 760, 293, 574, 412, 11, 411, 11, 264, 3825, 5110, 11, 312, 1075, 281, 764, 729, 13, 51064], "temperature": 0.0, "avg_logprob": -0.1872968292236328, "compression_ratio": 1.4680851063829787, "no_speech_prob": 0.14594313502311707}, {"id": 233, "seek": 137668, "start": 1390.68, "end": 1392.68, "text": " Excellent point. Thank you. Yes.", "tokens": [51064, 16723, 935, 13, 1044, 291, 13, 1079, 13, 51164], "temperature": 0.0, "avg_logprob": -0.1872968292236328, "compression_ratio": 1.4680851063829787, "no_speech_prob": 0.14594313502311707}, {"id": 234, "seek": 137668, "start": 1392.68, "end": 1402.68, "text": " Now is current code ready to convert a file from SPDX2 to 3.0?", "tokens": [51164, 823, 307, 2190, 3089, 1919, 281, 7620, 257, 3991, 490, 19572, 55, 17, 281, 805, 13, 15, 30, 51664], "temperature": 0.0, "avg_logprob": -0.1872968292236328, "compression_ratio": 1.4680851063829787, "no_speech_prob": 0.14594313502311707}, {"id": 235, "seek": 140268, "start": 1402.68, "end": 1408.68, "text": " Yeah, that's a really good question. So the question was, do we have code today that'll let you convert from 2 to 3?", "tokens": [50364, 865, 11, 300, 311, 257, 534, 665, 1168, 13, 407, 264, 1168, 390, 11, 360, 321, 362, 3089, 965, 300, 603, 718, 291, 7620, 490, 568, 281, 805, 30, 50664], "temperature": 0.0, "avg_logprob": -0.23149576374128752, "compression_ratio": 1.5321888412017168, "no_speech_prob": 0.03160921856760979}, {"id": 236, "seek": 140268, "start": 1408.68, "end": 1416.68, "text": " The Java code is not ready to be used yet, unfortunately. It compiles, but not quite ready. Yes, Dolph.", "tokens": [50664, 440, 10745, 3089, 307, 406, 1919, 281, 312, 1143, 1939, 11, 7015, 13, 467, 715, 4680, 11, 457, 406, 1596, 1919, 13, 1079, 11, 18786, 950, 13, 51064], "temperature": 0.0, "avg_logprob": -0.23149576374128752, "compression_ratio": 1.5321888412017168, "no_speech_prob": 0.03160921856760979}, {"id": 237, "seek": 140268, "start": 1416.68, "end": 1424.68, "text": " Yeah, we have a project that can do that with the 3DUSRC of SPDX3.", "tokens": [51064, 865, 11, 321, 362, 257, 1716, 300, 393, 360, 300, 365, 264, 805, 35, 3447, 28437, 295, 19572, 55, 18, 13, 51464], "temperature": 0.0, "avg_logprob": -0.23149576374128752, "compression_ratio": 1.5321888412017168, "no_speech_prob": 0.03160921856760979}, {"id": 238, "seek": 140268, "start": 1424.68, "end": 1428.68, "text": " So Dolph mentioned there is, is that in the presentation later today?", "tokens": [51464, 407, 18786, 950, 2835, 456, 307, 11, 307, 300, 294, 264, 5860, 1780, 965, 30, 51664], "temperature": 0.0, "avg_logprob": -0.23149576374128752, "compression_ratio": 1.5321888412017168, "no_speech_prob": 0.03160921856760979}, {"id": 239, "seek": 142868, "start": 1428.68, "end": 1436.68, "text": " Yeah. Okay. So we hear about a tool that can do that later today. It's not the Java library. So it's coming though. It's not quite ready yet. Yes.", "tokens": [50364, 865, 13, 1033, 13, 407, 321, 1568, 466, 257, 2290, 300, 393, 360, 300, 1780, 965, 13, 467, 311, 406, 264, 10745, 6405, 13, 407, 309, 311, 1348, 1673, 13, 467, 311, 406, 1596, 1919, 1939, 13, 1079, 13, 50764], "temperature": 0.0, "avg_logprob": -0.18295990979229962, "compression_ratio": 1.5862068965517242, "no_speech_prob": 0.06652674078941345}, {"id": 240, "seek": 142868, "start": 1436.68, "end": 1438.68, "text": " SPDX3 light coming?", "tokens": [50764, 19572, 55, 18, 1442, 1348, 30, 50864], "temperature": 0.0, "avg_logprob": -0.18295990979229962, "compression_ratio": 1.5862068965517242, "no_speech_prob": 0.06652674078941345}, {"id": 241, "seek": 142868, "start": 1438.68, "end": 1451.68, "text": " SPDX3 light is coming. And that will be, that's one of our profiles. It's got, it's unique in that it skinnies it down, you know, rather than adding things to it, which other ones do. Yeah. Sorry. Yes.", "tokens": [50864, 19572, 55, 18, 1442, 307, 1348, 13, 400, 300, 486, 312, 11, 300, 311, 472, 295, 527, 23693, 13, 467, 311, 658, 11, 309, 311, 3845, 294, 300, 309, 3178, 40549, 309, 760, 11, 291, 458, 11, 2831, 813, 5127, 721, 281, 309, 11, 597, 661, 2306, 360, 13, 865, 13, 4919, 13, 1079, 13, 51514], "temperature": 0.0, "avg_logprob": -0.18295990979229962, "compression_ratio": 1.5862068965517242, "no_speech_prob": 0.06652674078941345}, {"id": 242, "seek": 145168, "start": 1451.68, "end": 1465.68, "text": " Talk about some of the relationship of SPDX to RDF. I was wondering if you'd come up against any requirements, things that RDF doesn't support, stuff that you feel like you need to push back up into RDF.", "tokens": [50364, 8780, 466, 512, 295, 264, 2480, 295, 19572, 55, 281, 49488, 37, 13, 286, 390, 6359, 498, 291, 1116, 808, 493, 1970, 604, 7728, 11, 721, 300, 49488, 37, 1177, 380, 1406, 11, 1507, 300, 291, 841, 411, 291, 643, 281, 2944, 646, 493, 666, 49488, 37, 13, 51064], "temperature": 0.0, "avg_logprob": -0.13938388083744974, "compression_ratio": 1.584, "no_speech_prob": 0.28693872690200806}, {"id": 243, "seek": 145168, "start": 1465.68, "end": 1477.68, "text": " Ah, that's a good question. The question is, is there anything that we ran into in the RDF world that we, that we couldn't satisfy by using like, like the RDF, maybe Shackle Owl specification?", "tokens": [51064, 2438, 11, 300, 311, 257, 665, 1168, 13, 440, 1168, 307, 11, 307, 456, 1340, 300, 321, 5872, 666, 294, 264, 49488, 37, 1002, 300, 321, 11, 300, 321, 2809, 380, 19319, 538, 1228, 411, 11, 411, 264, 49488, 37, 11, 1310, 1160, 501, 306, 12773, 75, 31256, 30, 51664], "temperature": 0.0, "avg_logprob": -0.13938388083744974, "compression_ratio": 1.584, "no_speech_prob": 0.28693872690200806}, {"id": 244, "seek": 147768, "start": 1477.68, "end": 1488.68, "text": " I'd have to think about, I have a feeling we have, but I can't think of an example right now. You know, I, I, I, I, let me think about it and then give back to you later. Yeah. Thank you. Yes.", "tokens": [50364, 286, 1116, 362, 281, 519, 466, 11, 286, 362, 257, 2633, 321, 362, 11, 457, 286, 393, 380, 519, 295, 364, 1365, 558, 586, 13, 509, 458, 11, 286, 11, 286, 11, 286, 11, 286, 11, 718, 385, 519, 466, 309, 293, 550, 976, 646, 281, 291, 1780, 13, 865, 13, 1044, 291, 13, 1079, 13, 50914], "temperature": 0.0, "avg_logprob": -0.2521945601659464, "compression_ratio": 1.6166666666666667, "no_speech_prob": 0.22216543555259705}, {"id": 245, "seek": 147768, "start": 1488.68, "end": 1492.68, "text": " What's the view about converting SPDX3 to Cyclone DX and back and forth?", "tokens": [50914, 708, 311, 264, 1910, 466, 29942, 19572, 55, 18, 281, 49173, 546, 48817, 293, 646, 293, 5220, 30, 51114], "temperature": 0.0, "avg_logprob": -0.2521945601659464, "compression_ratio": 1.6166666666666667, "no_speech_prob": 0.22216543555259705}, {"id": 246, "seek": 147768, "start": 1492.68, "end": 1493.68, "text": " Oh, yes.", "tokens": [51114, 876, 11, 2086, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2521945601659464, "compression_ratio": 1.6166666666666667, "no_speech_prob": 0.22216543555259705}, {"id": 247, "seek": 147768, "start": 1493.68, "end": 1497.68, "text": " Because they've obviously got things like AI in their model 5. Right.", "tokens": [51164, 1436, 436, 600, 2745, 658, 721, 411, 7318, 294, 641, 2316, 1025, 13, 1779, 13, 51364], "temperature": 0.0, "avg_logprob": -0.2521945601659464, "compression_ratio": 1.6166666666666667, "no_speech_prob": 0.22216543555259705}, {"id": 248, "seek": 147768, "start": 1497.68, "end": 1499.68, "text": " 5, etc. You've got one. Right.", "tokens": [51364, 1025, 11, 5183, 13, 509, 600, 658, 472, 13, 1779, 13, 51464], "temperature": 0.0, "avg_logprob": -0.2521945601659464, "compression_ratio": 1.6166666666666667, "no_speech_prob": 0.22216543555259705}, {"id": 249, "seek": 147768, "start": 1499.68, "end": 1505.68, "text": " And security. So we're looking at compatibility because there's not people to be, what people to be flexible?", "tokens": [51464, 400, 3825, 13, 407, 321, 434, 1237, 412, 34237, 570, 456, 311, 406, 561, 281, 312, 11, 437, 561, 281, 312, 11358, 30, 51764], "temperature": 0.0, "avg_logprob": -0.2521945601659464, "compression_ratio": 1.6166666666666667, "no_speech_prob": 0.22216543555259705}, {"id": 250, "seek": 150568, "start": 1505.68, "end": 1521.68, "text": " Yes, we do. And I'm, I'm with you on that. So the question is, what about converting between Cyclone DX and SPDX? We actually had an effort going on in SPDX2 where we had people from Cyclone DX, myself included on the SPDX side collaborating and, and we were doing two things.", "tokens": [50364, 1079, 11, 321, 360, 13, 400, 286, 478, 11, 286, 478, 365, 291, 322, 300, 13, 407, 264, 1168, 307, 11, 437, 466, 29942, 1296, 49173, 546, 48817, 293, 19572, 55, 30, 492, 767, 632, 364, 4630, 516, 322, 294, 19572, 55, 17, 689, 321, 632, 561, 490, 49173, 546, 48817, 11, 2059, 5556, 322, 264, 19572, 55, 1252, 30188, 293, 11, 293, 321, 645, 884, 732, 721, 13, 51164], "temperature": 0.0, "avg_logprob": -0.13202103113724015, "compression_ratio": 1.6457564575645756, "no_speech_prob": 0.014061342924833298}, {"id": 251, "seek": 150568, "start": 1521.68, "end": 1532.68, "text": " We were, we were writing libraries to convert, you know, so kind of really testing it hands on. And, and then we were also working on the SPAC where we were like in 2.3.", "tokens": [51164, 492, 645, 11, 321, 645, 3579, 15148, 281, 7620, 11, 291, 458, 11, 370, 733, 295, 534, 4997, 309, 2377, 322, 13, 400, 11, 293, 550, 321, 645, 611, 1364, 322, 264, 8420, 4378, 689, 321, 645, 411, 294, 568, 13, 18, 13, 51714], "temperature": 0.0, "avg_logprob": -0.13202103113724015, "compression_ratio": 1.6457564575645756, "no_speech_prob": 0.014061342924833298}, {"id": 252, "seek": 153268, "start": 1532.68, "end": 1541.68, "text": " I actually put a number of things in per request of the Cyclone DX team to make it easier to convert. So we're doing both of those. Unfortunately, that collaboration stopped.", "tokens": [50364, 286, 767, 829, 257, 1230, 295, 721, 294, 680, 5308, 295, 264, 49173, 546, 48817, 1469, 281, 652, 309, 3571, 281, 7620, 13, 407, 321, 434, 884, 1293, 295, 729, 13, 8590, 11, 300, 9363, 5936, 13, 50814], "temperature": 0.0, "avg_logprob": -0.0795563364785815, "compression_ratio": 1.786764705882353, "no_speech_prob": 0.30049288272857666}, {"id": 253, "seek": 153268, "start": 1541.68, "end": 1558.68, "text": " I am looking for somebody from the Cyclone DX team to work with to do that in 3.0. So if you're on the Cyclone DX team or if any of you in the room are in Cyclone DX and are interested in, in collaborating with SPDX and make it easier for all of our users, let me know.", "tokens": [50814, 286, 669, 1237, 337, 2618, 490, 264, 49173, 546, 48817, 1469, 281, 589, 365, 281, 360, 300, 294, 805, 13, 15, 13, 407, 498, 291, 434, 322, 264, 49173, 546, 48817, 1469, 420, 498, 604, 295, 291, 294, 264, 1808, 366, 294, 49173, 546, 48817, 293, 366, 3102, 294, 11, 294, 30188, 365, 19572, 55, 293, 652, 309, 3571, 337, 439, 295, 527, 5022, 11, 718, 385, 458, 13, 51664], "temperature": 0.0, "avg_logprob": -0.0795563364785815, "compression_ratio": 1.786764705882353, "no_speech_prob": 0.30049288272857666}, {"id": 254, "seek": 153268, "start": 1558.68, "end": 1560.68, "text": " I'd be happy to work with you. Thank you.", "tokens": [51664, 286, 1116, 312, 2055, 281, 589, 365, 291, 13, 1044, 291, 13, 51764], "temperature": 0.0, "avg_logprob": -0.0795563364785815, "compression_ratio": 1.786764705882353, "no_speech_prob": 0.30049288272857666}, {"id": 255, "seek": 156068, "start": 1561.68, "end": 1562.68, "text": " Yeah.", "tokens": [50414, 865, 13, 50464], "temperature": 0.0, "avg_logprob": -0.2153934713912337, "compression_ratio": 1.4133333333333333, "no_speech_prob": 0.3300393521785736}, {"id": 256, "seek": 156068, "start": 1575.68, "end": 1579.68, "text": " Okay. So I, I'm not sure I completely understand the, oh, time's up.", "tokens": [51114, 1033, 13, 407, 286, 11, 286, 478, 406, 988, 286, 2584, 1223, 264, 11, 1954, 11, 565, 311, 493, 13, 51314], "temperature": 0.0, "avg_logprob": -0.2153934713912337, "compression_ratio": 1.4133333333333333, "no_speech_prob": 0.3300393521785736}, {"id": 257, "seek": 156068, "start": 1579.68, "end": 1580.68, "text": " Answer him.", "tokens": [51314, 24545, 796, 13, 51364], "temperature": 0.0, "avg_logprob": -0.2153934713912337, "compression_ratio": 1.4133333333333333, "no_speech_prob": 0.3300393521785736}, {"id": 258, "seek": 156068, "start": 1580.68, "end": 1581.68, "text": " Yeah.", "tokens": [51364, 865, 13, 51414], "temperature": 0.0, "avg_logprob": -0.2153934713912337, "compression_ratio": 1.4133333333333333, "no_speech_prob": 0.3300393521785736}, {"id": 259, "seek": 156068, "start": 1581.68, "end": 1585.68, "text": " Why don't you go ahead and shut me down and you can go ahead and close the screen and take that over. Yeah.", "tokens": [51414, 1545, 500, 380, 291, 352, 2286, 293, 5309, 385, 760, 293, 291, 393, 352, 2286, 293, 1998, 264, 2568, 293, 747, 300, 670, 13, 865, 13, 51614], "temperature": 0.0, "avg_logprob": -0.2153934713912337, "compression_ratio": 1.4133333333333333, "no_speech_prob": 0.3300393521785736}, {"id": 260, "seek": 156068, "start": 1585.68, "end": 1586.68, "text": " Yeah.", "tokens": [51614, 865, 13, 51664], "temperature": 0.0, "avg_logprob": -0.2153934713912337, "compression_ratio": 1.4133333333333333, "no_speech_prob": 0.3300393521785736}, {"id": 261, "seek": 156068, "start": 1586.68, "end": 1587.68, "text": " Just.", "tokens": [51664, 1449, 13, 51714], "temperature": 0.0, "avg_logprob": -0.2153934713912337, "compression_ratio": 1.4133333333333333, "no_speech_prob": 0.3300393521785736}, {"id": 262, "seek": 158768, "start": 1588.68, "end": 1590.68, "text": " So, sorry. So the, the decision about.", "tokens": [50414, 407, 11, 2597, 13, 407, 264, 11, 264, 3537, 466, 13, 50514], "temperature": 0.0, "avg_logprob": -0.20174049940265593, "compression_ratio": 1.7730496453900708, "no_speech_prob": 0.028847552835941315}, {"id": 263, "seek": 158768, "start": 1590.68, "end": 1593.68, "text": " These are committee that decide about the changes.", "tokens": [50514, 1981, 366, 7482, 300, 4536, 466, 264, 2962, 13, 50664], "temperature": 0.0, "avg_logprob": -0.20174049940265593, "compression_ratio": 1.7730496453900708, "no_speech_prob": 0.028847552835941315}, {"id": 264, "seek": 158768, "start": 1593.68, "end": 1605.68, "text": " Oh, how, okay. Like the governance of how the SPAC has made itself. Yeah. So we do have a formal governance process. We have a technical, we have kind of like a steering committee and then we have different work groups.", "tokens": [50664, 876, 11, 577, 11, 1392, 13, 1743, 264, 17449, 295, 577, 264, 8420, 4378, 575, 1027, 2564, 13, 865, 13, 407, 321, 360, 362, 257, 9860, 17449, 1399, 13, 492, 362, 257, 6191, 11, 321, 362, 733, 295, 411, 257, 14823, 7482, 293, 550, 321, 362, 819, 589, 3935, 13, 51264], "temperature": 0.0, "avg_logprob": -0.20174049940265593, "compression_ratio": 1.7730496453900708, "no_speech_prob": 0.028847552835941315}, {"id": 265, "seek": 158768, "start": 1605.68, "end": 1616.68, "text": " The real work gets done in the profile work group. Most of it's in the core. There are team leads that are nominated and, you know, the steering committee, this whole process that does that.", "tokens": [51264, 440, 957, 589, 2170, 1096, 294, 264, 7964, 589, 1594, 13, 4534, 295, 309, 311, 294, 264, 4965, 13, 821, 366, 1469, 6689, 300, 366, 25159, 293, 11, 291, 458, 11, 264, 14823, 7482, 11, 341, 1379, 1399, 300, 775, 300, 13, 51814], "temperature": 0.0, "avg_logprob": -0.20174049940265593, "compression_ratio": 1.7730496453900708, "no_speech_prob": 0.028847552835941315}, {"id": 266, "seek": 161668, "start": 1616.68, "end": 1624.68, "text": " And then the way that we really try hard to make all the decisions consensus space and it's, it's based on contributions too.", "tokens": [50364, 400, 550, 264, 636, 300, 321, 534, 853, 1152, 281, 652, 439, 264, 5327, 19115, 1901, 293, 309, 311, 11, 309, 311, 2361, 322, 15725, 886, 13, 50764], "temperature": 0.0, "avg_logprob": -0.1351604461669922, "compression_ratio": 1.7933333333333332, "no_speech_prob": 0.12575015425682068}, {"id": 267, "seek": 161668, "start": 1624.68, "end": 1630.68, "text": " So if somebody says, hey, I want to do this, but they don't contribute anything. Yeah, we don't really listen.", "tokens": [50764, 407, 498, 2618, 1619, 11, 4177, 11, 286, 528, 281, 360, 341, 11, 457, 436, 500, 380, 10586, 1340, 13, 865, 11, 321, 500, 380, 534, 2140, 13, 51064], "temperature": 0.0, "avg_logprob": -0.1351604461669922, "compression_ratio": 1.7933333333333332, "no_speech_prob": 0.12575015425682068}, {"id": 268, "seek": 161668, "start": 1630.68, "end": 1636.68, "text": " If they say, hey, I want to do this and here's a poll request. Here's the spec. Here's some tasks. You know, here's what you do to the schema to make it.", "tokens": [51064, 759, 436, 584, 11, 4177, 11, 286, 528, 281, 360, 341, 293, 510, 311, 257, 6418, 5308, 13, 1692, 311, 264, 1608, 13, 1692, 311, 512, 9608, 13, 509, 458, 11, 510, 311, 437, 291, 360, 281, 264, 34078, 281, 652, 309, 13, 51364], "temperature": 0.0, "avg_logprob": -0.1351604461669922, "compression_ratio": 1.7933333333333332, "no_speech_prob": 0.12575015425682068}, {"id": 269, "seek": 161668, "start": 1636.68, "end": 1638.68, "text": " Then it's like, oh yeah, come on in, you know, we'll work on it.", "tokens": [51364, 1396, 309, 311, 411, 11, 1954, 1338, 11, 808, 322, 294, 11, 291, 458, 11, 321, 603, 589, 322, 309, 13, 51464], "temperature": 0.0, "avg_logprob": -0.1351604461669922, "compression_ratio": 1.7933333333333332, "no_speech_prob": 0.12575015425682068}, {"id": 270, "seek": 161668, "start": 1638.68, "end": 1643.68, "text": " And sometimes there's differences of opinion. We try to work together very rarely.", "tokens": [51464, 400, 2171, 456, 311, 7300, 295, 4800, 13, 492, 853, 281, 589, 1214, 588, 13752, 13, 51714], "temperature": 0.0, "avg_logprob": -0.1351604461669922, "compression_ratio": 1.7933333333333332, "no_speech_prob": 0.12575015425682068}, {"id": 271, "seek": 164368, "start": 1643.68, "end": 1650.68, "text": " The team leads will have to make a call and we try to do it based on the majority, but you know, it's rare when we do that.", "tokens": [50364, 440, 1469, 6689, 486, 362, 281, 652, 257, 818, 293, 321, 853, 281, 360, 309, 2361, 322, 264, 6286, 11, 457, 291, 458, 11, 309, 311, 5892, 562, 321, 360, 300, 13, 50714], "temperature": 0.0, "avg_logprob": -0.1249252472605024, "compression_ratio": 1.3537414965986394, "no_speech_prob": 0.10071652382612228}, {"id": 272, "seek": 164368, "start": 1650.68, "end": 1656.68, "text": " We think very carefully before we do that. Yeah. All right. Max, thank you.", "tokens": [50714, 492, 519, 588, 7500, 949, 321, 360, 300, 13, 865, 13, 1057, 558, 13, 7402, 11, 1309, 291, 13, 51014], "temperature": 0.0, "avg_logprob": -0.1249252472605024, "compression_ratio": 1.3537414965986394, "no_speech_prob": 0.10071652382612228}], "language": "en"}