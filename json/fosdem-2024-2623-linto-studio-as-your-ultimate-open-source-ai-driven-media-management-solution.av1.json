{"text": " Okay, great thing everyone. Thanks to come to discover linto. linto is your ultimate open source AI driven media management solution. So I'm Damien Lenn. I'm head of R&D engineering here for linto at Lina Gora and I'm proud. So what is linto? Essentially linto is a set of voice technologies that enables you the best on the open source side of voice tech. You can find in linto all the cognitive APIs that you are craving about like transcription with a live or batch transcription. We have a set of NLP APIs that enables you to add punctuation, name entities and topics identification or so on. And also we worked on speech synthesis. This is the first set of linto technologies. Leveraging those technologies we built a full-figured surrogate, I mean alternative to Alexa and Dialogflow to build agents, smart agents which includes chatbots, smart assistants, voicebots with custom full software work walls that work on the browser that's very neat. And finally we the past two years leveraging further our technologies we built a business oriented solution which is called linto app which is a media management platform that enables you to load media and to make to run these cognitive APIs to edit the transcription in a nutshell to turn routine recording into fully qualified data lake. So there's a lot of software's closed source that enables you the same kind of features but more or less all of them uses the APIs from the big players you know them. Okay so the question here is always the same what happens to my data when I use the services provided by author, dictation, happy scribe and so on. In a nutshell you just send your data to them. So linto studio I will present you a quick video to show you the platform but here you have all the functionalities and note the link which is currently displayed you will find the link to immediately just use our alpha version which is online free you can just create your account and try yourself just after the meeting and you will find the link to our github pages to download and work with the source code. So linto studio enables you to use the APIs I've been talking about to add automatic stamp with our modified run times for whisper.ai not a whisper by openai. We are so enabled to speakers and turn identification and all I've been talking about before just note that the platform is a web platform where you can collaborate in real time using organization roles and share resources within the platform. It's shipped with companion Android application that you can use to to recall. The final slide before I move to the quick video of course as my colleagues presented you a work on the large language models of course we want to also leverage these technologies within linto studio and add this kind of feature I'm drafting here on the picture to work with the documents loaded into the platform and ask some things with large language models. Okay so here I jump to the video. Okay so I recorded this yesterday. Here on the left I'm currently recording something within the sorry so I'm recording with live transcription. Okay whenever I'm done I just stop I can navigate local files and listen back what I recorded but what I want to do is to send this recording directly within the platform which is of course the big window displayed on the right so I can change I can send it to the platform I choose the language the model I want to use then the media I uploaded just lands into the platform and here I can see that the transcription here includes the capitalization and normalization I can also explore the platform as I tell you media management solution so it's a multi-user platform we where everyone can create accounts and use roles within organization so here I just showcase the way you might invite users and assign roles within a given organization here I show the share mechanisms which is total rip off from notion way of doing things and I'm proud of it it was flawlessly I can share with external users as well send email automatically when I just share transcription to a user okay here I jump to the editor where I can you see use AI insight which is our NLP APIs okay you just click on the one you want to use and start generation forum identifying stuff in your text like name entities or locations and decisions topics and put highlights you can also manipulate the text and add manual highlights to annotate the text okay also we have another editor which is also very neat where it's a place where you can basically just built the SRT or VTT and you work with the screens you have the center the current screen you can arrange arrange them the timing you can of course correct the text which enables you to add something that you want to rip on the video directly some close captions here's the way I want to navigate within the platform I just can use tags and fetch the document I'm looking for also using full search text and so on and once again I get back to this recording I can show you here that I can also correct add some correction corrections to the text change speakers which is a real-time collaboration with a reconciliation of multi multiple users editing the text and finally as you saw we can export the document okay that's our platform demonstrated in a nutshell I took 10 minutes for this presentation hoping for any questions from you so if I am if you thank you for this presentation I have two questions one of them is technical and the other one is about money I'll start with the money this specific project how is it sustained that do you have revenue for this specific project and so what's the business and then the second question was what kind of power of computing power do you need to run this for a small organization maybe okay so the goal here for our business is very clear we offer as linear go around services for tuning models okay so this particular platform is also intended to be a SAS service where the user will be at some point when we have time to develop a subscription for that users will be able to use our system as a SAS but the source remains free and it can be austere on premise with the same features like away like like always at the Nogura we have no premium plan or whatever but we just feel that it's convenient to just host directly a solution as a SAS offer the other question was about the computing power okay so it requires quite a lot but we batch the process of the transcriptions and the long models inferences we just provide the best default way of doing stuff and if you dig in the code you'll see that our runtime supports kind of everything you can dream of we can run on CPU of course it will be a little bit clumsy we work on CPU with Intel extensions for transformers and so on and we of course work on GPU if you want to process a large batch of transcriptions when the hosting on premises any other questions we got time for one more how do you handle a typically French language setting which is irony how do you handle because of the keywords and so on the typically French set which is irony meaning that the speaker means exactly the opposite of what he says he's asking how do you do with the irony of French language of course using the you know the irony mark you know this one thank you Damian all right we're gonna start the next talk here in two minutes", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 16.94, "text": " Okay, great thing everyone. Thanks to come to discover linto. linto is your ultimate", "tokens": [50364, 1033, 11, 869, 551, 1518, 13, 2561, 281, 808, 281, 4411, 287, 17246, 13, 287, 17246, 307, 428, 9705, 51211], "temperature": 0.2, "avg_logprob": -0.3853559688645966, "compression_ratio": 1.2746478873239437, "no_speech_prob": 0.4583759903907776}, {"id": 1, "seek": 0, "start": 16.94, "end": 27.240000000000002, "text": " open source AI driven media management solution. So I'm Damien Lenn. I'm head of R&D engineering", "tokens": [51211, 1269, 4009, 7318, 9555, 3021, 4592, 3827, 13, 407, 286, 478, 5885, 1053, 441, 1857, 13, 286, 478, 1378, 295, 497, 5, 35, 7043, 51726], "temperature": 0.2, "avg_logprob": -0.3853559688645966, "compression_ratio": 1.2746478873239437, "no_speech_prob": 0.4583759903907776}, {"id": 2, "seek": 2724, "start": 27.24, "end": 38.48, "text": " here for linto at Lina Gora and I'm proud. So what is linto? Essentially linto is a set", "tokens": [50364, 510, 337, 287, 17246, 412, 441, 1426, 460, 3252, 293, 286, 478, 4570, 13, 407, 437, 307, 287, 17246, 30, 23596, 287, 17246, 307, 257, 992, 50926], "temperature": 0.0, "avg_logprob": -0.23439456434810862, "compression_ratio": 1.4722222222222223, "no_speech_prob": 0.3323172926902771}, {"id": 3, "seek": 2724, "start": 38.48, "end": 48.32, "text": " of voice technologies that enables you the best on the open source side of voice tech.", "tokens": [50926, 295, 3177, 7943, 300, 17077, 291, 264, 1151, 322, 264, 1269, 4009, 1252, 295, 3177, 7553, 13, 51418], "temperature": 0.0, "avg_logprob": -0.23439456434810862, "compression_ratio": 1.4722222222222223, "no_speech_prob": 0.3323172926902771}, {"id": 4, "seek": 2724, "start": 48.32, "end": 55.84, "text": " You can find in linto all the cognitive APIs that you are craving about like transcription", "tokens": [51418, 509, 393, 915, 294, 287, 17246, 439, 264, 15605, 21445, 300, 291, 366, 27320, 466, 411, 35288, 51794], "temperature": 0.0, "avg_logprob": -0.23439456434810862, "compression_ratio": 1.4722222222222223, "no_speech_prob": 0.3323172926902771}, {"id": 5, "seek": 5584, "start": 55.84, "end": 64.76, "text": " with a live or batch transcription. We have a set of NLP APIs that enables you to add", "tokens": [50364, 365, 257, 1621, 420, 15245, 35288, 13, 492, 362, 257, 992, 295, 426, 45196, 21445, 300, 17077, 291, 281, 909, 50810], "temperature": 0.0, "avg_logprob": -0.20425467057661575, "compression_ratio": 1.4731182795698925, "no_speech_prob": 0.0833132266998291}, {"id": 6, "seek": 5584, "start": 64.76, "end": 74.24000000000001, "text": " punctuation, name entities and topics identification or so on. And also we worked on speech synthesis.", "tokens": [50810, 27006, 16073, 11, 1315, 16667, 293, 8378, 22065, 420, 370, 322, 13, 400, 611, 321, 2732, 322, 6218, 30252, 13, 51284], "temperature": 0.0, "avg_logprob": -0.20425467057661575, "compression_ratio": 1.4731182795698925, "no_speech_prob": 0.0833132266998291}, {"id": 7, "seek": 5584, "start": 74.24000000000001, "end": 84.0, "text": " This is the first set of linto technologies. Leveraging those technologies we built a", "tokens": [51284, 639, 307, 264, 700, 992, 295, 287, 17246, 7943, 13, 441, 1054, 3568, 729, 7943, 321, 3094, 257, 51772], "temperature": 0.0, "avg_logprob": -0.20425467057661575, "compression_ratio": 1.4731182795698925, "no_speech_prob": 0.0833132266998291}, {"id": 8, "seek": 8400, "start": 84.0, "end": 95.72, "text": " full-figured surrogate, I mean alternative to Alexa and Dialogflow to build agents, smart agents", "tokens": [50364, 1577, 12, 20646, 3831, 1022, 6675, 473, 11, 286, 914, 8535, 281, 22595, 293, 29658, 664, 10565, 281, 1322, 12554, 11, 4069, 12554, 50950], "temperature": 0.0, "avg_logprob": -0.3932310610401387, "compression_ratio": 1.4, "no_speech_prob": 0.19280318915843964}, {"id": 9, "seek": 8400, "start": 95.72, "end": 106.0, "text": " which includes chatbots, smart assistants, voicebots with custom full software work walls that work", "tokens": [50950, 597, 5974, 5081, 65, 1971, 11, 4069, 34949, 11, 3177, 65, 1971, 365, 2375, 1577, 4722, 589, 7920, 300, 589, 51464], "temperature": 0.0, "avg_logprob": -0.3932310610401387, "compression_ratio": 1.4, "no_speech_prob": 0.19280318915843964}, {"id": 10, "seek": 10600, "start": 106.0, "end": 116.4, "text": " on the browser that's very neat. And finally we the past two years leveraging further our", "tokens": [50364, 322, 264, 11185, 300, 311, 588, 10654, 13, 400, 2721, 321, 264, 1791, 732, 924, 32666, 3052, 527, 50884], "temperature": 0.0, "avg_logprob": -0.2647169404110666, "compression_ratio": 1.4972677595628416, "no_speech_prob": 0.5105448961257935}, {"id": 11, "seek": 10600, "start": 116.4, "end": 124.96000000000001, "text": " technologies we built a business oriented solution which is called linto app which is a media", "tokens": [50884, 7943, 321, 3094, 257, 1606, 21841, 3827, 597, 307, 1219, 287, 17246, 724, 597, 307, 257, 3021, 51312], "temperature": 0.0, "avg_logprob": -0.2647169404110666, "compression_ratio": 1.4972677595628416, "no_speech_prob": 0.5105448961257935}, {"id": 12, "seek": 10600, "start": 124.96000000000001, "end": 133.24, "text": " management platform that enables you to load media and to make to run these cognitive APIs", "tokens": [51312, 4592, 3663, 300, 17077, 291, 281, 3677, 3021, 293, 281, 652, 281, 1190, 613, 15605, 21445, 51726], "temperature": 0.0, "avg_logprob": -0.2647169404110666, "compression_ratio": 1.4972677595628416, "no_speech_prob": 0.5105448961257935}, {"id": 13, "seek": 13324, "start": 133.32000000000002, "end": 144.88, "text": " to edit the transcription in a nutshell to turn routine recording into fully qualified data lake.", "tokens": [50368, 281, 8129, 264, 35288, 294, 257, 37711, 281, 1261, 9927, 6613, 666, 4498, 15904, 1412, 11001, 13, 50946], "temperature": 0.0, "avg_logprob": -0.30931093476035376, "compression_ratio": 1.4071428571428573, "no_speech_prob": 0.1591702550649643}, {"id": 14, "seek": 13324, "start": 146.88, "end": 156.64000000000001, "text": " So there's a lot of software's closed source that enables you the same kind of features but more or", "tokens": [51046, 407, 456, 311, 257, 688, 295, 4722, 311, 5395, 4009, 300, 17077, 291, 264, 912, 733, 295, 4122, 457, 544, 420, 51534], "temperature": 0.0, "avg_logprob": -0.30931093476035376, "compression_ratio": 1.4071428571428573, "no_speech_prob": 0.1591702550649643}, {"id": 15, "seek": 15664, "start": 156.67999999999998, "end": 163.95999999999998, "text": " less all of them uses the APIs from the big players you know them. Okay so the question", "tokens": [50366, 1570, 439, 295, 552, 4960, 264, 21445, 490, 264, 955, 4150, 291, 458, 552, 13, 1033, 370, 264, 1168, 50730], "temperature": 0.0, "avg_logprob": -0.2110156870600003, "compression_ratio": 1.5, "no_speech_prob": 0.36697933077812195}, {"id": 16, "seek": 15664, "start": 163.95999999999998, "end": 170.92, "text": " here is always the same what happens to my data when I use the services provided by author,", "tokens": [50730, 510, 307, 1009, 264, 912, 437, 2314, 281, 452, 1412, 562, 286, 764, 264, 3328, 5649, 538, 3793, 11, 51078], "temperature": 0.0, "avg_logprob": -0.2110156870600003, "compression_ratio": 1.5, "no_speech_prob": 0.36697933077812195}, {"id": 17, "seek": 15664, "start": 170.92, "end": 180.48, "text": " dictation, happy scribe and so on. In a nutshell you just send your data to them.", "tokens": [51078, 12569, 399, 11, 2055, 5545, 650, 293, 370, 322, 13, 682, 257, 37711, 291, 445, 2845, 428, 1412, 281, 552, 13, 51556], "temperature": 0.0, "avg_logprob": -0.2110156870600003, "compression_ratio": 1.5, "no_speech_prob": 0.36697933077812195}, {"id": 18, "seek": 18048, "start": 181.48, "end": 191.32, "text": " So linto studio I will present you a quick video to show you the platform but here you", "tokens": [50414, 407, 287, 17246, 6811, 286, 486, 1974, 291, 257, 1702, 960, 281, 855, 291, 264, 3663, 457, 510, 291, 50906], "temperature": 0.0, "avg_logprob": -0.16179007868612966, "compression_ratio": 1.6057142857142856, "no_speech_prob": 0.020520759746432304}, {"id": 19, "seek": 18048, "start": 191.32, "end": 199.72, "text": " have all the functionalities and note the link which is currently displayed you will find the link", "tokens": [50906, 362, 439, 264, 11745, 1088, 293, 3637, 264, 2113, 597, 307, 4362, 16372, 291, 486, 915, 264, 2113, 51326], "temperature": 0.0, "avg_logprob": -0.16179007868612966, "compression_ratio": 1.6057142857142856, "no_speech_prob": 0.020520759746432304}, {"id": 20, "seek": 18048, "start": 199.72, "end": 208.79999999999998, "text": " to immediately just use our alpha version which is online free you can just create your account", "tokens": [51326, 281, 4258, 445, 764, 527, 8961, 3037, 597, 307, 2950, 1737, 291, 393, 445, 1884, 428, 2696, 51780], "temperature": 0.0, "avg_logprob": -0.16179007868612966, "compression_ratio": 1.6057142857142856, "no_speech_prob": 0.020520759746432304}, {"id": 21, "seek": 20880, "start": 208.92000000000002, "end": 217.56, "text": " and try yourself just after the meeting and you will find the link to our github pages to download", "tokens": [50370, 293, 853, 1803, 445, 934, 264, 3440, 293, 291, 486, 915, 264, 2113, 281, 527, 290, 355, 836, 7183, 281, 5484, 50802], "temperature": 0.0, "avg_logprob": -0.18901515493587573, "compression_ratio": 1.3776223776223777, "no_speech_prob": 0.031684573739767075}, {"id": 22, "seek": 20880, "start": 217.56, "end": 228.56, "text": " and work with the source code. So linto studio enables you to use the APIs I've been talking about", "tokens": [50802, 293, 589, 365, 264, 4009, 3089, 13, 407, 287, 17246, 6811, 17077, 291, 281, 764, 264, 21445, 286, 600, 668, 1417, 466, 51352], "temperature": 0.0, "avg_logprob": -0.18901515493587573, "compression_ratio": 1.3776223776223777, "no_speech_prob": 0.031684573739767075}, {"id": 23, "seek": 22856, "start": 229.32, "end": 242.08, "text": " to add automatic stamp with our modified run times for whisper.ai not a whisper by openai.", "tokens": [50402, 281, 909, 12509, 9921, 365, 527, 15873, 1190, 1413, 337, 26018, 13, 1301, 406, 257, 26018, 538, 1269, 1301, 13, 51040], "temperature": 0.0, "avg_logprob": -0.44577589489164804, "compression_ratio": 1.353846153846154, "no_speech_prob": 0.17456266283988953}, {"id": 24, "seek": 22856, "start": 242.08, "end": 252.92000000000002, "text": " We are so enabled to speakers and turn identification and all I've been talking about", "tokens": [51040, 492, 366, 370, 15172, 281, 9518, 293, 1261, 22065, 293, 439, 286, 600, 668, 1417, 466, 51582], "temperature": 0.0, "avg_logprob": -0.44577589489164804, "compression_ratio": 1.353846153846154, "no_speech_prob": 0.17456266283988953}, {"id": 25, "seek": 25292, "start": 253.67999999999998, "end": 260.59999999999997, "text": " before just note that the platform is a web platform where you can collaborate in real time using", "tokens": [50402, 949, 445, 3637, 300, 264, 3663, 307, 257, 3670, 3663, 689, 291, 393, 18338, 294, 957, 565, 1228, 50748], "temperature": 0.0, "avg_logprob": -0.30242443084716797, "compression_ratio": 1.5240641711229947, "no_speech_prob": 0.17403756082057953}, {"id": 26, "seek": 25292, "start": 260.59999999999997, "end": 270.44, "text": " organization roles and share resources within the platform. It's shipped with companion", "tokens": [50748, 4475, 9604, 293, 2073, 3593, 1951, 264, 3663, 13, 467, 311, 25312, 365, 22363, 51240], "temperature": 0.0, "avg_logprob": -0.30242443084716797, "compression_ratio": 1.5240641711229947, "no_speech_prob": 0.17403756082057953}, {"id": 27, "seek": 25292, "start": 270.44, "end": 279.8, "text": " Android application that you can use to to recall. The final slide before I move to the quick video", "tokens": [51240, 8853, 3861, 300, 291, 393, 764, 281, 281, 9901, 13, 440, 2572, 4137, 949, 286, 1286, 281, 264, 1702, 960, 51708], "temperature": 0.0, "avg_logprob": -0.30242443084716797, "compression_ratio": 1.5240641711229947, "no_speech_prob": 0.17403756082057953}, {"id": 28, "seek": 27980, "start": 280.68, "end": 287.6, "text": " of course as my colleagues presented you a work on the large language models of course we want to", "tokens": [50408, 295, 1164, 382, 452, 7734, 8212, 291, 257, 589, 322, 264, 2416, 2856, 5245, 295, 1164, 321, 528, 281, 50754], "temperature": 0.0, "avg_logprob": -0.18997333895775578, "compression_ratio": 1.6055555555555556, "no_speech_prob": 0.10276417434215546}, {"id": 29, "seek": 27980, "start": 287.6, "end": 296.44, "text": " also leverage these technologies within linto studio and add this kind of feature I'm drafting", "tokens": [50754, 611, 13982, 613, 7943, 1951, 287, 17246, 6811, 293, 909, 341, 733, 295, 4111, 286, 478, 46378, 51196], "temperature": 0.0, "avg_logprob": -0.18997333895775578, "compression_ratio": 1.6055555555555556, "no_speech_prob": 0.10276417434215546}, {"id": 30, "seek": 27980, "start": 296.44, "end": 305.72, "text": " here on the picture to work with the documents loaded into the platform and ask some things with", "tokens": [51196, 510, 322, 264, 3036, 281, 589, 365, 264, 8512, 13210, 666, 264, 3663, 293, 1029, 512, 721, 365, 51660], "temperature": 0.0, "avg_logprob": -0.18997333895775578, "compression_ratio": 1.6055555555555556, "no_speech_prob": 0.10276417434215546}, {"id": 31, "seek": 30572, "start": 305.8, "end": 326.20000000000005, "text": " large language models. Okay so here I jump to the video. Okay so I recorded this yesterday. Here", "tokens": [50368, 2416, 2856, 5245, 13, 1033, 370, 510, 286, 3012, 281, 264, 960, 13, 1033, 370, 286, 8287, 341, 5186, 13, 1692, 51388], "temperature": 0.0, "avg_logprob": -0.3792771911621094, "compression_ratio": 1.1428571428571428, "no_speech_prob": 0.06748276948928833}, {"id": 32, "seek": 32620, "start": 326.28, "end": 338.76, "text": " on the left I'm currently recording something within the sorry so I'm recording with live", "tokens": [50368, 322, 264, 1411, 286, 478, 4362, 6613, 746, 1951, 264, 2597, 370, 286, 478, 6613, 365, 1621, 50992], "temperature": 0.0, "avg_logprob": -0.27971968539925507, "compression_ratio": 1.4, "no_speech_prob": 0.09573771059513092}, {"id": 33, "seek": 32620, "start": 338.76, "end": 348.15999999999997, "text": " transcription. Okay whenever I'm done I just stop I can navigate local files and listen back what I", "tokens": [50992, 35288, 13, 1033, 5699, 286, 478, 1096, 286, 445, 1590, 286, 393, 12350, 2654, 7098, 293, 2140, 646, 437, 286, 51462], "temperature": 0.0, "avg_logprob": -0.27971968539925507, "compression_ratio": 1.4, "no_speech_prob": 0.09573771059513092}, {"id": 34, "seek": 34816, "start": 349.12, "end": 356.92, "text": " recorded but what I want to do is to send this recording directly within the platform which is", "tokens": [50412, 8287, 457, 437, 286, 528, 281, 360, 307, 281, 2845, 341, 6613, 3838, 1951, 264, 3663, 597, 307, 50802], "temperature": 0.0, "avg_logprob": -0.21849993192232572, "compression_ratio": 1.7391304347826086, "no_speech_prob": 0.15435238182544708}, {"id": 35, "seek": 34816, "start": 356.92, "end": 365.0, "text": " of course the big window displayed on the right so I can change I can send it to the platform", "tokens": [50802, 295, 1164, 264, 955, 4910, 16372, 322, 264, 558, 370, 286, 393, 1319, 286, 393, 2845, 309, 281, 264, 3663, 51206], "temperature": 0.0, "avg_logprob": -0.21849993192232572, "compression_ratio": 1.7391304347826086, "no_speech_prob": 0.15435238182544708}, {"id": 36, "seek": 34816, "start": 365.0, "end": 374.12, "text": " I choose the language the model I want to use then the media I uploaded just lands into the", "tokens": [51206, 286, 2826, 264, 2856, 264, 2316, 286, 528, 281, 764, 550, 264, 3021, 286, 17135, 445, 5949, 666, 264, 51662], "temperature": 0.0, "avg_logprob": -0.21849993192232572, "compression_ratio": 1.7391304347826086, "no_speech_prob": 0.15435238182544708}, {"id": 37, "seek": 37412, "start": 374.12, "end": 384.48, "text": " platform and here I can see that the transcription here includes the capitalization and normalization", "tokens": [50364, 3663, 293, 510, 286, 393, 536, 300, 264, 35288, 510, 5974, 264, 4238, 2144, 293, 2710, 2144, 50882], "temperature": 0.0, "avg_logprob": -0.20413397179275264, "compression_ratio": 1.6477272727272727, "no_speech_prob": 0.03146979957818985}, {"id": 38, "seek": 37412, "start": 384.48, "end": 394.04, "text": " I can also explore the platform as I tell you media management solution so it's a multi-user", "tokens": [50882, 286, 393, 611, 6839, 264, 3663, 382, 286, 980, 291, 3021, 4592, 3827, 370, 309, 311, 257, 4825, 12, 18088, 51360], "temperature": 0.0, "avg_logprob": -0.20413397179275264, "compression_ratio": 1.6477272727272727, "no_speech_prob": 0.03146979957818985}, {"id": 39, "seek": 37412, "start": 394.04, "end": 403.52, "text": " platform we where everyone can create accounts and use roles within organization so here I just", "tokens": [51360, 3663, 321, 689, 1518, 393, 1884, 9402, 293, 764, 9604, 1951, 4475, 370, 510, 286, 445, 51834], "temperature": 0.0, "avg_logprob": -0.20413397179275264, "compression_ratio": 1.6477272727272727, "no_speech_prob": 0.03146979957818985}, {"id": 40, "seek": 40352, "start": 403.71999999999997, "end": 416.28, "text": " showcase the way you might invite users and assign roles within a given organization here I show the", "tokens": [50374, 20388, 264, 636, 291, 1062, 7980, 5022, 293, 6269, 9604, 1951, 257, 2212, 4475, 510, 286, 855, 264, 51002], "temperature": 0.0, "avg_logprob": -0.24520449340343475, "compression_ratio": 1.5585106382978724, "no_speech_prob": 0.030326582491397858}, {"id": 41, "seek": 40352, "start": 416.28, "end": 424.52, "text": " share mechanisms which is total rip off from notion way of doing things and I'm proud of it it was", "tokens": [51002, 2073, 15902, 597, 307, 3217, 12782, 766, 490, 10710, 636, 295, 884, 721, 293, 286, 478, 4570, 295, 309, 309, 390, 51414], "temperature": 0.0, "avg_logprob": -0.24520449340343475, "compression_ratio": 1.5585106382978724, "no_speech_prob": 0.030326582491397858}, {"id": 42, "seek": 40352, "start": 424.52, "end": 432.64, "text": " flawlessly I can share with external users as well send email automatically when I just share", "tokens": [51414, 13717, 12048, 286, 393, 2073, 365, 8320, 5022, 382, 731, 2845, 3796, 6772, 562, 286, 445, 2073, 51820], "temperature": 0.0, "avg_logprob": -0.24520449340343475, "compression_ratio": 1.5585106382978724, "no_speech_prob": 0.030326582491397858}, {"id": 43, "seek": 43264, "start": 432.88, "end": 442.47999999999996, "text": " transcription to a user okay here I jump to the editor where I can you see use AI insight which is our", "tokens": [50376, 35288, 281, 257, 4195, 1392, 510, 286, 3012, 281, 264, 9839, 689, 286, 393, 291, 536, 764, 7318, 11269, 597, 307, 527, 50856], "temperature": 0.0, "avg_logprob": -0.2562966054799605, "compression_ratio": 1.4405594405594406, "no_speech_prob": 0.04052814096212387}, {"id": 44, "seek": 43264, "start": 442.47999999999996, "end": 455.2, "text": " NLP APIs okay you just click on the one you want to use and start generation forum identifying stuff in", "tokens": [50856, 426, 45196, 21445, 1392, 291, 445, 2052, 322, 264, 472, 291, 528, 281, 764, 293, 722, 5125, 17542, 16696, 1507, 294, 51492], "temperature": 0.0, "avg_logprob": -0.2562966054799605, "compression_ratio": 1.4405594405594406, "no_speech_prob": 0.04052814096212387}, {"id": 45, "seek": 45520, "start": 455.24, "end": 464.32, "text": " your text like name entities or locations and decisions topics and put highlights you can also", "tokens": [50366, 428, 2487, 411, 1315, 16667, 420, 9253, 293, 5327, 8378, 293, 829, 14254, 291, 393, 611, 50820], "temperature": 0.0, "avg_logprob": -0.21563823406512922, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.1332155019044876}, {"id": 46, "seek": 45520, "start": 464.32, "end": 481.68, "text": " manipulate the text and add manual highlights to annotate the text okay also we have another", "tokens": [50820, 20459, 264, 2487, 293, 909, 9688, 14254, 281, 25339, 473, 264, 2487, 1392, 611, 321, 362, 1071, 51688], "temperature": 0.0, "avg_logprob": -0.21563823406512922, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.1332155019044876}, {"id": 47, "seek": 48168, "start": 481.92, "end": 492.40000000000003, "text": " editor which is also very neat where it's a place where you can basically just built the SRT or VTT", "tokens": [50376, 9839, 597, 307, 611, 588, 10654, 689, 309, 311, 257, 1081, 689, 291, 393, 1936, 445, 3094, 264, 20840, 51, 420, 691, 28178, 50900], "temperature": 0.0, "avg_logprob": -0.24068232143626495, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.08612986654043198}, {"id": 48, "seek": 48168, "start": 493.2, "end": 503.16, "text": " and you work with the screens you have the center the current screen you can arrange arrange them", "tokens": [50940, 293, 291, 589, 365, 264, 11171, 291, 362, 264, 3056, 264, 2190, 2568, 291, 393, 9424, 9424, 552, 51438], "temperature": 0.0, "avg_logprob": -0.24068232143626495, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.08612986654043198}, {"id": 49, "seek": 48168, "start": 505.16, "end": 511.48, "text": " the timing you can of course correct the text which enables you to add something that you want to", "tokens": [51538, 264, 10822, 291, 393, 295, 1164, 3006, 264, 2487, 597, 17077, 291, 281, 909, 746, 300, 291, 528, 281, 51854], "temperature": 0.0, "avg_logprob": -0.24068232143626495, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.08612986654043198}, {"id": 50, "seek": 51148, "start": 511.52000000000004, "end": 522.5600000000001, "text": " rip on the video directly some close captions here's the way I want to navigate within the platform", "tokens": [50366, 12782, 322, 264, 960, 3838, 512, 1998, 44832, 510, 311, 264, 636, 286, 528, 281, 12350, 1951, 264, 3663, 50918], "temperature": 0.0, "avg_logprob": -0.2476509135702382, "compression_ratio": 1.4411764705882353, "no_speech_prob": 0.022306252270936966}, {"id": 51, "seek": 51148, "start": 522.5600000000001, "end": 534.2, "text": " I just can use tags and fetch the document I'm looking for also using full search text and so on", "tokens": [50918, 286, 445, 393, 764, 18632, 293, 23673, 264, 4166, 286, 478, 1237, 337, 611, 1228, 1577, 3164, 2487, 293, 370, 322, 51500], "temperature": 0.0, "avg_logprob": -0.2476509135702382, "compression_ratio": 1.4411764705882353, "no_speech_prob": 0.022306252270936966}, {"id": 52, "seek": 53420, "start": 535.2, "end": 543.44, "text": " and once again I get back to this recording I can show you here that I can also correct add some", "tokens": [50414, 293, 1564, 797, 286, 483, 646, 281, 341, 6613, 286, 393, 855, 291, 510, 300, 286, 393, 611, 3006, 909, 512, 50826], "temperature": 0.0, "avg_logprob": -0.2662305610124455, "compression_ratio": 1.4881889763779528, "no_speech_prob": 0.0748087540268898}, {"id": 53, "seek": 53420, "start": 543.44, "end": 550.96, "text": " correction corrections to the text change speakers which is a real-time collaboration with a", "tokens": [50826, 19984, 36406, 281, 264, 2487, 1319, 9518, 597, 307, 257, 957, 12, 3766, 9363, 365, 257, 51202], "temperature": 0.0, "avg_logprob": -0.2662305610124455, "compression_ratio": 1.4881889763779528, "no_speech_prob": 0.0748087540268898}, {"id": 54, "seek": 55096, "start": 551.4000000000001, "end": 562.6800000000001, "text": " reconciliation of multi multiple users editing the text and finally as you saw we can export the", "tokens": [50386, 31281, 295, 4825, 3866, 5022, 10000, 264, 2487, 293, 2721, 382, 291, 1866, 321, 393, 10725, 264, 50950], "temperature": 0.0, "avg_logprob": -0.2778597354888916, "compression_ratio": 1.3971631205673758, "no_speech_prob": 0.08764351904392242}, {"id": 55, "seek": 55096, "start": 562.6800000000001, "end": 574.0, "text": " document okay that's our platform demonstrated in a nutshell I took 10 minutes for this presentation", "tokens": [50950, 4166, 1392, 300, 311, 527, 3663, 18772, 294, 257, 37711, 286, 1890, 1266, 2077, 337, 341, 5860, 51516], "temperature": 0.0, "avg_logprob": -0.2778597354888916, "compression_ratio": 1.3971631205673758, "no_speech_prob": 0.08764351904392242}, {"id": 56, "seek": 57400, "start": 574.6, "end": 597.4, "text": " hoping for any questions from you so if I am if you thank you for this presentation I have two", "tokens": [50394, 7159, 337, 604, 1651, 490, 291, 370, 498, 286, 669, 498, 291, 1309, 291, 337, 341, 5860, 286, 362, 732, 51534], "temperature": 0.0, "avg_logprob": -0.16944475795911706, "compression_ratio": 1.5196850393700787, "no_speech_prob": 0.028304213657975197}, {"id": 57, "seek": 57400, "start": 597.4, "end": 603.2, "text": " questions one of them is technical and the other one is about money I'll start with the money this", "tokens": [51534, 1651, 472, 295, 552, 307, 6191, 293, 264, 661, 472, 307, 466, 1460, 286, 603, 722, 365, 264, 1460, 341, 51824], "temperature": 0.0, "avg_logprob": -0.16944475795911706, "compression_ratio": 1.5196850393700787, "no_speech_prob": 0.028304213657975197}, {"id": 58, "seek": 60320, "start": 603.4000000000001, "end": 610.48, "text": " specific project how is it sustained that do you have revenue for this specific project and so what's", "tokens": [50374, 2685, 1716, 577, 307, 309, 23389, 300, 360, 291, 362, 9324, 337, 341, 2685, 1716, 293, 370, 437, 311, 50728], "temperature": 0.0, "avg_logprob": -0.20082792368802158, "compression_ratio": 1.5625, "no_speech_prob": 0.04123617336153984}, {"id": 59, "seek": 60320, "start": 610.48, "end": 619.44, "text": " the business and then the second question was what kind of power of computing power do you need to", "tokens": [50728, 264, 1606, 293, 550, 264, 1150, 1168, 390, 437, 733, 295, 1347, 295, 15866, 1347, 360, 291, 643, 281, 51176], "temperature": 0.0, "avg_logprob": -0.20082792368802158, "compression_ratio": 1.5625, "no_speech_prob": 0.04123617336153984}, {"id": 60, "seek": 61944, "start": 619.44, "end": 634.8000000000001, "text": " run this for a small organization maybe okay so the goal here for our business is very clear we", "tokens": [50364, 1190, 341, 337, 257, 1359, 4475, 1310, 1392, 370, 264, 3387, 510, 337, 527, 1606, 307, 588, 1850, 321, 51132], "temperature": 0.0, "avg_logprob": -0.2821618056878811, "compression_ratio": 1.4651162790697674, "no_speech_prob": 0.046665798872709274}, {"id": 61, "seek": 61944, "start": 634.8000000000001, "end": 644.4000000000001, "text": " offer as linear go around services for tuning models okay so this particular platform is also", "tokens": [51132, 2626, 382, 8213, 352, 926, 3328, 337, 15164, 5245, 1392, 370, 341, 1729, 3663, 307, 611, 51612], "temperature": 0.0, "avg_logprob": -0.2821618056878811, "compression_ratio": 1.4651162790697674, "no_speech_prob": 0.046665798872709274}, {"id": 62, "seek": 64440, "start": 644.48, "end": 653.88, "text": " intended to be a SAS service where the user will be at some point when we have time to develop", "tokens": [50368, 10226, 281, 312, 257, 33441, 2643, 689, 264, 4195, 486, 312, 412, 512, 935, 562, 321, 362, 565, 281, 1499, 50838], "temperature": 0.0, "avg_logprob": -0.21108401905406604, "compression_ratio": 1.6162790697674418, "no_speech_prob": 0.26633524894714355}, {"id": 63, "seek": 64440, "start": 653.88, "end": 665.16, "text": " a subscription for that users will be able to use our system as a SAS but the source remains", "tokens": [50838, 257, 17231, 337, 300, 5022, 486, 312, 1075, 281, 764, 527, 1185, 382, 257, 33441, 457, 264, 4009, 7023, 51402], "temperature": 0.0, "avg_logprob": -0.21108401905406604, "compression_ratio": 1.6162790697674418, "no_speech_prob": 0.26633524894714355}, {"id": 64, "seek": 64440, "start": 665.16, "end": 671.68, "text": " free and it can be austere on premise with the same features like away like like always at", "tokens": [51402, 1737, 293, 309, 393, 312, 34916, 323, 322, 22045, 365, 264, 912, 4122, 411, 1314, 411, 411, 1009, 412, 51728], "temperature": 0.0, "avg_logprob": -0.21108401905406604, "compression_ratio": 1.6162790697674418, "no_speech_prob": 0.26633524894714355}, {"id": 65, "seek": 67168, "start": 671.68, "end": 679.5999999999999, "text": " the Nogura we have no premium plan or whatever but we just feel that it's convenient to just host", "tokens": [50364, 264, 426, 664, 2991, 321, 362, 572, 12049, 1393, 420, 2035, 457, 321, 445, 841, 300, 309, 311, 10851, 281, 445, 3975, 50760], "temperature": 0.0, "avg_logprob": -0.35053510251252545, "compression_ratio": 1.3617021276595744, "no_speech_prob": 0.05428538843989372}, {"id": 66, "seek": 67168, "start": 679.5999999999999, "end": 689.04, "text": " directly a solution as a SAS offer the other question was about the computing power okay so it", "tokens": [50760, 3838, 257, 3827, 382, 257, 33441, 2626, 264, 661, 1168, 390, 466, 264, 15866, 1347, 1392, 370, 309, 51232], "temperature": 0.0, "avg_logprob": -0.35053510251252545, "compression_ratio": 1.3617021276595744, "no_speech_prob": 0.05428538843989372}, {"id": 67, "seek": 68904, "start": 689.0799999999999, "end": 701.8399999999999, "text": " requires quite a lot but we batch the process of the transcriptions and the long models inferences", "tokens": [50366, 7029, 1596, 257, 688, 457, 321, 15245, 264, 1399, 295, 264, 24444, 626, 293, 264, 938, 5245, 13596, 2667, 51004], "temperature": 0.0, "avg_logprob": -0.2137379853621773, "compression_ratio": 1.4846153846153847, "no_speech_prob": 0.3376888036727905}, {"id": 68, "seek": 68904, "start": 701.8399999999999, "end": 710.56, "text": " we just provide the best default way of doing stuff and if you dig in the code you'll see that", "tokens": [51004, 321, 445, 2893, 264, 1151, 7576, 636, 295, 884, 1507, 293, 498, 291, 2528, 294, 264, 3089, 291, 603, 536, 300, 51440], "temperature": 0.0, "avg_logprob": -0.2137379853621773, "compression_ratio": 1.4846153846153847, "no_speech_prob": 0.3376888036727905}, {"id": 69, "seek": 71056, "start": 710.92, "end": 719.1999999999999, "text": " our runtime supports kind of everything you can dream of we can run on CPU of course it will be a", "tokens": [50382, 527, 34474, 9346, 733, 295, 1203, 291, 393, 3055, 295, 321, 393, 1190, 322, 13199, 295, 1164, 309, 486, 312, 257, 50796], "temperature": 0.0, "avg_logprob": -0.1662424856157445, "compression_ratio": 1.5698924731182795, "no_speech_prob": 0.07580770552158356}, {"id": 70, "seek": 71056, "start": 719.1999999999999, "end": 727.56, "text": " little bit clumsy we work on CPU with Intel extensions for transformers and so on and we of", "tokens": [50796, 707, 857, 44640, 321, 589, 322, 13199, 365, 19762, 25129, 337, 4088, 433, 293, 370, 322, 293, 321, 295, 51214], "temperature": 0.0, "avg_logprob": -0.1662424856157445, "compression_ratio": 1.5698924731182795, "no_speech_prob": 0.07580770552158356}, {"id": 71, "seek": 71056, "start": 727.56, "end": 735.92, "text": " course work on GPU if you want to process a large batch of transcriptions when the hosting on premises", "tokens": [51214, 1164, 589, 322, 18407, 498, 291, 528, 281, 1399, 257, 2416, 15245, 295, 24444, 626, 562, 264, 16058, 322, 34266, 51632], "temperature": 0.0, "avg_logprob": -0.1662424856157445, "compression_ratio": 1.5698924731182795, "no_speech_prob": 0.07580770552158356}, {"id": 72, "seek": 74056, "start": 741.28, "end": 749.0, "text": " any other questions we got time for one more how do you handle a typically French language", "tokens": [50400, 604, 661, 1651, 321, 658, 565, 337, 472, 544, 577, 360, 291, 4813, 257, 5850, 5522, 2856, 50786], "temperature": 0.0, "avg_logprob": -0.2869552286659799, "compression_ratio": 1.55, "no_speech_prob": 0.00682049710303545}, {"id": 73, "seek": 74056, "start": 749.0, "end": 759.1199999999999, "text": " setting which is irony how do you handle because of the keywords and so on the typically French", "tokens": [50786, 3287, 597, 307, 35365, 577, 360, 291, 4813, 570, 295, 264, 21009, 293, 370, 322, 264, 5850, 5522, 51292], "temperature": 0.0, "avg_logprob": -0.2869552286659799, "compression_ratio": 1.55, "no_speech_prob": 0.00682049710303545}, {"id": 74, "seek": 75912, "start": 760.08, "end": 766.08, "text": " set which is irony meaning that the speaker means exactly the opposite of what he says", "tokens": [50412, 992, 597, 307, 35365, 3620, 300, 264, 8145, 1355, 2293, 264, 6182, 295, 437, 415, 1619, 50712], "temperature": 0.0, "avg_logprob": -0.34690032686506, "compression_ratio": 1.4793388429752066, "no_speech_prob": 0.04590141028165817}, {"id": 75, "seek": 75912, "start": 772.08, "end": 783.36, "text": " he's asking how do you do with the irony of French language of course using the you know the", "tokens": [51012, 415, 311, 3365, 577, 360, 291, 360, 365, 264, 35365, 295, 5522, 2856, 295, 1164, 1228, 264, 291, 458, 264, 51576], "temperature": 0.0, "avg_logprob": -0.34690032686506, "compression_ratio": 1.4793388429752066, "no_speech_prob": 0.04590141028165817}, {"id": 76, "seek": 78336, "start": 783.44, "end": 799.32, "text": " irony mark you know this one thank you Damian all right we're gonna start the next talk here in two", "tokens": [50368, 35365, 1491, 291, 458, 341, 472, 1309, 291, 5885, 952, 439, 558, 321, 434, 799, 722, 264, 958, 751, 510, 294, 732, 51162], "temperature": 0.0, "avg_logprob": -0.3073118414197649, "compression_ratio": 1.2298850574712643, "no_speech_prob": 0.03297821804881096}, {"id": 77, "seek": 78336, "start": 799.32, "end": 799.76, "text": " minutes", "tokens": [51162, 2077, 51184], "temperature": 0.0, "avg_logprob": -0.3073118414197649, "compression_ratio": 1.2298850574712643, "no_speech_prob": 0.03297821804881096}], "language": "en"}