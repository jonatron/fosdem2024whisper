{"text": " Then let's start. We would like to talk about Dora-Arres, which is a project to create a modern data flow framework for robotic applications. The idea of a data flow framework is that you split your applications into lots of small nodes that each perform some operation on the data, and then you can send the data by message passing to the next node, and this way you get a very isolated architecture. If one component goes down, for example, then the other components can keep on running, so you have very reliable architecture. For example, on the right in this example we have a webcam node that generates images, and these pictures are sent both to a plot node and an object detection node. The object detection uses an object detection algorithm to detect common objects in the image, and if it detects any it sends a bounding box to the plot node as well. The plot node can then combine the two and draw a rectangle around the detected objects in the image and print it out on the display or something. One nice feature of this design is that you can also split your data flow across multiple machines. For example, if you have an embedded system that has limited processing power, you can offload heavy computations to a remote machine and use the network for sending back the process data. Also, you have these nice boundaries, so by observing all the messages that are sent you can get a pretty good idea of what your system is doing. You have also, for example, the option to lock all the messages and try to replay them later on a debug system to debug issues. The most popular frameworks that implement this pattern are ROS and ROS2. They are both CNC++ based and have unfortunately quite a complex build system which can be a bit intimidating to beginners, but they are quite mature and widely used in both research and industry. The motivation for Dora was that we want to make the creation of robotic applications simple and fast, and we want to focus on modern languages like ROS and Python, but we still want to keep supporting CNC++. We also have plans to support WebAssembly in the future to have even more isolation between components. For the build system we try to keep things as simple as possible and to use the build system of the different languages when possible. So, for example, if you are writing one node in ROS, then you should just use the CrateZero dependency and run a cargo build command without any additional project specific tooling. And also we want to make it easy to integrate with latest technologies such as Python, AI models that you should be able to just use without much setup. For the general design we decided to make each node a separate process to benefit from the isolation and fairness guarantees of the operating system and to give authors of nodes a lot of flexibility because you have full control over the process so you can access devices or include some libraries that you need and so on. And the nodes communicate by sending messages as we said. So, for this we decided to use a declarative approach. We have a YAML file that lists all the outputs and inputs and how they map to each other so you have like a single crown of truth how your data flow graph is laid out. One feature that we are quite proud of is the zero copy implementation that is transparently added whenever the sender and receiver are on the same machine. So in this case we use chat memory to pass the message contents and we encode the messages using the Apache Arrow data format which allows us to access the data and process the data without any copying as well. So for example, on the right we could have a Rust node that sends some data to a Python node, the Python node in its Python runtime does some processing using NumPy for example and using this Apache Arrow format, all of that is possible without any serialization or copying of the data which is quite nice and also results in a quite nice performance. So here we see the latency of a Python node in Rust 2 compared with Dora and we see that for large messages the latency is much better because we don't need to copy the data or serialize the data at all. We also for compatibility try to create a Rust 2 bridge to allow the step by step migration of existing Rust 2 applications and also to use the existing Rust 2 tooling which is quite mature for our Dora nodes because we don't have that kind of tooling yet. For the implementation we decided to do the interfacing at the DDS level, so at the middleware level, so we don't link to the Rust 2 libraries but instead we have our own DDS implementation and this way the build process stays simple and we don't need to complicate things but we still are able to auto generate bindings for Rust in C++ because we pass the message definition files of Rust 2 and we also have automatic type conversions between the Rust 2 message types, the error data types and the native Rust or Python types. Yeah and lastly, so we have two more features, one is open telemetry, so it's for everything that is metadata, we don't want you to learn a new way of logging your logs, tracing your traces and having metrics, so we're using open telemetry which is an open format that is available on many languages, C++ Rust and it can connect to many back end as well, so if you're already using some promissory graphana you can just use Dora and use your back end really quickly and have all your data coming in and there's also a lot of applications that use this open telemetry such as website, servers and so you could have your Dora data at the same time as your other application data. So that's really useful and then we have also a hot reloading feature that helps us basically reload our application without having to reset the robots, this thing can take a bit of time and sometimes there's some calibration so we found it really useful to be able to change the code, change the logic without having to reset the robot and now that we can generate code with generative AI with chargeability as you probably tried out or mistral AI on a local machine, it's really useful and actually it's very simple to code, you can use, you just have to check your state and if the state doesn't change, if it's compatible you can just swap state and it works, so yeah I'm going to do a quick demo because I think it's probably easier for you to understand, so I have a robot, I have a microphone, I have a speaker, I'm going to use whisper as a node to convert my speech to text and then I'm going to use an LLM to change the text to code and using the hot reloading feature it's able to directly change the behavior of the robot and then I have two webcams just so that everyone can see and then I have additional node but I'll let you go into detail later because I don't have too much time, so this is kind of an overview of what is happening underneath and yeah let's do a quick demo, so I'm going to start my graph instead of my computer and fortunately I can't share my screen because somehow my event is not working with the HDMI so I'm just going to use my microphone to try to work with the robot, so let's say I have a robot here, I'm going to say okay, can you set the rotation to 50 and so now whisper is going to convert what I said to code and then the code is going to be hot reloaded in the robot in real time hopefully, so the first thing is takes a bit of time but it should get there at some point, I'm just going to try again, can you change the rotation to 50 please, just give me one sec and normally it should move, there is no problem, so I go and so this is just code, right, it's not something that I've pre-implemented, it's not and we can, if people want to have a look, we can have a look deep behind the back and talk about it, I can make him move but the table is really small so maybe I can just try something very small, yeah, can you set the variable x to 1, so yeah, okay he didn't understand, he didn't understand the Bible, so yeah, can you set the x variable to 1, okay, the node should move, yeah, so you can really, you have all the control, you can make him move, rotate, thing, just going to hope it's not going too far but hopefully it should be okay, yeah, and yeah, so this is like really simple logic, it's just changing one variable but I can also use charge-pt which is way more powerful to generate way more complicated code, okay, so this is kind of, if you already used charge-pt before, you will see that it's not always reliable, so it should work but it's not a promise, right, and I'm sorry if it doesn't work and I probably have to do some debugging of the code that charge-pt generate but let's say I say, can you set the rotation according to bounding boxes, so you can't probably see but I'm running an object detection on my computer and so he's able to get bounding boxes, you've probably already seen demo with deep learning and pie torch and things like that and so it's actually very simple, right, if you look into details of many demos and so it's actually very simple to get bounding boxes, so I'm getting the webcam, I'm sending it to object detection and then I'm plotting it on my computer but I'm also sending it to the planning which is the thing that is controlling the robot and so then, so charge-ptd has to link this bounding box to a rotation axis which is actually quite complicated because the rotation is in angles and then only what he has is bounding boxes with x, y on a, like an image frame, right, so it's probably like 20 pixel left, 20 pixel right and so he has to generate this code but normally it should work and so charge-pt takes about 30 seconds to one minute, maybe more depending on the file length because it's per token right and so now it's still like talking with charge-pt I think and now it's finished so it should be able to move, I'm just going to log it, I'm sorry if I take a bit of time and, alright, so there was a bit of an issue, the true value of an array is complicated so, alright, just give me one sec, center x ratio, center x, center x, okay and then I'm going to put a zero here and normally it should work, is it moving? Oh yeah, okay, so now he should move according to what he sees, so if I'm here maybe he's going to move like here, okay, yeah and now it should stop moving, yeah, it's like doing some PID stuff, right, like kind of like brewing so, and so if I move here, he's going to move from here, yeah and so this is the whole logic it was charge-pt, I didn't code anything, I'm probably too lazy to code this thing but yeah, but you can see the idea so if, yeah, that's kind of where we are now and, yeah, time's up, okay, so here's the feature we have and if you have any features you can let us know and we'll try our best to make it happen, sometimes it doesn't happen but we'll try our best and yeah, so well, thanks for listening, yeah, thanks for having us, thanks. I have any questions? Hi, it was very interesting, when you showed the graph of the latency with ROS2 versus Dora, do you know what middleware you were using to compare against, because obviously ROS2 has a whole bunch of different middlewares that you can use some of shared memory, some over the loop back, do you know which one it was? I think it was default DDS. Yeah, it was default DDS. Or TPS or? Now I can't remember exactly the details but we tried to use the exact, like, tutorial version of ROS2 and in Python you can't do like shared memory things so like, we tried to use MW isorox thing with Python but it didn't really work out, yeah. And on real time stuff, do you have bindings for say POSIX, Tread Priority setting and other real time integrations or is that still in the Python? Yeah, that's probably things that we can improve but actually there's a lot of time spent on serialization, copying and so this is where we think that the biggest difference is, yeah. But we can definitely look more into detail into the benchmark if you're interested, yeah. I'll take up one over there. Right, I'll give you some problems. Oh yeah, it's moving because of bounding boxes, yeah, if you see. Hello, I'm curious why you chose to have an, over here, an explicit definition of all the kind of topics of communication. Like why use that instead of kind of the raw style just publish and subscribe without, blindly publish and blindly subscribe? Do you want to answer? Okay, okay. Yeah, I think it was just to have additional insight at the beginning directly. We also plan, I think if we go to the road again, we also plan this dynamic data flow feature again because in some cases it's quite useful to add nodes at runtime but for like getting started it was useful to be able to generate a graph of the whole thing and yeah, so. Okay, one more question. There was a guy over here, yeah. Hi, sorry, very interesting. Maybe I missed it but how do you communicate across different computers which networking provider are using? Right, so there's an SDK and so basically you can send messages with a protocol buffer and there's a small computer and it's interesting and the video stream is using H.264. Yeah, so I was talking about like Protobuf but just like what is like, I don't know, DDS for raws, then now they are moving to senior or what are you, how are you sending the messages actually? Okay, so now I'm just using the SDK of the robot for communicating, yeah, so it's very simple. In the future if we have remote machine we can use TCP and maybe Xeno type of thing for Dora itself. Okay, so Dora now it's only one computer. Now it's kind of one computer. Yeah, we have like basic TCP support for remote machines but nothing too optimized. Yeah, but it's definitely something we want to do. May I ask another one? Yeah, so have you tried R2R like the another raws Rust binding which is also like using the raws C library but wrapped and it doesn't use all the complicated, the amend and what not, cash is building with cargo which I agree it's a good advantage. So maybe it's interesting to check that library also. Yeah, absolutely, yeah, we definitely look into the raws thing and there's many clients. We're actually working on the raws to bridge as well and so we are using the Rust client from like an unofficial raws client that enables you to not use the complex like raws to build system and still use raws to. So this is how things are. Okay, so the robots are ticking over. Okay, thank you very much. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 7.0, "text": " Then let's start. We would like to talk about Dora-Arres, which is a project to create a", "tokens": [50364, 1396, 718, 311, 722, 13, 492, 576, 411, 281, 751, 466, 413, 3252, 12, 10683, 495, 11, 597, 307, 257, 1716, 281, 1884, 257, 50714], "temperature": 0.0, "avg_logprob": -0.27730679512023926, "compression_ratio": 1.536723163841808, "no_speech_prob": 0.06590074300765991}, {"id": 1, "seek": 0, "start": 11.64, "end": 18.64, "text": " modern data flow framework for robotic applications. The idea of a data flow framework is that", "tokens": [50946, 4363, 1412, 3095, 8388, 337, 30468, 5821, 13, 440, 1558, 295, 257, 1412, 3095, 8388, 307, 300, 51296], "temperature": 0.0, "avg_logprob": -0.27730679512023926, "compression_ratio": 1.536723163841808, "no_speech_prob": 0.06590074300765991}, {"id": 2, "seek": 0, "start": 19.52, "end": 24.560000000000002, "text": " you split your applications into lots of small nodes that each perform some operation on", "tokens": [51340, 291, 7472, 428, 5821, 666, 3195, 295, 1359, 13891, 300, 1184, 2042, 512, 6916, 322, 51592], "temperature": 0.0, "avg_logprob": -0.27730679512023926, "compression_ratio": 1.536723163841808, "no_speech_prob": 0.06590074300765991}, {"id": 3, "seek": 2456, "start": 24.56, "end": 30.32, "text": " the data, and then you can send the data by message passing to the next node, and this", "tokens": [50364, 264, 1412, 11, 293, 550, 291, 393, 2845, 264, 1412, 538, 3636, 8437, 281, 264, 958, 9984, 11, 293, 341, 50652], "temperature": 0.0, "avg_logprob": -0.2014326532203031, "compression_ratio": 1.7389162561576355, "no_speech_prob": 0.09460573643445969}, {"id": 4, "seek": 2456, "start": 30.32, "end": 37.32, "text": " way you get a very isolated architecture. If one component goes down, for example, then", "tokens": [50652, 636, 291, 483, 257, 588, 14621, 9482, 13, 759, 472, 6542, 1709, 760, 11, 337, 1365, 11, 550, 51002], "temperature": 0.0, "avg_logprob": -0.2014326532203031, "compression_ratio": 1.7389162561576355, "no_speech_prob": 0.09460573643445969}, {"id": 5, "seek": 2456, "start": 38.12, "end": 43.879999999999995, "text": " the other components can keep on running, so you have very reliable architecture. For", "tokens": [51042, 264, 661, 6677, 393, 1066, 322, 2614, 11, 370, 291, 362, 588, 12924, 9482, 13, 1171, 51330], "temperature": 0.0, "avg_logprob": -0.2014326532203031, "compression_ratio": 1.7389162561576355, "no_speech_prob": 0.09460573643445969}, {"id": 6, "seek": 2456, "start": 43.879999999999995, "end": 50.68, "text": " example, on the right in this example we have a webcam node that generates images, and these", "tokens": [51330, 1365, 11, 322, 264, 558, 294, 341, 1365, 321, 362, 257, 39490, 9984, 300, 23815, 5267, 11, 293, 613, 51670], "temperature": 0.0, "avg_logprob": -0.2014326532203031, "compression_ratio": 1.7389162561576355, "no_speech_prob": 0.09460573643445969}, {"id": 7, "seek": 5068, "start": 50.72, "end": 57.72, "text": " pictures are sent both to a plot node and an object detection node. The object detection", "tokens": [50366, 5242, 366, 2279, 1293, 281, 257, 7542, 9984, 293, 364, 2657, 17784, 9984, 13, 440, 2657, 17784, 50716], "temperature": 0.0, "avg_logprob": -0.1596654142652239, "compression_ratio": 1.9617486338797814, "no_speech_prob": 0.010211029089987278}, {"id": 8, "seek": 5068, "start": 57.72, "end": 64.0, "text": " uses an object detection algorithm to detect common objects in the image, and if it detects", "tokens": [50716, 4960, 364, 2657, 17784, 9284, 281, 5531, 2689, 6565, 294, 264, 3256, 11, 293, 498, 309, 5531, 82, 51030], "temperature": 0.0, "avg_logprob": -0.1596654142652239, "compression_ratio": 1.9617486338797814, "no_speech_prob": 0.010211029089987278}, {"id": 9, "seek": 5068, "start": 64.0, "end": 68.92, "text": " any it sends a bounding box to the plot node as well. The plot node can then combine the", "tokens": [51030, 604, 309, 14790, 257, 5472, 278, 2424, 281, 264, 7542, 9984, 382, 731, 13, 440, 7542, 9984, 393, 550, 10432, 264, 51276], "temperature": 0.0, "avg_logprob": -0.1596654142652239, "compression_ratio": 1.9617486338797814, "no_speech_prob": 0.010211029089987278}, {"id": 10, "seek": 5068, "start": 68.92, "end": 75.92, "text": " two and draw a rectangle around the detected objects in the image and print it out on the", "tokens": [51276, 732, 293, 2642, 257, 21930, 926, 264, 21896, 6565, 294, 264, 3256, 293, 4482, 309, 484, 322, 264, 51626], "temperature": 0.0, "avg_logprob": -0.1596654142652239, "compression_ratio": 1.9617486338797814, "no_speech_prob": 0.010211029089987278}, {"id": 11, "seek": 7592, "start": 76.92, "end": 83.92, "text": " display or something. One nice feature of this design is that you can also split your data flow", "tokens": [50414, 4674, 420, 746, 13, 1485, 1481, 4111, 295, 341, 1715, 307, 300, 291, 393, 611, 7472, 428, 1412, 3095, 50764], "temperature": 0.0, "avg_logprob": -0.22661339364400723, "compression_ratio": 1.6, "no_speech_prob": 0.0021106800995767117}, {"id": 12, "seek": 7592, "start": 84.96000000000001, "end": 90.16, "text": " across multiple machines. For example, if you have an embedded system that has limited", "tokens": [50816, 2108, 3866, 8379, 13, 1171, 1365, 11, 498, 291, 362, 364, 16741, 1185, 300, 575, 5567, 51076], "temperature": 0.0, "avg_logprob": -0.22661339364400723, "compression_ratio": 1.6, "no_speech_prob": 0.0021106800995767117}, {"id": 13, "seek": 7592, "start": 90.16, "end": 95.56, "text": " processing power, you can offload heavy computations to a remote machine and use the network for", "tokens": [51076, 9007, 1347, 11, 291, 393, 766, 2907, 4676, 2807, 763, 281, 257, 8607, 3479, 293, 764, 264, 3209, 337, 51346], "temperature": 0.0, "avg_logprob": -0.22661339364400723, "compression_ratio": 1.6, "no_speech_prob": 0.0021106800995767117}, {"id": 14, "seek": 7592, "start": 95.56, "end": 102.24000000000001, "text": " sending back the process data. Also, you have these nice boundaries, so by observing all", "tokens": [51346, 7750, 646, 264, 1399, 1412, 13, 2743, 11, 291, 362, 613, 1481, 13180, 11, 370, 538, 22107, 439, 51680], "temperature": 0.0, "avg_logprob": -0.22661339364400723, "compression_ratio": 1.6, "no_speech_prob": 0.0021106800995767117}, {"id": 15, "seek": 10224, "start": 102.28, "end": 106.96, "text": " the messages that are sent you can get a pretty good idea of what your system is doing. You", "tokens": [50366, 264, 7897, 300, 366, 2279, 291, 393, 483, 257, 1238, 665, 1558, 295, 437, 428, 1185, 307, 884, 13, 509, 50600], "temperature": 0.0, "avg_logprob": -0.16412115097045898, "compression_ratio": 1.5584415584415585, "no_speech_prob": 0.006166819017380476}, {"id": 16, "seek": 10224, "start": 106.96, "end": 112.47999999999999, "text": " have also, for example, the option to lock all the messages and try to replay them later", "tokens": [50600, 362, 611, 11, 337, 1365, 11, 264, 3614, 281, 4017, 439, 264, 7897, 293, 853, 281, 23836, 552, 1780, 50876], "temperature": 0.0, "avg_logprob": -0.16412115097045898, "compression_ratio": 1.5584415584415585, "no_speech_prob": 0.006166819017380476}, {"id": 17, "seek": 10224, "start": 112.47999999999999, "end": 119.47999999999999, "text": " on a debug system to debug issues. The most popular frameworks that implement this pattern", "tokens": [50876, 322, 257, 24083, 1185, 281, 24083, 2663, 13, 440, 881, 3743, 29834, 300, 4445, 341, 5102, 51226], "temperature": 0.0, "avg_logprob": -0.16412115097045898, "compression_ratio": 1.5584415584415585, "no_speech_prob": 0.006166819017380476}, {"id": 18, "seek": 10224, "start": 120.84, "end": 127.84, "text": " are ROS and ROS2. They are both CNC++ based and have unfortunately quite a complex build", "tokens": [51294, 366, 31904, 293, 31904, 17, 13, 814, 366, 1293, 48714, 25472, 2361, 293, 362, 7015, 1596, 257, 3997, 1322, 51644], "temperature": 0.0, "avg_logprob": -0.16412115097045898, "compression_ratio": 1.5584415584415585, "no_speech_prob": 0.006166819017380476}, {"id": 19, "seek": 12784, "start": 128.84, "end": 135.84, "text": " system which can be a bit intimidating to beginners, but they are quite mature and widely used in", "tokens": [50414, 1185, 597, 393, 312, 257, 857, 29714, 281, 26992, 11, 457, 436, 366, 1596, 14442, 293, 13371, 1143, 294, 50764], "temperature": 0.0, "avg_logprob": -0.20727720605321678, "compression_ratio": 1.548936170212766, "no_speech_prob": 0.009704814292490482}, {"id": 20, "seek": 12784, "start": 135.96, "end": 142.96, "text": " both research and industry. The motivation for Dora was that we want to make the creation", "tokens": [50770, 1293, 2132, 293, 3518, 13, 440, 12335, 337, 413, 3252, 390, 300, 321, 528, 281, 652, 264, 8016, 51120], "temperature": 0.0, "avg_logprob": -0.20727720605321678, "compression_ratio": 1.548936170212766, "no_speech_prob": 0.009704814292490482}, {"id": 21, "seek": 12784, "start": 145.04, "end": 150.36, "text": " of robotic applications simple and fast, and we want to focus on modern languages like", "tokens": [51224, 295, 30468, 5821, 2199, 293, 2370, 11, 293, 321, 528, 281, 1879, 322, 4363, 8650, 411, 51490], "temperature": 0.0, "avg_logprob": -0.20727720605321678, "compression_ratio": 1.548936170212766, "no_speech_prob": 0.009704814292490482}, {"id": 22, "seek": 12784, "start": 150.36, "end": 155.52, "text": " ROS and Python, but we still want to keep supporting CNC++. We also have plans to support", "tokens": [51490, 31904, 293, 15329, 11, 457, 321, 920, 528, 281, 1066, 7231, 48714, 25472, 13, 492, 611, 362, 5482, 281, 1406, 51748], "temperature": 0.0, "avg_logprob": -0.20727720605321678, "compression_ratio": 1.548936170212766, "no_speech_prob": 0.009704814292490482}, {"id": 23, "seek": 15552, "start": 155.56, "end": 161.76000000000002, "text": " WebAssembly in the future to have even more isolation between components. For the build", "tokens": [50366, 9573, 10884, 19160, 294, 264, 2027, 281, 362, 754, 544, 16001, 1296, 6677, 13, 1171, 264, 1322, 50676], "temperature": 0.0, "avg_logprob": -0.2449790841282004, "compression_ratio": 1.6036363636363635, "no_speech_prob": 0.013347023166716099}, {"id": 24, "seek": 15552, "start": 161.76000000000002, "end": 165.48000000000002, "text": " system we try to keep things as simple as possible and to use the build system of the", "tokens": [50676, 1185, 321, 853, 281, 1066, 721, 382, 2199, 382, 1944, 293, 281, 764, 264, 1322, 1185, 295, 264, 50862], "temperature": 0.0, "avg_logprob": -0.2449790841282004, "compression_ratio": 1.6036363636363635, "no_speech_prob": 0.013347023166716099}, {"id": 25, "seek": 15552, "start": 165.48000000000002, "end": 170.0, "text": " different languages when possible. So, for example, if you are writing one node in ROS,", "tokens": [50862, 819, 8650, 562, 1944, 13, 407, 11, 337, 1365, 11, 498, 291, 366, 3579, 472, 9984, 294, 31904, 11, 51088], "temperature": 0.0, "avg_logprob": -0.2449790841282004, "compression_ratio": 1.6036363636363635, "no_speech_prob": 0.013347023166716099}, {"id": 26, "seek": 15552, "start": 170.0, "end": 175.32000000000002, "text": " then you should just use the CrateZero dependency and run a cargo build command without any", "tokens": [51088, 550, 291, 820, 445, 764, 264, 383, 4404, 57, 2032, 33621, 293, 1190, 257, 19449, 1322, 5622, 1553, 604, 51354], "temperature": 0.0, "avg_logprob": -0.2449790841282004, "compression_ratio": 1.6036363636363635, "no_speech_prob": 0.013347023166716099}, {"id": 27, "seek": 15552, "start": 175.32000000000002, "end": 182.32000000000002, "text": " additional project specific tooling. And also we want to make it easy to integrate with", "tokens": [51354, 4497, 1716, 2685, 46593, 13, 400, 611, 321, 528, 281, 652, 309, 1858, 281, 13365, 365, 51704], "temperature": 0.0, "avg_logprob": -0.2449790841282004, "compression_ratio": 1.6036363636363635, "no_speech_prob": 0.013347023166716099}, {"id": 28, "seek": 18232, "start": 182.44, "end": 189.04, "text": " latest technologies such as Python, AI models that you should be able to just use without", "tokens": [50370, 6792, 7943, 1270, 382, 15329, 11, 7318, 5245, 300, 291, 820, 312, 1075, 281, 445, 764, 1553, 50700], "temperature": 0.0, "avg_logprob": -0.16177350362141926, "compression_ratio": 1.5594713656387664, "no_speech_prob": 0.0045790825970470905}, {"id": 29, "seek": 18232, "start": 189.04, "end": 196.04, "text": " much setup. For the general design we decided to make each node a separate process to benefit", "tokens": [50700, 709, 8657, 13, 1171, 264, 2674, 1715, 321, 3047, 281, 652, 1184, 9984, 257, 4994, 1399, 281, 5121, 51050], "temperature": 0.0, "avg_logprob": -0.16177350362141926, "compression_ratio": 1.5594713656387664, "no_speech_prob": 0.0045790825970470905}, {"id": 30, "seek": 18232, "start": 196.51999999999998, "end": 201.92, "text": " from the isolation and fairness guarantees of the operating system and to give authors", "tokens": [51074, 490, 264, 16001, 293, 29765, 32567, 295, 264, 7447, 1185, 293, 281, 976, 16552, 51344], "temperature": 0.0, "avg_logprob": -0.16177350362141926, "compression_ratio": 1.5594713656387664, "no_speech_prob": 0.0045790825970470905}, {"id": 31, "seek": 18232, "start": 201.92, "end": 208.92, "text": " of nodes a lot of flexibility because you have full control over the process so you", "tokens": [51344, 295, 13891, 257, 688, 295, 12635, 570, 291, 362, 1577, 1969, 670, 264, 1399, 370, 291, 51694], "temperature": 0.0, "avg_logprob": -0.16177350362141926, "compression_ratio": 1.5594713656387664, "no_speech_prob": 0.0045790825970470905}, {"id": 32, "seek": 20892, "start": 208.92, "end": 215.23999999999998, "text": " can access devices or include some libraries that you need and so on. And the nodes communicate", "tokens": [50364, 393, 2105, 5759, 420, 4090, 512, 15148, 300, 291, 643, 293, 370, 322, 13, 400, 264, 13891, 7890, 50680], "temperature": 0.0, "avg_logprob": -0.19055706986757082, "compression_ratio": 1.6209386281588447, "no_speech_prob": 0.00331519590690732}, {"id": 33, "seek": 20892, "start": 215.23999999999998, "end": 220.2, "text": " by sending messages as we said. So, for this we decided to use a declarative approach.", "tokens": [50680, 538, 7750, 7897, 382, 321, 848, 13, 407, 11, 337, 341, 321, 3047, 281, 764, 257, 16694, 1166, 3109, 13, 50928], "temperature": 0.0, "avg_logprob": -0.19055706986757082, "compression_ratio": 1.6209386281588447, "no_speech_prob": 0.00331519590690732}, {"id": 34, "seek": 20892, "start": 220.2, "end": 224.07999999999998, "text": " We have a YAML file that lists all the outputs and inputs and how they map to each other", "tokens": [50928, 492, 362, 257, 398, 2865, 43, 3991, 300, 14511, 439, 264, 23930, 293, 15743, 293, 577, 436, 4471, 281, 1184, 661, 51122], "temperature": 0.0, "avg_logprob": -0.19055706986757082, "compression_ratio": 1.6209386281588447, "no_speech_prob": 0.00331519590690732}, {"id": 35, "seek": 20892, "start": 224.07999999999998, "end": 231.07999999999998, "text": " so you have like a single crown of truth how your data flow graph is laid out. One feature", "tokens": [51122, 370, 291, 362, 411, 257, 2167, 11841, 295, 3494, 577, 428, 1412, 3095, 4295, 307, 9897, 484, 13, 1485, 4111, 51472], "temperature": 0.0, "avg_logprob": -0.19055706986757082, "compression_ratio": 1.6209386281588447, "no_speech_prob": 0.00331519590690732}, {"id": 36, "seek": 20892, "start": 231.83999999999997, "end": 238.11999999999998, "text": " that we are quite proud of is the zero copy implementation that is transparently added", "tokens": [51510, 300, 321, 366, 1596, 4570, 295, 307, 264, 4018, 5055, 11420, 300, 307, 7132, 6420, 3869, 51824], "temperature": 0.0, "avg_logprob": -0.19055706986757082, "compression_ratio": 1.6209386281588447, "no_speech_prob": 0.00331519590690732}, {"id": 37, "seek": 23812, "start": 238.12, "end": 242.56, "text": " whenever the sender and receiver are on the same machine. So in this case we use chat", "tokens": [50364, 5699, 264, 2845, 260, 293, 20086, 366, 322, 264, 912, 3479, 13, 407, 294, 341, 1389, 321, 764, 5081, 50586], "temperature": 0.0, "avg_logprob": -0.20878454001553087, "compression_ratio": 1.6859903381642511, "no_speech_prob": 0.004382554441690445}, {"id": 38, "seek": 23812, "start": 242.56, "end": 248.68, "text": " memory to pass the message contents and we encode the messages using the Apache Arrow", "tokens": [50586, 4675, 281, 1320, 264, 3636, 15768, 293, 321, 2058, 1429, 264, 7897, 1228, 264, 46597, 40269, 50892], "temperature": 0.0, "avg_logprob": -0.20878454001553087, "compression_ratio": 1.6859903381642511, "no_speech_prob": 0.004382554441690445}, {"id": 39, "seek": 23812, "start": 248.68, "end": 255.68, "text": " data format which allows us to access the data and process the data without any copying", "tokens": [50892, 1412, 7877, 597, 4045, 505, 281, 2105, 264, 1412, 293, 1399, 264, 1412, 1553, 604, 27976, 51242], "temperature": 0.0, "avg_logprob": -0.20878454001553087, "compression_ratio": 1.6859903381642511, "no_speech_prob": 0.004382554441690445}, {"id": 40, "seek": 23812, "start": 258.76, "end": 265.76, "text": " as well. So for example, on the right we could have a Rust node that sends some data to a", "tokens": [51396, 382, 731, 13, 407, 337, 1365, 11, 322, 264, 558, 321, 727, 362, 257, 34952, 9984, 300, 14790, 512, 1412, 281, 257, 51746], "temperature": 0.0, "avg_logprob": -0.20878454001553087, "compression_ratio": 1.6859903381642511, "no_speech_prob": 0.004382554441690445}, {"id": 41, "seek": 26576, "start": 265.92, "end": 272.92, "text": " Python node, the Python node in its Python runtime does some processing using NumPy for", "tokens": [50372, 15329, 9984, 11, 264, 15329, 9984, 294, 1080, 15329, 34474, 775, 512, 9007, 1228, 22592, 47, 88, 337, 50722], "temperature": 0.0, "avg_logprob": -0.19757788521902903, "compression_ratio": 1.639269406392694, "no_speech_prob": 0.004121556878089905}, {"id": 42, "seek": 26576, "start": 273.64, "end": 279.28, "text": " example and using this Apache Arrow format, all of that is possible without any serialization", "tokens": [50758, 1365, 293, 1228, 341, 46597, 40269, 7877, 11, 439, 295, 300, 307, 1944, 1553, 604, 17436, 2144, 51040], "temperature": 0.0, "avg_logprob": -0.19757788521902903, "compression_ratio": 1.639269406392694, "no_speech_prob": 0.004121556878089905}, {"id": 43, "seek": 26576, "start": 279.28, "end": 285.4, "text": " or copying of the data which is quite nice and also results in a quite nice performance.", "tokens": [51040, 420, 27976, 295, 264, 1412, 597, 307, 1596, 1481, 293, 611, 3542, 294, 257, 1596, 1481, 3389, 13, 51346], "temperature": 0.0, "avg_logprob": -0.19757788521902903, "compression_ratio": 1.639269406392694, "no_speech_prob": 0.004121556878089905}, {"id": 44, "seek": 26576, "start": 285.4, "end": 291.24, "text": " So here we see the latency of a Python node in Rust 2 compared with Dora and we see that", "tokens": [51346, 407, 510, 321, 536, 264, 27043, 295, 257, 15329, 9984, 294, 34952, 568, 5347, 365, 413, 3252, 293, 321, 536, 300, 51638], "temperature": 0.0, "avg_logprob": -0.19757788521902903, "compression_ratio": 1.639269406392694, "no_speech_prob": 0.004121556878089905}, {"id": 45, "seek": 29124, "start": 291.24, "end": 295.84000000000003, "text": " for large messages the latency is much better because we don't need to copy the data or", "tokens": [50364, 337, 2416, 7897, 264, 27043, 307, 709, 1101, 570, 321, 500, 380, 643, 281, 5055, 264, 1412, 420, 50594], "temperature": 0.0, "avg_logprob": -0.14335808122014426, "compression_ratio": 1.6511627906976745, "no_speech_prob": 0.005702643655240536}, {"id": 46, "seek": 29124, "start": 295.84000000000003, "end": 302.84000000000003, "text": " serialize the data at all. We also for compatibility try to create a Rust 2 bridge to allow the", "tokens": [50594, 17436, 1125, 264, 1412, 412, 439, 13, 492, 611, 337, 34237, 853, 281, 1884, 257, 34952, 568, 7283, 281, 2089, 264, 50944], "temperature": 0.0, "avg_logprob": -0.14335808122014426, "compression_ratio": 1.6511627906976745, "no_speech_prob": 0.005702643655240536}, {"id": 47, "seek": 29124, "start": 305.72, "end": 311.92, "text": " step by step migration of existing Rust 2 applications and also to use the existing", "tokens": [51088, 1823, 538, 1823, 17011, 295, 6741, 34952, 568, 5821, 293, 611, 281, 764, 264, 6741, 51398], "temperature": 0.0, "avg_logprob": -0.14335808122014426, "compression_ratio": 1.6511627906976745, "no_speech_prob": 0.005702643655240536}, {"id": 48, "seek": 29124, "start": 311.92, "end": 317.96000000000004, "text": " Rust 2 tooling which is quite mature for our Dora nodes because we don't have that kind", "tokens": [51398, 34952, 568, 46593, 597, 307, 1596, 14442, 337, 527, 413, 3252, 13891, 570, 321, 500, 380, 362, 300, 733, 51700], "temperature": 0.0, "avg_logprob": -0.14335808122014426, "compression_ratio": 1.6511627906976745, "no_speech_prob": 0.005702643655240536}, {"id": 49, "seek": 31796, "start": 317.96, "end": 323.03999999999996, "text": " of tooling yet. For the implementation we decided to do the interfacing at the DDS level,", "tokens": [50364, 295, 46593, 1939, 13, 1171, 264, 11420, 321, 3047, 281, 360, 264, 14510, 5615, 412, 264, 413, 11844, 1496, 11, 50618], "temperature": 0.0, "avg_logprob": -0.18755279887806287, "compression_ratio": 1.6372093023255814, "no_speech_prob": 0.0027931651566177607}, {"id": 50, "seek": 31796, "start": 323.03999999999996, "end": 329.03999999999996, "text": " so at the middleware level, so we don't link to the Rust 2 libraries but instead we have", "tokens": [50618, 370, 412, 264, 2808, 3039, 1496, 11, 370, 321, 500, 380, 2113, 281, 264, 34952, 568, 15148, 457, 2602, 321, 362, 50918], "temperature": 0.0, "avg_logprob": -0.18755279887806287, "compression_ratio": 1.6372093023255814, "no_speech_prob": 0.0027931651566177607}, {"id": 51, "seek": 31796, "start": 329.71999999999997, "end": 336.71999999999997, "text": " our own DDS implementation and this way the build process stays simple and we don't need", "tokens": [50952, 527, 1065, 413, 11844, 11420, 293, 341, 636, 264, 1322, 1399, 10834, 2199, 293, 321, 500, 380, 643, 51302], "temperature": 0.0, "avg_logprob": -0.18755279887806287, "compression_ratio": 1.6372093023255814, "no_speech_prob": 0.0027931651566177607}, {"id": 52, "seek": 31796, "start": 336.91999999999996, "end": 342.91999999999996, "text": " to complicate things but we still are able to auto generate bindings for Rust in C++", "tokens": [51312, 281, 1209, 8700, 721, 457, 321, 920, 366, 1075, 281, 8399, 8460, 14786, 1109, 337, 34952, 294, 383, 25472, 51612], "temperature": 0.0, "avg_logprob": -0.18755279887806287, "compression_ratio": 1.6372093023255814, "no_speech_prob": 0.0027931651566177607}, {"id": 53, "seek": 34292, "start": 342.92, "end": 349.2, "text": " because we pass the message definition files of Rust 2 and we also have automatic type", "tokens": [50364, 570, 321, 1320, 264, 3636, 7123, 7098, 295, 34952, 568, 293, 321, 611, 362, 12509, 2010, 50678], "temperature": 0.0, "avg_logprob": -0.27102797964344855, "compression_ratio": 1.6577777777777778, "no_speech_prob": 0.004588305484503508}, {"id": 54, "seek": 34292, "start": 349.2, "end": 354.28000000000003, "text": " conversions between the Rust 2 message types, the error data types and the native Rust or", "tokens": [50678, 42256, 1296, 264, 34952, 568, 3636, 3467, 11, 264, 6713, 1412, 3467, 293, 264, 8470, 34952, 420, 50932], "temperature": 0.0, "avg_logprob": -0.27102797964344855, "compression_ratio": 1.6577777777777778, "no_speech_prob": 0.004588305484503508}, {"id": 55, "seek": 34292, "start": 354.28000000000003, "end": 357.28000000000003, "text": " Python types.", "tokens": [50932, 15329, 3467, 13, 51082], "temperature": 0.0, "avg_logprob": -0.27102797964344855, "compression_ratio": 1.6577777777777778, "no_speech_prob": 0.004588305484503508}, {"id": 56, "seek": 34292, "start": 357.28000000000003, "end": 363.96000000000004, "text": " Yeah and lastly, so we have two more features, one is open telemetry, so it's for everything", "tokens": [51082, 865, 293, 16386, 11, 370, 321, 362, 732, 544, 4122, 11, 472, 307, 1269, 4304, 5537, 627, 11, 370, 309, 311, 337, 1203, 51416], "temperature": 0.0, "avg_logprob": -0.27102797964344855, "compression_ratio": 1.6577777777777778, "no_speech_prob": 0.004588305484503508}, {"id": 57, "seek": 34292, "start": 363.96000000000004, "end": 370.08000000000004, "text": " that is metadata, we don't want you to learn a new way of logging your logs, tracing your", "tokens": [51416, 300, 307, 26603, 11, 321, 500, 380, 528, 291, 281, 1466, 257, 777, 636, 295, 27991, 428, 20820, 11, 25262, 428, 51722], "temperature": 0.0, "avg_logprob": -0.27102797964344855, "compression_ratio": 1.6577777777777778, "no_speech_prob": 0.004588305484503508}, {"id": 58, "seek": 37008, "start": 370.12, "end": 374.35999999999996, "text": " traces and having metrics, so we're using open telemetry which is an open format that", "tokens": [50366, 26076, 293, 1419, 16367, 11, 370, 321, 434, 1228, 1269, 4304, 5537, 627, 597, 307, 364, 1269, 7877, 300, 50578], "temperature": 0.0, "avg_logprob": -0.20415941306522914, "compression_ratio": 1.718146718146718, "no_speech_prob": 0.04925354942679405}, {"id": 59, "seek": 37008, "start": 374.35999999999996, "end": 380.47999999999996, "text": " is available on many languages, C++ Rust and it can connect to many back end as well,", "tokens": [50578, 307, 2435, 322, 867, 8650, 11, 383, 25472, 34952, 293, 309, 393, 1745, 281, 867, 646, 917, 382, 731, 11, 50884], "temperature": 0.0, "avg_logprob": -0.20415941306522914, "compression_ratio": 1.718146718146718, "no_speech_prob": 0.04925354942679405}, {"id": 60, "seek": 37008, "start": 380.47999999999996, "end": 385.28, "text": " so if you're already using some promissory graphana you can just use Dora and use your", "tokens": [50884, 370, 498, 291, 434, 1217, 1228, 512, 2234, 891, 827, 4295, 2095, 291, 393, 445, 764, 413, 3252, 293, 764, 428, 51124], "temperature": 0.0, "avg_logprob": -0.20415941306522914, "compression_ratio": 1.718146718146718, "no_speech_prob": 0.04925354942679405}, {"id": 61, "seek": 37008, "start": 385.28, "end": 390.52, "text": " back end really quickly and have all your data coming in and there's also a lot of applications", "tokens": [51124, 646, 917, 534, 2661, 293, 362, 439, 428, 1412, 1348, 294, 293, 456, 311, 611, 257, 688, 295, 5821, 51386], "temperature": 0.0, "avg_logprob": -0.20415941306522914, "compression_ratio": 1.718146718146718, "no_speech_prob": 0.04925354942679405}, {"id": 62, "seek": 37008, "start": 390.52, "end": 396.32, "text": " that use this open telemetry such as website, servers and so you could have your Dora data", "tokens": [51386, 300, 764, 341, 1269, 4304, 5537, 627, 1270, 382, 3144, 11, 15909, 293, 370, 291, 727, 362, 428, 413, 3252, 1412, 51676], "temperature": 0.0, "avg_logprob": -0.20415941306522914, "compression_ratio": 1.718146718146718, "no_speech_prob": 0.04925354942679405}, {"id": 63, "seek": 39632, "start": 396.36, "end": 400.36, "text": " at the same time as your other application data.", "tokens": [50366, 412, 264, 912, 565, 382, 428, 661, 3861, 1412, 13, 50566], "temperature": 0.0, "avg_logprob": -0.2040494959405128, "compression_ratio": 1.8482142857142858, "no_speech_prob": 0.009356762282550335}, {"id": 64, "seek": 39632, "start": 400.36, "end": 407.36, "text": " So that's really useful and then we have also a hot reloading feature that helps us basically", "tokens": [50566, 407, 300, 311, 534, 4420, 293, 550, 321, 362, 611, 257, 2368, 25628, 278, 4111, 300, 3665, 505, 1936, 50916], "temperature": 0.0, "avg_logprob": -0.2040494959405128, "compression_ratio": 1.8482142857142858, "no_speech_prob": 0.009356762282550335}, {"id": 65, "seek": 39632, "start": 409.88, "end": 414.84, "text": " reload our application without having to reset the robots, this thing can take a bit of time", "tokens": [51042, 25628, 527, 3861, 1553, 1419, 281, 14322, 264, 14733, 11, 341, 551, 393, 747, 257, 857, 295, 565, 51290], "temperature": 0.0, "avg_logprob": -0.2040494959405128, "compression_ratio": 1.8482142857142858, "no_speech_prob": 0.009356762282550335}, {"id": 66, "seek": 39632, "start": 414.84, "end": 420.4, "text": " and sometimes there's some calibration so we found it really useful to be able to change", "tokens": [51290, 293, 2171, 456, 311, 512, 38732, 370, 321, 1352, 309, 534, 4420, 281, 312, 1075, 281, 1319, 51568], "temperature": 0.0, "avg_logprob": -0.2040494959405128, "compression_ratio": 1.8482142857142858, "no_speech_prob": 0.009356762282550335}, {"id": 67, "seek": 39632, "start": 420.4, "end": 425.84, "text": " the code, change the logic without having to reset the robot and now that we can generate", "tokens": [51568, 264, 3089, 11, 1319, 264, 9952, 1553, 1419, 281, 14322, 264, 7881, 293, 586, 300, 321, 393, 8460, 51840], "temperature": 0.0, "avg_logprob": -0.2040494959405128, "compression_ratio": 1.8482142857142858, "no_speech_prob": 0.009356762282550335}, {"id": 68, "seek": 42584, "start": 425.88, "end": 431.88, "text": " code with generative AI with chargeability as you probably tried out or mistral AI on", "tokens": [50366, 3089, 365, 1337, 1166, 7318, 365, 4602, 2310, 382, 291, 1391, 3031, 484, 420, 3544, 2155, 7318, 322, 50666], "temperature": 0.0, "avg_logprob": -0.22040027484559177, "compression_ratio": 1.7294117647058824, "no_speech_prob": 0.006859760265797377}, {"id": 69, "seek": 42584, "start": 431.88, "end": 438.88, "text": " a local machine, it's really useful and actually it's very simple to code, you can use, you", "tokens": [50666, 257, 2654, 3479, 11, 309, 311, 534, 4420, 293, 767, 309, 311, 588, 2199, 281, 3089, 11, 291, 393, 764, 11, 291, 51016], "temperature": 0.0, "avg_logprob": -0.22040027484559177, "compression_ratio": 1.7294117647058824, "no_speech_prob": 0.006859760265797377}, {"id": 70, "seek": 42584, "start": 438.88, "end": 445.03999999999996, "text": " just have to check your state and if the state doesn't change, if it's compatible you can", "tokens": [51016, 445, 362, 281, 1520, 428, 1785, 293, 498, 264, 1785, 1177, 380, 1319, 11, 498, 309, 311, 18218, 291, 393, 51324], "temperature": 0.0, "avg_logprob": -0.22040027484559177, "compression_ratio": 1.7294117647058824, "no_speech_prob": 0.006859760265797377}, {"id": 71, "seek": 42584, "start": 445.03999999999996, "end": 450.59999999999997, "text": " just swap state and it works, so yeah I'm going to do a quick demo because I think it's", "tokens": [51324, 445, 18135, 1785, 293, 309, 1985, 11, 370, 1338, 286, 478, 516, 281, 360, 257, 1702, 10723, 570, 286, 519, 309, 311, 51602], "temperature": 0.0, "avg_logprob": -0.22040027484559177, "compression_ratio": 1.7294117647058824, "no_speech_prob": 0.006859760265797377}, {"id": 72, "seek": 42584, "start": 450.59999999999997, "end": 455.52, "text": " probably easier for you to understand, so I have a robot, I have a microphone, I have", "tokens": [51602, 1391, 3571, 337, 291, 281, 1223, 11, 370, 286, 362, 257, 7881, 11, 286, 362, 257, 10952, 11, 286, 362, 51848], "temperature": 0.0, "avg_logprob": -0.22040027484559177, "compression_ratio": 1.7294117647058824, "no_speech_prob": 0.006859760265797377}, {"id": 73, "seek": 45552, "start": 455.59999999999997, "end": 459.2, "text": " a speaker, I'm going to use whisper as a node to convert my speech to text and then I'm", "tokens": [50368, 257, 8145, 11, 286, 478, 516, 281, 764, 26018, 382, 257, 9984, 281, 7620, 452, 6218, 281, 2487, 293, 550, 286, 478, 50548], "temperature": 0.0, "avg_logprob": -0.19450754868356804, "compression_ratio": 1.7710843373493976, "no_speech_prob": 0.0077445353381335735}, {"id": 74, "seek": 45552, "start": 459.2, "end": 464.0, "text": " going to use an LLM to change the text to code and using the hot reloading feature it's", "tokens": [50548, 516, 281, 764, 364, 441, 43, 44, 281, 1319, 264, 2487, 281, 3089, 293, 1228, 264, 2368, 25628, 278, 4111, 309, 311, 50788], "temperature": 0.0, "avg_logprob": -0.19450754868356804, "compression_ratio": 1.7710843373493976, "no_speech_prob": 0.0077445353381335735}, {"id": 75, "seek": 45552, "start": 464.0, "end": 470.0, "text": " able to directly change the behavior of the robot and then I have two webcams just so", "tokens": [50788, 1075, 281, 3838, 1319, 264, 5223, 295, 264, 7881, 293, 550, 286, 362, 732, 3670, 66, 4070, 445, 370, 51088], "temperature": 0.0, "avg_logprob": -0.19450754868356804, "compression_ratio": 1.7710843373493976, "no_speech_prob": 0.0077445353381335735}, {"id": 76, "seek": 45552, "start": 470.0, "end": 474.76, "text": " that everyone can see and then I have additional node but I'll let you go into detail later", "tokens": [51088, 300, 1518, 393, 536, 293, 550, 286, 362, 4497, 9984, 457, 286, 603, 718, 291, 352, 666, 2607, 1780, 51326], "temperature": 0.0, "avg_logprob": -0.19450754868356804, "compression_ratio": 1.7710843373493976, "no_speech_prob": 0.0077445353381335735}, {"id": 77, "seek": 45552, "start": 474.76, "end": 479.2, "text": " because I don't have too much time, so this is kind of an overview of what is happening", "tokens": [51326, 570, 286, 500, 380, 362, 886, 709, 565, 11, 370, 341, 307, 733, 295, 364, 12492, 295, 437, 307, 2737, 51548], "temperature": 0.0, "avg_logprob": -0.19450754868356804, "compression_ratio": 1.7710843373493976, "no_speech_prob": 0.0077445353381335735}, {"id": 78, "seek": 47920, "start": 479.2, "end": 486.2, "text": " underneath and yeah let's do a quick demo, so I'm going to start my graph instead of", "tokens": [50364, 7223, 293, 1338, 718, 311, 360, 257, 1702, 10723, 11, 370, 286, 478, 516, 281, 722, 452, 4295, 2602, 295, 50714], "temperature": 0.0, "avg_logprob": -0.17751494959781045, "compression_ratio": 1.6238938053097345, "no_speech_prob": 0.0633927434682846}, {"id": 79, "seek": 47920, "start": 487.32, "end": 491.68, "text": " my computer and fortunately I can't share my screen because somehow my event is not working", "tokens": [50770, 452, 3820, 293, 25511, 286, 393, 380, 2073, 452, 2568, 570, 6063, 452, 2280, 307, 406, 1364, 50988], "temperature": 0.0, "avg_logprob": -0.17751494959781045, "compression_ratio": 1.6238938053097345, "no_speech_prob": 0.0633927434682846}, {"id": 80, "seek": 47920, "start": 491.68, "end": 498.68, "text": " with the HDMI so I'm just going to use my microphone to try to work with the robot, so let's say", "tokens": [50988, 365, 264, 30811, 370, 286, 478, 445, 516, 281, 764, 452, 10952, 281, 853, 281, 589, 365, 264, 7881, 11, 370, 718, 311, 584, 51338], "temperature": 0.0, "avg_logprob": -0.17751494959781045, "compression_ratio": 1.6238938053097345, "no_speech_prob": 0.0633927434682846}, {"id": 81, "seek": 47920, "start": 498.88, "end": 505.88, "text": " I have a robot here, I'm going to say okay, can you set the rotation to 50 and so now whisper", "tokens": [51348, 286, 362, 257, 7881, 510, 11, 286, 478, 516, 281, 584, 1392, 11, 393, 291, 992, 264, 12447, 281, 2625, 293, 370, 586, 26018, 51698], "temperature": 0.0, "avg_logprob": -0.17751494959781045, "compression_ratio": 1.6238938053097345, "no_speech_prob": 0.0633927434682846}, {"id": 82, "seek": 50588, "start": 506.08, "end": 513.08, "text": " is going to convert what I said to code and then the code is going to be hot reloaded", "tokens": [50374, 307, 516, 281, 7620, 437, 286, 848, 281, 3089, 293, 550, 264, 3089, 307, 516, 281, 312, 2368, 25628, 292, 50724], "temperature": 0.0, "avg_logprob": -0.2829193282913376, "compression_ratio": 1.674641148325359, "no_speech_prob": 0.003356382017955184}, {"id": 83, "seek": 50588, "start": 514.84, "end": 520.72, "text": " in the robot in real time hopefully, so the first thing is takes a bit of time but it", "tokens": [50812, 294, 264, 7881, 294, 957, 565, 4696, 11, 370, 264, 700, 551, 307, 2516, 257, 857, 295, 565, 457, 309, 51106], "temperature": 0.0, "avg_logprob": -0.2829193282913376, "compression_ratio": 1.674641148325359, "no_speech_prob": 0.003356382017955184}, {"id": 84, "seek": 50588, "start": 520.72, "end": 526.8, "text": " should get there at some point, I'm just going to try again, can you change the rotation", "tokens": [51106, 820, 483, 456, 412, 512, 935, 11, 286, 478, 445, 516, 281, 853, 797, 11, 393, 291, 1319, 264, 12447, 51410], "temperature": 0.0, "avg_logprob": -0.2829193282913376, "compression_ratio": 1.674641148325359, "no_speech_prob": 0.003356382017955184}, {"id": 85, "seek": 50588, "start": 526.8, "end": 533.8, "text": " to 50 please, just give me one sec and normally it should move, there is no problem, so I", "tokens": [51410, 281, 2625, 1767, 11, 445, 976, 385, 472, 907, 293, 5646, 309, 820, 1286, 11, 456, 307, 572, 1154, 11, 370, 286, 51760], "temperature": 0.0, "avg_logprob": -0.2829193282913376, "compression_ratio": 1.674641148325359, "no_speech_prob": 0.003356382017955184}, {"id": 86, "seek": 53588, "start": 535.88, "end": 542.88, "text": " go and so this is just code, right, it's not something that I've pre-implemented, it's", "tokens": [50364, 352, 293, 370, 341, 307, 445, 3089, 11, 558, 11, 309, 311, 406, 746, 300, 286, 600, 659, 12, 332, 781, 14684, 11, 309, 311, 50714], "temperature": 0.0, "avg_logprob": -0.2548173961072865, "compression_ratio": 1.6875, "no_speech_prob": 0.010746883228421211}, {"id": 87, "seek": 53588, "start": 547.2, "end": 552.8, "text": " not and we can, if people want to have a look, we can have a look deep behind the back and", "tokens": [50930, 406, 293, 321, 393, 11, 498, 561, 528, 281, 362, 257, 574, 11, 321, 393, 362, 257, 574, 2452, 2261, 264, 646, 293, 51210], "temperature": 0.0, "avg_logprob": -0.2548173961072865, "compression_ratio": 1.6875, "no_speech_prob": 0.010746883228421211}, {"id": 88, "seek": 53588, "start": 552.8, "end": 556.28, "text": " talk about it, I can make him move but the table is really small so maybe I can just", "tokens": [51210, 751, 466, 309, 11, 286, 393, 652, 796, 1286, 457, 264, 3199, 307, 534, 1359, 370, 1310, 286, 393, 445, 51384], "temperature": 0.0, "avg_logprob": -0.2548173961072865, "compression_ratio": 1.6875, "no_speech_prob": 0.010746883228421211}, {"id": 89, "seek": 53588, "start": 556.28, "end": 563.28, "text": " try something very small, yeah, can you set the variable x to 1, so yeah, okay he didn't", "tokens": [51384, 853, 746, 588, 1359, 11, 1338, 11, 393, 291, 992, 264, 7006, 2031, 281, 502, 11, 370, 1338, 11, 1392, 415, 994, 380, 51734], "temperature": 0.0, "avg_logprob": -0.2548173961072865, "compression_ratio": 1.6875, "no_speech_prob": 0.010746883228421211}, {"id": 90, "seek": 56328, "start": 564.28, "end": 571.28, "text": " understand, he didn't understand the Bible, so yeah, can you set the x variable to 1,", "tokens": [50414, 1223, 11, 415, 994, 380, 1223, 264, 6544, 11, 370, 1338, 11, 393, 291, 992, 264, 2031, 7006, 281, 502, 11, 50764], "temperature": 0.0, "avg_logprob": -0.32528855173211346, "compression_ratio": 1.7277227722772277, "no_speech_prob": 0.0009961784817278385}, {"id": 91, "seek": 56328, "start": 575.12, "end": 580.12, "text": " okay, the node should move, yeah, so you can really, you have all the control, you can", "tokens": [50956, 1392, 11, 264, 9984, 820, 1286, 11, 1338, 11, 370, 291, 393, 534, 11, 291, 362, 439, 264, 1969, 11, 291, 393, 51206], "temperature": 0.0, "avg_logprob": -0.32528855173211346, "compression_ratio": 1.7277227722772277, "no_speech_prob": 0.0009961784817278385}, {"id": 92, "seek": 56328, "start": 580.12, "end": 585.12, "text": " make him move, rotate, thing, just going to hope it's not going too far but hopefully", "tokens": [51206, 652, 796, 1286, 11, 13121, 11, 551, 11, 445, 516, 281, 1454, 309, 311, 406, 516, 886, 1400, 457, 4696, 51456], "temperature": 0.0, "avg_logprob": -0.32528855173211346, "compression_ratio": 1.7277227722772277, "no_speech_prob": 0.0009961784817278385}, {"id": 93, "seek": 56328, "start": 585.12, "end": 591.12, "text": " it should be okay, yeah, and yeah, so this is like really simple logic, it's just changing", "tokens": [51456, 309, 820, 312, 1392, 11, 1338, 11, 293, 1338, 11, 370, 341, 307, 411, 534, 2199, 9952, 11, 309, 311, 445, 4473, 51756], "temperature": 0.0, "avg_logprob": -0.32528855173211346, "compression_ratio": 1.7277227722772277, "no_speech_prob": 0.0009961784817278385}, {"id": 94, "seek": 59112, "start": 591.52, "end": 596.48, "text": " one variable but I can also use charge-pt which is way more powerful to generate way", "tokens": [50384, 472, 7006, 457, 286, 393, 611, 764, 4602, 12, 662, 597, 307, 636, 544, 4005, 281, 8460, 636, 50632], "temperature": 0.0, "avg_logprob": -0.1946021488734654, "compression_ratio": 1.72, "no_speech_prob": 0.007648997940123081}, {"id": 95, "seek": 59112, "start": 596.48, "end": 602.44, "text": " more complicated code, okay, so this is kind of, if you already used charge-pt before,", "tokens": [50632, 544, 6179, 3089, 11, 1392, 11, 370, 341, 307, 733, 295, 11, 498, 291, 1217, 1143, 4602, 12, 662, 949, 11, 50930], "temperature": 0.0, "avg_logprob": -0.1946021488734654, "compression_ratio": 1.72, "no_speech_prob": 0.007648997940123081}, {"id": 96, "seek": 59112, "start": 602.44, "end": 608.24, "text": " you will see that it's not always reliable, so it should work but it's not a promise,", "tokens": [50930, 291, 486, 536, 300, 309, 311, 406, 1009, 12924, 11, 370, 309, 820, 589, 457, 309, 311, 406, 257, 6228, 11, 51220], "temperature": 0.0, "avg_logprob": -0.1946021488734654, "compression_ratio": 1.72, "no_speech_prob": 0.007648997940123081}, {"id": 97, "seek": 59112, "start": 608.24, "end": 613.08, "text": " right, and I'm sorry if it doesn't work and I probably have to do some debugging of the", "tokens": [51220, 558, 11, 293, 286, 478, 2597, 498, 309, 1177, 380, 589, 293, 286, 1391, 362, 281, 360, 512, 45592, 295, 264, 51462], "temperature": 0.0, "avg_logprob": -0.1946021488734654, "compression_ratio": 1.72, "no_speech_prob": 0.007648997940123081}, {"id": 98, "seek": 59112, "start": 613.08, "end": 620.08, "text": " code that charge-pt generate but let's say I say, can you set the rotation according", "tokens": [51462, 3089, 300, 4602, 12, 662, 8460, 457, 718, 311, 584, 286, 584, 11, 393, 291, 992, 264, 12447, 4650, 51812], "temperature": 0.0, "avg_logprob": -0.1946021488734654, "compression_ratio": 1.72, "no_speech_prob": 0.007648997940123081}, {"id": 99, "seek": 62008, "start": 620.24, "end": 627.24, "text": " to bounding boxes, so you can't probably see but I'm running an object detection on", "tokens": [50372, 281, 5472, 278, 9002, 11, 370, 291, 393, 380, 1391, 536, 457, 286, 478, 2614, 364, 2657, 17784, 322, 50722], "temperature": 0.0, "avg_logprob": -0.23154780508457928, "compression_ratio": 1.7959183673469388, "no_speech_prob": 0.011605075560510159}, {"id": 100, "seek": 62008, "start": 631.44, "end": 635.0400000000001, "text": " my computer and so he's able to get bounding boxes, you've probably already seen demo", "tokens": [50932, 452, 3820, 293, 370, 415, 311, 1075, 281, 483, 5472, 278, 9002, 11, 291, 600, 1391, 1217, 1612, 10723, 51112], "temperature": 0.0, "avg_logprob": -0.23154780508457928, "compression_ratio": 1.7959183673469388, "no_speech_prob": 0.011605075560510159}, {"id": 101, "seek": 62008, "start": 635.0400000000001, "end": 640.0400000000001, "text": " with deep learning and pie torch and things like that and so it's actually very simple,", "tokens": [51112, 365, 2452, 2539, 293, 1730, 27822, 293, 721, 411, 300, 293, 370, 309, 311, 767, 588, 2199, 11, 51362], "temperature": 0.0, "avg_logprob": -0.23154780508457928, "compression_ratio": 1.7959183673469388, "no_speech_prob": 0.011605075560510159}, {"id": 102, "seek": 62008, "start": 640.0400000000001, "end": 647.0400000000001, "text": " right, if you look into details of many demos and so it's actually very simple to get bounding", "tokens": [51362, 558, 11, 498, 291, 574, 666, 4365, 295, 867, 33788, 293, 370, 309, 311, 767, 588, 2199, 281, 483, 5472, 278, 51712], "temperature": 0.0, "avg_logprob": -0.23154780508457928, "compression_ratio": 1.7959183673469388, "no_speech_prob": 0.011605075560510159}, {"id": 103, "seek": 64704, "start": 648.0, "end": 652.76, "text": " boxes, so I'm getting the webcam, I'm sending it to object detection and then I'm plotting", "tokens": [50412, 9002, 11, 370, 286, 478, 1242, 264, 39490, 11, 286, 478, 7750, 309, 281, 2657, 17784, 293, 550, 286, 478, 41178, 50650], "temperature": 0.0, "avg_logprob": -0.17441192559436358, "compression_ratio": 1.8065843621399178, "no_speech_prob": 0.12186035513877869}, {"id": 104, "seek": 64704, "start": 652.76, "end": 656.36, "text": " it on my computer but I'm also sending it to the planning which is the thing that is", "tokens": [50650, 309, 322, 452, 3820, 457, 286, 478, 611, 7750, 309, 281, 264, 5038, 597, 307, 264, 551, 300, 307, 50830], "temperature": 0.0, "avg_logprob": -0.17441192559436358, "compression_ratio": 1.8065843621399178, "no_speech_prob": 0.12186035513877869}, {"id": 105, "seek": 64704, "start": 656.36, "end": 663.36, "text": " controlling the robot and so then, so charge-ptd has to link this bounding box to a rotation", "tokens": [50830, 14905, 264, 7881, 293, 370, 550, 11, 370, 4602, 12, 662, 67, 575, 281, 2113, 341, 5472, 278, 2424, 281, 257, 12447, 51180], "temperature": 0.0, "avg_logprob": -0.17441192559436358, "compression_ratio": 1.8065843621399178, "no_speech_prob": 0.12186035513877869}, {"id": 106, "seek": 64704, "start": 663.4, "end": 668.1999999999999, "text": " axis which is actually quite complicated because the rotation is in angles and then", "tokens": [51182, 10298, 597, 307, 767, 1596, 6179, 570, 264, 12447, 307, 294, 14708, 293, 550, 51422], "temperature": 0.0, "avg_logprob": -0.17441192559436358, "compression_ratio": 1.8065843621399178, "no_speech_prob": 0.12186035513877869}, {"id": 107, "seek": 64704, "start": 668.1999999999999, "end": 673.52, "text": " only what he has is bounding boxes with x, y on a, like an image frame, right, so it's", "tokens": [51422, 787, 437, 415, 575, 307, 5472, 278, 9002, 365, 2031, 11, 288, 322, 257, 11, 411, 364, 3256, 3920, 11, 558, 11, 370, 309, 311, 51688], "temperature": 0.0, "avg_logprob": -0.17441192559436358, "compression_ratio": 1.8065843621399178, "no_speech_prob": 0.12186035513877869}, {"id": 108, "seek": 67352, "start": 673.56, "end": 679.68, "text": " probably like 20 pixel left, 20 pixel right and so he has to generate this code but normally", "tokens": [50366, 1391, 411, 945, 19261, 1411, 11, 945, 19261, 558, 293, 370, 415, 575, 281, 8460, 341, 3089, 457, 5646, 50672], "temperature": 0.0, "avg_logprob": -0.17654486452595572, "compression_ratio": 1.640552995391705, "no_speech_prob": 0.022814856842160225}, {"id": 109, "seek": 67352, "start": 679.68, "end": 685.1999999999999, "text": " it should work and so charge-pt takes about 30 seconds to one minute, maybe more depending", "tokens": [50672, 309, 820, 589, 293, 370, 4602, 12, 662, 2516, 466, 2217, 3949, 281, 472, 3456, 11, 1310, 544, 5413, 50948], "temperature": 0.0, "avg_logprob": -0.17654486452595572, "compression_ratio": 1.640552995391705, "no_speech_prob": 0.022814856842160225}, {"id": 110, "seek": 67352, "start": 685.1999999999999, "end": 691.56, "text": " on the file length because it's per token right and so now it's still like talking", "tokens": [50948, 322, 264, 3991, 4641, 570, 309, 311, 680, 14862, 558, 293, 370, 586, 309, 311, 920, 411, 1417, 51266], "temperature": 0.0, "avg_logprob": -0.17654486452595572, "compression_ratio": 1.640552995391705, "no_speech_prob": 0.022814856842160225}, {"id": 111, "seek": 67352, "start": 691.56, "end": 698.56, "text": " with charge-pt I think and now it's finished so it should be able to move, I'm just going", "tokens": [51266, 365, 4602, 12, 662, 286, 519, 293, 586, 309, 311, 4335, 370, 309, 820, 312, 1075, 281, 1286, 11, 286, 478, 445, 516, 51616], "temperature": 0.0, "avg_logprob": -0.17654486452595572, "compression_ratio": 1.640552995391705, "no_speech_prob": 0.022814856842160225}, {"id": 112, "seek": 69856, "start": 698.7199999999999, "end": 705.2199999999999, "text": " to log it, I'm sorry if I take a bit of time and, alright, so there was a bit of an issue,", "tokens": [50372, 281, 3565, 309, 11, 286, 478, 2597, 498, 286, 747, 257, 857, 295, 565, 293, 11, 5845, 11, 370, 456, 390, 257, 857, 295, 364, 2734, 11, 50697], "temperature": 0.0, "avg_logprob": -0.2897254753112793, "compression_ratio": 1.6602870813397128, "no_speech_prob": 0.018401699140667915}, {"id": 113, "seek": 69856, "start": 705.2199999999999, "end": 712.2199999999999, "text": " the true value of an array is complicated so, alright, just give me one sec, center", "tokens": [50697, 264, 2074, 2158, 295, 364, 10225, 307, 6179, 370, 11, 5845, 11, 445, 976, 385, 472, 907, 11, 3056, 51047], "temperature": 0.0, "avg_logprob": -0.2897254753112793, "compression_ratio": 1.6602870813397128, "no_speech_prob": 0.018401699140667915}, {"id": 114, "seek": 69856, "start": 713.1999999999999, "end": 720.1999999999999, "text": " x ratio, center x, center x, okay and then I'm going to put a zero here and normally", "tokens": [51096, 2031, 8509, 11, 3056, 2031, 11, 3056, 2031, 11, 1392, 293, 550, 286, 478, 516, 281, 829, 257, 4018, 510, 293, 5646, 51446], "temperature": 0.0, "avg_logprob": -0.2897254753112793, "compression_ratio": 1.6602870813397128, "no_speech_prob": 0.018401699140667915}, {"id": 115, "seek": 69856, "start": 720.1999999999999, "end": 727.1999999999999, "text": " it should work, is it moving? Oh yeah, okay, so now he should move according to what he", "tokens": [51446, 309, 820, 589, 11, 307, 309, 2684, 30, 876, 1338, 11, 1392, 11, 370, 586, 415, 820, 1286, 4650, 281, 437, 415, 51796], "temperature": 0.0, "avg_logprob": -0.2897254753112793, "compression_ratio": 1.6602870813397128, "no_speech_prob": 0.018401699140667915}, {"id": 116, "seek": 72720, "start": 727.9200000000001, "end": 734.5200000000001, "text": " sees, so if I'm here maybe he's going to move like here, okay, yeah and now it should stop", "tokens": [50400, 8194, 11, 370, 498, 286, 478, 510, 1310, 415, 311, 516, 281, 1286, 411, 510, 11, 1392, 11, 1338, 293, 586, 309, 820, 1590, 50730], "temperature": 0.0, "avg_logprob": -0.2768318818347289, "compression_ratio": 1.6778846153846154, "no_speech_prob": 0.007228865288197994}, {"id": 117, "seek": 72720, "start": 734.5200000000001, "end": 741.5200000000001, "text": " moving, yeah, it's like doing some PID stuff, right, like kind of like brewing so, and", "tokens": [50730, 2684, 11, 1338, 11, 309, 311, 411, 884, 512, 430, 2777, 1507, 11, 558, 11, 411, 733, 295, 411, 39019, 370, 11, 293, 51080], "temperature": 0.0, "avg_logprob": -0.2768318818347289, "compression_ratio": 1.6778846153846154, "no_speech_prob": 0.007228865288197994}, {"id": 118, "seek": 72720, "start": 741.6800000000001, "end": 746.6400000000001, "text": " so if I move here, he's going to move from here, yeah and so this is the whole logic", "tokens": [51088, 370, 498, 286, 1286, 510, 11, 415, 311, 516, 281, 1286, 490, 510, 11, 1338, 293, 370, 341, 307, 264, 1379, 9952, 51336], "temperature": 0.0, "avg_logprob": -0.2768318818347289, "compression_ratio": 1.6778846153846154, "no_speech_prob": 0.007228865288197994}, {"id": 119, "seek": 72720, "start": 746.6400000000001, "end": 752.32, "text": " it was charge-pt, I didn't code anything, I'm probably too lazy to code this thing but", "tokens": [51336, 309, 390, 4602, 12, 662, 11, 286, 994, 380, 3089, 1340, 11, 286, 478, 1391, 886, 14847, 281, 3089, 341, 551, 457, 51620], "temperature": 0.0, "avg_logprob": -0.2768318818347289, "compression_ratio": 1.6778846153846154, "no_speech_prob": 0.007228865288197994}, {"id": 120, "seek": 75232, "start": 752.32, "end": 759.32, "text": " yeah, but you can see the idea so if, yeah, that's kind of where we are now and, yeah,", "tokens": [50364, 1338, 11, 457, 291, 393, 536, 264, 1558, 370, 498, 11, 1338, 11, 300, 311, 733, 295, 689, 321, 366, 586, 293, 11, 1338, 11, 50714], "temperature": 0.0, "avg_logprob": -0.2940756934029715, "compression_ratio": 1.8105263157894738, "no_speech_prob": 0.014513188041746616}, {"id": 121, "seek": 75232, "start": 760.72, "end": 764.9200000000001, "text": " time's up, okay, so here's the feature we have and if you have any features you can", "tokens": [50784, 565, 311, 493, 11, 1392, 11, 370, 510, 311, 264, 4111, 321, 362, 293, 498, 291, 362, 604, 4122, 291, 393, 50994], "temperature": 0.0, "avg_logprob": -0.2940756934029715, "compression_ratio": 1.8105263157894738, "no_speech_prob": 0.014513188041746616}, {"id": 122, "seek": 75232, "start": 764.9200000000001, "end": 769.48, "text": " let us know and we'll try our best to make it happen, sometimes it doesn't happen but", "tokens": [50994, 718, 505, 458, 293, 321, 603, 853, 527, 1151, 281, 652, 309, 1051, 11, 2171, 309, 1177, 380, 1051, 457, 51222], "temperature": 0.0, "avg_logprob": -0.2940756934029715, "compression_ratio": 1.8105263157894738, "no_speech_prob": 0.014513188041746616}, {"id": 123, "seek": 75232, "start": 769.48, "end": 777.48, "text": " we'll try our best and yeah, so well, thanks for listening, yeah, thanks for having us,", "tokens": [51222, 321, 603, 853, 527, 1151, 293, 1338, 11, 370, 731, 11, 3231, 337, 4764, 11, 1338, 11, 3231, 337, 1419, 505, 11, 51622], "temperature": 0.0, "avg_logprob": -0.2940756934029715, "compression_ratio": 1.8105263157894738, "no_speech_prob": 0.014513188041746616}, {"id": 124, "seek": 77748, "start": 777.48, "end": 784.48, "text": " thanks.", "tokens": [50364, 3231, 13, 50714], "temperature": 0.4, "avg_logprob": -0.4099620967716366, "compression_ratio": 1.48, "no_speech_prob": 0.053400300443172455}, {"id": 125, "seek": 77748, "start": 784.48, "end": 791.48, "text": " I have any questions?", "tokens": [50714, 286, 362, 604, 1651, 30, 51064], "temperature": 0.4, "avg_logprob": -0.4099620967716366, "compression_ratio": 1.48, "no_speech_prob": 0.053400300443172455}, {"id": 126, "seek": 77748, "start": 795.52, "end": 799.52, "text": " Hi, it was very interesting, when you showed the graph of the latency with ROS2 versus", "tokens": [51266, 2421, 11, 309, 390, 588, 1880, 11, 562, 291, 4712, 264, 4295, 295, 264, 27043, 365, 31904, 17, 5717, 51466], "temperature": 0.4, "avg_logprob": -0.4099620967716366, "compression_ratio": 1.48, "no_speech_prob": 0.053400300443172455}, {"id": 127, "seek": 77748, "start": 799.52, "end": 802.9, "text": " Dora, do you know what middleware you were using to compare against, because obviously", "tokens": [51466, 413, 3252, 11, 360, 291, 458, 437, 2808, 3039, 291, 645, 1228, 281, 6794, 1970, 11, 570, 2745, 51635], "temperature": 0.4, "avg_logprob": -0.4099620967716366, "compression_ratio": 1.48, "no_speech_prob": 0.053400300443172455}, {"id": 128, "seek": 77748, "start": 802.9, "end": 807.4, "text": " ROS2 has a whole bunch of different middlewares that you can use some of shared memory, some", "tokens": [51635, 31904, 17, 575, 257, 1379, 3840, 295, 819, 2808, 4151, 495, 300, 291, 393, 764, 512, 295, 5507, 4675, 11, 512, 51860], "temperature": 0.4, "avg_logprob": -0.4099620967716366, "compression_ratio": 1.48, "no_speech_prob": 0.053400300443172455}, {"id": 129, "seek": 80740, "start": 807.4399999999999, "end": 810.4399999999999, "text": " over the loop back, do you know which one it was?", "tokens": [50366, 670, 264, 6367, 646, 11, 360, 291, 458, 597, 472, 309, 390, 30, 50516], "temperature": 0.0, "avg_logprob": -0.36898128264540925, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.058399662375450134}, {"id": 130, "seek": 80740, "start": 810.4399999999999, "end": 813.4399999999999, "text": " I think it was default DDS.", "tokens": [50516, 286, 519, 309, 390, 7576, 413, 11844, 13, 50666], "temperature": 0.0, "avg_logprob": -0.36898128264540925, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.058399662375450134}, {"id": 131, "seek": 80740, "start": 813.4399999999999, "end": 815.4399999999999, "text": " Yeah, it was default DDS.", "tokens": [50666, 865, 11, 309, 390, 7576, 413, 11844, 13, 50766], "temperature": 0.0, "avg_logprob": -0.36898128264540925, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.058399662375450134}, {"id": 132, "seek": 80740, "start": 815.4399999999999, "end": 816.4399999999999, "text": " Or TPS or?", "tokens": [50766, 1610, 314, 6273, 420, 30, 50816], "temperature": 0.0, "avg_logprob": -0.36898128264540925, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.058399662375450134}, {"id": 133, "seek": 80740, "start": 816.4399999999999, "end": 821.3199999999999, "text": " Now I can't remember exactly the details but we tried to use the exact, like, tutorial", "tokens": [50816, 823, 286, 393, 380, 1604, 2293, 264, 4365, 457, 321, 3031, 281, 764, 264, 1900, 11, 411, 11, 7073, 51060], "temperature": 0.0, "avg_logprob": -0.36898128264540925, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.058399662375450134}, {"id": 134, "seek": 80740, "start": 821.3199999999999, "end": 827.1999999999999, "text": " version of ROS2 and in Python you can't do like shared memory things so like, we tried", "tokens": [51060, 3037, 295, 31904, 17, 293, 294, 15329, 291, 393, 380, 360, 411, 5507, 4675, 721, 370, 411, 11, 321, 3031, 51354], "temperature": 0.0, "avg_logprob": -0.36898128264540925, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.058399662375450134}, {"id": 135, "seek": 80740, "start": 827.1999999999999, "end": 831.4, "text": " to use MW isorox thing with Python but it didn't really work out, yeah.", "tokens": [51354, 281, 764, 376, 54, 307, 284, 5230, 551, 365, 15329, 457, 309, 994, 380, 534, 589, 484, 11, 1338, 13, 51564], "temperature": 0.0, "avg_logprob": -0.36898128264540925, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.058399662375450134}, {"id": 136, "seek": 83140, "start": 831.4, "end": 838.4, "text": " And on real time stuff, do you have bindings for say POSIX, Tread Priority setting and other", "tokens": [50364, 400, 322, 957, 565, 1507, 11, 360, 291, 362, 14786, 1109, 337, 584, 430, 4367, 21124, 11, 314, 2538, 24032, 507, 3287, 293, 661, 50714], "temperature": 0.0, "avg_logprob": -0.2803994678315662, "compression_ratio": 1.623076923076923, "no_speech_prob": 0.10660221427679062}, {"id": 137, "seek": 83140, "start": 838.4, "end": 840.4, "text": " real time integrations or is that still in the Python?", "tokens": [50714, 957, 565, 3572, 763, 420, 307, 300, 920, 294, 264, 15329, 30, 50814], "temperature": 0.0, "avg_logprob": -0.2803994678315662, "compression_ratio": 1.623076923076923, "no_speech_prob": 0.10660221427679062}, {"id": 138, "seek": 83140, "start": 840.4, "end": 845.4, "text": " Yeah, that's probably things that we can improve but actually there's a lot of time spent on", "tokens": [50814, 865, 11, 300, 311, 1391, 721, 300, 321, 393, 3470, 457, 767, 456, 311, 257, 688, 295, 565, 4418, 322, 51064], "temperature": 0.0, "avg_logprob": -0.2803994678315662, "compression_ratio": 1.623076923076923, "no_speech_prob": 0.10660221427679062}, {"id": 139, "seek": 83140, "start": 845.4, "end": 852.4, "text": " serialization, copying and so this is where we think that the biggest difference is, yeah.", "tokens": [51064, 17436, 2144, 11, 27976, 293, 370, 341, 307, 689, 321, 519, 300, 264, 3880, 2649, 307, 11, 1338, 13, 51414], "temperature": 0.0, "avg_logprob": -0.2803994678315662, "compression_ratio": 1.623076923076923, "no_speech_prob": 0.10660221427679062}, {"id": 140, "seek": 83140, "start": 852.4, "end": 857.4, "text": " But we can definitely look more into detail into the benchmark if you're interested, yeah.", "tokens": [51414, 583, 321, 393, 2138, 574, 544, 666, 2607, 666, 264, 18927, 498, 291, 434, 3102, 11, 1338, 13, 51664], "temperature": 0.0, "avg_logprob": -0.2803994678315662, "compression_ratio": 1.623076923076923, "no_speech_prob": 0.10660221427679062}, {"id": 141, "seek": 85740, "start": 857.4, "end": 860.4, "text": " I'll take up one over there.", "tokens": [50364, 286, 603, 747, 493, 472, 670, 456, 13, 50514], "temperature": 0.0, "avg_logprob": -0.3476381036970351, "compression_ratio": 1.4457142857142857, "no_speech_prob": 0.24333293735980988}, {"id": 142, "seek": 85740, "start": 860.4, "end": 864.4, "text": " Right, I'll give you some problems.", "tokens": [50514, 1779, 11, 286, 603, 976, 291, 512, 2740, 13, 50714], "temperature": 0.0, "avg_logprob": -0.3476381036970351, "compression_ratio": 1.4457142857142857, "no_speech_prob": 0.24333293735980988}, {"id": 143, "seek": 85740, "start": 864.4, "end": 869.4, "text": " Oh yeah, it's moving because of bounding boxes, yeah, if you see.", "tokens": [50714, 876, 1338, 11, 309, 311, 2684, 570, 295, 5472, 278, 9002, 11, 1338, 11, 498, 291, 536, 13, 50964], "temperature": 0.0, "avg_logprob": -0.3476381036970351, "compression_ratio": 1.4457142857142857, "no_speech_prob": 0.24333293735980988}, {"id": 144, "seek": 85740, "start": 869.4, "end": 881.4, "text": " Hello, I'm curious why you chose to have an, over here, an explicit definition of all the kind of topics of communication.", "tokens": [50964, 2425, 11, 286, 478, 6369, 983, 291, 5111, 281, 362, 364, 11, 670, 510, 11, 364, 13691, 7123, 295, 439, 264, 733, 295, 8378, 295, 6101, 13, 51564], "temperature": 0.0, "avg_logprob": -0.3476381036970351, "compression_ratio": 1.4457142857142857, "no_speech_prob": 0.24333293735980988}, {"id": 145, "seek": 88140, "start": 882.4, "end": 889.4, "text": " Like why use that instead of kind of the raw style just publish and subscribe without, blindly publish and blindly", "tokens": [50414, 1743, 983, 764, 300, 2602, 295, 733, 295, 264, 8936, 3758, 445, 11374, 293, 3022, 1553, 11, 47744, 11374, 293, 47744, 50764], "temperature": 0.0, "avg_logprob": -0.24228153672329214, "compression_ratio": 1.588785046728972, "no_speech_prob": 0.14984093606472015}, {"id": 146, "seek": 88140, "start": 889.4, "end": 891.4, "text": " subscribe?", "tokens": [50764, 3022, 30, 50864], "temperature": 0.0, "avg_logprob": -0.24228153672329214, "compression_ratio": 1.588785046728972, "no_speech_prob": 0.14984093606472015}, {"id": 147, "seek": 88140, "start": 891.4, "end": 894.4, "text": " Do you want to answer?", "tokens": [50864, 1144, 291, 528, 281, 1867, 30, 51014], "temperature": 0.0, "avg_logprob": -0.24228153672329214, "compression_ratio": 1.588785046728972, "no_speech_prob": 0.14984093606472015}, {"id": 148, "seek": 88140, "start": 894.4, "end": 898.4, "text": " Okay, okay.", "tokens": [51014, 1033, 11, 1392, 13, 51214], "temperature": 0.0, "avg_logprob": -0.24228153672329214, "compression_ratio": 1.588785046728972, "no_speech_prob": 0.14984093606472015}, {"id": 149, "seek": 88140, "start": 898.4, "end": 903.4, "text": " Yeah, I think it was just to have additional insight at the beginning directly.", "tokens": [51214, 865, 11, 286, 519, 309, 390, 445, 281, 362, 4497, 11269, 412, 264, 2863, 3838, 13, 51464], "temperature": 0.0, "avg_logprob": -0.24228153672329214, "compression_ratio": 1.588785046728972, "no_speech_prob": 0.14984093606472015}, {"id": 150, "seek": 88140, "start": 903.4, "end": 910.4, "text": " We also plan, I think if we go to the road again, we also plan this dynamic data flow feature again", "tokens": [51464, 492, 611, 1393, 11, 286, 519, 498, 321, 352, 281, 264, 3060, 797, 11, 321, 611, 1393, 341, 8546, 1412, 3095, 4111, 797, 51814], "temperature": 0.0, "avg_logprob": -0.24228153672329214, "compression_ratio": 1.588785046728972, "no_speech_prob": 0.14984093606472015}, {"id": 151, "seek": 91040, "start": 910.4, "end": 917.4, "text": " because in some cases it's quite useful to add nodes at runtime but for like getting started it was useful to be able to", "tokens": [50364, 570, 294, 512, 3331, 309, 311, 1596, 4420, 281, 909, 13891, 412, 34474, 457, 337, 411, 1242, 1409, 309, 390, 4420, 281, 312, 1075, 281, 50714], "temperature": 0.0, "avg_logprob": -0.18423413706349803, "compression_ratio": 1.5378151260504203, "no_speech_prob": 0.012729222886264324}, {"id": 152, "seek": 91040, "start": 917.4, "end": 923.4, "text": " generate a graph of the whole thing and yeah, so.", "tokens": [50714, 8460, 257, 4295, 295, 264, 1379, 551, 293, 1338, 11, 370, 13, 51014], "temperature": 0.0, "avg_logprob": -0.18423413706349803, "compression_ratio": 1.5378151260504203, "no_speech_prob": 0.012729222886264324}, {"id": 153, "seek": 91040, "start": 923.4, "end": 925.4, "text": " Okay, one more question.", "tokens": [51014, 1033, 11, 472, 544, 1168, 13, 51114], "temperature": 0.0, "avg_logprob": -0.18423413706349803, "compression_ratio": 1.5378151260504203, "no_speech_prob": 0.012729222886264324}, {"id": 154, "seek": 91040, "start": 925.4, "end": 929.4, "text": " There was a guy over here, yeah.", "tokens": [51114, 821, 390, 257, 2146, 670, 510, 11, 1338, 13, 51314], "temperature": 0.0, "avg_logprob": -0.18423413706349803, "compression_ratio": 1.5378151260504203, "no_speech_prob": 0.012729222886264324}, {"id": 155, "seek": 91040, "start": 929.4, "end": 931.4, "text": " Hi, sorry, very interesting.", "tokens": [51314, 2421, 11, 2597, 11, 588, 1880, 13, 51414], "temperature": 0.0, "avg_logprob": -0.18423413706349803, "compression_ratio": 1.5378151260504203, "no_speech_prob": 0.012729222886264324}, {"id": 156, "seek": 91040, "start": 931.4, "end": 938.4, "text": " Maybe I missed it but how do you communicate across different computers which networking provider are using?", "tokens": [51414, 2704, 286, 6721, 309, 457, 577, 360, 291, 7890, 2108, 819, 10807, 597, 17985, 12398, 366, 1228, 30, 51764], "temperature": 0.0, "avg_logprob": -0.18423413706349803, "compression_ratio": 1.5378151260504203, "no_speech_prob": 0.012729222886264324}, {"id": 157, "seek": 93840, "start": 938.4, "end": 944.4, "text": " Right, so there's an SDK and so basically you can send messages with a protocol buffer and there's a small computer and it's", "tokens": [50364, 1779, 11, 370, 456, 311, 364, 37135, 293, 370, 1936, 291, 393, 2845, 7897, 365, 257, 10336, 21762, 293, 456, 311, 257, 1359, 3820, 293, 309, 311, 50664], "temperature": 0.0, "avg_logprob": -0.24166091795890562, "compression_ratio": 1.6382978723404256, "no_speech_prob": 0.039918359369039536}, {"id": 158, "seek": 93840, "start": 944.4, "end": 949.4, "text": " interesting and the video stream is using H.264.", "tokens": [50664, 1880, 293, 264, 960, 4309, 307, 1228, 389, 13, 10880, 19, 13, 50914], "temperature": 0.0, "avg_logprob": -0.24166091795890562, "compression_ratio": 1.6382978723404256, "no_speech_prob": 0.039918359369039536}, {"id": 159, "seek": 93840, "start": 949.4, "end": 956.4, "text": " Yeah, so I was talking about like Protobuf but just like what is like, I don't know, DDS for raws, then now they are moving to senior", "tokens": [50914, 865, 11, 370, 286, 390, 1417, 466, 411, 10019, 996, 2947, 457, 445, 411, 437, 307, 411, 11, 286, 500, 380, 458, 11, 413, 11844, 337, 8936, 82, 11, 550, 586, 436, 366, 2684, 281, 7965, 51264], "temperature": 0.0, "avg_logprob": -0.24166091795890562, "compression_ratio": 1.6382978723404256, "no_speech_prob": 0.039918359369039536}, {"id": 160, "seek": 93840, "start": 956.4, "end": 960.4, "text": " or what are you, how are you sending the messages actually?", "tokens": [51264, 420, 437, 366, 291, 11, 577, 366, 291, 7750, 264, 7897, 767, 30, 51464], "temperature": 0.0, "avg_logprob": -0.24166091795890562, "compression_ratio": 1.6382978723404256, "no_speech_prob": 0.039918359369039536}, {"id": 161, "seek": 93840, "start": 960.4, "end": 965.4, "text": " Okay, so now I'm just using the SDK of the robot for communicating, yeah, so it's very simple.", "tokens": [51464, 1033, 11, 370, 586, 286, 478, 445, 1228, 264, 37135, 295, 264, 7881, 337, 17559, 11, 1338, 11, 370, 309, 311, 588, 2199, 13, 51714], "temperature": 0.0, "avg_logprob": -0.24166091795890562, "compression_ratio": 1.6382978723404256, "no_speech_prob": 0.039918359369039536}, {"id": 162, "seek": 96540, "start": 965.4, "end": 971.4, "text": " In the future if we have remote machine we can use TCP and maybe Xeno type of thing for Dora itself.", "tokens": [50364, 682, 264, 2027, 498, 321, 362, 8607, 3479, 321, 393, 764, 48965, 293, 1310, 1783, 5808, 2010, 295, 551, 337, 413, 3252, 2564, 13, 50664], "temperature": 0.0, "avg_logprob": -0.18637368990027386, "compression_ratio": 1.5687203791469195, "no_speech_prob": 0.014618671499192715}, {"id": 163, "seek": 96540, "start": 971.4, "end": 973.4, "text": " Okay, so Dora now it's only one computer.", "tokens": [50664, 1033, 11, 370, 413, 3252, 586, 309, 311, 787, 472, 3820, 13, 50764], "temperature": 0.0, "avg_logprob": -0.18637368990027386, "compression_ratio": 1.5687203791469195, "no_speech_prob": 0.014618671499192715}, {"id": 164, "seek": 96540, "start": 973.4, "end": 975.4, "text": " Now it's kind of one computer.", "tokens": [50764, 823, 309, 311, 733, 295, 472, 3820, 13, 50864], "temperature": 0.0, "avg_logprob": -0.18637368990027386, "compression_ratio": 1.5687203791469195, "no_speech_prob": 0.014618671499192715}, {"id": 165, "seek": 96540, "start": 975.4, "end": 980.4, "text": " Yeah, we have like basic TCP support for remote machines but nothing too optimized.", "tokens": [50864, 865, 11, 321, 362, 411, 3875, 48965, 1406, 337, 8607, 8379, 457, 1825, 886, 26941, 13, 51114], "temperature": 0.0, "avg_logprob": -0.18637368990027386, "compression_ratio": 1.5687203791469195, "no_speech_prob": 0.014618671499192715}, {"id": 166, "seek": 96540, "start": 980.4, "end": 986.4, "text": " Yeah, but it's definitely something we want to do.", "tokens": [51114, 865, 11, 457, 309, 311, 2138, 746, 321, 528, 281, 360, 13, 51414], "temperature": 0.0, "avg_logprob": -0.18637368990027386, "compression_ratio": 1.5687203791469195, "no_speech_prob": 0.014618671499192715}, {"id": 167, "seek": 96540, "start": 986.4, "end": 989.4, "text": " May I ask another one?", "tokens": [51414, 1891, 286, 1029, 1071, 472, 30, 51564], "temperature": 0.0, "avg_logprob": -0.18637368990027386, "compression_ratio": 1.5687203791469195, "no_speech_prob": 0.014618671499192715}, {"id": 168, "seek": 98940, "start": 989.4, "end": 1000.4, "text": " Yeah, so have you tried R2R like the another raws Rust binding which is also like using the raws C library but wrapped and it doesn't", "tokens": [50364, 865, 11, 370, 362, 291, 3031, 497, 17, 49, 411, 264, 1071, 8936, 82, 34952, 17359, 597, 307, 611, 411, 1228, 264, 8936, 82, 383, 6405, 457, 14226, 293, 309, 1177, 380, 50914], "temperature": 0.0, "avg_logprob": -0.36123085021972656, "compression_ratio": 1.598360655737705, "no_speech_prob": 0.03067064844071865}, {"id": 169, "seek": 98940, "start": 1000.4, "end": 1008.4, "text": " use all the complicated, the amend and what not, cash is building with cargo which I agree it's a good advantage.", "tokens": [50914, 764, 439, 264, 6179, 11, 264, 11704, 293, 437, 406, 11, 6388, 307, 2390, 365, 19449, 597, 286, 3986, 309, 311, 257, 665, 5002, 13, 51314], "temperature": 0.0, "avg_logprob": -0.36123085021972656, "compression_ratio": 1.598360655737705, "no_speech_prob": 0.03067064844071865}, {"id": 170, "seek": 98940, "start": 1008.4, "end": 1012.4, "text": " So maybe it's interesting to check that library also.", "tokens": [51314, 407, 1310, 309, 311, 1880, 281, 1520, 300, 6405, 611, 13, 51514], "temperature": 0.0, "avg_logprob": -0.36123085021972656, "compression_ratio": 1.598360655737705, "no_speech_prob": 0.03067064844071865}, {"id": 171, "seek": 98940, "start": 1012.4, "end": 1017.4, "text": " Yeah, absolutely, yeah, we definitely look into the raws thing and there's many clients.", "tokens": [51514, 865, 11, 3122, 11, 1338, 11, 321, 2138, 574, 666, 264, 8936, 82, 551, 293, 456, 311, 867, 6982, 13, 51764], "temperature": 0.0, "avg_logprob": -0.36123085021972656, "compression_ratio": 1.598360655737705, "no_speech_prob": 0.03067064844071865}, {"id": 172, "seek": 101740, "start": 1017.4, "end": 1027.4, "text": " We're actually working on the raws to bridge as well and so we are using the Rust client from like an unofficial raws client that enables you to not use the", "tokens": [50364, 492, 434, 767, 1364, 322, 264, 8936, 82, 281, 7283, 382, 731, 293, 370, 321, 366, 1228, 264, 34952, 6423, 490, 411, 364, 8526, 37661, 8936, 82, 6423, 300, 17077, 291, 281, 406, 764, 264, 50864], "temperature": 0.0, "avg_logprob": -0.25397698276014213, "compression_ratio": 1.5885416666666667, "no_speech_prob": 0.05018722638487816}, {"id": 173, "seek": 101740, "start": 1027.4, "end": 1031.4, "text": " complex like raws to build system and still use raws to.", "tokens": [50864, 3997, 411, 8936, 82, 281, 1322, 1185, 293, 920, 764, 8936, 82, 281, 13, 51064], "temperature": 0.0, "avg_logprob": -0.25397698276014213, "compression_ratio": 1.5885416666666667, "no_speech_prob": 0.05018722638487816}, {"id": 174, "seek": 101740, "start": 1031.4, "end": 1034.4, "text": " So this is how things are.", "tokens": [51064, 407, 341, 307, 577, 721, 366, 13, 51214], "temperature": 0.0, "avg_logprob": -0.25397698276014213, "compression_ratio": 1.5885416666666667, "no_speech_prob": 0.05018722638487816}, {"id": 175, "seek": 101740, "start": 1034.4, "end": 1038.4, "text": " Okay, so the robots are ticking over.", "tokens": [51214, 1033, 11, 370, 264, 14733, 366, 33999, 670, 13, 51414], "temperature": 0.0, "avg_logprob": -0.25397698276014213, "compression_ratio": 1.5885416666666667, "no_speech_prob": 0.05018722638487816}, {"id": 176, "seek": 101740, "start": 1038.4, "end": 1040.4, "text": " Okay, thank you very much.", "tokens": [51414, 1033, 11, 1309, 291, 588, 709, 13, 51514], "temperature": 0.0, "avg_logprob": -0.25397698276014213, "compression_ratio": 1.5885416666666667, "no_speech_prob": 0.05018722638487816}, {"id": 177, "seek": 104740, "start": 1047.4, "end": 1050.4, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 50514], "temperature": 0.0, "avg_logprob": -0.6073652108510336, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.9907135963439941}], "language": "en"}