{"text": " Thank you so much guys. So is my audio, can everyone hear my voice? Perfect. So I would be talking about external Rooksef cluster. So people might not be aware like what's Rook, what's Sef and what thing I'm talking about. So I will tell you to the intro first about what topic is this and then we'll deep dive into this topic. So I am Parth Arora and I work for IBM Storage as a software developer and closely with Rook operator and I'm one of the lead approver of that repo. So anybody like might be storing data applications, creating applications through Kubernetes, but everyone knows like Kubernetes is designed in terms like which doesn't talks much about data but anyhow any application we can talk about there is storage for that and we need to store data in it. And for now if someone wants to store the data that is coming from Kubernetes application, we just talk about cloud providers and talking to the cloud and they might be doing anything we don't know at the back end. So why not to bring the storage into your data center and traditionally like there are some limitations also with cloud providers like number of nodes, how we can scale up the different AZs. So why not to have a native solution with your own Kubernetes cluster. So and also like to manage that cluster how natively your Kubernetes application manages and also manage that storage in the same way. So here comes the most trusted platform CIF that can like make the storage available to you in the form of Kubernetes, how it will be but first I will talk about CIF, why CIF. So it's like it has a lot of enterprise already enterprises using from like trusted platform from past 10 years and it provides all the storage at the same time the block file and object you name it and it provides and its open source and it has so many features its resilient, it's configurable, it's more disaster proven and it's consistent and provide like like give your data a safe point of view. And so CIF was designed even back when Kubernetes was introduced. So to bring the storage to the Kubernetes world we have designed Rook and this is how it was born to bring the CIF to the Kubernetes. It's the management layer so it helps in installing and managing the state. It's not just like it's there are Python scripts that just install it but it actually manage the state of it. How it does it's a Kubernetes operator which works how a Kubernetes actual desired and actual state works and we can manage to that and how we can define what we need to give the state so that's the CRDs. We can give any definition to that and that thing can be configured and like we can give I need monitoring, I need the block storage so these types of things we can provide through CRDs. And so this is how the architecture of Rook CIF looks like, Rook is the management layer which installs CIFs, the CIFC driver which helps in mounting the port, like the storage to your application port, how it's the native Kubernetes we have CIFC or CIF and CIF being the data layer. And Rook works in two mode, so first is what I talked about bringing the storage into your application cluster only, the same cluster that would be the Rook Converse mode. It's recommended if like we just have one to the single cluster but when we need external cluster that I would be talking about. So first of all what an external cluster is. So external cluster means you already have a CIF cluster installed in which like there are CIF domains, these are the CIF terminologies, the mon, OSTs, RGWMDS, these are some domains running that helps your storage to like store the data. So it's already been there and now comes the part like I'm in Kubernetes world, I need to connect this CIF to the Kubernetes, so how will you do that? So there would be a separate Kubernetes cluster running in which there would be a Rook operator and this FCS earlier and we need to provide data of external CIF cluster to Kubernetes, so how that magic does, so I will be taking to that part. So first of all I will tell why you need external cluster, in what cases like I told you like you can have this same cluster in your native application, so why you need external cluster. So you might be having a big enterprise where you have like different domains of Kubernetes cluster running, like there is an admin cluster that is there and there is a finance cluster department Kubernetes cluster there and you need isolation between them, they shouldn't talk with each other and underline storage you want the same, so you can make use of external cluster in that way. As you see like there is a standalone external CIF cluster that has been connected to different Kubernetes cluster and have isolation of what kind of data is stored and only access that data only, that is internal algorithm that maps the secret and puts your data safe. So this is how you can, like this is one use case when you can use external CIF cluster. So you see like for example you are native, you are already using CIF but you want to come into the Kubernetes world, so that would be one of the use case and the third would be like if you need complete isolation of data, like someone wants to keep the data totally separate, so then you can use that. So but external cluster provides all the three types of data, block file object, there is no restriction on that, so you can make use of that. So this is why external CIF cluster now comes apart how we can install it and how it internally works. Like I showed you like in the diagram we have to grab the information from the standalone cluster and give it to the Kubernetes cluster, so this is how it's been done. So there is a provider cluster that standalone where demons are running, so cluster admin will come, it will scrape the data from it and once scraping the data it will provide it to the consumer cluster and this is the Kubernetes cluster that is running. So that data it will create some secrets config map and after we have the details what all it has been first, like it will give the IP address and other details that we needed and once it's done it will give it to the Roku operator and Roku operator will perform in the external mode this time and will create the Roku resources and the storage class and then we can create PVCs and mount that PVCs to your application ports. So this is the working and how this scraping is done, so there is a Python script we have to give some CLI flags to it and this should be like user defined what kind of flags they are, like it's RBD data pool name or RGB endpoint, so if we give like the specific name of the pool then we run some self commands with this Python script and it will fetch the data. Like the monitoring endpoints and other things and give it to the Kubernetes cluster and once we have the JSON data then we run the import script for it to import it to the Kubernetes cluster and deploy the manifest, these are the CRDs, the definitions, how we want to configure our external cluster. So I will be showing this into them in the demo how this works. And once it's done then we will verify the connection, like we have the cluster running and so how we can check it, we can just get the self cluster and we can see it's in the connected and the health okay state. And then goes like we can go and create the storage class, pool and create PVC, on depending like what kind of storage you need, you need Cephaphase or RBD or RGW. And now comes the time for the demo. Everything breaks so I have recorded the demo. So is it visible? So this is the standalone self cluster where we can see the health is okay and now there are some pools already been there, RBD pools, so these are some self native commands that we can run by this Cephaphase, we list these Cephaphase file system pools. Now there is a Python script, I'm giving using the CLI flags and you can see I run the Python script with some flags and I got the exported data. So this was like external cluster, I export this data, then I will take this to the Kubernetes cluster that's the second cluster, we'll copy this and so in this terminal like there was the Minicube running and I have exported it and now I will run the import script that will use this exported values and create the config and I have to see grids for the Kubernetes. And after that I have to install the manifest, the CRDs, the definitions, I am using the example folder of Rook in which there are already defined some configurations so I am using that only for now. So there would be CRDs.ML, there would be common.ML which have the Rbex, the specific permissions to it, what permissions I need to give and the operator.ML, the Rook operator file and the cluster external, this is the Ceph extender cluster that I will create in Rook, in the Kubernetes side and there is also common external which creates the separate namespace if we want to keep the Ceph cluster in different namespace. So in this I am using a separate namespace for the Ceph cluster and for the Kubernetes cluster I am using the separate namespace in which the Rook operator resides. And now I am checking, I have created all the manifest, now I am waiting like to get the Ceph cluster up and running. So the Ceph cluster is created and so this is the Ceph cluster, internals, YAML if you want to see and now I will describe it and you can see like it is ready. Now the main thing is I have to wait for the Rook operator to get started. So this is how all the parts that will be get started, there is a Rook operator, there are some Ceph CSI plugins, demons that will use to mount the data and yeah that's all. And other demons are already running in external Ceph cluster, the Mons, OSDs in which our data will resides. So the connection is good what I have shown in previous slides, now I have created the storage class, the storage class will be also be created, we can create some others if we needed. Now in this demo I will tell you like how we can create a RBDPVC and store data and how it's disaster proven or how it's how Ceph internally replicates and make our data safe. So now the demo starts for that. So once we have the storage class the Ceph RBD or the Rook Ceph block these two belongs to the block pool and now I am creating this MySQL example in which it will create a MySQL pod and a PVC and a service to it. So what I will do is making use of that Ceph RBD storage class, I will create this PVC and mount this PVC to the MySQL pod and there is a service if you want to see that MySQL service outside the mini-cube you can make use of that service. So the PVC is created, you have the pod, I will wait for the pod, PVC is bounced it and pod is still getting created, the word press MySQL and the service is created. Once the pod is created, it's up and running. Now I will go inside the pod and I will go to the mount path that I have written and I will create a file in it. So this is actual application for example MySQL that might be your actual application there and what I am doing right now here. So this is I am telling like if you want to use a node pod service like this is something that is needed if you want to see are like I am on mini-cube if you want to see the cluster outside whatever you can use this node pod service but the main thing is the data so focusing on that. So I am inside the pod using this command, escape command. So I am inside it now I will go to a certain path that's the mount pod where the PVC is been mounted that is where so while creating the pod I have given this path so I am using that only and now in this part where PVC will write the data so I am creating a demo dot TXT where I will say I will be persisted because of CIF replication and now I will go so this is inside the mount pod and I will go and delete this pod. So this is file has been created I mean so it the pod now I will delete the pod for example there is a disaster this pod has been deleted I will delete this and as it is a deployment it will create again in some other node as the pod is deleted and now I can see the pod is recreated by Kubernetes it is 9 second ago and I will go inside it again to the exact path the CD where live mySQL and I can see that that file should re-exist there where live mySQL and if I cat it so there is still demo dot TXT even if the pod was gone but the file was still exist you can see that and that's all with the demo and quickly back to the slides so these are some new features we have added the RIDOS namespace the IPv6 support and the RGW multisite and we are also going to add some new more features the replica one and support for the topology awareness and also to improve the documentation and these are some community links and thanks for that this is my LinkedIn logo if you want someone wants to connect and yeah thanks for that any questions anyone have what credentials do you need to abstract after get all the information from the subcluster do you need to be admin user or can you also be a regular user so if you don't want to expose adding credentials to a user so can you do actually do this as a user with enough self to make an export of all these information and bring it into your own okay so the question is what all permissions we need when we actually the export the data the client admin is there like which actually gets the data and give it to the Kubernetes cluster so what all permissions we needed so we keep the permissions minimum we can give the admin key ring but we just give the minimum permissions to it to just read and write because we don't allow ROOP to create anything on this subcluster we just allow to read the data and manage it so that's the minimum permissions that was required to CFCSI so we expose that only anyone else okay I guess thanks thank you all", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 12.52, "text": " Thank you so much guys.", "tokens": [50364, 1044, 291, 370, 709, 1074, 13, 50990], "temperature": 0.0, "avg_logprob": -0.34235782623291017, "compression_ratio": 1.4230769230769231, "no_speech_prob": 0.3359755575656891}, {"id": 1, "seek": 0, "start": 12.52, "end": 17.56, "text": " So is my audio, can everyone hear my voice?", "tokens": [50990, 407, 307, 452, 6278, 11, 393, 1518, 1568, 452, 3177, 30, 51242], "temperature": 0.0, "avg_logprob": -0.34235782623291017, "compression_ratio": 1.4230769230769231, "no_speech_prob": 0.3359755575656891}, {"id": 2, "seek": 0, "start": 17.56, "end": 18.56, "text": " Perfect.", "tokens": [51242, 10246, 13, 51292], "temperature": 0.0, "avg_logprob": -0.34235782623291017, "compression_ratio": 1.4230769230769231, "no_speech_prob": 0.3359755575656891}, {"id": 3, "seek": 0, "start": 18.56, "end": 22.400000000000002, "text": " So I would be talking about external Rooksef cluster.", "tokens": [51292, 407, 286, 576, 312, 1417, 466, 8320, 497, 1212, 405, 69, 13630, 13, 51484], "temperature": 0.0, "avg_logprob": -0.34235782623291017, "compression_ratio": 1.4230769230769231, "no_speech_prob": 0.3359755575656891}, {"id": 4, "seek": 0, "start": 22.400000000000002, "end": 27.080000000000002, "text": " So people might not be aware like what's Rook, what's Sef and what thing I'm talking", "tokens": [51484, 407, 561, 1062, 406, 312, 3650, 411, 437, 311, 497, 1212, 11, 437, 311, 1100, 69, 293, 437, 551, 286, 478, 1417, 51718], "temperature": 0.0, "avg_logprob": -0.34235782623291017, "compression_ratio": 1.4230769230769231, "no_speech_prob": 0.3359755575656891}, {"id": 5, "seek": 0, "start": 27.080000000000002, "end": 28.080000000000002, "text": " about.", "tokens": [51718, 466, 13, 51768], "temperature": 0.0, "avg_logprob": -0.34235782623291017, "compression_ratio": 1.4230769230769231, "no_speech_prob": 0.3359755575656891}, {"id": 6, "seek": 2808, "start": 28.08, "end": 31.959999999999997, "text": " So I will tell you to the intro first about what topic is this and then we'll deep dive", "tokens": [50364, 407, 286, 486, 980, 291, 281, 264, 12897, 700, 466, 437, 4829, 307, 341, 293, 550, 321, 603, 2452, 9192, 50558], "temperature": 0.0, "avg_logprob": -0.28111566499222157, "compression_ratio": 1.5491071428571428, "no_speech_prob": 0.05475326254963875}, {"id": 7, "seek": 2808, "start": 31.959999999999997, "end": 35.4, "text": " into this topic.", "tokens": [50558, 666, 341, 4829, 13, 50730], "temperature": 0.0, "avg_logprob": -0.28111566499222157, "compression_ratio": 1.5491071428571428, "no_speech_prob": 0.05475326254963875}, {"id": 8, "seek": 2808, "start": 35.4, "end": 43.48, "text": " So I am Parth Arora and I work for IBM Storage as a software developer and closely with Rook", "tokens": [50730, 407, 286, 669, 3457, 392, 1587, 3252, 293, 286, 589, 337, 23487, 36308, 382, 257, 4722, 10754, 293, 8185, 365, 497, 1212, 51134], "temperature": 0.0, "avg_logprob": -0.28111566499222157, "compression_ratio": 1.5491071428571428, "no_speech_prob": 0.05475326254963875}, {"id": 9, "seek": 2808, "start": 43.48, "end": 50.12, "text": " operator and I'm one of the lead approver of that repo.", "tokens": [51134, 12973, 293, 286, 478, 472, 295, 264, 1477, 2075, 331, 295, 300, 49040, 13, 51466], "temperature": 0.0, "avg_logprob": -0.28111566499222157, "compression_ratio": 1.5491071428571428, "no_speech_prob": 0.05475326254963875}, {"id": 10, "seek": 2808, "start": 50.12, "end": 56.8, "text": " So anybody like might be storing data applications, creating applications through Kubernetes,", "tokens": [51466, 407, 4472, 411, 1062, 312, 26085, 1412, 5821, 11, 4084, 5821, 807, 23145, 11, 51800], "temperature": 0.0, "avg_logprob": -0.28111566499222157, "compression_ratio": 1.5491071428571428, "no_speech_prob": 0.05475326254963875}, {"id": 11, "seek": 5680, "start": 57.8, "end": 63.519999999999996, "text": " but everyone knows like Kubernetes is designed in terms like which doesn't talks much about", "tokens": [50414, 457, 1518, 3255, 411, 23145, 307, 4761, 294, 2115, 411, 597, 1177, 380, 6686, 709, 466, 50700], "temperature": 0.0, "avg_logprob": -0.20210673411687216, "compression_ratio": 1.7659574468085106, "no_speech_prob": 0.008097723126411438}, {"id": 12, "seek": 5680, "start": 63.519999999999996, "end": 69.08, "text": " data but anyhow any application we can talk about there is storage for that and we need", "tokens": [50700, 1412, 457, 44995, 604, 3861, 321, 393, 751, 466, 456, 307, 6725, 337, 300, 293, 321, 643, 50978], "temperature": 0.0, "avg_logprob": -0.20210673411687216, "compression_ratio": 1.7659574468085106, "no_speech_prob": 0.008097723126411438}, {"id": 13, "seek": 5680, "start": 69.08, "end": 71.64, "text": " to store data in it.", "tokens": [50978, 281, 3531, 1412, 294, 309, 13, 51106], "temperature": 0.0, "avg_logprob": -0.20210673411687216, "compression_ratio": 1.7659574468085106, "no_speech_prob": 0.008097723126411438}, {"id": 14, "seek": 5680, "start": 71.64, "end": 77.12, "text": " And for now if someone wants to store the data that is coming from Kubernetes application,", "tokens": [51106, 400, 337, 586, 498, 1580, 2738, 281, 3531, 264, 1412, 300, 307, 1348, 490, 23145, 3861, 11, 51380], "temperature": 0.0, "avg_logprob": -0.20210673411687216, "compression_ratio": 1.7659574468085106, "no_speech_prob": 0.008097723126411438}, {"id": 15, "seek": 5680, "start": 77.12, "end": 82.84, "text": " we just talk about cloud providers and talking to the cloud and they might be doing anything", "tokens": [51380, 321, 445, 751, 466, 4588, 11330, 293, 1417, 281, 264, 4588, 293, 436, 1062, 312, 884, 1340, 51666], "temperature": 0.0, "avg_logprob": -0.20210673411687216, "compression_ratio": 1.7659574468085106, "no_speech_prob": 0.008097723126411438}, {"id": 16, "seek": 5680, "start": 82.84, "end": 85.24, "text": " we don't know at the back end.", "tokens": [51666, 321, 500, 380, 458, 412, 264, 646, 917, 13, 51786], "temperature": 0.0, "avg_logprob": -0.20210673411687216, "compression_ratio": 1.7659574468085106, "no_speech_prob": 0.008097723126411438}, {"id": 17, "seek": 8524, "start": 85.24, "end": 90.52, "text": " So why not to bring the storage into your data center and traditionally like there are", "tokens": [50364, 407, 983, 406, 281, 1565, 264, 6725, 666, 428, 1412, 3056, 293, 19067, 411, 456, 366, 50628], "temperature": 0.0, "avg_logprob": -0.15191076066758896, "compression_ratio": 1.752212389380531, "no_speech_prob": 0.004892030730843544}, {"id": 18, "seek": 8524, "start": 90.52, "end": 95.11999999999999, "text": " some limitations also with cloud providers like number of nodes, how we can scale up", "tokens": [50628, 512, 15705, 611, 365, 4588, 11330, 411, 1230, 295, 13891, 11, 577, 321, 393, 4373, 493, 50858], "temperature": 0.0, "avg_logprob": -0.15191076066758896, "compression_ratio": 1.752212389380531, "no_speech_prob": 0.004892030730843544}, {"id": 19, "seek": 8524, "start": 95.11999999999999, "end": 96.6, "text": " the different AZs.", "tokens": [50858, 264, 819, 49698, 82, 13, 50932], "temperature": 0.0, "avg_logprob": -0.15191076066758896, "compression_ratio": 1.752212389380531, "no_speech_prob": 0.004892030730843544}, {"id": 20, "seek": 8524, "start": 96.6, "end": 102.19999999999999, "text": " So why not to have a native solution with your own Kubernetes cluster.", "tokens": [50932, 407, 983, 406, 281, 362, 257, 8470, 3827, 365, 428, 1065, 23145, 13630, 13, 51212], "temperature": 0.0, "avg_logprob": -0.15191076066758896, "compression_ratio": 1.752212389380531, "no_speech_prob": 0.004892030730843544}, {"id": 21, "seek": 8524, "start": 102.19999999999999, "end": 107.84, "text": " So and also like to manage that cluster how natively your Kubernetes application manages", "tokens": [51212, 407, 293, 611, 411, 281, 3067, 300, 13630, 577, 8470, 356, 428, 23145, 3861, 22489, 51494], "temperature": 0.0, "avg_logprob": -0.15191076066758896, "compression_ratio": 1.752212389380531, "no_speech_prob": 0.004892030730843544}, {"id": 22, "seek": 8524, "start": 107.84, "end": 112.0, "text": " and also manage that storage in the same way.", "tokens": [51494, 293, 611, 3067, 300, 6725, 294, 264, 912, 636, 13, 51702], "temperature": 0.0, "avg_logprob": -0.15191076066758896, "compression_ratio": 1.752212389380531, "no_speech_prob": 0.004892030730843544}, {"id": 23, "seek": 11200, "start": 112.0, "end": 122.72, "text": " So here comes the most trusted platform CIF that can like make the storage available to", "tokens": [50364, 407, 510, 1487, 264, 881, 16034, 3663, 383, 12775, 300, 393, 411, 652, 264, 6725, 2435, 281, 50900], "temperature": 0.0, "avg_logprob": -0.21264456257675635, "compression_ratio": 1.5227272727272727, "no_speech_prob": 0.005017614923417568}, {"id": 24, "seek": 11200, "start": 122.72, "end": 128.92000000000002, "text": " you in the form of Kubernetes, how it will be but first I will talk about CIF, why CIF.", "tokens": [50900, 291, 294, 264, 1254, 295, 23145, 11, 577, 309, 486, 312, 457, 700, 286, 486, 751, 466, 383, 12775, 11, 983, 383, 12775, 13, 51210], "temperature": 0.0, "avg_logprob": -0.21264456257675635, "compression_ratio": 1.5227272727272727, "no_speech_prob": 0.005017614923417568}, {"id": 25, "seek": 11200, "start": 128.92000000000002, "end": 139.36, "text": " So it's like it has a lot of enterprise already enterprises using from like trusted platform", "tokens": [51210, 407, 309, 311, 411, 309, 575, 257, 688, 295, 14132, 1217, 29034, 1228, 490, 411, 16034, 3663, 51732], "temperature": 0.0, "avg_logprob": -0.21264456257675635, "compression_ratio": 1.5227272727272727, "no_speech_prob": 0.005017614923417568}, {"id": 26, "seek": 13936, "start": 139.36, "end": 143.4, "text": " from past 10 years and it provides all the storage at the same time the block file and", "tokens": [50364, 490, 1791, 1266, 924, 293, 309, 6417, 439, 264, 6725, 412, 264, 912, 565, 264, 3461, 3991, 293, 50566], "temperature": 0.0, "avg_logprob": -0.2396948750813802, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.07089369744062424}, {"id": 27, "seek": 13936, "start": 143.4, "end": 150.12, "text": " object you name it and it provides and its open source and it has so many features its", "tokens": [50566, 2657, 291, 1315, 309, 293, 309, 6417, 293, 1080, 1269, 4009, 293, 309, 575, 370, 867, 4122, 1080, 50902], "temperature": 0.0, "avg_logprob": -0.2396948750813802, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.07089369744062424}, {"id": 28, "seek": 13936, "start": 150.12, "end": 157.36, "text": " resilient, it's configurable, it's more disaster proven and it's consistent and provide like", "tokens": [50902, 23699, 11, 309, 311, 22192, 712, 11, 309, 311, 544, 11293, 12785, 293, 309, 311, 8398, 293, 2893, 411, 51264], "temperature": 0.0, "avg_logprob": -0.2396948750813802, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.07089369744062424}, {"id": 29, "seek": 13936, "start": 157.36, "end": 164.04000000000002, "text": " like give your data a safe point of view.", "tokens": [51264, 411, 976, 428, 1412, 257, 3273, 935, 295, 1910, 13, 51598], "temperature": 0.0, "avg_logprob": -0.2396948750813802, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.07089369744062424}, {"id": 30, "seek": 16404, "start": 164.04, "end": 169.44, "text": " And so CIF was designed even back when Kubernetes was introduced.", "tokens": [50364, 400, 370, 383, 12775, 390, 4761, 754, 646, 562, 23145, 390, 7268, 13, 50634], "temperature": 0.0, "avg_logprob": -0.1996823874386874, "compression_ratio": 1.7190476190476192, "no_speech_prob": 0.15686224400997162}, {"id": 31, "seek": 16404, "start": 169.44, "end": 174.6, "text": " So to bring the storage to the Kubernetes world we have designed Rook and this is how", "tokens": [50634, 407, 281, 1565, 264, 6725, 281, 264, 23145, 1002, 321, 362, 4761, 497, 1212, 293, 341, 307, 577, 50892], "temperature": 0.0, "avg_logprob": -0.1996823874386874, "compression_ratio": 1.7190476190476192, "no_speech_prob": 0.15686224400997162}, {"id": 32, "seek": 16404, "start": 174.6, "end": 178.16, "text": " it was born to bring the CIF to the Kubernetes.", "tokens": [50892, 309, 390, 4232, 281, 1565, 264, 383, 12775, 281, 264, 23145, 13, 51070], "temperature": 0.0, "avg_logprob": -0.1996823874386874, "compression_ratio": 1.7190476190476192, "no_speech_prob": 0.15686224400997162}, {"id": 33, "seek": 16404, "start": 178.16, "end": 183.48, "text": " It's the management layer so it helps in installing and managing the state.", "tokens": [51070, 467, 311, 264, 4592, 4583, 370, 309, 3665, 294, 20762, 293, 11642, 264, 1785, 13, 51336], "temperature": 0.0, "avg_logprob": -0.1996823874386874, "compression_ratio": 1.7190476190476192, "no_speech_prob": 0.15686224400997162}, {"id": 34, "seek": 16404, "start": 183.48, "end": 187.56, "text": " It's not just like it's there are Python scripts that just install it but it actually", "tokens": [51336, 467, 311, 406, 445, 411, 309, 311, 456, 366, 15329, 23294, 300, 445, 3625, 309, 457, 309, 767, 51540], "temperature": 0.0, "avg_logprob": -0.1996823874386874, "compression_ratio": 1.7190476190476192, "no_speech_prob": 0.15686224400997162}, {"id": 35, "seek": 18756, "start": 187.56, "end": 189.52, "text": " manage the state of it.", "tokens": [50364, 3067, 264, 1785, 295, 309, 13, 50462], "temperature": 0.0, "avg_logprob": -0.20830484084141107, "compression_ratio": 1.770949720670391, "no_speech_prob": 0.35644978284835815}, {"id": 36, "seek": 18756, "start": 189.52, "end": 197.6, "text": " How it does it's a Kubernetes operator which works how a Kubernetes actual desired and", "tokens": [50462, 1012, 309, 775, 309, 311, 257, 23145, 12973, 597, 1985, 577, 257, 23145, 3539, 14721, 293, 50866], "temperature": 0.0, "avg_logprob": -0.20830484084141107, "compression_ratio": 1.770949720670391, "no_speech_prob": 0.35644978284835815}, {"id": 37, "seek": 18756, "start": 197.6, "end": 203.56, "text": " actual state works and we can manage to that and how we can define what we need to give", "tokens": [50866, 3539, 1785, 1985, 293, 321, 393, 3067, 281, 300, 293, 577, 321, 393, 6964, 437, 321, 643, 281, 976, 51164], "temperature": 0.0, "avg_logprob": -0.20830484084141107, "compression_ratio": 1.770949720670391, "no_speech_prob": 0.35644978284835815}, {"id": 38, "seek": 18756, "start": 203.56, "end": 205.92000000000002, "text": " the state so that's the CRDs.", "tokens": [51164, 264, 1785, 370, 300, 311, 264, 14123, 35, 82, 13, 51282], "temperature": 0.0, "avg_logprob": -0.20830484084141107, "compression_ratio": 1.770949720670391, "no_speech_prob": 0.35644978284835815}, {"id": 39, "seek": 18756, "start": 205.92000000000002, "end": 215.64000000000001, "text": " We can give any definition to that and that thing can be configured and like we can give", "tokens": [51282, 492, 393, 976, 604, 7123, 281, 300, 293, 300, 551, 393, 312, 30538, 293, 411, 321, 393, 976, 51768], "temperature": 0.0, "avg_logprob": -0.20830484084141107, "compression_ratio": 1.770949720670391, "no_speech_prob": 0.35644978284835815}, {"id": 40, "seek": 21564, "start": 216.0, "end": 221.76, "text": " I need monitoring, I need the block storage so these types of things we can provide through", "tokens": [50382, 286, 643, 11028, 11, 286, 643, 264, 3461, 6725, 370, 613, 3467, 295, 721, 321, 393, 2893, 807, 50670], "temperature": 0.0, "avg_logprob": -0.31521265029907225, "compression_ratio": 1.6008771929824561, "no_speech_prob": 0.023575324565172195}, {"id": 41, "seek": 21564, "start": 221.76, "end": 224.6, "text": " CRDs.", "tokens": [50670, 14123, 35, 82, 13, 50812], "temperature": 0.0, "avg_logprob": -0.31521265029907225, "compression_ratio": 1.6008771929824561, "no_speech_prob": 0.023575324565172195}, {"id": 42, "seek": 21564, "start": 224.6, "end": 228.95999999999998, "text": " And so this is how the architecture of Rook CIF looks like, Rook is the management layer", "tokens": [50812, 400, 370, 341, 307, 577, 264, 9482, 295, 497, 1212, 383, 12775, 1542, 411, 11, 497, 1212, 307, 264, 4592, 4583, 51030], "temperature": 0.0, "avg_logprob": -0.31521265029907225, "compression_ratio": 1.6008771929824561, "no_speech_prob": 0.023575324565172195}, {"id": 43, "seek": 21564, "start": 228.95999999999998, "end": 237.67999999999998, "text": " which installs CIFs, the CIFC driver which helps in mounting the port, like the storage", "tokens": [51030, 597, 3625, 82, 383, 12775, 82, 11, 264, 383, 12775, 34, 6787, 597, 3665, 294, 22986, 264, 2436, 11, 411, 264, 6725, 51466], "temperature": 0.0, "avg_logprob": -0.31521265029907225, "compression_ratio": 1.6008771929824561, "no_speech_prob": 0.023575324565172195}, {"id": 44, "seek": 21564, "start": 237.67999999999998, "end": 243.79999999999998, "text": " to your application port, how it's the native Kubernetes we have CIFC or CIF and CIF being", "tokens": [51466, 281, 428, 3861, 2436, 11, 577, 309, 311, 264, 8470, 23145, 321, 362, 383, 12775, 34, 420, 383, 12775, 293, 383, 12775, 885, 51772], "temperature": 0.0, "avg_logprob": -0.31521265029907225, "compression_ratio": 1.6008771929824561, "no_speech_prob": 0.023575324565172195}, {"id": 45, "seek": 24380, "start": 243.88000000000002, "end": 246.88000000000002, "text": " the data layer.", "tokens": [50368, 264, 1412, 4583, 13, 50518], "temperature": 0.0, "avg_logprob": -0.2546255509931963, "compression_ratio": 1.6712962962962963, "no_speech_prob": 0.00824609212577343}, {"id": 46, "seek": 24380, "start": 246.88000000000002, "end": 254.84, "text": " And Rook works in two mode, so first is what I talked about bringing the storage into your", "tokens": [50518, 400, 497, 1212, 1985, 294, 732, 4391, 11, 370, 700, 307, 437, 286, 2825, 466, 5062, 264, 6725, 666, 428, 50916], "temperature": 0.0, "avg_logprob": -0.2546255509931963, "compression_ratio": 1.6712962962962963, "no_speech_prob": 0.00824609212577343}, {"id": 47, "seek": 24380, "start": 254.84, "end": 260.2, "text": " application cluster only, the same cluster that would be the Rook Converse mode.", "tokens": [50916, 3861, 13630, 787, 11, 264, 912, 13630, 300, 576, 312, 264, 497, 1212, 2656, 4308, 4391, 13, 51184], "temperature": 0.0, "avg_logprob": -0.2546255509931963, "compression_ratio": 1.6712962962962963, "no_speech_prob": 0.00824609212577343}, {"id": 48, "seek": 24380, "start": 260.2, "end": 266.12, "text": " It's recommended if like we just have one to the single cluster but when we need external", "tokens": [51184, 467, 311, 9628, 498, 411, 321, 445, 362, 472, 281, 264, 2167, 13630, 457, 562, 321, 643, 8320, 51480], "temperature": 0.0, "avg_logprob": -0.2546255509931963, "compression_ratio": 1.6712962962962963, "no_speech_prob": 0.00824609212577343}, {"id": 49, "seek": 24380, "start": 266.12, "end": 270.04, "text": " cluster that I would be talking about.", "tokens": [51480, 13630, 300, 286, 576, 312, 1417, 466, 13, 51676], "temperature": 0.0, "avg_logprob": -0.2546255509931963, "compression_ratio": 1.6712962962962963, "no_speech_prob": 0.00824609212577343}, {"id": 50, "seek": 24380, "start": 270.04, "end": 273.12, "text": " So first of all what an external cluster is.", "tokens": [51676, 407, 700, 295, 439, 437, 364, 8320, 13630, 307, 13, 51830], "temperature": 0.0, "avg_logprob": -0.2546255509931963, "compression_ratio": 1.6712962962962963, "no_speech_prob": 0.00824609212577343}, {"id": 51, "seek": 27312, "start": 273.12, "end": 279.2, "text": " So external cluster means you already have a CIF cluster installed in which like there", "tokens": [50364, 407, 8320, 13630, 1355, 291, 1217, 362, 257, 383, 12775, 13630, 8899, 294, 597, 411, 456, 50668], "temperature": 0.0, "avg_logprob": -0.21729149591355096, "compression_ratio": 1.641350210970464, "no_speech_prob": 0.0006234662723727524}, {"id": 52, "seek": 27312, "start": 279.2, "end": 285.52, "text": " are CIF domains, these are the CIF terminologies, the mon, OSTs, RGWMDS, these are some domains", "tokens": [50668, 366, 383, 12775, 25514, 11, 613, 366, 264, 383, 12775, 10761, 6204, 11, 264, 1108, 11, 422, 6840, 82, 11, 497, 38, 54, 44, 11844, 11, 613, 366, 512, 25514, 50984], "temperature": 0.0, "avg_logprob": -0.21729149591355096, "compression_ratio": 1.641350210970464, "no_speech_prob": 0.0006234662723727524}, {"id": 53, "seek": 27312, "start": 285.52, "end": 289.2, "text": " running that helps your storage to like store the data.", "tokens": [50984, 2614, 300, 3665, 428, 6725, 281, 411, 3531, 264, 1412, 13, 51168], "temperature": 0.0, "avg_logprob": -0.21729149591355096, "compression_ratio": 1.641350210970464, "no_speech_prob": 0.0006234662723727524}, {"id": 54, "seek": 27312, "start": 289.2, "end": 295.16, "text": " So it's already been there and now comes the part like I'm in Kubernetes world, I need", "tokens": [51168, 407, 309, 311, 1217, 668, 456, 293, 586, 1487, 264, 644, 411, 286, 478, 294, 23145, 1002, 11, 286, 643, 51466], "temperature": 0.0, "avg_logprob": -0.21729149591355096, "compression_ratio": 1.641350210970464, "no_speech_prob": 0.0006234662723727524}, {"id": 55, "seek": 27312, "start": 295.16, "end": 299.08, "text": " to connect this CIF to the Kubernetes, so how will you do that?", "tokens": [51466, 281, 1745, 341, 383, 12775, 281, 264, 23145, 11, 370, 577, 486, 291, 360, 300, 30, 51662], "temperature": 0.0, "avg_logprob": -0.21729149591355096, "compression_ratio": 1.641350210970464, "no_speech_prob": 0.0006234662723727524}, {"id": 56, "seek": 29908, "start": 299.12, "end": 304.64, "text": " So there would be a separate Kubernetes cluster running in which there would be a Rook operator", "tokens": [50366, 407, 456, 576, 312, 257, 4994, 23145, 13630, 2614, 294, 597, 456, 576, 312, 257, 497, 1212, 12973, 50642], "temperature": 0.0, "avg_logprob": -0.24785188881747694, "compression_ratio": 1.6502463054187193, "no_speech_prob": 0.0037273126654326916}, {"id": 57, "seek": 29908, "start": 304.64, "end": 311.64, "text": " and this FCS earlier and we need to provide data of external CIF cluster to Kubernetes,", "tokens": [50642, 293, 341, 479, 26283, 3071, 293, 321, 643, 281, 2893, 1412, 295, 8320, 383, 12775, 13630, 281, 23145, 11, 50992], "temperature": 0.0, "avg_logprob": -0.24785188881747694, "compression_ratio": 1.6502463054187193, "no_speech_prob": 0.0037273126654326916}, {"id": 58, "seek": 29908, "start": 312.36, "end": 317.44, "text": " so how that magic does, so I will be taking to that part.", "tokens": [51028, 370, 577, 300, 5585, 775, 11, 370, 286, 486, 312, 1940, 281, 300, 644, 13, 51282], "temperature": 0.0, "avg_logprob": -0.24785188881747694, "compression_ratio": 1.6502463054187193, "no_speech_prob": 0.0037273126654326916}, {"id": 59, "seek": 29908, "start": 317.44, "end": 324.44, "text": " So first of all I will tell why you need external cluster, in what cases like I told you like", "tokens": [51282, 407, 700, 295, 439, 286, 486, 980, 983, 291, 643, 8320, 13630, 11, 294, 437, 3331, 411, 286, 1907, 291, 411, 51632], "temperature": 0.0, "avg_logprob": -0.24785188881747694, "compression_ratio": 1.6502463054187193, "no_speech_prob": 0.0037273126654326916}, {"id": 60, "seek": 32444, "start": 325.0, "end": 331.0, "text": " you can have this same cluster in your native application, so why you need external cluster.", "tokens": [50392, 291, 393, 362, 341, 912, 13630, 294, 428, 8470, 3861, 11, 370, 983, 291, 643, 8320, 13630, 13, 50692], "temperature": 0.0, "avg_logprob": -0.2475095729237979, "compression_ratio": 1.8072289156626506, "no_speech_prob": 0.003910442348569632}, {"id": 61, "seek": 32444, "start": 331.0, "end": 338.0, "text": " So you might be having a big enterprise where you have like different domains of Kubernetes", "tokens": [50692, 407, 291, 1062, 312, 1419, 257, 955, 14132, 689, 291, 362, 411, 819, 25514, 295, 23145, 51042], "temperature": 0.0, "avg_logprob": -0.2475095729237979, "compression_ratio": 1.8072289156626506, "no_speech_prob": 0.003910442348569632}, {"id": 62, "seek": 32444, "start": 339.52, "end": 344.15999999999997, "text": " cluster running, like there is an admin cluster that is there and there is a finance cluster", "tokens": [51118, 13630, 2614, 11, 411, 456, 307, 364, 24236, 13630, 300, 307, 456, 293, 456, 307, 257, 10719, 13630, 51350], "temperature": 0.0, "avg_logprob": -0.2475095729237979, "compression_ratio": 1.8072289156626506, "no_speech_prob": 0.003910442348569632}, {"id": 63, "seek": 32444, "start": 344.15999999999997, "end": 349.0, "text": " department Kubernetes cluster there and you need isolation between them, they shouldn't", "tokens": [51350, 5882, 23145, 13630, 456, 293, 291, 643, 16001, 1296, 552, 11, 436, 4659, 380, 51592], "temperature": 0.0, "avg_logprob": -0.2475095729237979, "compression_ratio": 1.8072289156626506, "no_speech_prob": 0.003910442348569632}, {"id": 64, "seek": 32444, "start": 349.0, "end": 354.0, "text": " talk with each other and underline storage you want the same, so you can make use of", "tokens": [51592, 751, 365, 1184, 661, 293, 833, 1889, 6725, 291, 528, 264, 912, 11, 370, 291, 393, 652, 764, 295, 51842], "temperature": 0.0, "avg_logprob": -0.2475095729237979, "compression_ratio": 1.8072289156626506, "no_speech_prob": 0.003910442348569632}, {"id": 65, "seek": 35400, "start": 354.04, "end": 357.16, "text": " external cluster in that way.", "tokens": [50366, 8320, 13630, 294, 300, 636, 13, 50522], "temperature": 0.0, "avg_logprob": -0.1812782706795158, "compression_ratio": 1.7477477477477477, "no_speech_prob": 0.0015453269006684422}, {"id": 66, "seek": 35400, "start": 357.16, "end": 361.36, "text": " As you see like there is a standalone external CIF cluster that has been connected to different", "tokens": [50522, 1018, 291, 536, 411, 456, 307, 257, 37454, 8320, 383, 12775, 13630, 300, 575, 668, 4582, 281, 819, 50732], "temperature": 0.0, "avg_logprob": -0.1812782706795158, "compression_ratio": 1.7477477477477477, "no_speech_prob": 0.0015453269006684422}, {"id": 67, "seek": 35400, "start": 361.36, "end": 367.4, "text": " Kubernetes cluster and have isolation of what kind of data is stored and only access that", "tokens": [50732, 23145, 13630, 293, 362, 16001, 295, 437, 733, 295, 1412, 307, 12187, 293, 787, 2105, 300, 51034], "temperature": 0.0, "avg_logprob": -0.1812782706795158, "compression_ratio": 1.7477477477477477, "no_speech_prob": 0.0015453269006684422}, {"id": 68, "seek": 35400, "start": 367.4, "end": 374.4, "text": " data only, that is internal algorithm that maps the secret and puts your data safe.", "tokens": [51034, 1412, 787, 11, 300, 307, 6920, 9284, 300, 11317, 264, 4054, 293, 8137, 428, 1412, 3273, 13, 51384], "temperature": 0.0, "avg_logprob": -0.1812782706795158, "compression_ratio": 1.7477477477477477, "no_speech_prob": 0.0015453269006684422}, {"id": 69, "seek": 35400, "start": 375.2, "end": 381.28, "text": " So this is how you can, like this is one use case when you can use external CIF cluster.", "tokens": [51424, 407, 341, 307, 577, 291, 393, 11, 411, 341, 307, 472, 764, 1389, 562, 291, 393, 764, 8320, 383, 12775, 13630, 13, 51728], "temperature": 0.0, "avg_logprob": -0.1812782706795158, "compression_ratio": 1.7477477477477477, "no_speech_prob": 0.0015453269006684422}, {"id": 70, "seek": 38128, "start": 381.28, "end": 385.15999999999997, "text": " So you see like for example you are native, you are already using CIF but you want to", "tokens": [50364, 407, 291, 536, 411, 337, 1365, 291, 366, 8470, 11, 291, 366, 1217, 1228, 383, 12775, 457, 291, 528, 281, 50558], "temperature": 0.0, "avg_logprob": -0.2316676474906303, "compression_ratio": 1.7315175097276265, "no_speech_prob": 0.004055812954902649}, {"id": 71, "seek": 38128, "start": 385.15999999999997, "end": 389.96, "text": " come into the Kubernetes world, so that would be one of the use case and the third would", "tokens": [50558, 808, 666, 264, 23145, 1002, 11, 370, 300, 576, 312, 472, 295, 264, 764, 1389, 293, 264, 2636, 576, 50798], "temperature": 0.0, "avg_logprob": -0.2316676474906303, "compression_ratio": 1.7315175097276265, "no_speech_prob": 0.004055812954902649}, {"id": 72, "seek": 38128, "start": 389.96, "end": 395.96, "text": " be like if you need complete isolation of data, like someone wants to keep the data totally", "tokens": [50798, 312, 411, 498, 291, 643, 3566, 16001, 295, 1412, 11, 411, 1580, 2738, 281, 1066, 264, 1412, 3879, 51098], "temperature": 0.0, "avg_logprob": -0.2316676474906303, "compression_ratio": 1.7315175097276265, "no_speech_prob": 0.004055812954902649}, {"id": 73, "seek": 38128, "start": 395.96, "end": 399.79999999999995, "text": " separate, so then you can use that.", "tokens": [51098, 4994, 11, 370, 550, 291, 393, 764, 300, 13, 51290], "temperature": 0.0, "avg_logprob": -0.2316676474906303, "compression_ratio": 1.7315175097276265, "no_speech_prob": 0.004055812954902649}, {"id": 74, "seek": 38128, "start": 399.79999999999995, "end": 403.47999999999996, "text": " So but external cluster provides all the three types of data, block file object, there is", "tokens": [51290, 407, 457, 8320, 13630, 6417, 439, 264, 1045, 3467, 295, 1412, 11, 3461, 3991, 2657, 11, 456, 307, 51474], "temperature": 0.0, "avg_logprob": -0.2316676474906303, "compression_ratio": 1.7315175097276265, "no_speech_prob": 0.004055812954902649}, {"id": 75, "seek": 38128, "start": 403.47999999999996, "end": 407.03999999999996, "text": " no restriction on that, so you can make use of that.", "tokens": [51474, 572, 29529, 322, 300, 11, 370, 291, 393, 652, 764, 295, 300, 13, 51652], "temperature": 0.0, "avg_logprob": -0.2316676474906303, "compression_ratio": 1.7315175097276265, "no_speech_prob": 0.004055812954902649}, {"id": 76, "seek": 40704, "start": 407.08000000000004, "end": 412.24, "text": " So this is why external CIF cluster now comes apart how we can install it and how it internally", "tokens": [50366, 407, 341, 307, 983, 8320, 383, 12775, 13630, 586, 1487, 4936, 577, 321, 393, 3625, 309, 293, 577, 309, 19501, 50624], "temperature": 0.0, "avg_logprob": -0.17888874304099162, "compression_ratio": 1.9301470588235294, "no_speech_prob": 0.0034712408669292927}, {"id": 77, "seek": 40704, "start": 412.24, "end": 413.40000000000003, "text": " works.", "tokens": [50624, 1985, 13, 50682], "temperature": 0.0, "avg_logprob": -0.17888874304099162, "compression_ratio": 1.9301470588235294, "no_speech_prob": 0.0034712408669292927}, {"id": 78, "seek": 40704, "start": 413.40000000000003, "end": 418.0, "text": " Like I showed you like in the diagram we have to grab the information from the standalone", "tokens": [50682, 1743, 286, 4712, 291, 411, 294, 264, 10686, 321, 362, 281, 4444, 264, 1589, 490, 264, 37454, 50912], "temperature": 0.0, "avg_logprob": -0.17888874304099162, "compression_ratio": 1.9301470588235294, "no_speech_prob": 0.0034712408669292927}, {"id": 79, "seek": 40704, "start": 418.0, "end": 422.24, "text": " cluster and give it to the Kubernetes cluster, so this is how it's been done.", "tokens": [50912, 13630, 293, 976, 309, 281, 264, 23145, 13630, 11, 370, 341, 307, 577, 309, 311, 668, 1096, 13, 51124], "temperature": 0.0, "avg_logprob": -0.17888874304099162, "compression_ratio": 1.9301470588235294, "no_speech_prob": 0.0034712408669292927}, {"id": 80, "seek": 40704, "start": 422.24, "end": 426.40000000000003, "text": " So there is a provider cluster that standalone where demons are running, so cluster admin", "tokens": [51124, 407, 456, 307, 257, 12398, 13630, 300, 37454, 689, 19733, 366, 2614, 11, 370, 13630, 24236, 51332], "temperature": 0.0, "avg_logprob": -0.17888874304099162, "compression_ratio": 1.9301470588235294, "no_speech_prob": 0.0034712408669292927}, {"id": 81, "seek": 40704, "start": 426.40000000000003, "end": 432.12, "text": " will come, it will scrape the data from it and once scraping the data it will provide", "tokens": [51332, 486, 808, 11, 309, 486, 32827, 264, 1412, 490, 309, 293, 1564, 43738, 264, 1412, 309, 486, 2893, 51618], "temperature": 0.0, "avg_logprob": -0.17888874304099162, "compression_ratio": 1.9301470588235294, "no_speech_prob": 0.0034712408669292927}, {"id": 82, "seek": 40704, "start": 432.12, "end": 436.28000000000003, "text": " it to the consumer cluster and this is the Kubernetes cluster that is running.", "tokens": [51618, 309, 281, 264, 9711, 13630, 293, 341, 307, 264, 23145, 13630, 300, 307, 2614, 13, 51826], "temperature": 0.0, "avg_logprob": -0.17888874304099162, "compression_ratio": 1.9301470588235294, "no_speech_prob": 0.0034712408669292927}, {"id": 83, "seek": 43628, "start": 436.32, "end": 445.32, "text": " So that data it will create some secrets config map and after we have the details what all", "tokens": [50366, 407, 300, 1412, 309, 486, 1884, 512, 14093, 6662, 4471, 293, 934, 321, 362, 264, 4365, 437, 439, 50816], "temperature": 0.0, "avg_logprob": -0.17521323476518905, "compression_ratio": 1.7878787878787878, "no_speech_prob": 0.0026646156329661608}, {"id": 84, "seek": 43628, "start": 445.32, "end": 450.64, "text": " it has been first, like it will give the IP address and other details that we needed", "tokens": [50816, 309, 575, 668, 700, 11, 411, 309, 486, 976, 264, 8671, 2985, 293, 661, 4365, 300, 321, 2978, 51082], "temperature": 0.0, "avg_logprob": -0.17521323476518905, "compression_ratio": 1.7878787878787878, "no_speech_prob": 0.0026646156329661608}, {"id": 85, "seek": 43628, "start": 450.64, "end": 456.15999999999997, "text": " and once it's done it will give it to the Roku operator and Roku operator will perform", "tokens": [51082, 293, 1564, 309, 311, 1096, 309, 486, 976, 309, 281, 264, 497, 13275, 12973, 293, 497, 13275, 12973, 486, 2042, 51358], "temperature": 0.0, "avg_logprob": -0.17521323476518905, "compression_ratio": 1.7878787878787878, "no_speech_prob": 0.0026646156329661608}, {"id": 86, "seek": 43628, "start": 456.15999999999997, "end": 463.11999999999995, "text": " in the external mode this time and will create the Roku resources and the storage class and", "tokens": [51358, 294, 264, 8320, 4391, 341, 565, 293, 486, 1884, 264, 497, 13275, 3593, 293, 264, 6725, 1508, 293, 51706], "temperature": 0.0, "avg_logprob": -0.17521323476518905, "compression_ratio": 1.7878787878787878, "no_speech_prob": 0.0026646156329661608}, {"id": 87, "seek": 46312, "start": 463.12, "end": 466.56, "text": " then we can create PVCs and mount that PVCs to your application ports.", "tokens": [50364, 550, 321, 393, 1884, 46700, 82, 293, 3746, 300, 46700, 82, 281, 428, 3861, 18160, 13, 50536], "temperature": 0.0, "avg_logprob": -0.28220129450526804, "compression_ratio": 1.6590038314176245, "no_speech_prob": 0.005197203252464533}, {"id": 88, "seek": 46312, "start": 468.84000000000003, "end": 475.08, "text": " So this is the working and how this scraping is done, so there is a Python script we have", "tokens": [50650, 407, 341, 307, 264, 1364, 293, 577, 341, 43738, 307, 1096, 11, 370, 456, 307, 257, 15329, 5755, 321, 362, 50962], "temperature": 0.0, "avg_logprob": -0.28220129450526804, "compression_ratio": 1.6590038314176245, "no_speech_prob": 0.005197203252464533}, {"id": 89, "seek": 46312, "start": 475.08, "end": 482.2, "text": " to give some CLI flags to it and this should be like user defined what kind of flags they are,", "tokens": [50962, 281, 976, 512, 12855, 40, 23265, 281, 309, 293, 341, 820, 312, 411, 4195, 7642, 437, 733, 295, 23265, 436, 366, 11, 51318], "temperature": 0.0, "avg_logprob": -0.28220129450526804, "compression_ratio": 1.6590038314176245, "no_speech_prob": 0.005197203252464533}, {"id": 90, "seek": 46312, "start": 482.2, "end": 488.32, "text": " like it's RBD data pool name or RGB endpoint, so if we give like the specific name of the", "tokens": [51318, 411, 309, 311, 40302, 35, 1412, 7005, 1315, 420, 31231, 35795, 11, 370, 498, 321, 976, 411, 264, 2685, 1315, 295, 264, 51624], "temperature": 0.0, "avg_logprob": -0.28220129450526804, "compression_ratio": 1.6590038314176245, "no_speech_prob": 0.005197203252464533}, {"id": 91, "seek": 46312, "start": 488.32, "end": 492.48, "text": " pool then we run some self commands with this Python script and it will fetch the data.", "tokens": [51624, 7005, 550, 321, 1190, 512, 2698, 16901, 365, 341, 15329, 5755, 293, 309, 486, 23673, 264, 1412, 13, 51832], "temperature": 0.0, "avg_logprob": -0.28220129450526804, "compression_ratio": 1.6590038314176245, "no_speech_prob": 0.005197203252464533}, {"id": 92, "seek": 49312, "start": 493.16, "end": 500.12, "text": " Like the monitoring endpoints and other things and give it to the Kubernetes cluster and once", "tokens": [50366, 1743, 264, 11028, 917, 20552, 293, 661, 721, 293, 976, 309, 281, 264, 23145, 13630, 293, 1564, 50714], "temperature": 0.0, "avg_logprob": -0.2301948680434116, "compression_ratio": 1.7169811320754718, "no_speech_prob": 0.004520548973232508}, {"id": 93, "seek": 49312, "start": 500.12, "end": 506.24, "text": " we have the JSON data then we run the import script for it to import it to the Kubernetes", "tokens": [50714, 321, 362, 264, 31828, 1412, 550, 321, 1190, 264, 974, 5755, 337, 309, 281, 974, 309, 281, 264, 23145, 51020], "temperature": 0.0, "avg_logprob": -0.2301948680434116, "compression_ratio": 1.7169811320754718, "no_speech_prob": 0.004520548973232508}, {"id": 94, "seek": 49312, "start": 506.24, "end": 511.52, "text": " cluster and deploy the manifest, these are the CRDs, the definitions, how we want to configure", "tokens": [51020, 13630, 293, 7274, 264, 10067, 11, 613, 366, 264, 14123, 35, 82, 11, 264, 21988, 11, 577, 321, 528, 281, 22162, 51284], "temperature": 0.0, "avg_logprob": -0.2301948680434116, "compression_ratio": 1.7169811320754718, "no_speech_prob": 0.004520548973232508}, {"id": 95, "seek": 49312, "start": 511.52, "end": 516.24, "text": " our external cluster. So I will be showing this into them in the demo how this works.", "tokens": [51284, 527, 8320, 13630, 13, 407, 286, 486, 312, 4099, 341, 666, 552, 294, 264, 10723, 577, 341, 1985, 13, 51520], "temperature": 0.0, "avg_logprob": -0.2301948680434116, "compression_ratio": 1.7169811320754718, "no_speech_prob": 0.004520548973232508}, {"id": 96, "seek": 51624, "start": 517.24, "end": 524.32, "text": " And once it's done then we will verify the connection, like we have the cluster running", "tokens": [50414, 400, 1564, 309, 311, 1096, 550, 321, 486, 16888, 264, 4984, 11, 411, 321, 362, 264, 13630, 2614, 50768], "temperature": 0.0, "avg_logprob": -0.27147217591603595, "compression_ratio": 1.727699530516432, "no_speech_prob": 0.009370354004204273}, {"id": 97, "seek": 51624, "start": 524.32, "end": 529.84, "text": " and so how we can check it, we can just get the self cluster and we can see it's in the", "tokens": [50768, 293, 370, 577, 321, 393, 1520, 309, 11, 321, 393, 445, 483, 264, 2698, 13630, 293, 321, 393, 536, 309, 311, 294, 264, 51044], "temperature": 0.0, "avg_logprob": -0.27147217591603595, "compression_ratio": 1.727699530516432, "no_speech_prob": 0.009370354004204273}, {"id": 98, "seek": 51624, "start": 529.84, "end": 535.88, "text": " connected and the health okay state. And then goes like we can go and create the storage class,", "tokens": [51044, 4582, 293, 264, 1585, 1392, 1785, 13, 400, 550, 1709, 411, 321, 393, 352, 293, 1884, 264, 6725, 1508, 11, 51346], "temperature": 0.0, "avg_logprob": -0.27147217591603595, "compression_ratio": 1.727699530516432, "no_speech_prob": 0.009370354004204273}, {"id": 99, "seek": 51624, "start": 535.88, "end": 543.0, "text": " pool and create PVC, on depending like what kind of storage you need, you need Cephaphase or RBD", "tokens": [51346, 7005, 293, 1884, 46700, 11, 322, 5413, 411, 437, 733, 295, 6725, 291, 643, 11, 291, 643, 383, 595, 71, 13957, 651, 420, 40302, 35, 51702], "temperature": 0.0, "avg_logprob": -0.27147217591603595, "compression_ratio": 1.727699530516432, "no_speech_prob": 0.009370354004204273}, {"id": 100, "seek": 54300, "start": 543.0, "end": 553.04, "text": " or RGW. And now comes the time for the demo. Everything breaks so I have recorded the demo.", "tokens": [50364, 420, 497, 38, 54, 13, 400, 586, 1487, 264, 565, 337, 264, 10723, 13, 5471, 9857, 370, 286, 362, 8287, 264, 10723, 13, 50866], "temperature": 0.0, "avg_logprob": -0.2940746545791626, "compression_ratio": 1.3529411764705883, "no_speech_prob": 0.012075838632881641}, {"id": 101, "seek": 54300, "start": 561.04, "end": 571.04, "text": " So is it visible? So this is the standalone self cluster where we can see the health is okay", "tokens": [51266, 407, 307, 309, 8974, 30, 407, 341, 307, 264, 37454, 2698, 13630, 689, 321, 393, 536, 264, 1585, 307, 1392, 51766], "temperature": 0.0, "avg_logprob": -0.2940746545791626, "compression_ratio": 1.3529411764705883, "no_speech_prob": 0.012075838632881641}, {"id": 102, "seek": 57300, "start": 573.04, "end": 581.12, "text": " and now there are some pools already been there, RBD pools, so these are some self native", "tokens": [50366, 293, 586, 456, 366, 512, 28688, 1217, 668, 456, 11, 40302, 35, 28688, 11, 370, 613, 366, 512, 2698, 8470, 50770], "temperature": 0.0, "avg_logprob": -0.23145229300272832, "compression_ratio": 1.6409090909090909, "no_speech_prob": 0.006884574890136719}, {"id": 103, "seek": 57300, "start": 581.12, "end": 586.88, "text": " commands that we can run by this Cephaphase, we list these Cephaphase file system pools.", "tokens": [50770, 16901, 300, 321, 393, 1190, 538, 341, 383, 595, 71, 13957, 651, 11, 321, 1329, 613, 383, 595, 71, 13957, 651, 3991, 1185, 28688, 13, 51058], "temperature": 0.0, "avg_logprob": -0.23145229300272832, "compression_ratio": 1.6409090909090909, "no_speech_prob": 0.006884574890136719}, {"id": 104, "seek": 57300, "start": 586.88, "end": 593.76, "text": " Now there is a Python script, I'm giving using the CLI flags and you can see I run the Python", "tokens": [51058, 823, 456, 307, 257, 15329, 5755, 11, 286, 478, 2902, 1228, 264, 12855, 40, 23265, 293, 291, 393, 536, 286, 1190, 264, 15329, 51402], "temperature": 0.0, "avg_logprob": -0.23145229300272832, "compression_ratio": 1.6409090909090909, "no_speech_prob": 0.006884574890136719}, {"id": 105, "seek": 57300, "start": 593.76, "end": 599.84, "text": " script with some flags and I got the exported data. So this was like external cluster, I", "tokens": [51402, 5755, 365, 512, 23265, 293, 286, 658, 264, 42055, 1412, 13, 407, 341, 390, 411, 8320, 13630, 11, 286, 51706], "temperature": 0.0, "avg_logprob": -0.23145229300272832, "compression_ratio": 1.6409090909090909, "no_speech_prob": 0.006884574890136719}, {"id": 106, "seek": 59984, "start": 599.88, "end": 605.12, "text": " export this data, then I will take this to the Kubernetes cluster that's the second cluster,", "tokens": [50366, 10725, 341, 1412, 11, 550, 286, 486, 747, 341, 281, 264, 23145, 13630, 300, 311, 264, 1150, 13630, 11, 50628], "temperature": 0.0, "avg_logprob": -0.23261502963393482, "compression_ratio": 1.6964285714285714, "no_speech_prob": 0.002283482113853097}, {"id": 107, "seek": 59984, "start": 605.12, "end": 618.5600000000001, "text": " we'll copy this and so in this terminal like there was the Minicube running and I have exported it", "tokens": [50628, 321, 603, 5055, 341, 293, 370, 294, 341, 14709, 411, 456, 390, 264, 2829, 299, 1977, 2614, 293, 286, 362, 42055, 309, 51300], "temperature": 0.0, "avg_logprob": -0.23261502963393482, "compression_ratio": 1.6964285714285714, "no_speech_prob": 0.002283482113853097}, {"id": 108, "seek": 59984, "start": 618.5600000000001, "end": 626.72, "text": " and now I will run the import script that will use this exported values and create the config", "tokens": [51300, 293, 586, 286, 486, 1190, 264, 974, 5755, 300, 486, 764, 341, 42055, 4190, 293, 1884, 264, 6662, 51708], "temperature": 0.0, "avg_logprob": -0.23261502963393482, "compression_ratio": 1.6964285714285714, "no_speech_prob": 0.002283482113853097}, {"id": 109, "seek": 62672, "start": 626.72, "end": 636.52, "text": " and I have to see grids for the Kubernetes. And after that I have to install the manifest,", "tokens": [50364, 293, 286, 362, 281, 536, 677, 3742, 337, 264, 23145, 13, 400, 934, 300, 286, 362, 281, 3625, 264, 10067, 11, 50854], "temperature": 0.0, "avg_logprob": -0.3706724016289962, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.011989968828856945}, {"id": 110, "seek": 62672, "start": 636.52, "end": 643.44, "text": " the CRDs, the definitions, I am using the example folder of Rook in which there are already defined", "tokens": [50854, 264, 14123, 35, 82, 11, 264, 21988, 11, 286, 669, 1228, 264, 1365, 10820, 295, 497, 1212, 294, 597, 456, 366, 1217, 7642, 51200], "temperature": 0.0, "avg_logprob": -0.3706724016289962, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.011989968828856945}, {"id": 111, "seek": 62672, "start": 643.44, "end": 650.34, "text": " some configurations so I am using that only for now. So there would be CRDs.ML, there would be", "tokens": [51200, 512, 31493, 370, 286, 669, 1228, 300, 787, 337, 586, 13, 407, 456, 576, 312, 14123, 35, 82, 13, 12683, 11, 456, 576, 312, 51545], "temperature": 0.0, "avg_logprob": -0.3706724016289962, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.011989968828856945}, {"id": 112, "seek": 65034, "start": 650.82, "end": 656.22, "text": " common.ML which have the Rbex, the specific permissions to it, what permissions I need to", "tokens": [50388, 2689, 13, 12683, 597, 362, 264, 497, 650, 87, 11, 264, 2685, 32723, 281, 309, 11, 437, 32723, 286, 643, 281, 50658], "temperature": 0.0, "avg_logprob": -0.24565511354258363, "compression_ratio": 1.598802395209581, "no_speech_prob": 0.039872732013463974}, {"id": 113, "seek": 65034, "start": 656.22, "end": 669.4200000000001, "text": " give and the operator.ML, the Rook operator file and the cluster external, this is the", "tokens": [50658, 976, 293, 264, 12973, 13, 12683, 11, 264, 497, 1212, 12973, 3991, 293, 264, 13630, 8320, 11, 341, 307, 264, 51318], "temperature": 0.0, "avg_logprob": -0.24565511354258363, "compression_ratio": 1.598802395209581, "no_speech_prob": 0.039872732013463974}, {"id": 114, "seek": 65034, "start": 669.4200000000001, "end": 678.74, "text": " Ceph extender cluster that I will create in Rook, in the Kubernetes side and there is also", "tokens": [51318, 383, 595, 71, 1279, 3216, 13630, 300, 286, 486, 1884, 294, 497, 1212, 11, 294, 264, 23145, 1252, 293, 456, 307, 611, 51784], "temperature": 0.0, "avg_logprob": -0.24565511354258363, "compression_ratio": 1.598802395209581, "no_speech_prob": 0.039872732013463974}, {"id": 115, "seek": 67874, "start": 678.74, "end": 683.1, "text": " common external which creates the separate namespace if we want to keep the Ceph cluster in", "tokens": [50364, 2689, 8320, 597, 7829, 264, 4994, 5288, 17940, 498, 321, 528, 281, 1066, 264, 383, 595, 71, 13630, 294, 50582], "temperature": 0.0, "avg_logprob": -0.18997342099425613, "compression_ratio": 1.8737373737373737, "no_speech_prob": 0.0032579773105680943}, {"id": 116, "seek": 67874, "start": 683.1, "end": 688.54, "text": " different namespace. So in this I am using a separate namespace for the Ceph cluster and for", "tokens": [50582, 819, 5288, 17940, 13, 407, 294, 341, 286, 669, 1228, 257, 4994, 5288, 17940, 337, 264, 383, 595, 71, 13630, 293, 337, 50854], "temperature": 0.0, "avg_logprob": -0.18997342099425613, "compression_ratio": 1.8737373737373737, "no_speech_prob": 0.0032579773105680943}, {"id": 117, "seek": 67874, "start": 688.54, "end": 692.94, "text": " the Kubernetes cluster I am using the separate namespace in which the Rook operator resides.", "tokens": [50854, 264, 23145, 13630, 286, 669, 1228, 264, 4994, 5288, 17940, 294, 597, 264, 497, 1212, 12973, 47157, 13, 51074], "temperature": 0.0, "avg_logprob": -0.18997342099425613, "compression_ratio": 1.8737373737373737, "no_speech_prob": 0.0032579773105680943}, {"id": 118, "seek": 67874, "start": 692.94, "end": 702.02, "text": " And now I am checking, I have created all the manifest, now I am waiting like to get the Ceph", "tokens": [51074, 400, 586, 286, 669, 8568, 11, 286, 362, 2942, 439, 264, 10067, 11, 586, 286, 669, 3806, 411, 281, 483, 264, 383, 595, 71, 51528], "temperature": 0.0, "avg_logprob": -0.18997342099425613, "compression_ratio": 1.8737373737373737, "no_speech_prob": 0.0032579773105680943}, {"id": 119, "seek": 70202, "start": 702.14, "end": 710.74, "text": " cluster up and running. So the Ceph cluster is created and so this is the Ceph cluster,", "tokens": [50370, 13630, 493, 293, 2614, 13, 407, 264, 383, 595, 71, 13630, 307, 2942, 293, 370, 341, 307, 264, 383, 595, 71, 13630, 11, 50800], "temperature": 0.0, "avg_logprob": -0.16723145110697685, "compression_ratio": 1.5423728813559323, "no_speech_prob": 0.007088668178766966}, {"id": 120, "seek": 70202, "start": 710.74, "end": 723.18, "text": " internals, YAML if you want to see and now I will describe it and you can see like it is", "tokens": [50800, 2154, 1124, 11, 398, 2865, 43, 498, 291, 528, 281, 536, 293, 586, 286, 486, 6786, 309, 293, 291, 393, 536, 411, 309, 307, 51422], "temperature": 0.0, "avg_logprob": -0.16723145110697685, "compression_ratio": 1.5423728813559323, "no_speech_prob": 0.007088668178766966}, {"id": 121, "seek": 70202, "start": 723.18, "end": 731.54, "text": " ready. Now the main thing is I have to wait for the Rook operator to get started. So this is how", "tokens": [51422, 1919, 13, 823, 264, 2135, 551, 307, 286, 362, 281, 1699, 337, 264, 497, 1212, 12973, 281, 483, 1409, 13, 407, 341, 307, 577, 51840], "temperature": 0.0, "avg_logprob": -0.16723145110697685, "compression_ratio": 1.5423728813559323, "no_speech_prob": 0.007088668178766966}, {"id": 122, "seek": 73154, "start": 732.06, "end": 737.14, "text": " all the parts that will be get started, there is a Rook operator, there are some Ceph CSI", "tokens": [50390, 439, 264, 3166, 300, 486, 312, 483, 1409, 11, 456, 307, 257, 497, 1212, 12973, 11, 456, 366, 512, 383, 595, 71, 9460, 40, 50644], "temperature": 0.0, "avg_logprob": -0.2591697537169165, "compression_ratio": 1.5948275862068966, "no_speech_prob": 0.000935435644350946}, {"id": 123, "seek": 73154, "start": 737.14, "end": 746.26, "text": " plugins, demons that will use to mount the data and yeah that's all. And other demons are already", "tokens": [50644, 33759, 11, 19733, 300, 486, 764, 281, 3746, 264, 1412, 293, 1338, 300, 311, 439, 13, 400, 661, 19733, 366, 1217, 51100], "temperature": 0.0, "avg_logprob": -0.2591697537169165, "compression_ratio": 1.5948275862068966, "no_speech_prob": 0.000935435644350946}, {"id": 124, "seek": 73154, "start": 746.26, "end": 754.6999999999999, "text": " running in external Ceph cluster, the Mons, OSDs in which our data will resides. So the", "tokens": [51100, 2614, 294, 8320, 383, 595, 71, 13630, 11, 264, 376, 892, 11, 12731, 35, 82, 294, 597, 527, 1412, 486, 47157, 13, 407, 264, 51522], "temperature": 0.0, "avg_logprob": -0.2591697537169165, "compression_ratio": 1.5948275862068966, "no_speech_prob": 0.000935435644350946}, {"id": 125, "seek": 73154, "start": 754.6999999999999, "end": 759.0999999999999, "text": " connection is good what I have shown in previous slides, now I have created the storage class,", "tokens": [51522, 4984, 307, 665, 437, 286, 362, 4898, 294, 3894, 9788, 11, 586, 286, 362, 2942, 264, 6725, 1508, 11, 51742], "temperature": 0.0, "avg_logprob": -0.2591697537169165, "compression_ratio": 1.5948275862068966, "no_speech_prob": 0.000935435644350946}, {"id": 126, "seek": 75910, "start": 760.0600000000001, "end": 766.22, "text": " the storage class will be also be created, we can create some others if we needed. Now in this", "tokens": [50412, 264, 6725, 1508, 486, 312, 611, 312, 2942, 11, 321, 393, 1884, 512, 2357, 498, 321, 2978, 13, 823, 294, 341, 50720], "temperature": 0.0, "avg_logprob": -0.24683368055126334, "compression_ratio": 1.5315789473684212, "no_speech_prob": 0.012068947777152061}, {"id": 127, "seek": 75910, "start": 766.22, "end": 777.26, "text": " demo I will tell you like how we can create a RBDPVC and store data and how it's disaster proven or", "tokens": [50720, 10723, 286, 486, 980, 291, 411, 577, 321, 393, 1884, 257, 40302, 11373, 53, 34, 293, 3531, 1412, 293, 577, 309, 311, 11293, 12785, 420, 51272], "temperature": 0.0, "avg_logprob": -0.24683368055126334, "compression_ratio": 1.5315789473684212, "no_speech_prob": 0.012068947777152061}, {"id": 128, "seek": 75910, "start": 777.26, "end": 785.7, "text": " how it's how Ceph internally replicates and make our data safe. So now the demo starts for that.", "tokens": [51272, 577, 309, 311, 577, 383, 595, 71, 19501, 3248, 299, 1024, 293, 652, 527, 1412, 3273, 13, 407, 586, 264, 10723, 3719, 337, 300, 13, 51694], "temperature": 0.0, "avg_logprob": -0.24683368055126334, "compression_ratio": 1.5315789473684212, "no_speech_prob": 0.012068947777152061}, {"id": 129, "seek": 78570, "start": 786.7, "end": 795.46, "text": " So once we have the storage class the Ceph RBD or the Rook Ceph block these two belongs to the", "tokens": [50414, 407, 1564, 321, 362, 264, 6725, 1508, 264, 383, 595, 71, 40302, 35, 420, 264, 497, 1212, 383, 595, 71, 3461, 613, 732, 12953, 281, 264, 50852], "temperature": 0.0, "avg_logprob": -0.20583830746737394, "compression_ratio": 1.411764705882353, "no_speech_prob": 0.002740429947152734}, {"id": 130, "seek": 78570, "start": 795.46, "end": 806.46, "text": " block pool and now I am creating this MySQL example in which it will create a MySQL pod and a PVC", "tokens": [50852, 3461, 7005, 293, 586, 286, 669, 4084, 341, 1222, 39934, 1365, 294, 597, 309, 486, 1884, 257, 1222, 39934, 2497, 293, 257, 46700, 51402], "temperature": 0.0, "avg_logprob": -0.20583830746737394, "compression_ratio": 1.411764705882353, "no_speech_prob": 0.002740429947152734}, {"id": 131, "seek": 80646, "start": 806.46, "end": 814.02, "text": " and a service to it. So what I will do is making use of that Ceph RBD storage class,", "tokens": [50364, 293, 257, 2643, 281, 309, 13, 407, 437, 286, 486, 360, 307, 1455, 764, 295, 300, 383, 595, 71, 40302, 35, 6725, 1508, 11, 50742], "temperature": 0.0, "avg_logprob": -0.16157838106155395, "compression_ratio": 1.6171428571428572, "no_speech_prob": 0.015854816883802414}, {"id": 132, "seek": 80646, "start": 814.02, "end": 824.7800000000001, "text": " I will create this PVC and mount this PVC to the MySQL pod and there is a service if you want to", "tokens": [50742, 286, 486, 1884, 341, 46700, 293, 3746, 341, 46700, 281, 264, 1222, 39934, 2497, 293, 456, 307, 257, 2643, 498, 291, 528, 281, 51280], "temperature": 0.0, "avg_logprob": -0.16157838106155395, "compression_ratio": 1.6171428571428572, "no_speech_prob": 0.015854816883802414}, {"id": 133, "seek": 80646, "start": 824.7800000000001, "end": 835.74, "text": " see that MySQL service outside the mini-cube you can make use of that service. So the PVC is created,", "tokens": [51280, 536, 300, 1222, 39934, 2643, 2380, 264, 8382, 12, 66, 1977, 291, 393, 652, 764, 295, 300, 2643, 13, 407, 264, 46700, 307, 2942, 11, 51828], "temperature": 0.0, "avg_logprob": -0.16157838106155395, "compression_ratio": 1.6171428571428572, "no_speech_prob": 0.015854816883802414}, {"id": 134, "seek": 83574, "start": 836.02, "end": 845.22, "text": " you have the pod, I will wait for the pod, PVC is bounced it and pod is still getting created,", "tokens": [50378, 291, 362, 264, 2497, 11, 286, 486, 1699, 337, 264, 2497, 11, 46700, 307, 46482, 309, 293, 2497, 307, 920, 1242, 2942, 11, 50838], "temperature": 0.0, "avg_logprob": -0.20561697544195714, "compression_ratio": 1.695906432748538, "no_speech_prob": 0.010337701998651028}, {"id": 135, "seek": 83574, "start": 845.22, "end": 854.7, "text": " the word press MySQL and the service is created. Once the pod is created, it's up and running.", "tokens": [50838, 264, 1349, 1886, 1222, 39934, 293, 264, 2643, 307, 2942, 13, 3443, 264, 2497, 307, 2942, 11, 309, 311, 493, 293, 2614, 13, 51312], "temperature": 0.0, "avg_logprob": -0.20561697544195714, "compression_ratio": 1.695906432748538, "no_speech_prob": 0.010337701998651028}, {"id": 136, "seek": 83574, "start": 854.7, "end": 861.9, "text": " Now I will go inside the pod and I will go to the mount path that I have written and I will create a", "tokens": [51312, 823, 286, 486, 352, 1854, 264, 2497, 293, 286, 486, 352, 281, 264, 3746, 3100, 300, 286, 362, 3720, 293, 286, 486, 1884, 257, 51672], "temperature": 0.0, "avg_logprob": -0.20561697544195714, "compression_ratio": 1.695906432748538, "no_speech_prob": 0.010337701998651028}, {"id": 137, "seek": 86190, "start": 861.9, "end": 869.9, "text": " file in it. So this is actual application for example MySQL that might be your actual application", "tokens": [50364, 3991, 294, 309, 13, 407, 341, 307, 3539, 3861, 337, 1365, 1222, 39934, 300, 1062, 312, 428, 3539, 3861, 50764], "temperature": 0.0, "avg_logprob": -0.1828815743729875, "compression_ratio": 1.676300578034682, "no_speech_prob": 0.010715135373175144}, {"id": 138, "seek": 86190, "start": 869.9, "end": 882.18, "text": " there and what I am doing right now here. So this is I am telling like if you want to use a", "tokens": [50764, 456, 293, 437, 286, 669, 884, 558, 586, 510, 13, 407, 341, 307, 286, 669, 3585, 411, 498, 291, 528, 281, 764, 257, 51378], "temperature": 0.0, "avg_logprob": -0.1828815743729875, "compression_ratio": 1.676300578034682, "no_speech_prob": 0.010715135373175144}, {"id": 139, "seek": 86190, "start": 882.18, "end": 889.78, "text": " node pod service like this is something that is needed if you want to see are like I am on mini-cube", "tokens": [51378, 9984, 2497, 2643, 411, 341, 307, 746, 300, 307, 2978, 498, 291, 528, 281, 536, 366, 411, 286, 669, 322, 8382, 12, 66, 1977, 51758], "temperature": 0.0, "avg_logprob": -0.1828815743729875, "compression_ratio": 1.676300578034682, "no_speech_prob": 0.010715135373175144}, {"id": 140, "seek": 88978, "start": 889.9, "end": 895.62, "text": " if you want to see the cluster outside whatever you can use this node pod service but the main thing", "tokens": [50370, 498, 291, 528, 281, 536, 264, 13630, 2380, 2035, 291, 393, 764, 341, 9984, 2497, 2643, 457, 264, 2135, 551, 50656], "temperature": 0.0, "avg_logprob": -0.2785802491953675, "compression_ratio": 1.6091954022988506, "no_speech_prob": 0.003803335363045335}, {"id": 141, "seek": 88978, "start": 895.62, "end": 904.14, "text": " is the data so focusing on that. So I am inside the pod using this command, escape command.", "tokens": [50656, 307, 264, 1412, 370, 8416, 322, 300, 13, 407, 286, 669, 1854, 264, 2497, 1228, 341, 5622, 11, 7615, 5622, 13, 51082], "temperature": 0.0, "avg_logprob": -0.2785802491953675, "compression_ratio": 1.6091954022988506, "no_speech_prob": 0.003803335363045335}, {"id": 142, "seek": 88978, "start": 911.5, "end": 917.6999999999999, "text": " So I am inside it now I will go to a certain path that's the mount pod where the PVC is", "tokens": [51450, 407, 286, 669, 1854, 309, 586, 286, 486, 352, 281, 257, 1629, 3100, 300, 311, 264, 3746, 2497, 689, 264, 46700, 307, 51760], "temperature": 0.0, "avg_logprob": -0.2785802491953675, "compression_ratio": 1.6091954022988506, "no_speech_prob": 0.003803335363045335}, {"id": 143, "seek": 91770, "start": 917.7, "end": 935.1800000000001, "text": " been mounted that is where so while creating the pod I have given this path so I am using that only", "tokens": [50364, 668, 19138, 300, 307, 689, 370, 1339, 4084, 264, 2497, 286, 362, 2212, 341, 3100, 370, 286, 669, 1228, 300, 787, 51238], "temperature": 0.0, "avg_logprob": -0.24782339096069336, "compression_ratio": 1.5, "no_speech_prob": 0.004893217235803604}, {"id": 144, "seek": 91770, "start": 935.1800000000001, "end": 943.9000000000001, "text": " and now in this part where PVC will write the data so I am creating a demo dot TXT where I will", "tokens": [51238, 293, 586, 294, 341, 644, 689, 46700, 486, 2464, 264, 1412, 370, 286, 669, 4084, 257, 10723, 5893, 314, 20542, 689, 286, 486, 51674], "temperature": 0.0, "avg_logprob": -0.24782339096069336, "compression_ratio": 1.5, "no_speech_prob": 0.004893217235803604}, {"id": 145, "seek": 94390, "start": 943.9399999999999, "end": 955.9399999999999, "text": " say I will be persisted because of CIF replication and now I will go so this is inside the mount", "tokens": [50366, 584, 286, 486, 312, 13233, 292, 570, 295, 383, 12775, 39911, 293, 586, 286, 486, 352, 370, 341, 307, 1854, 264, 3746, 50966], "temperature": 0.0, "avg_logprob": -0.27447541119301155, "compression_ratio": 1.7826086956521738, "no_speech_prob": 0.004970976151525974}, {"id": 146, "seek": 94390, "start": 955.9399999999999, "end": 963.78, "text": " pod and I will go and delete this pod. So this is file has been created I mean so it the pod now", "tokens": [50966, 2497, 293, 286, 486, 352, 293, 12097, 341, 2497, 13, 407, 341, 307, 3991, 575, 668, 2942, 286, 914, 370, 309, 264, 2497, 586, 51358], "temperature": 0.0, "avg_logprob": -0.27447541119301155, "compression_ratio": 1.7826086956521738, "no_speech_prob": 0.004970976151525974}, {"id": 147, "seek": 94390, "start": 963.78, "end": 969.02, "text": " I will delete the pod for example there is a disaster this pod has been deleted I will delete", "tokens": [51358, 286, 486, 12097, 264, 2497, 337, 1365, 456, 307, 257, 11293, 341, 2497, 575, 668, 22981, 286, 486, 12097, 51620], "temperature": 0.0, "avg_logprob": -0.27447541119301155, "compression_ratio": 1.7826086956521738, "no_speech_prob": 0.004970976151525974}, {"id": 148, "seek": 96902, "start": 969.06, "end": 976.1, "text": " this and as it is a deployment it will create again in some other node as the pod is deleted and", "tokens": [50366, 341, 293, 382, 309, 307, 257, 19317, 309, 486, 1884, 797, 294, 512, 661, 9984, 382, 264, 2497, 307, 22981, 293, 50718], "temperature": 0.0, "avg_logprob": -0.2610277742952914, "compression_ratio": 1.5856353591160222, "no_speech_prob": 0.004457318224012852}, {"id": 149, "seek": 96902, "start": 976.1, "end": 986.06, "text": " now I can see the pod is recreated by Kubernetes it is 9 second ago and I will go inside it again to", "tokens": [50718, 586, 286, 393, 536, 264, 2497, 307, 850, 26559, 538, 23145, 309, 307, 1722, 1150, 2057, 293, 286, 486, 352, 1854, 309, 797, 281, 51216], "temperature": 0.0, "avg_logprob": -0.2610277742952914, "compression_ratio": 1.5856353591160222, "no_speech_prob": 0.004457318224012852}, {"id": 150, "seek": 96902, "start": 986.06, "end": 991.78, "text": " the exact path the CD where live mySQL and I can see that that file should re-exist there", "tokens": [51216, 264, 1900, 3100, 264, 6743, 689, 1621, 452, 39934, 293, 286, 393, 536, 300, 300, 3991, 820, 319, 12, 18217, 456, 51502], "temperature": 0.0, "avg_logprob": -0.2610277742952914, "compression_ratio": 1.5856353591160222, "no_speech_prob": 0.004457318224012852}, {"id": 151, "seek": 99178, "start": 992.78, "end": 1007.06, "text": " where live mySQL and if I cat it so there is still demo dot TXT even if the pod was gone but the", "tokens": [50414, 689, 1621, 452, 39934, 293, 498, 286, 3857, 309, 370, 456, 307, 920, 10723, 5893, 314, 20542, 754, 498, 264, 2497, 390, 2780, 457, 264, 51128], "temperature": 0.0, "avg_logprob": -0.2454379521883451, "compression_ratio": 1.4057971014492754, "no_speech_prob": 0.009128918871283531}, {"id": 152, "seek": 99178, "start": 1007.06, "end": 1016.22, "text": " file was still exist you can see that and that's all with the demo and quickly back to the slides", "tokens": [51128, 3991, 390, 920, 2514, 291, 393, 536, 300, 293, 300, 311, 439, 365, 264, 10723, 293, 2661, 646, 281, 264, 9788, 51586], "temperature": 0.0, "avg_logprob": -0.2454379521883451, "compression_ratio": 1.4057971014492754, "no_speech_prob": 0.009128918871283531}, {"id": 153, "seek": 101622, "start": 1016.22, "end": 1023.98, "text": " so these are some new features we have added the RIDOS namespace the IPv6 support and the", "tokens": [50364, 370, 613, 366, 512, 777, 4122, 321, 362, 3869, 264, 497, 2777, 4367, 5288, 17940, 264, 8671, 85, 21, 1406, 293, 264, 50752], "temperature": 0.0, "avg_logprob": -0.20127778894761028, "compression_ratio": 1.6294117647058823, "no_speech_prob": 0.07768756151199341}, {"id": 154, "seek": 101622, "start": 1023.98, "end": 1032.22, "text": " RGW multisite and we are also going to add some new more features the replica one and support for", "tokens": [50752, 497, 38, 54, 2120, 271, 642, 293, 321, 366, 611, 516, 281, 909, 512, 777, 544, 4122, 264, 35456, 472, 293, 1406, 337, 51164], "temperature": 0.0, "avg_logprob": -0.20127778894761028, "compression_ratio": 1.6294117647058823, "no_speech_prob": 0.07768756151199341}, {"id": 155, "seek": 101622, "start": 1032.22, "end": 1039.22, "text": " the topology awareness and also to improve the documentation and these are some community", "tokens": [51164, 264, 1192, 1793, 8888, 293, 611, 281, 3470, 264, 14333, 293, 613, 366, 512, 1768, 51514], "temperature": 0.0, "avg_logprob": -0.20127778894761028, "compression_ratio": 1.6294117647058823, "no_speech_prob": 0.07768756151199341}, {"id": 156, "seek": 103922, "start": 1039.22, "end": 1045.6200000000001, "text": " links and thanks for that this is my LinkedIn logo if you want someone wants to connect and yeah", "tokens": [50364, 6123, 293, 3231, 337, 300, 341, 307, 452, 20657, 9699, 498, 291, 528, 1580, 2738, 281, 1745, 293, 1338, 50684], "temperature": 0.0, "avg_logprob": -0.33406734466552734, "compression_ratio": 1.4081632653061225, "no_speech_prob": 0.14550912380218506}, {"id": 157, "seek": 103922, "start": 1045.6200000000001, "end": 1055.98, "text": " thanks for that any questions anyone have", "tokens": [50684, 3231, 337, 300, 604, 1651, 2878, 362, 51202], "temperature": 0.0, "avg_logprob": -0.33406734466552734, "compression_ratio": 1.4081632653061225, "no_speech_prob": 0.14550912380218506}, {"id": 158, "seek": 105598, "start": 1055.98, "end": 1066.26, "text": " what credentials do you need to abstract after get all the information from the subcluster do you", "tokens": [50364, 437, 27404, 360, 291, 643, 281, 12649, 934, 483, 439, 264, 1589, 490, 264, 1422, 3474, 8393, 360, 291, 50878], "temperature": 0.0, "avg_logprob": -0.3090960184733073, "compression_ratio": 1.7261146496815287, "no_speech_prob": 0.21697576344013214}, {"id": 159, "seek": 105598, "start": 1066.26, "end": 1073.68, "text": " need to be admin user or can you also be a regular user so if you don't want to expose", "tokens": [50878, 643, 281, 312, 24236, 4195, 420, 393, 291, 611, 312, 257, 3890, 4195, 370, 498, 291, 500, 380, 528, 281, 19219, 51249], "temperature": 0.0, "avg_logprob": -0.3090960184733073, "compression_ratio": 1.7261146496815287, "no_speech_prob": 0.21697576344013214}, {"id": 160, "seek": 105598, "start": 1073.68, "end": 1078.46, "text": " adding credentials to a user so can you do actually do this as a user with enough self", "tokens": [51249, 5127, 27404, 281, 257, 4195, 370, 393, 291, 360, 767, 360, 341, 382, 257, 4195, 365, 1547, 2698, 51488], "temperature": 0.0, "avg_logprob": -0.3090960184733073, "compression_ratio": 1.7261146496815287, "no_speech_prob": 0.21697576344013214}, {"id": 161, "seek": 107846, "start": 1079.06, "end": 1090.22, "text": " to make an export of all these information and bring it into your own okay so the question is what", "tokens": [50394, 281, 652, 364, 10725, 295, 439, 613, 1589, 293, 1565, 309, 666, 428, 1065, 1392, 370, 264, 1168, 307, 437, 50952], "temperature": 0.0, "avg_logprob": -0.20640600295293898, "compression_ratio": 1.7852760736196318, "no_speech_prob": 0.012775388546288013}, {"id": 162, "seek": 107846, "start": 1090.22, "end": 1096.58, "text": " all permissions we need when we actually the export the data the client admin is there like", "tokens": [50952, 439, 32723, 321, 643, 562, 321, 767, 264, 10725, 264, 1412, 264, 6423, 24236, 307, 456, 411, 51270], "temperature": 0.0, "avg_logprob": -0.20640600295293898, "compression_ratio": 1.7852760736196318, "no_speech_prob": 0.012775388546288013}, {"id": 163, "seek": 107846, "start": 1096.58, "end": 1102.22, "text": " which actually gets the data and give it to the Kubernetes cluster so what all permissions we needed", "tokens": [51270, 597, 767, 2170, 264, 1412, 293, 976, 309, 281, 264, 23145, 13630, 370, 437, 439, 32723, 321, 2978, 51552], "temperature": 0.0, "avg_logprob": -0.20640600295293898, "compression_ratio": 1.7852760736196318, "no_speech_prob": 0.012775388546288013}, {"id": 164, "seek": 110222, "start": 1102.22, "end": 1109.26, "text": " so we keep the permissions minimum we can give the admin key ring but we just give the minimum", "tokens": [50364, 370, 321, 1066, 264, 32723, 7285, 321, 393, 976, 264, 24236, 2141, 4875, 457, 321, 445, 976, 264, 7285, 50716], "temperature": 0.0, "avg_logprob": -0.19833020602955537, "compression_ratio": 1.7592592592592593, "no_speech_prob": 0.01467555109411478}, {"id": 165, "seek": 110222, "start": 1109.26, "end": 1117.28, "text": " permissions to it to just read and write because we don't allow ROOP to create anything on this", "tokens": [50716, 32723, 281, 309, 281, 445, 1401, 293, 2464, 570, 321, 500, 380, 2089, 497, 3783, 47, 281, 1884, 1340, 322, 341, 51117], "temperature": 0.0, "avg_logprob": -0.19833020602955537, "compression_ratio": 1.7592592592592593, "no_speech_prob": 0.01467555109411478}, {"id": 166, "seek": 110222, "start": 1117.28, "end": 1123.34, "text": " subcluster we just allow to read the data and manage it so that's the minimum permissions that", "tokens": [51117, 1422, 3474, 8393, 321, 445, 2089, 281, 1401, 264, 1412, 293, 3067, 309, 370, 300, 311, 264, 7285, 32723, 300, 51420], "temperature": 0.0, "avg_logprob": -0.19833020602955537, "compression_ratio": 1.7592592592592593, "no_speech_prob": 0.01467555109411478}, {"id": 167, "seek": 112334, "start": 1123.34, "end": 1138.98, "text": " was required to CFCSI so we expose that only anyone else okay I guess thanks thank you all", "tokens": [50364, 390, 4739, 281, 383, 18671, 20262, 370, 321, 19219, 300, 787, 2878, 1646, 1392, 286, 2041, 3231, 1309, 291, 439, 51146], "temperature": 0.0, "avg_logprob": -0.43886649090310803, "compression_ratio": 1.0975609756097562, "no_speech_prob": 0.09155692160129547}], "language": "en"}