{"text": " So, I'm going to talk about the architecture. All right. Are we ready for the next session? So my name is Wim Hendricks. I work in Nokia. I'm heading the technology and architecture. In this talk, I'm going to talk about nephew. Nephils are about thousands of sites that potentially have to be working together to actually make this service happen to all of you who are using smartphones or tablets and what have you. So that's kind of the problem space that we are trying to work upon in nephew. And so there is basically a set of issues. One is the scale. The second is the heterogeneous environments of all these network connections and making them work seamlessly together. And then, of course, we are working into an environment where there is just not one single person in an organization involved. There is multiple roles within an organization who are actually involved. So that is what we call infra people. And that is the application side of people. There will be security people and so on and so forth. So we have to deal with all the roles and responsibilities in an organization who actually take care of certain aspects of that deployment that has to happen to make this service work. All right. Moreover, what you see is that if you look to, let's say, a mobile network, right, so we are talking sometimes about terabits of capacity. So that means that we are also, me being part of a vendor, right? So we used to basically own and control every piece of that stack, right? But because we are moving into this cloud-native environment, we have now desegregated stuff, right? The problem that we also face is that we are trying to have very tight control over the infra and we want to basically work in that cloud-native space, right? So the question is, how do you do that? Because you have to basically give away some of that control to other people, right? So if you can see, we are looking at this is a quite challenging space, right? And what has happened so far in the past is that every vendor, including ourselves, we basically said, okay, we control our own pace and then we have a bit of different vendors involved. And so what you will see is that you will end up being, connecting multiple components and components and components and it's actually quite challenging to do that in a cloud-native way. So we basically said, okay, can we do better, right? And this is where Nefio was born, in a sense, because we said, okay, all of these workloads, they are moving inside of a cloud-native space, meaning they are moving into a Kubernetes environment, right? And it's nice to basically do this aggregation. We can do microservices. We can basically put all these components onto a Kubernetes environment. Why don't we leverage that same framework to basically automate and orchestrate the configuration and the setup of that whole stack, right? And that's kind of, right? Now in Nefio, we basically do two things. We basically look at, on one hand, the application itself, right, which is 5G. And then we also look at a set of primitives that are not yet available to us that we would like to have to solve this problem, right? So we basically do two things. One is we are basically defining the use case that we are using to actually figure out what are the primitives that we are missing. And then we are basically adding those missing components inside of a Kubernetes framework to be able to address those problem spaces. And as such, I mean, we leverage KRM. So I haven't asked, so Kubernetes is probably a lot of people familiar with that. If you want to show hands, Kubernetes, I think we should be fairly familiar. Okay, pretty good. So we leverage, so you are familiar with the term of KRM, right? So KRM is the Kubernetes resource model, and we leverage that all the way, right? So that means we have a clearly defined API. We have the set of metadata. We leverage the desired versus observed state to basically figure out a declarative base of operation. We leverage the event-driven ecosystem and stuff like that. So we leverage that to the full extent. Now what we have seen in order to solve that problem at scale, we were missing a few primitives, right? And one of those primitives that we have been added to the component is what we call configuration as data, right? Because if you look to how Kubernetes works as its basis, you actually have a CRD or a Kubernetes resource that is basically triggering something, right? Now because we are dealing with this massively complex environment, right, we said, okay, a single unit is probably not sufficient for us. So we defined the concept of a package, right? So rather than having a single CRD, we actually built a package, and a package is a collection of KRM resources that you are going to use as a kind of what we call a blueprint or a service catalog, right? So it's basically think of it as a collection of KRM resources that do things together, right? The second thing that we did is today in order to use Kubernetes, you typically have to build a controller in code and stuff like that, right? So we added the capability better. You basically say I want to create a deployment and then there will be a replica set controller which basically says, okay, I'm going to select this node and I'm going to scale this out and I'm going to deploy a set of POTS over a number of resources, right? That's what typically happens today inside of Kubernetes and you have different methods to do so. You have deployment, you have replica sets and so on and so forth, or stateful sets, and you pick and choose the one that's familiar with you. Even that we work above a cluster level, what we do in nephew, we call it a term, what we call a package variant or a package variant set which basically says I want to have my package which I was talking about and I want to deploy that on these sites, right? And each of these sites will then be what we call specialized within their own context where the relative parameters, for example, this site needs this VLAN, this site needs this IP address, this size needs these PLM and ID's and stuff like that. So they will be specialized based on their specific context on where they get deployed and as a result, that's then being deployed on that particular cluster, right? So you see that if you look to the analogy of Kubernetes, we are working at the level, at the cluster level versus where as Kubernetes works at the node level scheduling type of level. So we work a level above but you see a lot of concepts that were born or that were basically derived from Kubernetes. We are leveraging within the framework that we are deploying within nephew in order to stay as close as possible to it so that we can leverage the benefits of that whole ecosystem. Now to put that into perspective, I try to explain that a little bit. So we have a concept of management clusters. So this is a regular Kubernetes cluster but we use it typically for our control engines, right? This is where our, what we call the configuration as data server which is ported in our implementation is used upon and then we schedule work, network functions onto those specific workloads, right? And how we do that is we basically have this concept of a package on the right hand side which is our blueprint. So think about someone as a vendor or as an operator, someone basically put that together, right? So we have the KRM resources that are needed for that particular environment and then we say, okay, I want to deploy that on 10,000 sites, right? When we do this, when we try to make variations of that package for a particular context, we also said, okay, let's divide and conquer, right? So because you could basically build a pipeline that is very narrow and very strict, right? But typically what we see is that you need flexibility, right? So you want to have a flexible system. And so we developed a concept, what we call the conditional dance of the choreography which is a set of primitives, I think of functions here that each do a specific thing. So for example, IP address, VLANs and so on and so forth. And each of them basically make sure that if those things are needed, they are basically being called upon and specialized those packages with a specific context for that type of environment. And that's how we can make this work in a very scalable and flexible and pluggable play and it's easily to extend that within a specific environment. So what did we do so far within Nefuse? We are a very early pro yet. So and it would be good if people would like to join us. So we have done, so we are just about to release release two, right? So what we have shown so far is basically the concept that I showed in the beginning. We have basically proven that with Free5GC. So Free5GC is an open source project that basically deploys the core side of a 5G type of network. So we have basically proven that we can use the machinery to actually deploy and show what I'm presenting here in the slides is actually working up to setting up a call, right? So we are using the whole network setup that actually connects all of these functions together. So all of that using the primitives that I was showing. And in release two we added OII which is another open source project mainly focused on the radio but also as the core so that we prove that we can do this not across one vendor but across multiple vendors, right? And so we are extending this whole framework with more primitives as we go along. As I said, we are a very young project, right? And so we seek for a lot of help. So if you are interested to join us, we would welcome. So please contact me or please look at one of those resources that are available here because this is all the information which you can have a look at to the operation. And what you see is that you can actually move rather more quickly than in an on-up type of approach but we are actually trying to solve a different level. So what we call the domain level whereas on-up is working at the orchestration level. Okay. And so is the same if we say the advantage of NetEar over VMware, orchestrator or other vendors? Yeah. So I think, see, okay, I'm of course trying to advocate it but personally I see the following. Kubernetes has been the orchestration for containers, right? That was where it is born. If you ask me, it has the right primitives to be an automation and orchestration platform for anything. So I see Kubernetes as an operating system to actually do any automation, right? That doesn't mean. And what is the advantage of that in my view is that, so when you have all of these different components, first of all, you have a huge ecosystem in open source that is developing and extending Kubernetes for lots of use cases, right? So you can deploy AWS resources, Google resources, you can deploy clusters, you can set up servers. So you first leverage a huge ecosystem that is being developed in open source which we should all love in this room, right? Secondly, that doesn't mean that you can as a vendor not benefit or do things specifically but the big advantage for you as a consumer when we do that is today when you do VMware orchestration, you build your own VMware orchestration server with your own database with your own and then you see it's not only VMware orchestration, you need a bit of this component and a bit of that component and a bit of this component and all of a sudden you have more servers to serve the network than actually the network. I'm exaggerating, right? But the advantage what I see personally is that you look at automation from these, the use case still will be specific to you and there will be a VMware specific controller, right? But if you build it on the same platform, you as a consumer, we benefit from not having to deploy another platform but leverage what we already have if that suits you. That doesn't mean you cannot deploy another Kubernetes instance for that specific environment, right? But at least the integration.", "segments": [{"id": 0, "seek": 3000, "start": 30.0, "end": 40.0, "text": " So, I'm going to talk about the architecture.", "tokens": [50364, 407, 11, 286, 478, 516, 281, 751, 466, 264, 9482, 13, 50864], "temperature": 0.0, "avg_logprob": -0.5537233222020815, "compression_ratio": 1.4901960784313726, "no_speech_prob": 0.6605710983276367}, {"id": 1, "seek": 3000, "start": 40.0, "end": 41.0, "text": " All right.", "tokens": [50864, 1057, 558, 13, 50914], "temperature": 0.0, "avg_logprob": -0.5537233222020815, "compression_ratio": 1.4901960784313726, "no_speech_prob": 0.6605710983276367}, {"id": 2, "seek": 3000, "start": 41.0, "end": 44.88, "text": " Are we ready for the next session?", "tokens": [50914, 2014, 321, 1919, 337, 264, 958, 5481, 30, 51108], "temperature": 0.0, "avg_logprob": -0.5537233222020815, "compression_ratio": 1.4901960784313726, "no_speech_prob": 0.6605710983276367}, {"id": 3, "seek": 3000, "start": 44.88, "end": 47.28, "text": " So my name is Wim Hendricks.", "tokens": [51108, 407, 452, 1315, 307, 343, 332, 28594, 81, 7663, 13, 51228], "temperature": 0.0, "avg_logprob": -0.5537233222020815, "compression_ratio": 1.4901960784313726, "no_speech_prob": 0.6605710983276367}, {"id": 4, "seek": 3000, "start": 47.28, "end": 48.68, "text": " I work in Nokia.", "tokens": [51228, 286, 589, 294, 43980, 13, 51298], "temperature": 0.0, "avg_logprob": -0.5537233222020815, "compression_ratio": 1.4901960784313726, "no_speech_prob": 0.6605710983276367}, {"id": 5, "seek": 3000, "start": 48.68, "end": 52.400000000000006, "text": " I'm heading the technology and architecture.", "tokens": [51298, 286, 478, 9864, 264, 2899, 293, 9482, 13, 51484], "temperature": 0.0, "avg_logprob": -0.5537233222020815, "compression_ratio": 1.4901960784313726, "no_speech_prob": 0.6605710983276367}, {"id": 6, "seek": 3000, "start": 52.400000000000006, "end": 55.8, "text": " In this talk, I'm going to talk about nephew.", "tokens": [51484, 682, 341, 751, 11, 286, 478, 516, 281, 751, 466, 30799, 13, 51654], "temperature": 0.0, "avg_logprob": -0.5537233222020815, "compression_ratio": 1.4901960784313726, "no_speech_prob": 0.6605710983276367}, {"id": 7, "seek": 5580, "start": 55.8, "end": 61.48, "text": " Nephils are about thousands of sites that potentially have to be working together to", "tokens": [50364, 24875, 71, 4174, 366, 466, 5383, 295, 7533, 300, 7263, 362, 281, 312, 1364, 1214, 281, 50648], "temperature": 0.0, "avg_logprob": -0.20322025946851047, "compression_ratio": 1.6905660377358491, "no_speech_prob": 0.40037235617637634}, {"id": 8, "seek": 5580, "start": 61.48, "end": 65.24, "text": " actually make this service happen to all of you who are using smartphones or tablets", "tokens": [50648, 767, 652, 341, 2643, 1051, 281, 439, 295, 291, 567, 366, 1228, 26782, 420, 27622, 50836], "temperature": 0.0, "avg_logprob": -0.20322025946851047, "compression_ratio": 1.6905660377358491, "no_speech_prob": 0.40037235617637634}, {"id": 9, "seek": 5580, "start": 65.24, "end": 66.24, "text": " and what have you.", "tokens": [50836, 293, 437, 362, 291, 13, 50886], "temperature": 0.0, "avg_logprob": -0.20322025946851047, "compression_ratio": 1.6905660377358491, "no_speech_prob": 0.40037235617637634}, {"id": 10, "seek": 5580, "start": 66.24, "end": 72.75999999999999, "text": " So that's kind of the problem space that we are trying to work upon in nephew.", "tokens": [50886, 407, 300, 311, 733, 295, 264, 1154, 1901, 300, 321, 366, 1382, 281, 589, 3564, 294, 30799, 13, 51212], "temperature": 0.0, "avg_logprob": -0.20322025946851047, "compression_ratio": 1.6905660377358491, "no_speech_prob": 0.40037235617637634}, {"id": 11, "seek": 5580, "start": 72.75999999999999, "end": 75.56, "text": " And so there is basically a set of issues.", "tokens": [51212, 400, 370, 456, 307, 1936, 257, 992, 295, 2663, 13, 51352], "temperature": 0.0, "avg_logprob": -0.20322025946851047, "compression_ratio": 1.6905660377358491, "no_speech_prob": 0.40037235617637634}, {"id": 12, "seek": 5580, "start": 75.56, "end": 77.67999999999999, "text": " One is the scale.", "tokens": [51352, 1485, 307, 264, 4373, 13, 51458], "temperature": 0.0, "avg_logprob": -0.20322025946851047, "compression_ratio": 1.6905660377358491, "no_speech_prob": 0.40037235617637634}, {"id": 13, "seek": 5580, "start": 77.67999999999999, "end": 81.16, "text": " The second is the heterogeneous environments of all these network connections and making", "tokens": [51458, 440, 1150, 307, 264, 20789, 31112, 12388, 295, 439, 613, 3209, 9271, 293, 1455, 51632], "temperature": 0.0, "avg_logprob": -0.20322025946851047, "compression_ratio": 1.6905660377358491, "no_speech_prob": 0.40037235617637634}, {"id": 14, "seek": 5580, "start": 81.16, "end": 84.2, "text": " them work seamlessly together.", "tokens": [51632, 552, 589, 38083, 1214, 13, 51784], "temperature": 0.0, "avg_logprob": -0.20322025946851047, "compression_ratio": 1.6905660377358491, "no_speech_prob": 0.40037235617637634}, {"id": 15, "seek": 8420, "start": 84.2, "end": 89.24000000000001, "text": " And then, of course, we are working into an environment where there is just not one single", "tokens": [50364, 400, 550, 11, 295, 1164, 11, 321, 366, 1364, 666, 364, 2823, 689, 456, 307, 445, 406, 472, 2167, 50616], "temperature": 0.0, "avg_logprob": -0.1539781939598822, "compression_ratio": 1.853658536585366, "no_speech_prob": 0.02017117291688919}, {"id": 16, "seek": 8420, "start": 89.24000000000001, "end": 91.28, "text": " person in an organization involved.", "tokens": [50616, 954, 294, 364, 4475, 3288, 13, 50718], "temperature": 0.0, "avg_logprob": -0.1539781939598822, "compression_ratio": 1.853658536585366, "no_speech_prob": 0.02017117291688919}, {"id": 17, "seek": 8420, "start": 91.28, "end": 94.76, "text": " There is multiple roles within an organization who are actually involved.", "tokens": [50718, 821, 307, 3866, 9604, 1951, 364, 4475, 567, 366, 767, 3288, 13, 50892], "temperature": 0.0, "avg_logprob": -0.1539781939598822, "compression_ratio": 1.853658536585366, "no_speech_prob": 0.02017117291688919}, {"id": 18, "seek": 8420, "start": 94.76, "end": 97.32000000000001, "text": " So that is what we call infra people.", "tokens": [50892, 407, 300, 307, 437, 321, 818, 23654, 561, 13, 51020], "temperature": 0.0, "avg_logprob": -0.1539781939598822, "compression_ratio": 1.853658536585366, "no_speech_prob": 0.02017117291688919}, {"id": 19, "seek": 8420, "start": 97.32000000000001, "end": 99.64, "text": " And that is the application side of people.", "tokens": [51020, 400, 300, 307, 264, 3861, 1252, 295, 561, 13, 51136], "temperature": 0.0, "avg_logprob": -0.1539781939598822, "compression_ratio": 1.853658536585366, "no_speech_prob": 0.02017117291688919}, {"id": 20, "seek": 8420, "start": 99.64, "end": 101.52000000000001, "text": " There will be security people and so on and so forth.", "tokens": [51136, 821, 486, 312, 3825, 561, 293, 370, 322, 293, 370, 5220, 13, 51230], "temperature": 0.0, "avg_logprob": -0.1539781939598822, "compression_ratio": 1.853658536585366, "no_speech_prob": 0.02017117291688919}, {"id": 21, "seek": 8420, "start": 101.52000000000001, "end": 106.28, "text": " So we have to deal with all the roles and responsibilities in an organization who actually", "tokens": [51230, 407, 321, 362, 281, 2028, 365, 439, 264, 9604, 293, 16190, 294, 364, 4475, 567, 767, 51468], "temperature": 0.0, "avg_logprob": -0.1539781939598822, "compression_ratio": 1.853658536585366, "no_speech_prob": 0.02017117291688919}, {"id": 22, "seek": 8420, "start": 106.28, "end": 112.0, "text": " take care of certain aspects of that deployment that has to happen to make this service work.", "tokens": [51468, 747, 1127, 295, 1629, 7270, 295, 300, 19317, 300, 575, 281, 1051, 281, 652, 341, 2643, 589, 13, 51754], "temperature": 0.0, "avg_logprob": -0.1539781939598822, "compression_ratio": 1.853658536585366, "no_speech_prob": 0.02017117291688919}, {"id": 23, "seek": 8420, "start": 112.0, "end": 113.0, "text": " All right.", "tokens": [51754, 1057, 558, 13, 51804], "temperature": 0.0, "avg_logprob": -0.1539781939598822, "compression_ratio": 1.853658536585366, "no_speech_prob": 0.02017117291688919}, {"id": 24, "seek": 11300, "start": 113.0, "end": 117.84, "text": " Moreover, what you see is that if you look to, let's say, a mobile network, right, so", "tokens": [50364, 19838, 11, 437, 291, 536, 307, 300, 498, 291, 574, 281, 11, 718, 311, 584, 11, 257, 6013, 3209, 11, 558, 11, 370, 50606], "temperature": 0.0, "avg_logprob": -0.2031988779703776, "compression_ratio": 1.59915611814346, "no_speech_prob": 0.021404560655355453}, {"id": 25, "seek": 11300, "start": 117.84, "end": 121.4, "text": " we are talking sometimes about terabits of capacity.", "tokens": [50606, 321, 366, 1417, 2171, 466, 1796, 455, 1208, 295, 6042, 13, 50784], "temperature": 0.0, "avg_logprob": -0.2031988779703776, "compression_ratio": 1.59915611814346, "no_speech_prob": 0.021404560655355453}, {"id": 26, "seek": 11300, "start": 121.4, "end": 125.76, "text": " So that means that we are also, me being part of a vendor, right?", "tokens": [50784, 407, 300, 1355, 300, 321, 366, 611, 11, 385, 885, 644, 295, 257, 24321, 11, 558, 30, 51002], "temperature": 0.0, "avg_logprob": -0.2031988779703776, "compression_ratio": 1.59915611814346, "no_speech_prob": 0.021404560655355453}, {"id": 27, "seek": 11300, "start": 125.76, "end": 130.84, "text": " So we used to basically own and control every piece of that stack, right?", "tokens": [51002, 407, 321, 1143, 281, 1936, 1065, 293, 1969, 633, 2522, 295, 300, 8630, 11, 558, 30, 51256], "temperature": 0.0, "avg_logprob": -0.2031988779703776, "compression_ratio": 1.59915611814346, "no_speech_prob": 0.021404560655355453}, {"id": 28, "seek": 11300, "start": 130.84, "end": 136.24, "text": " But because we are moving into this cloud-native environment, we have now desegregated stuff,", "tokens": [51256, 583, 570, 321, 366, 2684, 666, 341, 4588, 12, 77, 1166, 2823, 11, 321, 362, 586, 730, 1146, 3375, 770, 1507, 11, 51526], "temperature": 0.0, "avg_logprob": -0.2031988779703776, "compression_ratio": 1.59915611814346, "no_speech_prob": 0.021404560655355453}, {"id": 29, "seek": 11300, "start": 136.24, "end": 137.24, "text": " right?", "tokens": [51526, 558, 30, 51576], "temperature": 0.0, "avg_logprob": -0.2031988779703776, "compression_ratio": 1.59915611814346, "no_speech_prob": 0.021404560655355453}, {"id": 30, "seek": 13724, "start": 137.24, "end": 141.72, "text": " The problem that we also face is that we are trying to have very tight control over the", "tokens": [50364, 440, 1154, 300, 321, 611, 1851, 307, 300, 321, 366, 1382, 281, 362, 588, 4524, 1969, 670, 264, 50588], "temperature": 0.0, "avg_logprob": -0.130913165577671, "compression_ratio": 1.7607843137254902, "no_speech_prob": 0.016695113852620125}, {"id": 31, "seek": 13724, "start": 141.72, "end": 147.4, "text": " infra and we want to basically work in that cloud-native space, right?", "tokens": [50588, 23654, 293, 321, 528, 281, 1936, 589, 294, 300, 4588, 12, 77, 1166, 1901, 11, 558, 30, 50872], "temperature": 0.0, "avg_logprob": -0.130913165577671, "compression_ratio": 1.7607843137254902, "no_speech_prob": 0.016695113852620125}, {"id": 32, "seek": 13724, "start": 147.4, "end": 149.20000000000002, "text": " So the question is, how do you do that?", "tokens": [50872, 407, 264, 1168, 307, 11, 577, 360, 291, 360, 300, 30, 50962], "temperature": 0.0, "avg_logprob": -0.130913165577671, "compression_ratio": 1.7607843137254902, "no_speech_prob": 0.016695113852620125}, {"id": 33, "seek": 13724, "start": 149.20000000000002, "end": 153.48000000000002, "text": " Because you have to basically give away some of that control to other people, right?", "tokens": [50962, 1436, 291, 362, 281, 1936, 976, 1314, 512, 295, 300, 1969, 281, 661, 561, 11, 558, 30, 51176], "temperature": 0.0, "avg_logprob": -0.130913165577671, "compression_ratio": 1.7607843137254902, "no_speech_prob": 0.016695113852620125}, {"id": 34, "seek": 13724, "start": 153.48000000000002, "end": 158.12, "text": " So if you can see, we are looking at this is a quite challenging space, right?", "tokens": [51176, 407, 498, 291, 393, 536, 11, 321, 366, 1237, 412, 341, 307, 257, 1596, 7595, 1901, 11, 558, 30, 51408], "temperature": 0.0, "avg_logprob": -0.130913165577671, "compression_ratio": 1.7607843137254902, "no_speech_prob": 0.016695113852620125}, {"id": 35, "seek": 13724, "start": 158.12, "end": 163.36, "text": " And what has happened so far in the past is that every vendor, including ourselves, we", "tokens": [51408, 400, 437, 575, 2011, 370, 1400, 294, 264, 1791, 307, 300, 633, 24321, 11, 3009, 4175, 11, 321, 51670], "temperature": 0.0, "avg_logprob": -0.130913165577671, "compression_ratio": 1.7607843137254902, "no_speech_prob": 0.016695113852620125}, {"id": 36, "seek": 16336, "start": 163.36, "end": 167.68, "text": " basically said, okay, we control our own pace and then we have a bit of different vendors", "tokens": [50364, 1936, 848, 11, 1392, 11, 321, 1969, 527, 1065, 11638, 293, 550, 321, 362, 257, 857, 295, 819, 22056, 50580], "temperature": 0.0, "avg_logprob": -0.165360274138274, "compression_ratio": 1.818815331010453, "no_speech_prob": 0.05282540246844292}, {"id": 37, "seek": 16336, "start": 167.68, "end": 168.8, "text": " involved.", "tokens": [50580, 3288, 13, 50636], "temperature": 0.0, "avg_logprob": -0.165360274138274, "compression_ratio": 1.818815331010453, "no_speech_prob": 0.05282540246844292}, {"id": 38, "seek": 16336, "start": 168.8, "end": 173.72000000000003, "text": " And so what you will see is that you will end up being, connecting multiple components", "tokens": [50636, 400, 370, 437, 291, 486, 536, 307, 300, 291, 486, 917, 493, 885, 11, 11015, 3866, 6677, 50882], "temperature": 0.0, "avg_logprob": -0.165360274138274, "compression_ratio": 1.818815331010453, "no_speech_prob": 0.05282540246844292}, {"id": 39, "seek": 16336, "start": 173.72000000000003, "end": 178.20000000000002, "text": " and components and components and it's actually quite challenging to do that in a cloud-native", "tokens": [50882, 293, 6677, 293, 6677, 293, 309, 311, 767, 1596, 7595, 281, 360, 300, 294, 257, 4588, 12, 77, 1166, 51106], "temperature": 0.0, "avg_logprob": -0.165360274138274, "compression_ratio": 1.818815331010453, "no_speech_prob": 0.05282540246844292}, {"id": 40, "seek": 16336, "start": 178.20000000000002, "end": 179.20000000000002, "text": " way.", "tokens": [51106, 636, 13, 51156], "temperature": 0.0, "avg_logprob": -0.165360274138274, "compression_ratio": 1.818815331010453, "no_speech_prob": 0.05282540246844292}, {"id": 41, "seek": 16336, "start": 179.20000000000002, "end": 181.84, "text": " So we basically said, okay, can we do better, right?", "tokens": [51156, 407, 321, 1936, 848, 11, 1392, 11, 393, 321, 360, 1101, 11, 558, 30, 51288], "temperature": 0.0, "avg_logprob": -0.165360274138274, "compression_ratio": 1.818815331010453, "no_speech_prob": 0.05282540246844292}, {"id": 42, "seek": 16336, "start": 181.84, "end": 188.36, "text": " And this is where Nefio was born, in a sense, because we said, okay, all of these workloads,", "tokens": [51288, 400, 341, 307, 689, 1734, 69, 1004, 390, 4232, 11, 294, 257, 2020, 11, 570, 321, 848, 11, 1392, 11, 439, 295, 613, 32452, 11, 51614], "temperature": 0.0, "avg_logprob": -0.165360274138274, "compression_ratio": 1.818815331010453, "no_speech_prob": 0.05282540246844292}, {"id": 43, "seek": 16336, "start": 188.36, "end": 192.88000000000002, "text": " they are moving inside of a cloud-native space, meaning they are moving into a Kubernetes", "tokens": [51614, 436, 366, 2684, 1854, 295, 257, 4588, 12, 77, 1166, 1901, 11, 3620, 436, 366, 2684, 666, 257, 23145, 51840], "temperature": 0.0, "avg_logprob": -0.165360274138274, "compression_ratio": 1.818815331010453, "no_speech_prob": 0.05282540246844292}, {"id": 44, "seek": 19288, "start": 192.88, "end": 194.51999999999998, "text": " environment, right?", "tokens": [50364, 2823, 11, 558, 30, 50446], "temperature": 0.0, "avg_logprob": -0.14731626751042215, "compression_ratio": 1.755813953488372, "no_speech_prob": 0.034986212849617004}, {"id": 45, "seek": 19288, "start": 194.51999999999998, "end": 197.64, "text": " And it's nice to basically do this aggregation.", "tokens": [50446, 400, 309, 311, 1481, 281, 1936, 360, 341, 16743, 399, 13, 50602], "temperature": 0.0, "avg_logprob": -0.14731626751042215, "compression_ratio": 1.755813953488372, "no_speech_prob": 0.034986212849617004}, {"id": 46, "seek": 19288, "start": 197.64, "end": 199.07999999999998, "text": " We can do microservices.", "tokens": [50602, 492, 393, 360, 15547, 47480, 13, 50674], "temperature": 0.0, "avg_logprob": -0.14731626751042215, "compression_ratio": 1.755813953488372, "no_speech_prob": 0.034986212849617004}, {"id": 47, "seek": 19288, "start": 199.07999999999998, "end": 203.64, "text": " We can basically put all these components onto a Kubernetes environment.", "tokens": [50674, 492, 393, 1936, 829, 439, 613, 6677, 3911, 257, 23145, 2823, 13, 50902], "temperature": 0.0, "avg_logprob": -0.14731626751042215, "compression_ratio": 1.755813953488372, "no_speech_prob": 0.034986212849617004}, {"id": 48, "seek": 19288, "start": 203.64, "end": 210.07999999999998, "text": " Why don't we leverage that same framework to basically automate and orchestrate the configuration", "tokens": [50902, 1545, 500, 380, 321, 13982, 300, 912, 8388, 281, 1936, 31605, 293, 14161, 4404, 264, 11694, 51224], "temperature": 0.0, "avg_logprob": -0.14731626751042215, "compression_ratio": 1.755813953488372, "no_speech_prob": 0.034986212849617004}, {"id": 49, "seek": 19288, "start": 210.07999999999998, "end": 213.64, "text": " and the setup of that whole stack, right?", "tokens": [51224, 293, 264, 8657, 295, 300, 1379, 8630, 11, 558, 30, 51402], "temperature": 0.0, "avg_logprob": -0.14731626751042215, "compression_ratio": 1.755813953488372, "no_speech_prob": 0.034986212849617004}, {"id": 50, "seek": 19288, "start": 213.64, "end": 215.32, "text": " And that's kind of, right?", "tokens": [51402, 400, 300, 311, 733, 295, 11, 558, 30, 51486], "temperature": 0.0, "avg_logprob": -0.14731626751042215, "compression_ratio": 1.755813953488372, "no_speech_prob": 0.034986212849617004}, {"id": 51, "seek": 19288, "start": 215.32, "end": 217.56, "text": " Now in Nefio, we basically do two things.", "tokens": [51486, 823, 294, 1734, 69, 1004, 11, 321, 1936, 360, 732, 721, 13, 51598], "temperature": 0.0, "avg_logprob": -0.14731626751042215, "compression_ratio": 1.755813953488372, "no_speech_prob": 0.034986212849617004}, {"id": 52, "seek": 19288, "start": 217.56, "end": 222.64, "text": " We basically look at, on one hand, the application itself, right, which is 5G.", "tokens": [51598, 492, 1936, 574, 412, 11, 322, 472, 1011, 11, 264, 3861, 2564, 11, 558, 11, 597, 307, 1025, 38, 13, 51852], "temperature": 0.0, "avg_logprob": -0.14731626751042215, "compression_ratio": 1.755813953488372, "no_speech_prob": 0.034986212849617004}, {"id": 53, "seek": 22264, "start": 222.64, "end": 228.32, "text": " And then we also look at a set of primitives that are not yet available to us that we would", "tokens": [50364, 400, 550, 321, 611, 574, 412, 257, 992, 295, 2886, 38970, 300, 366, 406, 1939, 2435, 281, 505, 300, 321, 576, 50648], "temperature": 0.0, "avg_logprob": -0.10769478174356314, "compression_ratio": 1.815126050420168, "no_speech_prob": 0.016623295843601227}, {"id": 54, "seek": 22264, "start": 228.32, "end": 230.27999999999997, "text": " like to have to solve this problem, right?", "tokens": [50648, 411, 281, 362, 281, 5039, 341, 1154, 11, 558, 30, 50746], "temperature": 0.0, "avg_logprob": -0.10769478174356314, "compression_ratio": 1.815126050420168, "no_speech_prob": 0.016623295843601227}, {"id": 55, "seek": 22264, "start": 230.27999999999997, "end": 231.92, "text": " So we basically do two things.", "tokens": [50746, 407, 321, 1936, 360, 732, 721, 13, 50828], "temperature": 0.0, "avg_logprob": -0.10769478174356314, "compression_ratio": 1.815126050420168, "no_speech_prob": 0.016623295843601227}, {"id": 56, "seek": 22264, "start": 231.92, "end": 237.72, "text": " One is we are basically defining the use case that we are using to actually figure out what", "tokens": [50828, 1485, 307, 321, 366, 1936, 17827, 264, 764, 1389, 300, 321, 366, 1228, 281, 767, 2573, 484, 437, 51118], "temperature": 0.0, "avg_logprob": -0.10769478174356314, "compression_ratio": 1.815126050420168, "no_speech_prob": 0.016623295843601227}, {"id": 57, "seek": 22264, "start": 237.72, "end": 239.64, "text": " are the primitives that we are missing.", "tokens": [51118, 366, 264, 2886, 38970, 300, 321, 366, 5361, 13, 51214], "temperature": 0.0, "avg_logprob": -0.10769478174356314, "compression_ratio": 1.815126050420168, "no_speech_prob": 0.016623295843601227}, {"id": 58, "seek": 22264, "start": 239.64, "end": 244.51999999999998, "text": " And then we are basically adding those missing components inside of a Kubernetes framework", "tokens": [51214, 400, 550, 321, 366, 1936, 5127, 729, 5361, 6677, 1854, 295, 257, 23145, 8388, 51458], "temperature": 0.0, "avg_logprob": -0.10769478174356314, "compression_ratio": 1.815126050420168, "no_speech_prob": 0.016623295843601227}, {"id": 59, "seek": 22264, "start": 244.51999999999998, "end": 249.2, "text": " to be able to address those problem spaces.", "tokens": [51458, 281, 312, 1075, 281, 2985, 729, 1154, 7673, 13, 51692], "temperature": 0.0, "avg_logprob": -0.10769478174356314, "compression_ratio": 1.815126050420168, "no_speech_prob": 0.016623295843601227}, {"id": 60, "seek": 24920, "start": 249.2, "end": 251.32, "text": " And as such, I mean, we leverage KRM.", "tokens": [50364, 400, 382, 1270, 11, 286, 914, 11, 321, 13982, 591, 49, 44, 13, 50470], "temperature": 0.0, "avg_logprob": -0.1814764416407025, "compression_ratio": 1.7165354330708662, "no_speech_prob": 0.024095382541418076}, {"id": 61, "seek": 24920, "start": 251.32, "end": 256.71999999999997, "text": " So I haven't asked, so Kubernetes is probably a lot of people familiar with that.", "tokens": [50470, 407, 286, 2378, 380, 2351, 11, 370, 23145, 307, 1391, 257, 688, 295, 561, 4963, 365, 300, 13, 50740], "temperature": 0.0, "avg_logprob": -0.1814764416407025, "compression_ratio": 1.7165354330708662, "no_speech_prob": 0.024095382541418076}, {"id": 62, "seek": 24920, "start": 256.71999999999997, "end": 260.28, "text": " If you want to show hands, Kubernetes, I think we should be fairly familiar.", "tokens": [50740, 759, 291, 528, 281, 855, 2377, 11, 23145, 11, 286, 519, 321, 820, 312, 6457, 4963, 13, 50918], "temperature": 0.0, "avg_logprob": -0.1814764416407025, "compression_ratio": 1.7165354330708662, "no_speech_prob": 0.024095382541418076}, {"id": 63, "seek": 24920, "start": 260.28, "end": 261.96, "text": " Okay, pretty good.", "tokens": [50918, 1033, 11, 1238, 665, 13, 51002], "temperature": 0.0, "avg_logprob": -0.1814764416407025, "compression_ratio": 1.7165354330708662, "no_speech_prob": 0.024095382541418076}, {"id": 64, "seek": 24920, "start": 261.96, "end": 265.32, "text": " So we leverage, so you are familiar with the term of KRM, right?", "tokens": [51002, 407, 321, 13982, 11, 370, 291, 366, 4963, 365, 264, 1433, 295, 591, 49, 44, 11, 558, 30, 51170], "temperature": 0.0, "avg_logprob": -0.1814764416407025, "compression_ratio": 1.7165354330708662, "no_speech_prob": 0.024095382541418076}, {"id": 65, "seek": 24920, "start": 265.32, "end": 270.24, "text": " So KRM is the Kubernetes resource model, and we leverage that all the way, right?", "tokens": [51170, 407, 591, 49, 44, 307, 264, 23145, 7684, 2316, 11, 293, 321, 13982, 300, 439, 264, 636, 11, 558, 30, 51416], "temperature": 0.0, "avg_logprob": -0.1814764416407025, "compression_ratio": 1.7165354330708662, "no_speech_prob": 0.024095382541418076}, {"id": 66, "seek": 24920, "start": 270.24, "end": 273.68, "text": " So that means we have a clearly defined API.", "tokens": [51416, 407, 300, 1355, 321, 362, 257, 4448, 7642, 9362, 13, 51588], "temperature": 0.0, "avg_logprob": -0.1814764416407025, "compression_ratio": 1.7165354330708662, "no_speech_prob": 0.024095382541418076}, {"id": 67, "seek": 24920, "start": 273.68, "end": 276.28, "text": " We have the set of metadata.", "tokens": [51588, 492, 362, 264, 992, 295, 26603, 13, 51718], "temperature": 0.0, "avg_logprob": -0.1814764416407025, "compression_ratio": 1.7165354330708662, "no_speech_prob": 0.024095382541418076}, {"id": 68, "seek": 27628, "start": 276.28, "end": 282.88, "text": " We leverage the desired versus observed state to basically figure out a declarative base", "tokens": [50364, 492, 13982, 264, 14721, 5717, 13095, 1785, 281, 1936, 2573, 484, 257, 16694, 1166, 3096, 50694], "temperature": 0.0, "avg_logprob": -0.12931439535958425, "compression_ratio": 1.7254098360655739, "no_speech_prob": 0.0038139387033879757}, {"id": 69, "seek": 27628, "start": 282.88, "end": 284.2, "text": " of operation.", "tokens": [50694, 295, 6916, 13, 50760], "temperature": 0.0, "avg_logprob": -0.12931439535958425, "compression_ratio": 1.7254098360655739, "no_speech_prob": 0.0038139387033879757}, {"id": 70, "seek": 27628, "start": 284.2, "end": 287.23999999999995, "text": " We leverage the event-driven ecosystem and stuff like that.", "tokens": [50760, 492, 13982, 264, 2280, 12, 25456, 11311, 293, 1507, 411, 300, 13, 50912], "temperature": 0.0, "avg_logprob": -0.12931439535958425, "compression_ratio": 1.7254098360655739, "no_speech_prob": 0.0038139387033879757}, {"id": 71, "seek": 27628, "start": 287.23999999999995, "end": 290.03999999999996, "text": " So we leverage that to the full extent.", "tokens": [50912, 407, 321, 13982, 300, 281, 264, 1577, 8396, 13, 51052], "temperature": 0.0, "avg_logprob": -0.12931439535958425, "compression_ratio": 1.7254098360655739, "no_speech_prob": 0.0038139387033879757}, {"id": 72, "seek": 27628, "start": 290.03999999999996, "end": 296.4, "text": " Now what we have seen in order to solve that problem at scale, we were missing a few primitives,", "tokens": [51052, 823, 437, 321, 362, 1612, 294, 1668, 281, 5039, 300, 1154, 412, 4373, 11, 321, 645, 5361, 257, 1326, 2886, 38970, 11, 51370], "temperature": 0.0, "avg_logprob": -0.12931439535958425, "compression_ratio": 1.7254098360655739, "no_speech_prob": 0.0038139387033879757}, {"id": 73, "seek": 27628, "start": 296.4, "end": 297.4, "text": " right?", "tokens": [51370, 558, 30, 51420], "temperature": 0.0, "avg_logprob": -0.12931439535958425, "compression_ratio": 1.7254098360655739, "no_speech_prob": 0.0038139387033879757}, {"id": 74, "seek": 27628, "start": 297.4, "end": 302.91999999999996, "text": " And one of those primitives that we have been added to the component is what we call configuration", "tokens": [51420, 400, 472, 295, 729, 2886, 38970, 300, 321, 362, 668, 3869, 281, 264, 6542, 307, 437, 321, 818, 11694, 51696], "temperature": 0.0, "avg_logprob": -0.12931439535958425, "compression_ratio": 1.7254098360655739, "no_speech_prob": 0.0038139387033879757}, {"id": 75, "seek": 27628, "start": 302.91999999999996, "end": 304.84, "text": " as data, right?", "tokens": [51696, 382, 1412, 11, 558, 30, 51792], "temperature": 0.0, "avg_logprob": -0.12931439535958425, "compression_ratio": 1.7254098360655739, "no_speech_prob": 0.0038139387033879757}, {"id": 76, "seek": 30484, "start": 304.84, "end": 310.64, "text": " Because if you look to how Kubernetes works as its basis, you actually have a CRD or a", "tokens": [50364, 1436, 498, 291, 574, 281, 577, 23145, 1985, 382, 1080, 5143, 11, 291, 767, 362, 257, 14123, 35, 420, 257, 50654], "temperature": 0.0, "avg_logprob": -0.1166231815631573, "compression_ratio": 1.6692307692307693, "no_speech_prob": 0.007702953647822142}, {"id": 77, "seek": 30484, "start": 310.64, "end": 315.32, "text": " Kubernetes resource that is basically triggering something, right?", "tokens": [50654, 23145, 7684, 300, 307, 1936, 40406, 746, 11, 558, 30, 50888], "temperature": 0.0, "avg_logprob": -0.1166231815631573, "compression_ratio": 1.6692307692307693, "no_speech_prob": 0.007702953647822142}, {"id": 78, "seek": 30484, "start": 315.32, "end": 322.03999999999996, "text": " Now because we are dealing with this massively complex environment, right, we said, okay,", "tokens": [50888, 823, 570, 321, 366, 6260, 365, 341, 29379, 3997, 2823, 11, 558, 11, 321, 848, 11, 1392, 11, 51224], "temperature": 0.0, "avg_logprob": -0.1166231815631573, "compression_ratio": 1.6692307692307693, "no_speech_prob": 0.007702953647822142}, {"id": 79, "seek": 30484, "start": 322.03999999999996, "end": 324.64, "text": " a single unit is probably not sufficient for us.", "tokens": [51224, 257, 2167, 4985, 307, 1391, 406, 11563, 337, 505, 13, 51354], "temperature": 0.0, "avg_logprob": -0.1166231815631573, "compression_ratio": 1.6692307692307693, "no_speech_prob": 0.007702953647822142}, {"id": 80, "seek": 30484, "start": 324.64, "end": 327.44, "text": " So we defined the concept of a package, right?", "tokens": [51354, 407, 321, 7642, 264, 3410, 295, 257, 7372, 11, 558, 30, 51494], "temperature": 0.0, "avg_logprob": -0.1166231815631573, "compression_ratio": 1.6692307692307693, "no_speech_prob": 0.007702953647822142}, {"id": 81, "seek": 30484, "start": 327.44, "end": 333.44, "text": " So rather than having a single CRD, we actually built a package, and a package is a collection", "tokens": [51494, 407, 2831, 813, 1419, 257, 2167, 14123, 35, 11, 321, 767, 3094, 257, 7372, 11, 293, 257, 7372, 307, 257, 5765, 51794], "temperature": 0.0, "avg_logprob": -0.1166231815631573, "compression_ratio": 1.6692307692307693, "no_speech_prob": 0.007702953647822142}, {"id": 82, "seek": 33344, "start": 333.44, "end": 339.76, "text": " of KRM resources that you are going to use as a kind of what we call a blueprint or a", "tokens": [50364, 295, 37522, 44, 3593, 300, 291, 366, 516, 281, 764, 382, 257, 733, 295, 437, 321, 818, 257, 35868, 420, 257, 50680], "temperature": 0.0, "avg_logprob": -0.15816850662231446, "compression_ratio": 1.6608695652173913, "no_speech_prob": 0.004426418803632259}, {"id": 83, "seek": 33344, "start": 339.76, "end": 341.08, "text": " service catalog, right?", "tokens": [50680, 2643, 19746, 11, 558, 30, 50746], "temperature": 0.0, "avg_logprob": -0.15816850662231446, "compression_ratio": 1.6608695652173913, "no_speech_prob": 0.004426418803632259}, {"id": 84, "seek": 33344, "start": 341.08, "end": 346.88, "text": " So it's basically think of it as a collection of KRM resources that do things together,", "tokens": [50746, 407, 309, 311, 1936, 519, 295, 309, 382, 257, 5765, 295, 37522, 44, 3593, 300, 360, 721, 1214, 11, 51036], "temperature": 0.0, "avg_logprob": -0.15816850662231446, "compression_ratio": 1.6608695652173913, "no_speech_prob": 0.004426418803632259}, {"id": 85, "seek": 33344, "start": 346.88, "end": 348.16, "text": " right?", "tokens": [51036, 558, 30, 51100], "temperature": 0.0, "avg_logprob": -0.15816850662231446, "compression_ratio": 1.6608695652173913, "no_speech_prob": 0.004426418803632259}, {"id": 86, "seek": 33344, "start": 348.16, "end": 352.68, "text": " The second thing that we did is today in order to use Kubernetes, you typically have to build", "tokens": [51100, 440, 1150, 551, 300, 321, 630, 307, 965, 294, 1668, 281, 764, 23145, 11, 291, 5850, 362, 281, 1322, 51326], "temperature": 0.0, "avg_logprob": -0.15816850662231446, "compression_ratio": 1.6608695652173913, "no_speech_prob": 0.004426418803632259}, {"id": 87, "seek": 33344, "start": 352.68, "end": 355.6, "text": " a controller in code and stuff like that, right?", "tokens": [51326, 257, 10561, 294, 3089, 293, 1507, 411, 300, 11, 558, 30, 51472], "temperature": 0.0, "avg_logprob": -0.15816850662231446, "compression_ratio": 1.6608695652173913, "no_speech_prob": 0.004426418803632259}, {"id": 88, "seek": 33344, "start": 355.6, "end": 358.64, "text": " So we added the capability better.", "tokens": [51472, 407, 321, 3869, 264, 13759, 1101, 13, 51624], "temperature": 0.0, "avg_logprob": -0.15816850662231446, "compression_ratio": 1.6608695652173913, "no_speech_prob": 0.004426418803632259}, {"id": 89, "seek": 35864, "start": 358.64, "end": 363.8, "text": " You basically say I want to create a deployment and then there will be a replica set controller", "tokens": [50364, 509, 1936, 584, 286, 528, 281, 1884, 257, 19317, 293, 550, 456, 486, 312, 257, 35456, 992, 10561, 50622], "temperature": 0.0, "avg_logprob": -0.13889909169030568, "compression_ratio": 1.7695035460992907, "no_speech_prob": 0.02725820429623127}, {"id": 90, "seek": 35864, "start": 363.8, "end": 367.76, "text": " which basically says, okay, I'm going to select this node and I'm going to scale this out", "tokens": [50622, 597, 1936, 1619, 11, 1392, 11, 286, 478, 516, 281, 3048, 341, 9984, 293, 286, 478, 516, 281, 4373, 341, 484, 50820], "temperature": 0.0, "avg_logprob": -0.13889909169030568, "compression_ratio": 1.7695035460992907, "no_speech_prob": 0.02725820429623127}, {"id": 91, "seek": 35864, "start": 367.76, "end": 372.68, "text": " and I'm going to deploy a set of POTS over a number of resources, right?", "tokens": [50820, 293, 286, 478, 516, 281, 7274, 257, 992, 295, 430, 5068, 50, 670, 257, 1230, 295, 3593, 11, 558, 30, 51066], "temperature": 0.0, "avg_logprob": -0.13889909169030568, "compression_ratio": 1.7695035460992907, "no_speech_prob": 0.02725820429623127}, {"id": 92, "seek": 35864, "start": 372.68, "end": 377.59999999999997, "text": " That's what typically happens today inside of Kubernetes and you have different methods", "tokens": [51066, 663, 311, 437, 5850, 2314, 965, 1854, 295, 23145, 293, 291, 362, 819, 7150, 51312], "temperature": 0.0, "avg_logprob": -0.13889909169030568, "compression_ratio": 1.7695035460992907, "no_speech_prob": 0.02725820429623127}, {"id": 93, "seek": 35864, "start": 377.59999999999997, "end": 378.59999999999997, "text": " to do so.", "tokens": [51312, 281, 360, 370, 13, 51362], "temperature": 0.0, "avg_logprob": -0.13889909169030568, "compression_ratio": 1.7695035460992907, "no_speech_prob": 0.02725820429623127}, {"id": 94, "seek": 35864, "start": 378.59999999999997, "end": 382.03999999999996, "text": " You have deployment, you have replica sets and so on and so forth, or stateful sets,", "tokens": [51362, 509, 362, 19317, 11, 291, 362, 35456, 6352, 293, 370, 322, 293, 370, 5220, 11, 420, 1785, 906, 6352, 11, 51534], "temperature": 0.0, "avg_logprob": -0.13889909169030568, "compression_ratio": 1.7695035460992907, "no_speech_prob": 0.02725820429623127}, {"id": 95, "seek": 35864, "start": 382.03999999999996, "end": 385.8, "text": " and you pick and choose the one that's familiar with you.", "tokens": [51534, 293, 291, 1888, 293, 2826, 264, 472, 300, 311, 4963, 365, 291, 13, 51722], "temperature": 0.0, "avg_logprob": -0.13889909169030568, "compression_ratio": 1.7695035460992907, "no_speech_prob": 0.02725820429623127}, {"id": 96, "seek": 38580, "start": 385.8, "end": 392.32, "text": " Even that we work above a cluster level, what we do in nephew, we call it a term, what", "tokens": [50364, 2754, 300, 321, 589, 3673, 257, 13630, 1496, 11, 437, 321, 360, 294, 30799, 11, 321, 818, 309, 257, 1433, 11, 437, 50690], "temperature": 0.0, "avg_logprob": -0.21321304027850813, "compression_ratio": 1.7966804979253113, "no_speech_prob": 0.08499018847942352}, {"id": 97, "seek": 38580, "start": 392.32, "end": 397.96000000000004, "text": " we call a package variant or a package variant set which basically says I want to have my", "tokens": [50690, 321, 818, 257, 7372, 17501, 420, 257, 7372, 17501, 992, 597, 1936, 1619, 286, 528, 281, 362, 452, 50972], "temperature": 0.0, "avg_logprob": -0.21321304027850813, "compression_ratio": 1.7966804979253113, "no_speech_prob": 0.08499018847942352}, {"id": 98, "seek": 38580, "start": 397.96000000000004, "end": 404.16, "text": " package which I was talking about and I want to deploy that on these sites, right?", "tokens": [50972, 7372, 597, 286, 390, 1417, 466, 293, 286, 528, 281, 7274, 300, 322, 613, 7533, 11, 558, 30, 51282], "temperature": 0.0, "avg_logprob": -0.21321304027850813, "compression_ratio": 1.7966804979253113, "no_speech_prob": 0.08499018847942352}, {"id": 99, "seek": 38580, "start": 404.16, "end": 409.68, "text": " And each of these sites will then be what we call specialized within their own context", "tokens": [51282, 400, 1184, 295, 613, 7533, 486, 550, 312, 437, 321, 818, 19813, 1951, 641, 1065, 4319, 51558], "temperature": 0.0, "avg_logprob": -0.21321304027850813, "compression_ratio": 1.7966804979253113, "no_speech_prob": 0.08499018847942352}, {"id": 100, "seek": 38580, "start": 409.68, "end": 413.76, "text": " where the relative parameters, for example, this site needs this VLAN, this site needs", "tokens": [51558, 689, 264, 4972, 9834, 11, 337, 1365, 11, 341, 3621, 2203, 341, 691, 36527, 11, 341, 3621, 2203, 51762], "temperature": 0.0, "avg_logprob": -0.21321304027850813, "compression_ratio": 1.7966804979253113, "no_speech_prob": 0.08499018847942352}, {"id": 101, "seek": 41376, "start": 413.76, "end": 417.4, "text": " this IP address, this size needs these PLM and ID's and stuff like that.", "tokens": [50364, 341, 8671, 2985, 11, 341, 2744, 2203, 613, 6999, 44, 293, 7348, 311, 293, 1507, 411, 300, 13, 50546], "temperature": 0.0, "avg_logprob": -0.17002090331046812, "compression_ratio": 1.7731958762886597, "no_speech_prob": 0.01756066270172596}, {"id": 102, "seek": 41376, "start": 417.4, "end": 422.08, "text": " So they will be specialized based on their specific context on where they get deployed", "tokens": [50546, 407, 436, 486, 312, 19813, 2361, 322, 641, 2685, 4319, 322, 689, 436, 483, 17826, 50780], "temperature": 0.0, "avg_logprob": -0.17002090331046812, "compression_ratio": 1.7731958762886597, "no_speech_prob": 0.01756066270172596}, {"id": 103, "seek": 41376, "start": 422.08, "end": 427.03999999999996, "text": " and as a result, that's then being deployed on that particular cluster, right?", "tokens": [50780, 293, 382, 257, 1874, 11, 300, 311, 550, 885, 17826, 322, 300, 1729, 13630, 11, 558, 30, 51028], "temperature": 0.0, "avg_logprob": -0.17002090331046812, "compression_ratio": 1.7731958762886597, "no_speech_prob": 0.01756066270172596}, {"id": 104, "seek": 41376, "start": 427.03999999999996, "end": 431.96, "text": " So you see that if you look to the analogy of Kubernetes, we are working at the level,", "tokens": [51028, 407, 291, 536, 300, 498, 291, 574, 281, 264, 21663, 295, 23145, 11, 321, 366, 1364, 412, 264, 1496, 11, 51274], "temperature": 0.0, "avg_logprob": -0.17002090331046812, "compression_ratio": 1.7731958762886597, "no_speech_prob": 0.01756066270172596}, {"id": 105, "seek": 41376, "start": 431.96, "end": 436.32, "text": " at the cluster level versus where as Kubernetes works at the node level scheduling type of", "tokens": [51274, 412, 264, 13630, 1496, 5717, 689, 382, 23145, 1985, 412, 264, 9984, 1496, 29055, 2010, 295, 51492], "temperature": 0.0, "avg_logprob": -0.17002090331046812, "compression_ratio": 1.7731958762886597, "no_speech_prob": 0.01756066270172596}, {"id": 106, "seek": 41376, "start": 436.32, "end": 437.32, "text": " level.", "tokens": [51492, 1496, 13, 51542], "temperature": 0.0, "avg_logprob": -0.17002090331046812, "compression_ratio": 1.7731958762886597, "no_speech_prob": 0.01756066270172596}, {"id": 107, "seek": 41376, "start": 437.32, "end": 441.84, "text": " So we work a level above but you see a lot of concepts that were born or that were basically", "tokens": [51542, 407, 321, 589, 257, 1496, 3673, 457, 291, 536, 257, 688, 295, 10392, 300, 645, 4232, 420, 300, 645, 1936, 51768], "temperature": 0.0, "avg_logprob": -0.17002090331046812, "compression_ratio": 1.7731958762886597, "no_speech_prob": 0.01756066270172596}, {"id": 108, "seek": 44184, "start": 441.84, "end": 443.88, "text": " derived from Kubernetes.", "tokens": [50364, 18949, 490, 23145, 13, 50466], "temperature": 0.0, "avg_logprob": -0.12708015831149355, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.01265089400112629}, {"id": 109, "seek": 44184, "start": 443.88, "end": 448.32, "text": " We are leveraging within the framework that we are deploying within nephew in order to", "tokens": [50466, 492, 366, 32666, 1951, 264, 8388, 300, 321, 366, 34198, 1951, 30799, 294, 1668, 281, 50688], "temperature": 0.0, "avg_logprob": -0.12708015831149355, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.01265089400112629}, {"id": 110, "seek": 44184, "start": 448.32, "end": 455.03999999999996, "text": " stay as close as possible to it so that we can leverage the benefits of that whole ecosystem.", "tokens": [50688, 1754, 382, 1998, 382, 1944, 281, 309, 370, 300, 321, 393, 13982, 264, 5311, 295, 300, 1379, 11311, 13, 51024], "temperature": 0.0, "avg_logprob": -0.12708015831149355, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.01265089400112629}, {"id": 111, "seek": 44184, "start": 455.03999999999996, "end": 458.71999999999997, "text": " Now to put that into perspective, I try to explain that a little bit.", "tokens": [51024, 823, 281, 829, 300, 666, 4585, 11, 286, 853, 281, 2903, 300, 257, 707, 857, 13, 51208], "temperature": 0.0, "avg_logprob": -0.12708015831149355, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.01265089400112629}, {"id": 112, "seek": 44184, "start": 458.71999999999997, "end": 461.0, "text": " So we have a concept of management clusters.", "tokens": [51208, 407, 321, 362, 257, 3410, 295, 4592, 23313, 13, 51322], "temperature": 0.0, "avg_logprob": -0.12708015831149355, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.01265089400112629}, {"id": 113, "seek": 44184, "start": 461.0, "end": 466.52, "text": " So this is a regular Kubernetes cluster but we use it typically for our control engines,", "tokens": [51322, 407, 341, 307, 257, 3890, 23145, 13630, 457, 321, 764, 309, 5850, 337, 527, 1969, 12982, 11, 51598], "temperature": 0.0, "avg_logprob": -0.12708015831149355, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.01265089400112629}, {"id": 114, "seek": 44184, "start": 466.52, "end": 467.52, "text": " right?", "tokens": [51598, 558, 30, 51648], "temperature": 0.0, "avg_logprob": -0.12708015831149355, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.01265089400112629}, {"id": 115, "seek": 46752, "start": 467.52, "end": 472.88, "text": " This is where our, what we call the configuration as data server which is ported in our implementation", "tokens": [50364, 639, 307, 689, 527, 11, 437, 321, 818, 264, 11694, 382, 1412, 7154, 597, 307, 2436, 292, 294, 527, 11420, 50632], "temperature": 0.0, "avg_logprob": -0.2320891817410787, "compression_ratio": 1.6626016260162602, "no_speech_prob": 0.006864415016025305}, {"id": 116, "seek": 46752, "start": 472.88, "end": 481.68, "text": " is used upon and then we schedule work, network functions onto those specific workloads, right?", "tokens": [50632, 307, 1143, 3564, 293, 550, 321, 7567, 589, 11, 3209, 6828, 3911, 729, 2685, 32452, 11, 558, 30, 51072], "temperature": 0.0, "avg_logprob": -0.2320891817410787, "compression_ratio": 1.6626016260162602, "no_speech_prob": 0.006864415016025305}, {"id": 117, "seek": 46752, "start": 481.68, "end": 486.4, "text": " And how we do that is we basically have this concept of a package on the right hand side", "tokens": [51072, 400, 577, 321, 360, 300, 307, 321, 1936, 362, 341, 3410, 295, 257, 7372, 322, 264, 558, 1011, 1252, 51308], "temperature": 0.0, "avg_logprob": -0.2320891817410787, "compression_ratio": 1.6626016260162602, "no_speech_prob": 0.006864415016025305}, {"id": 118, "seek": 46752, "start": 486.4, "end": 487.64, "text": " which is our blueprint.", "tokens": [51308, 597, 307, 527, 35868, 13, 51370], "temperature": 0.0, "avg_logprob": -0.2320891817410787, "compression_ratio": 1.6626016260162602, "no_speech_prob": 0.006864415016025305}, {"id": 119, "seek": 46752, "start": 487.64, "end": 493.84, "text": " So think about someone as a vendor or as an operator, someone basically put that together,", "tokens": [51370, 407, 519, 466, 1580, 382, 257, 24321, 420, 382, 364, 12973, 11, 1580, 1936, 829, 300, 1214, 11, 51680], "temperature": 0.0, "avg_logprob": -0.2320891817410787, "compression_ratio": 1.6626016260162602, "no_speech_prob": 0.006864415016025305}, {"id": 120, "seek": 46752, "start": 493.84, "end": 494.84, "text": " right?", "tokens": [51680, 558, 30, 51730], "temperature": 0.0, "avg_logprob": -0.2320891817410787, "compression_ratio": 1.6626016260162602, "no_speech_prob": 0.006864415016025305}, {"id": 121, "seek": 49484, "start": 494.84, "end": 499.15999999999997, "text": " So we have the KRM resources that are needed for that particular environment and then we", "tokens": [50364, 407, 321, 362, 264, 591, 49, 44, 3593, 300, 366, 2978, 337, 300, 1729, 2823, 293, 550, 321, 50580], "temperature": 0.0, "avg_logprob": -0.1857613440482847, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.022555317729711533}, {"id": 122, "seek": 49484, "start": 499.15999999999997, "end": 502.28, "text": " say, okay, I want to deploy that on 10,000 sites, right?", "tokens": [50580, 584, 11, 1392, 11, 286, 528, 281, 7274, 300, 322, 1266, 11, 1360, 7533, 11, 558, 30, 50736], "temperature": 0.0, "avg_logprob": -0.1857613440482847, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.022555317729711533}, {"id": 123, "seek": 49484, "start": 502.28, "end": 508.76, "text": " When we do this, when we try to make variations of that package for a particular context,", "tokens": [50736, 1133, 321, 360, 341, 11, 562, 321, 853, 281, 652, 17840, 295, 300, 7372, 337, 257, 1729, 4319, 11, 51060], "temperature": 0.0, "avg_logprob": -0.1857613440482847, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.022555317729711533}, {"id": 124, "seek": 49484, "start": 508.76, "end": 511.84, "text": " we also said, okay, let's divide and conquer, right?", "tokens": [51060, 321, 611, 848, 11, 1392, 11, 718, 311, 9845, 293, 24136, 11, 558, 30, 51214], "temperature": 0.0, "avg_logprob": -0.1857613440482847, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.022555317729711533}, {"id": 125, "seek": 49484, "start": 511.84, "end": 517.12, "text": " So because you could basically build a pipeline that is very narrow and very strict, right?", "tokens": [51214, 407, 570, 291, 727, 1936, 1322, 257, 15517, 300, 307, 588, 9432, 293, 588, 10910, 11, 558, 30, 51478], "temperature": 0.0, "avg_logprob": -0.1857613440482847, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.022555317729711533}, {"id": 126, "seek": 49484, "start": 517.12, "end": 519.9599999999999, "text": " But typically what we see is that you need flexibility, right?", "tokens": [51478, 583, 5850, 437, 321, 536, 307, 300, 291, 643, 12635, 11, 558, 30, 51620], "temperature": 0.0, "avg_logprob": -0.1857613440482847, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.022555317729711533}, {"id": 127, "seek": 49484, "start": 519.9599999999999, "end": 522.1999999999999, "text": " So you want to have a flexible system.", "tokens": [51620, 407, 291, 528, 281, 362, 257, 11358, 1185, 13, 51732], "temperature": 0.0, "avg_logprob": -0.1857613440482847, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.022555317729711533}, {"id": 128, "seek": 52220, "start": 522.2, "end": 527.2800000000001, "text": " And so we developed a concept, what we call the conditional dance of the choreography which", "tokens": [50364, 400, 370, 321, 4743, 257, 3410, 11, 437, 321, 818, 264, 27708, 4489, 295, 264, 23482, 597, 50618], "temperature": 0.0, "avg_logprob": -0.17289851410220367, "compression_ratio": 1.6812749003984064, "no_speech_prob": 0.02960887737572193}, {"id": 129, "seek": 52220, "start": 527.2800000000001, "end": 534.5600000000001, "text": " is a set of primitives, I think of functions here that each do a specific thing.", "tokens": [50618, 307, 257, 992, 295, 2886, 38970, 11, 286, 519, 295, 6828, 510, 300, 1184, 360, 257, 2685, 551, 13, 50982], "temperature": 0.0, "avg_logprob": -0.17289851410220367, "compression_ratio": 1.6812749003984064, "no_speech_prob": 0.02960887737572193}, {"id": 130, "seek": 52220, "start": 534.5600000000001, "end": 539.6800000000001, "text": " So for example, IP address, VLANs and so on and so forth.", "tokens": [50982, 407, 337, 1365, 11, 8671, 2985, 11, 691, 36527, 82, 293, 370, 322, 293, 370, 5220, 13, 51238], "temperature": 0.0, "avg_logprob": -0.17289851410220367, "compression_ratio": 1.6812749003984064, "no_speech_prob": 0.02960887737572193}, {"id": 131, "seek": 52220, "start": 539.6800000000001, "end": 544.96, "text": " And each of them basically make sure that if those things are needed, they are basically", "tokens": [51238, 400, 1184, 295, 552, 1936, 652, 988, 300, 498, 729, 721, 366, 2978, 11, 436, 366, 1936, 51502], "temperature": 0.0, "avg_logprob": -0.17289851410220367, "compression_ratio": 1.6812749003984064, "no_speech_prob": 0.02960887737572193}, {"id": 132, "seek": 52220, "start": 544.96, "end": 551.4000000000001, "text": " being called upon and specialized those packages with a specific context for that type of environment.", "tokens": [51502, 885, 1219, 3564, 293, 19813, 729, 17401, 365, 257, 2685, 4319, 337, 300, 2010, 295, 2823, 13, 51824], "temperature": 0.0, "avg_logprob": -0.17289851410220367, "compression_ratio": 1.6812749003984064, "no_speech_prob": 0.02960887737572193}, {"id": 133, "seek": 55140, "start": 551.4, "end": 556.48, "text": " And that's how we can make this work in a very scalable and flexible and pluggable play", "tokens": [50364, 400, 300, 311, 577, 321, 393, 652, 341, 589, 294, 257, 588, 38481, 293, 11358, 293, 499, 3562, 712, 862, 50618], "temperature": 0.0, "avg_logprob": -0.20923077691461622, "compression_ratio": 1.6074766355140186, "no_speech_prob": 0.010187466628849506}, {"id": 134, "seek": 55140, "start": 556.48, "end": 561.76, "text": " and it's easily to extend that within a specific environment.", "tokens": [50618, 293, 309, 311, 3612, 281, 10101, 300, 1951, 257, 2685, 2823, 13, 50882], "temperature": 0.0, "avg_logprob": -0.20923077691461622, "compression_ratio": 1.6074766355140186, "no_speech_prob": 0.010187466628849506}, {"id": 135, "seek": 55140, "start": 561.76, "end": 564.4399999999999, "text": " So what did we do so far within Nefuse?", "tokens": [50882, 407, 437, 630, 321, 360, 370, 1400, 1951, 1734, 69, 438, 30, 51016], "temperature": 0.0, "avg_logprob": -0.20923077691461622, "compression_ratio": 1.6074766355140186, "no_speech_prob": 0.010187466628849506}, {"id": 136, "seek": 55140, "start": 564.4399999999999, "end": 567.0799999999999, "text": " We are a very early pro yet.", "tokens": [51016, 492, 366, 257, 588, 2440, 447, 1939, 13, 51148], "temperature": 0.0, "avg_logprob": -0.20923077691461622, "compression_ratio": 1.6074766355140186, "no_speech_prob": 0.010187466628849506}, {"id": 137, "seek": 55140, "start": 567.0799999999999, "end": 571.9599999999999, "text": " So and it would be good if people would like to join us.", "tokens": [51148, 407, 293, 309, 576, 312, 665, 498, 561, 576, 411, 281, 3917, 505, 13, 51392], "temperature": 0.0, "avg_logprob": -0.20923077691461622, "compression_ratio": 1.6074766355140186, "no_speech_prob": 0.010187466628849506}, {"id": 138, "seek": 55140, "start": 571.9599999999999, "end": 577.12, "text": " So we have done, so we are just about to release release two, right?", "tokens": [51392, 407, 321, 362, 1096, 11, 370, 321, 366, 445, 466, 281, 4374, 4374, 732, 11, 558, 30, 51650], "temperature": 0.0, "avg_logprob": -0.20923077691461622, "compression_ratio": 1.6074766355140186, "no_speech_prob": 0.010187466628849506}, {"id": 139, "seek": 57712, "start": 577.12, "end": 583.24, "text": " So what we have shown so far is basically the concept that I showed in the beginning.", "tokens": [50364, 407, 437, 321, 362, 4898, 370, 1400, 307, 1936, 264, 3410, 300, 286, 4712, 294, 264, 2863, 13, 50670], "temperature": 0.0, "avg_logprob": -0.16199102768531212, "compression_ratio": 1.7920353982300885, "no_speech_prob": 0.041530705988407135}, {"id": 140, "seek": 57712, "start": 583.24, "end": 585.64, "text": " We have basically proven that with Free5GC.", "tokens": [50670, 492, 362, 1936, 12785, 300, 365, 11551, 20, 38, 34, 13, 50790], "temperature": 0.0, "avg_logprob": -0.16199102768531212, "compression_ratio": 1.7920353982300885, "no_speech_prob": 0.041530705988407135}, {"id": 141, "seek": 57712, "start": 585.64, "end": 592.24, "text": " So Free5GC is an open source project that basically deploys the core side of a 5G type", "tokens": [50790, 407, 11551, 20, 38, 34, 307, 364, 1269, 4009, 1716, 300, 1936, 368, 49522, 264, 4965, 1252, 295, 257, 1025, 38, 2010, 51120], "temperature": 0.0, "avg_logprob": -0.16199102768531212, "compression_ratio": 1.7920353982300885, "no_speech_prob": 0.041530705988407135}, {"id": 142, "seek": 57712, "start": 592.24, "end": 593.24, "text": " of network.", "tokens": [51120, 295, 3209, 13, 51170], "temperature": 0.0, "avg_logprob": -0.16199102768531212, "compression_ratio": 1.7920353982300885, "no_speech_prob": 0.041530705988407135}, {"id": 143, "seek": 57712, "start": 593.24, "end": 598.64, "text": " So we have basically proven that we can use the machinery to actually deploy and show", "tokens": [51170, 407, 321, 362, 1936, 12785, 300, 321, 393, 764, 264, 27302, 281, 767, 7274, 293, 855, 51440], "temperature": 0.0, "avg_logprob": -0.16199102768531212, "compression_ratio": 1.7920353982300885, "no_speech_prob": 0.041530705988407135}, {"id": 144, "seek": 57712, "start": 598.64, "end": 603.8, "text": " what I'm presenting here in the slides is actually working up to setting up a call, right?", "tokens": [51440, 437, 286, 478, 15578, 510, 294, 264, 9788, 307, 767, 1364, 493, 281, 3287, 493, 257, 818, 11, 558, 30, 51698], "temperature": 0.0, "avg_logprob": -0.16199102768531212, "compression_ratio": 1.7920353982300885, "no_speech_prob": 0.041530705988407135}, {"id": 145, "seek": 60380, "start": 603.8, "end": 607.68, "text": " So we are using the whole network setup that actually connects all of these functions together.", "tokens": [50364, 407, 321, 366, 1228, 264, 1379, 3209, 8657, 300, 767, 16967, 439, 295, 613, 6828, 1214, 13, 50558], "temperature": 0.0, "avg_logprob": -0.18571804364522299, "compression_ratio": 1.779783393501805, "no_speech_prob": 0.10040856152772903}, {"id": 146, "seek": 60380, "start": 607.68, "end": 610.68, "text": " So all of that using the primitives that I was showing.", "tokens": [50558, 407, 439, 295, 300, 1228, 264, 2886, 38970, 300, 286, 390, 4099, 13, 50708], "temperature": 0.0, "avg_logprob": -0.18571804364522299, "compression_ratio": 1.779783393501805, "no_speech_prob": 0.10040856152772903}, {"id": 147, "seek": 60380, "start": 610.68, "end": 615.0, "text": " And in release two we added OII which is another open source project mainly focused on the", "tokens": [50708, 400, 294, 4374, 732, 321, 3869, 422, 9503, 597, 307, 1071, 1269, 4009, 1716, 8704, 5178, 322, 264, 50924], "temperature": 0.0, "avg_logprob": -0.18571804364522299, "compression_ratio": 1.779783393501805, "no_speech_prob": 0.10040856152772903}, {"id": 148, "seek": 60380, "start": 615.0, "end": 620.0799999999999, "text": " radio but also as the core so that we prove that we can do this not across one vendor", "tokens": [50924, 6477, 457, 611, 382, 264, 4965, 370, 300, 321, 7081, 300, 321, 393, 360, 341, 406, 2108, 472, 24321, 51178], "temperature": 0.0, "avg_logprob": -0.18571804364522299, "compression_ratio": 1.779783393501805, "no_speech_prob": 0.10040856152772903}, {"id": 149, "seek": 60380, "start": 620.0799999999999, "end": 622.64, "text": " but across multiple vendors, right?", "tokens": [51178, 457, 2108, 3866, 22056, 11, 558, 30, 51306], "temperature": 0.0, "avg_logprob": -0.18571804364522299, "compression_ratio": 1.779783393501805, "no_speech_prob": 0.10040856152772903}, {"id": 150, "seek": 60380, "start": 622.64, "end": 627.92, "text": " And so we are extending this whole framework with more primitives as we go along.", "tokens": [51306, 400, 370, 321, 366, 24360, 341, 1379, 8388, 365, 544, 2886, 38970, 382, 321, 352, 2051, 13, 51570], "temperature": 0.0, "avg_logprob": -0.18571804364522299, "compression_ratio": 1.779783393501805, "no_speech_prob": 0.10040856152772903}, {"id": 151, "seek": 60380, "start": 627.92, "end": 632.0, "text": " As I said, we are a very young project, right?", "tokens": [51570, 1018, 286, 848, 11, 321, 366, 257, 588, 2037, 1716, 11, 558, 30, 51774], "temperature": 0.0, "avg_logprob": -0.18571804364522299, "compression_ratio": 1.779783393501805, "no_speech_prob": 0.10040856152772903}, {"id": 152, "seek": 63200, "start": 632.0, "end": 633.88, "text": " And so we seek for a lot of help.", "tokens": [50364, 400, 370, 321, 8075, 337, 257, 688, 295, 854, 13, 50458], "temperature": 0.0, "avg_logprob": -0.16617556451593787, "compression_ratio": 1.652, "no_speech_prob": 0.052587516605854034}, {"id": 153, "seek": 63200, "start": 633.88, "end": 637.4, "text": " So if you are interested to join us, we would welcome.", "tokens": [50458, 407, 498, 291, 366, 3102, 281, 3917, 505, 11, 321, 576, 2928, 13, 50634], "temperature": 0.0, "avg_logprob": -0.16617556451593787, "compression_ratio": 1.652, "no_speech_prob": 0.052587516605854034}, {"id": 154, "seek": 63200, "start": 637.4, "end": 642.16, "text": " So please contact me or please look at one of those resources that are available here", "tokens": [50634, 407, 1767, 3385, 385, 420, 1767, 574, 412, 472, 295, 729, 3593, 300, 366, 2435, 510, 50872], "temperature": 0.0, "avg_logprob": -0.16617556451593787, "compression_ratio": 1.652, "no_speech_prob": 0.052587516605854034}, {"id": 155, "seek": 63200, "start": 642.16, "end": 647.88, "text": " because this is all the information which you can have a look at to the operation.", "tokens": [50872, 570, 341, 307, 439, 264, 1589, 597, 291, 393, 362, 257, 574, 412, 281, 264, 6916, 13, 51158], "temperature": 0.0, "avg_logprob": -0.16617556451593787, "compression_ratio": 1.652, "no_speech_prob": 0.052587516605854034}, {"id": 156, "seek": 63200, "start": 647.88, "end": 653.12, "text": " And what you see is that you can actually move rather more quickly than in an on-up", "tokens": [51158, 400, 437, 291, 536, 307, 300, 291, 393, 767, 1286, 2831, 544, 2661, 813, 294, 364, 322, 12, 1010, 51420], "temperature": 0.0, "avg_logprob": -0.16617556451593787, "compression_ratio": 1.652, "no_speech_prob": 0.052587516605854034}, {"id": 157, "seek": 63200, "start": 653.12, "end": 656.96, "text": " type of approach but we are actually trying to solve a different level.", "tokens": [51420, 2010, 295, 3109, 457, 321, 366, 767, 1382, 281, 5039, 257, 819, 1496, 13, 51612], "temperature": 0.0, "avg_logprob": -0.16617556451593787, "compression_ratio": 1.652, "no_speech_prob": 0.052587516605854034}, {"id": 158, "seek": 65696, "start": 656.96, "end": 662.24, "text": " So what we call the domain level whereas on-up is working at the orchestration level.", "tokens": [50364, 407, 437, 321, 818, 264, 9274, 1496, 9735, 322, 12, 1010, 307, 1364, 412, 264, 14161, 2405, 1496, 13, 50628], "temperature": 0.0, "avg_logprob": -0.33047710600353425, "compression_ratio": 1.532520325203252, "no_speech_prob": 0.3614228069782257}, {"id": 159, "seek": 65696, "start": 662.24, "end": 663.24, "text": " Okay.", "tokens": [50628, 1033, 13, 50678], "temperature": 0.0, "avg_logprob": -0.33047710600353425, "compression_ratio": 1.532520325203252, "no_speech_prob": 0.3614228069782257}, {"id": 160, "seek": 65696, "start": 663.24, "end": 671.9200000000001, "text": " And so is the same if we say the advantage of NetEar over VMware, orchestrator or other", "tokens": [50678, 400, 370, 307, 264, 912, 498, 321, 584, 264, 5002, 295, 6188, 36, 289, 670, 40146, 11, 14161, 19802, 420, 661, 51112], "temperature": 0.0, "avg_logprob": -0.33047710600353425, "compression_ratio": 1.532520325203252, "no_speech_prob": 0.3614228069782257}, {"id": 161, "seek": 65696, "start": 671.9200000000001, "end": 672.9200000000001, "text": " vendors?", "tokens": [51112, 22056, 30, 51162], "temperature": 0.0, "avg_logprob": -0.33047710600353425, "compression_ratio": 1.532520325203252, "no_speech_prob": 0.3614228069782257}, {"id": 162, "seek": 65696, "start": 672.9200000000001, "end": 673.9200000000001, "text": " Yeah.", "tokens": [51162, 865, 13, 51212], "temperature": 0.0, "avg_logprob": -0.33047710600353425, "compression_ratio": 1.532520325203252, "no_speech_prob": 0.3614228069782257}, {"id": 163, "seek": 65696, "start": 673.9200000000001, "end": 680.6800000000001, "text": " So I think, see, okay, I'm of course trying to advocate it but personally I see the following.", "tokens": [51212, 407, 286, 519, 11, 536, 11, 1392, 11, 286, 478, 295, 1164, 1382, 281, 14608, 309, 457, 5665, 286, 536, 264, 3480, 13, 51550], "temperature": 0.0, "avg_logprob": -0.33047710600353425, "compression_ratio": 1.532520325203252, "no_speech_prob": 0.3614228069782257}, {"id": 164, "seek": 65696, "start": 680.6800000000001, "end": 684.0400000000001, "text": " Kubernetes has been the orchestration for containers, right?", "tokens": [51550, 23145, 575, 668, 264, 14161, 2405, 337, 17089, 11, 558, 30, 51718], "temperature": 0.0, "avg_logprob": -0.33047710600353425, "compression_ratio": 1.532520325203252, "no_speech_prob": 0.3614228069782257}, {"id": 165, "seek": 65696, "start": 684.0400000000001, "end": 686.0400000000001, "text": " That was where it is born.", "tokens": [51718, 663, 390, 689, 309, 307, 4232, 13, 51818], "temperature": 0.0, "avg_logprob": -0.33047710600353425, "compression_ratio": 1.532520325203252, "no_speech_prob": 0.3614228069782257}, {"id": 166, "seek": 68604, "start": 686.04, "end": 692.0, "text": " If you ask me, it has the right primitives to be an automation and orchestration platform", "tokens": [50364, 759, 291, 1029, 385, 11, 309, 575, 264, 558, 2886, 38970, 281, 312, 364, 17769, 293, 14161, 2405, 3663, 50662], "temperature": 0.0, "avg_logprob": -0.15878912254616065, "compression_ratio": 1.6846153846153846, "no_speech_prob": 0.03280803561210632}, {"id": 167, "seek": 68604, "start": 692.0, "end": 693.48, "text": " for anything.", "tokens": [50662, 337, 1340, 13, 50736], "temperature": 0.0, "avg_logprob": -0.15878912254616065, "compression_ratio": 1.6846153846153846, "no_speech_prob": 0.03280803561210632}, {"id": 168, "seek": 68604, "start": 693.48, "end": 698.88, "text": " So I see Kubernetes as an operating system to actually do any automation, right?", "tokens": [50736, 407, 286, 536, 23145, 382, 364, 7447, 1185, 281, 767, 360, 604, 17769, 11, 558, 30, 51006], "temperature": 0.0, "avg_logprob": -0.15878912254616065, "compression_ratio": 1.6846153846153846, "no_speech_prob": 0.03280803561210632}, {"id": 169, "seek": 68604, "start": 698.88, "end": 700.64, "text": " That doesn't mean.", "tokens": [51006, 663, 1177, 380, 914, 13, 51094], "temperature": 0.0, "avg_logprob": -0.15878912254616065, "compression_ratio": 1.6846153846153846, "no_speech_prob": 0.03280803561210632}, {"id": 170, "seek": 68604, "start": 700.64, "end": 706.9599999999999, "text": " And what is the advantage of that in my view is that, so when you have all of these different", "tokens": [51094, 400, 437, 307, 264, 5002, 295, 300, 294, 452, 1910, 307, 300, 11, 370, 562, 291, 362, 439, 295, 613, 819, 51410], "temperature": 0.0, "avg_logprob": -0.15878912254616065, "compression_ratio": 1.6846153846153846, "no_speech_prob": 0.03280803561210632}, {"id": 171, "seek": 68604, "start": 706.9599999999999, "end": 711.48, "text": " components, first of all, you have a huge ecosystem in open source that is developing", "tokens": [51410, 6677, 11, 700, 295, 439, 11, 291, 362, 257, 2603, 11311, 294, 1269, 4009, 300, 307, 6416, 51636], "temperature": 0.0, "avg_logprob": -0.15878912254616065, "compression_ratio": 1.6846153846153846, "no_speech_prob": 0.03280803561210632}, {"id": 172, "seek": 68604, "start": 711.48, "end": 714.4, "text": " and extending Kubernetes for lots of use cases, right?", "tokens": [51636, 293, 24360, 23145, 337, 3195, 295, 764, 3331, 11, 558, 30, 51782], "temperature": 0.0, "avg_logprob": -0.15878912254616065, "compression_ratio": 1.6846153846153846, "no_speech_prob": 0.03280803561210632}, {"id": 173, "seek": 71440, "start": 714.4, "end": 720.48, "text": " So you can deploy AWS resources, Google resources, you can deploy clusters, you can set up servers.", "tokens": [50364, 407, 291, 393, 7274, 17650, 3593, 11, 3329, 3593, 11, 291, 393, 7274, 23313, 11, 291, 393, 992, 493, 15909, 13, 50668], "temperature": 0.0, "avg_logprob": -0.137390819348787, "compression_ratio": 1.654320987654321, "no_speech_prob": 0.04112111032009125}, {"id": 174, "seek": 71440, "start": 720.48, "end": 725.04, "text": " So you first leverage a huge ecosystem that is being developed in open source which we", "tokens": [50668, 407, 291, 700, 13982, 257, 2603, 11311, 300, 307, 885, 4743, 294, 1269, 4009, 597, 321, 50896], "temperature": 0.0, "avg_logprob": -0.137390819348787, "compression_ratio": 1.654320987654321, "no_speech_prob": 0.04112111032009125}, {"id": 175, "seek": 71440, "start": 725.04, "end": 729.0799999999999, "text": " should all love in this room, right?", "tokens": [50896, 820, 439, 959, 294, 341, 1808, 11, 558, 30, 51098], "temperature": 0.0, "avg_logprob": -0.137390819348787, "compression_ratio": 1.654320987654321, "no_speech_prob": 0.04112111032009125}, {"id": 176, "seek": 71440, "start": 729.0799999999999, "end": 736.0799999999999, "text": " Secondly, that doesn't mean that you can as a vendor not benefit or do things specifically", "tokens": [51098, 19483, 11, 300, 1177, 380, 914, 300, 291, 393, 382, 257, 24321, 406, 5121, 420, 360, 721, 4682, 51448], "temperature": 0.0, "avg_logprob": -0.137390819348787, "compression_ratio": 1.654320987654321, "no_speech_prob": 0.04112111032009125}, {"id": 177, "seek": 71440, "start": 736.0799999999999, "end": 741.6, "text": " but the big advantage for you as a consumer when we do that is today when you do VMware", "tokens": [51448, 457, 264, 955, 5002, 337, 291, 382, 257, 9711, 562, 321, 360, 300, 307, 965, 562, 291, 360, 40146, 51724], "temperature": 0.0, "avg_logprob": -0.137390819348787, "compression_ratio": 1.654320987654321, "no_speech_prob": 0.04112111032009125}, {"id": 178, "seek": 74160, "start": 741.6, "end": 747.4, "text": " orchestration, you build your own VMware orchestration server with your own database", "tokens": [50364, 14161, 2405, 11, 291, 1322, 428, 1065, 40146, 14161, 2405, 7154, 365, 428, 1065, 8149, 50654], "temperature": 0.0, "avg_logprob": -0.17092722938174293, "compression_ratio": 1.9385964912280702, "no_speech_prob": 0.04294420778751373}, {"id": 179, "seek": 74160, "start": 747.4, "end": 751.08, "text": " with your own and then you see it's not only VMware orchestration, you need a bit of this", "tokens": [50654, 365, 428, 1065, 293, 550, 291, 536, 309, 311, 406, 787, 40146, 14161, 2405, 11, 291, 643, 257, 857, 295, 341, 50838], "temperature": 0.0, "avg_logprob": -0.17092722938174293, "compression_ratio": 1.9385964912280702, "no_speech_prob": 0.04294420778751373}, {"id": 180, "seek": 74160, "start": 751.08, "end": 754.9200000000001, "text": " component and a bit of that component and a bit of this component and all of a sudden", "tokens": [50838, 6542, 293, 257, 857, 295, 300, 6542, 293, 257, 857, 295, 341, 6542, 293, 439, 295, 257, 3990, 51030], "temperature": 0.0, "avg_logprob": -0.17092722938174293, "compression_ratio": 1.9385964912280702, "no_speech_prob": 0.04294420778751373}, {"id": 181, "seek": 74160, "start": 754.9200000000001, "end": 759.12, "text": " you have more servers to serve the network than actually the network.", "tokens": [51030, 291, 362, 544, 15909, 281, 4596, 264, 3209, 813, 767, 264, 3209, 13, 51240], "temperature": 0.0, "avg_logprob": -0.17092722938174293, "compression_ratio": 1.9385964912280702, "no_speech_prob": 0.04294420778751373}, {"id": 182, "seek": 74160, "start": 759.12, "end": 760.44, "text": " I'm exaggerating, right?", "tokens": [51240, 286, 478, 19123, 990, 11, 558, 30, 51306], "temperature": 0.0, "avg_logprob": -0.17092722938174293, "compression_ratio": 1.9385964912280702, "no_speech_prob": 0.04294420778751373}, {"id": 183, "seek": 74160, "start": 760.44, "end": 766.84, "text": " But the advantage what I see personally is that you look at automation from these, the", "tokens": [51306, 583, 264, 5002, 437, 286, 536, 5665, 307, 300, 291, 574, 412, 17769, 490, 613, 11, 264, 51626], "temperature": 0.0, "avg_logprob": -0.17092722938174293, "compression_ratio": 1.9385964912280702, "no_speech_prob": 0.04294420778751373}, {"id": 184, "seek": 76684, "start": 766.84, "end": 772.6, "text": " use case still will be specific to you and there will be a VMware specific controller,", "tokens": [50364, 764, 1389, 920, 486, 312, 2685, 281, 291, 293, 456, 486, 312, 257, 40146, 2685, 10561, 11, 50652], "temperature": 0.0, "avg_logprob": -0.17420679589976434, "compression_ratio": 1.7012987012987013, "no_speech_prob": 0.69789057970047}, {"id": 185, "seek": 76684, "start": 772.6, "end": 773.6, "text": " right?", "tokens": [50652, 558, 30, 50702], "temperature": 0.0, "avg_logprob": -0.17420679589976434, "compression_ratio": 1.7012987012987013, "no_speech_prob": 0.69789057970047}, {"id": 186, "seek": 76684, "start": 773.6, "end": 779.0400000000001, "text": " But if you build it on the same platform, you as a consumer, we benefit from not having", "tokens": [50702, 583, 498, 291, 1322, 309, 322, 264, 912, 3663, 11, 291, 382, 257, 9711, 11, 321, 5121, 490, 406, 1419, 50974], "temperature": 0.0, "avg_logprob": -0.17420679589976434, "compression_ratio": 1.7012987012987013, "no_speech_prob": 0.69789057970047}, {"id": 187, "seek": 76684, "start": 779.0400000000001, "end": 783.6800000000001, "text": " to deploy another platform but leverage what we already have if that suits you.", "tokens": [50974, 281, 7274, 1071, 3663, 457, 13982, 437, 321, 1217, 362, 498, 300, 15278, 291, 13, 51206], "temperature": 0.0, "avg_logprob": -0.17420679589976434, "compression_ratio": 1.7012987012987013, "no_speech_prob": 0.69789057970047}, {"id": 188, "seek": 76684, "start": 783.6800000000001, "end": 787.64, "text": " That doesn't mean you cannot deploy another Kubernetes instance for that specific environment,", "tokens": [51206, 663, 1177, 380, 914, 291, 2644, 7274, 1071, 23145, 5197, 337, 300, 2685, 2823, 11, 51404], "temperature": 0.0, "avg_logprob": -0.17420679589976434, "compression_ratio": 1.7012987012987013, "no_speech_prob": 0.69789057970047}, {"id": 189, "seek": 76684, "start": 787.64, "end": 788.64, "text": " right?", "tokens": [51404, 558, 30, 51454], "temperature": 0.0, "avg_logprob": -0.17420679589976434, "compression_ratio": 1.7012987012987013, "no_speech_prob": 0.69789057970047}, {"id": 190, "seek": 76684, "start": 788.64, "end": 789.8000000000001, "text": " But at least the integration.", "tokens": [51454, 583, 412, 1935, 264, 10980, 13, 51512], "temperature": 0.0, "avg_logprob": -0.17420679589976434, "compression_ratio": 1.7012987012987013, "no_speech_prob": 0.69789057970047}], "language": "en"}