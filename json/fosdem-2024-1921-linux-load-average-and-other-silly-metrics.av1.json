{"text": " We'll see something very basic, the load average, the thing that you have on top, on top when you look at the performance of your server. Very basic, but with a lot of misunderstanding and the goal is really to understand if it's useful or not and at least how it works. I usually do that as a live demo, but I'm not sure about the Wi-Fi. I think I've lost the connection, but I have some recordings. Basically, what we will do, we will look at what we have in top. So this is not moving because I lost the connection, but we will see later on recordings. You can start to think about it. I have run something that you can see in the processes there. I have two CPUs. I have a load average of 32 for a long time. I don't know if you care, but I have 99% of weight I owe. Basically, my question to you is, do I have a problem or not? I am bound on a resource or not. If I'm bound on a resource, am I bound on CPU or I owe or memory or whatever? This simple question, I see a lot of people who cannot really explain it. The goal of the presentation will be to tell you that you can mostly ignore the numbers that are on top of top because those are about the systems, the processor, what you care about for your application performance is more the tasks that are running and this is probably more useful. Going back to the slides where I have the recordings of all the demos, so we will not try to reconnect to the Wi-Fi. Also, so that screenshot of what we have seen, people using the cloud, cloud providers like to provide nice graphs about performance and usually they put first the load average, the CPU usage. Typically, I have two processors. I have a load average of 30 and my CPU is doing nothing. Memory is 100%. What do they want to tell us with that because most systems will have usage at 100% and that's probably cool. We will look at that in the next 20 minutes. First, this is the recording of what I wanted to show you. That was what was running exactly the same. You see the load average, the number of CPU, the weight, IO, there. What do you think about it? Who thinks I'm bound on CPU? Who thinks I'm bound on IO? Who thinks I'm bound on IO because I have a weight IO? Less people. That's already good. Here, we see a high weight IO, but maybe I can advance on the recording. What I show in this case, when people think that I have a problem with IO, is just to run something else. Let me check where it is in the recording. If I have the wrong recording, I will just explain what I show usually. Sorry, maybe it's in the next recording. What we see is load average, high weight IO, but the most important, what I really care about is this, the state of the tasks. Who thinks I am bound on IO because of the D state? For me, this D state gives me a clue that most of my processors are waiting on IO. Probably. We see that it's not so exact science, but that's something that can give some clues. I'm lost in my slides. This is the next one. I'm running yes. You know the yes command? It displays yes. I'm still running the same IO there, the same throughput. I'm doing exactly the same, and my weight IO has decreased. This is how to solve weight IO, just run something else. I show that to explain that this weight IO is not about what your tasks are doing. It's about the CPUs. When you do IO, you don't need CPU, so you wait. If no one else wants to do something on the CPU, then the CPU state just remembers that, okay, I'm idle because someone is doing some IO. Now I'm running something else that uses this CPU. This CPU is not idle. This weight IO just means idle, and idle because the last one did some IO. The only information I have from weight IO is that the CPU could be used for something more useful than weighting, but doesn't really give me the information that I have a lot of IO because depending on the other workload, I will sit there or not. The state doesn't lie if my processes are all on the D state. At least they are not on the R state, the renewable state, so they are not using CPU. In the next one, what I do to understand better the kind of IO I'm doing, the kind of system call that puts this D state, I just run S trace on my processes, and I just did the S trace dash C to count them, and you see that most of the system calls are P writes. That's actually what I'm running there. I'm doing writes with the P write system call with direct IO. That's basically what I have there. If I want to understand really what is behind a state that is not the R state, the renewable state, I can trace the system calls to know exactly why. I will explain why I'm looking at that because even if D looks like disk, you can do some IOs that are not in D state, and you can have D state that has nothing to do with IO. So it can be misleading. The D state is uninterruptible calls. So your process has something to do that is not in CPU and does it in an uninterruptible state. Depending on the system call, it can do it uninterruptible or not. Often IO like the P write is using this, but there are some other kind of IOs. Any questions so far? Any remarks? Okay. So next one. I will run something else if I remember exactly what I'm doing here. I will run FIO. The difference is that I'm not calling the P write system call. I'm calling the Lib IO, asynchronous IO library. Basically I'm doing the same writing to the disk with direct IO and you can see the throughput is mostly the same. However, I'm not in D state anymore. So there are some IO who put the D state, but there are some IO who just put the sleep state, which is not uninterruptible. So very misleading when you see those things and try to guess what happens. If you are stressed, there is no guess. You know exactly the system call. And I think this is what I do just after. If I stress, I see that most of the IO calls here are IO get events and there is some IO submit. This is our asynchronous IO works. P write just ask the kernel, I want these blocks and wait to get those blocks. With asynchronous IO, it tells the kernel, I will need those blocks. So that's the submit and then can you work on something else and come back and say, oh, do you have my IO? If not, I will wait. The submit goes in this state, but it's very short because it's just a submit. The get events, if it waits, goes in sleep state, the S state, and not the D state. Depending on the kind of IO, you will see it at this state or not. And the wait IO there depends on the state, but more important, I don't know if I can go back. Well, I'm sure I can go back if I replay it. I guess that the load average was lower when I was running that because the D state counts in the load average, the S state doesn't. Means that some IO counts in the load average, some IO doesn't. Means that with load average, you don't really know what happens. Okay. The next one, I'm running something else. So those were direct writes by passing the buffer cache. And here I'm running reads and more I set direct equals zero to FIO. FIO just simulates different kind of IO. Typically I work with databases. I'm a developer advocate for UGA by DB that is a distributed SQL database compatible with Postgres. I've been working also a lot with Oracle. They do those kind of IO, Postgres does not do direct IO. It goes through buffer. Oracle, you have the choice. So really depends. Here, what I would like to show you, I don't see it from here, but I'm probably in the running state. Yeah, it was not sorted. But here, I'm mostly reading from memory, from the cache, from buffers. And this is why you see that much faster. And a difference, I'm using more CPU there. You access memory more than you access the disks. And then this is in CPU usage, the kernel part of the read. I mean, my application is doing the same. Just an IO call. So the user space CPU is still low. But on the system, on the kernel, what Linux does is read from memory. And this is where you have some system CPU there. That counts in the load average also. I just, okay, in the meantime, I did this trace to see the reads there. So I have periods, the same system call. What is different is what is behind. That it reads from buffer. And I don't know if you have seen it. When I was attaching with S trace, the state here was T. That's the state when you attach. And of course, it has a little overhead. You do that to troubleshoot. The important thing is the runable state. I'm saying that either I'm running in CPU or I want to run in CPU. And I don't know which one from those metrics. That's the point. I have only two CPUs. So I know that I cannot have more than two tasks running in CPU. They are running able. They are waiting in the run queue to be able to run on the CPU. Top will not show the figure. Load average will add those rating and those running. If you want to see the difference, you need to look at the statistics from the scheduler in slash proc scheduler statistics or VM stat is showing you the run queue. I'm saying that because I've seen a lot of people comparing the load average with the number of CPU. Like if load average is higher than the number of CPU, I have a problem. Maybe not because if the load average is due to IO, you don't really care about comparing with the CPU. And if the load average is high because you have a lot of processes in the run queue, then probably you have a problem because you have tasks who need to run something on the CPU and just cannot and are waiting in behind. So we have seen different kinds of IOs and they look differently. Many times where I've seen, especially on databases, where I've seen different teams, the Linux team looking at the system and the DBA team looking at the database. And in many companies, they don't really talk together. So one is guessing what the other is doing and a lot of misinterpretation on all that. It's very important if you look at the numbers from the system to understand what the database is doing. And also it's very important for the database administrator to look at the system because many things in the database metric will be different if the system is overloaded. I give a quick example on Oracle, you have wait events where you can know exactly how much time you spend on IO. But it's not exactly how much time you spend on IO. It's how much time between the time stamp it takes before the IO and after the IO. If your process is in the run queue, the database thinks that it is doing IO, but maybe the IO is done and it's just waiting to go back to the CPU just to set the counter on the time stamp. So that's also the message. I say that to database administrator, but applications, if you run on a system that is overloaded in CPU, then probably all of their metrics, because they require CPU cycles to get the number are probably wrong. So why did I call that silly metrics? I didn't came with this. If you want to understand what is what low-dverage measures, Linux is open source, so just look at the source of it. And you can look at the source, but more interesting are the comments which can explain the intention of the function. And so in Linux, the load average is defined as this file, so the source for load average contains the magic bits required to compute the global load average figure. It is a symmetric, but people think it is important. So you see why you see that first in top? It is silly, but some people think it is important, so let's give them something. And we go through the grid pane to make it work on big machine with T-class kernel. So the load average idea comes from Unix systems where it was really measuring the load in CPU and where it was easier to measure it because you just counted the ticks in the scheduler. Linux works differently and means that it is difficult to measure and maybe it makes no big sense. So yeah, good to know why this metric is there just because people coming from Unix were used to have this single graph showing the load and compare that with the application and what is done in the application, but if you don't look at the state of the processes, then it can be misleading. It's easy to understand exactly why we see this state, these IOCOLs in the load average, just the way it is calculated. There are two things that are interested in the way it is calculated. First, it is an average and that's also a problem. If you look at the load average, you will not see a peak of activity of five seconds because it is average. The other thing is that it counts the number of active, so the running state, which is more renewable because if you are in the run queue, you are not really running and it has the uninterruptible calls just because they thought that if we show only the CPU load, is it really the load of the machine? For example, you run a database doing a lot of IOCOL. Then we say that the load is low if everyone is waiting on the disk. Let's add an interoptable because in many cases, we have seen that those IOCOLs are uninterruptible calls, but they are not always, so it can be quite misleading. It doesn't mean that you don't have to look at it, but if you look at it and know what is behind, then it can give you some clues like the clue about IOCOL looking at other things, but more interesting is the process state. A process can have something to run in the CPU and then look at the scheduler statistics knowing if it waits for the CPU or there is CPU available and when it has some calls to do, they can be done in this state or as state and they will be accounted differently by the load average. Any questions so far? Okay, the next one is more about memory just because it's another thing that is misleading in some cases. I think it is quite clear in top that you can look at the available memory, but I see cloud provider showing the use memory or the free memory and here I just want to explain for those who don't know, if you do buffered IO like I did with direct equal zero. Okay, I thought we have five minutes now. Okay, perfect. So I will finish quickly on that. Do not look at the free memory. I'm just showing that if I do some IOs, it will take some free memory, but that is easily freed if it needs look at the available memory. That's the memory that is available to your process, but also think that it is available. You can use it, but if you use it, then another process doing buffered IO may not find its data in the case. So if it is available, doesn't mean that it's free from any impact on the others. Okay, I just put the last one while I'm talking and taking question. The idea there was just to show a really silly program doing V fork that has nothing to do with the data, but just to show that it will go to the state, it will increase the load average and that's the case I've seen in some system where the load average was thousands on a database having its file on NFS and network issues and then those uninterruptible calls increased the load average, but without any consequence because they weren't doing nothing. The only thing is that it's ugly when you look at the load average and the other thing is that they are uninterruptible. You cannot kill them. So you want to restart the system to have nicer numbers, but of course you wait for it. So just be careful, load average accounts some IO and accounts some CPU and you have some IO that you do not see there. Okay, do you have any questions, remarks? Thank you. What about pressure stall information? Very good question. If you have seen at the first screenshot I was running pressure stall information, which in my opinion is a better picture. The pressure stall information is counter telling you during the last 10 seconds, for example, how many, not how many, if there were some processes with pressure on CPU, so to run on CPU to get IO or to get some memory. So it really gives you an idea about the pressure itself. The only thing about pressure stall information I have is that in most of the kernels, the distributions I've seen, it is compiled in the kernel but not enabled by default. And then because it's not enabled by default, I've not seen it a lot. And then I think it's a good idea. Each time I used pressure stall information, it was giving me the right idea, but it's just a subset of the systems I've seen because it's not the default. And then maybe there are some cases that I don't know where it's not perfect, but I try to encourage people to enable pressure stall information where instead of looking at all that, you just see that you have some processes that could be faster if they were not on pressure, on RAM, IO, or CPU. Okay, I think we are just... Another question? If it's okay? So looking at a very generic use case, if you were to redesign the cloud provider's graphs, would you change it? What would you change it to? Could your list maybe the five most important metrics from a generic use case that you would put on a dashboard? On a dashboard, I think pressure stall information can be really nice on a dashboard because you can show that to user. User running on the cloud, for example, they want to know if they are on pressure on CPU or on IO because they pay for that. So those ones I would put that. Load average, maybe with a clear description that it is CPU plus some IO, and memory, available memory, not use memory because a system doing some IO, some buffered IO will always use all the memory in Linux. Maybe we have...", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 9.120000000000001, "text": " We'll see something very basic, the load average, the thing that you have on top, on top when", "tokens": [50364, 492, 603, 536, 746, 588, 3875, 11, 264, 3677, 4274, 11, 264, 551, 300, 291, 362, 322, 1192, 11, 322, 1192, 562, 50820], "temperature": 0.0, "avg_logprob": -0.22030154518459155, "compression_ratio": 1.6095238095238096, "no_speech_prob": 0.2533673942089081}, {"id": 1, "seek": 0, "start": 9.120000000000001, "end": 11.68, "text": " you look at the performance of your server.", "tokens": [50820, 291, 574, 412, 264, 3389, 295, 428, 7154, 13, 50948], "temperature": 0.0, "avg_logprob": -0.22030154518459155, "compression_ratio": 1.6095238095238096, "no_speech_prob": 0.2533673942089081}, {"id": 2, "seek": 0, "start": 11.68, "end": 17.080000000000002, "text": " Very basic, but with a lot of misunderstanding and the goal is really to understand if it's", "tokens": [50948, 4372, 3875, 11, 457, 365, 257, 688, 295, 29227, 293, 264, 3387, 307, 534, 281, 1223, 498, 309, 311, 51218], "temperature": 0.0, "avg_logprob": -0.22030154518459155, "compression_ratio": 1.6095238095238096, "no_speech_prob": 0.2533673942089081}, {"id": 3, "seek": 0, "start": 17.080000000000002, "end": 21.32, "text": " useful or not and at least how it works.", "tokens": [51218, 4420, 420, 406, 293, 412, 1935, 577, 309, 1985, 13, 51430], "temperature": 0.0, "avg_logprob": -0.22030154518459155, "compression_ratio": 1.6095238095238096, "no_speech_prob": 0.2533673942089081}, {"id": 4, "seek": 0, "start": 21.32, "end": 26.52, "text": " I usually do that as a live demo, but I'm not sure about the Wi-Fi.", "tokens": [51430, 286, 2673, 360, 300, 382, 257, 1621, 10723, 11, 457, 286, 478, 406, 988, 466, 264, 14035, 12, 13229, 13, 51690], "temperature": 0.0, "avg_logprob": -0.22030154518459155, "compression_ratio": 1.6095238095238096, "no_speech_prob": 0.2533673942089081}, {"id": 5, "seek": 2652, "start": 26.52, "end": 30.08, "text": " I think I've lost the connection, but I have some recordings.", "tokens": [50364, 286, 519, 286, 600, 2731, 264, 4984, 11, 457, 286, 362, 512, 25162, 13, 50542], "temperature": 0.0, "avg_logprob": -0.1542466299874442, "compression_ratio": 1.7268518518518519, "no_speech_prob": 0.026486124843358994}, {"id": 6, "seek": 2652, "start": 30.08, "end": 34.72, "text": " Basically, what we will do, we will look at what we have in top.", "tokens": [50542, 8537, 11, 437, 321, 486, 360, 11, 321, 486, 574, 412, 437, 321, 362, 294, 1192, 13, 50774], "temperature": 0.0, "avg_logprob": -0.1542466299874442, "compression_ratio": 1.7268518518518519, "no_speech_prob": 0.026486124843358994}, {"id": 7, "seek": 2652, "start": 34.72, "end": 41.480000000000004, "text": " So this is not moving because I lost the connection, but we will see later on recordings.", "tokens": [50774, 407, 341, 307, 406, 2684, 570, 286, 2731, 264, 4984, 11, 457, 321, 486, 536, 1780, 322, 25162, 13, 51112], "temperature": 0.0, "avg_logprob": -0.1542466299874442, "compression_ratio": 1.7268518518518519, "no_speech_prob": 0.026486124843358994}, {"id": 8, "seek": 2652, "start": 41.480000000000004, "end": 43.44, "text": " You can start to think about it.", "tokens": [51112, 509, 393, 722, 281, 519, 466, 309, 13, 51210], "temperature": 0.0, "avg_logprob": -0.1542466299874442, "compression_ratio": 1.7268518518518519, "no_speech_prob": 0.026486124843358994}, {"id": 9, "seek": 2652, "start": 43.44, "end": 47.92, "text": " I have run something that you can see in the processes there.", "tokens": [51210, 286, 362, 1190, 746, 300, 291, 393, 536, 294, 264, 7555, 456, 13, 51434], "temperature": 0.0, "avg_logprob": -0.1542466299874442, "compression_ratio": 1.7268518518518519, "no_speech_prob": 0.026486124843358994}, {"id": 10, "seek": 2652, "start": 47.92, "end": 51.239999999999995, "text": " I have two CPUs.", "tokens": [51434, 286, 362, 732, 13199, 82, 13, 51600], "temperature": 0.0, "avg_logprob": -0.1542466299874442, "compression_ratio": 1.7268518518518519, "no_speech_prob": 0.026486124843358994}, {"id": 11, "seek": 2652, "start": 51.239999999999995, "end": 55.879999999999995, "text": " I have a load average of 32 for a long time.", "tokens": [51600, 286, 362, 257, 3677, 4274, 295, 8858, 337, 257, 938, 565, 13, 51832], "temperature": 0.0, "avg_logprob": -0.1542466299874442, "compression_ratio": 1.7268518518518519, "no_speech_prob": 0.026486124843358994}, {"id": 12, "seek": 5588, "start": 55.88, "end": 61.32, "text": " I don't know if you care, but I have 99% of weight I owe.", "tokens": [50364, 286, 500, 380, 458, 498, 291, 1127, 11, 457, 286, 362, 11803, 4, 295, 3364, 286, 16655, 13, 50636], "temperature": 0.0, "avg_logprob": -0.24854636836696314, "compression_ratio": 1.464968152866242, "no_speech_prob": 0.017073985189199448}, {"id": 13, "seek": 5588, "start": 61.32, "end": 66.64, "text": " Basically, my question to you is, do I have a problem or not?", "tokens": [50636, 8537, 11, 452, 1168, 281, 291, 307, 11, 360, 286, 362, 257, 1154, 420, 406, 30, 50902], "temperature": 0.0, "avg_logprob": -0.24854636836696314, "compression_ratio": 1.464968152866242, "no_speech_prob": 0.017073985189199448}, {"id": 14, "seek": 5588, "start": 66.64, "end": 70.12, "text": " I am bound on a resource or not.", "tokens": [50902, 286, 669, 5472, 322, 257, 7684, 420, 406, 13, 51076], "temperature": 0.0, "avg_logprob": -0.24854636836696314, "compression_ratio": 1.464968152866242, "no_speech_prob": 0.017073985189199448}, {"id": 15, "seek": 5588, "start": 70.12, "end": 78.80000000000001, "text": " If I'm bound on a resource, am I bound on CPU or I owe or memory or whatever?", "tokens": [51076, 759, 286, 478, 5472, 322, 257, 7684, 11, 669, 286, 5472, 322, 13199, 420, 286, 16655, 420, 4675, 420, 2035, 30, 51510], "temperature": 0.0, "avg_logprob": -0.24854636836696314, "compression_ratio": 1.464968152866242, "no_speech_prob": 0.017073985189199448}, {"id": 16, "seek": 7880, "start": 78.8, "end": 86.24, "text": " This simple question, I see a lot of people who cannot really explain it.", "tokens": [50364, 639, 2199, 1168, 11, 286, 536, 257, 688, 295, 561, 567, 2644, 534, 2903, 309, 13, 50736], "temperature": 0.0, "avg_logprob": -0.14816006120428982, "compression_ratio": 1.6728971962616823, "no_speech_prob": 0.8484145402908325}, {"id": 17, "seek": 7880, "start": 86.24, "end": 92.0, "text": " The goal of the presentation will be to tell you that you can mostly ignore the numbers", "tokens": [50736, 440, 3387, 295, 264, 5860, 486, 312, 281, 980, 291, 300, 291, 393, 5240, 11200, 264, 3547, 51024], "temperature": 0.0, "avg_logprob": -0.14816006120428982, "compression_ratio": 1.6728971962616823, "no_speech_prob": 0.8484145402908325}, {"id": 18, "seek": 7880, "start": 92.0, "end": 97.52, "text": " that are on top of top because those are about the systems, the processor, what you care", "tokens": [51024, 300, 366, 322, 1192, 295, 1192, 570, 729, 366, 466, 264, 3652, 11, 264, 15321, 11, 437, 291, 1127, 51300], "temperature": 0.0, "avg_logprob": -0.14816006120428982, "compression_ratio": 1.6728971962616823, "no_speech_prob": 0.8484145402908325}, {"id": 19, "seek": 7880, "start": 97.52, "end": 102.72, "text": " about for your application performance is more the tasks that are running and this is", "tokens": [51300, 466, 337, 428, 3861, 3389, 307, 544, 264, 9608, 300, 366, 2614, 293, 341, 307, 51560], "temperature": 0.0, "avg_logprob": -0.14816006120428982, "compression_ratio": 1.6728971962616823, "no_speech_prob": 0.8484145402908325}, {"id": 20, "seek": 7880, "start": 102.72, "end": 105.24, "text": " probably more useful.", "tokens": [51560, 1391, 544, 4420, 13, 51686], "temperature": 0.0, "avg_logprob": -0.14816006120428982, "compression_ratio": 1.6728971962616823, "no_speech_prob": 0.8484145402908325}, {"id": 21, "seek": 10524, "start": 105.24, "end": 111.28, "text": " Going back to the slides where I have the recordings of all the demos, so we will not", "tokens": [50364, 10963, 646, 281, 264, 9788, 689, 286, 362, 264, 25162, 295, 439, 264, 33788, 11, 370, 321, 486, 406, 50666], "temperature": 0.0, "avg_logprob": -0.2887761042668269, "compression_ratio": 1.5147058823529411, "no_speech_prob": 0.1003669798374176}, {"id": 22, "seek": 10524, "start": 111.28, "end": 114.8, "text": " try to reconnect to the Wi-Fi.", "tokens": [50666, 853, 281, 30095, 281, 264, 14035, 12, 13229, 13, 50842], "temperature": 0.0, "avg_logprob": -0.2887761042668269, "compression_ratio": 1.5147058823529411, "no_speech_prob": 0.1003669798374176}, {"id": 23, "seek": 10524, "start": 114.8, "end": 123.8, "text": " Also, so that screenshot of what we have seen, people using the cloud, cloud providers like", "tokens": [50842, 2743, 11, 370, 300, 27712, 295, 437, 321, 362, 1612, 11, 561, 1228, 264, 4588, 11, 4588, 11330, 411, 51292], "temperature": 0.0, "avg_logprob": -0.2887761042668269, "compression_ratio": 1.5147058823529411, "no_speech_prob": 0.1003669798374176}, {"id": 24, "seek": 10524, "start": 123.8, "end": 130.6, "text": " to provide nice graphs about performance and usually they put first the load average, the", "tokens": [51292, 281, 2893, 1481, 24877, 466, 3389, 293, 2673, 436, 829, 700, 264, 3677, 4274, 11, 264, 51632], "temperature": 0.0, "avg_logprob": -0.2887761042668269, "compression_ratio": 1.5147058823529411, "no_speech_prob": 0.1003669798374176}, {"id": 25, "seek": 10524, "start": 130.6, "end": 132.51999999999998, "text": " CPU usage.", "tokens": [51632, 13199, 14924, 13, 51728], "temperature": 0.0, "avg_logprob": -0.2887761042668269, "compression_ratio": 1.5147058823529411, "no_speech_prob": 0.1003669798374176}, {"id": 26, "seek": 13252, "start": 132.92000000000002, "end": 136.12, "text": " Typically, I have two processors.", "tokens": [50384, 23129, 11, 286, 362, 732, 27751, 13, 50544], "temperature": 0.0, "avg_logprob": -0.2632622589936128, "compression_ratio": 1.3957219251336899, "no_speech_prob": 0.019398299977183342}, {"id": 27, "seek": 13252, "start": 136.12, "end": 145.64000000000001, "text": " I have a load average of 30 and my CPU is doing nothing.", "tokens": [50544, 286, 362, 257, 3677, 4274, 295, 2217, 293, 452, 13199, 307, 884, 1825, 13, 51020], "temperature": 0.0, "avg_logprob": -0.2632622589936128, "compression_ratio": 1.3957219251336899, "no_speech_prob": 0.019398299977183342}, {"id": 28, "seek": 13252, "start": 145.64000000000001, "end": 148.16000000000003, "text": " Memory is 100%.", "tokens": [51020, 38203, 307, 2319, 6856, 51146], "temperature": 0.0, "avg_logprob": -0.2632622589936128, "compression_ratio": 1.3957219251336899, "no_speech_prob": 0.019398299977183342}, {"id": 29, "seek": 13252, "start": 148.16000000000003, "end": 154.92000000000002, "text": " What do they want to tell us with that because most systems will have usage at 100% and that's", "tokens": [51146, 708, 360, 436, 528, 281, 980, 505, 365, 300, 570, 881, 3652, 486, 362, 14924, 412, 2319, 4, 293, 300, 311, 51484], "temperature": 0.0, "avg_logprob": -0.2632622589936128, "compression_ratio": 1.3957219251336899, "no_speech_prob": 0.019398299977183342}, {"id": 30, "seek": 13252, "start": 154.92000000000002, "end": 156.16000000000003, "text": " probably cool.", "tokens": [51484, 1391, 1627, 13, 51546], "temperature": 0.0, "avg_logprob": -0.2632622589936128, "compression_ratio": 1.3957219251336899, "no_speech_prob": 0.019398299977183342}, {"id": 31, "seek": 13252, "start": 156.16000000000003, "end": 160.60000000000002, "text": " We will look at that in the next 20 minutes.", "tokens": [51546, 492, 486, 574, 412, 300, 294, 264, 958, 945, 2077, 13, 51768], "temperature": 0.0, "avg_logprob": -0.2632622589936128, "compression_ratio": 1.3957219251336899, "no_speech_prob": 0.019398299977183342}, {"id": 32, "seek": 16060, "start": 161.56, "end": 166.51999999999998, "text": " First, this is the recording of what I wanted to show you.", "tokens": [50412, 2386, 11, 341, 307, 264, 6613, 295, 437, 286, 1415, 281, 855, 291, 13, 50660], "temperature": 0.0, "avg_logprob": -0.26366346310346556, "compression_ratio": 1.5178571428571428, "no_speech_prob": 0.007173614110797644}, {"id": 33, "seek": 16060, "start": 166.51999999999998, "end": 169.56, "text": " That was what was running exactly the same.", "tokens": [50660, 663, 390, 437, 390, 2614, 2293, 264, 912, 13, 50812], "temperature": 0.0, "avg_logprob": -0.26366346310346556, "compression_ratio": 1.5178571428571428, "no_speech_prob": 0.007173614110797644}, {"id": 34, "seek": 16060, "start": 169.56, "end": 177.2, "text": " You see the load average, the number of CPU, the weight, IO, there.", "tokens": [50812, 509, 536, 264, 3677, 4274, 11, 264, 1230, 295, 13199, 11, 264, 3364, 11, 39839, 11, 456, 13, 51194], "temperature": 0.0, "avg_logprob": -0.26366346310346556, "compression_ratio": 1.5178571428571428, "no_speech_prob": 0.007173614110797644}, {"id": 35, "seek": 16060, "start": 177.2, "end": 179.0, "text": " What do you think about it?", "tokens": [51194, 708, 360, 291, 519, 466, 309, 30, 51284], "temperature": 0.0, "avg_logprob": -0.26366346310346556, "compression_ratio": 1.5178571428571428, "no_speech_prob": 0.007173614110797644}, {"id": 36, "seek": 16060, "start": 179.0, "end": 184.12, "text": " Who thinks I'm bound on CPU?", "tokens": [51284, 2102, 7309, 286, 478, 5472, 322, 13199, 30, 51540], "temperature": 0.0, "avg_logprob": -0.26366346310346556, "compression_ratio": 1.5178571428571428, "no_speech_prob": 0.007173614110797644}, {"id": 37, "seek": 16060, "start": 184.12, "end": 187.2, "text": " Who thinks I'm bound on IO?", "tokens": [51540, 2102, 7309, 286, 478, 5472, 322, 39839, 30, 51694], "temperature": 0.0, "avg_logprob": -0.26366346310346556, "compression_ratio": 1.5178571428571428, "no_speech_prob": 0.007173614110797644}, {"id": 38, "seek": 18720, "start": 187.23999999999998, "end": 192.95999999999998, "text": " Who thinks I'm bound on IO because I have a weight IO?", "tokens": [50366, 2102, 7309, 286, 478, 5472, 322, 39839, 570, 286, 362, 257, 3364, 39839, 30, 50652], "temperature": 0.0, "avg_logprob": -0.38273800889106646, "compression_ratio": 1.4277456647398843, "no_speech_prob": 0.004214741289615631}, {"id": 39, "seek": 18720, "start": 194.83999999999997, "end": 196.04, "text": " Less people.", "tokens": [50746, 18649, 561, 13, 50806], "temperature": 0.0, "avg_logprob": -0.38273800889106646, "compression_ratio": 1.4277456647398843, "no_speech_prob": 0.004214741289615631}, {"id": 40, "seek": 18720, "start": 196.04, "end": 198.04, "text": " That's already good.", "tokens": [50806, 663, 311, 1217, 665, 13, 50906], "temperature": 0.0, "avg_logprob": -0.38273800889106646, "compression_ratio": 1.4277456647398843, "no_speech_prob": 0.004214741289615631}, {"id": 41, "seek": 18720, "start": 199.79999999999998, "end": 206.76, "text": " Here, we see a high weight IO, but maybe I can advance on the recording.", "tokens": [50994, 1692, 11, 321, 536, 257, 1090, 3364, 39839, 11, 457, 1310, 286, 393, 7295, 322, 264, 6613, 13, 51342], "temperature": 0.0, "avg_logprob": -0.38273800889106646, "compression_ratio": 1.4277456647398843, "no_speech_prob": 0.004214741289615631}, {"id": 42, "seek": 18720, "start": 206.76, "end": 215.67999999999998, "text": " What I show in this case, when people think that I have a problem with IO, is just to", "tokens": [51342, 708, 286, 855, 294, 341, 1389, 11, 562, 561, 519, 300, 286, 362, 257, 1154, 365, 39839, 11, 307, 445, 281, 51788], "temperature": 0.0, "avg_logprob": -0.38273800889106646, "compression_ratio": 1.4277456647398843, "no_speech_prob": 0.004214741289615631}, {"id": 43, "seek": 21568, "start": 215.68, "end": 216.92000000000002, "text": " run something else.", "tokens": [50364, 1190, 746, 1646, 13, 50426], "temperature": 0.0, "avg_logprob": -0.2399525907304552, "compression_ratio": 1.4943181818181819, "no_speech_prob": 0.009584972634911537}, {"id": 44, "seek": 21568, "start": 216.92000000000002, "end": 223.64000000000001, "text": " Let me check where it is in the recording.", "tokens": [50426, 961, 385, 1520, 689, 309, 307, 294, 264, 6613, 13, 50762], "temperature": 0.0, "avg_logprob": -0.2399525907304552, "compression_ratio": 1.4943181818181819, "no_speech_prob": 0.009584972634911537}, {"id": 45, "seek": 21568, "start": 223.64000000000001, "end": 228.68, "text": " If I have the wrong recording, I will just explain what I show usually.", "tokens": [50762, 759, 286, 362, 264, 2085, 6613, 11, 286, 486, 445, 2903, 437, 286, 855, 2673, 13, 51014], "temperature": 0.0, "avg_logprob": -0.2399525907304552, "compression_ratio": 1.4943181818181819, "no_speech_prob": 0.009584972634911537}, {"id": 46, "seek": 21568, "start": 233.68, "end": 237.08, "text": " Sorry, maybe it's in the next recording.", "tokens": [51264, 4919, 11, 1310, 309, 311, 294, 264, 958, 6613, 13, 51434], "temperature": 0.0, "avg_logprob": -0.2399525907304552, "compression_ratio": 1.4943181818181819, "no_speech_prob": 0.009584972634911537}, {"id": 47, "seek": 21568, "start": 237.08, "end": 243.52, "text": " What we see is load average, high weight IO, but the most important, what I really care", "tokens": [51434, 708, 321, 536, 307, 3677, 4274, 11, 1090, 3364, 39839, 11, 457, 264, 881, 1021, 11, 437, 286, 534, 1127, 51756], "temperature": 0.0, "avg_logprob": -0.2399525907304552, "compression_ratio": 1.4943181818181819, "no_speech_prob": 0.009584972634911537}, {"id": 48, "seek": 24352, "start": 243.52, "end": 248.16, "text": " about is this, the state of the tasks.", "tokens": [50364, 466, 307, 341, 11, 264, 1785, 295, 264, 9608, 13, 50596], "temperature": 0.0, "avg_logprob": -0.29245386990633876, "compression_ratio": 1.3555555555555556, "no_speech_prob": 0.029178842902183533}, {"id": 49, "seek": 24352, "start": 248.16, "end": 256.16, "text": " Who thinks I am bound on IO because of the D state?", "tokens": [50596, 2102, 7309, 286, 669, 5472, 322, 39839, 570, 295, 264, 413, 1785, 30, 50996], "temperature": 0.0, "avg_logprob": -0.29245386990633876, "compression_ratio": 1.3555555555555556, "no_speech_prob": 0.029178842902183533}, {"id": 50, "seek": 24352, "start": 258.16, "end": 266.36, "text": " For me, this D state gives me a clue that most of my processors are waiting on IO.", "tokens": [51096, 1171, 385, 11, 341, 413, 1785, 2709, 385, 257, 13602, 300, 881, 295, 452, 27751, 366, 3806, 322, 39839, 13, 51506], "temperature": 0.0, "avg_logprob": -0.29245386990633876, "compression_ratio": 1.3555555555555556, "no_speech_prob": 0.029178842902183533}, {"id": 51, "seek": 24352, "start": 266.36, "end": 267.36, "text": " Probably.", "tokens": [51506, 9210, 13, 51556], "temperature": 0.0, "avg_logprob": -0.29245386990633876, "compression_ratio": 1.3555555555555556, "no_speech_prob": 0.029178842902183533}, {"id": 52, "seek": 26736, "start": 267.36, "end": 277.84000000000003, "text": " We see that it's not so exact science, but that's something that can give some clues.", "tokens": [50364, 492, 536, 300, 309, 311, 406, 370, 1900, 3497, 11, 457, 300, 311, 746, 300, 393, 976, 512, 20936, 13, 50888], "temperature": 0.0, "avg_logprob": -0.21006395483529697, "compression_ratio": 1.5794871794871794, "no_speech_prob": 0.17915911972522736}, {"id": 53, "seek": 26736, "start": 277.84000000000003, "end": 280.48, "text": " I'm lost in my slides.", "tokens": [50888, 286, 478, 2731, 294, 452, 9788, 13, 51020], "temperature": 0.0, "avg_logprob": -0.21006395483529697, "compression_ratio": 1.5794871794871794, "no_speech_prob": 0.17915911972522736}, {"id": 54, "seek": 26736, "start": 280.48, "end": 282.72, "text": " This is the next one.", "tokens": [51020, 639, 307, 264, 958, 472, 13, 51132], "temperature": 0.0, "avg_logprob": -0.21006395483529697, "compression_ratio": 1.5794871794871794, "no_speech_prob": 0.17915911972522736}, {"id": 55, "seek": 26736, "start": 282.72, "end": 284.6, "text": " I'm running yes.", "tokens": [51132, 286, 478, 2614, 2086, 13, 51226], "temperature": 0.0, "avg_logprob": -0.21006395483529697, "compression_ratio": 1.5794871794871794, "no_speech_prob": 0.17915911972522736}, {"id": 56, "seek": 26736, "start": 284.6, "end": 286.24, "text": " You know the yes command?", "tokens": [51226, 509, 458, 264, 2086, 5622, 30, 51308], "temperature": 0.0, "avg_logprob": -0.21006395483529697, "compression_ratio": 1.5794871794871794, "no_speech_prob": 0.17915911972522736}, {"id": 57, "seek": 26736, "start": 286.24, "end": 287.88, "text": " It displays yes.", "tokens": [51308, 467, 20119, 2086, 13, 51390], "temperature": 0.0, "avg_logprob": -0.21006395483529697, "compression_ratio": 1.5794871794871794, "no_speech_prob": 0.17915911972522736}, {"id": 58, "seek": 26736, "start": 287.88, "end": 291.68, "text": " I'm still running the same IO there, the same throughput.", "tokens": [51390, 286, 478, 920, 2614, 264, 912, 39839, 456, 11, 264, 912, 44629, 13, 51580], "temperature": 0.0, "avg_logprob": -0.21006395483529697, "compression_ratio": 1.5794871794871794, "no_speech_prob": 0.17915911972522736}, {"id": 59, "seek": 26736, "start": 291.68, "end": 296.44, "text": " I'm doing exactly the same, and my weight IO has decreased.", "tokens": [51580, 286, 478, 884, 2293, 264, 912, 11, 293, 452, 3364, 39839, 575, 24436, 13, 51818], "temperature": 0.0, "avg_logprob": -0.21006395483529697, "compression_ratio": 1.5794871794871794, "no_speech_prob": 0.17915911972522736}, {"id": 60, "seek": 29644, "start": 296.52, "end": 305.08, "text": " This is how to solve weight IO, just run something else.", "tokens": [50368, 639, 307, 577, 281, 5039, 3364, 39839, 11, 445, 1190, 746, 1646, 13, 50796], "temperature": 0.0, "avg_logprob": -0.24076675233386813, "compression_ratio": 1.4315068493150684, "no_speech_prob": 0.007572953123599291}, {"id": 61, "seek": 29644, "start": 305.08, "end": 311.4, "text": " I show that to explain that this weight IO is not about what your tasks are doing.", "tokens": [50796, 286, 855, 300, 281, 2903, 300, 341, 3364, 39839, 307, 406, 466, 437, 428, 9608, 366, 884, 13, 51112], "temperature": 0.0, "avg_logprob": -0.24076675233386813, "compression_ratio": 1.4315068493150684, "no_speech_prob": 0.007572953123599291}, {"id": 62, "seek": 29644, "start": 311.4, "end": 315.08, "text": " It's about the CPUs.", "tokens": [51112, 467, 311, 466, 264, 13199, 82, 13, 51296], "temperature": 0.0, "avg_logprob": -0.24076675233386813, "compression_ratio": 1.4315068493150684, "no_speech_prob": 0.007572953123599291}, {"id": 63, "seek": 29644, "start": 315.08, "end": 319.68, "text": " When you do IO, you don't need CPU, so you wait.", "tokens": [51296, 1133, 291, 360, 39839, 11, 291, 500, 380, 643, 13199, 11, 370, 291, 1699, 13, 51526], "temperature": 0.0, "avg_logprob": -0.24076675233386813, "compression_ratio": 1.4315068493150684, "no_speech_prob": 0.007572953123599291}, {"id": 64, "seek": 31968, "start": 319.92, "end": 328.16, "text": " If no one else wants to do something on the CPU, then the CPU state just remembers that,", "tokens": [50376, 759, 572, 472, 1646, 2738, 281, 360, 746, 322, 264, 13199, 11, 550, 264, 13199, 1785, 445, 26228, 300, 11, 50788], "temperature": 0.0, "avg_logprob": -0.2311079807770558, "compression_ratio": 1.6473988439306357, "no_speech_prob": 0.05795859172940254}, {"id": 65, "seek": 31968, "start": 328.16, "end": 333.6, "text": " okay, I'm idle because someone is doing some IO.", "tokens": [50788, 1392, 11, 286, 478, 30650, 570, 1580, 307, 884, 512, 39839, 13, 51060], "temperature": 0.0, "avg_logprob": -0.2311079807770558, "compression_ratio": 1.6473988439306357, "no_speech_prob": 0.05795859172940254}, {"id": 66, "seek": 31968, "start": 333.6, "end": 337.64, "text": " Now I'm running something else that uses this CPU.", "tokens": [51060, 823, 286, 478, 2614, 746, 1646, 300, 4960, 341, 13199, 13, 51262], "temperature": 0.0, "avg_logprob": -0.2311079807770558, "compression_ratio": 1.6473988439306357, "no_speech_prob": 0.05795859172940254}, {"id": 67, "seek": 31968, "start": 337.64, "end": 340.6, "text": " This CPU is not idle.", "tokens": [51262, 639, 13199, 307, 406, 30650, 13, 51410], "temperature": 0.0, "avg_logprob": -0.2311079807770558, "compression_ratio": 1.6473988439306357, "no_speech_prob": 0.05795859172940254}, {"id": 68, "seek": 31968, "start": 340.6, "end": 346.76, "text": " This weight IO just means idle, and idle because the last one did some IO.", "tokens": [51410, 639, 3364, 39839, 445, 1355, 30650, 11, 293, 30650, 570, 264, 1036, 472, 630, 512, 39839, 13, 51718], "temperature": 0.0, "avg_logprob": -0.2311079807770558, "compression_ratio": 1.6473988439306357, "no_speech_prob": 0.05795859172940254}, {"id": 69, "seek": 34676, "start": 346.76, "end": 354.0, "text": " The only information I have from weight IO is that the CPU could be used for something", "tokens": [50364, 440, 787, 1589, 286, 362, 490, 3364, 39839, 307, 300, 264, 13199, 727, 312, 1143, 337, 746, 50726], "temperature": 0.0, "avg_logprob": -0.1088866444377156, "compression_ratio": 1.5527638190954773, "no_speech_prob": 0.01652904599905014}, {"id": 70, "seek": 34676, "start": 354.0, "end": 361.03999999999996, "text": " more useful than weighting, but doesn't really give me the information that I have a lot", "tokens": [50726, 544, 4420, 813, 3364, 278, 11, 457, 1177, 380, 534, 976, 385, 264, 1589, 300, 286, 362, 257, 688, 51078], "temperature": 0.0, "avg_logprob": -0.1088866444377156, "compression_ratio": 1.5527638190954773, "no_speech_prob": 0.01652904599905014}, {"id": 71, "seek": 34676, "start": 361.03999999999996, "end": 366.2, "text": " of IO because depending on the other workload, I will sit there or not.", "tokens": [51078, 295, 39839, 570, 5413, 322, 264, 661, 20139, 11, 286, 486, 1394, 456, 420, 406, 13, 51336], "temperature": 0.0, "avg_logprob": -0.1088866444377156, "compression_ratio": 1.5527638190954773, "no_speech_prob": 0.01652904599905014}, {"id": 72, "seek": 34676, "start": 366.2, "end": 373.44, "text": " The state doesn't lie if my processes are all on the D state.", "tokens": [51336, 440, 1785, 1177, 380, 4544, 498, 452, 7555, 366, 439, 322, 264, 413, 1785, 13, 51698], "temperature": 0.0, "avg_logprob": -0.1088866444377156, "compression_ratio": 1.5527638190954773, "no_speech_prob": 0.01652904599905014}, {"id": 73, "seek": 37344, "start": 373.44, "end": 385.44, "text": " At least they are not on the R state, the renewable state, so they are not using CPU.", "tokens": [50364, 1711, 1935, 436, 366, 406, 322, 264, 497, 1785, 11, 264, 20938, 1785, 11, 370, 436, 366, 406, 1228, 13199, 13, 50964], "temperature": 0.0, "avg_logprob": -0.19257629080994487, "compression_ratio": 1.5595238095238095, "no_speech_prob": 0.0035809187684208155}, {"id": 74, "seek": 37344, "start": 385.44, "end": 393.36, "text": " In the next one, what I do to understand better the kind of IO I'm doing, the kind of system", "tokens": [50964, 682, 264, 958, 472, 11, 437, 286, 360, 281, 1223, 1101, 264, 733, 295, 39839, 286, 478, 884, 11, 264, 733, 295, 1185, 51360], "temperature": 0.0, "avg_logprob": -0.19257629080994487, "compression_ratio": 1.5595238095238095, "no_speech_prob": 0.0035809187684208155}, {"id": 75, "seek": 37344, "start": 393.36, "end": 402.4, "text": " call that puts this D state, I just run S trace on my processes, and I just did the", "tokens": [51360, 818, 300, 8137, 341, 413, 1785, 11, 286, 445, 1190, 318, 13508, 322, 452, 7555, 11, 293, 286, 445, 630, 264, 51812], "temperature": 0.0, "avg_logprob": -0.19257629080994487, "compression_ratio": 1.5595238095238095, "no_speech_prob": 0.0035809187684208155}, {"id": 76, "seek": 40240, "start": 402.47999999999996, "end": 408.96, "text": " S trace dash C to count them, and you see that most of the system calls are P writes.", "tokens": [50368, 318, 13508, 8240, 383, 281, 1207, 552, 11, 293, 291, 536, 300, 881, 295, 264, 1185, 5498, 366, 430, 13657, 13, 50692], "temperature": 0.0, "avg_logprob": -0.19503759202503024, "compression_ratio": 1.6898395721925135, "no_speech_prob": 0.042234987020492554}, {"id": 77, "seek": 40240, "start": 408.96, "end": 410.56, "text": " That's actually what I'm running there.", "tokens": [50692, 663, 311, 767, 437, 286, 478, 2614, 456, 13, 50772], "temperature": 0.0, "avg_logprob": -0.19503759202503024, "compression_ratio": 1.6898395721925135, "no_speech_prob": 0.042234987020492554}, {"id": 78, "seek": 40240, "start": 410.56, "end": 418.91999999999996, "text": " I'm doing writes with the P write system call with direct IO.", "tokens": [50772, 286, 478, 884, 13657, 365, 264, 430, 2464, 1185, 818, 365, 2047, 39839, 13, 51190], "temperature": 0.0, "avg_logprob": -0.19503759202503024, "compression_ratio": 1.6898395721925135, "no_speech_prob": 0.042234987020492554}, {"id": 79, "seek": 40240, "start": 418.91999999999996, "end": 422.32, "text": " That's basically what I have there.", "tokens": [51190, 663, 311, 1936, 437, 286, 362, 456, 13, 51360], "temperature": 0.0, "avg_logprob": -0.19503759202503024, "compression_ratio": 1.6898395721925135, "no_speech_prob": 0.042234987020492554}, {"id": 80, "seek": 40240, "start": 422.32, "end": 429.03999999999996, "text": " If I want to understand really what is behind a state that is not the R state, the renewable", "tokens": [51360, 759, 286, 528, 281, 1223, 534, 437, 307, 2261, 257, 1785, 300, 307, 406, 264, 497, 1785, 11, 264, 20938, 51696], "temperature": 0.0, "avg_logprob": -0.19503759202503024, "compression_ratio": 1.6898395721925135, "no_speech_prob": 0.042234987020492554}, {"id": 81, "seek": 42904, "start": 429.04, "end": 433.48, "text": " state, I can trace the system calls to know exactly why.", "tokens": [50364, 1785, 11, 286, 393, 13508, 264, 1185, 5498, 281, 458, 2293, 983, 13, 50586], "temperature": 0.0, "avg_logprob": -0.21077550600652825, "compression_ratio": 1.511764705882353, "no_speech_prob": 0.023503229022026062}, {"id": 82, "seek": 42904, "start": 433.48, "end": 442.32000000000005, "text": " I will explain why I'm looking at that because even if D looks like disk, you can do some", "tokens": [50586, 286, 486, 2903, 983, 286, 478, 1237, 412, 300, 570, 754, 498, 413, 1542, 411, 12355, 11, 291, 393, 360, 512, 51028], "temperature": 0.0, "avg_logprob": -0.21077550600652825, "compression_ratio": 1.511764705882353, "no_speech_prob": 0.023503229022026062}, {"id": 83, "seek": 42904, "start": 442.32000000000005, "end": 449.0, "text": " IOs that are not in D state, and you can have D state that has nothing to do with IO.", "tokens": [51028, 39839, 82, 300, 366, 406, 294, 413, 1785, 11, 293, 291, 393, 362, 413, 1785, 300, 575, 1825, 281, 360, 365, 39839, 13, 51362], "temperature": 0.0, "avg_logprob": -0.21077550600652825, "compression_ratio": 1.511764705882353, "no_speech_prob": 0.023503229022026062}, {"id": 84, "seek": 42904, "start": 449.0, "end": 452.76, "text": " So it can be misleading.", "tokens": [51362, 407, 309, 393, 312, 36429, 13, 51550], "temperature": 0.0, "avg_logprob": -0.21077550600652825, "compression_ratio": 1.511764705882353, "no_speech_prob": 0.023503229022026062}, {"id": 85, "seek": 45276, "start": 452.76, "end": 459.12, "text": " The D state is uninterruptible calls.", "tokens": [50364, 440, 413, 1785, 307, 49234, 5428, 964, 5498, 13, 50682], "temperature": 0.0, "avg_logprob": -0.24608826939063735, "compression_ratio": 1.5942857142857143, "no_speech_prob": 0.05510590970516205}, {"id": 86, "seek": 45276, "start": 459.12, "end": 466.48, "text": " So your process has something to do that is not in CPU and does it in an uninterruptible", "tokens": [50682, 407, 428, 1399, 575, 746, 281, 360, 300, 307, 406, 294, 13199, 293, 775, 309, 294, 364, 49234, 5428, 964, 51050], "temperature": 0.0, "avg_logprob": -0.24608826939063735, "compression_ratio": 1.5942857142857143, "no_speech_prob": 0.05510590970516205}, {"id": 87, "seek": 45276, "start": 466.48, "end": 468.32, "text": " state.", "tokens": [51050, 1785, 13, 51142], "temperature": 0.0, "avg_logprob": -0.24608826939063735, "compression_ratio": 1.5942857142857143, "no_speech_prob": 0.05510590970516205}, {"id": 88, "seek": 45276, "start": 468.32, "end": 474.52, "text": " Depending on the system call, it can do it uninterruptible or not.", "tokens": [51142, 22539, 322, 264, 1185, 818, 11, 309, 393, 360, 309, 49234, 5428, 964, 420, 406, 13, 51452], "temperature": 0.0, "avg_logprob": -0.24608826939063735, "compression_ratio": 1.5942857142857143, "no_speech_prob": 0.05510590970516205}, {"id": 89, "seek": 45276, "start": 474.52, "end": 482.64, "text": " Often IO like the P write is using this, but there are some other kind of IOs.", "tokens": [51452, 20043, 39839, 411, 264, 430, 2464, 307, 1228, 341, 11, 457, 456, 366, 512, 661, 733, 295, 39839, 82, 13, 51858], "temperature": 0.0, "avg_logprob": -0.24608826939063735, "compression_ratio": 1.5942857142857143, "no_speech_prob": 0.05510590970516205}, {"id": 90, "seek": 48264, "start": 482.64, "end": 483.91999999999996, "text": " Any questions so far?", "tokens": [50364, 2639, 1651, 370, 1400, 30, 50428], "temperature": 0.0, "avg_logprob": -0.24770425649789662, "compression_ratio": 1.364864864864865, "no_speech_prob": 0.07072817534208298}, {"id": 91, "seek": 48264, "start": 483.91999999999996, "end": 486.24, "text": " Any remarks?", "tokens": [50428, 2639, 19151, 30, 50544], "temperature": 0.0, "avg_logprob": -0.24770425649789662, "compression_ratio": 1.364864864864865, "no_speech_prob": 0.07072817534208298}, {"id": 92, "seek": 48264, "start": 486.24, "end": 488.8, "text": " Okay.", "tokens": [50544, 1033, 13, 50672], "temperature": 0.0, "avg_logprob": -0.24770425649789662, "compression_ratio": 1.364864864864865, "no_speech_prob": 0.07072817534208298}, {"id": 93, "seek": 48264, "start": 488.8, "end": 493.53999999999996, "text": " So next one.", "tokens": [50672, 407, 958, 472, 13, 50909], "temperature": 0.0, "avg_logprob": -0.24770425649789662, "compression_ratio": 1.364864864864865, "no_speech_prob": 0.07072817534208298}, {"id": 94, "seek": 48264, "start": 493.53999999999996, "end": 499.84, "text": " I will run something else if I remember exactly what I'm doing here.", "tokens": [50909, 286, 486, 1190, 746, 1646, 498, 286, 1604, 2293, 437, 286, 478, 884, 510, 13, 51224], "temperature": 0.0, "avg_logprob": -0.24770425649789662, "compression_ratio": 1.364864864864865, "no_speech_prob": 0.07072817534208298}, {"id": 95, "seek": 48264, "start": 499.84, "end": 501.47999999999996, "text": " I will run FIO.", "tokens": [51224, 286, 486, 1190, 479, 15167, 13, 51306], "temperature": 0.0, "avg_logprob": -0.24770425649789662, "compression_ratio": 1.364864864864865, "no_speech_prob": 0.07072817534208298}, {"id": 96, "seek": 48264, "start": 501.47999999999996, "end": 506.36, "text": " The difference is that I'm not calling the P write system call.", "tokens": [51306, 440, 2649, 307, 300, 286, 478, 406, 5141, 264, 430, 2464, 1185, 818, 13, 51550], "temperature": 0.0, "avg_logprob": -0.24770425649789662, "compression_ratio": 1.364864864864865, "no_speech_prob": 0.07072817534208298}, {"id": 97, "seek": 50636, "start": 506.36, "end": 513.92, "text": " I'm calling the Lib IO, asynchronous IO library.", "tokens": [50364, 286, 478, 5141, 264, 15834, 39839, 11, 49174, 39839, 6405, 13, 50742], "temperature": 0.0, "avg_logprob": -0.32060210488059304, "compression_ratio": 1.3793103448275863, "no_speech_prob": 0.18558788299560547}, {"id": 98, "seek": 50636, "start": 513.92, "end": 519.76, "text": " Basically I'm doing the same writing to the disk with direct IO and you can see the throughput", "tokens": [50742, 8537, 286, 478, 884, 264, 912, 3579, 281, 264, 12355, 365, 2047, 39839, 293, 291, 393, 536, 264, 44629, 51034], "temperature": 0.0, "avg_logprob": -0.32060210488059304, "compression_ratio": 1.3793103448275863, "no_speech_prob": 0.18558788299560547}, {"id": 99, "seek": 50636, "start": 519.76, "end": 523.36, "text": " is mostly the same.", "tokens": [51034, 307, 5240, 264, 912, 13, 51214], "temperature": 0.0, "avg_logprob": -0.32060210488059304, "compression_ratio": 1.3793103448275863, "no_speech_prob": 0.18558788299560547}, {"id": 100, "seek": 50636, "start": 523.36, "end": 529.8000000000001, "text": " However, I'm not in D state anymore.", "tokens": [51214, 2908, 11, 286, 478, 406, 294, 413, 1785, 3602, 13, 51536], "temperature": 0.0, "avg_logprob": -0.32060210488059304, "compression_ratio": 1.3793103448275863, "no_speech_prob": 0.18558788299560547}, {"id": 101, "seek": 52980, "start": 529.8, "end": 536.8, "text": " So there are some IO who put the D state, but there are some IO who just put the sleep", "tokens": [50364, 407, 456, 366, 512, 39839, 567, 829, 264, 413, 1785, 11, 457, 456, 366, 512, 39839, 567, 445, 829, 264, 2817, 50714], "temperature": 0.0, "avg_logprob": -0.17934256630974846, "compression_ratio": 1.5689655172413792, "no_speech_prob": 0.0916670635342598}, {"id": 102, "seek": 52980, "start": 536.8, "end": 542.7199999999999, "text": " state, which is not uninterruptible.", "tokens": [50714, 1785, 11, 597, 307, 406, 49234, 5428, 964, 13, 51010], "temperature": 0.0, "avg_logprob": -0.17934256630974846, "compression_ratio": 1.5689655172413792, "no_speech_prob": 0.0916670635342598}, {"id": 103, "seek": 52980, "start": 542.7199999999999, "end": 549.8, "text": " So very misleading when you see those things and try to guess what happens.", "tokens": [51010, 407, 588, 36429, 562, 291, 536, 729, 721, 293, 853, 281, 2041, 437, 2314, 13, 51364], "temperature": 0.0, "avg_logprob": -0.17934256630974846, "compression_ratio": 1.5689655172413792, "no_speech_prob": 0.0916670635342598}, {"id": 104, "seek": 52980, "start": 549.8, "end": 551.7199999999999, "text": " If you are stressed, there is no guess.", "tokens": [51364, 759, 291, 366, 14471, 11, 456, 307, 572, 2041, 13, 51460], "temperature": 0.0, "avg_logprob": -0.17934256630974846, "compression_ratio": 1.5689655172413792, "no_speech_prob": 0.0916670635342598}, {"id": 105, "seek": 52980, "start": 551.7199999999999, "end": 554.64, "text": " You know exactly the system call.", "tokens": [51460, 509, 458, 2293, 264, 1185, 818, 13, 51606], "temperature": 0.0, "avg_logprob": -0.17934256630974846, "compression_ratio": 1.5689655172413792, "no_speech_prob": 0.0916670635342598}, {"id": 106, "seek": 55464, "start": 554.64, "end": 558.6, "text": " And I think this is what I do just after.", "tokens": [50364, 400, 286, 519, 341, 307, 437, 286, 360, 445, 934, 13, 50562], "temperature": 0.0, "avg_logprob": -0.23721990692481565, "compression_ratio": 1.6894736842105262, "no_speech_prob": 0.24844582378864288}, {"id": 107, "seek": 55464, "start": 558.6, "end": 568.92, "text": " If I stress, I see that most of the IO calls here are IO get events and there is some IO", "tokens": [50562, 759, 286, 4244, 11, 286, 536, 300, 881, 295, 264, 39839, 5498, 510, 366, 39839, 483, 3931, 293, 456, 307, 512, 39839, 51078], "temperature": 0.0, "avg_logprob": -0.23721990692481565, "compression_ratio": 1.6894736842105262, "no_speech_prob": 0.24844582378864288}, {"id": 108, "seek": 55464, "start": 568.92, "end": 569.92, "text": " submit.", "tokens": [51078, 10315, 13, 51128], "temperature": 0.0, "avg_logprob": -0.23721990692481565, "compression_ratio": 1.6894736842105262, "no_speech_prob": 0.24844582378864288}, {"id": 109, "seek": 55464, "start": 569.92, "end": 573.24, "text": " This is our asynchronous IO works.", "tokens": [51128, 639, 307, 527, 49174, 39839, 1985, 13, 51294], "temperature": 0.0, "avg_logprob": -0.23721990692481565, "compression_ratio": 1.6894736842105262, "no_speech_prob": 0.24844582378864288}, {"id": 110, "seek": 55464, "start": 573.24, "end": 579.0, "text": " P write just ask the kernel, I want these blocks and wait to get those blocks.", "tokens": [51294, 430, 2464, 445, 1029, 264, 28256, 11, 286, 528, 613, 8474, 293, 1699, 281, 483, 729, 8474, 13, 51582], "temperature": 0.0, "avg_logprob": -0.23721990692481565, "compression_ratio": 1.6894736842105262, "no_speech_prob": 0.24844582378864288}, {"id": 111, "seek": 55464, "start": 579.0, "end": 583.08, "text": " With asynchronous IO, it tells the kernel, I will need those blocks.", "tokens": [51582, 2022, 49174, 39839, 11, 309, 5112, 264, 28256, 11, 286, 486, 643, 729, 8474, 13, 51786], "temperature": 0.0, "avg_logprob": -0.23721990692481565, "compression_ratio": 1.6894736842105262, "no_speech_prob": 0.24844582378864288}, {"id": 112, "seek": 58308, "start": 583.08, "end": 592.1600000000001, "text": " So that's the submit and then can you work on something else and come back and say, oh,", "tokens": [50364, 407, 300, 311, 264, 10315, 293, 550, 393, 291, 589, 322, 746, 1646, 293, 808, 646, 293, 584, 11, 1954, 11, 50818], "temperature": 0.0, "avg_logprob": -0.22629607807506213, "compression_ratio": 1.576086956521739, "no_speech_prob": 0.202262744307518}, {"id": 113, "seek": 58308, "start": 592.1600000000001, "end": 593.44, "text": " do you have my IO?", "tokens": [50818, 360, 291, 362, 452, 39839, 30, 50882], "temperature": 0.0, "avg_logprob": -0.22629607807506213, "compression_ratio": 1.576086956521739, "no_speech_prob": 0.202262744307518}, {"id": 114, "seek": 58308, "start": 593.44, "end": 595.1600000000001, "text": " If not, I will wait.", "tokens": [50882, 759, 406, 11, 286, 486, 1699, 13, 50968], "temperature": 0.0, "avg_logprob": -0.22629607807506213, "compression_ratio": 1.576086956521739, "no_speech_prob": 0.202262744307518}, {"id": 115, "seek": 58308, "start": 595.1600000000001, "end": 600.2800000000001, "text": " The submit goes in this state, but it's very short because it's just a submit.", "tokens": [50968, 440, 10315, 1709, 294, 341, 1785, 11, 457, 309, 311, 588, 2099, 570, 309, 311, 445, 257, 10315, 13, 51224], "temperature": 0.0, "avg_logprob": -0.22629607807506213, "compression_ratio": 1.576086956521739, "no_speech_prob": 0.202262744307518}, {"id": 116, "seek": 58308, "start": 600.2800000000001, "end": 608.6400000000001, "text": " The get events, if it waits, goes in sleep state, the S state, and not the D state.", "tokens": [51224, 440, 483, 3931, 11, 498, 309, 40597, 11, 1709, 294, 2817, 1785, 11, 264, 318, 1785, 11, 293, 406, 264, 413, 1785, 13, 51642], "temperature": 0.0, "avg_logprob": -0.22629607807506213, "compression_ratio": 1.576086956521739, "no_speech_prob": 0.202262744307518}, {"id": 117, "seek": 60864, "start": 609.0, "end": 612.96, "text": " Depending on the kind of IO, you will see it at this state or not.", "tokens": [50382, 22539, 322, 264, 733, 295, 39839, 11, 291, 486, 536, 309, 412, 341, 1785, 420, 406, 13, 50580], "temperature": 0.0, "avg_logprob": -0.19482516120461857, "compression_ratio": 1.5309278350515463, "no_speech_prob": 0.24402186274528503}, {"id": 118, "seek": 60864, "start": 612.96, "end": 621.08, "text": " And the wait IO there depends on the state, but more important, I don't know if I can", "tokens": [50580, 400, 264, 1699, 39839, 456, 5946, 322, 264, 1785, 11, 457, 544, 1021, 11, 286, 500, 380, 458, 498, 286, 393, 50986], "temperature": 0.0, "avg_logprob": -0.19482516120461857, "compression_ratio": 1.5309278350515463, "no_speech_prob": 0.24402186274528503}, {"id": 119, "seek": 60864, "start": 621.08, "end": 622.08, "text": " go back.", "tokens": [50986, 352, 646, 13, 51036], "temperature": 0.0, "avg_logprob": -0.19482516120461857, "compression_ratio": 1.5309278350515463, "no_speech_prob": 0.24402186274528503}, {"id": 120, "seek": 60864, "start": 622.08, "end": 630.4, "text": " Well, I'm sure I can go back if I replay it.", "tokens": [51036, 1042, 11, 286, 478, 988, 286, 393, 352, 646, 498, 286, 23836, 309, 13, 51452], "temperature": 0.0, "avg_logprob": -0.19482516120461857, "compression_ratio": 1.5309278350515463, "no_speech_prob": 0.24402186274528503}, {"id": 121, "seek": 60864, "start": 630.4, "end": 638.3199999999999, "text": " I guess that the load average was lower when I was running that because the D state counts", "tokens": [51452, 286, 2041, 300, 264, 3677, 4274, 390, 3126, 562, 286, 390, 2614, 300, 570, 264, 413, 1785, 14893, 51848], "temperature": 0.0, "avg_logprob": -0.19482516120461857, "compression_ratio": 1.5309278350515463, "no_speech_prob": 0.24402186274528503}, {"id": 122, "seek": 63832, "start": 638.32, "end": 642.44, "text": " in the load average, the S state doesn't.", "tokens": [50364, 294, 264, 3677, 4274, 11, 264, 318, 1785, 1177, 380, 13, 50570], "temperature": 0.0, "avg_logprob": -0.27569273114204407, "compression_ratio": 1.5985401459854014, "no_speech_prob": 0.04190479591488838}, {"id": 123, "seek": 63832, "start": 642.44, "end": 648.9200000000001, "text": " Means that some IO counts in the load average, some IO doesn't.", "tokens": [50570, 40290, 300, 512, 39839, 14893, 294, 264, 3677, 4274, 11, 512, 39839, 1177, 380, 13, 50894], "temperature": 0.0, "avg_logprob": -0.27569273114204407, "compression_ratio": 1.5985401459854014, "no_speech_prob": 0.04190479591488838}, {"id": 124, "seek": 63832, "start": 648.9200000000001, "end": 655.2, "text": " Means that with load average, you don't really know what happens.", "tokens": [50894, 40290, 300, 365, 3677, 4274, 11, 291, 500, 380, 534, 458, 437, 2314, 13, 51208], "temperature": 0.0, "avg_logprob": -0.27569273114204407, "compression_ratio": 1.5985401459854014, "no_speech_prob": 0.04190479591488838}, {"id": 125, "seek": 63832, "start": 655.2, "end": 660.2, "text": " Okay.", "tokens": [51208, 1033, 13, 51458], "temperature": 0.0, "avg_logprob": -0.27569273114204407, "compression_ratio": 1.5985401459854014, "no_speech_prob": 0.04190479591488838}, {"id": 126, "seek": 63832, "start": 660.2, "end": 663.7600000000001, "text": " The next one, I'm running something else.", "tokens": [51458, 440, 958, 472, 11, 286, 478, 2614, 746, 1646, 13, 51636], "temperature": 0.0, "avg_logprob": -0.27569273114204407, "compression_ratio": 1.5985401459854014, "no_speech_prob": 0.04190479591488838}, {"id": 127, "seek": 66376, "start": 663.76, "end": 669.2, "text": " So those were direct writes by passing the buffer cache.", "tokens": [50364, 407, 729, 645, 2047, 13657, 538, 8437, 264, 21762, 19459, 13, 50636], "temperature": 0.0, "avg_logprob": -0.33038898090739827, "compression_ratio": 1.4761904761904763, "no_speech_prob": 0.2851417660713196}, {"id": 128, "seek": 66376, "start": 669.2, "end": 673.88, "text": " And here I'm running reads and more I set direct equals zero to FIO.", "tokens": [50636, 400, 510, 286, 478, 2614, 15700, 293, 544, 286, 992, 2047, 6915, 4018, 281, 479, 15167, 13, 50870], "temperature": 0.0, "avg_logprob": -0.33038898090739827, "compression_ratio": 1.4761904761904763, "no_speech_prob": 0.2851417660713196}, {"id": 129, "seek": 66376, "start": 673.88, "end": 677.92, "text": " FIO just simulates different kind of IO.", "tokens": [50870, 479, 15167, 445, 1034, 26192, 819, 733, 295, 39839, 13, 51072], "temperature": 0.0, "avg_logprob": -0.33038898090739827, "compression_ratio": 1.4761904761904763, "no_speech_prob": 0.2851417660713196}, {"id": 130, "seek": 66376, "start": 677.92, "end": 680.76, "text": " Typically I work with databases.", "tokens": [51072, 23129, 286, 589, 365, 22380, 13, 51214], "temperature": 0.0, "avg_logprob": -0.33038898090739827, "compression_ratio": 1.4761904761904763, "no_speech_prob": 0.2851417660713196}, {"id": 131, "seek": 66376, "start": 680.76, "end": 685.36, "text": " I'm a developer advocate for UGA by DB that is a distributed SQL database compatible", "tokens": [51214, 286, 478, 257, 10754, 14608, 337, 624, 12570, 538, 26754, 300, 307, 257, 12631, 19200, 8149, 18218, 51444], "temperature": 0.0, "avg_logprob": -0.33038898090739827, "compression_ratio": 1.4761904761904763, "no_speech_prob": 0.2851417660713196}, {"id": 132, "seek": 66376, "start": 685.36, "end": 686.86, "text": " with Postgres.", "tokens": [51444, 365, 10223, 45189, 13, 51519], "temperature": 0.0, "avg_logprob": -0.33038898090739827, "compression_ratio": 1.4761904761904763, "no_speech_prob": 0.2851417660713196}, {"id": 133, "seek": 66376, "start": 686.86, "end": 689.4, "text": " I've been working also a lot with Oracle.", "tokens": [51519, 286, 600, 668, 1364, 611, 257, 688, 365, 25654, 13, 51646], "temperature": 0.0, "avg_logprob": -0.33038898090739827, "compression_ratio": 1.4761904761904763, "no_speech_prob": 0.2851417660713196}, {"id": 134, "seek": 68940, "start": 689.4, "end": 695.1999999999999, "text": " They do those kind of IO, Postgres does not do direct IO.", "tokens": [50364, 814, 360, 729, 733, 295, 39839, 11, 10223, 45189, 775, 406, 360, 2047, 39839, 13, 50654], "temperature": 0.0, "avg_logprob": -0.33807992346492816, "compression_ratio": 1.4065934065934067, "no_speech_prob": 0.11465349048376083}, {"id": 135, "seek": 68940, "start": 695.1999999999999, "end": 696.1999999999999, "text": " It goes through buffer.", "tokens": [50654, 467, 1709, 807, 21762, 13, 50704], "temperature": 0.0, "avg_logprob": -0.33807992346492816, "compression_ratio": 1.4065934065934067, "no_speech_prob": 0.11465349048376083}, {"id": 136, "seek": 68940, "start": 696.1999999999999, "end": 697.4, "text": " Oracle, you have the choice.", "tokens": [50704, 25654, 11, 291, 362, 264, 3922, 13, 50764], "temperature": 0.0, "avg_logprob": -0.33807992346492816, "compression_ratio": 1.4065934065934067, "no_speech_prob": 0.11465349048376083}, {"id": 137, "seek": 68940, "start": 697.4, "end": 699.4, "text": " So really depends.", "tokens": [50764, 407, 534, 5946, 13, 50864], "temperature": 0.0, "avg_logprob": -0.33807992346492816, "compression_ratio": 1.4065934065934067, "no_speech_prob": 0.11465349048376083}, {"id": 138, "seek": 68940, "start": 699.4, "end": 707.4, "text": " Here, what I would like to show you, I don't see it from here, but I'm probably in the", "tokens": [50864, 1692, 11, 437, 286, 576, 411, 281, 855, 291, 11, 286, 500, 380, 536, 309, 490, 510, 11, 457, 286, 478, 1391, 294, 264, 51264], "temperature": 0.0, "avg_logprob": -0.33807992346492816, "compression_ratio": 1.4065934065934067, "no_speech_prob": 0.11465349048376083}, {"id": 139, "seek": 68940, "start": 707.4, "end": 709.4, "text": " running state.", "tokens": [51264, 2614, 1785, 13, 51364], "temperature": 0.0, "avg_logprob": -0.33807992346492816, "compression_ratio": 1.4065934065934067, "no_speech_prob": 0.11465349048376083}, {"id": 140, "seek": 68940, "start": 709.4, "end": 713.4, "text": " Yeah, it was not sorted.", "tokens": [51364, 865, 11, 309, 390, 406, 25462, 13, 51564], "temperature": 0.0, "avg_logprob": -0.33807992346492816, "compression_ratio": 1.4065934065934067, "no_speech_prob": 0.11465349048376083}, {"id": 141, "seek": 71340, "start": 713.4, "end": 719.1999999999999, "text": " But here, I'm mostly reading from memory, from the cache, from buffers.", "tokens": [50364, 583, 510, 11, 286, 478, 5240, 3760, 490, 4675, 11, 490, 264, 19459, 11, 490, 9204, 433, 13, 50654], "temperature": 0.0, "avg_logprob": -0.18704852053993626, "compression_ratio": 1.5748792270531402, "no_speech_prob": 0.16764003038406372}, {"id": 142, "seek": 71340, "start": 719.1999999999999, "end": 722.72, "text": " And this is why you see that much faster.", "tokens": [50654, 400, 341, 307, 983, 291, 536, 300, 709, 4663, 13, 50830], "temperature": 0.0, "avg_logprob": -0.18704852053993626, "compression_ratio": 1.5748792270531402, "no_speech_prob": 0.16764003038406372}, {"id": 143, "seek": 71340, "start": 722.72, "end": 728.0799999999999, "text": " And a difference, I'm using more CPU there.", "tokens": [50830, 400, 257, 2649, 11, 286, 478, 1228, 544, 13199, 456, 13, 51098], "temperature": 0.0, "avg_logprob": -0.18704852053993626, "compression_ratio": 1.5748792270531402, "no_speech_prob": 0.16764003038406372}, {"id": 144, "seek": 71340, "start": 728.0799999999999, "end": 731.88, "text": " You access memory more than you access the disks.", "tokens": [51098, 509, 2105, 4675, 544, 813, 291, 2105, 264, 41617, 13, 51288], "temperature": 0.0, "avg_logprob": -0.18704852053993626, "compression_ratio": 1.5748792270531402, "no_speech_prob": 0.16764003038406372}, {"id": 145, "seek": 71340, "start": 731.88, "end": 738.48, "text": " And then this is in CPU usage, the kernel part of the read.", "tokens": [51288, 400, 550, 341, 307, 294, 13199, 14924, 11, 264, 28256, 644, 295, 264, 1401, 13, 51618], "temperature": 0.0, "avg_logprob": -0.18704852053993626, "compression_ratio": 1.5748792270531402, "no_speech_prob": 0.16764003038406372}, {"id": 146, "seek": 71340, "start": 738.48, "end": 741.36, "text": " I mean, my application is doing the same.", "tokens": [51618, 286, 914, 11, 452, 3861, 307, 884, 264, 912, 13, 51762], "temperature": 0.0, "avg_logprob": -0.18704852053993626, "compression_ratio": 1.5748792270531402, "no_speech_prob": 0.16764003038406372}, {"id": 147, "seek": 71340, "start": 741.36, "end": 742.76, "text": " Just an IO call.", "tokens": [51762, 1449, 364, 39839, 818, 13, 51832], "temperature": 0.0, "avg_logprob": -0.18704852053993626, "compression_ratio": 1.5748792270531402, "no_speech_prob": 0.16764003038406372}, {"id": 148, "seek": 74276, "start": 742.76, "end": 746.88, "text": " So the user space CPU is still low.", "tokens": [50364, 407, 264, 4195, 1901, 13199, 307, 920, 2295, 13, 50570], "temperature": 0.0, "avg_logprob": -0.18190529129721902, "compression_ratio": 1.5743589743589743, "no_speech_prob": 0.024614078924059868}, {"id": 149, "seek": 74276, "start": 746.88, "end": 752.28, "text": " But on the system, on the kernel, what Linux does is read from memory.", "tokens": [50570, 583, 322, 264, 1185, 11, 322, 264, 28256, 11, 437, 18734, 775, 307, 1401, 490, 4675, 13, 50840], "temperature": 0.0, "avg_logprob": -0.18190529129721902, "compression_ratio": 1.5743589743589743, "no_speech_prob": 0.024614078924059868}, {"id": 150, "seek": 74276, "start": 752.28, "end": 756.04, "text": " And this is where you have some system CPU there.", "tokens": [50840, 400, 341, 307, 689, 291, 362, 512, 1185, 13199, 456, 13, 51028], "temperature": 0.0, "avg_logprob": -0.18190529129721902, "compression_ratio": 1.5743589743589743, "no_speech_prob": 0.024614078924059868}, {"id": 151, "seek": 74276, "start": 756.04, "end": 760.2, "text": " That counts in the load average also.", "tokens": [51028, 663, 14893, 294, 264, 3677, 4274, 611, 13, 51236], "temperature": 0.0, "avg_logprob": -0.18190529129721902, "compression_ratio": 1.5743589743589743, "no_speech_prob": 0.024614078924059868}, {"id": 152, "seek": 74276, "start": 760.2, "end": 769.36, "text": " I just, okay, in the meantime, I did this trace to see the reads there.", "tokens": [51236, 286, 445, 11, 1392, 11, 294, 264, 14991, 11, 286, 630, 341, 13508, 281, 536, 264, 15700, 456, 13, 51694], "temperature": 0.0, "avg_logprob": -0.18190529129721902, "compression_ratio": 1.5743589743589743, "no_speech_prob": 0.024614078924059868}, {"id": 153, "seek": 74276, "start": 769.36, "end": 772.16, "text": " So I have periods, the same system call.", "tokens": [51694, 407, 286, 362, 13804, 11, 264, 912, 1185, 818, 13, 51834], "temperature": 0.0, "avg_logprob": -0.18190529129721902, "compression_ratio": 1.5743589743589743, "no_speech_prob": 0.024614078924059868}, {"id": 154, "seek": 77216, "start": 772.16, "end": 776.16, "text": " What is different is what is behind.", "tokens": [50364, 708, 307, 819, 307, 437, 307, 2261, 13, 50564], "temperature": 0.0, "avg_logprob": -0.20947231335586378, "compression_ratio": 1.5510204081632653, "no_speech_prob": 0.02001575008034706}, {"id": 155, "seek": 77216, "start": 776.16, "end": 778.0799999999999, "text": " That it reads from buffer.", "tokens": [50564, 663, 309, 15700, 490, 21762, 13, 50660], "temperature": 0.0, "avg_logprob": -0.20947231335586378, "compression_ratio": 1.5510204081632653, "no_speech_prob": 0.02001575008034706}, {"id": 156, "seek": 77216, "start": 778.0799999999999, "end": 781.16, "text": " And I don't know if you have seen it.", "tokens": [50660, 400, 286, 500, 380, 458, 498, 291, 362, 1612, 309, 13, 50814], "temperature": 0.0, "avg_logprob": -0.20947231335586378, "compression_ratio": 1.5510204081632653, "no_speech_prob": 0.02001575008034706}, {"id": 157, "seek": 77216, "start": 781.16, "end": 787.7199999999999, "text": " When I was attaching with S trace, the state here was T. That's the state when you attach.", "tokens": [50814, 1133, 286, 390, 39074, 365, 318, 13508, 11, 264, 1785, 510, 390, 314, 13, 663, 311, 264, 1785, 562, 291, 5085, 13, 51142], "temperature": 0.0, "avg_logprob": -0.20947231335586378, "compression_ratio": 1.5510204081632653, "no_speech_prob": 0.02001575008034706}, {"id": 158, "seek": 77216, "start": 787.7199999999999, "end": 789.36, "text": " And of course, it has a little overhead.", "tokens": [51142, 400, 295, 1164, 11, 309, 575, 257, 707, 19922, 13, 51224], "temperature": 0.0, "avg_logprob": -0.20947231335586378, "compression_ratio": 1.5510204081632653, "no_speech_prob": 0.02001575008034706}, {"id": 159, "seek": 77216, "start": 789.36, "end": 793.24, "text": " You do that to troubleshoot.", "tokens": [51224, 509, 360, 300, 281, 15379, 24467, 13, 51418], "temperature": 0.0, "avg_logprob": -0.20947231335586378, "compression_ratio": 1.5510204081632653, "no_speech_prob": 0.02001575008034706}, {"id": 160, "seek": 77216, "start": 793.24, "end": 797.24, "text": " The important thing is the runable state.", "tokens": [51418, 440, 1021, 551, 307, 264, 1190, 712, 1785, 13, 51618], "temperature": 0.0, "avg_logprob": -0.20947231335586378, "compression_ratio": 1.5510204081632653, "no_speech_prob": 0.02001575008034706}, {"id": 161, "seek": 79724, "start": 797.24, "end": 803.48, "text": " I'm saying that either I'm running in CPU or I want to run in CPU.", "tokens": [50364, 286, 478, 1566, 300, 2139, 286, 478, 2614, 294, 13199, 420, 286, 528, 281, 1190, 294, 13199, 13, 50676], "temperature": 0.0, "avg_logprob": -0.24494324478448606, "compression_ratio": 1.675, "no_speech_prob": 0.3818361461162567}, {"id": 162, "seek": 79724, "start": 803.48, "end": 808.64, "text": " And I don't know which one from those metrics.", "tokens": [50676, 400, 286, 500, 380, 458, 597, 472, 490, 729, 16367, 13, 50934], "temperature": 0.0, "avg_logprob": -0.24494324478448606, "compression_ratio": 1.675, "no_speech_prob": 0.3818361461162567}, {"id": 163, "seek": 79724, "start": 808.64, "end": 809.64, "text": " That's the point.", "tokens": [50934, 663, 311, 264, 935, 13, 50984], "temperature": 0.0, "avg_logprob": -0.24494324478448606, "compression_ratio": 1.675, "no_speech_prob": 0.3818361461162567}, {"id": 164, "seek": 79724, "start": 809.64, "end": 810.64, "text": " I have only two CPUs.", "tokens": [50984, 286, 362, 787, 732, 13199, 82, 13, 51034], "temperature": 0.0, "avg_logprob": -0.24494324478448606, "compression_ratio": 1.675, "no_speech_prob": 0.3818361461162567}, {"id": 165, "seek": 79724, "start": 810.64, "end": 816.04, "text": " So I know that I cannot have more than two tasks running in CPU.", "tokens": [51034, 407, 286, 458, 300, 286, 2644, 362, 544, 813, 732, 9608, 2614, 294, 13199, 13, 51304], "temperature": 0.0, "avg_logprob": -0.24494324478448606, "compression_ratio": 1.675, "no_speech_prob": 0.3818361461162567}, {"id": 166, "seek": 79724, "start": 816.04, "end": 817.04, "text": " They are running able.", "tokens": [51304, 814, 366, 2614, 1075, 13, 51354], "temperature": 0.0, "avg_logprob": -0.24494324478448606, "compression_ratio": 1.675, "no_speech_prob": 0.3818361461162567}, {"id": 167, "seek": 79724, "start": 817.04, "end": 822.0, "text": " They are waiting in the run queue to be able to run on the CPU.", "tokens": [51354, 814, 366, 3806, 294, 264, 1190, 18639, 281, 312, 1075, 281, 1190, 322, 264, 13199, 13, 51602], "temperature": 0.0, "avg_logprob": -0.24494324478448606, "compression_ratio": 1.675, "no_speech_prob": 0.3818361461162567}, {"id": 168, "seek": 79724, "start": 822.0, "end": 824.16, "text": " Top will not show the figure.", "tokens": [51602, 8840, 486, 406, 855, 264, 2573, 13, 51710], "temperature": 0.0, "avg_logprob": -0.24494324478448606, "compression_ratio": 1.675, "no_speech_prob": 0.3818361461162567}, {"id": 169, "seek": 82416, "start": 824.16, "end": 830.12, "text": " Load average will add those rating and those running.", "tokens": [50364, 48408, 4274, 486, 909, 729, 10990, 293, 729, 2614, 13, 50662], "temperature": 0.0, "avg_logprob": -0.2317652883408945, "compression_ratio": 1.595, "no_speech_prob": 0.011708422563970089}, {"id": 170, "seek": 82416, "start": 830.12, "end": 835.68, "text": " If you want to see the difference, you need to look at the statistics from the scheduler", "tokens": [50662, 759, 291, 528, 281, 536, 264, 2649, 11, 291, 643, 281, 574, 412, 264, 12523, 490, 264, 12000, 260, 50940], "temperature": 0.0, "avg_logprob": -0.2317652883408945, "compression_ratio": 1.595, "no_speech_prob": 0.011708422563970089}, {"id": 171, "seek": 82416, "start": 835.68, "end": 841.64, "text": " in slash proc scheduler statistics or VM stat is showing you the run queue.", "tokens": [50940, 294, 17330, 9510, 12000, 260, 12523, 420, 18038, 2219, 307, 4099, 291, 264, 1190, 18639, 13, 51238], "temperature": 0.0, "avg_logprob": -0.2317652883408945, "compression_ratio": 1.595, "no_speech_prob": 0.011708422563970089}, {"id": 172, "seek": 82416, "start": 841.64, "end": 845.48, "text": " I'm saying that because I've seen a lot of people comparing the load average with the", "tokens": [51238, 286, 478, 1566, 300, 570, 286, 600, 1612, 257, 688, 295, 561, 15763, 264, 3677, 4274, 365, 264, 51430], "temperature": 0.0, "avg_logprob": -0.2317652883408945, "compression_ratio": 1.595, "no_speech_prob": 0.011708422563970089}, {"id": 173, "seek": 82416, "start": 845.48, "end": 846.7199999999999, "text": " number of CPU.", "tokens": [51430, 1230, 295, 13199, 13, 51492], "temperature": 0.0, "avg_logprob": -0.2317652883408945, "compression_ratio": 1.595, "no_speech_prob": 0.011708422563970089}, {"id": 174, "seek": 84672, "start": 846.72, "end": 853.96, "text": " Like if load average is higher than the number of CPU, I have a problem.", "tokens": [50364, 1743, 498, 3677, 4274, 307, 2946, 813, 264, 1230, 295, 13199, 11, 286, 362, 257, 1154, 13, 50726], "temperature": 0.0, "avg_logprob": -0.17277009920640427, "compression_ratio": 1.7462686567164178, "no_speech_prob": 0.19145119190216064}, {"id": 175, "seek": 84672, "start": 853.96, "end": 858.96, "text": " Maybe not because if the load average is due to IO, you don't really care about comparing", "tokens": [50726, 2704, 406, 570, 498, 264, 3677, 4274, 307, 3462, 281, 39839, 11, 291, 500, 380, 534, 1127, 466, 15763, 50976], "temperature": 0.0, "avg_logprob": -0.17277009920640427, "compression_ratio": 1.7462686567164178, "no_speech_prob": 0.19145119190216064}, {"id": 176, "seek": 84672, "start": 858.96, "end": 860.84, "text": " with the CPU.", "tokens": [50976, 365, 264, 13199, 13, 51070], "temperature": 0.0, "avg_logprob": -0.17277009920640427, "compression_ratio": 1.7462686567164178, "no_speech_prob": 0.19145119190216064}, {"id": 177, "seek": 84672, "start": 860.84, "end": 866.96, "text": " And if the load average is high because you have a lot of processes in the run queue,", "tokens": [51070, 400, 498, 264, 3677, 4274, 307, 1090, 570, 291, 362, 257, 688, 295, 7555, 294, 264, 1190, 18639, 11, 51376], "temperature": 0.0, "avg_logprob": -0.17277009920640427, "compression_ratio": 1.7462686567164178, "no_speech_prob": 0.19145119190216064}, {"id": 178, "seek": 84672, "start": 866.96, "end": 871.48, "text": " then probably you have a problem because you have tasks who need to run something on the", "tokens": [51376, 550, 1391, 291, 362, 257, 1154, 570, 291, 362, 9608, 567, 643, 281, 1190, 746, 322, 264, 51602], "temperature": 0.0, "avg_logprob": -0.17277009920640427, "compression_ratio": 1.7462686567164178, "no_speech_prob": 0.19145119190216064}, {"id": 179, "seek": 87148, "start": 871.48, "end": 879.16, "text": " CPU and just cannot and are waiting in behind.", "tokens": [50364, 13199, 293, 445, 2644, 293, 366, 3806, 294, 2261, 13, 50748], "temperature": 0.0, "avg_logprob": -0.23236844625817724, "compression_ratio": 1.6567164179104477, "no_speech_prob": 0.08978252112865448}, {"id": 180, "seek": 87148, "start": 879.16, "end": 884.72, "text": " So we have seen different kinds of IOs and they look differently.", "tokens": [50748, 407, 321, 362, 1612, 819, 3685, 295, 39839, 82, 293, 436, 574, 7614, 13, 51026], "temperature": 0.0, "avg_logprob": -0.23236844625817724, "compression_ratio": 1.6567164179104477, "no_speech_prob": 0.08978252112865448}, {"id": 181, "seek": 87148, "start": 884.72, "end": 891.76, "text": " Many times where I've seen, especially on databases, where I've seen different teams,", "tokens": [51026, 5126, 1413, 689, 286, 600, 1612, 11, 2318, 322, 22380, 11, 689, 286, 600, 1612, 819, 5491, 11, 51378], "temperature": 0.0, "avg_logprob": -0.23236844625817724, "compression_ratio": 1.6567164179104477, "no_speech_prob": 0.08978252112865448}, {"id": 182, "seek": 87148, "start": 891.76, "end": 897.12, "text": " the Linux team looking at the system and the DBA team looking at the database.", "tokens": [51378, 264, 18734, 1469, 1237, 412, 264, 1185, 293, 264, 413, 9295, 1469, 1237, 412, 264, 8149, 13, 51646], "temperature": 0.0, "avg_logprob": -0.23236844625817724, "compression_ratio": 1.6567164179104477, "no_speech_prob": 0.08978252112865448}, {"id": 183, "seek": 87148, "start": 897.12, "end": 899.84, "text": " And in many companies, they don't really talk together.", "tokens": [51646, 400, 294, 867, 3431, 11, 436, 500, 380, 534, 751, 1214, 13, 51782], "temperature": 0.0, "avg_logprob": -0.23236844625817724, "compression_ratio": 1.6567164179104477, "no_speech_prob": 0.08978252112865448}, {"id": 184, "seek": 89984, "start": 899.84, "end": 907.84, "text": " So one is guessing what the other is doing and a lot of misinterpretation on all that.", "tokens": [50364, 407, 472, 307, 17939, 437, 264, 661, 307, 884, 293, 257, 688, 295, 3346, 41935, 399, 322, 439, 300, 13, 50764], "temperature": 0.0, "avg_logprob": -0.10078545738669002, "compression_ratio": 1.797029702970297, "no_speech_prob": 0.07381894439458847}, {"id": 185, "seek": 89984, "start": 907.84, "end": 912.2, "text": " It's very important if you look at the numbers from the system to understand what the database", "tokens": [50764, 467, 311, 588, 1021, 498, 291, 574, 412, 264, 3547, 490, 264, 1185, 281, 1223, 437, 264, 8149, 50982], "temperature": 0.0, "avg_logprob": -0.10078545738669002, "compression_ratio": 1.797029702970297, "no_speech_prob": 0.07381894439458847}, {"id": 186, "seek": 89984, "start": 912.2, "end": 913.2, "text": " is doing.", "tokens": [50982, 307, 884, 13, 51032], "temperature": 0.0, "avg_logprob": -0.10078545738669002, "compression_ratio": 1.797029702970297, "no_speech_prob": 0.07381894439458847}, {"id": 187, "seek": 89984, "start": 913.2, "end": 918.2, "text": " And also it's very important for the database administrator to look at the system because", "tokens": [51032, 400, 611, 309, 311, 588, 1021, 337, 264, 8149, 25529, 281, 574, 412, 264, 1185, 570, 51282], "temperature": 0.0, "avg_logprob": -0.10078545738669002, "compression_ratio": 1.797029702970297, "no_speech_prob": 0.07381894439458847}, {"id": 188, "seek": 89984, "start": 918.2, "end": 926.96, "text": " many things in the database metric will be different if the system is overloaded.", "tokens": [51282, 867, 721, 294, 264, 8149, 20678, 486, 312, 819, 498, 264, 1185, 307, 28777, 292, 13, 51720], "temperature": 0.0, "avg_logprob": -0.10078545738669002, "compression_ratio": 1.797029702970297, "no_speech_prob": 0.07381894439458847}, {"id": 189, "seek": 92696, "start": 926.96, "end": 932.48, "text": " I give a quick example on Oracle, you have wait events where you can know exactly how", "tokens": [50364, 286, 976, 257, 1702, 1365, 322, 25654, 11, 291, 362, 1699, 3931, 689, 291, 393, 458, 2293, 577, 50640], "temperature": 0.0, "avg_logprob": -0.14261922997943424, "compression_ratio": 1.8132780082987552, "no_speech_prob": 0.43746310472488403}, {"id": 190, "seek": 92696, "start": 932.48, "end": 934.76, "text": " much time you spend on IO.", "tokens": [50640, 709, 565, 291, 3496, 322, 39839, 13, 50754], "temperature": 0.0, "avg_logprob": -0.14261922997943424, "compression_ratio": 1.8132780082987552, "no_speech_prob": 0.43746310472488403}, {"id": 191, "seek": 92696, "start": 934.76, "end": 938.0400000000001, "text": " But it's not exactly how much time you spend on IO.", "tokens": [50754, 583, 309, 311, 406, 2293, 577, 709, 565, 291, 3496, 322, 39839, 13, 50918], "temperature": 0.0, "avg_logprob": -0.14261922997943424, "compression_ratio": 1.8132780082987552, "no_speech_prob": 0.43746310472488403}, {"id": 192, "seek": 92696, "start": 938.0400000000001, "end": 943.1600000000001, "text": " It's how much time between the time stamp it takes before the IO and after the IO.", "tokens": [50918, 467, 311, 577, 709, 565, 1296, 264, 565, 9921, 309, 2516, 949, 264, 39839, 293, 934, 264, 39839, 13, 51174], "temperature": 0.0, "avg_logprob": -0.14261922997943424, "compression_ratio": 1.8132780082987552, "no_speech_prob": 0.43746310472488403}, {"id": 193, "seek": 92696, "start": 943.1600000000001, "end": 950.2800000000001, "text": " If your process is in the run queue, the database thinks that it is doing IO, but maybe the", "tokens": [51174, 759, 428, 1399, 307, 294, 264, 1190, 18639, 11, 264, 8149, 7309, 300, 309, 307, 884, 39839, 11, 457, 1310, 264, 51530], "temperature": 0.0, "avg_logprob": -0.14261922997943424, "compression_ratio": 1.8132780082987552, "no_speech_prob": 0.43746310472488403}, {"id": 194, "seek": 92696, "start": 950.2800000000001, "end": 955.08, "text": " IO is done and it's just waiting to go back to the CPU just to set the counter on the", "tokens": [51530, 39839, 307, 1096, 293, 309, 311, 445, 3806, 281, 352, 646, 281, 264, 13199, 445, 281, 992, 264, 5682, 322, 264, 51770], "temperature": 0.0, "avg_logprob": -0.14261922997943424, "compression_ratio": 1.8132780082987552, "no_speech_prob": 0.43746310472488403}, {"id": 195, "seek": 92696, "start": 955.08, "end": 956.08, "text": " time stamp.", "tokens": [51770, 565, 9921, 13, 51820], "temperature": 0.0, "avg_logprob": -0.14261922997943424, "compression_ratio": 1.8132780082987552, "no_speech_prob": 0.43746310472488403}, {"id": 196, "seek": 95608, "start": 956.08, "end": 958.0, "text": " So that's also the message.", "tokens": [50364, 407, 300, 311, 611, 264, 3636, 13, 50460], "temperature": 0.0, "avg_logprob": -0.21085324654212365, "compression_ratio": 1.5546875, "no_speech_prob": 0.013779685832560062}, {"id": 197, "seek": 95608, "start": 958.0, "end": 962.76, "text": " I say that to database administrator, but applications, if you run on a system that", "tokens": [50460, 286, 584, 300, 281, 8149, 25529, 11, 457, 5821, 11, 498, 291, 1190, 322, 257, 1185, 300, 50698], "temperature": 0.0, "avg_logprob": -0.21085324654212365, "compression_ratio": 1.5546875, "no_speech_prob": 0.013779685832560062}, {"id": 198, "seek": 95608, "start": 962.76, "end": 968.32, "text": " is overloaded in CPU, then probably all of their metrics, because they require CPU cycles", "tokens": [50698, 307, 28777, 292, 294, 13199, 11, 550, 1391, 439, 295, 641, 16367, 11, 570, 436, 3651, 13199, 17796, 50976], "temperature": 0.0, "avg_logprob": -0.21085324654212365, "compression_ratio": 1.5546875, "no_speech_prob": 0.013779685832560062}, {"id": 199, "seek": 95608, "start": 968.32, "end": 972.72, "text": " to get the number are probably wrong.", "tokens": [50976, 281, 483, 264, 1230, 366, 1391, 2085, 13, 51196], "temperature": 0.0, "avg_logprob": -0.21085324654212365, "compression_ratio": 1.5546875, "no_speech_prob": 0.013779685832560062}, {"id": 200, "seek": 95608, "start": 972.72, "end": 975.48, "text": " So why did I call that silly metrics?", "tokens": [51196, 407, 983, 630, 286, 818, 300, 11774, 16367, 30, 51334], "temperature": 0.0, "avg_logprob": -0.21085324654212365, "compression_ratio": 1.5546875, "no_speech_prob": 0.013779685832560062}, {"id": 201, "seek": 95608, "start": 975.48, "end": 978.4000000000001, "text": " I didn't came with this.", "tokens": [51334, 286, 994, 380, 1361, 365, 341, 13, 51480], "temperature": 0.0, "avg_logprob": -0.21085324654212365, "compression_ratio": 1.5546875, "no_speech_prob": 0.013779685832560062}, {"id": 202, "seek": 95608, "start": 978.4000000000001, "end": 985.4000000000001, "text": " If you want to understand what is what low-dverage measures, Linux is open source, so just look", "tokens": [51480, 759, 291, 528, 281, 1223, 437, 307, 437, 2295, 12, 67, 3623, 8000, 11, 18734, 307, 1269, 4009, 11, 370, 445, 574, 51830], "temperature": 0.0, "avg_logprob": -0.21085324654212365, "compression_ratio": 1.5546875, "no_speech_prob": 0.013779685832560062}, {"id": 203, "seek": 98540, "start": 985.4, "end": 987.8, "text": " at the source of it.", "tokens": [50364, 412, 264, 4009, 295, 309, 13, 50484], "temperature": 0.0, "avg_logprob": -0.2442743713791306, "compression_ratio": 1.7039106145251397, "no_speech_prob": 0.01191599853336811}, {"id": 204, "seek": 98540, "start": 987.8, "end": 993.92, "text": " And you can look at the source, but more interesting are the comments which can explain the intention", "tokens": [50484, 400, 291, 393, 574, 412, 264, 4009, 11, 457, 544, 1880, 366, 264, 3053, 597, 393, 2903, 264, 7789, 50790], "temperature": 0.0, "avg_logprob": -0.2442743713791306, "compression_ratio": 1.7039106145251397, "no_speech_prob": 0.01191599853336811}, {"id": 205, "seek": 98540, "start": 993.92, "end": 995.4399999999999, "text": " of the function.", "tokens": [50790, 295, 264, 2445, 13, 50866], "temperature": 0.0, "avg_logprob": -0.2442743713791306, "compression_ratio": 1.7039106145251397, "no_speech_prob": 0.01191599853336811}, {"id": 206, "seek": 98540, "start": 995.4399999999999, "end": 1003.64, "text": " And so in Linux, the load average is defined as this file, so the source for load average", "tokens": [50866, 400, 370, 294, 18734, 11, 264, 3677, 4274, 307, 7642, 382, 341, 3991, 11, 370, 264, 4009, 337, 3677, 4274, 51276], "temperature": 0.0, "avg_logprob": -0.2442743713791306, "compression_ratio": 1.7039106145251397, "no_speech_prob": 0.01191599853336811}, {"id": 207, "seek": 98540, "start": 1003.64, "end": 1011.4, "text": " contains the magic bits required to compute the global load average figure.", "tokens": [51276, 8306, 264, 5585, 9239, 4739, 281, 14722, 264, 4338, 3677, 4274, 2573, 13, 51664], "temperature": 0.0, "avg_logprob": -0.2442743713791306, "compression_ratio": 1.7039106145251397, "no_speech_prob": 0.01191599853336811}, {"id": 208, "seek": 101140, "start": 1011.4, "end": 1015.68, "text": " It is a symmetric, but people think it is important.", "tokens": [50364, 467, 307, 257, 32330, 11, 457, 561, 519, 309, 307, 1021, 13, 50578], "temperature": 0.0, "avg_logprob": -0.21978386243184408, "compression_ratio": 1.5568862275449102, "no_speech_prob": 0.128037229180336}, {"id": 209, "seek": 101140, "start": 1015.68, "end": 1021.24, "text": " So you see why you see that first in top?", "tokens": [50578, 407, 291, 536, 983, 291, 536, 300, 700, 294, 1192, 30, 50856], "temperature": 0.0, "avg_logprob": -0.21978386243184408, "compression_ratio": 1.5568862275449102, "no_speech_prob": 0.128037229180336}, {"id": 210, "seek": 101140, "start": 1021.24, "end": 1028.28, "text": " It is silly, but some people think it is important, so let's give them something.", "tokens": [50856, 467, 307, 11774, 11, 457, 512, 561, 519, 309, 307, 1021, 11, 370, 718, 311, 976, 552, 746, 13, 51208], "temperature": 0.0, "avg_logprob": -0.21978386243184408, "compression_ratio": 1.5568862275449102, "no_speech_prob": 0.128037229180336}, {"id": 211, "seek": 101140, "start": 1028.28, "end": 1033.96, "text": " And we go through the grid pane to make it work on big machine with T-class kernel.", "tokens": [51208, 400, 321, 352, 807, 264, 10748, 32605, 281, 652, 309, 589, 322, 955, 3479, 365, 314, 12, 11665, 28256, 13, 51492], "temperature": 0.0, "avg_logprob": -0.21978386243184408, "compression_ratio": 1.5568862275449102, "no_speech_prob": 0.128037229180336}, {"id": 212, "seek": 103396, "start": 1033.96, "end": 1042.88, "text": " So the load average idea comes from Unix systems where it was really measuring the load in", "tokens": [50364, 407, 264, 3677, 4274, 1558, 1487, 490, 1156, 970, 3652, 689, 309, 390, 534, 13389, 264, 3677, 294, 50810], "temperature": 0.0, "avg_logprob": -0.3274293706036996, "compression_ratio": 1.5604395604395604, "no_speech_prob": 0.8406543135643005}, {"id": 213, "seek": 103396, "start": 1042.88, "end": 1051.24, "text": " CPU and where it was easier to measure it because you just counted the ticks in the", "tokens": [50810, 13199, 293, 689, 309, 390, 3571, 281, 3481, 309, 570, 291, 445, 20150, 264, 42475, 294, 264, 51228], "temperature": 0.0, "avg_logprob": -0.3274293706036996, "compression_ratio": 1.5604395604395604, "no_speech_prob": 0.8406543135643005}, {"id": 214, "seek": 103396, "start": 1051.24, "end": 1052.24, "text": " scheduler.", "tokens": [51228, 12000, 260, 13, 51278], "temperature": 0.0, "avg_logprob": -0.3274293706036996, "compression_ratio": 1.5604395604395604, "no_speech_prob": 0.8406543135643005}, {"id": 215, "seek": 103396, "start": 1052.24, "end": 1058.92, "text": " Linux works differently and means that it is difficult to measure and maybe it makes", "tokens": [51278, 18734, 1985, 7614, 293, 1355, 300, 309, 307, 2252, 281, 3481, 293, 1310, 309, 1669, 51612], "temperature": 0.0, "avg_logprob": -0.3274293706036996, "compression_ratio": 1.5604395604395604, "no_speech_prob": 0.8406543135643005}, {"id": 216, "seek": 103396, "start": 1058.92, "end": 1062.4, "text": " no big sense.", "tokens": [51612, 572, 955, 2020, 13, 51786], "temperature": 0.0, "avg_logprob": -0.3274293706036996, "compression_ratio": 1.5604395604395604, "no_speech_prob": 0.8406543135643005}, {"id": 217, "seek": 106240, "start": 1062.4, "end": 1067.76, "text": " So yeah, good to know why this metric is there just because people coming from Unix", "tokens": [50364, 407, 1338, 11, 665, 281, 458, 983, 341, 20678, 307, 456, 445, 570, 561, 1348, 490, 1156, 970, 50632], "temperature": 0.0, "avg_logprob": -0.19557267847195478, "compression_ratio": 1.572972972972973, "no_speech_prob": 0.12422129511833191}, {"id": 218, "seek": 106240, "start": 1067.76, "end": 1074.0800000000002, "text": " were used to have this single graph showing the load and compare that with the application", "tokens": [50632, 645, 1143, 281, 362, 341, 2167, 4295, 4099, 264, 3677, 293, 6794, 300, 365, 264, 3861, 50948], "temperature": 0.0, "avg_logprob": -0.19557267847195478, "compression_ratio": 1.572972972972973, "no_speech_prob": 0.12422129511833191}, {"id": 219, "seek": 106240, "start": 1074.0800000000002, "end": 1080.16, "text": " and what is done in the application, but if you don't look at the state of the processes,", "tokens": [50948, 293, 437, 307, 1096, 294, 264, 3861, 11, 457, 498, 291, 500, 380, 574, 412, 264, 1785, 295, 264, 7555, 11, 51252], "temperature": 0.0, "avg_logprob": -0.19557267847195478, "compression_ratio": 1.572972972972973, "no_speech_prob": 0.12422129511833191}, {"id": 220, "seek": 106240, "start": 1080.16, "end": 1082.64, "text": " then it can be misleading.", "tokens": [51252, 550, 309, 393, 312, 36429, 13, 51376], "temperature": 0.0, "avg_logprob": -0.19557267847195478, "compression_ratio": 1.572972972972973, "no_speech_prob": 0.12422129511833191}, {"id": 221, "seek": 108264, "start": 1082.64, "end": 1094.5200000000002, "text": " It's easy to understand exactly why we see this state, these IOCOLs in the load average,", "tokens": [50364, 467, 311, 1858, 281, 1223, 2293, 983, 321, 536, 341, 1785, 11, 613, 286, 30087, 5046, 82, 294, 264, 3677, 4274, 11, 50958], "temperature": 0.0, "avg_logprob": -0.1927096995901554, "compression_ratio": 1.6730769230769231, "no_speech_prob": 0.5142266154289246}, {"id": 222, "seek": 108264, "start": 1094.5200000000002, "end": 1095.5200000000002, "text": " just the way it is calculated.", "tokens": [50958, 445, 264, 636, 309, 307, 15598, 13, 51008], "temperature": 0.0, "avg_logprob": -0.1927096995901554, "compression_ratio": 1.6730769230769231, "no_speech_prob": 0.5142266154289246}, {"id": 223, "seek": 108264, "start": 1095.5200000000002, "end": 1098.76, "text": " There are two things that are interested in the way it is calculated.", "tokens": [51008, 821, 366, 732, 721, 300, 366, 3102, 294, 264, 636, 309, 307, 15598, 13, 51170], "temperature": 0.0, "avg_logprob": -0.1927096995901554, "compression_ratio": 1.6730769230769231, "no_speech_prob": 0.5142266154289246}, {"id": 224, "seek": 108264, "start": 1098.76, "end": 1101.8400000000001, "text": " First, it is an average and that's also a problem.", "tokens": [51170, 2386, 11, 309, 307, 364, 4274, 293, 300, 311, 611, 257, 1154, 13, 51324], "temperature": 0.0, "avg_logprob": -0.1927096995901554, "compression_ratio": 1.6730769230769231, "no_speech_prob": 0.5142266154289246}, {"id": 225, "seek": 108264, "start": 1101.8400000000001, "end": 1105.5600000000002, "text": " If you look at the load average, you will not see a peak of activity of five seconds", "tokens": [51324, 759, 291, 574, 412, 264, 3677, 4274, 11, 291, 486, 406, 536, 257, 10651, 295, 5191, 295, 1732, 3949, 51510], "temperature": 0.0, "avg_logprob": -0.1927096995901554, "compression_ratio": 1.6730769230769231, "no_speech_prob": 0.5142266154289246}, {"id": 226, "seek": 108264, "start": 1105.5600000000002, "end": 1107.5600000000002, "text": " because it is average.", "tokens": [51510, 570, 309, 307, 4274, 13, 51610], "temperature": 0.0, "avg_logprob": -0.1927096995901554, "compression_ratio": 1.6730769230769231, "no_speech_prob": 0.5142266154289246}, {"id": 227, "seek": 110756, "start": 1108.2, "end": 1115.8, "text": " The other thing is that it counts the number of active, so the running state, which is", "tokens": [50396, 440, 661, 551, 307, 300, 309, 14893, 264, 1230, 295, 4967, 11, 370, 264, 2614, 1785, 11, 597, 307, 50776], "temperature": 0.0, "avg_logprob": -0.2659873552219842, "compression_ratio": 1.6136363636363635, "no_speech_prob": 0.28136202692985535}, {"id": 228, "seek": 110756, "start": 1115.8, "end": 1121.0, "text": " more renewable because if you are in the run queue, you are not really running and it has", "tokens": [50776, 544, 20938, 570, 498, 291, 366, 294, 264, 1190, 18639, 11, 291, 366, 406, 534, 2614, 293, 309, 575, 51036], "temperature": 0.0, "avg_logprob": -0.2659873552219842, "compression_ratio": 1.6136363636363635, "no_speech_prob": 0.28136202692985535}, {"id": 229, "seek": 110756, "start": 1121.0, "end": 1129.44, "text": " the uninterruptible calls just because they thought that if we show only the CPU load,", "tokens": [51036, 264, 517, 5106, 5428, 964, 5498, 445, 570, 436, 1194, 300, 498, 321, 855, 787, 264, 13199, 3677, 11, 51458], "temperature": 0.0, "avg_logprob": -0.2659873552219842, "compression_ratio": 1.6136363636363635, "no_speech_prob": 0.28136202692985535}, {"id": 230, "seek": 110756, "start": 1129.44, "end": 1131.0, "text": " is it really the load of the machine?", "tokens": [51458, 307, 309, 534, 264, 3677, 295, 264, 3479, 30, 51536], "temperature": 0.0, "avg_logprob": -0.2659873552219842, "compression_ratio": 1.6136363636363635, "no_speech_prob": 0.28136202692985535}, {"id": 231, "seek": 110756, "start": 1131.0, "end": 1134.1599999999999, "text": " For example, you run a database doing a lot of IOCOL.", "tokens": [51536, 1171, 1365, 11, 291, 1190, 257, 8149, 884, 257, 688, 295, 286, 30087, 5046, 13, 51694], "temperature": 0.0, "avg_logprob": -0.2659873552219842, "compression_ratio": 1.6136363636363635, "no_speech_prob": 0.28136202692985535}, {"id": 232, "seek": 113416, "start": 1134.16, "end": 1139.8400000000001, "text": " Then we say that the load is low if everyone is waiting on the disk.", "tokens": [50364, 1396, 321, 584, 300, 264, 3677, 307, 2295, 498, 1518, 307, 3806, 322, 264, 12355, 13, 50648], "temperature": 0.0, "avg_logprob": -0.21715690408434188, "compression_ratio": 1.6290322580645162, "no_speech_prob": 0.014220197685062885}, {"id": 233, "seek": 113416, "start": 1139.8400000000001, "end": 1147.0800000000002, "text": " Let's add an interoptable because in many cases, we have seen that those IOCOLs are", "tokens": [50648, 961, 311, 909, 364, 728, 5747, 712, 570, 294, 867, 3331, 11, 321, 362, 1612, 300, 729, 286, 30087, 5046, 82, 366, 51010], "temperature": 0.0, "avg_logprob": -0.21715690408434188, "compression_ratio": 1.6290322580645162, "no_speech_prob": 0.014220197685062885}, {"id": 234, "seek": 113416, "start": 1147.0800000000002, "end": 1153.44, "text": " uninterruptible calls, but they are not always, so it can be quite misleading.", "tokens": [51010, 517, 5106, 5428, 964, 5498, 11, 457, 436, 366, 406, 1009, 11, 370, 309, 393, 312, 1596, 36429, 13, 51328], "temperature": 0.0, "avg_logprob": -0.21715690408434188, "compression_ratio": 1.6290322580645162, "no_speech_prob": 0.014220197685062885}, {"id": 235, "seek": 113416, "start": 1153.44, "end": 1158.3200000000002, "text": " It doesn't mean that you don't have to look at it, but if you look at it and know what", "tokens": [51328, 467, 1177, 380, 914, 300, 291, 500, 380, 362, 281, 574, 412, 309, 11, 457, 498, 291, 574, 412, 309, 293, 458, 437, 51572], "temperature": 0.0, "avg_logprob": -0.21715690408434188, "compression_ratio": 1.6290322580645162, "no_speech_prob": 0.014220197685062885}, {"id": 236, "seek": 113416, "start": 1158.3200000000002, "end": 1163.88, "text": " is behind, then it can give you some clues like the clue about IOCOL looking at other", "tokens": [51572, 307, 2261, 11, 550, 309, 393, 976, 291, 512, 20936, 411, 264, 13602, 466, 286, 30087, 5046, 1237, 412, 661, 51850], "temperature": 0.0, "avg_logprob": -0.21715690408434188, "compression_ratio": 1.6290322580645162, "no_speech_prob": 0.014220197685062885}, {"id": 237, "seek": 116388, "start": 1163.92, "end": 1168.0, "text": " things, but more interesting is the process state.", "tokens": [50366, 721, 11, 457, 544, 1880, 307, 264, 1399, 1785, 13, 50570], "temperature": 0.0, "avg_logprob": -0.22048851613248333, "compression_ratio": 1.655813953488372, "no_speech_prob": 0.04425148665904999}, {"id": 238, "seek": 116388, "start": 1168.0, "end": 1173.68, "text": " A process can have something to run in the CPU and then look at the scheduler statistics", "tokens": [50570, 316, 1399, 393, 362, 746, 281, 1190, 294, 264, 13199, 293, 550, 574, 412, 264, 12000, 260, 12523, 50854], "temperature": 0.0, "avg_logprob": -0.22048851613248333, "compression_ratio": 1.655813953488372, "no_speech_prob": 0.04425148665904999}, {"id": 239, "seek": 116388, "start": 1173.68, "end": 1179.72, "text": " knowing if it waits for the CPU or there is CPU available and when it has some calls", "tokens": [50854, 5276, 498, 309, 40597, 337, 264, 13199, 420, 456, 307, 13199, 2435, 293, 562, 309, 575, 512, 5498, 51156], "temperature": 0.0, "avg_logprob": -0.22048851613248333, "compression_ratio": 1.655813953488372, "no_speech_prob": 0.04425148665904999}, {"id": 240, "seek": 116388, "start": 1179.72, "end": 1186.24, "text": " to do, they can be done in this state or as state and they will be accounted differently", "tokens": [51156, 281, 360, 11, 436, 393, 312, 1096, 294, 341, 1785, 420, 382, 1785, 293, 436, 486, 312, 43138, 7614, 51482], "temperature": 0.0, "avg_logprob": -0.22048851613248333, "compression_ratio": 1.655813953488372, "no_speech_prob": 0.04425148665904999}, {"id": 241, "seek": 116388, "start": 1186.24, "end": 1190.2, "text": " by the load average.", "tokens": [51482, 538, 264, 3677, 4274, 13, 51680], "temperature": 0.0, "avg_logprob": -0.22048851613248333, "compression_ratio": 1.655813953488372, "no_speech_prob": 0.04425148665904999}, {"id": 242, "seek": 116388, "start": 1190.2, "end": 1192.2, "text": " Any questions so far?", "tokens": [51680, 2639, 1651, 370, 1400, 30, 51780], "temperature": 0.0, "avg_logprob": -0.22048851613248333, "compression_ratio": 1.655813953488372, "no_speech_prob": 0.04425148665904999}, {"id": 243, "seek": 119220, "start": 1193.2, "end": 1200.88, "text": " Okay, the next one is more about memory just because it's another thing that is misleading", "tokens": [50414, 1033, 11, 264, 958, 472, 307, 544, 466, 4675, 445, 570, 309, 311, 1071, 551, 300, 307, 36429, 50798], "temperature": 0.0, "avg_logprob": -0.20959985428962155, "compression_ratio": 1.5642458100558658, "no_speech_prob": 0.007594470866024494}, {"id": 244, "seek": 119220, "start": 1200.88, "end": 1204.2, "text": " in some cases.", "tokens": [50798, 294, 512, 3331, 13, 50964], "temperature": 0.0, "avg_logprob": -0.20959985428962155, "compression_ratio": 1.5642458100558658, "no_speech_prob": 0.007594470866024494}, {"id": 245, "seek": 119220, "start": 1204.2, "end": 1210.0, "text": " I think it is quite clear in top that you can look at the available memory, but I see", "tokens": [50964, 286, 519, 309, 307, 1596, 1850, 294, 1192, 300, 291, 393, 574, 412, 264, 2435, 4675, 11, 457, 286, 536, 51254], "temperature": 0.0, "avg_logprob": -0.20959985428962155, "compression_ratio": 1.5642458100558658, "no_speech_prob": 0.007594470866024494}, {"id": 246, "seek": 119220, "start": 1210.0, "end": 1216.44, "text": " cloud provider showing the use memory or the free memory and here I just want to explain", "tokens": [51254, 4588, 12398, 4099, 264, 764, 4675, 420, 264, 1737, 4675, 293, 510, 286, 445, 528, 281, 2903, 51576], "temperature": 0.0, "avg_logprob": -0.20959985428962155, "compression_ratio": 1.5642458100558658, "no_speech_prob": 0.007594470866024494}, {"id": 247, "seek": 121644, "start": 1216.44, "end": 1224.44, "text": " for those who don't know, if you do buffered IO like I did with direct equal zero.", "tokens": [50364, 337, 729, 567, 500, 380, 458, 11, 498, 291, 360, 9204, 4073, 39839, 411, 286, 630, 365, 2047, 2681, 4018, 13, 50764], "temperature": 0.0, "avg_logprob": -0.3622450450110057, "compression_ratio": 1.3398692810457515, "no_speech_prob": 0.07619936764240265}, {"id": 248, "seek": 121644, "start": 1224.44, "end": 1230.44, "text": " Okay, I thought we have five minutes now.", "tokens": [50764, 1033, 11, 286, 1194, 321, 362, 1732, 2077, 586, 13, 51064], "temperature": 0.0, "avg_logprob": -0.3622450450110057, "compression_ratio": 1.3398692810457515, "no_speech_prob": 0.07619936764240265}, {"id": 249, "seek": 121644, "start": 1230.44, "end": 1235.44, "text": " Okay, perfect.", "tokens": [51064, 1033, 11, 2176, 13, 51314], "temperature": 0.0, "avg_logprob": -0.3622450450110057, "compression_ratio": 1.3398692810457515, "no_speech_prob": 0.07619936764240265}, {"id": 250, "seek": 121644, "start": 1235.44, "end": 1237.44, "text": " So I will finish quickly on that.", "tokens": [51314, 407, 286, 486, 2413, 2661, 322, 300, 13, 51414], "temperature": 0.0, "avg_logprob": -0.3622450450110057, "compression_ratio": 1.3398692810457515, "no_speech_prob": 0.07619936764240265}, {"id": 251, "seek": 121644, "start": 1237.44, "end": 1240.44, "text": " Do not look at the free memory.", "tokens": [51414, 1144, 406, 574, 412, 264, 1737, 4675, 13, 51564], "temperature": 0.0, "avg_logprob": -0.3622450450110057, "compression_ratio": 1.3398692810457515, "no_speech_prob": 0.07619936764240265}, {"id": 252, "seek": 124044, "start": 1240.44, "end": 1247.44, "text": " I'm just showing that if I do some IOs, it will take some free memory, but that is easily", "tokens": [50364, 286, 478, 445, 4099, 300, 498, 286, 360, 512, 39839, 82, 11, 309, 486, 747, 512, 1737, 4675, 11, 457, 300, 307, 3612, 50714], "temperature": 0.0, "avg_logprob": -0.12566201765458662, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.06599875539541245}, {"id": 253, "seek": 124044, "start": 1247.44, "end": 1251.44, "text": " freed if it needs look at the available memory.", "tokens": [50714, 21796, 498, 309, 2203, 574, 412, 264, 2435, 4675, 13, 50914], "temperature": 0.0, "avg_logprob": -0.12566201765458662, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.06599875539541245}, {"id": 254, "seek": 124044, "start": 1251.44, "end": 1257.44, "text": " That's the memory that is available to your process, but also think that it is available.", "tokens": [50914, 663, 311, 264, 4675, 300, 307, 2435, 281, 428, 1399, 11, 457, 611, 519, 300, 309, 307, 2435, 13, 51214], "temperature": 0.0, "avg_logprob": -0.12566201765458662, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.06599875539541245}, {"id": 255, "seek": 124044, "start": 1257.44, "end": 1263.44, "text": " You can use it, but if you use it, then another process doing buffered IO may not find its", "tokens": [51214, 509, 393, 764, 309, 11, 457, 498, 291, 764, 309, 11, 550, 1071, 1399, 884, 9204, 4073, 39839, 815, 406, 915, 1080, 51514], "temperature": 0.0, "avg_logprob": -0.12566201765458662, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.06599875539541245}, {"id": 256, "seek": 124044, "start": 1263.44, "end": 1265.44, "text": " data in the case.", "tokens": [51514, 1412, 294, 264, 1389, 13, 51614], "temperature": 0.0, "avg_logprob": -0.12566201765458662, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.06599875539541245}, {"id": 257, "seek": 126544, "start": 1265.44, "end": 1272.44, "text": " So if it is available, doesn't mean that it's free from any impact on the others.", "tokens": [50364, 407, 498, 309, 307, 2435, 11, 1177, 380, 914, 300, 309, 311, 1737, 490, 604, 2712, 322, 264, 2357, 13, 50714], "temperature": 0.0, "avg_logprob": -0.22508017222086588, "compression_ratio": 1.4431137724550898, "no_speech_prob": 0.02340562641620636}, {"id": 258, "seek": 126544, "start": 1272.44, "end": 1281.44, "text": " Okay, I just put the last one while I'm talking and taking question.", "tokens": [50714, 1033, 11, 286, 445, 829, 264, 1036, 472, 1339, 286, 478, 1417, 293, 1940, 1168, 13, 51164], "temperature": 0.0, "avg_logprob": -0.22508017222086588, "compression_ratio": 1.4431137724550898, "no_speech_prob": 0.02340562641620636}, {"id": 259, "seek": 126544, "start": 1281.44, "end": 1289.44, "text": " The idea there was just to show a really silly program doing V fork that has nothing to do", "tokens": [51164, 440, 1558, 456, 390, 445, 281, 855, 257, 534, 11774, 1461, 884, 691, 17716, 300, 575, 1825, 281, 360, 51564], "temperature": 0.0, "avg_logprob": -0.22508017222086588, "compression_ratio": 1.4431137724550898, "no_speech_prob": 0.02340562641620636}, {"id": 260, "seek": 128944, "start": 1289.44, "end": 1295.44, "text": " with the data, but just to show that it will go to the state, it will increase the load", "tokens": [50364, 365, 264, 1412, 11, 457, 445, 281, 855, 300, 309, 486, 352, 281, 264, 1785, 11, 309, 486, 3488, 264, 3677, 50664], "temperature": 0.0, "avg_logprob": -0.21649415916371567, "compression_ratio": 1.8299595141700404, "no_speech_prob": 0.3375810384750366}, {"id": 261, "seek": 128944, "start": 1295.44, "end": 1300.44, "text": " average and that's the case I've seen in some system where the load average was thousands", "tokens": [50664, 4274, 293, 300, 311, 264, 1389, 286, 600, 1612, 294, 512, 1185, 689, 264, 3677, 4274, 390, 5383, 50914], "temperature": 0.0, "avg_logprob": -0.21649415916371567, "compression_ratio": 1.8299595141700404, "no_speech_prob": 0.3375810384750366}, {"id": 262, "seek": 128944, "start": 1300.44, "end": 1308.44, "text": " on a database having its file on NFS and network issues and then those uninterruptible calls", "tokens": [50914, 322, 257, 8149, 1419, 1080, 3991, 322, 13576, 50, 293, 3209, 2663, 293, 550, 729, 517, 5106, 5428, 964, 5498, 51314], "temperature": 0.0, "avg_logprob": -0.21649415916371567, "compression_ratio": 1.8299595141700404, "no_speech_prob": 0.3375810384750366}, {"id": 263, "seek": 128944, "start": 1308.44, "end": 1313.44, "text": " increased the load average, but without any consequence because they weren't doing nothing.", "tokens": [51314, 6505, 264, 3677, 4274, 11, 457, 1553, 604, 18326, 570, 436, 4999, 380, 884, 1825, 13, 51564], "temperature": 0.0, "avg_logprob": -0.21649415916371567, "compression_ratio": 1.8299595141700404, "no_speech_prob": 0.3375810384750366}, {"id": 264, "seek": 128944, "start": 1313.44, "end": 1318.44, "text": " The only thing is that it's ugly when you look at the load average and the other thing is", "tokens": [51564, 440, 787, 551, 307, 300, 309, 311, 12246, 562, 291, 574, 412, 264, 3677, 4274, 293, 264, 661, 551, 307, 51814], "temperature": 0.0, "avg_logprob": -0.21649415916371567, "compression_ratio": 1.8299595141700404, "no_speech_prob": 0.3375810384750366}, {"id": 265, "seek": 131844, "start": 1318.44, "end": 1320.44, "text": " that they are uninterruptible.", "tokens": [50364, 300, 436, 366, 517, 5106, 5428, 964, 13, 50464], "temperature": 0.0, "avg_logprob": -0.21649100981562971, "compression_ratio": 1.5487179487179488, "no_speech_prob": 0.05934055894613266}, {"id": 266, "seek": 131844, "start": 1320.44, "end": 1322.44, "text": " You cannot kill them.", "tokens": [50464, 509, 2644, 1961, 552, 13, 50564], "temperature": 0.0, "avg_logprob": -0.21649100981562971, "compression_ratio": 1.5487179487179488, "no_speech_prob": 0.05934055894613266}, {"id": 267, "seek": 131844, "start": 1322.44, "end": 1330.44, "text": " So you want to restart the system to have nicer numbers, but of course you wait for it.", "tokens": [50564, 407, 291, 528, 281, 21022, 264, 1185, 281, 362, 22842, 3547, 11, 457, 295, 1164, 291, 1699, 337, 309, 13, 50964], "temperature": 0.0, "avg_logprob": -0.21649100981562971, "compression_ratio": 1.5487179487179488, "no_speech_prob": 0.05934055894613266}, {"id": 268, "seek": 131844, "start": 1330.44, "end": 1338.44, "text": " So just be careful, load average accounts some IO and accounts some CPU and you have some IO", "tokens": [50964, 407, 445, 312, 5026, 11, 3677, 4274, 9402, 512, 39839, 293, 9402, 512, 13199, 293, 291, 362, 512, 39839, 51364], "temperature": 0.0, "avg_logprob": -0.21649100981562971, "compression_ratio": 1.5487179487179488, "no_speech_prob": 0.05934055894613266}, {"id": 269, "seek": 131844, "start": 1338.44, "end": 1341.44, "text": " that you do not see there.", "tokens": [51364, 300, 291, 360, 406, 536, 456, 13, 51514], "temperature": 0.0, "avg_logprob": -0.21649100981562971, "compression_ratio": 1.5487179487179488, "no_speech_prob": 0.05934055894613266}, {"id": 270, "seek": 131844, "start": 1341.44, "end": 1345.44, "text": " Okay, do you have any questions, remarks?", "tokens": [51514, 1033, 11, 360, 291, 362, 604, 1651, 11, 19151, 30, 51714], "temperature": 0.0, "avg_logprob": -0.21649100981562971, "compression_ratio": 1.5487179487179488, "no_speech_prob": 0.05934055894613266}, {"id": 271, "seek": 134544, "start": 1345.44, "end": 1355.44, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 50864], "temperature": 0.4, "avg_logprob": -0.2389697347368513, "compression_ratio": 1.3983739837398375, "no_speech_prob": 0.039525408297777176}, {"id": 272, "seek": 134544, "start": 1355.44, "end": 1359.44, "text": " What about pressure stall information?", "tokens": [50864, 708, 466, 3321, 19633, 1589, 30, 51064], "temperature": 0.4, "avg_logprob": -0.2389697347368513, "compression_ratio": 1.3983739837398375, "no_speech_prob": 0.039525408297777176}, {"id": 273, "seek": 134544, "start": 1359.44, "end": 1361.44, "text": " Very good question.", "tokens": [51064, 4372, 665, 1168, 13, 51164], "temperature": 0.4, "avg_logprob": -0.2389697347368513, "compression_ratio": 1.3983739837398375, "no_speech_prob": 0.039525408297777176}, {"id": 274, "seek": 134544, "start": 1361.44, "end": 1367.44, "text": " If you have seen at the first screenshot I was running pressure stall information, which in my opinion", "tokens": [51164, 759, 291, 362, 1612, 412, 264, 700, 27712, 286, 390, 2614, 3321, 19633, 1589, 11, 597, 294, 452, 4800, 51464], "temperature": 0.4, "avg_logprob": -0.2389697347368513, "compression_ratio": 1.3983739837398375, "no_speech_prob": 0.039525408297777176}, {"id": 275, "seek": 136744, "start": 1367.44, "end": 1369.44, "text": " is a better picture.", "tokens": [50364, 307, 257, 1101, 3036, 13, 50464], "temperature": 0.0, "avg_logprob": -0.17635479221096287, "compression_ratio": 1.528205128205128, "no_speech_prob": 0.48663565516471863}, {"id": 276, "seek": 136744, "start": 1369.44, "end": 1377.44, "text": " The pressure stall information is counter telling you during the last 10 seconds, for example, how many,", "tokens": [50464, 440, 3321, 19633, 1589, 307, 5682, 3585, 291, 1830, 264, 1036, 1266, 3949, 11, 337, 1365, 11, 577, 867, 11, 50864], "temperature": 0.0, "avg_logprob": -0.17635479221096287, "compression_ratio": 1.528205128205128, "no_speech_prob": 0.48663565516471863}, {"id": 277, "seek": 136744, "start": 1377.44, "end": 1387.44, "text": " not how many, if there were some processes with pressure on CPU, so to run on CPU to get IO", "tokens": [50864, 406, 577, 867, 11, 498, 456, 645, 512, 7555, 365, 3321, 322, 13199, 11, 370, 281, 1190, 322, 13199, 281, 483, 39839, 51364], "temperature": 0.0, "avg_logprob": -0.17635479221096287, "compression_ratio": 1.528205128205128, "no_speech_prob": 0.48663565516471863}, {"id": 278, "seek": 136744, "start": 1387.44, "end": 1389.44, "text": " or to get some memory.", "tokens": [51364, 420, 281, 483, 512, 4675, 13, 51464], "temperature": 0.0, "avg_logprob": -0.17635479221096287, "compression_ratio": 1.528205128205128, "no_speech_prob": 0.48663565516471863}, {"id": 279, "seek": 136744, "start": 1389.44, "end": 1393.44, "text": " So it really gives you an idea about the pressure itself.", "tokens": [51464, 407, 309, 534, 2709, 291, 364, 1558, 466, 264, 3321, 2564, 13, 51664], "temperature": 0.0, "avg_logprob": -0.17635479221096287, "compression_ratio": 1.528205128205128, "no_speech_prob": 0.48663565516471863}, {"id": 280, "seek": 139344, "start": 1393.44, "end": 1401.44, "text": " The only thing about pressure stall information I have is that in most of the kernels, the distributions", "tokens": [50364, 440, 787, 551, 466, 3321, 19633, 1589, 286, 362, 307, 300, 294, 881, 295, 264, 23434, 1625, 11, 264, 37870, 50764], "temperature": 0.0, "avg_logprob": -0.09993265113052056, "compression_ratio": 1.7914691943127963, "no_speech_prob": 0.16000694036483765}, {"id": 281, "seek": 139344, "start": 1401.44, "end": 1405.44, "text": " I've seen, it is compiled in the kernel but not enabled by default.", "tokens": [50764, 286, 600, 1612, 11, 309, 307, 36548, 294, 264, 28256, 457, 406, 15172, 538, 7576, 13, 50964], "temperature": 0.0, "avg_logprob": -0.09993265113052056, "compression_ratio": 1.7914691943127963, "no_speech_prob": 0.16000694036483765}, {"id": 282, "seek": 139344, "start": 1405.44, "end": 1410.44, "text": " And then because it's not enabled by default, I've not seen it a lot.", "tokens": [50964, 400, 550, 570, 309, 311, 406, 15172, 538, 7576, 11, 286, 600, 406, 1612, 309, 257, 688, 13, 51214], "temperature": 0.0, "avg_logprob": -0.09993265113052056, "compression_ratio": 1.7914691943127963, "no_speech_prob": 0.16000694036483765}, {"id": 283, "seek": 139344, "start": 1410.44, "end": 1412.44, "text": " And then I think it's a good idea.", "tokens": [51214, 400, 550, 286, 519, 309, 311, 257, 665, 1558, 13, 51314], "temperature": 0.0, "avg_logprob": -0.09993265113052056, "compression_ratio": 1.7914691943127963, "no_speech_prob": 0.16000694036483765}, {"id": 284, "seek": 139344, "start": 1412.44, "end": 1419.44, "text": " Each time I used pressure stall information, it was giving me the right idea, but it's just a subset", "tokens": [51314, 6947, 565, 286, 1143, 3321, 19633, 1589, 11, 309, 390, 2902, 385, 264, 558, 1558, 11, 457, 309, 311, 445, 257, 25993, 51664], "temperature": 0.0, "avg_logprob": -0.09993265113052056, "compression_ratio": 1.7914691943127963, "no_speech_prob": 0.16000694036483765}, {"id": 285, "seek": 141944, "start": 1419.44, "end": 1422.44, "text": " of the systems I've seen because it's not the default.", "tokens": [50364, 295, 264, 3652, 286, 600, 1612, 570, 309, 311, 406, 264, 7576, 13, 50514], "temperature": 0.0, "avg_logprob": -0.102246120058257, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.1703680008649826}, {"id": 286, "seek": 141944, "start": 1422.44, "end": 1429.44, "text": " And then maybe there are some cases that I don't know where it's not perfect, but I try to encourage people", "tokens": [50514, 400, 550, 1310, 456, 366, 512, 3331, 300, 286, 500, 380, 458, 689, 309, 311, 406, 2176, 11, 457, 286, 853, 281, 5373, 561, 50864], "temperature": 0.0, "avg_logprob": -0.102246120058257, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.1703680008649826}, {"id": 287, "seek": 141944, "start": 1429.44, "end": 1435.44, "text": " to enable pressure stall information where instead of looking at all that, you just see that you have some", "tokens": [50864, 281, 9528, 3321, 19633, 1589, 689, 2602, 295, 1237, 412, 439, 300, 11, 291, 445, 536, 300, 291, 362, 512, 51164], "temperature": 0.0, "avg_logprob": -0.102246120058257, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.1703680008649826}, {"id": 288, "seek": 141944, "start": 1435.44, "end": 1447.44, "text": " processes that could be faster if they were not on pressure, on RAM, IO, or CPU.", "tokens": [51164, 7555, 300, 727, 312, 4663, 498, 436, 645, 406, 322, 3321, 11, 322, 14561, 11, 39839, 11, 420, 13199, 13, 51764], "temperature": 0.0, "avg_logprob": -0.102246120058257, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.1703680008649826}, {"id": 289, "seek": 144744, "start": 1447.44, "end": 1449.44, "text": " Okay, I think we are just...", "tokens": [50364, 1033, 11, 286, 519, 321, 366, 445, 485, 50464], "temperature": 0.0, "avg_logprob": -0.15593451040762443, "compression_ratio": 1.6926070038910506, "no_speech_prob": 0.028815982863307}, {"id": 290, "seek": 144744, "start": 1449.44, "end": 1451.44, "text": " Another question? If it's okay?", "tokens": [50464, 3996, 1168, 30, 759, 309, 311, 1392, 30, 50564], "temperature": 0.0, "avg_logprob": -0.15593451040762443, "compression_ratio": 1.6926070038910506, "no_speech_prob": 0.028815982863307}, {"id": 291, "seek": 144744, "start": 1451.44, "end": 1458.44, "text": " So looking at a very generic use case, if you were to redesign the cloud provider's graphs,", "tokens": [50564, 407, 1237, 412, 257, 588, 19577, 764, 1389, 11, 498, 291, 645, 281, 39853, 264, 4588, 12398, 311, 24877, 11, 50914], "temperature": 0.0, "avg_logprob": -0.15593451040762443, "compression_ratio": 1.6926070038910506, "no_speech_prob": 0.028815982863307}, {"id": 292, "seek": 144744, "start": 1458.44, "end": 1461.44, "text": " would you change it? What would you change it to?", "tokens": [50914, 576, 291, 1319, 309, 30, 708, 576, 291, 1319, 309, 281, 30, 51064], "temperature": 0.0, "avg_logprob": -0.15593451040762443, "compression_ratio": 1.6926070038910506, "no_speech_prob": 0.028815982863307}, {"id": 293, "seek": 144744, "start": 1461.44, "end": 1467.44, "text": " Could your list maybe the five most important metrics from a generic use case that you would put on a dashboard?", "tokens": [51064, 7497, 428, 1329, 1310, 264, 1732, 881, 1021, 16367, 490, 257, 19577, 764, 1389, 300, 291, 576, 829, 322, 257, 18342, 30, 51364], "temperature": 0.0, "avg_logprob": -0.15593451040762443, "compression_ratio": 1.6926070038910506, "no_speech_prob": 0.028815982863307}, {"id": 294, "seek": 144744, "start": 1467.44, "end": 1474.44, "text": " On a dashboard, I think pressure stall information can be really nice on a dashboard because you can show that to user.", "tokens": [51364, 1282, 257, 18342, 11, 286, 519, 3321, 19633, 1589, 393, 312, 534, 1481, 322, 257, 18342, 570, 291, 393, 855, 300, 281, 4195, 13, 51714], "temperature": 0.0, "avg_logprob": -0.15593451040762443, "compression_ratio": 1.6926070038910506, "no_speech_prob": 0.028815982863307}, {"id": 295, "seek": 147444, "start": 1474.44, "end": 1479.44, "text": " User running on the cloud, for example, they want to know if they are on pressure on CPU or on IO", "tokens": [50364, 32127, 2614, 322, 264, 4588, 11, 337, 1365, 11, 436, 528, 281, 458, 498, 436, 366, 322, 3321, 322, 13199, 420, 322, 39839, 50614], "temperature": 0.0, "avg_logprob": -0.15045572320620218, "compression_ratio": 1.6150442477876106, "no_speech_prob": 0.1273604929447174}, {"id": 296, "seek": 147444, "start": 1479.44, "end": 1481.44, "text": " because they pay for that.", "tokens": [50614, 570, 436, 1689, 337, 300, 13, 50714], "temperature": 0.0, "avg_logprob": -0.15045572320620218, "compression_ratio": 1.6150442477876106, "no_speech_prob": 0.1273604929447174}, {"id": 297, "seek": 147444, "start": 1481.44, "end": 1483.44, "text": " So those ones I would put that.", "tokens": [50714, 407, 729, 2306, 286, 576, 829, 300, 13, 50814], "temperature": 0.0, "avg_logprob": -0.15045572320620218, "compression_ratio": 1.6150442477876106, "no_speech_prob": 0.1273604929447174}, {"id": 298, "seek": 147444, "start": 1483.44, "end": 1490.44, "text": " Load average, maybe with a clear description that it is CPU plus some IO,", "tokens": [50814, 48408, 4274, 11, 1310, 365, 257, 1850, 3855, 300, 309, 307, 13199, 1804, 512, 39839, 11, 51164], "temperature": 0.0, "avg_logprob": -0.15045572320620218, "compression_ratio": 1.6150442477876106, "no_speech_prob": 0.1273604929447174}, {"id": 299, "seek": 147444, "start": 1490.44, "end": 1498.44, "text": " and memory, available memory, not use memory because a system doing some IO, some buffered IO", "tokens": [51164, 293, 4675, 11, 2435, 4675, 11, 406, 764, 4675, 570, 257, 1185, 884, 512, 39839, 11, 512, 9204, 4073, 39839, 51564], "temperature": 0.0, "avg_logprob": -0.15045572320620218, "compression_ratio": 1.6150442477876106, "no_speech_prob": 0.1273604929447174}, {"id": 300, "seek": 147444, "start": 1498.44, "end": 1501.44, "text": " will always use all the memory in Linux.", "tokens": [51564, 486, 1009, 764, 439, 264, 4675, 294, 18734, 13, 51714], "temperature": 0.0, "avg_logprob": -0.15045572320620218, "compression_ratio": 1.6150442477876106, "no_speech_prob": 0.1273604929447174}, {"id": 301, "seek": 150144, "start": 1501.44, "end": 1504.44, "text": " Maybe we have...", "tokens": [50414, 2704, 321, 362, 485, 50514], "temperature": 0.0, "avg_logprob": -0.19140950271061488, "compression_ratio": 0.6666666666666666, "no_speech_prob": 0.7731825709342957}], "language": "en"}