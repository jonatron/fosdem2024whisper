{"text": " Our next speaker is the esteemed and very famous Charlie Nutter, so let's give him a round of applause. Alright, microphone working. Can you hear me okay back there? Alright, great. I got a lot to cover. This is going to be a retrospective of all the problems that we've had trying to get Ruby onto the JVM. And then a little status report along the way about how we're doing on making the JVM catch up with those needs. Charles Nutter, that's me. There's my contact information. Been working at Red Hat now for I think 12 years. Before that worked for Ingeniard. It was a Ruby software as a service company. And then I was at Sun for the last three years as well. So I probably won't have time for interactive QA, but if you contact me online or post something in the Matrix channel, I will definitely get to it. I want to answer all the questions. Okay, so a little brief review of JRuby here. Ruby for the JVM, not too surprising there. It runs on Java 8 currently, but because of all the cool stuff and because we've ridden the Java 8 horse into the ground, we are going to be 17 or 21 minimum next release, which should be this year. In development for a long time, running Rails since 2006 and probably 2008, we started having production users. And we're the only alternative Ruby that's really had production users during that time. There's been a few other experiments, but nothing's ever really taken as well as JRuby. Maybe the most successful off-platform language brought to the JVM, Jython and Rhino Nazhorn might give us a run for our money, but given the maintenance state of those libraries, I think we're probably currently the most successful and most widely used JVM language that never was envisioned for this platform. So we've been chasing Rails all the time. That's kind of the gold standard for whether we can say we're a Ruby implementation or not. And after about two years of good work, we managed to get Rails working back then. Running Rails tests, running CRuby's tests, running all of the different libraries, suites, as much as possible. Compliance testing for Ruby has improved over the years, but we pretty much just run everything to try and make sure that we really are compatible. And very quickly, we ran into some serious challenges trying to bring a language like Ruby to the JVM and make it also usable and perform well. This is the quick summary. These are all areas I'm going to cover during this talk, so we will just blow right through here. These challenges help us grow both as a platform and as a community. They open up new worlds to Java developers, to JVM developers. They open up the potential of bringing new and unusual languages to the platform. It opens up the entire world of native libraries, native features that are out there that we don't necessarily have on the JVM. So we really need to focus on what are these challenges bringing a language like Ruby to the JVM and how can we make the JVM better to support languages like this in the future? So we'll start with strings and regular expressions. Excuse me for a moment. Okay. So one of the first things we ran into, JRuby's strings were just based on Java strings and we used Java's regular expressions. And at the time, regular expressions were being used in very unusual ways in the Ruby world. We ran into a case in an early version of Rails where they were using regular expression matching to parse HTTP requests that came in and look for, say, a mime header for an image and pull the image out. So you'd end up with a regular expression operating against a very large piece of data. And the built-in Java regular expression engine is implemented in such a way that for certain types of expressions like an alternation like this, it actually will recurse and recurse and recurse. And then very easily you can blow the stack out by feeding it too much data, just giving it too much data. To process, we'll blow it up. So we had to find other options. JRegix was an early one that worked against Java strings and we ran with that for quite a while. But eventually it came to be that the Java string itself was insufficient for us to represent Ruby's string behavior. Here's what that exception looks like. Very simple match here. It's just 10,000 of the A character followed by a B character with that same regular expression. It'll blow up on every version of JVM that's out there or anything based on OpenJDK classes. And I believe this is still an issue. So as we went forward and had to have a more robust, more robust regular expression engine that would work with a more custom type string on JRuby that matched CRuby's behavior, we ported over, or a contributor to JRuby, ported over Ruby's regular expression engine. So Oniguruma is the C library that Ruby uses for regular expression matching and ours is Joanie. It's a byte code based register machine, so there's no stack issues. It doesn't deepen the stack at all. It matches against byte arrays. And that'll be clear in a moment here why we need that. It also can do byte array matching with pluggable encodings, so regardless of what encoding those characters are in, and potentially if you want to use a different grammar for regular expression. This library was ported to characters and used by Nazhorn to do JavaScript regular expressions. They had the same sort of problems, and so they used our library but made it specific to JavaScript. So you see that I'm matching against byte arrays here and I said that strings were insufficient. Well the problem is that Ruby's string is not just one encoding, it's not just a blob of characters, it is represented as a byte array with an encoding. So within the system you can have many strings that all have different encodings and it all needs to be negotiated together when you combine them or use them against each other. So we had to follow suit essentially. We had to make a new string class for JRuby that used bytes, used a byte array, represented all the encodings, port all of the encoding logic over and the transcoding logic, which was a major piece of work. And essentially we have our own string now and we've had this for over a decade because Java strings just could not emulate all of the behaviors we needed for Ruby. This does complicate interop with Java but there are improvements coming there. So J-codings is the encoding library that we use. This provides the full set of encodings similar to what's in CRuby and the transcoding from any encoding to another encoding, which is used internally when we have two different strings come together and need to negotiate that. So where do we stand on the JVM today? Well rather than just having a character array inside strings, we do actually have a similar model now where there's a byte array but only two encodings are allowed inside that byte array. ISO 88591, which is essentially just the 128 bits of ASCII, or UTF-16, the old standard character. So this does lower our cost going to and from Ruby and Java when we are just using an ASCII range of characters, but UTF-8 would be nice to have there because most Ruby strings are going to be UTF-8 probably with at least one multi-byte character in there. So that has to all be copied over a lot more, a lot less efficiently. And Java Util Rejects does still blow the stack. I would love to see it get replaced at some point, but I don't know if there's any work being done to do that. Okay, so the next area that we ran into was that we have a nice runtime, but the performance wasn't there. We needed to be able to generate JVM bytecode from Ruby code and have it optimize like regular Java. So the interpreter was good. It was similar to Ruby 1.8 before they moved to their own bytecode runtime. It was very difficult for the JVM to optimize. We could walk through this stuff quickly and it was very easy to write as an interpreter, but you had a lot of polymorphic calls within that AST. It never really could see the optimization path through there. So we had to write a JIT. The reason that we did not just immediately start compiling all Ruby code into bytecode is because, for example, the Rails library will load into memory thousands of classes, tens of, or tens of thousands of methods, or tens of thousands of methods. That's a massive load for us to put onto the JVM when only a few hundred or a few thousand of those are ever going to be called. It also was slower for us to go straight to bytecode because the bytecode would end up being interpreted by the JVM's interpreter, which actually turned out to be slower than our interpreter after it JITs. So it made more sense for us to leave it in our interpreter until we saw it really needed JVM bytecode, and there we ended up with basically the first mixed-mode JIT runtime on top of the JVM. Later on, we did move to a more modern compiler design. We had a compiler engineer, Sabu Sastri, come in and help, and he basically helped us move a lot of the little P-Pole optimizations I was doing in my JIT up to a more modern compiler architecture. So this simplified the JIT, simplified what I had to write as far as emitting bytecode, which then let me explore performance a lot more in other ways. And then of course, as we move forward, we got invokeDynamic in Java 7. It's been steadily improving since then. It's used incredibly heavily in JRuby. If you take the bytecode of our JIT output from Ruby code, it's pretty much just stack moves and invokeDynamics for almost everything that we do. We will access local variables normally, but everything else has to have some little dynamic aspect as part of Ruby. So we use it very heavily and probably more heavily than almost any other project on the JVM. This is invokeDynamic performance over time from Java 8 up to 17. Really happy to see the performance improvements every release. It gets a little bit better. Looking at what we're doing with a more numeric algorithm, we get a bigger boost out of it. With something that's just walking a lot of objects, we're already kind of close to where Java would be on just walking an object graph, but still seeing that we do get some improvements from running invokeDynamic, making that more direct. Really cool is when we plug in a different JIT compiler here. So this is now using invokeDynamic on the Grawl JIT. And for a numeric algorithm where we're creating tons of numeric objects, we really see the impact of partial escape analysis helping us. And this is now really starting to get to the point of Java level performance for a numeric algorithm. This is the cases where it really helps. But over time, we have not seen that Grawl is generally faster and we don't generally recommend it unless you have something numeric or something that's doing a massive amount of allocation of temporary objects. So where are we today? One of the problems that we have generating individual methods or compiling at the runtime is ideally we want that compiled method to go away if the class goes away, or if it's a one-off generated method that eventually doesn't get used. So it's a class per method, and the only way to make those garbage collectible is a class loader per class per method. So every method that we JIT into the system has both a class surrounding it and an entire class loader just to work within the confines of the garbage collector. There's no other way to make garbage collectible classes right now on the JVM. There is anonymous class loader, but it's a hidden class, and we don't try to access that right now. Indie is clearly working very well. We're going to be doing more advanced call sites where we will have special case code along one fast path and then a slower dynamic path if it turns out it's not the logic we expected. It is a tricky API to use, but we have a lot of tooling that we've built around it. I've got some links to older talks of mine that go into detail on that. Okay, I think we're doing pretty good on time here. I know I talk fast. Come back to the video and do it at like half speed, and then maybe you'll catch everything that I'm trying to say here. So the next big area that we ran into was native interop. The sea ruby world really lives in a POSIX native sea environment. It's almost a DSL for writing POSIX code, really. And originally that's kind of what Mott's the creator wanted. He wanted something where he could write C, but essentially with a nice API, a nice language on top of it. So they are very heavily using JNI-like extensions to the runtime for most of their native access. This is clearly way too invasive for JRuby. It calls into internals of their object structures. It has direct access to the heap, direct access to garbage collector endpoints. Nothing that we can emulate efficiently in JNI, and we have tried. So we ended up pushing people more towards using programmatic access, like Project Panama, like libffi, rather than writing C extensions for C ruby to wrap a library. Let's just wrap the library by writing a little bit of ruby code. And so started out with the Java native runtime. It's basically our API for calling from Java down into native code and native memory. And then on top of that, porting the ruby ffi layer over with some invoke dynamic magic, try and make that all as clean and fast as possible. Java native runtime is actually a set of projects. Up at the top, jffi is the wrapper around libffi. That's where we ship about 20 different binaries in the jar for all the base platforms that we support. Libffi is in there, and we're just using standard libffi with some extra wrapper logic around it. JNR-fffi is kind of the baseline user API. If you're familiar with JNA, this is that level, where you say, I need a struct that's laid out like this. I need a function that takes these arguments, make these calls, allocate this memory. Then above that, we realize there were a lot of functions and a lot of behaviors that people were going to be rebinding over and over if we didn't provide them. So we have JNR-possicks, which is a slowly growing corpus of standard posix functions bound on top of JNR-fffi. So you can go in there and you can call things like posixpon or open a file or do native IO. You can even call fork, and it's a lot of fun to see what happens when you do that. JNR-enxio, extended native cross-platform IO, builds on JNR-possicks and provides an NIO channel that is all native down calls. So where we can't get selectable standard IO on the JVM, we can't get selectable sub-process channels, we can use JNR-enxio to have actual interactive control over standard input. Standard IO and sub-processes. You can actually use JRuby to spin up a VIM instance and it will have full console control and work properly. Basically impossible to do with the standard process builder stuff on Java. Unix socket, not too surprising, just wraps this other stuff with the Unix socket calls. And then JNR-process, like I mentioned, we have our own selectable channels for processes. You can use this as a Maven library, you pull it in and you'll have the same API as process builder but you'll get channels, selectable channels out of it instead of streams. So it's available right now for that. This is a little bit of what Ruby FFI looks like. Pretty straightforward, we're setting up a structure with particular widths of fields, attaching a function, get time of day, and then we can call it directly. Under the covers, this all uses JNR and ideally inlines as much as possible up to the native down call. So today, native interop on the JVM. Of course, we have Panama coming along, so the talk before me, Mauricio's talk, that's where all the information is about where things are going and we're really excited about that. I actually wrote the original JEP for Panama, which has now been walked away from many times, but we've been needing this for over a decade now and had to make our own but don't want to maintain it anymore. JNR is pretty much the fastest way outside of Panama to do these native down calls. In some cases, actually beating JNI because there's extensions to generate a little JNI function in memory using assembly that can cut out some of that overhead rather than just doing pure programmatic calling through lib.ffi. Jextract from Panama is coming along. We're also hoping that we can use that at runtime as a library to and access those data structures internally to generate Ruby.ffi code. This would be kind of the last mile for getting Rubyists to switch from writing C extensions to using FFI. If we could generate the Ruby.ffi code the same way we do the Panama code, there'd be nothing to stop them at that point. There is back-end work happening right now on JNR to integrate it with Panama. Michelle at Oracle is working on that and I'm hoping that we'll see something in the next couple of weeks. A little more review of some of these ideas. If we have Jextract that can generate Java code, we should be able to use Jextract to also generate Ruby.ffi code. That'll be the next big fun toy to play with is of Java 22. We also use the existing SQLite JDBC driver. Rubyists like to use SQLite for local development. But it's going through a JNI back-end. You have to make sure it's available for the platform that you're on. They are also playing with Panama behind the scenes. Early numbers look like two-ish times faster than the JNI wrapper around SQLite that they have. So this is coming along. We also are integrating a new Ruby parser called Prism, which is a simple C library that we all the implementations can share so that we are using the same Ruby parser. That we will integrate through Panama as well. And use Panama to make it much faster for us to downcall into this library, get our AST back out, and then proceed. Interestingly, we're also exploring using Prism as a Wasm-compiled library running on the chicory Wasm implementation on top of the JVM so that we can parse Ruby code using a native library even if we're not on a platform it's compiled for. And that's amazing that it works. All right. Moving along here. So lightweight threading is the next big one. Around Ruby 1.9, they introduced fibers, a coroutine-like concept, a micro thread concept. You would still have your native threads there, but they can bounce around to different fibers at any given time. And you get little structured concurrency, structured use of fibers, allows you to do multiple tasks in the same thread. There's also been a push toward structured concurrency in the Ruby world now, where fibers can wait on I.O. or make a blocking call on I.O. The runtime will see that and schedule another fiber to run in its place while it's waiting for that. So you can easily handle tens of thousands, hundreds of thousands of concurrent connections, for example, without blocking that many threads or having to write your own select loop and what not. So fibers on JRuby, without a coroutine API at the JVM level, of course, we've had to use native threads. And that clearly only scales up to a certain number of threads. With the structured concurrency example, we could have potentially thousands of fibers in the system, and it's almost impossible for us to support that with full, heavy native threads all along the way. Ruby also primarily uses internal iteration. Collections just have to implement an each method of basically a for each. And all collections in the system then expect you to pass a block of code into it. Well, how do you turn internal iteration into external iteration? You have to use a coroutine that can yield values back out while staying inside that loop. So now we've got that potential for all sorts of fibers, hundreds of thousands of fibers all over the system, just because we're iterating collections with an external iterator. I'm going to kind of blow through this because the next talk will cover fibers a bit more. The example here of handling requests on a thread. We've got a thread, a request comes in. Now it's waiting for more information, the thread's not being used. Finally we get more data, we can proceed with the rest of our request handling. With fibers, of course, we can use multiple different fibers handling different connections on the same native thread. So the request comes in, this fiber's waiting on IO. Well let's spin up another fiber that can handle the next request that comes in. And they can multiplex use of that same thread. This is what we're starting to see more and more in Ruby, and this is where it will be critical for us to have lightweight fibers, lightweight coroutines on J Ruby. Okay, so here is a little benchmark, a little example of trying to test how long it takes to spin up 100,000 fibers and run them all to completion. So they are 100,000 live fibers in the system at any given time on this benchmark. And of course as you would expect this doesn't work. We can't spin up 100,000 native threads, and it just crashes in horrific ways. I'd love to see this crash in less horrific ways, but ideally we just move away from this problem altogether. And that's where we get project loom. So JVM Today, as of 21, we now have an official API for lightweight coroutines for essentially fibers that maps almost perfectly to what we need in the Ruby world. And we've already got this integrated. We integrated it a year ago actually, and have only made minor changes along the way. I'd like to show this just to demonstrate how much work we had to do to switch from our built in native fiber, native thread fibers to the virtual thread fibers. I was shocked that this was all it took, and suddenly this benchmark actually could run. It could actually spin up all of those fibers and run them to completion. So amazing work on the loom side, and very happy with the results. Once wise, so here I drop it down to 10,000 so that I can actually try and get the threaded version to work. Clearly we're getting significant gains on passing, context switching between different fibers, because loom is just better at that, and there's a much lighter weight process for going from one fiber to another on the same thread. Not quite as fast as C Ruby. I suspect this is probably due to us relying on a very general purpose scheduler for the virtual threads behind the scenes, where we really just want to say, this fiber's done, now run this one, rather than unblock that fiber and wait for the scheduler to pick it up. I think we can make up most of this overhead. Similarly on M1, I don't know if this is general to arm or not, but this is the performance results we have. Could not get 10,000 to go on M1. I got to drop it down to like 2,000 or 3,000. The impact is a bit more here, but again I'm hoping that as loom evolves, as we use it better, we'll see improvements. Five minutes for the last section here. The classic problem with J Ruby is still startup time. If we did not have startup time, we probably would have won the Ruby war a long time ago. It's the number one, two, and three complaint about J Ruby is how much longer it takes to start up. The JBM is just not designed to start up quickly. Most of the core JD code starts in the interpreter. It takes a long time for that to optimize, and then your application can start getting fast. We make it worse because we interpret Ruby code, and then every once in a while we'll just throw more byte code at the JVM, like okay, now this call site's actually bound to a byte code method, not an interpreter, and we're just confusing the hell out of it all the time. This is one of the reasons we actually do lazy compilation to byte code, because we want to reduce the amount of overhead we force onto the JIT at the JVM level. Walk through J Ruby's architecture here quick. We have our Ruby parser, gives us our Ruby AST, we compile into our intermediate representation, interpret that for a while, and here's where it becomes mixed mode. Then eventually we will generate byte code for those methods, and then hopefully the rest of it all works and optimizes to native code. One of the early ways that we've tried to improve startup time is basically to turn most of that off, rather than turning anything into byte code, rather than even running the C2, the fast JIT in hotspot. We turn only to C1, we use the simple JIT in the JVM, and we only use our interpreter. This improves our startup time by about 2x. By far the best thing we've had so far. Now, another way that could be potentially a way to fix this would be ahead of time compilation. Of course, GrawlVM solves this very nicely for that world, but it completely disables all of the native things that we want. General purpose, invoke dynamic, and method handles just simply, essentially doesn't work. Then beyond that, we would have to pre-compile all of our code to byte code. We'd have to link it in some way that it could ahead of time compile the native. This is just not going to work for us. We're hoping that Layden will actually pick up here with a ahead of time option that can also do some dynamic stuff at runtime. Where are we today? The solutions we're looking at in the short term are mostly surrounding the checkpointing features. Checkpoint and restore in user space, the CRIU API on Linux allows us to run JRuby to a certain point, like just after startup, and then save off a copy of it that we can start quickly with later on. This is being standardized in Project Crack, an unfortunate name, but a lovely project. This is working pretty well with JRuby right now, just experimenting with it. We are still hoping that Layden with some ahead of time compilation that still enables the rest of JVM features will be our ultimate solution. You can see here, this is CRuby on the left side just doing a baseline startup. JRuby's baseline startup without our dash dash dev flag, which turns off all of the optimization. The dev flag here, not quite 2x, but giving us a good boost. Crack of course, significantly faster than all of those. We've actually gotten to a point in execution where we can start running Ruby code now, starting to get competitive with CRuby, which was essentially designed for fast startup. Same example generating a Rails app, again, getting very close to where CRuby sits on these numbers. So, wrapping up in the last minute here, JRuby is a test bed for all of these crazy JVM things that we're doing. We're pushing all of these edges. So whether you care about Ruby or not, we are the best invoke dynamic torture test. We're going to be hitting Panama extremely hard as it gets integrated into the system. All of the structural threading will be massively exercised by all of the structured concurrency stuff coming on the Ruby side. So if you're interested in helping us integrate any of these features, or if you're an implementer interested in testing these features at scale, JRuby is definitely something you should look at. This is more background. I'll let you take a quick picture of this if you want. These are talks I've done in the past that basically cover all of my many complaints about the JVM. That list of complaints gets smaller and smaller every year, thankfully.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 10.92, "text": " Our next speaker is the esteemed and very famous Charlie Nutter, so let's give him a", "tokens": [50364, 2621, 958, 8145, 307, 264, 4065, 15485, 293, 588, 4618, 13754, 426, 9947, 11, 370, 718, 311, 976, 796, 257, 50910], "temperature": 0.0, "avg_logprob": -0.3059051140494969, "compression_ratio": 1.4345794392523366, "no_speech_prob": 0.4391111433506012}, {"id": 1, "seek": 0, "start": 10.92, "end": 13.200000000000001, "text": " round of applause.", "tokens": [50910, 3098, 295, 9969, 13, 51024], "temperature": 0.0, "avg_logprob": -0.3059051140494969, "compression_ratio": 1.4345794392523366, "no_speech_prob": 0.4391111433506012}, {"id": 2, "seek": 0, "start": 13.200000000000001, "end": 17.76, "text": " Alright, microphone working.", "tokens": [51024, 2798, 11, 10952, 1364, 13, 51252], "temperature": 0.0, "avg_logprob": -0.3059051140494969, "compression_ratio": 1.4345794392523366, "no_speech_prob": 0.4391111433506012}, {"id": 3, "seek": 0, "start": 17.76, "end": 19.36, "text": " Can you hear me okay back there?", "tokens": [51252, 1664, 291, 1568, 385, 1392, 646, 456, 30, 51332], "temperature": 0.0, "avg_logprob": -0.3059051140494969, "compression_ratio": 1.4345794392523366, "no_speech_prob": 0.4391111433506012}, {"id": 4, "seek": 0, "start": 19.36, "end": 20.36, "text": " Alright, great.", "tokens": [51332, 2798, 11, 869, 13, 51382], "temperature": 0.0, "avg_logprob": -0.3059051140494969, "compression_ratio": 1.4345794392523366, "no_speech_prob": 0.4391111433506012}, {"id": 5, "seek": 0, "start": 20.36, "end": 22.240000000000002, "text": " I got a lot to cover.", "tokens": [51382, 286, 658, 257, 688, 281, 2060, 13, 51476], "temperature": 0.0, "avg_logprob": -0.3059051140494969, "compression_ratio": 1.4345794392523366, "no_speech_prob": 0.4391111433506012}, {"id": 6, "seek": 0, "start": 22.240000000000002, "end": 25.2, "text": " This is going to be a retrospective of all the problems that we've had trying to get", "tokens": [51476, 639, 307, 516, 281, 312, 257, 34997, 488, 295, 439, 264, 2740, 300, 321, 600, 632, 1382, 281, 483, 51624], "temperature": 0.0, "avg_logprob": -0.3059051140494969, "compression_ratio": 1.4345794392523366, "no_speech_prob": 0.4391111433506012}, {"id": 7, "seek": 0, "start": 25.2, "end": 26.76, "text": " Ruby onto the JVM.", "tokens": [51624, 19907, 3911, 264, 508, 53, 44, 13, 51702], "temperature": 0.0, "avg_logprob": -0.3059051140494969, "compression_ratio": 1.4345794392523366, "no_speech_prob": 0.4391111433506012}, {"id": 8, "seek": 2676, "start": 26.76, "end": 30.560000000000002, "text": " And then a little status report along the way about how we're doing on making the JVM", "tokens": [50364, 400, 550, 257, 707, 6558, 2275, 2051, 264, 636, 466, 577, 321, 434, 884, 322, 1455, 264, 508, 53, 44, 50554], "temperature": 0.0, "avg_logprob": -0.20716297815716456, "compression_ratio": 1.5620689655172413, "no_speech_prob": 0.11427569389343262}, {"id": 9, "seek": 2676, "start": 30.560000000000002, "end": 33.2, "text": " catch up with those needs.", "tokens": [50554, 3745, 493, 365, 729, 2203, 13, 50686], "temperature": 0.0, "avg_logprob": -0.20716297815716456, "compression_ratio": 1.5620689655172413, "no_speech_prob": 0.11427569389343262}, {"id": 10, "seek": 2676, "start": 33.2, "end": 35.160000000000004, "text": " Charles Nutter, that's me.", "tokens": [50686, 10523, 426, 9947, 11, 300, 311, 385, 13, 50784], "temperature": 0.0, "avg_logprob": -0.20716297815716456, "compression_ratio": 1.5620689655172413, "no_speech_prob": 0.11427569389343262}, {"id": 11, "seek": 2676, "start": 35.160000000000004, "end": 37.24, "text": " There's my contact information.", "tokens": [50784, 821, 311, 452, 3385, 1589, 13, 50888], "temperature": 0.0, "avg_logprob": -0.20716297815716456, "compression_ratio": 1.5620689655172413, "no_speech_prob": 0.11427569389343262}, {"id": 12, "seek": 2676, "start": 37.24, "end": 40.760000000000005, "text": " Been working at Red Hat now for I think 12 years.", "tokens": [50888, 32839, 1364, 412, 4477, 15867, 586, 337, 286, 519, 2272, 924, 13, 51064], "temperature": 0.0, "avg_logprob": -0.20716297815716456, "compression_ratio": 1.5620689655172413, "no_speech_prob": 0.11427569389343262}, {"id": 13, "seek": 2676, "start": 40.760000000000005, "end": 42.160000000000004, "text": " Before that worked for Ingeniard.", "tokens": [51064, 4546, 300, 2732, 337, 682, 1766, 72, 515, 13, 51134], "temperature": 0.0, "avg_logprob": -0.20716297815716456, "compression_ratio": 1.5620689655172413, "no_speech_prob": 0.11427569389343262}, {"id": 14, "seek": 2676, "start": 42.160000000000004, "end": 45.92, "text": " It was a Ruby software as a service company.", "tokens": [51134, 467, 390, 257, 19907, 4722, 382, 257, 2643, 2237, 13, 51322], "temperature": 0.0, "avg_logprob": -0.20716297815716456, "compression_ratio": 1.5620689655172413, "no_speech_prob": 0.11427569389343262}, {"id": 15, "seek": 2676, "start": 45.92, "end": 51.0, "text": " And then I was at Sun for the last three years as well.", "tokens": [51322, 400, 550, 286, 390, 412, 6163, 337, 264, 1036, 1045, 924, 382, 731, 13, 51576], "temperature": 0.0, "avg_logprob": -0.20716297815716456, "compression_ratio": 1.5620689655172413, "no_speech_prob": 0.11427569389343262}, {"id": 16, "seek": 2676, "start": 51.0, "end": 55.96, "text": " So I probably won't have time for interactive QA, but if you contact me online or post something", "tokens": [51576, 407, 286, 1391, 1582, 380, 362, 565, 337, 15141, 1249, 32, 11, 457, 498, 291, 3385, 385, 2950, 420, 2183, 746, 51824], "temperature": 0.0, "avg_logprob": -0.20716297815716456, "compression_ratio": 1.5620689655172413, "no_speech_prob": 0.11427569389343262}, {"id": 17, "seek": 5596, "start": 55.96, "end": 58.28, "text": " in the Matrix channel, I will definitely get to it.", "tokens": [50364, 294, 264, 36274, 2269, 11, 286, 486, 2138, 483, 281, 309, 13, 50480], "temperature": 0.0, "avg_logprob": -0.1628664498017213, "compression_ratio": 1.5222672064777327, "no_speech_prob": 0.017974911257624626}, {"id": 18, "seek": 5596, "start": 58.28, "end": 60.480000000000004, "text": " I want to answer all the questions.", "tokens": [50480, 286, 528, 281, 1867, 439, 264, 1651, 13, 50590], "temperature": 0.0, "avg_logprob": -0.1628664498017213, "compression_ratio": 1.5222672064777327, "no_speech_prob": 0.017974911257624626}, {"id": 19, "seek": 5596, "start": 60.480000000000004, "end": 65.04, "text": " Okay, so a little brief review of JRuby here.", "tokens": [50590, 1033, 11, 370, 257, 707, 5353, 3131, 295, 32849, 836, 88, 510, 13, 50818], "temperature": 0.0, "avg_logprob": -0.1628664498017213, "compression_ratio": 1.5222672064777327, "no_speech_prob": 0.017974911257624626}, {"id": 20, "seek": 5596, "start": 65.04, "end": 69.0, "text": " Ruby for the JVM, not too surprising there.", "tokens": [50818, 19907, 337, 264, 508, 53, 44, 11, 406, 886, 8830, 456, 13, 51016], "temperature": 0.0, "avg_logprob": -0.1628664498017213, "compression_ratio": 1.5222672064777327, "no_speech_prob": 0.017974911257624626}, {"id": 21, "seek": 5596, "start": 69.0, "end": 73.76, "text": " It runs on Java 8 currently, but because of all the cool stuff and because we've ridden", "tokens": [51016, 467, 6676, 322, 10745, 1649, 4362, 11, 457, 570, 295, 439, 264, 1627, 1507, 293, 570, 321, 600, 3973, 1556, 51254], "temperature": 0.0, "avg_logprob": -0.1628664498017213, "compression_ratio": 1.5222672064777327, "no_speech_prob": 0.017974911257624626}, {"id": 22, "seek": 5596, "start": 73.76, "end": 80.52000000000001, "text": " the Java 8 horse into the ground, we are going to be 17 or 21 minimum next release, which", "tokens": [51254, 264, 10745, 1649, 6832, 666, 264, 2727, 11, 321, 366, 516, 281, 312, 3282, 420, 5080, 7285, 958, 4374, 11, 597, 51592], "temperature": 0.0, "avg_logprob": -0.1628664498017213, "compression_ratio": 1.5222672064777327, "no_speech_prob": 0.017974911257624626}, {"id": 23, "seek": 5596, "start": 80.52000000000001, "end": 82.92, "text": " should be this year.", "tokens": [51592, 820, 312, 341, 1064, 13, 51712], "temperature": 0.0, "avg_logprob": -0.1628664498017213, "compression_ratio": 1.5222672064777327, "no_speech_prob": 0.017974911257624626}, {"id": 24, "seek": 8292, "start": 82.92, "end": 88.4, "text": " In development for a long time, running Rails since 2006 and probably 2008, we started having", "tokens": [50364, 682, 3250, 337, 257, 938, 565, 11, 2614, 48526, 1670, 14062, 293, 1391, 10389, 11, 321, 1409, 1419, 50638], "temperature": 0.0, "avg_logprob": -0.12670720141866934, "compression_ratio": 1.56, "no_speech_prob": 0.10656750202178955}, {"id": 25, "seek": 8292, "start": 88.4, "end": 89.4, "text": " production users.", "tokens": [50638, 4265, 5022, 13, 50688], "temperature": 0.0, "avg_logprob": -0.12670720141866934, "compression_ratio": 1.56, "no_speech_prob": 0.10656750202178955}, {"id": 26, "seek": 8292, "start": 89.4, "end": 94.68, "text": " And we're the only alternative Ruby that's really had production users during that time.", "tokens": [50688, 400, 321, 434, 264, 787, 8535, 19907, 300, 311, 534, 632, 4265, 5022, 1830, 300, 565, 13, 50952], "temperature": 0.0, "avg_logprob": -0.12670720141866934, "compression_ratio": 1.56, "no_speech_prob": 0.10656750202178955}, {"id": 27, "seek": 8292, "start": 94.68, "end": 99.76, "text": " There's been a few other experiments, but nothing's ever really taken as well as JRuby.", "tokens": [50952, 821, 311, 668, 257, 1326, 661, 12050, 11, 457, 1825, 311, 1562, 534, 2726, 382, 731, 382, 32849, 836, 88, 13, 51206], "temperature": 0.0, "avg_logprob": -0.12670720141866934, "compression_ratio": 1.56, "no_speech_prob": 0.10656750202178955}, {"id": 28, "seek": 8292, "start": 99.76, "end": 107.08, "text": " Maybe the most successful off-platform language brought to the JVM, Jython and Rhino Nazhorn", "tokens": [51206, 2704, 264, 881, 4406, 766, 12, 39975, 837, 2856, 3038, 281, 264, 508, 53, 44, 11, 508, 88, 11943, 293, 16111, 2982, 11870, 31990, 51572], "temperature": 0.0, "avg_logprob": -0.12670720141866934, "compression_ratio": 1.56, "no_speech_prob": 0.10656750202178955}, {"id": 29, "seek": 8292, "start": 107.08, "end": 111.64, "text": " might give us a run for our money, but given the maintenance state of those libraries,", "tokens": [51572, 1062, 976, 505, 257, 1190, 337, 527, 1460, 11, 457, 2212, 264, 11258, 1785, 295, 729, 15148, 11, 51800], "temperature": 0.0, "avg_logprob": -0.12670720141866934, "compression_ratio": 1.56, "no_speech_prob": 0.10656750202178955}, {"id": 30, "seek": 11164, "start": 111.64, "end": 117.24, "text": " I think we're probably currently the most successful and most widely used JVM language", "tokens": [50364, 286, 519, 321, 434, 1391, 4362, 264, 881, 4406, 293, 881, 13371, 1143, 508, 53, 44, 2856, 50644], "temperature": 0.0, "avg_logprob": -0.16198903864080255, "compression_ratio": 1.6117216117216118, "no_speech_prob": 0.13274142146110535}, {"id": 31, "seek": 11164, "start": 117.24, "end": 121.12, "text": " that never was envisioned for this platform.", "tokens": [50644, 300, 1128, 390, 47733, 337, 341, 3663, 13, 50838], "temperature": 0.0, "avg_logprob": -0.16198903864080255, "compression_ratio": 1.6117216117216118, "no_speech_prob": 0.13274142146110535}, {"id": 32, "seek": 11164, "start": 121.12, "end": 123.16, "text": " So we've been chasing Rails all the time.", "tokens": [50838, 407, 321, 600, 668, 17876, 48526, 439, 264, 565, 13, 50940], "temperature": 0.0, "avg_logprob": -0.16198903864080255, "compression_ratio": 1.6117216117216118, "no_speech_prob": 0.13274142146110535}, {"id": 33, "seek": 11164, "start": 123.16, "end": 126.92, "text": " That's kind of the gold standard for whether we can say we're a Ruby implementation or", "tokens": [50940, 663, 311, 733, 295, 264, 3821, 3832, 337, 1968, 321, 393, 584, 321, 434, 257, 19907, 11420, 420, 51128], "temperature": 0.0, "avg_logprob": -0.16198903864080255, "compression_ratio": 1.6117216117216118, "no_speech_prob": 0.13274142146110535}, {"id": 34, "seek": 11164, "start": 126.92, "end": 128.68, "text": " not.", "tokens": [51128, 406, 13, 51216], "temperature": 0.0, "avg_logprob": -0.16198903864080255, "compression_ratio": 1.6117216117216118, "no_speech_prob": 0.13274142146110535}, {"id": 35, "seek": 11164, "start": 128.68, "end": 134.4, "text": " And after about two years of good work, we managed to get Rails working back then.", "tokens": [51216, 400, 934, 466, 732, 924, 295, 665, 589, 11, 321, 6453, 281, 483, 48526, 1364, 646, 550, 13, 51502], "temperature": 0.0, "avg_logprob": -0.16198903864080255, "compression_ratio": 1.6117216117216118, "no_speech_prob": 0.13274142146110535}, {"id": 36, "seek": 11164, "start": 134.4, "end": 139.28, "text": " Running Rails tests, running CRuby's tests, running all of the different libraries, suites,", "tokens": [51502, 28136, 48526, 6921, 11, 2614, 14123, 836, 88, 311, 6921, 11, 2614, 439, 295, 264, 819, 15148, 11, 459, 3324, 11, 51746], "temperature": 0.0, "avg_logprob": -0.16198903864080255, "compression_ratio": 1.6117216117216118, "no_speech_prob": 0.13274142146110535}, {"id": 37, "seek": 13928, "start": 139.28, "end": 141.64000000000001, "text": " as much as possible.", "tokens": [50364, 382, 709, 382, 1944, 13, 50482], "temperature": 0.0, "avg_logprob": -0.1147926089999912, "compression_ratio": 1.6185185185185185, "no_speech_prob": 0.05495434254407883}, {"id": 38, "seek": 13928, "start": 141.64000000000001, "end": 145.24, "text": " Compliance testing for Ruby has improved over the years, but we pretty much just run everything", "tokens": [50482, 33736, 6276, 4997, 337, 19907, 575, 9689, 670, 264, 924, 11, 457, 321, 1238, 709, 445, 1190, 1203, 50662], "temperature": 0.0, "avg_logprob": -0.1147926089999912, "compression_ratio": 1.6185185185185185, "no_speech_prob": 0.05495434254407883}, {"id": 39, "seek": 13928, "start": 145.24, "end": 149.4, "text": " to try and make sure that we really are compatible.", "tokens": [50662, 281, 853, 293, 652, 988, 300, 321, 534, 366, 18218, 13, 50870], "temperature": 0.0, "avg_logprob": -0.1147926089999912, "compression_ratio": 1.6185185185185185, "no_speech_prob": 0.05495434254407883}, {"id": 40, "seek": 13928, "start": 149.4, "end": 153.8, "text": " And very quickly, we ran into some serious challenges trying to bring a language like", "tokens": [50870, 400, 588, 2661, 11, 321, 5872, 666, 512, 3156, 4759, 1382, 281, 1565, 257, 2856, 411, 51090], "temperature": 0.0, "avg_logprob": -0.1147926089999912, "compression_ratio": 1.6185185185185185, "no_speech_prob": 0.05495434254407883}, {"id": 41, "seek": 13928, "start": 153.8, "end": 160.0, "text": " Ruby to the JVM and make it also usable and perform well.", "tokens": [51090, 19907, 281, 264, 508, 53, 44, 293, 652, 309, 611, 29975, 293, 2042, 731, 13, 51400], "temperature": 0.0, "avg_logprob": -0.1147926089999912, "compression_ratio": 1.6185185185185185, "no_speech_prob": 0.05495434254407883}, {"id": 42, "seek": 13928, "start": 160.0, "end": 161.04, "text": " This is the quick summary.", "tokens": [51400, 639, 307, 264, 1702, 12691, 13, 51452], "temperature": 0.0, "avg_logprob": -0.1147926089999912, "compression_ratio": 1.6185185185185185, "no_speech_prob": 0.05495434254407883}, {"id": 43, "seek": 13928, "start": 161.04, "end": 165.12, "text": " These are all areas I'm going to cover during this talk, so we will just blow right through", "tokens": [51452, 1981, 366, 439, 3179, 286, 478, 516, 281, 2060, 1830, 341, 751, 11, 370, 321, 486, 445, 6327, 558, 807, 51656], "temperature": 0.0, "avg_logprob": -0.1147926089999912, "compression_ratio": 1.6185185185185185, "no_speech_prob": 0.05495434254407883}, {"id": 44, "seek": 13928, "start": 165.12, "end": 166.92000000000002, "text": " here.", "tokens": [51656, 510, 13, 51746], "temperature": 0.0, "avg_logprob": -0.1147926089999912, "compression_ratio": 1.6185185185185185, "no_speech_prob": 0.05495434254407883}, {"id": 45, "seek": 16692, "start": 166.92, "end": 170.95999999999998, "text": " These challenges help us grow both as a platform and as a community.", "tokens": [50364, 1981, 4759, 854, 505, 1852, 1293, 382, 257, 3663, 293, 382, 257, 1768, 13, 50566], "temperature": 0.0, "avg_logprob": -0.10236143320798874, "compression_ratio": 1.8210526315789475, "no_speech_prob": 0.06360878050327301}, {"id": 46, "seek": 16692, "start": 170.95999999999998, "end": 175.32, "text": " They open up new worlds to Java developers, to JVM developers.", "tokens": [50566, 814, 1269, 493, 777, 13401, 281, 10745, 8849, 11, 281, 508, 53, 44, 8849, 13, 50784], "temperature": 0.0, "avg_logprob": -0.10236143320798874, "compression_ratio": 1.8210526315789475, "no_speech_prob": 0.06360878050327301}, {"id": 47, "seek": 16692, "start": 175.32, "end": 179.51999999999998, "text": " They open up the potential of bringing new and unusual languages to the platform.", "tokens": [50784, 814, 1269, 493, 264, 3995, 295, 5062, 777, 293, 10901, 8650, 281, 264, 3663, 13, 50994], "temperature": 0.0, "avg_logprob": -0.10236143320798874, "compression_ratio": 1.8210526315789475, "no_speech_prob": 0.06360878050327301}, {"id": 48, "seek": 16692, "start": 179.51999999999998, "end": 184.07999999999998, "text": " It opens up the entire world of native libraries, native features that are out there that we", "tokens": [50994, 467, 9870, 493, 264, 2302, 1002, 295, 8470, 15148, 11, 8470, 4122, 300, 366, 484, 456, 300, 321, 51222], "temperature": 0.0, "avg_logprob": -0.10236143320798874, "compression_ratio": 1.8210526315789475, "no_speech_prob": 0.06360878050327301}, {"id": 49, "seek": 16692, "start": 184.07999999999998, "end": 186.29999999999998, "text": " don't necessarily have on the JVM.", "tokens": [51222, 500, 380, 4725, 362, 322, 264, 508, 53, 44, 13, 51333], "temperature": 0.0, "avg_logprob": -0.10236143320798874, "compression_ratio": 1.8210526315789475, "no_speech_prob": 0.06360878050327301}, {"id": 50, "seek": 16692, "start": 186.29999999999998, "end": 190.67999999999998, "text": " So we really need to focus on what are these challenges bringing a language like Ruby to", "tokens": [51333, 407, 321, 534, 643, 281, 1879, 322, 437, 366, 613, 4759, 5062, 257, 2856, 411, 19907, 281, 51552], "temperature": 0.0, "avg_logprob": -0.10236143320798874, "compression_ratio": 1.8210526315789475, "no_speech_prob": 0.06360878050327301}, {"id": 51, "seek": 16692, "start": 190.67999999999998, "end": 196.48, "text": " the JVM and how can we make the JVM better to support languages like this in the future?", "tokens": [51552, 264, 508, 53, 44, 293, 577, 393, 321, 652, 264, 508, 53, 44, 1101, 281, 1406, 8650, 411, 341, 294, 264, 2027, 30, 51842], "temperature": 0.0, "avg_logprob": -0.10236143320798874, "compression_ratio": 1.8210526315789475, "no_speech_prob": 0.06360878050327301}, {"id": 52, "seek": 19648, "start": 197.04, "end": 199.48, "text": " So we'll start with strings and regular expressions.", "tokens": [50392, 407, 321, 603, 722, 365, 13985, 293, 3890, 15277, 13, 50514], "temperature": 0.0, "avg_logprob": -0.2109855047546991, "compression_ratio": 1.7818181818181817, "no_speech_prob": 0.011146810837090015}, {"id": 53, "seek": 19648, "start": 199.48, "end": 205.07999999999998, "text": " Excuse me for a moment.", "tokens": [50514, 11359, 385, 337, 257, 1623, 13, 50794], "temperature": 0.0, "avg_logprob": -0.2109855047546991, "compression_ratio": 1.7818181818181817, "no_speech_prob": 0.011146810837090015}, {"id": 54, "seek": 19648, "start": 205.07999999999998, "end": 206.07999999999998, "text": " Okay.", "tokens": [50794, 1033, 13, 50844], "temperature": 0.0, "avg_logprob": -0.2109855047546991, "compression_ratio": 1.7818181818181817, "no_speech_prob": 0.011146810837090015}, {"id": 55, "seek": 19648, "start": 206.07999999999998, "end": 212.07999999999998, "text": " So one of the first things we ran into, JRuby's strings were just based on Java strings and", "tokens": [50844, 407, 472, 295, 264, 700, 721, 321, 5872, 666, 11, 32849, 836, 88, 311, 13985, 645, 445, 2361, 322, 10745, 13985, 293, 51144], "temperature": 0.0, "avg_logprob": -0.2109855047546991, "compression_ratio": 1.7818181818181817, "no_speech_prob": 0.011146810837090015}, {"id": 56, "seek": 19648, "start": 212.07999999999998, "end": 214.39999999999998, "text": " we used Java's regular expressions.", "tokens": [51144, 321, 1143, 10745, 311, 3890, 15277, 13, 51260], "temperature": 0.0, "avg_logprob": -0.2109855047546991, "compression_ratio": 1.7818181818181817, "no_speech_prob": 0.011146810837090015}, {"id": 57, "seek": 19648, "start": 214.39999999999998, "end": 219.39999999999998, "text": " And at the time, regular expressions were being used in very unusual ways in the Ruby", "tokens": [51260, 400, 412, 264, 565, 11, 3890, 15277, 645, 885, 1143, 294, 588, 10901, 2098, 294, 264, 19907, 51510], "temperature": 0.0, "avg_logprob": -0.2109855047546991, "compression_ratio": 1.7818181818181817, "no_speech_prob": 0.011146810837090015}, {"id": 58, "seek": 19648, "start": 219.39999999999998, "end": 220.6, "text": " world.", "tokens": [51510, 1002, 13, 51570], "temperature": 0.0, "avg_logprob": -0.2109855047546991, "compression_ratio": 1.7818181818181817, "no_speech_prob": 0.011146810837090015}, {"id": 59, "seek": 19648, "start": 220.6, "end": 225.04, "text": " We ran into a case in an early version of Rails where they were using regular expression", "tokens": [51570, 492, 5872, 666, 257, 1389, 294, 364, 2440, 3037, 295, 48526, 689, 436, 645, 1228, 3890, 6114, 51792], "temperature": 0.0, "avg_logprob": -0.2109855047546991, "compression_ratio": 1.7818181818181817, "no_speech_prob": 0.011146810837090015}, {"id": 60, "seek": 22504, "start": 225.04, "end": 232.79999999999998, "text": " matching to parse HTTP requests that came in and look for, say, a mime header for an", "tokens": [50364, 14324, 281, 48377, 33283, 12475, 300, 1361, 294, 293, 574, 337, 11, 584, 11, 257, 275, 1312, 23117, 337, 364, 50752], "temperature": 0.0, "avg_logprob": -0.1205501635869344, "compression_ratio": 1.6909722222222223, "no_speech_prob": 0.007573282346129417}, {"id": 61, "seek": 22504, "start": 232.79999999999998, "end": 234.76, "text": " image and pull the image out.", "tokens": [50752, 3256, 293, 2235, 264, 3256, 484, 13, 50850], "temperature": 0.0, "avg_logprob": -0.1205501635869344, "compression_ratio": 1.6909722222222223, "no_speech_prob": 0.007573282346129417}, {"id": 62, "seek": 22504, "start": 234.76, "end": 240.48, "text": " So you'd end up with a regular expression operating against a very large piece of data.", "tokens": [50850, 407, 291, 1116, 917, 493, 365, 257, 3890, 6114, 7447, 1970, 257, 588, 2416, 2522, 295, 1412, 13, 51136], "temperature": 0.0, "avg_logprob": -0.1205501635869344, "compression_ratio": 1.6909722222222223, "no_speech_prob": 0.007573282346129417}, {"id": 63, "seek": 22504, "start": 240.48, "end": 244.72, "text": " And the built-in Java regular expression engine is implemented in such a way that for certain", "tokens": [51136, 400, 264, 3094, 12, 259, 10745, 3890, 6114, 2848, 307, 12270, 294, 1270, 257, 636, 300, 337, 1629, 51348], "temperature": 0.0, "avg_logprob": -0.1205501635869344, "compression_ratio": 1.6909722222222223, "no_speech_prob": 0.007573282346129417}, {"id": 64, "seek": 22504, "start": 244.72, "end": 249.32, "text": " types of expressions like an alternation like this, it actually will recurse and recurse", "tokens": [51348, 3467, 295, 15277, 411, 364, 5400, 399, 411, 341, 11, 309, 767, 486, 18680, 405, 293, 18680, 405, 51578], "temperature": 0.0, "avg_logprob": -0.1205501635869344, "compression_ratio": 1.6909722222222223, "no_speech_prob": 0.007573282346129417}, {"id": 65, "seek": 22504, "start": 249.32, "end": 250.44, "text": " and recurse.", "tokens": [51578, 293, 18680, 405, 13, 51634], "temperature": 0.0, "avg_logprob": -0.1205501635869344, "compression_ratio": 1.6909722222222223, "no_speech_prob": 0.007573282346129417}, {"id": 66, "seek": 22504, "start": 250.44, "end": 254.76, "text": " And then very easily you can blow the stack out by feeding it too much data, just giving", "tokens": [51634, 400, 550, 588, 3612, 291, 393, 6327, 264, 8630, 484, 538, 12919, 309, 886, 709, 1412, 11, 445, 2902, 51850], "temperature": 0.0, "avg_logprob": -0.1205501635869344, "compression_ratio": 1.6909722222222223, "no_speech_prob": 0.007573282346129417}, {"id": 67, "seek": 25476, "start": 254.79999999999998, "end": 256.0, "text": " it too much data.", "tokens": [50366, 309, 886, 709, 1412, 13, 50426], "temperature": 0.0, "avg_logprob": -0.22527598371409407, "compression_ratio": 1.523404255319149, "no_speech_prob": 0.0010002516210079193}, {"id": 68, "seek": 25476, "start": 256.0, "end": 258.52, "text": " To process, we'll blow it up.", "tokens": [50426, 1407, 1399, 11, 321, 603, 6327, 309, 493, 13, 50552], "temperature": 0.0, "avg_logprob": -0.22527598371409407, "compression_ratio": 1.523404255319149, "no_speech_prob": 0.0010002516210079193}, {"id": 69, "seek": 25476, "start": 258.52, "end": 260.0, "text": " So we had to find other options.", "tokens": [50552, 407, 321, 632, 281, 915, 661, 3956, 13, 50626], "temperature": 0.0, "avg_logprob": -0.22527598371409407, "compression_ratio": 1.523404255319149, "no_speech_prob": 0.0010002516210079193}, {"id": 70, "seek": 25476, "start": 260.0, "end": 265.52, "text": " JRegix was an early one that worked against Java strings and we ran with that for quite", "tokens": [50626, 32849, 1146, 970, 390, 364, 2440, 472, 300, 2732, 1970, 10745, 13985, 293, 321, 5872, 365, 300, 337, 1596, 50902], "temperature": 0.0, "avg_logprob": -0.22527598371409407, "compression_ratio": 1.523404255319149, "no_speech_prob": 0.0010002516210079193}, {"id": 71, "seek": 25476, "start": 265.52, "end": 266.88, "text": " a while.", "tokens": [50902, 257, 1339, 13, 50970], "temperature": 0.0, "avg_logprob": -0.22527598371409407, "compression_ratio": 1.523404255319149, "no_speech_prob": 0.0010002516210079193}, {"id": 72, "seek": 25476, "start": 266.88, "end": 273.36, "text": " But eventually it came to be that the Java string itself was insufficient for us to represent", "tokens": [50970, 583, 4728, 309, 1361, 281, 312, 300, 264, 10745, 6798, 2564, 390, 41709, 337, 505, 281, 2906, 51294], "temperature": 0.0, "avg_logprob": -0.22527598371409407, "compression_ratio": 1.523404255319149, "no_speech_prob": 0.0010002516210079193}, {"id": 73, "seek": 25476, "start": 273.36, "end": 276.71999999999997, "text": " Ruby's string behavior.", "tokens": [51294, 19907, 311, 6798, 5223, 13, 51462], "temperature": 0.0, "avg_logprob": -0.22527598371409407, "compression_ratio": 1.523404255319149, "no_speech_prob": 0.0010002516210079193}, {"id": 74, "seek": 25476, "start": 276.71999999999997, "end": 279.2, "text": " Here's what that exception looks like.", "tokens": [51462, 1692, 311, 437, 300, 11183, 1542, 411, 13, 51586], "temperature": 0.0, "avg_logprob": -0.22527598371409407, "compression_ratio": 1.523404255319149, "no_speech_prob": 0.0010002516210079193}, {"id": 75, "seek": 25476, "start": 279.2, "end": 280.36, "text": " Very simple match here.", "tokens": [51586, 4372, 2199, 2995, 510, 13, 51644], "temperature": 0.0, "avg_logprob": -0.22527598371409407, "compression_ratio": 1.523404255319149, "no_speech_prob": 0.0010002516210079193}, {"id": 76, "seek": 28036, "start": 280.40000000000003, "end": 285.88, "text": " It's just 10,000 of the A character followed by a B character with that same regular expression.", "tokens": [50366, 467, 311, 445, 1266, 11, 1360, 295, 264, 316, 2517, 6263, 538, 257, 363, 2517, 365, 300, 912, 3890, 6114, 13, 50640], "temperature": 0.0, "avg_logprob": -0.14372558237236238, "compression_ratio": 1.5692307692307692, "no_speech_prob": 0.006288615986704826}, {"id": 77, "seek": 28036, "start": 285.88, "end": 291.76, "text": " It'll blow up on every version of JVM that's out there or anything based on OpenJDK classes.", "tokens": [50640, 467, 603, 6327, 493, 322, 633, 3037, 295, 508, 53, 44, 300, 311, 484, 456, 420, 1340, 2361, 322, 7238, 41, 35, 42, 5359, 13, 50934], "temperature": 0.0, "avg_logprob": -0.14372558237236238, "compression_ratio": 1.5692307692307692, "no_speech_prob": 0.006288615986704826}, {"id": 78, "seek": 28036, "start": 291.76, "end": 294.92, "text": " And I believe this is still an issue.", "tokens": [50934, 400, 286, 1697, 341, 307, 920, 364, 2734, 13, 51092], "temperature": 0.0, "avg_logprob": -0.14372558237236238, "compression_ratio": 1.5692307692307692, "no_speech_prob": 0.006288615986704826}, {"id": 79, "seek": 28036, "start": 294.92, "end": 303.08000000000004, "text": " So as we went forward and had to have a more robust, more robust regular expression engine", "tokens": [51092, 407, 382, 321, 1437, 2128, 293, 632, 281, 362, 257, 544, 13956, 11, 544, 13956, 3890, 6114, 2848, 51500], "temperature": 0.0, "avg_logprob": -0.14372558237236238, "compression_ratio": 1.5692307692307692, "no_speech_prob": 0.006288615986704826}, {"id": 80, "seek": 28036, "start": 303.08000000000004, "end": 308.8, "text": " that would work with a more custom type string on JRuby that matched CRuby's behavior, we", "tokens": [51500, 300, 576, 589, 365, 257, 544, 2375, 2010, 6798, 322, 32849, 836, 88, 300, 21447, 14123, 836, 88, 311, 5223, 11, 321, 51786], "temperature": 0.0, "avg_logprob": -0.14372558237236238, "compression_ratio": 1.5692307692307692, "no_speech_prob": 0.006288615986704826}, {"id": 81, "seek": 30880, "start": 308.84000000000003, "end": 315.84000000000003, "text": " ported over, or a contributor to JRuby, ported over Ruby's regular expression engine.", "tokens": [50366, 2436, 292, 670, 11, 420, 257, 42859, 281, 32849, 836, 88, 11, 2436, 292, 670, 19907, 311, 3890, 6114, 2848, 13, 50716], "temperature": 0.0, "avg_logprob": -0.19276881217956543, "compression_ratio": 1.609442060085837, "no_speech_prob": 0.009263243526220322}, {"id": 82, "seek": 30880, "start": 315.84000000000003, "end": 321.28000000000003, "text": " So Oniguruma is the C library that Ruby uses for regular expression matching and ours is", "tokens": [50716, 407, 1282, 328, 374, 5544, 307, 264, 383, 6405, 300, 19907, 4960, 337, 3890, 6114, 14324, 293, 11896, 307, 50988], "temperature": 0.0, "avg_logprob": -0.19276881217956543, "compression_ratio": 1.609442060085837, "no_speech_prob": 0.009263243526220322}, {"id": 83, "seek": 30880, "start": 321.28000000000003, "end": 322.28000000000003, "text": " Joanie.", "tokens": [50988, 3139, 7155, 13, 51038], "temperature": 0.0, "avg_logprob": -0.19276881217956543, "compression_ratio": 1.609442060085837, "no_speech_prob": 0.009263243526220322}, {"id": 84, "seek": 30880, "start": 322.28000000000003, "end": 326.8, "text": " It's a byte code based register machine, so there's no stack issues.", "tokens": [51038, 467, 311, 257, 40846, 3089, 2361, 7280, 3479, 11, 370, 456, 311, 572, 8630, 2663, 13, 51264], "temperature": 0.0, "avg_logprob": -0.19276881217956543, "compression_ratio": 1.609442060085837, "no_speech_prob": 0.009263243526220322}, {"id": 85, "seek": 30880, "start": 326.8, "end": 329.28000000000003, "text": " It doesn't deepen the stack at all.", "tokens": [51264, 467, 1177, 380, 45806, 264, 8630, 412, 439, 13, 51388], "temperature": 0.0, "avg_logprob": -0.19276881217956543, "compression_ratio": 1.609442060085837, "no_speech_prob": 0.009263243526220322}, {"id": 86, "seek": 30880, "start": 329.28000000000003, "end": 331.8, "text": " It matches against byte arrays.", "tokens": [51388, 467, 10676, 1970, 40846, 41011, 13, 51514], "temperature": 0.0, "avg_logprob": -0.19276881217956543, "compression_ratio": 1.609442060085837, "no_speech_prob": 0.009263243526220322}, {"id": 87, "seek": 30880, "start": 331.8, "end": 335.12, "text": " And that'll be clear in a moment here why we need that.", "tokens": [51514, 400, 300, 603, 312, 1850, 294, 257, 1623, 510, 983, 321, 643, 300, 13, 51680], "temperature": 0.0, "avg_logprob": -0.19276881217956543, "compression_ratio": 1.609442060085837, "no_speech_prob": 0.009263243526220322}, {"id": 88, "seek": 33512, "start": 335.12, "end": 340.56, "text": " It also can do byte array matching with pluggable encodings, so regardless of what encoding", "tokens": [50364, 467, 611, 393, 360, 40846, 10225, 14324, 365, 499, 3562, 712, 2058, 378, 1109, 11, 370, 10060, 295, 437, 43430, 50636], "temperature": 0.0, "avg_logprob": -0.13333335130111032, "compression_ratio": 1.6540084388185654, "no_speech_prob": 0.001866897102445364}, {"id": 89, "seek": 33512, "start": 340.56, "end": 345.76, "text": " those characters are in, and potentially if you want to use a different grammar for regular", "tokens": [50636, 729, 4342, 366, 294, 11, 293, 7263, 498, 291, 528, 281, 764, 257, 819, 22317, 337, 3890, 50896], "temperature": 0.0, "avg_logprob": -0.13333335130111032, "compression_ratio": 1.6540084388185654, "no_speech_prob": 0.001866897102445364}, {"id": 90, "seek": 33512, "start": 345.76, "end": 347.08, "text": " expression.", "tokens": [50896, 6114, 13, 50962], "temperature": 0.0, "avg_logprob": -0.13333335130111032, "compression_ratio": 1.6540084388185654, "no_speech_prob": 0.001866897102445364}, {"id": 91, "seek": 33512, "start": 347.08, "end": 354.28000000000003, "text": " This library was ported to characters and used by Nazhorn to do JavaScript regular expressions.", "tokens": [50962, 639, 6405, 390, 2436, 292, 281, 4342, 293, 1143, 538, 11870, 31990, 281, 360, 15778, 3890, 15277, 13, 51322], "temperature": 0.0, "avg_logprob": -0.13333335130111032, "compression_ratio": 1.6540084388185654, "no_speech_prob": 0.001866897102445364}, {"id": 92, "seek": 33512, "start": 354.28000000000003, "end": 358.68, "text": " They had the same sort of problems, and so they used our library but made it specific", "tokens": [51322, 814, 632, 264, 912, 1333, 295, 2740, 11, 293, 370, 436, 1143, 527, 6405, 457, 1027, 309, 2685, 51542], "temperature": 0.0, "avg_logprob": -0.13333335130111032, "compression_ratio": 1.6540084388185654, "no_speech_prob": 0.001866897102445364}, {"id": 93, "seek": 33512, "start": 358.68, "end": 362.08, "text": " to JavaScript.", "tokens": [51542, 281, 15778, 13, 51712], "temperature": 0.0, "avg_logprob": -0.13333335130111032, "compression_ratio": 1.6540084388185654, "no_speech_prob": 0.001866897102445364}, {"id": 94, "seek": 36208, "start": 362.08, "end": 366.32, "text": " So you see that I'm matching against byte arrays here and I said that strings were insufficient.", "tokens": [50364, 407, 291, 536, 300, 286, 478, 14324, 1970, 40846, 41011, 510, 293, 286, 848, 300, 13985, 645, 41709, 13, 50576], "temperature": 0.0, "avg_logprob": -0.11592634374445135, "compression_ratio": 1.768060836501901, "no_speech_prob": 0.13261345028877258}, {"id": 95, "seek": 36208, "start": 366.32, "end": 371.28, "text": " Well the problem is that Ruby's string is not just one encoding, it's not just a blob", "tokens": [50576, 1042, 264, 1154, 307, 300, 19907, 311, 6798, 307, 406, 445, 472, 43430, 11, 309, 311, 406, 445, 257, 46115, 50824], "temperature": 0.0, "avg_logprob": -0.11592634374445135, "compression_ratio": 1.768060836501901, "no_speech_prob": 0.13261345028877258}, {"id": 96, "seek": 36208, "start": 371.28, "end": 375.96, "text": " of characters, it is represented as a byte array with an encoding.", "tokens": [50824, 295, 4342, 11, 309, 307, 10379, 382, 257, 40846, 10225, 365, 364, 43430, 13, 51058], "temperature": 0.0, "avg_logprob": -0.11592634374445135, "compression_ratio": 1.768060836501901, "no_speech_prob": 0.13261345028877258}, {"id": 97, "seek": 36208, "start": 375.96, "end": 381.32, "text": " So within the system you can have many strings that all have different encodings and it all", "tokens": [51058, 407, 1951, 264, 1185, 291, 393, 362, 867, 13985, 300, 439, 362, 819, 2058, 378, 1109, 293, 309, 439, 51326], "temperature": 0.0, "avg_logprob": -0.11592634374445135, "compression_ratio": 1.768060836501901, "no_speech_prob": 0.13261345028877258}, {"id": 98, "seek": 36208, "start": 381.32, "end": 386.24, "text": " needs to be negotiated together when you combine them or use them against each other.", "tokens": [51326, 2203, 281, 312, 39028, 1214, 562, 291, 10432, 552, 420, 764, 552, 1970, 1184, 661, 13, 51572], "temperature": 0.0, "avg_logprob": -0.11592634374445135, "compression_ratio": 1.768060836501901, "no_speech_prob": 0.13261345028877258}, {"id": 99, "seek": 36208, "start": 386.24, "end": 388.32, "text": " So we had to follow suit essentially.", "tokens": [51572, 407, 321, 632, 281, 1524, 5722, 4476, 13, 51676], "temperature": 0.0, "avg_logprob": -0.11592634374445135, "compression_ratio": 1.768060836501901, "no_speech_prob": 0.13261345028877258}, {"id": 100, "seek": 38832, "start": 388.32, "end": 394.64, "text": " We had to make a new string class for JRuby that used bytes, used a byte array, represented", "tokens": [50364, 492, 632, 281, 652, 257, 777, 6798, 1508, 337, 32849, 836, 88, 300, 1143, 36088, 11, 1143, 257, 40846, 10225, 11, 10379, 50680], "temperature": 0.0, "avg_logprob": -0.145482535834785, "compression_ratio": 1.714828897338403, "no_speech_prob": 0.04204811528325081}, {"id": 101, "seek": 38832, "start": 394.64, "end": 399.32, "text": " all the encodings, port all of the encoding logic over and the transcoding logic, which", "tokens": [50680, 439, 264, 2058, 378, 1109, 11, 2436, 439, 295, 264, 43430, 9952, 670, 293, 264, 43800, 8616, 9952, 11, 597, 50914], "temperature": 0.0, "avg_logprob": -0.145482535834785, "compression_ratio": 1.714828897338403, "no_speech_prob": 0.04204811528325081}, {"id": 102, "seek": 38832, "start": 399.32, "end": 402.52, "text": " was a major piece of work.", "tokens": [50914, 390, 257, 2563, 2522, 295, 589, 13, 51074], "temperature": 0.0, "avg_logprob": -0.145482535834785, "compression_ratio": 1.714828897338403, "no_speech_prob": 0.04204811528325081}, {"id": 103, "seek": 38832, "start": 402.52, "end": 407.56, "text": " And essentially we have our own string now and we've had this for over a decade because", "tokens": [51074, 400, 4476, 321, 362, 527, 1065, 6798, 586, 293, 321, 600, 632, 341, 337, 670, 257, 10378, 570, 51326], "temperature": 0.0, "avg_logprob": -0.145482535834785, "compression_ratio": 1.714828897338403, "no_speech_prob": 0.04204811528325081}, {"id": 104, "seek": 38832, "start": 407.56, "end": 413.15999999999997, "text": " Java strings just could not emulate all of the behaviors we needed for Ruby.", "tokens": [51326, 10745, 13985, 445, 727, 406, 45497, 439, 295, 264, 15501, 321, 2978, 337, 19907, 13, 51606], "temperature": 0.0, "avg_logprob": -0.145482535834785, "compression_ratio": 1.714828897338403, "no_speech_prob": 0.04204811528325081}, {"id": 105, "seek": 38832, "start": 413.15999999999997, "end": 418.0, "text": " This does complicate interop with Java but there are improvements coming there.", "tokens": [51606, 639, 775, 1209, 8700, 728, 404, 365, 10745, 457, 456, 366, 13797, 1348, 456, 13, 51848], "temperature": 0.0, "avg_logprob": -0.145482535834785, "compression_ratio": 1.714828897338403, "no_speech_prob": 0.04204811528325081}, {"id": 106, "seek": 41800, "start": 418.0, "end": 422.0, "text": " So J-codings is the encoding library that we use.", "tokens": [50364, 407, 508, 12, 66, 378, 1109, 307, 264, 43430, 6405, 300, 321, 764, 13, 50564], "temperature": 0.0, "avg_logprob": -0.12694892287254333, "compression_ratio": 1.7719298245614035, "no_speech_prob": 0.0028000317979604006}, {"id": 107, "seek": 41800, "start": 422.0, "end": 427.32, "text": " This provides the full set of encodings similar to what's in CRuby and the transcoding from", "tokens": [50564, 639, 6417, 264, 1577, 992, 295, 2058, 378, 1109, 2531, 281, 437, 311, 294, 14123, 836, 88, 293, 264, 43800, 8616, 490, 50830], "temperature": 0.0, "avg_logprob": -0.12694892287254333, "compression_ratio": 1.7719298245614035, "no_speech_prob": 0.0028000317979604006}, {"id": 108, "seek": 41800, "start": 427.32, "end": 431.24, "text": " any encoding to another encoding, which is used internally when we have two different", "tokens": [50830, 604, 43430, 281, 1071, 43430, 11, 597, 307, 1143, 19501, 562, 321, 362, 732, 819, 51026], "temperature": 0.0, "avg_logprob": -0.12694892287254333, "compression_ratio": 1.7719298245614035, "no_speech_prob": 0.0028000317979604006}, {"id": 109, "seek": 41800, "start": 431.24, "end": 434.6, "text": " strings come together and need to negotiate that.", "tokens": [51026, 13985, 808, 1214, 293, 643, 281, 21713, 300, 13, 51194], "temperature": 0.0, "avg_logprob": -0.12694892287254333, "compression_ratio": 1.7719298245614035, "no_speech_prob": 0.0028000317979604006}, {"id": 110, "seek": 41800, "start": 434.6, "end": 436.4, "text": " So where do we stand on the JVM today?", "tokens": [51194, 407, 689, 360, 321, 1463, 322, 264, 508, 53, 44, 965, 30, 51284], "temperature": 0.0, "avg_logprob": -0.12694892287254333, "compression_ratio": 1.7719298245614035, "no_speech_prob": 0.0028000317979604006}, {"id": 111, "seek": 41800, "start": 436.4, "end": 440.8, "text": " Well rather than just having a character array inside strings, we do actually have a similar", "tokens": [51284, 1042, 2831, 813, 445, 1419, 257, 2517, 10225, 1854, 13985, 11, 321, 360, 767, 362, 257, 2531, 51504], "temperature": 0.0, "avg_logprob": -0.12694892287254333, "compression_ratio": 1.7719298245614035, "no_speech_prob": 0.0028000317979604006}, {"id": 112, "seek": 41800, "start": 440.8, "end": 445.24, "text": " model now where there's a byte array but only two encodings are allowed inside that", "tokens": [51504, 2316, 586, 689, 456, 311, 257, 40846, 10225, 457, 787, 732, 2058, 378, 1109, 366, 4350, 1854, 300, 51726], "temperature": 0.0, "avg_logprob": -0.12694892287254333, "compression_ratio": 1.7719298245614035, "no_speech_prob": 0.0028000317979604006}, {"id": 113, "seek": 41800, "start": 445.24, "end": 446.24, "text": " byte array.", "tokens": [51726, 40846, 10225, 13, 51776], "temperature": 0.0, "avg_logprob": -0.12694892287254333, "compression_ratio": 1.7719298245614035, "no_speech_prob": 0.0028000317979604006}, {"id": 114, "seek": 44624, "start": 446.68, "end": 454.24, "text": " ISO 88591, which is essentially just the 128 bits of ASCII, or UTF-16, the old standard", "tokens": [50386, 25042, 24587, 19600, 16, 11, 597, 307, 4476, 445, 264, 29810, 9239, 295, 7469, 34, 9503, 11, 420, 624, 20527, 12, 6866, 11, 264, 1331, 3832, 50764], "temperature": 0.0, "avg_logprob": -0.1749435686597637, "compression_ratio": 1.517094017094017, "no_speech_prob": 0.003171836491674185}, {"id": 115, "seek": 44624, "start": 454.24, "end": 455.64, "text": " character.", "tokens": [50764, 2517, 13, 50834], "temperature": 0.0, "avg_logprob": -0.1749435686597637, "compression_ratio": 1.517094017094017, "no_speech_prob": 0.003171836491674185}, {"id": 116, "seek": 44624, "start": 455.64, "end": 461.16, "text": " So this does lower our cost going to and from Ruby and Java when we are just using an ASCII", "tokens": [50834, 407, 341, 775, 3126, 527, 2063, 516, 281, 293, 490, 19907, 293, 10745, 562, 321, 366, 445, 1228, 364, 7469, 34, 9503, 51110], "temperature": 0.0, "avg_logprob": -0.1749435686597637, "compression_ratio": 1.517094017094017, "no_speech_prob": 0.003171836491674185}, {"id": 117, "seek": 44624, "start": 461.16, "end": 466.72, "text": " range of characters, but UTF-8 would be nice to have there because most Ruby strings are", "tokens": [51110, 3613, 295, 4342, 11, 457, 624, 20527, 12, 23, 576, 312, 1481, 281, 362, 456, 570, 881, 19907, 13985, 366, 51388], "temperature": 0.0, "avg_logprob": -0.1749435686597637, "compression_ratio": 1.517094017094017, "no_speech_prob": 0.003171836491674185}, {"id": 118, "seek": 44624, "start": 466.72, "end": 471.96000000000004, "text": " going to be UTF-8 probably with at least one multi-byte character in there.", "tokens": [51388, 516, 281, 312, 624, 20527, 12, 23, 1391, 365, 412, 1935, 472, 4825, 12, 2322, 975, 2517, 294, 456, 13, 51650], "temperature": 0.0, "avg_logprob": -0.1749435686597637, "compression_ratio": 1.517094017094017, "no_speech_prob": 0.003171836491674185}, {"id": 119, "seek": 47196, "start": 471.96, "end": 477.0, "text": " So that has to all be copied over a lot more, a lot less efficiently.", "tokens": [50364, 407, 300, 575, 281, 439, 312, 25365, 670, 257, 688, 544, 11, 257, 688, 1570, 19621, 13, 50616], "temperature": 0.0, "avg_logprob": -0.16361185998627634, "compression_ratio": 1.5904436860068258, "no_speech_prob": 0.01590304635465145}, {"id": 120, "seek": 47196, "start": 477.0, "end": 478.91999999999996, "text": " And Java Util Rejects does still blow the stack.", "tokens": [50616, 400, 10745, 12555, 388, 1300, 1020, 82, 775, 920, 6327, 264, 8630, 13, 50712], "temperature": 0.0, "avg_logprob": -0.16361185998627634, "compression_ratio": 1.5904436860068258, "no_speech_prob": 0.01590304635465145}, {"id": 121, "seek": 47196, "start": 478.91999999999996, "end": 482.0, "text": " I would love to see it get replaced at some point, but I don't know if there's any work", "tokens": [50712, 286, 576, 959, 281, 536, 309, 483, 10772, 412, 512, 935, 11, 457, 286, 500, 380, 458, 498, 456, 311, 604, 589, 50866], "temperature": 0.0, "avg_logprob": -0.16361185998627634, "compression_ratio": 1.5904436860068258, "no_speech_prob": 0.01590304635465145}, {"id": 122, "seek": 47196, "start": 482.0, "end": 483.88, "text": " being done to do that.", "tokens": [50866, 885, 1096, 281, 360, 300, 13, 50960], "temperature": 0.0, "avg_logprob": -0.16361185998627634, "compression_ratio": 1.5904436860068258, "no_speech_prob": 0.01590304635465145}, {"id": 123, "seek": 47196, "start": 483.88, "end": 490.32, "text": " Okay, so the next area that we ran into was that we have a nice runtime, but the performance", "tokens": [50960, 1033, 11, 370, 264, 958, 1859, 300, 321, 5872, 666, 390, 300, 321, 362, 257, 1481, 34474, 11, 457, 264, 3389, 51282], "temperature": 0.0, "avg_logprob": -0.16361185998627634, "compression_ratio": 1.5904436860068258, "no_speech_prob": 0.01590304635465145}, {"id": 124, "seek": 47196, "start": 490.32, "end": 491.32, "text": " wasn't there.", "tokens": [51282, 2067, 380, 456, 13, 51332], "temperature": 0.0, "avg_logprob": -0.16361185998627634, "compression_ratio": 1.5904436860068258, "no_speech_prob": 0.01590304635465145}, {"id": 125, "seek": 47196, "start": 491.32, "end": 496.71999999999997, "text": " We needed to be able to generate JVM bytecode from Ruby code and have it optimize like regular", "tokens": [51332, 492, 2978, 281, 312, 1075, 281, 8460, 508, 53, 44, 40846, 22332, 490, 19907, 3089, 293, 362, 309, 19719, 411, 3890, 51602], "temperature": 0.0, "avg_logprob": -0.16361185998627634, "compression_ratio": 1.5904436860068258, "no_speech_prob": 0.01590304635465145}, {"id": 126, "seek": 47196, "start": 496.71999999999997, "end": 497.71999999999997, "text": " Java.", "tokens": [51602, 10745, 13, 51652], "temperature": 0.0, "avg_logprob": -0.16361185998627634, "compression_ratio": 1.5904436860068258, "no_speech_prob": 0.01590304635465145}, {"id": 127, "seek": 47196, "start": 497.71999999999997, "end": 499.71999999999997, "text": " So the interpreter was good.", "tokens": [51652, 407, 264, 34132, 390, 665, 13, 51752], "temperature": 0.0, "avg_logprob": -0.16361185998627634, "compression_ratio": 1.5904436860068258, "no_speech_prob": 0.01590304635465145}, {"id": 128, "seek": 49972, "start": 499.72, "end": 506.56, "text": " It was similar to Ruby 1.8 before they moved to their own bytecode runtime.", "tokens": [50364, 467, 390, 2531, 281, 19907, 502, 13, 23, 949, 436, 4259, 281, 641, 1065, 40846, 22332, 34474, 13, 50706], "temperature": 0.0, "avg_logprob": -0.08955683259882478, "compression_ratio": 1.6064981949458483, "no_speech_prob": 0.019114624708890915}, {"id": 129, "seek": 49972, "start": 506.56, "end": 508.96000000000004, "text": " It was very difficult for the JVM to optimize.", "tokens": [50706, 467, 390, 588, 2252, 337, 264, 508, 53, 44, 281, 19719, 13, 50826], "temperature": 0.0, "avg_logprob": -0.08955683259882478, "compression_ratio": 1.6064981949458483, "no_speech_prob": 0.019114624708890915}, {"id": 130, "seek": 49972, "start": 508.96000000000004, "end": 512.84, "text": " We could walk through this stuff quickly and it was very easy to write as an interpreter,", "tokens": [50826, 492, 727, 1792, 807, 341, 1507, 2661, 293, 309, 390, 588, 1858, 281, 2464, 382, 364, 34132, 11, 51020], "temperature": 0.0, "avg_logprob": -0.08955683259882478, "compression_ratio": 1.6064981949458483, "no_speech_prob": 0.019114624708890915}, {"id": 131, "seek": 49972, "start": 512.84, "end": 516.6800000000001, "text": " but you had a lot of polymorphic calls within that AST.", "tokens": [51020, 457, 291, 632, 257, 688, 295, 6754, 76, 18191, 299, 5498, 1951, 300, 316, 6840, 13, 51212], "temperature": 0.0, "avg_logprob": -0.08955683259882478, "compression_ratio": 1.6064981949458483, "no_speech_prob": 0.019114624708890915}, {"id": 132, "seek": 49972, "start": 516.6800000000001, "end": 519.5600000000001, "text": " It never really could see the optimization path through there.", "tokens": [51212, 467, 1128, 534, 727, 536, 264, 19618, 3100, 807, 456, 13, 51356], "temperature": 0.0, "avg_logprob": -0.08955683259882478, "compression_ratio": 1.6064981949458483, "no_speech_prob": 0.019114624708890915}, {"id": 133, "seek": 49972, "start": 519.5600000000001, "end": 522.36, "text": " So we had to write a JIT.", "tokens": [51356, 407, 321, 632, 281, 2464, 257, 508, 3927, 13, 51496], "temperature": 0.0, "avg_logprob": -0.08955683259882478, "compression_ratio": 1.6064981949458483, "no_speech_prob": 0.019114624708890915}, {"id": 134, "seek": 49972, "start": 522.36, "end": 527.08, "text": " The reason that we did not just immediately start compiling all Ruby code into bytecode", "tokens": [51496, 440, 1778, 300, 321, 630, 406, 445, 4258, 722, 715, 4883, 439, 19907, 3089, 666, 40846, 22332, 51732], "temperature": 0.0, "avg_logprob": -0.08955683259882478, "compression_ratio": 1.6064981949458483, "no_speech_prob": 0.019114624708890915}, {"id": 135, "seek": 52708, "start": 527.08, "end": 535.2, "text": " is because, for example, the Rails library will load into memory thousands of classes,", "tokens": [50364, 307, 570, 11, 337, 1365, 11, 264, 48526, 6405, 486, 3677, 666, 4675, 5383, 295, 5359, 11, 50770], "temperature": 0.0, "avg_logprob": -0.13759445125221187, "compression_ratio": 1.8379446640316206, "no_speech_prob": 0.0209512822329998}, {"id": 136, "seek": 52708, "start": 535.2, "end": 539.32, "text": " tens of, or tens of thousands of methods, or tens of thousands of methods.", "tokens": [50770, 10688, 295, 11, 420, 10688, 295, 5383, 295, 7150, 11, 420, 10688, 295, 5383, 295, 7150, 13, 50976], "temperature": 0.0, "avg_logprob": -0.13759445125221187, "compression_ratio": 1.8379446640316206, "no_speech_prob": 0.0209512822329998}, {"id": 137, "seek": 52708, "start": 539.32, "end": 544.5, "text": " That's a massive load for us to put onto the JVM when only a few hundred or a few thousand", "tokens": [50976, 663, 311, 257, 5994, 3677, 337, 505, 281, 829, 3911, 264, 508, 53, 44, 562, 787, 257, 1326, 3262, 420, 257, 1326, 4714, 51235], "temperature": 0.0, "avg_logprob": -0.13759445125221187, "compression_ratio": 1.8379446640316206, "no_speech_prob": 0.0209512822329998}, {"id": 138, "seek": 52708, "start": 544.5, "end": 547.0, "text": " of those are ever going to be called.", "tokens": [51235, 295, 729, 366, 1562, 516, 281, 312, 1219, 13, 51360], "temperature": 0.0, "avg_logprob": -0.13759445125221187, "compression_ratio": 1.8379446640316206, "no_speech_prob": 0.0209512822329998}, {"id": 139, "seek": 52708, "start": 547.0, "end": 551.32, "text": " It also was slower for us to go straight to bytecode because the bytecode would end up", "tokens": [51360, 467, 611, 390, 14009, 337, 505, 281, 352, 2997, 281, 40846, 22332, 570, 264, 40846, 22332, 576, 917, 493, 51576], "temperature": 0.0, "avg_logprob": -0.13759445125221187, "compression_ratio": 1.8379446640316206, "no_speech_prob": 0.0209512822329998}, {"id": 140, "seek": 52708, "start": 551.32, "end": 556.36, "text": " being interpreted by the JVM's interpreter, which actually turned out to be slower than", "tokens": [51576, 885, 26749, 538, 264, 508, 53, 44, 311, 34132, 11, 597, 767, 3574, 484, 281, 312, 14009, 813, 51828], "temperature": 0.0, "avg_logprob": -0.13759445125221187, "compression_ratio": 1.8379446640316206, "no_speech_prob": 0.0209512822329998}, {"id": 141, "seek": 55636, "start": 556.36, "end": 559.0, "text": " our interpreter after it JITs.", "tokens": [50364, 527, 34132, 934, 309, 508, 3927, 82, 13, 50496], "temperature": 0.0, "avg_logprob": -0.1361449679037682, "compression_ratio": 1.7303370786516854, "no_speech_prob": 0.012813512235879898}, {"id": 142, "seek": 55636, "start": 559.0, "end": 563.12, "text": " So it made more sense for us to leave it in our interpreter until we saw it really needed", "tokens": [50496, 407, 309, 1027, 544, 2020, 337, 505, 281, 1856, 309, 294, 527, 34132, 1826, 321, 1866, 309, 534, 2978, 50702], "temperature": 0.0, "avg_logprob": -0.1361449679037682, "compression_ratio": 1.7303370786516854, "no_speech_prob": 0.012813512235879898}, {"id": 143, "seek": 55636, "start": 563.12, "end": 569.44, "text": " JVM bytecode, and there we ended up with basically the first mixed-mode JIT runtime on top of", "tokens": [50702, 508, 53, 44, 40846, 22332, 11, 293, 456, 321, 4590, 493, 365, 1936, 264, 700, 7467, 12, 76, 1429, 508, 3927, 34474, 322, 1192, 295, 51018], "temperature": 0.0, "avg_logprob": -0.1361449679037682, "compression_ratio": 1.7303370786516854, "no_speech_prob": 0.012813512235879898}, {"id": 144, "seek": 55636, "start": 569.44, "end": 572.12, "text": " the JVM.", "tokens": [51018, 264, 508, 53, 44, 13, 51152], "temperature": 0.0, "avg_logprob": -0.1361449679037682, "compression_ratio": 1.7303370786516854, "no_speech_prob": 0.012813512235879898}, {"id": 145, "seek": 55636, "start": 572.12, "end": 575.32, "text": " Later on, we did move to a more modern compiler design.", "tokens": [51152, 11965, 322, 11, 321, 630, 1286, 281, 257, 544, 4363, 31958, 1715, 13, 51312], "temperature": 0.0, "avg_logprob": -0.1361449679037682, "compression_ratio": 1.7303370786516854, "no_speech_prob": 0.012813512235879898}, {"id": 146, "seek": 55636, "start": 575.32, "end": 580.36, "text": " We had a compiler engineer, Sabu Sastri, come in and help, and he basically helped us move", "tokens": [51312, 492, 632, 257, 31958, 11403, 11, 13915, 84, 318, 525, 470, 11, 808, 294, 293, 854, 11, 293, 415, 1936, 4254, 505, 1286, 51564], "temperature": 0.0, "avg_logprob": -0.1361449679037682, "compression_ratio": 1.7303370786516854, "no_speech_prob": 0.012813512235879898}, {"id": 147, "seek": 55636, "start": 580.36, "end": 586.0, "text": " a lot of the little P-Pole optimizations I was doing in my JIT up to a more modern compiler", "tokens": [51564, 257, 688, 295, 264, 707, 430, 12, 47, 4812, 5028, 14455, 286, 390, 884, 294, 452, 508, 3927, 493, 281, 257, 544, 4363, 31958, 51846], "temperature": 0.0, "avg_logprob": -0.1361449679037682, "compression_ratio": 1.7303370786516854, "no_speech_prob": 0.012813512235879898}, {"id": 148, "seek": 58600, "start": 586.04, "end": 587.36, "text": " architecture.", "tokens": [50366, 9482, 13, 50432], "temperature": 0.0, "avg_logprob": -0.13802903836911862, "compression_ratio": 1.5598455598455598, "no_speech_prob": 0.02593350037932396}, {"id": 149, "seek": 58600, "start": 587.36, "end": 593.52, "text": " So this simplified the JIT, simplified what I had to write as far as emitting bytecode,", "tokens": [50432, 407, 341, 26335, 264, 508, 3927, 11, 26335, 437, 286, 632, 281, 2464, 382, 1400, 382, 846, 2414, 40846, 22332, 11, 50740], "temperature": 0.0, "avg_logprob": -0.13802903836911862, "compression_ratio": 1.5598455598455598, "no_speech_prob": 0.02593350037932396}, {"id": 150, "seek": 58600, "start": 593.52, "end": 597.56, "text": " which then let me explore performance a lot more in other ways.", "tokens": [50740, 597, 550, 718, 385, 6839, 3389, 257, 688, 544, 294, 661, 2098, 13, 50942], "temperature": 0.0, "avg_logprob": -0.13802903836911862, "compression_ratio": 1.5598455598455598, "no_speech_prob": 0.02593350037932396}, {"id": 151, "seek": 58600, "start": 597.56, "end": 601.84, "text": " And then of course, as we move forward, we got invokeDynamic in Java 7.", "tokens": [50942, 400, 550, 295, 1164, 11, 382, 321, 1286, 2128, 11, 321, 658, 41117, 35, 5216, 299, 294, 10745, 1614, 13, 51156], "temperature": 0.0, "avg_logprob": -0.13802903836911862, "compression_ratio": 1.5598455598455598, "no_speech_prob": 0.02593350037932396}, {"id": 152, "seek": 58600, "start": 601.84, "end": 604.08, "text": " It's been steadily improving since then.", "tokens": [51156, 467, 311, 668, 36129, 11470, 1670, 550, 13, 51268], "temperature": 0.0, "avg_logprob": -0.13802903836911862, "compression_ratio": 1.5598455598455598, "no_speech_prob": 0.02593350037932396}, {"id": 153, "seek": 58600, "start": 604.08, "end": 607.92, "text": " It's used incredibly heavily in JRuby.", "tokens": [51268, 467, 311, 1143, 6252, 10950, 294, 32849, 836, 88, 13, 51460], "temperature": 0.0, "avg_logprob": -0.13802903836911862, "compression_ratio": 1.5598455598455598, "no_speech_prob": 0.02593350037932396}, {"id": 154, "seek": 58600, "start": 607.92, "end": 613.76, "text": " If you take the bytecode of our JIT output from Ruby code, it's pretty much just stack", "tokens": [51460, 759, 291, 747, 264, 40846, 22332, 295, 527, 508, 3927, 5598, 490, 19907, 3089, 11, 309, 311, 1238, 709, 445, 8630, 51752], "temperature": 0.0, "avg_logprob": -0.13802903836911862, "compression_ratio": 1.5598455598455598, "no_speech_prob": 0.02593350037932396}, {"id": 155, "seek": 61376, "start": 613.8, "end": 618.12, "text": " moves and invokeDynamics for almost everything that we do.", "tokens": [50366, 6067, 293, 41117, 35, 5216, 1167, 337, 1920, 1203, 300, 321, 360, 13, 50582], "temperature": 0.0, "avg_logprob": -0.14068688187643746, "compression_ratio": 1.6273764258555132, "no_speech_prob": 0.0046074786223471165}, {"id": 156, "seek": 61376, "start": 618.12, "end": 622.04, "text": " We will access local variables normally, but everything else has to have some little", "tokens": [50582, 492, 486, 2105, 2654, 9102, 5646, 11, 457, 1203, 1646, 575, 281, 362, 512, 707, 50778], "temperature": 0.0, "avg_logprob": -0.14068688187643746, "compression_ratio": 1.6273764258555132, "no_speech_prob": 0.0046074786223471165}, {"id": 157, "seek": 61376, "start": 622.04, "end": 624.48, "text": " dynamic aspect as part of Ruby.", "tokens": [50778, 8546, 4171, 382, 644, 295, 19907, 13, 50900], "temperature": 0.0, "avg_logprob": -0.14068688187643746, "compression_ratio": 1.6273764258555132, "no_speech_prob": 0.0046074786223471165}, {"id": 158, "seek": 61376, "start": 624.48, "end": 628.6, "text": " So we use it very heavily and probably more heavily than almost any other project on the", "tokens": [50900, 407, 321, 764, 309, 588, 10950, 293, 1391, 544, 10950, 813, 1920, 604, 661, 1716, 322, 264, 51106], "temperature": 0.0, "avg_logprob": -0.14068688187643746, "compression_ratio": 1.6273764258555132, "no_speech_prob": 0.0046074786223471165}, {"id": 159, "seek": 61376, "start": 628.6, "end": 631.0, "text": " JVM.", "tokens": [51106, 508, 53, 44, 13, 51226], "temperature": 0.0, "avg_logprob": -0.14068688187643746, "compression_ratio": 1.6273764258555132, "no_speech_prob": 0.0046074786223471165}, {"id": 160, "seek": 61376, "start": 631.0, "end": 637.28, "text": " This is invokeDynamic performance over time from Java 8 up to 17.", "tokens": [51226, 639, 307, 41117, 35, 5216, 299, 3389, 670, 565, 490, 10745, 1649, 493, 281, 3282, 13, 51540], "temperature": 0.0, "avg_logprob": -0.14068688187643746, "compression_ratio": 1.6273764258555132, "no_speech_prob": 0.0046074786223471165}, {"id": 161, "seek": 61376, "start": 637.28, "end": 640.6, "text": " Really happy to see the performance improvements every release.", "tokens": [51540, 4083, 2055, 281, 536, 264, 3389, 13797, 633, 4374, 13, 51706], "temperature": 0.0, "avg_logprob": -0.14068688187643746, "compression_ratio": 1.6273764258555132, "no_speech_prob": 0.0046074786223471165}, {"id": 162, "seek": 61376, "start": 640.6, "end": 643.2, "text": " It gets a little bit better.", "tokens": [51706, 467, 2170, 257, 707, 857, 1101, 13, 51836], "temperature": 0.0, "avg_logprob": -0.14068688187643746, "compression_ratio": 1.6273764258555132, "no_speech_prob": 0.0046074786223471165}, {"id": 163, "seek": 64320, "start": 643.24, "end": 647.76, "text": " Looking at what we're doing with a more numeric algorithm, we get a bigger boost out of it.", "tokens": [50366, 11053, 412, 437, 321, 434, 884, 365, 257, 544, 7866, 299, 9284, 11, 321, 483, 257, 3801, 9194, 484, 295, 309, 13, 50592], "temperature": 0.0, "avg_logprob": -0.14056384134635652, "compression_ratio": 1.7581699346405228, "no_speech_prob": 0.013624880462884903}, {"id": 164, "seek": 64320, "start": 647.76, "end": 651.2800000000001, "text": " With something that's just walking a lot of objects, we're already kind of close to where", "tokens": [50592, 2022, 746, 300, 311, 445, 4494, 257, 688, 295, 6565, 11, 321, 434, 1217, 733, 295, 1998, 281, 689, 50768], "temperature": 0.0, "avg_logprob": -0.14056384134635652, "compression_ratio": 1.7581699346405228, "no_speech_prob": 0.013624880462884903}, {"id": 165, "seek": 64320, "start": 651.2800000000001, "end": 656.0400000000001, "text": " Java would be on just walking an object graph, but still seeing that we do get some improvements", "tokens": [50768, 10745, 576, 312, 322, 445, 4494, 364, 2657, 4295, 11, 457, 920, 2577, 300, 321, 360, 483, 512, 13797, 51006], "temperature": 0.0, "avg_logprob": -0.14056384134635652, "compression_ratio": 1.7581699346405228, "no_speech_prob": 0.013624880462884903}, {"id": 166, "seek": 64320, "start": 656.0400000000001, "end": 659.8000000000001, "text": " from running invokeDynamic, making that more direct.", "tokens": [51006, 490, 2614, 41117, 35, 5216, 299, 11, 1455, 300, 544, 2047, 13, 51194], "temperature": 0.0, "avg_logprob": -0.14056384134635652, "compression_ratio": 1.7581699346405228, "no_speech_prob": 0.013624880462884903}, {"id": 167, "seek": 64320, "start": 659.8000000000001, "end": 662.96, "text": " Really cool is when we plug in a different JIT compiler here.", "tokens": [51194, 4083, 1627, 307, 562, 321, 5452, 294, 257, 819, 508, 3927, 31958, 510, 13, 51352], "temperature": 0.0, "avg_logprob": -0.14056384134635652, "compression_ratio": 1.7581699346405228, "no_speech_prob": 0.013624880462884903}, {"id": 168, "seek": 64320, "start": 662.96, "end": 667.4000000000001, "text": " So this is now using invokeDynamic on the Grawl JIT.", "tokens": [51352, 407, 341, 307, 586, 1228, 41117, 35, 5216, 299, 322, 264, 460, 5131, 75, 508, 3927, 13, 51574], "temperature": 0.0, "avg_logprob": -0.14056384134635652, "compression_ratio": 1.7581699346405228, "no_speech_prob": 0.013624880462884903}, {"id": 169, "seek": 64320, "start": 667.4000000000001, "end": 672.24, "text": " And for a numeric algorithm where we're creating tons of numeric objects, we really see the", "tokens": [51574, 400, 337, 257, 7866, 299, 9284, 689, 321, 434, 4084, 9131, 295, 7866, 299, 6565, 11, 321, 534, 536, 264, 51816], "temperature": 0.0, "avg_logprob": -0.14056384134635652, "compression_ratio": 1.7581699346405228, "no_speech_prob": 0.013624880462884903}, {"id": 170, "seek": 67224, "start": 672.28, "end": 676.08, "text": " impact of partial escape analysis helping us.", "tokens": [50366, 2712, 295, 14641, 7615, 5215, 4315, 505, 13, 50556], "temperature": 0.0, "avg_logprob": -0.13468237106616682, "compression_ratio": 1.6434108527131783, "no_speech_prob": 0.0015004888409748673}, {"id": 171, "seek": 67224, "start": 676.08, "end": 681.52, "text": " And this is now really starting to get to the point of Java level performance for a numeric", "tokens": [50556, 400, 341, 307, 586, 534, 2891, 281, 483, 281, 264, 935, 295, 10745, 1496, 3389, 337, 257, 7866, 299, 50828], "temperature": 0.0, "avg_logprob": -0.13468237106616682, "compression_ratio": 1.6434108527131783, "no_speech_prob": 0.0015004888409748673}, {"id": 172, "seek": 67224, "start": 681.52, "end": 682.8, "text": " algorithm.", "tokens": [50828, 9284, 13, 50892], "temperature": 0.0, "avg_logprob": -0.13468237106616682, "compression_ratio": 1.6434108527131783, "no_speech_prob": 0.0015004888409748673}, {"id": 173, "seek": 67224, "start": 682.8, "end": 685.48, "text": " This is the cases where it really helps.", "tokens": [50892, 639, 307, 264, 3331, 689, 309, 534, 3665, 13, 51026], "temperature": 0.0, "avg_logprob": -0.13468237106616682, "compression_ratio": 1.6434108527131783, "no_speech_prob": 0.0015004888409748673}, {"id": 174, "seek": 67224, "start": 685.48, "end": 690.28, "text": " But over time, we have not seen that Grawl is generally faster and we don't generally", "tokens": [51026, 583, 670, 565, 11, 321, 362, 406, 1612, 300, 460, 5131, 75, 307, 5101, 4663, 293, 321, 500, 380, 5101, 51266], "temperature": 0.0, "avg_logprob": -0.13468237106616682, "compression_ratio": 1.6434108527131783, "no_speech_prob": 0.0015004888409748673}, {"id": 175, "seek": 67224, "start": 690.28, "end": 694.84, "text": " recommend it unless you have something numeric or something that's doing a massive amount", "tokens": [51266, 2748, 309, 5969, 291, 362, 746, 7866, 299, 420, 746, 300, 311, 884, 257, 5994, 2372, 51494], "temperature": 0.0, "avg_logprob": -0.13468237106616682, "compression_ratio": 1.6434108527131783, "no_speech_prob": 0.0015004888409748673}, {"id": 176, "seek": 67224, "start": 694.84, "end": 698.6, "text": " of allocation of temporary objects.", "tokens": [51494, 295, 27599, 295, 13413, 6565, 13, 51682], "temperature": 0.0, "avg_logprob": -0.13468237106616682, "compression_ratio": 1.6434108527131783, "no_speech_prob": 0.0015004888409748673}, {"id": 177, "seek": 67224, "start": 698.6, "end": 702.16, "text": " So where are we today?", "tokens": [51682, 407, 689, 366, 321, 965, 30, 51860], "temperature": 0.0, "avg_logprob": -0.13468237106616682, "compression_ratio": 1.6434108527131783, "no_speech_prob": 0.0015004888409748673}, {"id": 178, "seek": 70216, "start": 702.88, "end": 707.9599999999999, "text": " One of the problems that we have generating individual methods or compiling at the runtime", "tokens": [50400, 1485, 295, 264, 2740, 300, 321, 362, 17746, 2609, 7150, 420, 715, 4883, 412, 264, 34474, 50654], "temperature": 0.0, "avg_logprob": -0.11128784526478161, "compression_ratio": 1.7768924302788844, "no_speech_prob": 0.016905318945646286}, {"id": 179, "seek": 70216, "start": 707.9599999999999, "end": 713.68, "text": " is ideally we want that compiled method to go away if the class goes away, or if it's", "tokens": [50654, 307, 22915, 321, 528, 300, 36548, 3170, 281, 352, 1314, 498, 264, 1508, 1709, 1314, 11, 420, 498, 309, 311, 50940], "temperature": 0.0, "avg_logprob": -0.11128784526478161, "compression_ratio": 1.7768924302788844, "no_speech_prob": 0.016905318945646286}, {"id": 180, "seek": 70216, "start": 713.68, "end": 717.92, "text": " a one-off generated method that eventually doesn't get used.", "tokens": [50940, 257, 472, 12, 4506, 10833, 3170, 300, 4728, 1177, 380, 483, 1143, 13, 51152], "temperature": 0.0, "avg_logprob": -0.11128784526478161, "compression_ratio": 1.7768924302788844, "no_speech_prob": 0.016905318945646286}, {"id": 181, "seek": 70216, "start": 717.92, "end": 721.92, "text": " So it's a class per method, and the only way to make those garbage collectible is a class", "tokens": [51152, 407, 309, 311, 257, 1508, 680, 3170, 11, 293, 264, 787, 636, 281, 652, 729, 14150, 2500, 964, 307, 257, 1508, 51352], "temperature": 0.0, "avg_logprob": -0.11128784526478161, "compression_ratio": 1.7768924302788844, "no_speech_prob": 0.016905318945646286}, {"id": 182, "seek": 70216, "start": 721.92, "end": 724.1999999999999, "text": " loader per class per method.", "tokens": [51352, 3677, 260, 680, 1508, 680, 3170, 13, 51466], "temperature": 0.0, "avg_logprob": -0.11128784526478161, "compression_ratio": 1.7768924302788844, "no_speech_prob": 0.016905318945646286}, {"id": 183, "seek": 70216, "start": 724.1999999999999, "end": 729.1999999999999, "text": " So every method that we JIT into the system has both a class surrounding it and an entire", "tokens": [51466, 407, 633, 3170, 300, 321, 508, 3927, 666, 264, 1185, 575, 1293, 257, 1508, 11498, 309, 293, 364, 2302, 51716], "temperature": 0.0, "avg_logprob": -0.11128784526478161, "compression_ratio": 1.7768924302788844, "no_speech_prob": 0.016905318945646286}, {"id": 184, "seek": 72920, "start": 729.24, "end": 734.6400000000001, "text": " class loader just to work within the confines of the garbage collector.", "tokens": [50366, 1508, 3677, 260, 445, 281, 589, 1951, 264, 1497, 1652, 295, 264, 14150, 23960, 13, 50636], "temperature": 0.0, "avg_logprob": -0.14649840324155747, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.005382918287068605}, {"id": 185, "seek": 72920, "start": 734.6400000000001, "end": 739.0, "text": " There's no other way to make garbage collectible classes right now on the JVM.", "tokens": [50636, 821, 311, 572, 661, 636, 281, 652, 14150, 2500, 964, 5359, 558, 586, 322, 264, 508, 53, 44, 13, 50854], "temperature": 0.0, "avg_logprob": -0.14649840324155747, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.005382918287068605}, {"id": 186, "seek": 72920, "start": 739.0, "end": 742.48, "text": " There is anonymous class loader, but it's a hidden class, and we don't try to access", "tokens": [50854, 821, 307, 24932, 1508, 3677, 260, 11, 457, 309, 311, 257, 7633, 1508, 11, 293, 321, 500, 380, 853, 281, 2105, 51028], "temperature": 0.0, "avg_logprob": -0.14649840324155747, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.005382918287068605}, {"id": 187, "seek": 72920, "start": 742.48, "end": 744.2800000000001, "text": " that right now.", "tokens": [51028, 300, 558, 586, 13, 51118], "temperature": 0.0, "avg_logprob": -0.14649840324155747, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.005382918287068605}, {"id": 188, "seek": 72920, "start": 744.2800000000001, "end": 746.24, "text": " Indie is clearly working very well.", "tokens": [51118, 2333, 414, 307, 4448, 1364, 588, 731, 13, 51216], "temperature": 0.0, "avg_logprob": -0.14649840324155747, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.005382918287068605}, {"id": 189, "seek": 72920, "start": 746.24, "end": 750.2, "text": " We're going to be doing more advanced call sites where we will have special case code", "tokens": [51216, 492, 434, 516, 281, 312, 884, 544, 7339, 818, 7533, 689, 321, 486, 362, 2121, 1389, 3089, 51414], "temperature": 0.0, "avg_logprob": -0.14649840324155747, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.005382918287068605}, {"id": 190, "seek": 72920, "start": 750.2, "end": 755.0400000000001, "text": " along one fast path and then a slower dynamic path if it turns out it's not the logic we", "tokens": [51414, 2051, 472, 2370, 3100, 293, 550, 257, 14009, 8546, 3100, 498, 309, 4523, 484, 309, 311, 406, 264, 9952, 321, 51656], "temperature": 0.0, "avg_logprob": -0.14649840324155747, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.005382918287068605}, {"id": 191, "seek": 72920, "start": 755.0400000000001, "end": 757.24, "text": " expected.", "tokens": [51656, 5176, 13, 51766], "temperature": 0.0, "avg_logprob": -0.14649840324155747, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.005382918287068605}, {"id": 192, "seek": 75724, "start": 757.28, "end": 761.88, "text": " It is a tricky API to use, but we have a lot of tooling that we've built around it.", "tokens": [50366, 467, 307, 257, 12414, 9362, 281, 764, 11, 457, 321, 362, 257, 688, 295, 46593, 300, 321, 600, 3094, 926, 309, 13, 50596], "temperature": 0.0, "avg_logprob": -0.16988183491265596, "compression_ratio": 1.61986301369863, "no_speech_prob": 0.053345147520303726}, {"id": 193, "seek": 75724, "start": 761.88, "end": 766.0, "text": " I've got some links to older talks of mine that go into detail on that.", "tokens": [50596, 286, 600, 658, 512, 6123, 281, 4906, 6686, 295, 3892, 300, 352, 666, 2607, 322, 300, 13, 50802], "temperature": 0.0, "avg_logprob": -0.16988183491265596, "compression_ratio": 1.61986301369863, "no_speech_prob": 0.053345147520303726}, {"id": 194, "seek": 75724, "start": 766.0, "end": 770.5600000000001, "text": " Okay, I think we're doing pretty good on time here.", "tokens": [50802, 1033, 11, 286, 519, 321, 434, 884, 1238, 665, 322, 565, 510, 13, 51030], "temperature": 0.0, "avg_logprob": -0.16988183491265596, "compression_ratio": 1.61986301369863, "no_speech_prob": 0.053345147520303726}, {"id": 195, "seek": 75724, "start": 770.5600000000001, "end": 771.76, "text": " I know I talk fast.", "tokens": [51030, 286, 458, 286, 751, 2370, 13, 51090], "temperature": 0.0, "avg_logprob": -0.16988183491265596, "compression_ratio": 1.61986301369863, "no_speech_prob": 0.053345147520303726}, {"id": 196, "seek": 75724, "start": 771.76, "end": 775.52, "text": " Come back to the video and do it at like half speed, and then maybe you'll catch everything", "tokens": [51090, 2492, 646, 281, 264, 960, 293, 360, 309, 412, 411, 1922, 3073, 11, 293, 550, 1310, 291, 603, 3745, 1203, 51278], "temperature": 0.0, "avg_logprob": -0.16988183491265596, "compression_ratio": 1.61986301369863, "no_speech_prob": 0.053345147520303726}, {"id": 197, "seek": 75724, "start": 775.52, "end": 776.96, "text": " that I'm trying to say here.", "tokens": [51278, 300, 286, 478, 1382, 281, 584, 510, 13, 51350], "temperature": 0.0, "avg_logprob": -0.16988183491265596, "compression_ratio": 1.61986301369863, "no_speech_prob": 0.053345147520303726}, {"id": 198, "seek": 75724, "start": 776.96, "end": 780.96, "text": " So the next big area that we ran into was native interop.", "tokens": [51350, 407, 264, 958, 955, 1859, 300, 321, 5872, 666, 390, 8470, 728, 404, 13, 51550], "temperature": 0.0, "avg_logprob": -0.16988183491265596, "compression_ratio": 1.61986301369863, "no_speech_prob": 0.053345147520303726}, {"id": 199, "seek": 75724, "start": 780.96, "end": 786.24, "text": " The sea ruby world really lives in a POSIX native sea environment.", "tokens": [51550, 440, 4158, 5915, 88, 1002, 534, 2909, 294, 257, 430, 4367, 21124, 8470, 4158, 2823, 13, 51814], "temperature": 0.0, "avg_logprob": -0.16988183491265596, "compression_ratio": 1.61986301369863, "no_speech_prob": 0.053345147520303726}, {"id": 200, "seek": 78624, "start": 786.24, "end": 790.32, "text": " It's almost a DSL for writing POSIX code, really.", "tokens": [50364, 467, 311, 1920, 257, 15816, 43, 337, 3579, 430, 4367, 21124, 3089, 11, 534, 13, 50568], "temperature": 0.0, "avg_logprob": -0.14622565953418462, "compression_ratio": 1.4795081967213115, "no_speech_prob": 0.0016476943856105208}, {"id": 201, "seek": 78624, "start": 790.32, "end": 793.6, "text": " And originally that's kind of what Mott's the creator wanted.", "tokens": [50568, 400, 7993, 300, 311, 733, 295, 437, 376, 1521, 311, 264, 14181, 1415, 13, 50732], "temperature": 0.0, "avg_logprob": -0.14622565953418462, "compression_ratio": 1.4795081967213115, "no_speech_prob": 0.0016476943856105208}, {"id": 202, "seek": 78624, "start": 793.6, "end": 799.52, "text": " He wanted something where he could write C, but essentially with a nice API, a nice language", "tokens": [50732, 634, 1415, 746, 689, 415, 727, 2464, 383, 11, 457, 4476, 365, 257, 1481, 9362, 11, 257, 1481, 2856, 51028], "temperature": 0.0, "avg_logprob": -0.14622565953418462, "compression_ratio": 1.4795081967213115, "no_speech_prob": 0.0016476943856105208}, {"id": 203, "seek": 78624, "start": 799.52, "end": 801.76, "text": " on top of it.", "tokens": [51028, 322, 1192, 295, 309, 13, 51140], "temperature": 0.0, "avg_logprob": -0.14622565953418462, "compression_ratio": 1.4795081967213115, "no_speech_prob": 0.0016476943856105208}, {"id": 204, "seek": 78624, "start": 801.76, "end": 808.36, "text": " So they are very heavily using JNI-like extensions to the runtime for most of their native access.", "tokens": [51140, 407, 436, 366, 588, 10950, 1228, 508, 42496, 12, 4092, 25129, 281, 264, 34474, 337, 881, 295, 641, 8470, 2105, 13, 51470], "temperature": 0.0, "avg_logprob": -0.14622565953418462, "compression_ratio": 1.4795081967213115, "no_speech_prob": 0.0016476943856105208}, {"id": 205, "seek": 78624, "start": 808.36, "end": 812.84, "text": " This is clearly way too invasive for JRuby.", "tokens": [51470, 639, 307, 4448, 636, 886, 30894, 337, 32849, 836, 88, 13, 51694], "temperature": 0.0, "avg_logprob": -0.14622565953418462, "compression_ratio": 1.4795081967213115, "no_speech_prob": 0.0016476943856105208}, {"id": 206, "seek": 81284, "start": 812.84, "end": 816.1600000000001, "text": " It calls into internals of their object structures.", "tokens": [50364, 467, 5498, 666, 2154, 1124, 295, 641, 2657, 9227, 13, 50530], "temperature": 0.0, "avg_logprob": -0.14778593684850114, "compression_ratio": 1.5665236051502145, "no_speech_prob": 0.1292853206396103}, {"id": 207, "seek": 81284, "start": 816.1600000000001, "end": 821.9200000000001, "text": " It has direct access to the heap, direct access to garbage collector endpoints.", "tokens": [50530, 467, 575, 2047, 2105, 281, 264, 33591, 11, 2047, 2105, 281, 14150, 23960, 917, 20552, 13, 50818], "temperature": 0.0, "avg_logprob": -0.14778593684850114, "compression_ratio": 1.5665236051502145, "no_speech_prob": 0.1292853206396103}, {"id": 208, "seek": 81284, "start": 821.9200000000001, "end": 826.9200000000001, "text": " Nothing that we can emulate efficiently in JNI, and we have tried.", "tokens": [50818, 6693, 300, 321, 393, 45497, 19621, 294, 508, 42496, 11, 293, 321, 362, 3031, 13, 51068], "temperature": 0.0, "avg_logprob": -0.14778593684850114, "compression_ratio": 1.5665236051502145, "no_speech_prob": 0.1292853206396103}, {"id": 209, "seek": 81284, "start": 826.9200000000001, "end": 832.84, "text": " So we ended up pushing people more towards using programmatic access, like Project Panama,", "tokens": [51068, 407, 321, 4590, 493, 7380, 561, 544, 3030, 1228, 1461, 25915, 2105, 11, 411, 9849, 41202, 11, 51364], "temperature": 0.0, "avg_logprob": -0.14778593684850114, "compression_ratio": 1.5665236051502145, "no_speech_prob": 0.1292853206396103}, {"id": 210, "seek": 81284, "start": 832.84, "end": 839.0400000000001, "text": " like libffi, rather than writing C extensions for C ruby to wrap a library.", "tokens": [51364, 411, 22854, 69, 13325, 11, 2831, 813, 3579, 383, 25129, 337, 383, 5915, 88, 281, 7019, 257, 6405, 13, 51674], "temperature": 0.0, "avg_logprob": -0.14778593684850114, "compression_ratio": 1.5665236051502145, "no_speech_prob": 0.1292853206396103}, {"id": 211, "seek": 83904, "start": 839.04, "end": 843.0, "text": " Let's just wrap the library by writing a little bit of ruby code.", "tokens": [50364, 961, 311, 445, 7019, 264, 6405, 538, 3579, 257, 707, 857, 295, 5915, 88, 3089, 13, 50562], "temperature": 0.0, "avg_logprob": -0.14685558092476117, "compression_ratio": 1.6443514644351465, "no_speech_prob": 0.4718318283557892}, {"id": 212, "seek": 83904, "start": 843.0, "end": 845.56, "text": " And so started out with the Java native runtime.", "tokens": [50562, 400, 370, 1409, 484, 365, 264, 10745, 8470, 34474, 13, 50690], "temperature": 0.0, "avg_logprob": -0.14685558092476117, "compression_ratio": 1.6443514644351465, "no_speech_prob": 0.4718318283557892}, {"id": 213, "seek": 83904, "start": 845.56, "end": 851.52, "text": " It's basically our API for calling from Java down into native code and native memory.", "tokens": [50690, 467, 311, 1936, 527, 9362, 337, 5141, 490, 10745, 760, 666, 8470, 3089, 293, 8470, 4675, 13, 50988], "temperature": 0.0, "avg_logprob": -0.14685558092476117, "compression_ratio": 1.6443514644351465, "no_speech_prob": 0.4718318283557892}, {"id": 214, "seek": 83904, "start": 851.52, "end": 857.16, "text": " And then on top of that, porting the ruby ffi layer over with some invoke dynamic magic,", "tokens": [50988, 400, 550, 322, 1192, 295, 300, 11, 2436, 278, 264, 5915, 88, 283, 13325, 4583, 670, 365, 512, 41117, 8546, 5585, 11, 51270], "temperature": 0.0, "avg_logprob": -0.14685558092476117, "compression_ratio": 1.6443514644351465, "no_speech_prob": 0.4718318283557892}, {"id": 215, "seek": 83904, "start": 857.16, "end": 861.76, "text": " try and make that all as clean and fast as possible.", "tokens": [51270, 853, 293, 652, 300, 439, 382, 2541, 293, 2370, 382, 1944, 13, 51500], "temperature": 0.0, "avg_logprob": -0.14685558092476117, "compression_ratio": 1.6443514644351465, "no_speech_prob": 0.4718318283557892}, {"id": 216, "seek": 83904, "start": 861.76, "end": 865.24, "text": " Java native runtime is actually a set of projects.", "tokens": [51500, 10745, 8470, 34474, 307, 767, 257, 992, 295, 4455, 13, 51674], "temperature": 0.0, "avg_logprob": -0.14685558092476117, "compression_ratio": 1.6443514644351465, "no_speech_prob": 0.4718318283557892}, {"id": 217, "seek": 86524, "start": 865.24, "end": 869.6800000000001, "text": " Up at the top, jffi is the wrapper around libffi.", "tokens": [50364, 5858, 412, 264, 1192, 11, 361, 69, 13325, 307, 264, 46906, 926, 22854, 69, 13325, 13, 50586], "temperature": 0.0, "avg_logprob": -0.15529298000648373, "compression_ratio": 1.5849802371541502, "no_speech_prob": 0.33754581212997437}, {"id": 218, "seek": 86524, "start": 869.6800000000001, "end": 875.2, "text": " That's where we ship about 20 different binaries in the jar for all the base platforms that", "tokens": [50586, 663, 311, 689, 321, 5374, 466, 945, 819, 5171, 4889, 294, 264, 15181, 337, 439, 264, 3096, 9473, 300, 50862], "temperature": 0.0, "avg_logprob": -0.15529298000648373, "compression_ratio": 1.5849802371541502, "no_speech_prob": 0.33754581212997437}, {"id": 219, "seek": 86524, "start": 875.2, "end": 877.36, "text": " we support.", "tokens": [50862, 321, 1406, 13, 50970], "temperature": 0.0, "avg_logprob": -0.15529298000648373, "compression_ratio": 1.5849802371541502, "no_speech_prob": 0.33754581212997437}, {"id": 220, "seek": 86524, "start": 877.36, "end": 882.16, "text": " Libffi is in there, and we're just using standard libffi with some extra wrapper logic around", "tokens": [50970, 15834, 69, 13325, 307, 294, 456, 11, 293, 321, 434, 445, 1228, 3832, 22854, 69, 13325, 365, 512, 2857, 46906, 9952, 926, 51210], "temperature": 0.0, "avg_logprob": -0.15529298000648373, "compression_ratio": 1.5849802371541502, "no_speech_prob": 0.33754581212997437}, {"id": 221, "seek": 86524, "start": 882.16, "end": 883.16, "text": " it.", "tokens": [51210, 309, 13, 51260], "temperature": 0.0, "avg_logprob": -0.15529298000648373, "compression_ratio": 1.5849802371541502, "no_speech_prob": 0.33754581212997437}, {"id": 222, "seek": 86524, "start": 883.16, "end": 886.62, "text": " JNR-fffi is kind of the baseline user API.", "tokens": [51260, 508, 45, 49, 12, 602, 13325, 307, 733, 295, 264, 20518, 4195, 9362, 13, 51433], "temperature": 0.0, "avg_logprob": -0.15529298000648373, "compression_ratio": 1.5849802371541502, "no_speech_prob": 0.33754581212997437}, {"id": 223, "seek": 86524, "start": 886.62, "end": 891.5600000000001, "text": " If you're familiar with JNA, this is that level, where you say, I need a struct that's", "tokens": [51433, 759, 291, 434, 4963, 365, 508, 5321, 11, 341, 307, 300, 1496, 11, 689, 291, 584, 11, 286, 643, 257, 6594, 300, 311, 51680], "temperature": 0.0, "avg_logprob": -0.15529298000648373, "compression_ratio": 1.5849802371541502, "no_speech_prob": 0.33754581212997437}, {"id": 224, "seek": 86524, "start": 891.5600000000001, "end": 892.6800000000001, "text": " laid out like this.", "tokens": [51680, 9897, 484, 411, 341, 13, 51736], "temperature": 0.0, "avg_logprob": -0.15529298000648373, "compression_ratio": 1.5849802371541502, "no_speech_prob": 0.33754581212997437}, {"id": 225, "seek": 89268, "start": 892.68, "end": 897.3599999999999, "text": " I need a function that takes these arguments, make these calls, allocate this memory.", "tokens": [50364, 286, 643, 257, 2445, 300, 2516, 613, 12869, 11, 652, 613, 5498, 11, 35713, 341, 4675, 13, 50598], "temperature": 0.0, "avg_logprob": -0.17283876674381768, "compression_ratio": 1.6765799256505576, "no_speech_prob": 0.0012447229819372296}, {"id": 226, "seek": 89268, "start": 897.3599999999999, "end": 901.04, "text": " Then above that, we realize there were a lot of functions and a lot of behaviors that people", "tokens": [50598, 1396, 3673, 300, 11, 321, 4325, 456, 645, 257, 688, 295, 6828, 293, 257, 688, 295, 15501, 300, 561, 50782], "temperature": 0.0, "avg_logprob": -0.17283876674381768, "compression_ratio": 1.6765799256505576, "no_speech_prob": 0.0012447229819372296}, {"id": 227, "seek": 89268, "start": 901.04, "end": 905.1999999999999, "text": " were going to be rebinding over and over if we didn't provide them.", "tokens": [50782, 645, 516, 281, 312, 12970, 9245, 670, 293, 670, 498, 321, 994, 380, 2893, 552, 13, 50990], "temperature": 0.0, "avg_logprob": -0.17283876674381768, "compression_ratio": 1.6765799256505576, "no_speech_prob": 0.0012447229819372296}, {"id": 228, "seek": 89268, "start": 905.1999999999999, "end": 911.3599999999999, "text": " So we have JNR-possicks, which is a slowly growing corpus of standard posix functions", "tokens": [50990, 407, 321, 362, 508, 45, 49, 12, 79, 772, 7663, 11, 597, 307, 257, 5692, 4194, 1181, 31624, 295, 3832, 1366, 970, 6828, 51298], "temperature": 0.0, "avg_logprob": -0.17283876674381768, "compression_ratio": 1.6765799256505576, "no_speech_prob": 0.0012447229819372296}, {"id": 229, "seek": 89268, "start": 911.3599999999999, "end": 913.4799999999999, "text": " bound on top of JNR-fffi.", "tokens": [51298, 5472, 322, 1192, 295, 508, 45, 49, 12, 602, 13325, 13, 51404], "temperature": 0.0, "avg_logprob": -0.17283876674381768, "compression_ratio": 1.6765799256505576, "no_speech_prob": 0.0012447229819372296}, {"id": 230, "seek": 89268, "start": 913.4799999999999, "end": 919.4799999999999, "text": " So you can go in there and you can call things like posixpon or open a file or do native", "tokens": [51404, 407, 291, 393, 352, 294, 456, 293, 291, 393, 818, 721, 411, 1366, 970, 79, 266, 420, 1269, 257, 3991, 420, 360, 8470, 51704], "temperature": 0.0, "avg_logprob": -0.17283876674381768, "compression_ratio": 1.6765799256505576, "no_speech_prob": 0.0012447229819372296}, {"id": 231, "seek": 89268, "start": 919.4799999999999, "end": 921.1999999999999, "text": " IO.", "tokens": [51704, 39839, 13, 51790], "temperature": 0.0, "avg_logprob": -0.17283876674381768, "compression_ratio": 1.6765799256505576, "no_speech_prob": 0.0012447229819372296}, {"id": 232, "seek": 92120, "start": 921.2, "end": 926.6400000000001, "text": " You can even call fork, and it's a lot of fun to see what happens when you do that.", "tokens": [50364, 509, 393, 754, 818, 17716, 11, 293, 309, 311, 257, 688, 295, 1019, 281, 536, 437, 2314, 562, 291, 360, 300, 13, 50636], "temperature": 0.0, "avg_logprob": -0.18013217085498875, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.032083362340927124}, {"id": 233, "seek": 92120, "start": 926.6400000000001, "end": 933.5600000000001, "text": " JNR-enxio, extended native cross-platform IO, builds on JNR-possicks and provides an", "tokens": [50636, 508, 45, 49, 12, 268, 87, 1004, 11, 10913, 8470, 3278, 12, 39975, 837, 39839, 11, 15182, 322, 508, 45, 49, 12, 79, 772, 7663, 293, 6417, 364, 50982], "temperature": 0.0, "avg_logprob": -0.18013217085498875, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.032083362340927124}, {"id": 234, "seek": 92120, "start": 933.5600000000001, "end": 937.12, "text": " NIO channel that is all native down calls.", "tokens": [50982, 426, 15167, 2269, 300, 307, 439, 8470, 760, 5498, 13, 51160], "temperature": 0.0, "avg_logprob": -0.18013217085498875, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.032083362340927124}, {"id": 235, "seek": 92120, "start": 937.12, "end": 943.0400000000001, "text": " So where we can't get selectable standard IO on the JVM, we can't get selectable sub-process", "tokens": [51160, 407, 689, 321, 393, 380, 483, 3048, 712, 3832, 39839, 322, 264, 508, 53, 44, 11, 321, 393, 380, 483, 3048, 712, 1422, 12, 41075, 51456], "temperature": 0.0, "avg_logprob": -0.18013217085498875, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.032083362340927124}, {"id": 236, "seek": 92120, "start": 943.0400000000001, "end": 951.0400000000001, "text": " channels, we can use JNR-enxio to have actual interactive control over standard input.", "tokens": [51456, 9235, 11, 321, 393, 764, 508, 45, 49, 12, 268, 87, 1004, 281, 362, 3539, 15141, 1969, 670, 3832, 4846, 13, 51856], "temperature": 0.0, "avg_logprob": -0.18013217085498875, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.032083362340927124}, {"id": 237, "seek": 95104, "start": 951.5999999999999, "end": 953.4399999999999, "text": " Standard IO and sub-processes.", "tokens": [50392, 21298, 39839, 293, 1422, 12, 41075, 279, 13, 50484], "temperature": 0.0, "avg_logprob": -0.1803917978324142, "compression_ratio": 1.584, "no_speech_prob": 0.006690161302685738}, {"id": 238, "seek": 95104, "start": 953.4399999999999, "end": 958.68, "text": " You can actually use JRuby to spin up a VIM instance and it will have full console control", "tokens": [50484, 509, 393, 767, 764, 32849, 836, 88, 281, 6060, 493, 257, 691, 6324, 5197, 293, 309, 486, 362, 1577, 11076, 1969, 50746], "temperature": 0.0, "avg_logprob": -0.1803917978324142, "compression_ratio": 1.584, "no_speech_prob": 0.006690161302685738}, {"id": 239, "seek": 95104, "start": 958.68, "end": 960.7199999999999, "text": " and work properly.", "tokens": [50746, 293, 589, 6108, 13, 50848], "temperature": 0.0, "avg_logprob": -0.1803917978324142, "compression_ratio": 1.584, "no_speech_prob": 0.006690161302685738}, {"id": 240, "seek": 95104, "start": 960.7199999999999, "end": 966.28, "text": " Basically impossible to do with the standard process builder stuff on Java.", "tokens": [50848, 8537, 6243, 281, 360, 365, 264, 3832, 1399, 27377, 1507, 322, 10745, 13, 51126], "temperature": 0.0, "avg_logprob": -0.1803917978324142, "compression_ratio": 1.584, "no_speech_prob": 0.006690161302685738}, {"id": 241, "seek": 95104, "start": 966.28, "end": 970.64, "text": " Unix socket, not too surprising, just wraps this other stuff with the Unix socket calls.", "tokens": [51126, 1156, 970, 19741, 11, 406, 886, 8830, 11, 445, 25831, 341, 661, 1507, 365, 264, 1156, 970, 19741, 5498, 13, 51344], "temperature": 0.0, "avg_logprob": -0.1803917978324142, "compression_ratio": 1.584, "no_speech_prob": 0.006690161302685738}, {"id": 242, "seek": 95104, "start": 970.64, "end": 975.5799999999999, "text": " And then JNR-process, like I mentioned, we have our own selectable channels for processes.", "tokens": [51344, 400, 550, 508, 45, 49, 12, 41075, 11, 411, 286, 2835, 11, 321, 362, 527, 1065, 3048, 712, 9235, 337, 7555, 13, 51591], "temperature": 0.0, "avg_logprob": -0.1803917978324142, "compression_ratio": 1.584, "no_speech_prob": 0.006690161302685738}, {"id": 243, "seek": 97558, "start": 975.58, "end": 981.6600000000001, "text": " You can use this as a Maven library, you pull it in and you'll have the same API as process", "tokens": [50364, 509, 393, 764, 341, 382, 257, 4042, 553, 6405, 11, 291, 2235, 309, 294, 293, 291, 603, 362, 264, 912, 9362, 382, 1399, 50668], "temperature": 0.0, "avg_logprob": -0.14927022391503011, "compression_ratio": 1.5457875457875458, "no_speech_prob": 0.025168655440211296}, {"id": 244, "seek": 97558, "start": 981.6600000000001, "end": 987.1800000000001, "text": " builder but you'll get channels, selectable channels out of it instead of streams.", "tokens": [50668, 27377, 457, 291, 603, 483, 9235, 11, 3048, 712, 9235, 484, 295, 309, 2602, 295, 15842, 13, 50944], "temperature": 0.0, "avg_logprob": -0.14927022391503011, "compression_ratio": 1.5457875457875458, "no_speech_prob": 0.025168655440211296}, {"id": 245, "seek": 97558, "start": 987.1800000000001, "end": 989.9000000000001, "text": " So it's available right now for that.", "tokens": [50944, 407, 309, 311, 2435, 558, 586, 337, 300, 13, 51080], "temperature": 0.0, "avg_logprob": -0.14927022391503011, "compression_ratio": 1.5457875457875458, "no_speech_prob": 0.025168655440211296}, {"id": 246, "seek": 97558, "start": 989.9000000000001, "end": 993.26, "text": " This is a little bit of what Ruby FFI looks like.", "tokens": [51080, 639, 307, 257, 707, 857, 295, 437, 19907, 479, 38568, 1542, 411, 13, 51248], "temperature": 0.0, "avg_logprob": -0.14927022391503011, "compression_ratio": 1.5457875457875458, "no_speech_prob": 0.025168655440211296}, {"id": 247, "seek": 97558, "start": 993.26, "end": 998.3000000000001, "text": " Pretty straightforward, we're setting up a structure with particular widths of fields,", "tokens": [51248, 10693, 15325, 11, 321, 434, 3287, 493, 257, 3877, 365, 1729, 11402, 82, 295, 7909, 11, 51500], "temperature": 0.0, "avg_logprob": -0.14927022391503011, "compression_ratio": 1.5457875457875458, "no_speech_prob": 0.025168655440211296}, {"id": 248, "seek": 97558, "start": 998.3000000000001, "end": 1002.1, "text": " attaching a function, get time of day, and then we can call it directly.", "tokens": [51500, 39074, 257, 2445, 11, 483, 565, 295, 786, 11, 293, 550, 321, 393, 818, 309, 3838, 13, 51690], "temperature": 0.0, "avg_logprob": -0.14927022391503011, "compression_ratio": 1.5457875457875458, "no_speech_prob": 0.025168655440211296}, {"id": 249, "seek": 100210, "start": 1002.14, "end": 1007.58, "text": " Under the covers, this all uses JNR and ideally inlines as much as possible up to the native", "tokens": [50366, 6974, 264, 10538, 11, 341, 439, 4960, 508, 45, 49, 293, 22915, 294, 11045, 382, 709, 382, 1944, 493, 281, 264, 8470, 50638], "temperature": 0.0, "avg_logprob": -0.16551679319089596, "compression_ratio": 1.5757575757575757, "no_speech_prob": 0.005552708171308041}, {"id": 250, "seek": 100210, "start": 1007.58, "end": 1009.5, "text": " down call.", "tokens": [50638, 760, 818, 13, 50734], "temperature": 0.0, "avg_logprob": -0.16551679319089596, "compression_ratio": 1.5757575757575757, "no_speech_prob": 0.005552708171308041}, {"id": 251, "seek": 100210, "start": 1009.5, "end": 1012.58, "text": " So today, native interop on the JVM.", "tokens": [50734, 407, 965, 11, 8470, 728, 404, 322, 264, 508, 53, 44, 13, 50888], "temperature": 0.0, "avg_logprob": -0.16551679319089596, "compression_ratio": 1.5757575757575757, "no_speech_prob": 0.005552708171308041}, {"id": 252, "seek": 100210, "start": 1012.58, "end": 1017.58, "text": " Of course, we have Panama coming along, so the talk before me, Mauricio's talk, that's", "tokens": [50888, 2720, 1164, 11, 321, 362, 41202, 1348, 2051, 11, 370, 264, 751, 949, 385, 11, 26133, 18322, 311, 751, 11, 300, 311, 51138], "temperature": 0.0, "avg_logprob": -0.16551679319089596, "compression_ratio": 1.5757575757575757, "no_speech_prob": 0.005552708171308041}, {"id": 253, "seek": 100210, "start": 1017.58, "end": 1022.26, "text": " where all the information is about where things are going and we're really excited about that.", "tokens": [51138, 689, 439, 264, 1589, 307, 466, 689, 721, 366, 516, 293, 321, 434, 534, 2919, 466, 300, 13, 51372], "temperature": 0.0, "avg_logprob": -0.16551679319089596, "compression_ratio": 1.5757575757575757, "no_speech_prob": 0.005552708171308041}, {"id": 254, "seek": 100210, "start": 1022.26, "end": 1028.18, "text": " I actually wrote the original JEP for Panama, which has now been walked away from many times,", "tokens": [51372, 286, 767, 4114, 264, 3380, 508, 8929, 337, 41202, 11, 597, 575, 586, 668, 7628, 1314, 490, 867, 1413, 11, 51668], "temperature": 0.0, "avg_logprob": -0.16551679319089596, "compression_ratio": 1.5757575757575757, "no_speech_prob": 0.005552708171308041}, {"id": 255, "seek": 102818, "start": 1028.18, "end": 1033.94, "text": " but we've been needing this for over a decade now and had to make our own but don't want", "tokens": [50364, 457, 321, 600, 668, 18006, 341, 337, 670, 257, 10378, 586, 293, 632, 281, 652, 527, 1065, 457, 500, 380, 528, 50652], "temperature": 0.0, "avg_logprob": -0.14738602108425564, "compression_ratio": 1.5439330543933054, "no_speech_prob": 0.002322576940059662}, {"id": 256, "seek": 102818, "start": 1033.94, "end": 1035.94, "text": " to maintain it anymore.", "tokens": [50652, 281, 6909, 309, 3602, 13, 50752], "temperature": 0.0, "avg_logprob": -0.14738602108425564, "compression_ratio": 1.5439330543933054, "no_speech_prob": 0.002322576940059662}, {"id": 257, "seek": 102818, "start": 1035.94, "end": 1042.46, "text": " JNR is pretty much the fastest way outside of Panama to do these native down calls.", "tokens": [50752, 508, 45, 49, 307, 1238, 709, 264, 14573, 636, 2380, 295, 41202, 281, 360, 613, 8470, 760, 5498, 13, 51078], "temperature": 0.0, "avg_logprob": -0.14738602108425564, "compression_ratio": 1.5439330543933054, "no_speech_prob": 0.002322576940059662}, {"id": 258, "seek": 102818, "start": 1042.46, "end": 1049.0600000000002, "text": " In some cases, actually beating JNI because there's extensions to generate a little JNI", "tokens": [51078, 682, 512, 3331, 11, 767, 13497, 508, 42496, 570, 456, 311, 25129, 281, 8460, 257, 707, 508, 42496, 51408], "temperature": 0.0, "avg_logprob": -0.14738602108425564, "compression_ratio": 1.5439330543933054, "no_speech_prob": 0.002322576940059662}, {"id": 259, "seek": 102818, "start": 1049.0600000000002, "end": 1054.02, "text": " function in memory using assembly that can cut out some of that overhead rather than", "tokens": [51408, 2445, 294, 4675, 1228, 12103, 300, 393, 1723, 484, 512, 295, 300, 19922, 2831, 813, 51656], "temperature": 0.0, "avg_logprob": -0.14738602108425564, "compression_ratio": 1.5439330543933054, "no_speech_prob": 0.002322576940059662}, {"id": 260, "seek": 105402, "start": 1054.06, "end": 1057.58, "text": " just doing pure programmatic calling through lib.ffi.", "tokens": [50366, 445, 884, 6075, 1461, 25915, 5141, 807, 22854, 13, 69, 13325, 13, 50542], "temperature": 0.0, "avg_logprob": -0.24811810460583916, "compression_ratio": 1.4955357142857142, "no_speech_prob": 0.05179335176944733}, {"id": 261, "seek": 105402, "start": 1057.58, "end": 1062.5, "text": " Jextract from Panama is coming along.", "tokens": [50542, 508, 3828, 1897, 490, 41202, 307, 1348, 2051, 13, 50788], "temperature": 0.0, "avg_logprob": -0.24811810460583916, "compression_ratio": 1.4955357142857142, "no_speech_prob": 0.05179335176944733}, {"id": 262, "seek": 105402, "start": 1062.5, "end": 1068.98, "text": " We're also hoping that we can use that at runtime as a library to and access those data structures", "tokens": [50788, 492, 434, 611, 7159, 300, 321, 393, 764, 300, 412, 34474, 382, 257, 6405, 281, 293, 2105, 729, 1412, 9227, 51112], "temperature": 0.0, "avg_logprob": -0.24811810460583916, "compression_ratio": 1.4955357142857142, "no_speech_prob": 0.05179335176944733}, {"id": 263, "seek": 105402, "start": 1068.98, "end": 1072.3799999999999, "text": " internally to generate Ruby.ffi code.", "tokens": [51112, 19501, 281, 8460, 19907, 13, 69, 13325, 3089, 13, 51282], "temperature": 0.0, "avg_logprob": -0.24811810460583916, "compression_ratio": 1.4955357142857142, "no_speech_prob": 0.05179335176944733}, {"id": 264, "seek": 105402, "start": 1072.3799999999999, "end": 1077.82, "text": " This would be kind of the last mile for getting Rubyists to switch from writing C extensions", "tokens": [51282, 639, 576, 312, 733, 295, 264, 1036, 12620, 337, 1242, 19907, 1751, 281, 3679, 490, 3579, 383, 25129, 51554], "temperature": 0.0, "avg_logprob": -0.24811810460583916, "compression_ratio": 1.4955357142857142, "no_speech_prob": 0.05179335176944733}, {"id": 265, "seek": 105402, "start": 1077.82, "end": 1079.3, "text": " to using FFI.", "tokens": [51554, 281, 1228, 479, 38568, 13, 51628], "temperature": 0.0, "avg_logprob": -0.24811810460583916, "compression_ratio": 1.4955357142857142, "no_speech_prob": 0.05179335176944733}, {"id": 266, "seek": 107930, "start": 1079.3, "end": 1084.18, "text": " If we could generate the Ruby.ffi code the same way we do the Panama code, there'd be", "tokens": [50364, 759, 321, 727, 8460, 264, 19907, 13, 69, 13325, 3089, 264, 912, 636, 321, 360, 264, 41202, 3089, 11, 456, 1116, 312, 50608], "temperature": 0.0, "avg_logprob": -0.14103154402512771, "compression_ratio": 1.7043795620437956, "no_speech_prob": 0.09262708574533463}, {"id": 267, "seek": 107930, "start": 1084.18, "end": 1087.94, "text": " nothing to stop them at that point.", "tokens": [50608, 1825, 281, 1590, 552, 412, 300, 935, 13, 50796], "temperature": 0.0, "avg_logprob": -0.14103154402512771, "compression_ratio": 1.7043795620437956, "no_speech_prob": 0.09262708574533463}, {"id": 268, "seek": 107930, "start": 1087.94, "end": 1092.7, "text": " There is back-end work happening right now on JNR to integrate it with Panama.", "tokens": [50796, 821, 307, 646, 12, 521, 589, 2737, 558, 586, 322, 508, 45, 49, 281, 13365, 309, 365, 41202, 13, 51034], "temperature": 0.0, "avg_logprob": -0.14103154402512771, "compression_ratio": 1.7043795620437956, "no_speech_prob": 0.09262708574533463}, {"id": 269, "seek": 107930, "start": 1092.7, "end": 1096.34, "text": " Michelle at Oracle is working on that and I'm hoping that we'll see something in the", "tokens": [51034, 14933, 412, 25654, 307, 1364, 322, 300, 293, 286, 478, 7159, 300, 321, 603, 536, 746, 294, 264, 51216], "temperature": 0.0, "avg_logprob": -0.14103154402512771, "compression_ratio": 1.7043795620437956, "no_speech_prob": 0.09262708574533463}, {"id": 270, "seek": 107930, "start": 1096.34, "end": 1098.98, "text": " next couple of weeks.", "tokens": [51216, 958, 1916, 295, 3259, 13, 51348], "temperature": 0.0, "avg_logprob": -0.14103154402512771, "compression_ratio": 1.7043795620437956, "no_speech_prob": 0.09262708574533463}, {"id": 271, "seek": 107930, "start": 1098.98, "end": 1101.02, "text": " A little more review of some of these ideas.", "tokens": [51348, 316, 707, 544, 3131, 295, 512, 295, 613, 3487, 13, 51450], "temperature": 0.0, "avg_logprob": -0.14103154402512771, "compression_ratio": 1.7043795620437956, "no_speech_prob": 0.09262708574533463}, {"id": 272, "seek": 107930, "start": 1101.02, "end": 1104.94, "text": " If we have Jextract that can generate Java code, we should be able to use Jextract to", "tokens": [51450, 759, 321, 362, 508, 3828, 1897, 300, 393, 8460, 10745, 3089, 11, 321, 820, 312, 1075, 281, 764, 508, 3828, 1897, 281, 51646], "temperature": 0.0, "avg_logprob": -0.14103154402512771, "compression_ratio": 1.7043795620437956, "no_speech_prob": 0.09262708574533463}, {"id": 273, "seek": 107930, "start": 1104.94, "end": 1107.3799999999999, "text": " also generate Ruby.ffi code.", "tokens": [51646, 611, 8460, 19907, 13, 69, 13325, 3089, 13, 51768], "temperature": 0.0, "avg_logprob": -0.14103154402512771, "compression_ratio": 1.7043795620437956, "no_speech_prob": 0.09262708574533463}, {"id": 274, "seek": 110738, "start": 1107.46, "end": 1113.1000000000001, "text": " That'll be the next big fun toy to play with is of Java 22.", "tokens": [50368, 663, 603, 312, 264, 958, 955, 1019, 12058, 281, 862, 365, 307, 295, 10745, 5853, 13, 50650], "temperature": 0.0, "avg_logprob": -0.1334567111471425, "compression_ratio": 1.5183823529411764, "no_speech_prob": 0.1621120423078537}, {"id": 275, "seek": 110738, "start": 1113.1000000000001, "end": 1116.94, "text": " We also use the existing SQLite JDBC driver.", "tokens": [50650, 492, 611, 764, 264, 6741, 19200, 642, 37082, 7869, 6787, 13, 50842], "temperature": 0.0, "avg_logprob": -0.1334567111471425, "compression_ratio": 1.5183823529411764, "no_speech_prob": 0.1621120423078537}, {"id": 276, "seek": 110738, "start": 1116.94, "end": 1120.5400000000002, "text": " Rubyists like to use SQLite for local development.", "tokens": [50842, 19907, 1751, 411, 281, 764, 19200, 642, 337, 2654, 3250, 13, 51022], "temperature": 0.0, "avg_logprob": -0.1334567111471425, "compression_ratio": 1.5183823529411764, "no_speech_prob": 0.1621120423078537}, {"id": 277, "seek": 110738, "start": 1120.5400000000002, "end": 1122.6200000000001, "text": " But it's going through a JNI back-end.", "tokens": [51022, 583, 309, 311, 516, 807, 257, 508, 42496, 646, 12, 521, 13, 51126], "temperature": 0.0, "avg_logprob": -0.1334567111471425, "compression_ratio": 1.5183823529411764, "no_speech_prob": 0.1621120423078537}, {"id": 278, "seek": 110738, "start": 1122.6200000000001, "end": 1125.5, "text": " You have to make sure it's available for the platform that you're on.", "tokens": [51126, 509, 362, 281, 652, 988, 309, 311, 2435, 337, 264, 3663, 300, 291, 434, 322, 13, 51270], "temperature": 0.0, "avg_logprob": -0.1334567111471425, "compression_ratio": 1.5183823529411764, "no_speech_prob": 0.1621120423078537}, {"id": 279, "seek": 110738, "start": 1125.5, "end": 1128.94, "text": " They are also playing with Panama behind the scenes.", "tokens": [51270, 814, 366, 611, 2433, 365, 41202, 2261, 264, 8026, 13, 51442], "temperature": 0.0, "avg_logprob": -0.1334567111471425, "compression_ratio": 1.5183823529411764, "no_speech_prob": 0.1621120423078537}, {"id": 280, "seek": 110738, "start": 1128.94, "end": 1134.98, "text": " Early numbers look like two-ish times faster than the JNI wrapper around SQLite that they", "tokens": [51442, 18344, 3547, 574, 411, 732, 12, 742, 1413, 4663, 813, 264, 508, 42496, 46906, 926, 19200, 642, 300, 436, 51744], "temperature": 0.0, "avg_logprob": -0.1334567111471425, "compression_ratio": 1.5183823529411764, "no_speech_prob": 0.1621120423078537}, {"id": 281, "seek": 110738, "start": 1134.98, "end": 1135.98, "text": " have.", "tokens": [51744, 362, 13, 51794], "temperature": 0.0, "avg_logprob": -0.1334567111471425, "compression_ratio": 1.5183823529411764, "no_speech_prob": 0.1621120423078537}, {"id": 282, "seek": 113598, "start": 1135.98, "end": 1137.74, "text": " So this is coming along.", "tokens": [50364, 407, 341, 307, 1348, 2051, 13, 50452], "temperature": 0.0, "avg_logprob": -0.19516966260712723, "compression_ratio": 1.6679245283018869, "no_speech_prob": 0.007931938394904137}, {"id": 283, "seek": 113598, "start": 1137.74, "end": 1143.22, "text": " We also are integrating a new Ruby parser called Prism, which is a simple C library", "tokens": [50452, 492, 611, 366, 26889, 257, 777, 19907, 21156, 260, 1219, 2114, 1434, 11, 597, 307, 257, 2199, 383, 6405, 50726], "temperature": 0.0, "avg_logprob": -0.19516966260712723, "compression_ratio": 1.6679245283018869, "no_speech_prob": 0.007931938394904137}, {"id": 284, "seek": 113598, "start": 1143.22, "end": 1148.66, "text": " that we all the implementations can share so that we are using the same Ruby parser.", "tokens": [50726, 300, 321, 439, 264, 4445, 763, 393, 2073, 370, 300, 321, 366, 1228, 264, 912, 19907, 21156, 260, 13, 50998], "temperature": 0.0, "avg_logprob": -0.19516966260712723, "compression_ratio": 1.6679245283018869, "no_speech_prob": 0.007931938394904137}, {"id": 285, "seek": 113598, "start": 1148.66, "end": 1151.42, "text": " That we will integrate through Panama as well.", "tokens": [50998, 663, 321, 486, 13365, 807, 41202, 382, 731, 13, 51136], "temperature": 0.0, "avg_logprob": -0.19516966260712723, "compression_ratio": 1.6679245283018869, "no_speech_prob": 0.007931938394904137}, {"id": 286, "seek": 113598, "start": 1151.42, "end": 1157.1, "text": " And use Panama to make it much faster for us to downcall into this library, get our", "tokens": [51136, 400, 764, 41202, 281, 652, 309, 709, 4663, 337, 505, 281, 760, 45459, 666, 341, 6405, 11, 483, 527, 51420], "temperature": 0.0, "avg_logprob": -0.19516966260712723, "compression_ratio": 1.6679245283018869, "no_speech_prob": 0.007931938394904137}, {"id": 287, "seek": 113598, "start": 1157.1, "end": 1159.38, "text": " AST back out, and then proceed.", "tokens": [51420, 316, 6840, 646, 484, 11, 293, 550, 8991, 13, 51534], "temperature": 0.0, "avg_logprob": -0.19516966260712723, "compression_ratio": 1.6679245283018869, "no_speech_prob": 0.007931938394904137}, {"id": 288, "seek": 113598, "start": 1159.38, "end": 1165.42, "text": " Interestingly, we're also exploring using Prism as a Wasm-compiled library running on", "tokens": [51534, 30564, 11, 321, 434, 611, 12736, 1228, 2114, 1434, 382, 257, 343, 14774, 12, 21541, 7292, 6405, 2614, 322, 51836], "temperature": 0.0, "avg_logprob": -0.19516966260712723, "compression_ratio": 1.6679245283018869, "no_speech_prob": 0.007931938394904137}, {"id": 289, "seek": 116542, "start": 1165.42, "end": 1172.5, "text": " the chicory Wasm implementation on top of the JVM so that we can parse Ruby code using", "tokens": [50364, 264, 33590, 827, 343, 14774, 11420, 322, 1192, 295, 264, 508, 53, 44, 370, 300, 321, 393, 48377, 19907, 3089, 1228, 50718], "temperature": 0.0, "avg_logprob": -0.16557737618438467, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.011326771229505539}, {"id": 290, "seek": 116542, "start": 1172.5, "end": 1176.26, "text": " a native library even if we're not on a platform it's compiled for.", "tokens": [50718, 257, 8470, 6405, 754, 498, 321, 434, 406, 322, 257, 3663, 309, 311, 36548, 337, 13, 50906], "temperature": 0.0, "avg_logprob": -0.16557737618438467, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.011326771229505539}, {"id": 291, "seek": 116542, "start": 1176.26, "end": 1178.18, "text": " And that's amazing that it works.", "tokens": [50906, 400, 300, 311, 2243, 300, 309, 1985, 13, 51002], "temperature": 0.0, "avg_logprob": -0.16557737618438467, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.011326771229505539}, {"id": 292, "seek": 116542, "start": 1178.18, "end": 1179.78, "text": " All right.", "tokens": [51002, 1057, 558, 13, 51082], "temperature": 0.0, "avg_logprob": -0.16557737618438467, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.011326771229505539}, {"id": 293, "seek": 116542, "start": 1179.78, "end": 1180.78, "text": " Moving along here.", "tokens": [51082, 14242, 2051, 510, 13, 51132], "temperature": 0.0, "avg_logprob": -0.16557737618438467, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.011326771229505539}, {"id": 294, "seek": 116542, "start": 1180.78, "end": 1183.1000000000001, "text": " So lightweight threading is the next big one.", "tokens": [51132, 407, 22052, 7207, 278, 307, 264, 958, 955, 472, 13, 51248], "temperature": 0.0, "avg_logprob": -0.16557737618438467, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.011326771229505539}, {"id": 295, "seek": 116542, "start": 1183.1000000000001, "end": 1188.38, "text": " Around Ruby 1.9, they introduced fibers, a coroutine-like concept, a micro thread", "tokens": [51248, 17633, 19907, 502, 13, 24, 11, 436, 7268, 25252, 11, 257, 1181, 45075, 12, 4092, 3410, 11, 257, 4532, 7207, 51512], "temperature": 0.0, "avg_logprob": -0.16557737618438467, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.011326771229505539}, {"id": 296, "seek": 116542, "start": 1188.38, "end": 1190.5, "text": " concept.", "tokens": [51512, 3410, 13, 51618], "temperature": 0.0, "avg_logprob": -0.16557737618438467, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.011326771229505539}, {"id": 297, "seek": 116542, "start": 1190.5, "end": 1194.9, "text": " You would still have your native threads there, but they can bounce around to different fibers", "tokens": [51618, 509, 576, 920, 362, 428, 8470, 19314, 456, 11, 457, 436, 393, 15894, 926, 281, 819, 25252, 51838], "temperature": 0.0, "avg_logprob": -0.16557737618438467, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.011326771229505539}, {"id": 298, "seek": 119490, "start": 1194.9, "end": 1197.0600000000002, "text": " at any given time.", "tokens": [50364, 412, 604, 2212, 565, 13, 50472], "temperature": 0.0, "avg_logprob": -0.1228389834413434, "compression_ratio": 1.6422413793103448, "no_speech_prob": 0.029281770810484886}, {"id": 299, "seek": 119490, "start": 1197.0600000000002, "end": 1203.02, "text": " And you get little structured concurrency, structured use of fibers, allows you to do", "tokens": [50472, 400, 291, 483, 707, 18519, 23702, 10457, 11, 18519, 764, 295, 25252, 11, 4045, 291, 281, 360, 50770], "temperature": 0.0, "avg_logprob": -0.1228389834413434, "compression_ratio": 1.6422413793103448, "no_speech_prob": 0.029281770810484886}, {"id": 300, "seek": 119490, "start": 1203.02, "end": 1206.3000000000002, "text": " multiple tasks in the same thread.", "tokens": [50770, 3866, 9608, 294, 264, 912, 7207, 13, 50934], "temperature": 0.0, "avg_logprob": -0.1228389834413434, "compression_ratio": 1.6422413793103448, "no_speech_prob": 0.029281770810484886}, {"id": 301, "seek": 119490, "start": 1206.3000000000002, "end": 1210.38, "text": " There's also been a push toward structured concurrency in the Ruby world now, where fibers", "tokens": [50934, 821, 311, 611, 668, 257, 2944, 7361, 18519, 23702, 10457, 294, 264, 19907, 1002, 586, 11, 689, 25252, 51138], "temperature": 0.0, "avg_logprob": -0.1228389834413434, "compression_ratio": 1.6422413793103448, "no_speech_prob": 0.029281770810484886}, {"id": 302, "seek": 119490, "start": 1210.38, "end": 1214.5400000000002, "text": " can wait on I.O. or make a blocking call on I.O.", "tokens": [51138, 393, 1699, 322, 286, 13, 46, 13, 420, 652, 257, 17776, 818, 322, 286, 13, 46, 13, 51346], "temperature": 0.0, "avg_logprob": -0.1228389834413434, "compression_ratio": 1.6422413793103448, "no_speech_prob": 0.029281770810484886}, {"id": 303, "seek": 119490, "start": 1214.5400000000002, "end": 1218.94, "text": " The runtime will see that and schedule another fiber to run in its place while it's waiting", "tokens": [51346, 440, 34474, 486, 536, 300, 293, 7567, 1071, 12874, 281, 1190, 294, 1080, 1081, 1339, 309, 311, 3806, 51566], "temperature": 0.0, "avg_logprob": -0.1228389834413434, "compression_ratio": 1.6422413793103448, "no_speech_prob": 0.029281770810484886}, {"id": 304, "seek": 119490, "start": 1218.94, "end": 1219.94, "text": " for that.", "tokens": [51566, 337, 300, 13, 51616], "temperature": 0.0, "avg_logprob": -0.1228389834413434, "compression_ratio": 1.6422413793103448, "no_speech_prob": 0.029281770810484886}, {"id": 305, "seek": 121994, "start": 1219.94, "end": 1225.6200000000001, "text": " So you can easily handle tens of thousands, hundreds of thousands of concurrent connections,", "tokens": [50364, 407, 291, 393, 3612, 4813, 10688, 295, 5383, 11, 6779, 295, 5383, 295, 37702, 9271, 11, 50648], "temperature": 0.0, "avg_logprob": -0.11573704885780264, "compression_ratio": 1.6954887218045114, "no_speech_prob": 0.0032723841723054647}, {"id": 306, "seek": 121994, "start": 1225.6200000000001, "end": 1230.74, "text": " for example, without blocking that many threads or having to write your own select loop and", "tokens": [50648, 337, 1365, 11, 1553, 17776, 300, 867, 19314, 420, 1419, 281, 2464, 428, 1065, 3048, 6367, 293, 50904], "temperature": 0.0, "avg_logprob": -0.11573704885780264, "compression_ratio": 1.6954887218045114, "no_speech_prob": 0.0032723841723054647}, {"id": 307, "seek": 121994, "start": 1230.74, "end": 1233.06, "text": " what not.", "tokens": [50904, 437, 406, 13, 51020], "temperature": 0.0, "avg_logprob": -0.11573704885780264, "compression_ratio": 1.6954887218045114, "no_speech_prob": 0.0032723841723054647}, {"id": 308, "seek": 121994, "start": 1233.06, "end": 1237.74, "text": " So fibers on JRuby, without a coroutine API at the JVM level, of course, we've had to", "tokens": [51020, 407, 25252, 322, 32849, 836, 88, 11, 1553, 257, 1181, 45075, 9362, 412, 264, 508, 53, 44, 1496, 11, 295, 1164, 11, 321, 600, 632, 281, 51254], "temperature": 0.0, "avg_logprob": -0.11573704885780264, "compression_ratio": 1.6954887218045114, "no_speech_prob": 0.0032723841723054647}, {"id": 309, "seek": 121994, "start": 1237.74, "end": 1239.14, "text": " use native threads.", "tokens": [51254, 764, 8470, 19314, 13, 51324], "temperature": 0.0, "avg_logprob": -0.11573704885780264, "compression_ratio": 1.6954887218045114, "no_speech_prob": 0.0032723841723054647}, {"id": 310, "seek": 121994, "start": 1239.14, "end": 1243.06, "text": " And that clearly only scales up to a certain number of threads.", "tokens": [51324, 400, 300, 4448, 787, 17408, 493, 281, 257, 1629, 1230, 295, 19314, 13, 51520], "temperature": 0.0, "avg_logprob": -0.11573704885780264, "compression_ratio": 1.6954887218045114, "no_speech_prob": 0.0032723841723054647}, {"id": 311, "seek": 121994, "start": 1243.06, "end": 1246.6200000000001, "text": " With the structured concurrency example, we could have potentially thousands of fibers", "tokens": [51520, 2022, 264, 18519, 23702, 10457, 1365, 11, 321, 727, 362, 7263, 5383, 295, 25252, 51698], "temperature": 0.0, "avg_logprob": -0.11573704885780264, "compression_ratio": 1.6954887218045114, "no_speech_prob": 0.0032723841723054647}, {"id": 312, "seek": 124662, "start": 1246.62, "end": 1250.8999999999999, "text": " in the system, and it's almost impossible for us to support that with full, heavy native", "tokens": [50364, 294, 264, 1185, 11, 293, 309, 311, 1920, 6243, 337, 505, 281, 1406, 300, 365, 1577, 11, 4676, 8470, 50578], "temperature": 0.0, "avg_logprob": -0.1450693398191218, "compression_ratio": 1.7148014440433212, "no_speech_prob": 0.05496422201395035}, {"id": 313, "seek": 124662, "start": 1250.8999999999999, "end": 1253.2199999999998, "text": " threads all along the way.", "tokens": [50578, 19314, 439, 2051, 264, 636, 13, 50694], "temperature": 0.0, "avg_logprob": -0.1450693398191218, "compression_ratio": 1.7148014440433212, "no_speech_prob": 0.05496422201395035}, {"id": 314, "seek": 124662, "start": 1253.2199999999998, "end": 1257.26, "text": " Ruby also primarily uses internal iteration.", "tokens": [50694, 19907, 611, 10029, 4960, 6920, 24784, 13, 50896], "temperature": 0.0, "avg_logprob": -0.1450693398191218, "compression_ratio": 1.7148014440433212, "no_speech_prob": 0.05496422201395035}, {"id": 315, "seek": 124662, "start": 1257.26, "end": 1261.6599999999999, "text": " Collections just have to implement an each method of basically a for each.", "tokens": [50896, 31896, 626, 445, 362, 281, 4445, 364, 1184, 3170, 295, 1936, 257, 337, 1184, 13, 51116], "temperature": 0.0, "avg_logprob": -0.1450693398191218, "compression_ratio": 1.7148014440433212, "no_speech_prob": 0.05496422201395035}, {"id": 316, "seek": 124662, "start": 1261.6599999999999, "end": 1265.7399999999998, "text": " And all collections in the system then expect you to pass a block of code into it.", "tokens": [51116, 400, 439, 16641, 294, 264, 1185, 550, 2066, 291, 281, 1320, 257, 3461, 295, 3089, 666, 309, 13, 51320], "temperature": 0.0, "avg_logprob": -0.1450693398191218, "compression_ratio": 1.7148014440433212, "no_speech_prob": 0.05496422201395035}, {"id": 317, "seek": 124662, "start": 1265.7399999999998, "end": 1269.6399999999999, "text": " Well, how do you turn internal iteration into external iteration?", "tokens": [51320, 1042, 11, 577, 360, 291, 1261, 6920, 24784, 666, 8320, 24784, 30, 51515], "temperature": 0.0, "avg_logprob": -0.1450693398191218, "compression_ratio": 1.7148014440433212, "no_speech_prob": 0.05496422201395035}, {"id": 318, "seek": 124662, "start": 1269.6399999999999, "end": 1274.7399999999998, "text": " You have to use a coroutine that can yield values back out while staying inside that", "tokens": [51515, 509, 362, 281, 764, 257, 1181, 45075, 300, 393, 11257, 4190, 646, 484, 1339, 7939, 1854, 300, 51770], "temperature": 0.0, "avg_logprob": -0.1450693398191218, "compression_ratio": 1.7148014440433212, "no_speech_prob": 0.05496422201395035}, {"id": 319, "seek": 124662, "start": 1274.7399999999998, "end": 1275.7399999999998, "text": " loop.", "tokens": [51770, 6367, 13, 51820], "temperature": 0.0, "avg_logprob": -0.1450693398191218, "compression_ratio": 1.7148014440433212, "no_speech_prob": 0.05496422201395035}, {"id": 320, "seek": 127574, "start": 1275.74, "end": 1280.38, "text": " So now we've got that potential for all sorts of fibers, hundreds of thousands of fibers", "tokens": [50364, 407, 586, 321, 600, 658, 300, 3995, 337, 439, 7527, 295, 25252, 11, 6779, 295, 5383, 295, 25252, 50596], "temperature": 0.0, "avg_logprob": -0.15186492919921876, "compression_ratio": 1.7303754266211604, "no_speech_prob": 0.0007552444003522396}, {"id": 321, "seek": 127574, "start": 1280.38, "end": 1284.54, "text": " all over the system, just because we're iterating collections with an external iterator.", "tokens": [50596, 439, 670, 264, 1185, 11, 445, 570, 321, 434, 17138, 990, 16641, 365, 364, 8320, 17138, 1639, 13, 50804], "temperature": 0.0, "avg_logprob": -0.15186492919921876, "compression_ratio": 1.7303754266211604, "no_speech_prob": 0.0007552444003522396}, {"id": 322, "seek": 127574, "start": 1284.54, "end": 1291.54, "text": " I'm going to kind of blow through this because the next talk will cover fibers a bit more.", "tokens": [50804, 286, 478, 516, 281, 733, 295, 6327, 807, 341, 570, 264, 958, 751, 486, 2060, 25252, 257, 857, 544, 13, 51154], "temperature": 0.0, "avg_logprob": -0.15186492919921876, "compression_ratio": 1.7303754266211604, "no_speech_prob": 0.0007552444003522396}, {"id": 323, "seek": 127574, "start": 1291.54, "end": 1294.34, "text": " The example here of handling requests on a thread.", "tokens": [51154, 440, 1365, 510, 295, 13175, 12475, 322, 257, 7207, 13, 51294], "temperature": 0.0, "avg_logprob": -0.15186492919921876, "compression_ratio": 1.7303754266211604, "no_speech_prob": 0.0007552444003522396}, {"id": 324, "seek": 127574, "start": 1294.34, "end": 1296.64, "text": " We've got a thread, a request comes in.", "tokens": [51294, 492, 600, 658, 257, 7207, 11, 257, 5308, 1487, 294, 13, 51409], "temperature": 0.0, "avg_logprob": -0.15186492919921876, "compression_ratio": 1.7303754266211604, "no_speech_prob": 0.0007552444003522396}, {"id": 325, "seek": 127574, "start": 1296.64, "end": 1299.98, "text": " Now it's waiting for more information, the thread's not being used.", "tokens": [51409, 823, 309, 311, 3806, 337, 544, 1589, 11, 264, 7207, 311, 406, 885, 1143, 13, 51576], "temperature": 0.0, "avg_logprob": -0.15186492919921876, "compression_ratio": 1.7303754266211604, "no_speech_prob": 0.0007552444003522396}, {"id": 326, "seek": 127574, "start": 1299.98, "end": 1303.96, "text": " Finally we get more data, we can proceed with the rest of our request handling.", "tokens": [51576, 6288, 321, 483, 544, 1412, 11, 321, 393, 8991, 365, 264, 1472, 295, 527, 5308, 13175, 13, 51775], "temperature": 0.0, "avg_logprob": -0.15186492919921876, "compression_ratio": 1.7303754266211604, "no_speech_prob": 0.0007552444003522396}, {"id": 327, "seek": 130396, "start": 1303.96, "end": 1310.72, "text": " With fibers, of course, we can use multiple different fibers handling different connections", "tokens": [50364, 2022, 25252, 11, 295, 1164, 11, 321, 393, 764, 3866, 819, 25252, 13175, 819, 9271, 50702], "temperature": 0.0, "avg_logprob": -0.16877298769743546, "compression_ratio": 1.7613636363636365, "no_speech_prob": 0.00048778121708892286}, {"id": 328, "seek": 130396, "start": 1310.72, "end": 1312.3600000000001, "text": " on the same native thread.", "tokens": [50702, 322, 264, 912, 8470, 7207, 13, 50784], "temperature": 0.0, "avg_logprob": -0.16877298769743546, "compression_ratio": 1.7613636363636365, "no_speech_prob": 0.00048778121708892286}, {"id": 329, "seek": 130396, "start": 1312.3600000000001, "end": 1315.76, "text": " So the request comes in, this fiber's waiting on IO.", "tokens": [50784, 407, 264, 5308, 1487, 294, 11, 341, 12874, 311, 3806, 322, 39839, 13, 50954], "temperature": 0.0, "avg_logprob": -0.16877298769743546, "compression_ratio": 1.7613636363636365, "no_speech_prob": 0.00048778121708892286}, {"id": 330, "seek": 130396, "start": 1315.76, "end": 1320.1200000000001, "text": " Well let's spin up another fiber that can handle the next request that comes in.", "tokens": [50954, 1042, 718, 311, 6060, 493, 1071, 12874, 300, 393, 4813, 264, 958, 5308, 300, 1487, 294, 13, 51172], "temperature": 0.0, "avg_logprob": -0.16877298769743546, "compression_ratio": 1.7613636363636365, "no_speech_prob": 0.00048778121708892286}, {"id": 331, "seek": 130396, "start": 1320.1200000000001, "end": 1323.26, "text": " And they can multiplex use of that same thread.", "tokens": [51172, 400, 436, 393, 3311, 2021, 764, 295, 300, 912, 7207, 13, 51329], "temperature": 0.0, "avg_logprob": -0.16877298769743546, "compression_ratio": 1.7613636363636365, "no_speech_prob": 0.00048778121708892286}, {"id": 332, "seek": 130396, "start": 1323.26, "end": 1326.28, "text": " This is what we're starting to see more and more in Ruby, and this is where it will be", "tokens": [51329, 639, 307, 437, 321, 434, 2891, 281, 536, 544, 293, 544, 294, 19907, 11, 293, 341, 307, 689, 309, 486, 312, 51480], "temperature": 0.0, "avg_logprob": -0.16877298769743546, "compression_ratio": 1.7613636363636365, "no_speech_prob": 0.00048778121708892286}, {"id": 333, "seek": 130396, "start": 1326.28, "end": 1332.52, "text": " critical for us to have lightweight fibers, lightweight coroutines on J Ruby.", "tokens": [51480, 4924, 337, 505, 281, 362, 22052, 25252, 11, 22052, 1181, 346, 1652, 322, 508, 19907, 13, 51792], "temperature": 0.0, "avg_logprob": -0.16877298769743546, "compression_ratio": 1.7613636363636365, "no_speech_prob": 0.00048778121708892286}, {"id": 334, "seek": 133252, "start": 1333.44, "end": 1339.92, "text": " Okay, so here is a little benchmark, a little example of trying to test how long it takes", "tokens": [50410, 1033, 11, 370, 510, 307, 257, 707, 18927, 11, 257, 707, 1365, 295, 1382, 281, 1500, 577, 938, 309, 2516, 50734], "temperature": 0.0, "avg_logprob": -0.18048743406931558, "compression_ratio": 1.6088888888888888, "no_speech_prob": 0.003592207795009017}, {"id": 335, "seek": 133252, "start": 1339.92, "end": 1344.68, "text": " to spin up 100,000 fibers and run them all to completion.", "tokens": [50734, 281, 6060, 493, 2319, 11, 1360, 25252, 293, 1190, 552, 439, 281, 19372, 13, 50972], "temperature": 0.0, "avg_logprob": -0.18048743406931558, "compression_ratio": 1.6088888888888888, "no_speech_prob": 0.003592207795009017}, {"id": 336, "seek": 133252, "start": 1344.68, "end": 1349.78, "text": " So they are 100,000 live fibers in the system at any given time on this benchmark.", "tokens": [50972, 407, 436, 366, 2319, 11, 1360, 1621, 25252, 294, 264, 1185, 412, 604, 2212, 565, 322, 341, 18927, 13, 51227], "temperature": 0.0, "avg_logprob": -0.18048743406931558, "compression_ratio": 1.6088888888888888, "no_speech_prob": 0.003592207795009017}, {"id": 337, "seek": 133252, "start": 1349.78, "end": 1353.1399999999999, "text": " And of course as you would expect this doesn't work.", "tokens": [51227, 400, 295, 1164, 382, 291, 576, 2066, 341, 1177, 380, 589, 13, 51395], "temperature": 0.0, "avg_logprob": -0.18048743406931558, "compression_ratio": 1.6088888888888888, "no_speech_prob": 0.003592207795009017}, {"id": 338, "seek": 133252, "start": 1353.1399999999999, "end": 1359.72, "text": " We can't spin up 100,000 native threads, and it just crashes in horrific ways.", "tokens": [51395, 492, 393, 380, 6060, 493, 2319, 11, 1360, 8470, 19314, 11, 293, 309, 445, 28642, 294, 29248, 2098, 13, 51724], "temperature": 0.0, "avg_logprob": -0.18048743406931558, "compression_ratio": 1.6088888888888888, "no_speech_prob": 0.003592207795009017}, {"id": 339, "seek": 135972, "start": 1359.76, "end": 1364.0, "text": " I'd love to see this crash in less horrific ways, but ideally we just move away from this", "tokens": [50366, 286, 1116, 959, 281, 536, 341, 8252, 294, 1570, 29248, 2098, 11, 457, 22915, 321, 445, 1286, 1314, 490, 341, 50578], "temperature": 0.0, "avg_logprob": -0.1582489013671875, "compression_ratio": 1.5571428571428572, "no_speech_prob": 0.0041974373161792755}, {"id": 340, "seek": 135972, "start": 1364.0, "end": 1366.2, "text": " problem altogether.", "tokens": [50578, 1154, 19051, 13, 50688], "temperature": 0.0, "avg_logprob": -0.1582489013671875, "compression_ratio": 1.5571428571428572, "no_speech_prob": 0.0041974373161792755}, {"id": 341, "seek": 135972, "start": 1366.2, "end": 1368.52, "text": " And that's where we get project loom.", "tokens": [50688, 400, 300, 311, 689, 321, 483, 1716, 450, 298, 13, 50804], "temperature": 0.0, "avg_logprob": -0.1582489013671875, "compression_ratio": 1.5571428571428572, "no_speech_prob": 0.0041974373161792755}, {"id": 342, "seek": 135972, "start": 1368.52, "end": 1376.24, "text": " So JVM Today, as of 21, we now have an official API for lightweight coroutines for essentially", "tokens": [50804, 407, 508, 53, 44, 2692, 11, 382, 295, 5080, 11, 321, 586, 362, 364, 4783, 9362, 337, 22052, 1181, 346, 1652, 337, 4476, 51190], "temperature": 0.0, "avg_logprob": -0.1582489013671875, "compression_ratio": 1.5571428571428572, "no_speech_prob": 0.0041974373161792755}, {"id": 343, "seek": 135972, "start": 1376.24, "end": 1381.8, "text": " fibers that maps almost perfectly to what we need in the Ruby world.", "tokens": [51190, 25252, 300, 11317, 1920, 6239, 281, 437, 321, 643, 294, 264, 19907, 1002, 13, 51468], "temperature": 0.0, "avg_logprob": -0.1582489013671875, "compression_ratio": 1.5571428571428572, "no_speech_prob": 0.0041974373161792755}, {"id": 344, "seek": 135972, "start": 1381.8, "end": 1382.88, "text": " And we've already got this integrated.", "tokens": [51468, 400, 321, 600, 1217, 658, 341, 10919, 13, 51522], "temperature": 0.0, "avg_logprob": -0.1582489013671875, "compression_ratio": 1.5571428571428572, "no_speech_prob": 0.0041974373161792755}, {"id": 345, "seek": 135972, "start": 1382.88, "end": 1387.32, "text": " We integrated it a year ago actually, and have only made minor changes along the way.", "tokens": [51522, 492, 10919, 309, 257, 1064, 2057, 767, 11, 293, 362, 787, 1027, 6696, 2962, 2051, 264, 636, 13, 51744], "temperature": 0.0, "avg_logprob": -0.1582489013671875, "compression_ratio": 1.5571428571428572, "no_speech_prob": 0.0041974373161792755}, {"id": 346, "seek": 138732, "start": 1387.32, "end": 1393.6, "text": " I'd like to show this just to demonstrate how much work we had to do to switch from our", "tokens": [50364, 286, 1116, 411, 281, 855, 341, 445, 281, 11698, 577, 709, 589, 321, 632, 281, 360, 281, 3679, 490, 527, 50678], "temperature": 0.0, "avg_logprob": -0.18548361125745272, "compression_ratio": 1.6926406926406927, "no_speech_prob": 0.0008556899847462773}, {"id": 347, "seek": 138732, "start": 1393.6, "end": 1399.76, "text": " built in native fiber, native thread fibers to the virtual thread fibers.", "tokens": [50678, 3094, 294, 8470, 12874, 11, 8470, 7207, 25252, 281, 264, 6374, 7207, 25252, 13, 50986], "temperature": 0.0, "avg_logprob": -0.18548361125745272, "compression_ratio": 1.6926406926406927, "no_speech_prob": 0.0008556899847462773}, {"id": 348, "seek": 138732, "start": 1399.76, "end": 1405.4399999999998, "text": " I was shocked that this was all it took, and suddenly this benchmark actually could run.", "tokens": [50986, 286, 390, 12763, 300, 341, 390, 439, 309, 1890, 11, 293, 5800, 341, 18927, 767, 727, 1190, 13, 51270], "temperature": 0.0, "avg_logprob": -0.18548361125745272, "compression_ratio": 1.6926406926406927, "no_speech_prob": 0.0008556899847462773}, {"id": 349, "seek": 138732, "start": 1405.4399999999998, "end": 1408.8, "text": " It could actually spin up all of those fibers and run them to completion.", "tokens": [51270, 467, 727, 767, 6060, 493, 439, 295, 729, 25252, 293, 1190, 552, 281, 19372, 13, 51438], "temperature": 0.0, "avg_logprob": -0.18548361125745272, "compression_ratio": 1.6926406926406927, "no_speech_prob": 0.0008556899847462773}, {"id": 350, "seek": 138732, "start": 1408.8, "end": 1413.84, "text": " So amazing work on the loom side, and very happy with the results.", "tokens": [51438, 407, 2243, 589, 322, 264, 450, 298, 1252, 11, 293, 588, 2055, 365, 264, 3542, 13, 51690], "temperature": 0.0, "avg_logprob": -0.18548361125745272, "compression_ratio": 1.6926406926406927, "no_speech_prob": 0.0008556899847462773}, {"id": 351, "seek": 141384, "start": 1413.8799999999999, "end": 1419.04, "text": " Once wise, so here I drop it down to 10,000 so that I can actually try and get the threaded", "tokens": [50366, 3443, 10829, 11, 370, 510, 286, 3270, 309, 760, 281, 1266, 11, 1360, 370, 300, 286, 393, 767, 853, 293, 483, 264, 47493, 50624], "temperature": 0.0, "avg_logprob": -0.16369856775334451, "compression_ratio": 1.5650684931506849, "no_speech_prob": 0.056622229516506195}, {"id": 352, "seek": 141384, "start": 1419.04, "end": 1420.8799999999999, "text": " version to work.", "tokens": [50624, 3037, 281, 589, 13, 50716], "temperature": 0.0, "avg_logprob": -0.16369856775334451, "compression_ratio": 1.5650684931506849, "no_speech_prob": 0.056622229516506195}, {"id": 353, "seek": 141384, "start": 1420.8799999999999, "end": 1426.6, "text": " Clearly we're getting significant gains on passing, context switching between different", "tokens": [50716, 24120, 321, 434, 1242, 4776, 16823, 322, 8437, 11, 4319, 16493, 1296, 819, 51002], "temperature": 0.0, "avg_logprob": -0.16369856775334451, "compression_ratio": 1.5650684931506849, "no_speech_prob": 0.056622229516506195}, {"id": 354, "seek": 141384, "start": 1426.6, "end": 1430.9599999999998, "text": " fibers, because loom is just better at that, and there's a much lighter weight process", "tokens": [51002, 25252, 11, 570, 450, 298, 307, 445, 1101, 412, 300, 11, 293, 456, 311, 257, 709, 11546, 3364, 1399, 51220], "temperature": 0.0, "avg_logprob": -0.16369856775334451, "compression_ratio": 1.5650684931506849, "no_speech_prob": 0.056622229516506195}, {"id": 355, "seek": 141384, "start": 1430.9599999999998, "end": 1435.3999999999999, "text": " for going from one fiber to another on the same thread.", "tokens": [51220, 337, 516, 490, 472, 12874, 281, 1071, 322, 264, 912, 7207, 13, 51442], "temperature": 0.0, "avg_logprob": -0.16369856775334451, "compression_ratio": 1.5650684931506849, "no_speech_prob": 0.056622229516506195}, {"id": 356, "seek": 141384, "start": 1435.3999999999999, "end": 1436.9199999999998, "text": " Not quite as fast as C Ruby.", "tokens": [51442, 1726, 1596, 382, 2370, 382, 383, 19907, 13, 51518], "temperature": 0.0, "avg_logprob": -0.16369856775334451, "compression_ratio": 1.5650684931506849, "no_speech_prob": 0.056622229516506195}, {"id": 357, "seek": 141384, "start": 1436.9199999999998, "end": 1443.48, "text": " I suspect this is probably due to us relying on a very general purpose scheduler for the", "tokens": [51518, 286, 9091, 341, 307, 1391, 3462, 281, 505, 24140, 322, 257, 588, 2674, 4334, 12000, 260, 337, 264, 51846], "temperature": 0.0, "avg_logprob": -0.16369856775334451, "compression_ratio": 1.5650684931506849, "no_speech_prob": 0.056622229516506195}, {"id": 358, "seek": 144348, "start": 1443.52, "end": 1448.48, "text": " virtual threads behind the scenes, where we really just want to say, this fiber's done,", "tokens": [50366, 6374, 19314, 2261, 264, 8026, 11, 689, 321, 534, 445, 528, 281, 584, 11, 341, 12874, 311, 1096, 11, 50614], "temperature": 0.0, "avg_logprob": -0.15742953491210937, "compression_ratio": 1.582375478927203, "no_speech_prob": 0.013217593543231487}, {"id": 359, "seek": 144348, "start": 1448.48, "end": 1453.48, "text": " now run this one, rather than unblock that fiber and wait for the scheduler to pick it", "tokens": [50614, 586, 1190, 341, 472, 11, 2831, 813, 517, 28830, 300, 12874, 293, 1699, 337, 264, 12000, 260, 281, 1888, 309, 50864], "temperature": 0.0, "avg_logprob": -0.15742953491210937, "compression_ratio": 1.582375478927203, "no_speech_prob": 0.013217593543231487}, {"id": 360, "seek": 144348, "start": 1453.48, "end": 1454.48, "text": " up.", "tokens": [50864, 493, 13, 50914], "temperature": 0.0, "avg_logprob": -0.15742953491210937, "compression_ratio": 1.582375478927203, "no_speech_prob": 0.013217593543231487}, {"id": 361, "seek": 144348, "start": 1454.48, "end": 1457.0, "text": " I think we can make up most of this overhead.", "tokens": [50914, 286, 519, 321, 393, 652, 493, 881, 295, 341, 19922, 13, 51040], "temperature": 0.0, "avg_logprob": -0.15742953491210937, "compression_ratio": 1.582375478927203, "no_speech_prob": 0.013217593543231487}, {"id": 362, "seek": 144348, "start": 1457.0, "end": 1462.44, "text": " Similarly on M1, I don't know if this is general to arm or not, but this is the performance", "tokens": [51040, 13157, 322, 376, 16, 11, 286, 500, 380, 458, 498, 341, 307, 2674, 281, 3726, 420, 406, 11, 457, 341, 307, 264, 3389, 51312], "temperature": 0.0, "avg_logprob": -0.15742953491210937, "compression_ratio": 1.582375478927203, "no_speech_prob": 0.013217593543231487}, {"id": 363, "seek": 144348, "start": 1462.44, "end": 1463.44, "text": " results we have.", "tokens": [51312, 3542, 321, 362, 13, 51362], "temperature": 0.0, "avg_logprob": -0.15742953491210937, "compression_ratio": 1.582375478927203, "no_speech_prob": 0.013217593543231487}, {"id": 364, "seek": 144348, "start": 1463.44, "end": 1465.4, "text": " Could not get 10,000 to go on M1.", "tokens": [51362, 7497, 406, 483, 1266, 11, 1360, 281, 352, 322, 376, 16, 13, 51460], "temperature": 0.0, "avg_logprob": -0.15742953491210937, "compression_ratio": 1.582375478927203, "no_speech_prob": 0.013217593543231487}, {"id": 365, "seek": 144348, "start": 1465.4, "end": 1469.0, "text": " I got to drop it down to like 2,000 or 3,000.", "tokens": [51460, 286, 658, 281, 3270, 309, 760, 281, 411, 568, 11, 1360, 420, 805, 11, 1360, 13, 51640], "temperature": 0.0, "avg_logprob": -0.15742953491210937, "compression_ratio": 1.582375478927203, "no_speech_prob": 0.013217593543231487}, {"id": 366, "seek": 146900, "start": 1469.0, "end": 1474.8, "text": " The impact is a bit more here, but again I'm hoping that as loom evolves, as we use it", "tokens": [50364, 440, 2712, 307, 257, 857, 544, 510, 11, 457, 797, 286, 478, 7159, 300, 382, 450, 298, 43737, 11, 382, 321, 764, 309, 50654], "temperature": 0.0, "avg_logprob": -0.15598083311511624, "compression_ratio": 1.635379061371841, "no_speech_prob": 0.011685512028634548}, {"id": 367, "seek": 146900, "start": 1474.8, "end": 1478.08, "text": " better, we'll see improvements.", "tokens": [50654, 1101, 11, 321, 603, 536, 13797, 13, 50818], "temperature": 0.0, "avg_logprob": -0.15598083311511624, "compression_ratio": 1.635379061371841, "no_speech_prob": 0.011685512028634548}, {"id": 368, "seek": 146900, "start": 1478.08, "end": 1480.88, "text": " Five minutes for the last section here.", "tokens": [50818, 9436, 2077, 337, 264, 1036, 3541, 510, 13, 50958], "temperature": 0.0, "avg_logprob": -0.15598083311511624, "compression_ratio": 1.635379061371841, "no_speech_prob": 0.011685512028634548}, {"id": 369, "seek": 146900, "start": 1480.88, "end": 1484.6, "text": " The classic problem with J Ruby is still startup time.", "tokens": [50958, 440, 7230, 1154, 365, 508, 19907, 307, 920, 18578, 565, 13, 51144], "temperature": 0.0, "avg_logprob": -0.15598083311511624, "compression_ratio": 1.635379061371841, "no_speech_prob": 0.011685512028634548}, {"id": 370, "seek": 146900, "start": 1484.6, "end": 1488.6, "text": " If we did not have startup time, we probably would have won the Ruby war a long time ago.", "tokens": [51144, 759, 321, 630, 406, 362, 18578, 565, 11, 321, 1391, 576, 362, 1582, 264, 19907, 1516, 257, 938, 565, 2057, 13, 51344], "temperature": 0.0, "avg_logprob": -0.15598083311511624, "compression_ratio": 1.635379061371841, "no_speech_prob": 0.011685512028634548}, {"id": 371, "seek": 146900, "start": 1488.6, "end": 1493.36, "text": " It's the number one, two, and three complaint about J Ruby is how much longer it takes to", "tokens": [51344, 467, 311, 264, 1230, 472, 11, 732, 11, 293, 1045, 20100, 466, 508, 19907, 307, 577, 709, 2854, 309, 2516, 281, 51582], "temperature": 0.0, "avg_logprob": -0.15598083311511624, "compression_ratio": 1.635379061371841, "no_speech_prob": 0.011685512028634548}, {"id": 372, "seek": 146900, "start": 1493.36, "end": 1495.32, "text": " start up.", "tokens": [51582, 722, 493, 13, 51680], "temperature": 0.0, "avg_logprob": -0.15598083311511624, "compression_ratio": 1.635379061371841, "no_speech_prob": 0.011685512028634548}, {"id": 373, "seek": 146900, "start": 1495.32, "end": 1498.48, "text": " The JBM is just not designed to start up quickly.", "tokens": [51680, 440, 508, 18345, 307, 445, 406, 4761, 281, 722, 493, 2661, 13, 51838], "temperature": 0.0, "avg_logprob": -0.15598083311511624, "compression_ratio": 1.635379061371841, "no_speech_prob": 0.011685512028634548}, {"id": 374, "seek": 149848, "start": 1498.48, "end": 1501.84, "text": " Most of the core JD code starts in the interpreter.", "tokens": [50364, 4534, 295, 264, 4965, 37082, 3089, 3719, 294, 264, 34132, 13, 50532], "temperature": 0.0, "avg_logprob": -0.1571730527010831, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.03730766847729683}, {"id": 375, "seek": 149848, "start": 1501.84, "end": 1506.04, "text": " It takes a long time for that to optimize, and then your application can start getting", "tokens": [50532, 467, 2516, 257, 938, 565, 337, 300, 281, 19719, 11, 293, 550, 428, 3861, 393, 722, 1242, 50742], "temperature": 0.0, "avg_logprob": -0.1571730527010831, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.03730766847729683}, {"id": 376, "seek": 149848, "start": 1506.04, "end": 1507.28, "text": " fast.", "tokens": [50742, 2370, 13, 50804], "temperature": 0.0, "avg_logprob": -0.1571730527010831, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.03730766847729683}, {"id": 377, "seek": 149848, "start": 1507.28, "end": 1511.8, "text": " We make it worse because we interpret Ruby code, and then every once in a while we'll", "tokens": [50804, 492, 652, 309, 5324, 570, 321, 7302, 19907, 3089, 11, 293, 550, 633, 1564, 294, 257, 1339, 321, 603, 51030], "temperature": 0.0, "avg_logprob": -0.1571730527010831, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.03730766847729683}, {"id": 378, "seek": 149848, "start": 1511.8, "end": 1516.52, "text": " just throw more byte code at the JVM, like okay, now this call site's actually bound", "tokens": [51030, 445, 3507, 544, 40846, 3089, 412, 264, 508, 53, 44, 11, 411, 1392, 11, 586, 341, 818, 3621, 311, 767, 5472, 51266], "temperature": 0.0, "avg_logprob": -0.1571730527010831, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.03730766847729683}, {"id": 379, "seek": 149848, "start": 1516.52, "end": 1520.92, "text": " to a byte code method, not an interpreter, and we're just confusing the hell out of it", "tokens": [51266, 281, 257, 40846, 3089, 3170, 11, 406, 364, 34132, 11, 293, 321, 434, 445, 13181, 264, 4921, 484, 295, 309, 51486], "temperature": 0.0, "avg_logprob": -0.1571730527010831, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.03730766847729683}, {"id": 380, "seek": 149848, "start": 1520.92, "end": 1522.64, "text": " all the time.", "tokens": [51486, 439, 264, 565, 13, 51572], "temperature": 0.0, "avg_logprob": -0.1571730527010831, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.03730766847729683}, {"id": 381, "seek": 152264, "start": 1522.64, "end": 1528.48, "text": " This is one of the reasons we actually do lazy compilation to byte code, because we", "tokens": [50364, 639, 307, 472, 295, 264, 4112, 321, 767, 360, 14847, 40261, 281, 40846, 3089, 11, 570, 321, 50656], "temperature": 0.0, "avg_logprob": -0.13519356701825117, "compression_ratio": 1.624113475177305, "no_speech_prob": 0.02930361218750477}, {"id": 382, "seek": 152264, "start": 1528.48, "end": 1534.4, "text": " want to reduce the amount of overhead we force onto the JIT at the JVM level.", "tokens": [50656, 528, 281, 5407, 264, 2372, 295, 19922, 321, 3464, 3911, 264, 508, 3927, 412, 264, 508, 53, 44, 1496, 13, 50952], "temperature": 0.0, "avg_logprob": -0.13519356701825117, "compression_ratio": 1.624113475177305, "no_speech_prob": 0.02930361218750477}, {"id": 383, "seek": 152264, "start": 1534.4, "end": 1537.24, "text": " Walk through J Ruby's architecture here quick.", "tokens": [50952, 10818, 807, 508, 19907, 311, 9482, 510, 1702, 13, 51094], "temperature": 0.0, "avg_logprob": -0.13519356701825117, "compression_ratio": 1.624113475177305, "no_speech_prob": 0.02930361218750477}, {"id": 384, "seek": 152264, "start": 1537.24, "end": 1543.48, "text": " We have our Ruby parser, gives us our Ruby AST, we compile into our intermediate representation,", "tokens": [51094, 492, 362, 527, 19907, 21156, 260, 11, 2709, 505, 527, 19907, 316, 6840, 11, 321, 31413, 666, 527, 19376, 10290, 11, 51406], "temperature": 0.0, "avg_logprob": -0.13519356701825117, "compression_ratio": 1.624113475177305, "no_speech_prob": 0.02930361218750477}, {"id": 385, "seek": 152264, "start": 1543.48, "end": 1546.5600000000002, "text": " interpret that for a while, and here's where it becomes mixed mode.", "tokens": [51406, 7302, 300, 337, 257, 1339, 11, 293, 510, 311, 689, 309, 3643, 7467, 4391, 13, 51560], "temperature": 0.0, "avg_logprob": -0.13519356701825117, "compression_ratio": 1.624113475177305, "no_speech_prob": 0.02930361218750477}, {"id": 386, "seek": 152264, "start": 1546.5600000000002, "end": 1550.5600000000002, "text": " Then eventually we will generate byte code for those methods, and then hopefully the", "tokens": [51560, 1396, 4728, 321, 486, 8460, 40846, 3089, 337, 729, 7150, 11, 293, 550, 4696, 264, 51760], "temperature": 0.0, "avg_logprob": -0.13519356701825117, "compression_ratio": 1.624113475177305, "no_speech_prob": 0.02930361218750477}, {"id": 387, "seek": 155056, "start": 1550.56, "end": 1554.9199999999998, "text": " rest of it all works and optimizes to native code.", "tokens": [50364, 1472, 295, 309, 439, 1985, 293, 5028, 5660, 281, 8470, 3089, 13, 50582], "temperature": 0.0, "avg_logprob": -0.15296072430080837, "compression_ratio": 1.628691983122363, "no_speech_prob": 0.00475370092317462}, {"id": 388, "seek": 155056, "start": 1554.9199999999998, "end": 1559.0, "text": " One of the early ways that we've tried to improve startup time is basically to turn", "tokens": [50582, 1485, 295, 264, 2440, 2098, 300, 321, 600, 3031, 281, 3470, 18578, 565, 307, 1936, 281, 1261, 50786], "temperature": 0.0, "avg_logprob": -0.15296072430080837, "compression_ratio": 1.628691983122363, "no_speech_prob": 0.00475370092317462}, {"id": 389, "seek": 155056, "start": 1559.0, "end": 1565.72, "text": " most of that off, rather than turning anything into byte code, rather than even running the", "tokens": [50786, 881, 295, 300, 766, 11, 2831, 813, 6246, 1340, 666, 40846, 3089, 11, 2831, 813, 754, 2614, 264, 51122], "temperature": 0.0, "avg_logprob": -0.15296072430080837, "compression_ratio": 1.628691983122363, "no_speech_prob": 0.00475370092317462}, {"id": 390, "seek": 155056, "start": 1565.72, "end": 1570.28, "text": " C2, the fast JIT in hotspot.", "tokens": [51122, 383, 17, 11, 264, 2370, 508, 3927, 294, 36121, 17698, 13, 51350], "temperature": 0.0, "avg_logprob": -0.15296072430080837, "compression_ratio": 1.628691983122363, "no_speech_prob": 0.00475370092317462}, {"id": 391, "seek": 155056, "start": 1570.28, "end": 1575.52, "text": " We turn only to C1, we use the simple JIT in the JVM, and we only use our interpreter.", "tokens": [51350, 492, 1261, 787, 281, 383, 16, 11, 321, 764, 264, 2199, 508, 3927, 294, 264, 508, 53, 44, 11, 293, 321, 787, 764, 527, 34132, 13, 51612], "temperature": 0.0, "avg_logprob": -0.15296072430080837, "compression_ratio": 1.628691983122363, "no_speech_prob": 0.00475370092317462}, {"id": 392, "seek": 155056, "start": 1575.52, "end": 1578.6799999999998, "text": " This improves our startup time by about 2x.", "tokens": [51612, 639, 24771, 527, 18578, 565, 538, 466, 568, 87, 13, 51770], "temperature": 0.0, "avg_logprob": -0.15296072430080837, "compression_ratio": 1.628691983122363, "no_speech_prob": 0.00475370092317462}, {"id": 393, "seek": 157868, "start": 1578.72, "end": 1581.1200000000001, "text": " By far the best thing we've had so far.", "tokens": [50366, 3146, 1400, 264, 1151, 551, 321, 600, 632, 370, 1400, 13, 50486], "temperature": 0.0, "avg_logprob": -0.24298319900244997, "compression_ratio": 1.6374045801526718, "no_speech_prob": 0.06946468353271484}, {"id": 394, "seek": 157868, "start": 1581.1200000000001, "end": 1585.68, "text": " Now, another way that could be potentially a way to fix this would be ahead of time", "tokens": [50486, 823, 11, 1071, 636, 300, 727, 312, 7263, 257, 636, 281, 3191, 341, 576, 312, 2286, 295, 565, 50714], "temperature": 0.0, "avg_logprob": -0.24298319900244997, "compression_ratio": 1.6374045801526718, "no_speech_prob": 0.06946468353271484}, {"id": 395, "seek": 157868, "start": 1585.68, "end": 1586.68, "text": " compilation.", "tokens": [50714, 40261, 13, 50764], "temperature": 0.0, "avg_logprob": -0.24298319900244997, "compression_ratio": 1.6374045801526718, "no_speech_prob": 0.06946468353271484}, {"id": 396, "seek": 157868, "start": 1586.68, "end": 1592.2, "text": " Of course, GrawlVM solves this very nicely for that world, but it completely disables", "tokens": [50764, 2720, 1164, 11, 460, 5131, 75, 53, 44, 39890, 341, 588, 9594, 337, 300, 1002, 11, 457, 309, 2584, 717, 2965, 51040], "temperature": 0.0, "avg_logprob": -0.24298319900244997, "compression_ratio": 1.6374045801526718, "no_speech_prob": 0.06946468353271484}, {"id": 397, "seek": 157868, "start": 1592.2, "end": 1595.04, "text": " all of the native things that we want.", "tokens": [51040, 439, 295, 264, 8470, 721, 300, 321, 528, 13, 51182], "temperature": 0.0, "avg_logprob": -0.24298319900244997, "compression_ratio": 1.6374045801526718, "no_speech_prob": 0.06946468353271484}, {"id": 398, "seek": 157868, "start": 1595.04, "end": 1599.92, "text": " General purpose, invoke dynamic, and method handles just simply, essentially doesn't work.", "tokens": [51182, 6996, 4334, 11, 41117, 8546, 11, 293, 3170, 18722, 445, 2935, 11, 4476, 1177, 380, 589, 13, 51426], "temperature": 0.0, "avg_logprob": -0.24298319900244997, "compression_ratio": 1.6374045801526718, "no_speech_prob": 0.06946468353271484}, {"id": 399, "seek": 157868, "start": 1599.92, "end": 1604.04, "text": " Then beyond that, we would have to pre-compile all of our code to byte code.", "tokens": [51426, 1396, 4399, 300, 11, 321, 576, 362, 281, 659, 12, 21541, 794, 439, 295, 527, 3089, 281, 40846, 3089, 13, 51632], "temperature": 0.0, "avg_logprob": -0.24298319900244997, "compression_ratio": 1.6374045801526718, "no_speech_prob": 0.06946468353271484}, {"id": 400, "seek": 160404, "start": 1604.04, "end": 1609.44, "text": " We'd have to link it in some way that it could ahead of time compile the native.", "tokens": [50364, 492, 1116, 362, 281, 2113, 309, 294, 512, 636, 300, 309, 727, 2286, 295, 565, 31413, 264, 8470, 13, 50634], "temperature": 0.0, "avg_logprob": -0.17075249354044597, "compression_ratio": 1.578397212543554, "no_speech_prob": 0.01691085658967495}, {"id": 401, "seek": 160404, "start": 1609.44, "end": 1610.96, "text": " This is just not going to work for us.", "tokens": [50634, 639, 307, 445, 406, 516, 281, 589, 337, 505, 13, 50710], "temperature": 0.0, "avg_logprob": -0.17075249354044597, "compression_ratio": 1.578397212543554, "no_speech_prob": 0.01691085658967495}, {"id": 402, "seek": 160404, "start": 1610.96, "end": 1615.8799999999999, "text": " We're hoping that Layden will actually pick up here with a ahead of time option that can", "tokens": [50710, 492, 434, 7159, 300, 20084, 1556, 486, 767, 1888, 493, 510, 365, 257, 2286, 295, 565, 3614, 300, 393, 50956], "temperature": 0.0, "avg_logprob": -0.17075249354044597, "compression_ratio": 1.578397212543554, "no_speech_prob": 0.01691085658967495}, {"id": 403, "seek": 160404, "start": 1615.8799999999999, "end": 1619.36, "text": " also do some dynamic stuff at runtime.", "tokens": [50956, 611, 360, 512, 8546, 1507, 412, 34474, 13, 51130], "temperature": 0.0, "avg_logprob": -0.17075249354044597, "compression_ratio": 1.578397212543554, "no_speech_prob": 0.01691085658967495}, {"id": 404, "seek": 160404, "start": 1619.36, "end": 1620.92, "text": " Where are we today?", "tokens": [51130, 2305, 366, 321, 965, 30, 51208], "temperature": 0.0, "avg_logprob": -0.17075249354044597, "compression_ratio": 1.578397212543554, "no_speech_prob": 0.01691085658967495}, {"id": 405, "seek": 160404, "start": 1620.92, "end": 1624.8, "text": " The solutions we're looking at in the short term are mostly surrounding the checkpointing", "tokens": [51208, 440, 6547, 321, 434, 1237, 412, 294, 264, 2099, 1433, 366, 5240, 11498, 264, 42269, 278, 51402], "temperature": 0.0, "avg_logprob": -0.17075249354044597, "compression_ratio": 1.578397212543554, "no_speech_prob": 0.01691085658967495}, {"id": 406, "seek": 160404, "start": 1624.8, "end": 1627.08, "text": " features.", "tokens": [51402, 4122, 13, 51516], "temperature": 0.0, "avg_logprob": -0.17075249354044597, "compression_ratio": 1.578397212543554, "no_speech_prob": 0.01691085658967495}, {"id": 407, "seek": 160404, "start": 1627.08, "end": 1633.0, "text": " Checkpoint and restore in user space, the CRIU API on Linux allows us to run JRuby to", "tokens": [51516, 6881, 6053, 293, 15227, 294, 4195, 1901, 11, 264, 383, 5577, 52, 9362, 322, 18734, 4045, 505, 281, 1190, 32849, 836, 88, 281, 51812], "temperature": 0.0, "avg_logprob": -0.17075249354044597, "compression_ratio": 1.578397212543554, "no_speech_prob": 0.01691085658967495}, {"id": 408, "seek": 163300, "start": 1633.0, "end": 1638.28, "text": " a certain point, like just after startup, and then save off a copy of it that we can", "tokens": [50364, 257, 1629, 935, 11, 411, 445, 934, 18578, 11, 293, 550, 3155, 766, 257, 5055, 295, 309, 300, 321, 393, 50628], "temperature": 0.0, "avg_logprob": -0.11991407321049617, "compression_ratio": 1.5687732342007434, "no_speech_prob": 0.02296406775712967}, {"id": 409, "seek": 163300, "start": 1638.28, "end": 1640.4, "text": " start quickly with later on.", "tokens": [50628, 722, 2661, 365, 1780, 322, 13, 50734], "temperature": 0.0, "avg_logprob": -0.11991407321049617, "compression_ratio": 1.5687732342007434, "no_speech_prob": 0.02296406775712967}, {"id": 410, "seek": 163300, "start": 1640.4, "end": 1648.2, "text": " This is being standardized in Project Crack, an unfortunate name, but a lovely project.", "tokens": [50734, 639, 307, 885, 31677, 294, 9849, 4779, 501, 11, 364, 17843, 1315, 11, 457, 257, 7496, 1716, 13, 51124], "temperature": 0.0, "avg_logprob": -0.11991407321049617, "compression_ratio": 1.5687732342007434, "no_speech_prob": 0.02296406775712967}, {"id": 411, "seek": 163300, "start": 1648.2, "end": 1652.12, "text": " This is working pretty well with JRuby right now, just experimenting with it.", "tokens": [51124, 639, 307, 1364, 1238, 731, 365, 32849, 836, 88, 558, 586, 11, 445, 29070, 365, 309, 13, 51320], "temperature": 0.0, "avg_logprob": -0.11991407321049617, "compression_ratio": 1.5687732342007434, "no_speech_prob": 0.02296406775712967}, {"id": 412, "seek": 163300, "start": 1652.12, "end": 1657.16, "text": " We are still hoping that Layden with some ahead of time compilation that still enables", "tokens": [51320, 492, 366, 920, 7159, 300, 20084, 1556, 365, 512, 2286, 295, 565, 40261, 300, 920, 17077, 51572], "temperature": 0.0, "avg_logprob": -0.11991407321049617, "compression_ratio": 1.5687732342007434, "no_speech_prob": 0.02296406775712967}, {"id": 413, "seek": 163300, "start": 1657.16, "end": 1661.24, "text": " the rest of JVM features will be our ultimate solution.", "tokens": [51572, 264, 1472, 295, 508, 53, 44, 4122, 486, 312, 527, 9705, 3827, 13, 51776], "temperature": 0.0, "avg_logprob": -0.11991407321049617, "compression_ratio": 1.5687732342007434, "no_speech_prob": 0.02296406775712967}, {"id": 414, "seek": 166124, "start": 1661.32, "end": 1667.6, "text": " You can see here, this is CRuby on the left side just doing a baseline startup.", "tokens": [50368, 509, 393, 536, 510, 11, 341, 307, 14123, 836, 88, 322, 264, 1411, 1252, 445, 884, 257, 20518, 18578, 13, 50682], "temperature": 0.0, "avg_logprob": -0.18863414732877873, "compression_ratio": 1.656140350877193, "no_speech_prob": 0.1822863519191742}, {"id": 415, "seek": 166124, "start": 1667.6, "end": 1672.24, "text": " JRuby's baseline startup without our dash dash dev flag, which turns off all of the", "tokens": [50682, 32849, 836, 88, 311, 20518, 18578, 1553, 527, 8240, 8240, 1905, 7166, 11, 597, 4523, 766, 439, 295, 264, 50914], "temperature": 0.0, "avg_logprob": -0.18863414732877873, "compression_ratio": 1.656140350877193, "no_speech_prob": 0.1822863519191742}, {"id": 416, "seek": 166124, "start": 1672.24, "end": 1673.68, "text": " optimization.", "tokens": [50914, 19618, 13, 50986], "temperature": 0.0, "avg_logprob": -0.18863414732877873, "compression_ratio": 1.656140350877193, "no_speech_prob": 0.1822863519191742}, {"id": 417, "seek": 166124, "start": 1673.68, "end": 1678.04, "text": " The dev flag here, not quite 2x, but giving us a good boost.", "tokens": [50986, 440, 1905, 7166, 510, 11, 406, 1596, 568, 87, 11, 457, 2902, 505, 257, 665, 9194, 13, 51204], "temperature": 0.0, "avg_logprob": -0.18863414732877873, "compression_ratio": 1.656140350877193, "no_speech_prob": 0.1822863519191742}, {"id": 418, "seek": 166124, "start": 1678.04, "end": 1680.64, "text": " Crack of course, significantly faster than all of those.", "tokens": [51204, 4779, 501, 295, 1164, 11, 10591, 4663, 813, 439, 295, 729, 13, 51334], "temperature": 0.0, "avg_logprob": -0.18863414732877873, "compression_ratio": 1.656140350877193, "no_speech_prob": 0.1822863519191742}, {"id": 419, "seek": 166124, "start": 1680.64, "end": 1685.52, "text": " We've actually gotten to a point in execution where we can start running Ruby code now,", "tokens": [51334, 492, 600, 767, 5768, 281, 257, 935, 294, 15058, 689, 321, 393, 722, 2614, 19907, 3089, 586, 11, 51578], "temperature": 0.0, "avg_logprob": -0.18863414732877873, "compression_ratio": 1.656140350877193, "no_speech_prob": 0.1822863519191742}, {"id": 420, "seek": 166124, "start": 1685.52, "end": 1691.16, "text": " starting to get competitive with CRuby, which was essentially designed for fast startup.", "tokens": [51578, 2891, 281, 483, 10043, 365, 14123, 836, 88, 11, 597, 390, 4476, 4761, 337, 2370, 18578, 13, 51860], "temperature": 0.0, "avg_logprob": -0.18863414732877873, "compression_ratio": 1.656140350877193, "no_speech_prob": 0.1822863519191742}, {"id": 421, "seek": 169116, "start": 1691.16, "end": 1695.44, "text": " Same example generating a Rails app, again, getting very close to where CRuby sits on", "tokens": [50364, 10635, 1365, 17746, 257, 48526, 724, 11, 797, 11, 1242, 588, 1998, 281, 689, 14123, 836, 88, 12696, 322, 50578], "temperature": 0.0, "avg_logprob": -0.18463192667279923, "compression_ratio": 1.6015325670498084, "no_speech_prob": 0.0011333381989970803}, {"id": 422, "seek": 169116, "start": 1695.44, "end": 1696.64, "text": " these numbers.", "tokens": [50578, 613, 3547, 13, 50638], "temperature": 0.0, "avg_logprob": -0.18463192667279923, "compression_ratio": 1.6015325670498084, "no_speech_prob": 0.0011333381989970803}, {"id": 423, "seek": 169116, "start": 1696.64, "end": 1703.76, "text": " So, wrapping up in the last minute here, JRuby is a test bed for all of these crazy", "tokens": [50638, 407, 11, 21993, 493, 294, 264, 1036, 3456, 510, 11, 32849, 836, 88, 307, 257, 1500, 2901, 337, 439, 295, 613, 3219, 50994], "temperature": 0.0, "avg_logprob": -0.18463192667279923, "compression_ratio": 1.6015325670498084, "no_speech_prob": 0.0011333381989970803}, {"id": 424, "seek": 169116, "start": 1703.76, "end": 1705.3200000000002, "text": " JVM things that we're doing.", "tokens": [50994, 508, 53, 44, 721, 300, 321, 434, 884, 13, 51072], "temperature": 0.0, "avg_logprob": -0.18463192667279923, "compression_ratio": 1.6015325670498084, "no_speech_prob": 0.0011333381989970803}, {"id": 425, "seek": 169116, "start": 1705.3200000000002, "end": 1707.24, "text": " We're pushing all of these edges.", "tokens": [51072, 492, 434, 7380, 439, 295, 613, 8819, 13, 51168], "temperature": 0.0, "avg_logprob": -0.18463192667279923, "compression_ratio": 1.6015325670498084, "no_speech_prob": 0.0011333381989970803}, {"id": 426, "seek": 169116, "start": 1707.24, "end": 1714.28, "text": " So whether you care about Ruby or not, we are the best invoke dynamic torture test.", "tokens": [51168, 407, 1968, 291, 1127, 466, 19907, 420, 406, 11, 321, 366, 264, 1151, 41117, 8546, 20711, 1500, 13, 51520], "temperature": 0.0, "avg_logprob": -0.18463192667279923, "compression_ratio": 1.6015325670498084, "no_speech_prob": 0.0011333381989970803}, {"id": 427, "seek": 169116, "start": 1714.28, "end": 1719.5600000000002, "text": " We're going to be hitting Panama extremely hard as it gets integrated into the system.", "tokens": [51520, 492, 434, 516, 281, 312, 8850, 41202, 4664, 1152, 382, 309, 2170, 10919, 666, 264, 1185, 13, 51784], "temperature": 0.0, "avg_logprob": -0.18463192667279923, "compression_ratio": 1.6015325670498084, "no_speech_prob": 0.0011333381989970803}, {"id": 428, "seek": 171956, "start": 1719.56, "end": 1725.6799999999998, "text": " All of the structural threading will be massively exercised by all of the structured concurrency", "tokens": [50364, 1057, 295, 264, 15067, 7207, 278, 486, 312, 29379, 4057, 2640, 538, 439, 295, 264, 18519, 23702, 10457, 50670], "temperature": 0.0, "avg_logprob": -0.1976663888978564, "compression_ratio": 1.7291666666666667, "no_speech_prob": 0.1440577208995819}, {"id": 429, "seek": 171956, "start": 1725.6799999999998, "end": 1727.3999999999999, "text": " stuff coming on the Ruby side.", "tokens": [50670, 1507, 1348, 322, 264, 19907, 1252, 13, 50756], "temperature": 0.0, "avg_logprob": -0.1976663888978564, "compression_ratio": 1.7291666666666667, "no_speech_prob": 0.1440577208995819}, {"id": 430, "seek": 171956, "start": 1727.3999999999999, "end": 1731.76, "text": " So if you're interested in helping us integrate any of these features, or if you're an implementer", "tokens": [50756, 407, 498, 291, 434, 3102, 294, 4315, 505, 13365, 604, 295, 613, 4122, 11, 420, 498, 291, 434, 364, 4445, 260, 50974], "temperature": 0.0, "avg_logprob": -0.1976663888978564, "compression_ratio": 1.7291666666666667, "no_speech_prob": 0.1440577208995819}, {"id": 431, "seek": 171956, "start": 1731.76, "end": 1737.24, "text": " interested in testing these features at scale, JRuby is definitely something you should look", "tokens": [50974, 3102, 294, 4997, 613, 4122, 412, 4373, 11, 32849, 836, 88, 307, 2138, 746, 291, 820, 574, 51248], "temperature": 0.0, "avg_logprob": -0.1976663888978564, "compression_ratio": 1.7291666666666667, "no_speech_prob": 0.1440577208995819}, {"id": 432, "seek": 171956, "start": 1737.24, "end": 1738.8799999999999, "text": " at.", "tokens": [51248, 412, 13, 51330], "temperature": 0.0, "avg_logprob": -0.1976663888978564, "compression_ratio": 1.7291666666666667, "no_speech_prob": 0.1440577208995819}, {"id": 433, "seek": 171956, "start": 1738.8799999999999, "end": 1739.8799999999999, "text": " This is more background.", "tokens": [51330, 639, 307, 544, 3678, 13, 51380], "temperature": 0.0, "avg_logprob": -0.1976663888978564, "compression_ratio": 1.7291666666666667, "no_speech_prob": 0.1440577208995819}, {"id": 434, "seek": 171956, "start": 1739.8799999999999, "end": 1742.48, "text": " I'll let you take a quick picture of this if you want.", "tokens": [51380, 286, 603, 718, 291, 747, 257, 1702, 3036, 295, 341, 498, 291, 528, 13, 51510], "temperature": 0.0, "avg_logprob": -0.1976663888978564, "compression_ratio": 1.7291666666666667, "no_speech_prob": 0.1440577208995819}, {"id": 435, "seek": 171956, "start": 1742.48, "end": 1746.6399999999999, "text": " These are talks I've done in the past that basically cover all of my many complaints about the", "tokens": [51510, 1981, 366, 6686, 286, 600, 1096, 294, 264, 1791, 300, 1936, 2060, 439, 295, 452, 867, 19585, 466, 264, 51718], "temperature": 0.0, "avg_logprob": -0.1976663888978564, "compression_ratio": 1.7291666666666667, "no_speech_prob": 0.1440577208995819}, {"id": 436, "seek": 174664, "start": 1746.64, "end": 1748.0, "text": " JVM.", "tokens": [50364, 508, 53, 44, 13, 50432], "temperature": 0.0, "avg_logprob": -0.28167009353637695, "compression_ratio": 1.013157894736842, "no_speech_prob": 0.8471263647079468}, {"id": 437, "seek": 174664, "start": 1748.0, "end": 1752.6000000000001, "text": " That list of complaints gets smaller and smaller every year, thankfully.", "tokens": [50432, 663, 1329, 295, 19585, 2170, 4356, 293, 4356, 633, 1064, 11, 27352, 13, 50662], "temperature": 0.0, "avg_logprob": -0.28167009353637695, "compression_ratio": 1.013157894736842, "no_speech_prob": 0.8471263647079468}], "language": "en"}