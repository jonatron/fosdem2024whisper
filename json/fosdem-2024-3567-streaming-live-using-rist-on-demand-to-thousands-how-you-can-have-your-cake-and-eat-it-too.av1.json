{"text": " All right, good morning. Again, I'm Sergio Amarata. I'm a board member on the RISC forum, and an active member of the RISC committee that writes specs for RISC. And I'm also the maintainer of the Librisque Open Source project. So today, we'll be talking about how RISC can support end to end live streaming with packet recovery. But in particular, I will explain how we can support this in a broadcast scenario, meaning streaming to as many users as your bandwidth can support. So we'll cover the topic in two sections. First, we'll provide a roadmap or an update on the RISC specification and the Librisque project itself. And then we'll go to a practical application and show you how you can do live streaming in a large scale with the open source tools provided. So on to part one, the development roadmap. The last time I gave an update at FOSDEM regarding RISC was February 2020, a few days before the pandemic shutdown. Now, four years later, we will explore what happens instead. I guess if I have waited one more year, I could have blamed the Thanos snap for the delay. So let's do a brief recap of the beginning of the protocol. In 2017, the VSS forum created the RISC activity group for the purpose of creating a unified interoperable protocol for transmission of IP data over loss in networks. The requirements were that it needed to be based on the UDP protocol, and it needed to include negative acknowledgment retransmission requests. So one year later, after a successful multi-vendor interop event, the simple profile specification was published. You can see that in the bottom. The RISC activity group then proceeded to add multiplexing and encryption capabilities and publish the main profile specification in early 2020. It was at that time that the Libris Library Open Source Project first was published. And you can refer to my talk I gave back then, where I go into detail explanation of what the simple profile does and the main profiles and the differences, et cetera. So as you can see on this slide, the RISC activity group has been quite busy adding features to the protocol to accommodate all possible use cases during the last four years. What started with the simple profile, the first release, as the desire to add packet recovery to an RTP stream with an MPEG-TS payload, has now turned into a reach protocol that will work with any payload and which includes multiplexing, encryption, and authentication. So Libris, the open source project, currently supports a simple profile and main profile. And we're working on adding support for the advanced profile. So in addition to the core specifications for the protocol, the RISC activity group has also published a series of recommendation or best practice documents. These are documents that extend the protocol into specific applications, into specific niches, and you need to actually consider that in the library that is compatible with this specification. So the library Libris, when applicable, has been made compatible with these recommendations, the code synchronization, the relay, et cetera, et cetera. So enough history about the protocol and the specification documents, those are all publicly available. They're not behind any payload. The VSF documents can be downloaded, the PDFs, and you can look at the specs and all the recommendations. Let's talk about the Libris open source project itself, right? In case you are not familiar with what RISC is, we can define it with just one simple sentence, like you see up there. It's a new protocol for transmission of IP data across lossing networks using UDP with NAT-based retransmissions. Before getting into anything else, I'd like to clarify the three most common misconceptions people have about the RISC protocol. And this has come about in talks and conversations. People tell me, oh, well, RISC is only for MPEC-TS, false. Advanced profile includes support for any payload with clearly identified payload types in the header now. There's even an registration with support binary payloads, et cetera. And misconception number two, you need a large buffer and therefore latency is large, a second or more, right? In order for you to use RISC, false. You really need two to six times the round trip time, the RTT, between the two endpoints you're trying to send the data through. So the shorter the RTT, the total buffer required will also be shorter and you can talk about 10 milliseconds, 20 millisecond total latency. It's just depending on what network you're deploying it in. In addition, and this is a major misconception on that second point, RISC also supports real-time data channels with no added latency, with lossy channels that you can have APIs going back and forth in real-time and send data that cannot wait for these buffers. Misconception number three, you can only use RISC for transmitting in one direction, right? You send data over there, this is packet recovery, you're done. That's false. The protocol allows for bidirectional transmission both with and without packet recovery on both directions. The limitations are usually introduced by the implementer of the protocol. The specifications are broad enough so that each implementer has the freedom to add or remove features at will. So let's talk about the Libris Development Roadmap. How do we determine where to go next, right? So we divide it into three categories. The first one is we want to improve the reach of the library. And by improving the reach, we mean improving the adoption of the library by client applications so that users can go ahead and have it available on every device. Libris, of course, adds support for all the different specs like I showed before and all the recommendations so that all these reach features that make the protocol have more use cases are available immediately under the Libris library. The second is distribution, right? We make sure that our library compiles on every platform so that it can easily be adopted by anybody and that it makes it when possible into open source applications like FFMPEG, Libris, OBS, etc. As a matter of fact, when running it within the video LAN servers, it compiles in all 21 different architectures that are predefined in their CI. So we're pretty confident that if somebody wants to use it, they can. In the distribution aspect, we also have it on the major distros now available in Debian, OpenBSD, etc. And the third aspect of how to determine what the roadmap is is we do timely enhancements and timely bug fixes very quickly when they come about. So on the feature set, I think that the most important addition recently that allows the application to be used into this broadcast market like one too many, the media service scenario is the EAPSRP6A authentication protocol. It was introduced in 2022 and what it allows you to do is instead of the normal model where you have a pre-shared key that you have to share among two endpoints which makes it very insecure because if that communication of that key for the encryption gets compromised, your entire network is compromised now. This protocol allows you to do a username and password, a unique username and password for each of the connected clients and part of the protocol, doing that username and password exchange which is different for them, includes the negotiation and the exchange of the pre-shared key. So there's no risk anymore of that pre-shared key to ever be compromised. Other features that allow the broader adoption is that we're working on a one-way satellite application, we're working on multicast discovery and a few other things. So third aspect, the distribution. Many FOSS projects already have Libreps compiled by default or have it as an option. If you know of additional projects or if you know, please drop me a line, I'd like to keep a database of which projects are actually already included in it, if possible. Ritz is also a part of my own day-to-day operations which gives us the advantage of finding the bugs before they are found in the wild and we fix them very quickly. OK. So performance enhancements over the last few years, we now have the ability to automatically configure based on the network conditions. The Libreps library does an RTT with a new packet that was released, the Echo packet, 10 times per second. What that does is it lets us measure, with a UDP, you know, ping, not a regular ping, the network conditions between the two endpoints. We know the inter-packet spacing, the variance, mid and max, we know the latency, we know all these things and with those values, with those parameters, and if you look at the default configuration, the library will auto-adjust its buffer to the perfect buffer for that link without you having to guess or know anything about the network. It will also adjust the initial buffer, the reordering buffer based on your jitter on the network. Your inter-packet spacing jitter, gaps in maximum jitter, and make sure your reorder buffer is at least that much. We've added, you know, because we've done these very large improvements, we've realized we need better metrics, so we've added support for Prometheus and other things straight out of the library, so that you can actually grab that and, you know, plug it into third-party tools and immediately create your dashboard that gives you the proper visibility in the connections. And, you know, last release was just a couple of months ago. So the top priorities for 2024 for the development roadmap is we want to add support for DTLS encryption and authentication. We want to fully add support for the new advanced profile that adds, you know, the new header ID with the special payloads. And we want to try to see if we can get back support of the library into VLC 3.0. So the goal of the original project, like we mentioned before, was an interoperable standard for this type of transmission. There were, you know, half a dozen or a dozen different methods or there still are of doing UDP with packet recovery, each vendor specific, et cetera, et cetera. Our goal was to create an interoperable standard with multiple implementations, and I think we've achieved that at this point, at least at the higher broadcast level and tier one, tier two companies and a lot of the open source projects that support REST. They all talk to each other, even if it's not the same implementation. So now to part two, right? Let's look at REST as a live streaming platform, right? And particularly we want to look at a model that does N2S. How do you use REST and Libris in particular to do an N2N streaming chain, like the one we're doing here, for example, or, you know, any one-to-many scenario, right? Lots of viewers. So let's diagram, you know, a simple scenario here. We have three components, sources, the sender, which is a REST device, and many receivers on the bottom, and the box here on the bottom, you know, symbolizes a single one of those receivers. So we see the logos up there for FFMPEG, BLC, and Open Broadcast Studio. That could be also G-streamer, any source, any encoder, it doesn't matter. Somebody that has the ability to generate compressed or uncompressed video stream, right? Well, we need a binary stream of some kind pushed to the library. Libris in particular doesn't care about what the payload is. You can push anything in the payload, we'll deliver that to the other side, even though the spec for simple profile and main profile say that you're transmitting MPEG-TS, the library doesn't look at the payload or restrict it in any way. Okay. So the source is sending a UDP, or RTP media stream into the input. We buffer it so that we have it available for retransmission, and the minute the buffer is full, we start listening on, we put the sender in what we call listening mode. It opens a UDP port and start listening for receivers that want that stream, right? So the minute our receiver wants to connect to us, then the handshake happens. I'm obviously oversimplifying the process of the handshake that all happens. The SRP68 protocol is quite complex. It would take a talk just to go through the details of that handshake and everything that happens. So this is only symbolic. The handshake happens. The username is sent to us, and we check for that username within our database of username and passwords. It's not really a data-major password, but a password hashes to keep everything safe. If the authentication succeeds, then we send as part of the SRP68 protocol the pre-shared key so that the receiver can decrypt the data now. Once the data is decrypted, that's it. We have an end-to-end transmission from source to hundreds of destinations with just the risk protocol in between. So with proper planning and setting everything up correctly, you can have a 300 millisecond glass-to-glass, one to hundreds of listeners. You need a good network. Like I said, the latency is more dependent upon the RTT between the endpoints than anything else. I mentioned 300 milliseconds because in our large-scale deployments, we've done this anywhere within the U.S. with 300 milliseconds glass-to-glass. When you have to expand it and have users that are across the ocean or with crappy networks or Wi-Fi, the latency will auto-adjust. The protocol will auto-adjust. For those players, suddenly they get 500 milliseconds. We notice as a rule of thumb that somebody in Wi-Fi gets a penalty of another 200 milliseconds automatically. So how do you do this from a practical point of view? The LibreSploracle includes some command-line utilities that allows you to send, receive, and relay. The RISC2RISC is the one... If you want to do a relay application one-to-many, this is the ideal scenario. You can also do it with a RISC sender, to be honest, but the RISC2RISC is effective because it acts as a relay, doesn't encrypt or decrypt, doesn't do anything, but receives data and sends data both in the RISC format. You can put this in a CDN, your data sender anywhere, and you configure in the RISC2RISC a listener with authentication, and then you put your stream from anywhere, your source, like from here, to that endpoint. Then you configure the other end, the one that's going to send to the older viewers with a database of user-oriented passwords, and now you have the full authentication. It adds no additional latency in that process. It's only the latency that you decide to put as far as buffering. As far as quality and quantity, the sweet spot seems to be between 3 and 5 megabits per second, resolution 720p or 1080p, whatever code you're using gives you better or less quality, and that seems to traverse all the different VPNs, corporate networks, et cetera, without any issues. Quantity, the RISC2RISC can handle 100 simultaneous connections, and the number seems low, but because of the threading model and the fact that it has to do retransmissions, after that the retransmissions get compromised. The way you scale is that you can instantiate multiple instances of the same RISC2RISC application within the same machine, and in our case, we have 1500 simultaneous viewers going off of this type of transmissions 24-7. So the RISC password utility is also a command line utility available on the project that allows you to create the username and password combination hashes, just like the HD password file in Apache has a similar format, that's why we created it this way. You run the utility, put a username and password and that outputs this username with a hash, and then you append that to a file, and then the sender can grab that file and use it as an authentication database. In the case you want to scale that to a much higher level, you integrate directly with the library and you use the library callbacks to do the authentication yourself against your own databases, and you can scale that to thousands of users. The command line sender is a typical scenario of what I put in the diagram, what I was using in the diagram, you put the input any type of UDP stream, output you encrypt it, and then the output URL, if you look at RISC, is in your column, column, you add 127, you add the add, just like you do typically for FFMpeg or VLC or that type of stuff, when you want to listen instead of send, and it creates a listening on that port, and that's all you would need to do to create a sender and use the sender as a really, as well, just for one stream. On the receiver side, you want a player, for example, that you can put the username and password, right? You put the RISC in FFMpeg as the input, RISC, column, forward, slash, forward, slash, et cetera, or VLC, or any one of your choice. In our case, we did a custom VLC application inside of Raspberry Pi where we were doing this 1500 at the same time. There were Raspberry Pi's running VLC 3.0 inside with a lib-RISC implementation inside. The transmission of the secret in this case, which is a password for the username and password, should be handled in the same way you share passwords now for any account outside the scope of the protocol, and that's it. Then it becomes very simple to create a large-scale network with this. So the summary is the key feature for this is this new type of authentication that makes the secure implementation on a large scale, and it gives you better latency, lower latency, then the equivalent HLS or dash, with a security model that's built into the protocol. It's no longer the browser or the DRM inside the browser, everything. It's the protocol handles the entire DRM. So we have a really solid roadmap for the future. We were looking for additional contributors and people that want to help adding the next set of features. We're looking for open-source projects that want to implement the library. We'll help you put it in. And that's it. Thank you very much. Thank you. Okay, the question is, what if you're pushing your stream to Africa with a really bad connection? What is the acceptable packet loss? I'm not sure what you mean by acceptable packet loss. To me, zero is an acceptable packet loss, and the protocol is capable of achieving zero if you give it enough buffer. You give it a second buffer, and the round trip is 200 milliseconds, and you will get zero packet loss. We've done tests and we've done transmissions between Australia. I was just two weeks ago doing a demo, a transmission from Australia to Madrid. 16 cameras at 10 megabits per second each were being transmitted in real-time using RISC, and they were being used in Madrid for a production of the event. And the transmission didn't have a single packet loss, and it was all done across open internet. We used one second buffer there because the connections were relatively good, but if you go and, you know, if your transmission is really bad, just increase your latency, and the protocol will recover. We have part of our CI integration process tests that add 50% and even 75% packet loss. And you see spikes in bandwidth, but we recover every single packet if you give it enough buffer. Does it support simultaneous build rates? Does it support simultaneous build rates? Yes, we support multiplexing. In all this example, I've done just one UDP input. You can configure the library and the command lines to ingest multiple UDP inputs, give it a different ID, and then on the other side, you can demultiplex them. I assume that's what you mean by maybe having different build rates within the same stream. The camera, like, sends it on the fly according to network to the combination? Correct, yes. And one of the specifications that you saw on the recommendations was called source adaptation. It was written precisely to accommodate that scenario. What is the best case, best use, or the best practice recommendation on how to do source adaptation? Reduce the build rate, adjust the build rate based on network conditions. It's all documented in a part of a spec as well. So for non-MPEC-PS payloads, as you mentioned, is there already a mechanism like a composite trail to basically define the mapping of different payloads? Absolutely. For advanced profile, there's a GitHub repository that has the mappings already. We have a dozen or two dozen of them. I'm one of the administrators of the repository. All you need to do is go in and, you know, put an MR for whatever binary payload you want to define. All right, thank you. I have another question here. Is it also possible to multiplex and demultiplex subtitles? Is it also possible to multiplex and demultiplex subtitles? Yes. The protocol itself doesn't care what you put in. We consider each of them as a binary payload of some sort. You're the one that determines what the format of that payload is. And you have this pipe. You put multiple UDP streams. One of them is going to be your VTT payload or closed caption or whatever you want to put in with whatever format you want. We don't define or control the format of what you put in. We do to decide on multiplex and mulling. We give you the capability to give them IDs so that in the other side you can map those IDs to different outputs when it comes out. Thank you. But it means that you don't do any timing, right? In between the different streams. That's all user-side. Well, no. When you give us... The question is, that means that you don't do any timing or synchronization. On the contrary, because we are taking care of the multiplexing, when we ingest all the different UDP streams, the timing is guaranteed. The minute we receive that UDP stream, we actually, in the library, the implementation that we did, we grab the timestamp at the network card. This stream came in at this time, and then we reproduce that exact timing on the other end. We reproduce the spacing, the pacing, and the latency. We make it fixed, so that is not variable. That means that when you multiplex many things in the same tunnel, you're guaranteed they're in sync on the other side, or at least as they were when they came in. We're starting the use cases of the protocols to the more for... kind of the current adoption on endpoint devices, mobile devices, browsers. Okay, the question is, the use cases of the protocol, what is it towards more, point-to-point devices, point-to-multipoint, browsers, etc. This is the last question of our time. The original idea was to just do point-to-point transmissions. That was the original scope when we created the first version of the spec. That has changed. We achieved that, and now we went beyond that. Now we want to tackle the distribution. We want to tackle the one-to-many, the media servers. We have actually a project going on with Miss Server to add a lot of this functionality and the scalability as part of the project itself, so that we have at least one media server that already supports that in a very scalable way, where it becomes very simple for an application like VLC, or VFF Play, or Gstreamer to hook up to this media server and start the playback immediately using the Pshuoroko. Thank you very much.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 8.52, "text": " All right, good morning.", "tokens": [50364, 1057, 558, 11, 665, 2446, 13, 50790], "temperature": 0.0, "avg_logprob": -0.30218077720479763, "compression_ratio": 1.471502590673575, "no_speech_prob": 0.1428220570087433}, {"id": 1, "seek": 0, "start": 8.52, "end": 10.92, "text": " Again, I'm Sergio Amarata.", "tokens": [50790, 3764, 11, 286, 478, 45078, 2012, 289, 3274, 13, 50910], "temperature": 0.0, "avg_logprob": -0.30218077720479763, "compression_ratio": 1.471502590673575, "no_speech_prob": 0.1428220570087433}, {"id": 2, "seek": 0, "start": 10.92, "end": 14.8, "text": " I'm a board member on the RISC forum,", "tokens": [50910, 286, 478, 257, 3150, 4006, 322, 264, 497, 2343, 34, 17542, 11, 51104], "temperature": 0.0, "avg_logprob": -0.30218077720479763, "compression_ratio": 1.471502590673575, "no_speech_prob": 0.1428220570087433}, {"id": 3, "seek": 0, "start": 14.8, "end": 19.12, "text": " and an active member of the RISC committee that", "tokens": [51104, 293, 364, 4967, 4006, 295, 264, 497, 2343, 34, 7482, 300, 51320], "temperature": 0.0, "avg_logprob": -0.30218077720479763, "compression_ratio": 1.471502590673575, "no_speech_prob": 0.1428220570087433}, {"id": 4, "seek": 0, "start": 19.12, "end": 20.8, "text": " writes specs for RISC.", "tokens": [51320, 13657, 27911, 337, 497, 2343, 34, 13, 51404], "temperature": 0.0, "avg_logprob": -0.30218077720479763, "compression_ratio": 1.471502590673575, "no_speech_prob": 0.1428220570087433}, {"id": 5, "seek": 0, "start": 20.8, "end": 24.240000000000002, "text": " And I'm also the maintainer of the Librisque Open Source", "tokens": [51404, 400, 286, 478, 611, 264, 6909, 260, 295, 264, 15834, 5714, 1077, 7238, 29629, 51576], "temperature": 0.0, "avg_logprob": -0.30218077720479763, "compression_ratio": 1.471502590673575, "no_speech_prob": 0.1428220570087433}, {"id": 6, "seek": 0, "start": 24.240000000000002, "end": 25.84, "text": " project.", "tokens": [51576, 1716, 13, 51656], "temperature": 0.0, "avg_logprob": -0.30218077720479763, "compression_ratio": 1.471502590673575, "no_speech_prob": 0.1428220570087433}, {"id": 7, "seek": 0, "start": 25.84, "end": 29.52, "text": " So today, we'll be talking about how RISC can support end", "tokens": [51656, 407, 965, 11, 321, 603, 312, 1417, 466, 577, 497, 2343, 34, 393, 1406, 917, 51840], "temperature": 0.0, "avg_logprob": -0.30218077720479763, "compression_ratio": 1.471502590673575, "no_speech_prob": 0.1428220570087433}, {"id": 8, "seek": 2952, "start": 29.52, "end": 32.48, "text": " to end live streaming with packet recovery.", "tokens": [50364, 281, 917, 1621, 11791, 365, 20300, 8597, 13, 50512], "temperature": 0.0, "avg_logprob": -0.1749905224504142, "compression_ratio": 1.515695067264574, "no_speech_prob": 0.0015688921557739377}, {"id": 9, "seek": 2952, "start": 32.48, "end": 34.8, "text": " But in particular, I will explain", "tokens": [50512, 583, 294, 1729, 11, 286, 486, 2903, 50628], "temperature": 0.0, "avg_logprob": -0.1749905224504142, "compression_ratio": 1.515695067264574, "no_speech_prob": 0.0015688921557739377}, {"id": 10, "seek": 2952, "start": 34.8, "end": 38.84, "text": " how we can support this in a broadcast scenario, meaning", "tokens": [50628, 577, 321, 393, 1406, 341, 294, 257, 9975, 9005, 11, 3620, 50830], "temperature": 0.0, "avg_logprob": -0.1749905224504142, "compression_ratio": 1.515695067264574, "no_speech_prob": 0.0015688921557739377}, {"id": 11, "seek": 2952, "start": 38.84, "end": 42.56, "text": " streaming to as many users as your bandwidth can support.", "tokens": [50830, 11791, 281, 382, 867, 5022, 382, 428, 23647, 393, 1406, 13, 51016], "temperature": 0.0, "avg_logprob": -0.1749905224504142, "compression_ratio": 1.515695067264574, "no_speech_prob": 0.0015688921557739377}, {"id": 12, "seek": 2952, "start": 45.8, "end": 49.56, "text": " So we'll cover the topic in two sections.", "tokens": [51178, 407, 321, 603, 2060, 264, 4829, 294, 732, 10863, 13, 51366], "temperature": 0.0, "avg_logprob": -0.1749905224504142, "compression_ratio": 1.515695067264574, "no_speech_prob": 0.0015688921557739377}, {"id": 13, "seek": 2952, "start": 49.56, "end": 52.519999999999996, "text": " First, we'll provide a roadmap or an update", "tokens": [51366, 2386, 11, 321, 603, 2893, 257, 35738, 420, 364, 5623, 51514], "temperature": 0.0, "avg_logprob": -0.1749905224504142, "compression_ratio": 1.515695067264574, "no_speech_prob": 0.0015688921557739377}, {"id": 14, "seek": 2952, "start": 52.519999999999996, "end": 58.120000000000005, "text": " on the RISC specification and the Librisque project itself.", "tokens": [51514, 322, 264, 497, 2343, 34, 31256, 293, 264, 15834, 5714, 1077, 1716, 2564, 13, 51794], "temperature": 0.0, "avg_logprob": -0.1749905224504142, "compression_ratio": 1.515695067264574, "no_speech_prob": 0.0015688921557739377}, {"id": 15, "seek": 5812, "start": 58.12, "end": 61.519999999999996, "text": " And then we'll go to a practical application", "tokens": [50364, 400, 550, 321, 603, 352, 281, 257, 8496, 3861, 50534], "temperature": 0.0, "avg_logprob": -0.18226091361340183, "compression_ratio": 1.3870967741935485, "no_speech_prob": 0.00039075626409612596}, {"id": 16, "seek": 5812, "start": 61.519999999999996, "end": 64.64, "text": " and show you how you can do live streaming in a large scale", "tokens": [50534, 293, 855, 291, 577, 291, 393, 360, 1621, 11791, 294, 257, 2416, 4373, 50690], "temperature": 0.0, "avg_logprob": -0.18226091361340183, "compression_ratio": 1.3870967741935485, "no_speech_prob": 0.00039075626409612596}, {"id": 17, "seek": 5812, "start": 64.64, "end": 66.64, "text": " with the open source tools provided.", "tokens": [50690, 365, 264, 1269, 4009, 3873, 5649, 13, 50790], "temperature": 0.0, "avg_logprob": -0.18226091361340183, "compression_ratio": 1.3870967741935485, "no_speech_prob": 0.00039075626409612596}, {"id": 18, "seek": 5812, "start": 70.47999999999999, "end": 74.28, "text": " So on to part one, the development roadmap.", "tokens": [50982, 407, 322, 281, 644, 472, 11, 264, 3250, 35738, 13, 51172], "temperature": 0.0, "avg_logprob": -0.18226091361340183, "compression_ratio": 1.3870967741935485, "no_speech_prob": 0.00039075626409612596}, {"id": 19, "seek": 5812, "start": 74.28, "end": 78.44, "text": " The last time I gave an update at FOSDEM regarding RISC", "tokens": [51172, 440, 1036, 565, 286, 2729, 364, 5623, 412, 479, 4367, 35, 6683, 8595, 497, 2343, 34, 51380], "temperature": 0.0, "avg_logprob": -0.18226091361340183, "compression_ratio": 1.3870967741935485, "no_speech_prob": 0.00039075626409612596}, {"id": 20, "seek": 5812, "start": 78.44, "end": 84.8, "text": " was February 2020, a few days before the pandemic shutdown.", "tokens": [51380, 390, 8711, 4808, 11, 257, 1326, 1708, 949, 264, 5388, 34927, 13, 51698], "temperature": 0.0, "avg_logprob": -0.18226091361340183, "compression_ratio": 1.3870967741935485, "no_speech_prob": 0.00039075626409612596}, {"id": 21, "seek": 8480, "start": 84.8, "end": 88.16, "text": " Now, four years later, we will explore what happens", "tokens": [50364, 823, 11, 1451, 924, 1780, 11, 321, 486, 6839, 437, 2314, 50532], "temperature": 0.0, "avg_logprob": -0.2074129581451416, "compression_ratio": 1.3926701570680629, "no_speech_prob": 0.0012058739084750414}, {"id": 22, "seek": 8480, "start": 88.16, "end": 90.56, "text": " instead.", "tokens": [50532, 2602, 13, 50652], "temperature": 0.0, "avg_logprob": -0.2074129581451416, "compression_ratio": 1.3926701570680629, "no_speech_prob": 0.0012058739084750414}, {"id": 23, "seek": 8480, "start": 90.56, "end": 93.64, "text": " I guess if I have waited one more year,", "tokens": [50652, 286, 2041, 498, 286, 362, 15240, 472, 544, 1064, 11, 50806], "temperature": 0.0, "avg_logprob": -0.2074129581451416, "compression_ratio": 1.3926701570680629, "no_speech_prob": 0.0012058739084750414}, {"id": 24, "seek": 8480, "start": 93.64, "end": 96.84, "text": " I could have blamed the Thanos snap for the delay.", "tokens": [50806, 286, 727, 362, 32027, 264, 35993, 13650, 337, 264, 8577, 13, 50966], "temperature": 0.0, "avg_logprob": -0.2074129581451416, "compression_ratio": 1.3926701570680629, "no_speech_prob": 0.0012058739084750414}, {"id": 25, "seek": 8480, "start": 101.6, "end": 106.88, "text": " So let's do a brief recap of the beginning of the protocol.", "tokens": [51204, 407, 718, 311, 360, 257, 5353, 20928, 295, 264, 2863, 295, 264, 10336, 13, 51468], "temperature": 0.0, "avg_logprob": -0.2074129581451416, "compression_ratio": 1.3926701570680629, "no_speech_prob": 0.0012058739084750414}, {"id": 26, "seek": 8480, "start": 106.88, "end": 112.0, "text": " In 2017, the VSS forum created the RISC activity group", "tokens": [51468, 682, 6591, 11, 264, 691, 21929, 17542, 2942, 264, 497, 2343, 34, 5191, 1594, 51724], "temperature": 0.0, "avg_logprob": -0.2074129581451416, "compression_ratio": 1.3926701570680629, "no_speech_prob": 0.0012058739084750414}, {"id": 27, "seek": 11200, "start": 112.0, "end": 116.72, "text": " for the purpose of creating a unified interoperable protocol", "tokens": [50364, 337, 264, 4334, 295, 4084, 257, 26787, 728, 7192, 712, 10336, 50600], "temperature": 0.0, "avg_logprob": -0.15450940348885275, "compression_ratio": 1.5733333333333333, "no_speech_prob": 0.0020462495740503073}, {"id": 28, "seek": 11200, "start": 116.72, "end": 120.92, "text": " for transmission of IP data over loss in networks.", "tokens": [50600, 337, 11574, 295, 8671, 1412, 670, 4470, 294, 9590, 13, 50810], "temperature": 0.0, "avg_logprob": -0.15450940348885275, "compression_ratio": 1.5733333333333333, "no_speech_prob": 0.0020462495740503073}, {"id": 29, "seek": 11200, "start": 120.92, "end": 124.4, "text": " The requirements were that it needed", "tokens": [50810, 440, 7728, 645, 300, 309, 2978, 50984], "temperature": 0.0, "avg_logprob": -0.15450940348885275, "compression_ratio": 1.5733333333333333, "no_speech_prob": 0.0020462495740503073}, {"id": 30, "seek": 11200, "start": 124.4, "end": 127.88, "text": " to be based on the UDP protocol, and it needed", "tokens": [50984, 281, 312, 2361, 322, 264, 624, 11373, 10336, 11, 293, 309, 2978, 51158], "temperature": 0.0, "avg_logprob": -0.15450940348885275, "compression_ratio": 1.5733333333333333, "no_speech_prob": 0.0020462495740503073}, {"id": 31, "seek": 11200, "start": 127.88, "end": 132.56, "text": " to include negative acknowledgment retransmission", "tokens": [51158, 281, 4090, 3671, 15195, 10433, 23106, 599, 29797, 51392], "temperature": 0.0, "avg_logprob": -0.15450940348885275, "compression_ratio": 1.5733333333333333, "no_speech_prob": 0.0020462495740503073}, {"id": 32, "seek": 11200, "start": 132.56, "end": 133.88, "text": " requests.", "tokens": [51392, 12475, 13, 51458], "temperature": 0.0, "avg_logprob": -0.15450940348885275, "compression_ratio": 1.5733333333333333, "no_speech_prob": 0.0020462495740503073}, {"id": 33, "seek": 11200, "start": 133.88, "end": 137.8, "text": " So one year later, after a successful multi-vendor", "tokens": [51458, 407, 472, 1064, 1780, 11, 934, 257, 4406, 4825, 12, 85, 521, 284, 51654], "temperature": 0.0, "avg_logprob": -0.15450940348885275, "compression_ratio": 1.5733333333333333, "no_speech_prob": 0.0020462495740503073}, {"id": 34, "seek": 11200, "start": 137.8, "end": 141.04, "text": " interop event, the simple profile specification", "tokens": [51654, 728, 404, 2280, 11, 264, 2199, 7964, 31256, 51816], "temperature": 0.0, "avg_logprob": -0.15450940348885275, "compression_ratio": 1.5733333333333333, "no_speech_prob": 0.0020462495740503073}, {"id": 35, "seek": 14104, "start": 141.04, "end": 142.04, "text": " was published.", "tokens": [50364, 390, 6572, 13, 50414], "temperature": 0.0, "avg_logprob": -0.16902531110323393, "compression_ratio": 1.609375, "no_speech_prob": 0.003366800956428051}, {"id": 36, "seek": 14104, "start": 142.04, "end": 144.51999999999998, "text": " You can see that in the bottom.", "tokens": [50414, 509, 393, 536, 300, 294, 264, 2767, 13, 50538], "temperature": 0.0, "avg_logprob": -0.16902531110323393, "compression_ratio": 1.609375, "no_speech_prob": 0.003366800956428051}, {"id": 37, "seek": 14104, "start": 144.51999999999998, "end": 146.4, "text": " The RISC activity group then proceeded", "tokens": [50538, 440, 497, 2343, 34, 5191, 1594, 550, 39053, 50632], "temperature": 0.0, "avg_logprob": -0.16902531110323393, "compression_ratio": 1.609375, "no_speech_prob": 0.003366800956428051}, {"id": 38, "seek": 14104, "start": 146.4, "end": 150.23999999999998, "text": " to add multiplexing and encryption capabilities", "tokens": [50632, 281, 909, 3311, 2021, 278, 293, 29575, 10862, 50824], "temperature": 0.0, "avg_logprob": -0.16902531110323393, "compression_ratio": 1.609375, "no_speech_prob": 0.003366800956428051}, {"id": 39, "seek": 14104, "start": 150.23999999999998, "end": 156.39999999999998, "text": " and publish the main profile specification in early 2020.", "tokens": [50824, 293, 11374, 264, 2135, 7964, 31256, 294, 2440, 4808, 13, 51132], "temperature": 0.0, "avg_logprob": -0.16902531110323393, "compression_ratio": 1.609375, "no_speech_prob": 0.003366800956428051}, {"id": 40, "seek": 14104, "start": 156.39999999999998, "end": 160.0, "text": " It was at that time that the Libris Library Open Source Project", "tokens": [51132, 467, 390, 412, 300, 565, 300, 264, 15834, 5714, 12806, 7238, 29629, 9849, 51312], "temperature": 0.0, "avg_logprob": -0.16902531110323393, "compression_ratio": 1.609375, "no_speech_prob": 0.003366800956428051}, {"id": 41, "seek": 14104, "start": 160.0, "end": 161.95999999999998, "text": " first was published.", "tokens": [51312, 700, 390, 6572, 13, 51410], "temperature": 0.0, "avg_logprob": -0.16902531110323393, "compression_ratio": 1.609375, "no_speech_prob": 0.003366800956428051}, {"id": 42, "seek": 14104, "start": 161.95999999999998, "end": 164.39999999999998, "text": " And you can refer to my talk I gave back then,", "tokens": [51410, 400, 291, 393, 2864, 281, 452, 751, 286, 2729, 646, 550, 11, 51532], "temperature": 0.0, "avg_logprob": -0.16902531110323393, "compression_ratio": 1.609375, "no_speech_prob": 0.003366800956428051}, {"id": 43, "seek": 14104, "start": 164.39999999999998, "end": 166.76, "text": " where I go into detail explanation", "tokens": [51532, 689, 286, 352, 666, 2607, 10835, 51650], "temperature": 0.0, "avg_logprob": -0.16902531110323393, "compression_ratio": 1.609375, "no_speech_prob": 0.003366800956428051}, {"id": 44, "seek": 14104, "start": 166.76, "end": 169.95999999999998, "text": " of what the simple profile does and the main profiles", "tokens": [51650, 295, 437, 264, 2199, 7964, 775, 293, 264, 2135, 23693, 51810], "temperature": 0.0, "avg_logprob": -0.16902531110323393, "compression_ratio": 1.609375, "no_speech_prob": 0.003366800956428051}, {"id": 45, "seek": 16996, "start": 170.0, "end": 173.6, "text": " and the differences, et cetera.", "tokens": [50366, 293, 264, 7300, 11, 1030, 11458, 13, 50546], "temperature": 0.0, "avg_logprob": -0.16676543398601254, "compression_ratio": 1.5023696682464456, "no_speech_prob": 0.00018502207240089774}, {"id": 46, "seek": 16996, "start": 173.6, "end": 179.36, "text": " So as you can see on this slide, the RISC activity group", "tokens": [50546, 407, 382, 291, 393, 536, 322, 341, 4137, 11, 264, 497, 2343, 34, 5191, 1594, 50834], "temperature": 0.0, "avg_logprob": -0.16676543398601254, "compression_ratio": 1.5023696682464456, "no_speech_prob": 0.00018502207240089774}, {"id": 47, "seek": 16996, "start": 179.36, "end": 182.36, "text": " has been quite busy adding features to the protocol", "tokens": [50834, 575, 668, 1596, 5856, 5127, 4122, 281, 264, 10336, 50984], "temperature": 0.0, "avg_logprob": -0.16676543398601254, "compression_ratio": 1.5023696682464456, "no_speech_prob": 0.00018502207240089774}, {"id": 48, "seek": 16996, "start": 182.36, "end": 185.24, "text": " to accommodate all possible use cases", "tokens": [50984, 281, 21410, 439, 1944, 764, 3331, 51128], "temperature": 0.0, "avg_logprob": -0.16676543398601254, "compression_ratio": 1.5023696682464456, "no_speech_prob": 0.00018502207240089774}, {"id": 49, "seek": 16996, "start": 185.24, "end": 188.36, "text": " during the last four years.", "tokens": [51128, 1830, 264, 1036, 1451, 924, 13, 51284], "temperature": 0.0, "avg_logprob": -0.16676543398601254, "compression_ratio": 1.5023696682464456, "no_speech_prob": 0.00018502207240089774}, {"id": 50, "seek": 16996, "start": 188.36, "end": 191.8, "text": " What started with the simple profile, the first release,", "tokens": [51284, 708, 1409, 365, 264, 2199, 7964, 11, 264, 700, 4374, 11, 51456], "temperature": 0.0, "avg_logprob": -0.16676543398601254, "compression_ratio": 1.5023696682464456, "no_speech_prob": 0.00018502207240089774}, {"id": 51, "seek": 16996, "start": 191.8, "end": 196.76000000000002, "text": " as the desire to add packet recovery to an RTP stream", "tokens": [51456, 382, 264, 7516, 281, 909, 20300, 8597, 281, 364, 497, 16804, 4309, 51704], "temperature": 0.0, "avg_logprob": -0.16676543398601254, "compression_ratio": 1.5023696682464456, "no_speech_prob": 0.00018502207240089774}, {"id": 52, "seek": 19676, "start": 196.76, "end": 203.07999999999998, "text": " with an MPEG-TS payload, has now turned into a reach protocol", "tokens": [50364, 365, 364, 376, 5208, 38, 12, 7327, 30918, 11, 575, 586, 3574, 666, 257, 2524, 10336, 50680], "temperature": 0.0, "avg_logprob": -0.26528735038561696, "compression_ratio": 1.4903846153846154, "no_speech_prob": 0.0009508875082246959}, {"id": 53, "seek": 19676, "start": 203.07999999999998, "end": 206.56, "text": " that will work with any payload and which includes", "tokens": [50680, 300, 486, 589, 365, 604, 30918, 293, 597, 5974, 50854], "temperature": 0.0, "avg_logprob": -0.26528735038561696, "compression_ratio": 1.4903846153846154, "no_speech_prob": 0.0009508875082246959}, {"id": 54, "seek": 19676, "start": 206.56, "end": 209.76, "text": " multiplexing, encryption, and authentication.", "tokens": [50854, 3311, 2021, 278, 11, 29575, 11, 293, 26643, 13, 51014], "temperature": 0.0, "avg_logprob": -0.26528735038561696, "compression_ratio": 1.4903846153846154, "no_speech_prob": 0.0009508875082246959}, {"id": 55, "seek": 19676, "start": 212.76, "end": 214.76, "text": " So Libris, the open source project,", "tokens": [51164, 407, 15834, 5714, 11, 264, 1269, 4009, 1716, 11, 51264], "temperature": 0.0, "avg_logprob": -0.26528735038561696, "compression_ratio": 1.4903846153846154, "no_speech_prob": 0.0009508875082246959}, {"id": 56, "seek": 19676, "start": 214.76, "end": 217.48, "text": " currently supports a simple profile and main profile.", "tokens": [51264, 4362, 9346, 257, 2199, 7964, 293, 2135, 7964, 13, 51400], "temperature": 0.0, "avg_logprob": -0.26528735038561696, "compression_ratio": 1.4903846153846154, "no_speech_prob": 0.0009508875082246959}, {"id": 57, "seek": 19676, "start": 217.48, "end": 219.84, "text": " And we're working on adding support for the advanced profile.", "tokens": [51400, 400, 321, 434, 1364, 322, 5127, 1406, 337, 264, 7339, 7964, 13, 51518], "temperature": 0.0, "avg_logprob": -0.26528735038561696, "compression_ratio": 1.4903846153846154, "no_speech_prob": 0.0009508875082246959}, {"id": 58, "seek": 21984, "start": 220.84, "end": 224.84, "text": " So in addition to the core specifications for the protocol,", "tokens": [50414, 407, 294, 4500, 281, 264, 4965, 29448, 337, 264, 10336, 11, 50614], "temperature": 0.0, "avg_logprob": -0.22542226155598957, "compression_ratio": 1.6908212560386473, "no_speech_prob": 0.00030860400875099003}, {"id": 59, "seek": 21984, "start": 224.84, "end": 228.84, "text": " the RISC activity group has also published a series", "tokens": [50614, 264, 497, 2343, 34, 5191, 1594, 575, 611, 6572, 257, 2638, 50814], "temperature": 0.0, "avg_logprob": -0.22542226155598957, "compression_ratio": 1.6908212560386473, "no_speech_prob": 0.00030860400875099003}, {"id": 60, "seek": 21984, "start": 228.84, "end": 232.84, "text": " of recommendation or best practice documents.", "tokens": [50814, 295, 11879, 420, 1151, 3124, 8512, 13, 51014], "temperature": 0.0, "avg_logprob": -0.22542226155598957, "compression_ratio": 1.6908212560386473, "no_speech_prob": 0.00030860400875099003}, {"id": 61, "seek": 21984, "start": 232.84, "end": 238.84, "text": " These are documents that extend the protocol into specific applications,", "tokens": [51014, 1981, 366, 8512, 300, 10101, 264, 10336, 666, 2685, 5821, 11, 51314], "temperature": 0.0, "avg_logprob": -0.22542226155598957, "compression_ratio": 1.6908212560386473, "no_speech_prob": 0.00030860400875099003}, {"id": 62, "seek": 21984, "start": 238.84, "end": 243.84, "text": " into specific niches, and you need to actually consider that", "tokens": [51314, 666, 2685, 25570, 279, 11, 293, 291, 643, 281, 767, 1949, 300, 51564], "temperature": 0.0, "avg_logprob": -0.22542226155598957, "compression_ratio": 1.6908212560386473, "no_speech_prob": 0.00030860400875099003}, {"id": 63, "seek": 21984, "start": 243.84, "end": 248.84, "text": " in the library that is compatible with this specification.", "tokens": [51564, 294, 264, 6405, 300, 307, 18218, 365, 341, 31256, 13, 51814], "temperature": 0.0, "avg_logprob": -0.22542226155598957, "compression_ratio": 1.6908212560386473, "no_speech_prob": 0.00030860400875099003}, {"id": 64, "seek": 24984, "start": 250.84, "end": 253.84, "text": " So the library Libris, when applicable,", "tokens": [50414, 407, 264, 6405, 15834, 5714, 11, 562, 21142, 11, 50564], "temperature": 0.0, "avg_logprob": -0.16958107267107284, "compression_ratio": 1.6764705882352942, "no_speech_prob": 0.0013021071208640933}, {"id": 65, "seek": 24984, "start": 253.84, "end": 255.84, "text": " has been made compatible with these recommendations,", "tokens": [50564, 575, 668, 1027, 18218, 365, 613, 10434, 11, 50664], "temperature": 0.0, "avg_logprob": -0.16958107267107284, "compression_ratio": 1.6764705882352942, "no_speech_prob": 0.0013021071208640933}, {"id": 66, "seek": 24984, "start": 255.84, "end": 260.84000000000003, "text": " the code synchronization, the relay, et cetera, et cetera.", "tokens": [50664, 264, 3089, 19331, 2144, 11, 264, 24214, 11, 1030, 11458, 11, 1030, 11458, 13, 50914], "temperature": 0.0, "avg_logprob": -0.16958107267107284, "compression_ratio": 1.6764705882352942, "no_speech_prob": 0.0013021071208640933}, {"id": 67, "seek": 24984, "start": 262.84000000000003, "end": 265.84000000000003, "text": " So enough history about the protocol and the specification documents,", "tokens": [51014, 407, 1547, 2503, 466, 264, 10336, 293, 264, 31256, 8512, 11, 51164], "temperature": 0.0, "avg_logprob": -0.16958107267107284, "compression_ratio": 1.6764705882352942, "no_speech_prob": 0.0013021071208640933}, {"id": 68, "seek": 24984, "start": 265.84000000000003, "end": 267.84000000000003, "text": " those are all publicly available.", "tokens": [51164, 729, 366, 439, 14843, 2435, 13, 51264], "temperature": 0.0, "avg_logprob": -0.16958107267107284, "compression_ratio": 1.6764705882352942, "no_speech_prob": 0.0013021071208640933}, {"id": 69, "seek": 24984, "start": 267.84000000000003, "end": 268.84000000000003, "text": " They're not behind any payload.", "tokens": [51264, 814, 434, 406, 2261, 604, 30918, 13, 51314], "temperature": 0.0, "avg_logprob": -0.16958107267107284, "compression_ratio": 1.6764705882352942, "no_speech_prob": 0.0013021071208640933}, {"id": 70, "seek": 24984, "start": 268.84000000000003, "end": 271.84000000000003, "text": " The VSF documents can be downloaded, the PDFs,", "tokens": [51314, 440, 25091, 37, 8512, 393, 312, 21748, 11, 264, 17752, 82, 11, 51464], "temperature": 0.0, "avg_logprob": -0.16958107267107284, "compression_ratio": 1.6764705882352942, "no_speech_prob": 0.0013021071208640933}, {"id": 71, "seek": 24984, "start": 271.84000000000003, "end": 274.84000000000003, "text": " and you can look at the specs and all the recommendations.", "tokens": [51464, 293, 291, 393, 574, 412, 264, 27911, 293, 439, 264, 10434, 13, 51614], "temperature": 0.0, "avg_logprob": -0.16958107267107284, "compression_ratio": 1.6764705882352942, "no_speech_prob": 0.0013021071208640933}, {"id": 72, "seek": 24984, "start": 275.84000000000003, "end": 278.84000000000003, "text": " Let's talk about the Libris open source project itself, right?", "tokens": [51664, 961, 311, 751, 466, 264, 15834, 5714, 1269, 4009, 1716, 2564, 11, 558, 30, 51814], "temperature": 0.0, "avg_logprob": -0.16958107267107284, "compression_ratio": 1.6764705882352942, "no_speech_prob": 0.0013021071208640933}, {"id": 73, "seek": 27984, "start": 280.84, "end": 284.84, "text": " In case you are not familiar with what RISC is,", "tokens": [50414, 682, 1389, 291, 366, 406, 4963, 365, 437, 497, 2343, 34, 307, 11, 50614], "temperature": 0.0, "avg_logprob": -0.11130184374357524, "compression_ratio": 1.5104602510460252, "no_speech_prob": 0.0012435279786586761}, {"id": 74, "seek": 27984, "start": 284.84, "end": 288.84, "text": " we can define it with just one simple sentence, like you see up there.", "tokens": [50614, 321, 393, 6964, 309, 365, 445, 472, 2199, 8174, 11, 411, 291, 536, 493, 456, 13, 50814], "temperature": 0.0, "avg_logprob": -0.11130184374357524, "compression_ratio": 1.5104602510460252, "no_speech_prob": 0.0012435279786586761}, {"id": 75, "seek": 27984, "start": 288.84, "end": 291.84, "text": " It's a new protocol for transmission of IP data", "tokens": [50814, 467, 311, 257, 777, 10336, 337, 11574, 295, 8671, 1412, 50964], "temperature": 0.0, "avg_logprob": -0.11130184374357524, "compression_ratio": 1.5104602510460252, "no_speech_prob": 0.0012435279786586761}, {"id": 76, "seek": 27984, "start": 291.84, "end": 297.84, "text": " across lossing networks using UDP with NAT-based retransmissions.", "tokens": [50964, 2108, 4470, 278, 9590, 1228, 624, 11373, 365, 14500, 12, 6032, 23106, 599, 76, 7922, 13, 51264], "temperature": 0.0, "avg_logprob": -0.11130184374357524, "compression_ratio": 1.5104602510460252, "no_speech_prob": 0.0012435279786586761}, {"id": 77, "seek": 27984, "start": 300.84, "end": 302.84, "text": " Before getting into anything else,", "tokens": [51414, 4546, 1242, 666, 1340, 1646, 11, 51514], "temperature": 0.0, "avg_logprob": -0.11130184374357524, "compression_ratio": 1.5104602510460252, "no_speech_prob": 0.0012435279786586761}, {"id": 78, "seek": 27984, "start": 302.84, "end": 305.84, "text": " I'd like to clarify the three most common misconceptions", "tokens": [51514, 286, 1116, 411, 281, 17594, 264, 1045, 881, 2689, 50012, 51664], "temperature": 0.0, "avg_logprob": -0.11130184374357524, "compression_ratio": 1.5104602510460252, "no_speech_prob": 0.0012435279786586761}, {"id": 79, "seek": 27984, "start": 305.84, "end": 308.84, "text": " people have about the RISC protocol.", "tokens": [51664, 561, 362, 466, 264, 497, 2343, 34, 10336, 13, 51814], "temperature": 0.0, "avg_logprob": -0.11130184374357524, "compression_ratio": 1.5104602510460252, "no_speech_prob": 0.0012435279786586761}, {"id": 80, "seek": 30984, "start": 309.84, "end": 314.84, "text": " And this has come about in talks and conversations.", "tokens": [50364, 400, 341, 575, 808, 466, 294, 6686, 293, 7315, 13, 50614], "temperature": 0.0, "avg_logprob": -0.1970348171159333, "compression_ratio": 1.5075757575757576, "no_speech_prob": 0.0012235938338562846}, {"id": 81, "seek": 30984, "start": 314.84, "end": 319.84, "text": " People tell me, oh, well, RISC is only for MPEC-TS, false.", "tokens": [50614, 3432, 980, 385, 11, 1954, 11, 731, 11, 497, 2343, 34, 307, 787, 337, 376, 5208, 34, 12, 7327, 11, 7908, 13, 50864], "temperature": 0.0, "avg_logprob": -0.1970348171159333, "compression_ratio": 1.5075757575757576, "no_speech_prob": 0.0012235938338562846}, {"id": 82, "seek": 30984, "start": 319.84, "end": 322.84, "text": " Advanced profile includes support for any payload", "tokens": [50864, 26951, 7964, 5974, 1406, 337, 604, 30918, 51014], "temperature": 0.0, "avg_logprob": -0.1970348171159333, "compression_ratio": 1.5075757575757576, "no_speech_prob": 0.0012235938338562846}, {"id": 83, "seek": 30984, "start": 322.84, "end": 326.84, "text": " with clearly identified payload types in the header now.", "tokens": [51014, 365, 4448, 9234, 30918, 3467, 294, 264, 23117, 586, 13, 51214], "temperature": 0.0, "avg_logprob": -0.1970348171159333, "compression_ratio": 1.5075757575757576, "no_speech_prob": 0.0012235938338562846}, {"id": 84, "seek": 30984, "start": 326.84, "end": 330.84, "text": " There's even an registration with support binary payloads, et cetera.", "tokens": [51214, 821, 311, 754, 364, 16847, 365, 1406, 17434, 30918, 82, 11, 1030, 11458, 13, 51414], "temperature": 0.0, "avg_logprob": -0.1970348171159333, "compression_ratio": 1.5075757575757576, "no_speech_prob": 0.0012235938338562846}, {"id": 85, "seek": 30984, "start": 331.84, "end": 334.84, "text": " And misconception number two, you need a large buffer", "tokens": [51464, 400, 41350, 1230, 732, 11, 291, 643, 257, 2416, 21762, 51614], "temperature": 0.0, "avg_logprob": -0.1970348171159333, "compression_ratio": 1.5075757575757576, "no_speech_prob": 0.0012235938338562846}, {"id": 86, "seek": 30984, "start": 334.84, "end": 338.84, "text": " and therefore latency is large, a second or more, right?", "tokens": [51614, 293, 4412, 27043, 307, 2416, 11, 257, 1150, 420, 544, 11, 558, 30, 51814], "temperature": 0.0, "avg_logprob": -0.1970348171159333, "compression_ratio": 1.5075757575757576, "no_speech_prob": 0.0012235938338562846}, {"id": 87, "seek": 33884, "start": 338.84, "end": 341.84, "text": " In order for you to use RISC, false.", "tokens": [50364, 682, 1668, 337, 291, 281, 764, 497, 2343, 34, 11, 7908, 13, 50514], "temperature": 0.0, "avg_logprob": -0.08353704452514649, "compression_ratio": 1.5775862068965518, "no_speech_prob": 0.0004301616863813251}, {"id": 88, "seek": 33884, "start": 341.84, "end": 345.84, "text": " You really need two to six times the round trip time,", "tokens": [50514, 509, 534, 643, 732, 281, 2309, 1413, 264, 3098, 4931, 565, 11, 50714], "temperature": 0.0, "avg_logprob": -0.08353704452514649, "compression_ratio": 1.5775862068965518, "no_speech_prob": 0.0004301616863813251}, {"id": 89, "seek": 33884, "start": 345.84, "end": 347.84, "text": " the RTT, between the two endpoints", "tokens": [50714, 264, 21797, 51, 11, 1296, 264, 732, 917, 20552, 50814], "temperature": 0.0, "avg_logprob": -0.08353704452514649, "compression_ratio": 1.5775862068965518, "no_speech_prob": 0.0004301616863813251}, {"id": 90, "seek": 33884, "start": 347.84, "end": 350.84, "text": " you're trying to send the data through.", "tokens": [50814, 291, 434, 1382, 281, 2845, 264, 1412, 807, 13, 50964], "temperature": 0.0, "avg_logprob": -0.08353704452514649, "compression_ratio": 1.5775862068965518, "no_speech_prob": 0.0004301616863813251}, {"id": 91, "seek": 33884, "start": 350.84, "end": 355.84, "text": " So the shorter the RTT, the total buffer required will also be shorter", "tokens": [50964, 407, 264, 11639, 264, 21797, 51, 11, 264, 3217, 21762, 4739, 486, 611, 312, 11639, 51214], "temperature": 0.0, "avg_logprob": -0.08353704452514649, "compression_ratio": 1.5775862068965518, "no_speech_prob": 0.0004301616863813251}, {"id": 92, "seek": 33884, "start": 355.84, "end": 360.84, "text": " and you can talk about 10 milliseconds, 20 millisecond total latency.", "tokens": [51214, 293, 291, 393, 751, 466, 1266, 34184, 11, 945, 27940, 18882, 3217, 27043, 13, 51464], "temperature": 0.0, "avg_logprob": -0.08353704452514649, "compression_ratio": 1.5775862068965518, "no_speech_prob": 0.0004301616863813251}, {"id": 93, "seek": 33884, "start": 360.84, "end": 363.84, "text": " It's just depending on what network you're deploying it in.", "tokens": [51464, 467, 311, 445, 5413, 322, 437, 3209, 291, 434, 34198, 309, 294, 13, 51614], "temperature": 0.0, "avg_logprob": -0.08353704452514649, "compression_ratio": 1.5775862068965518, "no_speech_prob": 0.0004301616863813251}, {"id": 94, "seek": 36384, "start": 364.84, "end": 367.84, "text": " In addition, and this is a major misconception", "tokens": [50414, 682, 4500, 11, 293, 341, 307, 257, 2563, 41350, 50564], "temperature": 0.0, "avg_logprob": -0.0727975192822908, "compression_ratio": 1.6045454545454545, "no_speech_prob": 0.00031973543809726834}, {"id": 95, "seek": 36384, "start": 367.84, "end": 373.84, "text": " on that second point, RISC also supports real-time data channels", "tokens": [50564, 322, 300, 1150, 935, 11, 497, 2343, 34, 611, 9346, 957, 12, 3766, 1412, 9235, 50864], "temperature": 0.0, "avg_logprob": -0.0727975192822908, "compression_ratio": 1.6045454545454545, "no_speech_prob": 0.00031973543809726834}, {"id": 96, "seek": 36384, "start": 373.84, "end": 378.84, "text": " with no added latency, with lossy channels", "tokens": [50864, 365, 572, 3869, 27043, 11, 365, 4470, 88, 9235, 51114], "temperature": 0.0, "avg_logprob": -0.0727975192822908, "compression_ratio": 1.6045454545454545, "no_speech_prob": 0.00031973543809726834}, {"id": 97, "seek": 36384, "start": 378.84, "end": 382.84, "text": " that you can have APIs going back and forth in real-time", "tokens": [51114, 300, 291, 393, 362, 21445, 516, 646, 293, 5220, 294, 957, 12, 3766, 51314], "temperature": 0.0, "avg_logprob": -0.0727975192822908, "compression_ratio": 1.6045454545454545, "no_speech_prob": 0.00031973543809726834}, {"id": 98, "seek": 36384, "start": 382.84, "end": 385.84, "text": " and send data that cannot wait for these buffers.", "tokens": [51314, 293, 2845, 1412, 300, 2644, 1699, 337, 613, 9204, 433, 13, 51464], "temperature": 0.0, "avg_logprob": -0.0727975192822908, "compression_ratio": 1.6045454545454545, "no_speech_prob": 0.00031973543809726834}, {"id": 99, "seek": 36384, "start": 385.84, "end": 389.84, "text": " Misconception number three, you can only use RISC", "tokens": [51464, 23240, 1671, 7311, 1230, 1045, 11, 291, 393, 787, 764, 497, 2343, 34, 51664], "temperature": 0.0, "avg_logprob": -0.0727975192822908, "compression_ratio": 1.6045454545454545, "no_speech_prob": 0.00031973543809726834}, {"id": 100, "seek": 36384, "start": 389.84, "end": 391.84, "text": " for transmitting in one direction, right?", "tokens": [51664, 337, 7715, 2414, 294, 472, 3513, 11, 558, 30, 51764], "temperature": 0.0, "avg_logprob": -0.0727975192822908, "compression_ratio": 1.6045454545454545, "no_speech_prob": 0.00031973543809726834}, {"id": 101, "seek": 39184, "start": 391.84, "end": 394.84, "text": " You send data over there, this is packet recovery, you're done.", "tokens": [50364, 509, 2845, 1412, 670, 456, 11, 341, 307, 20300, 8597, 11, 291, 434, 1096, 13, 50514], "temperature": 0.0, "avg_logprob": -0.08463113386552412, "compression_ratio": 1.7031963470319635, "no_speech_prob": 0.0016987393610179424}, {"id": 102, "seek": 39184, "start": 394.84, "end": 395.84, "text": " That's false.", "tokens": [50514, 663, 311, 7908, 13, 50564], "temperature": 0.0, "avg_logprob": -0.08463113386552412, "compression_ratio": 1.7031963470319635, "no_speech_prob": 0.0016987393610179424}, {"id": 103, "seek": 39184, "start": 395.84, "end": 398.84, "text": " The protocol allows for bidirectional transmission", "tokens": [50564, 440, 10336, 4045, 337, 12957, 621, 41048, 11574, 50714], "temperature": 0.0, "avg_logprob": -0.08463113386552412, "compression_ratio": 1.7031963470319635, "no_speech_prob": 0.0016987393610179424}, {"id": 104, "seek": 39184, "start": 398.84, "end": 401.84, "text": " both with and without packet recovery on both directions.", "tokens": [50714, 1293, 365, 293, 1553, 20300, 8597, 322, 1293, 11095, 13, 50864], "temperature": 0.0, "avg_logprob": -0.08463113386552412, "compression_ratio": 1.7031963470319635, "no_speech_prob": 0.0016987393610179424}, {"id": 105, "seek": 39184, "start": 401.84, "end": 404.84, "text": " The limitations are usually introduced", "tokens": [50864, 440, 15705, 366, 2673, 7268, 51014], "temperature": 0.0, "avg_logprob": -0.08463113386552412, "compression_ratio": 1.7031963470319635, "no_speech_prob": 0.0016987393610179424}, {"id": 106, "seek": 39184, "start": 404.84, "end": 406.84, "text": " by the implementer of the protocol.", "tokens": [51014, 538, 264, 4445, 260, 295, 264, 10336, 13, 51114], "temperature": 0.0, "avg_logprob": -0.08463113386552412, "compression_ratio": 1.7031963470319635, "no_speech_prob": 0.0016987393610179424}, {"id": 107, "seek": 39184, "start": 406.84, "end": 409.84, "text": " The specifications are broad enough", "tokens": [51114, 440, 29448, 366, 4152, 1547, 51264], "temperature": 0.0, "avg_logprob": -0.08463113386552412, "compression_ratio": 1.7031963470319635, "no_speech_prob": 0.0016987393610179424}, {"id": 108, "seek": 39184, "start": 409.84, "end": 413.84, "text": " so that each implementer has the freedom", "tokens": [51264, 370, 300, 1184, 4445, 260, 575, 264, 5645, 51464], "temperature": 0.0, "avg_logprob": -0.08463113386552412, "compression_ratio": 1.7031963470319635, "no_speech_prob": 0.0016987393610179424}, {"id": 109, "seek": 39184, "start": 413.84, "end": 416.84, "text": " to add or remove features at will.", "tokens": [51464, 281, 909, 420, 4159, 4122, 412, 486, 13, 51614], "temperature": 0.0, "avg_logprob": -0.08463113386552412, "compression_ratio": 1.7031963470319635, "no_speech_prob": 0.0016987393610179424}, {"id": 110, "seek": 41684, "start": 417.84, "end": 421.84, "text": " So let's talk about the Libris Development Roadmap.", "tokens": [50414, 407, 718, 311, 751, 466, 264, 15834, 5714, 15041, 11507, 24223, 13, 50614], "temperature": 0.0, "avg_logprob": -0.1164664720234118, "compression_ratio": 1.53125, "no_speech_prob": 0.00030525680631399155}, {"id": 111, "seek": 41684, "start": 421.84, "end": 424.84, "text": " How do we determine where to go next, right?", "tokens": [50614, 1012, 360, 321, 6997, 689, 281, 352, 958, 11, 558, 30, 50764], "temperature": 0.0, "avg_logprob": -0.1164664720234118, "compression_ratio": 1.53125, "no_speech_prob": 0.00030525680631399155}, {"id": 112, "seek": 41684, "start": 424.84, "end": 427.84, "text": " So we divide it into three categories.", "tokens": [50764, 407, 321, 9845, 309, 666, 1045, 10479, 13, 50914], "temperature": 0.0, "avg_logprob": -0.1164664720234118, "compression_ratio": 1.53125, "no_speech_prob": 0.00030525680631399155}, {"id": 113, "seek": 41684, "start": 427.84, "end": 433.84, "text": " The first one is we want to improve the reach of the library.", "tokens": [50914, 440, 700, 472, 307, 321, 528, 281, 3470, 264, 2524, 295, 264, 6405, 13, 51214], "temperature": 0.0, "avg_logprob": -0.1164664720234118, "compression_ratio": 1.53125, "no_speech_prob": 0.00030525680631399155}, {"id": 114, "seek": 41684, "start": 433.84, "end": 440.84, "text": " And by improving the reach, we mean improving the adoption", "tokens": [51214, 400, 538, 11470, 264, 2524, 11, 321, 914, 11470, 264, 19215, 51564], "temperature": 0.0, "avg_logprob": -0.1164664720234118, "compression_ratio": 1.53125, "no_speech_prob": 0.00030525680631399155}, {"id": 115, "seek": 41684, "start": 440.84, "end": 444.84, "text": " of the library by client applications", "tokens": [51564, 295, 264, 6405, 538, 6423, 5821, 51764], "temperature": 0.0, "avg_logprob": -0.1164664720234118, "compression_ratio": 1.53125, "no_speech_prob": 0.00030525680631399155}, {"id": 116, "seek": 44484, "start": 444.84, "end": 449.84, "text": " so that users can go ahead and have it available on every device.", "tokens": [50364, 370, 300, 5022, 393, 352, 2286, 293, 362, 309, 2435, 322, 633, 4302, 13, 50614], "temperature": 0.0, "avg_logprob": -0.06237073654824115, "compression_ratio": 1.6485355648535565, "no_speech_prob": 0.0026291676331311464}, {"id": 117, "seek": 44484, "start": 449.84, "end": 454.84, "text": " Libris, of course, adds support for all the different specs", "tokens": [50614, 15834, 5714, 11, 295, 1164, 11, 10860, 1406, 337, 439, 264, 819, 27911, 50864], "temperature": 0.0, "avg_logprob": -0.06237073654824115, "compression_ratio": 1.6485355648535565, "no_speech_prob": 0.0026291676331311464}, {"id": 118, "seek": 44484, "start": 454.84, "end": 458.84, "text": " like I showed before and all the recommendations", "tokens": [50864, 411, 286, 4712, 949, 293, 439, 264, 10434, 51064], "temperature": 0.0, "avg_logprob": -0.06237073654824115, "compression_ratio": 1.6485355648535565, "no_speech_prob": 0.0026291676331311464}, {"id": 119, "seek": 44484, "start": 458.84, "end": 461.84, "text": " so that all these reach features that make the protocol", "tokens": [51064, 370, 300, 439, 613, 2524, 4122, 300, 652, 264, 10336, 51214], "temperature": 0.0, "avg_logprob": -0.06237073654824115, "compression_ratio": 1.6485355648535565, "no_speech_prob": 0.0026291676331311464}, {"id": 120, "seek": 44484, "start": 461.84, "end": 464.84, "text": " have more use cases are available immediately", "tokens": [51214, 362, 544, 764, 3331, 366, 2435, 4258, 51364], "temperature": 0.0, "avg_logprob": -0.06237073654824115, "compression_ratio": 1.6485355648535565, "no_speech_prob": 0.0026291676331311464}, {"id": 121, "seek": 44484, "start": 464.84, "end": 467.84, "text": " under the Libris library.", "tokens": [51364, 833, 264, 15834, 5714, 6405, 13, 51514], "temperature": 0.0, "avg_logprob": -0.06237073654824115, "compression_ratio": 1.6485355648535565, "no_speech_prob": 0.0026291676331311464}, {"id": 122, "seek": 44484, "start": 467.84, "end": 469.84, "text": " The second is distribution, right?", "tokens": [51514, 440, 1150, 307, 7316, 11, 558, 30, 51614], "temperature": 0.0, "avg_logprob": -0.06237073654824115, "compression_ratio": 1.6485355648535565, "no_speech_prob": 0.0026291676331311464}, {"id": 123, "seek": 44484, "start": 469.84, "end": 473.84, "text": " We make sure that our library compiles on every platform", "tokens": [51614, 492, 652, 988, 300, 527, 6405, 715, 4680, 322, 633, 3663, 51814], "temperature": 0.0, "avg_logprob": -0.06237073654824115, "compression_ratio": 1.6485355648535565, "no_speech_prob": 0.0026291676331311464}, {"id": 124, "seek": 47384, "start": 473.84, "end": 476.84, "text": " so that it can easily be adopted by anybody", "tokens": [50364, 370, 300, 309, 393, 3612, 312, 12175, 538, 4472, 50514], "temperature": 0.0, "avg_logprob": -0.1497398070347162, "compression_ratio": 1.3970588235294117, "no_speech_prob": 0.0026687071658670902}, {"id": 125, "seek": 47384, "start": 476.84, "end": 479.84, "text": " and that it makes it when possible", "tokens": [50514, 293, 300, 309, 1669, 309, 562, 1944, 50664], "temperature": 0.0, "avg_logprob": -0.1497398070347162, "compression_ratio": 1.3970588235294117, "no_speech_prob": 0.0026687071658670902}, {"id": 126, "seek": 47384, "start": 479.84, "end": 487.84, "text": " into open source applications like FFMPEG, Libris, OBS, etc.", "tokens": [50664, 666, 1269, 4009, 5821, 411, 479, 37, 44, 5208, 38, 11, 15834, 5714, 11, 422, 8176, 11, 5183, 13, 51064], "temperature": 0.0, "avg_logprob": -0.1497398070347162, "compression_ratio": 1.3970588235294117, "no_speech_prob": 0.0026687071658670902}, {"id": 127, "seek": 47384, "start": 487.84, "end": 494.84, "text": " As a matter of fact, when running it within the video LAN servers,", "tokens": [51064, 1018, 257, 1871, 295, 1186, 11, 562, 2614, 309, 1951, 264, 960, 37387, 15909, 11, 51414], "temperature": 0.0, "avg_logprob": -0.1497398070347162, "compression_ratio": 1.3970588235294117, "no_speech_prob": 0.0026687071658670902}, {"id": 128, "seek": 47384, "start": 494.84, "end": 497.84, "text": " it compiles in all 21 different architectures", "tokens": [51414, 309, 715, 4680, 294, 439, 5080, 819, 6331, 1303, 51564], "temperature": 0.0, "avg_logprob": -0.1497398070347162, "compression_ratio": 1.3970588235294117, "no_speech_prob": 0.0026687071658670902}, {"id": 129, "seek": 47384, "start": 497.84, "end": 500.84, "text": " that are predefined in their CI.", "tokens": [51564, 300, 366, 659, 37716, 294, 641, 37777, 13, 51714], "temperature": 0.0, "avg_logprob": -0.1497398070347162, "compression_ratio": 1.3970588235294117, "no_speech_prob": 0.0026687071658670902}, {"id": 130, "seek": 50084, "start": 500.84, "end": 504.84, "text": " So we're pretty confident that if somebody wants to use it, they can.", "tokens": [50364, 407, 321, 434, 1238, 6679, 300, 498, 2618, 2738, 281, 764, 309, 11, 436, 393, 13, 50564], "temperature": 0.0, "avg_logprob": -0.09594534705666935, "compression_ratio": 1.4906542056074767, "no_speech_prob": 0.001431323355063796}, {"id": 131, "seek": 50084, "start": 504.84, "end": 511.84, "text": " In the distribution aspect, we also have it on the major distros now", "tokens": [50564, 682, 264, 7316, 4171, 11, 321, 611, 362, 309, 322, 264, 2563, 1483, 2635, 586, 50914], "temperature": 0.0, "avg_logprob": -0.09594534705666935, "compression_ratio": 1.4906542056074767, "no_speech_prob": 0.001431323355063796}, {"id": 132, "seek": 50084, "start": 511.84, "end": 515.8399999999999, "text": " available in Debian, OpenBSD, etc.", "tokens": [50914, 2435, 294, 1346, 20196, 11, 7238, 8176, 35, 11, 5183, 13, 51114], "temperature": 0.0, "avg_logprob": -0.09594534705666935, "compression_ratio": 1.4906542056074767, "no_speech_prob": 0.001431323355063796}, {"id": 133, "seek": 50084, "start": 515.8399999999999, "end": 519.8399999999999, "text": " And the third aspect of how to determine what the roadmap is", "tokens": [51114, 400, 264, 2636, 4171, 295, 577, 281, 6997, 437, 264, 35738, 307, 51314], "temperature": 0.0, "avg_logprob": -0.09594534705666935, "compression_ratio": 1.4906542056074767, "no_speech_prob": 0.001431323355063796}, {"id": 134, "seek": 50084, "start": 519.8399999999999, "end": 525.8399999999999, "text": " is we do timely enhancements and timely bug fixes", "tokens": [51314, 307, 321, 360, 25150, 11985, 1117, 293, 25150, 7426, 32539, 51614], "temperature": 0.0, "avg_logprob": -0.09594534705666935, "compression_ratio": 1.4906542056074767, "no_speech_prob": 0.001431323355063796}, {"id": 135, "seek": 50084, "start": 525.8399999999999, "end": 529.8399999999999, "text": " very quickly when they come about.", "tokens": [51614, 588, 2661, 562, 436, 808, 466, 13, 51814], "temperature": 0.0, "avg_logprob": -0.09594534705666935, "compression_ratio": 1.4906542056074767, "no_speech_prob": 0.001431323355063796}, {"id": 136, "seek": 52984, "start": 529.84, "end": 535.84, "text": " So on the feature set, I think that the most important addition recently", "tokens": [50364, 407, 322, 264, 4111, 992, 11, 286, 519, 300, 264, 881, 1021, 4500, 3938, 50664], "temperature": 0.0, "avg_logprob": -0.1326311851034359, "compression_ratio": 1.5819672131147542, "no_speech_prob": 0.000999204465188086}, {"id": 137, "seek": 52984, "start": 535.84, "end": 539.84, "text": " that allows the application to be used into this broadcast market", "tokens": [50664, 300, 4045, 264, 3861, 281, 312, 1143, 666, 341, 9975, 2142, 50864], "temperature": 0.0, "avg_logprob": -0.1326311851034359, "compression_ratio": 1.5819672131147542, "no_speech_prob": 0.000999204465188086}, {"id": 138, "seek": 52984, "start": 539.84, "end": 541.84, "text": " like one too many, the media service scenario", "tokens": [50864, 411, 472, 886, 867, 11, 264, 3021, 2643, 9005, 50964], "temperature": 0.0, "avg_logprob": -0.1326311851034359, "compression_ratio": 1.5819672131147542, "no_speech_prob": 0.000999204465188086}, {"id": 139, "seek": 52984, "start": 541.84, "end": 546.84, "text": " is the EAPSRP6A authentication protocol.", "tokens": [50964, 307, 264, 462, 4715, 50, 49, 47, 21, 32, 26643, 10336, 13, 51214], "temperature": 0.0, "avg_logprob": -0.1326311851034359, "compression_ratio": 1.5819672131147542, "no_speech_prob": 0.000999204465188086}, {"id": 140, "seek": 52984, "start": 546.84, "end": 550.84, "text": " It was introduced in 2022 and what it allows you to do", "tokens": [51214, 467, 390, 7268, 294, 20229, 293, 437, 309, 4045, 291, 281, 360, 51414], "temperature": 0.0, "avg_logprob": -0.1326311851034359, "compression_ratio": 1.5819672131147542, "no_speech_prob": 0.000999204465188086}, {"id": 141, "seek": 52984, "start": 550.84, "end": 555.84, "text": " is instead of the normal model where you have a pre-shared key", "tokens": [51414, 307, 2602, 295, 264, 2710, 2316, 689, 291, 362, 257, 659, 12, 2716, 1642, 2141, 51664], "temperature": 0.0, "avg_logprob": -0.1326311851034359, "compression_ratio": 1.5819672131147542, "no_speech_prob": 0.000999204465188086}, {"id": 142, "seek": 52984, "start": 555.84, "end": 557.84, "text": " that you have to share among two endpoints", "tokens": [51664, 300, 291, 362, 281, 2073, 3654, 732, 917, 20552, 51764], "temperature": 0.0, "avg_logprob": -0.1326311851034359, "compression_ratio": 1.5819672131147542, "no_speech_prob": 0.000999204465188086}, {"id": 143, "seek": 55784, "start": 557.84, "end": 561.84, "text": " which makes it very insecure because if that communication of that key", "tokens": [50364, 597, 1669, 309, 588, 32215, 570, 498, 300, 6101, 295, 300, 2141, 50564], "temperature": 0.0, "avg_logprob": -0.10744159096165708, "compression_ratio": 1.853448275862069, "no_speech_prob": 0.005990621633827686}, {"id": 144, "seek": 55784, "start": 561.84, "end": 565.84, "text": " for the encryption gets compromised, your entire network is compromised now.", "tokens": [50564, 337, 264, 29575, 2170, 32463, 11, 428, 2302, 3209, 307, 32463, 586, 13, 50764], "temperature": 0.0, "avg_logprob": -0.10744159096165708, "compression_ratio": 1.853448275862069, "no_speech_prob": 0.005990621633827686}, {"id": 145, "seek": 55784, "start": 565.84, "end": 570.84, "text": " This protocol allows you to do a username and password,", "tokens": [50764, 639, 10336, 4045, 291, 281, 360, 257, 30351, 293, 11524, 11, 51014], "temperature": 0.0, "avg_logprob": -0.10744159096165708, "compression_ratio": 1.853448275862069, "no_speech_prob": 0.005990621633827686}, {"id": 146, "seek": 55784, "start": 570.84, "end": 573.84, "text": " a unique username and password for each of the connected clients", "tokens": [51014, 257, 3845, 30351, 293, 11524, 337, 1184, 295, 264, 4582, 6982, 51164], "temperature": 0.0, "avg_logprob": -0.10744159096165708, "compression_ratio": 1.853448275862069, "no_speech_prob": 0.005990621633827686}, {"id": 147, "seek": 55784, "start": 573.84, "end": 577.84, "text": " and part of the protocol, doing that username and password exchange", "tokens": [51164, 293, 644, 295, 264, 10336, 11, 884, 300, 30351, 293, 11524, 7742, 51364], "temperature": 0.0, "avg_logprob": -0.10744159096165708, "compression_ratio": 1.853448275862069, "no_speech_prob": 0.005990621633827686}, {"id": 148, "seek": 55784, "start": 577.84, "end": 580.84, "text": " which is different for them, includes the negotiation", "tokens": [51364, 597, 307, 819, 337, 552, 11, 5974, 264, 27573, 51514], "temperature": 0.0, "avg_logprob": -0.10744159096165708, "compression_ratio": 1.853448275862069, "no_speech_prob": 0.005990621633827686}, {"id": 149, "seek": 55784, "start": 580.84, "end": 582.84, "text": " and the exchange of the pre-shared key.", "tokens": [51514, 293, 264, 7742, 295, 264, 659, 12, 2716, 1642, 2141, 13, 51614], "temperature": 0.0, "avg_logprob": -0.10744159096165708, "compression_ratio": 1.853448275862069, "no_speech_prob": 0.005990621633827686}, {"id": 150, "seek": 58284, "start": 582.84, "end": 588.84, "text": " So there's no risk anymore of that pre-shared key to ever be compromised.", "tokens": [50364, 407, 456, 311, 572, 3148, 3602, 295, 300, 659, 12, 2716, 1642, 2141, 281, 1562, 312, 32463, 13, 50664], "temperature": 0.0, "avg_logprob": -0.1300412859235491, "compression_ratio": 1.5307262569832403, "no_speech_prob": 0.003644238691776991}, {"id": 151, "seek": 58284, "start": 588.84, "end": 592.84, "text": " Other features that allow the broader adoption", "tokens": [50664, 5358, 4122, 300, 2089, 264, 13227, 19215, 50864], "temperature": 0.0, "avg_logprob": -0.1300412859235491, "compression_ratio": 1.5307262569832403, "no_speech_prob": 0.003644238691776991}, {"id": 152, "seek": 58284, "start": 592.84, "end": 597.84, "text": " is that we're working on a one-way satellite application,", "tokens": [50864, 307, 300, 321, 434, 1364, 322, 257, 472, 12, 676, 16016, 3861, 11, 51114], "temperature": 0.0, "avg_logprob": -0.1300412859235491, "compression_ratio": 1.5307262569832403, "no_speech_prob": 0.003644238691776991}, {"id": 153, "seek": 58284, "start": 597.84, "end": 604.84, "text": " we're working on multicast discovery and a few other things.", "tokens": [51114, 321, 434, 1364, 322, 30608, 525, 12114, 293, 257, 1326, 661, 721, 13, 51464], "temperature": 0.0, "avg_logprob": -0.1300412859235491, "compression_ratio": 1.5307262569832403, "no_speech_prob": 0.003644238691776991}, {"id": 154, "seek": 58284, "start": 604.84, "end": 607.84, "text": " So third aspect, the distribution.", "tokens": [51464, 407, 2636, 4171, 11, 264, 7316, 13, 51614], "temperature": 0.0, "avg_logprob": -0.1300412859235491, "compression_ratio": 1.5307262569832403, "no_speech_prob": 0.003644238691776991}, {"id": 155, "seek": 60784, "start": 607.84, "end": 612.84, "text": " Many FOSS projects already have Libreps compiled by default", "tokens": [50364, 5126, 479, 35683, 4455, 1217, 362, 15834, 265, 1878, 36548, 538, 7576, 50614], "temperature": 0.0, "avg_logprob": -0.18721543480368222, "compression_ratio": 1.5223880597014925, "no_speech_prob": 0.006278778426349163}, {"id": 156, "seek": 60784, "start": 612.84, "end": 614.84, "text": " or have it as an option.", "tokens": [50614, 420, 362, 309, 382, 364, 3614, 13, 50714], "temperature": 0.0, "avg_logprob": -0.18721543480368222, "compression_ratio": 1.5223880597014925, "no_speech_prob": 0.006278778426349163}, {"id": 157, "seek": 60784, "start": 614.84, "end": 618.84, "text": " If you know of additional projects or if you know,", "tokens": [50714, 759, 291, 458, 295, 4497, 4455, 420, 498, 291, 458, 11, 50914], "temperature": 0.0, "avg_logprob": -0.18721543480368222, "compression_ratio": 1.5223880597014925, "no_speech_prob": 0.006278778426349163}, {"id": 158, "seek": 60784, "start": 618.84, "end": 622.84, "text": " please drop me a line, I'd like to keep a database", "tokens": [50914, 1767, 3270, 385, 257, 1622, 11, 286, 1116, 411, 281, 1066, 257, 8149, 51114], "temperature": 0.0, "avg_logprob": -0.18721543480368222, "compression_ratio": 1.5223880597014925, "no_speech_prob": 0.006278778426349163}, {"id": 159, "seek": 60784, "start": 622.84, "end": 627.84, "text": " of which projects are actually already included in it, if possible.", "tokens": [51114, 295, 597, 4455, 366, 767, 1217, 5556, 294, 309, 11, 498, 1944, 13, 51364], "temperature": 0.0, "avg_logprob": -0.18721543480368222, "compression_ratio": 1.5223880597014925, "no_speech_prob": 0.006278778426349163}, {"id": 160, "seek": 60784, "start": 627.84, "end": 633.84, "text": " Ritz is also a part of my own day-to-day operations", "tokens": [51364, 497, 6862, 307, 611, 257, 644, 295, 452, 1065, 786, 12, 1353, 12, 810, 7705, 51664], "temperature": 0.0, "avg_logprob": -0.18721543480368222, "compression_ratio": 1.5223880597014925, "no_speech_prob": 0.006278778426349163}, {"id": 161, "seek": 63384, "start": 633.84, "end": 636.84, "text": " which gives us the advantage of finding the bugs", "tokens": [50364, 597, 2709, 505, 264, 5002, 295, 5006, 264, 15120, 50514], "temperature": 0.0, "avg_logprob": -0.1253450455204133, "compression_ratio": 1.5, "no_speech_prob": 0.002887271810323}, {"id": 162, "seek": 63384, "start": 636.84, "end": 642.84, "text": " before they are found in the wild and we fix them very quickly.", "tokens": [50514, 949, 436, 366, 1352, 294, 264, 4868, 293, 321, 3191, 552, 588, 2661, 13, 50814], "temperature": 0.0, "avg_logprob": -0.1253450455204133, "compression_ratio": 1.5, "no_speech_prob": 0.002887271810323}, {"id": 163, "seek": 63384, "start": 642.84, "end": 646.84, "text": " OK.", "tokens": [50814, 2264, 13, 51014], "temperature": 0.0, "avg_logprob": -0.1253450455204133, "compression_ratio": 1.5, "no_speech_prob": 0.002887271810323}, {"id": 164, "seek": 63384, "start": 646.84, "end": 650.84, "text": " So performance enhancements over the last few years,", "tokens": [51014, 407, 3389, 11985, 1117, 670, 264, 1036, 1326, 924, 11, 51214], "temperature": 0.0, "avg_logprob": -0.1253450455204133, "compression_ratio": 1.5, "no_speech_prob": 0.002887271810323}, {"id": 165, "seek": 63384, "start": 650.84, "end": 653.84, "text": " we now have the ability to automatically configure", "tokens": [51214, 321, 586, 362, 264, 3485, 281, 6772, 22162, 51364], "temperature": 0.0, "avg_logprob": -0.1253450455204133, "compression_ratio": 1.5, "no_speech_prob": 0.002887271810323}, {"id": 166, "seek": 63384, "start": 653.84, "end": 655.84, "text": " based on the network conditions.", "tokens": [51364, 2361, 322, 264, 3209, 4487, 13, 51464], "temperature": 0.0, "avg_logprob": -0.1253450455204133, "compression_ratio": 1.5, "no_speech_prob": 0.002887271810323}, {"id": 167, "seek": 63384, "start": 655.84, "end": 659.84, "text": " The Libreps library does an RTT with a new packet", "tokens": [51464, 440, 15834, 265, 1878, 6405, 775, 364, 21797, 51, 365, 257, 777, 20300, 51664], "temperature": 0.0, "avg_logprob": -0.1253450455204133, "compression_ratio": 1.5, "no_speech_prob": 0.002887271810323}, {"id": 168, "seek": 63384, "start": 659.84, "end": 662.84, "text": " that was released, the Echo packet, 10 times per second.", "tokens": [51664, 300, 390, 4736, 11, 264, 31887, 20300, 11, 1266, 1413, 680, 1150, 13, 51814], "temperature": 0.0, "avg_logprob": -0.1253450455204133, "compression_ratio": 1.5, "no_speech_prob": 0.002887271810323}, {"id": 169, "seek": 66284, "start": 662.84, "end": 666.84, "text": " What that does is it lets us measure, with a UDP,", "tokens": [50364, 708, 300, 775, 307, 309, 6653, 505, 3481, 11, 365, 257, 624, 11373, 11, 50564], "temperature": 0.0, "avg_logprob": -0.15399318458759678, "compression_ratio": 1.680327868852459, "no_speech_prob": 0.007660986855626106}, {"id": 170, "seek": 66284, "start": 666.84, "end": 670.84, "text": " you know, ping, not a regular ping, the network conditions", "tokens": [50564, 291, 458, 11, 26151, 11, 406, 257, 3890, 26151, 11, 264, 3209, 4487, 50764], "temperature": 0.0, "avg_logprob": -0.15399318458759678, "compression_ratio": 1.680327868852459, "no_speech_prob": 0.007660986855626106}, {"id": 171, "seek": 66284, "start": 670.84, "end": 672.84, "text": " between the two endpoints.", "tokens": [50764, 1296, 264, 732, 917, 20552, 13, 50864], "temperature": 0.0, "avg_logprob": -0.15399318458759678, "compression_ratio": 1.680327868852459, "no_speech_prob": 0.007660986855626106}, {"id": 172, "seek": 66284, "start": 672.84, "end": 676.84, "text": " We know the inter-packet spacing, the variance, mid and max,", "tokens": [50864, 492, 458, 264, 728, 12, 9539, 302, 27739, 11, 264, 21977, 11, 2062, 293, 11469, 11, 51064], "temperature": 0.0, "avg_logprob": -0.15399318458759678, "compression_ratio": 1.680327868852459, "no_speech_prob": 0.007660986855626106}, {"id": 173, "seek": 66284, "start": 676.84, "end": 678.84, "text": " we know the latency, we know all these things", "tokens": [51064, 321, 458, 264, 27043, 11, 321, 458, 439, 613, 721, 51164], "temperature": 0.0, "avg_logprob": -0.15399318458759678, "compression_ratio": 1.680327868852459, "no_speech_prob": 0.007660986855626106}, {"id": 174, "seek": 66284, "start": 678.84, "end": 681.84, "text": " and with those values, with those parameters,", "tokens": [51164, 293, 365, 729, 4190, 11, 365, 729, 9834, 11, 51314], "temperature": 0.0, "avg_logprob": -0.15399318458759678, "compression_ratio": 1.680327868852459, "no_speech_prob": 0.007660986855626106}, {"id": 175, "seek": 66284, "start": 681.84, "end": 684.84, "text": " and if you look at the default configuration,", "tokens": [51314, 293, 498, 291, 574, 412, 264, 7576, 11694, 11, 51464], "temperature": 0.0, "avg_logprob": -0.15399318458759678, "compression_ratio": 1.680327868852459, "no_speech_prob": 0.007660986855626106}, {"id": 176, "seek": 66284, "start": 684.84, "end": 687.84, "text": " the library will auto-adjust its buffer", "tokens": [51464, 264, 6405, 486, 8399, 12, 345, 3424, 1080, 21762, 51614], "temperature": 0.0, "avg_logprob": -0.15399318458759678, "compression_ratio": 1.680327868852459, "no_speech_prob": 0.007660986855626106}, {"id": 177, "seek": 66284, "start": 687.84, "end": 690.84, "text": " to the perfect buffer for that link", "tokens": [51614, 281, 264, 2176, 21762, 337, 300, 2113, 51764], "temperature": 0.0, "avg_logprob": -0.15399318458759678, "compression_ratio": 1.680327868852459, "no_speech_prob": 0.007660986855626106}, {"id": 178, "seek": 69084, "start": 690.84, "end": 693.84, "text": " without you having to guess or know anything about the network.", "tokens": [50364, 1553, 291, 1419, 281, 2041, 420, 458, 1340, 466, 264, 3209, 13, 50514], "temperature": 0.0, "avg_logprob": -0.12599259807217505, "compression_ratio": 1.6953405017921146, "no_speech_prob": 0.0020168819464743137}, {"id": 179, "seek": 69084, "start": 693.84, "end": 696.84, "text": " It will also adjust the initial buffer,", "tokens": [50514, 467, 486, 611, 4369, 264, 5883, 21762, 11, 50664], "temperature": 0.0, "avg_logprob": -0.12599259807217505, "compression_ratio": 1.6953405017921146, "no_speech_prob": 0.0020168819464743137}, {"id": 180, "seek": 69084, "start": 696.84, "end": 701.84, "text": " the reordering buffer based on your jitter on the network.", "tokens": [50664, 264, 319, 765, 1794, 21762, 2361, 322, 428, 361, 3904, 322, 264, 3209, 13, 50914], "temperature": 0.0, "avg_logprob": -0.12599259807217505, "compression_ratio": 1.6953405017921146, "no_speech_prob": 0.0020168819464743137}, {"id": 181, "seek": 69084, "start": 701.84, "end": 704.84, "text": " Your inter-packet spacing jitter, gaps in maximum jitter,", "tokens": [50914, 2260, 728, 12, 9539, 302, 27739, 361, 3904, 11, 15031, 294, 6674, 361, 3904, 11, 51064], "temperature": 0.0, "avg_logprob": -0.12599259807217505, "compression_ratio": 1.6953405017921146, "no_speech_prob": 0.0020168819464743137}, {"id": 182, "seek": 69084, "start": 704.84, "end": 708.84, "text": " and make sure your reorder buffer is at least that much.", "tokens": [51064, 293, 652, 988, 428, 319, 4687, 21762, 307, 412, 1935, 300, 709, 13, 51264], "temperature": 0.0, "avg_logprob": -0.12599259807217505, "compression_ratio": 1.6953405017921146, "no_speech_prob": 0.0020168819464743137}, {"id": 183, "seek": 69084, "start": 708.84, "end": 711.84, "text": " We've added, you know, because we've done these", "tokens": [51264, 492, 600, 3869, 11, 291, 458, 11, 570, 321, 600, 1096, 613, 51414], "temperature": 0.0, "avg_logprob": -0.12599259807217505, "compression_ratio": 1.6953405017921146, "no_speech_prob": 0.0020168819464743137}, {"id": 184, "seek": 69084, "start": 711.84, "end": 715.84, "text": " very large improvements, we've realized we need better metrics,", "tokens": [51414, 588, 2416, 13797, 11, 321, 600, 5334, 321, 643, 1101, 16367, 11, 51614], "temperature": 0.0, "avg_logprob": -0.12599259807217505, "compression_ratio": 1.6953405017921146, "no_speech_prob": 0.0020168819464743137}, {"id": 185, "seek": 69084, "start": 715.84, "end": 717.84, "text": " so we've added support for Prometheus", "tokens": [51614, 370, 321, 600, 3869, 1406, 337, 2114, 649, 42209, 51714], "temperature": 0.0, "avg_logprob": -0.12599259807217505, "compression_ratio": 1.6953405017921146, "no_speech_prob": 0.0020168819464743137}, {"id": 186, "seek": 69084, "start": 717.84, "end": 719.84, "text": " and other things straight out of the library,", "tokens": [51714, 293, 661, 721, 2997, 484, 295, 264, 6405, 11, 51814], "temperature": 0.0, "avg_logprob": -0.12599259807217505, "compression_ratio": 1.6953405017921146, "no_speech_prob": 0.0020168819464743137}, {"id": 187, "seek": 71984, "start": 719.84, "end": 721.84, "text": " so that you can actually grab that and, you know,", "tokens": [50364, 370, 300, 291, 393, 767, 4444, 300, 293, 11, 291, 458, 11, 50464], "temperature": 0.0, "avg_logprob": -0.08670319762884401, "compression_ratio": 1.6303501945525292, "no_speech_prob": 0.000518905813805759}, {"id": 188, "seek": 71984, "start": 721.84, "end": 723.84, "text": " plug it into third-party tools", "tokens": [50464, 5452, 309, 666, 2636, 12, 23409, 3873, 50564], "temperature": 0.0, "avg_logprob": -0.08670319762884401, "compression_ratio": 1.6303501945525292, "no_speech_prob": 0.000518905813805759}, {"id": 189, "seek": 71984, "start": 723.84, "end": 725.84, "text": " and immediately create your dashboard", "tokens": [50564, 293, 4258, 1884, 428, 18342, 50664], "temperature": 0.0, "avg_logprob": -0.08670319762884401, "compression_ratio": 1.6303501945525292, "no_speech_prob": 0.000518905813805759}, {"id": 190, "seek": 71984, "start": 725.84, "end": 730.84, "text": " that gives you the proper visibility in the connections.", "tokens": [50664, 300, 2709, 291, 264, 2296, 19883, 294, 264, 9271, 13, 50914], "temperature": 0.0, "avg_logprob": -0.08670319762884401, "compression_ratio": 1.6303501945525292, "no_speech_prob": 0.000518905813805759}, {"id": 191, "seek": 71984, "start": 730.84, "end": 735.84, "text": " And, you know, last release was just a couple of months ago.", "tokens": [50914, 400, 11, 291, 458, 11, 1036, 4374, 390, 445, 257, 1916, 295, 2493, 2057, 13, 51164], "temperature": 0.0, "avg_logprob": -0.08670319762884401, "compression_ratio": 1.6303501945525292, "no_speech_prob": 0.000518905813805759}, {"id": 192, "seek": 71984, "start": 735.84, "end": 739.84, "text": " So the top priorities for 2024 for the development roadmap", "tokens": [51164, 407, 264, 1192, 15503, 337, 45237, 337, 264, 3250, 35738, 51364], "temperature": 0.0, "avg_logprob": -0.08670319762884401, "compression_ratio": 1.6303501945525292, "no_speech_prob": 0.000518905813805759}, {"id": 193, "seek": 71984, "start": 739.84, "end": 744.84, "text": " is we want to add support for DTLS encryption and authentication.", "tokens": [51364, 307, 321, 528, 281, 909, 1406, 337, 413, 51, 19198, 29575, 293, 26643, 13, 51614], "temperature": 0.0, "avg_logprob": -0.08670319762884401, "compression_ratio": 1.6303501945525292, "no_speech_prob": 0.000518905813805759}, {"id": 194, "seek": 71984, "start": 744.84, "end": 747.84, "text": " We want to fully add support for the new advanced profile", "tokens": [51614, 492, 528, 281, 4498, 909, 1406, 337, 264, 777, 7339, 7964, 51764], "temperature": 0.0, "avg_logprob": -0.08670319762884401, "compression_ratio": 1.6303501945525292, "no_speech_prob": 0.000518905813805759}, {"id": 195, "seek": 74784, "start": 748.84, "end": 753.84, "text": " that adds, you know, the new header ID with the special payloads.", "tokens": [50414, 300, 10860, 11, 291, 458, 11, 264, 777, 23117, 7348, 365, 264, 2121, 30918, 82, 13, 50664], "temperature": 0.0, "avg_logprob": -0.13484088234279468, "compression_ratio": 1.4955357142857142, "no_speech_prob": 0.0027987028006464243}, {"id": 196, "seek": 74784, "start": 753.84, "end": 756.84, "text": " And we want to try to see if we can get back support", "tokens": [50664, 400, 321, 528, 281, 853, 281, 536, 498, 321, 393, 483, 646, 1406, 50814], "temperature": 0.0, "avg_logprob": -0.13484088234279468, "compression_ratio": 1.4955357142857142, "no_speech_prob": 0.0027987028006464243}, {"id": 197, "seek": 74784, "start": 756.84, "end": 759.84, "text": " of the library into VLC 3.0.", "tokens": [50814, 295, 264, 6405, 666, 691, 14766, 805, 13, 15, 13, 50964], "temperature": 0.0, "avg_logprob": -0.13484088234279468, "compression_ratio": 1.4955357142857142, "no_speech_prob": 0.0027987028006464243}, {"id": 198, "seek": 74784, "start": 764.84, "end": 768.84, "text": " So the goal of the original project, like we mentioned before,", "tokens": [51214, 407, 264, 3387, 295, 264, 3380, 1716, 11, 411, 321, 2835, 949, 11, 51414], "temperature": 0.0, "avg_logprob": -0.13484088234279468, "compression_ratio": 1.4955357142857142, "no_speech_prob": 0.0027987028006464243}, {"id": 199, "seek": 74784, "start": 768.84, "end": 773.84, "text": " was an interoperable standard for this type of transmission.", "tokens": [51414, 390, 364, 728, 7192, 712, 3832, 337, 341, 2010, 295, 11574, 13, 51664], "temperature": 0.0, "avg_logprob": -0.13484088234279468, "compression_ratio": 1.4955357142857142, "no_speech_prob": 0.0027987028006464243}, {"id": 200, "seek": 74784, "start": 773.84, "end": 776.84, "text": " There were, you know, half a dozen or a dozen different methods", "tokens": [51664, 821, 645, 11, 291, 458, 11, 1922, 257, 16654, 420, 257, 16654, 819, 7150, 51814], "temperature": 0.0, "avg_logprob": -0.13484088234279468, "compression_ratio": 1.4955357142857142, "no_speech_prob": 0.0027987028006464243}, {"id": 201, "seek": 77684, "start": 777.84, "end": 780.84, "text": " or there still are of doing UDP with packet recovery,", "tokens": [50414, 420, 456, 920, 366, 295, 884, 624, 11373, 365, 20300, 8597, 11, 50564], "temperature": 0.0, "avg_logprob": -0.10533954416002546, "compression_ratio": 1.6, "no_speech_prob": 0.0013032682472839952}, {"id": 202, "seek": 77684, "start": 780.84, "end": 783.84, "text": " each vendor specific, et cetera, et cetera.", "tokens": [50564, 1184, 24321, 2685, 11, 1030, 11458, 11, 1030, 11458, 13, 50714], "temperature": 0.0, "avg_logprob": -0.10533954416002546, "compression_ratio": 1.6, "no_speech_prob": 0.0013032682472839952}, {"id": 203, "seek": 77684, "start": 783.84, "end": 786.84, "text": " Our goal was to create an interoperable standard", "tokens": [50714, 2621, 3387, 390, 281, 1884, 364, 728, 7192, 712, 3832, 50864], "temperature": 0.0, "avg_logprob": -0.10533954416002546, "compression_ratio": 1.6, "no_speech_prob": 0.0013032682472839952}, {"id": 204, "seek": 77684, "start": 786.84, "end": 788.84, "text": " with multiple implementations,", "tokens": [50864, 365, 3866, 4445, 763, 11, 50964], "temperature": 0.0, "avg_logprob": -0.10533954416002546, "compression_ratio": 1.6, "no_speech_prob": 0.0013032682472839952}, {"id": 205, "seek": 77684, "start": 788.84, "end": 791.84, "text": " and I think we've achieved that at this point,", "tokens": [50964, 293, 286, 519, 321, 600, 11042, 300, 412, 341, 935, 11, 51114], "temperature": 0.0, "avg_logprob": -0.10533954416002546, "compression_ratio": 1.6, "no_speech_prob": 0.0013032682472839952}, {"id": 206, "seek": 77684, "start": 791.84, "end": 794.84, "text": " at least at the higher broadcast level", "tokens": [51114, 412, 1935, 412, 264, 2946, 9975, 1496, 51264], "temperature": 0.0, "avg_logprob": -0.10533954416002546, "compression_ratio": 1.6, "no_speech_prob": 0.0013032682472839952}, {"id": 207, "seek": 77684, "start": 794.84, "end": 796.84, "text": " and tier one, tier two companies", "tokens": [51264, 293, 12362, 472, 11, 12362, 732, 3431, 51364], "temperature": 0.0, "avg_logprob": -0.10533954416002546, "compression_ratio": 1.6, "no_speech_prob": 0.0013032682472839952}, {"id": 208, "seek": 77684, "start": 796.84, "end": 799.84, "text": " and a lot of the open source projects that support REST.", "tokens": [51364, 293, 257, 688, 295, 264, 1269, 4009, 4455, 300, 1406, 497, 14497, 13, 51514], "temperature": 0.0, "avg_logprob": -0.10533954416002546, "compression_ratio": 1.6, "no_speech_prob": 0.0013032682472839952}, {"id": 209, "seek": 77684, "start": 799.84, "end": 801.84, "text": " They all talk to each other,", "tokens": [51514, 814, 439, 751, 281, 1184, 661, 11, 51614], "temperature": 0.0, "avg_logprob": -0.10533954416002546, "compression_ratio": 1.6, "no_speech_prob": 0.0013032682472839952}, {"id": 210, "seek": 77684, "start": 801.84, "end": 803.84, "text": " even if it's not the same implementation.", "tokens": [51614, 754, 498, 309, 311, 406, 264, 912, 11420, 13, 51714], "temperature": 0.0, "avg_logprob": -0.10533954416002546, "compression_ratio": 1.6, "no_speech_prob": 0.0013032682472839952}, {"id": 211, "seek": 80684, "start": 806.84, "end": 808.84, "text": " So now to part two, right?", "tokens": [50364, 407, 586, 281, 644, 732, 11, 558, 30, 50464], "temperature": 0.0, "avg_logprob": -0.1209115743637085, "compression_ratio": 1.613733905579399, "no_speech_prob": 0.0005109763587825}, {"id": 212, "seek": 80684, "start": 808.84, "end": 812.84, "text": " Let's look at REST as a live streaming platform, right?", "tokens": [50464, 961, 311, 574, 412, 497, 14497, 382, 257, 1621, 11791, 3663, 11, 558, 30, 50664], "temperature": 0.0, "avg_logprob": -0.1209115743637085, "compression_ratio": 1.613733905579399, "no_speech_prob": 0.0005109763587825}, {"id": 213, "seek": 80684, "start": 812.84, "end": 816.84, "text": " And particularly we want to look at a model that does N2S.", "tokens": [50664, 400, 4098, 321, 528, 281, 574, 412, 257, 2316, 300, 775, 426, 17, 50, 13, 50864], "temperature": 0.0, "avg_logprob": -0.1209115743637085, "compression_ratio": 1.613733905579399, "no_speech_prob": 0.0005109763587825}, {"id": 214, "seek": 80684, "start": 816.84, "end": 819.84, "text": " How do you use REST and Libris in particular", "tokens": [50864, 1012, 360, 291, 764, 497, 14497, 293, 15834, 5714, 294, 1729, 51014], "temperature": 0.0, "avg_logprob": -0.1209115743637085, "compression_ratio": 1.613733905579399, "no_speech_prob": 0.0005109763587825}, {"id": 215, "seek": 80684, "start": 819.84, "end": 822.84, "text": " to do an N2N streaming chain,", "tokens": [51014, 281, 360, 364, 426, 17, 45, 11791, 5021, 11, 51164], "temperature": 0.0, "avg_logprob": -0.1209115743637085, "compression_ratio": 1.613733905579399, "no_speech_prob": 0.0005109763587825}, {"id": 216, "seek": 80684, "start": 822.84, "end": 824.84, "text": " like the one we're doing here, for example,", "tokens": [51164, 411, 264, 472, 321, 434, 884, 510, 11, 337, 1365, 11, 51264], "temperature": 0.0, "avg_logprob": -0.1209115743637085, "compression_ratio": 1.613733905579399, "no_speech_prob": 0.0005109763587825}, {"id": 217, "seek": 80684, "start": 824.84, "end": 828.84, "text": " or, you know, any one-to-many scenario, right?", "tokens": [51264, 420, 11, 291, 458, 11, 604, 472, 12, 1353, 12, 76, 1325, 9005, 11, 558, 30, 51464], "temperature": 0.0, "avg_logprob": -0.1209115743637085, "compression_ratio": 1.613733905579399, "no_speech_prob": 0.0005109763587825}, {"id": 218, "seek": 80684, "start": 829.84, "end": 831.84, "text": " Lots of viewers.", "tokens": [51514, 15908, 295, 8499, 13, 51614], "temperature": 0.0, "avg_logprob": -0.1209115743637085, "compression_ratio": 1.613733905579399, "no_speech_prob": 0.0005109763587825}, {"id": 219, "seek": 80684, "start": 831.84, "end": 835.84, "text": " So let's diagram, you know, a simple scenario here.", "tokens": [51614, 407, 718, 311, 10686, 11, 291, 458, 11, 257, 2199, 9005, 510, 13, 51814], "temperature": 0.0, "avg_logprob": -0.1209115743637085, "compression_ratio": 1.613733905579399, "no_speech_prob": 0.0005109763587825}, {"id": 220, "seek": 83684, "start": 836.84, "end": 839.84, "text": " We have three components,", "tokens": [50364, 492, 362, 1045, 6677, 11, 50514], "temperature": 0.0, "avg_logprob": -0.12633778633327658, "compression_ratio": 1.5022222222222221, "no_speech_prob": 0.00011957437527598813}, {"id": 221, "seek": 83684, "start": 839.84, "end": 842.84, "text": " sources, the sender, which is a REST device,", "tokens": [50514, 7139, 11, 264, 2845, 260, 11, 597, 307, 257, 497, 14497, 4302, 11, 50664], "temperature": 0.0, "avg_logprob": -0.12633778633327658, "compression_ratio": 1.5022222222222221, "no_speech_prob": 0.00011957437527598813}, {"id": 222, "seek": 83684, "start": 842.84, "end": 844.84, "text": " and many receivers on the bottom,", "tokens": [50664, 293, 867, 49196, 322, 264, 2767, 11, 50764], "temperature": 0.0, "avg_logprob": -0.12633778633327658, "compression_ratio": 1.5022222222222221, "no_speech_prob": 0.00011957437527598813}, {"id": 223, "seek": 83684, "start": 844.84, "end": 847.84, "text": " and the box here on the bottom, you know,", "tokens": [50764, 293, 264, 2424, 510, 322, 264, 2767, 11, 291, 458, 11, 50914], "temperature": 0.0, "avg_logprob": -0.12633778633327658, "compression_ratio": 1.5022222222222221, "no_speech_prob": 0.00011957437527598813}, {"id": 224, "seek": 83684, "start": 847.84, "end": 850.84, "text": " symbolizes a single one of those receivers.", "tokens": [50914, 5986, 5660, 257, 2167, 472, 295, 729, 49196, 13, 51064], "temperature": 0.0, "avg_logprob": -0.12633778633327658, "compression_ratio": 1.5022222222222221, "no_speech_prob": 0.00011957437527598813}, {"id": 225, "seek": 83684, "start": 853.84, "end": 856.84, "text": " So we see the logos up there for FFMPEG, BLC,", "tokens": [51214, 407, 321, 536, 264, 40654, 493, 456, 337, 479, 37, 44, 5208, 38, 11, 363, 14766, 11, 51364], "temperature": 0.0, "avg_logprob": -0.12633778633327658, "compression_ratio": 1.5022222222222221, "no_speech_prob": 0.00011957437527598813}, {"id": 226, "seek": 83684, "start": 856.84, "end": 858.84, "text": " and Open Broadcast Studio.", "tokens": [51364, 293, 7238, 14074, 3734, 13500, 13, 51464], "temperature": 0.0, "avg_logprob": -0.12633778633327658, "compression_ratio": 1.5022222222222221, "no_speech_prob": 0.00011957437527598813}, {"id": 227, "seek": 83684, "start": 858.84, "end": 861.84, "text": " That could be also G-streamer, any source,", "tokens": [51464, 663, 727, 312, 611, 460, 12, 9291, 260, 11, 604, 4009, 11, 51614], "temperature": 0.0, "avg_logprob": -0.12633778633327658, "compression_ratio": 1.5022222222222221, "no_speech_prob": 0.00011957437527598813}, {"id": 228, "seek": 83684, "start": 861.84, "end": 863.84, "text": " any encoder, it doesn't matter.", "tokens": [51614, 604, 2058, 19866, 11, 309, 1177, 380, 1871, 13, 51714], "temperature": 0.0, "avg_logprob": -0.12633778633327658, "compression_ratio": 1.5022222222222221, "no_speech_prob": 0.00011957437527598813}, {"id": 229, "seek": 86384, "start": 863.84, "end": 866.84, "text": " Somebody that has the ability to generate", "tokens": [50364, 13463, 300, 575, 264, 3485, 281, 8460, 50514], "temperature": 0.0, "avg_logprob": -0.11573144090854055, "compression_ratio": 1.6691176470588236, "no_speech_prob": 0.0004303955938667059}, {"id": 230, "seek": 86384, "start": 866.84, "end": 869.84, "text": " compressed or uncompressed video stream, right?", "tokens": [50514, 30353, 420, 8585, 79, 3805, 960, 4309, 11, 558, 30, 50664], "temperature": 0.0, "avg_logprob": -0.11573144090854055, "compression_ratio": 1.6691176470588236, "no_speech_prob": 0.0004303955938667059}, {"id": 231, "seek": 86384, "start": 869.84, "end": 872.84, "text": " Well, we need a binary stream of some kind", "tokens": [50664, 1042, 11, 321, 643, 257, 17434, 4309, 295, 512, 733, 50814], "temperature": 0.0, "avg_logprob": -0.11573144090854055, "compression_ratio": 1.6691176470588236, "no_speech_prob": 0.0004303955938667059}, {"id": 232, "seek": 86384, "start": 872.84, "end": 874.84, "text": " pushed to the library.", "tokens": [50814, 9152, 281, 264, 6405, 13, 50914], "temperature": 0.0, "avg_logprob": -0.11573144090854055, "compression_ratio": 1.6691176470588236, "no_speech_prob": 0.0004303955938667059}, {"id": 233, "seek": 86384, "start": 874.84, "end": 878.84, "text": " Libris in particular doesn't care about what the payload is.", "tokens": [50914, 15834, 5714, 294, 1729, 1177, 380, 1127, 466, 437, 264, 30918, 307, 13, 51114], "temperature": 0.0, "avg_logprob": -0.11573144090854055, "compression_ratio": 1.6691176470588236, "no_speech_prob": 0.0004303955938667059}, {"id": 234, "seek": 86384, "start": 878.84, "end": 880.84, "text": " You can push anything in the payload,", "tokens": [51114, 509, 393, 2944, 1340, 294, 264, 30918, 11, 51214], "temperature": 0.0, "avg_logprob": -0.11573144090854055, "compression_ratio": 1.6691176470588236, "no_speech_prob": 0.0004303955938667059}, {"id": 235, "seek": 86384, "start": 880.84, "end": 882.84, "text": " we'll deliver that to the other side,", "tokens": [51214, 321, 603, 4239, 300, 281, 264, 661, 1252, 11, 51314], "temperature": 0.0, "avg_logprob": -0.11573144090854055, "compression_ratio": 1.6691176470588236, "no_speech_prob": 0.0004303955938667059}, {"id": 236, "seek": 86384, "start": 882.84, "end": 884.84, "text": " even though the spec for simple profile and main profile", "tokens": [51314, 754, 1673, 264, 1608, 337, 2199, 7964, 293, 2135, 7964, 51414], "temperature": 0.0, "avg_logprob": -0.11573144090854055, "compression_ratio": 1.6691176470588236, "no_speech_prob": 0.0004303955938667059}, {"id": 237, "seek": 86384, "start": 884.84, "end": 886.84, "text": " say that you're transmitting MPEG-TS,", "tokens": [51414, 584, 300, 291, 434, 7715, 2414, 376, 5208, 38, 12, 7327, 11, 51514], "temperature": 0.0, "avg_logprob": -0.11573144090854055, "compression_ratio": 1.6691176470588236, "no_speech_prob": 0.0004303955938667059}, {"id": 238, "seek": 86384, "start": 886.84, "end": 888.84, "text": " the library doesn't look at the payload", "tokens": [51514, 264, 6405, 1177, 380, 574, 412, 264, 30918, 51614], "temperature": 0.0, "avg_logprob": -0.11573144090854055, "compression_ratio": 1.6691176470588236, "no_speech_prob": 0.0004303955938667059}, {"id": 239, "seek": 86384, "start": 888.84, "end": 890.84, "text": " or restrict it in any way.", "tokens": [51614, 420, 7694, 309, 294, 604, 636, 13, 51714], "temperature": 0.0, "avg_logprob": -0.11573144090854055, "compression_ratio": 1.6691176470588236, "no_speech_prob": 0.0004303955938667059}, {"id": 240, "seek": 89084, "start": 891.84, "end": 893.84, "text": " Okay.", "tokens": [50414, 1033, 13, 50514], "temperature": 0.0, "avg_logprob": -0.13236327023850275, "compression_ratio": 1.6108374384236452, "no_speech_prob": 0.00030996743589639664}, {"id": 241, "seek": 89084, "start": 893.84, "end": 898.84, "text": " So the source is sending a UDP,", "tokens": [50514, 407, 264, 4009, 307, 7750, 257, 624, 11373, 11, 50764], "temperature": 0.0, "avg_logprob": -0.13236327023850275, "compression_ratio": 1.6108374384236452, "no_speech_prob": 0.00030996743589639664}, {"id": 242, "seek": 89084, "start": 898.84, "end": 901.84, "text": " or RTP media stream into the input.", "tokens": [50764, 420, 497, 16804, 3021, 4309, 666, 264, 4846, 13, 50914], "temperature": 0.0, "avg_logprob": -0.13236327023850275, "compression_ratio": 1.6108374384236452, "no_speech_prob": 0.00030996743589639664}, {"id": 243, "seek": 89084, "start": 901.84, "end": 904.84, "text": " We buffer it so that we have it available", "tokens": [50914, 492, 21762, 309, 370, 300, 321, 362, 309, 2435, 51064], "temperature": 0.0, "avg_logprob": -0.13236327023850275, "compression_ratio": 1.6108374384236452, "no_speech_prob": 0.00030996743589639664}, {"id": 244, "seek": 89084, "start": 904.84, "end": 908.84, "text": " for retransmission, and the minute the buffer is full,", "tokens": [51064, 337, 23106, 599, 29797, 11, 293, 264, 3456, 264, 21762, 307, 1577, 11, 51264], "temperature": 0.0, "avg_logprob": -0.13236327023850275, "compression_ratio": 1.6108374384236452, "no_speech_prob": 0.00030996743589639664}, {"id": 245, "seek": 89084, "start": 908.84, "end": 911.84, "text": " we start listening on, we put the sender", "tokens": [51264, 321, 722, 4764, 322, 11, 321, 829, 264, 2845, 260, 51414], "temperature": 0.0, "avg_logprob": -0.13236327023850275, "compression_ratio": 1.6108374384236452, "no_speech_prob": 0.00030996743589639664}, {"id": 246, "seek": 89084, "start": 911.84, "end": 913.84, "text": " in what we call listening mode.", "tokens": [51414, 294, 437, 321, 818, 4764, 4391, 13, 51514], "temperature": 0.0, "avg_logprob": -0.13236327023850275, "compression_ratio": 1.6108374384236452, "no_speech_prob": 0.00030996743589639664}, {"id": 247, "seek": 89084, "start": 913.84, "end": 915.84, "text": " It opens a UDP port and start listening", "tokens": [51514, 467, 9870, 257, 624, 11373, 2436, 293, 722, 4764, 51614], "temperature": 0.0, "avg_logprob": -0.13236327023850275, "compression_ratio": 1.6108374384236452, "no_speech_prob": 0.00030996743589639664}, {"id": 248, "seek": 89084, "start": 915.84, "end": 919.84, "text": " for receivers that want that stream, right?", "tokens": [51614, 337, 49196, 300, 528, 300, 4309, 11, 558, 30, 51814], "temperature": 0.0, "avg_logprob": -0.13236327023850275, "compression_ratio": 1.6108374384236452, "no_speech_prob": 0.00030996743589639664}, {"id": 249, "seek": 91984, "start": 920.84, "end": 924.84, "text": " So the minute our receiver wants to connect to us,", "tokens": [50414, 407, 264, 3456, 527, 20086, 2738, 281, 1745, 281, 505, 11, 50614], "temperature": 0.0, "avg_logprob": -0.09912371403962664, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.0005969357443973422}, {"id": 250, "seek": 91984, "start": 924.84, "end": 926.84, "text": " then the handshake happens.", "tokens": [50614, 550, 264, 2377, 34593, 2314, 13, 50714], "temperature": 0.0, "avg_logprob": -0.09912371403962664, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.0005969357443973422}, {"id": 251, "seek": 91984, "start": 926.84, "end": 928.84, "text": " I'm obviously oversimplifying the process", "tokens": [50714, 286, 478, 2745, 15488, 332, 564, 5489, 264, 1399, 50814], "temperature": 0.0, "avg_logprob": -0.09912371403962664, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.0005969357443973422}, {"id": 252, "seek": 91984, "start": 928.84, "end": 930.84, "text": " of the handshake that all happens.", "tokens": [50814, 295, 264, 2377, 34593, 300, 439, 2314, 13, 50914], "temperature": 0.0, "avg_logprob": -0.09912371403962664, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.0005969357443973422}, {"id": 253, "seek": 91984, "start": 930.84, "end": 935.84, "text": " The SRP68 protocol is quite complex.", "tokens": [50914, 440, 20840, 47, 27102, 10336, 307, 1596, 3997, 13, 51164], "temperature": 0.0, "avg_logprob": -0.09912371403962664, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.0005969357443973422}, {"id": 254, "seek": 91984, "start": 935.84, "end": 937.84, "text": " It would take a talk just to go through the details", "tokens": [51164, 467, 576, 747, 257, 751, 445, 281, 352, 807, 264, 4365, 51264], "temperature": 0.0, "avg_logprob": -0.09912371403962664, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.0005969357443973422}, {"id": 255, "seek": 91984, "start": 937.84, "end": 939.84, "text": " of that handshake and everything that happens.", "tokens": [51264, 295, 300, 2377, 34593, 293, 1203, 300, 2314, 13, 51364], "temperature": 0.0, "avg_logprob": -0.09912371403962664, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.0005969357443973422}, {"id": 256, "seek": 91984, "start": 939.84, "end": 941.84, "text": " So this is only symbolic.", "tokens": [51364, 407, 341, 307, 787, 25755, 13, 51464], "temperature": 0.0, "avg_logprob": -0.09912371403962664, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.0005969357443973422}, {"id": 257, "seek": 91984, "start": 941.84, "end": 943.84, "text": " The handshake happens.", "tokens": [51464, 440, 2377, 34593, 2314, 13, 51564], "temperature": 0.0, "avg_logprob": -0.09912371403962664, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.0005969357443973422}, {"id": 258, "seek": 91984, "start": 943.84, "end": 946.84, "text": " The username is sent to us,", "tokens": [51564, 440, 30351, 307, 2279, 281, 505, 11, 51714], "temperature": 0.0, "avg_logprob": -0.09912371403962664, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.0005969357443973422}, {"id": 259, "seek": 94684, "start": 946.84, "end": 949.84, "text": " and we check for that username within our database", "tokens": [50364, 293, 321, 1520, 337, 300, 30351, 1951, 527, 8149, 50514], "temperature": 0.0, "avg_logprob": -0.1226685873352655, "compression_ratio": 1.5953488372093023, "no_speech_prob": 0.0009691026643849909}, {"id": 260, "seek": 94684, "start": 949.84, "end": 950.84, "text": " of username and passwords.", "tokens": [50514, 295, 30351, 293, 33149, 13, 50564], "temperature": 0.0, "avg_logprob": -0.1226685873352655, "compression_ratio": 1.5953488372093023, "no_speech_prob": 0.0009691026643849909}, {"id": 261, "seek": 94684, "start": 950.84, "end": 952.84, "text": " It's not really a data-major password,", "tokens": [50564, 467, 311, 406, 534, 257, 1412, 12, 1696, 2337, 11524, 11, 50664], "temperature": 0.0, "avg_logprob": -0.1226685873352655, "compression_ratio": 1.5953488372093023, "no_speech_prob": 0.0009691026643849909}, {"id": 262, "seek": 94684, "start": 952.84, "end": 957.84, "text": " but a password hashes to keep everything safe.", "tokens": [50664, 457, 257, 11524, 575, 8076, 281, 1066, 1203, 3273, 13, 50914], "temperature": 0.0, "avg_logprob": -0.1226685873352655, "compression_ratio": 1.5953488372093023, "no_speech_prob": 0.0009691026643849909}, {"id": 263, "seek": 94684, "start": 957.84, "end": 961.84, "text": " If the authentication succeeds,", "tokens": [50914, 759, 264, 26643, 49263, 11, 51114], "temperature": 0.0, "avg_logprob": -0.1226685873352655, "compression_ratio": 1.5953488372093023, "no_speech_prob": 0.0009691026643849909}, {"id": 264, "seek": 94684, "start": 961.84, "end": 965.84, "text": " then we send as part of the SRP68 protocol", "tokens": [51114, 550, 321, 2845, 382, 644, 295, 264, 20840, 47, 27102, 10336, 51314], "temperature": 0.0, "avg_logprob": -0.1226685873352655, "compression_ratio": 1.5953488372093023, "no_speech_prob": 0.0009691026643849909}, {"id": 265, "seek": 94684, "start": 965.84, "end": 968.84, "text": " the pre-shared key so that the receiver", "tokens": [51314, 264, 659, 12, 2716, 1642, 2141, 370, 300, 264, 20086, 51464], "temperature": 0.0, "avg_logprob": -0.1226685873352655, "compression_ratio": 1.5953488372093023, "no_speech_prob": 0.0009691026643849909}, {"id": 266, "seek": 94684, "start": 968.84, "end": 971.84, "text": " can decrypt the data now.", "tokens": [51464, 393, 979, 627, 662, 264, 1412, 586, 13, 51614], "temperature": 0.0, "avg_logprob": -0.1226685873352655, "compression_ratio": 1.5953488372093023, "no_speech_prob": 0.0009691026643849909}, {"id": 267, "seek": 94684, "start": 971.84, "end": 974.84, "text": " Once the data is decrypted, that's it.", "tokens": [51614, 3443, 264, 1412, 307, 979, 627, 25383, 11, 300, 311, 309, 13, 51764], "temperature": 0.0, "avg_logprob": -0.1226685873352655, "compression_ratio": 1.5953488372093023, "no_speech_prob": 0.0009691026643849909}, {"id": 268, "seek": 97484, "start": 974.84, "end": 979.84, "text": " We have an end-to-end transmission from source", "tokens": [50364, 492, 362, 364, 917, 12, 1353, 12, 521, 11574, 490, 4009, 50614], "temperature": 0.0, "avg_logprob": -0.11259338154512293, "compression_ratio": 1.5023474178403755, "no_speech_prob": 0.00081614003283903}, {"id": 269, "seek": 97484, "start": 979.84, "end": 983.84, "text": " to hundreds of destinations", "tokens": [50614, 281, 6779, 295, 37787, 50814], "temperature": 0.0, "avg_logprob": -0.11259338154512293, "compression_ratio": 1.5023474178403755, "no_speech_prob": 0.00081614003283903}, {"id": 270, "seek": 97484, "start": 983.84, "end": 986.84, "text": " with just the risk protocol in between.", "tokens": [50814, 365, 445, 264, 3148, 10336, 294, 1296, 13, 50964], "temperature": 0.0, "avg_logprob": -0.11259338154512293, "compression_ratio": 1.5023474178403755, "no_speech_prob": 0.00081614003283903}, {"id": 271, "seek": 97484, "start": 986.84, "end": 991.84, "text": " So with proper planning and setting everything up correctly,", "tokens": [50964, 407, 365, 2296, 5038, 293, 3287, 1203, 493, 8944, 11, 51214], "temperature": 0.0, "avg_logprob": -0.11259338154512293, "compression_ratio": 1.5023474178403755, "no_speech_prob": 0.00081614003283903}, {"id": 272, "seek": 97484, "start": 991.84, "end": 994.84, "text": " you can have a 300 millisecond glass-to-glass,", "tokens": [51214, 291, 393, 362, 257, 6641, 27940, 18882, 4276, 12, 1353, 12, 28851, 11, 51364], "temperature": 0.0, "avg_logprob": -0.11259338154512293, "compression_ratio": 1.5023474178403755, "no_speech_prob": 0.00081614003283903}, {"id": 273, "seek": 97484, "start": 994.84, "end": 998.84, "text": " one to hundreds of listeners.", "tokens": [51364, 472, 281, 6779, 295, 23274, 13, 51564], "temperature": 0.0, "avg_logprob": -0.11259338154512293, "compression_ratio": 1.5023474178403755, "no_speech_prob": 0.00081614003283903}, {"id": 274, "seek": 97484, "start": 998.84, "end": 1000.84, "text": " You need a good network.", "tokens": [51564, 509, 643, 257, 665, 3209, 13, 51664], "temperature": 0.0, "avg_logprob": -0.11259338154512293, "compression_ratio": 1.5023474178403755, "no_speech_prob": 0.00081614003283903}, {"id": 275, "seek": 97484, "start": 1000.84, "end": 1002.84, "text": " Like I said, the latency is more dependent", "tokens": [51664, 1743, 286, 848, 11, 264, 27043, 307, 544, 12334, 51764], "temperature": 0.0, "avg_logprob": -0.11259338154512293, "compression_ratio": 1.5023474178403755, "no_speech_prob": 0.00081614003283903}, {"id": 276, "seek": 100284, "start": 1002.84, "end": 1006.84, "text": " upon the RTT between the endpoints than anything else.", "tokens": [50364, 3564, 264, 21797, 51, 1296, 264, 917, 20552, 813, 1340, 1646, 13, 50564], "temperature": 0.0, "avg_logprob": -0.10710969338050255, "compression_ratio": 1.6008771929824561, "no_speech_prob": 0.002470695413649082}, {"id": 277, "seek": 100284, "start": 1006.84, "end": 1009.84, "text": " I mentioned 300 milliseconds", "tokens": [50564, 286, 2835, 6641, 34184, 50714], "temperature": 0.0, "avg_logprob": -0.10710969338050255, "compression_ratio": 1.6008771929824561, "no_speech_prob": 0.002470695413649082}, {"id": 278, "seek": 100284, "start": 1009.84, "end": 1012.84, "text": " because in our large-scale deployments,", "tokens": [50714, 570, 294, 527, 2416, 12, 20033, 7274, 1117, 11, 50864], "temperature": 0.0, "avg_logprob": -0.10710969338050255, "compression_ratio": 1.6008771929824561, "no_speech_prob": 0.002470695413649082}, {"id": 279, "seek": 100284, "start": 1012.84, "end": 1014.84, "text": " we've done this anywhere within the U.S.", "tokens": [50864, 321, 600, 1096, 341, 4992, 1951, 264, 624, 13, 50, 13, 50964], "temperature": 0.0, "avg_logprob": -0.10710969338050255, "compression_ratio": 1.6008771929824561, "no_speech_prob": 0.002470695413649082}, {"id": 280, "seek": 100284, "start": 1014.84, "end": 1018.84, "text": " with 300 milliseconds glass-to-glass.", "tokens": [50964, 365, 6641, 34184, 4276, 12, 1353, 12, 28851, 13, 51164], "temperature": 0.0, "avg_logprob": -0.10710969338050255, "compression_ratio": 1.6008771929824561, "no_speech_prob": 0.002470695413649082}, {"id": 281, "seek": 100284, "start": 1018.84, "end": 1022.84, "text": " When you have to expand it and have users that are", "tokens": [51164, 1133, 291, 362, 281, 5268, 309, 293, 362, 5022, 300, 366, 51364], "temperature": 0.0, "avg_logprob": -0.10710969338050255, "compression_ratio": 1.6008771929824561, "no_speech_prob": 0.002470695413649082}, {"id": 282, "seek": 100284, "start": 1022.84, "end": 1026.8400000000001, "text": " across the ocean or with crappy networks or Wi-Fi,", "tokens": [51364, 2108, 264, 7810, 420, 365, 36531, 9590, 420, 14035, 12, 13229, 11, 51564], "temperature": 0.0, "avg_logprob": -0.10710969338050255, "compression_ratio": 1.6008771929824561, "no_speech_prob": 0.002470695413649082}, {"id": 283, "seek": 100284, "start": 1026.8400000000001, "end": 1029.8400000000001, "text": " the latency will auto-adjust.", "tokens": [51564, 264, 27043, 486, 8399, 12, 345, 3424, 13, 51714], "temperature": 0.0, "avg_logprob": -0.10710969338050255, "compression_ratio": 1.6008771929824561, "no_speech_prob": 0.002470695413649082}, {"id": 284, "seek": 100284, "start": 1029.8400000000001, "end": 1031.8400000000001, "text": " The protocol will auto-adjust.", "tokens": [51714, 440, 10336, 486, 8399, 12, 345, 3424, 13, 51814], "temperature": 0.0, "avg_logprob": -0.10710969338050255, "compression_ratio": 1.6008771929824561, "no_speech_prob": 0.002470695413649082}, {"id": 285, "seek": 103184, "start": 1031.84, "end": 1034.84, "text": " For those players, suddenly they get 500 milliseconds.", "tokens": [50364, 1171, 729, 4150, 11, 5800, 436, 483, 5923, 34184, 13, 50514], "temperature": 0.0, "avg_logprob": -0.1888722107473728, "compression_ratio": 1.524904214559387, "no_speech_prob": 0.001865866594016552}, {"id": 286, "seek": 103184, "start": 1034.84, "end": 1037.84, "text": " We notice as a rule of thumb that somebody in Wi-Fi", "tokens": [50514, 492, 3449, 382, 257, 4978, 295, 9298, 300, 2618, 294, 14035, 12, 13229, 50664], "temperature": 0.0, "avg_logprob": -0.1888722107473728, "compression_ratio": 1.524904214559387, "no_speech_prob": 0.001865866594016552}, {"id": 287, "seek": 103184, "start": 1037.84, "end": 1041.84, "text": " gets a penalty of another 200 milliseconds automatically.", "tokens": [50664, 2170, 257, 16263, 295, 1071, 2331, 34184, 6772, 13, 50864], "temperature": 0.0, "avg_logprob": -0.1888722107473728, "compression_ratio": 1.524904214559387, "no_speech_prob": 0.001865866594016552}, {"id": 288, "seek": 103184, "start": 1041.84, "end": 1047.84, "text": " So how do you do this from a practical point of view?", "tokens": [50864, 407, 577, 360, 291, 360, 341, 490, 257, 8496, 935, 295, 1910, 30, 51164], "temperature": 0.0, "avg_logprob": -0.1888722107473728, "compression_ratio": 1.524904214559387, "no_speech_prob": 0.001865866594016552}, {"id": 289, "seek": 103184, "start": 1047.84, "end": 1051.84, "text": " The LibreSploracle includes some command-line utilities", "tokens": [51164, 440, 15834, 265, 50, 564, 284, 7041, 5974, 512, 5622, 12, 1889, 30482, 51364], "temperature": 0.0, "avg_logprob": -0.1888722107473728, "compression_ratio": 1.524904214559387, "no_speech_prob": 0.001865866594016552}, {"id": 290, "seek": 103184, "start": 1051.84, "end": 1055.84, "text": " that allows you to send, receive, and relay.", "tokens": [51364, 300, 4045, 291, 281, 2845, 11, 4774, 11, 293, 24214, 13, 51564], "temperature": 0.0, "avg_logprob": -0.1888722107473728, "compression_ratio": 1.524904214559387, "no_speech_prob": 0.001865866594016552}, {"id": 291, "seek": 103184, "start": 1055.84, "end": 1057.84, "text": " The RISC2RISC is the one...", "tokens": [51564, 440, 497, 2343, 34, 17, 9698, 34, 307, 264, 472, 485, 51664], "temperature": 0.0, "avg_logprob": -0.1888722107473728, "compression_ratio": 1.524904214559387, "no_speech_prob": 0.001865866594016552}, {"id": 292, "seek": 103184, "start": 1057.84, "end": 1059.84, "text": " If you want to do a relay application one-to-many,", "tokens": [51664, 759, 291, 528, 281, 360, 257, 24214, 3861, 472, 12, 1353, 12, 76, 1325, 11, 51764], "temperature": 0.0, "avg_logprob": -0.1888722107473728, "compression_ratio": 1.524904214559387, "no_speech_prob": 0.001865866594016552}, {"id": 293, "seek": 105984, "start": 1059.84, "end": 1061.84, "text": " this is the ideal scenario.", "tokens": [50364, 341, 307, 264, 7157, 9005, 13, 50464], "temperature": 0.0, "avg_logprob": -0.10945712668555123, "compression_ratio": 1.624413145539906, "no_speech_prob": 0.007552787195891142}, {"id": 294, "seek": 105984, "start": 1061.84, "end": 1065.84, "text": " You can also do it with a RISC sender, to be honest,", "tokens": [50464, 509, 393, 611, 360, 309, 365, 257, 497, 2343, 34, 2845, 260, 11, 281, 312, 3245, 11, 50664], "temperature": 0.0, "avg_logprob": -0.10945712668555123, "compression_ratio": 1.624413145539906, "no_speech_prob": 0.007552787195891142}, {"id": 295, "seek": 105984, "start": 1065.84, "end": 1070.84, "text": " but the RISC2RISC is effective because it acts as a relay,", "tokens": [50664, 457, 264, 497, 2343, 34, 17, 9698, 34, 307, 4942, 570, 309, 10672, 382, 257, 24214, 11, 50914], "temperature": 0.0, "avg_logprob": -0.10945712668555123, "compression_ratio": 1.624413145539906, "no_speech_prob": 0.007552787195891142}, {"id": 296, "seek": 105984, "start": 1070.84, "end": 1072.84, "text": " doesn't encrypt or decrypt, doesn't do anything,", "tokens": [50914, 1177, 380, 17972, 662, 420, 979, 627, 662, 11, 1177, 380, 360, 1340, 11, 51014], "temperature": 0.0, "avg_logprob": -0.10945712668555123, "compression_ratio": 1.624413145539906, "no_speech_prob": 0.007552787195891142}, {"id": 297, "seek": 105984, "start": 1072.84, "end": 1077.84, "text": " but receives data and sends data both in the RISC format.", "tokens": [51014, 457, 20717, 1412, 293, 14790, 1412, 1293, 294, 264, 497, 2343, 34, 7877, 13, 51264], "temperature": 0.0, "avg_logprob": -0.10945712668555123, "compression_ratio": 1.624413145539906, "no_speech_prob": 0.007552787195891142}, {"id": 298, "seek": 105984, "start": 1077.84, "end": 1083.84, "text": " You can put this in a CDN, your data sender anywhere,", "tokens": [51264, 509, 393, 829, 341, 294, 257, 6743, 45, 11, 428, 1412, 2845, 260, 4992, 11, 51564], "temperature": 0.0, "avg_logprob": -0.10945712668555123, "compression_ratio": 1.624413145539906, "no_speech_prob": 0.007552787195891142}, {"id": 299, "seek": 105984, "start": 1083.84, "end": 1086.84, "text": " and you configure in the RISC2RISC a listener", "tokens": [51564, 293, 291, 22162, 294, 264, 497, 2343, 34, 17, 9698, 34, 257, 31569, 51714], "temperature": 0.0, "avg_logprob": -0.10945712668555123, "compression_ratio": 1.624413145539906, "no_speech_prob": 0.007552787195891142}, {"id": 300, "seek": 108684, "start": 1086.84, "end": 1091.84, "text": " with authentication, and then you put your stream from anywhere,", "tokens": [50364, 365, 26643, 11, 293, 550, 291, 829, 428, 4309, 490, 4992, 11, 50614], "temperature": 0.0, "avg_logprob": -0.13213369161775795, "compression_ratio": 1.7433628318584071, "no_speech_prob": 0.004605441819876432}, {"id": 301, "seek": 108684, "start": 1091.84, "end": 1095.84, "text": " your source, like from here, to that endpoint.", "tokens": [50614, 428, 4009, 11, 411, 490, 510, 11, 281, 300, 35795, 13, 50814], "temperature": 0.0, "avg_logprob": -0.13213369161775795, "compression_ratio": 1.7433628318584071, "no_speech_prob": 0.004605441819876432}, {"id": 302, "seek": 108684, "start": 1095.84, "end": 1097.84, "text": " Then you configure the other end,", "tokens": [50814, 1396, 291, 22162, 264, 661, 917, 11, 50914], "temperature": 0.0, "avg_logprob": -0.13213369161775795, "compression_ratio": 1.7433628318584071, "no_speech_prob": 0.004605441819876432}, {"id": 303, "seek": 108684, "start": 1097.84, "end": 1100.84, "text": " the one that's going to send to the older viewers", "tokens": [50914, 264, 472, 300, 311, 516, 281, 2845, 281, 264, 4906, 8499, 51064], "temperature": 0.0, "avg_logprob": -0.13213369161775795, "compression_ratio": 1.7433628318584071, "no_speech_prob": 0.004605441819876432}, {"id": 304, "seek": 108684, "start": 1100.84, "end": 1102.84, "text": " with a database of user-oriented passwords,", "tokens": [51064, 365, 257, 8149, 295, 4195, 12, 27414, 33149, 11, 51164], "temperature": 0.0, "avg_logprob": -0.13213369161775795, "compression_ratio": 1.7433628318584071, "no_speech_prob": 0.004605441819876432}, {"id": 305, "seek": 108684, "start": 1102.84, "end": 1106.84, "text": " and now you have the full authentication.", "tokens": [51164, 293, 586, 291, 362, 264, 1577, 26643, 13, 51364], "temperature": 0.0, "avg_logprob": -0.13213369161775795, "compression_ratio": 1.7433628318584071, "no_speech_prob": 0.004605441819876432}, {"id": 306, "seek": 108684, "start": 1106.84, "end": 1109.84, "text": " It adds no additional latency in that process.", "tokens": [51364, 467, 10860, 572, 4497, 27043, 294, 300, 1399, 13, 51514], "temperature": 0.0, "avg_logprob": -0.13213369161775795, "compression_ratio": 1.7433628318584071, "no_speech_prob": 0.004605441819876432}, {"id": 307, "seek": 108684, "start": 1109.84, "end": 1114.84, "text": " It's only the latency that you decide to put as far as buffering.", "tokens": [51514, 467, 311, 787, 264, 27043, 300, 291, 4536, 281, 829, 382, 1400, 382, 9204, 1794, 13, 51764], "temperature": 0.0, "avg_logprob": -0.13213369161775795, "compression_ratio": 1.7433628318584071, "no_speech_prob": 0.004605441819876432}, {"id": 308, "seek": 111484, "start": 1114.84, "end": 1117.84, "text": " As far as quality and quantity,", "tokens": [50364, 1018, 1400, 382, 3125, 293, 11275, 11, 50514], "temperature": 0.0, "avg_logprob": -0.14145321521944212, "compression_ratio": 1.5182186234817814, "no_speech_prob": 0.001985285896807909}, {"id": 309, "seek": 111484, "start": 1117.84, "end": 1123.84, "text": " the sweet spot seems to be between 3 and 5 megabits per second,", "tokens": [50514, 264, 3844, 4008, 2544, 281, 312, 1296, 805, 293, 1025, 10816, 455, 1208, 680, 1150, 11, 50814], "temperature": 0.0, "avg_logprob": -0.14145321521944212, "compression_ratio": 1.5182186234817814, "no_speech_prob": 0.001985285896807909}, {"id": 310, "seek": 111484, "start": 1123.84, "end": 1127.84, "text": " resolution 720p or 1080p, whatever code you're using", "tokens": [50814, 8669, 40881, 79, 420, 24547, 79, 11, 2035, 3089, 291, 434, 1228, 51014], "temperature": 0.0, "avg_logprob": -0.14145321521944212, "compression_ratio": 1.5182186234817814, "no_speech_prob": 0.001985285896807909}, {"id": 311, "seek": 111484, "start": 1127.84, "end": 1129.84, "text": " gives you better or less quality,", "tokens": [51014, 2709, 291, 1101, 420, 1570, 3125, 11, 51114], "temperature": 0.0, "avg_logprob": -0.14145321521944212, "compression_ratio": 1.5182186234817814, "no_speech_prob": 0.001985285896807909}, {"id": 312, "seek": 111484, "start": 1129.84, "end": 1133.84, "text": " and that seems to traverse all the different VPNs,", "tokens": [51114, 293, 300, 2544, 281, 45674, 439, 264, 819, 24512, 82, 11, 51314], "temperature": 0.0, "avg_logprob": -0.14145321521944212, "compression_ratio": 1.5182186234817814, "no_speech_prob": 0.001985285896807909}, {"id": 313, "seek": 111484, "start": 1133.84, "end": 1136.84, "text": " corporate networks, et cetera, without any issues.", "tokens": [51314, 10896, 9590, 11, 1030, 11458, 11, 1553, 604, 2663, 13, 51464], "temperature": 0.0, "avg_logprob": -0.14145321521944212, "compression_ratio": 1.5182186234817814, "no_speech_prob": 0.001985285896807909}, {"id": 314, "seek": 111484, "start": 1136.84, "end": 1140.84, "text": " Quantity, the RISC2RISC can handle 100 simultaneous connections,", "tokens": [51464, 26968, 507, 11, 264, 497, 2343, 34, 17, 9698, 34, 393, 4813, 2319, 46218, 9271, 11, 51664], "temperature": 0.0, "avg_logprob": -0.14145321521944212, "compression_ratio": 1.5182186234817814, "no_speech_prob": 0.001985285896807909}, {"id": 315, "seek": 111484, "start": 1140.84, "end": 1142.84, "text": " and the number seems low,", "tokens": [51664, 293, 264, 1230, 2544, 2295, 11, 51764], "temperature": 0.0, "avg_logprob": -0.14145321521944212, "compression_ratio": 1.5182186234817814, "no_speech_prob": 0.001985285896807909}, {"id": 316, "seek": 114284, "start": 1142.84, "end": 1144.84, "text": " but because of the threading model", "tokens": [50364, 457, 570, 295, 264, 7207, 278, 2316, 50464], "temperature": 0.0, "avg_logprob": -0.08205858577381481, "compression_ratio": 1.6639676113360324, "no_speech_prob": 0.0012041617883369327}, {"id": 317, "seek": 114284, "start": 1144.84, "end": 1146.84, "text": " and the fact that it has to do retransmissions,", "tokens": [50464, 293, 264, 1186, 300, 309, 575, 281, 360, 23106, 599, 76, 7922, 11, 50564], "temperature": 0.0, "avg_logprob": -0.08205858577381481, "compression_ratio": 1.6639676113360324, "no_speech_prob": 0.0012041617883369327}, {"id": 318, "seek": 114284, "start": 1146.84, "end": 1149.84, "text": " after that the retransmissions get compromised.", "tokens": [50564, 934, 300, 264, 23106, 599, 76, 7922, 483, 32463, 13, 50714], "temperature": 0.0, "avg_logprob": -0.08205858577381481, "compression_ratio": 1.6639676113360324, "no_speech_prob": 0.0012041617883369327}, {"id": 319, "seek": 114284, "start": 1149.84, "end": 1153.84, "text": " The way you scale is that you can instantiate multiple instances", "tokens": [50714, 440, 636, 291, 4373, 307, 300, 291, 393, 9836, 13024, 3866, 14519, 50914], "temperature": 0.0, "avg_logprob": -0.08205858577381481, "compression_ratio": 1.6639676113360324, "no_speech_prob": 0.0012041617883369327}, {"id": 320, "seek": 114284, "start": 1153.84, "end": 1156.84, "text": " of the same RISC2RISC application within the same machine,", "tokens": [50914, 295, 264, 912, 497, 2343, 34, 17, 9698, 34, 3861, 1951, 264, 912, 3479, 11, 51064], "temperature": 0.0, "avg_logprob": -0.08205858577381481, "compression_ratio": 1.6639676113360324, "no_speech_prob": 0.0012041617883369327}, {"id": 321, "seek": 114284, "start": 1156.84, "end": 1161.84, "text": " and in our case, we have 1500 simultaneous viewers", "tokens": [51064, 293, 294, 527, 1389, 11, 321, 362, 22671, 46218, 8499, 51314], "temperature": 0.0, "avg_logprob": -0.08205858577381481, "compression_ratio": 1.6639676113360324, "no_speech_prob": 0.0012041617883369327}, {"id": 322, "seek": 114284, "start": 1161.84, "end": 1166.84, "text": " going off of this type of transmissions 24-7.", "tokens": [51314, 516, 766, 295, 341, 2010, 295, 7715, 7922, 4022, 12, 22, 13, 51564], "temperature": 0.0, "avg_logprob": -0.08205858577381481, "compression_ratio": 1.6639676113360324, "no_speech_prob": 0.0012041617883369327}, {"id": 323, "seek": 114284, "start": 1166.84, "end": 1170.84, "text": " So the RISC password utility is also a command line utility", "tokens": [51564, 407, 264, 497, 2343, 34, 11524, 14877, 307, 611, 257, 5622, 1622, 14877, 51764], "temperature": 0.0, "avg_logprob": -0.08205858577381481, "compression_ratio": 1.6639676113360324, "no_speech_prob": 0.0012041617883369327}, {"id": 324, "seek": 117084, "start": 1170.84, "end": 1174.84, "text": " available on the project that allows you to create", "tokens": [50364, 2435, 322, 264, 1716, 300, 4045, 291, 281, 1884, 50564], "temperature": 0.0, "avg_logprob": -0.09204567273457845, "compression_ratio": 1.801556420233463, "no_speech_prob": 0.006685858126729727}, {"id": 325, "seek": 117084, "start": 1174.84, "end": 1177.84, "text": " the username and password combination hashes,", "tokens": [50564, 264, 30351, 293, 11524, 6562, 575, 8076, 11, 50714], "temperature": 0.0, "avg_logprob": -0.09204567273457845, "compression_ratio": 1.801556420233463, "no_speech_prob": 0.006685858126729727}, {"id": 326, "seek": 117084, "start": 1177.84, "end": 1180.84, "text": " just like the HD password file in Apache has a similar format,", "tokens": [50714, 445, 411, 264, 12149, 11524, 3991, 294, 46597, 575, 257, 2531, 7877, 11, 50864], "temperature": 0.0, "avg_logprob": -0.09204567273457845, "compression_ratio": 1.801556420233463, "no_speech_prob": 0.006685858126729727}, {"id": 327, "seek": 117084, "start": 1180.84, "end": 1182.84, "text": " that's why we created it this way.", "tokens": [50864, 300, 311, 983, 321, 2942, 309, 341, 636, 13, 50964], "temperature": 0.0, "avg_logprob": -0.09204567273457845, "compression_ratio": 1.801556420233463, "no_speech_prob": 0.006685858126729727}, {"id": 328, "seek": 117084, "start": 1182.84, "end": 1185.84, "text": " You run the utility, put a username and password", "tokens": [50964, 509, 1190, 264, 14877, 11, 829, 257, 30351, 293, 11524, 51114], "temperature": 0.0, "avg_logprob": -0.09204567273457845, "compression_ratio": 1.801556420233463, "no_speech_prob": 0.006685858126729727}, {"id": 329, "seek": 117084, "start": 1185.84, "end": 1188.84, "text": " and that outputs this username with a hash,", "tokens": [51114, 293, 300, 23930, 341, 30351, 365, 257, 22019, 11, 51264], "temperature": 0.0, "avg_logprob": -0.09204567273457845, "compression_ratio": 1.801556420233463, "no_speech_prob": 0.006685858126729727}, {"id": 330, "seek": 117084, "start": 1188.84, "end": 1190.84, "text": " and then you append that to a file,", "tokens": [51264, 293, 550, 291, 34116, 300, 281, 257, 3991, 11, 51364], "temperature": 0.0, "avg_logprob": -0.09204567273457845, "compression_ratio": 1.801556420233463, "no_speech_prob": 0.006685858126729727}, {"id": 331, "seek": 117084, "start": 1190.84, "end": 1193.84, "text": " and then the sender can grab that file", "tokens": [51364, 293, 550, 264, 2845, 260, 393, 4444, 300, 3991, 51514], "temperature": 0.0, "avg_logprob": -0.09204567273457845, "compression_ratio": 1.801556420233463, "no_speech_prob": 0.006685858126729727}, {"id": 332, "seek": 117084, "start": 1193.84, "end": 1196.84, "text": " and use it as an authentication database.", "tokens": [51514, 293, 764, 309, 382, 364, 26643, 8149, 13, 51664], "temperature": 0.0, "avg_logprob": -0.09204567273457845, "compression_ratio": 1.801556420233463, "no_speech_prob": 0.006685858126729727}, {"id": 333, "seek": 117084, "start": 1196.84, "end": 1199.84, "text": " In the case you want to scale that to a much higher level,", "tokens": [51664, 682, 264, 1389, 291, 528, 281, 4373, 300, 281, 257, 709, 2946, 1496, 11, 51814], "temperature": 0.0, "avg_logprob": -0.09204567273457845, "compression_ratio": 1.801556420233463, "no_speech_prob": 0.006685858126729727}, {"id": 334, "seek": 119984, "start": 1199.84, "end": 1201.84, "text": " you integrate directly with the library", "tokens": [50364, 291, 13365, 3838, 365, 264, 6405, 50464], "temperature": 0.0, "avg_logprob": -0.17720330771753343, "compression_ratio": 1.7188755020080322, "no_speech_prob": 0.0009998527821153402}, {"id": 335, "seek": 119984, "start": 1201.84, "end": 1204.84, "text": " and you use the library callbacks to do the authentication", "tokens": [50464, 293, 291, 764, 264, 6405, 818, 17758, 281, 360, 264, 26643, 50614], "temperature": 0.0, "avg_logprob": -0.17720330771753343, "compression_ratio": 1.7188755020080322, "no_speech_prob": 0.0009998527821153402}, {"id": 336, "seek": 119984, "start": 1204.84, "end": 1206.84, "text": " yourself against your own databases,", "tokens": [50614, 1803, 1970, 428, 1065, 22380, 11, 50714], "temperature": 0.0, "avg_logprob": -0.17720330771753343, "compression_ratio": 1.7188755020080322, "no_speech_prob": 0.0009998527821153402}, {"id": 337, "seek": 119984, "start": 1206.84, "end": 1209.84, "text": " and you can scale that to thousands of users.", "tokens": [50714, 293, 291, 393, 4373, 300, 281, 5383, 295, 5022, 13, 50864], "temperature": 0.0, "avg_logprob": -0.17720330771753343, "compression_ratio": 1.7188755020080322, "no_speech_prob": 0.0009998527821153402}, {"id": 338, "seek": 119984, "start": 1209.84, "end": 1214.84, "text": " The command line sender is a typical scenario", "tokens": [50864, 440, 5622, 1622, 2845, 260, 307, 257, 7476, 9005, 51114], "temperature": 0.0, "avg_logprob": -0.17720330771753343, "compression_ratio": 1.7188755020080322, "no_speech_prob": 0.0009998527821153402}, {"id": 339, "seek": 119984, "start": 1214.84, "end": 1216.84, "text": " of what I put in the diagram,", "tokens": [51114, 295, 437, 286, 829, 294, 264, 10686, 11, 51214], "temperature": 0.0, "avg_logprob": -0.17720330771753343, "compression_ratio": 1.7188755020080322, "no_speech_prob": 0.0009998527821153402}, {"id": 340, "seek": 119984, "start": 1216.84, "end": 1218.84, "text": " what I was using in the diagram,", "tokens": [51214, 437, 286, 390, 1228, 294, 264, 10686, 11, 51314], "temperature": 0.0, "avg_logprob": -0.17720330771753343, "compression_ratio": 1.7188755020080322, "no_speech_prob": 0.0009998527821153402}, {"id": 341, "seek": 119984, "start": 1218.84, "end": 1221.84, "text": " you put the input any type of UDP stream,", "tokens": [51314, 291, 829, 264, 4846, 604, 2010, 295, 624, 11373, 4309, 11, 51464], "temperature": 0.0, "avg_logprob": -0.17720330771753343, "compression_ratio": 1.7188755020080322, "no_speech_prob": 0.0009998527821153402}, {"id": 342, "seek": 119984, "start": 1221.84, "end": 1224.84, "text": " output you encrypt it, and then the output URL,", "tokens": [51464, 5598, 291, 17972, 662, 309, 11, 293, 550, 264, 5598, 12905, 11, 51614], "temperature": 0.0, "avg_logprob": -0.17720330771753343, "compression_ratio": 1.7188755020080322, "no_speech_prob": 0.0009998527821153402}, {"id": 343, "seek": 119984, "start": 1224.84, "end": 1227.84, "text": " if you look at RISC, is in your column, column,", "tokens": [51614, 498, 291, 574, 412, 497, 2343, 34, 11, 307, 294, 428, 7738, 11, 7738, 11, 51764], "temperature": 0.0, "avg_logprob": -0.17720330771753343, "compression_ratio": 1.7188755020080322, "no_speech_prob": 0.0009998527821153402}, {"id": 344, "seek": 122784, "start": 1227.84, "end": 1229.84, "text": " you add 127, you add the add,", "tokens": [50364, 291, 909, 47561, 11, 291, 909, 264, 909, 11, 50464], "temperature": 0.0, "avg_logprob": -0.15587612787882488, "compression_ratio": 1.684873949579832, "no_speech_prob": 0.0007912102155387402}, {"id": 345, "seek": 122784, "start": 1229.84, "end": 1232.84, "text": " just like you do typically for FFMpeg or VLC", "tokens": [50464, 445, 411, 291, 360, 5850, 337, 479, 37, 44, 494, 70, 420, 691, 14766, 50614], "temperature": 0.0, "avg_logprob": -0.15587612787882488, "compression_ratio": 1.684873949579832, "no_speech_prob": 0.0007912102155387402}, {"id": 346, "seek": 122784, "start": 1232.84, "end": 1235.84, "text": " or that type of stuff, when you want to listen instead of send,", "tokens": [50614, 420, 300, 2010, 295, 1507, 11, 562, 291, 528, 281, 2140, 2602, 295, 2845, 11, 50764], "temperature": 0.0, "avg_logprob": -0.15587612787882488, "compression_ratio": 1.684873949579832, "no_speech_prob": 0.0007912102155387402}, {"id": 347, "seek": 122784, "start": 1235.84, "end": 1237.84, "text": " and it creates a listening on that port,", "tokens": [50764, 293, 309, 7829, 257, 4764, 322, 300, 2436, 11, 50864], "temperature": 0.0, "avg_logprob": -0.15587612787882488, "compression_ratio": 1.684873949579832, "no_speech_prob": 0.0007912102155387402}, {"id": 348, "seek": 122784, "start": 1237.84, "end": 1240.84, "text": " and that's all you would need to do to create a sender", "tokens": [50864, 293, 300, 311, 439, 291, 576, 643, 281, 360, 281, 1884, 257, 2845, 260, 51014], "temperature": 0.0, "avg_logprob": -0.15587612787882488, "compression_ratio": 1.684873949579832, "no_speech_prob": 0.0007912102155387402}, {"id": 349, "seek": 122784, "start": 1240.84, "end": 1244.84, "text": " and use the sender as a really, as well, just for one stream.", "tokens": [51014, 293, 764, 264, 2845, 260, 382, 257, 534, 11, 382, 731, 11, 445, 337, 472, 4309, 13, 51214], "temperature": 0.0, "avg_logprob": -0.15587612787882488, "compression_ratio": 1.684873949579832, "no_speech_prob": 0.0007912102155387402}, {"id": 350, "seek": 122784, "start": 1244.84, "end": 1248.84, "text": " On the receiver side, you want a player, for example,", "tokens": [51214, 1282, 264, 20086, 1252, 11, 291, 528, 257, 4256, 11, 337, 1365, 11, 51414], "temperature": 0.0, "avg_logprob": -0.15587612787882488, "compression_ratio": 1.684873949579832, "no_speech_prob": 0.0007912102155387402}, {"id": 351, "seek": 122784, "start": 1248.84, "end": 1253.84, "text": " that you can put the username and password, right?", "tokens": [51414, 300, 291, 393, 829, 264, 30351, 293, 11524, 11, 558, 30, 51664], "temperature": 0.0, "avg_logprob": -0.15587612787882488, "compression_ratio": 1.684873949579832, "no_speech_prob": 0.0007912102155387402}, {"id": 352, "seek": 125384, "start": 1253.84, "end": 1257.84, "text": " You put the RISC in FFMpeg as the input,", "tokens": [50364, 509, 829, 264, 497, 2343, 34, 294, 479, 37, 44, 494, 70, 382, 264, 4846, 11, 50564], "temperature": 0.0, "avg_logprob": -0.16001162134615102, "compression_ratio": 1.6615384615384616, "no_speech_prob": 0.0018075635889545083}, {"id": 353, "seek": 125384, "start": 1257.84, "end": 1259.84, "text": " RISC, column, forward, slash, forward, slash, et cetera,", "tokens": [50564, 497, 2343, 34, 11, 7738, 11, 2128, 11, 17330, 11, 2128, 11, 17330, 11, 1030, 11458, 11, 50664], "temperature": 0.0, "avg_logprob": -0.16001162134615102, "compression_ratio": 1.6615384615384616, "no_speech_prob": 0.0018075635889545083}, {"id": 354, "seek": 125384, "start": 1259.84, "end": 1262.84, "text": " or VLC, or any one of your choice.", "tokens": [50664, 420, 691, 14766, 11, 420, 604, 472, 295, 428, 3922, 13, 50814], "temperature": 0.0, "avg_logprob": -0.16001162134615102, "compression_ratio": 1.6615384615384616, "no_speech_prob": 0.0018075635889545083}, {"id": 355, "seek": 125384, "start": 1262.84, "end": 1265.84, "text": " In our case, we did a custom VLC application", "tokens": [50814, 682, 527, 1389, 11, 321, 630, 257, 2375, 691, 14766, 3861, 50964], "temperature": 0.0, "avg_logprob": -0.16001162134615102, "compression_ratio": 1.6615384615384616, "no_speech_prob": 0.0018075635889545083}, {"id": 356, "seek": 125384, "start": 1265.84, "end": 1269.84, "text": " inside of Raspberry Pi where we were doing this 1500", "tokens": [50964, 1854, 295, 41154, 17741, 689, 321, 645, 884, 341, 22671, 51164], "temperature": 0.0, "avg_logprob": -0.16001162134615102, "compression_ratio": 1.6615384615384616, "no_speech_prob": 0.0018075635889545083}, {"id": 357, "seek": 125384, "start": 1269.84, "end": 1270.84, "text": " at the same time.", "tokens": [51164, 412, 264, 912, 565, 13, 51214], "temperature": 0.0, "avg_logprob": -0.16001162134615102, "compression_ratio": 1.6615384615384616, "no_speech_prob": 0.0018075635889545083}, {"id": 358, "seek": 125384, "start": 1270.84, "end": 1273.84, "text": " There were Raspberry Pi's running VLC 3.0 inside", "tokens": [51214, 821, 645, 41154, 17741, 311, 2614, 691, 14766, 805, 13, 15, 1854, 51364], "temperature": 0.0, "avg_logprob": -0.16001162134615102, "compression_ratio": 1.6615384615384616, "no_speech_prob": 0.0018075635889545083}, {"id": 359, "seek": 125384, "start": 1273.84, "end": 1277.84, "text": " with a lib-RISC implementation inside.", "tokens": [51364, 365, 257, 22854, 12, 49, 2343, 34, 11420, 1854, 13, 51564], "temperature": 0.0, "avg_logprob": -0.16001162134615102, "compression_ratio": 1.6615384615384616, "no_speech_prob": 0.0018075635889545083}, {"id": 360, "seek": 125384, "start": 1277.84, "end": 1279.84, "text": " The transmission of the secret in this case,", "tokens": [51564, 440, 11574, 295, 264, 4054, 294, 341, 1389, 11, 51664], "temperature": 0.0, "avg_logprob": -0.16001162134615102, "compression_ratio": 1.6615384615384616, "no_speech_prob": 0.0018075635889545083}, {"id": 361, "seek": 125384, "start": 1279.84, "end": 1281.84, "text": " which is a password for the username and password,", "tokens": [51664, 597, 307, 257, 11524, 337, 264, 30351, 293, 11524, 11, 51764], "temperature": 0.0, "avg_logprob": -0.16001162134615102, "compression_ratio": 1.6615384615384616, "no_speech_prob": 0.0018075635889545083}, {"id": 362, "seek": 128184, "start": 1281.84, "end": 1285.84, "text": " should be handled in the same way you share passwords now", "tokens": [50364, 820, 312, 18033, 294, 264, 912, 636, 291, 2073, 33149, 586, 50564], "temperature": 0.0, "avg_logprob": -0.07183372974395752, "compression_ratio": 1.6519823788546255, "no_speech_prob": 0.001753108692355454}, {"id": 363, "seek": 128184, "start": 1285.84, "end": 1289.84, "text": " for any account outside the scope of the protocol,", "tokens": [50564, 337, 604, 2696, 2380, 264, 11923, 295, 264, 10336, 11, 50764], "temperature": 0.0, "avg_logprob": -0.07183372974395752, "compression_ratio": 1.6519823788546255, "no_speech_prob": 0.001753108692355454}, {"id": 364, "seek": 128184, "start": 1289.84, "end": 1290.84, "text": " and that's it.", "tokens": [50764, 293, 300, 311, 309, 13, 50814], "temperature": 0.0, "avg_logprob": -0.07183372974395752, "compression_ratio": 1.6519823788546255, "no_speech_prob": 0.001753108692355454}, {"id": 365, "seek": 128184, "start": 1290.84, "end": 1294.84, "text": " Then it becomes very simple to create a large-scale network", "tokens": [50814, 1396, 309, 3643, 588, 2199, 281, 1884, 257, 2416, 12, 20033, 3209, 51014], "temperature": 0.0, "avg_logprob": -0.07183372974395752, "compression_ratio": 1.6519823788546255, "no_speech_prob": 0.001753108692355454}, {"id": 366, "seek": 128184, "start": 1294.84, "end": 1296.84, "text": " with this.", "tokens": [51014, 365, 341, 13, 51114], "temperature": 0.0, "avg_logprob": -0.07183372974395752, "compression_ratio": 1.6519823788546255, "no_speech_prob": 0.001753108692355454}, {"id": 367, "seek": 128184, "start": 1296.84, "end": 1300.84, "text": " So the summary is the key feature for this", "tokens": [51114, 407, 264, 12691, 307, 264, 2141, 4111, 337, 341, 51314], "temperature": 0.0, "avg_logprob": -0.07183372974395752, "compression_ratio": 1.6519823788546255, "no_speech_prob": 0.001753108692355454}, {"id": 368, "seek": 128184, "start": 1300.84, "end": 1302.84, "text": " is this new type of authentication", "tokens": [51314, 307, 341, 777, 2010, 295, 26643, 51414], "temperature": 0.0, "avg_logprob": -0.07183372974395752, "compression_ratio": 1.6519823788546255, "no_speech_prob": 0.001753108692355454}, {"id": 369, "seek": 128184, "start": 1302.84, "end": 1306.84, "text": " that makes the secure implementation on a large scale,", "tokens": [51414, 300, 1669, 264, 7144, 11420, 322, 257, 2416, 4373, 11, 51614], "temperature": 0.0, "avg_logprob": -0.07183372974395752, "compression_ratio": 1.6519823788546255, "no_speech_prob": 0.001753108692355454}, {"id": 370, "seek": 128184, "start": 1306.84, "end": 1309.84, "text": " and it gives you better latency, lower latency,", "tokens": [51614, 293, 309, 2709, 291, 1101, 27043, 11, 3126, 27043, 11, 51764], "temperature": 0.0, "avg_logprob": -0.07183372974395752, "compression_ratio": 1.6519823788546255, "no_speech_prob": 0.001753108692355454}, {"id": 371, "seek": 130984, "start": 1309.84, "end": 1313.84, "text": " then the equivalent HLS or dash,", "tokens": [50364, 550, 264, 10344, 389, 19198, 420, 8240, 11, 50564], "temperature": 0.0, "avg_logprob": -0.13278752106886643, "compression_ratio": 1.5368421052631578, "no_speech_prob": 0.0015240374486893415}, {"id": 372, "seek": 130984, "start": 1313.84, "end": 1316.84, "text": " with a security model that's built into the protocol.", "tokens": [50564, 365, 257, 3825, 2316, 300, 311, 3094, 666, 264, 10336, 13, 50714], "temperature": 0.0, "avg_logprob": -0.13278752106886643, "compression_ratio": 1.5368421052631578, "no_speech_prob": 0.0015240374486893415}, {"id": 373, "seek": 130984, "start": 1316.84, "end": 1321.84, "text": " It's no longer the browser or the DRM inside the browser,", "tokens": [50714, 467, 311, 572, 2854, 264, 11185, 420, 264, 12118, 44, 1854, 264, 11185, 11, 50964], "temperature": 0.0, "avg_logprob": -0.13278752106886643, "compression_ratio": 1.5368421052631578, "no_speech_prob": 0.0015240374486893415}, {"id": 374, "seek": 130984, "start": 1321.84, "end": 1322.84, "text": " everything.", "tokens": [50964, 1203, 13, 51014], "temperature": 0.0, "avg_logprob": -0.13278752106886643, "compression_ratio": 1.5368421052631578, "no_speech_prob": 0.0015240374486893415}, {"id": 375, "seek": 130984, "start": 1322.84, "end": 1325.84, "text": " It's the protocol handles the entire DRM.", "tokens": [51014, 467, 311, 264, 10336, 18722, 264, 2302, 12118, 44, 13, 51164], "temperature": 0.0, "avg_logprob": -0.13278752106886643, "compression_ratio": 1.5368421052631578, "no_speech_prob": 0.0015240374486893415}, {"id": 376, "seek": 130984, "start": 1328.84, "end": 1334.84, "text": " So we have a really solid roadmap for the future.", "tokens": [51314, 407, 321, 362, 257, 534, 5100, 35738, 337, 264, 2027, 13, 51614], "temperature": 0.0, "avg_logprob": -0.13278752106886643, "compression_ratio": 1.5368421052631578, "no_speech_prob": 0.0015240374486893415}, {"id": 377, "seek": 130984, "start": 1334.84, "end": 1336.84, "text": " We were looking for additional contributors", "tokens": [51614, 492, 645, 1237, 337, 4497, 45627, 51714], "temperature": 0.0, "avg_logprob": -0.13278752106886643, "compression_ratio": 1.5368421052631578, "no_speech_prob": 0.0015240374486893415}, {"id": 378, "seek": 133684, "start": 1336.84, "end": 1340.84, "text": " and people that want to help adding the next set of features.", "tokens": [50364, 293, 561, 300, 528, 281, 854, 5127, 264, 958, 992, 295, 4122, 13, 50564], "temperature": 0.0, "avg_logprob": -0.11520971457163492, "compression_ratio": 1.3846153846153846, "no_speech_prob": 0.006677818484604359}, {"id": 379, "seek": 133684, "start": 1340.84, "end": 1343.84, "text": " We're looking for open-source projects", "tokens": [50564, 492, 434, 1237, 337, 1269, 12, 41676, 4455, 50714], "temperature": 0.0, "avg_logprob": -0.11520971457163492, "compression_ratio": 1.3846153846153846, "no_speech_prob": 0.006677818484604359}, {"id": 380, "seek": 133684, "start": 1343.84, "end": 1345.84, "text": " that want to implement the library.", "tokens": [50714, 300, 528, 281, 4445, 264, 6405, 13, 50814], "temperature": 0.0, "avg_logprob": -0.11520971457163492, "compression_ratio": 1.3846153846153846, "no_speech_prob": 0.006677818484604359}, {"id": 381, "seek": 133684, "start": 1345.84, "end": 1348.84, "text": " We'll help you put it in.", "tokens": [50814, 492, 603, 854, 291, 829, 309, 294, 13, 50964], "temperature": 0.0, "avg_logprob": -0.11520971457163492, "compression_ratio": 1.3846153846153846, "no_speech_prob": 0.006677818484604359}, {"id": 382, "seek": 133684, "start": 1348.84, "end": 1349.84, "text": " And that's it.", "tokens": [50964, 400, 300, 311, 309, 13, 51014], "temperature": 0.0, "avg_logprob": -0.11520971457163492, "compression_ratio": 1.3846153846153846, "no_speech_prob": 0.006677818484604359}, {"id": 383, "seek": 133684, "start": 1349.84, "end": 1351.84, "text": " Thank you very much.", "tokens": [51014, 1044, 291, 588, 709, 13, 51114], "temperature": 0.0, "avg_logprob": -0.11520971457163492, "compression_ratio": 1.3846153846153846, "no_speech_prob": 0.006677818484604359}, {"id": 384, "seek": 135184, "start": 1351.84, "end": 1353.84, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 50464], "temperature": 0.0, "avg_logprob": -0.5189427137374878, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.3665299415588379}, {"id": 385, "seek": 138184, "start": 1382.84, "end": 1386.84, "text": " Okay, the question is, what if you're pushing your stream", "tokens": [50414, 1033, 11, 264, 1168, 307, 11, 437, 498, 291, 434, 7380, 428, 4309, 50614], "temperature": 0.0, "avg_logprob": -0.10154773712158204, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.1186649426817894}, {"id": 386, "seek": 138184, "start": 1386.84, "end": 1389.84, "text": " to Africa with a really bad connection?", "tokens": [50614, 281, 7349, 365, 257, 534, 1578, 4984, 30, 50764], "temperature": 0.0, "avg_logprob": -0.10154773712158204, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.1186649426817894}, {"id": 387, "seek": 138184, "start": 1389.84, "end": 1392.84, "text": " What is the acceptable packet loss?", "tokens": [50764, 708, 307, 264, 15513, 20300, 4470, 30, 50914], "temperature": 0.0, "avg_logprob": -0.10154773712158204, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.1186649426817894}, {"id": 388, "seek": 138184, "start": 1392.84, "end": 1395.84, "text": " I'm not sure what you mean by acceptable packet loss.", "tokens": [50914, 286, 478, 406, 988, 437, 291, 914, 538, 15513, 20300, 4470, 13, 51064], "temperature": 0.0, "avg_logprob": -0.10154773712158204, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.1186649426817894}, {"id": 389, "seek": 138184, "start": 1395.84, "end": 1398.84, "text": " To me, zero is an acceptable packet loss,", "tokens": [51064, 1407, 385, 11, 4018, 307, 364, 15513, 20300, 4470, 11, 51214], "temperature": 0.0, "avg_logprob": -0.10154773712158204, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.1186649426817894}, {"id": 390, "seek": 138184, "start": 1398.84, "end": 1401.84, "text": " and the protocol is capable of achieving zero", "tokens": [51214, 293, 264, 10336, 307, 8189, 295, 19626, 4018, 51364], "temperature": 0.0, "avg_logprob": -0.10154773712158204, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.1186649426817894}, {"id": 391, "seek": 138184, "start": 1401.84, "end": 1403.84, "text": " if you give it enough buffer.", "tokens": [51364, 498, 291, 976, 309, 1547, 21762, 13, 51464], "temperature": 0.0, "avg_logprob": -0.10154773712158204, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.1186649426817894}, {"id": 392, "seek": 138184, "start": 1403.84, "end": 1405.84, "text": " You give it a second buffer,", "tokens": [51464, 509, 976, 309, 257, 1150, 21762, 11, 51564], "temperature": 0.0, "avg_logprob": -0.10154773712158204, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.1186649426817894}, {"id": 393, "seek": 138184, "start": 1405.84, "end": 1408.84, "text": " and the round trip is 200 milliseconds,", "tokens": [51564, 293, 264, 3098, 4931, 307, 2331, 34184, 11, 51714], "temperature": 0.0, "avg_logprob": -0.10154773712158204, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.1186649426817894}, {"id": 394, "seek": 140884, "start": 1408.84, "end": 1411.84, "text": " and you will get zero packet loss.", "tokens": [50364, 293, 291, 486, 483, 4018, 20300, 4470, 13, 50514], "temperature": 0.0, "avg_logprob": -0.11596553439185733, "compression_ratio": 1.6455696202531647, "no_speech_prob": 0.008677023462951183}, {"id": 395, "seek": 140884, "start": 1411.84, "end": 1414.84, "text": " We've done tests and we've done transmissions between Australia.", "tokens": [50514, 492, 600, 1096, 6921, 293, 321, 600, 1096, 7715, 7922, 1296, 7060, 13, 50664], "temperature": 0.0, "avg_logprob": -0.11596553439185733, "compression_ratio": 1.6455696202531647, "no_speech_prob": 0.008677023462951183}, {"id": 396, "seek": 140884, "start": 1414.84, "end": 1416.84, "text": " I was just two weeks ago doing a demo,", "tokens": [50664, 286, 390, 445, 732, 3259, 2057, 884, 257, 10723, 11, 50764], "temperature": 0.0, "avg_logprob": -0.11596553439185733, "compression_ratio": 1.6455696202531647, "no_speech_prob": 0.008677023462951183}, {"id": 397, "seek": 140884, "start": 1416.84, "end": 1420.84, "text": " a transmission from Australia to Madrid.", "tokens": [50764, 257, 11574, 490, 7060, 281, 22091, 13, 50964], "temperature": 0.0, "avg_logprob": -0.11596553439185733, "compression_ratio": 1.6455696202531647, "no_speech_prob": 0.008677023462951183}, {"id": 398, "seek": 140884, "start": 1420.84, "end": 1422.84, "text": " 16 cameras at 10 megabits per second each", "tokens": [50964, 3165, 8622, 412, 1266, 10816, 455, 1208, 680, 1150, 1184, 51064], "temperature": 0.0, "avg_logprob": -0.11596553439185733, "compression_ratio": 1.6455696202531647, "no_speech_prob": 0.008677023462951183}, {"id": 399, "seek": 140884, "start": 1422.84, "end": 1425.84, "text": " were being transmitted in real-time using RISC,", "tokens": [51064, 645, 885, 25355, 294, 957, 12, 3766, 1228, 497, 2343, 34, 11, 51214], "temperature": 0.0, "avg_logprob": -0.11596553439185733, "compression_ratio": 1.6455696202531647, "no_speech_prob": 0.008677023462951183}, {"id": 400, "seek": 140884, "start": 1425.84, "end": 1428.84, "text": " and they were being used in Madrid", "tokens": [51214, 293, 436, 645, 885, 1143, 294, 22091, 51364], "temperature": 0.0, "avg_logprob": -0.11596553439185733, "compression_ratio": 1.6455696202531647, "no_speech_prob": 0.008677023462951183}, {"id": 401, "seek": 140884, "start": 1428.84, "end": 1432.84, "text": " for a production of the event.", "tokens": [51364, 337, 257, 4265, 295, 264, 2280, 13, 51564], "temperature": 0.0, "avg_logprob": -0.11596553439185733, "compression_ratio": 1.6455696202531647, "no_speech_prob": 0.008677023462951183}, {"id": 402, "seek": 140884, "start": 1432.84, "end": 1435.84, "text": " And the transmission didn't have a single packet loss,", "tokens": [51564, 400, 264, 11574, 994, 380, 362, 257, 2167, 20300, 4470, 11, 51714], "temperature": 0.0, "avg_logprob": -0.11596553439185733, "compression_ratio": 1.6455696202531647, "no_speech_prob": 0.008677023462951183}, {"id": 403, "seek": 143584, "start": 1435.84, "end": 1438.84, "text": " and it was all done across open internet.", "tokens": [50364, 293, 309, 390, 439, 1096, 2108, 1269, 4705, 13, 50514], "temperature": 0.0, "avg_logprob": -0.09477540162893441, "compression_ratio": 1.5708661417322836, "no_speech_prob": 0.004896132275462151}, {"id": 404, "seek": 143584, "start": 1438.84, "end": 1440.84, "text": " We used one second buffer there", "tokens": [50514, 492, 1143, 472, 1150, 21762, 456, 50614], "temperature": 0.0, "avg_logprob": -0.09477540162893441, "compression_ratio": 1.5708661417322836, "no_speech_prob": 0.004896132275462151}, {"id": 405, "seek": 143584, "start": 1440.84, "end": 1442.84, "text": " because the connections were relatively good,", "tokens": [50614, 570, 264, 9271, 645, 7226, 665, 11, 50714], "temperature": 0.0, "avg_logprob": -0.09477540162893441, "compression_ratio": 1.5708661417322836, "no_speech_prob": 0.004896132275462151}, {"id": 406, "seek": 143584, "start": 1442.84, "end": 1445.84, "text": " but if you go and, you know,", "tokens": [50714, 457, 498, 291, 352, 293, 11, 291, 458, 11, 50864], "temperature": 0.0, "avg_logprob": -0.09477540162893441, "compression_ratio": 1.5708661417322836, "no_speech_prob": 0.004896132275462151}, {"id": 407, "seek": 143584, "start": 1445.84, "end": 1448.84, "text": " if your transmission is really bad,", "tokens": [50864, 498, 428, 11574, 307, 534, 1578, 11, 51014], "temperature": 0.0, "avg_logprob": -0.09477540162893441, "compression_ratio": 1.5708661417322836, "no_speech_prob": 0.004896132275462151}, {"id": 408, "seek": 143584, "start": 1448.84, "end": 1451.84, "text": " just increase your latency, and the protocol will recover.", "tokens": [51014, 445, 3488, 428, 27043, 11, 293, 264, 10336, 486, 8114, 13, 51164], "temperature": 0.0, "avg_logprob": -0.09477540162893441, "compression_ratio": 1.5708661417322836, "no_speech_prob": 0.004896132275462151}, {"id": 409, "seek": 143584, "start": 1451.84, "end": 1454.84, "text": " We have part of our CI integration process", "tokens": [51164, 492, 362, 644, 295, 527, 37777, 10980, 1399, 51314], "temperature": 0.0, "avg_logprob": -0.09477540162893441, "compression_ratio": 1.5708661417322836, "no_speech_prob": 0.004896132275462151}, {"id": 410, "seek": 143584, "start": 1454.84, "end": 1459.84, "text": " tests that add 50% and even 75% packet loss.", "tokens": [51314, 6921, 300, 909, 2625, 4, 293, 754, 9562, 4, 20300, 4470, 13, 51564], "temperature": 0.0, "avg_logprob": -0.09477540162893441, "compression_ratio": 1.5708661417322836, "no_speech_prob": 0.004896132275462151}, {"id": 411, "seek": 143584, "start": 1459.84, "end": 1461.84, "text": " And you see spikes in bandwidth,", "tokens": [51564, 400, 291, 536, 28997, 294, 23647, 11, 51664], "temperature": 0.0, "avg_logprob": -0.09477540162893441, "compression_ratio": 1.5708661417322836, "no_speech_prob": 0.004896132275462151}, {"id": 412, "seek": 143584, "start": 1461.84, "end": 1463.84, "text": " but we recover every single packet", "tokens": [51664, 457, 321, 8114, 633, 2167, 20300, 51764], "temperature": 0.0, "avg_logprob": -0.09477540162893441, "compression_ratio": 1.5708661417322836, "no_speech_prob": 0.004896132275462151}, {"id": 413, "seek": 146384, "start": 1463.84, "end": 1468.84, "text": " if you give it enough buffer.", "tokens": [50364, 498, 291, 976, 309, 1547, 21762, 13, 50614], "temperature": 0.0, "avg_logprob": -0.09623953375485864, "compression_ratio": 1.7317073170731707, "no_speech_prob": 0.003590430598706007}, {"id": 414, "seek": 146384, "start": 1468.84, "end": 1472.84, "text": " Does it support simultaneous build rates?", "tokens": [50614, 4402, 309, 1406, 46218, 1322, 6846, 30, 50814], "temperature": 0.0, "avg_logprob": -0.09623953375485864, "compression_ratio": 1.7317073170731707, "no_speech_prob": 0.003590430598706007}, {"id": 415, "seek": 146384, "start": 1472.84, "end": 1474.84, "text": " Does it support simultaneous build rates?", "tokens": [50814, 4402, 309, 1406, 46218, 1322, 6846, 30, 50914], "temperature": 0.0, "avg_logprob": -0.09623953375485864, "compression_ratio": 1.7317073170731707, "no_speech_prob": 0.003590430598706007}, {"id": 416, "seek": 146384, "start": 1474.84, "end": 1477.84, "text": " Yes, we support multiplexing.", "tokens": [50914, 1079, 11, 321, 1406, 3311, 2021, 278, 13, 51064], "temperature": 0.0, "avg_logprob": -0.09623953375485864, "compression_ratio": 1.7317073170731707, "no_speech_prob": 0.003590430598706007}, {"id": 417, "seek": 146384, "start": 1477.84, "end": 1481.84, "text": " In all this example, I've done just one UDP input.", "tokens": [51064, 682, 439, 341, 1365, 11, 286, 600, 1096, 445, 472, 624, 11373, 4846, 13, 51264], "temperature": 0.0, "avg_logprob": -0.09623953375485864, "compression_ratio": 1.7317073170731707, "no_speech_prob": 0.003590430598706007}, {"id": 418, "seek": 146384, "start": 1481.84, "end": 1484.84, "text": " You can configure the library and the command lines", "tokens": [51264, 509, 393, 22162, 264, 6405, 293, 264, 5622, 3876, 51414], "temperature": 0.0, "avg_logprob": -0.09623953375485864, "compression_ratio": 1.7317073170731707, "no_speech_prob": 0.003590430598706007}, {"id": 419, "seek": 146384, "start": 1484.84, "end": 1487.84, "text": " to ingest multiple UDP inputs,", "tokens": [51414, 281, 3957, 377, 3866, 624, 11373, 15743, 11, 51564], "temperature": 0.0, "avg_logprob": -0.09623953375485864, "compression_ratio": 1.7317073170731707, "no_speech_prob": 0.003590430598706007}, {"id": 420, "seek": 146384, "start": 1487.84, "end": 1489.84, "text": " give it a different ID,", "tokens": [51564, 976, 309, 257, 819, 7348, 11, 51664], "temperature": 0.0, "avg_logprob": -0.09623953375485864, "compression_ratio": 1.7317073170731707, "no_speech_prob": 0.003590430598706007}, {"id": 421, "seek": 146384, "start": 1489.84, "end": 1491.84, "text": " and then on the other side, you can demultiplex them.", "tokens": [51664, 293, 550, 322, 264, 661, 1252, 11, 291, 393, 1371, 723, 647, 2021, 552, 13, 51764], "temperature": 0.0, "avg_logprob": -0.09623953375485864, "compression_ratio": 1.7317073170731707, "no_speech_prob": 0.003590430598706007}, {"id": 422, "seek": 149184, "start": 1491.84, "end": 1493.84, "text": " I assume that's what you mean by maybe having", "tokens": [50364, 286, 6552, 300, 311, 437, 291, 914, 538, 1310, 1419, 50464], "temperature": 0.0, "avg_logprob": -0.21027901352092784, "compression_ratio": 1.5793991416309012, "no_speech_prob": 0.004455833695828915}, {"id": 423, "seek": 149184, "start": 1493.84, "end": 1495.84, "text": " different build rates within the same stream.", "tokens": [50464, 819, 1322, 6846, 1951, 264, 912, 4309, 13, 50564], "temperature": 0.0, "avg_logprob": -0.21027901352092784, "compression_ratio": 1.5793991416309012, "no_speech_prob": 0.004455833695828915}, {"id": 424, "seek": 149184, "start": 1495.84, "end": 1499.84, "text": " The camera, like, sends it on the fly", "tokens": [50564, 440, 2799, 11, 411, 11, 14790, 309, 322, 264, 3603, 50764], "temperature": 0.0, "avg_logprob": -0.21027901352092784, "compression_ratio": 1.5793991416309012, "no_speech_prob": 0.004455833695828915}, {"id": 425, "seek": 149184, "start": 1499.84, "end": 1502.84, "text": " according to network to the combination?", "tokens": [50764, 4650, 281, 3209, 281, 264, 6562, 30, 50914], "temperature": 0.0, "avg_logprob": -0.21027901352092784, "compression_ratio": 1.5793991416309012, "no_speech_prob": 0.004455833695828915}, {"id": 426, "seek": 149184, "start": 1502.84, "end": 1506.84, "text": " Correct, yes.", "tokens": [50914, 12753, 11, 2086, 13, 51114], "temperature": 0.0, "avg_logprob": -0.21027901352092784, "compression_ratio": 1.5793991416309012, "no_speech_prob": 0.004455833695828915}, {"id": 427, "seek": 149184, "start": 1506.84, "end": 1508.84, "text": " And one of the specifications that you saw", "tokens": [51114, 400, 472, 295, 264, 29448, 300, 291, 1866, 51214], "temperature": 0.0, "avg_logprob": -0.21027901352092784, "compression_ratio": 1.5793991416309012, "no_speech_prob": 0.004455833695828915}, {"id": 428, "seek": 149184, "start": 1508.84, "end": 1512.84, "text": " on the recommendations was called source adaptation.", "tokens": [51214, 322, 264, 10434, 390, 1219, 4009, 21549, 13, 51414], "temperature": 0.0, "avg_logprob": -0.21027901352092784, "compression_ratio": 1.5793991416309012, "no_speech_prob": 0.004455833695828915}, {"id": 429, "seek": 149184, "start": 1512.84, "end": 1515.84, "text": " It was written precisely to accommodate that scenario.", "tokens": [51414, 467, 390, 3720, 13402, 281, 21410, 300, 9005, 13, 51564], "temperature": 0.0, "avg_logprob": -0.21027901352092784, "compression_ratio": 1.5793991416309012, "no_speech_prob": 0.004455833695828915}, {"id": 430, "seek": 149184, "start": 1515.84, "end": 1518.84, "text": " What is the best case, best use,", "tokens": [51564, 708, 307, 264, 1151, 1389, 11, 1151, 764, 11, 51714], "temperature": 0.0, "avg_logprob": -0.21027901352092784, "compression_ratio": 1.5793991416309012, "no_speech_prob": 0.004455833695828915}, {"id": 431, "seek": 151884, "start": 1518.84, "end": 1521.84, "text": " or the best practice recommendation", "tokens": [50364, 420, 264, 1151, 3124, 11879, 50514], "temperature": 0.0, "avg_logprob": -0.257319480494449, "compression_ratio": 1.502183406113537, "no_speech_prob": 0.003939860034734011}, {"id": 432, "seek": 151884, "start": 1521.84, "end": 1524.84, "text": " on how to do source adaptation?", "tokens": [50514, 322, 577, 281, 360, 4009, 21549, 30, 50664], "temperature": 0.0, "avg_logprob": -0.257319480494449, "compression_ratio": 1.502183406113537, "no_speech_prob": 0.003939860034734011}, {"id": 433, "seek": 151884, "start": 1524.84, "end": 1526.84, "text": " Reduce the build rate, adjust the build rate", "tokens": [50664, 4477, 4176, 264, 1322, 3314, 11, 4369, 264, 1322, 3314, 50764], "temperature": 0.0, "avg_logprob": -0.257319480494449, "compression_ratio": 1.502183406113537, "no_speech_prob": 0.003939860034734011}, {"id": 434, "seek": 151884, "start": 1526.84, "end": 1528.84, "text": " based on network conditions.", "tokens": [50764, 2361, 322, 3209, 4487, 13, 50864], "temperature": 0.0, "avg_logprob": -0.257319480494449, "compression_ratio": 1.502183406113537, "no_speech_prob": 0.003939860034734011}, {"id": 435, "seek": 151884, "start": 1528.84, "end": 1534.84, "text": " It's all documented in a part of a spec as well.", "tokens": [50864, 467, 311, 439, 23007, 294, 257, 644, 295, 257, 1608, 382, 731, 13, 51164], "temperature": 0.0, "avg_logprob": -0.257319480494449, "compression_ratio": 1.502183406113537, "no_speech_prob": 0.003939860034734011}, {"id": 436, "seek": 151884, "start": 1534.84, "end": 1538.84, "text": " So for non-MPEC-PS payloads,", "tokens": [51164, 407, 337, 2107, 12, 44, 5208, 34, 12, 6273, 30918, 82, 11, 51364], "temperature": 0.0, "avg_logprob": -0.257319480494449, "compression_ratio": 1.502183406113537, "no_speech_prob": 0.003939860034734011}, {"id": 437, "seek": 151884, "start": 1538.84, "end": 1539.84, "text": " as you mentioned,", "tokens": [51364, 382, 291, 2835, 11, 51414], "temperature": 0.0, "avg_logprob": -0.257319480494449, "compression_ratio": 1.502183406113537, "no_speech_prob": 0.003939860034734011}, {"id": 438, "seek": 151884, "start": 1539.84, "end": 1542.84, "text": " is there already a mechanism like a composite trail", "tokens": [51414, 307, 456, 1217, 257, 7513, 411, 257, 25557, 9924, 51564], "temperature": 0.0, "avg_logprob": -0.257319480494449, "compression_ratio": 1.502183406113537, "no_speech_prob": 0.003939860034734011}, {"id": 439, "seek": 151884, "start": 1542.84, "end": 1546.84, "text": " to basically define the mapping of different payloads?", "tokens": [51564, 281, 1936, 6964, 264, 18350, 295, 819, 30918, 82, 30, 51764], "temperature": 0.0, "avg_logprob": -0.257319480494449, "compression_ratio": 1.502183406113537, "no_speech_prob": 0.003939860034734011}, {"id": 440, "seek": 154684, "start": 1546.84, "end": 1547.84, "text": " Absolutely.", "tokens": [50364, 7021, 13, 50414], "temperature": 0.0, "avg_logprob": -0.11757285722339426, "compression_ratio": 1.78515625, "no_speech_prob": 0.0041935034096241}, {"id": 441, "seek": 154684, "start": 1547.84, "end": 1549.84, "text": " For advanced profile, there's a GitHub repository", "tokens": [50414, 1171, 7339, 7964, 11, 456, 311, 257, 23331, 25841, 50514], "temperature": 0.0, "avg_logprob": -0.11757285722339426, "compression_ratio": 1.78515625, "no_speech_prob": 0.0041935034096241}, {"id": 442, "seek": 154684, "start": 1549.84, "end": 1550.84, "text": " that has the mappings already.", "tokens": [50514, 300, 575, 264, 463, 28968, 1217, 13, 50564], "temperature": 0.0, "avg_logprob": -0.11757285722339426, "compression_ratio": 1.78515625, "no_speech_prob": 0.0041935034096241}, {"id": 443, "seek": 154684, "start": 1550.84, "end": 1553.84, "text": " We have a dozen or two dozen of them.", "tokens": [50564, 492, 362, 257, 16654, 420, 732, 16654, 295, 552, 13, 50714], "temperature": 0.0, "avg_logprob": -0.11757285722339426, "compression_ratio": 1.78515625, "no_speech_prob": 0.0041935034096241}, {"id": 444, "seek": 154684, "start": 1553.84, "end": 1556.84, "text": " I'm one of the administrators of the repository.", "tokens": [50714, 286, 478, 472, 295, 264, 27754, 295, 264, 25841, 13, 50864], "temperature": 0.0, "avg_logprob": -0.11757285722339426, "compression_ratio": 1.78515625, "no_speech_prob": 0.0041935034096241}, {"id": 445, "seek": 154684, "start": 1556.84, "end": 1558.84, "text": " All you need to do is go in and, you know,", "tokens": [50864, 1057, 291, 643, 281, 360, 307, 352, 294, 293, 11, 291, 458, 11, 50964], "temperature": 0.0, "avg_logprob": -0.11757285722339426, "compression_ratio": 1.78515625, "no_speech_prob": 0.0041935034096241}, {"id": 446, "seek": 154684, "start": 1558.84, "end": 1562.84, "text": " put an MR for whatever binary payload you want to define.", "tokens": [50964, 829, 364, 9808, 337, 2035, 17434, 30918, 291, 528, 281, 6964, 13, 51164], "temperature": 0.0, "avg_logprob": -0.11757285722339426, "compression_ratio": 1.78515625, "no_speech_prob": 0.0041935034096241}, {"id": 447, "seek": 154684, "start": 1562.84, "end": 1564.84, "text": " All right, thank you.", "tokens": [51164, 1057, 558, 11, 1309, 291, 13, 51264], "temperature": 0.0, "avg_logprob": -0.11757285722339426, "compression_ratio": 1.78515625, "no_speech_prob": 0.0041935034096241}, {"id": 448, "seek": 154684, "start": 1564.84, "end": 1566.84, "text": " I have another question here.", "tokens": [51264, 286, 362, 1071, 1168, 510, 13, 51364], "temperature": 0.0, "avg_logprob": -0.11757285722339426, "compression_ratio": 1.78515625, "no_speech_prob": 0.0041935034096241}, {"id": 449, "seek": 154684, "start": 1566.84, "end": 1570.84, "text": " Is it also possible to multiplex and demultiplex subtitles?", "tokens": [51364, 1119, 309, 611, 1944, 281, 3311, 2021, 293, 1371, 723, 647, 2021, 42045, 30, 51564], "temperature": 0.0, "avg_logprob": -0.11757285722339426, "compression_ratio": 1.78515625, "no_speech_prob": 0.0041935034096241}, {"id": 450, "seek": 154684, "start": 1570.84, "end": 1573.84, "text": " Is it also possible to multiplex and demultiplex subtitles?", "tokens": [51564, 1119, 309, 611, 1944, 281, 3311, 2021, 293, 1371, 723, 647, 2021, 42045, 30, 51714], "temperature": 0.0, "avg_logprob": -0.11757285722339426, "compression_ratio": 1.78515625, "no_speech_prob": 0.0041935034096241}, {"id": 451, "seek": 154684, "start": 1573.84, "end": 1574.84, "text": " Yes.", "tokens": [51714, 1079, 13, 51764], "temperature": 0.0, "avg_logprob": -0.11757285722339426, "compression_ratio": 1.78515625, "no_speech_prob": 0.0041935034096241}, {"id": 452, "seek": 157484, "start": 1574.84, "end": 1577.84, "text": " The protocol itself doesn't care what you put in.", "tokens": [50364, 440, 10336, 2564, 1177, 380, 1127, 437, 291, 829, 294, 13, 50514], "temperature": 0.0, "avg_logprob": -0.072583726474217, "compression_ratio": 1.7196652719665273, "no_speech_prob": 0.004130399785935879}, {"id": 453, "seek": 157484, "start": 1577.84, "end": 1581.84, "text": " We consider each of them as a binary payload of some sort.", "tokens": [50514, 492, 1949, 1184, 295, 552, 382, 257, 17434, 30918, 295, 512, 1333, 13, 50714], "temperature": 0.0, "avg_logprob": -0.072583726474217, "compression_ratio": 1.7196652719665273, "no_speech_prob": 0.004130399785935879}, {"id": 454, "seek": 157484, "start": 1581.84, "end": 1585.84, "text": " You're the one that determines what the format of that payload is.", "tokens": [50714, 509, 434, 264, 472, 300, 24799, 437, 264, 7877, 295, 300, 30918, 307, 13, 50914], "temperature": 0.0, "avg_logprob": -0.072583726474217, "compression_ratio": 1.7196652719665273, "no_speech_prob": 0.004130399785935879}, {"id": 455, "seek": 157484, "start": 1585.84, "end": 1587.84, "text": " And you have this pipe.", "tokens": [50914, 400, 291, 362, 341, 11240, 13, 51014], "temperature": 0.0, "avg_logprob": -0.072583726474217, "compression_ratio": 1.7196652719665273, "no_speech_prob": 0.004130399785935879}, {"id": 456, "seek": 157484, "start": 1587.84, "end": 1589.84, "text": " You put multiple UDP streams.", "tokens": [51014, 509, 829, 3866, 624, 11373, 15842, 13, 51114], "temperature": 0.0, "avg_logprob": -0.072583726474217, "compression_ratio": 1.7196652719665273, "no_speech_prob": 0.004130399785935879}, {"id": 457, "seek": 157484, "start": 1589.84, "end": 1592.84, "text": " One of them is going to be your VTT payload", "tokens": [51114, 1485, 295, 552, 307, 516, 281, 312, 428, 691, 28178, 30918, 51264], "temperature": 0.0, "avg_logprob": -0.072583726474217, "compression_ratio": 1.7196652719665273, "no_speech_prob": 0.004130399785935879}, {"id": 458, "seek": 157484, "start": 1592.84, "end": 1595.84, "text": " or closed caption or whatever you want to put in", "tokens": [51264, 420, 5395, 31974, 420, 2035, 291, 528, 281, 829, 294, 51414], "temperature": 0.0, "avg_logprob": -0.072583726474217, "compression_ratio": 1.7196652719665273, "no_speech_prob": 0.004130399785935879}, {"id": 459, "seek": 157484, "start": 1595.84, "end": 1597.84, "text": " with whatever format you want.", "tokens": [51414, 365, 2035, 7877, 291, 528, 13, 51514], "temperature": 0.0, "avg_logprob": -0.072583726474217, "compression_ratio": 1.7196652719665273, "no_speech_prob": 0.004130399785935879}, {"id": 460, "seek": 157484, "start": 1597.84, "end": 1602.84, "text": " We don't define or control the format of what you put in.", "tokens": [51514, 492, 500, 380, 6964, 420, 1969, 264, 7877, 295, 437, 291, 829, 294, 13, 51764], "temperature": 0.0, "avg_logprob": -0.072583726474217, "compression_ratio": 1.7196652719665273, "no_speech_prob": 0.004130399785935879}, {"id": 461, "seek": 160284, "start": 1602.84, "end": 1604.84, "text": " We do to decide on multiplex and mulling.", "tokens": [50364, 492, 360, 281, 4536, 322, 3311, 2021, 293, 275, 858, 278, 13, 50464], "temperature": 0.0, "avg_logprob": -0.19384385657122755, "compression_ratio": 1.6761133603238867, "no_speech_prob": 0.010633019730448723}, {"id": 462, "seek": 160284, "start": 1604.84, "end": 1607.84, "text": " We give you the capability to give them IDs", "tokens": [50464, 492, 976, 291, 264, 13759, 281, 976, 552, 48212, 50614], "temperature": 0.0, "avg_logprob": -0.19384385657122755, "compression_ratio": 1.6761133603238867, "no_speech_prob": 0.010633019730448723}, {"id": 463, "seek": 160284, "start": 1607.84, "end": 1609.84, "text": " so that in the other side you can map those IDs", "tokens": [50614, 370, 300, 294, 264, 661, 1252, 291, 393, 4471, 729, 48212, 50714], "temperature": 0.0, "avg_logprob": -0.19384385657122755, "compression_ratio": 1.6761133603238867, "no_speech_prob": 0.010633019730448723}, {"id": 464, "seek": 160284, "start": 1609.84, "end": 1612.84, "text": " to different outputs when it comes out.", "tokens": [50714, 281, 819, 23930, 562, 309, 1487, 484, 13, 50864], "temperature": 0.0, "avg_logprob": -0.19384385657122755, "compression_ratio": 1.6761133603238867, "no_speech_prob": 0.010633019730448723}, {"id": 465, "seek": 160284, "start": 1612.84, "end": 1614.84, "text": " Thank you.", "tokens": [50864, 1044, 291, 13, 50964], "temperature": 0.0, "avg_logprob": -0.19384385657122755, "compression_ratio": 1.6761133603238867, "no_speech_prob": 0.010633019730448723}, {"id": 466, "seek": 160284, "start": 1614.84, "end": 1617.84, "text": " But it means that you don't do any timing, right?", "tokens": [50964, 583, 309, 1355, 300, 291, 500, 380, 360, 604, 10822, 11, 558, 30, 51114], "temperature": 0.0, "avg_logprob": -0.19384385657122755, "compression_ratio": 1.6761133603238867, "no_speech_prob": 0.010633019730448723}, {"id": 467, "seek": 160284, "start": 1617.84, "end": 1619.84, "text": " In between the different streams.", "tokens": [51114, 682, 1296, 264, 819, 15842, 13, 51214], "temperature": 0.0, "avg_logprob": -0.19384385657122755, "compression_ratio": 1.6761133603238867, "no_speech_prob": 0.010633019730448723}, {"id": 468, "seek": 160284, "start": 1619.84, "end": 1620.84, "text": " That's all user-side.", "tokens": [51214, 663, 311, 439, 4195, 12, 1812, 13, 51264], "temperature": 0.0, "avg_logprob": -0.19384385657122755, "compression_ratio": 1.6761133603238867, "no_speech_prob": 0.010633019730448723}, {"id": 469, "seek": 160284, "start": 1620.84, "end": 1621.84, "text": " Well, no.", "tokens": [51264, 1042, 11, 572, 13, 51314], "temperature": 0.0, "avg_logprob": -0.19384385657122755, "compression_ratio": 1.6761133603238867, "no_speech_prob": 0.010633019730448723}, {"id": 470, "seek": 160284, "start": 1621.84, "end": 1623.84, "text": " When you give us...", "tokens": [51314, 1133, 291, 976, 505, 485, 51414], "temperature": 0.0, "avg_logprob": -0.19384385657122755, "compression_ratio": 1.6761133603238867, "no_speech_prob": 0.010633019730448723}, {"id": 471, "seek": 160284, "start": 1623.84, "end": 1625.84, "text": " The question is,", "tokens": [51414, 440, 1168, 307, 11, 51514], "temperature": 0.0, "avg_logprob": -0.19384385657122755, "compression_ratio": 1.6761133603238867, "no_speech_prob": 0.010633019730448723}, {"id": 472, "seek": 160284, "start": 1625.84, "end": 1628.84, "text": " that means that you don't do any timing or synchronization.", "tokens": [51514, 300, 1355, 300, 291, 500, 380, 360, 604, 10822, 420, 19331, 2144, 13, 51664], "temperature": 0.0, "avg_logprob": -0.19384385657122755, "compression_ratio": 1.6761133603238867, "no_speech_prob": 0.010633019730448723}, {"id": 473, "seek": 160284, "start": 1628.84, "end": 1629.84, "text": " On the contrary,", "tokens": [51664, 1282, 264, 19506, 11, 51714], "temperature": 0.0, "avg_logprob": -0.19384385657122755, "compression_ratio": 1.6761133603238867, "no_speech_prob": 0.010633019730448723}, {"id": 474, "seek": 162984, "start": 1629.84, "end": 1632.84, "text": " because we are taking care of the multiplexing,", "tokens": [50364, 570, 321, 366, 1940, 1127, 295, 264, 3311, 2021, 278, 11, 50514], "temperature": 0.0, "avg_logprob": -0.08489329414030092, "compression_ratio": 1.7705627705627707, "no_speech_prob": 0.00381783046759665}, {"id": 475, "seek": 162984, "start": 1632.84, "end": 1635.84, "text": " when we ingest all the different UDP streams,", "tokens": [50514, 562, 321, 3957, 377, 439, 264, 819, 624, 11373, 15842, 11, 50664], "temperature": 0.0, "avg_logprob": -0.08489329414030092, "compression_ratio": 1.7705627705627707, "no_speech_prob": 0.00381783046759665}, {"id": 476, "seek": 162984, "start": 1635.84, "end": 1637.84, "text": " the timing is guaranteed.", "tokens": [50664, 264, 10822, 307, 18031, 13, 50764], "temperature": 0.0, "avg_logprob": -0.08489329414030092, "compression_ratio": 1.7705627705627707, "no_speech_prob": 0.00381783046759665}, {"id": 477, "seek": 162984, "start": 1637.84, "end": 1639.84, "text": " The minute we receive that UDP stream,", "tokens": [50764, 440, 3456, 321, 4774, 300, 624, 11373, 4309, 11, 50864], "temperature": 0.0, "avg_logprob": -0.08489329414030092, "compression_ratio": 1.7705627705627707, "no_speech_prob": 0.00381783046759665}, {"id": 478, "seek": 162984, "start": 1639.84, "end": 1642.84, "text": " we actually, in the library, the implementation that we did,", "tokens": [50864, 321, 767, 11, 294, 264, 6405, 11, 264, 11420, 300, 321, 630, 11, 51014], "temperature": 0.0, "avg_logprob": -0.08489329414030092, "compression_ratio": 1.7705627705627707, "no_speech_prob": 0.00381783046759665}, {"id": 479, "seek": 162984, "start": 1642.84, "end": 1644.84, "text": " we grab the timestamp at the network card.", "tokens": [51014, 321, 4444, 264, 49108, 1215, 412, 264, 3209, 2920, 13, 51114], "temperature": 0.0, "avg_logprob": -0.08489329414030092, "compression_ratio": 1.7705627705627707, "no_speech_prob": 0.00381783046759665}, {"id": 480, "seek": 162984, "start": 1644.84, "end": 1648.84, "text": " This stream came in at this time,", "tokens": [51114, 639, 4309, 1361, 294, 412, 341, 565, 11, 51314], "temperature": 0.0, "avg_logprob": -0.08489329414030092, "compression_ratio": 1.7705627705627707, "no_speech_prob": 0.00381783046759665}, {"id": 481, "seek": 162984, "start": 1648.84, "end": 1652.84, "text": " and then we reproduce that exact timing on the other end.", "tokens": [51314, 293, 550, 321, 29501, 300, 1900, 10822, 322, 264, 661, 917, 13, 51514], "temperature": 0.0, "avg_logprob": -0.08489329414030092, "compression_ratio": 1.7705627705627707, "no_speech_prob": 0.00381783046759665}, {"id": 482, "seek": 162984, "start": 1652.84, "end": 1654.84, "text": " We reproduce the spacing, the pacing,", "tokens": [51514, 492, 29501, 264, 27739, 11, 264, 43285, 11, 51614], "temperature": 0.0, "avg_logprob": -0.08489329414030092, "compression_ratio": 1.7705627705627707, "no_speech_prob": 0.00381783046759665}, {"id": 483, "seek": 162984, "start": 1654.84, "end": 1656.84, "text": " and the latency.", "tokens": [51614, 293, 264, 27043, 13, 51714], "temperature": 0.0, "avg_logprob": -0.08489329414030092, "compression_ratio": 1.7705627705627707, "no_speech_prob": 0.00381783046759665}, {"id": 484, "seek": 165684, "start": 1656.84, "end": 1659.84, "text": " We make it fixed, so that is not variable.", "tokens": [50364, 492, 652, 309, 6806, 11, 370, 300, 307, 406, 7006, 13, 50514], "temperature": 0.0, "avg_logprob": -0.23289440075556436, "compression_ratio": 1.6214953271028036, "no_speech_prob": 0.007435468025505543}, {"id": 485, "seek": 165684, "start": 1659.84, "end": 1662.84, "text": " That means that when you multiplex many things", "tokens": [50514, 663, 1355, 300, 562, 291, 3311, 2021, 867, 721, 50664], "temperature": 0.0, "avg_logprob": -0.23289440075556436, "compression_ratio": 1.6214953271028036, "no_speech_prob": 0.007435468025505543}, {"id": 486, "seek": 165684, "start": 1662.84, "end": 1663.84, "text": " in the same tunnel,", "tokens": [50664, 294, 264, 912, 13186, 11, 50714], "temperature": 0.0, "avg_logprob": -0.23289440075556436, "compression_ratio": 1.6214953271028036, "no_speech_prob": 0.007435468025505543}, {"id": 487, "seek": 165684, "start": 1663.84, "end": 1665.84, "text": " you're guaranteed they're in sync on the other side,", "tokens": [50714, 291, 434, 18031, 436, 434, 294, 20271, 322, 264, 661, 1252, 11, 50814], "temperature": 0.0, "avg_logprob": -0.23289440075556436, "compression_ratio": 1.6214953271028036, "no_speech_prob": 0.007435468025505543}, {"id": 488, "seek": 165684, "start": 1665.84, "end": 1668.84, "text": " or at least as they were when they came in.", "tokens": [50814, 420, 412, 1935, 382, 436, 645, 562, 436, 1361, 294, 13, 50964], "temperature": 0.0, "avg_logprob": -0.23289440075556436, "compression_ratio": 1.6214953271028036, "no_speech_prob": 0.007435468025505543}, {"id": 489, "seek": 165684, "start": 1673.84, "end": 1676.84, "text": " We're starting the use cases of the protocols", "tokens": [51214, 492, 434, 2891, 264, 764, 3331, 295, 264, 20618, 51364], "temperature": 0.0, "avg_logprob": -0.23289440075556436, "compression_ratio": 1.6214953271028036, "no_speech_prob": 0.007435468025505543}, {"id": 490, "seek": 165684, "start": 1676.84, "end": 1678.84, "text": " to the more for...", "tokens": [51364, 281, 264, 544, 337, 485, 51464], "temperature": 0.0, "avg_logprob": -0.23289440075556436, "compression_ratio": 1.6214953271028036, "no_speech_prob": 0.007435468025505543}, {"id": 491, "seek": 165684, "start": 1678.84, "end": 1681.84, "text": " kind of the current adoption on endpoint devices,", "tokens": [51464, 733, 295, 264, 2190, 19215, 322, 35795, 5759, 11, 51614], "temperature": 0.0, "avg_logprob": -0.23289440075556436, "compression_ratio": 1.6214953271028036, "no_speech_prob": 0.007435468025505543}, {"id": 492, "seek": 165684, "start": 1681.84, "end": 1684.84, "text": " mobile devices, browsers.", "tokens": [51614, 6013, 5759, 11, 36069, 13, 51764], "temperature": 0.0, "avg_logprob": -0.23289440075556436, "compression_ratio": 1.6214953271028036, "no_speech_prob": 0.007435468025505543}, {"id": 493, "seek": 168484, "start": 1685.84, "end": 1688.84, "text": " Okay, the question is,", "tokens": [50414, 1033, 11, 264, 1168, 307, 11, 50564], "temperature": 0.0, "avg_logprob": -0.13013146881364349, "compression_ratio": 1.7194570135746607, "no_speech_prob": 0.000543845584616065}, {"id": 494, "seek": 168484, "start": 1688.84, "end": 1690.84, "text": " the use cases of the protocol,", "tokens": [50564, 264, 764, 3331, 295, 264, 10336, 11, 50664], "temperature": 0.0, "avg_logprob": -0.13013146881364349, "compression_ratio": 1.7194570135746607, "no_speech_prob": 0.000543845584616065}, {"id": 495, "seek": 168484, "start": 1690.84, "end": 1692.84, "text": " what is it towards more,", "tokens": [50664, 437, 307, 309, 3030, 544, 11, 50764], "temperature": 0.0, "avg_logprob": -0.13013146881364349, "compression_ratio": 1.7194570135746607, "no_speech_prob": 0.000543845584616065}, {"id": 496, "seek": 168484, "start": 1692.84, "end": 1693.84, "text": " point-to-point devices,", "tokens": [50764, 935, 12, 1353, 12, 6053, 5759, 11, 50814], "temperature": 0.0, "avg_logprob": -0.13013146881364349, "compression_ratio": 1.7194570135746607, "no_speech_prob": 0.000543845584616065}, {"id": 497, "seek": 168484, "start": 1693.84, "end": 1696.84, "text": " point-to-multipoint, browsers, etc.", "tokens": [50814, 935, 12, 1353, 12, 76, 723, 647, 3600, 11, 36069, 11, 5183, 13, 50964], "temperature": 0.0, "avg_logprob": -0.13013146881364349, "compression_ratio": 1.7194570135746607, "no_speech_prob": 0.000543845584616065}, {"id": 498, "seek": 168484, "start": 1696.84, "end": 1698.84, "text": " This is the last question of our time.", "tokens": [50964, 639, 307, 264, 1036, 1168, 295, 527, 565, 13, 51064], "temperature": 0.0, "avg_logprob": -0.13013146881364349, "compression_ratio": 1.7194570135746607, "no_speech_prob": 0.000543845584616065}, {"id": 499, "seek": 168484, "start": 1698.84, "end": 1703.84, "text": " The original idea was to just do point-to-point transmissions.", "tokens": [51064, 440, 3380, 1558, 390, 281, 445, 360, 935, 12, 1353, 12, 6053, 7715, 7922, 13, 51314], "temperature": 0.0, "avg_logprob": -0.13013146881364349, "compression_ratio": 1.7194570135746607, "no_speech_prob": 0.000543845584616065}, {"id": 500, "seek": 168484, "start": 1703.84, "end": 1705.84, "text": " That was the original scope", "tokens": [51314, 663, 390, 264, 3380, 11923, 51414], "temperature": 0.0, "avg_logprob": -0.13013146881364349, "compression_ratio": 1.7194570135746607, "no_speech_prob": 0.000543845584616065}, {"id": 501, "seek": 168484, "start": 1705.84, "end": 1708.84, "text": " when we created the first version of the spec.", "tokens": [51414, 562, 321, 2942, 264, 700, 3037, 295, 264, 1608, 13, 51564], "temperature": 0.0, "avg_logprob": -0.13013146881364349, "compression_ratio": 1.7194570135746607, "no_speech_prob": 0.000543845584616065}, {"id": 502, "seek": 168484, "start": 1708.84, "end": 1709.84, "text": " That has changed.", "tokens": [51564, 663, 575, 3105, 13, 51614], "temperature": 0.0, "avg_logprob": -0.13013146881364349, "compression_ratio": 1.7194570135746607, "no_speech_prob": 0.000543845584616065}, {"id": 503, "seek": 168484, "start": 1709.84, "end": 1712.84, "text": " We achieved that, and now we went beyond that.", "tokens": [51614, 492, 11042, 300, 11, 293, 586, 321, 1437, 4399, 300, 13, 51764], "temperature": 0.0, "avg_logprob": -0.13013146881364349, "compression_ratio": 1.7194570135746607, "no_speech_prob": 0.000543845584616065}, {"id": 504, "seek": 171284, "start": 1712.84, "end": 1715.84, "text": " Now we want to tackle the distribution.", "tokens": [50364, 823, 321, 528, 281, 14896, 264, 7316, 13, 50514], "temperature": 0.0, "avg_logprob": -0.1255209662697532, "compression_ratio": 1.72265625, "no_speech_prob": 0.014220794662833214}, {"id": 505, "seek": 171284, "start": 1715.84, "end": 1718.84, "text": " We want to tackle the one-to-many, the media servers.", "tokens": [50514, 492, 528, 281, 14896, 264, 472, 12, 1353, 12, 76, 1325, 11, 264, 3021, 15909, 13, 50664], "temperature": 0.0, "avg_logprob": -0.1255209662697532, "compression_ratio": 1.72265625, "no_speech_prob": 0.014220794662833214}, {"id": 506, "seek": 171284, "start": 1718.84, "end": 1722.84, "text": " We have actually a project going on with Miss Server", "tokens": [50664, 492, 362, 767, 257, 1716, 516, 322, 365, 5275, 25684, 50864], "temperature": 0.0, "avg_logprob": -0.1255209662697532, "compression_ratio": 1.72265625, "no_speech_prob": 0.014220794662833214}, {"id": 507, "seek": 171284, "start": 1722.84, "end": 1725.84, "text": " to add a lot of this functionality and the scalability", "tokens": [50864, 281, 909, 257, 688, 295, 341, 14980, 293, 264, 15664, 2310, 51014], "temperature": 0.0, "avg_logprob": -0.1255209662697532, "compression_ratio": 1.72265625, "no_speech_prob": 0.014220794662833214}, {"id": 508, "seek": 171284, "start": 1725.84, "end": 1727.84, "text": " as part of the project itself,", "tokens": [51014, 382, 644, 295, 264, 1716, 2564, 11, 51114], "temperature": 0.0, "avg_logprob": -0.1255209662697532, "compression_ratio": 1.72265625, "no_speech_prob": 0.014220794662833214}, {"id": 509, "seek": 171284, "start": 1727.84, "end": 1729.84, "text": " so that we have at least one media server", "tokens": [51114, 370, 300, 321, 362, 412, 1935, 472, 3021, 7154, 51214], "temperature": 0.0, "avg_logprob": -0.1255209662697532, "compression_ratio": 1.72265625, "no_speech_prob": 0.014220794662833214}, {"id": 510, "seek": 171284, "start": 1729.84, "end": 1731.84, "text": " that already supports that in a very scalable way,", "tokens": [51214, 300, 1217, 9346, 300, 294, 257, 588, 38481, 636, 11, 51314], "temperature": 0.0, "avg_logprob": -0.1255209662697532, "compression_ratio": 1.72265625, "no_speech_prob": 0.014220794662833214}, {"id": 511, "seek": 171284, "start": 1731.84, "end": 1734.84, "text": " where it becomes very simple for an application", "tokens": [51314, 689, 309, 3643, 588, 2199, 337, 364, 3861, 51464], "temperature": 0.0, "avg_logprob": -0.1255209662697532, "compression_ratio": 1.72265625, "no_speech_prob": 0.014220794662833214}, {"id": 512, "seek": 171284, "start": 1734.84, "end": 1737.84, "text": " like VLC, or VFF Play, or Gstreamer", "tokens": [51464, 411, 691, 14766, 11, 420, 691, 6345, 5506, 11, 420, 460, 9291, 260, 51614], "temperature": 0.0, "avg_logprob": -0.1255209662697532, "compression_ratio": 1.72265625, "no_speech_prob": 0.014220794662833214}, {"id": 513, "seek": 171284, "start": 1737.84, "end": 1739.84, "text": " to hook up to this media server", "tokens": [51614, 281, 6328, 493, 281, 341, 3021, 7154, 51714], "temperature": 0.0, "avg_logprob": -0.1255209662697532, "compression_ratio": 1.72265625, "no_speech_prob": 0.014220794662833214}, {"id": 514, "seek": 173984, "start": 1739.84, "end": 1744.84, "text": " and start the playback immediately using the Pshuoroko.", "tokens": [50364, 293, 722, 264, 37223, 4258, 1228, 264, 430, 2716, 84, 284, 13704, 13, 50614], "temperature": 0.0, "avg_logprob": -0.6324436353600543, "compression_ratio": 1.0, "no_speech_prob": 0.008322037756443024}, {"id": 515, "seek": 173984, "start": 1744.84, "end": 1746.84, "text": " Thank you very much.", "tokens": [50614, 1044, 291, 588, 709, 13, 50714], "temperature": 0.0, "avg_logprob": -0.6324436353600543, "compression_ratio": 1.0, "no_speech_prob": 0.008322037756443024}], "language": "en"}