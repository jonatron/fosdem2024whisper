{"text": " Hello everyone. My name is Natesh. I work as a scientific software engineer at Al Yander. I'm also a developer at the Power Grid model project on which I'm going to give a talk now. So it is a high performance distribution grid power system analysis library. Yeah. And the next slide. Oh. Oh. Yes. So in this presentation I'm going to mention why do we need this project? How did we come across building this? So what does the library do? And how does it perform compared to other solutions that are already available in the space? And how do we use this within Al Yander which is Dutch DSO for its own products and applications? There's also some talk about open source since we are open source and we would like new contributors as well. In a traditional way up until a few years ago at least the power system analysis used to happen within the DSOs, DSOs in this way. The electrical engineers would usually have some data files where they run the calculation in a GUI focused software where we have built-in presets for running the calculation and we get only certain results and then we make decisions on whether to add a new transformer, add a new cable and such components within the grid or not. If the grid can handle more solar panels, if the grid can handle more EVs or not was done using this way. But now with the new smart meters and EVs and renewable energy we have to do a lot more and for that we have to have all of the data of the smart meters which is in a really huge volume in a database where also lies our topology and electrical parameters and then we cannot just use a custom, we cannot just use a preset of the calculation method. So we have to have some customization available over there and then we have to do the calculations in the cloud because these calculations are in the set of millions now because we are trying to simulate the entire year for example of time series and the volume increases a lot. So why did we decide to make this and what makes a good power system analysis library? So around I think 2018 also Alianthar faced a problem where we were not able to do this using any of the open source software or the commercial software. We faced these pain points actually and then we decided to make the library which are focused on around them. So we needed a well-defined software API. That's because we want this calculation library to be part of a really bigger application which does a lot of things apart from just calculations and we also wanted this library to be cross-platform and scalable so that we can use it within the cloud. And of course since the volume is in millions, high performance and parallelization was needed otherwise you might have to wait for a month or so to get results which is not adequate and if it's in cloud it costs you money as well. That was in 2018 by the way and after that at that point our power grid model was in our source within Alianthar. We had some applications in 2021 then we made it open source at around 22 and we do have a lot of applications now which I'll cover soon enough. What the library does? So it does some calculations especially the power flow calculations, state estimation and short circuit calculations for both single phase and three phase grids. We have many algorithms with which we can do this and these sum up the calculation functionalities in a really short way. We have a huge focus on the software side of the library because of the pain points that we did mention before. So we have a native shared memory multi-threading and that enables us to do the parallelization for batches and in as many cores as possible when we do deploy it in the cloud and yes the implementation is in C++ and the API for the users is in Python if they wish to use it and it's well documented, it's quite stable and then we have the binaries available in PyPy and Anaconda for the Kondaforge and we have support for Windows, Linux and Mac OS all three of them. And since making this library is not just enough we have to show that these calculations are actually correct as well and for that we have done the validation of the library against some theoretical hand calculations at the start. Then Vision and Chaya which are commercial software and also PowerFactory, we validated the library against them and PandaPower which is another open source library. So we validated against these software and then we use them as a reference for each new revision of Power Grid model. So it's part of our CI pipeline if any of the new features do not comply with it, it won't, yeah that should not be worse than. How does it perform compared to other libraries because yeah there are a lot of libraries within this domain. We have some more presentations now as well about them and each one has its own specific plus point and the plus point of Power Grid model is its performance. For the performance benchmark the link is in the presentation if you wish to do the benchmark yourself. We try to compare it with PandaPower and OpenDSS to get an idea of how it performs and we found that the performance in case of PandaPower is almost 20 times of their calculation which was a huge boost and will really help in doing these calculations much faster. So these were the symmetrical calculations and the asymmetrical calculations is where Power Grid model shines as well because we as a distribution, I mean when it started as a distribution analysis library within Alieander this was really needed at that point. So the Newton-Raphson for PandaPower is around 100 times and with OpenDSS we have to compare it with iterative current that was four times faster than that library. We have data conversions as well because we don't have the best data model to store it and hence we have we have conversions to SIM and other softwares that are used for power system analysis. SIM because we can then integrate with other applications throughout this ecosystem. And we currently use it within 10 plus applications within Alieander so it's a mature project at a production grid and yeah there are many applications grid planning, automatic network design, automatic network design, monitoring asset allocation and congestion management. Since I do have some time within automatic network design for example we try to forecast what the effect of the grid based on the EV growth will happen in the coming 30-40 years, EV growth and the solar panels and based on that we simulate this and then we identify the bottleneck, add the cable, run the simulation again and in this automatic way we design the whole network. That's what this application does. There are actually multiple congestion management applications as well. So one is the active one with which we do real-time congestion management. We take in the measurements from the previous 48 hours and predict if there's going to be a congestion in the coming 48 hours based on any plan maintenance if there is any and the other type of congestion management that we also do not present here. It's on the assessing the measurements of the entire year of this past year and then what would be the congestion in the coming year and based on that we might offer new contracts to our customers because the grid in Netherlands is highly congested right now. We have a lot of people waiting for new connections but we can't add them and hence power grid model really helps in making all of these calculations. For the open source you can just use the library and provide feedback. That's a great contribution in itself. Report any bugs as well. That's really helpful too and you can also do the validation for the library with any test cases of the 80 cases that I mentioned. You can provide more and validate the library. You can improve if you have an idea for a new way to make the API. You can suggest that too or you can also add new algorithms and make the code more efficient in the C++ code. That's also possible. We have a list of good first issues within the repository too if you wish to have a look. We have a few partners. There are DSOs, TSO research institutions, universities and other open source projects as well. The DSOs do use them. Aliantha does have those products as well as an access and study and are also trying to add to their operations. That's all from me. Do we have any questions? Hello. Thank you so much. This looks really, really, really cool. I have one question. If I am running a project, hello Chris Adams, Green Web Foundation. If I have a new project on to build a big solar farm or put a 100 megawatt data center somewhere, can I use this to model how I might integrate with your grid to say this is why you should let me build here or possibly this is what it's going to be the implication if we keep growing at this space. Yes, definitely. We do some calculations on our side. We would be able to, I mean, like Aliantha does it on its side if it can integrate the customer. On the side of the producer, the producer does it so it can identify if it's profitable to make this investment or not. What would be the ROI in the coming years based on what the grid looks like? That's definitely what the producers still do and they do use the model over there. Hi, Peter Dutfield from Open Climate Fix. Thank you for the talk. How did you say some other TSOs have used this? Have you had any feedback from them and how they found it? Well, I said that they are active partners so they did not actually use it. They are TANET and RTE as well. I'm trying to look if they could use this model. But some of the core features of TSOs, we do need to add them as well. That's one of the requirements from the TSO side. Once that happens, TSOs would use it as well. But the focus is primarily on the distribution system analysis side. In Germany, we have this TSO tells you please reduce your consumption. Can I use your project for this calculation? Is it fine enough or is your project just a scope of the complete DSO or a larger part of the grid? Can I use it for a single grid collection point or just for larger parts? Let me think if I got the question correctly. If you do have a single connection point and you wish to use the library, then the motivation would not be so that what would be the transition somewhere. But if it would be a profitable thing for you, right? Did I get it right? No, the DSO uses your library to calculate that tomorrow there's not enough energy. So he wants to tell some customers please we to use your consumption tomorrow. Is the library able to calculate this for single connection and grid connection points? So that I can really can say you and you and you have to reduce tomorrow? Or does it just calculate a very yes, is it just for a large part or also for a very narrow part of the grid? Now I understood. Nice point. The library does not do that. It just calculates the yeah, the power flow results, the voltages, the powers. One of the applications that I did mention about the active congestion management, we tell the customers to reduce their generations. We have certain contracts within Alieander to do that, but it's not part of the power grid model. Yes.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 15.24, "text": " Hello everyone. My name is Natesh. I work as a scientific software engineer at Al Yander.", "tokens": [50364, 2425, 1518, 13, 1222, 1315, 307, 426, 1024, 71, 13, 286, 589, 382, 257, 8134, 4722, 11403, 412, 967, 398, 4483, 13, 51126], "temperature": 0.0, "avg_logprob": -0.34303287665049237, "compression_ratio": 1.2753623188405796, "no_speech_prob": 0.2964259088039398}, {"id": 1, "seek": 0, "start": 15.24, "end": 21.240000000000002, "text": " I'm also a developer at the Power Grid model project on which I'm going to give a talk", "tokens": [51126, 286, 478, 611, 257, 10754, 412, 264, 7086, 42905, 2316, 1716, 322, 597, 286, 478, 516, 281, 976, 257, 751, 51426], "temperature": 0.0, "avg_logprob": -0.34303287665049237, "compression_ratio": 1.2753623188405796, "no_speech_prob": 0.2964259088039398}, {"id": 2, "seek": 2124, "start": 21.24, "end": 31.56, "text": " now. So it is a high performance distribution grid power system analysis library. Yeah.", "tokens": [50364, 586, 13, 407, 309, 307, 257, 1090, 3389, 7316, 10748, 1347, 1185, 5215, 6405, 13, 865, 13, 50880], "temperature": 0.0, "avg_logprob": -0.4514183771042597, "compression_ratio": 1.0740740740740742, "no_speech_prob": 0.43827229738235474}, {"id": 3, "seek": 3156, "start": 31.56, "end": 60.0, "text": " And the next slide. Oh. Oh. Yes. So in this presentation I'm going to mention why do we", "tokens": [50364, 400, 264, 958, 4137, 13, 876, 13, 876, 13, 1079, 13, 407, 294, 341, 5860, 286, 478, 516, 281, 2152, 983, 360, 321, 51786], "temperature": 0.0, "avg_logprob": -0.42639615800645614, "compression_ratio": 1.0357142857142858, "no_speech_prob": 0.3086293637752533}, {"id": 4, "seek": 6000, "start": 60.0, "end": 67.68, "text": " need this project? How did we come across building this? So what does the library do? And how does", "tokens": [50364, 643, 341, 1716, 30, 1012, 630, 321, 808, 2108, 2390, 341, 30, 407, 437, 775, 264, 6405, 360, 30, 400, 577, 775, 50748], "temperature": 0.0, "avg_logprob": -0.16613701714409723, "compression_ratio": 1.5755102040816327, "no_speech_prob": 0.4478926956653595}, {"id": 5, "seek": 6000, "start": 67.68, "end": 73.84, "text": " it perform compared to other solutions that are already available in the space? And how do we use", "tokens": [50748, 309, 2042, 5347, 281, 661, 6547, 300, 366, 1217, 2435, 294, 264, 1901, 30, 400, 577, 360, 321, 764, 51056], "temperature": 0.0, "avg_logprob": -0.16613701714409723, "compression_ratio": 1.5755102040816327, "no_speech_prob": 0.4478926956653595}, {"id": 6, "seek": 6000, "start": 73.84, "end": 82.8, "text": " this within Al Yander which is Dutch DSO for its own products and applications? There's also some", "tokens": [51056, 341, 1951, 967, 398, 4483, 597, 307, 15719, 15816, 46, 337, 1080, 1065, 3383, 293, 5821, 30, 821, 311, 611, 512, 51504], "temperature": 0.0, "avg_logprob": -0.16613701714409723, "compression_ratio": 1.5755102040816327, "no_speech_prob": 0.4478926956653595}, {"id": 7, "seek": 6000, "start": 82.8, "end": 87.72, "text": " talk about open source since we are open source and we would like new contributors as well.", "tokens": [51504, 751, 466, 1269, 4009, 1670, 321, 366, 1269, 4009, 293, 321, 576, 411, 777, 45627, 382, 731, 13, 51750], "temperature": 0.0, "avg_logprob": -0.16613701714409723, "compression_ratio": 1.5755102040816327, "no_speech_prob": 0.4478926956653595}, {"id": 8, "seek": 8772, "start": 87.72, "end": 99.28, "text": " In a traditional way up until a few years ago at least the power system analysis used to happen", "tokens": [50364, 682, 257, 5164, 636, 493, 1826, 257, 1326, 924, 2057, 412, 1935, 264, 1347, 1185, 5215, 1143, 281, 1051, 50942], "temperature": 0.0, "avg_logprob": -0.23333881840561377, "compression_ratio": 1.4764397905759161, "no_speech_prob": 0.025673313066363335}, {"id": 9, "seek": 8772, "start": 99.28, "end": 106.96000000000001, "text": " within the DSOs, DSOs in this way. The electrical engineers would usually have some data files", "tokens": [50942, 1951, 264, 15816, 31376, 11, 15816, 31376, 294, 341, 636, 13, 440, 12147, 11955, 576, 2673, 362, 512, 1412, 7098, 51326], "temperature": 0.0, "avg_logprob": -0.23333881840561377, "compression_ratio": 1.4764397905759161, "no_speech_prob": 0.025673313066363335}, {"id": 10, "seek": 8772, "start": 106.96000000000001, "end": 117.64, "text": " where they run the calculation in a GUI focused software where we have built-in presets for", "tokens": [51326, 689, 436, 1190, 264, 17108, 294, 257, 17917, 40, 5178, 4722, 689, 321, 362, 3094, 12, 259, 41865, 337, 51860], "temperature": 0.0, "avg_logprob": -0.23333881840561377, "compression_ratio": 1.4764397905759161, "no_speech_prob": 0.025673313066363335}, {"id": 11, "seek": 11764, "start": 117.68, "end": 123.8, "text": " running the calculation and we get only certain results and then we make decisions on whether to", "tokens": [50366, 2614, 264, 17108, 293, 321, 483, 787, 1629, 3542, 293, 550, 321, 652, 5327, 322, 1968, 281, 50672], "temperature": 0.0, "avg_logprob": -0.14334840774536134, "compression_ratio": 1.6277777777777778, "no_speech_prob": 0.06414011865854263}, {"id": 12, "seek": 11764, "start": 123.8, "end": 130.96, "text": " add a new transformer, add a new cable and such components within the grid or not. If the grid can", "tokens": [50672, 909, 257, 777, 31782, 11, 909, 257, 777, 8220, 293, 1270, 6677, 1951, 264, 10748, 420, 406, 13, 759, 264, 10748, 393, 51030], "temperature": 0.0, "avg_logprob": -0.14334840774536134, "compression_ratio": 1.6277777777777778, "no_speech_prob": 0.06414011865854263}, {"id": 13, "seek": 11764, "start": 130.96, "end": 141.0, "text": " handle more solar panels, if the grid can handle more EVs or not was done using this way. But now", "tokens": [51030, 4813, 544, 7936, 13419, 11, 498, 264, 10748, 393, 4813, 544, 15733, 82, 420, 406, 390, 1096, 1228, 341, 636, 13, 583, 586, 51532], "temperature": 0.0, "avg_logprob": -0.14334840774536134, "compression_ratio": 1.6277777777777778, "no_speech_prob": 0.06414011865854263}, {"id": 14, "seek": 14100, "start": 141.04, "end": 149.84, "text": " with the new smart meters and EVs and renewable energy we have to do a lot more and for that we", "tokens": [50366, 365, 264, 777, 4069, 8146, 293, 15733, 82, 293, 20938, 2281, 321, 362, 281, 360, 257, 688, 544, 293, 337, 300, 321, 50806], "temperature": 0.0, "avg_logprob": -0.12491356117137964, "compression_ratio": 1.6705882352941177, "no_speech_prob": 0.05940011143684387}, {"id": 15, "seek": 14100, "start": 149.84, "end": 156.48, "text": " have to have all of the data of the smart meters which is in a really huge volume in a database", "tokens": [50806, 362, 281, 362, 439, 295, 264, 1412, 295, 264, 4069, 8146, 597, 307, 294, 257, 534, 2603, 5523, 294, 257, 8149, 51138], "temperature": 0.0, "avg_logprob": -0.12491356117137964, "compression_ratio": 1.6705882352941177, "no_speech_prob": 0.05940011143684387}, {"id": 16, "seek": 14100, "start": 156.48, "end": 164.96, "text": " where also lies our topology and electrical parameters and then we cannot just use a custom,", "tokens": [51138, 689, 611, 9134, 527, 1192, 1793, 293, 12147, 9834, 293, 550, 321, 2644, 445, 764, 257, 2375, 11, 51562], "temperature": 0.0, "avg_logprob": -0.12491356117137964, "compression_ratio": 1.6705882352941177, "no_speech_prob": 0.05940011143684387}, {"id": 17, "seek": 16496, "start": 165.56, "end": 173.28, "text": " we cannot just use a preset of the calculation method. So we have to have some customization", "tokens": [50394, 321, 2644, 445, 764, 257, 32081, 295, 264, 17108, 3170, 13, 407, 321, 362, 281, 362, 512, 39387, 50780], "temperature": 0.0, "avg_logprob": -0.17967353328581778, "compression_ratio": 1.7621951219512195, "no_speech_prob": 0.02577284164726734}, {"id": 18, "seek": 16496, "start": 173.28, "end": 180.60000000000002, "text": " available over there and then we have to do the calculations in the cloud because these calculations", "tokens": [50780, 2435, 670, 456, 293, 550, 321, 362, 281, 360, 264, 20448, 294, 264, 4588, 570, 613, 20448, 51146], "temperature": 0.0, "avg_logprob": -0.17967353328581778, "compression_ratio": 1.7621951219512195, "no_speech_prob": 0.02577284164726734}, {"id": 19, "seek": 16496, "start": 180.60000000000002, "end": 189.32, "text": " are in the set of millions now because we are trying to simulate the entire year for example of", "tokens": [51146, 366, 294, 264, 992, 295, 6803, 586, 570, 321, 366, 1382, 281, 27817, 264, 2302, 1064, 337, 1365, 295, 51582], "temperature": 0.0, "avg_logprob": -0.17967353328581778, "compression_ratio": 1.7621951219512195, "no_speech_prob": 0.02577284164726734}, {"id": 20, "seek": 18932, "start": 190.12, "end": 199.28, "text": " time series and the volume increases a lot. So why did we decide to make this and what", "tokens": [50404, 565, 2638, 293, 264, 5523, 8637, 257, 688, 13, 407, 983, 630, 321, 4536, 281, 652, 341, 293, 437, 50862], "temperature": 0.0, "avg_logprob": -0.2630369013006037, "compression_ratio": 1.4497354497354498, "no_speech_prob": 0.013934322632849216}, {"id": 21, "seek": 18932, "start": 199.28, "end": 209.64, "text": " makes a good power system analysis library? So around I think 2018 also Alianthar faced a", "tokens": [50862, 1669, 257, 665, 1347, 1185, 5215, 6405, 30, 407, 926, 286, 519, 6096, 611, 967, 952, 392, 289, 11446, 257, 51380], "temperature": 0.0, "avg_logprob": -0.2630369013006037, "compression_ratio": 1.4497354497354498, "no_speech_prob": 0.013934322632849216}, {"id": 22, "seek": 18932, "start": 209.64, "end": 218.24, "text": " problem where we were not able to do this using any of the open source software or the commercial", "tokens": [51380, 1154, 689, 321, 645, 406, 1075, 281, 360, 341, 1228, 604, 295, 264, 1269, 4009, 4722, 420, 264, 6841, 51810], "temperature": 0.0, "avg_logprob": -0.2630369013006037, "compression_ratio": 1.4497354497354498, "no_speech_prob": 0.013934322632849216}, {"id": 23, "seek": 21824, "start": 218.28, "end": 226.8, "text": " software. We faced these pain points actually and then we decided to make the library which are", "tokens": [50366, 4722, 13, 492, 11446, 613, 1822, 2793, 767, 293, 550, 321, 3047, 281, 652, 264, 6405, 597, 366, 50792], "temperature": 0.0, "avg_logprob": -0.14659359271709735, "compression_ratio": 1.513089005235602, "no_speech_prob": 0.010076657868921757}, {"id": 24, "seek": 21824, "start": 226.8, "end": 235.72, "text": " focused on around them. So we needed a well-defined software API. That's because we want this", "tokens": [50792, 5178, 322, 926, 552, 13, 407, 321, 2978, 257, 731, 12, 37716, 4722, 9362, 13, 663, 311, 570, 321, 528, 341, 51238], "temperature": 0.0, "avg_logprob": -0.14659359271709735, "compression_ratio": 1.513089005235602, "no_speech_prob": 0.010076657868921757}, {"id": 25, "seek": 21824, "start": 235.72, "end": 244.0, "text": " calculation library to be part of a really bigger application which does a lot of things apart from", "tokens": [51238, 17108, 6405, 281, 312, 644, 295, 257, 534, 3801, 3861, 597, 775, 257, 688, 295, 721, 4936, 490, 51652], "temperature": 0.0, "avg_logprob": -0.14659359271709735, "compression_ratio": 1.513089005235602, "no_speech_prob": 0.010076657868921757}, {"id": 26, "seek": 24400, "start": 244.04, "end": 253.12, "text": " just calculations and we also wanted this library to be cross-platform and scalable so that we can", "tokens": [50366, 445, 20448, 293, 321, 611, 1415, 341, 6405, 281, 312, 3278, 12, 39975, 837, 293, 38481, 370, 300, 321, 393, 50820], "temperature": 0.0, "avg_logprob": -0.15680640294001652, "compression_ratio": 1.5268817204301075, "no_speech_prob": 0.009596074000000954}, {"id": 27, "seek": 24400, "start": 253.12, "end": 259.48, "text": " use it within the cloud. And of course since the volume is in millions, high performance and", "tokens": [50820, 764, 309, 1951, 264, 4588, 13, 400, 295, 1164, 1670, 264, 5523, 307, 294, 6803, 11, 1090, 3389, 293, 51138], "temperature": 0.0, "avg_logprob": -0.15680640294001652, "compression_ratio": 1.5268817204301075, "no_speech_prob": 0.009596074000000954}, {"id": 28, "seek": 24400, "start": 259.48, "end": 265.52, "text": " parallelization was needed otherwise you might have to wait for a month or so to get results", "tokens": [51138, 8952, 2144, 390, 2978, 5911, 291, 1062, 362, 281, 1699, 337, 257, 1618, 420, 370, 281, 483, 3542, 51440], "temperature": 0.0, "avg_logprob": -0.15680640294001652, "compression_ratio": 1.5268817204301075, "no_speech_prob": 0.009596074000000954}, {"id": 29, "seek": 26552, "start": 265.56, "end": 269.12, "text": " which is not adequate and if it's in cloud it costs you money as well.", "tokens": [50366, 597, 307, 406, 20927, 293, 498, 309, 311, 294, 4588, 309, 5497, 291, 1460, 382, 731, 13, 50544], "temperature": 0.0, "avg_logprob": -0.236386573675907, "compression_ratio": 1.4488636363636365, "no_speech_prob": 0.03439853712916374}, {"id": 30, "seek": 26552, "start": 269.12, "end": 281.64, "text": " That was in 2018 by the way and after that at that point our power grid model was in our", "tokens": [50544, 663, 390, 294, 6096, 538, 264, 636, 293, 934, 300, 412, 300, 935, 527, 1347, 10748, 2316, 390, 294, 527, 51170], "temperature": 0.0, "avg_logprob": -0.236386573675907, "compression_ratio": 1.4488636363636365, "no_speech_prob": 0.03439853712916374}, {"id": 31, "seek": 26552, "start": 281.64, "end": 291.96, "text": " source within Alianthar. We had some applications in 2021 then we made it open source at around", "tokens": [51170, 4009, 1951, 967, 952, 392, 289, 13, 492, 632, 512, 5821, 294, 7201, 550, 321, 1027, 309, 1269, 4009, 412, 926, 51686], "temperature": 0.0, "avg_logprob": -0.236386573675907, "compression_ratio": 1.4488636363636365, "no_speech_prob": 0.03439853712916374}, {"id": 32, "seek": 29196, "start": 292.56, "end": 300.84, "text": " 22 and we do have a lot of applications now which I'll cover soon enough. What the library does? So it", "tokens": [50394, 5853, 293, 321, 360, 362, 257, 688, 295, 5821, 586, 597, 286, 603, 2060, 2321, 1547, 13, 708, 264, 6405, 775, 30, 407, 309, 50808], "temperature": 0.0, "avg_logprob": -0.1898787865271935, "compression_ratio": 1.5625, "no_speech_prob": 0.025497442111372948}, {"id": 33, "seek": 29196, "start": 300.84, "end": 308.28, "text": " does some calculations especially the power flow calculations, state estimation and short circuit", "tokens": [50808, 775, 512, 20448, 2318, 264, 1347, 3095, 20448, 11, 1785, 35701, 293, 2099, 9048, 51180], "temperature": 0.0, "avg_logprob": -0.1898787865271935, "compression_ratio": 1.5625, "no_speech_prob": 0.025497442111372948}, {"id": 34, "seek": 29196, "start": 308.28, "end": 317.08, "text": " calculations for both single phase and three phase grids. We have many algorithms with which we can", "tokens": [51180, 20448, 337, 1293, 2167, 5574, 293, 1045, 5574, 677, 3742, 13, 492, 362, 867, 14642, 365, 597, 321, 393, 51620], "temperature": 0.0, "avg_logprob": -0.1898787865271935, "compression_ratio": 1.5625, "no_speech_prob": 0.025497442111372948}, {"id": 35, "seek": 31708, "start": 317.12, "end": 325.88, "text": " do this and these sum up the calculation functionalities in a really short way.", "tokens": [50366, 360, 341, 293, 613, 2408, 493, 264, 17108, 11745, 1088, 294, 257, 534, 2099, 636, 13, 50804], "temperature": 0.0, "avg_logprob": -0.17382054030895233, "compression_ratio": 1.5344827586206897, "no_speech_prob": 0.02368842251598835}, {"id": 36, "seek": 31708, "start": 325.88, "end": 336.36, "text": " We have a huge focus on the software side of the library because of the pain points that we", "tokens": [50804, 492, 362, 257, 2603, 1879, 322, 264, 4722, 1252, 295, 264, 6405, 570, 295, 264, 1822, 2793, 300, 321, 51328], "temperature": 0.0, "avg_logprob": -0.17382054030895233, "compression_ratio": 1.5344827586206897, "no_speech_prob": 0.02368842251598835}, {"id": 37, "seek": 31708, "start": 336.36, "end": 345.91999999999996, "text": " did mention before. So we have a native shared memory multi-threading and that enables us to do", "tokens": [51328, 630, 2152, 949, 13, 407, 321, 362, 257, 8470, 5507, 4675, 4825, 12, 392, 35908, 293, 300, 17077, 505, 281, 360, 51806], "temperature": 0.0, "avg_logprob": -0.17382054030895233, "compression_ratio": 1.5344827586206897, "no_speech_prob": 0.02368842251598835}, {"id": 38, "seek": 34592, "start": 345.92, "end": 352.6, "text": " the parallelization for batches and in as many cores as possible when we do deploy it in the", "tokens": [50364, 264, 8952, 2144, 337, 15245, 279, 293, 294, 382, 867, 24826, 382, 1944, 562, 321, 360, 7274, 309, 294, 264, 50698], "temperature": 0.0, "avg_logprob": -0.1505191829842581, "compression_ratio": 1.5777777777777777, "no_speech_prob": 0.01794695481657982}, {"id": 39, "seek": 34592, "start": 352.6, "end": 362.40000000000003, "text": " cloud and yes the implementation is in C++ and the API for the users is in Python if they wish to", "tokens": [50698, 4588, 293, 2086, 264, 11420, 307, 294, 383, 25472, 293, 264, 9362, 337, 264, 5022, 307, 294, 15329, 498, 436, 3172, 281, 51188], "temperature": 0.0, "avg_logprob": -0.1505191829842581, "compression_ratio": 1.5777777777777777, "no_speech_prob": 0.01794695481657982}, {"id": 40, "seek": 34592, "start": 362.40000000000003, "end": 370.52000000000004, "text": " use it and it's well documented, it's quite stable and then we have the binaries available in", "tokens": [51188, 764, 309, 293, 309, 311, 731, 23007, 11, 309, 311, 1596, 8351, 293, 550, 321, 362, 264, 5171, 4889, 2435, 294, 51594], "temperature": 0.0, "avg_logprob": -0.1505191829842581, "compression_ratio": 1.5777777777777777, "no_speech_prob": 0.01794695481657982}, {"id": 41, "seek": 37052, "start": 371.12, "end": 382.24, "text": " PyPy and Anaconda for the Kondaforge and we have support for Windows, Linux and Mac OS all three of them.", "tokens": [50394, 9953, 47, 88, 293, 1107, 326, 12233, 337, 264, 591, 684, 2792, 4685, 293, 321, 362, 1406, 337, 8591, 11, 18734, 293, 5707, 12731, 439, 1045, 295, 552, 13, 50950], "temperature": 0.0, "avg_logprob": -0.3305524790062095, "compression_ratio": 1.3529411764705883, "no_speech_prob": 0.011976431123912334}, {"id": 42, "seek": 37052, "start": 382.24, "end": 394.68, "text": " And since making this library is not just enough we have to show that these calculations are actually", "tokens": [50950, 400, 1670, 1455, 341, 6405, 307, 406, 445, 1547, 321, 362, 281, 855, 300, 613, 20448, 366, 767, 51572], "temperature": 0.0, "avg_logprob": -0.3305524790062095, "compression_ratio": 1.3529411764705883, "no_speech_prob": 0.011976431123912334}, {"id": 43, "seek": 39468, "start": 394.68, "end": 402.64, "text": " correct as well and for that we have done the validation of the library against some", "tokens": [50364, 3006, 382, 731, 293, 337, 300, 321, 362, 1096, 264, 24071, 295, 264, 6405, 1970, 512, 50762], "temperature": 0.0, "avg_logprob": -0.22189070049085116, "compression_ratio": 1.7761194029850746, "no_speech_prob": 0.018582554534077644}, {"id": 44, "seek": 39468, "start": 402.64, "end": 409.36, "text": " theoretical hand calculations at the start. Then Vision and Chaya which are commercial", "tokens": [50762, 20864, 1011, 20448, 412, 264, 722, 13, 1396, 25170, 293, 761, 4427, 597, 366, 6841, 51098], "temperature": 0.0, "avg_logprob": -0.22189070049085116, "compression_ratio": 1.7761194029850746, "no_speech_prob": 0.018582554534077644}, {"id": 45, "seek": 39468, "start": 409.36, "end": 414.92, "text": " software and also PowerFactory, we validated the library against them and PandaPower which", "tokens": [51098, 4722, 293, 611, 7086, 37, 21840, 11, 321, 40693, 264, 6405, 1970, 552, 293, 44207, 46057, 597, 51376], "temperature": 0.0, "avg_logprob": -0.22189070049085116, "compression_ratio": 1.7761194029850746, "no_speech_prob": 0.018582554534077644}, {"id": 46, "seek": 39468, "start": 414.92, "end": 424.04, "text": " is another open source library. So we validated against these software and then we use them as", "tokens": [51376, 307, 1071, 1269, 4009, 6405, 13, 407, 321, 40693, 1970, 613, 4722, 293, 550, 321, 764, 552, 382, 51832], "temperature": 0.0, "avg_logprob": -0.22189070049085116, "compression_ratio": 1.7761194029850746, "no_speech_prob": 0.018582554534077644}, {"id": 47, "seek": 42404, "start": 424.08000000000004, "end": 431.8, "text": " a reference for each new revision of Power Grid model. So it's part of our CI pipeline if any of", "tokens": [50366, 257, 6408, 337, 1184, 777, 34218, 295, 7086, 42905, 2316, 13, 407, 309, 311, 644, 295, 527, 37777, 15517, 498, 604, 295, 50752], "temperature": 0.0, "avg_logprob": -0.24997293247896082, "compression_ratio": 1.4919786096256684, "no_speech_prob": 0.013527719303965569}, {"id": 48, "seek": 42404, "start": 431.8, "end": 438.32000000000005, "text": " the new features do not comply with it, it won't, yeah that should not be worse than.", "tokens": [50752, 264, 777, 4122, 360, 406, 27956, 365, 309, 11, 309, 1582, 380, 11, 1338, 300, 820, 406, 312, 5324, 813, 13, 51078], "temperature": 0.0, "avg_logprob": -0.24997293247896082, "compression_ratio": 1.4919786096256684, "no_speech_prob": 0.013527719303965569}, {"id": 49, "seek": 42404, "start": 438.32000000000005, "end": 448.88, "text": " How does it perform compared to other libraries because yeah there are a lot of libraries within", "tokens": [51078, 1012, 775, 309, 2042, 5347, 281, 661, 15148, 570, 1338, 456, 366, 257, 688, 295, 15148, 1951, 51606], "temperature": 0.0, "avg_logprob": -0.24997293247896082, "compression_ratio": 1.4919786096256684, "no_speech_prob": 0.013527719303965569}, {"id": 50, "seek": 44888, "start": 448.92, "end": 454.92, "text": " this domain. We have some more presentations now as well about them and each one has its own", "tokens": [50366, 341, 9274, 13, 492, 362, 512, 544, 18964, 586, 382, 731, 466, 552, 293, 1184, 472, 575, 1080, 1065, 50666], "temperature": 0.0, "avg_logprob": -0.1990773185851082, "compression_ratio": 1.6491228070175439, "no_speech_prob": 0.06567460298538208}, {"id": 51, "seek": 44888, "start": 454.92, "end": 463.8, "text": " specific plus point and the plus point of Power Grid model is its performance. For the", "tokens": [50666, 2685, 1804, 935, 293, 264, 1804, 935, 295, 7086, 42905, 2316, 307, 1080, 3389, 13, 1171, 264, 51110], "temperature": 0.0, "avg_logprob": -0.1990773185851082, "compression_ratio": 1.6491228070175439, "no_speech_prob": 0.06567460298538208}, {"id": 52, "seek": 44888, "start": 463.8, "end": 472.32, "text": " performance benchmark the link is in the presentation if you wish to do the benchmark yourself. We try", "tokens": [51110, 3389, 18927, 264, 2113, 307, 294, 264, 5860, 498, 291, 3172, 281, 360, 264, 18927, 1803, 13, 492, 853, 51536], "temperature": 0.0, "avg_logprob": -0.1990773185851082, "compression_ratio": 1.6491228070175439, "no_speech_prob": 0.06567460298538208}, {"id": 53, "seek": 47232, "start": 472.36, "end": 481.2, "text": " to compare it with PandaPower and OpenDSS to get an idea of how it performs and we found that", "tokens": [50366, 281, 6794, 309, 365, 44207, 46057, 293, 7238, 11844, 50, 281, 483, 364, 1558, 295, 577, 309, 26213, 293, 321, 1352, 300, 50808], "temperature": 0.0, "avg_logprob": -0.13548427820205688, "compression_ratio": 1.5657142857142856, "no_speech_prob": 0.11143973469734192}, {"id": 54, "seek": 47232, "start": 481.2, "end": 491.24, "text": " the performance in case of PandaPower is almost 20 times of their calculation which was a huge", "tokens": [50808, 264, 3389, 294, 1389, 295, 44207, 46057, 307, 1920, 945, 1413, 295, 641, 17108, 597, 390, 257, 2603, 51310], "temperature": 0.0, "avg_logprob": -0.13548427820205688, "compression_ratio": 1.5657142857142856, "no_speech_prob": 0.11143973469734192}, {"id": 55, "seek": 47232, "start": 491.24, "end": 497.6, "text": " boost and will really help in doing these calculations much faster. So these were the", "tokens": [51310, 9194, 293, 486, 534, 854, 294, 884, 613, 20448, 709, 4663, 13, 407, 613, 645, 264, 51628], "temperature": 0.0, "avg_logprob": -0.13548427820205688, "compression_ratio": 1.5657142857142856, "no_speech_prob": 0.11143973469734192}, {"id": 56, "seek": 49760, "start": 497.68, "end": 505.28000000000003, "text": " symmetrical calculations and the asymmetrical calculations is where Power Grid model shines as", "tokens": [50368, 40360, 20448, 293, 264, 37277, 32283, 20448, 307, 689, 7086, 42905, 2316, 28056, 382, 50748], "temperature": 0.0, "avg_logprob": -0.2768923851751512, "compression_ratio": 1.5842696629213484, "no_speech_prob": 0.019639529287815094}, {"id": 57, "seek": 49760, "start": 505.28000000000003, "end": 513.32, "text": " well because we as a distribution, I mean when it started as a distribution analysis library", "tokens": [50748, 731, 570, 321, 382, 257, 7316, 11, 286, 914, 562, 309, 1409, 382, 257, 7316, 5215, 6405, 51150], "temperature": 0.0, "avg_logprob": -0.2768923851751512, "compression_ratio": 1.5842696629213484, "no_speech_prob": 0.019639529287815094}, {"id": 58, "seek": 49760, "start": 513.32, "end": 521.0, "text": " within Alieander this was really needed at that point. So the Newton-Raphson for PandaPower is", "tokens": [51150, 1951, 967, 414, 4483, 341, 390, 534, 2978, 412, 300, 935, 13, 407, 264, 19541, 12, 49, 13957, 3015, 337, 44207, 46057, 307, 51534], "temperature": 0.0, "avg_logprob": -0.2768923851751512, "compression_ratio": 1.5842696629213484, "no_speech_prob": 0.019639529287815094}, {"id": 59, "seek": 52100, "start": 521.2, "end": 527.6, "text": " around 100 times and with OpenDSS we have to compare it with iterative current that was four", "tokens": [50374, 926, 2319, 1413, 293, 365, 7238, 11844, 50, 321, 362, 281, 6794, 309, 365, 17138, 1166, 2190, 300, 390, 1451, 50694], "temperature": 0.0, "avg_logprob": -0.2029702625577412, "compression_ratio": 1.5647058823529412, "no_speech_prob": 0.01993981935083866}, {"id": 60, "seek": 52100, "start": 527.6, "end": 539.36, "text": " times faster than that library. We have data conversions as well because we don't have the", "tokens": [50694, 1413, 4663, 813, 300, 6405, 13, 492, 362, 1412, 42256, 382, 731, 570, 321, 500, 380, 362, 264, 51282], "temperature": 0.0, "avg_logprob": -0.2029702625577412, "compression_ratio": 1.5647058823529412, "no_speech_prob": 0.01993981935083866}, {"id": 61, "seek": 52100, "start": 539.36, "end": 546.96, "text": " best data model to store it and hence we have we have conversions to SIM and other", "tokens": [51282, 1151, 1412, 2316, 281, 3531, 309, 293, 16678, 321, 362, 321, 362, 42256, 281, 24738, 293, 661, 51662], "temperature": 0.0, "avg_logprob": -0.2029702625577412, "compression_ratio": 1.5647058823529412, "no_speech_prob": 0.01993981935083866}, {"id": 62, "seek": 54696, "start": 547.84, "end": 553.6800000000001, "text": " softwares that are used for power system analysis. SIM because we can then integrate with other", "tokens": [50408, 2787, 4151, 495, 300, 366, 1143, 337, 1347, 1185, 5215, 13, 24738, 570, 321, 393, 550, 13365, 365, 661, 50700], "temperature": 0.0, "avg_logprob": -0.19208296791451876, "compression_ratio": 1.543010752688172, "no_speech_prob": 0.00666245399042964}, {"id": 63, "seek": 54696, "start": 553.6800000000001, "end": 567.8000000000001, "text": " applications throughout this ecosystem. And we currently use it within 10 plus applications", "tokens": [50700, 5821, 3710, 341, 11311, 13, 400, 321, 4362, 764, 309, 1951, 1266, 1804, 5821, 51406], "temperature": 0.0, "avg_logprob": -0.19208296791451876, "compression_ratio": 1.543010752688172, "no_speech_prob": 0.00666245399042964}, {"id": 64, "seek": 54696, "start": 567.8000000000001, "end": 575.88, "text": " within Alieander so it's a mature project at a production grid and yeah there are many applications", "tokens": [51406, 1951, 967, 414, 4483, 370, 309, 311, 257, 14442, 1716, 412, 257, 4265, 10748, 293, 1338, 456, 366, 867, 5821, 51810], "temperature": 0.0, "avg_logprob": -0.19208296791451876, "compression_ratio": 1.543010752688172, "no_speech_prob": 0.00666245399042964}, {"id": 65, "seek": 57588, "start": 576.8, "end": 585.04, "text": " grid planning, automatic network design, automatic network design, monitoring asset", "tokens": [50410, 10748, 5038, 11, 12509, 3209, 1715, 11, 12509, 3209, 1715, 11, 11028, 11999, 50822], "temperature": 0.0, "avg_logprob": -0.19782183851514543, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.01925073005259037}, {"id": 66, "seek": 57588, "start": 585.04, "end": 593.72, "text": " allocation and congestion management. Since I do have some time within automatic network design", "tokens": [50822, 27599, 293, 40816, 4592, 13, 4162, 286, 360, 362, 512, 565, 1951, 12509, 3209, 1715, 51256], "temperature": 0.0, "avg_logprob": -0.19782183851514543, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.01925073005259037}, {"id": 67, "seek": 57588, "start": 593.72, "end": 605.04, "text": " for example we try to forecast what the effect of the grid based on the EV growth will happen in", "tokens": [51256, 337, 1365, 321, 853, 281, 14330, 437, 264, 1802, 295, 264, 10748, 2361, 322, 264, 15733, 4599, 486, 1051, 294, 51822], "temperature": 0.0, "avg_logprob": -0.19782183851514543, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.01925073005259037}, {"id": 68, "seek": 60504, "start": 605.04, "end": 612.5999999999999, "text": " the coming 30-40 years, EV growth and the solar panels and based on that we simulate this and then", "tokens": [50364, 264, 1348, 2217, 12, 5254, 924, 11, 15733, 4599, 293, 264, 7936, 13419, 293, 2361, 322, 300, 321, 27817, 341, 293, 550, 50742], "temperature": 0.0, "avg_logprob": -0.1545426270057415, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.02902441844344139}, {"id": 69, "seek": 60504, "start": 612.5999999999999, "end": 619.64, "text": " we identify the bottleneck, add the cable, run the simulation again and in this automatic way", "tokens": [50742, 321, 5876, 264, 44641, 547, 11, 909, 264, 8220, 11, 1190, 264, 16575, 797, 293, 294, 341, 12509, 636, 51094], "temperature": 0.0, "avg_logprob": -0.1545426270057415, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.02902441844344139}, {"id": 70, "seek": 60504, "start": 619.64, "end": 626.7199999999999, "text": " we design the whole network. That's what this application does. There are actually multiple", "tokens": [51094, 321, 1715, 264, 1379, 3209, 13, 663, 311, 437, 341, 3861, 775, 13, 821, 366, 767, 3866, 51448], "temperature": 0.0, "avg_logprob": -0.1545426270057415, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.02902441844344139}, {"id": 71, "seek": 60504, "start": 626.7199999999999, "end": 633.12, "text": " congestion management applications as well. So one is the active one with which we do real-time", "tokens": [51448, 40816, 4592, 5821, 382, 731, 13, 407, 472, 307, 264, 4967, 472, 365, 597, 321, 360, 957, 12, 3766, 51768], "temperature": 0.0, "avg_logprob": -0.1545426270057415, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.02902441844344139}, {"id": 72, "seek": 63312, "start": 633.2, "end": 639.36, "text": " congestion management. We take in the measurements from the previous 48 hours and predict if there's", "tokens": [50368, 40816, 4592, 13, 492, 747, 294, 264, 15383, 490, 264, 3894, 11174, 2496, 293, 6069, 498, 456, 311, 50676], "temperature": 0.0, "avg_logprob": -0.14600448830183163, "compression_ratio": 1.8714285714285714, "no_speech_prob": 0.033212751150131226}, {"id": 73, "seek": 63312, "start": 639.36, "end": 646.36, "text": " going to be a congestion in the coming 48 hours based on any plan maintenance if there is any and", "tokens": [50676, 516, 281, 312, 257, 40816, 294, 264, 1348, 11174, 2496, 2361, 322, 604, 1393, 11258, 498, 456, 307, 604, 293, 51026], "temperature": 0.0, "avg_logprob": -0.14600448830183163, "compression_ratio": 1.8714285714285714, "no_speech_prob": 0.033212751150131226}, {"id": 74, "seek": 63312, "start": 646.36, "end": 655.36, "text": " the other type of congestion management that we also do not present here. It's on the assessing", "tokens": [51026, 264, 661, 2010, 295, 40816, 4592, 300, 321, 611, 360, 406, 1974, 510, 13, 467, 311, 322, 264, 34348, 51476], "temperature": 0.0, "avg_logprob": -0.14600448830183163, "compression_ratio": 1.8714285714285714, "no_speech_prob": 0.033212751150131226}, {"id": 75, "seek": 63312, "start": 655.36, "end": 661.24, "text": " the measurements of the entire year of this past year and then what would be the congestion in the", "tokens": [51476, 264, 15383, 295, 264, 2302, 1064, 295, 341, 1791, 1064, 293, 550, 437, 576, 312, 264, 40816, 294, 264, 51770], "temperature": 0.0, "avg_logprob": -0.14600448830183163, "compression_ratio": 1.8714285714285714, "no_speech_prob": 0.033212751150131226}, {"id": 76, "seek": 66124, "start": 661.32, "end": 670.36, "text": " coming year and based on that we might offer new contracts to our customers because the grid in", "tokens": [50368, 1348, 1064, 293, 2361, 322, 300, 321, 1062, 2626, 777, 13952, 281, 527, 4581, 570, 264, 10748, 294, 50820], "temperature": 0.0, "avg_logprob": -0.19866128265857697, "compression_ratio": 1.553763440860215, "no_speech_prob": 0.00905662588775158}, {"id": 77, "seek": 66124, "start": 670.36, "end": 676.04, "text": " Netherlands is highly congested right now. We have a lot of people waiting for new connections but", "tokens": [50820, 20873, 307, 5405, 31871, 292, 558, 586, 13, 492, 362, 257, 688, 295, 561, 3806, 337, 777, 9271, 457, 51104], "temperature": 0.0, "avg_logprob": -0.19866128265857697, "compression_ratio": 1.553763440860215, "no_speech_prob": 0.00905662588775158}, {"id": 78, "seek": 66124, "start": 676.04, "end": 682.6800000000001, "text": " we can't add them and hence power grid model really helps in making all of these calculations.", "tokens": [51104, 321, 393, 380, 909, 552, 293, 16678, 1347, 10748, 2316, 534, 3665, 294, 1455, 439, 295, 613, 20448, 13, 51436], "temperature": 0.0, "avg_logprob": -0.19866128265857697, "compression_ratio": 1.553763440860215, "no_speech_prob": 0.00905662588775158}, {"id": 79, "seek": 68268, "start": 683.52, "end": 694.04, "text": " For the open source you can just use the library and provide feedback. That's a great contribution", "tokens": [50406, 1171, 264, 1269, 4009, 291, 393, 445, 764, 264, 6405, 293, 2893, 5824, 13, 663, 311, 257, 869, 13150, 50932], "temperature": 0.0, "avg_logprob": -0.22299788979923024, "compression_ratio": 1.5508021390374331, "no_speech_prob": 0.03195276856422424}, {"id": 80, "seek": 68268, "start": 694.04, "end": 702.9599999999999, "text": " in itself. Report any bugs as well. That's really helpful too and you can also do the validation", "tokens": [50932, 294, 2564, 13, 16057, 604, 15120, 382, 731, 13, 663, 311, 534, 4961, 886, 293, 291, 393, 611, 360, 264, 24071, 51378], "temperature": 0.0, "avg_logprob": -0.22299788979923024, "compression_ratio": 1.5508021390374331, "no_speech_prob": 0.03195276856422424}, {"id": 81, "seek": 68268, "start": 702.9599999999999, "end": 711.04, "text": " for the library with any test cases of the 80 cases that I mentioned. You can provide more and", "tokens": [51378, 337, 264, 6405, 365, 604, 1500, 3331, 295, 264, 4688, 3331, 300, 286, 2835, 13, 509, 393, 2893, 544, 293, 51782], "temperature": 0.0, "avg_logprob": -0.22299788979923024, "compression_ratio": 1.5508021390374331, "no_speech_prob": 0.03195276856422424}, {"id": 82, "seek": 71104, "start": 711.12, "end": 719.0799999999999, "text": " validate the library. You can improve if you have an idea for a new way to make the API. You can", "tokens": [50368, 29562, 264, 6405, 13, 509, 393, 3470, 498, 291, 362, 364, 1558, 337, 257, 777, 636, 281, 652, 264, 9362, 13, 509, 393, 50766], "temperature": 0.0, "avg_logprob": -0.15626499387953016, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.012730869464576244}, {"id": 83, "seek": 71104, "start": 719.0799999999999, "end": 728.52, "text": " suggest that too or you can also add new algorithms and make the code more efficient in the C++", "tokens": [50766, 3402, 300, 886, 420, 291, 393, 611, 909, 777, 14642, 293, 652, 264, 3089, 544, 7148, 294, 264, 383, 25472, 51238], "temperature": 0.0, "avg_logprob": -0.15626499387953016, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.012730869464576244}, {"id": 84, "seek": 71104, "start": 728.52, "end": 736.8, "text": " code. That's also possible. We have a list of good first issues within the repository too if you", "tokens": [51238, 3089, 13, 663, 311, 611, 1944, 13, 492, 362, 257, 1329, 295, 665, 700, 2663, 1951, 264, 25841, 886, 498, 291, 51652], "temperature": 0.0, "avg_logprob": -0.15626499387953016, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.012730869464576244}, {"id": 85, "seek": 73680, "start": 736.8399999999999, "end": 747.92, "text": " wish to have a look. We have a few partners. There are DSOs, TSO research institutions,", "tokens": [50366, 3172, 281, 362, 257, 574, 13, 492, 362, 257, 1326, 4462, 13, 821, 366, 15816, 31376, 11, 314, 17188, 2132, 8142, 11, 50920], "temperature": 0.0, "avg_logprob": -0.32412175337473553, "compression_ratio": 1.3233082706766917, "no_speech_prob": 0.014538915827870369}, {"id": 86, "seek": 73680, "start": 747.92, "end": 762.0799999999999, "text": " universities and other open source projects as well. The DSOs do use them. Aliantha does", "tokens": [50920, 11779, 293, 661, 1269, 4009, 4455, 382, 731, 13, 440, 15816, 31376, 360, 764, 552, 13, 967, 952, 13571, 775, 51628], "temperature": 0.0, "avg_logprob": -0.32412175337473553, "compression_ratio": 1.3233082706766917, "no_speech_prob": 0.014538915827870369}, {"id": 87, "seek": 76208, "start": 763.0400000000001, "end": 771.48, "text": " have those products as well as an access and study and are also trying to add to their operations.", "tokens": [50412, 362, 729, 3383, 382, 731, 382, 364, 2105, 293, 2979, 293, 366, 611, 1382, 281, 909, 281, 641, 7705, 13, 50834], "temperature": 0.0, "avg_logprob": -0.3934321016878695, "compression_ratio": 1.263157894736842, "no_speech_prob": 0.012816502712666988}, {"id": 88, "seek": 76208, "start": 771.48, "end": 777.1600000000001, "text": " That's all from me. Do we have any questions?", "tokens": [50834, 663, 311, 439, 490, 385, 13, 1144, 321, 362, 604, 1651, 30, 51118], "temperature": 0.0, "avg_logprob": -0.3934321016878695, "compression_ratio": 1.263157894736842, "no_speech_prob": 0.012816502712666988}, {"id": 89, "seek": 79208, "start": 793.08, "end": 799.2800000000001, "text": " Hello. Thank you so much. This looks really, really, really cool. I have one question. If I am", "tokens": [50414, 2425, 13, 1044, 291, 370, 709, 13, 639, 1542, 534, 11, 534, 11, 534, 1627, 13, 286, 362, 472, 1168, 13, 759, 286, 669, 50724], "temperature": 0.0, "avg_logprob": -0.24572268399325284, "compression_ratio": 1.5950413223140496, "no_speech_prob": 0.08772162348031998}, {"id": 90, "seek": 79208, "start": 799.2800000000001, "end": 806.0400000000001, "text": " running a project, hello Chris Adams, Green Web Foundation. If I have a new project on to build", "tokens": [50724, 2614, 257, 1716, 11, 7751, 6688, 25214, 11, 6969, 9573, 10335, 13, 759, 286, 362, 257, 777, 1716, 322, 281, 1322, 51062], "temperature": 0.0, "avg_logprob": -0.24572268399325284, "compression_ratio": 1.5950413223140496, "no_speech_prob": 0.08772162348031998}, {"id": 91, "seek": 79208, "start": 806.0400000000001, "end": 813.24, "text": " a big solar farm or put a 100 megawatt data center somewhere, can I use this to model how I might", "tokens": [51062, 257, 955, 7936, 5421, 420, 829, 257, 2319, 10816, 1607, 1591, 1412, 3056, 4079, 11, 393, 286, 764, 341, 281, 2316, 577, 286, 1062, 51422], "temperature": 0.0, "avg_logprob": -0.24572268399325284, "compression_ratio": 1.5950413223140496, "no_speech_prob": 0.08772162348031998}, {"id": 92, "seek": 79208, "start": 813.24, "end": 819.2, "text": " integrate with your grid to say this is why you should let me build here or possibly this is what", "tokens": [51422, 13365, 365, 428, 10748, 281, 584, 341, 307, 983, 291, 820, 718, 385, 1322, 510, 420, 6264, 341, 307, 437, 51720], "temperature": 0.0, "avg_logprob": -0.24572268399325284, "compression_ratio": 1.5950413223140496, "no_speech_prob": 0.08772162348031998}, {"id": 93, "seek": 81920, "start": 819.2800000000001, "end": 821.32, "text": " it's going to be the implication if we keep growing at this space.", "tokens": [50368, 309, 311, 516, 281, 312, 264, 37814, 498, 321, 1066, 4194, 412, 341, 1901, 13, 50470], "temperature": 0.0, "avg_logprob": -0.24448386105624112, "compression_ratio": 1.6047619047619048, "no_speech_prob": 0.023773323744535446}, {"id": 94, "seek": 81920, "start": 821.32, "end": 833.6, "text": " Yes, definitely. We do some calculations on our side. We would be able to, I mean,", "tokens": [50470, 1079, 11, 2138, 13, 492, 360, 512, 20448, 322, 527, 1252, 13, 492, 576, 312, 1075, 281, 11, 286, 914, 11, 51084], "temperature": 0.0, "avg_logprob": -0.24448386105624112, "compression_ratio": 1.6047619047619048, "no_speech_prob": 0.023773323744535446}, {"id": 95, "seek": 81920, "start": 833.6, "end": 839.2800000000001, "text": " like Aliantha does it on its side if it can integrate the customer. On the side of the", "tokens": [51084, 411, 967, 952, 13571, 775, 309, 322, 1080, 1252, 498, 309, 393, 13365, 264, 5474, 13, 1282, 264, 1252, 295, 264, 51368], "temperature": 0.0, "avg_logprob": -0.24448386105624112, "compression_ratio": 1.6047619047619048, "no_speech_prob": 0.023773323744535446}, {"id": 96, "seek": 81920, "start": 839.2800000000001, "end": 846.24, "text": " producer, the producer does it so it can identify if it's profitable to make this investment or not.", "tokens": [51368, 12314, 11, 264, 12314, 775, 309, 370, 309, 393, 5876, 498, 309, 311, 21608, 281, 652, 341, 6078, 420, 406, 13, 51716], "temperature": 0.0, "avg_logprob": -0.24448386105624112, "compression_ratio": 1.6047619047619048, "no_speech_prob": 0.023773323744535446}, {"id": 97, "seek": 84624, "start": 846.76, "end": 855.52, "text": " What would be the ROI in the coming years based on what the grid looks like? That's definitely what", "tokens": [50390, 708, 576, 312, 264, 49808, 294, 264, 1348, 924, 2361, 322, 437, 264, 10748, 1542, 411, 30, 663, 311, 2138, 437, 50828], "temperature": 0.0, "avg_logprob": -0.2527319313823313, "compression_ratio": 1.398936170212766, "no_speech_prob": 0.006733201909810305}, {"id": 98, "seek": 84624, "start": 856.16, "end": 859.04, "text": " the producers still do and they do use the model over there.", "tokens": [50860, 264, 16080, 920, 360, 293, 436, 360, 764, 264, 2316, 670, 456, 13, 51004], "temperature": 0.0, "avg_logprob": -0.2527319313823313, "compression_ratio": 1.398936170212766, "no_speech_prob": 0.006733201909810305}, {"id": 99, "seek": 84624, "start": 866.16, "end": 872.88, "text": " Hi, Peter Dutfield from Open Climate Fix. Thank you for the talk. How did you say some other TSOs have", "tokens": [51360, 2421, 11, 6508, 413, 325, 7610, 490, 7238, 27025, 25538, 13, 1044, 291, 337, 264, 751, 13, 1012, 630, 291, 584, 512, 661, 314, 17188, 82, 362, 51696], "temperature": 0.0, "avg_logprob": -0.2527319313823313, "compression_ratio": 1.398936170212766, "no_speech_prob": 0.006733201909810305}, {"id": 100, "seek": 87288, "start": 872.96, "end": 879.92, "text": " used this? Have you had any feedback from them and how they found it?", "tokens": [50368, 1143, 341, 30, 3560, 291, 632, 604, 5824, 490, 552, 293, 577, 436, 1352, 309, 30, 50716], "temperature": 0.0, "avg_logprob": -0.24597437540690104, "compression_ratio": 1.4171122994652405, "no_speech_prob": 0.0353844128549099}, {"id": 101, "seek": 87288, "start": 879.92, "end": 889.52, "text": " Well, I said that they are active partners so they did not actually use it. They are TANET and", "tokens": [50716, 1042, 11, 286, 848, 300, 436, 366, 4967, 4462, 370, 436, 630, 406, 767, 764, 309, 13, 814, 366, 314, 1770, 4850, 293, 51196], "temperature": 0.0, "avg_logprob": -0.24597437540690104, "compression_ratio": 1.4171122994652405, "no_speech_prob": 0.0353844128549099}, {"id": 102, "seek": 87288, "start": 889.52, "end": 900.24, "text": " RTE as well. I'm trying to look if they could use this model. But some of the core features of TSOs,", "tokens": [51196, 497, 13639, 382, 731, 13, 286, 478, 1382, 281, 574, 498, 436, 727, 764, 341, 2316, 13, 583, 512, 295, 264, 4965, 4122, 295, 314, 17188, 82, 11, 51732], "temperature": 0.0, "avg_logprob": -0.24597437540690104, "compression_ratio": 1.4171122994652405, "no_speech_prob": 0.0353844128549099}, {"id": 103, "seek": 90024, "start": 901.2, "end": 910.0, "text": " we do need to add them as well. That's one of the requirements from the TSO side.", "tokens": [50412, 321, 360, 643, 281, 909, 552, 382, 731, 13, 663, 311, 472, 295, 264, 7728, 490, 264, 314, 17188, 1252, 13, 50852], "temperature": 0.0, "avg_logprob": -0.21419459802133065, "compression_ratio": 1.380281690140845, "no_speech_prob": 0.033133942633867264}, {"id": 104, "seek": 90024, "start": 914.0, "end": 919.36, "text": " Once that happens, TSOs would use it as well. But the focus is primarily on the distribution", "tokens": [51052, 3443, 300, 2314, 11, 314, 17188, 82, 576, 764, 309, 382, 731, 13, 583, 264, 1879, 307, 10029, 322, 264, 7316, 51320], "temperature": 0.0, "avg_logprob": -0.21419459802133065, "compression_ratio": 1.380281690140845, "no_speech_prob": 0.033133942633867264}, {"id": 105, "seek": 90024, "start": 919.92, "end": 921.2, "text": " system analysis side.", "tokens": [51348, 1185, 5215, 1252, 13, 51412], "temperature": 0.0, "avg_logprob": -0.21419459802133065, "compression_ratio": 1.380281690140845, "no_speech_prob": 0.033133942633867264}, {"id": 106, "seek": 92120, "start": 921.44, "end": 936.4000000000001, "text": " In Germany, we have this TSO tells you please reduce your consumption. Can I use your project", "tokens": [50376, 682, 7244, 11, 321, 362, 341, 314, 17188, 5112, 291, 1767, 5407, 428, 12126, 13, 1664, 286, 764, 428, 1716, 51124], "temperature": 0.0, "avg_logprob": -0.3172836925672448, "compression_ratio": 1.3405797101449275, "no_speech_prob": 0.05569864436984062}, {"id": 107, "seek": 92120, "start": 937.2800000000001, "end": 945.84, "text": " for this calculation? Is it fine enough or is your project just a scope of the complete DSO", "tokens": [51168, 337, 341, 17108, 30, 1119, 309, 2489, 1547, 420, 307, 428, 1716, 445, 257, 11923, 295, 264, 3566, 15816, 46, 51596], "temperature": 0.0, "avg_logprob": -0.3172836925672448, "compression_ratio": 1.3405797101449275, "no_speech_prob": 0.05569864436984062}, {"id": 108, "seek": 94584, "start": 946.8000000000001, "end": 952.96, "text": " or a larger part of the grid? Can I use it for a single grid collection point or just for larger", "tokens": [50412, 420, 257, 4833, 644, 295, 264, 10748, 30, 1664, 286, 764, 309, 337, 257, 2167, 10748, 5765, 935, 420, 445, 337, 4833, 50720], "temperature": 0.0, "avg_logprob": -0.1490964755206041, "compression_ratio": 1.6368715083798884, "no_speech_prob": 0.07339271157979965}, {"id": 109, "seek": 94584, "start": 952.96, "end": 961.84, "text": " parts? Let me think if I got the question correctly. If you do have a single connection point and you", "tokens": [50720, 3166, 30, 961, 385, 519, 498, 286, 658, 264, 1168, 8944, 13, 759, 291, 360, 362, 257, 2167, 4984, 935, 293, 291, 51164], "temperature": 0.0, "avg_logprob": -0.1490964755206041, "compression_ratio": 1.6368715083798884, "no_speech_prob": 0.07339271157979965}, {"id": 110, "seek": 94584, "start": 961.84, "end": 970.08, "text": " wish to use the library, then the motivation would not be so that what would be the transition", "tokens": [51164, 3172, 281, 764, 264, 6405, 11, 550, 264, 12335, 576, 406, 312, 370, 300, 437, 576, 312, 264, 6034, 51576], "temperature": 0.0, "avg_logprob": -0.1490964755206041, "compression_ratio": 1.6368715083798884, "no_speech_prob": 0.07339271157979965}, {"id": 111, "seek": 97008, "start": 970.08, "end": 975.0400000000001, "text": " somewhere. But if it would be a profitable thing for you, right? Did I get it right?", "tokens": [50364, 4079, 13, 583, 498, 309, 576, 312, 257, 21608, 551, 337, 291, 11, 558, 30, 2589, 286, 483, 309, 558, 30, 50612], "temperature": 0.0, "avg_logprob": -0.21561127674730518, "compression_ratio": 1.5952380952380953, "no_speech_prob": 0.07935284823179245}, {"id": 112, "seek": 97008, "start": 975.6800000000001, "end": 982.48, "text": " No, the DSO uses your library to calculate that tomorrow there's not enough energy.", "tokens": [50644, 883, 11, 264, 15816, 46, 4960, 428, 6405, 281, 8873, 300, 4153, 456, 311, 406, 1547, 2281, 13, 50984], "temperature": 0.0, "avg_logprob": -0.21561127674730518, "compression_ratio": 1.5952380952380953, "no_speech_prob": 0.07935284823179245}, {"id": 113, "seek": 97008, "start": 982.48, "end": 987.36, "text": " So he wants to tell some customers please we to use your consumption tomorrow.", "tokens": [50984, 407, 415, 2738, 281, 980, 512, 4581, 1767, 321, 281, 764, 428, 12126, 4153, 13, 51228], "temperature": 0.0, "avg_logprob": -0.21561127674730518, "compression_ratio": 1.5952380952380953, "no_speech_prob": 0.07935284823179245}, {"id": 114, "seek": 97008, "start": 988.8000000000001, "end": 994.72, "text": " Is the library able to calculate this for single connection and grid connection points?", "tokens": [51300, 1119, 264, 6405, 1075, 281, 8873, 341, 337, 2167, 4984, 293, 10748, 4984, 2793, 30, 51596], "temperature": 0.0, "avg_logprob": -0.21561127674730518, "compression_ratio": 1.5952380952380953, "no_speech_prob": 0.07935284823179245}, {"id": 115, "seek": 99472, "start": 994.8000000000001, "end": 998.24, "text": " So that I can really can say you and you and you have to reduce tomorrow?", "tokens": [50368, 407, 300, 286, 393, 534, 393, 584, 291, 293, 291, 293, 291, 362, 281, 5407, 4153, 30, 50540], "temperature": 0.0, "avg_logprob": -0.1886381253804246, "compression_ratio": 1.592814371257485, "no_speech_prob": 0.042487189173698425}, {"id": 116, "seek": 99472, "start": 998.88, "end": 1002.32, "text": " Or does it just calculate a very", "tokens": [50572, 1610, 775, 309, 445, 8873, 257, 588, 50744], "temperature": 0.0, "avg_logprob": -0.1886381253804246, "compression_ratio": 1.592814371257485, "no_speech_prob": 0.042487189173698425}, {"id": 117, "seek": 99472, "start": 1007.52, "end": 1014.48, "text": " yes, is it just for a large part or also for a very narrow part of the grid?", "tokens": [51004, 2086, 11, 307, 309, 445, 337, 257, 2416, 644, 420, 611, 337, 257, 588, 9432, 644, 295, 264, 10748, 30, 51352], "temperature": 0.0, "avg_logprob": -0.1886381253804246, "compression_ratio": 1.592814371257485, "no_speech_prob": 0.042487189173698425}, {"id": 118, "seek": 99472, "start": 1015.2, "end": 1020.96, "text": " Now I understood. Nice point. The library does not do that. It just calculates the", "tokens": [51388, 823, 286, 7320, 13, 5490, 935, 13, 440, 6405, 775, 406, 360, 300, 13, 467, 445, 4322, 1024, 264, 51676], "temperature": 0.0, "avg_logprob": -0.1886381253804246, "compression_ratio": 1.592814371257485, "no_speech_prob": 0.042487189173698425}, {"id": 119, "seek": 102096, "start": 1021.9200000000001, "end": 1027.2, "text": " yeah, the power flow results, the voltages, the powers. One of the applications that I did mention", "tokens": [50412, 1338, 11, 264, 1347, 3095, 3542, 11, 264, 49614, 11, 264, 8674, 13, 1485, 295, 264, 5821, 300, 286, 630, 2152, 50676], "temperature": 0.0, "avg_logprob": -0.2476597699252042, "compression_ratio": 1.559782608695652, "no_speech_prob": 0.012935961596667767}, {"id": 120, "seek": 102096, "start": 1027.2, "end": 1038.0, "text": " about the active congestion management, we tell the customers to reduce their generations. We", "tokens": [50676, 466, 264, 4967, 40816, 4592, 11, 321, 980, 264, 4581, 281, 5407, 641, 10593, 13, 492, 51216], "temperature": 0.0, "avg_logprob": -0.2476597699252042, "compression_ratio": 1.559782608695652, "no_speech_prob": 0.012935961596667767}, {"id": 121, "seek": 102096, "start": 1038.0, "end": 1042.0, "text": " have certain contracts within Alieander to do that, but it's not part of the power grid model.", "tokens": [51216, 362, 1629, 13952, 1951, 967, 414, 4483, 281, 360, 300, 11, 457, 309, 311, 406, 644, 295, 264, 1347, 10748, 2316, 13, 51416], "temperature": 0.0, "avg_logprob": -0.2476597699252042, "compression_ratio": 1.559782608695652, "no_speech_prob": 0.012935961596667767}, {"id": 122, "seek": 105096, "start": 1050.96, "end": 1055.3, "text": " Yes.", "tokens": [50400, 1079, 13, 50581], "temperature": 1.0, "avg_logprob": -2.672476577758789, "compression_ratio": 0.3333333333333333, "no_speech_prob": 0.5716938376426697}], "language": "en"}