{"text": " Good afternoon all. I'm here to talk about the VVC decoder in FFMPEG. I'm going to introduce VVC. I should imagine if you're in this room you're already somewhat familiar or at least interested but I'll refresh some of the coding tools and some of the objectives that it has. Talk about where FFVVC, the FFMPEG VVC decoder fits into that. Again, what new coding tools VVC introduces. Talk a bit about the threading model which is one of the most more interesting things for those of you who already have some experience with FFMPEG. Then go over performance, how that compares to previous codecs and the other VVC decoders out there. Conclude the talk, talking a little bit about the Google Summer of Code program this summer and the next steps for FFMPEG. First of all, a disclaimer. I did not write very much of this code at all. The credit should go to Noemi in China who unfortunately couldn't be here today. Who am I? I am Frank Palmer. You can find me at frankclammer.com. There's various other contact details on there. I was one of the Google Summer of Code students this summer working on this project. As you saw in the agenda, we'll talk a little bit more about what that involved later. Going into the introduction then. VVC or not H265, H266, that should read, is a new standard from the Java. It's succeeding H264 and HEVC, so quite big boots to follow. It's got two main objectives. It aims to have 50% lower bit rates than HEVC for the same quality of video. As the name suggests, versatility is the other main objective. That involves a lot of new coding tools for things like screen content coding, adaptive resolution change for things like video teleconferencing, independent sub-pictures. Versatile applications underlie a lot of the decisions made in the design of VVC. The open source landscape of VVC. For encoders, you have VTM, which is the reference software. You're not really going to want to use that for practical encoding. You have ENC, VVNC, which is developed by the Fraunhofer Institute. That is a practical decoder, encoder very fast. Finally, you have UVG266, which is an open source project developed by the community. Then on the decoder side, you again have VTM. You have the dual of VVNC, you have VVDEC, which I believe there's a lightning talk on that in a little while, which is very fast, very good decoder. You have also developed by the Fraunhofer Institute. You have OpenVVC, which is a community project VVC decoder, which is relatively performant for a single core. Unfortunately, that has now been abandoned. I don't think there's been a commit in about two years. Finally, we have what this talk is introducing, FFVVC. The state of FFVVC, the C code was merged at the start of the year. I believe it was a month ago exactly now. As John Baptiste talked about in his talk a little while ago, we believe it will be in FFMPEG 7.0, but possibly under some sort of experimental flag. The Inter-Prediction Assembly has just been merged about a week ago. We have some other assembly that has been written and is in the review process. It's important to note though that FFVVC is not yet maintain complete. There are some coding tools that are missing. The big one that we've heard from the community is intra-block copy support is not yet implemented. There is a patch set for that that's in the works. I'd be doubtful it will be in the 7.0 release of FFVVC though. Most of the other features that are missing are things that are a bit more exotic than intra-block copy. Features such as wrap around for 360 degree videos not yet implemented, independent sub-pictures, reference picture resizing, some of the more exotic stuff, but that will all come in time. This shows the assembly status, what has been written so far, what we're prioritizing, and what we've been able to reuse from HEVC. Things that we've prioritized so far are largely low hanging fruits. The inter-prediction we were able to reuse quite a lot of that from HEVC for good gain. SAO is entirely identical between HEVC and VVC so we've been able to rip that directly. Inter-prediction and ALF are both big contributors to the decode time in C only, their high priority. One of the GSOC projects last year was working on the ALF stuff so we'll talk about that a bit more so that's on its way. Inter we've managed to get some bits out of David for the more generic stuff just like averaging functions. That's been effective in getting a quick speed up there but we need your help with this. There's not many of us working on this at the moment and there's a lot of assembly to write. That's going to be key to performance as we'll see in the performance later on. Decoder size. I believe the biggest decoder now in FFMPEG in terms of lines of C. I'm not sure how it compares to David but even being the biggest decoder in FFMPEG it's still much smaller than open VVC and VVDC as you can see here. How do we manage to achieve that? By being in FFMPEG basically we're able to reuse parts from previous codecs. We're able to use the CBS Quebec reader you can see there and reuse like whole swathes of code also parts of the binary so it's kind of hard to measure that but you get a more bang for your buck in terms of the size of a compiled delivery codec. In the future I believe we may be able to also use some aspects of hardware decoder APIs to do the DPB reference management. We managed to be much much smaller and that's one of the main reasons really motivating putting this inside of FFMPEG. The other one being FFMPEG's vibrant community we can say which hopefully will help maintain this into the future. Moving on to what's new in VVC so there's a lot of new coding tools like a dizzying amount. You can see here you could talk for an hour and many people have about even a subset of these. As you say we haven't implemented them all yet but there's loads to play with which yeah feedback to them the ability to make much smaller bit streams and also to make more versatile video content. What FFVVC introduces that's new for FFMPEG is this stage-based thread model so lots of previous codecs have the frame and slice thread models which do well for sort of low number of cores but have some sort of here ceiling at certain point and so FFVVC uses a much more fine-grained thread model which is able to allocate threads based on the stage of decoding individual CTUs and yeah as that says it means we're able to much better utilize higher core counts and so our C code with no assembly we're able to decode 4k over 30 fps on you know relatively high-end desktop processor but I think that's really impressive. This thread model is possible to implement in HEVC. FFVVC does not use it I think it's also possible to do stage-based decoding in AV1 but it wasn't a factor in the design of AVC. The way that it works is you divide each CTU into several stages of decoding they're all listed there and the key thing is that each stage depends only on the current or previous stage of the neighboring CTUs and so you can start doing the D block of one stage before you've done the pass even in the like top left corner very far away sorry before you've done the intro I think you have to do the pass for all first and the effect you get from this is this sort of wave front that progresses across the image of each of the different stages and yeah it allows you to use much more cores. To allocate those cores we've had to introduce this new AV executor utility which has been made available in LibAVUtil so you can use this for other projects inside FFMpeg. It's a really simple algorithm at the moment but centralizing the control of allocation of threads you know not repeating yourself means we have now one location where we can make improvements here. It's a really simple algorithm it's based on I think some of the earlier implementations inside Python and Java's executor structures or whatever they call them but yeah having that one thing in one location that can be used throughout FFMpeg to improve multi-threading. Yeah so onto the performance section so at the moment it's pretty slow compared to previous codecs I mean this is to be expected by to a certain extent VVC is just a more complex codec than previous generation stuff it has to be in order to achieve high rates compression. This SIMD here false and true for FFVVC so this is with stuff that's not yet in FFMpeg master this is with the current state on the development staging repo. You can see we are getting about over 200 over a doubling of speed increase for FFVVC already but there's a long way to go as you can see from David's really impressive assembly speed up they have there but our multi-threading picture is quite different so that shows you the effect of doing that stage based multi-threading we're just much more easily able to use higher numbers cause yeah note here that this is using hyperthreading which is why you've got quite the knee there at six threads and but below six threads it's really not far off from that ideal you get a core you get the same multiplicative increase in the speed up comparing it to VVDC then. VVDC uses the same stage based threading model so you're getting a very similar performance between FFVVC and VVDC. Open VVC uses the conventional frame and tile based multi-threading techniques so that's quite useful on the left hand side there that figure to compare what is the effect of this new threading model but you can see and then on the right hand side the single threaded performance C only between FFVVC and VVDC is pretty much on par. VVDC behaves has quite significantly different performance on different operating systems but the average between the two is pretty much the same and on 4k it's a similar picture but everything just gets slightly more pronounced. Open VVC is slower that the speed up that we're getting from using more threads matters even more for larger videos so you can see that effect here but we're still lacking on the assembly front so VVDC has a lot of assembly already for quite a few different architectures and you can see that they're really pulling ahead once you enable the assembly there. The theoretically FFNPEG VVDC decoder should have somewhat of a higher ceiling due to the fact that FFVVC's assembly will be handwritten whereas VVDC's is using intrinsics and on some architectures using SIMD anywhere as like a portable SIMD library which introduces them overhead so with enough time hopefully FFVVC can be even faster but we've got a long way to go to catch up to them at the moment. So just sort of wrapping up to the last couple of things here so talking about the Google Summer of Code program in 2023 so there was two Google Summer of Code students contributing to the VVDC decoder this summer. Myself and Sean Liu so I worked on a lot of the stuff that was added in version two of VVDC so that includes the support for 12 and 14 bit which needs the range extension which changes various things to the entropy encoder when you get to higher bit depths and I've also been working on AVX2 optimizations for the inverse transforms they all had to be written from scratch in the end there's not very much that you can share between HEVC and VVC due to the way that the HEVC transforms are written in FFNPEG and Sean Liu is working on also on assembly transforms for the filters which some of them are in the process of being upstreamed at the moment I believe. So yeah next steps as I'm sure this performance and what we've been working on has sort of shown we've got a very solid baseline with the C performance and the multi-threading but we need lots more assembly in there to be able to compete with existing decoders so upstreaming and what we've already got implementing more functions with assembly also more architectures so ARM is going to be a Google Summer of Code project for this summer potentially also risk five there's a lot of work on doing risk five assembly for FFNPEG at the moment so we'll need that in time polishing off the maintain conformance so implementing those features that I mentioned for missing earlier particularly intra block copy is a high priority the thread optimization 32 plus cores so we may be able to improve the AVX2 utility for higher core counts if there's sufficient demand for that and the GPU based decoder so a lot of the stuff in VBC is really well designed particularly to do with the separation of stages that we saw earlier means that it's really well suited to decoding on the GPU so that's something on the far horizon. Concluding so FFNPEG now has a VBC decoder I've introduced that new threading model showing some of the benefits of that talks about the C in multi-threading performance and how that compares with VVDC and given an update on the status including the optimized assembly we're currently working on we'd help with this like especially with the assembly there's just very few of us who only work in our free time so progress on that front has been relatively slow so yeah patches welcome alright yeah thank you very much for listening. If anyone's got any questions I'll be happy to try and answer them as best I can as I said in that just like disclaimer I did not write very much of this code I just did you know the bits I've talked about and then I've worked on doing bug fixes especially since we've one thing I forgot to mention part of why we're going to have to be experimental is OSS fuzz we've only recently started being fuzzed since we went into FFNPEG master so we're getting a lot of reports for that at the moment that we're trying to work through before we go into like a normal release but I'll try and answer any questions as best I can yes. So the question was have we considered trying to use C in forensics? Yeah as a step between having fully C code and having handwritten assembly for everything it's not the FFNPEG way FFNPEG everything is handwritten assembly I think there's a little bit in like lib SW scale I believe but that's when the FFNPEG is in the process of removing that tiny bit of C in forensics that we still have so yeah I mean we're probably not going to do that just out of you can go faster with handwritten assembly so if we're trying to get that same performance and even be VVDC I think it's the only way to go really. Okay there's no more questions yeah thank you very much.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 13.56, "text": " Good afternoon all. I'm here to talk about the VVC decoder in FFMPEG. I'm going to introduce", "tokens": [50364, 2205, 6499, 439, 13, 286, 478, 510, 281, 751, 466, 264, 691, 53, 34, 979, 19866, 294, 479, 37, 44, 5208, 38, 13, 286, 478, 516, 281, 5366, 51042], "temperature": 0.0, "avg_logprob": -0.24336398275274979, "compression_ratio": 1.478494623655914, "no_speech_prob": 0.2709618806838989}, {"id": 1, "seek": 0, "start": 13.56, "end": 17.0, "text": " VVC. I should imagine if you're in this room you're already somewhat familiar or at least", "tokens": [51042, 691, 53, 34, 13, 286, 820, 3811, 498, 291, 434, 294, 341, 1808, 291, 434, 1217, 8344, 4963, 420, 412, 1935, 51214], "temperature": 0.0, "avg_logprob": -0.24336398275274979, "compression_ratio": 1.478494623655914, "no_speech_prob": 0.2709618806838989}, {"id": 2, "seek": 0, "start": 17.0, "end": 22.52, "text": " interested but I'll refresh some of the coding tools and some of the objectives that it has.", "tokens": [51214, 3102, 457, 286, 603, 15134, 512, 295, 264, 17720, 3873, 293, 512, 295, 264, 15961, 300, 309, 575, 13, 51490], "temperature": 0.0, "avg_logprob": -0.24336398275274979, "compression_ratio": 1.478494623655914, "no_speech_prob": 0.2709618806838989}, {"id": 3, "seek": 2252, "start": 23.04, "end": 31.6, "text": " Talk about where FFVVC, the FFMPEG VVC decoder fits into that. Again, what new coding tools", "tokens": [50390, 8780, 466, 689, 479, 37, 53, 53, 34, 11, 264, 479, 37, 44, 5208, 38, 691, 53, 34, 979, 19866, 9001, 666, 300, 13, 3764, 11, 437, 777, 17720, 3873, 50818], "temperature": 0.0, "avg_logprob": -0.2038964957834404, "compression_ratio": 1.5798319327731092, "no_speech_prob": 0.1368420422077179}, {"id": 4, "seek": 2252, "start": 31.6, "end": 36.04, "text": " VVC introduces. Talk a bit about the threading model which is one of the most more interesting", "tokens": [50818, 691, 53, 34, 31472, 13, 8780, 257, 857, 466, 264, 7207, 278, 2316, 597, 307, 472, 295, 264, 881, 544, 1880, 51040], "temperature": 0.0, "avg_logprob": -0.2038964957834404, "compression_ratio": 1.5798319327731092, "no_speech_prob": 0.1368420422077179}, {"id": 5, "seek": 2252, "start": 36.04, "end": 42.239999999999995, "text": " things for those of you who already have some experience with FFMPEG. Then go over performance,", "tokens": [51040, 721, 337, 729, 295, 291, 567, 1217, 362, 512, 1752, 365, 479, 37, 44, 5208, 38, 13, 1396, 352, 670, 3389, 11, 51350], "temperature": 0.0, "avg_logprob": -0.2038964957834404, "compression_ratio": 1.5798319327731092, "no_speech_prob": 0.1368420422077179}, {"id": 6, "seek": 2252, "start": 42.239999999999995, "end": 50.36, "text": " how that compares to previous codecs and the other VVC decoders out there. Conclude the talk,", "tokens": [51350, 577, 300, 38334, 281, 3894, 3089, 14368, 293, 264, 661, 691, 53, 34, 979, 378, 433, 484, 456, 13, 18200, 32334, 264, 751, 11, 51756], "temperature": 0.0, "avg_logprob": -0.2038964957834404, "compression_ratio": 1.5798319327731092, "no_speech_prob": 0.1368420422077179}, {"id": 7, "seek": 5036, "start": 50.4, "end": 55.44, "text": " talking a little bit about the Google Summer of Code program this summer and the next steps", "tokens": [50366, 1417, 257, 707, 857, 466, 264, 3329, 16161, 295, 15549, 1461, 341, 4266, 293, 264, 958, 4439, 50618], "temperature": 0.0, "avg_logprob": -0.21920471565396177, "compression_ratio": 1.4689922480620154, "no_speech_prob": 0.09227252006530762}, {"id": 8, "seek": 5036, "start": 55.44, "end": 62.36, "text": " for FFMPEG. First of all, a disclaimer. I did not write very much of this code at all. The", "tokens": [50618, 337, 479, 37, 44, 5208, 38, 13, 2386, 295, 439, 11, 257, 40896, 13, 286, 630, 406, 2464, 588, 709, 295, 341, 3089, 412, 439, 13, 440, 50964], "temperature": 0.0, "avg_logprob": -0.21920471565396177, "compression_ratio": 1.4689922480620154, "no_speech_prob": 0.09227252006530762}, {"id": 9, "seek": 5036, "start": 62.36, "end": 71.16, "text": " credit should go to Noemi in China who unfortunately couldn't be here today. Who am I? I am Frank", "tokens": [50964, 5397, 820, 352, 281, 883, 13372, 294, 3533, 567, 7015, 2809, 380, 312, 510, 965, 13, 2102, 669, 286, 30, 286, 669, 6823, 51404], "temperature": 0.0, "avg_logprob": -0.21920471565396177, "compression_ratio": 1.4689922480620154, "no_speech_prob": 0.09227252006530762}, {"id": 10, "seek": 5036, "start": 71.16, "end": 76.32, "text": " Palmer. You can find me at frankclammer.com. There's various other contact details on there. I was", "tokens": [51404, 43889, 13, 509, 393, 915, 385, 412, 10455, 3474, 335, 936, 13, 1112, 13, 821, 311, 3683, 661, 3385, 4365, 322, 456, 13, 286, 390, 51662], "temperature": 0.0, "avg_logprob": -0.21920471565396177, "compression_ratio": 1.4689922480620154, "no_speech_prob": 0.09227252006530762}, {"id": 11, "seek": 7632, "start": 76.39999999999999, "end": 82.24, "text": " one of the Google Summer of Code students this summer working on this project. As you saw in", "tokens": [50368, 472, 295, 264, 3329, 16161, 295, 15549, 1731, 341, 4266, 1364, 322, 341, 1716, 13, 1018, 291, 1866, 294, 50660], "temperature": 0.0, "avg_logprob": -0.16949496331152977, "compression_ratio": 1.4236453201970443, "no_speech_prob": 0.01296737976372242}, {"id": 12, "seek": 7632, "start": 82.24, "end": 88.39999999999999, "text": " the agenda, we'll talk a little bit more about what that involved later. Going into the introduction", "tokens": [50660, 264, 9829, 11, 321, 603, 751, 257, 707, 857, 544, 466, 437, 300, 3288, 1780, 13, 10963, 666, 264, 9339, 50968], "temperature": 0.0, "avg_logprob": -0.16949496331152977, "compression_ratio": 1.4236453201970443, "no_speech_prob": 0.01296737976372242}, {"id": 13, "seek": 7632, "start": 88.39999999999999, "end": 98.28, "text": " then. VVC or not H265, H266, that should read, is a new standard from the Java. It's succeeding", "tokens": [50968, 550, 13, 691, 53, 34, 420, 406, 389, 10880, 20, 11, 389, 10880, 21, 11, 300, 820, 1401, 11, 307, 257, 777, 3832, 490, 264, 10745, 13, 467, 311, 47912, 51462], "temperature": 0.0, "avg_logprob": -0.16949496331152977, "compression_ratio": 1.4236453201970443, "no_speech_prob": 0.01296737976372242}, {"id": 14, "seek": 9828, "start": 99.24, "end": 108.96000000000001, "text": " H264 and HEVC, so quite big boots to follow. It's got two main objectives. It aims to have 50%", "tokens": [50412, 389, 10880, 19, 293, 11827, 53, 34, 11, 370, 1596, 955, 15194, 281, 1524, 13, 467, 311, 658, 732, 2135, 15961, 13, 467, 24683, 281, 362, 2625, 4, 50898], "temperature": 0.0, "avg_logprob": -0.1670236298532197, "compression_ratio": 1.6083333333333334, "no_speech_prob": 0.261617511510849}, {"id": 15, "seek": 9828, "start": 108.96000000000001, "end": 116.4, "text": " lower bit rates than HEVC for the same quality of video. As the name suggests, versatility is", "tokens": [50898, 3126, 857, 6846, 813, 11827, 53, 34, 337, 264, 912, 3125, 295, 960, 13, 1018, 264, 1315, 13409, 11, 1774, 20758, 307, 51270], "temperature": 0.0, "avg_logprob": -0.1670236298532197, "compression_ratio": 1.6083333333333334, "no_speech_prob": 0.261617511510849}, {"id": 16, "seek": 9828, "start": 116.4, "end": 121.04, "text": " the other main objective. That involves a lot of new coding tools for things like screen content", "tokens": [51270, 264, 661, 2135, 10024, 13, 663, 11626, 257, 688, 295, 777, 17720, 3873, 337, 721, 411, 2568, 2701, 51502], "temperature": 0.0, "avg_logprob": -0.1670236298532197, "compression_ratio": 1.6083333333333334, "no_speech_prob": 0.261617511510849}, {"id": 17, "seek": 9828, "start": 121.04, "end": 127.56, "text": " coding, adaptive resolution change for things like video teleconferencing, independent sub-pictures.", "tokens": [51502, 17720, 11, 27912, 8669, 1319, 337, 721, 411, 960, 4304, 1671, 612, 13644, 11, 6695, 1422, 12, 79, 985, 1303, 13, 51828], "temperature": 0.0, "avg_logprob": -0.1670236298532197, "compression_ratio": 1.6083333333333334, "no_speech_prob": 0.261617511510849}, {"id": 18, "seek": 12756, "start": 128.52, "end": 134.16, "text": " Versatile applications underlie a lot of the decisions made in the design of VVC.", "tokens": [50412, 12226, 17445, 5821, 833, 6302, 257, 688, 295, 264, 5327, 1027, 294, 264, 1715, 295, 691, 53, 34, 13, 50694], "temperature": 0.0, "avg_logprob": -0.2629867591480217, "compression_ratio": 1.5517241379310345, "no_speech_prob": 0.002085874555632472}, {"id": 19, "seek": 12756, "start": 134.16, "end": 142.0, "text": " The open source landscape of VVC. For encoders, you have VTM, which is the reference software.", "tokens": [50694, 440, 1269, 4009, 9661, 295, 691, 53, 34, 13, 1171, 2058, 378, 433, 11, 291, 362, 691, 42023, 11, 597, 307, 264, 6408, 4722, 13, 51086], "temperature": 0.0, "avg_logprob": -0.2629867591480217, "compression_ratio": 1.5517241379310345, "no_speech_prob": 0.002085874555632472}, {"id": 20, "seek": 12756, "start": 142.0, "end": 147.08, "text": " You're not really going to want to use that for practical encoding. You have ENC, VVNC,", "tokens": [51086, 509, 434, 406, 534, 516, 281, 528, 281, 764, 300, 337, 8496, 43430, 13, 509, 362, 15244, 34, 11, 691, 53, 45, 34, 11, 51340], "temperature": 0.0, "avg_logprob": -0.2629867591480217, "compression_ratio": 1.5517241379310345, "no_speech_prob": 0.002085874555632472}, {"id": 21, "seek": 12756, "start": 147.08, "end": 153.8, "text": " which is developed by the Fraunhofer Institute. That is a practical decoder, encoder very fast.", "tokens": [51340, 597, 307, 4743, 538, 264, 5849, 409, 1289, 612, 9446, 13, 663, 307, 257, 8496, 979, 19866, 11, 2058, 19866, 588, 2370, 13, 51676], "temperature": 0.0, "avg_logprob": -0.2629867591480217, "compression_ratio": 1.5517241379310345, "no_speech_prob": 0.002085874555632472}, {"id": 22, "seek": 15380, "start": 154.76000000000002, "end": 161.32000000000002, "text": " Finally, you have UVG266, which is an open source project developed by the community.", "tokens": [50412, 6288, 11, 291, 362, 17887, 38, 10880, 21, 11, 597, 307, 364, 1269, 4009, 1716, 4743, 538, 264, 1768, 13, 50740], "temperature": 0.0, "avg_logprob": -0.22289277957035944, "compression_ratio": 1.614678899082569, "no_speech_prob": 0.010906057432293892}, {"id": 23, "seek": 15380, "start": 164.84, "end": 171.64000000000001, "text": " Then on the decoder side, you again have VTM. You have the dual of VVNC, you have VVDEC,", "tokens": [50916, 1396, 322, 264, 979, 19866, 1252, 11, 291, 797, 362, 691, 42023, 13, 509, 362, 264, 11848, 295, 691, 53, 45, 34, 11, 291, 362, 691, 53, 35, 8140, 11, 51256], "temperature": 0.0, "avg_logprob": -0.22289277957035944, "compression_ratio": 1.614678899082569, "no_speech_prob": 0.010906057432293892}, {"id": 24, "seek": 15380, "start": 171.64000000000001, "end": 175.12, "text": " which I believe there's a lightning talk on that in a little while, which is very fast,", "tokens": [51256, 597, 286, 1697, 456, 311, 257, 16589, 751, 322, 300, 294, 257, 707, 1339, 11, 597, 307, 588, 2370, 11, 51430], "temperature": 0.0, "avg_logprob": -0.22289277957035944, "compression_ratio": 1.614678899082569, "no_speech_prob": 0.010906057432293892}, {"id": 25, "seek": 15380, "start": 175.12, "end": 181.12, "text": " very good decoder. You have also developed by the Fraunhofer Institute. You have OpenVVC,", "tokens": [51430, 588, 665, 979, 19866, 13, 509, 362, 611, 4743, 538, 264, 5849, 409, 1289, 612, 9446, 13, 509, 362, 7238, 53, 53, 34, 11, 51730], "temperature": 0.0, "avg_logprob": -0.22289277957035944, "compression_ratio": 1.614678899082569, "no_speech_prob": 0.010906057432293892}, {"id": 26, "seek": 18112, "start": 181.24, "end": 188.24, "text": " which is a community project VVC decoder, which is relatively performant for a single", "tokens": [50370, 597, 307, 257, 1768, 1716, 691, 53, 34, 979, 19866, 11, 597, 307, 7226, 2042, 394, 337, 257, 2167, 50720], "temperature": 0.0, "avg_logprob": -0.15226661682128906, "compression_ratio": 1.5411255411255411, "no_speech_prob": 0.003613370703533292}, {"id": 27, "seek": 18112, "start": 188.24, "end": 192.6, "text": " core. Unfortunately, that has now been abandoned. I don't think there's been a commit in about two", "tokens": [50720, 4965, 13, 8590, 11, 300, 575, 586, 668, 13732, 13, 286, 500, 380, 519, 456, 311, 668, 257, 5599, 294, 466, 732, 50938], "temperature": 0.0, "avg_logprob": -0.15226661682128906, "compression_ratio": 1.5411255411255411, "no_speech_prob": 0.003613370703533292}, {"id": 28, "seek": 18112, "start": 192.6, "end": 200.64000000000001, "text": " years. Finally, we have what this talk is introducing, FFVVC. The state of FFVVC,", "tokens": [50938, 924, 13, 6288, 11, 321, 362, 437, 341, 751, 307, 15424, 11, 479, 37, 53, 53, 34, 13, 440, 1785, 295, 479, 37, 53, 53, 34, 11, 51340], "temperature": 0.0, "avg_logprob": -0.15226661682128906, "compression_ratio": 1.5411255411255411, "no_speech_prob": 0.003613370703533292}, {"id": 29, "seek": 18112, "start": 200.64000000000001, "end": 206.68, "text": " the C code was merged at the start of the year. I believe it was a month ago exactly now.", "tokens": [51340, 264, 383, 3089, 390, 36427, 412, 264, 722, 295, 264, 1064, 13, 286, 1697, 309, 390, 257, 1618, 2057, 2293, 586, 13, 51642], "temperature": 0.0, "avg_logprob": -0.15226661682128906, "compression_ratio": 1.5411255411255411, "no_speech_prob": 0.003613370703533292}, {"id": 30, "seek": 20668, "start": 207.68, "end": 213.28, "text": " As John Baptiste talked about in his talk a little while ago, we believe it will be in", "tokens": [50414, 1018, 2619, 25991, 8375, 2825, 466, 294, 702, 751, 257, 707, 1339, 2057, 11, 321, 1697, 309, 486, 312, 294, 50694], "temperature": 0.0, "avg_logprob": -0.17770568691954322, "compression_ratio": 1.4642857142857142, "no_speech_prob": 0.008719547651708126}, {"id": 31, "seek": 20668, "start": 213.28, "end": 221.36, "text": " FFMPEG 7.0, but possibly under some sort of experimental flag. The Inter-Prediction Assembly", "tokens": [50694, 479, 37, 44, 5208, 38, 1614, 13, 15, 11, 457, 6264, 833, 512, 1333, 295, 17069, 7166, 13, 440, 5751, 12, 47, 986, 4105, 20399, 51098], "temperature": 0.0, "avg_logprob": -0.17770568691954322, "compression_ratio": 1.4642857142857142, "no_speech_prob": 0.008719547651708126}, {"id": 32, "seek": 20668, "start": 221.36, "end": 225.72, "text": " has just been merged about a week ago. We have some other assembly that has been written and is", "tokens": [51098, 575, 445, 668, 36427, 466, 257, 1243, 2057, 13, 492, 362, 512, 661, 12103, 300, 575, 668, 3720, 293, 307, 51316], "temperature": 0.0, "avg_logprob": -0.17770568691954322, "compression_ratio": 1.4642857142857142, "no_speech_prob": 0.008719547651708126}, {"id": 33, "seek": 20668, "start": 225.72, "end": 232.96, "text": " in the review process. It's important to note though that FFVVC is not yet maintain complete.", "tokens": [51316, 294, 264, 3131, 1399, 13, 467, 311, 1021, 281, 3637, 1673, 300, 479, 37, 53, 53, 34, 307, 406, 1939, 6909, 3566, 13, 51678], "temperature": 0.0, "avg_logprob": -0.17770568691954322, "compression_ratio": 1.4642857142857142, "no_speech_prob": 0.008719547651708126}, {"id": 34, "seek": 23296, "start": 233.08, "end": 238.12, "text": " There are some coding tools that are missing. The big one that we've heard from the community is", "tokens": [50370, 821, 366, 512, 17720, 3873, 300, 366, 5361, 13, 440, 955, 472, 300, 321, 600, 2198, 490, 264, 1768, 307, 50622], "temperature": 0.0, "avg_logprob": -0.1989131776413115, "compression_ratio": 1.6493506493506493, "no_speech_prob": 0.027368061244487762}, {"id": 35, "seek": 23296, "start": 238.12, "end": 243.44, "text": " intra-block copy support is not yet implemented. There is a patch set for that that's in the works.", "tokens": [50622, 43358, 12, 28830, 5055, 1406, 307, 406, 1939, 12270, 13, 821, 307, 257, 9972, 992, 337, 300, 300, 311, 294, 264, 1985, 13, 50888], "temperature": 0.0, "avg_logprob": -0.1989131776413115, "compression_ratio": 1.6493506493506493, "no_speech_prob": 0.027368061244487762}, {"id": 36, "seek": 23296, "start": 243.44, "end": 255.04000000000002, "text": " I'd be doubtful it will be in the 7.0 release of FFVVC though. Most of the other features", "tokens": [50888, 286, 1116, 312, 6385, 906, 309, 486, 312, 294, 264, 1614, 13, 15, 4374, 295, 479, 37, 53, 53, 34, 1673, 13, 4534, 295, 264, 661, 4122, 51468], "temperature": 0.0, "avg_logprob": -0.1989131776413115, "compression_ratio": 1.6493506493506493, "no_speech_prob": 0.027368061244487762}, {"id": 37, "seek": 23296, "start": 255.04000000000002, "end": 260.56, "text": " that are missing are things that are a bit more exotic than intra-block copy. Features such as", "tokens": [51468, 300, 366, 5361, 366, 721, 300, 366, 257, 857, 544, 27063, 813, 43358, 12, 28830, 5055, 13, 3697, 3377, 1270, 382, 51744], "temperature": 0.0, "avg_logprob": -0.1989131776413115, "compression_ratio": 1.6493506493506493, "no_speech_prob": 0.027368061244487762}, {"id": 38, "seek": 26056, "start": 261.08, "end": 267.36, "text": " wrap around for 360 degree videos not yet implemented, independent sub-pictures,", "tokens": [50390, 7019, 926, 337, 13898, 4314, 2145, 406, 1939, 12270, 11, 6695, 1422, 12, 79, 985, 1303, 11, 50704], "temperature": 0.0, "avg_logprob": -0.2110495620898986, "compression_ratio": 1.543859649122807, "no_speech_prob": 0.0029486550483852625}, {"id": 39, "seek": 26056, "start": 267.36, "end": 272.36, "text": " reference picture resizing, some of the more exotic stuff, but that will all come in time.", "tokens": [50704, 6408, 3036, 725, 3319, 11, 512, 295, 264, 544, 27063, 1507, 11, 457, 300, 486, 439, 808, 294, 565, 13, 50954], "temperature": 0.0, "avg_logprob": -0.2110495620898986, "compression_ratio": 1.543859649122807, "no_speech_prob": 0.0029486550483852625}, {"id": 40, "seek": 26056, "start": 272.36, "end": 281.4, "text": " This shows the assembly status, what has been written so far, what we're prioritizing,", "tokens": [50954, 639, 3110, 264, 12103, 6558, 11, 437, 575, 668, 3720, 370, 1400, 11, 437, 321, 434, 14846, 3319, 11, 51406], "temperature": 0.0, "avg_logprob": -0.2110495620898986, "compression_ratio": 1.543859649122807, "no_speech_prob": 0.0029486550483852625}, {"id": 41, "seek": 26056, "start": 281.4, "end": 287.6, "text": " and what we've been able to reuse from HEVC. Things that we've prioritized so far are largely", "tokens": [51406, 293, 437, 321, 600, 668, 1075, 281, 26225, 490, 11827, 53, 34, 13, 9514, 300, 321, 600, 14846, 1602, 370, 1400, 366, 11611, 51716], "temperature": 0.0, "avg_logprob": -0.2110495620898986, "compression_ratio": 1.543859649122807, "no_speech_prob": 0.0029486550483852625}, {"id": 42, "seek": 28760, "start": 288.24, "end": 294.20000000000005, "text": " low hanging fruits. The inter-prediction we were able to reuse quite a lot of that from HEVC for", "tokens": [50396, 2295, 8345, 12148, 13, 440, 728, 12, 79, 986, 4105, 321, 645, 1075, 281, 26225, 1596, 257, 688, 295, 300, 490, 11827, 53, 34, 337, 50694], "temperature": 0.0, "avg_logprob": -0.21575555801391602, "compression_ratio": 1.4375, "no_speech_prob": 0.0049132187850773335}, {"id": 43, "seek": 28760, "start": 294.20000000000005, "end": 301.8, "text": " good gain. SAO is entirely identical between HEVC and VVC so we've been able to rip that directly.", "tokens": [50694, 665, 6052, 13, 16482, 46, 307, 7696, 14800, 1296, 11827, 53, 34, 293, 691, 53, 34, 370, 321, 600, 668, 1075, 281, 12782, 300, 3838, 13, 51074], "temperature": 0.0, "avg_logprob": -0.21575555801391602, "compression_ratio": 1.4375, "no_speech_prob": 0.0049132187850773335}, {"id": 44, "seek": 28760, "start": 301.8, "end": 310.16, "text": " Inter-prediction and ALF are both big contributors to the decode time in C only,", "tokens": [51074, 5751, 12, 79, 986, 4105, 293, 7056, 37, 366, 1293, 955, 45627, 281, 264, 979, 1429, 565, 294, 383, 787, 11, 51492], "temperature": 0.0, "avg_logprob": -0.21575555801391602, "compression_ratio": 1.4375, "no_speech_prob": 0.0049132187850773335}, {"id": 45, "seek": 31016, "start": 310.72, "end": 318.40000000000003, "text": " their high priority. One of the GSOC projects last year was working on the ALF stuff so we'll", "tokens": [50392, 641, 1090, 9365, 13, 1485, 295, 264, 460, 17188, 34, 4455, 1036, 1064, 390, 1364, 322, 264, 7056, 37, 1507, 370, 321, 603, 50776], "temperature": 0.0, "avg_logprob": -0.16333103968092233, "compression_ratio": 1.657439446366782, "no_speech_prob": 0.0452108159661293}, {"id": 46, "seek": 31016, "start": 318.40000000000003, "end": 322.92, "text": " talk about that a bit more so that's on its way. Inter we've managed to get some bits out of David", "tokens": [50776, 751, 466, 300, 257, 857, 544, 370, 300, 311, 322, 1080, 636, 13, 5751, 321, 600, 6453, 281, 483, 512, 9239, 484, 295, 4389, 51002], "temperature": 0.0, "avg_logprob": -0.16333103968092233, "compression_ratio": 1.657439446366782, "no_speech_prob": 0.0452108159661293}, {"id": 47, "seek": 31016, "start": 322.92, "end": 328.72, "text": " for the more generic stuff just like averaging functions. That's been effective in getting a", "tokens": [51002, 337, 264, 544, 19577, 1507, 445, 411, 47308, 6828, 13, 663, 311, 668, 4942, 294, 1242, 257, 51292], "temperature": 0.0, "avg_logprob": -0.16333103968092233, "compression_ratio": 1.657439446366782, "no_speech_prob": 0.0452108159661293}, {"id": 48, "seek": 31016, "start": 328.72, "end": 333.32000000000005, "text": " quick speed up there but we need your help with this. There's not many of us working on this at", "tokens": [51292, 1702, 3073, 493, 456, 457, 321, 643, 428, 854, 365, 341, 13, 821, 311, 406, 867, 295, 505, 1364, 322, 341, 412, 51522], "temperature": 0.0, "avg_logprob": -0.16333103968092233, "compression_ratio": 1.657439446366782, "no_speech_prob": 0.0452108159661293}, {"id": 49, "seek": 31016, "start": 333.32000000000005, "end": 338.76000000000005, "text": " the moment and there's a lot of assembly to write. That's going to be key to performance as we'll", "tokens": [51522, 264, 1623, 293, 456, 311, 257, 688, 295, 12103, 281, 2464, 13, 663, 311, 516, 281, 312, 2141, 281, 3389, 382, 321, 603, 51794], "temperature": 0.0, "avg_logprob": -0.16333103968092233, "compression_ratio": 1.657439446366782, "no_speech_prob": 0.0452108159661293}, {"id": 50, "seek": 33876, "start": 338.84, "end": 348.03999999999996, "text": " see in the performance later on. Decoder size. I believe the biggest decoder now in FFMPEG in", "tokens": [50368, 536, 294, 264, 3389, 1780, 322, 13, 12427, 19866, 2744, 13, 286, 1697, 264, 3880, 979, 19866, 586, 294, 479, 37, 44, 5208, 38, 294, 50828], "temperature": 0.0, "avg_logprob": -0.18798641825831214, "compression_ratio": 1.5159574468085106, "no_speech_prob": 0.011001626960933208}, {"id": 51, "seek": 33876, "start": 348.03999999999996, "end": 356.48, "text": " terms of lines of C. I'm not sure how it compares to David but even being the biggest decoder in", "tokens": [50828, 2115, 295, 3876, 295, 383, 13, 286, 478, 406, 988, 577, 309, 38334, 281, 4389, 457, 754, 885, 264, 3880, 979, 19866, 294, 51250], "temperature": 0.0, "avg_logprob": -0.18798641825831214, "compression_ratio": 1.5159574468085106, "no_speech_prob": 0.011001626960933208}, {"id": 52, "seek": 33876, "start": 356.48, "end": 366.0, "text": " FFMPEG it's still much smaller than open VVC and VVDC as you can see here. How do we manage to", "tokens": [51250, 479, 37, 44, 5208, 38, 309, 311, 920, 709, 4356, 813, 1269, 691, 53, 34, 293, 691, 53, 25619, 382, 291, 393, 536, 510, 13, 1012, 360, 321, 3067, 281, 51726], "temperature": 0.0, "avg_logprob": -0.18798641825831214, "compression_ratio": 1.5159574468085106, "no_speech_prob": 0.011001626960933208}, {"id": 53, "seek": 36600, "start": 366.08, "end": 374.4, "text": " achieve that? By being in FFMPEG basically we're able to reuse parts from previous codecs. We're", "tokens": [50368, 4584, 300, 30, 3146, 885, 294, 479, 37, 44, 5208, 38, 1936, 321, 434, 1075, 281, 26225, 3166, 490, 3894, 3089, 14368, 13, 492, 434, 50784], "temperature": 0.0, "avg_logprob": -0.23408156555968446, "compression_ratio": 1.469387755102041, "no_speech_prob": 0.02574784681200981}, {"id": 54, "seek": 36600, "start": 374.4, "end": 382.88, "text": " able to use the CBS Quebec reader you can see there and reuse like whole swathes of code also", "tokens": [50784, 1075, 281, 764, 264, 35856, 38903, 15149, 291, 393, 536, 456, 293, 26225, 411, 1379, 1693, 998, 279, 295, 3089, 611, 51208], "temperature": 0.0, "avg_logprob": -0.23408156555968446, "compression_ratio": 1.469387755102041, "no_speech_prob": 0.02574784681200981}, {"id": 55, "seek": 36600, "start": 382.88, "end": 389.2, "text": " parts of the binary so it's kind of hard to measure that but you get a more bang for your buck in", "tokens": [51208, 3166, 295, 264, 17434, 370, 309, 311, 733, 295, 1152, 281, 3481, 300, 457, 291, 483, 257, 544, 8550, 337, 428, 14894, 294, 51524], "temperature": 0.0, "avg_logprob": -0.23408156555968446, "compression_ratio": 1.469387755102041, "no_speech_prob": 0.02574784681200981}, {"id": 56, "seek": 38920, "start": 389.24, "end": 396.76, "text": " terms of the size of a compiled delivery codec. In the future I believe we may be able to also use", "tokens": [50366, 2115, 295, 264, 2744, 295, 257, 36548, 8982, 3089, 66, 13, 682, 264, 2027, 286, 1697, 321, 815, 312, 1075, 281, 611, 764, 50742], "temperature": 0.0, "avg_logprob": -0.16009623805681863, "compression_ratio": 1.556, "no_speech_prob": 0.011947489343583584}, {"id": 57, "seek": 38920, "start": 396.76, "end": 407.32, "text": " some aspects of hardware decoder APIs to do the DPB reference management. We managed to be much", "tokens": [50742, 512, 7270, 295, 8837, 979, 19866, 21445, 281, 360, 264, 42796, 33, 6408, 4592, 13, 492, 6453, 281, 312, 709, 51270], "temperature": 0.0, "avg_logprob": -0.16009623805681863, "compression_ratio": 1.556, "no_speech_prob": 0.011947489343583584}, {"id": 58, "seek": 38920, "start": 407.32, "end": 412.15999999999997, "text": " much smaller and that's one of the main reasons really motivating putting this inside of FFMPEG.", "tokens": [51270, 709, 4356, 293, 300, 311, 472, 295, 264, 2135, 4112, 534, 41066, 3372, 341, 1854, 295, 479, 37, 44, 5208, 38, 13, 51512], "temperature": 0.0, "avg_logprob": -0.16009623805681863, "compression_ratio": 1.556, "no_speech_prob": 0.011947489343583584}, {"id": 59, "seek": 38920, "start": 412.15999999999997, "end": 419.08, "text": " The other one being FFMPEG's vibrant community we can say which hopefully will help maintain this", "tokens": [51512, 440, 661, 472, 885, 479, 37, 44, 5208, 38, 311, 21571, 1768, 321, 393, 584, 597, 4696, 486, 854, 6909, 341, 51858], "temperature": 0.0, "avg_logprob": -0.16009623805681863, "compression_ratio": 1.556, "no_speech_prob": 0.011947489343583584}, {"id": 60, "seek": 41908, "start": 419.15999999999997, "end": 428.35999999999996, "text": " into the future. Moving on to what's new in VVC so there's a lot of new coding tools like a dizzying", "tokens": [50368, 666, 264, 2027, 13, 14242, 322, 281, 437, 311, 777, 294, 691, 53, 34, 370, 456, 311, 257, 688, 295, 777, 17720, 3873, 411, 257, 31098, 278, 50828], "temperature": 0.0, "avg_logprob": -0.20982232031884132, "compression_ratio": 1.4974358974358974, "no_speech_prob": 0.0026060217060148716}, {"id": 61, "seek": 41908, "start": 428.35999999999996, "end": 436.47999999999996, "text": " amount. You can see here you could talk for an hour and many people have about even a subset of", "tokens": [50828, 2372, 13, 509, 393, 536, 510, 291, 727, 751, 337, 364, 1773, 293, 867, 561, 362, 466, 754, 257, 25993, 295, 51234], "temperature": 0.0, "avg_logprob": -0.20982232031884132, "compression_ratio": 1.4974358974358974, "no_speech_prob": 0.0026060217060148716}, {"id": 62, "seek": 41908, "start": 436.47999999999996, "end": 444.36, "text": " these. As you say we haven't implemented them all yet but there's loads to play with which yeah", "tokens": [51234, 613, 13, 1018, 291, 584, 321, 2378, 380, 12270, 552, 439, 1939, 457, 456, 311, 12668, 281, 862, 365, 597, 1338, 51628], "temperature": 0.0, "avg_logprob": -0.20982232031884132, "compression_ratio": 1.4974358974358974, "no_speech_prob": 0.0026060217060148716}, {"id": 63, "seek": 44436, "start": 445.12, "end": 451.52000000000004, "text": " feedback to them the ability to make much smaller bit streams and also to make more versatile", "tokens": [50402, 5824, 281, 552, 264, 3485, 281, 652, 709, 4356, 857, 15842, 293, 611, 281, 652, 544, 25057, 50722], "temperature": 0.0, "avg_logprob": -0.16100215911865234, "compression_ratio": 1.4712041884816753, "no_speech_prob": 0.004649111069738865}, {"id": 64, "seek": 44436, "start": 451.52000000000004, "end": 460.44, "text": " video content. What FFVVC introduces that's new for FFMPEG is this stage-based thread model so", "tokens": [50722, 960, 2701, 13, 708, 479, 37, 53, 53, 34, 31472, 300, 311, 777, 337, 479, 37, 44, 5208, 38, 307, 341, 3233, 12, 6032, 7207, 2316, 370, 51168], "temperature": 0.0, "avg_logprob": -0.16100215911865234, "compression_ratio": 1.4712041884816753, "no_speech_prob": 0.004649111069738865}, {"id": 65, "seek": 44436, "start": 460.44, "end": 469.08000000000004, "text": " lots of previous codecs have the frame and slice thread models which do well for sort of low", "tokens": [51168, 3195, 295, 3894, 3089, 14368, 362, 264, 3920, 293, 13153, 7207, 5245, 597, 360, 731, 337, 1333, 295, 2295, 51600], "temperature": 0.0, "avg_logprob": -0.16100215911865234, "compression_ratio": 1.4712041884816753, "no_speech_prob": 0.004649111069738865}, {"id": 66, "seek": 46908, "start": 469.15999999999997, "end": 476.15999999999997, "text": " number of cores but have some sort of here ceiling at certain point and so FFVVC uses a much more", "tokens": [50368, 1230, 295, 24826, 457, 362, 512, 1333, 295, 510, 13655, 412, 1629, 935, 293, 370, 479, 37, 53, 53, 34, 4960, 257, 709, 544, 50718], "temperature": 0.0, "avg_logprob": -0.24492359161376953, "compression_ratio": 1.5591836734693878, "no_speech_prob": 0.029229972511529922}, {"id": 67, "seek": 46908, "start": 476.15999999999997, "end": 481.76, "text": " fine-grained thread model which is able to allocate threads based on the stage of decoding", "tokens": [50718, 2489, 12, 20735, 2001, 7207, 2316, 597, 307, 1075, 281, 35713, 19314, 2361, 322, 264, 3233, 295, 979, 8616, 50998], "temperature": 0.0, "avg_logprob": -0.24492359161376953, "compression_ratio": 1.5591836734693878, "no_speech_prob": 0.029229972511529922}, {"id": 68, "seek": 46908, "start": 481.76, "end": 489.59999999999997, "text": " individual CTUs and yeah as that says it means we're able to much better utilize higher core", "tokens": [50998, 2609, 19529, 29211, 293, 1338, 382, 300, 1619, 309, 1355, 321, 434, 1075, 281, 709, 1101, 16117, 2946, 4965, 51390], "temperature": 0.0, "avg_logprob": -0.24492359161376953, "compression_ratio": 1.5591836734693878, "no_speech_prob": 0.029229972511529922}, {"id": 69, "seek": 46908, "start": 489.59999999999997, "end": 496.56, "text": " counts and so our C code with no assembly we're able to decode 4k over 30 fps on you know relatively", "tokens": [51390, 14893, 293, 370, 527, 383, 3089, 365, 572, 12103, 321, 434, 1075, 281, 979, 1429, 1017, 74, 670, 2217, 44981, 322, 291, 458, 7226, 51738], "temperature": 0.0, "avg_logprob": -0.24492359161376953, "compression_ratio": 1.5591836734693878, "no_speech_prob": 0.029229972511529922}, {"id": 70, "seek": 49656, "start": 496.64, "end": 505.08, "text": " high-end desktop processor but I think that's really impressive. This thread model is possible to", "tokens": [50368, 1090, 12, 521, 14502, 15321, 457, 286, 519, 300, 311, 534, 8992, 13, 639, 7207, 2316, 307, 1944, 281, 50790], "temperature": 0.0, "avg_logprob": -0.18122376591326242, "compression_ratio": 1.4554455445544554, "no_speech_prob": 0.006475955713540316}, {"id": 71, "seek": 49656, "start": 505.08, "end": 511.32, "text": " implement in HEVC. FFVVC does not use it I think it's also possible to do stage-based decoding in", "tokens": [50790, 4445, 294, 11827, 53, 34, 13, 479, 37, 53, 53, 34, 775, 406, 764, 309, 286, 519, 309, 311, 611, 1944, 281, 360, 3233, 12, 6032, 979, 8616, 294, 51102], "temperature": 0.0, "avg_logprob": -0.18122376591326242, "compression_ratio": 1.4554455445544554, "no_speech_prob": 0.006475955713540316}, {"id": 72, "seek": 49656, "start": 511.32, "end": 521.64, "text": " AV1 but it wasn't a factor in the design of AVC. The way that it works is you divide each CTU into", "tokens": [51102, 30198, 16, 457, 309, 2067, 380, 257, 5952, 294, 264, 1715, 295, 30198, 34, 13, 440, 636, 300, 309, 1985, 307, 291, 9845, 1184, 19529, 52, 666, 51618], "temperature": 0.0, "avg_logprob": -0.18122376591326242, "compression_ratio": 1.4554455445544554, "no_speech_prob": 0.006475955713540316}, {"id": 73, "seek": 52164, "start": 521.72, "end": 527.92, "text": " several stages of decoding they're all listed there and the key thing is that each stage depends", "tokens": [50368, 2940, 10232, 295, 979, 8616, 436, 434, 439, 10052, 456, 293, 264, 2141, 551, 307, 300, 1184, 3233, 5946, 50678], "temperature": 0.0, "avg_logprob": -0.16112163331773546, "compression_ratio": 1.7477064220183487, "no_speech_prob": 0.037364739924669266}, {"id": 74, "seek": 52164, "start": 527.92, "end": 533.72, "text": " only on the current or previous stage of the neighboring CTUs and so you can start doing the", "tokens": [50678, 787, 322, 264, 2190, 420, 3894, 3233, 295, 264, 31521, 19529, 29211, 293, 370, 291, 393, 722, 884, 264, 50968], "temperature": 0.0, "avg_logprob": -0.16112163331773546, "compression_ratio": 1.7477064220183487, "no_speech_prob": 0.037364739924669266}, {"id": 75, "seek": 52164, "start": 533.72, "end": 541.56, "text": " D block of one stage before you've done the pass even in the like top left corner very far away", "tokens": [50968, 413, 3461, 295, 472, 3233, 949, 291, 600, 1096, 264, 1320, 754, 294, 264, 411, 1192, 1411, 4538, 588, 1400, 1314, 51360], "temperature": 0.0, "avg_logprob": -0.16112163331773546, "compression_ratio": 1.7477064220183487, "no_speech_prob": 0.037364739924669266}, {"id": 76, "seek": 52164, "start": 541.56, "end": 548.28, "text": " sorry before you've done the intro I think you have to do the pass for all first and the effect", "tokens": [51360, 2597, 949, 291, 600, 1096, 264, 12897, 286, 519, 291, 362, 281, 360, 264, 1320, 337, 439, 700, 293, 264, 1802, 51696], "temperature": 0.0, "avg_logprob": -0.16112163331773546, "compression_ratio": 1.7477064220183487, "no_speech_prob": 0.037364739924669266}, {"id": 77, "seek": 54828, "start": 548.36, "end": 553.48, "text": " you get from this is this sort of wave front that progresses across the image of each of the", "tokens": [50368, 291, 483, 490, 341, 307, 341, 1333, 295, 5772, 1868, 300, 41929, 2108, 264, 3256, 295, 1184, 295, 264, 50624], "temperature": 0.0, "avg_logprob": -0.1729893017840642, "compression_ratio": 1.5365853658536586, "no_speech_prob": 0.00983571819961071}, {"id": 78, "seek": 54828, "start": 553.48, "end": 561.1999999999999, "text": " different stages and yeah it allows you to use much more cores. To allocate those cores we've had", "tokens": [50624, 819, 10232, 293, 1338, 309, 4045, 291, 281, 764, 709, 544, 24826, 13, 1407, 35713, 729, 24826, 321, 600, 632, 51010], "temperature": 0.0, "avg_logprob": -0.1729893017840642, "compression_ratio": 1.5365853658536586, "no_speech_prob": 0.00983571819961071}, {"id": 79, "seek": 54828, "start": 561.1999999999999, "end": 568.48, "text": " to introduce this new AV executor utility which has been made available in LibAVUtil so you can", "tokens": [51010, 281, 5366, 341, 777, 30198, 7568, 284, 14877, 597, 575, 668, 1027, 2435, 294, 15834, 32, 53, 52, 20007, 370, 291, 393, 51374], "temperature": 0.0, "avg_logprob": -0.1729893017840642, "compression_ratio": 1.5365853658536586, "no_speech_prob": 0.00983571819961071}, {"id": 80, "seek": 54828, "start": 568.48, "end": 574.92, "text": " use this for other projects inside FFMpeg. It's a really simple algorithm at the moment but", "tokens": [51374, 764, 341, 337, 661, 4455, 1854, 479, 37, 44, 494, 70, 13, 467, 311, 257, 534, 2199, 9284, 412, 264, 1623, 457, 51696], "temperature": 0.0, "avg_logprob": -0.1729893017840642, "compression_ratio": 1.5365853658536586, "no_speech_prob": 0.00983571819961071}, {"id": 81, "seek": 57492, "start": 574.9599999999999, "end": 581.28, "text": " centralizing the control of allocation of threads you know not repeating yourself means we have", "tokens": [50366, 5777, 3319, 264, 1969, 295, 27599, 295, 19314, 291, 458, 406, 18617, 1803, 1355, 321, 362, 50682], "temperature": 0.0, "avg_logprob": -0.1466504909374096, "compression_ratio": 1.63135593220339, "no_speech_prob": 0.008054397068917751}, {"id": 82, "seek": 57492, "start": 581.28, "end": 588.0, "text": " now one location where we can make improvements here. It's a really simple algorithm it's based", "tokens": [50682, 586, 472, 4914, 689, 321, 393, 652, 13797, 510, 13, 467, 311, 257, 534, 2199, 9284, 309, 311, 2361, 51018], "temperature": 0.0, "avg_logprob": -0.1466504909374096, "compression_ratio": 1.63135593220339, "no_speech_prob": 0.008054397068917751}, {"id": 83, "seek": 57492, "start": 588.0, "end": 595.56, "text": " on I think some of the earlier implementations inside Python and Java's executor structures or", "tokens": [51018, 322, 286, 519, 512, 295, 264, 3071, 4445, 763, 1854, 15329, 293, 10745, 311, 7568, 284, 9227, 420, 51396], "temperature": 0.0, "avg_logprob": -0.1466504909374096, "compression_ratio": 1.63135593220339, "no_speech_prob": 0.008054397068917751}, {"id": 84, "seek": 57492, "start": 595.56, "end": 600.92, "text": " whatever they call them but yeah having that one thing in one location that can be used throughout", "tokens": [51396, 2035, 436, 818, 552, 457, 1338, 1419, 300, 472, 551, 294, 472, 4914, 300, 393, 312, 1143, 3710, 51664], "temperature": 0.0, "avg_logprob": -0.1466504909374096, "compression_ratio": 1.63135593220339, "no_speech_prob": 0.008054397068917751}, {"id": 85, "seek": 60092, "start": 600.92, "end": 612.0, "text": " FFMpeg to improve multi-threading. Yeah so onto the performance section so at the moment it's pretty", "tokens": [50364, 479, 37, 44, 494, 70, 281, 3470, 4825, 12, 392, 35908, 13, 865, 370, 3911, 264, 3389, 3541, 370, 412, 264, 1623, 309, 311, 1238, 50918], "temperature": 0.0, "avg_logprob": -0.1792339579264323, "compression_ratio": 1.5, "no_speech_prob": 0.0034497908782213926}, {"id": 86, "seek": 60092, "start": 612.0, "end": 618.16, "text": " slow compared to previous codecs I mean this is to be expected by to a certain extent VVC is just", "tokens": [50918, 2964, 5347, 281, 3894, 3089, 14368, 286, 914, 341, 307, 281, 312, 5176, 538, 281, 257, 1629, 8396, 691, 53, 34, 307, 445, 51226], "temperature": 0.0, "avg_logprob": -0.1792339579264323, "compression_ratio": 1.5, "no_speech_prob": 0.0034497908782213926}, {"id": 87, "seek": 60092, "start": 618.16, "end": 624.12, "text": " a more complex codec than previous generation stuff it has to be in order to achieve high rates", "tokens": [51226, 257, 544, 3997, 3089, 66, 813, 3894, 5125, 1507, 309, 575, 281, 312, 294, 1668, 281, 4584, 1090, 6846, 51524], "temperature": 0.0, "avg_logprob": -0.1792339579264323, "compression_ratio": 1.5, "no_speech_prob": 0.0034497908782213926}, {"id": 88, "seek": 62412, "start": 624.16, "end": 632.68, "text": " compression. This SIMD here false and true for FFVVC so this is with stuff that's not yet in FFMpeg", "tokens": [50366, 19355, 13, 639, 24738, 35, 510, 7908, 293, 2074, 337, 479, 37, 53, 53, 34, 370, 341, 307, 365, 1507, 300, 311, 406, 1939, 294, 479, 37, 44, 494, 70, 50792], "temperature": 0.0, "avg_logprob": -0.14988008171620995, "compression_ratio": 1.590717299578059, "no_speech_prob": 0.032204560935497284}, {"id": 89, "seek": 62412, "start": 632.68, "end": 638.72, "text": " master this is with the current state on the development staging repo. You can see we are", "tokens": [50792, 4505, 341, 307, 365, 264, 2190, 1785, 322, 264, 3250, 41085, 49040, 13, 509, 393, 536, 321, 366, 51094], "temperature": 0.0, "avg_logprob": -0.14988008171620995, "compression_ratio": 1.590717299578059, "no_speech_prob": 0.032204560935497284}, {"id": 90, "seek": 62412, "start": 638.72, "end": 645.44, "text": " getting about over 200 over a doubling of speed increase for FFVVC already but there's a long", "tokens": [51094, 1242, 466, 670, 2331, 670, 257, 33651, 295, 3073, 3488, 337, 479, 37, 53, 53, 34, 1217, 457, 456, 311, 257, 938, 51430], "temperature": 0.0, "avg_logprob": -0.14988008171620995, "compression_ratio": 1.590717299578059, "no_speech_prob": 0.032204560935497284}, {"id": 91, "seek": 62412, "start": 645.44, "end": 650.4, "text": " way to go as you can see from David's really impressive assembly speed up they have there but", "tokens": [51430, 636, 281, 352, 382, 291, 393, 536, 490, 4389, 311, 534, 8992, 12103, 3073, 493, 436, 362, 456, 457, 51678], "temperature": 0.0, "avg_logprob": -0.14988008171620995, "compression_ratio": 1.590717299578059, "no_speech_prob": 0.032204560935497284}, {"id": 92, "seek": 65040, "start": 650.48, "end": 657.72, "text": " our multi-threading picture is quite different so that shows you the effect of doing that stage", "tokens": [50368, 527, 4825, 12, 392, 35908, 3036, 307, 1596, 819, 370, 300, 3110, 291, 264, 1802, 295, 884, 300, 3233, 50730], "temperature": 0.0, "avg_logprob": -0.1697190672486693, "compression_ratio": 1.7342342342342343, "no_speech_prob": 0.009138370864093304}, {"id": 93, "seek": 65040, "start": 657.72, "end": 664.12, "text": " based multi-threading we're just much more easily able to use higher numbers cause yeah note here", "tokens": [50730, 2361, 4825, 12, 392, 35908, 321, 434, 445, 709, 544, 3612, 1075, 281, 764, 2946, 3547, 3082, 1338, 3637, 510, 51050], "temperature": 0.0, "avg_logprob": -0.1697190672486693, "compression_ratio": 1.7342342342342343, "no_speech_prob": 0.009138370864093304}, {"id": 94, "seek": 65040, "start": 664.12, "end": 668.52, "text": " that this is using hyperthreading which is why you've got quite the knee there at six threads", "tokens": [51050, 300, 341, 307, 1228, 9848, 392, 35908, 597, 307, 983, 291, 600, 658, 1596, 264, 9434, 456, 412, 2309, 19314, 51270], "temperature": 0.0, "avg_logprob": -0.1697190672486693, "compression_ratio": 1.7342342342342343, "no_speech_prob": 0.009138370864093304}, {"id": 95, "seek": 65040, "start": 668.52, "end": 675.8, "text": " and but below six threads it's really not far off from that ideal you get a core you get the same", "tokens": [51270, 293, 457, 2507, 2309, 19314, 309, 311, 534, 406, 1400, 766, 490, 300, 7157, 291, 483, 257, 4965, 291, 483, 264, 912, 51634], "temperature": 0.0, "avg_logprob": -0.1697190672486693, "compression_ratio": 1.7342342342342343, "no_speech_prob": 0.009138370864093304}, {"id": 96, "seek": 67580, "start": 675.8399999999999, "end": 687.1999999999999, "text": " multiplicative increase in the speed up comparing it to VVDC then. VVDC uses the same stage based", "tokens": [50366, 17596, 1166, 3488, 294, 264, 3073, 493, 15763, 309, 281, 691, 53, 25619, 550, 13, 691, 53, 25619, 4960, 264, 912, 3233, 2361, 50934], "temperature": 0.0, "avg_logprob": -0.11936304443760921, "compression_ratio": 1.515625, "no_speech_prob": 0.004903100896626711}, {"id": 97, "seek": 67580, "start": 687.1999999999999, "end": 694.56, "text": " threading model so you're getting a very similar performance between FFVVC and VVDC. Open VVC uses", "tokens": [50934, 7207, 278, 2316, 370, 291, 434, 1242, 257, 588, 2531, 3389, 1296, 479, 37, 53, 53, 34, 293, 691, 53, 25619, 13, 7238, 691, 53, 34, 4960, 51302], "temperature": 0.0, "avg_logprob": -0.11936304443760921, "compression_ratio": 1.515625, "no_speech_prob": 0.004903100896626711}, {"id": 98, "seek": 67580, "start": 694.56, "end": 702.92, "text": " the conventional frame and tile based multi-threading techniques so that's quite useful on the", "tokens": [51302, 264, 16011, 3920, 293, 20590, 2361, 4825, 12, 392, 35908, 7512, 370, 300, 311, 1596, 4420, 322, 264, 51720], "temperature": 0.0, "avg_logprob": -0.11936304443760921, "compression_ratio": 1.515625, "no_speech_prob": 0.004903100896626711}, {"id": 99, "seek": 70292, "start": 703.0, "end": 706.4799999999999, "text": " left hand side there that figure to compare what is the effect of this new threading model", "tokens": [50368, 1411, 1011, 1252, 456, 300, 2573, 281, 6794, 437, 307, 264, 1802, 295, 341, 777, 7207, 278, 2316, 50542], "temperature": 0.0, "avg_logprob": -0.1298616521498736, "compression_ratio": 1.740566037735849, "no_speech_prob": 0.002770409919321537}, {"id": 100, "seek": 70292, "start": 706.4799999999999, "end": 713.7199999999999, "text": " but you can see and then on the right hand side the single threaded performance C only between", "tokens": [50542, 457, 291, 393, 536, 293, 550, 322, 264, 558, 1011, 1252, 264, 2167, 47493, 3389, 383, 787, 1296, 50904], "temperature": 0.0, "avg_logprob": -0.1298616521498736, "compression_ratio": 1.740566037735849, "no_speech_prob": 0.002770409919321537}, {"id": 101, "seek": 70292, "start": 713.7199999999999, "end": 721.24, "text": " FFVVC and VVDC is pretty much on par. VVDC behaves has quite significantly different", "tokens": [50904, 479, 37, 53, 53, 34, 293, 691, 53, 25619, 307, 1238, 709, 322, 971, 13, 691, 53, 25619, 36896, 575, 1596, 10591, 819, 51280], "temperature": 0.0, "avg_logprob": -0.1298616521498736, "compression_ratio": 1.740566037735849, "no_speech_prob": 0.002770409919321537}, {"id": 102, "seek": 70292, "start": 721.24, "end": 727.0799999999999, "text": " performance on different operating systems but the average between the two is pretty much the same", "tokens": [51280, 3389, 322, 819, 7447, 3652, 457, 264, 4274, 1296, 264, 732, 307, 1238, 709, 264, 912, 51572], "temperature": 0.0, "avg_logprob": -0.1298616521498736, "compression_ratio": 1.740566037735849, "no_speech_prob": 0.002770409919321537}, {"id": 103, "seek": 72708, "start": 728.0400000000001, "end": 735.36, "text": " and on 4k it's a similar picture but everything just gets slightly more pronounced. Open VVC is", "tokens": [50412, 293, 322, 1017, 74, 309, 311, 257, 2531, 3036, 457, 1203, 445, 2170, 4748, 544, 23155, 13, 7238, 691, 53, 34, 307, 50778], "temperature": 0.0, "avg_logprob": -0.1723205838884626, "compression_ratio": 1.4896907216494846, "no_speech_prob": 0.001666713273152709}, {"id": 104, "seek": 72708, "start": 735.36, "end": 742.4000000000001, "text": " slower that the speed up that we're getting from using more threads matters even more for larger", "tokens": [50778, 14009, 300, 264, 3073, 493, 300, 321, 434, 1242, 490, 1228, 544, 19314, 7001, 754, 544, 337, 4833, 51130], "temperature": 0.0, "avg_logprob": -0.1723205838884626, "compression_ratio": 1.4896907216494846, "no_speech_prob": 0.001666713273152709}, {"id": 105, "seek": 72708, "start": 742.4000000000001, "end": 752.32, "text": " videos so you can see that effect here but we're still lacking on the assembly front so VVDC has", "tokens": [51130, 2145, 370, 291, 393, 536, 300, 1802, 510, 457, 321, 434, 920, 20889, 322, 264, 12103, 1868, 370, 691, 53, 25619, 575, 51626], "temperature": 0.0, "avg_logprob": -0.1723205838884626, "compression_ratio": 1.4896907216494846, "no_speech_prob": 0.001666713273152709}, {"id": 106, "seek": 75232, "start": 752.6, "end": 759.5200000000001, "text": " a lot of assembly already for quite a few different architectures and you can see that they're", "tokens": [50378, 257, 688, 295, 12103, 1217, 337, 1596, 257, 1326, 819, 6331, 1303, 293, 291, 393, 536, 300, 436, 434, 50724], "temperature": 0.0, "avg_logprob": -0.18133171399434408, "compression_ratio": 1.5967078189300412, "no_speech_prob": 0.01075128186494112}, {"id": 107, "seek": 75232, "start": 759.5200000000001, "end": 766.84, "text": " really pulling ahead once you enable the assembly there. The theoretically FFNPEG VVDC decoder should", "tokens": [50724, 534, 8407, 2286, 1564, 291, 9528, 264, 12103, 456, 13, 440, 29400, 479, 37, 45, 5208, 38, 691, 53, 25619, 979, 19866, 820, 51090], "temperature": 0.0, "avg_logprob": -0.18133171399434408, "compression_ratio": 1.5967078189300412, "no_speech_prob": 0.01075128186494112}, {"id": 108, "seek": 75232, "start": 766.84, "end": 772.72, "text": " have somewhat of a higher ceiling due to the fact that FFVVC's assembly will be handwritten", "tokens": [51090, 362, 8344, 295, 257, 2946, 13655, 3462, 281, 264, 1186, 300, 479, 37, 53, 53, 34, 311, 12103, 486, 312, 1011, 26859, 51384], "temperature": 0.0, "avg_logprob": -0.18133171399434408, "compression_ratio": 1.5967078189300412, "no_speech_prob": 0.01075128186494112}, {"id": 109, "seek": 75232, "start": 772.72, "end": 782.0400000000001, "text": " whereas VVDC's is using intrinsics and on some architectures using SIMD anywhere as like a portable", "tokens": [51384, 9735, 691, 53, 25619, 311, 307, 1228, 28621, 1167, 293, 322, 512, 6331, 1303, 1228, 24738, 35, 4992, 382, 411, 257, 21800, 51850], "temperature": 0.0, "avg_logprob": -0.18133171399434408, "compression_ratio": 1.5967078189300412, "no_speech_prob": 0.01075128186494112}, {"id": 110, "seek": 78204, "start": 782.64, "end": 791.92, "text": " SIMD library which introduces them overhead so with enough time hopefully FFVVC can be even", "tokens": [50394, 24738, 35, 6405, 597, 31472, 552, 19922, 370, 365, 1547, 565, 4696, 479, 37, 53, 53, 34, 393, 312, 754, 50858], "temperature": 0.0, "avg_logprob": -0.17054602920368153, "compression_ratio": 1.5532786885245902, "no_speech_prob": 0.00391531502828002}, {"id": 111, "seek": 78204, "start": 791.92, "end": 797.76, "text": " faster but we've got a long way to go to catch up to them at the moment. So just sort of wrapping", "tokens": [50858, 4663, 457, 321, 600, 658, 257, 938, 636, 281, 352, 281, 3745, 493, 281, 552, 412, 264, 1623, 13, 407, 445, 1333, 295, 21993, 51150], "temperature": 0.0, "avg_logprob": -0.17054602920368153, "compression_ratio": 1.5532786885245902, "no_speech_prob": 0.00391531502828002}, {"id": 112, "seek": 78204, "start": 797.76, "end": 804.1999999999999, "text": " up to the last couple of things here so talking about the Google Summer of Code program in 2023", "tokens": [51150, 493, 281, 264, 1036, 1916, 295, 721, 510, 370, 1417, 466, 264, 3329, 16161, 295, 15549, 1461, 294, 44377, 51472], "temperature": 0.0, "avg_logprob": -0.17054602920368153, "compression_ratio": 1.5532786885245902, "no_speech_prob": 0.00391531502828002}, {"id": 113, "seek": 78204, "start": 804.1999999999999, "end": 810.92, "text": " so there was two Google Summer of Code students contributing to the VVDC decoder this summer.", "tokens": [51472, 370, 456, 390, 732, 3329, 16161, 295, 15549, 1731, 19270, 281, 264, 691, 53, 25619, 979, 19866, 341, 4266, 13, 51808], "temperature": 0.0, "avg_logprob": -0.17054602920368153, "compression_ratio": 1.5532786885245902, "no_speech_prob": 0.00391531502828002}, {"id": 114, "seek": 81092, "start": 811.8, "end": 819.5999999999999, "text": " Myself and Sean Liu so I worked on a lot of the stuff that was added in version two of VVDC so that", "tokens": [50408, 37795, 1967, 293, 14839, 18056, 370, 286, 2732, 322, 257, 688, 295, 264, 1507, 300, 390, 3869, 294, 3037, 732, 295, 691, 53, 25619, 370, 300, 50798], "temperature": 0.0, "avg_logprob": -0.19210693110590396, "compression_ratio": 1.5506072874493928, "no_speech_prob": 0.004909451585263014}, {"id": 115, "seek": 81092, "start": 819.5999999999999, "end": 826.7199999999999, "text": " includes the support for 12 and 14 bit which needs the range extension which changes various things", "tokens": [50798, 5974, 264, 1406, 337, 2272, 293, 3499, 857, 597, 2203, 264, 3613, 10320, 597, 2962, 3683, 721, 51154], "temperature": 0.0, "avg_logprob": -0.19210693110590396, "compression_ratio": 1.5506072874493928, "no_speech_prob": 0.004909451585263014}, {"id": 116, "seek": 81092, "start": 826.7199999999999, "end": 832.52, "text": " to the entropy encoder when you get to higher bit depths and I've also been working on AVX2", "tokens": [51154, 281, 264, 30867, 2058, 19866, 562, 291, 483, 281, 2946, 857, 28439, 293, 286, 600, 611, 668, 1364, 322, 30198, 55, 17, 51444], "temperature": 0.0, "avg_logprob": -0.19210693110590396, "compression_ratio": 1.5506072874493928, "no_speech_prob": 0.004909451585263014}, {"id": 117, "seek": 81092, "start": 832.52, "end": 837.48, "text": " optimizations for the inverse transforms they all had to be written from scratch in the end", "tokens": [51444, 5028, 14455, 337, 264, 17340, 35592, 436, 439, 632, 281, 312, 3720, 490, 8459, 294, 264, 917, 51692], "temperature": 0.0, "avg_logprob": -0.19210693110590396, "compression_ratio": 1.5506072874493928, "no_speech_prob": 0.004909451585263014}, {"id": 118, "seek": 83748, "start": 837.52, "end": 846.16, "text": " there's not very much that you can share between HEVC and VVC due to the way that the HEVC transforms", "tokens": [50366, 456, 311, 406, 588, 709, 300, 291, 393, 2073, 1296, 11827, 53, 34, 293, 691, 53, 34, 3462, 281, 264, 636, 300, 264, 11827, 53, 34, 35592, 50798], "temperature": 0.0, "avg_logprob": -0.15328751721428435, "compression_ratio": 1.6072874493927125, "no_speech_prob": 0.003109938930720091}, {"id": 119, "seek": 83748, "start": 846.16, "end": 854.2, "text": " are written in FFNPEG and Sean Liu is working on also on assembly transforms for the filters which", "tokens": [50798, 366, 3720, 294, 479, 37, 45, 5208, 38, 293, 14839, 18056, 307, 1364, 322, 611, 322, 12103, 35592, 337, 264, 15995, 597, 51200], "temperature": 0.0, "avg_logprob": -0.15328751721428435, "compression_ratio": 1.6072874493927125, "no_speech_prob": 0.003109938930720091}, {"id": 120, "seek": 83748, "start": 854.2, "end": 861.32, "text": " some of them are in the process of being upstreamed at the moment I believe. So yeah next steps as", "tokens": [51200, 512, 295, 552, 366, 294, 264, 1399, 295, 885, 33915, 292, 412, 264, 1623, 286, 1697, 13, 407, 1338, 958, 4439, 382, 51556], "temperature": 0.0, "avg_logprob": -0.15328751721428435, "compression_ratio": 1.6072874493927125, "no_speech_prob": 0.003109938930720091}, {"id": 121, "seek": 83748, "start": 861.32, "end": 867.16, "text": " I'm sure this performance and what we've been working on has sort of shown we've got a very solid", "tokens": [51556, 286, 478, 988, 341, 3389, 293, 437, 321, 600, 668, 1364, 322, 575, 1333, 295, 4898, 321, 600, 658, 257, 588, 5100, 51848], "temperature": 0.0, "avg_logprob": -0.15328751721428435, "compression_ratio": 1.6072874493927125, "no_speech_prob": 0.003109938930720091}, {"id": 122, "seek": 86716, "start": 867.28, "end": 872.48, "text": " baseline with the C performance and the multi-threading but we need lots more assembly in there to be", "tokens": [50370, 20518, 365, 264, 383, 3389, 293, 264, 4825, 12, 392, 35908, 457, 321, 643, 3195, 544, 12103, 294, 456, 281, 312, 50630], "temperature": 0.0, "avg_logprob": -0.1670644338740859, "compression_ratio": 1.6425531914893616, "no_speech_prob": 0.0044547514989972115}, {"id": 123, "seek": 86716, "start": 872.48, "end": 879.28, "text": " able to compete with existing decoders so upstreaming and what we've already got implementing", "tokens": [50630, 1075, 281, 11831, 365, 6741, 979, 378, 433, 370, 33915, 278, 293, 437, 321, 600, 1217, 658, 18114, 50970], "temperature": 0.0, "avg_logprob": -0.1670644338740859, "compression_ratio": 1.6425531914893616, "no_speech_prob": 0.0044547514989972115}, {"id": 124, "seek": 86716, "start": 879.28, "end": 887.28, "text": " more functions with assembly also more architectures so ARM is going to be a Google Summer of Code", "tokens": [50970, 544, 6828, 365, 12103, 611, 544, 6331, 1303, 370, 45209, 307, 516, 281, 312, 257, 3329, 16161, 295, 15549, 51370], "temperature": 0.0, "avg_logprob": -0.1670644338740859, "compression_ratio": 1.6425531914893616, "no_speech_prob": 0.0044547514989972115}, {"id": 125, "seek": 86716, "start": 887.28, "end": 893.16, "text": " project for this summer potentially also risk five there's a lot of work on doing risk five", "tokens": [51370, 1716, 337, 341, 4266, 7263, 611, 3148, 1732, 456, 311, 257, 688, 295, 589, 322, 884, 3148, 1732, 51664], "temperature": 0.0, "avg_logprob": -0.1670644338740859, "compression_ratio": 1.6425531914893616, "no_speech_prob": 0.0044547514989972115}, {"id": 126, "seek": 89316, "start": 893.16, "end": 900.28, "text": " assembly for FFNPEG at the moment so we'll need that in time polishing off the maintain", "tokens": [50364, 12103, 337, 479, 37, 45, 5208, 38, 412, 264, 1623, 370, 321, 603, 643, 300, 294, 565, 47258, 766, 264, 6909, 50720], "temperature": 0.0, "avg_logprob": -0.22305855927643953, "compression_ratio": 1.553191489361702, "no_speech_prob": 0.012279093265533447}, {"id": 127, "seek": 89316, "start": 900.28, "end": 905.1999999999999, "text": " conformance so implementing those features that I mentioned for missing earlier particularly", "tokens": [50720, 18975, 719, 370, 18114, 729, 4122, 300, 286, 2835, 337, 5361, 3071, 4098, 50966], "temperature": 0.0, "avg_logprob": -0.22305855927643953, "compression_ratio": 1.553191489361702, "no_speech_prob": 0.012279093265533447}, {"id": 128, "seek": 89316, "start": 905.1999999999999, "end": 912.88, "text": " intra block copy is a high priority the thread optimization 32 plus cores so we may be able to", "tokens": [50966, 43358, 3461, 5055, 307, 257, 1090, 9365, 264, 7207, 19618, 8858, 1804, 24826, 370, 321, 815, 312, 1075, 281, 51350], "temperature": 0.0, "avg_logprob": -0.22305855927643953, "compression_ratio": 1.553191489361702, "no_speech_prob": 0.012279093265533447}, {"id": 129, "seek": 89316, "start": 912.88, "end": 922.04, "text": " improve the AVX2 utility for higher core counts if there's sufficient demand for that and", "tokens": [51350, 3470, 264, 30198, 55, 17, 14877, 337, 2946, 4965, 14893, 498, 456, 311, 11563, 4733, 337, 300, 293, 51808], "temperature": 0.0, "avg_logprob": -0.22305855927643953, "compression_ratio": 1.553191489361702, "no_speech_prob": 0.012279093265533447}, {"id": 130, "seek": 92204, "start": 922.5999999999999, "end": 929.9599999999999, "text": " the GPU based decoder so a lot of the stuff in VBC is really well designed particularly to do with", "tokens": [50392, 264, 18407, 2361, 979, 19866, 370, 257, 688, 295, 264, 1507, 294, 691, 7869, 307, 534, 731, 4761, 4098, 281, 360, 365, 50760], "temperature": 0.0, "avg_logprob": -0.1395724036476829, "compression_ratio": 1.5372340425531914, "no_speech_prob": 0.0011530251940712333}, {"id": 131, "seek": 92204, "start": 929.9599999999999, "end": 935.52, "text": " the separation of stages that we saw earlier means that it's really well suited to decoding on the", "tokens": [50760, 264, 14634, 295, 10232, 300, 321, 1866, 3071, 1355, 300, 309, 311, 534, 731, 24736, 281, 979, 8616, 322, 264, 51038], "temperature": 0.0, "avg_logprob": -0.1395724036476829, "compression_ratio": 1.5372340425531914, "no_speech_prob": 0.0011530251940712333}, {"id": 132, "seek": 92204, "start": 935.52, "end": 946.88, "text": " GPU so that's something on the far horizon. Concluding so FFNPEG now has a VBC decoder I've", "tokens": [51038, 18407, 370, 300, 311, 746, 322, 264, 1400, 18046, 13, 18200, 20626, 370, 479, 37, 45, 5208, 38, 586, 575, 257, 691, 7869, 979, 19866, 286, 600, 51606], "temperature": 0.0, "avg_logprob": -0.1395724036476829, "compression_ratio": 1.5372340425531914, "no_speech_prob": 0.0011530251940712333}, {"id": 133, "seek": 94688, "start": 946.92, "end": 954.32, "text": " introduced that new threading model showing some of the benefits of that talks about the", "tokens": [50366, 7268, 300, 777, 7207, 278, 2316, 4099, 512, 295, 264, 5311, 295, 300, 6686, 466, 264, 50736], "temperature": 0.0, "avg_logprob": -0.17490107838700458, "compression_ratio": 1.6205357142857142, "no_speech_prob": 0.009482822380959988}, {"id": 134, "seek": 94688, "start": 954.32, "end": 962.32, "text": " C in multi-threading performance and how that compares with VVDC and given an update on the", "tokens": [50736, 383, 294, 4825, 12, 392, 35908, 3389, 293, 577, 300, 38334, 365, 691, 53, 25619, 293, 2212, 364, 5623, 322, 264, 51136], "temperature": 0.0, "avg_logprob": -0.17490107838700458, "compression_ratio": 1.6205357142857142, "no_speech_prob": 0.009482822380959988}, {"id": 135, "seek": 94688, "start": 962.32, "end": 967.0, "text": " status including the optimized assembly we're currently working on we'd help with this like", "tokens": [51136, 6558, 3009, 264, 26941, 12103, 321, 434, 4362, 1364, 322, 321, 1116, 854, 365, 341, 411, 51370], "temperature": 0.0, "avg_logprob": -0.17490107838700458, "compression_ratio": 1.6205357142857142, "no_speech_prob": 0.009482822380959988}, {"id": 136, "seek": 94688, "start": 967.0, "end": 972.96, "text": " especially with the assembly there's just very few of us who only work in our free time so", "tokens": [51370, 2318, 365, 264, 12103, 456, 311, 445, 588, 1326, 295, 505, 567, 787, 589, 294, 527, 1737, 565, 370, 51668], "temperature": 0.0, "avg_logprob": -0.17490107838700458, "compression_ratio": 1.6205357142857142, "no_speech_prob": 0.009482822380959988}, {"id": 137, "seek": 97296, "start": 973.0, "end": 979.36, "text": " progress on that front has been relatively slow so yeah patches welcome alright yeah thank you very", "tokens": [50366, 4205, 322, 300, 1868, 575, 668, 7226, 2964, 370, 1338, 26531, 2928, 5845, 1338, 1309, 291, 588, 50684], "temperature": 0.0, "avg_logprob": -0.16094087244390132, "compression_ratio": 1.6099585062240664, "no_speech_prob": 0.006709146313369274}, {"id": 138, "seek": 97296, "start": 979.36, "end": 990.24, "text": " much for listening. If anyone's got any questions I'll be happy to try and answer them as best I", "tokens": [50684, 709, 337, 4764, 13, 759, 2878, 311, 658, 604, 1651, 286, 603, 312, 2055, 281, 853, 293, 1867, 552, 382, 1151, 286, 51228], "temperature": 0.0, "avg_logprob": -0.16094087244390132, "compression_ratio": 1.6099585062240664, "no_speech_prob": 0.006709146313369274}, {"id": 139, "seek": 97296, "start": 990.24, "end": 996.2, "text": " can as I said in that just like disclaimer I did not write very much of this code I just did you", "tokens": [51228, 393, 382, 286, 848, 294, 300, 445, 411, 40896, 286, 630, 406, 2464, 588, 709, 295, 341, 3089, 286, 445, 630, 291, 51526], "temperature": 0.0, "avg_logprob": -0.16094087244390132, "compression_ratio": 1.6099585062240664, "no_speech_prob": 0.006709146313369274}, {"id": 140, "seek": 97296, "start": 996.2, "end": 1002.5600000000001, "text": " know the bits I've talked about and then I've worked on doing bug fixes especially since we've", "tokens": [51526, 458, 264, 9239, 286, 600, 2825, 466, 293, 550, 286, 600, 2732, 322, 884, 7426, 32539, 2318, 1670, 321, 600, 51844], "temperature": 0.0, "avg_logprob": -0.16094087244390132, "compression_ratio": 1.6099585062240664, "no_speech_prob": 0.006709146313369274}, {"id": 141, "seek": 100256, "start": 1002.5999999999999, "end": 1008.92, "text": " one thing I forgot to mention part of why we're going to have to be experimental is OSS fuzz", "tokens": [50366, 472, 551, 286, 5298, 281, 2152, 644, 295, 983, 321, 434, 516, 281, 362, 281, 312, 17069, 307, 12731, 50, 283, 16740, 50682], "temperature": 0.0, "avg_logprob": -0.13723004466355448, "compression_ratio": 1.6118143459915613, "no_speech_prob": 0.005103249102830887}, {"id": 142, "seek": 100256, "start": 1008.92, "end": 1013.4, "text": " we've only recently started being fuzzed since we went into FFNPEG master so we're getting a lot", "tokens": [50682, 321, 600, 787, 3938, 1409, 885, 283, 16740, 292, 1670, 321, 1437, 666, 479, 37, 45, 5208, 38, 4505, 370, 321, 434, 1242, 257, 688, 50906], "temperature": 0.0, "avg_logprob": -0.13723004466355448, "compression_ratio": 1.6118143459915613, "no_speech_prob": 0.005103249102830887}, {"id": 143, "seek": 100256, "start": 1013.4, "end": 1018.92, "text": " of reports for that at the moment that we're trying to work through before we go into like a", "tokens": [50906, 295, 7122, 337, 300, 412, 264, 1623, 300, 321, 434, 1382, 281, 589, 807, 949, 321, 352, 666, 411, 257, 51182], "temperature": 0.0, "avg_logprob": -0.13723004466355448, "compression_ratio": 1.6118143459915613, "no_speech_prob": 0.005103249102830887}, {"id": 144, "seek": 100256, "start": 1018.92, "end": 1032.1599999999999, "text": " normal release but I'll try and answer any questions as best I can yes. So the question was have we", "tokens": [51182, 2710, 4374, 457, 286, 603, 853, 293, 1867, 604, 1651, 382, 1151, 286, 393, 2086, 13, 407, 264, 1168, 390, 362, 321, 51844], "temperature": 0.0, "avg_logprob": -0.13723004466355448, "compression_ratio": 1.6118143459915613, "no_speech_prob": 0.005103249102830887}, {"id": 145, "seek": 103216, "start": 1032.2, "end": 1044.1200000000001, "text": " considered trying to use C in forensics? Yeah as a step between having fully C code and having", "tokens": [50366, 4888, 1382, 281, 764, 383, 294, 32034, 1167, 30, 865, 382, 257, 1823, 1296, 1419, 4498, 383, 3089, 293, 1419, 50962], "temperature": 0.0, "avg_logprob": -0.2084811773055639, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.004706173203885555}, {"id": 146, "seek": 103216, "start": 1044.1200000000001, "end": 1051.44, "text": " handwritten assembly for everything it's not the FFNPEG way FFNPEG everything is handwritten", "tokens": [50962, 1011, 26859, 12103, 337, 1203, 309, 311, 406, 264, 479, 37, 45, 5208, 38, 636, 479, 37, 45, 5208, 38, 1203, 307, 1011, 26859, 51328], "temperature": 0.0, "avg_logprob": -0.2084811773055639, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.004706173203885555}, {"id": 147, "seek": 103216, "start": 1051.44, "end": 1059.76, "text": " assembly I think there's a little bit in like lib SW scale I believe but that's when the FFNPEG is", "tokens": [51328, 12103, 286, 519, 456, 311, 257, 707, 857, 294, 411, 22854, 20346, 4373, 286, 1697, 457, 300, 311, 562, 264, 479, 37, 45, 5208, 38, 307, 51744], "temperature": 0.0, "avg_logprob": -0.2084811773055639, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.004706173203885555}, {"id": 148, "seek": 105976, "start": 1059.8, "end": 1067.04, "text": " in the process of removing that tiny bit of C in forensics that we still have so yeah I mean", "tokens": [50366, 294, 264, 1399, 295, 12720, 300, 5870, 857, 295, 383, 294, 32034, 1167, 300, 321, 920, 362, 370, 1338, 286, 914, 50728], "temperature": 0.0, "avg_logprob": -0.15856481242824244, "compression_ratio": 1.529100529100529, "no_speech_prob": 0.008806137368083}, {"id": 149, "seek": 105976, "start": 1067.04, "end": 1074.4, "text": " we're probably not going to do that just out of you can go faster with handwritten assembly so", "tokens": [50728, 321, 434, 1391, 406, 516, 281, 360, 300, 445, 484, 295, 291, 393, 352, 4663, 365, 1011, 26859, 12103, 370, 51096], "temperature": 0.0, "avg_logprob": -0.15856481242824244, "compression_ratio": 1.529100529100529, "no_speech_prob": 0.008806137368083}, {"id": 150, "seek": 105976, "start": 1074.4, "end": 1083.8, "text": " if we're trying to get that same performance and even be VVDC I think it's the only way to go really.", "tokens": [51096, 498, 321, 434, 1382, 281, 483, 300, 912, 3389, 293, 754, 312, 691, 53, 25619, 286, 519, 309, 311, 264, 787, 636, 281, 352, 534, 13, 51566], "temperature": 0.0, "avg_logprob": -0.15856481242824244, "compression_ratio": 1.529100529100529, "no_speech_prob": 0.008806137368083}, {"id": 151, "seek": 108976, "start": 1089.76, "end": 1094.56, "text": " Okay there's no more questions yeah thank you very much.", "tokens": [50414, 1033, 456, 311, 572, 544, 1651, 1338, 1309, 291, 588, 709, 13, 50604], "temperature": 0.0, "avg_logprob": -0.3481784184773763, "compression_ratio": 0.8888888888888888, "no_speech_prob": 0.002675419207662344}], "language": "en"}