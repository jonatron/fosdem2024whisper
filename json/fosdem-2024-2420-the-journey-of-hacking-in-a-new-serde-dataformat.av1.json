{"text": " Now we have the last talk of the day with Paul. He's going to teach us how to hack a new sturdy data format. And I'm really looking forward to it. Thank you. Thank you. Yeah. Hello, everyone. Hello, everyone, for the last talk of this day and of the Rustaf room, the journey of hacking in a new sturdy data format. If you read through the abstract, there are a lot of more things in there, but the main talking points are near for us. You're 30 and I want to present the journey of building that. And before we go into, I want to also emphasize what this talk is not what I'm not going to talk about. This is not going to be an introduction to 30. It's also not going to be an introduction to Neo4S. You don't really need to know what these are to understand what I'm talking about, hopefully, but you're also not going to know what these are after the fact. And similar to the talk about tower, I'm also not going to do an actual deep dive, also a shallow deep dive. And I'm also not going to do a discussion about how to pronounce 30. So with that about me, hi, I'm Paul. You can find me on GitHub with Knut Waco or on Hackyderm. And I work for a company called Neo4J, which is a graph database written in not Rust. We do have a Rust driver though, which is Neo4RS, hence the name. That one is written in poor Rust. We're not wrapping any existing C, ABI or API from some other driver, but it's developed under this thing called Neo4J Labs, which is an incubation community focused process. So there's not really that much product engineering behind it as mostly me doing this in my 20% time with contributions from occasional other people from the company or from the community. And a Neo4J driver for a database, we communicate via Bolt. Bolt is a binary protocol that is built on top of a pack stream, which is something that we use for general data types like strings, ints, lists and so on. This basically a binary JSON-ish thing, I think is an extension of a message pack. And you can have domain specific structs defined in there. And Bolt has some 15 structs on top of that and then another 15 for communication purposes, but we don't really need to talk about those. All of those various data types that the Bolt protocol can have as natively represents are in this big enum. Like you have a null type, you have an integer, you have a float, a string list and a node for graph database and node is an important thing. So it's also on there and there's a bunch of other stuff. Now in Neo4S in the 0.6 release, what is now the previous version, if you wanted to get some data from a node you would write something like this and in 0.7 you would write something like this. And if you think that looks exactly the same, that is on purpose. It's not a fact of low oxygen in the room. But you can also do something like this where you have your struct, you put a 30D0-size thing on it and then you can convert that into your node into that struct. And so I want to talk about how to, or some things that we did to implement this, to provide this functionality. 30, if you're absolutely not familiar with it, I mean it's been mentioned a couple of times today already, a framework for serializing and deserializing data. If you want to get into what it is, you will not find it here but you can go to 30.rs and there's a video linked from John Janseth who goes into great detail about one side of 30 that I'm not going to talk about. And in particular there are these kind of three big concepts there. There's a data type which is your structs where you put your derived serialize and deserialize on it. And then there's the data format which is the other side which has the trade serializer and deserializer. Notice the R at the end of the names. That's the main difference. And they communicate via this 30Data model but not really wire but this data model is mostly represented in the API only. This is one of the examples of something where I would have to put a big asterisk on it and then talk five minutes about why it's not actually like this but shallow dive. So for example JSON is a 30Data format. It's like how your data is represented, formatted in your bytes, in your string, on your desk, wherever it is. And 30Data is the trade that implements this data format, implements the serializer and deserializer trades. Now we want to bring them together. We already have this bold type enum and so we want to implement the data type for this particular thing. And we're also going to focus on the deserializer side only. Doing this while parsing the data into bold type and serializer implementations are on the roadmap. Let's say down there. And we also want to maintain the API compatibility. So as you saw before, the API should look the same. It's not actually the same but it's still going to be breaking but we don't want to have to introduce a lot of things we need to change. All right. So let's talk about this node, this thing that graph databases use. This is the definition from the bold documentation. We can put this in Rust. Very much looks the same. We have ID, labels and properties. And just to show what those actually are. This is Cypher, the query language for users. This is going to be the last slide on Cypher that you see in this talk. I'm just breaking this down so I can show you this particular thing. It's the label of the node. These JSON-ish looking thing are the properties of the node and we have in our end, in our return column, we have the actual node as this node struct. And we have our session thing with our deserialize on and we want to do something like this. I would say give me the value, it's called n as a session, which we could also write like get me a node and then convert that node into a session. So let's try to do that. First attempt that we could try is make our lives easy. Make our bold node, make that deserialize and then use some other data format to do the job for us. So we have here this tool function that we had earlier and we have a t bound that needs to implement deserialize and then we just say, okay, let's lose JSON and then convert our value into JSON and then convert from JSON to the actual user type. And say, are we done? If this was the solution, then this would be a 20 minute talk, not a 40 minute talk. So no. You get a bunch of these error messages that like field event in the year on there and that is because this, what we really want to read from node are the properties, mainly the properties, but we are deserializing the internal structure of a node like the fields, IDs, labels and properties. So user would have to write something like this where they wrap the actual thing in something like a node thing with the properties. We don't want them, but maybe we can fix it easily by just using the properties to pass them into JSON. And that kind of works in the sense that this example could compile and could run, but there's a one there's a fact that we're using JSON, which does not have the same representability of things that Bolt does, like it doesn't know about all those special data structures. And there's also no way to get to the IDs and labels and sometimes we really do want to use them and not just use the properties. So let's try again. We're not going to do this with JSON anymore. We're going to now start writing our own deserializer finally. And we want to, I think it might be able to look like this where we have our session struct with the two fields and then we have some other fields in there which are IDs and labels. So before we can talk about what the deserializer would look like, we need to understand how SIRD brings those as a data format side and the data type side, how it brings those together. If you have this thing where you have this derive deserialize attribute, you can use something like cargo expand to have a look what the result of that macro expansion looks like. And I'm going to show you a very simplified version of that which is more similar to what you would probably write if you would implement this on your own, if not be a macro that would implement this. So you start by implementing the deserialized trade for session. There's only one method that you need to implement called deserialize which gets a deserializer and it returns itself or an error where the error is defined by the deserializer. Here's a deserializer bound and for this particular session struct we call the deserialized struct method. So the deserializer has a bunch of methods and the idea is that we call a method that describes in the most precise way what we actually want to have. That's as we want to have a struct. It's called session. It got those four fields. There's something else and we hope that the deserializer can provide us the data in order to build this thing. And that's something else is a so-called visitor. Whereas a visitor is also a trade from Suri and we implement this as well. We don't need anything on the visitor except like some struct to implement it. So we have our struct, we implement visitor. This one actually defines what the value is that we return. This is the session struct and there's only one method, one function we actually need to implement which is this expecting thing that helps with reporting errors. If you only have a visitor like that it's not useful because the only thing it can do is report an error. So you also want to implement one of the other methods that you get. And you know like Rust Analyzer or so. Or your IDE can help you in figuring out what the methods are or documentation. And we expect when we say to the deserializer, hey, I want to have a struct, we expect that we get a map in return. Structs are like basically like named maps if you will. The keys are your field names, the values are the actual fields. And so we implement the visit map method we get, we also say we return our own value, we return the error from whatever the deserializer gives us. And it gives us this map access thing which is fancy iterator over key value pairs. And if we actually implement this, this looks very mechanical. We have our fields, we don't have any values for them. So they are all options of the actual field types with none of these defaults. We use the map access to say what is the next key in the map. We would match over that key if it's an event, we'll take the next value and put it into the event value. And here we are saying in the TurboFish there we want to have a string. And this call looks quite similar to the node.to call. The bound for string is deserialize and the map access implementation that has the actual value will know what the deserializer is and then you've got another deserializer and deserializer that come together and they do the same thing over again. So it's all like this kind of back and forth from top down. We do that with the rest of the fields and then we can build the value at the end and then we can throw an error for any fields that are missing. Then we plot that in and that is the deserialize site. What is generating and what we need to provide. So let's start by adding a struct for our bold node and we can also implement the into deserializer trait which we can use to tell us what kind of deserializer we want to deserialize a bold node. That is like a very fancy into this, nothing really special to it. So it's up to implementing deserializer for that bold node deserializer. We define an error. The error needs to implement a certain trait. I'm not going to talk more about this. It's like an enum of some typical error cases. And then there's this fancy thing. So if you implement deserializer you have a lot, like a lot of methods that you need to implement. Usually you don't really want to do that. And then there's this concept of self-describing data formats which is that within your data format you know what the next type is, what the next value is, what the next key is. You don't need any kind of information from the outside. And so in JSON, like if you're parsing a key you know okay that's the key, it's called that and then you have a value. So you know at every time where you are and you don't need the information that the next thing that comes is a string or an integer or something. You figure it out by the, just by looking at the data. Bold is such a self-describing data format and for those SIRTY recommends to just implement deserialize any and then use this macro to say every other thing just goes to any and we're all doing that. So we only need to look at ourselves and we don't need anything else. So let's implement this deserialize any here where we say we want to call this visit map method because that's what expected. And there's a map deserializer which is also from SIRTY where you can give an iterator over key value pairs and that will do the correct thing. So we don't actually need to implement anything fancy here. And we can bring those together in this two methods by calling deserialize and using the into deserializer trade to bring those together. So now after we did all of that, we are basically at where we started. We can deserialize our properties or deserialize our properties. But we also want to have the IDs and labels so let's have those before and instead of just using our properties, we are having, we're training this with getting the ID and getting the labels and then we're just passing that on. And that kind of works for this particular example only. We do get our IDs and labels but we only get them if we call the field ID and label string. It's harder than here as this ID string and label string. So you could never call him something else and we could use like special fields like underscore underscore ID or something. But if you want to have an ID, you would have to use one of those field names and you could never use this name in your actual properties because then you would have multiple entries in this map thing and SIRTY will say no, there's multiple values for the key ID and that is an error. And using like underscore like magic field names or something like that would maybe be possible but it feels not really that great to me. So let's try something else and we want to do something like this where we have, we call those extractors internally but these are new type structs. You have an ID struct and the public field that is the ID type and if a label struct with the public field is the labels type and instead of using the field name to say these are IDs or these are labels we're using the field type to say for whatever field name you have we want to, this one gets the ID from the node and everything else in the struct is still being deserialized from the properties. So in order to do that we can no longer use deserializeAny but we already know that we're not actually calling deserializeAny, we're calling deserializeStruct which has been using the forwarder from struct to any but if we also, if we remove struct from this big macro with the forwarding and then implement these there struct on our own we can basically say this is a special version if we know that you want to have a struct. Once we do that because we get these two additional information that deserializeAny doesn't get which is the name of the struct which we actually don't care about but we also get all the fields of the struct. And what we're doing here is we take our properties, we have another enum type in there if I want to show you all the code that is related to the enum there's a lot of it but it's very mechanical code. It's struct data has an enum of two cases property or node and there's a deserializer that's also an enum of two cases and each of those cases have their own deserializer implementation. And so we have our property fields and then we also iterate through all the fields that we get from this struct and we check if any of them are not in our node properties and then we say okay those we are going to deserialize by giving you some additional data from the node and not from the property. And then through this like big enum chain eventually we have okay here we chain them together and through this big enum chain we actually get to to in so-called to another internal deserializer and the new type fields ID and labels they when they get deserialized they don't call deserialized struct they call deserialized new type struct because they're a new type thing and here you get also the name of this struct you don't get any fields and new types there aren't any fields or like there is one field that's just called zero technique. And so we have this additional deserializer where we can implement this one and then here we can match on the name of the struct and if it's called ID we can say oh yeah okay I get the ID from my node and if it's labels we can deserialize labels of the node. And I see deserializer here similar to the map deserializer where we can use 30 to say here a bunch of values and put them in like a list at the end. These are things that SOTI provides in order to avoid like having to allocate a VAC or a map a hash map and then using that one so you can use this you know with like less overhead without allocations and potentially maybe also use it in in in no std environments. Right so if we're doing that and put those together then that works and the example will give you the data. There's still some downsides and I'm not gonna we're not gonna go into a fifth attempt now because those downsides are still not fixed and we're figuring out how to work around them and the biggest downside is that the deserial default attribute doesn't work. So if you have a struct and you annotate one of the fields with this SOTI default what SOTI will do when it generates this deserialize code instead of saying at the end hey I have this value and I do unwrap or else an error with the missing field it's gonna call the default method and then get the value from there and that's the only thing that changes. Like there's nothing else in this whole method call where we get the information that the user actually has this annotated with this default attribute. That means if you go through this next key next value train and we say here is a value and Zuri expects that we give it an actual value like if we say we have something for that value for that key we should provide something. And on the other side what we are doing is saying all the fields in the struct we put them in this iterator where we are saying we have something for the struct. So we eventually see the year field and we think well it must be one of those additional types because the year is not in the properties because it's missing in our node but then we are saying we are not getting one of those new types but we get these U64 and then we don't know what to do about it. Because it's not in the properties we have to do something we cannot say this type isn't available it's too late for that at that point in time and so we have to fail. So using the default attribute doesn't work but there is a workaround that you can use the option wrapper around it so you can manually choose and report default at the end and that works so we have a workaround and so we can figure out how to solve this eventually. So now that we are done with the nodes we can do the same thing for all the other 20 variants. We are not going to do that here of course but you can imagine. But then we are still not done at the end there are still some smaller things that I wanted to mention that are just like things that we ran into and that gave us some learning experience. In particular Bolt has a bytes type so there is a native thing for here is a vec of U8 and this is like some glob of data that the user has defined. Not many data types and many data formats have a bytes type so 30 while the data mod model has something for bytes. We can start by doing this like we get for example a string and we get a bytes and there is a visit string and visit bytes so hey cool we can just pass on our bytes array. But like I said many data formats have them so 30 doesn't actually generate visitors that expect that you call this visit bytes method because then you could never use it with for example JSON. What's really sad is if you have a vec of U8 in your data type you should call this as a sequence of individual bytes instead of like one blob of bytes. So you would have this visit seek and then there is a seek user and that doesn't really matter what is at the end there but we need to call this. But then we can use the same thing where there is a deserialized bytes and there are some third party crates there is 30 bytes there is 30 width that can be used to say to tell 30 hey this is a vec of U8 but actually I can provide bytes for that and please expect call to visit bytes and on the other side like I said earlier deserializer should call the most special like the method with the most information and so it should call not deserialize any at the end but deserialize bytes because it's saying well I actually can accept a call to visit bytes and so in here we can check if we are actually if we have bytes and then we can just pass them on and then we're done. So not really but we're running out of time here so I want to do a quick run through a couple of other things and if you ever ran into one of those issues I don't know you can find me afterwards and we can talk about this. So one thing is I said earlier we want to maintain the existing API and the existing API was based on conversions via the try from and from traits. So there was a bunch of traits implemented for try from bold type for a bunch of other types so we also needed to make sure that if you're using these bunch of other types at the other end our deserializer will do the right thing and part of those bunch of other types are various state related things from the chrono and time crates because bold has native structs for dates and times and date times and without time zones and all the fun with dealing with those. So this taught us about there's a thing called a human readable where you can say whether or not you're a deserializer or your serializer works with a human readable data format and I think the time crates, the time crates uses that in order to say if it's a human readable one it's being serialized and deserialized from string and it parsed from the RFC something 3.9 format and the non-human readable format will pass in a bunch of integers and so we have to set that flag in order to provide the correct data and you can use annotations for one of those where you can say this is a time stamp but the resolution is in milliseconds or in seconds or in microseconds and then we have to figure out okay what is the actual value that we have to give you so that the calculation at the end turns out to be correct. So that was fun. The other thing is if you have conversion via from and try from trades because of the planket implementation you could also convert the bold type into a bold type and so we also need to be able to say we can visualize into from a bold type into another bold type and so we have a custom deserialized implementation for bold type that calls the appropriate method in a way that we know that we get the correct data which is not really that straightforward at the end result is a deserializer that isn't really usable for any other data format and so if you use that one and then deserialize a bold type into a trace on you get some trace on but that doesn't really make sense which is unfortunate and then there's there are things like what if you have more data in your node properties than you actually have in your struct and then usually a data format is expected to be implemented or to be doing the deserialization while parsing and if you're a imagine you're parsing through some JSON and you have this key and you give it to the visitor and the visitor says yeah I don't I don't I don't need this key it can't just continue and say give me the next key you have to go back and say well I don't care about this key but you need to still give me a value so that your parsing state is gonna be correct so that when I call you next you're gonna give me the next key and this is done by this ignored anything where so you will say give me a next value but I'm gonna ignore it so you can give me whatever you want just do the right thing on your end so that your internal state is correct for us we didn't really need to do anything because we already had everything fast and it's enum but since we're moving to doing this while parsing as well we need to take care of that properly then there's the zero copy deserialization we had earlier like oh I want zero copies being a red flag so consider the red flag if you will and all this code that I showed you actually doesn't compile because every trade from 30 has a lifetime around typically called take DE for deserialize and also our deserializer for the boat node doesn't actually have doesn't own the boat node it has a reference to the boat node and we put lifetimes on everything and then implement a bunch of methods that say well if you can make the Rust compiler happy with all the lifetimes that you're using then we don't need to copy data and so you could do things like extracting the labels not as a bag of string but bag of stir slices where you would still get an allocation for the back but the strings would point into the actual data from the boat node thing and we do that for how long we can do that but it's it's it was too much to show it in all the slides and yeah with that I am done and I think we still have time for questions if there are any otherwise yeah thanks for listening questions questions no questions no questions I do have one maybe just a short one you were mentioning like deserializing the bytes before when you say bytes do you mean like a vector of u8 or like the bytes crates or both actually that primarily a back of u8 because that's what we have in a standard library but I think we also have a test that makes sure that it works with the bytes type from the bytes grid so I think you can use that one as well okay then I think that's it for the day thank you the speaker thank you to the whole audience for staying with us next year", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 12.64, "text": " Now we have the last talk of the day with Paul.", "tokens": [50364, 823, 321, 362, 264, 1036, 751, 295, 264, 786, 365, 4552, 13, 50996], "temperature": 0.0, "avg_logprob": -0.3242189586162567, "compression_ratio": 1.3356643356643356, "no_speech_prob": 0.14254172146320343}, {"id": 1, "seek": 0, "start": 12.64, "end": 18.2, "text": " He's going to teach us how to hack a new sturdy data format.", "tokens": [50996, 634, 311, 516, 281, 2924, 505, 577, 281, 10339, 257, 777, 31506, 1412, 7877, 13, 51274], "temperature": 0.0, "avg_logprob": -0.3242189586162567, "compression_ratio": 1.3356643356643356, "no_speech_prob": 0.14254172146320343}, {"id": 2, "seek": 0, "start": 18.2, "end": 20.12, "text": " And I'm really looking forward to it.", "tokens": [51274, 400, 286, 478, 534, 1237, 2128, 281, 309, 13, 51370], "temperature": 0.0, "avg_logprob": -0.3242189586162567, "compression_ratio": 1.3356643356643356, "no_speech_prob": 0.14254172146320343}, {"id": 3, "seek": 0, "start": 20.12, "end": 21.12, "text": " Thank you.", "tokens": [51370, 1044, 291, 13, 51420], "temperature": 0.0, "avg_logprob": -0.3242189586162567, "compression_ratio": 1.3356643356643356, "no_speech_prob": 0.14254172146320343}, {"id": 4, "seek": 0, "start": 21.12, "end": 22.12, "text": " Thank you.", "tokens": [51420, 1044, 291, 13, 51470], "temperature": 0.0, "avg_logprob": -0.3242189586162567, "compression_ratio": 1.3356643356643356, "no_speech_prob": 0.14254172146320343}, {"id": 5, "seek": 0, "start": 22.12, "end": 23.12, "text": " Yeah.", "tokens": [51470, 865, 13, 51520], "temperature": 0.0, "avg_logprob": -0.3242189586162567, "compression_ratio": 1.3356643356643356, "no_speech_prob": 0.14254172146320343}, {"id": 6, "seek": 0, "start": 23.12, "end": 24.12, "text": " Hello, everyone.", "tokens": [51520, 2425, 11, 1518, 13, 51570], "temperature": 0.0, "avg_logprob": -0.3242189586162567, "compression_ratio": 1.3356643356643356, "no_speech_prob": 0.14254172146320343}, {"id": 7, "seek": 2412, "start": 24.12, "end": 33.2, "text": " Hello, everyone, for the last talk of this day and of the Rustaf room, the journey of", "tokens": [50364, 2425, 11, 1518, 11, 337, 264, 1036, 751, 295, 341, 786, 293, 295, 264, 34952, 2792, 1808, 11, 264, 4671, 295, 50818], "temperature": 0.0, "avg_logprob": -0.27240949063687714, "compression_ratio": 1.6518218623481782, "no_speech_prob": 0.00594736123457551}, {"id": 8, "seek": 2412, "start": 33.2, "end": 36.120000000000005, "text": " hacking in a new sturdy data format.", "tokens": [50818, 31422, 294, 257, 777, 31506, 1412, 7877, 13, 50964], "temperature": 0.0, "avg_logprob": -0.27240949063687714, "compression_ratio": 1.6518218623481782, "no_speech_prob": 0.00594736123457551}, {"id": 9, "seek": 2412, "start": 36.120000000000005, "end": 39.96, "text": " If you read through the abstract, there are a lot of more things in there, but the main", "tokens": [50964, 759, 291, 1401, 807, 264, 12649, 11, 456, 366, 257, 688, 295, 544, 721, 294, 456, 11, 457, 264, 2135, 51156], "temperature": 0.0, "avg_logprob": -0.27240949063687714, "compression_ratio": 1.6518218623481782, "no_speech_prob": 0.00594736123457551}, {"id": 10, "seek": 2412, "start": 39.96, "end": 42.040000000000006, "text": " talking points are near for us.", "tokens": [51156, 1417, 2793, 366, 2651, 337, 505, 13, 51260], "temperature": 0.0, "avg_logprob": -0.27240949063687714, "compression_ratio": 1.6518218623481782, "no_speech_prob": 0.00594736123457551}, {"id": 11, "seek": 2412, "start": 42.040000000000006, "end": 45.64, "text": " You're 30 and I want to present the journey of building that.", "tokens": [51260, 509, 434, 2217, 293, 286, 528, 281, 1974, 264, 4671, 295, 2390, 300, 13, 51440], "temperature": 0.0, "avg_logprob": -0.27240949063687714, "compression_ratio": 1.6518218623481782, "no_speech_prob": 0.00594736123457551}, {"id": 12, "seek": 2412, "start": 45.64, "end": 50.36, "text": " And before we go into, I want to also emphasize what this talk is not what I'm not going", "tokens": [51440, 400, 949, 321, 352, 666, 11, 286, 528, 281, 611, 16078, 437, 341, 751, 307, 406, 437, 286, 478, 406, 516, 51676], "temperature": 0.0, "avg_logprob": -0.27240949063687714, "compression_ratio": 1.6518218623481782, "no_speech_prob": 0.00594736123457551}, {"id": 13, "seek": 2412, "start": 50.36, "end": 51.36, "text": " to talk about.", "tokens": [51676, 281, 751, 466, 13, 51726], "temperature": 0.0, "avg_logprob": -0.27240949063687714, "compression_ratio": 1.6518218623481782, "no_speech_prob": 0.00594736123457551}, {"id": 14, "seek": 5136, "start": 51.36, "end": 54.36, "text": " This is not going to be an introduction to 30.", "tokens": [50364, 639, 307, 406, 516, 281, 312, 364, 9339, 281, 2217, 13, 50514], "temperature": 0.0, "avg_logprob": -0.26133023278187895, "compression_ratio": 1.9162995594713657, "no_speech_prob": 0.0066313003189861774}, {"id": 15, "seek": 5136, "start": 54.36, "end": 58.28, "text": " It's also not going to be an introduction to Neo4S.", "tokens": [50514, 467, 311, 611, 406, 516, 281, 312, 364, 9339, 281, 24458, 19, 50, 13, 50710], "temperature": 0.0, "avg_logprob": -0.26133023278187895, "compression_ratio": 1.9162995594713657, "no_speech_prob": 0.0066313003189861774}, {"id": 16, "seek": 5136, "start": 58.28, "end": 63.64, "text": " You don't really need to know what these are to understand what I'm talking about, hopefully,", "tokens": [50710, 509, 500, 380, 534, 643, 281, 458, 437, 613, 366, 281, 1223, 437, 286, 478, 1417, 466, 11, 4696, 11, 50978], "temperature": 0.0, "avg_logprob": -0.26133023278187895, "compression_ratio": 1.9162995594713657, "no_speech_prob": 0.0066313003189861774}, {"id": 17, "seek": 5136, "start": 63.64, "end": 68.36, "text": " but you're also not going to know what these are after the fact.", "tokens": [50978, 457, 291, 434, 611, 406, 516, 281, 458, 437, 613, 366, 934, 264, 1186, 13, 51214], "temperature": 0.0, "avg_logprob": -0.26133023278187895, "compression_ratio": 1.9162995594713657, "no_speech_prob": 0.0066313003189861774}, {"id": 18, "seek": 5136, "start": 68.36, "end": 74.6, "text": " And similar to the talk about tower, I'm also not going to do an actual deep dive, also", "tokens": [51214, 400, 2531, 281, 264, 751, 466, 10567, 11, 286, 478, 611, 406, 516, 281, 360, 364, 3539, 2452, 9192, 11, 611, 51526], "temperature": 0.0, "avg_logprob": -0.26133023278187895, "compression_ratio": 1.9162995594713657, "no_speech_prob": 0.0066313003189861774}, {"id": 19, "seek": 5136, "start": 74.6, "end": 76.32, "text": " a shallow deep dive.", "tokens": [51526, 257, 20488, 2452, 9192, 13, 51612], "temperature": 0.0, "avg_logprob": -0.26133023278187895, "compression_ratio": 1.9162995594713657, "no_speech_prob": 0.0066313003189861774}, {"id": 20, "seek": 5136, "start": 76.32, "end": 81.0, "text": " And I'm also not going to do a discussion about how to pronounce 30.", "tokens": [51612, 400, 286, 478, 611, 406, 516, 281, 360, 257, 5017, 466, 577, 281, 19567, 2217, 13, 51846], "temperature": 0.0, "avg_logprob": -0.26133023278187895, "compression_ratio": 1.9162995594713657, "no_speech_prob": 0.0066313003189861774}, {"id": 21, "seek": 8100, "start": 81.0, "end": 84.4, "text": " So with that about me, hi, I'm Paul.", "tokens": [50364, 407, 365, 300, 466, 385, 11, 4879, 11, 286, 478, 4552, 13, 50534], "temperature": 0.0, "avg_logprob": -0.21953656651952244, "compression_ratio": 1.4819277108433735, "no_speech_prob": 0.0065691652707755566}, {"id": 22, "seek": 8100, "start": 84.4, "end": 88.48, "text": " You can find me on GitHub with Knut Waco or on Hackyderm.", "tokens": [50534, 509, 393, 915, 385, 322, 23331, 365, 10519, 325, 343, 11428, 420, 322, 35170, 6655, 966, 13, 50738], "temperature": 0.0, "avg_logprob": -0.21953656651952244, "compression_ratio": 1.4819277108433735, "no_speech_prob": 0.0065691652707755566}, {"id": 23, "seek": 8100, "start": 88.48, "end": 97.2, "text": " And I work for a company called Neo4J, which is a graph database written in not Rust.", "tokens": [50738, 400, 286, 589, 337, 257, 2237, 1219, 24458, 19, 41, 11, 597, 307, 257, 4295, 8149, 3720, 294, 406, 34952, 13, 51174], "temperature": 0.0, "avg_logprob": -0.21953656651952244, "compression_ratio": 1.4819277108433735, "no_speech_prob": 0.0065691652707755566}, {"id": 24, "seek": 8100, "start": 97.2, "end": 102.76, "text": " We do have a Rust driver though, which is Neo4RS, hence the name.", "tokens": [51174, 492, 360, 362, 257, 34952, 6787, 1673, 11, 597, 307, 24458, 19, 43580, 11, 16678, 264, 1315, 13, 51452], "temperature": 0.0, "avg_logprob": -0.21953656651952244, "compression_ratio": 1.4819277108433735, "no_speech_prob": 0.0065691652707755566}, {"id": 25, "seek": 8100, "start": 102.76, "end": 103.92, "text": " That one is written in poor Rust.", "tokens": [51452, 663, 472, 307, 3720, 294, 4716, 34952, 13, 51510], "temperature": 0.0, "avg_logprob": -0.21953656651952244, "compression_ratio": 1.4819277108433735, "no_speech_prob": 0.0065691652707755566}, {"id": 26, "seek": 8100, "start": 103.92, "end": 110.12, "text": " We're not wrapping any existing C, ABI or API from some other driver, but it's developed", "tokens": [51510, 492, 434, 406, 21993, 604, 6741, 383, 11, 316, 11291, 420, 9362, 490, 512, 661, 6787, 11, 457, 309, 311, 4743, 51820], "temperature": 0.0, "avg_logprob": -0.21953656651952244, "compression_ratio": 1.4819277108433735, "no_speech_prob": 0.0065691652707755566}, {"id": 27, "seek": 11012, "start": 110.12, "end": 116.56, "text": " under this thing called Neo4J Labs, which is an incubation community focused process.", "tokens": [50364, 833, 341, 551, 1219, 24458, 19, 41, 40047, 11, 597, 307, 364, 33345, 399, 1768, 5178, 1399, 13, 50686], "temperature": 0.0, "avg_logprob": -0.2483683121510041, "compression_ratio": 1.518181818181818, "no_speech_prob": 0.000813640421256423}, {"id": 28, "seek": 11012, "start": 116.56, "end": 121.92, "text": " So there's not really that much product engineering behind it as mostly me doing this in my 20%", "tokens": [50686, 407, 456, 311, 406, 534, 300, 709, 1674, 7043, 2261, 309, 382, 5240, 385, 884, 341, 294, 452, 945, 4, 50954], "temperature": 0.0, "avg_logprob": -0.2483683121510041, "compression_ratio": 1.518181818181818, "no_speech_prob": 0.000813640421256423}, {"id": 29, "seek": 11012, "start": 121.92, "end": 129.48000000000002, "text": " time with contributions from occasional other people from the company or from the community.", "tokens": [50954, 565, 365, 15725, 490, 31644, 661, 561, 490, 264, 2237, 420, 490, 264, 1768, 13, 51332], "temperature": 0.0, "avg_logprob": -0.2483683121510041, "compression_ratio": 1.518181818181818, "no_speech_prob": 0.000813640421256423}, {"id": 30, "seek": 11012, "start": 129.48000000000002, "end": 137.84, "text": " And a Neo4J driver for a database, we communicate via Bolt.", "tokens": [51332, 400, 257, 24458, 19, 41, 6787, 337, 257, 8149, 11, 321, 7890, 5766, 37884, 13, 51750], "temperature": 0.0, "avg_logprob": -0.2483683121510041, "compression_ratio": 1.518181818181818, "no_speech_prob": 0.000813640421256423}, {"id": 31, "seek": 13784, "start": 137.84, "end": 144.52, "text": " Bolt is a binary protocol that is built on top of a pack stream, which is something that", "tokens": [50364, 37884, 307, 257, 17434, 10336, 300, 307, 3094, 322, 1192, 295, 257, 2844, 4309, 11, 597, 307, 746, 300, 50698], "temperature": 0.0, "avg_logprob": -0.291116020896218, "compression_ratio": 1.4702970297029703, "no_speech_prob": 0.08497947454452515}, {"id": 32, "seek": 13784, "start": 144.52, "end": 151.32, "text": " we use for general data types like strings, ints, lists and so on.", "tokens": [50698, 321, 764, 337, 2674, 1412, 3467, 411, 13985, 11, 560, 82, 11, 14511, 293, 370, 322, 13, 51038], "temperature": 0.0, "avg_logprob": -0.291116020896218, "compression_ratio": 1.4702970297029703, "no_speech_prob": 0.08497947454452515}, {"id": 33, "seek": 13784, "start": 151.32, "end": 157.6, "text": " This basically a binary JSON-ish thing, I think is an extension of a message pack.", "tokens": [51038, 639, 1936, 257, 17434, 31828, 12, 742, 551, 11, 286, 519, 307, 364, 10320, 295, 257, 3636, 2844, 13, 51352], "temperature": 0.0, "avg_logprob": -0.291116020896218, "compression_ratio": 1.4702970297029703, "no_speech_prob": 0.08497947454452515}, {"id": 34, "seek": 13784, "start": 157.6, "end": 161.28, "text": " And you can have domain specific structs defined in there.", "tokens": [51352, 400, 291, 393, 362, 9274, 2685, 6594, 82, 7642, 294, 456, 13, 51536], "temperature": 0.0, "avg_logprob": -0.291116020896218, "compression_ratio": 1.4702970297029703, "no_speech_prob": 0.08497947454452515}, {"id": 35, "seek": 16128, "start": 161.28, "end": 171.96, "text": " And Bolt has some 15 structs on top of that and then another 15 for communication purposes,", "tokens": [50364, 400, 37884, 575, 512, 2119, 6594, 82, 322, 1192, 295, 300, 293, 550, 1071, 2119, 337, 6101, 9932, 11, 50898], "temperature": 0.0, "avg_logprob": -0.24901643666354092, "compression_ratio": 1.5674418604651164, "no_speech_prob": 0.0053797136060893536}, {"id": 36, "seek": 16128, "start": 171.96, "end": 175.24, "text": " but we don't really need to talk about those.", "tokens": [50898, 457, 321, 500, 380, 534, 643, 281, 751, 466, 729, 13, 51062], "temperature": 0.0, "avg_logprob": -0.24901643666354092, "compression_ratio": 1.5674418604651164, "no_speech_prob": 0.0053797136060893536}, {"id": 37, "seek": 16128, "start": 175.24, "end": 182.92000000000002, "text": " All of those various data types that the Bolt protocol can have as natively represents are", "tokens": [51062, 1057, 295, 729, 3683, 1412, 3467, 300, 264, 37884, 10336, 393, 362, 382, 8470, 356, 8855, 366, 51446], "temperature": 0.0, "avg_logprob": -0.24901643666354092, "compression_ratio": 1.5674418604651164, "no_speech_prob": 0.0053797136060893536}, {"id": 38, "seek": 16128, "start": 182.92000000000002, "end": 185.44, "text": " in this big enum.", "tokens": [51446, 294, 341, 955, 465, 449, 13, 51572], "temperature": 0.0, "avg_logprob": -0.24901643666354092, "compression_ratio": 1.5674418604651164, "no_speech_prob": 0.0053797136060893536}, {"id": 39, "seek": 16128, "start": 185.44, "end": 191.16, "text": " Like you have a null type, you have an integer, you have a float, a string list and a node", "tokens": [51572, 1743, 291, 362, 257, 18184, 2010, 11, 291, 362, 364, 24922, 11, 291, 362, 257, 15706, 11, 257, 6798, 1329, 293, 257, 9984, 51858], "temperature": 0.0, "avg_logprob": -0.24901643666354092, "compression_ratio": 1.5674418604651164, "no_speech_prob": 0.0053797136060893536}, {"id": 40, "seek": 19116, "start": 191.16, "end": 196.24, "text": " for graph database and node is an important thing.", "tokens": [50364, 337, 4295, 8149, 293, 9984, 307, 364, 1021, 551, 13, 50618], "temperature": 0.0, "avg_logprob": -0.19787943245160697, "compression_ratio": 1.665158371040724, "no_speech_prob": 0.016872795298695564}, {"id": 41, "seek": 19116, "start": 196.24, "end": 199.04, "text": " So it's also on there and there's a bunch of other stuff.", "tokens": [50618, 407, 309, 311, 611, 322, 456, 293, 456, 311, 257, 3840, 295, 661, 1507, 13, 50758], "temperature": 0.0, "avg_logprob": -0.19787943245160697, "compression_ratio": 1.665158371040724, "no_speech_prob": 0.016872795298695564}, {"id": 42, "seek": 19116, "start": 199.04, "end": 207.76, "text": " Now in Neo4S in the 0.6 release, what is now the previous version, if you wanted to get", "tokens": [50758, 823, 294, 24458, 19, 50, 294, 264, 1958, 13, 21, 4374, 11, 437, 307, 586, 264, 3894, 3037, 11, 498, 291, 1415, 281, 483, 51194], "temperature": 0.0, "avg_logprob": -0.19787943245160697, "compression_ratio": 1.665158371040724, "no_speech_prob": 0.016872795298695564}, {"id": 43, "seek": 19116, "start": 207.76, "end": 213.16, "text": " some data from a node you would write something like this and in 0.7 you would write something", "tokens": [51194, 512, 1412, 490, 257, 9984, 291, 576, 2464, 746, 411, 341, 293, 294, 1958, 13, 22, 291, 576, 2464, 746, 51464], "temperature": 0.0, "avg_logprob": -0.19787943245160697, "compression_ratio": 1.665158371040724, "no_speech_prob": 0.016872795298695564}, {"id": 44, "seek": 19116, "start": 213.16, "end": 214.8, "text": " like this.", "tokens": [51464, 411, 341, 13, 51546], "temperature": 0.0, "avg_logprob": -0.19787943245160697, "compression_ratio": 1.665158371040724, "no_speech_prob": 0.016872795298695564}, {"id": 45, "seek": 19116, "start": 214.8, "end": 218.92, "text": " And if you think that looks exactly the same, that is on purpose.", "tokens": [51546, 400, 498, 291, 519, 300, 1542, 2293, 264, 912, 11, 300, 307, 322, 4334, 13, 51752], "temperature": 0.0, "avg_logprob": -0.19787943245160697, "compression_ratio": 1.665158371040724, "no_speech_prob": 0.016872795298695564}, {"id": 46, "seek": 21892, "start": 218.92, "end": 223.88, "text": " It's not a fact of low oxygen in the room.", "tokens": [50364, 467, 311, 406, 257, 1186, 295, 2295, 9169, 294, 264, 1808, 13, 50612], "temperature": 0.0, "avg_logprob": -0.26611823597173584, "compression_ratio": 1.551219512195122, "no_speech_prob": 0.009233120828866959}, {"id": 47, "seek": 21892, "start": 223.88, "end": 229.76, "text": " But you can also do something like this where you have your struct, you put a 30D0-size thing", "tokens": [50612, 583, 291, 393, 611, 360, 746, 411, 341, 689, 291, 362, 428, 6594, 11, 291, 829, 257, 2217, 35, 15, 12, 27553, 551, 50906], "temperature": 0.0, "avg_logprob": -0.26611823597173584, "compression_ratio": 1.551219512195122, "no_speech_prob": 0.009233120828866959}, {"id": 48, "seek": 21892, "start": 229.76, "end": 236.11999999999998, "text": " on it and then you can convert that into your node into that struct.", "tokens": [50906, 322, 309, 293, 550, 291, 393, 7620, 300, 666, 428, 9984, 666, 300, 6594, 13, 51224], "temperature": 0.0, "avg_logprob": -0.26611823597173584, "compression_ratio": 1.551219512195122, "no_speech_prob": 0.009233120828866959}, {"id": 49, "seek": 21892, "start": 236.11999999999998, "end": 242.23999999999998, "text": " And so I want to talk about how to, or some things that we did to implement this, to provide", "tokens": [51224, 400, 370, 286, 528, 281, 751, 466, 577, 281, 11, 420, 512, 721, 300, 321, 630, 281, 4445, 341, 11, 281, 2893, 51530], "temperature": 0.0, "avg_logprob": -0.26611823597173584, "compression_ratio": 1.551219512195122, "no_speech_prob": 0.009233120828866959}, {"id": 50, "seek": 21892, "start": 242.23999999999998, "end": 244.04, "text": " this functionality.", "tokens": [51530, 341, 14980, 13, 51620], "temperature": 0.0, "avg_logprob": -0.26611823597173584, "compression_ratio": 1.551219512195122, "no_speech_prob": 0.009233120828866959}, {"id": 51, "seek": 24404, "start": 244.95999999999998, "end": 248.92, "text": " 30, if you're absolutely not familiar with it, I mean it's been mentioned a couple of", "tokens": [50410, 2217, 11, 498, 291, 434, 3122, 406, 4963, 365, 309, 11, 286, 914, 309, 311, 668, 2835, 257, 1916, 295, 50608], "temperature": 0.0, "avg_logprob": -0.2582748263489966, "compression_ratio": 1.5588235294117647, "no_speech_prob": 0.006256913300603628}, {"id": 52, "seek": 24404, "start": 248.92, "end": 254.32, "text": " times today already, a framework for serializing and deserializing data.", "tokens": [50608, 1413, 965, 1217, 11, 257, 8388, 337, 17436, 3319, 293, 730, 260, 831, 3319, 1412, 13, 50878], "temperature": 0.0, "avg_logprob": -0.2582748263489966, "compression_ratio": 1.5588235294117647, "no_speech_prob": 0.006256913300603628}, {"id": 53, "seek": 24404, "start": 254.32, "end": 261.56, "text": " If you want to get into what it is, you will not find it here but you can go to 30.rs and", "tokens": [50878, 759, 291, 528, 281, 483, 666, 437, 309, 307, 11, 291, 486, 406, 915, 309, 510, 457, 291, 393, 352, 281, 2217, 13, 22943, 293, 51240], "temperature": 0.0, "avg_logprob": -0.2582748263489966, "compression_ratio": 1.5588235294117647, "no_speech_prob": 0.006256913300603628}, {"id": 54, "seek": 24404, "start": 261.56, "end": 269.48, "text": " there's a video linked from John Janseth who goes into great detail about one side of 30", "tokens": [51240, 456, 311, 257, 960, 9408, 490, 2619, 508, 599, 3293, 567, 1709, 666, 869, 2607, 466, 472, 1252, 295, 2217, 51636], "temperature": 0.0, "avg_logprob": -0.2582748263489966, "compression_ratio": 1.5588235294117647, "no_speech_prob": 0.006256913300603628}, {"id": 55, "seek": 24404, "start": 269.48, "end": 273.08, "text": " that I'm not going to talk about.", "tokens": [51636, 300, 286, 478, 406, 516, 281, 751, 466, 13, 51816], "temperature": 0.0, "avg_logprob": -0.2582748263489966, "compression_ratio": 1.5588235294117647, "no_speech_prob": 0.006256913300603628}, {"id": 56, "seek": 27308, "start": 273.12, "end": 278.03999999999996, "text": " And in particular there are these kind of three big concepts there.", "tokens": [50366, 400, 294, 1729, 456, 366, 613, 733, 295, 1045, 955, 10392, 456, 13, 50612], "temperature": 0.0, "avg_logprob": -0.22906832109417832, "compression_ratio": 1.7644628099173554, "no_speech_prob": 0.00019105208048131317}, {"id": 57, "seek": 27308, "start": 278.03999999999996, "end": 283.35999999999996, "text": " There's a data type which is your structs where you put your derived serialize and deserialize", "tokens": [50612, 821, 311, 257, 1412, 2010, 597, 307, 428, 6594, 82, 689, 291, 829, 428, 18949, 17436, 1125, 293, 730, 260, 831, 1125, 50878], "temperature": 0.0, "avg_logprob": -0.22906832109417832, "compression_ratio": 1.7644628099173554, "no_speech_prob": 0.00019105208048131317}, {"id": 58, "seek": 27308, "start": 283.35999999999996, "end": 284.64, "text": " on it.", "tokens": [50878, 322, 309, 13, 50942], "temperature": 0.0, "avg_logprob": -0.22906832109417832, "compression_ratio": 1.7644628099173554, "no_speech_prob": 0.00019105208048131317}, {"id": 59, "seek": 27308, "start": 284.64, "end": 289.24, "text": " And then there's the data format which is the other side which has the trade serializer", "tokens": [50942, 400, 550, 456, 311, 264, 1412, 7877, 597, 307, 264, 661, 1252, 597, 575, 264, 4923, 17436, 6545, 51172], "temperature": 0.0, "avg_logprob": -0.22906832109417832, "compression_ratio": 1.7644628099173554, "no_speech_prob": 0.00019105208048131317}, {"id": 60, "seek": 27308, "start": 289.24, "end": 290.79999999999995, "text": " and deserializer.", "tokens": [51172, 293, 730, 260, 831, 6545, 13, 51250], "temperature": 0.0, "avg_logprob": -0.22906832109417832, "compression_ratio": 1.7644628099173554, "no_speech_prob": 0.00019105208048131317}, {"id": 61, "seek": 27308, "start": 290.79999999999995, "end": 294.2, "text": " Notice the R at the end of the names.", "tokens": [51250, 13428, 264, 497, 412, 264, 917, 295, 264, 5288, 13, 51420], "temperature": 0.0, "avg_logprob": -0.22906832109417832, "compression_ratio": 1.7644628099173554, "no_speech_prob": 0.00019105208048131317}, {"id": 62, "seek": 27308, "start": 294.2, "end": 296.56, "text": " That's the main difference.", "tokens": [51420, 663, 311, 264, 2135, 2649, 13, 51538], "temperature": 0.0, "avg_logprob": -0.22906832109417832, "compression_ratio": 1.7644628099173554, "no_speech_prob": 0.00019105208048131317}, {"id": 63, "seek": 27308, "start": 296.56, "end": 302.91999999999996, "text": " And they communicate via this 30Data model but not really wire but this data model is", "tokens": [51538, 400, 436, 7890, 5766, 341, 2217, 35, 3274, 2316, 457, 406, 534, 6234, 457, 341, 1412, 2316, 307, 51856], "temperature": 0.0, "avg_logprob": -0.22906832109417832, "compression_ratio": 1.7644628099173554, "no_speech_prob": 0.00019105208048131317}, {"id": 64, "seek": 30292, "start": 302.96000000000004, "end": 308.8, "text": " mostly represented in the API only.", "tokens": [50366, 5240, 10379, 294, 264, 9362, 787, 13, 50658], "temperature": 0.0, "avg_logprob": -0.1990541544827548, "compression_ratio": 1.3442622950819672, "no_speech_prob": 0.0010970600415021181}, {"id": 65, "seek": 30292, "start": 308.8, "end": 313.92, "text": " This is one of the examples of something where I would have to put a big asterisk on it and", "tokens": [50658, 639, 307, 472, 295, 264, 5110, 295, 746, 689, 286, 576, 362, 281, 829, 257, 955, 257, 3120, 7797, 322, 309, 293, 50914], "temperature": 0.0, "avg_logprob": -0.1990541544827548, "compression_ratio": 1.3442622950819672, "no_speech_prob": 0.0010970600415021181}, {"id": 66, "seek": 30292, "start": 313.92, "end": 322.20000000000005, "text": " then talk five minutes about why it's not actually like this but shallow dive.", "tokens": [50914, 550, 751, 1732, 2077, 466, 983, 309, 311, 406, 767, 411, 341, 457, 20488, 9192, 13, 51328], "temperature": 0.0, "avg_logprob": -0.1990541544827548, "compression_ratio": 1.3442622950819672, "no_speech_prob": 0.0010970600415021181}, {"id": 67, "seek": 30292, "start": 322.20000000000005, "end": 327.12, "text": " So for example JSON is a 30Data format.", "tokens": [51328, 407, 337, 1365, 31828, 307, 257, 2217, 35, 3274, 7877, 13, 51574], "temperature": 0.0, "avg_logprob": -0.1990541544827548, "compression_ratio": 1.3442622950819672, "no_speech_prob": 0.0010970600415021181}, {"id": 68, "seek": 32712, "start": 327.12, "end": 332.84000000000003, "text": " It's like how your data is represented, formatted in your bytes, in your string, on your desk,", "tokens": [50364, 467, 311, 411, 577, 428, 1412, 307, 10379, 11, 1254, 32509, 294, 428, 36088, 11, 294, 428, 6798, 11, 322, 428, 10026, 11, 50650], "temperature": 0.0, "avg_logprob": -0.24099816216362846, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.005631497595459223}, {"id": 69, "seek": 32712, "start": 332.84000000000003, "end": 334.64, "text": " wherever it is.", "tokens": [50650, 8660, 309, 307, 13, 50740], "temperature": 0.0, "avg_logprob": -0.24099816216362846, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.005631497595459223}, {"id": 70, "seek": 32712, "start": 334.64, "end": 341.28000000000003, "text": " And 30Data is the trade that implements this data format, implements the serializer and", "tokens": [50740, 400, 2217, 35, 3274, 307, 264, 4923, 300, 704, 17988, 341, 1412, 7877, 11, 704, 17988, 264, 17436, 6545, 293, 51072], "temperature": 0.0, "avg_logprob": -0.24099816216362846, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.005631497595459223}, {"id": 71, "seek": 32712, "start": 341.28000000000003, "end": 343.88, "text": " deserializer trades.", "tokens": [51072, 730, 260, 831, 6545, 21287, 13, 51202], "temperature": 0.0, "avg_logprob": -0.24099816216362846, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.005631497595459223}, {"id": 72, "seek": 32712, "start": 343.88, "end": 347.88, "text": " Now we want to bring them together.", "tokens": [51202, 823, 321, 528, 281, 1565, 552, 1214, 13, 51402], "temperature": 0.0, "avg_logprob": -0.24099816216362846, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.005631497595459223}, {"id": 73, "seek": 32712, "start": 347.88, "end": 354.4, "text": " We already have this bold type enum and so we want to implement the data type for this", "tokens": [51402, 492, 1217, 362, 341, 11928, 2010, 465, 449, 293, 370, 321, 528, 281, 4445, 264, 1412, 2010, 337, 341, 51728], "temperature": 0.0, "avg_logprob": -0.24099816216362846, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.005631497595459223}, {"id": 74, "seek": 32712, "start": 354.4, "end": 357.04, "text": " particular thing.", "tokens": [51728, 1729, 551, 13, 51860], "temperature": 0.0, "avg_logprob": -0.24099816216362846, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.005631497595459223}, {"id": 75, "seek": 35704, "start": 357.04, "end": 362.56, "text": " And we're also going to focus on the deserializer side only.", "tokens": [50364, 400, 321, 434, 611, 516, 281, 1879, 322, 264, 730, 260, 831, 6545, 1252, 787, 13, 50640], "temperature": 0.0, "avg_logprob": -0.20724090727248995, "compression_ratio": 1.6228070175438596, "no_speech_prob": 0.0006552966078743339}, {"id": 76, "seek": 35704, "start": 362.56, "end": 369.92, "text": " Doing this while parsing the data into bold type and serializer implementations are on", "tokens": [50640, 18496, 341, 1339, 21156, 278, 264, 1412, 666, 11928, 2010, 293, 17436, 6545, 4445, 763, 366, 322, 51008], "temperature": 0.0, "avg_logprob": -0.20724090727248995, "compression_ratio": 1.6228070175438596, "no_speech_prob": 0.0006552966078743339}, {"id": 77, "seek": 35704, "start": 369.92, "end": 371.0, "text": " the roadmap.", "tokens": [51008, 264, 35738, 13, 51062], "temperature": 0.0, "avg_logprob": -0.20724090727248995, "compression_ratio": 1.6228070175438596, "no_speech_prob": 0.0006552966078743339}, {"id": 78, "seek": 35704, "start": 371.0, "end": 372.96000000000004, "text": " Let's say down there.", "tokens": [51062, 961, 311, 584, 760, 456, 13, 51160], "temperature": 0.0, "avg_logprob": -0.20724090727248995, "compression_ratio": 1.6228070175438596, "no_speech_prob": 0.0006552966078743339}, {"id": 79, "seek": 35704, "start": 372.96000000000004, "end": 377.28000000000003, "text": " And we also want to maintain the API compatibility.", "tokens": [51160, 400, 321, 611, 528, 281, 6909, 264, 9362, 34237, 13, 51376], "temperature": 0.0, "avg_logprob": -0.20724090727248995, "compression_ratio": 1.6228070175438596, "no_speech_prob": 0.0006552966078743339}, {"id": 80, "seek": 35704, "start": 377.28000000000003, "end": 382.72, "text": " So as you saw before, the API should look the same.", "tokens": [51376, 407, 382, 291, 1866, 949, 11, 264, 9362, 820, 574, 264, 912, 13, 51648], "temperature": 0.0, "avg_logprob": -0.20724090727248995, "compression_ratio": 1.6228070175438596, "no_speech_prob": 0.0006552966078743339}, {"id": 81, "seek": 35704, "start": 382.72, "end": 386.68, "text": " It's not actually the same but it's still going to be breaking but we don't want to", "tokens": [51648, 467, 311, 406, 767, 264, 912, 457, 309, 311, 920, 516, 281, 312, 7697, 457, 321, 500, 380, 528, 281, 51846], "temperature": 0.0, "avg_logprob": -0.20724090727248995, "compression_ratio": 1.6228070175438596, "no_speech_prob": 0.0006552966078743339}, {"id": 82, "seek": 38668, "start": 386.68, "end": 392.16, "text": " have to introduce a lot of things we need to change.", "tokens": [50364, 362, 281, 5366, 257, 688, 295, 721, 321, 643, 281, 1319, 13, 50638], "temperature": 0.0, "avg_logprob": -0.2719523769685592, "compression_ratio": 1.480952380952381, "no_speech_prob": 0.0011154285166412592}, {"id": 83, "seek": 38668, "start": 392.16, "end": 393.16, "text": " All right.", "tokens": [50638, 1057, 558, 13, 50688], "temperature": 0.0, "avg_logprob": -0.2719523769685592, "compression_ratio": 1.480952380952381, "no_speech_prob": 0.0011154285166412592}, {"id": 84, "seek": 38668, "start": 393.16, "end": 399.16, "text": " So let's talk about this node, this thing that graph databases use.", "tokens": [50688, 407, 718, 311, 751, 466, 341, 9984, 11, 341, 551, 300, 4295, 22380, 764, 13, 50988], "temperature": 0.0, "avg_logprob": -0.2719523769685592, "compression_ratio": 1.480952380952381, "no_speech_prob": 0.0011154285166412592}, {"id": 85, "seek": 38668, "start": 399.16, "end": 403.76, "text": " This is the definition from the bold documentation.", "tokens": [50988, 639, 307, 264, 7123, 490, 264, 11928, 14333, 13, 51218], "temperature": 0.0, "avg_logprob": -0.2719523769685592, "compression_ratio": 1.480952380952381, "no_speech_prob": 0.0011154285166412592}, {"id": 86, "seek": 38668, "start": 403.76, "end": 406.6, "text": " We can put this in Rust.", "tokens": [51218, 492, 393, 829, 341, 294, 34952, 13, 51360], "temperature": 0.0, "avg_logprob": -0.2719523769685592, "compression_ratio": 1.480952380952381, "no_speech_prob": 0.0011154285166412592}, {"id": 87, "seek": 38668, "start": 406.6, "end": 407.6, "text": " Very much looks the same.", "tokens": [51360, 4372, 709, 1542, 264, 912, 13, 51410], "temperature": 0.0, "avg_logprob": -0.2719523769685592, "compression_ratio": 1.480952380952381, "no_speech_prob": 0.0011154285166412592}, {"id": 88, "seek": 38668, "start": 407.6, "end": 411.12, "text": " We have ID, labels and properties.", "tokens": [51410, 492, 362, 7348, 11, 16949, 293, 7221, 13, 51586], "temperature": 0.0, "avg_logprob": -0.2719523769685592, "compression_ratio": 1.480952380952381, "no_speech_prob": 0.0011154285166412592}, {"id": 89, "seek": 38668, "start": 411.12, "end": 415.52, "text": " And just to show what those actually are.", "tokens": [51586, 400, 445, 281, 855, 437, 729, 767, 366, 13, 51806], "temperature": 0.0, "avg_logprob": -0.2719523769685592, "compression_ratio": 1.480952380952381, "no_speech_prob": 0.0011154285166412592}, {"id": 90, "seek": 41552, "start": 415.52, "end": 419.96, "text": " This is Cypher, the query language for users.", "tokens": [50364, 639, 307, 10295, 79, 511, 11, 264, 14581, 2856, 337, 5022, 13, 50586], "temperature": 0.0, "avg_logprob": -0.32402584599513634, "compression_ratio": 1.6515837104072397, "no_speech_prob": 0.00999973714351654}, {"id": 91, "seek": 41552, "start": 419.96, "end": 422.76, "text": " This is going to be the last slide on Cypher that you see in this talk.", "tokens": [50586, 639, 307, 516, 281, 312, 264, 1036, 4137, 322, 10295, 79, 511, 300, 291, 536, 294, 341, 751, 13, 50726], "temperature": 0.0, "avg_logprob": -0.32402584599513634, "compression_ratio": 1.6515837104072397, "no_speech_prob": 0.00999973714351654}, {"id": 92, "seek": 41552, "start": 422.76, "end": 426.59999999999997, "text": " I'm just breaking this down so I can show you this particular thing.", "tokens": [50726, 286, 478, 445, 7697, 341, 760, 370, 286, 393, 855, 291, 341, 1729, 551, 13, 50918], "temperature": 0.0, "avg_logprob": -0.32402584599513634, "compression_ratio": 1.6515837104072397, "no_speech_prob": 0.00999973714351654}, {"id": 93, "seek": 41552, "start": 426.59999999999997, "end": 429.15999999999997, "text": " It's the label of the node.", "tokens": [50918, 467, 311, 264, 7645, 295, 264, 9984, 13, 51046], "temperature": 0.0, "avg_logprob": -0.32402584599513634, "compression_ratio": 1.6515837104072397, "no_speech_prob": 0.00999973714351654}, {"id": 94, "seek": 41552, "start": 429.15999999999997, "end": 435.96, "text": " These JSON-ish looking thing are the properties of the node and we have in our end, in our", "tokens": [51046, 1981, 31828, 12, 742, 1237, 551, 366, 264, 7221, 295, 264, 9984, 293, 321, 362, 294, 527, 917, 11, 294, 527, 51386], "temperature": 0.0, "avg_logprob": -0.32402584599513634, "compression_ratio": 1.6515837104072397, "no_speech_prob": 0.00999973714351654}, {"id": 95, "seek": 41552, "start": 435.96, "end": 441.03999999999996, "text": " return column, we have the actual node as this node struct.", "tokens": [51386, 2736, 7738, 11, 321, 362, 264, 3539, 9984, 382, 341, 9984, 6594, 13, 51640], "temperature": 0.0, "avg_logprob": -0.32402584599513634, "compression_ratio": 1.6515837104072397, "no_speech_prob": 0.00999973714351654}, {"id": 96, "seek": 44104, "start": 441.04, "end": 448.40000000000003, "text": " And we have our session thing with our deserialize on and we want to do something like this.", "tokens": [50364, 400, 321, 362, 527, 5481, 551, 365, 527, 730, 260, 831, 1125, 322, 293, 321, 528, 281, 360, 746, 411, 341, 13, 50732], "temperature": 0.0, "avg_logprob": -0.27013962992121665, "compression_ratio": 1.6326530612244898, "no_speech_prob": 0.0026300367899239063}, {"id": 97, "seek": 44104, "start": 448.40000000000003, "end": 455.40000000000003, "text": " I would say give me the value, it's called n as a session, which we could also write", "tokens": [50732, 286, 576, 584, 976, 385, 264, 2158, 11, 309, 311, 1219, 297, 382, 257, 5481, 11, 597, 321, 727, 611, 2464, 51082], "temperature": 0.0, "avg_logprob": -0.27013962992121665, "compression_ratio": 1.6326530612244898, "no_speech_prob": 0.0026300367899239063}, {"id": 98, "seek": 44104, "start": 455.40000000000003, "end": 460.84000000000003, "text": " like get me a node and then convert that node into a session.", "tokens": [51082, 411, 483, 385, 257, 9984, 293, 550, 7620, 300, 9984, 666, 257, 5481, 13, 51354], "temperature": 0.0, "avg_logprob": -0.27013962992121665, "compression_ratio": 1.6326530612244898, "no_speech_prob": 0.0026300367899239063}, {"id": 99, "seek": 44104, "start": 460.84000000000003, "end": 463.32000000000005, "text": " So let's try to do that.", "tokens": [51354, 407, 718, 311, 853, 281, 360, 300, 13, 51478], "temperature": 0.0, "avg_logprob": -0.27013962992121665, "compression_ratio": 1.6326530612244898, "no_speech_prob": 0.0026300367899239063}, {"id": 100, "seek": 44104, "start": 463.32000000000005, "end": 467.32000000000005, "text": " First attempt that we could try is make our lives easy.", "tokens": [51478, 2386, 5217, 300, 321, 727, 853, 307, 652, 527, 2909, 1858, 13, 51678], "temperature": 0.0, "avg_logprob": -0.27013962992121665, "compression_ratio": 1.6326530612244898, "no_speech_prob": 0.0026300367899239063}, {"id": 101, "seek": 46732, "start": 467.32, "end": 473.48, "text": " Make our bold node, make that deserialize and then use some other data format to do", "tokens": [50364, 4387, 527, 11928, 9984, 11, 652, 300, 730, 260, 831, 1125, 293, 550, 764, 512, 661, 1412, 7877, 281, 360, 50672], "temperature": 0.0, "avg_logprob": -0.28908294180165167, "compression_ratio": 1.7079207920792079, "no_speech_prob": 0.004260069690644741}, {"id": 102, "seek": 46732, "start": 473.48, "end": 474.48, "text": " the job for us.", "tokens": [50672, 264, 1691, 337, 505, 13, 50722], "temperature": 0.0, "avg_logprob": -0.28908294180165167, "compression_ratio": 1.7079207920792079, "no_speech_prob": 0.004260069690644741}, {"id": 103, "seek": 46732, "start": 474.48, "end": 483.04, "text": " So we have here this tool function that we had earlier and we have a t bound that needs", "tokens": [50722, 407, 321, 362, 510, 341, 2290, 2445, 300, 321, 632, 3071, 293, 321, 362, 257, 256, 5472, 300, 2203, 51150], "temperature": 0.0, "avg_logprob": -0.28908294180165167, "compression_ratio": 1.7079207920792079, "no_speech_prob": 0.004260069690644741}, {"id": 104, "seek": 46732, "start": 483.04, "end": 488.76, "text": " to implement deserialize and then we just say, okay, let's lose JSON and then convert", "tokens": [51150, 281, 4445, 730, 260, 831, 1125, 293, 550, 321, 445, 584, 11, 1392, 11, 718, 311, 3624, 31828, 293, 550, 7620, 51436], "temperature": 0.0, "avg_logprob": -0.28908294180165167, "compression_ratio": 1.7079207920792079, "no_speech_prob": 0.004260069690644741}, {"id": 105, "seek": 46732, "start": 488.76, "end": 493.24, "text": " our value into JSON and then convert from JSON to the actual user type.", "tokens": [51436, 527, 2158, 666, 31828, 293, 550, 7620, 490, 31828, 281, 264, 3539, 4195, 2010, 13, 51660], "temperature": 0.0, "avg_logprob": -0.28908294180165167, "compression_ratio": 1.7079207920792079, "no_speech_prob": 0.004260069690644741}, {"id": 106, "seek": 49324, "start": 493.24, "end": 498.36, "text": " And say, are we done?", "tokens": [50364, 400, 584, 11, 366, 321, 1096, 30, 50620], "temperature": 0.0, "avg_logprob": -0.2188170595866878, "compression_ratio": 1.5699481865284974, "no_speech_prob": 0.026718251407146454}, {"id": 107, "seek": 49324, "start": 498.36, "end": 503.04, "text": " If this was the solution, then this would be a 20 minute talk, not a 40 minute talk.", "tokens": [50620, 759, 341, 390, 264, 3827, 11, 550, 341, 576, 312, 257, 945, 3456, 751, 11, 406, 257, 3356, 3456, 751, 13, 50854], "temperature": 0.0, "avg_logprob": -0.2188170595866878, "compression_ratio": 1.5699481865284974, "no_speech_prob": 0.026718251407146454}, {"id": 108, "seek": 49324, "start": 503.04, "end": 504.68, "text": " So no.", "tokens": [50854, 407, 572, 13, 50936], "temperature": 0.0, "avg_logprob": -0.2188170595866878, "compression_ratio": 1.5699481865284974, "no_speech_prob": 0.026718251407146454}, {"id": 109, "seek": 49324, "start": 504.68, "end": 512.32, "text": " You get a bunch of these error messages that like field event in the year on there and that", "tokens": [50936, 509, 483, 257, 3840, 295, 613, 6713, 7897, 300, 411, 2519, 2280, 294, 264, 1064, 322, 456, 293, 300, 51318], "temperature": 0.0, "avg_logprob": -0.2188170595866878, "compression_ratio": 1.5699481865284974, "no_speech_prob": 0.026718251407146454}, {"id": 110, "seek": 49324, "start": 512.32, "end": 521.76, "text": " is because this, what we really want to read from node are the properties, mainly the properties,", "tokens": [51318, 307, 570, 341, 11, 437, 321, 534, 528, 281, 1401, 490, 9984, 366, 264, 7221, 11, 8704, 264, 7221, 11, 51790], "temperature": 0.0, "avg_logprob": -0.2188170595866878, "compression_ratio": 1.5699481865284974, "no_speech_prob": 0.026718251407146454}, {"id": 111, "seek": 52176, "start": 521.76, "end": 527.48, "text": " but we are deserializing the internal structure of a node like the fields, IDs, labels and", "tokens": [50364, 457, 321, 366, 730, 260, 831, 3319, 264, 6920, 3877, 295, 257, 9984, 411, 264, 7909, 11, 48212, 11, 16949, 293, 50650], "temperature": 0.0, "avg_logprob": -0.24577901529711346, "compression_ratio": 1.6142857142857143, "no_speech_prob": 0.04202975332736969}, {"id": 112, "seek": 52176, "start": 527.48, "end": 529.48, "text": " properties.", "tokens": [50650, 7221, 13, 50750], "temperature": 0.0, "avg_logprob": -0.24577901529711346, "compression_ratio": 1.6142857142857143, "no_speech_prob": 0.04202975332736969}, {"id": 113, "seek": 52176, "start": 529.48, "end": 533.8, "text": " So user would have to write something like this where they wrap the actual thing in something", "tokens": [50750, 407, 4195, 576, 362, 281, 2464, 746, 411, 341, 689, 436, 7019, 264, 3539, 551, 294, 746, 50966], "temperature": 0.0, "avg_logprob": -0.24577901529711346, "compression_ratio": 1.6142857142857143, "no_speech_prob": 0.04202975332736969}, {"id": 114, "seek": 52176, "start": 533.8, "end": 536.64, "text": " like a node thing with the properties.", "tokens": [50966, 411, 257, 9984, 551, 365, 264, 7221, 13, 51108], "temperature": 0.0, "avg_logprob": -0.24577901529711346, "compression_ratio": 1.6142857142857143, "no_speech_prob": 0.04202975332736969}, {"id": 115, "seek": 52176, "start": 536.64, "end": 540.3199999999999, "text": " We don't want them, but maybe we can fix it easily by just using the properties to pass", "tokens": [51108, 492, 500, 380, 528, 552, 11, 457, 1310, 321, 393, 3191, 309, 3612, 538, 445, 1228, 264, 7221, 281, 1320, 51292], "temperature": 0.0, "avg_logprob": -0.24577901529711346, "compression_ratio": 1.6142857142857143, "no_speech_prob": 0.04202975332736969}, {"id": 116, "seek": 52176, "start": 540.3199999999999, "end": 542.0, "text": " them into JSON.", "tokens": [51292, 552, 666, 31828, 13, 51376], "temperature": 0.0, "avg_logprob": -0.24577901529711346, "compression_ratio": 1.6142857142857143, "no_speech_prob": 0.04202975332736969}, {"id": 117, "seek": 54200, "start": 542.0, "end": 552.4, "text": " And that kind of works in the sense that this example could compile and could run, but there's", "tokens": [50364, 400, 300, 733, 295, 1985, 294, 264, 2020, 300, 341, 1365, 727, 31413, 293, 727, 1190, 11, 457, 456, 311, 50884], "temperature": 0.0, "avg_logprob": -0.22892164909976653, "compression_ratio": 1.5657894736842106, "no_speech_prob": 0.009999956004321575}, {"id": 118, "seek": 54200, "start": 552.4, "end": 559.68, "text": " a one there's a fact that we're using JSON, which does not have the same representability", "tokens": [50884, 257, 472, 456, 311, 257, 1186, 300, 321, 434, 1228, 31828, 11, 597, 775, 406, 362, 264, 912, 2906, 2310, 51248], "temperature": 0.0, "avg_logprob": -0.22892164909976653, "compression_ratio": 1.5657894736842106, "no_speech_prob": 0.009999956004321575}, {"id": 119, "seek": 54200, "start": 559.68, "end": 564.92, "text": " of things that Bolt does, like it doesn't know about all those special data structures.", "tokens": [51248, 295, 721, 300, 37884, 775, 11, 411, 309, 1177, 380, 458, 466, 439, 729, 2121, 1412, 9227, 13, 51510], "temperature": 0.0, "avg_logprob": -0.22892164909976653, "compression_ratio": 1.5657894736842106, "no_speech_prob": 0.009999956004321575}, {"id": 120, "seek": 54200, "start": 564.92, "end": 570.52, "text": " And there's also no way to get to the IDs and labels and sometimes we really do want", "tokens": [51510, 400, 456, 311, 611, 572, 636, 281, 483, 281, 264, 48212, 293, 16949, 293, 2171, 321, 534, 360, 528, 51790], "temperature": 0.0, "avg_logprob": -0.22892164909976653, "compression_ratio": 1.5657894736842106, "no_speech_prob": 0.009999956004321575}, {"id": 121, "seek": 57052, "start": 570.56, "end": 573.92, "text": " to use them and not just use the properties.", "tokens": [50366, 281, 764, 552, 293, 406, 445, 764, 264, 7221, 13, 50534], "temperature": 0.0, "avg_logprob": -0.20790829261144003, "compression_ratio": 1.5848214285714286, "no_speech_prob": 0.044595491141080856}, {"id": 122, "seek": 57052, "start": 573.92, "end": 575.92, "text": " So let's try again.", "tokens": [50534, 407, 718, 311, 853, 797, 13, 50634], "temperature": 0.0, "avg_logprob": -0.20790829261144003, "compression_ratio": 1.5848214285714286, "no_speech_prob": 0.044595491141080856}, {"id": 123, "seek": 57052, "start": 575.92, "end": 577.48, "text": " We're not going to do this with JSON anymore.", "tokens": [50634, 492, 434, 406, 516, 281, 360, 341, 365, 31828, 3602, 13, 50712], "temperature": 0.0, "avg_logprob": -0.20790829261144003, "compression_ratio": 1.5848214285714286, "no_speech_prob": 0.044595491141080856}, {"id": 124, "seek": 57052, "start": 577.48, "end": 583.1999999999999, "text": " We're going to now start writing our own deserializer finally.", "tokens": [50712, 492, 434, 516, 281, 586, 722, 3579, 527, 1065, 730, 260, 831, 6545, 2721, 13, 50998], "temperature": 0.0, "avg_logprob": -0.20790829261144003, "compression_ratio": 1.5848214285714286, "no_speech_prob": 0.044595491141080856}, {"id": 125, "seek": 57052, "start": 583.1999999999999, "end": 589.6, "text": " And we want to, I think it might be able to look like this where we have our session struct", "tokens": [50998, 400, 321, 528, 281, 11, 286, 519, 309, 1062, 312, 1075, 281, 574, 411, 341, 689, 321, 362, 527, 5481, 6594, 51318], "temperature": 0.0, "avg_logprob": -0.20790829261144003, "compression_ratio": 1.5848214285714286, "no_speech_prob": 0.044595491141080856}, {"id": 126, "seek": 57052, "start": 589.6, "end": 598.12, "text": " with the two fields and then we have some other fields in there which are IDs and labels.", "tokens": [51318, 365, 264, 732, 7909, 293, 550, 321, 362, 512, 661, 7909, 294, 456, 597, 366, 48212, 293, 16949, 13, 51744], "temperature": 0.0, "avg_logprob": -0.20790829261144003, "compression_ratio": 1.5848214285714286, "no_speech_prob": 0.044595491141080856}, {"id": 127, "seek": 59812, "start": 598.12, "end": 605.92, "text": " So before we can talk about what the deserializer would look like, we need to understand how", "tokens": [50364, 407, 949, 321, 393, 751, 466, 437, 264, 730, 260, 831, 6545, 576, 574, 411, 11, 321, 643, 281, 1223, 577, 50754], "temperature": 0.0, "avg_logprob": -0.2561239545995539, "compression_ratio": 1.7061611374407584, "no_speech_prob": 0.0006067054346203804}, {"id": 128, "seek": 59812, "start": 605.92, "end": 613.6, "text": " SIRD brings those as a data format side and the data type side, how it brings those together.", "tokens": [50754, 318, 7740, 35, 5607, 729, 382, 257, 1412, 7877, 1252, 293, 264, 1412, 2010, 1252, 11, 577, 309, 5607, 729, 1214, 13, 51138], "temperature": 0.0, "avg_logprob": -0.2561239545995539, "compression_ratio": 1.7061611374407584, "no_speech_prob": 0.0006067054346203804}, {"id": 129, "seek": 59812, "start": 613.6, "end": 619.68, "text": " If you have this thing where you have this derive deserialize attribute, you can use", "tokens": [51138, 759, 291, 362, 341, 551, 689, 291, 362, 341, 28446, 730, 260, 831, 1125, 19667, 11, 291, 393, 764, 51442], "temperature": 0.0, "avg_logprob": -0.2561239545995539, "compression_ratio": 1.7061611374407584, "no_speech_prob": 0.0006067054346203804}, {"id": 130, "seek": 59812, "start": 619.68, "end": 625.04, "text": " something like cargo expand to have a look what the result of that macro expansion looks", "tokens": [51442, 746, 411, 19449, 5268, 281, 362, 257, 574, 437, 264, 1874, 295, 300, 18887, 11260, 1542, 51710], "temperature": 0.0, "avg_logprob": -0.2561239545995539, "compression_ratio": 1.7061611374407584, "no_speech_prob": 0.0006067054346203804}, {"id": 131, "seek": 62504, "start": 625.12, "end": 627.12, "text": " like.", "tokens": [50368, 411, 13, 50468], "temperature": 0.0, "avg_logprob": -0.17966862942310088, "compression_ratio": 1.7476190476190476, "no_speech_prob": 0.0008035742212086916}, {"id": 132, "seek": 62504, "start": 627.12, "end": 635.0, "text": " And I'm going to show you a very simplified version of that which is more similar to what", "tokens": [50468, 400, 286, 478, 516, 281, 855, 291, 257, 588, 26335, 3037, 295, 300, 597, 307, 544, 2531, 281, 437, 50862], "temperature": 0.0, "avg_logprob": -0.17966862942310088, "compression_ratio": 1.7476190476190476, "no_speech_prob": 0.0008035742212086916}, {"id": 133, "seek": 62504, "start": 635.0, "end": 640.0, "text": " you would probably write if you would implement this on your own, if not be a macro that", "tokens": [50862, 291, 576, 1391, 2464, 498, 291, 576, 4445, 341, 322, 428, 1065, 11, 498, 406, 312, 257, 18887, 300, 51112], "temperature": 0.0, "avg_logprob": -0.17966862942310088, "compression_ratio": 1.7476190476190476, "no_speech_prob": 0.0008035742212086916}, {"id": 134, "seek": 62504, "start": 640.0, "end": 643.04, "text": " would implement this.", "tokens": [51112, 576, 4445, 341, 13, 51264], "temperature": 0.0, "avg_logprob": -0.17966862942310088, "compression_ratio": 1.7476190476190476, "no_speech_prob": 0.0008035742212086916}, {"id": 135, "seek": 62504, "start": 643.04, "end": 646.4, "text": " So you start by implementing the deserialized trade for session.", "tokens": [51264, 407, 291, 722, 538, 18114, 264, 730, 260, 831, 1602, 4923, 337, 5481, 13, 51432], "temperature": 0.0, "avg_logprob": -0.17966862942310088, "compression_ratio": 1.7476190476190476, "no_speech_prob": 0.0008035742212086916}, {"id": 136, "seek": 62504, "start": 646.4, "end": 653.04, "text": " There's only one method that you need to implement called deserialize which gets a deserializer", "tokens": [51432, 821, 311, 787, 472, 3170, 300, 291, 643, 281, 4445, 1219, 730, 260, 831, 1125, 597, 2170, 257, 730, 260, 831, 6545, 51764], "temperature": 0.0, "avg_logprob": -0.17966862942310088, "compression_ratio": 1.7476190476190476, "no_speech_prob": 0.0008035742212086916}, {"id": 137, "seek": 65304, "start": 653.04, "end": 659.04, "text": " and it returns itself or an error where the error is defined by the deserializer.", "tokens": [50364, 293, 309, 11247, 2564, 420, 364, 6713, 689, 264, 6713, 307, 7642, 538, 264, 730, 260, 831, 6545, 13, 50664], "temperature": 0.0, "avg_logprob": -0.19039620579899968, "compression_ratio": 1.7564102564102564, "no_speech_prob": 0.0006454276735894382}, {"id": 138, "seek": 65304, "start": 659.04, "end": 671.1999999999999, "text": " Here's a deserializer bound and for this particular session struct we call the deserialized struct", "tokens": [50664, 1692, 311, 257, 730, 260, 831, 6545, 5472, 293, 337, 341, 1729, 5481, 6594, 321, 818, 264, 730, 260, 831, 1602, 6594, 51272], "temperature": 0.0, "avg_logprob": -0.19039620579899968, "compression_ratio": 1.7564102564102564, "no_speech_prob": 0.0006454276735894382}, {"id": 139, "seek": 65304, "start": 671.1999999999999, "end": 672.64, "text": " method.", "tokens": [51272, 3170, 13, 51344], "temperature": 0.0, "avg_logprob": -0.19039620579899968, "compression_ratio": 1.7564102564102564, "no_speech_prob": 0.0006454276735894382}, {"id": 140, "seek": 65304, "start": 672.64, "end": 680.3199999999999, "text": " So the deserializer has a bunch of methods and the idea is that we call a method that", "tokens": [51344, 407, 264, 730, 260, 831, 6545, 575, 257, 3840, 295, 7150, 293, 264, 1558, 307, 300, 321, 818, 257, 3170, 300, 51728], "temperature": 0.0, "avg_logprob": -0.19039620579899968, "compression_ratio": 1.7564102564102564, "no_speech_prob": 0.0006454276735894382}, {"id": 141, "seek": 68032, "start": 680.32, "end": 685.36, "text": " describes in the most precise way what we actually want to have.", "tokens": [50364, 15626, 294, 264, 881, 13600, 636, 437, 321, 767, 528, 281, 362, 13, 50616], "temperature": 0.0, "avg_logprob": -0.1999084867280105, "compression_ratio": 1.612565445026178, "no_speech_prob": 0.0006756447837688029}, {"id": 142, "seek": 68032, "start": 685.36, "end": 687.36, "text": " That's as we want to have a struct.", "tokens": [50616, 663, 311, 382, 321, 528, 281, 362, 257, 6594, 13, 50716], "temperature": 0.0, "avg_logprob": -0.1999084867280105, "compression_ratio": 1.612565445026178, "no_speech_prob": 0.0006756447837688029}, {"id": 143, "seek": 68032, "start": 687.36, "end": 688.36, "text": " It's called session.", "tokens": [50716, 467, 311, 1219, 5481, 13, 50766], "temperature": 0.0, "avg_logprob": -0.1999084867280105, "compression_ratio": 1.612565445026178, "no_speech_prob": 0.0006756447837688029}, {"id": 144, "seek": 68032, "start": 688.36, "end": 691.48, "text": " It got those four fields.", "tokens": [50766, 467, 658, 729, 1451, 7909, 13, 50922], "temperature": 0.0, "avg_logprob": -0.1999084867280105, "compression_ratio": 1.612565445026178, "no_speech_prob": 0.0006756447837688029}, {"id": 145, "seek": 68032, "start": 691.48, "end": 698.4000000000001, "text": " There's something else and we hope that the deserializer can provide us the data in order", "tokens": [50922, 821, 311, 746, 1646, 293, 321, 1454, 300, 264, 730, 260, 831, 6545, 393, 2893, 505, 264, 1412, 294, 1668, 51268], "temperature": 0.0, "avg_logprob": -0.1999084867280105, "compression_ratio": 1.612565445026178, "no_speech_prob": 0.0006756447837688029}, {"id": 146, "seek": 68032, "start": 698.4000000000001, "end": 700.88, "text": " to build this thing.", "tokens": [51268, 281, 1322, 341, 551, 13, 51392], "temperature": 0.0, "avg_logprob": -0.1999084867280105, "compression_ratio": 1.612565445026178, "no_speech_prob": 0.0006756447837688029}, {"id": 147, "seek": 68032, "start": 700.88, "end": 704.84, "text": " And that's something else is a so-called visitor.", "tokens": [51392, 400, 300, 311, 746, 1646, 307, 257, 370, 12, 11880, 28222, 13, 51590], "temperature": 0.0, "avg_logprob": -0.1999084867280105, "compression_ratio": 1.612565445026178, "no_speech_prob": 0.0006756447837688029}, {"id": 148, "seek": 70484, "start": 704.84, "end": 710.64, "text": " Whereas a visitor is also a trade from Suri and we implement this as well.", "tokens": [50364, 13813, 257, 28222, 307, 611, 257, 4923, 490, 6732, 72, 293, 321, 4445, 341, 382, 731, 13, 50654], "temperature": 0.0, "avg_logprob": -0.1978750132551097, "compression_ratio": 1.7914893617021277, "no_speech_prob": 0.0013874944997951388}, {"id": 149, "seek": 70484, "start": 710.64, "end": 716.0400000000001, "text": " We don't need anything on the visitor except like some struct to implement it.", "tokens": [50654, 492, 500, 380, 643, 1340, 322, 264, 28222, 3993, 411, 512, 6594, 281, 4445, 309, 13, 50924], "temperature": 0.0, "avg_logprob": -0.1978750132551097, "compression_ratio": 1.7914893617021277, "no_speech_prob": 0.0013874944997951388}, {"id": 150, "seek": 70484, "start": 716.0400000000001, "end": 718.36, "text": " So we have our struct, we implement visitor.", "tokens": [50924, 407, 321, 362, 527, 6594, 11, 321, 4445, 28222, 13, 51040], "temperature": 0.0, "avg_logprob": -0.1978750132551097, "compression_ratio": 1.7914893617021277, "no_speech_prob": 0.0013874944997951388}, {"id": 151, "seek": 70484, "start": 718.36, "end": 721.2800000000001, "text": " This one actually defines what the value is that we return.", "tokens": [51040, 639, 472, 767, 23122, 437, 264, 2158, 307, 300, 321, 2736, 13, 51186], "temperature": 0.0, "avg_logprob": -0.1978750132551097, "compression_ratio": 1.7914893617021277, "no_speech_prob": 0.0013874944997951388}, {"id": 152, "seek": 70484, "start": 721.2800000000001, "end": 725.76, "text": " This is the session struct and there's only one method, one function we actually need", "tokens": [51186, 639, 307, 264, 5481, 6594, 293, 456, 311, 787, 472, 3170, 11, 472, 2445, 321, 767, 643, 51410], "temperature": 0.0, "avg_logprob": -0.1978750132551097, "compression_ratio": 1.7914893617021277, "no_speech_prob": 0.0013874944997951388}, {"id": 153, "seek": 70484, "start": 725.76, "end": 732.36, "text": " to implement which is this expecting thing that helps with reporting errors.", "tokens": [51410, 281, 4445, 597, 307, 341, 9650, 551, 300, 3665, 365, 10031, 13603, 13, 51740], "temperature": 0.0, "avg_logprob": -0.1978750132551097, "compression_ratio": 1.7914893617021277, "no_speech_prob": 0.0013874944997951388}, {"id": 154, "seek": 73236, "start": 732.36, "end": 735.92, "text": " If you only have a visitor like that it's not useful because the only thing it can do", "tokens": [50364, 759, 291, 787, 362, 257, 28222, 411, 300, 309, 311, 406, 4420, 570, 264, 787, 551, 309, 393, 360, 50542], "temperature": 0.0, "avg_logprob": -0.16378704252697174, "compression_ratio": 1.6176470588235294, "no_speech_prob": 0.004674033727496862}, {"id": 155, "seek": 73236, "start": 735.92, "end": 738.04, "text": " is report an error.", "tokens": [50542, 307, 2275, 364, 6713, 13, 50648], "temperature": 0.0, "avg_logprob": -0.16378704252697174, "compression_ratio": 1.6176470588235294, "no_speech_prob": 0.004674033727496862}, {"id": 156, "seek": 73236, "start": 738.04, "end": 742.92, "text": " So you also want to implement one of the other methods that you get.", "tokens": [50648, 407, 291, 611, 528, 281, 4445, 472, 295, 264, 661, 7150, 300, 291, 483, 13, 50892], "temperature": 0.0, "avg_logprob": -0.16378704252697174, "compression_ratio": 1.6176470588235294, "no_speech_prob": 0.004674033727496862}, {"id": 157, "seek": 73236, "start": 742.92, "end": 745.52, "text": " And you know like Rust Analyzer or so.", "tokens": [50892, 400, 291, 458, 411, 34952, 1107, 5222, 4527, 420, 370, 13, 51022], "temperature": 0.0, "avg_logprob": -0.16378704252697174, "compression_ratio": 1.6176470588235294, "no_speech_prob": 0.004674033727496862}, {"id": 158, "seek": 73236, "start": 745.52, "end": 752.12, "text": " Or your IDE can help you in figuring out what the methods are or documentation.", "tokens": [51022, 1610, 428, 40930, 393, 854, 291, 294, 15213, 484, 437, 264, 7150, 366, 420, 14333, 13, 51352], "temperature": 0.0, "avg_logprob": -0.16378704252697174, "compression_ratio": 1.6176470588235294, "no_speech_prob": 0.004674033727496862}, {"id": 159, "seek": 73236, "start": 752.12, "end": 758.9200000000001, "text": " And we expect when we say to the deserializer, hey, I want to have a struct, we expect that", "tokens": [51352, 400, 321, 2066, 562, 321, 584, 281, 264, 730, 260, 831, 6545, 11, 4177, 11, 286, 528, 281, 362, 257, 6594, 11, 321, 2066, 300, 51692], "temperature": 0.0, "avg_logprob": -0.16378704252697174, "compression_ratio": 1.6176470588235294, "no_speech_prob": 0.004674033727496862}, {"id": 160, "seek": 75892, "start": 758.92, "end": 763.28, "text": " we get a map in return.", "tokens": [50364, 321, 483, 257, 4471, 294, 2736, 13, 50582], "temperature": 0.0, "avg_logprob": -0.28467297554016113, "compression_ratio": 1.598901098901099, "no_speech_prob": 0.0010467793326824903}, {"id": 161, "seek": 75892, "start": 763.28, "end": 768.0799999999999, "text": " Structs are like basically like named maps if you will.", "tokens": [50582, 745, 1757, 82, 366, 411, 1936, 411, 4926, 11317, 498, 291, 486, 13, 50822], "temperature": 0.0, "avg_logprob": -0.28467297554016113, "compression_ratio": 1.598901098901099, "no_speech_prob": 0.0010467793326824903}, {"id": 162, "seek": 75892, "start": 768.0799999999999, "end": 772.36, "text": " The keys are your field names, the values are the actual fields.", "tokens": [50822, 440, 9317, 366, 428, 2519, 5288, 11, 264, 4190, 366, 264, 3539, 7909, 13, 51036], "temperature": 0.0, "avg_logprob": -0.28467297554016113, "compression_ratio": 1.598901098901099, "no_speech_prob": 0.0010467793326824903}, {"id": 163, "seek": 75892, "start": 772.36, "end": 779.4399999999999, "text": " And so we implement the visit map method we get, we also say we return our own value,", "tokens": [51036, 400, 370, 321, 4445, 264, 3441, 4471, 3170, 321, 483, 11, 321, 611, 584, 321, 2736, 527, 1065, 2158, 11, 51390], "temperature": 0.0, "avg_logprob": -0.28467297554016113, "compression_ratio": 1.598901098901099, "no_speech_prob": 0.0010467793326824903}, {"id": 164, "seek": 75892, "start": 779.4399999999999, "end": 782.8, "text": " we return the error from whatever the deserializer gives us.", "tokens": [51390, 321, 2736, 264, 6713, 490, 2035, 264, 730, 260, 831, 6545, 2709, 505, 13, 51558], "temperature": 0.0, "avg_logprob": -0.28467297554016113, "compression_ratio": 1.598901098901099, "no_speech_prob": 0.0010467793326824903}, {"id": 165, "seek": 78280, "start": 782.8, "end": 789.16, "text": " And it gives us this map access thing which is fancy iterator over key value pairs.", "tokens": [50364, 400, 309, 2709, 505, 341, 4471, 2105, 551, 597, 307, 10247, 17138, 1639, 670, 2141, 2158, 15494, 13, 50682], "temperature": 0.0, "avg_logprob": -0.19034846483078677, "compression_ratio": 1.6968503937007875, "no_speech_prob": 0.006588339805603027}, {"id": 166, "seek": 78280, "start": 789.16, "end": 793.8, "text": " And if we actually implement this, this looks very mechanical.", "tokens": [50682, 400, 498, 321, 767, 4445, 341, 11, 341, 1542, 588, 12070, 13, 50914], "temperature": 0.0, "avg_logprob": -0.19034846483078677, "compression_ratio": 1.6968503937007875, "no_speech_prob": 0.006588339805603027}, {"id": 167, "seek": 78280, "start": 793.8, "end": 797.28, "text": " We have our fields, we don't have any values for them.", "tokens": [50914, 492, 362, 527, 7909, 11, 321, 500, 380, 362, 604, 4190, 337, 552, 13, 51088], "temperature": 0.0, "avg_logprob": -0.19034846483078677, "compression_ratio": 1.6968503937007875, "no_speech_prob": 0.006588339805603027}, {"id": 168, "seek": 78280, "start": 797.28, "end": 802.5999999999999, "text": " So they are all options of the actual field types with none of these defaults.", "tokens": [51088, 407, 436, 366, 439, 3956, 295, 264, 3539, 2519, 3467, 365, 6022, 295, 613, 7576, 82, 13, 51354], "temperature": 0.0, "avg_logprob": -0.19034846483078677, "compression_ratio": 1.6968503937007875, "no_speech_prob": 0.006588339805603027}, {"id": 169, "seek": 78280, "start": 802.5999999999999, "end": 806.5999999999999, "text": " We use the map access to say what is the next key in the map.", "tokens": [51354, 492, 764, 264, 4471, 2105, 281, 584, 437, 307, 264, 958, 2141, 294, 264, 4471, 13, 51554], "temperature": 0.0, "avg_logprob": -0.19034846483078677, "compression_ratio": 1.6968503937007875, "no_speech_prob": 0.006588339805603027}, {"id": 170, "seek": 78280, "start": 806.5999999999999, "end": 811.7199999999999, "text": " We would match over that key if it's an event, we'll take the next value and put it into", "tokens": [51554, 492, 576, 2995, 670, 300, 2141, 498, 309, 311, 364, 2280, 11, 321, 603, 747, 264, 958, 2158, 293, 829, 309, 666, 51810], "temperature": 0.0, "avg_logprob": -0.19034846483078677, "compression_ratio": 1.6968503937007875, "no_speech_prob": 0.006588339805603027}, {"id": 171, "seek": 81172, "start": 811.72, "end": 813.52, "text": " the event value.", "tokens": [50364, 264, 2280, 2158, 13, 50454], "temperature": 0.0, "avg_logprob": -0.20450240241156684, "compression_ratio": 1.6852791878172588, "no_speech_prob": 0.00648359302431345}, {"id": 172, "seek": 81172, "start": 813.52, "end": 818.48, "text": " And here we are saying in the TurboFish there we want to have a string.", "tokens": [50454, 400, 510, 321, 366, 1566, 294, 264, 35848, 37, 742, 456, 321, 528, 281, 362, 257, 6798, 13, 50702], "temperature": 0.0, "avg_logprob": -0.20450240241156684, "compression_ratio": 1.6852791878172588, "no_speech_prob": 0.00648359302431345}, {"id": 173, "seek": 81172, "start": 818.48, "end": 825.6800000000001, "text": " And this call looks quite similar to the node.to call.", "tokens": [50702, 400, 341, 818, 1542, 1596, 2531, 281, 264, 9984, 13, 1353, 818, 13, 51062], "temperature": 0.0, "avg_logprob": -0.20450240241156684, "compression_ratio": 1.6852791878172588, "no_speech_prob": 0.00648359302431345}, {"id": 174, "seek": 81172, "start": 825.6800000000001, "end": 833.52, "text": " The bound for string is deserialize and the map access implementation that has the actual", "tokens": [51062, 440, 5472, 337, 6798, 307, 730, 260, 831, 1125, 293, 264, 4471, 2105, 11420, 300, 575, 264, 3539, 51454], "temperature": 0.0, "avg_logprob": -0.20450240241156684, "compression_ratio": 1.6852791878172588, "no_speech_prob": 0.00648359302431345}, {"id": 175, "seek": 81172, "start": 833.52, "end": 839.36, "text": " value will know what the deserializer is and then you've got another deserializer and deserializer", "tokens": [51454, 2158, 486, 458, 437, 264, 730, 260, 831, 6545, 307, 293, 550, 291, 600, 658, 1071, 730, 260, 831, 6545, 293, 730, 260, 831, 6545, 51746], "temperature": 0.0, "avg_logprob": -0.20450240241156684, "compression_ratio": 1.6852791878172588, "no_speech_prob": 0.00648359302431345}, {"id": 176, "seek": 83936, "start": 839.36, "end": 842.4, "text": " that come together and they do the same thing over again.", "tokens": [50364, 300, 808, 1214, 293, 436, 360, 264, 912, 551, 670, 797, 13, 50516], "temperature": 0.0, "avg_logprob": -0.201055855586611, "compression_ratio": 1.6825396825396826, "no_speech_prob": 0.008406239561736584}, {"id": 177, "seek": 83936, "start": 842.4, "end": 847.24, "text": " So it's all like this kind of back and forth from top down.", "tokens": [50516, 407, 309, 311, 439, 411, 341, 733, 295, 646, 293, 5220, 490, 1192, 760, 13, 50758], "temperature": 0.0, "avg_logprob": -0.201055855586611, "compression_ratio": 1.6825396825396826, "no_speech_prob": 0.008406239561736584}, {"id": 178, "seek": 83936, "start": 847.24, "end": 851.88, "text": " We do that with the rest of the fields and then we can build the value at the end and", "tokens": [50758, 492, 360, 300, 365, 264, 1472, 295, 264, 7909, 293, 550, 321, 393, 1322, 264, 2158, 412, 264, 917, 293, 50990], "temperature": 0.0, "avg_logprob": -0.201055855586611, "compression_ratio": 1.6825396825396826, "no_speech_prob": 0.008406239561736584}, {"id": 179, "seek": 83936, "start": 851.88, "end": 856.08, "text": " then we can throw an error for any fields that are missing.", "tokens": [50990, 550, 321, 393, 3507, 364, 6713, 337, 604, 7909, 300, 366, 5361, 13, 51200], "temperature": 0.0, "avg_logprob": -0.201055855586611, "compression_ratio": 1.6825396825396826, "no_speech_prob": 0.008406239561736584}, {"id": 180, "seek": 83936, "start": 856.08, "end": 864.04, "text": " Then we plot that in and that is the deserialize site.", "tokens": [51200, 1396, 321, 7542, 300, 294, 293, 300, 307, 264, 730, 260, 831, 1125, 3621, 13, 51598], "temperature": 0.0, "avg_logprob": -0.201055855586611, "compression_ratio": 1.6825396825396826, "no_speech_prob": 0.008406239561736584}, {"id": 181, "seek": 86404, "start": 864.04, "end": 869.64, "text": " What is generating and what we need to provide.", "tokens": [50364, 708, 307, 17746, 293, 437, 321, 643, 281, 2893, 13, 50644], "temperature": 0.0, "avg_logprob": -0.3192980788474859, "compression_ratio": 1.6230366492146597, "no_speech_prob": 0.02359583042562008}, {"id": 182, "seek": 86404, "start": 869.64, "end": 876.7199999999999, "text": " So let's start by adding a struct for our bold node and we can also implement the into", "tokens": [50644, 407, 718, 311, 722, 538, 5127, 257, 6594, 337, 527, 11928, 9984, 293, 321, 393, 611, 4445, 264, 666, 50998], "temperature": 0.0, "avg_logprob": -0.3192980788474859, "compression_ratio": 1.6230366492146597, "no_speech_prob": 0.02359583042562008}, {"id": 183, "seek": 86404, "start": 876.7199999999999, "end": 883.0, "text": " deserializer trait which we can use to tell us what kind of deserializer we want to deserialize", "tokens": [50998, 730, 260, 831, 6545, 22538, 597, 321, 393, 764, 281, 980, 505, 437, 733, 295, 730, 260, 831, 6545, 321, 528, 281, 730, 260, 831, 1125, 51312], "temperature": 0.0, "avg_logprob": -0.3192980788474859, "compression_ratio": 1.6230366492146597, "no_speech_prob": 0.02359583042562008}, {"id": 184, "seek": 86404, "start": 883.0, "end": 885.24, "text": " a bold node.", "tokens": [51312, 257, 11928, 9984, 13, 51424], "temperature": 0.0, "avg_logprob": -0.3192980788474859, "compression_ratio": 1.6230366492146597, "no_speech_prob": 0.02359583042562008}, {"id": 185, "seek": 86404, "start": 885.24, "end": 889.4399999999999, "text": " That is like a very fancy into this, nothing really special to it.", "tokens": [51424, 663, 307, 411, 257, 588, 10247, 666, 341, 11, 1825, 534, 2121, 281, 309, 13, 51634], "temperature": 0.0, "avg_logprob": -0.3192980788474859, "compression_ratio": 1.6230366492146597, "no_speech_prob": 0.02359583042562008}, {"id": 186, "seek": 88944, "start": 890.44, "end": 894.5600000000001, "text": " So it's up to implementing deserializer for that bold node deserializer.", "tokens": [50414, 407, 309, 311, 493, 281, 18114, 730, 260, 831, 6545, 337, 300, 11928, 9984, 730, 260, 831, 6545, 13, 50620], "temperature": 0.0, "avg_logprob": -0.220458493913923, "compression_ratio": 1.7294685990338163, "no_speech_prob": 0.0019242390990257263}, {"id": 187, "seek": 88944, "start": 894.5600000000001, "end": 896.36, "text": " We define an error.", "tokens": [50620, 492, 6964, 364, 6713, 13, 50710], "temperature": 0.0, "avg_logprob": -0.220458493913923, "compression_ratio": 1.7294685990338163, "no_speech_prob": 0.0019242390990257263}, {"id": 188, "seek": 88944, "start": 896.36, "end": 898.44, "text": " The error needs to implement a certain trait.", "tokens": [50710, 440, 6713, 2203, 281, 4445, 257, 1629, 22538, 13, 50814], "temperature": 0.0, "avg_logprob": -0.220458493913923, "compression_ratio": 1.7294685990338163, "no_speech_prob": 0.0019242390990257263}, {"id": 189, "seek": 88944, "start": 898.44, "end": 900.2800000000001, "text": " I'm not going to talk more about this.", "tokens": [50814, 286, 478, 406, 516, 281, 751, 544, 466, 341, 13, 50906], "temperature": 0.0, "avg_logprob": -0.220458493913923, "compression_ratio": 1.7294685990338163, "no_speech_prob": 0.0019242390990257263}, {"id": 190, "seek": 88944, "start": 900.2800000000001, "end": 906.6400000000001, "text": " It's like an enum of some typical error cases.", "tokens": [50906, 467, 311, 411, 364, 465, 449, 295, 512, 7476, 6713, 3331, 13, 51224], "temperature": 0.0, "avg_logprob": -0.220458493913923, "compression_ratio": 1.7294685990338163, "no_speech_prob": 0.0019242390990257263}, {"id": 191, "seek": 88944, "start": 906.6400000000001, "end": 908.6400000000001, "text": " And then there's this fancy thing.", "tokens": [51224, 400, 550, 456, 311, 341, 10247, 551, 13, 51324], "temperature": 0.0, "avg_logprob": -0.220458493913923, "compression_ratio": 1.7294685990338163, "no_speech_prob": 0.0019242390990257263}, {"id": 192, "seek": 88944, "start": 908.6400000000001, "end": 914.4000000000001, "text": " So if you implement deserializer you have a lot, like a lot of methods that you need", "tokens": [51324, 407, 498, 291, 4445, 730, 260, 831, 6545, 291, 362, 257, 688, 11, 411, 257, 688, 295, 7150, 300, 291, 643, 51612], "temperature": 0.0, "avg_logprob": -0.220458493913923, "compression_ratio": 1.7294685990338163, "no_speech_prob": 0.0019242390990257263}, {"id": 193, "seek": 88944, "start": 914.4000000000001, "end": 916.48, "text": " to implement.", "tokens": [51612, 281, 4445, 13, 51716], "temperature": 0.0, "avg_logprob": -0.220458493913923, "compression_ratio": 1.7294685990338163, "no_speech_prob": 0.0019242390990257263}, {"id": 194, "seek": 91648, "start": 917.48, "end": 920.5600000000001, "text": " Usually you don't really want to do that.", "tokens": [50414, 11419, 291, 500, 380, 534, 528, 281, 360, 300, 13, 50568], "temperature": 0.0, "avg_logprob": -0.18894705949006257, "compression_ratio": 1.724890829694323, "no_speech_prob": 0.0031627940479665995}, {"id": 195, "seek": 91648, "start": 920.5600000000001, "end": 926.88, "text": " And then there's this concept of self-describing data formats which is that within your data", "tokens": [50568, 400, 550, 456, 311, 341, 3410, 295, 2698, 12, 14792, 39541, 1412, 25879, 597, 307, 300, 1951, 428, 1412, 50884], "temperature": 0.0, "avg_logprob": -0.18894705949006257, "compression_ratio": 1.724890829694323, "no_speech_prob": 0.0031627940479665995}, {"id": 196, "seek": 91648, "start": 926.88, "end": 934.72, "text": " format you know what the next type is, what the next value is, what the next key is.", "tokens": [50884, 7877, 291, 458, 437, 264, 958, 2010, 307, 11, 437, 264, 958, 2158, 307, 11, 437, 264, 958, 2141, 307, 13, 51276], "temperature": 0.0, "avg_logprob": -0.18894705949006257, "compression_ratio": 1.724890829694323, "no_speech_prob": 0.0031627940479665995}, {"id": 197, "seek": 91648, "start": 934.72, "end": 938.0, "text": " You don't need any kind of information from the outside.", "tokens": [51276, 509, 500, 380, 643, 604, 733, 295, 1589, 490, 264, 2380, 13, 51440], "temperature": 0.0, "avg_logprob": -0.18894705949006257, "compression_ratio": 1.724890829694323, "no_speech_prob": 0.0031627940479665995}, {"id": 198, "seek": 91648, "start": 938.0, "end": 942.84, "text": " And so in JSON, like if you're parsing a key you know okay that's the key, it's called", "tokens": [51440, 400, 370, 294, 31828, 11, 411, 498, 291, 434, 21156, 278, 257, 2141, 291, 458, 1392, 300, 311, 264, 2141, 11, 309, 311, 1219, 51682], "temperature": 0.0, "avg_logprob": -0.18894705949006257, "compression_ratio": 1.724890829694323, "no_speech_prob": 0.0031627940479665995}, {"id": 199, "seek": 91648, "start": 942.84, "end": 944.2, "text": " that and then you have a value.", "tokens": [51682, 300, 293, 550, 291, 362, 257, 2158, 13, 51750], "temperature": 0.0, "avg_logprob": -0.18894705949006257, "compression_ratio": 1.724890829694323, "no_speech_prob": 0.0031627940479665995}, {"id": 200, "seek": 94420, "start": 944.24, "end": 948.96, "text": " So you know at every time where you are and you don't need the information that the next", "tokens": [50366, 407, 291, 458, 412, 633, 565, 689, 291, 366, 293, 291, 500, 380, 643, 264, 1589, 300, 264, 958, 50602], "temperature": 0.0, "avg_logprob": -0.24341466994512648, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0008527332684025168}, {"id": 201, "seek": 94420, "start": 948.96, "end": 952.48, "text": " thing that comes is a string or an integer or something.", "tokens": [50602, 551, 300, 1487, 307, 257, 6798, 420, 364, 24922, 420, 746, 13, 50778], "temperature": 0.0, "avg_logprob": -0.24341466994512648, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0008527332684025168}, {"id": 202, "seek": 94420, "start": 952.48, "end": 957.24, "text": " You figure it out by the, just by looking at the data.", "tokens": [50778, 509, 2573, 309, 484, 538, 264, 11, 445, 538, 1237, 412, 264, 1412, 13, 51016], "temperature": 0.0, "avg_logprob": -0.24341466994512648, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0008527332684025168}, {"id": 203, "seek": 94420, "start": 957.24, "end": 962.84, "text": " Bold is such a self-describing data format and for those SIRTY recommends to just implement", "tokens": [51016, 48954, 307, 1270, 257, 2698, 12, 14792, 39541, 1412, 7877, 293, 337, 729, 318, 7740, 23433, 34556, 281, 445, 4445, 51296], "temperature": 0.0, "avg_logprob": -0.24341466994512648, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0008527332684025168}, {"id": 204, "seek": 94420, "start": 962.84, "end": 969.12, "text": " deserialize any and then use this macro to say every other thing just goes to any and", "tokens": [51296, 730, 260, 831, 1125, 604, 293, 550, 764, 341, 18887, 281, 584, 633, 661, 551, 445, 1709, 281, 604, 293, 51610], "temperature": 0.0, "avg_logprob": -0.24341466994512648, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0008527332684025168}, {"id": 205, "seek": 94420, "start": 969.12, "end": 970.48, "text": " we're all doing that.", "tokens": [51610, 321, 434, 439, 884, 300, 13, 51678], "temperature": 0.0, "avg_logprob": -0.24341466994512648, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0008527332684025168}, {"id": 206, "seek": 97048, "start": 970.88, "end": 974.36, "text": " So we only need to look at ourselves and we don't need anything else.", "tokens": [50384, 407, 321, 787, 643, 281, 574, 412, 4175, 293, 321, 500, 380, 643, 1340, 1646, 13, 50558], "temperature": 0.0, "avg_logprob": -0.1951386951264881, "compression_ratio": 1.6835443037974684, "no_speech_prob": 0.004458227194845676}, {"id": 207, "seek": 97048, "start": 974.36, "end": 981.12, "text": " So let's implement this deserialize any here where we say we want to call this visit map", "tokens": [50558, 407, 718, 311, 4445, 341, 730, 260, 831, 1125, 604, 510, 689, 321, 584, 321, 528, 281, 818, 341, 3441, 4471, 50896], "temperature": 0.0, "avg_logprob": -0.1951386951264881, "compression_ratio": 1.6835443037974684, "no_speech_prob": 0.004458227194845676}, {"id": 208, "seek": 97048, "start": 981.12, "end": 983.64, "text": " method because that's what expected.", "tokens": [50896, 3170, 570, 300, 311, 437, 5176, 13, 51022], "temperature": 0.0, "avg_logprob": -0.1951386951264881, "compression_ratio": 1.6835443037974684, "no_speech_prob": 0.004458227194845676}, {"id": 209, "seek": 97048, "start": 983.64, "end": 988.84, "text": " And there's a map deserializer which is also from SIRTY where you can give an iterator", "tokens": [51022, 400, 456, 311, 257, 4471, 730, 260, 831, 6545, 597, 307, 611, 490, 318, 7740, 23433, 689, 291, 393, 976, 364, 17138, 1639, 51282], "temperature": 0.0, "avg_logprob": -0.1951386951264881, "compression_ratio": 1.6835443037974684, "no_speech_prob": 0.004458227194845676}, {"id": 210, "seek": 97048, "start": 988.84, "end": 992.44, "text": " over key value pairs and that will do the correct thing.", "tokens": [51282, 670, 2141, 2158, 15494, 293, 300, 486, 360, 264, 3006, 551, 13, 51462], "temperature": 0.0, "avg_logprob": -0.1951386951264881, "compression_ratio": 1.6835443037974684, "no_speech_prob": 0.004458227194845676}, {"id": 211, "seek": 97048, "start": 992.44, "end": 997.16, "text": " So we don't actually need to implement anything fancy here.", "tokens": [51462, 407, 321, 500, 380, 767, 643, 281, 4445, 1340, 10247, 510, 13, 51698], "temperature": 0.0, "avg_logprob": -0.1951386951264881, "compression_ratio": 1.6835443037974684, "no_speech_prob": 0.004458227194845676}, {"id": 212, "seek": 99716, "start": 997.16, "end": 1002.52, "text": " And we can bring those together in this two methods by calling deserialize and using the", "tokens": [50364, 400, 321, 393, 1565, 729, 1214, 294, 341, 732, 7150, 538, 5141, 730, 260, 831, 1125, 293, 1228, 264, 50632], "temperature": 0.0, "avg_logprob": -0.2492549977404006, "compression_ratio": 1.795, "no_speech_prob": 0.006482419092208147}, {"id": 213, "seek": 99716, "start": 1002.52, "end": 1006.0799999999999, "text": " into deserializer trade to bring those together.", "tokens": [50632, 666, 730, 260, 831, 6545, 4923, 281, 1565, 729, 1214, 13, 50810], "temperature": 0.0, "avg_logprob": -0.2492549977404006, "compression_ratio": 1.795, "no_speech_prob": 0.006482419092208147}, {"id": 214, "seek": 99716, "start": 1006.0799999999999, "end": 1011.64, "text": " So now after we did all of that, we are basically at where we started.", "tokens": [50810, 407, 586, 934, 321, 630, 439, 295, 300, 11, 321, 366, 1936, 412, 689, 321, 1409, 13, 51088], "temperature": 0.0, "avg_logprob": -0.2492549977404006, "compression_ratio": 1.795, "no_speech_prob": 0.006482419092208147}, {"id": 215, "seek": 99716, "start": 1011.64, "end": 1015.76, "text": " We can deserialize our properties or deserialize our properties.", "tokens": [51088, 492, 393, 730, 260, 831, 1125, 527, 7221, 420, 730, 260, 831, 1125, 527, 7221, 13, 51294], "temperature": 0.0, "avg_logprob": -0.2492549977404006, "compression_ratio": 1.795, "no_speech_prob": 0.006482419092208147}, {"id": 216, "seek": 99716, "start": 1015.76, "end": 1020.88, "text": " But we also want to have the IDs and labels so let's have those before and instead of", "tokens": [51294, 583, 321, 611, 528, 281, 362, 264, 48212, 293, 16949, 370, 718, 311, 362, 729, 949, 293, 2602, 295, 51550], "temperature": 0.0, "avg_logprob": -0.2492549977404006, "compression_ratio": 1.795, "no_speech_prob": 0.006482419092208147}, {"id": 217, "seek": 102088, "start": 1020.92, "end": 1027.84, "text": " just using our properties, we are having, we're training this with getting the ID and", "tokens": [50366, 445, 1228, 527, 7221, 11, 321, 366, 1419, 11, 321, 434, 3097, 341, 365, 1242, 264, 7348, 293, 50712], "temperature": 0.0, "avg_logprob": -0.2155821756883101, "compression_ratio": 1.7227722772277227, "no_speech_prob": 0.0023955542128533125}, {"id": 218, "seek": 102088, "start": 1027.84, "end": 1033.44, "text": " getting the labels and then we're just passing that on.", "tokens": [50712, 1242, 264, 16949, 293, 550, 321, 434, 445, 8437, 300, 322, 13, 50992], "temperature": 0.0, "avg_logprob": -0.2155821756883101, "compression_ratio": 1.7227722772277227, "no_speech_prob": 0.0023955542128533125}, {"id": 219, "seek": 102088, "start": 1033.44, "end": 1037.48, "text": " And that kind of works for this particular example only.", "tokens": [50992, 400, 300, 733, 295, 1985, 337, 341, 1729, 1365, 787, 13, 51194], "temperature": 0.0, "avg_logprob": -0.2155821756883101, "compression_ratio": 1.7227722772277227, "no_speech_prob": 0.0023955542128533125}, {"id": 220, "seek": 102088, "start": 1037.48, "end": 1043.72, "text": " We do get our IDs and labels but we only get them if we call the field ID and label string.", "tokens": [51194, 492, 360, 483, 527, 48212, 293, 16949, 457, 321, 787, 483, 552, 498, 321, 818, 264, 2519, 7348, 293, 7645, 6798, 13, 51506], "temperature": 0.0, "avg_logprob": -0.2155821756883101, "compression_ratio": 1.7227722772277227, "no_speech_prob": 0.0023955542128533125}, {"id": 221, "seek": 102088, "start": 1043.72, "end": 1048.76, "text": " It's harder than here as this ID string and label string.", "tokens": [51506, 467, 311, 6081, 813, 510, 382, 341, 7348, 6798, 293, 7645, 6798, 13, 51758], "temperature": 0.0, "avg_logprob": -0.2155821756883101, "compression_ratio": 1.7227722772277227, "no_speech_prob": 0.0023955542128533125}, {"id": 222, "seek": 104876, "start": 1048.76, "end": 1055.08, "text": " So you could never call him something else and we could use like special fields like", "tokens": [50364, 407, 291, 727, 1128, 818, 796, 746, 1646, 293, 321, 727, 764, 411, 2121, 7909, 411, 50680], "temperature": 0.0, "avg_logprob": -0.1426070242217093, "compression_ratio": 1.7510729613733906, "no_speech_prob": 0.003644922049716115}, {"id": 223, "seek": 104876, "start": 1055.08, "end": 1059.12, "text": " underscore underscore ID or something.", "tokens": [50680, 37556, 37556, 7348, 420, 746, 13, 50882], "temperature": 0.0, "avg_logprob": -0.1426070242217093, "compression_ratio": 1.7510729613733906, "no_speech_prob": 0.003644922049716115}, {"id": 224, "seek": 104876, "start": 1059.12, "end": 1062.52, "text": " But if you want to have an ID, you would have to use one of those field names and you could", "tokens": [50882, 583, 498, 291, 528, 281, 362, 364, 7348, 11, 291, 576, 362, 281, 764, 472, 295, 729, 2519, 5288, 293, 291, 727, 51052], "temperature": 0.0, "avg_logprob": -0.1426070242217093, "compression_ratio": 1.7510729613733906, "no_speech_prob": 0.003644922049716115}, {"id": 225, "seek": 104876, "start": 1062.52, "end": 1067.8, "text": " never use this name in your actual properties because then you would have multiple entries", "tokens": [51052, 1128, 764, 341, 1315, 294, 428, 3539, 7221, 570, 550, 291, 576, 362, 3866, 23041, 51316], "temperature": 0.0, "avg_logprob": -0.1426070242217093, "compression_ratio": 1.7510729613733906, "no_speech_prob": 0.003644922049716115}, {"id": 226, "seek": 104876, "start": 1067.8, "end": 1073.92, "text": " in this map thing and SIRTY will say no, there's multiple values for the key ID and that is", "tokens": [51316, 294, 341, 4471, 551, 293, 318, 7740, 23433, 486, 584, 572, 11, 456, 311, 3866, 4190, 337, 264, 2141, 7348, 293, 300, 307, 51622], "temperature": 0.0, "avg_logprob": -0.1426070242217093, "compression_ratio": 1.7510729613733906, "no_speech_prob": 0.003644922049716115}, {"id": 227, "seek": 104876, "start": 1073.92, "end": 1076.84, "text": " an error.", "tokens": [51622, 364, 6713, 13, 51768], "temperature": 0.0, "avg_logprob": -0.1426070242217093, "compression_ratio": 1.7510729613733906, "no_speech_prob": 0.003644922049716115}, {"id": 228, "seek": 107684, "start": 1076.9199999999998, "end": 1083.24, "text": " And using like underscore like magic field names or something like that would maybe be", "tokens": [50368, 400, 1228, 411, 37556, 411, 5585, 2519, 5288, 420, 746, 411, 300, 576, 1310, 312, 50684], "temperature": 0.0, "avg_logprob": -0.21187222941537923, "compression_ratio": 1.6711711711711712, "no_speech_prob": 0.002510370220988989}, {"id": 229, "seek": 107684, "start": 1083.24, "end": 1090.0, "text": " possible but it feels not really that great to me.", "tokens": [50684, 1944, 457, 309, 3417, 406, 534, 300, 869, 281, 385, 13, 51022], "temperature": 0.0, "avg_logprob": -0.21187222941537923, "compression_ratio": 1.6711711711711712, "no_speech_prob": 0.002510370220988989}, {"id": 230, "seek": 107684, "start": 1090.0, "end": 1096.4399999999998, "text": " So let's try something else and we want to do something like this where we have, we call", "tokens": [51022, 407, 718, 311, 853, 746, 1646, 293, 321, 528, 281, 360, 746, 411, 341, 689, 321, 362, 11, 321, 818, 51344], "temperature": 0.0, "avg_logprob": -0.21187222941537923, "compression_ratio": 1.6711711711711712, "no_speech_prob": 0.002510370220988989}, {"id": 231, "seek": 107684, "start": 1096.4399999999998, "end": 1100.9599999999998, "text": " those extractors internally but these are new type structs.", "tokens": [51344, 729, 8947, 830, 19501, 457, 613, 366, 777, 2010, 6594, 82, 13, 51570], "temperature": 0.0, "avg_logprob": -0.21187222941537923, "compression_ratio": 1.6711711711711712, "no_speech_prob": 0.002510370220988989}, {"id": 232, "seek": 107684, "start": 1100.9599999999998, "end": 1105.56, "text": " You have an ID struct and the public field that is the ID type and if a label struct", "tokens": [51570, 509, 362, 364, 7348, 6594, 293, 264, 1908, 2519, 300, 307, 264, 7348, 2010, 293, 498, 257, 7645, 6594, 51800], "temperature": 0.0, "avg_logprob": -0.21187222941537923, "compression_ratio": 1.6711711711711712, "no_speech_prob": 0.002510370220988989}, {"id": 233, "seek": 110556, "start": 1105.6, "end": 1112.44, "text": " with the public field is the labels type and instead of using the field name to say these", "tokens": [50366, 365, 264, 1908, 2519, 307, 264, 16949, 2010, 293, 2602, 295, 1228, 264, 2519, 1315, 281, 584, 613, 50708], "temperature": 0.0, "avg_logprob": -0.17487922272124848, "compression_ratio": 1.715846994535519, "no_speech_prob": 0.0010641181143000722}, {"id": 234, "seek": 110556, "start": 1112.44, "end": 1118.36, "text": " are IDs or these are labels we're using the field type to say for whatever field name", "tokens": [50708, 366, 48212, 420, 613, 366, 16949, 321, 434, 1228, 264, 2519, 2010, 281, 584, 337, 2035, 2519, 1315, 51004], "temperature": 0.0, "avg_logprob": -0.17487922272124848, "compression_ratio": 1.715846994535519, "no_speech_prob": 0.0010641181143000722}, {"id": 235, "seek": 110556, "start": 1118.36, "end": 1124.2, "text": " you have we want to, this one gets the ID from the node and everything else in the struct", "tokens": [51004, 291, 362, 321, 528, 281, 11, 341, 472, 2170, 264, 7348, 490, 264, 9984, 293, 1203, 1646, 294, 264, 6594, 51296], "temperature": 0.0, "avg_logprob": -0.17487922272124848, "compression_ratio": 1.715846994535519, "no_speech_prob": 0.0010641181143000722}, {"id": 236, "seek": 110556, "start": 1124.2, "end": 1130.6, "text": " is still being deserialized from the properties.", "tokens": [51296, 307, 920, 885, 730, 260, 831, 1602, 490, 264, 7221, 13, 51616], "temperature": 0.0, "avg_logprob": -0.17487922272124848, "compression_ratio": 1.715846994535519, "no_speech_prob": 0.0010641181143000722}, {"id": 237, "seek": 113060, "start": 1130.6, "end": 1136.56, "text": " So in order to do that we can no longer use deserializeAny but we already know that we're", "tokens": [50364, 407, 294, 1668, 281, 360, 300, 321, 393, 572, 2854, 764, 730, 260, 831, 1125, 29647, 457, 321, 1217, 458, 300, 321, 434, 50662], "temperature": 0.0, "avg_logprob": -0.19484216516668146, "compression_ratio": 1.8405172413793103, "no_speech_prob": 0.0007205242873169482}, {"id": 238, "seek": 113060, "start": 1136.56, "end": 1140.9599999999998, "text": " not actually calling deserializeAny, we're calling deserializeStruct which has been using", "tokens": [50662, 406, 767, 5141, 730, 260, 831, 1125, 29647, 11, 321, 434, 5141, 730, 260, 831, 1125, 4520, 1757, 597, 575, 668, 1228, 50882], "temperature": 0.0, "avg_logprob": -0.19484216516668146, "compression_ratio": 1.8405172413793103, "no_speech_prob": 0.0007205242873169482}, {"id": 239, "seek": 113060, "start": 1140.9599999999998, "end": 1148.4399999999998, "text": " the forwarder from struct to any but if we also, if we remove struct from this big macro", "tokens": [50882, 264, 2128, 260, 490, 6594, 281, 604, 457, 498, 321, 611, 11, 498, 321, 4159, 6594, 490, 341, 955, 18887, 51256], "temperature": 0.0, "avg_logprob": -0.19484216516668146, "compression_ratio": 1.8405172413793103, "no_speech_prob": 0.0007205242873169482}, {"id": 240, "seek": 113060, "start": 1148.4399999999998, "end": 1153.24, "text": " with the forwarding and then implement these there struct on our own we can basically say", "tokens": [51256, 365, 264, 2128, 278, 293, 550, 4445, 613, 456, 6594, 322, 527, 1065, 321, 393, 1936, 584, 51496], "temperature": 0.0, "avg_logprob": -0.19484216516668146, "compression_ratio": 1.8405172413793103, "no_speech_prob": 0.0007205242873169482}, {"id": 241, "seek": 113060, "start": 1153.24, "end": 1157.48, "text": " this is a special version if we know that you want to have a struct.", "tokens": [51496, 341, 307, 257, 2121, 3037, 498, 321, 458, 300, 291, 528, 281, 362, 257, 6594, 13, 51708], "temperature": 0.0, "avg_logprob": -0.19484216516668146, "compression_ratio": 1.8405172413793103, "no_speech_prob": 0.0007205242873169482}, {"id": 242, "seek": 115748, "start": 1157.56, "end": 1161.24, "text": " Once we do that because we get these two additional information that deserializeAny", "tokens": [50368, 3443, 321, 360, 300, 570, 321, 483, 613, 732, 4497, 1589, 300, 730, 260, 831, 1125, 29647, 50552], "temperature": 0.0, "avg_logprob": -0.20558515548706055, "compression_ratio": 1.6724890829694323, "no_speech_prob": 0.00364807341247797}, {"id": 243, "seek": 115748, "start": 1161.24, "end": 1166.3600000000001, "text": " doesn't get which is the name of the struct which we actually don't care about but we", "tokens": [50552, 1177, 380, 483, 597, 307, 264, 1315, 295, 264, 6594, 597, 321, 767, 500, 380, 1127, 466, 457, 321, 50808], "temperature": 0.0, "avg_logprob": -0.20558515548706055, "compression_ratio": 1.6724890829694323, "no_speech_prob": 0.00364807341247797}, {"id": 244, "seek": 115748, "start": 1166.3600000000001, "end": 1169.64, "text": " also get all the fields of the struct.", "tokens": [50808, 611, 483, 439, 264, 7909, 295, 264, 6594, 13, 50972], "temperature": 0.0, "avg_logprob": -0.20558515548706055, "compression_ratio": 1.6724890829694323, "no_speech_prob": 0.00364807341247797}, {"id": 245, "seek": 115748, "start": 1169.64, "end": 1178.28, "text": " And what we're doing here is we take our properties, we have another enum type in there", "tokens": [50972, 400, 437, 321, 434, 884, 510, 307, 321, 747, 527, 7221, 11, 321, 362, 1071, 465, 449, 2010, 294, 456, 51404], "temperature": 0.0, "avg_logprob": -0.20558515548706055, "compression_ratio": 1.6724890829694323, "no_speech_prob": 0.00364807341247797}, {"id": 246, "seek": 115748, "start": 1178.28, "end": 1184.16, "text": " if I want to show you all the code that is related to the enum there's a lot of it but", "tokens": [51404, 498, 286, 528, 281, 855, 291, 439, 264, 3089, 300, 307, 4077, 281, 264, 465, 449, 456, 311, 257, 688, 295, 309, 457, 51698], "temperature": 0.0, "avg_logprob": -0.20558515548706055, "compression_ratio": 1.6724890829694323, "no_speech_prob": 0.00364807341247797}, {"id": 247, "seek": 118416, "start": 1184.16, "end": 1187.8400000000001, "text": " it's very mechanical code.", "tokens": [50364, 309, 311, 588, 12070, 3089, 13, 50548], "temperature": 0.0, "avg_logprob": -0.23821754455566407, "compression_ratio": 1.7298850574712643, "no_speech_prob": 0.0009836893295869231}, {"id": 248, "seek": 118416, "start": 1187.8400000000001, "end": 1195.92, "text": " It's struct data has an enum of two cases property or node and there's a deserializer", "tokens": [50548, 467, 311, 6594, 1412, 575, 364, 465, 449, 295, 732, 3331, 4707, 420, 9984, 293, 456, 311, 257, 730, 260, 831, 6545, 50952], "temperature": 0.0, "avg_logprob": -0.23821754455566407, "compression_ratio": 1.7298850574712643, "no_speech_prob": 0.0009836893295869231}, {"id": 249, "seek": 118416, "start": 1195.92, "end": 1200.3200000000002, "text": " that's also an enum of two cases and each of those cases have their own deserializer", "tokens": [50952, 300, 311, 611, 364, 465, 449, 295, 732, 3331, 293, 1184, 295, 729, 3331, 362, 641, 1065, 730, 260, 831, 6545, 51172], "temperature": 0.0, "avg_logprob": -0.23821754455566407, "compression_ratio": 1.7298850574712643, "no_speech_prob": 0.0009836893295869231}, {"id": 250, "seek": 118416, "start": 1200.3200000000002, "end": 1202.8400000000001, "text": " implementation.", "tokens": [51172, 11420, 13, 51298], "temperature": 0.0, "avg_logprob": -0.23821754455566407, "compression_ratio": 1.7298850574712643, "no_speech_prob": 0.0009836893295869231}, {"id": 251, "seek": 118416, "start": 1202.8400000000001, "end": 1208.0, "text": " And so we have our property fields and then we also iterate through all the fields that", "tokens": [51298, 400, 370, 321, 362, 527, 4707, 7909, 293, 550, 321, 611, 44497, 807, 439, 264, 7909, 300, 51556], "temperature": 0.0, "avg_logprob": -0.23821754455566407, "compression_ratio": 1.7298850574712643, "no_speech_prob": 0.0009836893295869231}, {"id": 252, "seek": 120800, "start": 1208.0, "end": 1216.8, "text": " we get from this struct and we check if any of them are not in our node properties and", "tokens": [50364, 321, 483, 490, 341, 6594, 293, 321, 1520, 498, 604, 295, 552, 366, 406, 294, 527, 9984, 7221, 293, 50804], "temperature": 0.0, "avg_logprob": -0.1950096331144634, "compression_ratio": 1.7660550458715596, "no_speech_prob": 0.004065507557243109}, {"id": 253, "seek": 120800, "start": 1216.8, "end": 1222.76, "text": " then we say okay those we are going to deserialize by giving you some additional data from the", "tokens": [50804, 550, 321, 584, 1392, 729, 321, 366, 516, 281, 730, 260, 831, 1125, 538, 2902, 291, 512, 4497, 1412, 490, 264, 51102], "temperature": 0.0, "avg_logprob": -0.1950096331144634, "compression_ratio": 1.7660550458715596, "no_speech_prob": 0.004065507557243109}, {"id": 254, "seek": 120800, "start": 1222.76, "end": 1225.88, "text": " node and not from the property.", "tokens": [51102, 9984, 293, 406, 490, 264, 4707, 13, 51258], "temperature": 0.0, "avg_logprob": -0.1950096331144634, "compression_ratio": 1.7660550458715596, "no_speech_prob": 0.004065507557243109}, {"id": 255, "seek": 120800, "start": 1225.88, "end": 1231.04, "text": " And then through this like big enum chain eventually we have okay here we chain them", "tokens": [51258, 400, 550, 807, 341, 411, 955, 465, 449, 5021, 4728, 321, 362, 1392, 510, 321, 5021, 552, 51516], "temperature": 0.0, "avg_logprob": -0.1950096331144634, "compression_ratio": 1.7660550458715596, "no_speech_prob": 0.004065507557243109}, {"id": 256, "seek": 120800, "start": 1231.04, "end": 1237.32, "text": " together and through this big enum chain we actually get to to in so-called to another", "tokens": [51516, 1214, 293, 807, 341, 955, 465, 449, 5021, 321, 767, 483, 281, 281, 294, 370, 12, 11880, 281, 1071, 51830], "temperature": 0.0, "avg_logprob": -0.1950096331144634, "compression_ratio": 1.7660550458715596, "no_speech_prob": 0.004065507557243109}, {"id": 257, "seek": 123732, "start": 1237.32, "end": 1248.04, "text": " internal deserializer and the new type fields ID and labels they when they get deserialized", "tokens": [50364, 6920, 730, 260, 831, 6545, 293, 264, 777, 2010, 7909, 7348, 293, 16949, 436, 562, 436, 483, 730, 260, 831, 1602, 50900], "temperature": 0.0, "avg_logprob": -0.2204467018881997, "compression_ratio": 2.0168539325842696, "no_speech_prob": 0.004060797393321991}, {"id": 258, "seek": 123732, "start": 1248.04, "end": 1252.8799999999999, "text": " they don't call deserialized struct they call deserialized new type struct because they're", "tokens": [50900, 436, 500, 380, 818, 730, 260, 831, 1602, 6594, 436, 818, 730, 260, 831, 1602, 777, 2010, 6594, 570, 436, 434, 51142], "temperature": 0.0, "avg_logprob": -0.2204467018881997, "compression_ratio": 2.0168539325842696, "no_speech_prob": 0.004060797393321991}, {"id": 259, "seek": 123732, "start": 1252.8799999999999, "end": 1258.2, "text": " a new type thing and here you get also the name of this struct you don't get any fields", "tokens": [51142, 257, 777, 2010, 551, 293, 510, 291, 483, 611, 264, 1315, 295, 341, 6594, 291, 500, 380, 483, 604, 7909, 51408], "temperature": 0.0, "avg_logprob": -0.2204467018881997, "compression_ratio": 2.0168539325842696, "no_speech_prob": 0.004060797393321991}, {"id": 260, "seek": 123732, "start": 1258.2, "end": 1262.1599999999999, "text": " and new types there aren't any fields or like there is one field that's just called zero", "tokens": [51408, 293, 777, 3467, 456, 3212, 380, 604, 7909, 420, 411, 456, 307, 472, 2519, 300, 311, 445, 1219, 4018, 51606], "temperature": 0.0, "avg_logprob": -0.2204467018881997, "compression_ratio": 2.0168539325842696, "no_speech_prob": 0.004060797393321991}, {"id": 261, "seek": 126216, "start": 1262.28, "end": 1264.0400000000002, "text": " technique.", "tokens": [50370, 6532, 13, 50458], "temperature": 0.0, "avg_logprob": -0.20799402236938477, "compression_ratio": 1.8350515463917525, "no_speech_prob": 0.08479878306388855}, {"id": 262, "seek": 126216, "start": 1264.0400000000002, "end": 1269.0, "text": " And so we have this additional deserializer where we can implement this one and then", "tokens": [50458, 400, 370, 321, 362, 341, 4497, 730, 260, 831, 6545, 689, 321, 393, 4445, 341, 472, 293, 550, 50706], "temperature": 0.0, "avg_logprob": -0.20799402236938477, "compression_ratio": 1.8350515463917525, "no_speech_prob": 0.08479878306388855}, {"id": 263, "seek": 126216, "start": 1269.0, "end": 1273.6000000000001, "text": " here we can match on the name of the struct and if it's called ID we can say oh yeah", "tokens": [50706, 510, 321, 393, 2995, 322, 264, 1315, 295, 264, 6594, 293, 498, 309, 311, 1219, 7348, 321, 393, 584, 1954, 1338, 50936], "temperature": 0.0, "avg_logprob": -0.20799402236938477, "compression_ratio": 1.8350515463917525, "no_speech_prob": 0.08479878306388855}, {"id": 264, "seek": 126216, "start": 1273.6000000000001, "end": 1282.16, "text": " okay I get the ID from my node and if it's labels we can deserialize labels of the node.", "tokens": [50936, 1392, 286, 483, 264, 7348, 490, 452, 9984, 293, 498, 309, 311, 16949, 321, 393, 730, 260, 831, 1125, 16949, 295, 264, 9984, 13, 51364], "temperature": 0.0, "avg_logprob": -0.20799402236938477, "compression_ratio": 1.8350515463917525, "no_speech_prob": 0.08479878306388855}, {"id": 265, "seek": 126216, "start": 1282.16, "end": 1287.88, "text": " And I see deserializer here similar to the map deserializer where we can use 30 to say", "tokens": [51364, 400, 286, 536, 730, 260, 831, 6545, 510, 2531, 281, 264, 4471, 730, 260, 831, 6545, 689, 321, 393, 764, 2217, 281, 584, 51650], "temperature": 0.0, "avg_logprob": -0.20799402236938477, "compression_ratio": 1.8350515463917525, "no_speech_prob": 0.08479878306388855}, {"id": 266, "seek": 128788, "start": 1287.92, "end": 1293.7600000000002, "text": " here a bunch of values and put them in like a list at the end.", "tokens": [50366, 510, 257, 3840, 295, 4190, 293, 829, 552, 294, 411, 257, 1329, 412, 264, 917, 13, 50658], "temperature": 0.0, "avg_logprob": -0.2630093211219424, "compression_ratio": 1.587378640776699, "no_speech_prob": 0.020845863968133926}, {"id": 267, "seek": 128788, "start": 1293.7600000000002, "end": 1300.44, "text": " These are things that SOTI provides in order to avoid like having to allocate a VAC or", "tokens": [50658, 1981, 366, 721, 300, 318, 5068, 40, 6417, 294, 1668, 281, 5042, 411, 1419, 281, 35713, 257, 691, 4378, 420, 50992], "temperature": 0.0, "avg_logprob": -0.2630093211219424, "compression_ratio": 1.587378640776699, "no_speech_prob": 0.020845863968133926}, {"id": 268, "seek": 128788, "start": 1300.44, "end": 1309.64, "text": " a map a hash map and then using that one so you can use this you know with like less", "tokens": [50992, 257, 4471, 257, 22019, 4471, 293, 550, 1228, 300, 472, 370, 291, 393, 764, 341, 291, 458, 365, 411, 1570, 51452], "temperature": 0.0, "avg_logprob": -0.2630093211219424, "compression_ratio": 1.587378640776699, "no_speech_prob": 0.020845863968133926}, {"id": 269, "seek": 128788, "start": 1309.64, "end": 1317.7600000000002, "text": " overhead without allocations and potentially maybe also use it in in in no std environments.", "tokens": [51452, 19922, 1553, 12660, 763, 293, 7263, 1310, 611, 764, 309, 294, 294, 294, 572, 342, 67, 12388, 13, 51858], "temperature": 0.0, "avg_logprob": -0.2630093211219424, "compression_ratio": 1.587378640776699, "no_speech_prob": 0.020845863968133926}, {"id": 270, "seek": 131776, "start": 1318.76, "end": 1326.96, "text": " Right so if we're doing that and put those together then that works and the example will", "tokens": [50414, 1779, 370, 498, 321, 434, 884, 300, 293, 829, 729, 1214, 550, 300, 1985, 293, 264, 1365, 486, 50824], "temperature": 0.0, "avg_logprob": -0.24583693610297308, "compression_ratio": 1.7149532710280373, "no_speech_prob": 0.0012350069591775537}, {"id": 271, "seek": 131776, "start": 1326.96, "end": 1329.2, "text": " give you the data.", "tokens": [50824, 976, 291, 264, 1412, 13, 50936], "temperature": 0.0, "avg_logprob": -0.24583693610297308, "compression_ratio": 1.7149532710280373, "no_speech_prob": 0.0012350069591775537}, {"id": 272, "seek": 131776, "start": 1329.2, "end": 1334.44, "text": " There's still some downsides and I'm not gonna we're not gonna go into a fifth attempt", "tokens": [50936, 821, 311, 920, 512, 21554, 1875, 293, 286, 478, 406, 799, 321, 434, 406, 799, 352, 666, 257, 9266, 5217, 51198], "temperature": 0.0, "avg_logprob": -0.24583693610297308, "compression_ratio": 1.7149532710280373, "no_speech_prob": 0.0012350069591775537}, {"id": 273, "seek": 131776, "start": 1334.44, "end": 1339.64, "text": " now because those downsides are still not fixed and we're figuring out how to work around", "tokens": [51198, 586, 570, 729, 21554, 1875, 366, 920, 406, 6806, 293, 321, 434, 15213, 484, 577, 281, 589, 926, 51458], "temperature": 0.0, "avg_logprob": -0.24583693610297308, "compression_ratio": 1.7149532710280373, "no_speech_prob": 0.0012350069591775537}, {"id": 274, "seek": 131776, "start": 1339.64, "end": 1345.08, "text": " them and the biggest downside is that the deserial default attribute doesn't work.", "tokens": [51458, 552, 293, 264, 3880, 25060, 307, 300, 264, 730, 260, 831, 7576, 19667, 1177, 380, 589, 13, 51730], "temperature": 0.0, "avg_logprob": -0.24583693610297308, "compression_ratio": 1.7149532710280373, "no_speech_prob": 0.0012350069591775537}, {"id": 275, "seek": 134508, "start": 1345.08, "end": 1354.1999999999998, "text": " So if you have a struct and you annotate one of the fields with this SOTI default what", "tokens": [50364, 407, 498, 291, 362, 257, 6594, 293, 291, 25339, 473, 472, 295, 264, 7909, 365, 341, 318, 5068, 40, 7576, 437, 50820], "temperature": 0.0, "avg_logprob": -0.14339524766673212, "compression_ratio": 1.658878504672897, "no_speech_prob": 0.0004877114261034876}, {"id": 276, "seek": 134508, "start": 1354.1999999999998, "end": 1363.84, "text": " SOTI will do when it generates this deserialize code instead of saying at the end hey I have", "tokens": [50820, 318, 5068, 40, 486, 360, 562, 309, 23815, 341, 730, 260, 831, 1125, 3089, 2602, 295, 1566, 412, 264, 917, 4177, 286, 362, 51302], "temperature": 0.0, "avg_logprob": -0.14339524766673212, "compression_ratio": 1.658878504672897, "no_speech_prob": 0.0004877114261034876}, {"id": 277, "seek": 134508, "start": 1363.84, "end": 1369.8, "text": " this value and I do unwrap or else an error with the missing field it's gonna call the", "tokens": [51302, 341, 2158, 293, 286, 360, 14853, 4007, 420, 1646, 364, 6713, 365, 264, 5361, 2519, 309, 311, 799, 818, 264, 51600], "temperature": 0.0, "avg_logprob": -0.14339524766673212, "compression_ratio": 1.658878504672897, "no_speech_prob": 0.0004877114261034876}, {"id": 278, "seek": 134508, "start": 1369.8, "end": 1374.8799999999999, "text": " default method and then get the value from there and that's the only thing that changes.", "tokens": [51600, 7576, 3170, 293, 550, 483, 264, 2158, 490, 456, 293, 300, 311, 264, 787, 551, 300, 2962, 13, 51854], "temperature": 0.0, "avg_logprob": -0.14339524766673212, "compression_ratio": 1.658878504672897, "no_speech_prob": 0.0004877114261034876}, {"id": 279, "seek": 137488, "start": 1374.88, "end": 1380.24, "text": " Like there's nothing else in this whole method call where we get the information that the", "tokens": [50364, 1743, 456, 311, 1825, 1646, 294, 341, 1379, 3170, 818, 689, 321, 483, 264, 1589, 300, 264, 50632], "temperature": 0.0, "avg_logprob": -0.2107442942532626, "compression_ratio": 1.7293577981651376, "no_speech_prob": 0.0005438774824142456}, {"id": 280, "seek": 137488, "start": 1380.24, "end": 1386.0, "text": " user actually has this annotated with this default attribute.", "tokens": [50632, 4195, 767, 575, 341, 25339, 770, 365, 341, 7576, 19667, 13, 50920], "temperature": 0.0, "avg_logprob": -0.2107442942532626, "compression_ratio": 1.7293577981651376, "no_speech_prob": 0.0005438774824142456}, {"id": 281, "seek": 137488, "start": 1386.0, "end": 1392.64, "text": " That means if you go through this next key next value train and we say here is a value", "tokens": [50920, 663, 1355, 498, 291, 352, 807, 341, 958, 2141, 958, 2158, 3847, 293, 321, 584, 510, 307, 257, 2158, 51252], "temperature": 0.0, "avg_logprob": -0.2107442942532626, "compression_ratio": 1.7293577981651376, "no_speech_prob": 0.0005438774824142456}, {"id": 282, "seek": 137488, "start": 1392.64, "end": 1398.3200000000002, "text": " and Zuri expects that we give it an actual value like if we say we have something for", "tokens": [51252, 293, 1176, 9744, 33280, 300, 321, 976, 309, 364, 3539, 2158, 411, 498, 321, 584, 321, 362, 746, 337, 51536], "temperature": 0.0, "avg_logprob": -0.2107442942532626, "compression_ratio": 1.7293577981651376, "no_speech_prob": 0.0005438774824142456}, {"id": 283, "seek": 137488, "start": 1398.3200000000002, "end": 1404.4, "text": " that value for that key we should provide something.", "tokens": [51536, 300, 2158, 337, 300, 2141, 321, 820, 2893, 746, 13, 51840], "temperature": 0.0, "avg_logprob": -0.2107442942532626, "compression_ratio": 1.7293577981651376, "no_speech_prob": 0.0005438774824142456}, {"id": 284, "seek": 140440, "start": 1405.1200000000001, "end": 1413.2800000000002, "text": " And on the other side what we are doing is saying all the fields in the struct we put", "tokens": [50400, 400, 322, 264, 661, 1252, 437, 321, 366, 884, 307, 1566, 439, 264, 7909, 294, 264, 6594, 321, 829, 50808], "temperature": 0.0, "avg_logprob": -0.206749381088629, "compression_ratio": 1.715, "no_speech_prob": 0.011480865068733692}, {"id": 285, "seek": 140440, "start": 1413.2800000000002, "end": 1417.3200000000002, "text": " them in this iterator where we are saying we have something for the struct.", "tokens": [50808, 552, 294, 341, 17138, 1639, 689, 321, 366, 1566, 321, 362, 746, 337, 264, 6594, 13, 51010], "temperature": 0.0, "avg_logprob": -0.206749381088629, "compression_ratio": 1.715, "no_speech_prob": 0.011480865068733692}, {"id": 286, "seek": 140440, "start": 1417.3200000000002, "end": 1425.48, "text": " So we eventually see the year field and we think well it must be one of those additional", "tokens": [51010, 407, 321, 4728, 536, 264, 1064, 2519, 293, 321, 519, 731, 309, 1633, 312, 472, 295, 729, 4497, 51418], "temperature": 0.0, "avg_logprob": -0.206749381088629, "compression_ratio": 1.715, "no_speech_prob": 0.011480865068733692}, {"id": 287, "seek": 140440, "start": 1425.48, "end": 1434.2, "text": " types because the year is not in the properties because it's missing in our node but then we", "tokens": [51418, 3467, 570, 264, 1064, 307, 406, 294, 264, 7221, 570, 309, 311, 5361, 294, 527, 9984, 457, 550, 321, 51854], "temperature": 0.0, "avg_logprob": -0.206749381088629, "compression_ratio": 1.715, "no_speech_prob": 0.011480865068733692}, {"id": 288, "seek": 143420, "start": 1434.2, "end": 1438.2, "text": " are saying we are not getting one of those new types but we get these U64 and then we", "tokens": [50364, 366, 1566, 321, 366, 406, 1242, 472, 295, 729, 777, 3467, 457, 321, 483, 613, 624, 19395, 293, 550, 321, 50564], "temperature": 0.0, "avg_logprob": -0.2234370831361751, "compression_ratio": 1.6681614349775784, "no_speech_prob": 0.0025878390297293663}, {"id": 289, "seek": 143420, "start": 1438.2, "end": 1441.44, "text": " don't know what to do about it.", "tokens": [50564, 500, 380, 458, 437, 281, 360, 466, 309, 13, 50726], "temperature": 0.0, "avg_logprob": -0.2234370831361751, "compression_ratio": 1.6681614349775784, "no_speech_prob": 0.0025878390297293663}, {"id": 290, "seek": 143420, "start": 1441.44, "end": 1445.72, "text": " Because it's not in the properties we have to do something we cannot say this type isn't", "tokens": [50726, 1436, 309, 311, 406, 294, 264, 7221, 321, 362, 281, 360, 746, 321, 2644, 584, 341, 2010, 1943, 380, 50940], "temperature": 0.0, "avg_logprob": -0.2234370831361751, "compression_ratio": 1.6681614349775784, "no_speech_prob": 0.0025878390297293663}, {"id": 291, "seek": 143420, "start": 1445.72, "end": 1453.52, "text": " available it's too late for that at that point in time and so we have to fail.", "tokens": [50940, 2435, 309, 311, 886, 3469, 337, 300, 412, 300, 935, 294, 565, 293, 370, 321, 362, 281, 3061, 13, 51330], "temperature": 0.0, "avg_logprob": -0.2234370831361751, "compression_ratio": 1.6681614349775784, "no_speech_prob": 0.0025878390297293663}, {"id": 292, "seek": 143420, "start": 1453.52, "end": 1459.64, "text": " So using the default attribute doesn't work but there is a workaround that you can use", "tokens": [51330, 407, 1228, 264, 7576, 19667, 1177, 380, 589, 457, 456, 307, 257, 589, 25762, 300, 291, 393, 764, 51636], "temperature": 0.0, "avg_logprob": -0.2234370831361751, "compression_ratio": 1.6681614349775784, "no_speech_prob": 0.0025878390297293663}, {"id": 293, "seek": 145964, "start": 1459.64, "end": 1466.5200000000002, "text": " the option wrapper around it so you can manually choose and report default at the end and that", "tokens": [50364, 264, 3614, 46906, 926, 309, 370, 291, 393, 16945, 2826, 293, 2275, 7576, 412, 264, 917, 293, 300, 50708], "temperature": 0.0, "avg_logprob": -0.2217247801006965, "compression_ratio": 1.7479338842975207, "no_speech_prob": 0.002048953901976347}, {"id": 294, "seek": 145964, "start": 1466.5200000000002, "end": 1472.0, "text": " works so we have a workaround and so we can figure out how to solve this eventually.", "tokens": [50708, 1985, 370, 321, 362, 257, 589, 25762, 293, 370, 321, 393, 2573, 484, 577, 281, 5039, 341, 4728, 13, 50982], "temperature": 0.0, "avg_logprob": -0.2217247801006965, "compression_ratio": 1.7479338842975207, "no_speech_prob": 0.002048953901976347}, {"id": 295, "seek": 145964, "start": 1472.0, "end": 1475.4, "text": " So now that we are done with the nodes we can do the same thing for all the other 20", "tokens": [50982, 407, 586, 300, 321, 366, 1096, 365, 264, 13891, 321, 393, 360, 264, 912, 551, 337, 439, 264, 661, 945, 51152], "temperature": 0.0, "avg_logprob": -0.2217247801006965, "compression_ratio": 1.7479338842975207, "no_speech_prob": 0.002048953901976347}, {"id": 296, "seek": 145964, "start": 1475.4, "end": 1476.4, "text": " variants.", "tokens": [51152, 21669, 13, 51202], "temperature": 0.0, "avg_logprob": -0.2217247801006965, "compression_ratio": 1.7479338842975207, "no_speech_prob": 0.002048953901976347}, {"id": 297, "seek": 145964, "start": 1476.4, "end": 1483.76, "text": " We are not going to do that here of course but you can imagine.", "tokens": [51202, 492, 366, 406, 516, 281, 360, 300, 510, 295, 1164, 457, 291, 393, 3811, 13, 51570], "temperature": 0.0, "avg_logprob": -0.2217247801006965, "compression_ratio": 1.7479338842975207, "no_speech_prob": 0.002048953901976347}, {"id": 298, "seek": 145964, "start": 1483.76, "end": 1488.16, "text": " But then we are still not done at the end there are still some smaller things that I", "tokens": [51570, 583, 550, 321, 366, 920, 406, 1096, 412, 264, 917, 456, 366, 920, 512, 4356, 721, 300, 286, 51790], "temperature": 0.0, "avg_logprob": -0.2217247801006965, "compression_ratio": 1.7479338842975207, "no_speech_prob": 0.002048953901976347}, {"id": 299, "seek": 148816, "start": 1488.16, "end": 1495.0400000000002, "text": " wanted to mention that are just like things that we ran into and that gave us some learning", "tokens": [50364, 1415, 281, 2152, 300, 366, 445, 411, 721, 300, 321, 5872, 666, 293, 300, 2729, 505, 512, 2539, 50708], "temperature": 0.0, "avg_logprob": -0.2752457113826976, "compression_ratio": 1.6683168316831682, "no_speech_prob": 0.0032669836655259132}, {"id": 300, "seek": 148816, "start": 1495.0400000000002, "end": 1497.52, "text": " experience.", "tokens": [50708, 1752, 13, 50832], "temperature": 0.0, "avg_logprob": -0.2752457113826976, "compression_ratio": 1.6683168316831682, "no_speech_prob": 0.0032669836655259132}, {"id": 301, "seek": 148816, "start": 1497.52, "end": 1504.64, "text": " In particular Bolt has a bytes type so there is a native thing for here is a vec of U8", "tokens": [50832, 682, 1729, 37884, 575, 257, 36088, 2010, 370, 456, 307, 257, 8470, 551, 337, 510, 307, 257, 42021, 295, 624, 23, 51188], "temperature": 0.0, "avg_logprob": -0.2752457113826976, "compression_ratio": 1.6683168316831682, "no_speech_prob": 0.0032669836655259132}, {"id": 302, "seek": 148816, "start": 1504.64, "end": 1511.1200000000001, "text": " and this is like some glob of data that the user has defined.", "tokens": [51188, 293, 341, 307, 411, 512, 16125, 295, 1412, 300, 264, 4195, 575, 7642, 13, 51512], "temperature": 0.0, "avg_logprob": -0.2752457113826976, "compression_ratio": 1.6683168316831682, "no_speech_prob": 0.0032669836655259132}, {"id": 303, "seek": 148816, "start": 1511.1200000000001, "end": 1518.1200000000001, "text": " Not many data types and many data formats have a bytes type so 30 while the data mod", "tokens": [51512, 1726, 867, 1412, 3467, 293, 867, 1412, 25879, 362, 257, 36088, 2010, 370, 2217, 1339, 264, 1412, 1072, 51862], "temperature": 0.0, "avg_logprob": -0.2752457113826976, "compression_ratio": 1.6683168316831682, "no_speech_prob": 0.0032669836655259132}, {"id": 304, "seek": 151812, "start": 1518.2399999999998, "end": 1520.0, "text": " model has something for bytes.", "tokens": [50370, 2316, 575, 746, 337, 36088, 13, 50458], "temperature": 0.0, "avg_logprob": -0.3248395125071208, "compression_ratio": 1.6995708154506437, "no_speech_prob": 0.004259836860001087}, {"id": 305, "seek": 151812, "start": 1520.0, "end": 1524.9199999999998, "text": " We can start by doing this like we get for example a string and we get a bytes and there", "tokens": [50458, 492, 393, 722, 538, 884, 341, 411, 321, 483, 337, 1365, 257, 6798, 293, 321, 483, 257, 36088, 293, 456, 50704], "temperature": 0.0, "avg_logprob": -0.3248395125071208, "compression_ratio": 1.6995708154506437, "no_speech_prob": 0.004259836860001087}, {"id": 306, "seek": 151812, "start": 1524.9199999999998, "end": 1530.56, "text": " is a visit string and visit bytes so hey cool we can just pass on our bytes array.", "tokens": [50704, 307, 257, 3441, 6798, 293, 3441, 36088, 370, 4177, 1627, 321, 393, 445, 1320, 322, 527, 36088, 10225, 13, 50986], "temperature": 0.0, "avg_logprob": -0.3248395125071208, "compression_ratio": 1.6995708154506437, "no_speech_prob": 0.004259836860001087}, {"id": 307, "seek": 151812, "start": 1530.56, "end": 1537.8, "text": " But like I said many data formats have them so 30 doesn't actually generate visitors", "tokens": [50986, 583, 411, 286, 848, 867, 1412, 25879, 362, 552, 370, 2217, 1177, 380, 767, 8460, 14315, 51348], "temperature": 0.0, "avg_logprob": -0.3248395125071208, "compression_ratio": 1.6995708154506437, "no_speech_prob": 0.004259836860001087}, {"id": 308, "seek": 151812, "start": 1537.8, "end": 1542.3999999999999, "text": " that expect that you call this visit bytes method because then you could never use it", "tokens": [51348, 300, 2066, 300, 291, 818, 341, 3441, 36088, 3170, 570, 550, 291, 727, 1128, 764, 309, 51578], "temperature": 0.0, "avg_logprob": -0.3248395125071208, "compression_ratio": 1.6995708154506437, "no_speech_prob": 0.004259836860001087}, {"id": 309, "seek": 151812, "start": 1542.3999999999999, "end": 1546.1599999999999, "text": " with for example JSON.", "tokens": [51578, 365, 337, 1365, 31828, 13, 51766], "temperature": 0.0, "avg_logprob": -0.3248395125071208, "compression_ratio": 1.6995708154506437, "no_speech_prob": 0.004259836860001087}, {"id": 310, "seek": 154616, "start": 1546.52, "end": 1554.68, "text": " What's really sad is if you have a vec of U8 in your data type you should call this as", "tokens": [50382, 708, 311, 534, 4227, 307, 498, 291, 362, 257, 42021, 295, 624, 23, 294, 428, 1412, 2010, 291, 820, 818, 341, 382, 50790], "temperature": 0.0, "avg_logprob": -0.2984287310869266, "compression_ratio": 1.6108108108108108, "no_speech_prob": 0.0033188427332788706}, {"id": 311, "seek": 154616, "start": 1554.68, "end": 1561.3600000000001, "text": " a sequence of individual bytes instead of like one blob of bytes.", "tokens": [50790, 257, 8310, 295, 2609, 36088, 2602, 295, 411, 472, 46115, 295, 36088, 13, 51124], "temperature": 0.0, "avg_logprob": -0.2984287310869266, "compression_ratio": 1.6108108108108108, "no_speech_prob": 0.0033188427332788706}, {"id": 312, "seek": 154616, "start": 1561.3600000000001, "end": 1565.48, "text": " So you would have this visit seek and then there is a seek user and that doesn't really", "tokens": [51124, 407, 291, 576, 362, 341, 3441, 8075, 293, 550, 456, 307, 257, 8075, 4195, 293, 300, 1177, 380, 534, 51330], "temperature": 0.0, "avg_logprob": -0.2984287310869266, "compression_ratio": 1.6108108108108108, "no_speech_prob": 0.0033188427332788706}, {"id": 313, "seek": 154616, "start": 1565.48, "end": 1569.68, "text": " matter what is at the end there but we need to call this.", "tokens": [51330, 1871, 437, 307, 412, 264, 917, 456, 457, 321, 643, 281, 818, 341, 13, 51540], "temperature": 0.0, "avg_logprob": -0.2984287310869266, "compression_ratio": 1.6108108108108108, "no_speech_prob": 0.0033188427332788706}, {"id": 314, "seek": 156968, "start": 1569.68, "end": 1574.88, "text": " But then we can use the same thing where there is a deserialized bytes and there are", "tokens": [50364, 583, 550, 321, 393, 764, 264, 912, 551, 689, 456, 307, 257, 730, 260, 831, 1602, 36088, 293, 456, 366, 50624], "temperature": 0.0, "avg_logprob": -0.22044209374321833, "compression_ratio": 1.7156862745098038, "no_speech_prob": 0.013201090507209301}, {"id": 315, "seek": 156968, "start": 1574.88, "end": 1583.5600000000002, "text": " some third party crates there is 30 bytes there is 30 width that can be used to say", "tokens": [50624, 512, 2636, 3595, 941, 1024, 456, 307, 2217, 36088, 456, 307, 2217, 11402, 300, 393, 312, 1143, 281, 584, 51058], "temperature": 0.0, "avg_logprob": -0.22044209374321833, "compression_ratio": 1.7156862745098038, "no_speech_prob": 0.013201090507209301}, {"id": 316, "seek": 156968, "start": 1583.5600000000002, "end": 1590.8, "text": " to tell 30 hey this is a vec of U8 but actually I can provide bytes for that and please expect", "tokens": [51058, 281, 980, 2217, 4177, 341, 307, 257, 42021, 295, 624, 23, 457, 767, 286, 393, 2893, 36088, 337, 300, 293, 1767, 2066, 51420], "temperature": 0.0, "avg_logprob": -0.22044209374321833, "compression_ratio": 1.7156862745098038, "no_speech_prob": 0.013201090507209301}, {"id": 317, "seek": 156968, "start": 1590.8, "end": 1599.64, "text": " call to visit bytes and on the other side like I said earlier deserializer should call", "tokens": [51420, 818, 281, 3441, 36088, 293, 322, 264, 661, 1252, 411, 286, 848, 3071, 730, 260, 831, 6545, 820, 818, 51862], "temperature": 0.0, "avg_logprob": -0.22044209374321833, "compression_ratio": 1.7156862745098038, "no_speech_prob": 0.013201090507209301}, {"id": 318, "seek": 159964, "start": 1600.6000000000001, "end": 1607.0800000000002, "text": " the most special like the method with the most information and so it should call not", "tokens": [50412, 264, 881, 2121, 411, 264, 3170, 365, 264, 881, 1589, 293, 370, 309, 820, 818, 406, 50736], "temperature": 0.0, "avg_logprob": -0.22582479270107775, "compression_ratio": 1.7258064516129032, "no_speech_prob": 0.0016980371437966824}, {"id": 319, "seek": 159964, "start": 1607.0800000000002, "end": 1610.76, "text": " deserialize any at the end but deserialize bytes because it's saying well I actually", "tokens": [50736, 730, 260, 831, 1125, 604, 412, 264, 917, 457, 730, 260, 831, 1125, 36088, 570, 309, 311, 1566, 731, 286, 767, 50920], "temperature": 0.0, "avg_logprob": -0.22582479270107775, "compression_ratio": 1.7258064516129032, "no_speech_prob": 0.0016980371437966824}, {"id": 320, "seek": 159964, "start": 1610.76, "end": 1619.48, "text": " can accept a call to visit bytes and so in here we can check if we are actually if we", "tokens": [50920, 393, 3241, 257, 818, 281, 3441, 36088, 293, 370, 294, 510, 321, 393, 1520, 498, 321, 366, 767, 498, 321, 51356], "temperature": 0.0, "avg_logprob": -0.22582479270107775, "compression_ratio": 1.7258064516129032, "no_speech_prob": 0.0016980371437966824}, {"id": 321, "seek": 159964, "start": 1619.48, "end": 1625.3600000000001, "text": " have bytes and then we can just pass them on and then we're done.", "tokens": [51356, 362, 36088, 293, 550, 321, 393, 445, 1320, 552, 322, 293, 550, 321, 434, 1096, 13, 51650], "temperature": 0.0, "avg_logprob": -0.22582479270107775, "compression_ratio": 1.7258064516129032, "no_speech_prob": 0.0016980371437966824}, {"id": 322, "seek": 162536, "start": 1625.36, "end": 1630.7199999999998, "text": " So not really but we're running out of time here so I want to do a quick run through a", "tokens": [50364, 407, 406, 534, 457, 321, 434, 2614, 484, 295, 565, 510, 370, 286, 528, 281, 360, 257, 1702, 1190, 807, 257, 50632], "temperature": 0.0, "avg_logprob": -0.2069546689269363, "compression_ratio": 1.6371681415929205, "no_speech_prob": 0.05075773969292641}, {"id": 323, "seek": 162536, "start": 1630.7199999999998, "end": 1635.7199999999998, "text": " couple of other things and if you ever ran into one of those issues I don't know you", "tokens": [50632, 1916, 295, 661, 721, 293, 498, 291, 1562, 5872, 666, 472, 295, 729, 2663, 286, 500, 380, 458, 291, 50882], "temperature": 0.0, "avg_logprob": -0.2069546689269363, "compression_ratio": 1.6371681415929205, "no_speech_prob": 0.05075773969292641}, {"id": 324, "seek": 162536, "start": 1635.7199999999998, "end": 1639.36, "text": " can find me afterwards and we can talk about this.", "tokens": [50882, 393, 915, 385, 10543, 293, 321, 393, 751, 466, 341, 13, 51064], "temperature": 0.0, "avg_logprob": -0.2069546689269363, "compression_ratio": 1.6371681415929205, "no_speech_prob": 0.05075773969292641}, {"id": 325, "seek": 162536, "start": 1639.36, "end": 1645.08, "text": " So one thing is I said earlier we want to maintain the existing API and the existing", "tokens": [51064, 407, 472, 551, 307, 286, 848, 3071, 321, 528, 281, 6909, 264, 6741, 9362, 293, 264, 6741, 51350], "temperature": 0.0, "avg_logprob": -0.2069546689269363, "compression_ratio": 1.6371681415929205, "no_speech_prob": 0.05075773969292641}, {"id": 326, "seek": 162536, "start": 1645.08, "end": 1652.76, "text": " API was based on conversions via the try from and from traits.", "tokens": [51350, 9362, 390, 2361, 322, 42256, 5766, 264, 853, 490, 293, 490, 19526, 13, 51734], "temperature": 0.0, "avg_logprob": -0.2069546689269363, "compression_ratio": 1.6371681415929205, "no_speech_prob": 0.05075773969292641}, {"id": 327, "seek": 165276, "start": 1652.76, "end": 1660.04, "text": " So there was a bunch of traits implemented for try from bold type for a bunch of other", "tokens": [50364, 407, 456, 390, 257, 3840, 295, 19526, 12270, 337, 853, 490, 11928, 2010, 337, 257, 3840, 295, 661, 50728], "temperature": 0.0, "avg_logprob": -0.1473390740084361, "compression_ratio": 1.8020833333333333, "no_speech_prob": 0.010305571369826794}, {"id": 328, "seek": 165276, "start": 1660.04, "end": 1664.08, "text": " types so we also needed to make sure that if you're using these bunch of other types", "tokens": [50728, 3467, 370, 321, 611, 2978, 281, 652, 988, 300, 498, 291, 434, 1228, 613, 3840, 295, 661, 3467, 50930], "temperature": 0.0, "avg_logprob": -0.1473390740084361, "compression_ratio": 1.8020833333333333, "no_speech_prob": 0.010305571369826794}, {"id": 329, "seek": 165276, "start": 1664.08, "end": 1669.96, "text": " at the other end our deserializer will do the right thing and part of those bunch of", "tokens": [50930, 412, 264, 661, 917, 527, 730, 260, 831, 6545, 486, 360, 264, 558, 551, 293, 644, 295, 729, 3840, 295, 51224], "temperature": 0.0, "avg_logprob": -0.1473390740084361, "compression_ratio": 1.8020833333333333, "no_speech_prob": 0.010305571369826794}, {"id": 330, "seek": 165276, "start": 1669.96, "end": 1676.8799999999999, "text": " other types are various state related things from the chrono and time crates because bold", "tokens": [51224, 661, 3467, 366, 3683, 1785, 4077, 721, 490, 264, 19393, 78, 293, 565, 941, 1024, 570, 11928, 51570], "temperature": 0.0, "avg_logprob": -0.1473390740084361, "compression_ratio": 1.8020833333333333, "no_speech_prob": 0.010305571369826794}, {"id": 331, "seek": 167688, "start": 1676.88, "end": 1686.2800000000002, "text": " has native structs for dates and times and date times and without time zones and all", "tokens": [50364, 575, 8470, 6594, 82, 337, 11691, 293, 1413, 293, 4002, 1413, 293, 1553, 565, 16025, 293, 439, 50834], "temperature": 0.0, "avg_logprob": -0.2348213979642685, "compression_ratio": 1.7485380116959064, "no_speech_prob": 0.017398590222001076}, {"id": 332, "seek": 167688, "start": 1686.2800000000002, "end": 1690.24, "text": " the fun with dealing with those.", "tokens": [50834, 264, 1019, 365, 6260, 365, 729, 13, 51032], "temperature": 0.0, "avg_logprob": -0.2348213979642685, "compression_ratio": 1.7485380116959064, "no_speech_prob": 0.017398590222001076}, {"id": 333, "seek": 167688, "start": 1690.24, "end": 1695.0600000000002, "text": " So this taught us about there's a thing called a human readable where you can say whether", "tokens": [51032, 407, 341, 5928, 505, 466, 456, 311, 257, 551, 1219, 257, 1952, 49857, 689, 291, 393, 584, 1968, 51273], "temperature": 0.0, "avg_logprob": -0.2348213979642685, "compression_ratio": 1.7485380116959064, "no_speech_prob": 0.017398590222001076}, {"id": 334, "seek": 167688, "start": 1695.0600000000002, "end": 1702.5200000000002, "text": " or not you're a deserializer or your serializer works with a human readable data format and", "tokens": [51273, 420, 406, 291, 434, 257, 730, 260, 831, 6545, 420, 428, 17436, 6545, 1985, 365, 257, 1952, 49857, 1412, 7877, 293, 51646], "temperature": 0.0, "avg_logprob": -0.2348213979642685, "compression_ratio": 1.7485380116959064, "no_speech_prob": 0.017398590222001076}, {"id": 335, "seek": 170252, "start": 1702.52, "end": 1708.12, "text": " I think the time crates, the time crates uses that in order to say if it's a human readable", "tokens": [50364, 286, 519, 264, 565, 941, 1024, 11, 264, 565, 941, 1024, 4960, 300, 294, 1668, 281, 584, 498, 309, 311, 257, 1952, 49857, 50644], "temperature": 0.0, "avg_logprob": -0.2221167949920005, "compression_ratio": 1.6807511737089202, "no_speech_prob": 0.03351866826415062}, {"id": 336, "seek": 170252, "start": 1708.12, "end": 1714.46, "text": " one it's being serialized and deserialized from string and it parsed from the RFC something", "tokens": [50644, 472, 309, 311, 885, 17436, 1602, 293, 730, 260, 831, 1602, 490, 6798, 293, 309, 21156, 292, 490, 264, 497, 18671, 746, 50961], "temperature": 0.0, "avg_logprob": -0.2221167949920005, "compression_ratio": 1.6807511737089202, "no_speech_prob": 0.03351866826415062}, {"id": 337, "seek": 170252, "start": 1714.46, "end": 1722.36, "text": " 3.9 format and the non-human readable format will pass in a bunch of integers and so we", "tokens": [50961, 805, 13, 24, 7877, 293, 264, 2107, 12, 18796, 49857, 7877, 486, 1320, 294, 257, 3840, 295, 41674, 293, 370, 321, 51356], "temperature": 0.0, "avg_logprob": -0.2221167949920005, "compression_ratio": 1.6807511737089202, "no_speech_prob": 0.03351866826415062}, {"id": 338, "seek": 170252, "start": 1722.36, "end": 1729.84, "text": " have to set that flag in order to provide the correct data and you can use annotations", "tokens": [51356, 362, 281, 992, 300, 7166, 294, 1668, 281, 2893, 264, 3006, 1412, 293, 291, 393, 764, 25339, 763, 51730], "temperature": 0.0, "avg_logprob": -0.2221167949920005, "compression_ratio": 1.6807511737089202, "no_speech_prob": 0.03351866826415062}, {"id": 339, "seek": 172984, "start": 1729.84, "end": 1734.9199999999998, "text": " for one of those where you can say this is a time stamp but the resolution is in milliseconds", "tokens": [50364, 337, 472, 295, 729, 689, 291, 393, 584, 341, 307, 257, 565, 9921, 457, 264, 8669, 307, 294, 34184, 50618], "temperature": 0.0, "avg_logprob": -0.1881517594860446, "compression_ratio": 1.7523364485981308, "no_speech_prob": 0.005809631664305925}, {"id": 340, "seek": 172984, "start": 1734.9199999999998, "end": 1740.0, "text": " or in seconds or in microseconds and then we have to figure out okay what is the actual", "tokens": [50618, 420, 294, 3949, 420, 294, 3123, 37841, 28750, 293, 550, 321, 362, 281, 2573, 484, 1392, 437, 307, 264, 3539, 50872], "temperature": 0.0, "avg_logprob": -0.1881517594860446, "compression_ratio": 1.7523364485981308, "no_speech_prob": 0.005809631664305925}, {"id": 341, "seek": 172984, "start": 1740.0, "end": 1746.1999999999998, "text": " value that we have to give you so that the calculation at the end turns out to be correct.", "tokens": [50872, 2158, 300, 321, 362, 281, 976, 291, 370, 300, 264, 17108, 412, 264, 917, 4523, 484, 281, 312, 3006, 13, 51182], "temperature": 0.0, "avg_logprob": -0.1881517594860446, "compression_ratio": 1.7523364485981308, "no_speech_prob": 0.005809631664305925}, {"id": 342, "seek": 172984, "start": 1746.1999999999998, "end": 1749.08, "text": " So that was fun.", "tokens": [51182, 407, 300, 390, 1019, 13, 51326], "temperature": 0.0, "avg_logprob": -0.1881517594860446, "compression_ratio": 1.7523364485981308, "no_speech_prob": 0.005809631664305925}, {"id": 343, "seek": 172984, "start": 1749.08, "end": 1755.56, "text": " The other thing is if you have conversion via from and try from trades because of the", "tokens": [51326, 440, 661, 551, 307, 498, 291, 362, 14298, 5766, 490, 293, 853, 490, 21287, 570, 295, 264, 51650], "temperature": 0.0, "avg_logprob": -0.1881517594860446, "compression_ratio": 1.7523364485981308, "no_speech_prob": 0.005809631664305925}, {"id": 344, "seek": 175556, "start": 1755.56, "end": 1761.2, "text": " planket implementation you could also convert the bold type into a bold type and so we also", "tokens": [50364, 27861, 302, 11420, 291, 727, 611, 7620, 264, 11928, 2010, 666, 257, 11928, 2010, 293, 370, 321, 611, 50646], "temperature": 0.0, "avg_logprob": -0.20421666984098502, "compression_ratio": 1.8969072164948453, "no_speech_prob": 0.0032190445344895124}, {"id": 345, "seek": 175556, "start": 1761.2, "end": 1768.32, "text": " need to be able to say we can visualize into from a bold type into another bold type and", "tokens": [50646, 643, 281, 312, 1075, 281, 584, 321, 393, 23273, 666, 490, 257, 11928, 2010, 666, 1071, 11928, 2010, 293, 51002], "temperature": 0.0, "avg_logprob": -0.20421666984098502, "compression_ratio": 1.8969072164948453, "no_speech_prob": 0.0032190445344895124}, {"id": 346, "seek": 175556, "start": 1768.32, "end": 1775.76, "text": " so we have a custom deserialized implementation for bold type that calls the appropriate method", "tokens": [51002, 370, 321, 362, 257, 2375, 730, 260, 831, 1602, 11420, 337, 11928, 2010, 300, 5498, 264, 6854, 3170, 51374], "temperature": 0.0, "avg_logprob": -0.20421666984098502, "compression_ratio": 1.8969072164948453, "no_speech_prob": 0.0032190445344895124}, {"id": 347, "seek": 175556, "start": 1775.76, "end": 1781.9199999999998, "text": " in a way that we know that we get the correct data which is not really that straightforward", "tokens": [51374, 294, 257, 636, 300, 321, 458, 300, 321, 483, 264, 3006, 1412, 597, 307, 406, 534, 300, 15325, 51682], "temperature": 0.0, "avg_logprob": -0.20421666984098502, "compression_ratio": 1.8969072164948453, "no_speech_prob": 0.0032190445344895124}, {"id": 348, "seek": 178192, "start": 1781.92, "end": 1787.24, "text": " at the end result is a deserializer that isn't really usable for any other data format and", "tokens": [50364, 412, 264, 917, 1874, 307, 257, 730, 260, 831, 6545, 300, 1943, 380, 534, 29975, 337, 604, 661, 1412, 7877, 293, 50630], "temperature": 0.0, "avg_logprob": -0.20223670782044875, "compression_ratio": 1.7938144329896908, "no_speech_prob": 0.00220882729627192}, {"id": 349, "seek": 178192, "start": 1787.24, "end": 1791.64, "text": " so if you use that one and then deserialize a bold type into a trace on you get some", "tokens": [50630, 370, 498, 291, 764, 300, 472, 293, 550, 730, 260, 831, 1125, 257, 11928, 2010, 666, 257, 13508, 322, 291, 483, 512, 50850], "temperature": 0.0, "avg_logprob": -0.20223670782044875, "compression_ratio": 1.7938144329896908, "no_speech_prob": 0.00220882729627192}, {"id": 350, "seek": 178192, "start": 1791.64, "end": 1801.44, "text": " trace on but that doesn't really make sense which is unfortunate and then there's there", "tokens": [50850, 13508, 322, 457, 300, 1177, 380, 534, 652, 2020, 597, 307, 17843, 293, 550, 456, 311, 456, 51340], "temperature": 0.0, "avg_logprob": -0.20223670782044875, "compression_ratio": 1.7938144329896908, "no_speech_prob": 0.00220882729627192}, {"id": 351, "seek": 178192, "start": 1801.44, "end": 1808.96, "text": " are things like what if you have more data in your node properties than you actually", "tokens": [51340, 366, 721, 411, 437, 498, 291, 362, 544, 1412, 294, 428, 9984, 7221, 813, 291, 767, 51716], "temperature": 0.0, "avg_logprob": -0.20223670782044875, "compression_ratio": 1.7938144329896908, "no_speech_prob": 0.00220882729627192}, {"id": 352, "seek": 180896, "start": 1809.0, "end": 1815.68, "text": " have in your struct and then usually a data format is expected to be implemented or to be", "tokens": [50366, 362, 294, 428, 6594, 293, 550, 2673, 257, 1412, 7877, 307, 5176, 281, 312, 12270, 420, 281, 312, 50700], "temperature": 0.0, "avg_logprob": -0.19817797342936197, "compression_ratio": 1.7523364485981308, "no_speech_prob": 0.0007550341542810202}, {"id": 353, "seek": 180896, "start": 1815.68, "end": 1824.04, "text": " doing the deserialization while parsing and if you're a imagine you're parsing through some", "tokens": [50700, 884, 264, 730, 260, 831, 2144, 1339, 21156, 278, 293, 498, 291, 434, 257, 3811, 291, 434, 21156, 278, 807, 512, 51118], "temperature": 0.0, "avg_logprob": -0.19817797342936197, "compression_ratio": 1.7523364485981308, "no_speech_prob": 0.0007550341542810202}, {"id": 354, "seek": 180896, "start": 1824.04, "end": 1828.1200000000001, "text": " JSON and you have this key and you give it to the visitor and the visitor says yeah I don't I", "tokens": [51118, 31828, 293, 291, 362, 341, 2141, 293, 291, 976, 309, 281, 264, 28222, 293, 264, 28222, 1619, 1338, 286, 500, 380, 286, 51322], "temperature": 0.0, "avg_logprob": -0.19817797342936197, "compression_ratio": 1.7523364485981308, "no_speech_prob": 0.0007550341542810202}, {"id": 355, "seek": 180896, "start": 1828.1200000000001, "end": 1835.52, "text": " don't I don't need this key it can't just continue and say give me the next key you have to go back", "tokens": [51322, 500, 380, 286, 500, 380, 643, 341, 2141, 309, 393, 380, 445, 2354, 293, 584, 976, 385, 264, 958, 2141, 291, 362, 281, 352, 646, 51692], "temperature": 0.0, "avg_logprob": -0.19817797342936197, "compression_ratio": 1.7523364485981308, "no_speech_prob": 0.0007550341542810202}, {"id": 356, "seek": 183552, "start": 1835.6399999999999, "end": 1842.76, "text": " and say well I don't care about this key but you need to still give me a value so that your", "tokens": [50370, 293, 584, 731, 286, 500, 380, 1127, 466, 341, 2141, 457, 291, 643, 281, 920, 976, 385, 257, 2158, 370, 300, 428, 50726], "temperature": 0.0, "avg_logprob": -0.13228124441559783, "compression_ratio": 1.8502415458937198, "no_speech_prob": 0.022908050566911697}, {"id": 357, "seek": 183552, "start": 1842.76, "end": 1847.2, "text": " parsing state is gonna be correct so that when I call you next you're gonna give me the next key", "tokens": [50726, 21156, 278, 1785, 307, 799, 312, 3006, 370, 300, 562, 286, 818, 291, 958, 291, 434, 799, 976, 385, 264, 958, 2141, 50948], "temperature": 0.0, "avg_logprob": -0.13228124441559783, "compression_ratio": 1.8502415458937198, "no_speech_prob": 0.022908050566911697}, {"id": 358, "seek": 183552, "start": 1847.2, "end": 1857.0, "text": " and this is done by this ignored anything where so you will say give me a next value but I'm gonna", "tokens": [50948, 293, 341, 307, 1096, 538, 341, 19735, 1340, 689, 370, 291, 486, 584, 976, 385, 257, 958, 2158, 457, 286, 478, 799, 51438], "temperature": 0.0, "avg_logprob": -0.13228124441559783, "compression_ratio": 1.8502415458937198, "no_speech_prob": 0.022908050566911697}, {"id": 359, "seek": 183552, "start": 1857.0, "end": 1862.08, "text": " ignore it so you can give me whatever you want just do the right thing on your end so that your", "tokens": [51438, 11200, 309, 370, 291, 393, 976, 385, 2035, 291, 528, 445, 360, 264, 558, 551, 322, 428, 917, 370, 300, 428, 51692], "temperature": 0.0, "avg_logprob": -0.13228124441559783, "compression_ratio": 1.8502415458937198, "no_speech_prob": 0.022908050566911697}, {"id": 360, "seek": 186208, "start": 1862.12, "end": 1869.04, "text": " internal state is correct for us we didn't really need to do anything because we already had everything", "tokens": [50366, 6920, 1785, 307, 3006, 337, 505, 321, 994, 380, 534, 643, 281, 360, 1340, 570, 321, 1217, 632, 1203, 50712], "temperature": 0.0, "avg_logprob": -0.18637974161497303, "compression_ratio": 1.5614973262032086, "no_speech_prob": 0.0014757710741832852}, {"id": 361, "seek": 186208, "start": 1869.04, "end": 1875.8, "text": " fast and it's enum but since we're moving to doing this while parsing as well we need to take", "tokens": [50712, 2370, 293, 309, 311, 465, 449, 457, 1670, 321, 434, 2684, 281, 884, 341, 1339, 21156, 278, 382, 731, 321, 643, 281, 747, 51050], "temperature": 0.0, "avg_logprob": -0.18637974161497303, "compression_ratio": 1.5614973262032086, "no_speech_prob": 0.0014757710741832852}, {"id": 362, "seek": 186208, "start": 1875.8, "end": 1886.6399999999999, "text": " care of that properly then there's the zero copy deserialization we had earlier like oh I want", "tokens": [51050, 1127, 295, 300, 6108, 550, 456, 311, 264, 4018, 5055, 730, 260, 831, 2144, 321, 632, 3071, 411, 1954, 286, 528, 51592], "temperature": 0.0, "avg_logprob": -0.18637974161497303, "compression_ratio": 1.5614973262032086, "no_speech_prob": 0.0014757710741832852}, {"id": 363, "seek": 188664, "start": 1886.68, "end": 1893.44, "text": " zero copies being a red flag so consider the red flag if you will and all this code that I showed", "tokens": [50366, 4018, 14341, 885, 257, 2182, 7166, 370, 1949, 264, 2182, 7166, 498, 291, 486, 293, 439, 341, 3089, 300, 286, 4712, 50704], "temperature": 0.0, "avg_logprob": -0.1801748788484963, "compression_ratio": 1.7762557077625571, "no_speech_prob": 0.021580776199698448}, {"id": 364, "seek": 188664, "start": 1893.44, "end": 1900.6000000000001, "text": " you actually doesn't compile because every trade from 30 has a lifetime around typically called", "tokens": [50704, 291, 767, 1177, 380, 31413, 570, 633, 4923, 490, 2217, 575, 257, 11364, 926, 5850, 1219, 51062], "temperature": 0.0, "avg_logprob": -0.1801748788484963, "compression_ratio": 1.7762557077625571, "no_speech_prob": 0.021580776199698448}, {"id": 365, "seek": 188664, "start": 1900.6000000000001, "end": 1910.2, "text": " take DE for deserialize and also our deserializer for the boat node doesn't actually have doesn't", "tokens": [51062, 747, 10113, 337, 730, 260, 831, 1125, 293, 611, 527, 730, 260, 831, 6545, 337, 264, 6582, 9984, 1177, 380, 767, 362, 1177, 380, 51542], "temperature": 0.0, "avg_logprob": -0.1801748788484963, "compression_ratio": 1.7762557077625571, "no_speech_prob": 0.021580776199698448}, {"id": 366, "seek": 188664, "start": 1910.2, "end": 1915.5600000000002, "text": " own the boat node it has a reference to the boat node and we put lifetimes on everything and then", "tokens": [51542, 1065, 264, 6582, 9984, 309, 575, 257, 6408, 281, 264, 6582, 9984, 293, 321, 829, 4545, 302, 1532, 322, 1203, 293, 550, 51810], "temperature": 0.0, "avg_logprob": -0.1801748788484963, "compression_ratio": 1.7762557077625571, "no_speech_prob": 0.021580776199698448}, {"id": 367, "seek": 191556, "start": 1916.1599999999999, "end": 1921.72, "text": " implement a bunch of methods that say well if you can make the Rust compiler happy with all the", "tokens": [50394, 4445, 257, 3840, 295, 7150, 300, 584, 731, 498, 291, 393, 652, 264, 34952, 31958, 2055, 365, 439, 264, 50672], "temperature": 0.0, "avg_logprob": -0.18541678953706547, "compression_ratio": 1.6977777777777778, "no_speech_prob": 0.0015228460542857647}, {"id": 368, "seek": 191556, "start": 1921.72, "end": 1928.1599999999999, "text": " lifetimes that you're using then we don't need to copy data and so you could do things like", "tokens": [50672, 4545, 302, 1532, 300, 291, 434, 1228, 550, 321, 500, 380, 643, 281, 5055, 1412, 293, 370, 291, 727, 360, 721, 411, 50994], "temperature": 0.0, "avg_logprob": -0.18541678953706547, "compression_ratio": 1.6977777777777778, "no_speech_prob": 0.0015228460542857647}, {"id": 369, "seek": 191556, "start": 1928.1599999999999, "end": 1936.76, "text": " extracting the labels not as a bag of string but bag of stir slices where you would still get an", "tokens": [50994, 49844, 264, 16949, 406, 382, 257, 3411, 295, 6798, 457, 3411, 295, 8946, 19793, 689, 291, 576, 920, 483, 364, 51424], "temperature": 0.0, "avg_logprob": -0.18541678953706547, "compression_ratio": 1.6977777777777778, "no_speech_prob": 0.0015228460542857647}, {"id": 370, "seek": 191556, "start": 1936.76, "end": 1943.36, "text": " allocation for the back but the strings would point into the actual data from the boat node thing", "tokens": [51424, 27599, 337, 264, 646, 457, 264, 13985, 576, 935, 666, 264, 3539, 1412, 490, 264, 6582, 9984, 551, 51754], "temperature": 0.0, "avg_logprob": -0.18541678953706547, "compression_ratio": 1.6977777777777778, "no_speech_prob": 0.0015228460542857647}, {"id": 371, "seek": 194336, "start": 1943.9599999999998, "end": 1953.28, "text": " and we do that for how long we can do that but it's it's it was too much to show it in all", "tokens": [50394, 293, 321, 360, 300, 337, 577, 938, 321, 393, 360, 300, 457, 309, 311, 309, 311, 309, 390, 886, 709, 281, 855, 309, 294, 439, 50860], "temperature": 0.0, "avg_logprob": -0.21010807844308707, "compression_ratio": 1.4803149606299213, "no_speech_prob": 0.006606410723179579}, {"id": 372, "seek": 194336, "start": 1953.28, "end": 1961.24, "text": " the slides and yeah with that I am done and I think we still have time for questions if there are", "tokens": [50860, 264, 9788, 293, 1338, 365, 300, 286, 669, 1096, 293, 286, 519, 321, 920, 362, 565, 337, 1651, 498, 456, 366, 51258], "temperature": 0.0, "avg_logprob": -0.21010807844308707, "compression_ratio": 1.4803149606299213, "no_speech_prob": 0.006606410723179579}, {"id": 373, "seek": 196124, "start": 1961.24, "end": 1983.16, "text": " any otherwise yeah thanks for listening questions questions no questions no questions I do have", "tokens": [50364, 604, 5911, 1338, 3231, 337, 4764, 1651, 1651, 572, 1651, 572, 1651, 286, 360, 362, 51460], "temperature": 0.0, "avg_logprob": -0.3618435859680176, "compression_ratio": 1.4179104477611941, "no_speech_prob": 0.029974455013871193}, {"id": 374, "seek": 198316, "start": 1983.16, "end": 1990.68, "text": " one maybe just a short one you were mentioning like deserializing the bytes before when you say", "tokens": [50364, 472, 1310, 445, 257, 2099, 472, 291, 645, 18315, 411, 730, 260, 831, 3319, 264, 36088, 949, 562, 291, 584, 50740], "temperature": 0.0, "avg_logprob": -0.22181197718570106, "compression_ratio": 1.7330316742081449, "no_speech_prob": 0.3203338086605072}, {"id": 375, "seek": 198316, "start": 1990.68, "end": 2000.68, "text": " bytes do you mean like a vector of u8 or like the bytes crates or both actually that primarily a", "tokens": [50740, 36088, 360, 291, 914, 411, 257, 8062, 295, 344, 23, 420, 411, 264, 36088, 941, 1024, 420, 1293, 767, 300, 10029, 257, 51240], "temperature": 0.0, "avg_logprob": -0.22181197718570106, "compression_ratio": 1.7330316742081449, "no_speech_prob": 0.3203338086605072}, {"id": 376, "seek": 198316, "start": 2000.68, "end": 2007.68, "text": " back of u8 because that's what we have in a standard library but I think we also have a test", "tokens": [51240, 646, 295, 344, 23, 570, 300, 311, 437, 321, 362, 294, 257, 3832, 6405, 457, 286, 519, 321, 611, 362, 257, 1500, 51590], "temperature": 0.0, "avg_logprob": -0.22181197718570106, "compression_ratio": 1.7330316742081449, "no_speech_prob": 0.3203338086605072}, {"id": 377, "seek": 198316, "start": 2007.68, "end": 2012.44, "text": " that makes sure that it works with the bytes type from the bytes grid so I think you can use that", "tokens": [51590, 300, 1669, 988, 300, 309, 1985, 365, 264, 36088, 2010, 490, 264, 36088, 10748, 370, 286, 519, 291, 393, 764, 300, 51828], "temperature": 0.0, "avg_logprob": -0.22181197718570106, "compression_ratio": 1.7330316742081449, "no_speech_prob": 0.3203338086605072}, {"id": 378, "seek": 201244, "start": 2012.44, "end": 2023.04, "text": " one as well okay then I think that's it for the day thank you the speaker thank you to the whole", "tokens": [50364, 472, 382, 731, 1392, 550, 286, 519, 300, 311, 309, 337, 264, 786, 1309, 291, 264, 8145, 1309, 291, 281, 264, 1379, 50894], "temperature": 0.0, "avg_logprob": -0.2908163351171157, "compression_ratio": 1.3636363636363635, "no_speech_prob": 0.02737831324338913}, {"id": 379, "seek": 201244, "start": 2023.04, "end": 2026.3600000000001, "text": " audience for staying with us next year", "tokens": [50894, 4034, 337, 7939, 365, 505, 958, 1064, 51060], "temperature": 0.0, "avg_logprob": -0.2908163351171157, "compression_ratio": 1.3636363636363635, "no_speech_prob": 0.02737831324338913}], "language": "en"}