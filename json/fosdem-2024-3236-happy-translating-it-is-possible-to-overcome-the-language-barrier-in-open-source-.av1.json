{"text": " Language barrier and open source. Here's my biology. I'm an open source advocate, educated, in-through asset, e-commerce and e-commerce practitioner. In recent years, last year, I switched my direction to the e-commerce. I'm also a patch open meetings contributor. I joined the project in 2012, so I got about many years experience. I'm also an interpreter and translator for some largest China's open source communities. I'm a member of Microsoft for startup founders in China. Also, I'm a founder of omoforce.com and www.omoforce.com. Last year, I was very honored to be a patchy community coach and a Force Asia conference speaker. So today, first, I'm going to introduce a little bit about my translation experience. First thing, I'll share you some experience and lessons we learned from the New York's open source Congress report, 2023, and open source initiatives, deep dive AS series, which those two projects we finished last year. Then I'll talk a little bit about the team build strategy. Finally, I want to show you a patch open meetings website translation. So here comes to my translation experience. Back two months ago, 2002, when I worked in college, I taught course like in ABUK courses. For example, information system analysis and design and also data structure. We used English textbooks for students, but to help students to better understand the concept, we use Chinese translation course materials. And then late in year 2011, I was Oracle offshore outsourcing project manager in China for an Alcon logic development, Alcon logic clinical trial study management platform. I was a project manager. We translate like a source, emails, testing, package, delivery, everything. So for one year, then I joined a patch open meetings team, I translated a website into Chinese and promote the website, promote the project in China. In recent years, most of my translation experience related to Kai Yuan Shou. That's probably somebody you never heard of, but in China is a famous open source community. We have each year, we have open source conference in China called Coastcom. And we got a lot of communication and cooperation with the Patch and the Neelix Foundation. So in year 2018, I was an interpreter for the Patch and the Sofa Foundation speakers for Coastcom, China. And in 2021, I gave my first talk in how to integrate AFDAP and AD with the Patch Open Meetings. In 2022, I was a translator for China Open Source Report. And last year, I mentioned before, right, in FOSA Asia and the Community Code over China for the role-based access control mechanism by unifying AD, Neelix and Patch Open Meetings. So in English session and the Chinese session. For the 2023 China Open Source Report, I was a translator. And last year, around November and December, I was involved in Open Source Congress Report reviewer and also a translator and a reviewer for OSI Deep Dive AS sessions, which is a video captioning project. So here I just got some images, photos. This is my first visit to Europe. This is my second time. And this is Coastcom 2018 in China. Those speakers from Patch. The interesting thing is, after five years, last year in Beijing, I fortunately met these two gentlemen again five years later. We made friends, right? But you can see the change after five years, all hair turned gray. Okay, this is the talk in the virtual, my first talk in the Open Source community, how to integrate FDAP and Active Directory with Patch Open Meetings. At that time, I was the personal former member of Kaiyuan City. This is last year, the FOSA Asia. We got both here right at the second floor and that's in Singapore. We have a group of Chinese developers from different cities in China like Shanghai, Beijing, Chengdu, Changsha. And also is a Japanese guy from Japan. We have a second group to the meeting. This is last year, a committee of code in China, in Beijing. See many Chinese developers, commuters. And I also gave a talk in the integration check. For Open Source Congress report, 2023, the title of the report is Standing Together on Shared Challenges. Report on the Open Source Congress. Probably somebody here, maybe you read the English or other versions reported, right? But in China, we are absolutely very honored to be part of the group. We do the translation work. The project created on November 17th, project complete on January 12th, 2024. The whole report length is 34 pages. We got six translators, two reviewers. We divide the task into six subtexts, including infographics. We use AI assistant such as DPL, CloudIn, ChagBt, Co-Panel, Google Documents to help us to facilitate translation. Usually, we use like a Google, Google translate to do translation. But when we compare the result, we find that Google translate is not accurate as DPL. So we just use the AI tool to help us. We labeled the whole translation process in different stages, like in-process, like translated, like reviewed. So each team member, okay, each team member, you can look at the labels, okay, got it. If the former process finishes, then I can start my process. The initial translation finished on December 2nd. And then we start our first round of QA and the second round of QA and final review. So left side, the English version front page, and the right side is Chinese version front page. Here is six subtexts, and here is my nickname. So I reviewed the two parts. So for the infographics, we know in the translation, for text translation, it's comparably easy, right? But for the image translation, we need to use more time. For example, we speed the infographics, there's 12 images, we speed it and get one of them, and we use the Google translator to get the Chinese version. But you can see the title and the content is unreadable, right? It's too small. So we just use, clean everything out and use Photoshop to add the content. So finally, we combined the 12 images together to get the infographics. Can you see? Sorry, it's not very clearly. Left side is the content of English version, and the right side is the content table in Chinese version. You can see the page number here. The English version is 28 pages. In Chinese version, it's 20 pages, which means after the translation, the five sides shrink. Just I only got two thirds of the source file. So here comes the lessons I learned. Original paper has some quotes, which some experts, some leaders, they say something, right? But the translation has some discrepancies, so we need a final review. After we send the paper to the latest foundation, they say, okay, we got some discrepancies. You guys need to pay attention. You need to have a final review. So when we check these discrepancies, we need to keep constantly looking at the content discrepancies. We need to keep consistency and one format, otherwise it would cause confusion. Because we are sending tasks based on the source file in Google documents, but the discrepancies exist in the target PDF files we send to the latest foundation, right? Okay, then we identify how many book codes and in which part of the paper so the corresponding translators will be able to check the codes. Because of the five sides shrink adjustment, right? And in PDF format, we got two column format. So talk to the file page number, it's different from source file page number. So if we didn't keep consistency on source file, then we got confused. This happened in the communication process. Okay, we found this postcode. Who did this? Nobody knows because when we check the PDF format, I didn't do this, I didn't do this, right? So the final solution is the leader, the leader of the project, he took all the responsibility. He checked all the protocols and the translated by himself. After we send the paper to the latest foundation, they used us some badges for just four. I'm very happy to get this for the recognition. For Year 2023 OSI DeepDive AI sessions, this is a video caption project. Project created on November 7th and the project will be completed on February 14th, which means we're still in the process. Total, there are 17 sessions. We had 10 translators in two groups. Only have two reviews. So we follow the steps. First, we use the raw video material to get the scripts. And then we check each word and the sentences by translating ears. We also use like TPL, charge PTE, quite easy, GNY. This is a Chinese automatic translation platform and YouTube to help us. We also put the status in translation translated in review under reviewed to identify the progress of each process. The initial translation finished on December 2nd. Then we immediately started the first round QA, round QA and final review. Then we have the second group to help us to publish in different social media like in WeChat as a web pop in China and also in Facebook and Twitter and YouTube. Sorry, it's too small. See the 17 sessions and we are forcited the publishing process. We subgrouped the 17 sessions into different groups. We got three groups. First one is open risk and challenge. And the second one is governance. And the last one is the fireside track. So for each group, we also got some subgroups. For the year about which are the sessions, I either reviewed or be a translator. I am the reviewer. So you can see it's almost half of the sessions. So this is project management system in Chinese. That's my role. So you can see the yellow bar is my role. And here the arrows pointed to the different process. First one that means reviewed. And this one means in translation. So we can identify the process because the team members, we will work together and work on different cities. Okay, here comes the lessons I learned. We need to check subtitles versus warriors to make sure every word matched. It is very time consuming. For the video session, usually like if it is 30 minute session, we usually take about 10 or more than 10 times time for a 30 minute session. We need like 6 or 7 hours for the check. Because subtitle has 120 character length restriction for bad audience sense of reading. So we need to split every sentence, longer than 120 characters into small parts and also split the subtitle time frame. The split caused some subtitles didn't show up because the time frame didn't match. So we need to listen every word very carefully and adjust the corresponding time frame into secondary seconds, which is 100 seconds. So it's a time consuming. Especially when some adjectives and longer sentences come up, we need to adjust the front and back word time frames next to get perfect effects. Here are some links of some published sessions. See Facebook, Twitter and let's we check. Team build the strategy. Right now we have more than 50 translators. Most of them come from universities, some students in Europe. So team leaders recruit some new translators from various sources, companies, universities. Then new translators will introduce to team members. Every member assigns the workload by identifying tasks by one theory. So you can just okay when the project comes up, you just pick whatever task you want to get involved with. Then we have basic benchmark scoring system, student trial period to record every member's performance. For the benefits, we each code tokens for technique on the long technical contributors. For those team members who have good performance, we grant them the privilege to use community resources such as DPL and the crowdfunding platform. Community also provided the chances to team members as a voluntary for each year's conference. And the students can also add the voluntary experience to resume. So here is the code K token system. But that's in Chinese. Upside is for technical translators. Low side is for non-technical translators. We got like ABC three different kinds of tokens. You use the tokens, you can to cooperate with open source community for different kinds of like Hexen, like different kinds of events. You can join the events. Here is the basic benchmark system. We have a different contribution type like principal, helper, consultant, informer. For each different role, we have basic score weight. So the benchmark score value is 10. So after you just use the score value 10 times by score weight, you get the basic score for different roles. Then here is the task management system for the team members you join the project. We use the system to calculate the contribution score. Finally, we sum up all the scores of your contributions. You can see on the top one is my name. I got 51. So they grant me some privilege. I can use the crowdfunding, I can use DPL. Some AI translation tools help me. Okay, here's my Apache Open Meetings Translation. Apache Open Meetings, may I ask, have anybody heard about the project or used the project before? Never have I heard? Okay, this online video conference system. Originally, it is from European. It is Apache project. It is only fully web browser based open source video conference system. No need to download apps, no need client-side installation. You can create a middle server for remote collaboration. The server can be installed either locally or via container. But I recommend use locally because if you're not very familiar with container, in the installation or in the configuration process, probably you've got to trouble, right? Sometimes, you know, if you do not do the commit, you probably will lose the original configuration data. Usually, we need to install the server behind the term server for NAT configuration for the whole function. Otherwise, you cannot use system. The system supports multi-language. The latest version now is 7.2.0. It supports 39 different languages. So, for the translation website, we cannot use just like Google Translators. You can use Google Translators for static website. But that's interactive, right? It's an interactive website. We've got actions. We've got scripts. So, you can only use the original, use the building framework to change the language. So, you need to change the labels and text strings. All language strings should be localized and stored in the language section. You have full future language editor with every installation of open meetings. So, you need to check out the language editor to look up the label IDs in the GUI. Just you need to run the open meetings client with the debug model. You cannot use the deploying model. The way every text string has label ID in places additionally in the text field. Later on, I'm going to show you the difference between the deploying model and the debug model. Sorry, this one. So, the upside image is the original language, this configuration file in Chinese. So, okay, when I first started, this is the one issue I found. I sent the issue to the JIRA for Apache. So, I said, okay, this configuration file didn't work. Some labels didn't get translated. They said, okay, you can do translation and you can send the file to the JIRA and we're going to update the source. See, can you see the difference between the first image and the second image? There is one actual space, right? You can see here, braces, the number braces, but upside means braces, space, braces. So, they used the file compare, found this problem and send emails to the group, to the email list. There is an issue in Chinese translation, actual space characters. So, that's not the lesson I learned, which means for the translation file, you cannot change anything except the translated content. You cannot even add one more space. Okay, I almost finished my presentation and there is some time left and I'm going to show very quickly about the debug model and the debug model. So, here is my contact information and my emails. This is my website. Okay, excuse me. I used that mean log in system. This is already Chinese version because we set the added profile here. I already set the language in Chinese, set time zone in Asian Singapore, but here you cannot see every label. There is no label ID, right? No label ID. So, how can I bring out the label ID? Because if you want to change, if you have no label ID, okay, let me bring back to English so you can read it. So, current password request. Okay, we'll change. Every time you change the language configuration, it will take effect immediately after you log in and log out again. So now you can see the interface already changed to English, right? But for each label, like if I wanted to do translation, so if you don't know the label ID, you need the Geltron Language Editor, you need find the corresponding language file, which is... We got a language configuration file here. So you can see total is 39 different language files, right? For example, for Chinese, that's 11. And also you can change it to French or to Dutch. So for example, if I want to change like a project website, right? If you want to rebranding or to do something, if you want to change this one, if you have no label ID, you got to remember the text ID. So go to the language editor, go to the... Then you need the remember. I remember because I test many times, I remember the label ID. It's 282, so you can change it here, right? Okay, then let's see the deploying model. Oh, so... There is a configuration file, WIPER.xml here, so you need to go to your WIPER.xml, then you search the deploying model. You can see that's a deploying model. You need to change the deploying to the development model. To deploy model, now the added command... Oh, sorry, small case. Okay. Now you can see we change it, right? Change and then... Come out, then restart the server. Okay. We restart the server, then... I need to... I need to make sure the server is start up. Okay, so we start. Then I used admin to login again. You only need to be slow. Let's sort install the virtual machine, so all the memory is already exhausted, almost exhausted, so you only need to be slow, sorry. Do the thing. Sorry. Some bad things happened. Okay, now you can see this is in the DIPWIPER model. See, from here you can see each text label, you got a label ID, right? So if you want to change the label, you just go to your language editor, find the label ID number, change it, then you can get a different version. Okay, thanks. I finished my presentation. If you got any questions, I would be more than happy to answer. Thank you. So translating the open source report, what was the format of the files that you used as a translator? Was it Google Docs, was it PO, was it actually for what you used in which format? For the source file, we upload the file to the Google Documents, and each team members, if you want to identify which part you want to translate, you just label, select text and say, okay, this part I'm going to do it. So the translator works directly in the Google Docs? Yeah, yeah, yeah. Translate it, we got no problem to access the Google Documents because almost everybody we use the VPN, you know. Good question. Thanks. You have some way to detect space issues or using the maybe double width character instead of the format character, the spaces? Yeah, for the spaces, I'm not 100% sure how the project leader he found the spaces, but I know some guys, they use the file compression. Like in VSS Studio, there is a file compression function. You can use the file compression to compare the source file and the translation file to find the extra space. Yeah, I don't appreciate it. Do you use translation memory to speed up your translation process? Excuse me? Can you repeat the question again? Do you use translation memory to speed up your translation process? When you have a good question, I guess the translation memory is the crowding function. Crowding, you use such kind of translation memory, right? Yeah, we use translation memory. That's the building function. And we also use machine translation, which is AI tools such as child GPT or Microsoft translator, which do the integration with the platform. Thank you. Thank you very much. Thanks. Thank you. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 7.0, "text": " Language barrier and open source.", "tokens": [50364, 24445, 13357, 293, 1269, 4009, 13, 50714], "temperature": 0.0, "avg_logprob": -0.4614919835870916, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.42836204171180725}, {"id": 1, "seek": 0, "start": 7.0, "end": 19.6, "text": " Here's my biology. I'm an open source advocate, educated, in-through asset, e-commerce and", "tokens": [50714, 1692, 311, 452, 14956, 13, 286, 478, 364, 1269, 4009, 14608, 11, 15872, 11, 294, 12, 11529, 11999, 11, 308, 12, 26926, 293, 51344], "temperature": 0.0, "avg_logprob": -0.4614919835870916, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.42836204171180725}, {"id": 2, "seek": 0, "start": 19.6, "end": 25.560000000000002, "text": " e-commerce practitioner. In recent years, last year, I switched my direction to the", "tokens": [51344, 308, 12, 26926, 32125, 13, 682, 5162, 924, 11, 1036, 1064, 11, 286, 16858, 452, 3513, 281, 264, 51642], "temperature": 0.0, "avg_logprob": -0.4614919835870916, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.42836204171180725}, {"id": 3, "seek": 2556, "start": 25.56, "end": 36.8, "text": " e-commerce. I'm also a patch open meetings contributor. I joined the project in 2012,", "tokens": [50364, 308, 12, 26926, 13, 286, 478, 611, 257, 9972, 1269, 8410, 42859, 13, 286, 6869, 264, 1716, 294, 9125, 11, 50926], "temperature": 0.0, "avg_logprob": -0.25442475178202645, "compression_ratio": 1.446927374301676, "no_speech_prob": 0.14845922589302063}, {"id": 4, "seek": 2556, "start": 36.8, "end": 43.16, "text": " so I got about many years experience. I'm also an interpreter and translator for some", "tokens": [50926, 370, 286, 658, 466, 867, 924, 1752, 13, 286, 478, 611, 364, 34132, 293, 35223, 337, 512, 51244], "temperature": 0.0, "avg_logprob": -0.25442475178202645, "compression_ratio": 1.446927374301676, "no_speech_prob": 0.14845922589302063}, {"id": 5, "seek": 2556, "start": 43.16, "end": 50.84, "text": " largest China's open source communities. I'm a member of Microsoft for startup founders", "tokens": [51244, 6443, 3533, 311, 1269, 4009, 4456, 13, 286, 478, 257, 4006, 295, 8116, 337, 18578, 25608, 51628], "temperature": 0.0, "avg_logprob": -0.25442475178202645, "compression_ratio": 1.446927374301676, "no_speech_prob": 0.14845922589302063}, {"id": 6, "seek": 5084, "start": 50.84, "end": 62.440000000000005, "text": " in China. Also, I'm a founder of omoforce.com and www.omoforce.com. Last year, I was very", "tokens": [50364, 294, 3533, 13, 2743, 11, 286, 478, 257, 14917, 295, 3406, 2670, 284, 384, 13, 1112, 293, 12520, 13, 298, 2670, 284, 384, 13, 1112, 13, 5264, 1064, 11, 286, 390, 588, 50944], "temperature": 0.0, "avg_logprob": -0.3647530176868177, "compression_ratio": 1.4022346368715084, "no_speech_prob": 0.08838507533073425}, {"id": 7, "seek": 5084, "start": 62.440000000000005, "end": 71.28, "text": " honored to be a patchy community coach and a Force Asia conference speaker.", "tokens": [50944, 14556, 281, 312, 257, 9972, 88, 1768, 6560, 293, 257, 10580, 10038, 7586, 8145, 13, 51386], "temperature": 0.0, "avg_logprob": -0.3647530176868177, "compression_ratio": 1.4022346368715084, "no_speech_prob": 0.08838507533073425}, {"id": 8, "seek": 5084, "start": 71.28, "end": 77.76, "text": " So today, first, I'm going to introduce a little bit about my translation experience.", "tokens": [51386, 407, 965, 11, 700, 11, 286, 478, 516, 281, 5366, 257, 707, 857, 466, 452, 12853, 1752, 13, 51710], "temperature": 0.0, "avg_logprob": -0.3647530176868177, "compression_ratio": 1.4022346368715084, "no_speech_prob": 0.08838507533073425}, {"id": 9, "seek": 7776, "start": 77.76, "end": 83.92, "text": " First thing, I'll share you some experience and lessons we learned from the New York's", "tokens": [50364, 2386, 551, 11, 286, 603, 2073, 291, 512, 1752, 293, 8820, 321, 3264, 490, 264, 1873, 3609, 311, 50672], "temperature": 0.0, "avg_logprob": -0.4034493057816117, "compression_ratio": 1.4663865546218486, "no_speech_prob": 0.13633573055267334}, {"id": 10, "seek": 7776, "start": 83.92, "end": 92.08000000000001, "text": " open source Congress report, 2023, and open source initiatives, deep dive AS series, which", "tokens": [50672, 1269, 4009, 6426, 2275, 11, 44377, 11, 293, 1269, 4009, 16194, 11, 2452, 9192, 7469, 2638, 11, 597, 51080], "temperature": 0.0, "avg_logprob": -0.4034493057816117, "compression_ratio": 1.4663865546218486, "no_speech_prob": 0.13633573055267334}, {"id": 11, "seek": 7776, "start": 92.08000000000001, "end": 97.88000000000001, "text": " those two projects we finished last year. Then I'll talk a little bit about the team", "tokens": [51080, 729, 732, 4455, 321, 4335, 1036, 1064, 13, 1396, 286, 603, 751, 257, 707, 857, 466, 264, 1469, 51370], "temperature": 0.0, "avg_logprob": -0.4034493057816117, "compression_ratio": 1.4663865546218486, "no_speech_prob": 0.13633573055267334}, {"id": 12, "seek": 7776, "start": 97.88000000000001, "end": 104.56, "text": " build strategy. Finally, I want to show you a patch open meetings website translation.", "tokens": [51370, 1322, 5206, 13, 6288, 11, 286, 528, 281, 855, 291, 257, 9972, 1269, 8410, 3144, 12853, 13, 51704], "temperature": 0.0, "avg_logprob": -0.4034493057816117, "compression_ratio": 1.4663865546218486, "no_speech_prob": 0.13633573055267334}, {"id": 13, "seek": 10456, "start": 104.56, "end": 120.16, "text": " So here comes to my translation experience. Back two months ago, 2002, when I worked in", "tokens": [50364, 407, 510, 1487, 281, 452, 12853, 1752, 13, 5833, 732, 2493, 2057, 11, 17822, 11, 562, 286, 2732, 294, 51144], "temperature": 0.0, "avg_logprob": -0.37084848230535333, "compression_ratio": 1.2605633802816902, "no_speech_prob": 0.026325851678848267}, {"id": 14, "seek": 10456, "start": 120.16, "end": 128.76, "text": " college, I taught course like in ABUK courses. For example, information system analysis and", "tokens": [51144, 3859, 11, 286, 5928, 1164, 411, 294, 13838, 52, 42, 7712, 13, 1171, 1365, 11, 1589, 1185, 5215, 293, 51574], "temperature": 0.0, "avg_logprob": -0.37084848230535333, "compression_ratio": 1.2605633802816902, "no_speech_prob": 0.026325851678848267}, {"id": 15, "seek": 12876, "start": 128.76, "end": 138.56, "text": " design and also data structure. We used English textbooks for students, but to help students", "tokens": [50364, 1715, 293, 611, 1412, 3877, 13, 492, 1143, 3669, 33587, 337, 1731, 11, 457, 281, 854, 1731, 50854], "temperature": 0.0, "avg_logprob": -0.30423089436122347, "compression_ratio": 1.423913043478261, "no_speech_prob": 0.6291411519050598}, {"id": 16, "seek": 12876, "start": 138.56, "end": 145.68, "text": " to better understand the concept, we use Chinese translation course materials.", "tokens": [50854, 281, 1101, 1223, 264, 3410, 11, 321, 764, 4649, 12853, 1164, 5319, 13, 51210], "temperature": 0.0, "avg_logprob": -0.30423089436122347, "compression_ratio": 1.423913043478261, "no_speech_prob": 0.6291411519050598}, {"id": 17, "seek": 12876, "start": 145.68, "end": 156.44, "text": " And then late in year 2011, I was Oracle offshore outsourcing project manager in China for", "tokens": [51210, 400, 550, 3469, 294, 1064, 10154, 11, 286, 390, 25654, 34567, 14758, 41849, 1716, 6598, 294, 3533, 337, 51748], "temperature": 0.0, "avg_logprob": -0.30423089436122347, "compression_ratio": 1.423913043478261, "no_speech_prob": 0.6291411519050598}, {"id": 18, "seek": 15644, "start": 156.44, "end": 165.35999999999999, "text": " an Alcon logic development, Alcon logic clinical trial study management platform. I was a project", "tokens": [50364, 364, 967, 1671, 9952, 3250, 11, 967, 1671, 9952, 9115, 7308, 2979, 4592, 3663, 13, 286, 390, 257, 1716, 50810], "temperature": 0.0, "avg_logprob": -0.48576607337364786, "compression_ratio": 1.489247311827957, "no_speech_prob": 0.13332189619541168}, {"id": 19, "seek": 15644, "start": 165.35999999999999, "end": 171.0, "text": " manager. We translate like a source, emails, testing, package, delivery, everything. So", "tokens": [50810, 6598, 13, 492, 13799, 411, 257, 4009, 11, 12524, 11, 4997, 11, 7372, 11, 8982, 11, 1203, 13, 407, 51092], "temperature": 0.0, "avg_logprob": -0.48576607337364786, "compression_ratio": 1.489247311827957, "no_speech_prob": 0.13332189619541168}, {"id": 20, "seek": 15644, "start": 171.0, "end": 180.2, "text": " for one year, then I joined a patch open meetings team, I translated a website into Chinese", "tokens": [51092, 337, 472, 1064, 11, 550, 286, 6869, 257, 9972, 1269, 8410, 1469, 11, 286, 16805, 257, 3144, 666, 4649, 51552], "temperature": 0.0, "avg_logprob": -0.48576607337364786, "compression_ratio": 1.489247311827957, "no_speech_prob": 0.13332189619541168}, {"id": 21, "seek": 18020, "start": 180.2, "end": 190.76, "text": " and promote the website, promote the project in China. In recent years, most of my translation", "tokens": [50364, 293, 9773, 264, 3144, 11, 9773, 264, 1716, 294, 3533, 13, 682, 5162, 924, 11, 881, 295, 452, 12853, 50892], "temperature": 0.0, "avg_logprob": -0.31639397144317627, "compression_ratio": 1.4972677595628416, "no_speech_prob": 0.23978985846042633}, {"id": 22, "seek": 18020, "start": 190.76, "end": 197.76, "text": " experience related to Kai Yuan Shou. That's probably somebody you never heard of, but", "tokens": [50892, 1752, 4077, 281, 20753, 22730, 1160, 263, 13, 663, 311, 1391, 2618, 291, 1128, 2198, 295, 11, 457, 51242], "temperature": 0.0, "avg_logprob": -0.31639397144317627, "compression_ratio": 1.4972677595628416, "no_speech_prob": 0.23978985846042633}, {"id": 23, "seek": 18020, "start": 197.76, "end": 205.39999999999998, "text": " in China is a famous open source community. We have each year, we have open source conference", "tokens": [51242, 294, 3533, 307, 257, 4618, 1269, 4009, 1768, 13, 492, 362, 1184, 1064, 11, 321, 362, 1269, 4009, 7586, 51624], "temperature": 0.0, "avg_logprob": -0.31639397144317627, "compression_ratio": 1.4972677595628416, "no_speech_prob": 0.23978985846042633}, {"id": 24, "seek": 20540, "start": 205.4, "end": 213.92000000000002, "text": " in China called Coastcom. And we got a lot of communication and cooperation with the", "tokens": [50364, 294, 3533, 1219, 14960, 1112, 13, 400, 321, 658, 257, 688, 295, 6101, 293, 14968, 365, 264, 50790], "temperature": 0.0, "avg_logprob": -0.4558652940687242, "compression_ratio": 1.6036866359447004, "no_speech_prob": 0.47575563192367554}, {"id": 25, "seek": 20540, "start": 213.92000000000002, "end": 220.88, "text": " Patch and the Neelix Foundation. So in year 2018, I was an interpreter for the Patch and", "tokens": [50790, 44359, 293, 264, 1734, 338, 970, 10335, 13, 407, 294, 1064, 6096, 11, 286, 390, 364, 34132, 337, 264, 44359, 293, 51138], "temperature": 0.0, "avg_logprob": -0.4558652940687242, "compression_ratio": 1.6036866359447004, "no_speech_prob": 0.47575563192367554}, {"id": 26, "seek": 20540, "start": 220.88, "end": 228.64000000000001, "text": " the Sofa Foundation speakers for Coastcom, China. And in 2021, I gave my first talk in", "tokens": [51138, 264, 407, 11771, 10335, 9518, 337, 14960, 1112, 11, 3533, 13, 400, 294, 7201, 11, 286, 2729, 452, 700, 751, 294, 51526], "temperature": 0.0, "avg_logprob": -0.4558652940687242, "compression_ratio": 1.6036866359447004, "no_speech_prob": 0.47575563192367554}, {"id": 27, "seek": 20540, "start": 228.64000000000001, "end": 235.0, "text": " how to integrate AFDAP and AD with the Patch Open Meetings. In 2022, I was a translator", "tokens": [51526, 577, 281, 13365, 20389, 35, 4715, 293, 9135, 365, 264, 44359, 7238, 22963, 1109, 13, 682, 20229, 11, 286, 390, 257, 35223, 51844], "temperature": 0.0, "avg_logprob": -0.4558652940687242, "compression_ratio": 1.6036866359447004, "no_speech_prob": 0.47575563192367554}, {"id": 28, "seek": 23500, "start": 235.04, "end": 242.4, "text": " for China Open Source Report. And last year, I mentioned before, right, in FOSA Asia and", "tokens": [50366, 337, 3533, 7238, 29629, 16057, 13, 400, 1036, 1064, 11, 286, 2835, 949, 11, 558, 11, 294, 479, 4367, 32, 10038, 293, 50734], "temperature": 0.0, "avg_logprob": -0.35937042236328126, "compression_ratio": 1.422680412371134, "no_speech_prob": 0.061382897198200226}, {"id": 29, "seek": 23500, "start": 242.4, "end": 249.0, "text": " the Community Code over China for the role-based access control mechanism by unifying AD, Neelix", "tokens": [50734, 264, 10421, 15549, 670, 3533, 337, 264, 3090, 12, 6032, 2105, 1969, 7513, 538, 517, 5489, 9135, 11, 1734, 338, 970, 51064], "temperature": 0.0, "avg_logprob": -0.35937042236328126, "compression_ratio": 1.422680412371134, "no_speech_prob": 0.061382897198200226}, {"id": 30, "seek": 23500, "start": 249.0, "end": 258.92, "text": " and Patch Open Meetings. So in English session and the Chinese session. For the 2023 China", "tokens": [51064, 293, 44359, 7238, 22963, 1109, 13, 407, 294, 3669, 5481, 293, 264, 4649, 5481, 13, 1171, 264, 44377, 3533, 51560], "temperature": 0.0, "avg_logprob": -0.35937042236328126, "compression_ratio": 1.422680412371134, "no_speech_prob": 0.061382897198200226}, {"id": 31, "seek": 25892, "start": 258.92, "end": 267.88, "text": " Open Source Report, I was a translator. And last year, around November and December, I", "tokens": [50364, 7238, 29629, 16057, 11, 286, 390, 257, 35223, 13, 400, 1036, 1064, 11, 926, 7674, 293, 7687, 11, 286, 50812], "temperature": 0.0, "avg_logprob": -0.31122628966374183, "compression_ratio": 1.5141242937853108, "no_speech_prob": 0.13141566514968872}, {"id": 32, "seek": 25892, "start": 267.88, "end": 273.64000000000004, "text": " was involved in Open Source Congress Report reviewer and also a translator and a reviewer", "tokens": [50812, 390, 3288, 294, 7238, 29629, 6426, 16057, 3131, 260, 293, 611, 257, 35223, 293, 257, 3131, 260, 51100], "temperature": 0.0, "avg_logprob": -0.31122628966374183, "compression_ratio": 1.5141242937853108, "no_speech_prob": 0.13141566514968872}, {"id": 33, "seek": 25892, "start": 273.64000000000004, "end": 284.88, "text": " for OSI Deep Dive AS sessions, which is a video captioning project. So here I just got some", "tokens": [51100, 337, 12731, 40, 14895, 413, 488, 7469, 11081, 11, 597, 307, 257, 960, 31974, 278, 1716, 13, 407, 510, 286, 445, 658, 512, 51662], "temperature": 0.0, "avg_logprob": -0.31122628966374183, "compression_ratio": 1.5141242937853108, "no_speech_prob": 0.13141566514968872}, {"id": 34, "seek": 28488, "start": 284.88, "end": 301.56, "text": " images, photos. This is my first visit to Europe. This is my second time. And this is", "tokens": [50364, 5267, 11, 5787, 13, 639, 307, 452, 700, 3441, 281, 3315, 13, 639, 307, 452, 1150, 565, 13, 400, 341, 307, 51198], "temperature": 0.0, "avg_logprob": -0.3665610843234592, "compression_ratio": 1.3206106870229009, "no_speech_prob": 0.14476296305656433}, {"id": 35, "seek": 28488, "start": 301.56, "end": 311.08, "text": " Coastcom 2018 in China. Those speakers from Patch. The interesting thing is, after five", "tokens": [51198, 14960, 1112, 6096, 294, 3533, 13, 3950, 9518, 490, 44359, 13, 440, 1880, 551, 307, 11, 934, 1732, 51674], "temperature": 0.0, "avg_logprob": -0.3665610843234592, "compression_ratio": 1.3206106870229009, "no_speech_prob": 0.14476296305656433}, {"id": 36, "seek": 31108, "start": 311.15999999999997, "end": 317.47999999999996, "text": " years, last year in Beijing, I fortunately met these two gentlemen again five years later.", "tokens": [50368, 924, 11, 1036, 1064, 294, 20240, 11, 286, 25511, 1131, 613, 732, 11669, 797, 1732, 924, 1780, 13, 50684], "temperature": 0.0, "avg_logprob": -0.34889674909187085, "compression_ratio": 1.4505494505494505, "no_speech_prob": 0.18184983730316162}, {"id": 37, "seek": 31108, "start": 317.47999999999996, "end": 324.24, "text": " We made friends, right? But you can see the change after five years, all hair turned gray.", "tokens": [50684, 492, 1027, 1855, 11, 558, 30, 583, 291, 393, 536, 264, 1319, 934, 1732, 924, 11, 439, 2578, 3574, 10855, 13, 51022], "temperature": 0.0, "avg_logprob": -0.34889674909187085, "compression_ratio": 1.4505494505494505, "no_speech_prob": 0.18184983730316162}, {"id": 38, "seek": 31108, "start": 324.24, "end": 335.28, "text": " Okay, this is the talk in the virtual, my first talk in the Open Source community,", "tokens": [51022, 1033, 11, 341, 307, 264, 751, 294, 264, 6374, 11, 452, 700, 751, 294, 264, 7238, 29629, 1768, 11, 51574], "temperature": 0.0, "avg_logprob": -0.34889674909187085, "compression_ratio": 1.4505494505494505, "no_speech_prob": 0.18184983730316162}, {"id": 39, "seek": 33528, "start": 336.0, "end": 344.2, "text": " how to integrate FDAP and Active Directory with Patch Open Meetings. At that time, I was the", "tokens": [50400, 577, 281, 13365, 479, 35, 4715, 293, 26635, 49598, 365, 44359, 7238, 22963, 1109, 13, 1711, 300, 565, 11, 286, 390, 264, 50810], "temperature": 0.0, "avg_logprob": -0.4113736871170671, "compression_ratio": 1.3781094527363185, "no_speech_prob": 0.3046339154243469}, {"id": 40, "seek": 33528, "start": 344.2, "end": 352.71999999999997, "text": " personal former member of Kaiyuan City. This is last year, the FOSA Asia. We got both here", "tokens": [50810, 2973, 5819, 4006, 295, 20753, 88, 6139, 4392, 13, 639, 307, 1036, 1064, 11, 264, 479, 4367, 32, 10038, 13, 492, 658, 1293, 510, 51236], "temperature": 0.0, "avg_logprob": -0.4113736871170671, "compression_ratio": 1.3781094527363185, "no_speech_prob": 0.3046339154243469}, {"id": 41, "seek": 33528, "start": 352.71999999999997, "end": 361.08, "text": " right at the second floor and that's in Singapore. We have a group of Chinese developers from", "tokens": [51236, 558, 412, 264, 1150, 4123, 293, 300, 311, 294, 14491, 13, 492, 362, 257, 1594, 295, 4649, 8849, 490, 51654], "temperature": 0.0, "avg_logprob": -0.4113736871170671, "compression_ratio": 1.3781094527363185, "no_speech_prob": 0.3046339154243469}, {"id": 42, "seek": 36108, "start": 361.2, "end": 367.84, "text": " different cities in China like Shanghai, Beijing, Chengdu, Changsha. And also is a Japanese guy", "tokens": [50370, 819, 6486, 294, 3533, 411, 26135, 11, 20240, 11, 24363, 769, 11, 17179, 82, 1641, 13, 400, 611, 307, 257, 5433, 2146, 50702], "temperature": 0.0, "avg_logprob": -0.28822845136615594, "compression_ratio": 1.4754098360655739, "no_speech_prob": 0.05835629254579544}, {"id": 43, "seek": 36108, "start": 367.84, "end": 378.2, "text": " from Japan. We have a second group to the meeting. This is last year, a committee of", "tokens": [50702, 490, 3367, 13, 492, 362, 257, 1150, 1594, 281, 264, 3440, 13, 639, 307, 1036, 1064, 11, 257, 7482, 295, 51220], "temperature": 0.0, "avg_logprob": -0.28822845136615594, "compression_ratio": 1.4754098360655739, "no_speech_prob": 0.05835629254579544}, {"id": 44, "seek": 36108, "start": 378.2, "end": 388.76, "text": " code in China, in Beijing. See many Chinese developers, commuters. And I also gave a talk", "tokens": [51220, 3089, 294, 3533, 11, 294, 20240, 13, 3008, 867, 4649, 8849, 11, 800, 48396, 13, 400, 286, 611, 2729, 257, 751, 51748], "temperature": 0.0, "avg_logprob": -0.28822845136615594, "compression_ratio": 1.4754098360655739, "no_speech_prob": 0.05835629254579544}, {"id": 45, "seek": 38876, "start": 389.64, "end": 404.64, "text": " in the integration check. For Open Source Congress report, 2023, the title of the report is", "tokens": [50408, 294, 264, 10980, 1520, 13, 1171, 7238, 29629, 6426, 2275, 11, 44377, 11, 264, 4876, 295, 264, 2275, 307, 51158], "temperature": 0.0, "avg_logprob": -0.32591783432733445, "compression_ratio": 1.3805970149253732, "no_speech_prob": 0.03197328373789787}, {"id": 46, "seek": 38876, "start": 404.64, "end": 410.84, "text": " Standing Together on Shared Challenges. Report on the Open Source Congress. Probably somebody", "tokens": [51158, 33655, 15911, 322, 1160, 1642, 14398, 47077, 13, 16057, 322, 264, 7238, 29629, 6426, 13, 9210, 2618, 51468], "temperature": 0.0, "avg_logprob": -0.32591783432733445, "compression_ratio": 1.3805970149253732, "no_speech_prob": 0.03197328373789787}, {"id": 47, "seek": 41084, "start": 411.47999999999996, "end": 419.08, "text": " here, maybe you read the English or other versions reported, right? But in China, we are absolutely", "tokens": [50396, 510, 11, 1310, 291, 1401, 264, 3669, 420, 661, 9606, 7055, 11, 558, 30, 583, 294, 3533, 11, 321, 366, 3122, 50776], "temperature": 0.0, "avg_logprob": -0.24201575915018717, "compression_ratio": 1.3923444976076556, "no_speech_prob": 0.41923773288726807}, {"id": 48, "seek": 41084, "start": 419.08, "end": 425.59999999999997, "text": " very honored to be part of the group. We do the translation work. The project created on November", "tokens": [50776, 588, 14556, 281, 312, 644, 295, 264, 1594, 13, 492, 360, 264, 12853, 589, 13, 440, 1716, 2942, 322, 7674, 51102], "temperature": 0.0, "avg_logprob": -0.24201575915018717, "compression_ratio": 1.3923444976076556, "no_speech_prob": 0.41923773288726807}, {"id": 49, "seek": 41084, "start": 425.59999999999997, "end": 436.76, "text": " 17th, project complete on January 12th, 2024. The whole report length is 34 pages. We got six", "tokens": [51102, 3282, 392, 11, 1716, 3566, 322, 7061, 2272, 392, 11, 45237, 13, 440, 1379, 2275, 4641, 307, 12790, 7183, 13, 492, 658, 2309, 51660], "temperature": 0.0, "avg_logprob": -0.24201575915018717, "compression_ratio": 1.3923444976076556, "no_speech_prob": 0.41923773288726807}, {"id": 50, "seek": 43676, "start": 436.76, "end": 449.15999999999997, "text": " translators, two reviewers. We divide the task into six subtexts, including infographics. We use AI", "tokens": [50364, 5105, 3391, 11, 732, 45837, 13, 492, 9845, 264, 5633, 666, 2309, 1422, 25111, 82, 11, 3009, 1536, 29933, 13, 492, 764, 7318, 50984], "temperature": 0.0, "avg_logprob": -0.4725020971053686, "compression_ratio": 1.4894736842105263, "no_speech_prob": 0.09967029094696045}, {"id": 51, "seek": 43676, "start": 449.15999999999997, "end": 458.36, "text": " assistant such as DPL, CloudIn, ChagBt, Co-Panel, Google Documents to help us to facilitate", "tokens": [50984, 10994, 1270, 382, 413, 21593, 11, 8061, 4575, 11, 761, 559, 33, 83, 11, 3066, 12, 47, 282, 338, 11, 3329, 16024, 4697, 281, 854, 505, 281, 20207, 51444], "temperature": 0.0, "avg_logprob": -0.4725020971053686, "compression_ratio": 1.4894736842105263, "no_speech_prob": 0.09967029094696045}, {"id": 52, "seek": 43676, "start": 458.36, "end": 466.71999999999997, "text": " translation. Usually, we use like a Google, Google translate to do translation. But when we", "tokens": [51444, 12853, 13, 11419, 11, 321, 764, 411, 257, 3329, 11, 3329, 13799, 281, 360, 12853, 13, 583, 562, 321, 51862], "temperature": 0.0, "avg_logprob": -0.4725020971053686, "compression_ratio": 1.4894736842105263, "no_speech_prob": 0.09967029094696045}, {"id": 53, "seek": 46672, "start": 466.72, "end": 476.0, "text": " compare the result, we find that Google translate is not accurate as DPL. So we just use the AI", "tokens": [50364, 6794, 264, 1874, 11, 321, 915, 300, 3329, 13799, 307, 406, 8559, 382, 413, 21593, 13, 407, 321, 445, 764, 264, 7318, 50828], "temperature": 0.0, "avg_logprob": -0.34192442212785995, "compression_ratio": 1.53551912568306, "no_speech_prob": 0.02327599748969078}, {"id": 54, "seek": 46672, "start": 476.0, "end": 488.56, "text": " tool to help us. We labeled the whole translation process in different stages, like in-process,", "tokens": [50828, 2290, 281, 854, 505, 13, 492, 21335, 264, 1379, 12853, 1399, 294, 819, 10232, 11, 411, 294, 12, 41075, 11, 51456], "temperature": 0.0, "avg_logprob": -0.34192442212785995, "compression_ratio": 1.53551912568306, "no_speech_prob": 0.02327599748969078}, {"id": 55, "seek": 46672, "start": 488.56, "end": 494.12, "text": " like translated, like reviewed. So each team member, okay, each team member, you can look", "tokens": [51456, 411, 16805, 11, 411, 18429, 13, 407, 1184, 1469, 4006, 11, 1392, 11, 1184, 1469, 4006, 11, 291, 393, 574, 51734], "temperature": 0.0, "avg_logprob": -0.34192442212785995, "compression_ratio": 1.53551912568306, "no_speech_prob": 0.02327599748969078}, {"id": 56, "seek": 49412, "start": 494.2, "end": 502.8, "text": " at the labels, okay, got it. If the former process finishes, then I can start my process. The initial", "tokens": [50368, 412, 264, 16949, 11, 1392, 11, 658, 309, 13, 759, 264, 5819, 1399, 23615, 11, 550, 286, 393, 722, 452, 1399, 13, 440, 5883, 50798], "temperature": 0.0, "avg_logprob": -0.31102127777902705, "compression_ratio": 1.5873015873015872, "no_speech_prob": 0.09522241353988647}, {"id": 57, "seek": 49412, "start": 502.8, "end": 510.56, "text": " translation finished on December 2nd. And then we start our first round of QA and the second round", "tokens": [50798, 12853, 4335, 322, 7687, 568, 273, 13, 400, 550, 321, 722, 527, 700, 3098, 295, 1249, 32, 293, 264, 1150, 3098, 51186], "temperature": 0.0, "avg_logprob": -0.31102127777902705, "compression_ratio": 1.5873015873015872, "no_speech_prob": 0.09522241353988647}, {"id": 58, "seek": 49412, "start": 510.56, "end": 520.8, "text": " of QA and final review. So left side, the English version front page, and the right side is Chinese", "tokens": [51186, 295, 1249, 32, 293, 2572, 3131, 13, 407, 1411, 1252, 11, 264, 3669, 3037, 1868, 3028, 11, 293, 264, 558, 1252, 307, 4649, 51698], "temperature": 0.0, "avg_logprob": -0.31102127777902705, "compression_ratio": 1.5873015873015872, "no_speech_prob": 0.09522241353988647}, {"id": 59, "seek": 52080, "start": 521.4799999999999, "end": 531.3599999999999, "text": " version front page. Here is six subtexts, and here is my nickname. So I reviewed the two parts.", "tokens": [50398, 3037, 1868, 3028, 13, 1692, 307, 2309, 1422, 25111, 82, 11, 293, 510, 307, 452, 21641, 13, 407, 286, 18429, 264, 732, 3166, 13, 50892], "temperature": 0.0, "avg_logprob": -0.32077232996622723, "compression_ratio": 1.4112903225806452, "no_speech_prob": 0.014724286273121834}, {"id": 60, "seek": 52080, "start": 531.3599999999999, "end": 540.28, "text": " So for the infographics, we know in the translation, for text translation, it's", "tokens": [50892, 407, 337, 264, 1536, 29933, 11, 321, 458, 294, 264, 12853, 11, 337, 2487, 12853, 11, 309, 311, 51338], "temperature": 0.0, "avg_logprob": -0.32077232996622723, "compression_ratio": 1.4112903225806452, "no_speech_prob": 0.014724286273121834}, {"id": 61, "seek": 54028, "start": 541.24, "end": 553.0, "text": " comparably easy, right? But for the image translation, we need to use more time. For example, we speed", "tokens": [50412, 6311, 1188, 1858, 11, 558, 30, 583, 337, 264, 3256, 12853, 11, 321, 643, 281, 764, 544, 565, 13, 1171, 1365, 11, 321, 3073, 51000], "temperature": 0.0, "avg_logprob": -0.27713411732723836, "compression_ratio": 1.5425531914893618, "no_speech_prob": 0.08059808611869812}, {"id": 62, "seek": 54028, "start": 553.0, "end": 559.8399999999999, "text": " the infographics, there's 12 images, we speed it and get one of them, and we use the Google", "tokens": [51000, 264, 1536, 29933, 11, 456, 311, 2272, 5267, 11, 321, 3073, 309, 293, 483, 472, 295, 552, 11, 293, 321, 764, 264, 3329, 51342], "temperature": 0.0, "avg_logprob": -0.27713411732723836, "compression_ratio": 1.5425531914893618, "no_speech_prob": 0.08059808611869812}, {"id": 63, "seek": 54028, "start": 559.8399999999999, "end": 564.9599999999999, "text": " translator to get the Chinese version. But you can see the title and the content is unreadable,", "tokens": [51342, 35223, 281, 483, 264, 4649, 3037, 13, 583, 291, 393, 536, 264, 4876, 293, 264, 2701, 307, 517, 2538, 712, 11, 51598], "temperature": 0.0, "avg_logprob": -0.27713411732723836, "compression_ratio": 1.5425531914893618, "no_speech_prob": 0.08059808611869812}, {"id": 64, "seek": 56496, "start": 565.0, "end": 574.48, "text": " right? It's too small. So we just use, clean everything out and use Photoshop to add the content.", "tokens": [50366, 558, 30, 467, 311, 886, 1359, 13, 407, 321, 445, 764, 11, 2541, 1203, 484, 293, 764, 20821, 281, 909, 264, 2701, 13, 50840], "temperature": 0.0, "avg_logprob": -0.30622980487880425, "compression_ratio": 1.419889502762431, "no_speech_prob": 0.01915869303047657}, {"id": 65, "seek": 56496, "start": 577.48, "end": 582.32, "text": " So finally, we combined the 12 images together to get the infographics.", "tokens": [50990, 407, 2721, 11, 321, 9354, 264, 2272, 5267, 1214, 281, 483, 264, 1536, 29933, 13, 51232], "temperature": 0.0, "avg_logprob": -0.30622980487880425, "compression_ratio": 1.419889502762431, "no_speech_prob": 0.01915869303047657}, {"id": 66, "seek": 56496, "start": 587.76, "end": 593.44, "text": " Can you see? Sorry, it's not very clearly. Left side is the content of English version,", "tokens": [51504, 1664, 291, 536, 30, 4919, 11, 309, 311, 406, 588, 4448, 13, 16405, 1252, 307, 264, 2701, 295, 3669, 3037, 11, 51788], "temperature": 0.0, "avg_logprob": -0.30622980487880425, "compression_ratio": 1.419889502762431, "no_speech_prob": 0.01915869303047657}, {"id": 67, "seek": 59344, "start": 593.5600000000001, "end": 600.08, "text": " and the right side is the content table in Chinese version. You can see the page number here.", "tokens": [50370, 293, 264, 558, 1252, 307, 264, 2701, 3199, 294, 4649, 3037, 13, 509, 393, 536, 264, 3028, 1230, 510, 13, 50696], "temperature": 0.0, "avg_logprob": -0.36620417508212005, "compression_ratio": 1.5113636363636365, "no_speech_prob": 0.015477009117603302}, {"id": 68, "seek": 59344, "start": 600.08, "end": 606.2, "text": " The English version is 28 pages. In Chinese version, it's 20 pages, which means after the", "tokens": [50696, 440, 3669, 3037, 307, 7562, 7183, 13, 682, 4649, 3037, 11, 309, 311, 945, 7183, 11, 597, 1355, 934, 264, 51002], "temperature": 0.0, "avg_logprob": -0.36620417508212005, "compression_ratio": 1.5113636363636365, "no_speech_prob": 0.015477009117603302}, {"id": 69, "seek": 59344, "start": 606.2, "end": 612.12, "text": " translation, the five sides shrink. Just I only got two thirds of the source file.", "tokens": [51002, 12853, 11, 264, 1732, 4881, 23060, 13, 1449, 286, 787, 658, 732, 34552, 295, 264, 4009, 3991, 13, 51298], "temperature": 0.0, "avg_logprob": -0.36620417508212005, "compression_ratio": 1.5113636363636365, "no_speech_prob": 0.015477009117603302}, {"id": 70, "seek": 61212, "start": 613.12, "end": 620.6, "text": " So here comes the lessons I learned. Original paper has some quotes, which some experts,", "tokens": [50414, 407, 510, 1487, 264, 8820, 286, 3264, 13, 30022, 3035, 575, 512, 19963, 11, 597, 512, 8572, 11, 50788], "temperature": 0.0, "avg_logprob": -0.4127989335493608, "compression_ratio": 1.805668016194332, "no_speech_prob": 0.06696390360593796}, {"id": 71, "seek": 61212, "start": 620.6, "end": 626.24, "text": " some leaders, they say something, right? But the translation has some discrepancies, so", "tokens": [50788, 512, 3523, 11, 436, 584, 746, 11, 558, 30, 583, 264, 12853, 575, 512, 2983, 19919, 32286, 11, 370, 51070], "temperature": 0.0, "avg_logprob": -0.4127989335493608, "compression_ratio": 1.805668016194332, "no_speech_prob": 0.06696390360593796}, {"id": 72, "seek": 61212, "start": 626.24, "end": 630.04, "text": " we need a final review. After we send the paper to the latest foundation, they say, okay,", "tokens": [51070, 321, 643, 257, 2572, 3131, 13, 2381, 321, 2845, 264, 3035, 281, 264, 6792, 7030, 11, 436, 584, 11, 1392, 11, 51260], "temperature": 0.0, "avg_logprob": -0.4127989335493608, "compression_ratio": 1.805668016194332, "no_speech_prob": 0.06696390360593796}, {"id": 73, "seek": 61212, "start": 630.04, "end": 635.16, "text": " we got some discrepancies. You guys need to pay attention. You need to have a final review.", "tokens": [51260, 321, 658, 512, 2983, 19919, 32286, 13, 509, 1074, 643, 281, 1689, 3202, 13, 509, 643, 281, 362, 257, 2572, 3131, 13, 51516], "temperature": 0.0, "avg_logprob": -0.4127989335493608, "compression_ratio": 1.805668016194332, "no_speech_prob": 0.06696390360593796}, {"id": 74, "seek": 61212, "start": 635.16, "end": 640.24, "text": " So when we check these discrepancies, we need to keep constantly looking at the content", "tokens": [51516, 407, 562, 321, 1520, 613, 2983, 19919, 32286, 11, 321, 643, 281, 1066, 6460, 1237, 412, 264, 2701, 51770], "temperature": 0.0, "avg_logprob": -0.4127989335493608, "compression_ratio": 1.805668016194332, "no_speech_prob": 0.06696390360593796}, {"id": 75, "seek": 64024, "start": 640.24, "end": 646.6, "text": " discrepancies. We need to keep consistency and one format, otherwise it would cause confusion.", "tokens": [50364, 2983, 19919, 32286, 13, 492, 643, 281, 1066, 14416, 293, 472, 7877, 11, 5911, 309, 576, 3082, 15075, 13, 50682], "temperature": 0.0, "avg_logprob": -0.3360773352689521, "compression_ratio": 1.5578512396694215, "no_speech_prob": 0.012664280831813812}, {"id": 76, "seek": 64024, "start": 646.6, "end": 653.32, "text": " Because we are sending tasks based on the source file in Google documents, but the discrepancies", "tokens": [50682, 1436, 321, 366, 7750, 9608, 2361, 322, 264, 4009, 3991, 294, 3329, 8512, 11, 457, 264, 2983, 19919, 32286, 51018], "temperature": 0.0, "avg_logprob": -0.3360773352689521, "compression_ratio": 1.5578512396694215, "no_speech_prob": 0.012664280831813812}, {"id": 77, "seek": 64024, "start": 653.32, "end": 660.88, "text": " exist in the target PDF files we send to the latest foundation, right? Okay, then we identify", "tokens": [51018, 2514, 294, 264, 3779, 17752, 7098, 321, 2845, 281, 264, 6792, 7030, 11, 558, 30, 1033, 11, 550, 321, 5876, 51396], "temperature": 0.0, "avg_logprob": -0.3360773352689521, "compression_ratio": 1.5578512396694215, "no_speech_prob": 0.012664280831813812}, {"id": 78, "seek": 64024, "start": 660.88, "end": 666.92, "text": " how many book codes and in which part of the paper so the corresponding translators will be", "tokens": [51396, 577, 867, 1446, 14211, 293, 294, 597, 644, 295, 264, 3035, 370, 264, 11760, 5105, 3391, 486, 312, 51698], "temperature": 0.0, "avg_logprob": -0.3360773352689521, "compression_ratio": 1.5578512396694215, "no_speech_prob": 0.012664280831813812}, {"id": 79, "seek": 66692, "start": 666.9599999999999, "end": 675.9599999999999, "text": " able to check the codes. Because of the five sides shrink adjustment, right? And in PDF format,", "tokens": [50366, 1075, 281, 1520, 264, 14211, 13, 1436, 295, 264, 1732, 4881, 23060, 17132, 11, 558, 30, 400, 294, 17752, 7877, 11, 50816], "temperature": 0.0, "avg_logprob": -0.3290936364067925, "compression_ratio": 1.5598290598290598, "no_speech_prob": 0.02078702114522457}, {"id": 80, "seek": 66692, "start": 675.9599999999999, "end": 681.4799999999999, "text": " we got two column format. So talk to the file page number, it's different from source file", "tokens": [50816, 321, 658, 732, 7738, 7877, 13, 407, 751, 281, 264, 3991, 3028, 1230, 11, 309, 311, 819, 490, 4009, 3991, 51092], "temperature": 0.0, "avg_logprob": -0.3290936364067925, "compression_ratio": 1.5598290598290598, "no_speech_prob": 0.02078702114522457}, {"id": 81, "seek": 66692, "start": 681.4799999999999, "end": 688.04, "text": " page number. So if we didn't keep consistency on source file, then we got confused. This", "tokens": [51092, 3028, 1230, 13, 407, 498, 321, 994, 380, 1066, 14416, 322, 4009, 3991, 11, 550, 321, 658, 9019, 13, 639, 51420], "temperature": 0.0, "avg_logprob": -0.3290936364067925, "compression_ratio": 1.5598290598290598, "no_speech_prob": 0.02078702114522457}, {"id": 82, "seek": 66692, "start": 688.04, "end": 693.88, "text": " happened in the communication process. Okay, we found this postcode. Who did this? Nobody", "tokens": [51420, 2011, 294, 264, 6101, 1399, 13, 1033, 11, 321, 1352, 341, 2183, 22332, 13, 2102, 630, 341, 30, 9297, 51712], "temperature": 0.0, "avg_logprob": -0.3290936364067925, "compression_ratio": 1.5598290598290598, "no_speech_prob": 0.02078702114522457}, {"id": 83, "seek": 69388, "start": 693.92, "end": 700.24, "text": " knows because when we check the PDF format, I didn't do this, I didn't do this, right? So the final", "tokens": [50366, 3255, 570, 562, 321, 1520, 264, 17752, 7877, 11, 286, 994, 380, 360, 341, 11, 286, 994, 380, 360, 341, 11, 558, 30, 407, 264, 2572, 50682], "temperature": 0.0, "avg_logprob": -0.26636330286661786, "compression_ratio": 1.5614973262032086, "no_speech_prob": 0.028424439951777458}, {"id": 84, "seek": 69388, "start": 700.24, "end": 706.84, "text": " solution is the leader, the leader of the project, he took all the responsibility. He checked all", "tokens": [50682, 3827, 307, 264, 5263, 11, 264, 5263, 295, 264, 1716, 11, 415, 1890, 439, 264, 6357, 13, 634, 10033, 439, 51012], "temperature": 0.0, "avg_logprob": -0.26636330286661786, "compression_ratio": 1.5614973262032086, "no_speech_prob": 0.028424439951777458}, {"id": 85, "seek": 69388, "start": 706.84, "end": 716.32, "text": " the protocols and the translated by himself. After we send the paper to the latest foundation,", "tokens": [51012, 264, 20618, 293, 264, 16805, 538, 3647, 13, 2381, 321, 2845, 264, 3035, 281, 264, 6792, 7030, 11, 51486], "temperature": 0.0, "avg_logprob": -0.26636330286661786, "compression_ratio": 1.5614973262032086, "no_speech_prob": 0.028424439951777458}, {"id": 86, "seek": 71632, "start": 716.4000000000001, "end": 725.24, "text": " they used us some badges for just four. I'm very happy to get this for the recognition.", "tokens": [50368, 436, 1143, 505, 512, 43894, 337, 445, 1451, 13, 286, 478, 588, 2055, 281, 483, 341, 337, 264, 11150, 13, 50810], "temperature": 0.0, "avg_logprob": -0.4632029837750374, "compression_ratio": 1.2605633802816902, "no_speech_prob": 0.11008609086275101}, {"id": 87, "seek": 71632, "start": 732.96, "end": 743.2800000000001, "text": " For Year 2023 OSI DeepDive AI sessions, this is a video caption project. Project created on", "tokens": [51196, 1171, 10289, 44377, 12731, 40, 14895, 35, 488, 7318, 11081, 11, 341, 307, 257, 960, 31974, 1716, 13, 9849, 2942, 322, 51712], "temperature": 0.0, "avg_logprob": -0.4632029837750374, "compression_ratio": 1.2605633802816902, "no_speech_prob": 0.11008609086275101}, {"id": 88, "seek": 74328, "start": 743.3199999999999, "end": 750.88, "text": " November 7th and the project will be completed on February 14th, which means we're still in the", "tokens": [50366, 7674, 1614, 392, 293, 264, 1716, 486, 312, 7365, 322, 8711, 3499, 392, 11, 597, 1355, 321, 434, 920, 294, 264, 50744], "temperature": 0.0, "avg_logprob": -0.2547484619976723, "compression_ratio": 1.4343434343434343, "no_speech_prob": 0.04630685970187187}, {"id": 89, "seek": 74328, "start": 750.88, "end": 761.4399999999999, "text": " process. Total, there are 17 sessions. We had 10 translators in two groups. Only have two", "tokens": [50744, 1399, 13, 23170, 11, 456, 366, 3282, 11081, 13, 492, 632, 1266, 5105, 3391, 294, 732, 3935, 13, 5686, 362, 732, 51272], "temperature": 0.0, "avg_logprob": -0.2547484619976723, "compression_ratio": 1.4343434343434343, "no_speech_prob": 0.04630685970187187}, {"id": 90, "seek": 74328, "start": 761.4399999999999, "end": 768.4, "text": " reviews. So we follow the steps. First, we use the raw video material to get the scripts. And then", "tokens": [51272, 10229, 13, 407, 321, 1524, 264, 4439, 13, 2386, 11, 321, 764, 264, 8936, 960, 2527, 281, 483, 264, 23294, 13, 400, 550, 51620], "temperature": 0.0, "avg_logprob": -0.2547484619976723, "compression_ratio": 1.4343434343434343, "no_speech_prob": 0.04630685970187187}, {"id": 91, "seek": 76840, "start": 768.88, "end": 774.8, "text": " we check each word and the sentences by translating ears. We also use like TPL,", "tokens": [50388, 321, 1520, 1184, 1349, 293, 264, 16579, 538, 35030, 8798, 13, 492, 611, 764, 411, 314, 21593, 11, 50684], "temperature": 0.0, "avg_logprob": -0.5171864221966456, "compression_ratio": 1.467032967032967, "no_speech_prob": 0.024065697565674782}, {"id": 92, "seek": 76840, "start": 774.8, "end": 782.0, "text": " charge PTE, quite easy, GNY. This is a Chinese automatic translation platform and YouTube to", "tokens": [50684, 4602, 430, 13639, 11, 1596, 1858, 11, 460, 27647, 13, 639, 307, 257, 4649, 12509, 12853, 3663, 293, 3088, 281, 51044], "temperature": 0.0, "avg_logprob": -0.5171864221966456, "compression_ratio": 1.467032967032967, "no_speech_prob": 0.024065697565674782}, {"id": 93, "seek": 76840, "start": 782.0, "end": 791.04, "text": " help us. We also put the status in translation translated in review under reviewed to identify", "tokens": [51044, 854, 505, 13, 492, 611, 829, 264, 6558, 294, 12853, 16805, 294, 3131, 833, 18429, 281, 5876, 51496], "temperature": 0.0, "avg_logprob": -0.5171864221966456, "compression_ratio": 1.467032967032967, "no_speech_prob": 0.024065697565674782}, {"id": 94, "seek": 79104, "start": 791.52, "end": 801.04, "text": " the progress of each process. The initial translation finished on December 2nd. Then we", "tokens": [50388, 264, 4205, 295, 1184, 1399, 13, 440, 5883, 12853, 4335, 322, 7687, 568, 273, 13, 1396, 321, 50864], "temperature": 0.0, "avg_logprob": -0.30464281755335193, "compression_ratio": 1.4867724867724867, "no_speech_prob": 0.1082688719034195}, {"id": 95, "seek": 79104, "start": 801.5999999999999, "end": 809.76, "text": " immediately started the first round QA, round QA and final review. Then we have the second group to", "tokens": [50892, 4258, 1409, 264, 700, 3098, 1249, 32, 11, 3098, 1249, 32, 293, 2572, 3131, 13, 1396, 321, 362, 264, 1150, 1594, 281, 51300], "temperature": 0.0, "avg_logprob": -0.30464281755335193, "compression_ratio": 1.4867724867724867, "no_speech_prob": 0.1082688719034195}, {"id": 96, "seek": 79104, "start": 809.76, "end": 818.0, "text": " help us to publish in different social media like in WeChat as a web pop in China and also in", "tokens": [51300, 854, 505, 281, 11374, 294, 819, 2093, 3021, 411, 294, 492, 41683, 382, 257, 3670, 1665, 294, 3533, 293, 611, 294, 51712], "temperature": 0.0, "avg_logprob": -0.30464281755335193, "compression_ratio": 1.4867724867724867, "no_speech_prob": 0.1082688719034195}, {"id": 97, "seek": 81800, "start": 818.0, "end": 832.72, "text": " Facebook and Twitter and YouTube. Sorry, it's too small. See the 17 sessions and we are forcited", "tokens": [50364, 4384, 293, 5794, 293, 3088, 13, 4919, 11, 309, 311, 886, 1359, 13, 3008, 264, 3282, 11081, 293, 321, 366, 337, 66, 1226, 51100], "temperature": 0.0, "avg_logprob": -0.2654970986502511, "compression_ratio": 1.5635359116022098, "no_speech_prob": 0.036220960319042206}, {"id": 98, "seek": 81800, "start": 832.72, "end": 840.8, "text": " the publishing process. We subgrouped the 17 sessions into different groups. We got three", "tokens": [51100, 264, 17832, 1399, 13, 492, 1422, 17377, 292, 264, 3282, 11081, 666, 819, 3935, 13, 492, 658, 1045, 51504], "temperature": 0.0, "avg_logprob": -0.2654970986502511, "compression_ratio": 1.5635359116022098, "no_speech_prob": 0.036220960319042206}, {"id": 99, "seek": 81800, "start": 841.44, "end": 847.6, "text": " groups. First one is open risk and challenge. And the second one is governance. And the last one", "tokens": [51536, 3935, 13, 2386, 472, 307, 1269, 3148, 293, 3430, 13, 400, 264, 1150, 472, 307, 17449, 13, 400, 264, 1036, 472, 51844], "temperature": 0.0, "avg_logprob": -0.2654970986502511, "compression_ratio": 1.5635359116022098, "no_speech_prob": 0.036220960319042206}, {"id": 100, "seek": 84760, "start": 847.6, "end": 856.72, "text": " is the fireside track. So for each group, we also got some subgroups. For the year about which", "tokens": [50364, 307, 264, 15044, 482, 2837, 13, 407, 337, 1184, 1594, 11, 321, 611, 658, 512, 1422, 17377, 82, 13, 1171, 264, 1064, 466, 597, 50820], "temperature": 0.0, "avg_logprob": -0.30256197187635636, "compression_ratio": 1.3897058823529411, "no_speech_prob": 0.011253917589783669}, {"id": 101, "seek": 84760, "start": 856.72, "end": 865.2, "text": " are the sessions, I either reviewed or be a translator. I am the reviewer. So you can see it's", "tokens": [50820, 366, 264, 11081, 11, 286, 2139, 18429, 420, 312, 257, 35223, 13, 286, 669, 264, 3131, 260, 13, 407, 291, 393, 536, 309, 311, 51244], "temperature": 0.0, "avg_logprob": -0.30256197187635636, "compression_ratio": 1.3897058823529411, "no_speech_prob": 0.011253917589783669}, {"id": 102, "seek": 86520, "start": 865.2, "end": 877.84, "text": " almost half of the sessions. So this is project management system in Chinese. That's my role.", "tokens": [50364, 1920, 1922, 295, 264, 11081, 13, 407, 341, 307, 1716, 4592, 1185, 294, 4649, 13, 663, 311, 452, 3090, 13, 50996], "temperature": 0.0, "avg_logprob": -0.2619694260989918, "compression_ratio": 1.5543478260869565, "no_speech_prob": 0.049078553915023804}, {"id": 103, "seek": 86520, "start": 877.84, "end": 885.0400000000001, "text": " So you can see the yellow bar is my role. And here the arrows pointed to the different process.", "tokens": [50996, 407, 291, 393, 536, 264, 5566, 2159, 307, 452, 3090, 13, 400, 510, 264, 19669, 10932, 281, 264, 819, 1399, 13, 51356], "temperature": 0.0, "avg_logprob": -0.2619694260989918, "compression_ratio": 1.5543478260869565, "no_speech_prob": 0.049078553915023804}, {"id": 104, "seek": 86520, "start": 885.0400000000001, "end": 892.96, "text": " First one that means reviewed. And this one means in translation. So we can identify the process", "tokens": [51356, 2386, 472, 300, 1355, 18429, 13, 400, 341, 472, 1355, 294, 12853, 13, 407, 321, 393, 5876, 264, 1399, 51752], "temperature": 0.0, "avg_logprob": -0.2619694260989918, "compression_ratio": 1.5543478260869565, "no_speech_prob": 0.049078553915023804}, {"id": 105, "seek": 89296, "start": 892.96, "end": 898.0, "text": " because the team members, we will work together and work on different cities.", "tokens": [50364, 570, 264, 1469, 2679, 11, 321, 486, 589, 1214, 293, 589, 322, 819, 6486, 13, 50616], "temperature": 0.0, "avg_logprob": -0.2885994709713358, "compression_ratio": 1.5073891625615763, "no_speech_prob": 0.01022093091160059}, {"id": 106, "seek": 89296, "start": 902.48, "end": 904.4000000000001, "text": " Okay, here comes the lessons I learned.", "tokens": [50840, 1033, 11, 510, 1487, 264, 8820, 286, 3264, 13, 50936], "temperature": 0.0, "avg_logprob": -0.2885994709713358, "compression_ratio": 1.5073891625615763, "no_speech_prob": 0.01022093091160059}, {"id": 107, "seek": 89296, "start": 907.44, "end": 914.72, "text": " We need to check subtitles versus warriors to make sure every word matched. It is very time consuming.", "tokens": [51088, 492, 643, 281, 1520, 42045, 5717, 25303, 281, 652, 988, 633, 1349, 21447, 13, 467, 307, 588, 565, 19867, 13, 51452], "temperature": 0.0, "avg_logprob": -0.2885994709713358, "compression_ratio": 1.5073891625615763, "no_speech_prob": 0.01022093091160059}, {"id": 108, "seek": 89296, "start": 914.72, "end": 921.84, "text": " For the video session, usually like if it is 30 minute session, we usually take about", "tokens": [51452, 1171, 264, 960, 5481, 11, 2673, 411, 498, 309, 307, 2217, 3456, 5481, 11, 321, 2673, 747, 466, 51808], "temperature": 0.0, "avg_logprob": -0.2885994709713358, "compression_ratio": 1.5073891625615763, "no_speech_prob": 0.01022093091160059}, {"id": 109, "seek": 92296, "start": 923.0400000000001, "end": 934.4000000000001, "text": " 10 or more than 10 times time for a 30 minute session. We need like 6 or 7 hours for the", "tokens": [50368, 1266, 420, 544, 813, 1266, 1413, 565, 337, 257, 2217, 3456, 5481, 13, 492, 643, 411, 1386, 420, 1614, 2496, 337, 264, 50936], "temperature": 0.0, "avg_logprob": -0.2930158468393179, "compression_ratio": 1.4919786096256684, "no_speech_prob": 0.01232608687132597}, {"id": 110, "seek": 92296, "start": 934.4000000000001, "end": 943.44, "text": " check. Because subtitle has 120 character length restriction for bad audience sense of reading.", "tokens": [50936, 1520, 13, 1436, 30706, 306, 575, 10411, 2517, 4641, 29529, 337, 1578, 4034, 2020, 295, 3760, 13, 51388], "temperature": 0.0, "avg_logprob": -0.2930158468393179, "compression_ratio": 1.4919786096256684, "no_speech_prob": 0.01232608687132597}, {"id": 111, "seek": 92296, "start": 943.44, "end": 951.0400000000001, "text": " So we need to split every sentence, longer than 120 characters into small parts and also split", "tokens": [51388, 407, 321, 643, 281, 7472, 633, 8174, 11, 2854, 813, 10411, 4342, 666, 1359, 3166, 293, 611, 7472, 51768], "temperature": 0.0, "avg_logprob": -0.2930158468393179, "compression_ratio": 1.4919786096256684, "no_speech_prob": 0.01232608687132597}, {"id": 112, "seek": 95104, "start": 951.12, "end": 958.48, "text": " the subtitle time frame. The split caused some subtitles didn't show up because the time frame", "tokens": [50368, 264, 30706, 306, 565, 3920, 13, 440, 7472, 7008, 512, 42045, 994, 380, 855, 493, 570, 264, 565, 3920, 50736], "temperature": 0.0, "avg_logprob": -0.24127018268291767, "compression_ratio": 1.6179775280898876, "no_speech_prob": 0.021256959065794945}, {"id": 113, "seek": 95104, "start": 958.48, "end": 965.36, "text": " didn't match. So we need to listen every word very carefully and adjust the corresponding time frame", "tokens": [50736, 994, 380, 2995, 13, 407, 321, 643, 281, 2140, 633, 1349, 588, 7500, 293, 4369, 264, 11760, 565, 3920, 51080], "temperature": 0.0, "avg_logprob": -0.24127018268291767, "compression_ratio": 1.6179775280898876, "no_speech_prob": 0.021256959065794945}, {"id": 114, "seek": 95104, "start": 965.36, "end": 978.0, "text": " into secondary seconds, which is 100 seconds. So it's a time consuming. Especially when some", "tokens": [51080, 666, 11396, 3949, 11, 597, 307, 2319, 3949, 13, 407, 309, 311, 257, 565, 19867, 13, 8545, 562, 512, 51712], "temperature": 0.0, "avg_logprob": -0.24127018268291767, "compression_ratio": 1.6179775280898876, "no_speech_prob": 0.021256959065794945}, {"id": 115, "seek": 97800, "start": 978.72, "end": 984.16, "text": " adjectives and longer sentences come up, we need to adjust the front and back word time frames", "tokens": [50400, 29378, 1539, 293, 2854, 16579, 808, 493, 11, 321, 643, 281, 4369, 264, 1868, 293, 646, 1349, 565, 12083, 50672], "temperature": 0.0, "avg_logprob": -0.3135005726533778, "compression_ratio": 1.3831168831168832, "no_speech_prob": 0.005154728889465332}, {"id": 116, "seek": 97800, "start": 985.12, "end": 986.8, "text": " next to get perfect effects.", "tokens": [50720, 958, 281, 483, 2176, 5065, 13, 50804], "temperature": 0.0, "avg_logprob": -0.3135005726533778, "compression_ratio": 1.3831168831168832, "no_speech_prob": 0.005154728889465332}, {"id": 117, "seek": 97800, "start": 991.28, "end": 1002.08, "text": " Here are some links of some published sessions. See Facebook, Twitter and let's we check.", "tokens": [51028, 1692, 366, 512, 6123, 295, 512, 6572, 11081, 13, 3008, 4384, 11, 5794, 293, 718, 311, 321, 1520, 13, 51568], "temperature": 0.0, "avg_logprob": -0.3135005726533778, "compression_ratio": 1.3831168831168832, "no_speech_prob": 0.005154728889465332}, {"id": 118, "seek": 100800, "start": 1008.4, "end": 1016.16, "text": " Team build the strategy. Right now we have more than 50 translators. Most of them come from", "tokens": [50384, 7606, 1322, 264, 5206, 13, 1779, 586, 321, 362, 544, 813, 2625, 5105, 3391, 13, 4534, 295, 552, 808, 490, 50772], "temperature": 0.0, "avg_logprob": -0.2034765462406346, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.5861936211585999}, {"id": 119, "seek": 100800, "start": 1017.68, "end": 1028.72, "text": " universities, some students in Europe. So team leaders recruit some new translators from various", "tokens": [50848, 11779, 11, 512, 1731, 294, 3315, 13, 407, 1469, 3523, 15119, 512, 777, 5105, 3391, 490, 3683, 51400], "temperature": 0.0, "avg_logprob": -0.2034765462406346, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.5861936211585999}, {"id": 120, "seek": 100800, "start": 1028.72, "end": 1033.68, "text": " sources, companies, universities. Then new translators will introduce to team members.", "tokens": [51400, 7139, 11, 3431, 11, 11779, 13, 1396, 777, 5105, 3391, 486, 5366, 281, 1469, 2679, 13, 51648], "temperature": 0.0, "avg_logprob": -0.2034765462406346, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.5861936211585999}, {"id": 121, "seek": 103368, "start": 1034.3200000000002, "end": 1042.88, "text": " Every member assigns the workload by identifying tasks by one theory. So you can just okay when", "tokens": [50396, 2048, 4006, 6269, 82, 264, 20139, 538, 16696, 9608, 538, 472, 5261, 13, 407, 291, 393, 445, 1392, 562, 50824], "temperature": 0.0, "avg_logprob": -0.2824559365549395, "compression_ratio": 1.4973262032085561, "no_speech_prob": 0.06215328723192215}, {"id": 122, "seek": 103368, "start": 1042.88, "end": 1051.92, "text": " the project comes up, you just pick whatever task you want to get involved with. Then we have basic", "tokens": [50824, 264, 1716, 1487, 493, 11, 291, 445, 1888, 2035, 5633, 291, 528, 281, 483, 3288, 365, 13, 1396, 321, 362, 3875, 51276], "temperature": 0.0, "avg_logprob": -0.2824559365549395, "compression_ratio": 1.4973262032085561, "no_speech_prob": 0.06215328723192215}, {"id": 123, "seek": 103368, "start": 1051.92, "end": 1057.2, "text": " benchmark scoring system, student trial period to record every member's performance.", "tokens": [51276, 18927, 22358, 1185, 11, 3107, 7308, 2896, 281, 2136, 633, 4006, 311, 3389, 13, 51540], "temperature": 0.0, "avg_logprob": -0.2824559365549395, "compression_ratio": 1.4973262032085561, "no_speech_prob": 0.06215328723192215}, {"id": 124, "seek": 105720, "start": 1057.52, "end": 1062.64, "text": " For the benefits, we each code tokens for technique on the long technical", "tokens": [50380, 1171, 264, 5311, 11, 321, 1184, 3089, 22667, 337, 6532, 322, 264, 938, 6191, 50636], "temperature": 0.0, "avg_logprob": -0.42203021395033685, "compression_ratio": 1.551219512195122, "no_speech_prob": 0.03449971601366997}, {"id": 125, "seek": 105720, "start": 1062.64, "end": 1068.96, "text": " contributors. For those team members who have good performance, we grant them the", "tokens": [50636, 45627, 13, 1171, 729, 1469, 2679, 567, 362, 665, 3389, 11, 321, 6386, 552, 264, 50952], "temperature": 0.0, "avg_logprob": -0.42203021395033685, "compression_ratio": 1.551219512195122, "no_speech_prob": 0.03449971601366997}, {"id": 126, "seek": 105720, "start": 1068.96, "end": 1075.1200000000001, "text": " privilege to use community resources such as DPL and the crowdfunding platform.", "tokens": [50952, 12122, 281, 764, 1768, 3593, 1270, 382, 413, 21593, 293, 264, 6919, 45033, 3663, 13, 51260], "temperature": 0.0, "avg_logprob": -0.42203021395033685, "compression_ratio": 1.551219512195122, "no_speech_prob": 0.03449971601366997}, {"id": 127, "seek": 105720, "start": 1078.96, "end": 1085.68, "text": " Community also provided the chances to team members as a voluntary for each year's", "tokens": [51452, 10421, 611, 5649, 264, 10486, 281, 1469, 2679, 382, 257, 28563, 337, 1184, 1064, 311, 51788], "temperature": 0.0, "avg_logprob": -0.42203021395033685, "compression_ratio": 1.551219512195122, "no_speech_prob": 0.03449971601366997}, {"id": 128, "seek": 108568, "start": 1085.76, "end": 1093.04, "text": " conference. And the students can also add the voluntary experience to resume.", "tokens": [50368, 7586, 13, 400, 264, 1731, 393, 611, 909, 264, 28563, 1752, 281, 15358, 13, 50732], "temperature": 0.0, "avg_logprob": -0.4823180699752549, "compression_ratio": 1.5302013422818792, "no_speech_prob": 0.00587267242372036}, {"id": 129, "seek": 108568, "start": 1094.96, "end": 1099.6000000000001, "text": " So here is the code K token system. But that's in Chinese.", "tokens": [50828, 407, 510, 307, 264, 3089, 591, 14862, 1185, 13, 583, 300, 311, 294, 4649, 13, 51060], "temperature": 0.0, "avg_logprob": -0.4823180699752549, "compression_ratio": 1.5302013422818792, "no_speech_prob": 0.00587267242372036}, {"id": 130, "seek": 108568, "start": 1102.16, "end": 1109.1200000000001, "text": " Upside is for technical translators. Low side is for non-technical translators. We got like", "tokens": [51188, 5858, 1812, 307, 337, 6191, 5105, 3391, 13, 17078, 1252, 307, 337, 2107, 12, 29113, 804, 5105, 3391, 13, 492, 658, 411, 51536], "temperature": 0.0, "avg_logprob": -0.4823180699752549, "compression_ratio": 1.5302013422818792, "no_speech_prob": 0.00587267242372036}, {"id": 131, "seek": 110912, "start": 1109.76, "end": 1115.84, "text": " ABC three different kinds of tokens. You use the tokens, you can", "tokens": [50396, 22342, 1045, 819, 3685, 295, 22667, 13, 509, 764, 264, 22667, 11, 291, 393, 50700], "temperature": 0.0, "avg_logprob": -0.33009188725398136, "compression_ratio": 1.6768292682926829, "no_speech_prob": 0.016414517536759377}, {"id": 132, "seek": 110912, "start": 1118.08, "end": 1123.9199999999998, "text": " to cooperate with open source community for different kinds of like Hexen,", "tokens": [50812, 281, 26667, 365, 1269, 4009, 1768, 337, 819, 3685, 295, 411, 634, 87, 268, 11, 51104], "temperature": 0.0, "avg_logprob": -0.33009188725398136, "compression_ratio": 1.6768292682926829, "no_speech_prob": 0.016414517536759377}, {"id": 133, "seek": 110912, "start": 1123.9199999999998, "end": 1127.12, "text": " like different kinds of events. You can join the events.", "tokens": [51104, 411, 819, 3685, 295, 3931, 13, 509, 393, 3917, 264, 3931, 13, 51264], "temperature": 0.0, "avg_logprob": -0.33009188725398136, "compression_ratio": 1.6768292682926829, "no_speech_prob": 0.016414517536759377}, {"id": 134, "seek": 110912, "start": 1130.2399999999998, "end": 1137.28, "text": " Here is the basic benchmark system. We have a different contribution type like", "tokens": [51420, 1692, 307, 264, 3875, 18927, 1185, 13, 492, 362, 257, 819, 13150, 2010, 411, 51772], "temperature": 0.0, "avg_logprob": -0.33009188725398136, "compression_ratio": 1.6768292682926829, "no_speech_prob": 0.016414517536759377}, {"id": 135, "seek": 113728, "start": 1138.24, "end": 1144.8799999999999, "text": " principal, helper, consultant, informer. For each different role, we have basic score weight.", "tokens": [50412, 9716, 11, 36133, 11, 24676, 11, 1356, 260, 13, 1171, 1184, 819, 3090, 11, 321, 362, 3875, 6175, 3364, 13, 50744], "temperature": 0.0, "avg_logprob": -0.2633184375184955, "compression_ratio": 1.5977011494252873, "no_speech_prob": 0.009220905601978302}, {"id": 136, "seek": 113728, "start": 1146.24, "end": 1154.48, "text": " So the benchmark score value is 10. So after you just use the score value 10 times by", "tokens": [50812, 407, 264, 18927, 6175, 2158, 307, 1266, 13, 407, 934, 291, 445, 764, 264, 6175, 2158, 1266, 1413, 538, 51224], "temperature": 0.0, "avg_logprob": -0.2633184375184955, "compression_ratio": 1.5977011494252873, "no_speech_prob": 0.009220905601978302}, {"id": 137, "seek": 113728, "start": 1155.52, "end": 1162.8799999999999, "text": " score weight, you get the basic score for different roles. Then here is the task management system", "tokens": [51276, 6175, 3364, 11, 291, 483, 264, 3875, 6175, 337, 819, 9604, 13, 1396, 510, 307, 264, 5633, 4592, 1185, 51644], "temperature": 0.0, "avg_logprob": -0.2633184375184955, "compression_ratio": 1.5977011494252873, "no_speech_prob": 0.009220905601978302}, {"id": 138, "seek": 116288, "start": 1163.8400000000001, "end": 1172.88, "text": " for the team members you join the project. We use the system to calculate the contribution score.", "tokens": [50412, 337, 264, 1469, 2679, 291, 3917, 264, 1716, 13, 492, 764, 264, 1185, 281, 8873, 264, 13150, 6175, 13, 50864], "temperature": 0.0, "avg_logprob": -0.24994225697974637, "compression_ratio": 1.508108108108108, "no_speech_prob": 0.014519557356834412}, {"id": 139, "seek": 116288, "start": 1175.92, "end": 1182.0800000000002, "text": " Finally, we sum up all the scores of your contributions. You can see on the top one is", "tokens": [51016, 6288, 11, 321, 2408, 493, 439, 264, 13444, 295, 428, 15725, 13, 509, 393, 536, 322, 264, 1192, 472, 307, 51324], "temperature": 0.0, "avg_logprob": -0.24994225697974637, "compression_ratio": 1.508108108108108, "no_speech_prob": 0.014519557356834412}, {"id": 140, "seek": 116288, "start": 1182.0800000000002, "end": 1192.3200000000002, "text": " my name. I got 51. So they grant me some privilege. I can use the crowdfunding, I can use DPL.", "tokens": [51324, 452, 1315, 13, 286, 658, 18485, 13, 407, 436, 6386, 385, 512, 12122, 13, 286, 393, 764, 264, 6919, 45033, 11, 286, 393, 764, 413, 21593, 13, 51836], "temperature": 0.0, "avg_logprob": -0.24994225697974637, "compression_ratio": 1.508108108108108, "no_speech_prob": 0.014519557356834412}, {"id": 141, "seek": 119288, "start": 1192.88, "end": 1196.0800000000002, "text": " Some AI translation tools help me.", "tokens": [50364, 2188, 7318, 12853, 3873, 854, 385, 13, 50524], "temperature": 0.0, "avg_logprob": -0.32610130310058594, "compression_ratio": 1.502857142857143, "no_speech_prob": 0.008828352205455303}, {"id": 142, "seek": 119288, "start": 1200.5600000000002, "end": 1204.0, "text": " Okay, here's my Apache Open Meetings Translation.", "tokens": [50748, 1033, 11, 510, 311, 452, 46597, 7238, 22963, 1109, 6531, 24278, 13, 50920], "temperature": 0.0, "avg_logprob": -0.32610130310058594, "compression_ratio": 1.502857142857143, "no_speech_prob": 0.008828352205455303}, {"id": 143, "seek": 119288, "start": 1207.7600000000002, "end": 1213.92, "text": " Apache Open Meetings, may I ask, have anybody heard about the project or used the project before?", "tokens": [51108, 46597, 7238, 22963, 1109, 11, 815, 286, 1029, 11, 362, 4472, 2198, 466, 264, 1716, 420, 1143, 264, 1716, 949, 30, 51416], "temperature": 0.0, "avg_logprob": -0.32610130310058594, "compression_ratio": 1.502857142857143, "no_speech_prob": 0.008828352205455303}, {"id": 144, "seek": 119288, "start": 1215.2800000000002, "end": 1222.0, "text": " Never have I heard? Okay, this online video conference system. Originally, it is", "tokens": [51484, 7344, 362, 286, 2198, 30, 1033, 11, 341, 2950, 960, 7586, 1185, 13, 28696, 11, 309, 307, 51820], "temperature": 0.0, "avg_logprob": -0.32610130310058594, "compression_ratio": 1.502857142857143, "no_speech_prob": 0.008828352205455303}, {"id": 145, "seek": 122288, "start": 1222.96, "end": 1233.1200000000001, "text": " from European. It is Apache project. It is only fully web browser based open source video", "tokens": [50368, 490, 6473, 13, 467, 307, 46597, 1716, 13, 467, 307, 787, 4498, 3670, 11185, 2361, 1269, 4009, 960, 50876], "temperature": 0.0, "avg_logprob": -0.2671606381734212, "compression_ratio": 1.4808743169398908, "no_speech_prob": 0.009418376721441746}, {"id": 146, "seek": 122288, "start": 1233.1200000000001, "end": 1239.2, "text": " conference system. No need to download apps, no need client-side installation. You can", "tokens": [50876, 7586, 1185, 13, 883, 643, 281, 5484, 7733, 11, 572, 643, 6423, 12, 1812, 13260, 13, 509, 393, 51180], "temperature": 0.0, "avg_logprob": -0.2671606381734212, "compression_ratio": 1.4808743169398908, "no_speech_prob": 0.009418376721441746}, {"id": 147, "seek": 122288, "start": 1239.2, "end": 1245.92, "text": " create a middle server for remote collaboration. The server can be installed either locally or", "tokens": [51180, 1884, 257, 2808, 7154, 337, 8607, 9363, 13, 440, 7154, 393, 312, 8899, 2139, 16143, 420, 51516], "temperature": 0.0, "avg_logprob": -0.2671606381734212, "compression_ratio": 1.4808743169398908, "no_speech_prob": 0.009418376721441746}, {"id": 148, "seek": 124592, "start": 1245.92, "end": 1253.8400000000001, "text": " via container. But I recommend use locally because if you're not very familiar with container,", "tokens": [50364, 5766, 10129, 13, 583, 286, 2748, 764, 16143, 570, 498, 291, 434, 406, 588, 4963, 365, 10129, 11, 50760], "temperature": 0.0, "avg_logprob": -0.2586791946227292, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.014317836612462997}, {"id": 149, "seek": 124592, "start": 1253.8400000000001, "end": 1257.92, "text": " in the installation or in the configuration process, probably you've got to trouble, right?", "tokens": [50760, 294, 264, 13260, 420, 294, 264, 11694, 1399, 11, 1391, 291, 600, 658, 281, 5253, 11, 558, 30, 50964], "temperature": 0.0, "avg_logprob": -0.2586791946227292, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.014317836612462997}, {"id": 150, "seek": 124592, "start": 1257.92, "end": 1263.04, "text": " Sometimes, you know, if you do not do the commit, you probably will lose the original configuration data.", "tokens": [50964, 4803, 11, 291, 458, 11, 498, 291, 360, 406, 360, 264, 5599, 11, 291, 1391, 486, 3624, 264, 3380, 11694, 1412, 13, 51220], "temperature": 0.0, "avg_logprob": -0.2586791946227292, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.014317836612462997}, {"id": 151, "seek": 124592, "start": 1266.3200000000002, "end": 1270.8000000000002, "text": " Usually, we need to install the server behind the term server for NAT configuration", "tokens": [51384, 11419, 11, 321, 643, 281, 3625, 264, 7154, 2261, 264, 1433, 7154, 337, 14500, 11694, 51608], "temperature": 0.0, "avg_logprob": -0.2586791946227292, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.014317836612462997}, {"id": 152, "seek": 127080, "start": 1270.8, "end": 1277.44, "text": " for the whole function. Otherwise, you cannot use system. The system supports multi-language.", "tokens": [50364, 337, 264, 1379, 2445, 13, 10328, 11, 291, 2644, 764, 1185, 13, 440, 1185, 9346, 4825, 12, 25241, 20473, 13, 50696], "temperature": 0.0, "avg_logprob": -0.1726798266172409, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.017993800342082977}, {"id": 153, "seek": 127080, "start": 1277.44, "end": 1286.72, "text": " The latest version now is 7.2.0. It supports 39 different languages.", "tokens": [50696, 440, 6792, 3037, 586, 307, 1614, 13, 17, 13, 15, 13, 467, 9346, 15238, 819, 8650, 13, 51160], "temperature": 0.0, "avg_logprob": -0.1726798266172409, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.017993800342082977}, {"id": 154, "seek": 127080, "start": 1289.9199999999998, "end": 1296.32, "text": " So, for the translation website, we cannot use just like Google Translators. You can", "tokens": [51320, 407, 11, 337, 264, 12853, 3144, 11, 321, 2644, 764, 445, 411, 3329, 6531, 75, 3391, 13, 509, 393, 51640], "temperature": 0.0, "avg_logprob": -0.1726798266172409, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.017993800342082977}, {"id": 155, "seek": 129632, "start": 1296.8799999999999, "end": 1302.8799999999999, "text": " use Google Translators for static website. But that's interactive, right? It's an interactive", "tokens": [50392, 764, 3329, 6531, 75, 3391, 337, 13437, 3144, 13, 583, 300, 311, 15141, 11, 558, 30, 467, 311, 364, 15141, 50692], "temperature": 0.0, "avg_logprob": -0.18951697879367405, "compression_ratio": 1.742081447963801, "no_speech_prob": 0.07888514548540115}, {"id": 156, "seek": 129632, "start": 1302.8799999999999, "end": 1311.52, "text": " website. We've got actions. We've got scripts. So, you can only use the original, use the building", "tokens": [50692, 3144, 13, 492, 600, 658, 5909, 13, 492, 600, 658, 23294, 13, 407, 11, 291, 393, 787, 764, 264, 3380, 11, 764, 264, 2390, 51124], "temperature": 0.0, "avg_logprob": -0.18951697879367405, "compression_ratio": 1.742081447963801, "no_speech_prob": 0.07888514548540115}, {"id": 157, "seek": 129632, "start": 1311.52, "end": 1317.6799999999998, "text": " framework to change the language. So, you need to change the labels and text strings. All language", "tokens": [51124, 8388, 281, 1319, 264, 2856, 13, 407, 11, 291, 643, 281, 1319, 264, 16949, 293, 2487, 13985, 13, 1057, 2856, 51432], "temperature": 0.0, "avg_logprob": -0.18951697879367405, "compression_ratio": 1.742081447963801, "no_speech_prob": 0.07888514548540115}, {"id": 158, "seek": 129632, "start": 1317.6799999999998, "end": 1323.6, "text": " strings should be localized and stored in the language section. You have full future language", "tokens": [51432, 13985, 820, 312, 44574, 293, 12187, 294, 264, 2856, 3541, 13, 509, 362, 1577, 2027, 2856, 51728], "temperature": 0.0, "avg_logprob": -0.18951697879367405, "compression_ratio": 1.742081447963801, "no_speech_prob": 0.07888514548540115}, {"id": 159, "seek": 132360, "start": 1323.6, "end": 1328.7199999999998, "text": " editor with every installation of open meetings. So, you need to check out the language editor", "tokens": [50364, 9839, 365, 633, 13260, 295, 1269, 8410, 13, 407, 11, 291, 643, 281, 1520, 484, 264, 2856, 9839, 50620], "temperature": 0.0, "avg_logprob": -0.1932608143667157, "compression_ratio": 1.6519823788546255, "no_speech_prob": 0.04078911989927292}, {"id": 160, "seek": 132360, "start": 1329.4399999999998, "end": 1335.36, "text": " to look up the label IDs in the GUI. Just you need to run the open meetings client with the debug", "tokens": [50656, 281, 574, 493, 264, 7645, 48212, 294, 264, 17917, 40, 13, 1449, 291, 643, 281, 1190, 264, 1269, 8410, 6423, 365, 264, 24083, 50952], "temperature": 0.0, "avg_logprob": -0.1932608143667157, "compression_ratio": 1.6519823788546255, "no_speech_prob": 0.04078911989927292}, {"id": 161, "seek": 132360, "start": 1335.36, "end": 1341.12, "text": " model. You cannot use the deploying model. The way every text string has label ID in", "tokens": [50952, 2316, 13, 509, 2644, 764, 264, 34198, 2316, 13, 440, 636, 633, 2487, 6798, 575, 7645, 7348, 294, 51240], "temperature": 0.0, "avg_logprob": -0.1932608143667157, "compression_ratio": 1.6519823788546255, "no_speech_prob": 0.04078911989927292}, {"id": 162, "seek": 132360, "start": 1341.12, "end": 1348.7199999999998, "text": " places additionally in the text field. Later on, I'm going to show you the difference between the", "tokens": [51240, 3190, 43181, 294, 264, 2487, 2519, 13, 11965, 322, 11, 286, 478, 516, 281, 855, 291, 264, 2649, 1296, 264, 51620], "temperature": 0.0, "avg_logprob": -0.1932608143667157, "compression_ratio": 1.6519823788546255, "no_speech_prob": 0.04078911989927292}, {"id": 163, "seek": 134872, "start": 1348.72, "end": 1360.8, "text": " deploying model and the debug model. Sorry, this one. So, the upside image is the original", "tokens": [50364, 34198, 2316, 293, 264, 24083, 2316, 13, 4919, 11, 341, 472, 13, 407, 11, 264, 14119, 3256, 307, 264, 3380, 50968], "temperature": 0.0, "avg_logprob": -0.4169724486594976, "compression_ratio": 1.3658536585365855, "no_speech_prob": 0.022292528301477432}, {"id": 164, "seek": 134872, "start": 1362.32, "end": 1371.84, "text": " language, this configuration file in Chinese. So, okay, when I first started,", "tokens": [51044, 2856, 11, 341, 11694, 3991, 294, 4649, 13, 407, 11, 1392, 11, 562, 286, 700, 1409, 11, 51520], "temperature": 0.0, "avg_logprob": -0.4169724486594976, "compression_ratio": 1.3658536585365855, "no_speech_prob": 0.022292528301477432}, {"id": 165, "seek": 137184, "start": 1372.8, "end": 1380.0, "text": " this is the one issue I found. I sent the issue to the JIRA for Apache. So, I said, okay, this", "tokens": [50412, 341, 307, 264, 472, 2734, 286, 1352, 13, 286, 2279, 264, 2734, 281, 264, 50172, 3750, 337, 46597, 13, 407, 11, 286, 848, 11, 1392, 11, 341, 50772], "temperature": 0.0, "avg_logprob": -0.23467815045228937, "compression_ratio": 1.695852534562212, "no_speech_prob": 0.055998314172029495}, {"id": 166, "seek": 137184, "start": 1380.0, "end": 1385.6, "text": " configuration file didn't work. Some labels didn't get translated. They said, okay, you can do", "tokens": [50772, 11694, 3991, 994, 380, 589, 13, 2188, 16949, 994, 380, 483, 16805, 13, 814, 848, 11, 1392, 11, 291, 393, 360, 51052], "temperature": 0.0, "avg_logprob": -0.23467815045228937, "compression_ratio": 1.695852534562212, "no_speech_prob": 0.055998314172029495}, {"id": 167, "seek": 137184, "start": 1385.6, "end": 1391.76, "text": " translation and you can send the file to the JIRA and we're going to update the source.", "tokens": [51052, 12853, 293, 291, 393, 2845, 264, 3991, 281, 264, 50172, 3750, 293, 321, 434, 516, 281, 5623, 264, 4009, 13, 51360], "temperature": 0.0, "avg_logprob": -0.23467815045228937, "compression_ratio": 1.695852534562212, "no_speech_prob": 0.055998314172029495}, {"id": 168, "seek": 137184, "start": 1393.52, "end": 1397.9199999999998, "text": " See, can you see the difference between the first image and the second image? There is one", "tokens": [51448, 3008, 11, 393, 291, 536, 264, 2649, 1296, 264, 700, 3256, 293, 264, 1150, 3256, 30, 821, 307, 472, 51668], "temperature": 0.0, "avg_logprob": -0.23467815045228937, "compression_ratio": 1.695852534562212, "no_speech_prob": 0.055998314172029495}, {"id": 169, "seek": 139792, "start": 1398.5600000000002, "end": 1405.8400000000001, "text": " actual space, right? You can see here, braces, the number braces, but upside means braces, space,", "tokens": [50396, 3539, 1901, 11, 558, 30, 509, 393, 536, 510, 11, 41537, 11, 264, 1230, 41537, 11, 457, 14119, 1355, 41537, 11, 1901, 11, 50760], "temperature": 0.0, "avg_logprob": -0.27729539556817695, "compression_ratio": 1.7, "no_speech_prob": 0.021946845576167107}, {"id": 170, "seek": 139792, "start": 1406.4, "end": 1414.4, "text": " braces. So, they used the file compare, found this problem and send emails to the group,", "tokens": [50788, 41537, 13, 407, 11, 436, 1143, 264, 3991, 6794, 11, 1352, 341, 1154, 293, 2845, 12524, 281, 264, 1594, 11, 51188], "temperature": 0.0, "avg_logprob": -0.27729539556817695, "compression_ratio": 1.7, "no_speech_prob": 0.021946845576167107}, {"id": 171, "seek": 139792, "start": 1414.4, "end": 1419.76, "text": " to the email list. There is an issue in Chinese translation, actual space characters. So, that's", "tokens": [51188, 281, 264, 3796, 1329, 13, 821, 307, 364, 2734, 294, 4649, 12853, 11, 3539, 1901, 4342, 13, 407, 11, 300, 311, 51456], "temperature": 0.0, "avg_logprob": -0.27729539556817695, "compression_ratio": 1.7, "no_speech_prob": 0.021946845576167107}, {"id": 172, "seek": 139792, "start": 1421.04, "end": 1426.5600000000002, "text": " not the lesson I learned, which means for the translation file, you cannot change anything", "tokens": [51520, 406, 264, 6898, 286, 3264, 11, 597, 1355, 337, 264, 12853, 3991, 11, 291, 2644, 1319, 1340, 51796], "temperature": 0.0, "avg_logprob": -0.27729539556817695, "compression_ratio": 1.7, "no_speech_prob": 0.021946845576167107}, {"id": 173, "seek": 142656, "start": 1426.56, "end": 1430.3999999999999, "text": " except the translated content. You cannot even add one more space.", "tokens": [50364, 3993, 264, 16805, 2701, 13, 509, 2644, 754, 909, 472, 544, 1901, 13, 50556], "temperature": 0.0, "avg_logprob": -0.21564210255940755, "compression_ratio": 1.4853801169590644, "no_speech_prob": 0.002296626102179289}, {"id": 174, "seek": 142656, "start": 1435.76, "end": 1442.96, "text": " Okay, I almost finished my presentation and there is some time left and I'm going to show", "tokens": [50824, 1033, 11, 286, 1920, 4335, 452, 5860, 293, 456, 307, 512, 565, 1411, 293, 286, 478, 516, 281, 855, 51184], "temperature": 0.0, "avg_logprob": -0.21564210255940755, "compression_ratio": 1.4853801169590644, "no_speech_prob": 0.002296626102179289}, {"id": 175, "seek": 142656, "start": 1442.96, "end": 1450.24, "text": " very quickly about the debug model and the debug model. So, here is my contact information and my", "tokens": [51184, 588, 2661, 466, 264, 24083, 2316, 293, 264, 24083, 2316, 13, 407, 11, 510, 307, 452, 3385, 1589, 293, 452, 51548], "temperature": 0.0, "avg_logprob": -0.21564210255940755, "compression_ratio": 1.4853801169590644, "no_speech_prob": 0.002296626102179289}, {"id": 176, "seek": 145024, "start": 1450.24, "end": 1467.92, "text": " emails. This is my website. Okay, excuse me.", "tokens": [50364, 12524, 13, 639, 307, 452, 3144, 13, 1033, 11, 8960, 385, 13, 51248], "temperature": 0.0, "avg_logprob": -0.4573413848876953, "compression_ratio": 0.88, "no_speech_prob": 0.20684681832790375}, {"id": 177, "seek": 148024, "start": 1480.24, "end": 1490.24, "text": " I used that mean log in system.", "tokens": [50364, 286, 1143, 300, 914, 3565, 294, 1185, 13, 50864], "temperature": 0.0, "avg_logprob": -0.38718700408935547, "compression_ratio": 1.2371134020618557, "no_speech_prob": 0.005161437205970287}, {"id": 178, "seek": 148024, "start": 1495.76, "end": 1503.04, "text": " This is already Chinese version because we set the added profile here. I already set the", "tokens": [51140, 639, 307, 1217, 4649, 3037, 570, 321, 992, 264, 3869, 7964, 510, 13, 286, 1217, 992, 264, 51504], "temperature": 0.0, "avg_logprob": -0.38718700408935547, "compression_ratio": 1.2371134020618557, "no_speech_prob": 0.005161437205970287}, {"id": 179, "seek": 150304, "start": 1503.6, "end": 1510.8, "text": " language in Chinese, set time zone in Asian Singapore, but here you cannot see every", "tokens": [50392, 2856, 294, 4649, 11, 992, 565, 6668, 294, 10645, 14491, 11, 457, 510, 291, 2644, 536, 633, 50752], "temperature": 0.0, "avg_logprob": -0.21082647744711344, "compression_ratio": 1.558011049723757, "no_speech_prob": 0.07942657172679901}, {"id": 180, "seek": 150304, "start": 1511.68, "end": 1518.8799999999999, "text": " label. There is no label ID, right? No label ID. So, how can I bring out the label ID? Because", "tokens": [50796, 7645, 13, 821, 307, 572, 7645, 7348, 11, 558, 30, 883, 7645, 7348, 13, 407, 11, 577, 393, 286, 1565, 484, 264, 7645, 7348, 30, 1436, 51156], "temperature": 0.0, "avg_logprob": -0.21082647744711344, "compression_ratio": 1.558011049723757, "no_speech_prob": 0.07942657172679901}, {"id": 181, "seek": 150304, "start": 1518.8799999999999, "end": 1526.3999999999999, "text": " if you want to change, if you have no label ID, okay, let me bring back to English so you can read it.", "tokens": [51156, 498, 291, 528, 281, 1319, 11, 498, 291, 362, 572, 7645, 7348, 11, 1392, 11, 718, 385, 1565, 646, 281, 3669, 370, 291, 393, 1401, 309, 13, 51532], "temperature": 0.0, "avg_logprob": -0.21082647744711344, "compression_ratio": 1.558011049723757, "no_speech_prob": 0.07942657172679901}, {"id": 182, "seek": 153304, "start": 1533.2, "end": 1551.52, "text": " So,", "tokens": [50372, 407, 11, 51288], "temperature": 1.0, "avg_logprob": -1.9386707941691081, "compression_ratio": 0.2727272727272727, "no_speech_prob": 0.3163001835346222}, {"id": 183, "seek": 155152, "start": 1551.52, "end": 1553.52, "text": " current password request.", "tokens": [50364, 2190, 11524, 5308, 13, 50464], "temperature": 0.0, "avg_logprob": -0.408862928064858, "compression_ratio": 1.304, "no_speech_prob": 0.3646029233932495}, {"id": 184, "seek": 155152, "start": 1562.52, "end": 1564.52, "text": " Okay, we'll change.", "tokens": [50914, 1033, 11, 321, 603, 1319, 13, 51014], "temperature": 0.0, "avg_logprob": -0.408862928064858, "compression_ratio": 1.304, "no_speech_prob": 0.3646029233932495}, {"id": 185, "seek": 155152, "start": 1564.52, "end": 1566.52, "text": " Every time you change the language configuration,", "tokens": [51014, 2048, 565, 291, 1319, 264, 2856, 11694, 11, 51114], "temperature": 0.0, "avg_logprob": -0.408862928064858, "compression_ratio": 1.304, "no_speech_prob": 0.3646029233932495}, {"id": 186, "seek": 155152, "start": 1566.52, "end": 1571.52, "text": " it will take effect immediately after you log in and log out again.", "tokens": [51114, 309, 486, 747, 1802, 4258, 934, 291, 3565, 294, 293, 3565, 484, 797, 13, 51364], "temperature": 0.0, "avg_logprob": -0.408862928064858, "compression_ratio": 1.304, "no_speech_prob": 0.3646029233932495}, {"id": 187, "seek": 158152, "start": 1582.52, "end": 1587.52, "text": " So now you can see the interface already changed to English, right?", "tokens": [50414, 407, 586, 291, 393, 536, 264, 9226, 1217, 3105, 281, 3669, 11, 558, 30, 50664], "temperature": 0.0, "avg_logprob": -0.2929693777349931, "compression_ratio": 1.5126903553299493, "no_speech_prob": 0.09057237952947617}, {"id": 188, "seek": 158152, "start": 1587.52, "end": 1591.52, "text": " But for each label, like if I wanted to do translation,", "tokens": [50664, 583, 337, 1184, 7645, 11, 411, 498, 286, 1415, 281, 360, 12853, 11, 50864], "temperature": 0.0, "avg_logprob": -0.2929693777349931, "compression_ratio": 1.5126903553299493, "no_speech_prob": 0.09057237952947617}, {"id": 189, "seek": 158152, "start": 1591.52, "end": 1596.52, "text": " so if you don't know the label ID, you need the Geltron Language Editor,", "tokens": [50864, 370, 498, 291, 500, 380, 458, 264, 7645, 7348, 11, 291, 643, 264, 460, 2018, 2044, 24445, 24281, 11, 51114], "temperature": 0.0, "avg_logprob": -0.2929693777349931, "compression_ratio": 1.5126903553299493, "no_speech_prob": 0.09057237952947617}, {"id": 190, "seek": 158152, "start": 1596.52, "end": 1601.52, "text": " you need find the corresponding language file,", "tokens": [51114, 291, 643, 915, 264, 11760, 2856, 3991, 11, 51364], "temperature": 0.0, "avg_logprob": -0.2929693777349931, "compression_ratio": 1.5126903553299493, "no_speech_prob": 0.09057237952947617}, {"id": 191, "seek": 158152, "start": 1601.52, "end": 1603.52, "text": " which is...", "tokens": [51364, 597, 307, 485, 51464], "temperature": 0.0, "avg_logprob": -0.2929693777349931, "compression_ratio": 1.5126903553299493, "no_speech_prob": 0.09057237952947617}, {"id": 192, "seek": 158152, "start": 1606.52, "end": 1609.52, "text": " We got a language configuration file here.", "tokens": [51614, 492, 658, 257, 2856, 11694, 3991, 510, 13, 51764], "temperature": 0.0, "avg_logprob": -0.2929693777349931, "compression_ratio": 1.5126903553299493, "no_speech_prob": 0.09057237952947617}, {"id": 193, "seek": 160952, "start": 1610.52, "end": 1614.52, "text": " So you can see total is 39 different language files, right?", "tokens": [50414, 407, 291, 393, 536, 3217, 307, 15238, 819, 2856, 7098, 11, 558, 30, 50614], "temperature": 0.0, "avg_logprob": -0.1985329818725586, "compression_ratio": 1.4885057471264367, "no_speech_prob": 0.036359164863824844}, {"id": 194, "seek": 160952, "start": 1614.52, "end": 1617.52, "text": " For example, for Chinese, that's 11.", "tokens": [50614, 1171, 1365, 11, 337, 4649, 11, 300, 311, 2975, 13, 50764], "temperature": 0.0, "avg_logprob": -0.1985329818725586, "compression_ratio": 1.4885057471264367, "no_speech_prob": 0.036359164863824844}, {"id": 195, "seek": 160952, "start": 1617.52, "end": 1622.52, "text": " And also you can change it to French or to Dutch.", "tokens": [50764, 400, 611, 291, 393, 1319, 309, 281, 5522, 420, 281, 15719, 13, 51014], "temperature": 0.0, "avg_logprob": -0.1985329818725586, "compression_ratio": 1.4885057471264367, "no_speech_prob": 0.036359164863824844}, {"id": 196, "seek": 160952, "start": 1625.52, "end": 1634.52, "text": " So for example, if I want to change like a project website, right?", "tokens": [51164, 407, 337, 1365, 11, 498, 286, 528, 281, 1319, 411, 257, 1716, 3144, 11, 558, 30, 51614], "temperature": 0.0, "avg_logprob": -0.1985329818725586, "compression_ratio": 1.4885057471264367, "no_speech_prob": 0.036359164863824844}, {"id": 197, "seek": 160952, "start": 1634.52, "end": 1636.52, "text": " If you want to rebranding or to do something,", "tokens": [51614, 759, 291, 528, 281, 12970, 3699, 278, 420, 281, 360, 746, 11, 51714], "temperature": 0.0, "avg_logprob": -0.1985329818725586, "compression_ratio": 1.4885057471264367, "no_speech_prob": 0.036359164863824844}, {"id": 198, "seek": 163652, "start": 1636.52, "end": 1639.52, "text": " if you want to change this one, if you have no label ID,", "tokens": [50364, 498, 291, 528, 281, 1319, 341, 472, 11, 498, 291, 362, 572, 7645, 7348, 11, 50514], "temperature": 0.0, "avg_logprob": -0.19046844974640878, "compression_ratio": 1.609375, "no_speech_prob": 0.05685193091630936}, {"id": 199, "seek": 163652, "start": 1639.52, "end": 1641.52, "text": " you got to remember the text ID.", "tokens": [50514, 291, 658, 281, 1604, 264, 2487, 7348, 13, 50614], "temperature": 0.0, "avg_logprob": -0.19046844974640878, "compression_ratio": 1.609375, "no_speech_prob": 0.05685193091630936}, {"id": 200, "seek": 163652, "start": 1641.52, "end": 1646.52, "text": " So go to the language editor, go to the...", "tokens": [50614, 407, 352, 281, 264, 2856, 9839, 11, 352, 281, 264, 485, 50864], "temperature": 0.0, "avg_logprob": -0.19046844974640878, "compression_ratio": 1.609375, "no_speech_prob": 0.05685193091630936}, {"id": 201, "seek": 163652, "start": 1648.52, "end": 1650.52, "text": " Then you need the remember.", "tokens": [50964, 1396, 291, 643, 264, 1604, 13, 51064], "temperature": 0.0, "avg_logprob": -0.19046844974640878, "compression_ratio": 1.609375, "no_speech_prob": 0.05685193091630936}, {"id": 202, "seek": 163652, "start": 1650.52, "end": 1653.52, "text": " I remember because I test many times, I remember the label ID.", "tokens": [51064, 286, 1604, 570, 286, 1500, 867, 1413, 11, 286, 1604, 264, 7645, 7348, 13, 51214], "temperature": 0.0, "avg_logprob": -0.19046844974640878, "compression_ratio": 1.609375, "no_speech_prob": 0.05685193091630936}, {"id": 203, "seek": 163652, "start": 1653.52, "end": 1658.52, "text": " It's 282, so you can change it here, right?", "tokens": [51214, 467, 311, 7562, 17, 11, 370, 291, 393, 1319, 309, 510, 11, 558, 30, 51464], "temperature": 0.0, "avg_logprob": -0.19046844974640878, "compression_ratio": 1.609375, "no_speech_prob": 0.05685193091630936}, {"id": 204, "seek": 163652, "start": 1661.52, "end": 1664.52, "text": " Okay, then let's see the deploying model.", "tokens": [51614, 1033, 11, 550, 718, 311, 536, 264, 34198, 2316, 13, 51764], "temperature": 0.0, "avg_logprob": -0.19046844974640878, "compression_ratio": 1.609375, "no_speech_prob": 0.05685193091630936}, {"id": 205, "seek": 166652, "start": 1667.52, "end": 1670.52, "text": " Oh, so...", "tokens": [50414, 876, 11, 370, 485, 50564], "temperature": 0.0, "avg_logprob": -0.35267152786254885, "compression_ratio": 1.0941176470588236, "no_speech_prob": 0.045500148087739944}, {"id": 206, "seek": 166652, "start": 1686.52, "end": 1691.52, "text": " There is a configuration file, WIPER.xml here,", "tokens": [51364, 821, 307, 257, 11694, 3991, 11, 343, 9139, 1598, 13, 87, 15480, 510, 11, 51614], "temperature": 0.0, "avg_logprob": -0.35267152786254885, "compression_ratio": 1.0941176470588236, "no_speech_prob": 0.045500148087739944}, {"id": 207, "seek": 166652, "start": 1691.52, "end": 1695.52, "text": " so you need to go to your WIPER.xml,", "tokens": [51614, 370, 291, 643, 281, 352, 281, 428, 343, 9139, 1598, 13, 87, 15480, 11, 51814], "temperature": 0.0, "avg_logprob": -0.35267152786254885, "compression_ratio": 1.0941176470588236, "no_speech_prob": 0.045500148087739944}, {"id": 208, "seek": 169552, "start": 1695.52, "end": 1702.52, "text": " then you search the deploying model.", "tokens": [50364, 550, 291, 3164, 264, 34198, 2316, 13, 50714], "temperature": 0.0, "avg_logprob": -0.17367177851059856, "compression_ratio": 1.528735632183908, "no_speech_prob": 0.011959115043282509}, {"id": 209, "seek": 169552, "start": 1706.52, "end": 1710.52, "text": " You can see that's a deploying model.", "tokens": [50914, 509, 393, 536, 300, 311, 257, 34198, 2316, 13, 51114], "temperature": 0.0, "avg_logprob": -0.17367177851059856, "compression_ratio": 1.528735632183908, "no_speech_prob": 0.011959115043282509}, {"id": 210, "seek": 169552, "start": 1710.52, "end": 1714.52, "text": " You need to change the deploying to the development model.", "tokens": [51114, 509, 643, 281, 1319, 264, 34198, 281, 264, 3250, 2316, 13, 51314], "temperature": 0.0, "avg_logprob": -0.17367177851059856, "compression_ratio": 1.528735632183908, "no_speech_prob": 0.011959115043282509}, {"id": 211, "seek": 172552, "start": 1725.52, "end": 1735.52, "text": " To deploy model, now the added command...", "tokens": [50364, 1407, 7274, 2316, 11, 586, 264, 3869, 5622, 485, 50864], "temperature": 0.0, "avg_logprob": -0.45532357065301193, "compression_ratio": 1.1145833333333333, "no_speech_prob": 0.12587973475456238}, {"id": 212, "seek": 172552, "start": 1735.52, "end": 1738.52, "text": " Oh, sorry, small case.", "tokens": [50864, 876, 11, 2597, 11, 1359, 1389, 13, 51014], "temperature": 0.0, "avg_logprob": -0.45532357065301193, "compression_ratio": 1.1145833333333333, "no_speech_prob": 0.12587973475456238}, {"id": 213, "seek": 172552, "start": 1744.52, "end": 1745.52, "text": " Okay.", "tokens": [51314, 1033, 13, 51364], "temperature": 0.0, "avg_logprob": -0.45532357065301193, "compression_ratio": 1.1145833333333333, "no_speech_prob": 0.12587973475456238}, {"id": 214, "seek": 172552, "start": 1747.52, "end": 1749.52, "text": " Now you can see we change it, right?", "tokens": [51464, 823, 291, 393, 536, 321, 1319, 309, 11, 558, 30, 51564], "temperature": 0.0, "avg_logprob": -0.45532357065301193, "compression_ratio": 1.1145833333333333, "no_speech_prob": 0.12587973475456238}, {"id": 215, "seek": 174952, "start": 1749.52, "end": 1751.52, "text": " Change and then...", "tokens": [50364, 15060, 293, 550, 485, 50464], "temperature": 0.0, "avg_logprob": -0.3360104825761583, "compression_ratio": 0.9636363636363636, "no_speech_prob": 0.264950692653656}, {"id": 216, "seek": 174952, "start": 1757.52, "end": 1762.52, "text": " Come out, then restart the server.", "tokens": [50764, 2492, 484, 11, 550, 21022, 264, 7154, 13, 51014], "temperature": 0.0, "avg_logprob": -0.3360104825761583, "compression_ratio": 0.9636363636363636, "no_speech_prob": 0.264950692653656}, {"id": 217, "seek": 176252, "start": 1762.52, "end": 1767.52, "text": " Okay.", "tokens": [50364, 1033, 13, 50614], "temperature": 0.0, "avg_logprob": -0.4770873955317906, "compression_ratio": 0.8780487804878049, "no_speech_prob": 0.15885040163993835}, {"id": 218, "seek": 176252, "start": 1777.52, "end": 1780.52, "text": " We restart the server, then...", "tokens": [51114, 492, 21022, 264, 7154, 11, 550, 485, 51264], "temperature": 0.0, "avg_logprob": -0.4770873955317906, "compression_ratio": 0.8780487804878049, "no_speech_prob": 0.15885040163993835}, {"id": 219, "seek": 179252, "start": 1792.52, "end": 1794.52, "text": " I need to...", "tokens": [50364, 286, 643, 281, 485, 50464], "temperature": 0.0, "avg_logprob": -0.3204193868135151, "compression_ratio": 1.1720430107526882, "no_speech_prob": 0.08840124309062958}, {"id": 220, "seek": 179252, "start": 1800.52, "end": 1803.52, "text": " I need to make sure the server is start up.", "tokens": [50764, 286, 643, 281, 652, 988, 264, 7154, 307, 722, 493, 13, 50914], "temperature": 0.0, "avg_logprob": -0.3204193868135151, "compression_ratio": 1.1720430107526882, "no_speech_prob": 0.08840124309062958}, {"id": 221, "seek": 179252, "start": 1807.52, "end": 1809.52, "text": " Okay, so we start.", "tokens": [51114, 1033, 11, 370, 321, 722, 13, 51214], "temperature": 0.0, "avg_logprob": -0.3204193868135151, "compression_ratio": 1.1720430107526882, "no_speech_prob": 0.08840124309062958}, {"id": 222, "seek": 179252, "start": 1809.52, "end": 1813.52, "text": " Then I used admin to login again.", "tokens": [51214, 1396, 286, 1143, 24236, 281, 24276, 797, 13, 51414], "temperature": 0.0, "avg_logprob": -0.3204193868135151, "compression_ratio": 1.1720430107526882, "no_speech_prob": 0.08840124309062958}, {"id": 223, "seek": 182252, "start": 1822.52, "end": 1829.52, "text": " You only need to be slow.", "tokens": [50364, 509, 787, 643, 281, 312, 2964, 13, 50714], "temperature": 0.0, "avg_logprob": -0.41752370198567706, "compression_ratio": 1.4587155963302751, "no_speech_prob": 0.018893931061029434}, {"id": 224, "seek": 182252, "start": 1835.52, "end": 1838.52, "text": " Let's sort install the virtual machine,", "tokens": [51014, 961, 311, 1333, 3625, 264, 6374, 3479, 11, 51164], "temperature": 0.0, "avg_logprob": -0.41752370198567706, "compression_ratio": 1.4587155963302751, "no_speech_prob": 0.018893931061029434}, {"id": 225, "seek": 182252, "start": 1838.52, "end": 1843.52, "text": " so all the memory is already exhausted, almost exhausted,", "tokens": [51164, 370, 439, 264, 4675, 307, 1217, 17992, 11, 1920, 17992, 11, 51414], "temperature": 0.0, "avg_logprob": -0.41752370198567706, "compression_ratio": 1.4587155963302751, "no_speech_prob": 0.018893931061029434}, {"id": 226, "seek": 182252, "start": 1843.52, "end": 1846.52, "text": " so you only need to be slow, sorry.", "tokens": [51414, 370, 291, 787, 643, 281, 312, 2964, 11, 2597, 13, 51564], "temperature": 0.0, "avg_logprob": -0.41752370198567706, "compression_ratio": 1.4587155963302751, "no_speech_prob": 0.018893931061029434}, {"id": 227, "seek": 185252, "start": 1853.52, "end": 1859.52, "text": " Do the thing.", "tokens": [50414, 1144, 264, 551, 13, 50714], "temperature": 0.0, "avg_logprob": -0.5553346739874946, "compression_ratio": 1.0, "no_speech_prob": 0.10021001100540161}, {"id": 228, "seek": 185252, "start": 1870.52, "end": 1871.52, "text": " Sorry.", "tokens": [51264, 4919, 13, 51314], "temperature": 0.0, "avg_logprob": -0.5553346739874946, "compression_ratio": 1.0, "no_speech_prob": 0.10021001100540161}, {"id": 229, "seek": 185252, "start": 1875.52, "end": 1877.52, "text": " Some bad things happened.", "tokens": [51514, 2188, 1578, 721, 2011, 13, 51614], "temperature": 0.0, "avg_logprob": -0.5553346739874946, "compression_ratio": 1.0, "no_speech_prob": 0.10021001100540161}, {"id": 230, "seek": 188252, "start": 1883.52, "end": 1894.52, "text": " Okay, now you can see this is in the DIPWIPER model.", "tokens": [50414, 1033, 11, 586, 291, 393, 536, 341, 307, 294, 264, 413, 9139, 54, 9139, 1598, 2316, 13, 50964], "temperature": 0.0, "avg_logprob": -0.1965723481289176, "compression_ratio": 1.5310734463276836, "no_speech_prob": 0.01117992028594017}, {"id": 231, "seek": 188252, "start": 1894.52, "end": 1898.52, "text": " See, from here you can see each text label,", "tokens": [50964, 3008, 11, 490, 510, 291, 393, 536, 1184, 2487, 7645, 11, 51164], "temperature": 0.0, "avg_logprob": -0.1965723481289176, "compression_ratio": 1.5310734463276836, "no_speech_prob": 0.01117992028594017}, {"id": 232, "seek": 188252, "start": 1898.52, "end": 1901.52, "text": " you got a label ID, right?", "tokens": [51164, 291, 658, 257, 7645, 7348, 11, 558, 30, 51314], "temperature": 0.0, "avg_logprob": -0.1965723481289176, "compression_ratio": 1.5310734463276836, "no_speech_prob": 0.01117992028594017}, {"id": 233, "seek": 188252, "start": 1901.52, "end": 1903.52, "text": " So if you want to change the label,", "tokens": [51314, 407, 498, 291, 528, 281, 1319, 264, 7645, 11, 51414], "temperature": 0.0, "avg_logprob": -0.1965723481289176, "compression_ratio": 1.5310734463276836, "no_speech_prob": 0.01117992028594017}, {"id": 234, "seek": 188252, "start": 1903.52, "end": 1905.52, "text": " you just go to your language editor,", "tokens": [51414, 291, 445, 352, 281, 428, 2856, 9839, 11, 51514], "temperature": 0.0, "avg_logprob": -0.1965723481289176, "compression_ratio": 1.5310734463276836, "no_speech_prob": 0.01117992028594017}, {"id": 235, "seek": 188252, "start": 1905.52, "end": 1907.52, "text": " find the label ID number, change it,", "tokens": [51514, 915, 264, 7645, 7348, 1230, 11, 1319, 309, 11, 51614], "temperature": 0.0, "avg_logprob": -0.1965723481289176, "compression_ratio": 1.5310734463276836, "no_speech_prob": 0.01117992028594017}, {"id": 236, "seek": 188252, "start": 1907.52, "end": 1909.52, "text": " then you can get a different version.", "tokens": [51614, 550, 291, 393, 483, 257, 819, 3037, 13, 51714], "temperature": 0.0, "avg_logprob": -0.1965723481289176, "compression_ratio": 1.5310734463276836, "no_speech_prob": 0.01117992028594017}, {"id": 237, "seek": 190952, "start": 1910.52, "end": 1913.52, "text": " Okay, thanks.", "tokens": [50414, 1033, 11, 3231, 13, 50564], "temperature": 0.0, "avg_logprob": -0.2753234803676605, "compression_ratio": 1.1538461538461537, "no_speech_prob": 0.01816345378756523}, {"id": 238, "seek": 190952, "start": 1913.52, "end": 1915.52, "text": " I finished my presentation.", "tokens": [50564, 286, 4335, 452, 5860, 13, 50664], "temperature": 0.0, "avg_logprob": -0.2753234803676605, "compression_ratio": 1.1538461538461537, "no_speech_prob": 0.01816345378756523}, {"id": 239, "seek": 190952, "start": 1915.52, "end": 1919.52, "text": " If you got any questions, I would be more than happy to answer.", "tokens": [50664, 759, 291, 658, 604, 1651, 11, 286, 576, 312, 544, 813, 2055, 281, 1867, 13, 50864], "temperature": 0.0, "avg_logprob": -0.2753234803676605, "compression_ratio": 1.1538461538461537, "no_speech_prob": 0.01816345378756523}, {"id": 240, "seek": 191952, "start": 1920.52, "end": 1922.52, "text": " Thank you.", "tokens": [50414, 1044, 291, 13, 50514], "temperature": 0.0, "avg_logprob": -0.2977142035961151, "compression_ratio": 1.2282608695652173, "no_speech_prob": 0.1430090367794037}, {"id": 241, "seek": 191952, "start": 1937.52, "end": 1940.52, "text": " So translating the open source report,", "tokens": [51264, 407, 35030, 264, 1269, 4009, 2275, 11, 51414], "temperature": 0.0, "avg_logprob": -0.2977142035961151, "compression_ratio": 1.2282608695652173, "no_speech_prob": 0.1430090367794037}, {"id": 242, "seek": 191952, "start": 1940.52, "end": 1946.52, "text": " what was the format of the files that you used as a translator?", "tokens": [51414, 437, 390, 264, 7877, 295, 264, 7098, 300, 291, 1143, 382, 257, 35223, 30, 51714], "temperature": 0.0, "avg_logprob": -0.2977142035961151, "compression_ratio": 1.2282608695652173, "no_speech_prob": 0.1430090367794037}, {"id": 243, "seek": 194652, "start": 1946.52, "end": 1949.52, "text": " Was it Google Docs, was it PO,", "tokens": [50364, 3027, 309, 3329, 16024, 82, 11, 390, 309, 22299, 11, 50514], "temperature": 0.0, "avg_logprob": -0.3194220531945941, "compression_ratio": 1.5544041450777202, "no_speech_prob": 0.13494141399860382}, {"id": 244, "seek": 194652, "start": 1949.52, "end": 1954.52, "text": " was it actually for what you used in which format?", "tokens": [50514, 390, 309, 767, 337, 437, 291, 1143, 294, 597, 7877, 30, 50764], "temperature": 0.0, "avg_logprob": -0.3194220531945941, "compression_ratio": 1.5544041450777202, "no_speech_prob": 0.13494141399860382}, {"id": 245, "seek": 194652, "start": 1954.52, "end": 1960.52, "text": " For the source file, we upload the file to the Google Documents,", "tokens": [50764, 1171, 264, 4009, 3991, 11, 321, 6580, 264, 3991, 281, 264, 3329, 16024, 4697, 11, 51064], "temperature": 0.0, "avg_logprob": -0.3194220531945941, "compression_ratio": 1.5544041450777202, "no_speech_prob": 0.13494141399860382}, {"id": 246, "seek": 194652, "start": 1960.52, "end": 1964.52, "text": " and each team members, if you want to identify which part", "tokens": [51064, 293, 1184, 1469, 2679, 11, 498, 291, 528, 281, 5876, 597, 644, 51264], "temperature": 0.0, "avg_logprob": -0.3194220531945941, "compression_ratio": 1.5544041450777202, "no_speech_prob": 0.13494141399860382}, {"id": 247, "seek": 194652, "start": 1964.52, "end": 1968.52, "text": " you want to translate, you just label,", "tokens": [51264, 291, 528, 281, 13799, 11, 291, 445, 7645, 11, 51464], "temperature": 0.0, "avg_logprob": -0.3194220531945941, "compression_ratio": 1.5544041450777202, "no_speech_prob": 0.13494141399860382}, {"id": 248, "seek": 194652, "start": 1968.52, "end": 1971.52, "text": " select text and say, okay, this part I'm going to do it.", "tokens": [51464, 3048, 2487, 293, 584, 11, 1392, 11, 341, 644, 286, 478, 516, 281, 360, 309, 13, 51614], "temperature": 0.0, "avg_logprob": -0.3194220531945941, "compression_ratio": 1.5544041450777202, "no_speech_prob": 0.13494141399860382}, {"id": 249, "seek": 197152, "start": 1972.52, "end": 1976.52, "text": " So the translator works directly in the Google Docs?", "tokens": [50414, 407, 264, 35223, 1985, 3838, 294, 264, 3329, 16024, 82, 30, 50614], "temperature": 0.0, "avg_logprob": -0.2572350569174323, "compression_ratio": 1.4090909090909092, "no_speech_prob": 0.04153725504875183}, {"id": 250, "seek": 197152, "start": 1976.52, "end": 1977.52, "text": " Yeah, yeah, yeah.", "tokens": [50614, 865, 11, 1338, 11, 1338, 13, 50664], "temperature": 0.0, "avg_logprob": -0.2572350569174323, "compression_ratio": 1.4090909090909092, "no_speech_prob": 0.04153725504875183}, {"id": 251, "seek": 197152, "start": 1977.52, "end": 1981.52, "text": " Translate it, we got no problem to access the Google Documents", "tokens": [50664, 6531, 17593, 309, 11, 321, 658, 572, 1154, 281, 2105, 264, 3329, 16024, 4697, 50864], "temperature": 0.0, "avg_logprob": -0.2572350569174323, "compression_ratio": 1.4090909090909092, "no_speech_prob": 0.04153725504875183}, {"id": 252, "seek": 197152, "start": 1981.52, "end": 1985.52, "text": " because almost everybody we use the VPN, you know.", "tokens": [50864, 570, 1920, 2201, 321, 764, 264, 24512, 11, 291, 458, 13, 51064], "temperature": 0.0, "avg_logprob": -0.2572350569174323, "compression_ratio": 1.4090909090909092, "no_speech_prob": 0.04153725504875183}, {"id": 253, "seek": 197152, "start": 1986.52, "end": 1988.52, "text": " Good question.", "tokens": [51114, 2205, 1168, 13, 51214], "temperature": 0.0, "avg_logprob": -0.2572350569174323, "compression_ratio": 1.4090909090909092, "no_speech_prob": 0.04153725504875183}, {"id": 254, "seek": 197152, "start": 1988.52, "end": 1990.52, "text": " Thanks.", "tokens": [51214, 2561, 13, 51314], "temperature": 0.0, "avg_logprob": -0.2572350569174323, "compression_ratio": 1.4090909090909092, "no_speech_prob": 0.04153725504875183}, {"id": 255, "seek": 197152, "start": 1993.52, "end": 1998.52, "text": " You have some way to detect space issues", "tokens": [51464, 509, 362, 512, 636, 281, 5531, 1901, 2663, 51714], "temperature": 0.0, "avg_logprob": -0.2572350569174323, "compression_ratio": 1.4090909090909092, "no_speech_prob": 0.04153725504875183}, {"id": 256, "seek": 199852, "start": 1998.52, "end": 2003.52, "text": " or using the maybe double width character", "tokens": [50364, 420, 1228, 264, 1310, 3834, 11402, 2517, 50614], "temperature": 0.0, "avg_logprob": -0.2520520059685958, "compression_ratio": 1.5611111111111111, "no_speech_prob": 0.05180533975362778}, {"id": 257, "seek": 199852, "start": 2003.52, "end": 2008.52, "text": " instead of the format character, the spaces?", "tokens": [50614, 2602, 295, 264, 7877, 2517, 11, 264, 7673, 30, 50864], "temperature": 0.0, "avg_logprob": -0.2520520059685958, "compression_ratio": 1.5611111111111111, "no_speech_prob": 0.05180533975362778}, {"id": 258, "seek": 199852, "start": 2008.52, "end": 2011.52, "text": " Yeah, for the spaces,", "tokens": [50864, 865, 11, 337, 264, 7673, 11, 51014], "temperature": 0.0, "avg_logprob": -0.2520520059685958, "compression_ratio": 1.5611111111111111, "no_speech_prob": 0.05180533975362778}, {"id": 259, "seek": 199852, "start": 2011.52, "end": 2016.52, "text": " I'm not 100% sure how the project leader he found the spaces,", "tokens": [51014, 286, 478, 406, 2319, 4, 988, 577, 264, 1716, 5263, 415, 1352, 264, 7673, 11, 51264], "temperature": 0.0, "avg_logprob": -0.2520520059685958, "compression_ratio": 1.5611111111111111, "no_speech_prob": 0.05180533975362778}, {"id": 260, "seek": 199852, "start": 2016.52, "end": 2020.52, "text": " but I know some guys, they use the file compression.", "tokens": [51264, 457, 286, 458, 512, 1074, 11, 436, 764, 264, 3991, 19355, 13, 51464], "temperature": 0.0, "avg_logprob": -0.2520520059685958, "compression_ratio": 1.5611111111111111, "no_speech_prob": 0.05180533975362778}, {"id": 261, "seek": 199852, "start": 2020.52, "end": 2024.52, "text": " Like in VSS Studio, there is a file compression function.", "tokens": [51464, 1743, 294, 691, 21929, 13500, 11, 456, 307, 257, 3991, 19355, 2445, 13, 51664], "temperature": 0.0, "avg_logprob": -0.2520520059685958, "compression_ratio": 1.5611111111111111, "no_speech_prob": 0.05180533975362778}, {"id": 262, "seek": 202452, "start": 2024.52, "end": 2027.52, "text": " You can use the file compression to compare the source file", "tokens": [50364, 509, 393, 764, 264, 3991, 19355, 281, 6794, 264, 4009, 3991, 50514], "temperature": 0.0, "avg_logprob": -0.19781787486015995, "compression_ratio": 1.927710843373494, "no_speech_prob": 0.025598283857107162}, {"id": 263, "seek": 202452, "start": 2027.52, "end": 2030.52, "text": " and the translation file to find the extra space.", "tokens": [50514, 293, 264, 12853, 3991, 281, 915, 264, 2857, 1901, 13, 50664], "temperature": 0.0, "avg_logprob": -0.19781787486015995, "compression_ratio": 1.927710843373494, "no_speech_prob": 0.025598283857107162}, {"id": 264, "seek": 202452, "start": 2036.52, "end": 2039.52, "text": " Yeah, I don't appreciate it.", "tokens": [50964, 865, 11, 286, 500, 380, 4449, 309, 13, 51114], "temperature": 0.0, "avg_logprob": -0.19781787486015995, "compression_ratio": 1.927710843373494, "no_speech_prob": 0.025598283857107162}, {"id": 265, "seek": 202452, "start": 2039.52, "end": 2044.52, "text": " Do you use translation memory to speed up your translation process?", "tokens": [51114, 1144, 291, 764, 12853, 4675, 281, 3073, 493, 428, 12853, 1399, 30, 51364], "temperature": 0.0, "avg_logprob": -0.19781787486015995, "compression_ratio": 1.927710843373494, "no_speech_prob": 0.025598283857107162}, {"id": 266, "seek": 202452, "start": 2044.52, "end": 2046.52, "text": " Excuse me?", "tokens": [51364, 11359, 385, 30, 51464], "temperature": 0.0, "avg_logprob": -0.19781787486015995, "compression_ratio": 1.927710843373494, "no_speech_prob": 0.025598283857107162}, {"id": 267, "seek": 202452, "start": 2046.52, "end": 2048.52, "text": " Can you repeat the question again?", "tokens": [51464, 1664, 291, 7149, 264, 1168, 797, 30, 51564], "temperature": 0.0, "avg_logprob": -0.19781787486015995, "compression_ratio": 1.927710843373494, "no_speech_prob": 0.025598283857107162}, {"id": 268, "seek": 202452, "start": 2048.52, "end": 2053.52, "text": " Do you use translation memory to speed up your translation process?", "tokens": [51564, 1144, 291, 764, 12853, 4675, 281, 3073, 493, 428, 12853, 1399, 30, 51814], "temperature": 0.0, "avg_logprob": -0.19781787486015995, "compression_ratio": 1.927710843373494, "no_speech_prob": 0.025598283857107162}, {"id": 269, "seek": 205352, "start": 2054.52, "end": 2057.52, "text": " When you have a good question,", "tokens": [50414, 1133, 291, 362, 257, 665, 1168, 11, 50564], "temperature": 0.0, "avg_logprob": -0.29496212005615235, "compression_ratio": 1.6721311475409837, "no_speech_prob": 0.002752789529040456}, {"id": 270, "seek": 205352, "start": 2057.52, "end": 2062.52, "text": " I guess the translation memory is the crowding function.", "tokens": [50564, 286, 2041, 264, 12853, 4675, 307, 264, 6919, 278, 2445, 13, 50814], "temperature": 0.0, "avg_logprob": -0.29496212005615235, "compression_ratio": 1.6721311475409837, "no_speech_prob": 0.002752789529040456}, {"id": 271, "seek": 205352, "start": 2062.52, "end": 2066.52, "text": " Crowding, you use such kind of translation memory, right?", "tokens": [50814, 40110, 278, 11, 291, 764, 1270, 733, 295, 12853, 4675, 11, 558, 30, 51014], "temperature": 0.0, "avg_logprob": -0.29496212005615235, "compression_ratio": 1.6721311475409837, "no_speech_prob": 0.002752789529040456}, {"id": 272, "seek": 205352, "start": 2066.52, "end": 2068.52, "text": " Yeah, we use translation memory.", "tokens": [51014, 865, 11, 321, 764, 12853, 4675, 13, 51114], "temperature": 0.0, "avg_logprob": -0.29496212005615235, "compression_ratio": 1.6721311475409837, "no_speech_prob": 0.002752789529040456}, {"id": 273, "seek": 205352, "start": 2068.52, "end": 2070.52, "text": " That's the building function.", "tokens": [51114, 663, 311, 264, 2390, 2445, 13, 51214], "temperature": 0.0, "avg_logprob": -0.29496212005615235, "compression_ratio": 1.6721311475409837, "no_speech_prob": 0.002752789529040456}, {"id": 274, "seek": 205352, "start": 2070.52, "end": 2074.52, "text": " And we also use machine translation,", "tokens": [51214, 400, 321, 611, 764, 3479, 12853, 11, 51414], "temperature": 0.0, "avg_logprob": -0.29496212005615235, "compression_ratio": 1.6721311475409837, "no_speech_prob": 0.002752789529040456}, {"id": 275, "seek": 205352, "start": 2074.52, "end": 2081.52, "text": " which is AI tools such as child GPT or Microsoft translator,", "tokens": [51414, 597, 307, 7318, 3873, 1270, 382, 1440, 26039, 51, 420, 8116, 35223, 11, 51764], "temperature": 0.0, "avg_logprob": -0.29496212005615235, "compression_ratio": 1.6721311475409837, "no_speech_prob": 0.002752789529040456}, {"id": 276, "seek": 208152, "start": 2081.52, "end": 2084.52, "text": " which do the integration with the platform.", "tokens": [50364, 597, 360, 264, 10980, 365, 264, 3663, 13, 50514], "temperature": 0.0, "avg_logprob": -0.2912452220916748, "compression_ratio": 1.1369863013698631, "no_speech_prob": 0.014670446515083313}, {"id": 277, "seek": 208152, "start": 2091.52, "end": 2092.52, "text": " Thank you.", "tokens": [50864, 1044, 291, 13, 50914], "temperature": 0.0, "avg_logprob": -0.2912452220916748, "compression_ratio": 1.1369863013698631, "no_speech_prob": 0.014670446515083313}, {"id": 278, "seek": 208152, "start": 2092.52, "end": 2094.52, "text": " Thank you very much.", "tokens": [50914, 1044, 291, 588, 709, 13, 51014], "temperature": 0.0, "avg_logprob": -0.2912452220916748, "compression_ratio": 1.1369863013698631, "no_speech_prob": 0.014670446515083313}, {"id": 279, "seek": 208152, "start": 2094.52, "end": 2096.52, "text": " Thanks.", "tokens": [51014, 2561, 13, 51114], "temperature": 0.0, "avg_logprob": -0.2912452220916748, "compression_ratio": 1.1369863013698631, "no_speech_prob": 0.014670446515083313}, {"id": 280, "seek": 209652, "start": 2096.52, "end": 2098.52, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 50464], "temperature": 0.0, "avg_logprob": -0.44590961933135986, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.615911602973938}, {"id": 281, "seek": 212652, "start": 2126.52, "end": 2128.52, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 50464], "temperature": 0.0, "avg_logprob": -0.4048188130060832, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.9910679459571838}], "language": "en"}