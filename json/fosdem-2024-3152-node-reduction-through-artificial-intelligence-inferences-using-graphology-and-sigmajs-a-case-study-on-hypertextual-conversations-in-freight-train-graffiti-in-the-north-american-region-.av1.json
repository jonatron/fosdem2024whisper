{"text": " I had my notes here, so I'm supposed to read them because my English is really not that well. So in some parts I'm going to try to just read the slides and in some others I'm going to try to improve. So first of all I want to really thank you guys being here, the Graphology and Sigma developers because thank you, thank you for your work and thank you for being here. I really appreciate that. I'm using that library. I'm also in one moment. So in one moment I also used Force Atlas II that Matthew Jacome is also here. So it's kind of really, really amazing for me being in this chance to at least talk to somebody that has the same interest and that's why in my own country maybe it's difficult to do this kind of presentation because I have to make a long introduction. As I'm going to do right now, but about the social phenomena I'm studying, it's freight graffiti. So this is one of the visualizations we can achieve and this is, as you can see, it's a really hot mess happening there. It's a lot of stuff and we're trying to get this. It's kind of a synthesis or maybe an abstraction too. So in this visualization at the end we'll be able to link the users to the symbolic forms, the symbolic or the meaning they are using to make a community. So I just invite you to have that in mind. We're going from this to this, but before we actually have to get all that information, gather all that information and make it happen in this visualization, in this computational visualization. Something is happening in these train yards. So we have two different stuff. We have to break that, this really long title. I know maybe social scientists were always in verbose mode and we were just talking right and talking right and I see how you guys are really into synthesis and really straightforward. So what I'm going to do here is talking about two different stuff. One, a computational process that is a really fancy name, no production through artificial intelligence, inferences, but it's just a filter. We're just cleaning all the mess. And the other one is about a social phenomenon. This is happening in physical world, real world if you want to say so, but we're trying to take that data also and make it happen in our own framework. So these guys tend to write their names on the freight trains and these trains will always travel from all the North America region and then some other persons will track them, will take some pictures and will post this on Instagram. So this has been happening before social media. So this is a community. It's a practice community. If somebody here know Jenkins, maybe you will know what I'm talking about, participatory culture. So that's kind of the same. There's two, two, that's the same phenomenon happening in two different places. In the physical world, in the digital world, and that's what we called an on-life phenomenon. So the case of study for this presentation, as I told you, is the graffiti, the freight train graffiti in the North America region. So an hypertextual conversations, I don't know if it makes sense for somebody here. One guy in the morning make a presentation about his presentation was Cosma. That's the software he was presenting and he talked about that guy that invent this kind of linking document idea and that's hypertext. What about hashtags? Hashtags may be this kind of hypertext too because they will function like a gathering point. People will join in those places through their own publishing, their own post after they tag them with any hashtag. This network will be talking about users, Instagram users, that post and mark this post with any hashtag. So this can make clusters or clicks and that's what we are trying to look. These small groups that share something in commune, that share meaning, all these posts are meaningful for themselves. So that's I think something happening here too. This is like this big group of persons that gets together and fuzz them and then we have these little clicks happening in each room and then anybody will move from place to place and make these kind of networks if we try to see it that way. So the other part I would like to talk to you is about this filter. This filter happens in two different levels. One with a Python using some other libraries too and the second one through Graphology and Sigma, I think misspelled, using JavaScript. So this was introduction guys. The point here is I'm going to share to you how each step uses different open source libraries or software and that's one way to acknowledge to all the developers here that all that effort you are doing is making people like me that is not really a developer. Trying to make a dialogue, talk between social science, computational science with the tools that I can try to use. So there's a word there that is really important. It will go all the way from the whole slide show, it's data. We have been listening to that concept a lot and I really feel kind of sad because the effort that I can see in those talks before was about standard data. Big platforms make tools to make standard data and this example is the whole other thing. It's really different because it's a really custom data set. It's a really custom, it's a really niche social phenomena so there's no tools to study this study object. So we have to make them with anything we can. So data is the key and it's the link between execution devices, between disciplines, between programming languages, theoretical frameworks, development libraries and social phenomena. That will help us to make interoperability between all of these different dimensions. And I think, and I hope you do too, this will be only possible through open source and data. Data is the key here. So the journey starts. I'm going to try to be really fast so I can have some of your comments. I will tell you this is a master's degree thesis so each step it was way long. If you think this is verbose, that's some other stuff. So I'm using the first link between, I want to show you is between conceptual frameworks, theories. So we have Thompson, a guy from England that is trying to find these kind of categories to detect meaning, to detect symbolic stuff. And we also have the graffiti de firma from Figueroa, that's a Spaniard, another Spaniard guy that retomb these I exist, I am the SCART, I don't know in French maybe, the SCART, I don't know the right pronunciation, the SCART, the SCART is to the cart. To see how graffiti writers broadcast themselves to the world. So we're making this link, right? Because data will be the key here. To make this link between some theoretical point view perspective, to a way we can manage to just back up at least, we need to make this, look for these terms, look for these stuff and make it some sort of way to, well to data. So we at least have these three categories, those things we are looking for. We are looking for geographies, so we are looking for cities, so we are making a dictionary, a city dictionary. We are looking for communities, that's symbolic, shared terms, so this dictionary is about the words that graffiti writers use to tag their own posts and the freight workers use too, so we can mix them, merge them and make this freight train dictionary. And last but not least, we have entities, so we are looking for graffiti writers names. We are going to scrap, we're going to mine these hashtags, these hashtags, conversations, these hypertextual conversations and the network, we have that simple structure. Users post some publication and add some tags. But we are not only using one user's post, we are using a lot of them. So we have this seed node, the seed node is the first hashtag scrapped and this Instagram data mining boat, really original name, will download an infinite number of posts and then add new hashtags that are found on these publications. That will give us this primitive kind of network, this is a small one, the seed node was graffiti bombing, we used a mining depth of only zero, so it will only mine that in this case 30 posts that are using this specific hashtag, but as you will see, graffiti bombing has 30 posts, but this other post is also using different hashtags. So that is how this network is built. For making this mining, I'm using Instagram app, it's an unofficial Instagram app for Python. I don't know if it's a privacy stuff and I know it's tricky, so I won't talk about it. But I use Docker, so I can make a Raspberry, we try to mimic human behaviors, so this mining will last for maybe one week for each conversation and if these conversations are really large, it will last longer. So that's why we are using this low consumption computer and then after we scrap this, we will put it on the SQL database. So we are going from the publications to the SQL database. So this will be a really fast way to put it. We came from reality to Instagram and from Instagram to our own dataset. But we are now looking for these terms on the dictionary we already made before. So in this case, this is a writer from my city, Afex, he wrote that train in Mexico and now somebody else sent him the photo in Utah. So he will put his name, the place it was found, some other stuff and some slang for the same community and also his crew, his group. So if we try to put this text in spicy, we'll give us only one token and that won't help. So we have to split the hashtag in small words. So the answer was really cool. It was already on Stack Overflow. So thank you to that guy. I put it in the paperwork. It's there because we have to acknowledge some others work. So I have to build this really big dictionary of all the words we know in Spanish and English to split the hashtag. And after that, we'll look in these dictionaries. If some word is inside any dictionary, it will be marked as. If it's not, we will think about it as a writer name or as a crew name too. But we're making sure this is real and we will look for graffiti in any part of the caption to make us sure that that strange string is actually a graffiti writer's name. So this is simple, but it works. We have those words, how those hashtags were marked by this software. So we have throw up calls, bubble style. And this is interesting, but it will be more interesting when we try to put everything together. We do it with a spicy docker on Sorrasberry. I'm going to be really fast now. These are two image detection models, ones for Google, ones for IMAID. And that's cool because this is the same technical process, the same image, but it's seeing two different stuff, right? Because the models will see what we want them to see in the training. So that's really straightforward, but it's really important because the Google model, it won't be useful for me at all. So this is the result of using this model. Also it will be interesting when we put everything together. We are using Jupyter with Google collab because it's free, so we can make an SQL query and then it will download the images and apply the model. So the beauty of relational databases is you can access to these different content from different sizes. You already know this. But the point here, we are going from the database to JSON network and we will get something like this, right? We have in the middle, in yellow, the inference notes and purple, the images were detected. And the point here is to see how users gather using the same symbolic stuff. That can be the same symbolic stuff, some kind of graffiti, some specific slang word, some kind of city. We can see in this point how somebody in Tijuana maybe will use the same... Some group in Tijuana will use maybe the same style. I think that's important. But this is a hot mess again. It's thousands of notes of different types, so we have to clean this. Looking for significance, or meaning or symbolic forms. We know a man is an animal suspend in webs of significance. He himself has fun, but we can clean that. We're trying to clean that. So the note reduction will be the shortest path to the meaning. We're going from that to the really clean network. At least I think so. So the algorithm, the thing that's happening here is that for each user node, we're making an array. Then I have another array of the whole network. And if they have a shortest path that is like an algorithm using graphology, and another place is two, that if this match some... If it match three steps, it means that the user has some symbolic node detected and then it will link them. If it's not like that, it will delay the node. So it will change the network structure to this now. It will be... It's really different from that one from before. So I think... I don't know if we have some time. If you want to see how this works, and if you have also some comments too, because I would really love to see if you guys have anything that I can change, I can add. I think it's really... I don't feel like there's some questions you can do. I think it would be better if you just told me what to think about it. So in this case, the network starts with 4,000, almost 5,000 nodes. And at the end, it's really small. Let's see. I don't even remember which one is the biggest. Sorry. We went from 5,000 to only 500. So I put this example because... There's a principle phenomenon called divergence that when we mine the whole hypertextual conversation, it will go for a lot of places that we are not interested. Like if somebody used red as a hashtag, if somebody used love, if somebody else used no, it will just move the conversation that we are trying to mine to different places that we are not interested. So in this case, macro, it's a really known writer. Let's see if we can find it. Well, this one is also a really known writer. So in this specific example, we can see how the object detection model tagged this photo as a wild style, as a throw up, and the Google model will tag them like a wheel and a train. But also, we can see how this hashtag was tagged as a graffiti writer. So that gives us an idea that... Well, not an idea, an evidence that this guy is a graffiti writer name and we can see his intervention. We can see who is the user that makes this post. When we can access to the user, the user neighbor network, we can also be sure that he's using these specific graffiti styles. Okay. So I'm going to finish with this. In this case, when we apply this filter, it's way better, it's way cleaner, and we can start to see... I think I'm just talking nonsense now. Do you want to add something? That's my answer question. Thank you. How did you get inspired to run this as a master piece and continue doing research? I mean, checking the throw ups and the graffiti on trains. What was the practical aspect that motivated you to be fine? Okay. So the question was, what was the practical aspect of attracting the graffiti and what motivates you personally to do it? I had a pre-grad also graffiti as a central topic and I thought it would be easier to do something that will continue this personal initiative. But at last, I've been late for two years now. I shouldn't deliver this last year because... But it was really interesting to how learn this new stuff and put it together to make some scholar work. What made the difference? What do you see? Right train, for instance. How do you know that right train is the background and not the name of the artist? Okay. That's a really... That's a good question. I... You can repeat the question. Okay. How we managed to difference the freight as a graffiti... Is not a graffiti writer's name. So there's a big dictionary. It's built with all the known words. So it will distinguish between known words and words that are out of that vocabulary. Yes, Alison? I have one question then if no one else has one. How do you... Have you had any insights in your graph that really excited you? Yes. So the question is if the insight of the network really excited me. Yeah, I think it does because it was like a kind of a serendipity, you know? When I start to see like this small notes linked together from the terms, it will pop like how some terms are linked for some graffiti styles too. So everything's connected and I think the way to get to this is tailoring data to our own needs. Right. Yeah. Okay, folks. Can we have a big round of applause? Thank you. Thank you. Thank you. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 17.88, "text": " I had my notes here, so I'm supposed to read them because my English is really not that", "tokens": [50364, 286, 632, 452, 5570, 510, 11, 370, 286, 478, 3442, 281, 1401, 552, 570, 452, 3669, 307, 534, 406, 300, 51258], "temperature": 0.0, "avg_logprob": -0.23772269281847724, "compression_ratio": 1.4962406015037595, "no_speech_prob": 0.2913503348827362}, {"id": 1, "seek": 0, "start": 17.88, "end": 18.88, "text": " well.", "tokens": [51258, 731, 13, 51308], "temperature": 0.0, "avg_logprob": -0.23772269281847724, "compression_ratio": 1.4962406015037595, "no_speech_prob": 0.2913503348827362}, {"id": 2, "seek": 0, "start": 18.88, "end": 25.28, "text": " So in some parts I'm going to try to just read the slides and in some others I'm going", "tokens": [51308, 407, 294, 512, 3166, 286, 478, 516, 281, 853, 281, 445, 1401, 264, 9788, 293, 294, 512, 2357, 286, 478, 516, 51628], "temperature": 0.0, "avg_logprob": -0.23772269281847724, "compression_ratio": 1.4962406015037595, "no_speech_prob": 0.2913503348827362}, {"id": 3, "seek": 0, "start": 25.28, "end": 26.48, "text": " to try to improve.", "tokens": [51628, 281, 853, 281, 3470, 13, 51688], "temperature": 0.0, "avg_logprob": -0.23772269281847724, "compression_ratio": 1.4962406015037595, "no_speech_prob": 0.2913503348827362}, {"id": 4, "seek": 2648, "start": 26.48, "end": 36.72, "text": " So first of all I want to really thank you guys being here, the Graphology and Sigma developers", "tokens": [50364, 407, 700, 295, 439, 286, 528, 281, 534, 1309, 291, 1074, 885, 510, 11, 264, 21884, 1793, 293, 36595, 8849, 50876], "temperature": 0.0, "avg_logprob": -0.2798796567049893, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.01690041273832321}, {"id": 5, "seek": 2648, "start": 36.72, "end": 40.84, "text": " because thank you, thank you for your work and thank you for being here.", "tokens": [50876, 570, 1309, 291, 11, 1309, 291, 337, 428, 589, 293, 1309, 291, 337, 885, 510, 13, 51082], "temperature": 0.0, "avg_logprob": -0.2798796567049893, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.01690041273832321}, {"id": 6, "seek": 2648, "start": 40.84, "end": 43.2, "text": " I really appreciate that.", "tokens": [51082, 286, 534, 4449, 300, 13, 51200], "temperature": 0.0, "avg_logprob": -0.2798796567049893, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.01690041273832321}, {"id": 7, "seek": 2648, "start": 43.2, "end": 46.32, "text": " I'm using that library.", "tokens": [51200, 286, 478, 1228, 300, 6405, 13, 51356], "temperature": 0.0, "avg_logprob": -0.2798796567049893, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.01690041273832321}, {"id": 8, "seek": 2648, "start": 46.32, "end": 55.0, "text": " I'm also in one moment.", "tokens": [51356, 286, 478, 611, 294, 472, 1623, 13, 51790], "temperature": 0.0, "avg_logprob": -0.2798796567049893, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.01690041273832321}, {"id": 9, "seek": 5500, "start": 55.0, "end": 61.08, "text": " So in one moment I also used Force Atlas II that Matthew Jacome is also here.", "tokens": [50364, 407, 294, 472, 1623, 286, 611, 1143, 10580, 32485, 6351, 300, 12434, 9538, 423, 307, 611, 510, 13, 50668], "temperature": 0.0, "avg_logprob": -0.17785940052550517, "compression_ratio": 1.5348837209302326, "no_speech_prob": 0.016219668090343475}, {"id": 10, "seek": 5500, "start": 61.08, "end": 71.16, "text": " So it's kind of really, really amazing for me being in this chance to at least talk to", "tokens": [50668, 407, 309, 311, 733, 295, 534, 11, 534, 2243, 337, 385, 885, 294, 341, 2931, 281, 412, 1935, 751, 281, 51172], "temperature": 0.0, "avg_logprob": -0.17785940052550517, "compression_ratio": 1.5348837209302326, "no_speech_prob": 0.016219668090343475}, {"id": 11, "seek": 5500, "start": 71.16, "end": 78.4, "text": " somebody that has the same interest and that's why in my own country maybe it's difficult", "tokens": [51172, 2618, 300, 575, 264, 912, 1179, 293, 300, 311, 983, 294, 452, 1065, 1941, 1310, 309, 311, 2252, 51534], "temperature": 0.0, "avg_logprob": -0.17785940052550517, "compression_ratio": 1.5348837209302326, "no_speech_prob": 0.016219668090343475}, {"id": 12, "seek": 5500, "start": 78.4, "end": 84.36, "text": " to do this kind of presentation because I have to make a long introduction.", "tokens": [51534, 281, 360, 341, 733, 295, 5860, 570, 286, 362, 281, 652, 257, 938, 9339, 13, 51832], "temperature": 0.0, "avg_logprob": -0.17785940052550517, "compression_ratio": 1.5348837209302326, "no_speech_prob": 0.016219668090343475}, {"id": 13, "seek": 8436, "start": 84.36, "end": 90.32, "text": " As I'm going to do right now, but about the social phenomena I'm studying, it's freight", "tokens": [50364, 1018, 286, 478, 516, 281, 360, 558, 586, 11, 457, 466, 264, 2093, 22004, 286, 478, 7601, 11, 309, 311, 37181, 50662], "temperature": 0.0, "avg_logprob": -0.1989027728205142, "compression_ratio": 1.5631067961165048, "no_speech_prob": 0.010119888931512833}, {"id": 14, "seek": 8436, "start": 90.32, "end": 91.32, "text": " graffiti.", "tokens": [50662, 40531, 13, 50712], "temperature": 0.0, "avg_logprob": -0.1989027728205142, "compression_ratio": 1.5631067961165048, "no_speech_prob": 0.010119888931512833}, {"id": 15, "seek": 8436, "start": 91.32, "end": 99.03999999999999, "text": " So this is one of the visualizations we can achieve and this is, as you can see, it's", "tokens": [50712, 407, 341, 307, 472, 295, 264, 5056, 14455, 321, 393, 4584, 293, 341, 307, 11, 382, 291, 393, 536, 11, 309, 311, 51098], "temperature": 0.0, "avg_logprob": -0.1989027728205142, "compression_ratio": 1.5631067961165048, "no_speech_prob": 0.010119888931512833}, {"id": 16, "seek": 8436, "start": 99.03999999999999, "end": 100.72, "text": " a really hot mess happening there.", "tokens": [51098, 257, 534, 2368, 2082, 2737, 456, 13, 51182], "temperature": 0.0, "avg_logprob": -0.1989027728205142, "compression_ratio": 1.5631067961165048, "no_speech_prob": 0.010119888931512833}, {"id": 17, "seek": 8436, "start": 100.72, "end": 105.24, "text": " It's a lot of stuff and we're trying to get this.", "tokens": [51182, 467, 311, 257, 688, 295, 1507, 293, 321, 434, 1382, 281, 483, 341, 13, 51408], "temperature": 0.0, "avg_logprob": -0.1989027728205142, "compression_ratio": 1.5631067961165048, "no_speech_prob": 0.010119888931512833}, {"id": 18, "seek": 8436, "start": 105.24, "end": 109.48, "text": " It's kind of a synthesis or maybe an abstraction too.", "tokens": [51408, 467, 311, 733, 295, 257, 30252, 420, 1310, 364, 37765, 886, 13, 51620], "temperature": 0.0, "avg_logprob": -0.1989027728205142, "compression_ratio": 1.5631067961165048, "no_speech_prob": 0.010119888931512833}, {"id": 19, "seek": 10948, "start": 109.48, "end": 117.76, "text": " So in this visualization at the end we'll be able to link the users to the symbolic", "tokens": [50364, 407, 294, 341, 25801, 412, 264, 917, 321, 603, 312, 1075, 281, 2113, 264, 5022, 281, 264, 25755, 50778], "temperature": 0.0, "avg_logprob": -0.19184281275822565, "compression_ratio": 1.437956204379562, "no_speech_prob": 0.01397555973380804}, {"id": 20, "seek": 10948, "start": 117.76, "end": 127.56, "text": " forms, the symbolic or the meaning they are using to make a community.", "tokens": [50778, 6422, 11, 264, 25755, 420, 264, 3620, 436, 366, 1228, 281, 652, 257, 1768, 13, 51268], "temperature": 0.0, "avg_logprob": -0.19184281275822565, "compression_ratio": 1.437956204379562, "no_speech_prob": 0.01397555973380804}, {"id": 21, "seek": 10948, "start": 127.56, "end": 131.64000000000001, "text": " So I just invite you to have that in mind.", "tokens": [51268, 407, 286, 445, 7980, 291, 281, 362, 300, 294, 1575, 13, 51472], "temperature": 0.0, "avg_logprob": -0.19184281275822565, "compression_ratio": 1.437956204379562, "no_speech_prob": 0.01397555973380804}, {"id": 22, "seek": 13164, "start": 131.64, "end": 140.39999999999998, "text": " We're going from this to this, but before we actually have to get all that information,", "tokens": [50364, 492, 434, 516, 490, 341, 281, 341, 11, 457, 949, 321, 767, 362, 281, 483, 439, 300, 1589, 11, 50802], "temperature": 0.0, "avg_logprob": -0.2874368940080915, "compression_ratio": 1.6524390243902438, "no_speech_prob": 0.22220686078071594}, {"id": 23, "seek": 13164, "start": 140.39999999999998, "end": 147.88, "text": " gather all that information and make it happen in this visualization, in this computational", "tokens": [50802, 5448, 439, 300, 1589, 293, 652, 309, 1051, 294, 341, 25801, 11, 294, 341, 28270, 51176], "temperature": 0.0, "avg_logprob": -0.2874368940080915, "compression_ratio": 1.6524390243902438, "no_speech_prob": 0.22220686078071594}, {"id": 24, "seek": 13164, "start": 147.88, "end": 150.07999999999998, "text": " visualization.", "tokens": [51176, 25801, 13, 51286], "temperature": 0.0, "avg_logprob": -0.2874368940080915, "compression_ratio": 1.6524390243902438, "no_speech_prob": 0.22220686078071594}, {"id": 25, "seek": 13164, "start": 150.07999999999998, "end": 154.95999999999998, "text": " Something is happening in these train yards.", "tokens": [51286, 6595, 307, 2737, 294, 613, 3847, 18685, 13, 51530], "temperature": 0.0, "avg_logprob": -0.2874368940080915, "compression_ratio": 1.6524390243902438, "no_speech_prob": 0.22220686078071594}, {"id": 26, "seek": 13164, "start": 154.95999999999998, "end": 157.56, "text": " So we have two different stuff.", "tokens": [51530, 407, 321, 362, 732, 819, 1507, 13, 51660], "temperature": 0.0, "avg_logprob": -0.2874368940080915, "compression_ratio": 1.6524390243902438, "no_speech_prob": 0.22220686078071594}, {"id": 27, "seek": 15756, "start": 157.56, "end": 161.28, "text": " We have to break that, this really long title.", "tokens": [50364, 492, 362, 281, 1821, 300, 11, 341, 534, 938, 4876, 13, 50550], "temperature": 0.0, "avg_logprob": -0.19907912341031161, "compression_ratio": 1.6141078838174274, "no_speech_prob": 0.30039963126182556}, {"id": 28, "seek": 15756, "start": 161.28, "end": 167.04, "text": " I know maybe social scientists were always in verbose mode and we were just talking right", "tokens": [50550, 286, 458, 1310, 2093, 7708, 645, 1009, 294, 9595, 541, 4391, 293, 321, 645, 445, 1417, 558, 50838], "temperature": 0.0, "avg_logprob": -0.19907912341031161, "compression_ratio": 1.6141078838174274, "no_speech_prob": 0.30039963126182556}, {"id": 29, "seek": 15756, "start": 167.04, "end": 173.36, "text": " and talking right and I see how you guys are really into synthesis and really straightforward.", "tokens": [50838, 293, 1417, 558, 293, 286, 536, 577, 291, 1074, 366, 534, 666, 30252, 293, 534, 15325, 13, 51154], "temperature": 0.0, "avg_logprob": -0.19907912341031161, "compression_ratio": 1.6141078838174274, "no_speech_prob": 0.30039963126182556}, {"id": 30, "seek": 15756, "start": 173.36, "end": 178.8, "text": " So what I'm going to do here is talking about two different stuff.", "tokens": [51154, 407, 437, 286, 478, 516, 281, 360, 510, 307, 1417, 466, 732, 819, 1507, 13, 51426], "temperature": 0.0, "avg_logprob": -0.19907912341031161, "compression_ratio": 1.6141078838174274, "no_speech_prob": 0.30039963126182556}, {"id": 31, "seek": 15756, "start": 178.8, "end": 184.36, "text": " One, a computational process that is a really fancy name, no production through artificial", "tokens": [51426, 1485, 11, 257, 28270, 1399, 300, 307, 257, 534, 10247, 1315, 11, 572, 4265, 807, 11677, 51704], "temperature": 0.0, "avg_logprob": -0.19907912341031161, "compression_ratio": 1.6141078838174274, "no_speech_prob": 0.30039963126182556}, {"id": 32, "seek": 18436, "start": 184.36, "end": 189.72000000000003, "text": " intelligence, inferences, but it's just a filter.", "tokens": [50364, 7599, 11, 13596, 2667, 11, 457, 309, 311, 445, 257, 6608, 13, 50632], "temperature": 0.0, "avg_logprob": -0.24251558906153628, "compression_ratio": 1.5133689839572193, "no_speech_prob": 0.057132016867399216}, {"id": 33, "seek": 18436, "start": 189.72000000000003, "end": 192.12, "text": " We're just cleaning all the mess.", "tokens": [50632, 492, 434, 445, 8924, 439, 264, 2082, 13, 50752], "temperature": 0.0, "avg_logprob": -0.24251558906153628, "compression_ratio": 1.5133689839572193, "no_speech_prob": 0.057132016867399216}, {"id": 34, "seek": 18436, "start": 192.12, "end": 195.16000000000003, "text": " And the other one is about a social phenomenon.", "tokens": [50752, 400, 264, 661, 472, 307, 466, 257, 2093, 14029, 13, 50904], "temperature": 0.0, "avg_logprob": -0.24251558906153628, "compression_ratio": 1.5133689839572193, "no_speech_prob": 0.057132016867399216}, {"id": 35, "seek": 18436, "start": 195.16000000000003, "end": 201.32000000000002, "text": " This is happening in physical world, real world if you want to say so, but we're trying", "tokens": [50904, 639, 307, 2737, 294, 4001, 1002, 11, 957, 1002, 498, 291, 528, 281, 584, 370, 11, 457, 321, 434, 1382, 51212], "temperature": 0.0, "avg_logprob": -0.24251558906153628, "compression_ratio": 1.5133689839572193, "no_speech_prob": 0.057132016867399216}, {"id": 36, "seek": 18436, "start": 201.32000000000002, "end": 208.52, "text": " to take that data also and make it happen in our own framework.", "tokens": [51212, 281, 747, 300, 1412, 611, 293, 652, 309, 1051, 294, 527, 1065, 8388, 13, 51572], "temperature": 0.0, "avg_logprob": -0.24251558906153628, "compression_ratio": 1.5133689839572193, "no_speech_prob": 0.057132016867399216}, {"id": 37, "seek": 20852, "start": 208.52, "end": 217.60000000000002, "text": " So these guys tend to write their names on the freight trains and these trains will always", "tokens": [50364, 407, 613, 1074, 3928, 281, 2464, 641, 5288, 322, 264, 37181, 16329, 293, 613, 16329, 486, 1009, 50818], "temperature": 0.0, "avg_logprob": -0.16346320300035075, "compression_ratio": 1.6137566137566137, "no_speech_prob": 0.03717387095093727}, {"id": 38, "seek": 20852, "start": 217.60000000000002, "end": 226.36, "text": " travel from all the North America region and then some other persons will track them, will", "tokens": [50818, 3147, 490, 439, 264, 4067, 3374, 4458, 293, 550, 512, 661, 14453, 486, 2837, 552, 11, 486, 51256], "temperature": 0.0, "avg_logprob": -0.16346320300035075, "compression_ratio": 1.6137566137566137, "no_speech_prob": 0.03717387095093727}, {"id": 39, "seek": 20852, "start": 226.36, "end": 230.16000000000003, "text": " take some pictures and will post this on Instagram.", "tokens": [51256, 747, 512, 5242, 293, 486, 2183, 341, 322, 5281, 13, 51446], "temperature": 0.0, "avg_logprob": -0.16346320300035075, "compression_ratio": 1.6137566137566137, "no_speech_prob": 0.03717387095093727}, {"id": 40, "seek": 20852, "start": 230.16000000000003, "end": 233.64000000000001, "text": " So this has been happening before social media.", "tokens": [51446, 407, 341, 575, 668, 2737, 949, 2093, 3021, 13, 51620], "temperature": 0.0, "avg_logprob": -0.16346320300035075, "compression_ratio": 1.6137566137566137, "no_speech_prob": 0.03717387095093727}, {"id": 41, "seek": 20852, "start": 233.64000000000001, "end": 237.60000000000002, "text": " So this is a community.", "tokens": [51620, 407, 341, 307, 257, 1768, 13, 51818], "temperature": 0.0, "avg_logprob": -0.16346320300035075, "compression_ratio": 1.6137566137566137, "no_speech_prob": 0.03717387095093727}, {"id": 42, "seek": 23760, "start": 237.6, "end": 239.2, "text": " It's a practice community.", "tokens": [50364, 467, 311, 257, 3124, 1768, 13, 50444], "temperature": 0.0, "avg_logprob": -0.24023444077064252, "compression_ratio": 1.5673076923076923, "no_speech_prob": 0.015483597293496132}, {"id": 43, "seek": 23760, "start": 239.2, "end": 248.12, "text": " If somebody here know Jenkins, maybe you will know what I'm talking about, participatory", "tokens": [50444, 759, 2618, 510, 458, 41273, 11, 1310, 291, 486, 458, 437, 286, 478, 1417, 466, 11, 3421, 4745, 50890], "temperature": 0.0, "avg_logprob": -0.24023444077064252, "compression_ratio": 1.5673076923076923, "no_speech_prob": 0.015483597293496132}, {"id": 44, "seek": 23760, "start": 248.12, "end": 249.56, "text": " culture.", "tokens": [50890, 3713, 13, 50962], "temperature": 0.0, "avg_logprob": -0.24023444077064252, "compression_ratio": 1.5673076923076923, "no_speech_prob": 0.015483597293496132}, {"id": 45, "seek": 23760, "start": 249.56, "end": 251.84, "text": " So that's kind of the same.", "tokens": [50962, 407, 300, 311, 733, 295, 264, 912, 13, 51076], "temperature": 0.0, "avg_logprob": -0.24023444077064252, "compression_ratio": 1.5673076923076923, "no_speech_prob": 0.015483597293496132}, {"id": 46, "seek": 23760, "start": 251.84, "end": 258.8, "text": " There's two, two, that's the same phenomenon happening in two different places.", "tokens": [51076, 821, 311, 732, 11, 732, 11, 300, 311, 264, 912, 14029, 2737, 294, 732, 819, 3190, 13, 51424], "temperature": 0.0, "avg_logprob": -0.24023444077064252, "compression_ratio": 1.5673076923076923, "no_speech_prob": 0.015483597293496132}, {"id": 47, "seek": 23760, "start": 258.8, "end": 266.12, "text": " In the physical world, in the digital world, and that's what we called an on-life phenomenon.", "tokens": [51424, 682, 264, 4001, 1002, 11, 294, 264, 4562, 1002, 11, 293, 300, 311, 437, 321, 1219, 364, 322, 12, 9073, 14029, 13, 51790], "temperature": 0.0, "avg_logprob": -0.24023444077064252, "compression_ratio": 1.5673076923076923, "no_speech_prob": 0.015483597293496132}, {"id": 48, "seek": 26612, "start": 266.12, "end": 272.44, "text": " So the case of study for this presentation, as I told you, is the graffiti, the freight", "tokens": [50364, 407, 264, 1389, 295, 2979, 337, 341, 5860, 11, 382, 286, 1907, 291, 11, 307, 264, 40531, 11, 264, 37181, 50680], "temperature": 0.0, "avg_logprob": -0.22432785563998753, "compression_ratio": 1.5368421052631578, "no_speech_prob": 0.028921235352754593}, {"id": 49, "seek": 26612, "start": 272.44, "end": 275.8, "text": " train graffiti in the North America region.", "tokens": [50680, 3847, 40531, 294, 264, 4067, 3374, 4458, 13, 50848], "temperature": 0.0, "avg_logprob": -0.22432785563998753, "compression_ratio": 1.5368421052631578, "no_speech_prob": 0.028921235352754593}, {"id": 50, "seek": 26612, "start": 275.8, "end": 283.88, "text": " So an hypertextual conversations, I don't know if it makes sense for somebody here.", "tokens": [50848, 407, 364, 9848, 25111, 901, 7315, 11, 286, 500, 380, 458, 498, 309, 1669, 2020, 337, 2618, 510, 13, 51252], "temperature": 0.0, "avg_logprob": -0.22432785563998753, "compression_ratio": 1.5368421052631578, "no_speech_prob": 0.028921235352754593}, {"id": 51, "seek": 26612, "start": 283.88, "end": 294.24, "text": " One guy in the morning make a presentation about his presentation was Cosma.", "tokens": [51252, 1485, 2146, 294, 264, 2446, 652, 257, 5860, 466, 702, 5860, 390, 15855, 1696, 13, 51770], "temperature": 0.0, "avg_logprob": -0.22432785563998753, "compression_ratio": 1.5368421052631578, "no_speech_prob": 0.028921235352754593}, {"id": 52, "seek": 29424, "start": 294.24, "end": 299.28000000000003, "text": " That's the software he was presenting and he talked about that guy that invent this", "tokens": [50364, 663, 311, 264, 4722, 415, 390, 15578, 293, 415, 2825, 466, 300, 2146, 300, 7962, 341, 50616], "temperature": 0.0, "avg_logprob": -0.23514311990620176, "compression_ratio": 1.6220095693779903, "no_speech_prob": 0.3655844032764435}, {"id": 53, "seek": 29424, "start": 299.28000000000003, "end": 304.12, "text": " kind of linking document idea and that's hypertext.", "tokens": [50616, 733, 295, 25775, 4166, 1558, 293, 300, 311, 9848, 25111, 13, 50858], "temperature": 0.0, "avg_logprob": -0.23514311990620176, "compression_ratio": 1.6220095693779903, "no_speech_prob": 0.3655844032764435}, {"id": 54, "seek": 29424, "start": 304.12, "end": 305.68, "text": " What about hashtags?", "tokens": [50858, 708, 466, 50016, 30, 50936], "temperature": 0.0, "avg_logprob": -0.23514311990620176, "compression_ratio": 1.6220095693779903, "no_speech_prob": 0.3655844032764435}, {"id": 55, "seek": 29424, "start": 305.68, "end": 311.92, "text": " Hashtags may be this kind of hypertext too because they will function like a gathering", "tokens": [50936, 8646, 357, 12109, 815, 312, 341, 733, 295, 9848, 25111, 886, 570, 436, 486, 2445, 411, 257, 13519, 51248], "temperature": 0.0, "avg_logprob": -0.23514311990620176, "compression_ratio": 1.6220095693779903, "no_speech_prob": 0.3655844032764435}, {"id": 56, "seek": 29424, "start": 311.92, "end": 313.28000000000003, "text": " point.", "tokens": [51248, 935, 13, 51316], "temperature": 0.0, "avg_logprob": -0.23514311990620176, "compression_ratio": 1.6220095693779903, "no_speech_prob": 0.3655844032764435}, {"id": 57, "seek": 29424, "start": 313.28000000000003, "end": 321.40000000000003, "text": " People will join in those places through their own publishing, their own post after they", "tokens": [51316, 3432, 486, 3917, 294, 729, 3190, 807, 641, 1065, 17832, 11, 641, 1065, 2183, 934, 436, 51722], "temperature": 0.0, "avg_logprob": -0.23514311990620176, "compression_ratio": 1.6220095693779903, "no_speech_prob": 0.3655844032764435}, {"id": 58, "seek": 32140, "start": 321.4, "end": 329.52, "text": " tag them with any hashtag.", "tokens": [50364, 6162, 552, 365, 604, 20379, 13, 50770], "temperature": 0.0, "avg_logprob": -0.26105449817798754, "compression_ratio": 1.4785714285714286, "no_speech_prob": 0.5823893547058105}, {"id": 59, "seek": 32140, "start": 329.52, "end": 338.2, "text": " This network will be talking about users, Instagram users, that post and mark this post", "tokens": [50770, 639, 3209, 486, 312, 1417, 466, 5022, 11, 5281, 5022, 11, 300, 2183, 293, 1491, 341, 2183, 51204], "temperature": 0.0, "avg_logprob": -0.26105449817798754, "compression_ratio": 1.4785714285714286, "no_speech_prob": 0.5823893547058105}, {"id": 60, "seek": 32140, "start": 338.2, "end": 340.08, "text": " with any hashtag.", "tokens": [51204, 365, 604, 20379, 13, 51298], "temperature": 0.0, "avg_logprob": -0.26105449817798754, "compression_ratio": 1.4785714285714286, "no_speech_prob": 0.5823893547058105}, {"id": 61, "seek": 32140, "start": 340.08, "end": 347.56, "text": " So this can make clusters or clicks and that's what we are trying to look.", "tokens": [51298, 407, 341, 393, 652, 23313, 420, 18521, 293, 300, 311, 437, 321, 366, 1382, 281, 574, 13, 51672], "temperature": 0.0, "avg_logprob": -0.26105449817798754, "compression_ratio": 1.4785714285714286, "no_speech_prob": 0.5823893547058105}, {"id": 62, "seek": 34756, "start": 347.56, "end": 353.88, "text": " These small groups that share something in commune, that share meaning, all these posts", "tokens": [50364, 1981, 1359, 3935, 300, 2073, 746, 294, 1199, 68, 11, 300, 2073, 3620, 11, 439, 613, 12300, 50680], "temperature": 0.0, "avg_logprob": -0.22523710999307753, "compression_ratio": 1.7336683417085428, "no_speech_prob": 0.8776096105575562}, {"id": 63, "seek": 34756, "start": 353.88, "end": 356.56, "text": " are meaningful for themselves.", "tokens": [50680, 366, 10995, 337, 2969, 13, 50814], "temperature": 0.0, "avg_logprob": -0.22523710999307753, "compression_ratio": 1.7336683417085428, "no_speech_prob": 0.8776096105575562}, {"id": 64, "seek": 34756, "start": 356.56, "end": 360.12, "text": " So that's I think something happening here too.", "tokens": [50814, 407, 300, 311, 286, 519, 746, 2737, 510, 886, 13, 50992], "temperature": 0.0, "avg_logprob": -0.22523710999307753, "compression_ratio": 1.7336683417085428, "no_speech_prob": 0.8776096105575562}, {"id": 65, "seek": 34756, "start": 360.12, "end": 366.32, "text": " This is like this big group of persons that gets together and fuzz them and then we have", "tokens": [50992, 639, 307, 411, 341, 955, 1594, 295, 14453, 300, 2170, 1214, 293, 283, 16740, 552, 293, 550, 321, 362, 51302], "temperature": 0.0, "avg_logprob": -0.22523710999307753, "compression_ratio": 1.7336683417085428, "no_speech_prob": 0.8776096105575562}, {"id": 66, "seek": 34756, "start": 366.32, "end": 373.48, "text": " these little clicks happening in each room and then anybody will move from place to place", "tokens": [51302, 613, 707, 18521, 2737, 294, 1184, 1808, 293, 550, 4472, 486, 1286, 490, 1081, 281, 1081, 51660], "temperature": 0.0, "avg_logprob": -0.22523710999307753, "compression_ratio": 1.7336683417085428, "no_speech_prob": 0.8776096105575562}, {"id": 67, "seek": 37348, "start": 373.48, "end": 379.64000000000004, "text": " and make these kind of networks if we try to see it that way.", "tokens": [50364, 293, 652, 613, 733, 295, 9590, 498, 321, 853, 281, 536, 309, 300, 636, 13, 50672], "temperature": 0.0, "avg_logprob": -0.24520751757499498, "compression_ratio": 1.4903846153846154, "no_speech_prob": 0.15603822469711304}, {"id": 68, "seek": 37348, "start": 379.64000000000004, "end": 385.72, "text": " So the other part I would like to talk to you is about this filter.", "tokens": [50672, 407, 264, 661, 644, 286, 576, 411, 281, 751, 281, 291, 307, 466, 341, 6608, 13, 50976], "temperature": 0.0, "avg_logprob": -0.24520751757499498, "compression_ratio": 1.4903846153846154, "no_speech_prob": 0.15603822469711304}, {"id": 69, "seek": 37348, "start": 385.72, "end": 389.56, "text": " This filter happens in two different levels.", "tokens": [50976, 639, 6608, 2314, 294, 732, 819, 4358, 13, 51168], "temperature": 0.0, "avg_logprob": -0.24520751757499498, "compression_ratio": 1.4903846153846154, "no_speech_prob": 0.15603822469711304}, {"id": 70, "seek": 37348, "start": 389.56, "end": 396.72, "text": " One with a Python using some other libraries too and the second one through Graphology and", "tokens": [51168, 1485, 365, 257, 15329, 1228, 512, 661, 15148, 886, 293, 264, 1150, 472, 807, 21884, 1793, 293, 51526], "temperature": 0.0, "avg_logprob": -0.24520751757499498, "compression_ratio": 1.4903846153846154, "no_speech_prob": 0.15603822469711304}, {"id": 71, "seek": 37348, "start": 396.72, "end": 402.6, "text": " Sigma, I think misspelled, using JavaScript.", "tokens": [51526, 36595, 11, 286, 519, 1713, 33000, 11, 1228, 15778, 13, 51820], "temperature": 0.0, "avg_logprob": -0.24520751757499498, "compression_ratio": 1.4903846153846154, "no_speech_prob": 0.15603822469711304}, {"id": 72, "seek": 40260, "start": 403.6, "end": 409.08000000000004, "text": " So this was introduction guys.", "tokens": [50414, 407, 341, 390, 9339, 1074, 13, 50688], "temperature": 0.0, "avg_logprob": -0.2819968952852137, "compression_ratio": 1.5591397849462365, "no_speech_prob": 0.026227332651615143}, {"id": 73, "seek": 40260, "start": 409.08000000000004, "end": 417.72, "text": " The point here is I'm going to share to you how each step uses different open source libraries", "tokens": [50688, 440, 935, 510, 307, 286, 478, 516, 281, 2073, 281, 291, 577, 1184, 1823, 4960, 819, 1269, 4009, 15148, 51120], "temperature": 0.0, "avg_logprob": -0.2819968952852137, "compression_ratio": 1.5591397849462365, "no_speech_prob": 0.026227332651615143}, {"id": 74, "seek": 40260, "start": 417.72, "end": 424.0, "text": " or software and that's one way to acknowledge to all the developers here that all that effort", "tokens": [51120, 420, 4722, 293, 300, 311, 472, 636, 281, 10692, 281, 439, 264, 8849, 510, 300, 439, 300, 4630, 51434], "temperature": 0.0, "avg_logprob": -0.2819968952852137, "compression_ratio": 1.5591397849462365, "no_speech_prob": 0.026227332651615143}, {"id": 75, "seek": 40260, "start": 424.0, "end": 432.56, "text": " you are doing is making people like me that is not really a developer.", "tokens": [51434, 291, 366, 884, 307, 1455, 561, 411, 385, 300, 307, 406, 534, 257, 10754, 13, 51862], "temperature": 0.0, "avg_logprob": -0.2819968952852137, "compression_ratio": 1.5591397849462365, "no_speech_prob": 0.026227332651615143}, {"id": 76, "seek": 43256, "start": 432.56, "end": 443.2, "text": " Trying to make a dialogue, talk between social science, computational science with the tools", "tokens": [50364, 20180, 281, 652, 257, 10221, 11, 751, 1296, 2093, 3497, 11, 28270, 3497, 365, 264, 3873, 50896], "temperature": 0.0, "avg_logprob": -0.2399744987487793, "compression_ratio": 1.4580645161290322, "no_speech_prob": 0.005777041893452406}, {"id": 77, "seek": 43256, "start": 443.2, "end": 447.8, "text": " that I can try to use.", "tokens": [50896, 300, 286, 393, 853, 281, 764, 13, 51126], "temperature": 0.0, "avg_logprob": -0.2399744987487793, "compression_ratio": 1.4580645161290322, "no_speech_prob": 0.005777041893452406}, {"id": 78, "seek": 43256, "start": 447.8, "end": 451.76, "text": " So there's a word there that is really important.", "tokens": [51126, 407, 456, 311, 257, 1349, 456, 300, 307, 534, 1021, 13, 51324], "temperature": 0.0, "avg_logprob": -0.2399744987487793, "compression_ratio": 1.4580645161290322, "no_speech_prob": 0.005777041893452406}, {"id": 79, "seek": 43256, "start": 451.76, "end": 458.64, "text": " It will go all the way from the whole slide show, it's data.", "tokens": [51324, 467, 486, 352, 439, 264, 636, 490, 264, 1379, 4137, 855, 11, 309, 311, 1412, 13, 51668], "temperature": 0.0, "avg_logprob": -0.2399744987487793, "compression_ratio": 1.4580645161290322, "no_speech_prob": 0.005777041893452406}, {"id": 80, "seek": 45864, "start": 458.71999999999997, "end": 469.0, "text": " We have been listening to that concept a lot and I really feel kind of sad because the", "tokens": [50368, 492, 362, 668, 4764, 281, 300, 3410, 257, 688, 293, 286, 534, 841, 733, 295, 4227, 570, 264, 50882], "temperature": 0.0, "avg_logprob": -0.3254545111405222, "compression_ratio": 1.3247863247863247, "no_speech_prob": 0.019953735172748566}, {"id": 81, "seek": 45864, "start": 469.0, "end": 485.0, "text": " effort that I can see in those talks before was about standard data.", "tokens": [50882, 4630, 300, 286, 393, 536, 294, 729, 6686, 949, 390, 466, 3832, 1412, 13, 51682], "temperature": 0.0, "avg_logprob": -0.3254545111405222, "compression_ratio": 1.3247863247863247, "no_speech_prob": 0.019953735172748566}, {"id": 82, "seek": 48500, "start": 485.0, "end": 493.24, "text": " Big platforms make tools to make standard data and this example is the whole other thing.", "tokens": [50364, 5429, 9473, 652, 3873, 281, 652, 3832, 1412, 293, 341, 1365, 307, 264, 1379, 661, 551, 13, 50776], "temperature": 0.0, "avg_logprob": -0.2586989998817444, "compression_ratio": 1.6474358974358974, "no_speech_prob": 0.21587318181991577}, {"id": 83, "seek": 48500, "start": 493.24, "end": 498.68, "text": " It's really different because it's a really custom data set.", "tokens": [50776, 467, 311, 534, 819, 570, 309, 311, 257, 534, 2375, 1412, 992, 13, 51048], "temperature": 0.0, "avg_logprob": -0.2586989998817444, "compression_ratio": 1.6474358974358974, "no_speech_prob": 0.21587318181991577}, {"id": 84, "seek": 48500, "start": 498.68, "end": 506.44, "text": " It's a really custom, it's a really niche social phenomena so there's no tools to study", "tokens": [51048, 467, 311, 257, 534, 2375, 11, 309, 311, 257, 534, 19956, 2093, 22004, 370, 456, 311, 572, 3873, 281, 2979, 51436], "temperature": 0.0, "avg_logprob": -0.2586989998817444, "compression_ratio": 1.6474358974358974, "no_speech_prob": 0.21587318181991577}, {"id": 85, "seek": 48500, "start": 506.44, "end": 511.72, "text": " this study object.", "tokens": [51436, 341, 2979, 2657, 13, 51700], "temperature": 0.0, "avg_logprob": -0.2586989998817444, "compression_ratio": 1.6474358974358974, "no_speech_prob": 0.21587318181991577}, {"id": 86, "seek": 51172, "start": 511.72, "end": 516.9200000000001, "text": " So we have to make them with anything we can.", "tokens": [50364, 407, 321, 362, 281, 652, 552, 365, 1340, 321, 393, 13, 50624], "temperature": 0.0, "avg_logprob": -0.16095081640749562, "compression_ratio": 1.4774193548387098, "no_speech_prob": 0.0029179800767451525}, {"id": 87, "seek": 51172, "start": 516.9200000000001, "end": 525.36, "text": " So data is the key and it's the link between execution devices, between disciplines, between", "tokens": [50624, 407, 1412, 307, 264, 2141, 293, 309, 311, 264, 2113, 1296, 15058, 5759, 11, 1296, 21919, 11, 1296, 51046], "temperature": 0.0, "avg_logprob": -0.16095081640749562, "compression_ratio": 1.4774193548387098, "no_speech_prob": 0.0029179800767451525}, {"id": 88, "seek": 51172, "start": 525.36, "end": 535.48, "text": " programming languages, theoretical frameworks, development libraries and social phenomena.", "tokens": [51046, 9410, 8650, 11, 20864, 29834, 11, 3250, 15148, 293, 2093, 22004, 13, 51552], "temperature": 0.0, "avg_logprob": -0.16095081640749562, "compression_ratio": 1.4774193548387098, "no_speech_prob": 0.0029179800767451525}, {"id": 89, "seek": 53548, "start": 535.48, "end": 543.0, "text": " That will help us to make interoperability between all of these different dimensions.", "tokens": [50364, 663, 486, 854, 505, 281, 652, 728, 7192, 2310, 1296, 439, 295, 613, 819, 12819, 13, 50740], "temperature": 0.0, "avg_logprob": -0.2089771560475796, "compression_ratio": 1.4676616915422886, "no_speech_prob": 0.21630138158798218}, {"id": 90, "seek": 53548, "start": 543.0, "end": 550.08, "text": " And I think, and I hope you do too, this will be only possible through open source and data.", "tokens": [50740, 400, 286, 519, 11, 293, 286, 1454, 291, 360, 886, 11, 341, 486, 312, 787, 1944, 807, 1269, 4009, 293, 1412, 13, 51094], "temperature": 0.0, "avg_logprob": -0.2089771560475796, "compression_ratio": 1.4676616915422886, "no_speech_prob": 0.21630138158798218}, {"id": 91, "seek": 53548, "start": 550.08, "end": 552.96, "text": " Data is the key here.", "tokens": [51094, 11888, 307, 264, 2141, 510, 13, 51238], "temperature": 0.0, "avg_logprob": -0.2089771560475796, "compression_ratio": 1.4676616915422886, "no_speech_prob": 0.21630138158798218}, {"id": 92, "seek": 53548, "start": 552.96, "end": 556.2, "text": " So the journey starts.", "tokens": [51238, 407, 264, 4671, 3719, 13, 51400], "temperature": 0.0, "avg_logprob": -0.2089771560475796, "compression_ratio": 1.4676616915422886, "no_speech_prob": 0.21630138158798218}, {"id": 93, "seek": 53548, "start": 556.2, "end": 563.28, "text": " I'm going to try to be really fast so I can have some of your comments.", "tokens": [51400, 286, 478, 516, 281, 853, 281, 312, 534, 2370, 370, 286, 393, 362, 512, 295, 428, 3053, 13, 51754], "temperature": 0.0, "avg_logprob": -0.2089771560475796, "compression_ratio": 1.4676616915422886, "no_speech_prob": 0.21630138158798218}, {"id": 94, "seek": 56328, "start": 563.28, "end": 569.6, "text": " I will tell you this is a master's degree thesis so each step it was way long.", "tokens": [50364, 286, 486, 980, 291, 341, 307, 257, 4505, 311, 4314, 22288, 370, 1184, 1823, 309, 390, 636, 938, 13, 50680], "temperature": 0.0, "avg_logprob": -0.234152689576149, "compression_ratio": 1.484076433121019, "no_speech_prob": 0.025649581104516983}, {"id": 95, "seek": 56328, "start": 569.6, "end": 575.4, "text": " If you think this is verbose, that's some other stuff.", "tokens": [50680, 759, 291, 519, 341, 307, 9595, 541, 11, 300, 311, 512, 661, 1507, 13, 50970], "temperature": 0.0, "avg_logprob": -0.234152689576149, "compression_ratio": 1.484076433121019, "no_speech_prob": 0.025649581104516983}, {"id": 96, "seek": 56328, "start": 575.4, "end": 585.8, "text": " So I'm using the first link between, I want to show you is between conceptual frameworks,", "tokens": [50970, 407, 286, 478, 1228, 264, 700, 2113, 1296, 11, 286, 528, 281, 855, 291, 307, 1296, 24106, 29834, 11, 51490], "temperature": 0.0, "avg_logprob": -0.234152689576149, "compression_ratio": 1.484076433121019, "no_speech_prob": 0.025649581104516983}, {"id": 97, "seek": 56328, "start": 585.8, "end": 587.0, "text": " theories.", "tokens": [51490, 13667, 13, 51550], "temperature": 0.0, "avg_logprob": -0.234152689576149, "compression_ratio": 1.484076433121019, "no_speech_prob": 0.025649581104516983}, {"id": 98, "seek": 58700, "start": 587.0, "end": 594.56, "text": " So we have Thompson, a guy from England that is trying to find these kind of categories", "tokens": [50364, 407, 321, 362, 23460, 11, 257, 2146, 490, 8196, 300, 307, 1382, 281, 915, 613, 733, 295, 10479, 50742], "temperature": 0.0, "avg_logprob": -0.3644098069932726, "compression_ratio": 1.5294117647058822, "no_speech_prob": 0.06419207900762558}, {"id": 99, "seek": 58700, "start": 594.56, "end": 601.28, "text": " to detect meaning, to detect symbolic stuff.", "tokens": [50742, 281, 5531, 3620, 11, 281, 5531, 25755, 1507, 13, 51078], "temperature": 0.0, "avg_logprob": -0.3644098069932726, "compression_ratio": 1.5294117647058822, "no_speech_prob": 0.06419207900762558}, {"id": 100, "seek": 58700, "start": 601.28, "end": 608.8, "text": " And we also have the graffiti de firma from Figueroa, that's a Spaniard, another Spaniard", "tokens": [51078, 400, 321, 611, 362, 264, 40531, 368, 12159, 1696, 490, 479, 16397, 2032, 64, 11, 300, 311, 257, 1738, 3782, 515, 11, 1071, 1738, 3782, 515, 51454], "temperature": 0.0, "avg_logprob": -0.3644098069932726, "compression_ratio": 1.5294117647058822, "no_speech_prob": 0.06419207900762558}, {"id": 101, "seek": 58700, "start": 608.8, "end": 615.88, "text": " guy that retomb these I exist, I am the SCART, I don't know in French maybe, the SCART, I", "tokens": [51454, 2146, 300, 1533, 3548, 613, 286, 2514, 11, 286, 669, 264, 9028, 15118, 11, 286, 500, 380, 458, 294, 5522, 1310, 11, 264, 9028, 15118, 11, 286, 51808], "temperature": 0.0, "avg_logprob": -0.3644098069932726, "compression_ratio": 1.5294117647058822, "no_speech_prob": 0.06419207900762558}, {"id": 102, "seek": 61588, "start": 615.88, "end": 625.08, "text": " don't know the right pronunciation, the SCART, the SCART is to the cart.", "tokens": [50364, 500, 380, 458, 264, 558, 23338, 11, 264, 9028, 15118, 11, 264, 9028, 15118, 307, 281, 264, 5467, 13, 50824], "temperature": 0.0, "avg_logprob": -0.306631790964227, "compression_ratio": 1.3877551020408163, "no_speech_prob": 0.02221854031085968}, {"id": 103, "seek": 61588, "start": 625.08, "end": 633.0, "text": " To see how graffiti writers broadcast themselves to the world.", "tokens": [50824, 1407, 536, 577, 40531, 13491, 9975, 2969, 281, 264, 1002, 13, 51220], "temperature": 0.0, "avg_logprob": -0.306631790964227, "compression_ratio": 1.3877551020408163, "no_speech_prob": 0.02221854031085968}, {"id": 104, "seek": 61588, "start": 633.0, "end": 635.4, "text": " So we're making this link, right?", "tokens": [51220, 407, 321, 434, 1455, 341, 2113, 11, 558, 30, 51340], "temperature": 0.0, "avg_logprob": -0.306631790964227, "compression_ratio": 1.3877551020408163, "no_speech_prob": 0.02221854031085968}, {"id": 105, "seek": 61588, "start": 635.4, "end": 639.92, "text": " Because data will be the key here.", "tokens": [51340, 1436, 1412, 486, 312, 264, 2141, 510, 13, 51566], "temperature": 0.0, "avg_logprob": -0.306631790964227, "compression_ratio": 1.3877551020408163, "no_speech_prob": 0.02221854031085968}, {"id": 106, "seek": 63992, "start": 640.4799999999999, "end": 648.92, "text": " To make this link between some theoretical point view perspective, to a way we can manage", "tokens": [50392, 1407, 652, 341, 2113, 1296, 512, 20864, 935, 1910, 4585, 11, 281, 257, 636, 321, 393, 3067, 50814], "temperature": 0.0, "avg_logprob": -0.25656429926554364, "compression_ratio": 1.5655172413793104, "no_speech_prob": 0.18779826164245605}, {"id": 107, "seek": 63992, "start": 648.92, "end": 657.16, "text": " to just back up at least, we need to make this, look for these terms, look for these", "tokens": [50814, 281, 445, 646, 493, 412, 1935, 11, 321, 643, 281, 652, 341, 11, 574, 337, 613, 2115, 11, 574, 337, 613, 51226], "temperature": 0.0, "avg_logprob": -0.25656429926554364, "compression_ratio": 1.5655172413793104, "no_speech_prob": 0.18779826164245605}, {"id": 108, "seek": 63992, "start": 657.16, "end": 666.4399999999999, "text": " stuff and make it some sort of way to, well to data.", "tokens": [51226, 1507, 293, 652, 309, 512, 1333, 295, 636, 281, 11, 731, 281, 1412, 13, 51690], "temperature": 0.0, "avg_logprob": -0.25656429926554364, "compression_ratio": 1.5655172413793104, "no_speech_prob": 0.18779826164245605}, {"id": 109, "seek": 66644, "start": 666.48, "end": 674.8800000000001, "text": " So we at least have these three categories, those things we are looking for.", "tokens": [50366, 407, 321, 412, 1935, 362, 613, 1045, 10479, 11, 729, 721, 321, 366, 1237, 337, 13, 50786], "temperature": 0.0, "avg_logprob": -0.2681990637295488, "compression_ratio": 1.9241379310344828, "no_speech_prob": 0.0036150827072560787}, {"id": 110, "seek": 66644, "start": 674.8800000000001, "end": 681.48, "text": " We are looking for geographies, so we are looking for cities, so we are making a dictionary,", "tokens": [50786, 492, 366, 1237, 337, 25435, 530, 11, 370, 321, 366, 1237, 337, 6486, 11, 370, 321, 366, 1455, 257, 25890, 11, 51116], "temperature": 0.0, "avg_logprob": -0.2681990637295488, "compression_ratio": 1.9241379310344828, "no_speech_prob": 0.0036150827072560787}, {"id": 111, "seek": 66644, "start": 681.48, "end": 682.6, "text": " a city dictionary.", "tokens": [51116, 257, 2307, 25890, 13, 51172], "temperature": 0.0, "avg_logprob": -0.2681990637295488, "compression_ratio": 1.9241379310344828, "no_speech_prob": 0.0036150827072560787}, {"id": 112, "seek": 66644, "start": 682.6, "end": 693.7600000000001, "text": " We are looking for communities, that's symbolic, shared terms, so this dictionary is about", "tokens": [51172, 492, 366, 1237, 337, 4456, 11, 300, 311, 25755, 11, 5507, 2115, 11, 370, 341, 25890, 307, 466, 51730], "temperature": 0.0, "avg_logprob": -0.2681990637295488, "compression_ratio": 1.9241379310344828, "no_speech_prob": 0.0036150827072560787}, {"id": 113, "seek": 69376, "start": 693.76, "end": 702.56, "text": " the words that graffiti writers use to tag their own posts and the freight workers use", "tokens": [50364, 264, 2283, 300, 40531, 13491, 764, 281, 6162, 641, 1065, 12300, 293, 264, 37181, 5600, 764, 50804], "temperature": 0.0, "avg_logprob": -0.27313531239827477, "compression_ratio": 1.6129032258064515, "no_speech_prob": 0.019180603325366974}, {"id": 114, "seek": 69376, "start": 702.56, "end": 710.24, "text": " too, so we can mix them, merge them and make this freight train dictionary.", "tokens": [50804, 886, 11, 370, 321, 393, 2890, 552, 11, 22183, 552, 293, 652, 341, 37181, 3847, 25890, 13, 51188], "temperature": 0.0, "avg_logprob": -0.27313531239827477, "compression_ratio": 1.6129032258064515, "no_speech_prob": 0.019180603325366974}, {"id": 115, "seek": 69376, "start": 710.24, "end": 721.04, "text": " And last but not least, we have entities, so we are looking for graffiti writers names.", "tokens": [51188, 400, 1036, 457, 406, 1935, 11, 321, 362, 16667, 11, 370, 321, 366, 1237, 337, 40531, 13491, 5288, 13, 51728], "temperature": 0.0, "avg_logprob": -0.27313531239827477, "compression_ratio": 1.6129032258064515, "no_speech_prob": 0.019180603325366974}, {"id": 116, "seek": 72104, "start": 721.04, "end": 731.3199999999999, "text": " We are going to scrap, we're going to mine these hashtags, these hashtags, conversations,", "tokens": [50364, 492, 366, 516, 281, 23138, 11, 321, 434, 516, 281, 3892, 613, 50016, 11, 613, 50016, 11, 7315, 11, 50878], "temperature": 0.0, "avg_logprob": -0.2710862814211378, "compression_ratio": 1.5955882352941178, "no_speech_prob": 0.017822246998548508}, {"id": 117, "seek": 72104, "start": 731.3199999999999, "end": 738.56, "text": " these hypertextual conversations and the network, we have that simple structure.", "tokens": [50878, 613, 9848, 25111, 901, 7315, 293, 264, 3209, 11, 321, 362, 300, 2199, 3877, 13, 51240], "temperature": 0.0, "avg_logprob": -0.2710862814211378, "compression_ratio": 1.5955882352941178, "no_speech_prob": 0.017822246998548508}, {"id": 118, "seek": 72104, "start": 738.56, "end": 746.1999999999999, "text": " Users post some publication and add some tags.", "tokens": [51240, 47092, 2183, 512, 19953, 293, 909, 512, 18632, 13, 51622], "temperature": 0.0, "avg_logprob": -0.2710862814211378, "compression_ratio": 1.5955882352941178, "no_speech_prob": 0.017822246998548508}, {"id": 119, "seek": 74620, "start": 746.2, "end": 752.1600000000001, "text": " But we are not only using one user's post, we are using a lot of them.", "tokens": [50364, 583, 321, 366, 406, 787, 1228, 472, 4195, 311, 2183, 11, 321, 366, 1228, 257, 688, 295, 552, 13, 50662], "temperature": 0.0, "avg_logprob": -0.24066070556640626, "compression_ratio": 1.59375, "no_speech_prob": 0.1489855796098709}, {"id": 120, "seek": 74620, "start": 752.1600000000001, "end": 759.32, "text": " So we have this seed node, the seed node is the first hashtag scrapped and this Instagram", "tokens": [50662, 407, 321, 362, 341, 8871, 9984, 11, 264, 8871, 9984, 307, 264, 700, 20379, 13943, 3320, 293, 341, 5281, 51020], "temperature": 0.0, "avg_logprob": -0.24066070556640626, "compression_ratio": 1.59375, "no_speech_prob": 0.1489855796098709}, {"id": 121, "seek": 74620, "start": 759.32, "end": 769.6, "text": " data mining boat, really original name, will download an infinite number of posts and then", "tokens": [51020, 1412, 15512, 6582, 11, 534, 3380, 1315, 11, 486, 5484, 364, 13785, 1230, 295, 12300, 293, 550, 51534], "temperature": 0.0, "avg_logprob": -0.24066070556640626, "compression_ratio": 1.59375, "no_speech_prob": 0.1489855796098709}, {"id": 122, "seek": 74620, "start": 769.6, "end": 775.6, "text": " add new hashtags that are found on these publications.", "tokens": [51534, 909, 777, 50016, 300, 366, 1352, 322, 613, 25618, 13, 51834], "temperature": 0.0, "avg_logprob": -0.24066070556640626, "compression_ratio": 1.59375, "no_speech_prob": 0.1489855796098709}, {"id": 123, "seek": 77560, "start": 775.6, "end": 784.52, "text": " That will give us this primitive kind of network, this is a small one, the seed node was graffiti", "tokens": [50364, 663, 486, 976, 505, 341, 28540, 733, 295, 3209, 11, 341, 307, 257, 1359, 472, 11, 264, 8871, 9984, 390, 40531, 50810], "temperature": 0.0, "avg_logprob": -0.25470864594872317, "compression_ratio": 1.6035502958579881, "no_speech_prob": 0.07101021707057953}, {"id": 124, "seek": 77560, "start": 784.52, "end": 793.44, "text": " bombing, we used a mining depth of only zero, so it will only mine that in this case 30", "tokens": [50810, 31292, 11, 321, 1143, 257, 15512, 7161, 295, 787, 4018, 11, 370, 309, 486, 787, 3892, 300, 294, 341, 1389, 2217, 51256], "temperature": 0.0, "avg_logprob": -0.25470864594872317, "compression_ratio": 1.6035502958579881, "no_speech_prob": 0.07101021707057953}, {"id": 125, "seek": 77560, "start": 793.44, "end": 804.72, "text": " posts that are using this specific hashtag, but as you will see, graffiti bombing has", "tokens": [51256, 12300, 300, 366, 1228, 341, 2685, 20379, 11, 457, 382, 291, 486, 536, 11, 40531, 31292, 575, 51820], "temperature": 0.0, "avg_logprob": -0.25470864594872317, "compression_ratio": 1.6035502958579881, "no_speech_prob": 0.07101021707057953}, {"id": 126, "seek": 80472, "start": 804.72, "end": 813.44, "text": " 30 posts, but this other post is also using different hashtags.", "tokens": [50364, 2217, 12300, 11, 457, 341, 661, 2183, 307, 611, 1228, 819, 50016, 13, 50800], "temperature": 0.0, "avg_logprob": -0.3760493296497273, "compression_ratio": 1.3732394366197183, "no_speech_prob": 0.053152669221162796}, {"id": 127, "seek": 80472, "start": 813.44, "end": 820.9200000000001, "text": " So that is how this network is built.", "tokens": [50800, 407, 300, 307, 577, 341, 3209, 307, 3094, 13, 51174], "temperature": 0.0, "avg_logprob": -0.3760493296497273, "compression_ratio": 1.3732394366197183, "no_speech_prob": 0.053152669221162796}, {"id": 128, "seek": 80472, "start": 820.9200000000001, "end": 831.88, "text": " For making this mining, I'm using Instagram app, it's an unofficial Instagram app for", "tokens": [51174, 1171, 1455, 341, 15512, 11, 286, 478, 1228, 5281, 724, 11, 309, 311, 364, 8526, 37661, 5281, 724, 337, 51722], "temperature": 0.0, "avg_logprob": -0.3760493296497273, "compression_ratio": 1.3732394366197183, "no_speech_prob": 0.053152669221162796}, {"id": 129, "seek": 80472, "start": 831.88, "end": 832.96, "text": " Python.", "tokens": [51722, 15329, 13, 51776], "temperature": 0.0, "avg_logprob": -0.3760493296497273, "compression_ratio": 1.3732394366197183, "no_speech_prob": 0.053152669221162796}, {"id": 130, "seek": 83296, "start": 833.4000000000001, "end": 842.36, "text": " I don't know if it's a privacy stuff and I know it's tricky, so I won't talk about it.", "tokens": [50386, 286, 500, 380, 458, 498, 309, 311, 257, 11427, 1507, 293, 286, 458, 309, 311, 12414, 11, 370, 286, 1582, 380, 751, 466, 309, 13, 50834], "temperature": 0.0, "avg_logprob": -0.2510004647170441, "compression_ratio": 1.5179487179487179, "no_speech_prob": 0.0686856135725975}, {"id": 131, "seek": 83296, "start": 842.36, "end": 853.08, "text": " But I use Docker, so I can make a Raspberry, we try to mimic human behaviors, so this mining", "tokens": [50834, 583, 286, 764, 33772, 11, 370, 286, 393, 652, 257, 41154, 11, 321, 853, 281, 31075, 1952, 15501, 11, 370, 341, 15512, 51370], "temperature": 0.0, "avg_logprob": -0.2510004647170441, "compression_ratio": 1.5179487179487179, "no_speech_prob": 0.0686856135725975}, {"id": 132, "seek": 83296, "start": 853.08, "end": 860.0, "text": " will last for maybe one week for each conversation and if these conversations are really large,", "tokens": [51370, 486, 1036, 337, 1310, 472, 1243, 337, 1184, 3761, 293, 498, 613, 7315, 366, 534, 2416, 11, 51716], "temperature": 0.0, "avg_logprob": -0.2510004647170441, "compression_ratio": 1.5179487179487179, "no_speech_prob": 0.0686856135725975}, {"id": 133, "seek": 83296, "start": 860.0, "end": 861.8000000000001, "text": " it will last longer.", "tokens": [51716, 309, 486, 1036, 2854, 13, 51806], "temperature": 0.0, "avg_logprob": -0.2510004647170441, "compression_ratio": 1.5179487179487179, "no_speech_prob": 0.0686856135725975}, {"id": 134, "seek": 86180, "start": 861.8, "end": 871.4399999999999, "text": " So that's why we are using this low consumption computer and then after we scrap this, we", "tokens": [50364, 407, 300, 311, 983, 321, 366, 1228, 341, 2295, 12126, 3820, 293, 550, 934, 321, 23138, 341, 11, 321, 50846], "temperature": 0.0, "avg_logprob": -0.18126445520119588, "compression_ratio": 1.547945205479452, "no_speech_prob": 0.006348198279738426}, {"id": 135, "seek": 86180, "start": 871.4399999999999, "end": 875.24, "text": " will put it on the SQL database.", "tokens": [50846, 486, 829, 309, 322, 264, 19200, 8149, 13, 51036], "temperature": 0.0, "avg_logprob": -0.18126445520119588, "compression_ratio": 1.547945205479452, "no_speech_prob": 0.006348198279738426}, {"id": 136, "seek": 86180, "start": 875.24, "end": 879.9599999999999, "text": " So we are going from the publications to the SQL database.", "tokens": [51036, 407, 321, 366, 516, 490, 264, 25618, 281, 264, 19200, 8149, 13, 51272], "temperature": 0.0, "avg_logprob": -0.18126445520119588, "compression_ratio": 1.547945205479452, "no_speech_prob": 0.006348198279738426}, {"id": 137, "seek": 86180, "start": 879.9599999999999, "end": 884.8, "text": " So this will be a really fast way to put it.", "tokens": [51272, 407, 341, 486, 312, 257, 534, 2370, 636, 281, 829, 309, 13, 51514], "temperature": 0.0, "avg_logprob": -0.18126445520119588, "compression_ratio": 1.547945205479452, "no_speech_prob": 0.006348198279738426}, {"id": 138, "seek": 88480, "start": 884.8, "end": 893.76, "text": " We came from reality to Instagram and from Instagram to our own dataset.", "tokens": [50364, 492, 1361, 490, 4103, 281, 5281, 293, 490, 5281, 281, 527, 1065, 28872, 13, 50812], "temperature": 0.0, "avg_logprob": -0.1834079768206622, "compression_ratio": 1.4947916666666667, "no_speech_prob": 0.055740125477313995}, {"id": 139, "seek": 88480, "start": 893.76, "end": 900.52, "text": " But we are now looking for these terms on the dictionary we already made before.", "tokens": [50812, 583, 321, 366, 586, 1237, 337, 613, 2115, 322, 264, 25890, 321, 1217, 1027, 949, 13, 51150], "temperature": 0.0, "avg_logprob": -0.1834079768206622, "compression_ratio": 1.4947916666666667, "no_speech_prob": 0.055740125477313995}, {"id": 140, "seek": 88480, "start": 900.52, "end": 910.16, "text": " So in this case, this is a writer from my city, Afex, he wrote that train in Mexico and", "tokens": [51150, 407, 294, 341, 1389, 11, 341, 307, 257, 9936, 490, 452, 2307, 11, 316, 2106, 87, 11, 415, 4114, 300, 3847, 294, 8612, 293, 51632], "temperature": 0.0, "avg_logprob": -0.1834079768206622, "compression_ratio": 1.4947916666666667, "no_speech_prob": 0.055740125477313995}, {"id": 141, "seek": 88480, "start": 910.16, "end": 914.4, "text": " now somebody else sent him the photo in Utah.", "tokens": [51632, 586, 2618, 1646, 2279, 796, 264, 5052, 294, 20226, 13, 51844], "temperature": 0.0, "avg_logprob": -0.1834079768206622, "compression_ratio": 1.4947916666666667, "no_speech_prob": 0.055740125477313995}, {"id": 142, "seek": 91440, "start": 914.4, "end": 922.88, "text": " So he will put his name, the place it was found, some other stuff and some slang for", "tokens": [50364, 407, 415, 486, 829, 702, 1315, 11, 264, 1081, 309, 390, 1352, 11, 512, 661, 1507, 293, 512, 42517, 337, 50788], "temperature": 0.0, "avg_logprob": -0.25334653400239493, "compression_ratio": 1.448051948051948, "no_speech_prob": 0.005096592009067535}, {"id": 143, "seek": 91440, "start": 922.88, "end": 929.92, "text": " the same community and also his crew, his group.", "tokens": [50788, 264, 912, 1768, 293, 611, 702, 7260, 11, 702, 1594, 13, 51140], "temperature": 0.0, "avg_logprob": -0.25334653400239493, "compression_ratio": 1.448051948051948, "no_speech_prob": 0.005096592009067535}, {"id": 144, "seek": 91440, "start": 933.4399999999999, "end": 941.72, "text": " So if we try to put this text in spicy, we'll give us only one token and that won't help.", "tokens": [51316, 407, 498, 321, 853, 281, 829, 341, 2487, 294, 9127, 11, 321, 603, 976, 505, 787, 472, 14862, 293, 300, 1582, 380, 854, 13, 51730], "temperature": 0.0, "avg_logprob": -0.25334653400239493, "compression_ratio": 1.448051948051948, "no_speech_prob": 0.005096592009067535}, {"id": 145, "seek": 94172, "start": 941.76, "end": 945.48, "text": " So we have to split the hashtag in small words.", "tokens": [50366, 407, 321, 362, 281, 7472, 264, 20379, 294, 1359, 2283, 13, 50552], "temperature": 0.0, "avg_logprob": -0.26321090351451526, "compression_ratio": 1.480263157894737, "no_speech_prob": 0.018173877149820328}, {"id": 146, "seek": 94172, "start": 945.48, "end": 948.84, "text": " So the answer was really cool.", "tokens": [50552, 407, 264, 1867, 390, 534, 1627, 13, 50720], "temperature": 0.0, "avg_logprob": -0.26321090351451526, "compression_ratio": 1.480263157894737, "no_speech_prob": 0.018173877149820328}, {"id": 147, "seek": 94172, "start": 948.84, "end": 951.52, "text": " It was already on Stack Overflow.", "tokens": [50720, 467, 390, 1217, 322, 37649, 4886, 10565, 13, 50854], "temperature": 0.0, "avg_logprob": -0.26321090351451526, "compression_ratio": 1.480263157894737, "no_speech_prob": 0.018173877149820328}, {"id": 148, "seek": 94172, "start": 951.52, "end": 956.12, "text": " So thank you to that guy.", "tokens": [50854, 407, 1309, 291, 281, 300, 2146, 13, 51084], "temperature": 0.0, "avg_logprob": -0.26321090351451526, "compression_ratio": 1.480263157894737, "no_speech_prob": 0.018173877149820328}, {"id": 149, "seek": 94172, "start": 956.12, "end": 959.1600000000001, "text": " I put it in the paperwork.", "tokens": [51084, 286, 829, 309, 294, 264, 27953, 13, 51236], "temperature": 0.0, "avg_logprob": -0.26321090351451526, "compression_ratio": 1.480263157894737, "no_speech_prob": 0.018173877149820328}, {"id": 150, "seek": 94172, "start": 959.1600000000001, "end": 963.4, "text": " It's there because we have to acknowledge some others work.", "tokens": [51236, 467, 311, 456, 570, 321, 362, 281, 10692, 512, 2357, 589, 13, 51448], "temperature": 0.0, "avg_logprob": -0.26321090351451526, "compression_ratio": 1.480263157894737, "no_speech_prob": 0.018173877149820328}, {"id": 151, "seek": 96340, "start": 963.4, "end": 973.04, "text": " So I have to build this really big dictionary of all the words we know in Spanish and English", "tokens": [50364, 407, 286, 362, 281, 1322, 341, 534, 955, 25890, 295, 439, 264, 2283, 321, 458, 294, 8058, 293, 3669, 50846], "temperature": 0.0, "avg_logprob": -0.17900942166646322, "compression_ratio": 1.4303797468354431, "no_speech_prob": 0.0061778537929058075}, {"id": 152, "seek": 96340, "start": 973.04, "end": 975.72, "text": " to split the hashtag.", "tokens": [50846, 281, 7472, 264, 20379, 13, 50980], "temperature": 0.0, "avg_logprob": -0.17900942166646322, "compression_ratio": 1.4303797468354431, "no_speech_prob": 0.0061778537929058075}, {"id": 153, "seek": 96340, "start": 975.72, "end": 979.52, "text": " And after that, we'll look in these dictionaries.", "tokens": [50980, 400, 934, 300, 11, 321, 603, 574, 294, 613, 22352, 4889, 13, 51170], "temperature": 0.0, "avg_logprob": -0.17900942166646322, "compression_ratio": 1.4303797468354431, "no_speech_prob": 0.0061778537929058075}, {"id": 154, "seek": 96340, "start": 979.52, "end": 984.6, "text": " If some word is inside any dictionary, it will be marked as.", "tokens": [51170, 759, 512, 1349, 307, 1854, 604, 25890, 11, 309, 486, 312, 12658, 382, 13, 51424], "temperature": 0.0, "avg_logprob": -0.17900942166646322, "compression_ratio": 1.4303797468354431, "no_speech_prob": 0.0061778537929058075}, {"id": 155, "seek": 98460, "start": 984.72, "end": 994.72, "text": " If it's not, we will think about it as a writer name or as a crew name too.", "tokens": [50370, 759, 309, 311, 406, 11, 321, 486, 519, 466, 309, 382, 257, 9936, 1315, 420, 382, 257, 7260, 1315, 886, 13, 50870], "temperature": 0.0, "avg_logprob": -0.19789681067833534, "compression_ratio": 1.5375, "no_speech_prob": 0.1679595559835434}, {"id": 156, "seek": 98460, "start": 994.72, "end": 1003.96, "text": " But we're making sure this is real and we will look for graffiti in any part of the", "tokens": [50870, 583, 321, 434, 1455, 988, 341, 307, 957, 293, 321, 486, 574, 337, 40531, 294, 604, 644, 295, 264, 51332], "temperature": 0.0, "avg_logprob": -0.19789681067833534, "compression_ratio": 1.5375, "no_speech_prob": 0.1679595559835434}, {"id": 157, "seek": 98460, "start": 1003.96, "end": 1013.88, "text": " caption to make us sure that that strange string is actually a graffiti writer's name.", "tokens": [51332, 31974, 281, 652, 505, 988, 300, 300, 5861, 6798, 307, 767, 257, 40531, 9936, 311, 1315, 13, 51828], "temperature": 0.0, "avg_logprob": -0.19789681067833534, "compression_ratio": 1.5375, "no_speech_prob": 0.1679595559835434}, {"id": 158, "seek": 101388, "start": 1013.88, "end": 1016.48, "text": " So this is simple, but it works.", "tokens": [50364, 407, 341, 307, 2199, 11, 457, 309, 1985, 13, 50494], "temperature": 0.0, "avg_logprob": -0.29432719266867335, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.0034637972712516785}, {"id": 159, "seek": 101388, "start": 1016.48, "end": 1026.0, "text": " We have those words, how those hashtags were marked by this software.", "tokens": [50494, 492, 362, 729, 2283, 11, 577, 729, 50016, 645, 12658, 538, 341, 4722, 13, 50970], "temperature": 0.0, "avg_logprob": -0.29432719266867335, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.0034637972712516785}, {"id": 160, "seek": 101388, "start": 1026.0, "end": 1030.48, "text": " So we have throw up calls, bubble style.", "tokens": [50970, 407, 321, 362, 3507, 493, 5498, 11, 12212, 3758, 13, 51194], "temperature": 0.0, "avg_logprob": -0.29432719266867335, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.0034637972712516785}, {"id": 161, "seek": 101388, "start": 1030.48, "end": 1035.56, "text": " And this is interesting, but it will be more interesting when we try to put everything", "tokens": [51194, 400, 341, 307, 1880, 11, 457, 309, 486, 312, 544, 1880, 562, 321, 853, 281, 829, 1203, 51448], "temperature": 0.0, "avg_logprob": -0.29432719266867335, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.0034637972712516785}, {"id": 162, "seek": 101388, "start": 1035.56, "end": 1038.56, "text": " together.", "tokens": [51448, 1214, 13, 51598], "temperature": 0.0, "avg_logprob": -0.29432719266867335, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.0034637972712516785}, {"id": 163, "seek": 101388, "start": 1038.56, "end": 1042.8, "text": " We do it with a spicy docker on Sorrasberry.", "tokens": [51598, 492, 360, 309, 365, 257, 9127, 360, 9178, 322, 21421, 3906, 9099, 13, 51810], "temperature": 0.0, "avg_logprob": -0.29432719266867335, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.0034637972712516785}, {"id": 164, "seek": 104280, "start": 1042.9199999999998, "end": 1045.04, "text": " I'm going to be really fast now.", "tokens": [50370, 286, 478, 516, 281, 312, 534, 2370, 586, 13, 50476], "temperature": 0.0, "avg_logprob": -0.20104841642741916, "compression_ratio": 1.5103092783505154, "no_speech_prob": 0.029904479160904884}, {"id": 165, "seek": 104280, "start": 1045.04, "end": 1053.12, "text": " These are two image detection models, ones for Google, ones for IMAID.", "tokens": [50476, 1981, 366, 732, 3256, 17784, 5245, 11, 2306, 337, 3329, 11, 2306, 337, 286, 9998, 2777, 13, 50880], "temperature": 0.0, "avg_logprob": -0.20104841642741916, "compression_ratio": 1.5103092783505154, "no_speech_prob": 0.029904479160904884}, {"id": 166, "seek": 104280, "start": 1053.12, "end": 1060.72, "text": " And that's cool because this is the same technical process, the same image, but it's seeing two", "tokens": [50880, 400, 300, 311, 1627, 570, 341, 307, 264, 912, 6191, 1399, 11, 264, 912, 3256, 11, 457, 309, 311, 2577, 732, 51260], "temperature": 0.0, "avg_logprob": -0.20104841642741916, "compression_ratio": 1.5103092783505154, "no_speech_prob": 0.029904479160904884}, {"id": 167, "seek": 104280, "start": 1060.72, "end": 1063.72, "text": " different stuff, right?", "tokens": [51260, 819, 1507, 11, 558, 30, 51410], "temperature": 0.0, "avg_logprob": -0.20104841642741916, "compression_ratio": 1.5103092783505154, "no_speech_prob": 0.029904479160904884}, {"id": 168, "seek": 104280, "start": 1063.72, "end": 1069.32, "text": " Because the models will see what we want them to see in the training.", "tokens": [51410, 1436, 264, 5245, 486, 536, 437, 321, 528, 552, 281, 536, 294, 264, 3097, 13, 51690], "temperature": 0.0, "avg_logprob": -0.20104841642741916, "compression_ratio": 1.5103092783505154, "no_speech_prob": 0.029904479160904884}, {"id": 169, "seek": 106932, "start": 1069.36, "end": 1076.3999999999999, "text": " So that's really straightforward, but it's really important because the Google model,", "tokens": [50366, 407, 300, 311, 534, 15325, 11, 457, 309, 311, 534, 1021, 570, 264, 3329, 2316, 11, 50718], "temperature": 0.0, "avg_logprob": -0.2231578324970446, "compression_ratio": 1.457516339869281, "no_speech_prob": 0.005200184416025877}, {"id": 170, "seek": 106932, "start": 1076.3999999999999, "end": 1081.28, "text": " it won't be useful for me at all.", "tokens": [50718, 309, 1582, 380, 312, 4420, 337, 385, 412, 439, 13, 50962], "temperature": 0.0, "avg_logprob": -0.2231578324970446, "compression_ratio": 1.457516339869281, "no_speech_prob": 0.005200184416025877}, {"id": 171, "seek": 106932, "start": 1081.28, "end": 1088.2, "text": " So this is the result of using this model.", "tokens": [50962, 407, 341, 307, 264, 1874, 295, 1228, 341, 2316, 13, 51308], "temperature": 0.0, "avg_logprob": -0.2231578324970446, "compression_ratio": 1.457516339869281, "no_speech_prob": 0.005200184416025877}, {"id": 172, "seek": 106932, "start": 1088.2, "end": 1094.32, "text": " Also it will be interesting when we put everything together.", "tokens": [51308, 2743, 309, 486, 312, 1880, 562, 321, 829, 1203, 1214, 13, 51614], "temperature": 0.0, "avg_logprob": -0.2231578324970446, "compression_ratio": 1.457516339869281, "no_speech_prob": 0.005200184416025877}, {"id": 173, "seek": 109432, "start": 1094.32, "end": 1100.8, "text": " We are using Jupyter with Google collab because it's free, so we can make an SQL query and", "tokens": [50364, 492, 366, 1228, 22125, 88, 391, 365, 3329, 44228, 570, 309, 311, 1737, 11, 370, 321, 393, 652, 364, 19200, 14581, 293, 50688], "temperature": 0.0, "avg_logprob": -0.20476457651923685, "compression_ratio": 1.439153439153439, "no_speech_prob": 0.008956572972238064}, {"id": 174, "seek": 109432, "start": 1100.8, "end": 1106.08, "text": " then it will download the images and apply the model.", "tokens": [50688, 550, 309, 486, 5484, 264, 5267, 293, 3079, 264, 2316, 13, 50952], "temperature": 0.0, "avg_logprob": -0.20476457651923685, "compression_ratio": 1.439153439153439, "no_speech_prob": 0.008956572972238064}, {"id": 175, "seek": 109432, "start": 1106.08, "end": 1115.56, "text": " So the beauty of relational databases is you can access to these different content from", "tokens": [50952, 407, 264, 6643, 295, 38444, 22380, 307, 291, 393, 2105, 281, 613, 819, 2701, 490, 51426], "temperature": 0.0, "avg_logprob": -0.20476457651923685, "compression_ratio": 1.439153439153439, "no_speech_prob": 0.008956572972238064}, {"id": 176, "seek": 109432, "start": 1115.56, "end": 1117.32, "text": " different sizes.", "tokens": [51426, 819, 11602, 13, 51514], "temperature": 0.0, "avg_logprob": -0.20476457651923685, "compression_ratio": 1.439153439153439, "no_speech_prob": 0.008956572972238064}, {"id": 177, "seek": 109432, "start": 1117.32, "end": 1119.6399999999999, "text": " You already know this.", "tokens": [51514, 509, 1217, 458, 341, 13, 51630], "temperature": 0.0, "avg_logprob": -0.20476457651923685, "compression_ratio": 1.439153439153439, "no_speech_prob": 0.008956572972238064}, {"id": 178, "seek": 111964, "start": 1119.64, "end": 1129.5600000000002, "text": " But the point here, we are going from the database to JSON network and we will get something", "tokens": [50364, 583, 264, 935, 510, 11, 321, 366, 516, 490, 264, 8149, 281, 31828, 3209, 293, 321, 486, 483, 746, 50860], "temperature": 0.0, "avg_logprob": -0.24003361293247769, "compression_ratio": 1.4761904761904763, "no_speech_prob": 0.011793364770710468}, {"id": 179, "seek": 111964, "start": 1129.5600000000002, "end": 1131.5200000000002, "text": " like this, right?", "tokens": [50860, 411, 341, 11, 558, 30, 50958], "temperature": 0.0, "avg_logprob": -0.24003361293247769, "compression_ratio": 1.4761904761904763, "no_speech_prob": 0.011793364770710468}, {"id": 180, "seek": 111964, "start": 1131.5200000000002, "end": 1140.6000000000001, "text": " We have in the middle, in yellow, the inference notes and purple, the images were detected.", "tokens": [50958, 492, 362, 294, 264, 2808, 11, 294, 5566, 11, 264, 38253, 5570, 293, 9656, 11, 264, 5267, 645, 21896, 13, 51412], "temperature": 0.0, "avg_logprob": -0.24003361293247769, "compression_ratio": 1.4761904761904763, "no_speech_prob": 0.011793364770710468}, {"id": 181, "seek": 111964, "start": 1140.6000000000001, "end": 1146.8400000000001, "text": " And the point here is to see how users gather using the same symbolic stuff.", "tokens": [51412, 400, 264, 935, 510, 307, 281, 536, 577, 5022, 5448, 1228, 264, 912, 25755, 1507, 13, 51724], "temperature": 0.0, "avg_logprob": -0.24003361293247769, "compression_ratio": 1.4761904761904763, "no_speech_prob": 0.011793364770710468}, {"id": 182, "seek": 114684, "start": 1146.9199999999998, "end": 1153.4399999999998, "text": " That can be the same symbolic stuff, some kind of graffiti, some specific slang word,", "tokens": [50368, 663, 393, 312, 264, 912, 25755, 1507, 11, 512, 733, 295, 40531, 11, 512, 2685, 42517, 1349, 11, 50694], "temperature": 0.0, "avg_logprob": -0.27321634292602537, "compression_ratio": 1.5966850828729282, "no_speech_prob": 0.05960482731461525}, {"id": 183, "seek": 114684, "start": 1153.4399999999998, "end": 1155.4399999999998, "text": " some kind of city.", "tokens": [50694, 512, 733, 295, 2307, 13, 50794], "temperature": 0.0, "avg_logprob": -0.27321634292602537, "compression_ratio": 1.5966850828729282, "no_speech_prob": 0.05960482731461525}, {"id": 184, "seek": 114684, "start": 1155.4399999999998, "end": 1163.6, "text": " We can see in this point how somebody in Tijuana maybe will use the same...", "tokens": [50794, 492, 393, 536, 294, 341, 935, 577, 2618, 294, 314, 21992, 1310, 486, 764, 264, 912, 485, 51202], "temperature": 0.0, "avg_logprob": -0.27321634292602537, "compression_ratio": 1.5966850828729282, "no_speech_prob": 0.05960482731461525}, {"id": 185, "seek": 114684, "start": 1163.6, "end": 1168.1999999999998, "text": " Some group in Tijuana will use maybe the same style.", "tokens": [51202, 2188, 1594, 294, 314, 21992, 486, 764, 1310, 264, 912, 3758, 13, 51432], "temperature": 0.0, "avg_logprob": -0.27321634292602537, "compression_ratio": 1.5966850828729282, "no_speech_prob": 0.05960482731461525}, {"id": 186, "seek": 114684, "start": 1168.1999999999998, "end": 1169.9599999999998, "text": " I think that's important.", "tokens": [51432, 286, 519, 300, 311, 1021, 13, 51520], "temperature": 0.0, "avg_logprob": -0.27321634292602537, "compression_ratio": 1.5966850828729282, "no_speech_prob": 0.05960482731461525}, {"id": 187, "seek": 114684, "start": 1169.9599999999998, "end": 1174.72, "text": " But this is a hot mess again.", "tokens": [51520, 583, 341, 307, 257, 2368, 2082, 797, 13, 51758], "temperature": 0.0, "avg_logprob": -0.27321634292602537, "compression_ratio": 1.5966850828729282, "no_speech_prob": 0.05960482731461525}, {"id": 188, "seek": 117472, "start": 1174.72, "end": 1181.68, "text": " It's thousands of notes of different types, so we have to clean this.", "tokens": [50364, 467, 311, 5383, 295, 5570, 295, 819, 3467, 11, 370, 321, 362, 281, 2541, 341, 13, 50712], "temperature": 0.0, "avg_logprob": -0.22450800909512286, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.04425806179642677}, {"id": 189, "seek": 117472, "start": 1181.68, "end": 1190.84, "text": " Looking for significance, or meaning or symbolic forms.", "tokens": [50712, 11053, 337, 17687, 11, 420, 3620, 420, 25755, 6422, 13, 51170], "temperature": 0.0, "avg_logprob": -0.22450800909512286, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.04425806179642677}, {"id": 190, "seek": 117472, "start": 1190.84, "end": 1194.92, "text": " We know a man is an animal suspend in webs of significance.", "tokens": [51170, 492, 458, 257, 587, 307, 364, 5496, 42546, 294, 2859, 295, 17687, 13, 51374], "temperature": 0.0, "avg_logprob": -0.22450800909512286, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.04425806179642677}, {"id": 191, "seek": 117472, "start": 1194.92, "end": 1199.04, "text": " He himself has fun, but we can clean that.", "tokens": [51374, 634, 3647, 575, 1019, 11, 457, 321, 393, 2541, 300, 13, 51580], "temperature": 0.0, "avg_logprob": -0.22450800909512286, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.04425806179642677}, {"id": 192, "seek": 117472, "start": 1199.04, "end": 1202.64, "text": " We're trying to clean that.", "tokens": [51580, 492, 434, 1382, 281, 2541, 300, 13, 51760], "temperature": 0.0, "avg_logprob": -0.22450800909512286, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.04425806179642677}, {"id": 193, "seek": 120264, "start": 1202.64, "end": 1207.5200000000002, "text": " So the note reduction will be the shortest path to the meaning.", "tokens": [50364, 407, 264, 3637, 11004, 486, 312, 264, 31875, 3100, 281, 264, 3620, 13, 50608], "temperature": 0.0, "avg_logprob": -0.233324620630834, "compression_ratio": 1.5604395604395604, "no_speech_prob": 0.00314721348695457}, {"id": 194, "seek": 120264, "start": 1207.5200000000002, "end": 1213.72, "text": " We're going from that to the really clean network.", "tokens": [50608, 492, 434, 516, 490, 300, 281, 264, 534, 2541, 3209, 13, 50918], "temperature": 0.0, "avg_logprob": -0.233324620630834, "compression_ratio": 1.5604395604395604, "no_speech_prob": 0.00314721348695457}, {"id": 195, "seek": 120264, "start": 1213.72, "end": 1215.68, "text": " At least I think so.", "tokens": [50918, 1711, 1935, 286, 519, 370, 13, 51016], "temperature": 0.0, "avg_logprob": -0.233324620630834, "compression_ratio": 1.5604395604395604, "no_speech_prob": 0.00314721348695457}, {"id": 196, "seek": 120264, "start": 1215.68, "end": 1223.6000000000001, "text": " So the algorithm, the thing that's happening here is that for each user node, we're making", "tokens": [51016, 407, 264, 9284, 11, 264, 551, 300, 311, 2737, 510, 307, 300, 337, 1184, 4195, 9984, 11, 321, 434, 1455, 51412], "temperature": 0.0, "avg_logprob": -0.233324620630834, "compression_ratio": 1.5604395604395604, "no_speech_prob": 0.00314721348695457}, {"id": 197, "seek": 120264, "start": 1223.6000000000001, "end": 1224.92, "text": " an array.", "tokens": [51412, 364, 10225, 13, 51478], "temperature": 0.0, "avg_logprob": -0.233324620630834, "compression_ratio": 1.5604395604395604, "no_speech_prob": 0.00314721348695457}, {"id": 198, "seek": 120264, "start": 1224.92, "end": 1229.0400000000002, "text": " Then I have another array of the whole network.", "tokens": [51478, 1396, 286, 362, 1071, 10225, 295, 264, 1379, 3209, 13, 51684], "temperature": 0.0, "avg_logprob": -0.233324620630834, "compression_ratio": 1.5604395604395604, "no_speech_prob": 0.00314721348695457}, {"id": 199, "seek": 122904, "start": 1229.04, "end": 1236.84, "text": " And if they have a shortest path that is like an algorithm using graphology, and another", "tokens": [50364, 400, 498, 436, 362, 257, 31875, 3100, 300, 307, 411, 364, 9284, 1228, 4295, 1793, 11, 293, 1071, 50754], "temperature": 0.0, "avg_logprob": -0.27572601719906453, "compression_ratio": 1.5777777777777777, "no_speech_prob": 0.010865612886846066}, {"id": 200, "seek": 122904, "start": 1236.84, "end": 1242.36, "text": " place is two, that if this match some...", "tokens": [50754, 1081, 307, 732, 11, 300, 498, 341, 2995, 512, 485, 51030], "temperature": 0.0, "avg_logprob": -0.27572601719906453, "compression_ratio": 1.5777777777777777, "no_speech_prob": 0.010865612886846066}, {"id": 201, "seek": 122904, "start": 1242.36, "end": 1249.3999999999999, "text": " If it match three steps, it means that the user has some symbolic node detected and then", "tokens": [51030, 759, 309, 2995, 1045, 4439, 11, 309, 1355, 300, 264, 4195, 575, 512, 25755, 9984, 21896, 293, 550, 51382], "temperature": 0.0, "avg_logprob": -0.27572601719906453, "compression_ratio": 1.5777777777777777, "no_speech_prob": 0.010865612886846066}, {"id": 202, "seek": 122904, "start": 1249.3999999999999, "end": 1250.84, "text": " it will link them.", "tokens": [51382, 309, 486, 2113, 552, 13, 51454], "temperature": 0.0, "avg_logprob": -0.27572601719906453, "compression_ratio": 1.5777777777777777, "no_speech_prob": 0.010865612886846066}, {"id": 203, "seek": 122904, "start": 1250.84, "end": 1255.68, "text": " If it's not like that, it will delay the node.", "tokens": [51454, 759, 309, 311, 406, 411, 300, 11, 309, 486, 8577, 264, 9984, 13, 51696], "temperature": 0.0, "avg_logprob": -0.27572601719906453, "compression_ratio": 1.5777777777777777, "no_speech_prob": 0.010865612886846066}, {"id": 204, "seek": 125568, "start": 1255.68, "end": 1259.5600000000002, "text": " So it will change the network structure to this now.", "tokens": [50364, 407, 309, 486, 1319, 264, 3209, 3877, 281, 341, 586, 13, 50558], "temperature": 0.0, "avg_logprob": -0.20909408673848193, "compression_ratio": 1.5, "no_speech_prob": 0.016098085790872574}, {"id": 205, "seek": 125568, "start": 1259.5600000000002, "end": 1260.5600000000002, "text": " It will be...", "tokens": [50558, 467, 486, 312, 485, 50608], "temperature": 0.0, "avg_logprob": -0.20909408673848193, "compression_ratio": 1.5, "no_speech_prob": 0.016098085790872574}, {"id": 206, "seek": 125568, "start": 1260.5600000000002, "end": 1265.3600000000001, "text": " It's really different from that one from before.", "tokens": [50608, 467, 311, 534, 819, 490, 300, 472, 490, 949, 13, 50848], "temperature": 0.0, "avg_logprob": -0.20909408673848193, "compression_ratio": 1.5, "no_speech_prob": 0.016098085790872574}, {"id": 207, "seek": 125568, "start": 1265.3600000000001, "end": 1266.76, "text": " So I think...", "tokens": [50848, 407, 286, 519, 485, 50918], "temperature": 0.0, "avg_logprob": -0.20909408673848193, "compression_ratio": 1.5, "no_speech_prob": 0.016098085790872574}, {"id": 208, "seek": 125568, "start": 1266.76, "end": 1270.0800000000002, "text": " I don't know if we have some time.", "tokens": [50918, 286, 500, 380, 458, 498, 321, 362, 512, 565, 13, 51084], "temperature": 0.0, "avg_logprob": -0.20909408673848193, "compression_ratio": 1.5, "no_speech_prob": 0.016098085790872574}, {"id": 209, "seek": 125568, "start": 1270.0800000000002, "end": 1277.16, "text": " If you want to see how this works, and if you have also some comments too, because I", "tokens": [51084, 759, 291, 528, 281, 536, 577, 341, 1985, 11, 293, 498, 291, 362, 611, 512, 3053, 886, 11, 570, 286, 51438], "temperature": 0.0, "avg_logprob": -0.20909408673848193, "compression_ratio": 1.5, "no_speech_prob": 0.016098085790872574}, {"id": 210, "seek": 127716, "start": 1277.16, "end": 1284.5600000000002, "text": " would really love to see if you guys have anything that I can change, I can add.", "tokens": [50364, 576, 534, 959, 281, 536, 498, 291, 1074, 362, 1340, 300, 286, 393, 1319, 11, 286, 393, 909, 13, 50734], "temperature": 0.0, "avg_logprob": -0.17655388758732724, "compression_ratio": 1.5033112582781456, "no_speech_prob": 0.4322216510772705}, {"id": 211, "seek": 127716, "start": 1284.5600000000002, "end": 1287.3600000000001, "text": " I think it's really...", "tokens": [50734, 286, 519, 309, 311, 534, 485, 50874], "temperature": 0.0, "avg_logprob": -0.17655388758732724, "compression_ratio": 1.5033112582781456, "no_speech_prob": 0.4322216510772705}, {"id": 212, "seek": 127716, "start": 1287.3600000000001, "end": 1290.5600000000002, "text": " I don't feel like there's some questions you can do.", "tokens": [50874, 286, 500, 380, 841, 411, 456, 311, 512, 1651, 291, 393, 360, 13, 51034], "temperature": 0.0, "avg_logprob": -0.17655388758732724, "compression_ratio": 1.5033112582781456, "no_speech_prob": 0.4322216510772705}, {"id": 213, "seek": 127716, "start": 1290.5600000000002, "end": 1296.0800000000002, "text": " I think it would be better if you just told me what to think about it.", "tokens": [51034, 286, 519, 309, 576, 312, 1101, 498, 291, 445, 1907, 385, 437, 281, 519, 466, 309, 13, 51310], "temperature": 0.0, "avg_logprob": -0.17655388758732724, "compression_ratio": 1.5033112582781456, "no_speech_prob": 0.4322216510772705}, {"id": 214, "seek": 129608, "start": 1296.08, "end": 1312.48, "text": " So in this case, the network starts with 4,000, almost 5,000 nodes.", "tokens": [50364, 407, 294, 341, 1389, 11, 264, 3209, 3719, 365, 1017, 11, 1360, 11, 1920, 1025, 11, 1360, 13891, 13, 51184], "temperature": 0.0, "avg_logprob": -0.38282832392939814, "compression_ratio": 1.248062015503876, "no_speech_prob": 0.01528992597013712}, {"id": 215, "seek": 129608, "start": 1312.48, "end": 1318.3999999999999, "text": " And at the end, it's really small.", "tokens": [51184, 400, 412, 264, 917, 11, 309, 311, 534, 1359, 13, 51480], "temperature": 0.0, "avg_logprob": -0.38282832392939814, "compression_ratio": 1.248062015503876, "no_speech_prob": 0.01528992597013712}, {"id": 216, "seek": 129608, "start": 1318.3999999999999, "end": 1319.3999999999999, "text": " Let's see.", "tokens": [51480, 961, 311, 536, 13, 51530], "temperature": 0.0, "avg_logprob": -0.38282832392939814, "compression_ratio": 1.248062015503876, "no_speech_prob": 0.01528992597013712}, {"id": 217, "seek": 129608, "start": 1319.3999999999999, "end": 1325.9199999999998, "text": " I don't even remember which one is the biggest.", "tokens": [51530, 286, 500, 380, 754, 1604, 597, 472, 307, 264, 3880, 13, 51856], "temperature": 0.0, "avg_logprob": -0.38282832392939814, "compression_ratio": 1.248062015503876, "no_speech_prob": 0.01528992597013712}, {"id": 218, "seek": 132592, "start": 1326.8400000000001, "end": 1329.2, "text": " Sorry.", "tokens": [50410, 4919, 13, 50528], "temperature": 0.0, "avg_logprob": -0.3902297730141498, "compression_ratio": 1.2681159420289856, "no_speech_prob": 0.06945551186800003}, {"id": 219, "seek": 132592, "start": 1329.2, "end": 1334.44, "text": " We went from 5,000 to only 500.", "tokens": [50528, 492, 1437, 490, 1025, 11, 1360, 281, 787, 5923, 13, 50790], "temperature": 0.0, "avg_logprob": -0.3902297730141498, "compression_ratio": 1.2681159420289856, "no_speech_prob": 0.06945551186800003}, {"id": 220, "seek": 132592, "start": 1334.44, "end": 1346.4, "text": " So I put this example because...", "tokens": [50790, 407, 286, 829, 341, 1365, 570, 485, 51388], "temperature": 0.0, "avg_logprob": -0.3902297730141498, "compression_ratio": 1.2681159420289856, "no_speech_prob": 0.06945551186800003}, {"id": 221, "seek": 132592, "start": 1346.4, "end": 1355.04, "text": " There's a principle phenomenon called divergence that when we mine the whole hypertextual conversation,", "tokens": [51388, 821, 311, 257, 8665, 14029, 1219, 47387, 300, 562, 321, 3892, 264, 1379, 9848, 25111, 901, 3761, 11, 51820], "temperature": 0.0, "avg_logprob": -0.3902297730141498, "compression_ratio": 1.2681159420289856, "no_speech_prob": 0.06945551186800003}, {"id": 222, "seek": 135504, "start": 1356.04, "end": 1360.76, "text": " it will go for a lot of places that we are not interested.", "tokens": [50414, 309, 486, 352, 337, 257, 688, 295, 3190, 300, 321, 366, 406, 3102, 13, 50650], "temperature": 0.0, "avg_logprob": -0.23682410900409406, "compression_ratio": 1.8098591549295775, "no_speech_prob": 0.012494569644331932}, {"id": 223, "seek": 135504, "start": 1360.76, "end": 1367.32, "text": " Like if somebody used red as a hashtag, if somebody used love, if somebody else used", "tokens": [50650, 1743, 498, 2618, 1143, 2182, 382, 257, 20379, 11, 498, 2618, 1143, 959, 11, 498, 2618, 1646, 1143, 50978], "temperature": 0.0, "avg_logprob": -0.23682410900409406, "compression_ratio": 1.8098591549295775, "no_speech_prob": 0.012494569644331932}, {"id": 224, "seek": 135504, "start": 1367.32, "end": 1375.1599999999999, "text": " no, it will just move the conversation that we are trying to mine to different places", "tokens": [50978, 572, 11, 309, 486, 445, 1286, 264, 3761, 300, 321, 366, 1382, 281, 3892, 281, 819, 3190, 51370], "temperature": 0.0, "avg_logprob": -0.23682410900409406, "compression_ratio": 1.8098591549295775, "no_speech_prob": 0.012494569644331932}, {"id": 225, "seek": 135504, "start": 1375.1599999999999, "end": 1376.6399999999999, "text": " that we are not interested.", "tokens": [51370, 300, 321, 366, 406, 3102, 13, 51444], "temperature": 0.0, "avg_logprob": -0.23682410900409406, "compression_ratio": 1.8098591549295775, "no_speech_prob": 0.012494569644331932}, {"id": 226, "seek": 137664, "start": 1376.64, "end": 1385.5200000000002, "text": " So in this case, macro, it's a really known writer.", "tokens": [50364, 407, 294, 341, 1389, 11, 18887, 11, 309, 311, 257, 534, 2570, 9936, 13, 50808], "temperature": 0.0, "avg_logprob": -0.23916714532034739, "compression_ratio": 1.3404255319148937, "no_speech_prob": 0.002745068399235606}, {"id": 227, "seek": 137664, "start": 1385.5200000000002, "end": 1388.3200000000002, "text": " Let's see if we can find it.", "tokens": [50808, 961, 311, 536, 498, 321, 393, 915, 309, 13, 50948], "temperature": 0.0, "avg_logprob": -0.23916714532034739, "compression_ratio": 1.3404255319148937, "no_speech_prob": 0.002745068399235606}, {"id": 228, "seek": 137664, "start": 1388.3200000000002, "end": 1397.4, "text": " Well, this one is also a really known writer.", "tokens": [50948, 1042, 11, 341, 472, 307, 611, 257, 534, 2570, 9936, 13, 51402], "temperature": 0.0, "avg_logprob": -0.23916714532034739, "compression_ratio": 1.3404255319148937, "no_speech_prob": 0.002745068399235606}, {"id": 229, "seek": 139740, "start": 1397.4, "end": 1411.88, "text": " So in this specific example, we can see how the object detection model tagged this photo", "tokens": [50364, 407, 294, 341, 2685, 1365, 11, 321, 393, 536, 577, 264, 2657, 17784, 2316, 40239, 341, 5052, 51088], "temperature": 0.0, "avg_logprob": -0.20028250268165101, "compression_ratio": 1.4140625, "no_speech_prob": 0.0176092442125082}, {"id": 230, "seek": 139740, "start": 1411.88, "end": 1423.24, "text": " as a wild style, as a throw up, and the Google model will tag them like a wheel and a train.", "tokens": [51088, 382, 257, 4868, 3758, 11, 382, 257, 3507, 493, 11, 293, 264, 3329, 2316, 486, 6162, 552, 411, 257, 5589, 293, 257, 3847, 13, 51656], "temperature": 0.0, "avg_logprob": -0.20028250268165101, "compression_ratio": 1.4140625, "no_speech_prob": 0.0176092442125082}, {"id": 231, "seek": 142324, "start": 1423.24, "end": 1430.68, "text": " But also, we can see how this hashtag was tagged as a graffiti writer.", "tokens": [50364, 583, 611, 11, 321, 393, 536, 577, 341, 20379, 390, 40239, 382, 257, 40531, 9936, 13, 50736], "temperature": 0.0, "avg_logprob": -0.2641900828186895, "compression_ratio": 1.6305732484076434, "no_speech_prob": 0.053171053528785706}, {"id": 232, "seek": 142324, "start": 1430.68, "end": 1434.08, "text": " So that gives us an idea that...", "tokens": [50736, 407, 300, 2709, 505, 364, 1558, 300, 485, 50906], "temperature": 0.0, "avg_logprob": -0.2641900828186895, "compression_ratio": 1.6305732484076434, "no_speech_prob": 0.053171053528785706}, {"id": 233, "seek": 142324, "start": 1434.08, "end": 1440.48, "text": " Well, not an idea, an evidence that this guy is a graffiti writer name and we can see", "tokens": [50906, 1042, 11, 406, 364, 1558, 11, 364, 4467, 300, 341, 2146, 307, 257, 40531, 9936, 1315, 293, 321, 393, 536, 51226], "temperature": 0.0, "avg_logprob": -0.2641900828186895, "compression_ratio": 1.6305732484076434, "no_speech_prob": 0.053171053528785706}, {"id": 234, "seek": 142324, "start": 1440.48, "end": 1443.64, "text": " his intervention.", "tokens": [51226, 702, 13176, 13, 51384], "temperature": 0.0, "avg_logprob": -0.2641900828186895, "compression_ratio": 1.6305732484076434, "no_speech_prob": 0.053171053528785706}, {"id": 235, "seek": 142324, "start": 1443.64, "end": 1448.4, "text": " We can see who is the user that makes this post.", "tokens": [51384, 492, 393, 536, 567, 307, 264, 4195, 300, 1669, 341, 2183, 13, 51622], "temperature": 0.0, "avg_logprob": -0.2641900828186895, "compression_ratio": 1.6305732484076434, "no_speech_prob": 0.053171053528785706}, {"id": 236, "seek": 144840, "start": 1449.3600000000001, "end": 1460.0, "text": " When we can access to the user, the user neighbor network, we can also be sure that", "tokens": [50412, 1133, 321, 393, 2105, 281, 264, 4195, 11, 264, 4195, 5987, 3209, 11, 321, 393, 611, 312, 988, 300, 50944], "temperature": 0.0, "avg_logprob": -0.35921287536621094, "compression_ratio": 1.328, "no_speech_prob": 0.033217404037714005}, {"id": 237, "seek": 144840, "start": 1460.0, "end": 1466.52, "text": " he's using these specific graffiti styles.", "tokens": [50944, 415, 311, 1228, 613, 2685, 40531, 13273, 13, 51270], "temperature": 0.0, "avg_logprob": -0.35921287536621094, "compression_ratio": 1.328, "no_speech_prob": 0.033217404037714005}, {"id": 238, "seek": 144840, "start": 1466.52, "end": 1467.72, "text": " Okay.", "tokens": [51270, 1033, 13, 51330], "temperature": 0.0, "avg_logprob": -0.35921287536621094, "compression_ratio": 1.328, "no_speech_prob": 0.033217404037714005}, {"id": 239, "seek": 144840, "start": 1467.72, "end": 1472.0, "text": " So I'm going to finish with this.", "tokens": [51330, 407, 286, 478, 516, 281, 2413, 365, 341, 13, 51544], "temperature": 0.0, "avg_logprob": -0.35921287536621094, "compression_ratio": 1.328, "no_speech_prob": 0.033217404037714005}, {"id": 240, "seek": 147200, "start": 1472.0, "end": 1480.88, "text": " In this case, when we apply this filter, it's way better, it's way cleaner, and we can start", "tokens": [50364, 682, 341, 1389, 11, 562, 321, 3079, 341, 6608, 11, 309, 311, 636, 1101, 11, 309, 311, 636, 16532, 11, 293, 321, 393, 722, 50808], "temperature": 0.0, "avg_logprob": -0.39777463855165424, "compression_ratio": 1.4026845637583893, "no_speech_prob": 0.13747401535511017}, {"id": 241, "seek": 147200, "start": 1480.88, "end": 1485.12, "text": " to see...", "tokens": [50808, 281, 536, 485, 51020], "temperature": 0.0, "avg_logprob": -0.39777463855165424, "compression_ratio": 1.4026845637583893, "no_speech_prob": 0.13747401535511017}, {"id": 242, "seek": 147200, "start": 1485.12, "end": 1487.44, "text": " I think I'm just talking nonsense now.", "tokens": [51020, 286, 519, 286, 478, 445, 1417, 14925, 586, 13, 51136], "temperature": 0.0, "avg_logprob": -0.39777463855165424, "compression_ratio": 1.4026845637583893, "no_speech_prob": 0.13747401535511017}, {"id": 243, "seek": 147200, "start": 1487.44, "end": 1489.44, "text": " Do you want to add something?", "tokens": [51136, 1144, 291, 528, 281, 909, 746, 30, 51236], "temperature": 0.0, "avg_logprob": -0.39777463855165424, "compression_ratio": 1.4026845637583893, "no_speech_prob": 0.13747401535511017}, {"id": 244, "seek": 147200, "start": 1489.44, "end": 1491.44, "text": " That's my answer question.", "tokens": [51236, 663, 311, 452, 1867, 1168, 13, 51336], "temperature": 0.0, "avg_logprob": -0.39777463855165424, "compression_ratio": 1.4026845637583893, "no_speech_prob": 0.13747401535511017}, {"id": 245, "seek": 147200, "start": 1491.44, "end": 1493.44, "text": " Thank you.", "tokens": [51336, 1044, 291, 13, 51436], "temperature": 0.0, "avg_logprob": -0.39777463855165424, "compression_ratio": 1.4026845637583893, "no_speech_prob": 0.13747401535511017}, {"id": 246, "seek": 149344, "start": 1493.44, "end": 1505.44, "text": " How did you get inspired to run this as a master piece and continue doing research?", "tokens": [50364, 1012, 630, 291, 483, 7547, 281, 1190, 341, 382, 257, 4505, 2522, 293, 2354, 884, 2132, 30, 50964], "temperature": 0.0, "avg_logprob": -0.3311120256965543, "compression_ratio": 1.6467661691542288, "no_speech_prob": 0.0529651902616024}, {"id": 247, "seek": 149344, "start": 1505.44, "end": 1509.44, "text": " I mean, checking the throw ups and the graffiti on trains.", "tokens": [50964, 286, 914, 11, 8568, 264, 3507, 15497, 293, 264, 40531, 322, 16329, 13, 51164], "temperature": 0.0, "avg_logprob": -0.3311120256965543, "compression_ratio": 1.6467661691542288, "no_speech_prob": 0.0529651902616024}, {"id": 248, "seek": 149344, "start": 1509.44, "end": 1513.44, "text": " What was the practical aspect that motivated you to be fine?", "tokens": [51164, 708, 390, 264, 8496, 4171, 300, 14515, 291, 281, 312, 2489, 30, 51364], "temperature": 0.0, "avg_logprob": -0.3311120256965543, "compression_ratio": 1.6467661691542288, "no_speech_prob": 0.0529651902616024}, {"id": 249, "seek": 149344, "start": 1513.44, "end": 1514.44, "text": " Okay.", "tokens": [51364, 1033, 13, 51414], "temperature": 0.0, "avg_logprob": -0.3311120256965543, "compression_ratio": 1.6467661691542288, "no_speech_prob": 0.0529651902616024}, {"id": 250, "seek": 149344, "start": 1514.44, "end": 1519.44, "text": " So the question was, what was the practical aspect of attracting the graffiti and what", "tokens": [51414, 407, 264, 1168, 390, 11, 437, 390, 264, 8496, 4171, 295, 36594, 264, 40531, 293, 437, 51664], "temperature": 0.0, "avg_logprob": -0.3311120256965543, "compression_ratio": 1.6467661691542288, "no_speech_prob": 0.0529651902616024}, {"id": 251, "seek": 149344, "start": 1519.44, "end": 1521.8400000000001, "text": " motivates you personally to do it?", "tokens": [51664, 42569, 291, 5665, 281, 360, 309, 30, 51784], "temperature": 0.0, "avg_logprob": -0.3311120256965543, "compression_ratio": 1.6467661691542288, "no_speech_prob": 0.0529651902616024}, {"id": 252, "seek": 152184, "start": 1521.84, "end": 1539.84, "text": " I had a pre-grad also graffiti as a central topic and I thought it would be easier to do", "tokens": [50364, 286, 632, 257, 659, 12, 7165, 611, 40531, 382, 257, 5777, 4829, 293, 286, 1194, 309, 576, 312, 3571, 281, 360, 51264], "temperature": 0.0, "avg_logprob": -0.38630763462611606, "compression_ratio": 1.3, "no_speech_prob": 0.0135134132578969}, {"id": 253, "seek": 152184, "start": 1539.84, "end": 1549.84, "text": " something that will continue this personal initiative.", "tokens": [51264, 746, 300, 486, 2354, 341, 2973, 11552, 13, 51764], "temperature": 0.0, "avg_logprob": -0.38630763462611606, "compression_ratio": 1.3, "no_speech_prob": 0.0135134132578969}, {"id": 254, "seek": 154984, "start": 1549.84, "end": 1554.84, "text": " But at last, I've been late for two years now.", "tokens": [50364, 583, 412, 1036, 11, 286, 600, 668, 3469, 337, 732, 924, 586, 13, 50614], "temperature": 0.0, "avg_logprob": -0.1967253415089733, "compression_ratio": 1.3776223776223777, "no_speech_prob": 0.106636181473732}, {"id": 255, "seek": 154984, "start": 1554.84, "end": 1559.84, "text": " I shouldn't deliver this last year because...", "tokens": [50614, 286, 4659, 380, 4239, 341, 1036, 1064, 570, 485, 50864], "temperature": 0.0, "avg_logprob": -0.1967253415089733, "compression_ratio": 1.3776223776223777, "no_speech_prob": 0.106636181473732}, {"id": 256, "seek": 154984, "start": 1559.84, "end": 1566.84, "text": " But it was really interesting to how learn this new stuff and put it together to make", "tokens": [50864, 583, 309, 390, 534, 1880, 281, 577, 1466, 341, 777, 1507, 293, 829, 309, 1214, 281, 652, 51214], "temperature": 0.0, "avg_logprob": -0.1967253415089733, "compression_ratio": 1.3776223776223777, "no_speech_prob": 0.106636181473732}, {"id": 257, "seek": 154984, "start": 1566.84, "end": 1568.84, "text": " some scholar work.", "tokens": [51214, 512, 17912, 589, 13, 51314], "temperature": 0.0, "avg_logprob": -0.1967253415089733, "compression_ratio": 1.3776223776223777, "no_speech_prob": 0.106636181473732}, {"id": 258, "seek": 156884, "start": 1568.84, "end": 1570.84, "text": " What made the difference?", "tokens": [50364, 708, 1027, 264, 2649, 30, 50464], "temperature": 0.0, "avg_logprob": -0.3221527548397289, "compression_ratio": 1.6517412935323383, "no_speech_prob": 0.29094117879867554}, {"id": 259, "seek": 156884, "start": 1570.84, "end": 1572.84, "text": " What do you see?", "tokens": [50464, 708, 360, 291, 536, 30, 50564], "temperature": 0.0, "avg_logprob": -0.3221527548397289, "compression_ratio": 1.6517412935323383, "no_speech_prob": 0.29094117879867554}, {"id": 260, "seek": 156884, "start": 1572.84, "end": 1574.84, "text": " Right train, for instance.", "tokens": [50564, 1779, 3847, 11, 337, 5197, 13, 50664], "temperature": 0.0, "avg_logprob": -0.3221527548397289, "compression_ratio": 1.6517412935323383, "no_speech_prob": 0.29094117879867554}, {"id": 261, "seek": 156884, "start": 1574.84, "end": 1581.84, "text": " How do you know that right train is the background and not the name of the artist?", "tokens": [50664, 1012, 360, 291, 458, 300, 558, 3847, 307, 264, 3678, 293, 406, 264, 1315, 295, 264, 5748, 30, 51014], "temperature": 0.0, "avg_logprob": -0.3221527548397289, "compression_ratio": 1.6517412935323383, "no_speech_prob": 0.29094117879867554}, {"id": 262, "seek": 156884, "start": 1581.84, "end": 1582.84, "text": " Okay.", "tokens": [51014, 1033, 13, 51064], "temperature": 0.0, "avg_logprob": -0.3221527548397289, "compression_ratio": 1.6517412935323383, "no_speech_prob": 0.29094117879867554}, {"id": 263, "seek": 156884, "start": 1582.84, "end": 1583.84, "text": " That's a really...", "tokens": [51064, 663, 311, 257, 534, 485, 51114], "temperature": 0.0, "avg_logprob": -0.3221527548397289, "compression_ratio": 1.6517412935323383, "no_speech_prob": 0.29094117879867554}, {"id": 264, "seek": 156884, "start": 1583.84, "end": 1584.84, "text": " That's a good question.", "tokens": [51114, 663, 311, 257, 665, 1168, 13, 51164], "temperature": 0.0, "avg_logprob": -0.3221527548397289, "compression_ratio": 1.6517412935323383, "no_speech_prob": 0.29094117879867554}, {"id": 265, "seek": 156884, "start": 1584.84, "end": 1585.84, "text": " I...", "tokens": [51164, 286, 485, 51214], "temperature": 0.0, "avg_logprob": -0.3221527548397289, "compression_ratio": 1.6517412935323383, "no_speech_prob": 0.29094117879867554}, {"id": 266, "seek": 156884, "start": 1585.84, "end": 1587.84, "text": " You can repeat the question.", "tokens": [51214, 509, 393, 7149, 264, 1168, 13, 51314], "temperature": 0.0, "avg_logprob": -0.3221527548397289, "compression_ratio": 1.6517412935323383, "no_speech_prob": 0.29094117879867554}, {"id": 267, "seek": 156884, "start": 1587.84, "end": 1588.84, "text": " Okay.", "tokens": [51314, 1033, 13, 51364], "temperature": 0.0, "avg_logprob": -0.3221527548397289, "compression_ratio": 1.6517412935323383, "no_speech_prob": 0.29094117879867554}, {"id": 268, "seek": 156884, "start": 1588.84, "end": 1593.84, "text": " How we managed to difference the freight as a graffiti...", "tokens": [51364, 1012, 321, 6453, 281, 2649, 264, 37181, 382, 257, 40531, 485, 51614], "temperature": 0.0, "avg_logprob": -0.3221527548397289, "compression_ratio": 1.6517412935323383, "no_speech_prob": 0.29094117879867554}, {"id": 269, "seek": 156884, "start": 1593.84, "end": 1596.84, "text": " Is not a graffiti writer's name.", "tokens": [51614, 1119, 406, 257, 40531, 9936, 311, 1315, 13, 51764], "temperature": 0.0, "avg_logprob": -0.3221527548397289, "compression_ratio": 1.6517412935323383, "no_speech_prob": 0.29094117879867554}, {"id": 270, "seek": 159684, "start": 1596.84, "end": 1599.84, "text": " So there's a big dictionary.", "tokens": [50364, 407, 456, 311, 257, 955, 25890, 13, 50514], "temperature": 0.0, "avg_logprob": -0.292651112874349, "compression_ratio": 1.429530201342282, "no_speech_prob": 0.03490341454744339}, {"id": 271, "seek": 159684, "start": 1599.84, "end": 1606.84, "text": " It's built with all the known words.", "tokens": [50514, 467, 311, 3094, 365, 439, 264, 2570, 2283, 13, 50864], "temperature": 0.0, "avg_logprob": -0.292651112874349, "compression_ratio": 1.429530201342282, "no_speech_prob": 0.03490341454744339}, {"id": 272, "seek": 159684, "start": 1606.84, "end": 1620.84, "text": " So it will distinguish between known words and words that are out of that vocabulary.", "tokens": [50864, 407, 309, 486, 20206, 1296, 2570, 2283, 293, 2283, 300, 366, 484, 295, 300, 19864, 13, 51564], "temperature": 0.0, "avg_logprob": -0.292651112874349, "compression_ratio": 1.429530201342282, "no_speech_prob": 0.03490341454744339}, {"id": 273, "seek": 159684, "start": 1620.84, "end": 1622.84, "text": " Yes, Alison?", "tokens": [51564, 1079, 11, 41001, 30, 51664], "temperature": 0.0, "avg_logprob": -0.292651112874349, "compression_ratio": 1.429530201342282, "no_speech_prob": 0.03490341454744339}, {"id": 274, "seek": 159684, "start": 1622.84, "end": 1625.84, "text": " I have one question then if no one else has one.", "tokens": [51664, 286, 362, 472, 1168, 550, 498, 572, 472, 1646, 575, 472, 13, 51814], "temperature": 0.0, "avg_logprob": -0.292651112874349, "compression_ratio": 1.429530201342282, "no_speech_prob": 0.03490341454744339}, {"id": 275, "seek": 162584, "start": 1625.84, "end": 1627.84, "text": " How do you...", "tokens": [50364, 1012, 360, 291, 485, 50464], "temperature": 0.0, "avg_logprob": -0.16475109555828038, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.04868893697857857}, {"id": 276, "seek": 162584, "start": 1627.84, "end": 1631.84, "text": " Have you had any insights in your graph that really excited you?", "tokens": [50464, 3560, 291, 632, 604, 14310, 294, 428, 4295, 300, 534, 2919, 291, 30, 50664], "temperature": 0.0, "avg_logprob": -0.16475109555828038, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.04868893697857857}, {"id": 277, "seek": 162584, "start": 1631.84, "end": 1632.84, "text": " Yes.", "tokens": [50664, 1079, 13, 50714], "temperature": 0.0, "avg_logprob": -0.16475109555828038, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.04868893697857857}, {"id": 278, "seek": 162584, "start": 1632.84, "end": 1640.84, "text": " So the question is if the insight of the network really excited me.", "tokens": [50714, 407, 264, 1168, 307, 498, 264, 11269, 295, 264, 3209, 534, 2919, 385, 13, 51114], "temperature": 0.0, "avg_logprob": -0.16475109555828038, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.04868893697857857}, {"id": 279, "seek": 162584, "start": 1640.84, "end": 1647.84, "text": " Yeah, I think it does because it was like a kind of a serendipity, you know?", "tokens": [51114, 865, 11, 286, 519, 309, 775, 570, 309, 390, 411, 257, 733, 295, 257, 816, 521, 647, 507, 11, 291, 458, 30, 51464], "temperature": 0.0, "avg_logprob": -0.16475109555828038, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.04868893697857857}, {"id": 280, "seek": 164784, "start": 1647.84, "end": 1662.84, "text": " When I start to see like this small notes linked together from the terms, it will pop like how some terms are linked for some graffiti styles too.", "tokens": [50364, 1133, 286, 722, 281, 536, 411, 341, 1359, 5570, 9408, 1214, 490, 264, 2115, 11, 309, 486, 1665, 411, 577, 512, 2115, 366, 9408, 337, 512, 40531, 13273, 886, 13, 51114], "temperature": 0.0, "avg_logprob": -0.19719056288401285, "compression_ratio": 1.4619565217391304, "no_speech_prob": 0.35227054357528687}, {"id": 281, "seek": 164784, "start": 1662.84, "end": 1671.84, "text": " So everything's connected and I think the way to get to this is tailoring data to our own needs.", "tokens": [51114, 407, 1203, 311, 4582, 293, 286, 519, 264, 636, 281, 483, 281, 341, 307, 6838, 3662, 1412, 281, 527, 1065, 2203, 13, 51564], "temperature": 0.0, "avg_logprob": -0.19719056288401285, "compression_ratio": 1.4619565217391304, "no_speech_prob": 0.35227054357528687}, {"id": 282, "seek": 164784, "start": 1671.84, "end": 1672.84, "text": " Right.", "tokens": [51564, 1779, 13, 51614], "temperature": 0.0, "avg_logprob": -0.19719056288401285, "compression_ratio": 1.4619565217391304, "no_speech_prob": 0.35227054357528687}, {"id": 283, "seek": 164784, "start": 1672.84, "end": 1673.84, "text": " Yeah.", "tokens": [51614, 865, 13, 51664], "temperature": 0.0, "avg_logprob": -0.19719056288401285, "compression_ratio": 1.4619565217391304, "no_speech_prob": 0.35227054357528687}, {"id": 284, "seek": 164784, "start": 1673.84, "end": 1674.84, "text": " Okay, folks.", "tokens": [51664, 1033, 11, 4024, 13, 51714], "temperature": 0.0, "avg_logprob": -0.19719056288401285, "compression_ratio": 1.4619565217391304, "no_speech_prob": 0.35227054357528687}, {"id": 285, "seek": 167484, "start": 1674.84, "end": 1676.84, "text": " Can we have a big round of applause?", "tokens": [50364, 1664, 321, 362, 257, 955, 3098, 295, 9969, 30, 50464], "temperature": 0.0, "avg_logprob": -0.3228148818016052, "compression_ratio": 1.4035087719298245, "no_speech_prob": 0.6831016540527344}, {"id": 286, "seek": 167484, "start": 1676.84, "end": 1677.84, "text": " Thank you.", "tokens": [50464, 1044, 291, 13, 50514], "temperature": 0.0, "avg_logprob": -0.3228148818016052, "compression_ratio": 1.4035087719298245, "no_speech_prob": 0.6831016540527344}, {"id": 287, "seek": 167484, "start": 1677.84, "end": 1678.84, "text": " Thank you.", "tokens": [50514, 1044, 291, 13, 50564], "temperature": 0.0, "avg_logprob": -0.3228148818016052, "compression_ratio": 1.4035087719298245, "no_speech_prob": 0.6831016540527344}, {"id": 288, "seek": 167484, "start": 1678.84, "end": 1679.84, "text": " Thank you.", "tokens": [50564, 1044, 291, 13, 50614], "temperature": 0.0, "avg_logprob": -0.3228148818016052, "compression_ratio": 1.4035087719298245, "no_speech_prob": 0.6831016540527344}, {"id": 289, "seek": 167484, "start": 1679.84, "end": 1680.84, "text": " Thank you.", "tokens": [50614, 1044, 291, 13, 50664], "temperature": 0.0, "avg_logprob": -0.3228148818016052, "compression_ratio": 1.4035087719298245, "no_speech_prob": 0.6831016540527344}], "language": "en"}