{"text": " Okay, so now we can start. Thank you very much for coming to the Python Dev Room and getting up early on Sunday morning with this cool weather outside. So now we are going to have a very, very nice talk by Pierre Denis, who is a long-time Python user. He's also the creator of Liya, and he's going to talk about Liya in this talk. Liya is a Python module for helping to calculate probabilities on situations presenting uncertainties. And what that means, I hope he's going to explain to us now. Thank you. So welcome everybody. So we are here about something serious, a sad story. I'm not a good storyteller. I'm afraid, but okay, Dr. Black has been killed last night. Maybe you have heard about that. And okay, we have three suspects that have been identified with given probability to be the killer. And it seems that colonel Mustard is the most likely, is most likely the killer with 40% to be the killer. Then we have Mrs. Peacock, 25%. Mrs. White, 10%, and Professor Plum, 25%. Okay, then these are prior probabilities, but we have the help of a profiler, a segment, the profiler. This guy is very smart. And he can tell, for example, that if Mrs. White is the killer, she'll be absent for the investigation with 95%. Otherwise, if she's innocent, she'll be absent with only a probability of 20%. And the profiler tells you several statements like this with probabilities. So when you see this kind of situation, you see, okay, it's quite complex. How can I use this information? Because nothing is certain. Okay. So the investigator is Leah. Here, Leah is not a person, as you have understood. It's a module dedicated to probabilities. So okay, I have several statements here. In other presentation, I elaborate on this, but this time I prefer to show you Leah in action so you can better understand what it is about. My claim is that Leah is something quite easy to use, quite intuitive. You know probably that there are several packages dedicated to probability or statistics. The core feature of Leah is to be easy to understand and probably well suited for education. Okay. Let's start. First, I import Leah, which is here in version 401B. Anyway, so first of all, I want to define a fair coin with head and tail. I do that. So Leah can work with any Python object here. I define probabilities on strings, but you can define probabilities on numbers on any Python object. Okay. Here for education, I prefer to switch to fractions. You know that Python has fraction included. So I've switched the display to have fractions. So if I want to create a biased coin, I can define several values and here it means that tails will be three times likely to go that then head. So I have a new probability distribution. So what I'm doing here is a crash course on Leah because we want to be acquainted to it before doing the investigation. I can also use a probability mass function to define probability in a fraction. So Matplutlib is integrated so you can display your histogram about any probability distribution. Okay. So I want to make 100 throws. So I use my B coin variable, my probability distribution to calculate to make 100 random coins, throws. So you see in this random throws that there is more tail than head. But okay, how can I be sure that it follows the probability that I given? Simply you can use Leah, the same function as before, Leah, VALS. You provide the values and this time it will use the random sample as it will be a frequency counter and you see that here more or less it conforms to the probability distribution that I provided for the biased coin. So what is interesting on this kind of object is that you can use many of what you do usually on your Python object. For example, you can index. If I ask for zero, it will take the first letter, head or tail, H or T. I can chain with the Python lower method and I have lower case H or T. I can map Python function here. This means that it count the number of characters which is four, head and tail, four characters each. So we have a certain four. And as you could expect also, all the operators are overloaded. So if I concatenate my distribution B coin with fixed string, I have a new distribution that follows what has been defined. Okay and here it's something a bit funny. What happens if you multiply a dice with a coin? You get that. Okay. Let's now throw two coins. So the new method allows you to define new event with the same probability. Here I define two coins which are biased together. If I add them together, I have all the combination possible with associated probabilities. So we will see that this is very important. We are able to calculate conditional probability with the given method. So here I try to see, okay, assuming that I know that the first coin is tail, what is the combination of the two coins? So here we see that the previous result has been filtered out to get just the two remaining possibilities. So it's a common feature of LIA is that when you define variable, there is a kind of lazy evaluation. They remain linked together in a network that define the relationship, the dependencies between the random variables. Okay. And you can also define Boolean events like, okay, what is the probability to be? I define it at 140 seconds. And then I can use operator like to be or not to be. And the result is it's true, it's certain true. Because okay, to be it's either true or false and not to be it's the contrary. So together it's certainly true. Okay. And there is also a dedicated function in LIA which is P. So you can extract the probability of true. So you get really a real probability like this. Okay. Let's go on. So here it's an excerpt of a book that it's three centuries old from Abraham de Moivre. It's probably one of the first problem solved by de Moivre here. Okay. Let's ask to find the probability of throwing a nace in three throws given a fair dive. This is how to calculate in LIA. So here I define a dive. I create three instances which are independent, which are assigned to the 1, 2, 3. And then I ask for the probability of any of one of these dives is a nace. The result is 91, 216th as calculated three centuries ago by de Moivre. So far so good. Okay. No, I don't know if you like playing a role-playing game. So there's a small example that where you can use LIA. So imagine that you have here this dwarf which fights against a troll. Okay. I first define a new kind of display with percentage because it's more convenient here. I define two different kind of dice. Okay. Imagine that your attack hole is d25 plus 4. Okay. What is the probability to ever hit? You see, okay, it's easy to calculate with inequality. So you have to be greater or equal that the troll armor class. You get this probability. So the damage of the magic axe is to d6 plus 5. Here is the result. But this damage is only applied if the dwarf can hit the troll. So for that we have a special construction, LIA if underscore underscore to avoid collision with the Python if. And okay, this means if there is a hit, then I apply the magic axe. Otherwise, the damage is zero. And here is the new histogram. So this is the probability, the actual damage that is done to the troll. And then from this data you can answer the, okay, assuming that the troll has 20 health points remaining was the probability to kill him in four rounds or less. You see it's deadly simple with this formula to calculate. We find it's 40%, something like that. Okay. Okay. You follow? So I will, I have many, many, many examples. But by lack of time I will drop maybe some of these examples. Boys or girls paradox, something very funny also that you can find on Wikipedia. So the chance to be a boy or girl are even. So okay, boy, one half, girl, one half. Mr Smith asked two children, at least one of them is a boy. What is the probability that both children are boys? Many people and including myself, the first time I heard this I think, okay, the information give me no clues. It's one half. But if you calculate like this with Leah, so you define children as two, a joint of two children and that you count the number of boys, calculate the conditional probability, the answer is one third actually. And what is interesting with Leah, you can understand why this is the answer by asking Leah to show you all the combinations. So here I show you the gender of all the children, the number of boys and given that the number of boys is greater or equal to one. And we see here the answer is here and we understand better why it is one third. Okay. It's a bit fast but you can do it at your own pace later. Okay. What happens if you have more elaborate problem? Like here we have several children. The eldest is a boy and he's got three brothers at least. What is the probability that all children are boys? Okay. You can model this like this. Here I create seven children. And I put, so you see when you read this expression, it's quite close to the initial problem. Of course you have to understand the elements of Leah to do that but after that it's quite easy to model. The answer is one forty second. Again it's possible to ask why it is so and here by joining you see that's okay, seven children is this part and the other are this. So you can better understand why it is so. Okay. I will drop this Monte Hall problem which is well known. You can read that after the session offline. Okay. Let's go back to the initial problem. So okay. First I change the display options. So the, first we define the pure probabilities like that. So here I ask Leah to display the probability in one line because it's more convenient in this case and as a percentage. Okay. So we have like this and we see, okay, colon and mustard. Our priority is the killer, the most likely the killer. Okay. Let's now try to write down the different information we have. So if Mrs. White is the killer she'll be absent with probability ninety percent. So I define here a variable. Mrs. White is absent using the if as we've seen before. I put the condition if the killer is Mrs. White then she'll be absent with ninety five percent else twenty five, twenty percent. Sorry. Okay. This is the percentage that Mrs. White is absent. But it's not very interesting because we, we, we are more interested about who is the killer but we will see what will happen later. And then we can continue and define other rules like this. If Mrs. Peacock is innocent she knows who's the killer with probability seventy five percent. So you see here there is a missing information which is the else part but we assume that Mrs. Peacock is not insane and if she's the killer then she knows who's the killer hopefully. So I put here the else part as one hundred percent. Okay. And then we can elaborate on more complex information like this one. Okay. I will not detail but you see again it's quite, when you see the statement, the tradition in LIA it's quite straightforward. And the last one is here. So what have we done here is to define what we call the Bayesian network which put the relation between different random variables. What is interesting with this kind of network is that if you get evidence about something you can go backwards and refine the probability to be the killer. So for that, okay, I define a list of evidence here. So first of all it's empty and the conditional probability is the same as before because I have no new evidence. So imagine now that Mrs. White is absent. I can add it to the evidence and define a new conditional probability. So you see it change a bit. Evidence two added to the previous one. Mrs. Peacock is drunk. Okay. I add this information and I get new probability and so on. Professor Plum accuses Colin and Mustard. And finally we know that the killer is a woman. So for that I use here the Python start with Mrs. because it's a handy way to say given the suspects that the killer is a woman, I add it to the evidence like that and you see, okay, there is a new probability. So there are just two suspects remaining, two women and Mrs. White is likely the killer. Okay. Yeah. Maybe you can consider this as a game but sometimes probability can play a very important role in some trials. So long time ago there was the Dreyfus Affair. There was a big flow of a so-called expert that makes a mistake in this affair. And also more recently, Selik Larch case where also there is a bad reasoning about probability. Okay. So I want to mention also that Leah is able to do symbolic calculation. So by using the SIMPY module that maybe you know, so it's very easy. It's the same interface. So instead of number you put variable name between quotes like this and you have probability defined with formula. So you can redo all the same exercise and you will get formulas to be the killer, etc. So a small example here. Okay. I don't detail here. It's a binomial function here with P and here I calculate a conditional probability and it displays me a nice formula. So you can check offline if you want that it is correct. Okay. I want just to finish about my bullshit generator which was made 15 years ago. So here the goal is to produce sentences at random based on a list of words and a list of grammar rules like this. Then you see that I put here a probability on each grammar rule so that the most simple rule are used preferably to avoid to get to long sentences. So yeah. Okay. I get... So it has produced... I don't know why it's... Okay. So maybe I don't know what happens but... Okay. I restart my kernel. Normally it's supposed to speak and to write down sentences but... Okay. Anyway. You can play that also. The Python code is really small so you can try it at yourself. Oh yeah. Okay. Of course I didn't import LIA. Okay. That's it. But anyway, sorry for the small interruptions but I think we don't have time for questions or... Maybe one question. Maybe one question. Okay. Thank you for the presentation. I have indeed one question which is about performance. So do you have information about performance, your libraries compared to other libraries or yeah, what are your insights on that? Yeah. It's a good question. So okay. It's not really the concern. So here as you have seen the results are exact. So okay. As you have seen also it's quite fast. So there are several optimizations. I have no figures but okay. As you expect there are many problems which are very complex and for that LIA provides Monte Carlo several Monte Carlo algorithm that gives approximate results in a fair time. Yeah. But I have no figures. Yeah. Okay. Thank you. Thank you very much. Thank you very much.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 12.92, "text": " Okay, so now we can start.", "tokens": [50364, 1033, 11, 370, 586, 321, 393, 722, 13, 51010], "temperature": 0.0, "avg_logprob": -0.2914568094106821, "compression_ratio": 1.4251497005988023, "no_speech_prob": 0.25134408473968506}, {"id": 1, "seek": 0, "start": 12.92, "end": 18.0, "text": " Thank you very much for coming to the Python Dev Room and getting up early on Sunday morning", "tokens": [51010, 1044, 291, 588, 709, 337, 1348, 281, 264, 15329, 9096, 19190, 293, 1242, 493, 2440, 322, 7776, 2446, 51264], "temperature": 0.0, "avg_logprob": -0.2914568094106821, "compression_ratio": 1.4251497005988023, "no_speech_prob": 0.25134408473968506}, {"id": 2, "seek": 0, "start": 18.0, "end": 20.64, "text": " with this cool weather outside.", "tokens": [51264, 365, 341, 1627, 5503, 2380, 13, 51396], "temperature": 0.0, "avg_logprob": -0.2914568094106821, "compression_ratio": 1.4251497005988023, "no_speech_prob": 0.25134408473968506}, {"id": 3, "seek": 0, "start": 20.64, "end": 26.28, "text": " So now we are going to have a very, very nice talk by Pierre Denis, who is a long-time", "tokens": [51396, 407, 586, 321, 366, 516, 281, 362, 257, 588, 11, 588, 1481, 751, 538, 28461, 45351, 11, 567, 307, 257, 938, 12, 3766, 51678], "temperature": 0.0, "avg_logprob": -0.2914568094106821, "compression_ratio": 1.4251497005988023, "no_speech_prob": 0.25134408473968506}, {"id": 4, "seek": 2628, "start": 26.28, "end": 27.28, "text": " Python user.", "tokens": [50364, 15329, 4195, 13, 50414], "temperature": 0.0, "avg_logprob": -0.22926125017184656, "compression_ratio": 1.5836909871244635, "no_speech_prob": 0.08176368474960327}, {"id": 5, "seek": 2628, "start": 27.28, "end": 31.28, "text": " He's also the creator of Liya, and he's going to talk about Liya in this talk.", "tokens": [50414, 634, 311, 611, 264, 14181, 295, 8349, 3016, 11, 293, 415, 311, 516, 281, 751, 466, 8349, 3016, 294, 341, 751, 13, 50614], "temperature": 0.0, "avg_logprob": -0.22926125017184656, "compression_ratio": 1.5836909871244635, "no_speech_prob": 0.08176368474960327}, {"id": 6, "seek": 2628, "start": 31.28, "end": 37.56, "text": " Liya is a Python module for helping to calculate probabilities on situations presenting uncertainties.", "tokens": [50614, 8349, 3016, 307, 257, 15329, 10088, 337, 4315, 281, 8873, 33783, 322, 6851, 15578, 11308, 6097, 13, 50928], "temperature": 0.0, "avg_logprob": -0.22926125017184656, "compression_ratio": 1.5836909871244635, "no_speech_prob": 0.08176368474960327}, {"id": 7, "seek": 2628, "start": 37.56, "end": 40.36, "text": " And what that means, I hope he's going to explain to us now.", "tokens": [50928, 400, 437, 300, 1355, 11, 286, 1454, 415, 311, 516, 281, 2903, 281, 505, 586, 13, 51068], "temperature": 0.0, "avg_logprob": -0.22926125017184656, "compression_ratio": 1.5836909871244635, "no_speech_prob": 0.08176368474960327}, {"id": 8, "seek": 2628, "start": 40.36, "end": 42.64, "text": " Thank you.", "tokens": [51068, 1044, 291, 13, 51182], "temperature": 0.0, "avg_logprob": -0.22926125017184656, "compression_ratio": 1.5836909871244635, "no_speech_prob": 0.08176368474960327}, {"id": 9, "seek": 2628, "start": 42.64, "end": 44.480000000000004, "text": " So welcome everybody.", "tokens": [51182, 407, 2928, 2201, 13, 51274], "temperature": 0.0, "avg_logprob": -0.22926125017184656, "compression_ratio": 1.5836909871244635, "no_speech_prob": 0.08176368474960327}, {"id": 10, "seek": 2628, "start": 44.480000000000004, "end": 51.24, "text": " So we are here about something serious, a sad story.", "tokens": [51274, 407, 321, 366, 510, 466, 746, 3156, 11, 257, 4227, 1657, 13, 51612], "temperature": 0.0, "avg_logprob": -0.22926125017184656, "compression_ratio": 1.5836909871244635, "no_speech_prob": 0.08176368474960327}, {"id": 11, "seek": 2628, "start": 51.24, "end": 53.28, "text": " I'm not a good storyteller.", "tokens": [51612, 286, 478, 406, 257, 665, 17541, 14983, 13, 51714], "temperature": 0.0, "avg_logprob": -0.22926125017184656, "compression_ratio": 1.5836909871244635, "no_speech_prob": 0.08176368474960327}, {"id": 12, "seek": 5328, "start": 53.28, "end": 58.88, "text": " I'm afraid, but okay, Dr. Black has been killed last night.", "tokens": [50364, 286, 478, 4638, 11, 457, 1392, 11, 2491, 13, 4076, 575, 668, 4652, 1036, 1818, 13, 50644], "temperature": 0.0, "avg_logprob": -0.2641290283203125, "compression_ratio": 1.5524861878453038, "no_speech_prob": 0.035592712461948395}, {"id": 13, "seek": 5328, "start": 58.88, "end": 62.160000000000004, "text": " Maybe you have heard about that.", "tokens": [50644, 2704, 291, 362, 2198, 466, 300, 13, 50808], "temperature": 0.0, "avg_logprob": -0.2641290283203125, "compression_ratio": 1.5524861878453038, "no_speech_prob": 0.035592712461948395}, {"id": 14, "seek": 5328, "start": 62.160000000000004, "end": 73.4, "text": " And okay, we have three suspects that have been identified with given probability to", "tokens": [50808, 400, 1392, 11, 321, 362, 1045, 35667, 300, 362, 668, 9234, 365, 2212, 8482, 281, 51370], "temperature": 0.0, "avg_logprob": -0.2641290283203125, "compression_ratio": 1.5524861878453038, "no_speech_prob": 0.035592712461948395}, {"id": 15, "seek": 5328, "start": 73.4, "end": 74.48, "text": " be the killer.", "tokens": [51370, 312, 264, 13364, 13, 51424], "temperature": 0.0, "avg_logprob": -0.2641290283203125, "compression_ratio": 1.5524861878453038, "no_speech_prob": 0.035592712461948395}, {"id": 16, "seek": 5328, "start": 74.48, "end": 81.64, "text": " And it seems that colonel Mustard is the most likely, is most likely the killer with 40%", "tokens": [51424, 400, 309, 2544, 300, 8255, 338, 13252, 515, 307, 264, 881, 3700, 11, 307, 881, 3700, 264, 13364, 365, 3356, 4, 51782], "temperature": 0.0, "avg_logprob": -0.2641290283203125, "compression_ratio": 1.5524861878453038, "no_speech_prob": 0.035592712461948395}, {"id": 17, "seek": 8164, "start": 81.64, "end": 83.84, "text": " to be the killer.", "tokens": [50364, 281, 312, 264, 13364, 13, 50474], "temperature": 0.0, "avg_logprob": -0.2933172793001742, "compression_ratio": 1.379746835443038, "no_speech_prob": 0.09124474227428436}, {"id": 18, "seek": 8164, "start": 83.84, "end": 87.08, "text": " Then we have Mrs. Peacock, 25%.", "tokens": [50474, 1396, 321, 362, 9814, 13, 2396, 326, 1560, 11, 3552, 6856, 50636], "temperature": 0.0, "avg_logprob": -0.2933172793001742, "compression_ratio": 1.379746835443038, "no_speech_prob": 0.09124474227428436}, {"id": 19, "seek": 8164, "start": 87.08, "end": 91.84, "text": " Mrs. White, 10%, and Professor Plum, 25%.", "tokens": [50636, 9814, 13, 5552, 11, 1266, 8923, 293, 8419, 2149, 449, 11, 3552, 6856, 50874], "temperature": 0.0, "avg_logprob": -0.2933172793001742, "compression_ratio": 1.379746835443038, "no_speech_prob": 0.09124474227428436}, {"id": 20, "seek": 8164, "start": 91.84, "end": 101.72, "text": " Okay, then these are prior probabilities, but we have the help of a profiler, a segment,", "tokens": [50874, 1033, 11, 550, 613, 366, 4059, 33783, 11, 457, 321, 362, 264, 854, 295, 257, 1740, 5441, 11, 257, 9469, 11, 51368], "temperature": 0.0, "avg_logprob": -0.2933172793001742, "compression_ratio": 1.379746835443038, "no_speech_prob": 0.09124474227428436}, {"id": 21, "seek": 8164, "start": 101.72, "end": 104.2, "text": " the profiler.", "tokens": [51368, 264, 1740, 5441, 13, 51492], "temperature": 0.0, "avg_logprob": -0.2933172793001742, "compression_ratio": 1.379746835443038, "no_speech_prob": 0.09124474227428436}, {"id": 22, "seek": 8164, "start": 104.2, "end": 106.24000000000001, "text": " This guy is very smart.", "tokens": [51492, 639, 2146, 307, 588, 4069, 13, 51594], "temperature": 0.0, "avg_logprob": -0.2933172793001742, "compression_ratio": 1.379746835443038, "no_speech_prob": 0.09124474227428436}, {"id": 23, "seek": 10624, "start": 106.24, "end": 113.96, "text": " And he can tell, for example, that if Mrs. White is the killer, she'll be absent for", "tokens": [50364, 400, 415, 393, 980, 11, 337, 1365, 11, 300, 498, 9814, 13, 5552, 307, 264, 13364, 11, 750, 603, 312, 25185, 337, 50750], "temperature": 0.0, "avg_logprob": -0.20166575207429774, "compression_ratio": 1.4916201117318435, "no_speech_prob": 0.04368163272738457}, {"id": 24, "seek": 10624, "start": 113.96, "end": 118.08, "text": " the investigation with 95%.", "tokens": [50750, 264, 9627, 365, 13420, 6856, 50956], "temperature": 0.0, "avg_logprob": -0.20166575207429774, "compression_ratio": 1.4916201117318435, "no_speech_prob": 0.04368163272738457}, {"id": 25, "seek": 10624, "start": 118.08, "end": 126.19999999999999, "text": " Otherwise, if she's innocent, she'll be absent with only a probability of 20%.", "tokens": [50956, 10328, 11, 498, 750, 311, 13171, 11, 750, 603, 312, 25185, 365, 787, 257, 8482, 295, 945, 6856, 51362], "temperature": 0.0, "avg_logprob": -0.20166575207429774, "compression_ratio": 1.4916201117318435, "no_speech_prob": 0.04368163272738457}, {"id": 26, "seek": 10624, "start": 126.19999999999999, "end": 132.88, "text": " And the profiler tells you several statements like this with probabilities.", "tokens": [51362, 400, 264, 1740, 5441, 5112, 291, 2940, 12363, 411, 341, 365, 33783, 13, 51696], "temperature": 0.0, "avg_logprob": -0.20166575207429774, "compression_ratio": 1.4916201117318435, "no_speech_prob": 0.04368163272738457}, {"id": 27, "seek": 13288, "start": 132.88, "end": 140.56, "text": " So when you see this kind of situation, you see, okay, it's quite complex.", "tokens": [50364, 407, 562, 291, 536, 341, 733, 295, 2590, 11, 291, 536, 11, 1392, 11, 309, 311, 1596, 3997, 13, 50748], "temperature": 0.0, "avg_logprob": -0.2866358323530717, "compression_ratio": 1.38125, "no_speech_prob": 0.02393830008804798}, {"id": 28, "seek": 13288, "start": 140.56, "end": 143.51999999999998, "text": " How can I use this information?", "tokens": [50748, 1012, 393, 286, 764, 341, 1589, 30, 50896], "temperature": 0.0, "avg_logprob": -0.2866358323530717, "compression_ratio": 1.38125, "no_speech_prob": 0.02393830008804798}, {"id": 29, "seek": 13288, "start": 143.51999999999998, "end": 146.72, "text": " Because nothing is certain.", "tokens": [50896, 1436, 1825, 307, 1629, 13, 51056], "temperature": 0.0, "avg_logprob": -0.2866358323530717, "compression_ratio": 1.38125, "no_speech_prob": 0.02393830008804798}, {"id": 30, "seek": 13288, "start": 146.72, "end": 149.96, "text": " Okay.", "tokens": [51056, 1033, 13, 51218], "temperature": 0.0, "avg_logprob": -0.2866358323530717, "compression_ratio": 1.38125, "no_speech_prob": 0.02393830008804798}, {"id": 31, "seek": 13288, "start": 149.96, "end": 154.44, "text": " So the investigator is Leah.", "tokens": [51218, 407, 264, 38330, 307, 38591, 13, 51442], "temperature": 0.0, "avg_logprob": -0.2866358323530717, "compression_ratio": 1.38125, "no_speech_prob": 0.02393830008804798}, {"id": 32, "seek": 13288, "start": 154.44, "end": 159.35999999999999, "text": " Here, Leah is not a person, as you have understood.", "tokens": [51442, 1692, 11, 38591, 307, 406, 257, 954, 11, 382, 291, 362, 7320, 13, 51688], "temperature": 0.0, "avg_logprob": -0.2866358323530717, "compression_ratio": 1.38125, "no_speech_prob": 0.02393830008804798}, {"id": 33, "seek": 15936, "start": 159.36, "end": 163.8, "text": " It's a module dedicated to probabilities.", "tokens": [50364, 467, 311, 257, 10088, 8374, 281, 33783, 13, 50586], "temperature": 0.0, "avg_logprob": -0.1671024786459433, "compression_ratio": 1.5, "no_speech_prob": 0.03848058357834816}, {"id": 34, "seek": 15936, "start": 163.8, "end": 166.52, "text": " So okay, I have several statements here.", "tokens": [50586, 407, 1392, 11, 286, 362, 2940, 12363, 510, 13, 50722], "temperature": 0.0, "avg_logprob": -0.1671024786459433, "compression_ratio": 1.5, "no_speech_prob": 0.03848058357834816}, {"id": 35, "seek": 15936, "start": 166.52, "end": 173.88000000000002, "text": " In other presentation, I elaborate on this, but this time I prefer to show you Leah in", "tokens": [50722, 682, 661, 5860, 11, 286, 20945, 322, 341, 11, 457, 341, 565, 286, 4382, 281, 855, 291, 38591, 294, 51090], "temperature": 0.0, "avg_logprob": -0.1671024786459433, "compression_ratio": 1.5, "no_speech_prob": 0.03848058357834816}, {"id": 36, "seek": 15936, "start": 173.88000000000002, "end": 180.36, "text": " action so you can better understand what it is about.", "tokens": [51090, 3069, 370, 291, 393, 1101, 1223, 437, 309, 307, 466, 13, 51414], "temperature": 0.0, "avg_logprob": -0.1671024786459433, "compression_ratio": 1.5, "no_speech_prob": 0.03848058357834816}, {"id": 37, "seek": 15936, "start": 180.36, "end": 188.72000000000003, "text": " My claim is that Leah is something quite easy to use, quite intuitive.", "tokens": [51414, 1222, 3932, 307, 300, 38591, 307, 746, 1596, 1858, 281, 764, 11, 1596, 21769, 13, 51832], "temperature": 0.0, "avg_logprob": -0.1671024786459433, "compression_ratio": 1.5, "no_speech_prob": 0.03848058357834816}, {"id": 38, "seek": 18872, "start": 188.72, "end": 197.6, "text": " You know probably that there are several packages dedicated to probability or statistics.", "tokens": [50364, 509, 458, 1391, 300, 456, 366, 2940, 17401, 8374, 281, 8482, 420, 12523, 13, 50808], "temperature": 0.0, "avg_logprob": -0.20664364099502563, "compression_ratio": 1.3958333333333333, "no_speech_prob": 0.006516862660646439}, {"id": 39, "seek": 18872, "start": 197.6, "end": 206.72, "text": " The core feature of Leah is to be easy to understand and probably well suited for education.", "tokens": [50808, 440, 4965, 4111, 295, 38591, 307, 281, 312, 1858, 281, 1223, 293, 1391, 731, 24736, 337, 3309, 13, 51264], "temperature": 0.0, "avg_logprob": -0.20664364099502563, "compression_ratio": 1.3958333333333333, "no_speech_prob": 0.006516862660646439}, {"id": 40, "seek": 18872, "start": 206.72, "end": 209.48, "text": " Okay.", "tokens": [51264, 1033, 13, 51402], "temperature": 0.0, "avg_logprob": -0.20664364099502563, "compression_ratio": 1.3958333333333333, "no_speech_prob": 0.006516862660646439}, {"id": 41, "seek": 18872, "start": 209.48, "end": 210.48, "text": " Let's start.", "tokens": [51402, 961, 311, 722, 13, 51452], "temperature": 0.0, "avg_logprob": -0.20664364099502563, "compression_ratio": 1.3958333333333333, "no_speech_prob": 0.006516862660646439}, {"id": 42, "seek": 21048, "start": 210.48, "end": 217.84, "text": " First, I import Leah, which is here in version 401B.", "tokens": [50364, 2386, 11, 286, 974, 38591, 11, 597, 307, 510, 294, 3037, 37510, 33, 13, 50732], "temperature": 0.0, "avg_logprob": -0.2925165279491528, "compression_ratio": 1.4944444444444445, "no_speech_prob": 0.11545710265636444}, {"id": 43, "seek": 21048, "start": 217.84, "end": 225.23999999999998, "text": " Anyway, so first of all, I want to define a fair coin with head and tail.", "tokens": [50732, 5684, 11, 370, 700, 295, 439, 11, 286, 528, 281, 6964, 257, 3143, 11464, 365, 1378, 293, 6838, 13, 51102], "temperature": 0.0, "avg_logprob": -0.2925165279491528, "compression_ratio": 1.4944444444444445, "no_speech_prob": 0.11545710265636444}, {"id": 44, "seek": 21048, "start": 225.23999999999998, "end": 228.12, "text": " I do that.", "tokens": [51102, 286, 360, 300, 13, 51246], "temperature": 0.0, "avg_logprob": -0.2925165279491528, "compression_ratio": 1.4944444444444445, "no_speech_prob": 0.11545710265636444}, {"id": 45, "seek": 21048, "start": 228.12, "end": 231.51999999999998, "text": " So Leah can work with any Python object here.", "tokens": [51246, 407, 38591, 393, 589, 365, 604, 15329, 2657, 510, 13, 51416], "temperature": 0.0, "avg_logprob": -0.2925165279491528, "compression_ratio": 1.4944444444444445, "no_speech_prob": 0.11545710265636444}, {"id": 46, "seek": 21048, "start": 231.51999999999998, "end": 238.32, "text": " I define probabilities on strings, but you can define probabilities on numbers on any", "tokens": [51416, 286, 6964, 33783, 322, 13985, 11, 457, 291, 393, 6964, 33783, 322, 3547, 322, 604, 51756], "temperature": 0.0, "avg_logprob": -0.2925165279491528, "compression_ratio": 1.4944444444444445, "no_speech_prob": 0.11545710265636444}, {"id": 47, "seek": 23832, "start": 238.32, "end": 240.07999999999998, "text": " Python object.", "tokens": [50364, 15329, 2657, 13, 50452], "temperature": 0.0, "avg_logprob": -0.28950330485468323, "compression_ratio": 1.32, "no_speech_prob": 0.01812482252717018}, {"id": 48, "seek": 23832, "start": 240.07999999999998, "end": 242.35999999999999, "text": " Okay.", "tokens": [50452, 1033, 13, 50566], "temperature": 0.0, "avg_logprob": -0.28950330485468323, "compression_ratio": 1.32, "no_speech_prob": 0.01812482252717018}, {"id": 49, "seek": 23832, "start": 242.35999999999999, "end": 249.76, "text": " Here for education, I prefer to switch to fractions.", "tokens": [50566, 1692, 337, 3309, 11, 286, 4382, 281, 3679, 281, 36058, 13, 50936], "temperature": 0.0, "avg_logprob": -0.28950330485468323, "compression_ratio": 1.32, "no_speech_prob": 0.01812482252717018}, {"id": 50, "seek": 23832, "start": 249.76, "end": 257.92, "text": " You know that Python has fraction included.", "tokens": [50936, 509, 458, 300, 15329, 575, 14135, 5556, 13, 51344], "temperature": 0.0, "avg_logprob": -0.28950330485468323, "compression_ratio": 1.32, "no_speech_prob": 0.01812482252717018}, {"id": 51, "seek": 23832, "start": 257.92, "end": 261.36, "text": " So I've switched the display to have fractions.", "tokens": [51344, 407, 286, 600, 16858, 264, 4674, 281, 362, 36058, 13, 51516], "temperature": 0.0, "avg_logprob": -0.28950330485468323, "compression_ratio": 1.32, "no_speech_prob": 0.01812482252717018}, {"id": 52, "seek": 26136, "start": 261.36, "end": 271.72, "text": " So if I want to create a biased coin, I can define several values and here it means that", "tokens": [50364, 407, 498, 286, 528, 281, 1884, 257, 28035, 11464, 11, 286, 393, 6964, 2940, 4190, 293, 510, 309, 1355, 300, 50882], "temperature": 0.0, "avg_logprob": -0.15831189836774553, "compression_ratio": 1.467741935483871, "no_speech_prob": 0.006522929295897484}, {"id": 53, "seek": 26136, "start": 271.72, "end": 277.68, "text": " tails will be three times likely to go that then head.", "tokens": [50882, 28537, 486, 312, 1045, 1413, 3700, 281, 352, 300, 550, 1378, 13, 51180], "temperature": 0.0, "avg_logprob": -0.15831189836774553, "compression_ratio": 1.467741935483871, "no_speech_prob": 0.006522929295897484}, {"id": 54, "seek": 26136, "start": 277.68, "end": 282.24, "text": " So I have a new probability distribution.", "tokens": [51180, 407, 286, 362, 257, 777, 8482, 7316, 13, 51408], "temperature": 0.0, "avg_logprob": -0.15831189836774553, "compression_ratio": 1.467741935483871, "no_speech_prob": 0.006522929295897484}, {"id": 55, "seek": 26136, "start": 282.24, "end": 287.64, "text": " So what I'm doing here is a crash course on Leah because we want to be acquainted to it", "tokens": [51408, 407, 437, 286, 478, 884, 510, 307, 257, 8252, 1164, 322, 38591, 570, 321, 528, 281, 312, 50224, 281, 309, 51678], "temperature": 0.0, "avg_logprob": -0.15831189836774553, "compression_ratio": 1.467741935483871, "no_speech_prob": 0.006522929295897484}, {"id": 56, "seek": 28764, "start": 287.64, "end": 292.03999999999996, "text": " before doing the investigation.", "tokens": [50364, 949, 884, 264, 9627, 13, 50584], "temperature": 0.0, "avg_logprob": -0.2585540199279785, "compression_ratio": 1.4930555555555556, "no_speech_prob": 0.02255667746067047}, {"id": 57, "seek": 28764, "start": 292.03999999999996, "end": 304.64, "text": " I can also use a probability mass function to define probability in a fraction.", "tokens": [50584, 286, 393, 611, 764, 257, 8482, 2758, 2445, 281, 6964, 8482, 294, 257, 14135, 13, 51214], "temperature": 0.0, "avg_logprob": -0.2585540199279785, "compression_ratio": 1.4930555555555556, "no_speech_prob": 0.02255667746067047}, {"id": 58, "seek": 28764, "start": 304.64, "end": 312.64, "text": " So Matplutlib is integrated so you can display your histogram about any probability distribution.", "tokens": [51214, 407, 6789, 564, 325, 38270, 307, 10919, 370, 291, 393, 4674, 428, 49816, 466, 604, 8482, 7316, 13, 51614], "temperature": 0.0, "avg_logprob": -0.2585540199279785, "compression_ratio": 1.4930555555555556, "no_speech_prob": 0.02255667746067047}, {"id": 59, "seek": 28764, "start": 312.64, "end": 313.96, "text": " Okay.", "tokens": [51614, 1033, 13, 51680], "temperature": 0.0, "avg_logprob": -0.2585540199279785, "compression_ratio": 1.4930555555555556, "no_speech_prob": 0.02255667746067047}, {"id": 60, "seek": 31396, "start": 313.96, "end": 317.76, "text": " So I want to make 100 throws.", "tokens": [50364, 407, 286, 528, 281, 652, 2319, 19251, 13, 50554], "temperature": 0.0, "avg_logprob": -0.3283087498432881, "compression_ratio": 1.2666666666666666, "no_speech_prob": 0.029659144580364227}, {"id": 61, "seek": 31396, "start": 317.76, "end": 329.56, "text": " So I use my B coin variable, my probability distribution to calculate to make 100 random", "tokens": [50554, 407, 286, 764, 452, 363, 11464, 7006, 11, 452, 8482, 7316, 281, 8873, 281, 652, 2319, 4974, 51144], "temperature": 0.0, "avg_logprob": -0.3283087498432881, "compression_ratio": 1.2666666666666666, "no_speech_prob": 0.029659144580364227}, {"id": 62, "seek": 31396, "start": 329.56, "end": 333.79999999999995, "text": " coins, throws.", "tokens": [51144, 13561, 11, 19251, 13, 51356], "temperature": 0.0, "avg_logprob": -0.3283087498432881, "compression_ratio": 1.2666666666666666, "no_speech_prob": 0.029659144580364227}, {"id": 63, "seek": 33380, "start": 333.8, "end": 343.72, "text": " So you see in this random throws that there is more tail than head.", "tokens": [50364, 407, 291, 536, 294, 341, 4974, 19251, 300, 456, 307, 544, 6838, 813, 1378, 13, 50860], "temperature": 0.0, "avg_logprob": -0.23017224179038517, "compression_ratio": 1.5, "no_speech_prob": 0.00914931483566761}, {"id": 64, "seek": 33380, "start": 343.72, "end": 350.44, "text": " But okay, how can I be sure that it follows the probability that I given?", "tokens": [50860, 583, 1392, 11, 577, 393, 286, 312, 988, 300, 309, 10002, 264, 8482, 300, 286, 2212, 30, 51196], "temperature": 0.0, "avg_logprob": -0.23017224179038517, "compression_ratio": 1.5, "no_speech_prob": 0.00914931483566761}, {"id": 65, "seek": 33380, "start": 350.44, "end": 354.52, "text": " Simply you can use Leah, the same function as before, Leah, VALS.", "tokens": [51196, 19596, 291, 393, 764, 38591, 11, 264, 912, 2445, 382, 949, 11, 38591, 11, 691, 3427, 50, 13, 51400], "temperature": 0.0, "avg_logprob": -0.23017224179038517, "compression_ratio": 1.5, "no_speech_prob": 0.00914931483566761}, {"id": 66, "seek": 33380, "start": 354.52, "end": 363.6, "text": " You provide the values and this time it will use the random sample as it will be a frequency", "tokens": [51400, 509, 2893, 264, 4190, 293, 341, 565, 309, 486, 764, 264, 4974, 6889, 382, 309, 486, 312, 257, 7893, 51854], "temperature": 0.0, "avg_logprob": -0.23017224179038517, "compression_ratio": 1.5, "no_speech_prob": 0.00914931483566761}, {"id": 67, "seek": 36360, "start": 363.6, "end": 371.28000000000003, "text": " counter and you see that here more or less it conforms to the probability distribution", "tokens": [50364, 5682, 293, 291, 536, 300, 510, 544, 420, 1570, 309, 18975, 82, 281, 264, 8482, 7316, 50748], "temperature": 0.0, "avg_logprob": -0.1611921787261963, "compression_ratio": 1.5227272727272727, "no_speech_prob": 0.016836922615766525}, {"id": 68, "seek": 36360, "start": 371.28000000000003, "end": 374.56, "text": " that I provided for the biased coin.", "tokens": [50748, 300, 286, 5649, 337, 264, 28035, 11464, 13, 50912], "temperature": 0.0, "avg_logprob": -0.1611921787261963, "compression_ratio": 1.5227272727272727, "no_speech_prob": 0.016836922615766525}, {"id": 69, "seek": 36360, "start": 374.56, "end": 382.64000000000004, "text": " So what is interesting on this kind of object is that you can use many of what you do usually", "tokens": [50912, 407, 437, 307, 1880, 322, 341, 733, 295, 2657, 307, 300, 291, 393, 764, 867, 295, 437, 291, 360, 2673, 51316], "temperature": 0.0, "avg_logprob": -0.1611921787261963, "compression_ratio": 1.5227272727272727, "no_speech_prob": 0.016836922615766525}, {"id": 70, "seek": 36360, "start": 382.64000000000004, "end": 384.04, "text": " on your Python object.", "tokens": [51316, 322, 428, 15329, 2657, 13, 51386], "temperature": 0.0, "avg_logprob": -0.1611921787261963, "compression_ratio": 1.5227272727272727, "no_speech_prob": 0.016836922615766525}, {"id": 71, "seek": 36360, "start": 384.04, "end": 387.0, "text": " For example, you can index.", "tokens": [51386, 1171, 1365, 11, 291, 393, 8186, 13, 51534], "temperature": 0.0, "avg_logprob": -0.1611921787261963, "compression_ratio": 1.5227272727272727, "no_speech_prob": 0.016836922615766525}, {"id": 72, "seek": 38700, "start": 387.0, "end": 393.12, "text": " If I ask for zero, it will take the first letter, head or tail, H or T.", "tokens": [50364, 759, 286, 1029, 337, 4018, 11, 309, 486, 747, 264, 700, 5063, 11, 1378, 420, 6838, 11, 389, 420, 314, 13, 50670], "temperature": 0.0, "avg_logprob": -0.19932876236137304, "compression_ratio": 1.6290322580645162, "no_speech_prob": 0.07971055805683136}, {"id": 73, "seek": 38700, "start": 393.12, "end": 401.36, "text": " I can chain with the Python lower method and I have lower case H or T.", "tokens": [50670, 286, 393, 5021, 365, 264, 15329, 3126, 3170, 293, 286, 362, 3126, 1389, 389, 420, 314, 13, 51082], "temperature": 0.0, "avg_logprob": -0.19932876236137304, "compression_ratio": 1.6290322580645162, "no_speech_prob": 0.07971055805683136}, {"id": 74, "seek": 38700, "start": 401.36, "end": 405.4, "text": " I can map Python function here.", "tokens": [51082, 286, 393, 4471, 15329, 2445, 510, 13, 51284], "temperature": 0.0, "avg_logprob": -0.19932876236137304, "compression_ratio": 1.6290322580645162, "no_speech_prob": 0.07971055805683136}, {"id": 75, "seek": 38700, "start": 405.4, "end": 410.88, "text": " This means that it count the number of characters which is four, head and tail, four characters", "tokens": [51284, 639, 1355, 300, 309, 1207, 264, 1230, 295, 4342, 597, 307, 1451, 11, 1378, 293, 6838, 11, 1451, 4342, 51558], "temperature": 0.0, "avg_logprob": -0.19932876236137304, "compression_ratio": 1.6290322580645162, "no_speech_prob": 0.07971055805683136}, {"id": 76, "seek": 38700, "start": 410.88, "end": 411.88, "text": " each.", "tokens": [51558, 1184, 13, 51608], "temperature": 0.0, "avg_logprob": -0.19932876236137304, "compression_ratio": 1.6290322580645162, "no_speech_prob": 0.07971055805683136}, {"id": 77, "seek": 38700, "start": 411.88, "end": 416.04, "text": " So we have a certain four.", "tokens": [51608, 407, 321, 362, 257, 1629, 1451, 13, 51816], "temperature": 0.0, "avg_logprob": -0.19932876236137304, "compression_ratio": 1.6290322580645162, "no_speech_prob": 0.07971055805683136}, {"id": 78, "seek": 41604, "start": 416.04, "end": 421.20000000000005, "text": " And as you could expect also, all the operators are overloaded.", "tokens": [50364, 400, 382, 291, 727, 2066, 611, 11, 439, 264, 19077, 366, 28777, 292, 13, 50622], "temperature": 0.0, "avg_logprob": -0.25559237231946974, "compression_ratio": 1.4479166666666667, "no_speech_prob": 0.005546659231185913}, {"id": 79, "seek": 41604, "start": 421.20000000000005, "end": 431.8, "text": " So if I concatenate my distribution B coin with fixed string, I have a new distribution", "tokens": [50622, 407, 498, 286, 1588, 7186, 473, 452, 7316, 363, 11464, 365, 6806, 6798, 11, 286, 362, 257, 777, 7316, 51152], "temperature": 0.0, "avg_logprob": -0.25559237231946974, "compression_ratio": 1.4479166666666667, "no_speech_prob": 0.005546659231185913}, {"id": 80, "seek": 41604, "start": 431.8, "end": 437.20000000000005, "text": " that follows what has been defined.", "tokens": [51152, 300, 10002, 437, 575, 668, 7642, 13, 51422], "temperature": 0.0, "avg_logprob": -0.25559237231946974, "compression_ratio": 1.4479166666666667, "no_speech_prob": 0.005546659231185913}, {"id": 81, "seek": 41604, "start": 437.20000000000005, "end": 441.16, "text": " Okay and here it's something a bit funny.", "tokens": [51422, 1033, 293, 510, 309, 311, 746, 257, 857, 4074, 13, 51620], "temperature": 0.0, "avg_logprob": -0.25559237231946974, "compression_ratio": 1.4479166666666667, "no_speech_prob": 0.005546659231185913}, {"id": 82, "seek": 41604, "start": 441.16, "end": 445.44, "text": " What happens if you multiply a dice with a coin?", "tokens": [51620, 708, 2314, 498, 291, 12972, 257, 10313, 365, 257, 11464, 30, 51834], "temperature": 0.0, "avg_logprob": -0.25559237231946974, "compression_ratio": 1.4479166666666667, "no_speech_prob": 0.005546659231185913}, {"id": 83, "seek": 44544, "start": 445.44, "end": 447.68, "text": " You get that.", "tokens": [50364, 509, 483, 300, 13, 50476], "temperature": 0.0, "avg_logprob": -0.24014798332663143, "compression_ratio": 1.5260115606936415, "no_speech_prob": 0.011952045373618603}, {"id": 84, "seek": 44544, "start": 447.68, "end": 451.28, "text": " Okay.", "tokens": [50476, 1033, 13, 50656], "temperature": 0.0, "avg_logprob": -0.24014798332663143, "compression_ratio": 1.5260115606936415, "no_speech_prob": 0.011952045373618603}, {"id": 85, "seek": 44544, "start": 451.28, "end": 453.16, "text": " Let's now throw two coins.", "tokens": [50656, 961, 311, 586, 3507, 732, 13561, 13, 50750], "temperature": 0.0, "avg_logprob": -0.24014798332663143, "compression_ratio": 1.5260115606936415, "no_speech_prob": 0.011952045373618603}, {"id": 86, "seek": 44544, "start": 453.16, "end": 458.72, "text": " So the new method allows you to define new event with the same probability.", "tokens": [50750, 407, 264, 777, 3170, 4045, 291, 281, 6964, 777, 2280, 365, 264, 912, 8482, 13, 51028], "temperature": 0.0, "avg_logprob": -0.24014798332663143, "compression_ratio": 1.5260115606936415, "no_speech_prob": 0.011952045373618603}, {"id": 87, "seek": 44544, "start": 458.72, "end": 465.24, "text": " Here I define two coins which are biased together.", "tokens": [51028, 1692, 286, 6964, 732, 13561, 597, 366, 28035, 1214, 13, 51354], "temperature": 0.0, "avg_logprob": -0.24014798332663143, "compression_ratio": 1.5260115606936415, "no_speech_prob": 0.011952045373618603}, {"id": 88, "seek": 44544, "start": 465.24, "end": 473.88, "text": " If I add them together, I have all the combination possible with associated probabilities.", "tokens": [51354, 759, 286, 909, 552, 1214, 11, 286, 362, 439, 264, 6562, 1944, 365, 6615, 33783, 13, 51786], "temperature": 0.0, "avg_logprob": -0.24014798332663143, "compression_ratio": 1.5260115606936415, "no_speech_prob": 0.011952045373618603}, {"id": 89, "seek": 47388, "start": 473.88, "end": 476.6, "text": " So we will see that this is very important.", "tokens": [50364, 407, 321, 486, 536, 300, 341, 307, 588, 1021, 13, 50500], "temperature": 0.0, "avg_logprob": -0.13102324214982397, "compression_ratio": 1.5645933014354068, "no_speech_prob": 0.015486476942896843}, {"id": 90, "seek": 47388, "start": 476.6, "end": 483.48, "text": " We are able to calculate conditional probability with the given method.", "tokens": [50500, 492, 366, 1075, 281, 8873, 27708, 8482, 365, 264, 2212, 3170, 13, 50844], "temperature": 0.0, "avg_logprob": -0.13102324214982397, "compression_ratio": 1.5645933014354068, "no_speech_prob": 0.015486476942896843}, {"id": 91, "seek": 47388, "start": 483.48, "end": 490.6, "text": " So here I try to see, okay, assuming that I know that the first coin is tail, what", "tokens": [50844, 407, 510, 286, 853, 281, 536, 11, 1392, 11, 11926, 300, 286, 458, 300, 264, 700, 11464, 307, 6838, 11, 437, 51200], "temperature": 0.0, "avg_logprob": -0.13102324214982397, "compression_ratio": 1.5645933014354068, "no_speech_prob": 0.015486476942896843}, {"id": 92, "seek": 47388, "start": 490.6, "end": 493.28, "text": " is the combination of the two coins?", "tokens": [51200, 307, 264, 6562, 295, 264, 732, 13561, 30, 51334], "temperature": 0.0, "avg_logprob": -0.13102324214982397, "compression_ratio": 1.5645933014354068, "no_speech_prob": 0.015486476942896843}, {"id": 93, "seek": 47388, "start": 493.28, "end": 502.15999999999997, "text": " So here we see that the previous result has been filtered out to get just the two remaining", "tokens": [51334, 407, 510, 321, 536, 300, 264, 3894, 1874, 575, 668, 37111, 484, 281, 483, 445, 264, 732, 8877, 51778], "temperature": 0.0, "avg_logprob": -0.13102324214982397, "compression_ratio": 1.5645933014354068, "no_speech_prob": 0.015486476942896843}, {"id": 94, "seek": 50216, "start": 502.16, "end": 504.0, "text": " possibilities.", "tokens": [50364, 12178, 13, 50456], "temperature": 0.0, "avg_logprob": -0.30926676265528946, "compression_ratio": 1.411764705882353, "no_speech_prob": 0.03573528677225113}, {"id": 95, "seek": 50216, "start": 504.0, "end": 511.72, "text": " So it's a common feature of LIA is that when you define variable, there is a kind of lazy", "tokens": [50456, 407, 309, 311, 257, 2689, 4111, 295, 7169, 32, 307, 300, 562, 291, 6964, 7006, 11, 456, 307, 257, 733, 295, 14847, 50842], "temperature": 0.0, "avg_logprob": -0.30926676265528946, "compression_ratio": 1.411764705882353, "no_speech_prob": 0.03573528677225113}, {"id": 96, "seek": 50216, "start": 511.72, "end": 512.72, "text": " evaluation.", "tokens": [50842, 13344, 13, 50892], "temperature": 0.0, "avg_logprob": -0.30926676265528946, "compression_ratio": 1.411764705882353, "no_speech_prob": 0.03573528677225113}, {"id": 97, "seek": 50216, "start": 512.72, "end": 519.6, "text": " They remain linked together in a network that define the relationship, the dependencies", "tokens": [50892, 814, 6222, 9408, 1214, 294, 257, 3209, 300, 6964, 264, 2480, 11, 264, 36606, 51236], "temperature": 0.0, "avg_logprob": -0.30926676265528946, "compression_ratio": 1.411764705882353, "no_speech_prob": 0.03573528677225113}, {"id": 98, "seek": 50216, "start": 519.6, "end": 523.72, "text": " between the random variables.", "tokens": [51236, 1296, 264, 4974, 9102, 13, 51442], "temperature": 0.0, "avg_logprob": -0.30926676265528946, "compression_ratio": 1.411764705882353, "no_speech_prob": 0.03573528677225113}, {"id": 99, "seek": 50216, "start": 523.72, "end": 525.52, "text": " Okay.", "tokens": [51442, 1033, 13, 51532], "temperature": 0.0, "avg_logprob": -0.30926676265528946, "compression_ratio": 1.411764705882353, "no_speech_prob": 0.03573528677225113}, {"id": 100, "seek": 52552, "start": 525.52, "end": 533.56, "text": " And you can also define Boolean events like, okay, what is the probability to be?", "tokens": [50364, 400, 291, 393, 611, 6964, 23351, 28499, 3931, 411, 11, 1392, 11, 437, 307, 264, 8482, 281, 312, 30, 50766], "temperature": 0.0, "avg_logprob": -0.2059531741672092, "compression_ratio": 1.4383561643835616, "no_speech_prob": 0.01639009639620781}, {"id": 101, "seek": 52552, "start": 533.56, "end": 537.6, "text": " I define it at 140 seconds.", "tokens": [50766, 286, 6964, 309, 412, 21548, 3949, 13, 50968], "temperature": 0.0, "avg_logprob": -0.2059531741672092, "compression_ratio": 1.4383561643835616, "no_speech_prob": 0.01639009639620781}, {"id": 102, "seek": 52552, "start": 537.6, "end": 543.76, "text": " And then I can use operator like to be or not to be.", "tokens": [50968, 400, 550, 286, 393, 764, 12973, 411, 281, 312, 420, 406, 281, 312, 13, 51276], "temperature": 0.0, "avg_logprob": -0.2059531741672092, "compression_ratio": 1.4383561643835616, "no_speech_prob": 0.01639009639620781}, {"id": 103, "seek": 52552, "start": 543.76, "end": 551.16, "text": " And the result is it's true, it's certain true.", "tokens": [51276, 400, 264, 1874, 307, 309, 311, 2074, 11, 309, 311, 1629, 2074, 13, 51646], "temperature": 0.0, "avg_logprob": -0.2059531741672092, "compression_ratio": 1.4383561643835616, "no_speech_prob": 0.01639009639620781}, {"id": 104, "seek": 55116, "start": 551.16, "end": 556.3199999999999, "text": " Because okay, to be it's either true or false and not to be it's the contrary.", "tokens": [50364, 1436, 1392, 11, 281, 312, 309, 311, 2139, 2074, 420, 7908, 293, 406, 281, 312, 309, 311, 264, 19506, 13, 50622], "temperature": 0.0, "avg_logprob": -0.2755193381473936, "compression_ratio": 1.5977653631284916, "no_speech_prob": 0.022637637332081795}, {"id": 105, "seek": 55116, "start": 556.3199999999999, "end": 560.0, "text": " So together it's certainly true.", "tokens": [50622, 407, 1214, 309, 311, 3297, 2074, 13, 50806], "temperature": 0.0, "avg_logprob": -0.2755193381473936, "compression_ratio": 1.5977653631284916, "no_speech_prob": 0.022637637332081795}, {"id": 106, "seek": 55116, "start": 560.0, "end": 563.24, "text": " Okay.", "tokens": [50806, 1033, 13, 50968], "temperature": 0.0, "avg_logprob": -0.2755193381473936, "compression_ratio": 1.5977653631284916, "no_speech_prob": 0.022637637332081795}, {"id": 107, "seek": 55116, "start": 563.24, "end": 570.8, "text": " And there is also a dedicated function in LIA which is P. So you can extract the probability", "tokens": [50968, 400, 456, 307, 611, 257, 8374, 2445, 294, 7169, 32, 597, 307, 430, 13, 407, 291, 393, 8947, 264, 8482, 51346], "temperature": 0.0, "avg_logprob": -0.2755193381473936, "compression_ratio": 1.5977653631284916, "no_speech_prob": 0.022637637332081795}, {"id": 108, "seek": 55116, "start": 570.8, "end": 571.8, "text": " of true.", "tokens": [51346, 295, 2074, 13, 51396], "temperature": 0.0, "avg_logprob": -0.2755193381473936, "compression_ratio": 1.5977653631284916, "no_speech_prob": 0.022637637332081795}, {"id": 109, "seek": 55116, "start": 571.8, "end": 576.76, "text": " So you get really a real probability like this.", "tokens": [51396, 407, 291, 483, 534, 257, 957, 8482, 411, 341, 13, 51644], "temperature": 0.0, "avg_logprob": -0.2755193381473936, "compression_ratio": 1.5977653631284916, "no_speech_prob": 0.022637637332081795}, {"id": 110, "seek": 55116, "start": 576.76, "end": 577.76, "text": " Okay.", "tokens": [51644, 1033, 13, 51694], "temperature": 0.0, "avg_logprob": -0.2755193381473936, "compression_ratio": 1.5977653631284916, "no_speech_prob": 0.022637637332081795}, {"id": 111, "seek": 55116, "start": 577.76, "end": 580.28, "text": " Let's go on.", "tokens": [51694, 961, 311, 352, 322, 13, 51820], "temperature": 0.0, "avg_logprob": -0.2755193381473936, "compression_ratio": 1.5977653631284916, "no_speech_prob": 0.022637637332081795}, {"id": 112, "seek": 58028, "start": 580.28, "end": 588.8, "text": " So here it's an excerpt of a book that it's three centuries old from Abraham de Moivre.", "tokens": [50364, 407, 510, 309, 311, 364, 42760, 662, 295, 257, 1446, 300, 309, 311, 1045, 13926, 1331, 490, 17782, 368, 3335, 592, 265, 13, 50790], "temperature": 0.0, "avg_logprob": -0.22175387946926817, "compression_ratio": 1.3057851239669422, "no_speech_prob": 0.02252071350812912}, {"id": 113, "seek": 58028, "start": 588.8, "end": 599.4, "text": " It's probably one of the first problem solved by de Moivre here.", "tokens": [50790, 467, 311, 1391, 472, 295, 264, 700, 1154, 13041, 538, 368, 3335, 592, 265, 510, 13, 51320], "temperature": 0.0, "avg_logprob": -0.22175387946926817, "compression_ratio": 1.3057851239669422, "no_speech_prob": 0.02252071350812912}, {"id": 114, "seek": 58028, "start": 599.4, "end": 600.4, "text": " Okay.", "tokens": [51320, 1033, 13, 51370], "temperature": 0.0, "avg_logprob": -0.22175387946926817, "compression_ratio": 1.3057851239669422, "no_speech_prob": 0.02252071350812912}, {"id": 115, "seek": 60040, "start": 600.4, "end": 610.4, "text": " Let's ask to find the probability of throwing a nace in three throws given a fair dive.", "tokens": [50364, 961, 311, 1029, 281, 915, 264, 8482, 295, 10238, 257, 297, 617, 294, 1045, 19251, 2212, 257, 3143, 9192, 13, 50864], "temperature": 0.0, "avg_logprob": -0.3539134979248047, "compression_ratio": 1.4161490683229814, "no_speech_prob": 0.16835737228393555}, {"id": 116, "seek": 60040, "start": 610.4, "end": 612.4399999999999, "text": " This is how to calculate in LIA.", "tokens": [50864, 639, 307, 577, 281, 8873, 294, 7169, 32, 13, 50966], "temperature": 0.0, "avg_logprob": -0.3539134979248047, "compression_ratio": 1.4161490683229814, "no_speech_prob": 0.16835737228393555}, {"id": 117, "seek": 60040, "start": 612.4399999999999, "end": 617.1999999999999, "text": " So here I define a dive.", "tokens": [50966, 407, 510, 286, 6964, 257, 9192, 13, 51204], "temperature": 0.0, "avg_logprob": -0.3539134979248047, "compression_ratio": 1.4161490683229814, "no_speech_prob": 0.16835737228393555}, {"id": 118, "seek": 60040, "start": 617.1999999999999, "end": 624.4, "text": " I create three instances which are independent, which are assigned to the 1, 2, 3.", "tokens": [51204, 286, 1884, 1045, 14519, 597, 366, 6695, 11, 597, 366, 13279, 281, 264, 502, 11, 568, 11, 805, 13, 51564], "temperature": 0.0, "avg_logprob": -0.3539134979248047, "compression_ratio": 1.4161490683229814, "no_speech_prob": 0.16835737228393555}, {"id": 119, "seek": 62440, "start": 624.4, "end": 631.12, "text": " And then I ask for the probability of any of one of these dives is a nace.", "tokens": [50364, 400, 550, 286, 1029, 337, 264, 8482, 295, 604, 295, 472, 295, 613, 274, 1539, 307, 257, 297, 617, 13, 50700], "temperature": 0.0, "avg_logprob": -0.22202271355523004, "compression_ratio": 1.3842364532019704, "no_speech_prob": 0.025654956698417664}, {"id": 120, "seek": 62440, "start": 631.12, "end": 641.24, "text": " The result is 91, 216th as calculated three centuries ago by de Moivre.", "tokens": [50700, 440, 1874, 307, 31064, 11, 5080, 21, 392, 382, 15598, 1045, 13926, 2057, 538, 368, 3335, 592, 265, 13, 51206], "temperature": 0.0, "avg_logprob": -0.22202271355523004, "compression_ratio": 1.3842364532019704, "no_speech_prob": 0.025654956698417664}, {"id": 121, "seek": 62440, "start": 641.24, "end": 643.1999999999999, "text": " So far so good.", "tokens": [51206, 407, 1400, 370, 665, 13, 51304], "temperature": 0.0, "avg_logprob": -0.22202271355523004, "compression_ratio": 1.3842364532019704, "no_speech_prob": 0.025654956698417664}, {"id": 122, "seek": 62440, "start": 643.1999999999999, "end": 644.1999999999999, "text": " Okay.", "tokens": [51304, 1033, 13, 51354], "temperature": 0.0, "avg_logprob": -0.22202271355523004, "compression_ratio": 1.3842364532019704, "no_speech_prob": 0.025654956698417664}, {"id": 123, "seek": 62440, "start": 644.1999999999999, "end": 649.36, "text": " No, I don't know if you like playing a role-playing game.", "tokens": [51354, 883, 11, 286, 500, 380, 458, 498, 291, 411, 2433, 257, 3090, 12, 32944, 1216, 13, 51612], "temperature": 0.0, "avg_logprob": -0.22202271355523004, "compression_ratio": 1.3842364532019704, "no_speech_prob": 0.025654956698417664}, {"id": 124, "seek": 62440, "start": 649.36, "end": 654.24, "text": " So there's a small example that where you can use LIA.", "tokens": [51612, 407, 456, 311, 257, 1359, 1365, 300, 689, 291, 393, 764, 7169, 32, 13, 51856], "temperature": 0.0, "avg_logprob": -0.22202271355523004, "compression_ratio": 1.3842364532019704, "no_speech_prob": 0.025654956698417664}, {"id": 125, "seek": 65424, "start": 654.24, "end": 659.8, "text": " So imagine that you have here this dwarf which fights against a troll.", "tokens": [50364, 407, 3811, 300, 291, 362, 510, 341, 35527, 597, 14512, 1970, 257, 20680, 13, 50642], "temperature": 0.0, "avg_logprob": -0.33385683508480296, "compression_ratio": 1.4911242603550297, "no_speech_prob": 0.007912160828709602}, {"id": 126, "seek": 65424, "start": 659.8, "end": 660.96, "text": " Okay.", "tokens": [50642, 1033, 13, 50700], "temperature": 0.0, "avg_logprob": -0.33385683508480296, "compression_ratio": 1.4911242603550297, "no_speech_prob": 0.007912160828709602}, {"id": 127, "seek": 65424, "start": 660.96, "end": 668.6800000000001, "text": " I first define a new kind of display with percentage because it's more convenient here.", "tokens": [50700, 286, 700, 6964, 257, 777, 733, 295, 4674, 365, 9668, 570, 309, 311, 544, 10851, 510, 13, 51086], "temperature": 0.0, "avg_logprob": -0.33385683508480296, "compression_ratio": 1.4911242603550297, "no_speech_prob": 0.007912160828709602}, {"id": 128, "seek": 65424, "start": 668.6800000000001, "end": 673.16, "text": " I define two different kind of dice.", "tokens": [51086, 286, 6964, 732, 819, 733, 295, 10313, 13, 51310], "temperature": 0.0, "avg_logprob": -0.33385683508480296, "compression_ratio": 1.4911242603550297, "no_speech_prob": 0.007912160828709602}, {"id": 129, "seek": 65424, "start": 673.16, "end": 674.16, "text": " Okay.", "tokens": [51310, 1033, 13, 51360], "temperature": 0.0, "avg_logprob": -0.33385683508480296, "compression_ratio": 1.4911242603550297, "no_speech_prob": 0.007912160828709602}, {"id": 130, "seek": 65424, "start": 674.16, "end": 680.8, "text": " Imagine that your attack hole is d25 plus 4.", "tokens": [51360, 11739, 300, 428, 2690, 5458, 307, 274, 6074, 1804, 1017, 13, 51692], "temperature": 0.0, "avg_logprob": -0.33385683508480296, "compression_ratio": 1.4911242603550297, "no_speech_prob": 0.007912160828709602}, {"id": 131, "seek": 68080, "start": 680.8, "end": 681.8, "text": " Okay.", "tokens": [50364, 1033, 13, 50414], "temperature": 0.0, "avg_logprob": -0.2409762345351182, "compression_ratio": 1.4682080924855492, "no_speech_prob": 0.003210602793842554}, {"id": 132, "seek": 68080, "start": 681.8, "end": 686.92, "text": " What is the probability to ever hit?", "tokens": [50414, 708, 307, 264, 8482, 281, 1562, 2045, 30, 50670], "temperature": 0.0, "avg_logprob": -0.2409762345351182, "compression_ratio": 1.4682080924855492, "no_speech_prob": 0.003210602793842554}, {"id": 133, "seek": 68080, "start": 686.92, "end": 692.12, "text": " You see, okay, it's easy to calculate with inequality.", "tokens": [50670, 509, 536, 11, 1392, 11, 309, 311, 1858, 281, 8873, 365, 16970, 13, 50930], "temperature": 0.0, "avg_logprob": -0.2409762345351182, "compression_ratio": 1.4682080924855492, "no_speech_prob": 0.003210602793842554}, {"id": 134, "seek": 68080, "start": 692.12, "end": 696.88, "text": " So you have to be greater or equal that the troll armor class.", "tokens": [50930, 407, 291, 362, 281, 312, 5044, 420, 2681, 300, 264, 20680, 13124, 1508, 13, 51168], "temperature": 0.0, "avg_logprob": -0.2409762345351182, "compression_ratio": 1.4682080924855492, "no_speech_prob": 0.003210602793842554}, {"id": 135, "seek": 68080, "start": 696.88, "end": 700.04, "text": " You get this probability.", "tokens": [51168, 509, 483, 341, 8482, 13, 51326], "temperature": 0.0, "avg_logprob": -0.2409762345351182, "compression_ratio": 1.4682080924855492, "no_speech_prob": 0.003210602793842554}, {"id": 136, "seek": 68080, "start": 700.04, "end": 705.92, "text": " So the damage of the magic axe is to d6 plus 5.", "tokens": [51326, 407, 264, 4344, 295, 264, 5585, 30195, 307, 281, 274, 21, 1804, 1025, 13, 51620], "temperature": 0.0, "avg_logprob": -0.2409762345351182, "compression_ratio": 1.4682080924855492, "no_speech_prob": 0.003210602793842554}, {"id": 137, "seek": 68080, "start": 705.92, "end": 708.24, "text": " Here is the result.", "tokens": [51620, 1692, 307, 264, 1874, 13, 51736], "temperature": 0.0, "avg_logprob": -0.2409762345351182, "compression_ratio": 1.4682080924855492, "no_speech_prob": 0.003210602793842554}, {"id": 138, "seek": 70824, "start": 708.24, "end": 717.24, "text": " But this damage is only applied if the dwarf can hit the troll.", "tokens": [50364, 583, 341, 4344, 307, 787, 6456, 498, 264, 35527, 393, 2045, 264, 20680, 13, 50814], "temperature": 0.0, "avg_logprob": -0.22279282138772208, "compression_ratio": 1.5138121546961325, "no_speech_prob": 0.012192092835903168}, {"id": 139, "seek": 70824, "start": 717.24, "end": 723.5600000000001, "text": " So for that we have a special construction, LIA if underscore underscore to avoid collision", "tokens": [50814, 407, 337, 300, 321, 362, 257, 2121, 6435, 11, 7169, 32, 498, 37556, 37556, 281, 5042, 24644, 51130], "temperature": 0.0, "avg_logprob": -0.22279282138772208, "compression_ratio": 1.5138121546961325, "no_speech_prob": 0.012192092835903168}, {"id": 140, "seek": 70824, "start": 723.5600000000001, "end": 726.92, "text": " with the Python if.", "tokens": [51130, 365, 264, 15329, 498, 13, 51298], "temperature": 0.0, "avg_logprob": -0.22279282138772208, "compression_ratio": 1.5138121546961325, "no_speech_prob": 0.012192092835903168}, {"id": 141, "seek": 70824, "start": 726.92, "end": 733.8, "text": " And okay, this means if there is a hit, then I apply the magic axe.", "tokens": [51298, 400, 1392, 11, 341, 1355, 498, 456, 307, 257, 2045, 11, 550, 286, 3079, 264, 5585, 30195, 13, 51642], "temperature": 0.0, "avg_logprob": -0.22279282138772208, "compression_ratio": 1.5138121546961325, "no_speech_prob": 0.012192092835903168}, {"id": 142, "seek": 70824, "start": 733.8, "end": 736.88, "text": " Otherwise, the damage is zero.", "tokens": [51642, 10328, 11, 264, 4344, 307, 4018, 13, 51796], "temperature": 0.0, "avg_logprob": -0.22279282138772208, "compression_ratio": 1.5138121546961325, "no_speech_prob": 0.012192092835903168}, {"id": 143, "seek": 73688, "start": 736.88, "end": 739.12, "text": " And here is the new histogram.", "tokens": [50364, 400, 510, 307, 264, 777, 49816, 13, 50476], "temperature": 0.0, "avg_logprob": -0.187087082862854, "compression_ratio": 1.5603864734299517, "no_speech_prob": 0.013172181323170662}, {"id": 144, "seek": 73688, "start": 739.12, "end": 745.6, "text": " So this is the probability, the actual damage that is done to the troll.", "tokens": [50476, 407, 341, 307, 264, 8482, 11, 264, 3539, 4344, 300, 307, 1096, 281, 264, 20680, 13, 50800], "temperature": 0.0, "avg_logprob": -0.187087082862854, "compression_ratio": 1.5603864734299517, "no_speech_prob": 0.013172181323170662}, {"id": 145, "seek": 73688, "start": 745.6, "end": 752.56, "text": " And then from this data you can answer the, okay, assuming that the troll has 20 health", "tokens": [50800, 400, 550, 490, 341, 1412, 291, 393, 1867, 264, 11, 1392, 11, 11926, 300, 264, 20680, 575, 945, 1585, 51148], "temperature": 0.0, "avg_logprob": -0.187087082862854, "compression_ratio": 1.5603864734299517, "no_speech_prob": 0.013172181323170662}, {"id": 146, "seek": 73688, "start": 752.56, "end": 759.4, "text": " points remaining was the probability to kill him in four rounds or less.", "tokens": [51148, 2793, 8877, 390, 264, 8482, 281, 1961, 796, 294, 1451, 13757, 420, 1570, 13, 51490], "temperature": 0.0, "avg_logprob": -0.187087082862854, "compression_ratio": 1.5603864734299517, "no_speech_prob": 0.013172181323170662}, {"id": 147, "seek": 73688, "start": 759.4, "end": 764.56, "text": " You see it's deadly simple with this formula to calculate.", "tokens": [51490, 509, 536, 309, 311, 18232, 2199, 365, 341, 8513, 281, 8873, 13, 51748], "temperature": 0.0, "avg_logprob": -0.187087082862854, "compression_ratio": 1.5603864734299517, "no_speech_prob": 0.013172181323170662}, {"id": 148, "seek": 76456, "start": 765.0, "end": 769.16, "text": " We find it's 40%, something like that.", "tokens": [50386, 492, 915, 309, 311, 3356, 8923, 746, 411, 300, 13, 50594], "temperature": 0.0, "avg_logprob": -0.32783463126734685, "compression_ratio": 1.4619883040935673, "no_speech_prob": 0.0589933842420578}, {"id": 149, "seek": 76456, "start": 769.16, "end": 770.16, "text": " Okay.", "tokens": [50594, 1033, 13, 50644], "temperature": 0.0, "avg_logprob": -0.32783463126734685, "compression_ratio": 1.4619883040935673, "no_speech_prob": 0.0589933842420578}, {"id": 150, "seek": 76456, "start": 770.16, "end": 771.16, "text": " Okay.", "tokens": [50644, 1033, 13, 50694], "temperature": 0.0, "avg_logprob": -0.32783463126734685, "compression_ratio": 1.4619883040935673, "no_speech_prob": 0.0589933842420578}, {"id": 151, "seek": 76456, "start": 771.16, "end": 775.3599999999999, "text": " You follow?", "tokens": [50694, 509, 1524, 30, 50904], "temperature": 0.0, "avg_logprob": -0.32783463126734685, "compression_ratio": 1.4619883040935673, "no_speech_prob": 0.0589933842420578}, {"id": 152, "seek": 76456, "start": 775.3599999999999, "end": 779.52, "text": " So I will, I have many, many, many examples.", "tokens": [50904, 407, 286, 486, 11, 286, 362, 867, 11, 867, 11, 867, 5110, 13, 51112], "temperature": 0.0, "avg_logprob": -0.32783463126734685, "compression_ratio": 1.4619883040935673, "no_speech_prob": 0.0589933842420578}, {"id": 153, "seek": 76456, "start": 779.52, "end": 786.0, "text": " But by lack of time I will drop maybe some of these examples.", "tokens": [51112, 583, 538, 5011, 295, 565, 286, 486, 3270, 1310, 512, 295, 613, 5110, 13, 51436], "temperature": 0.0, "avg_logprob": -0.32783463126734685, "compression_ratio": 1.4619883040935673, "no_speech_prob": 0.0589933842420578}, {"id": 154, "seek": 76456, "start": 786.0, "end": 792.2399999999999, "text": " Boys or girls paradox, something very funny also that you can find on Wikipedia.", "tokens": [51436, 21963, 420, 4519, 26221, 11, 746, 588, 4074, 611, 300, 291, 393, 915, 322, 28999, 13, 51748], "temperature": 0.0, "avg_logprob": -0.32783463126734685, "compression_ratio": 1.4619883040935673, "no_speech_prob": 0.0589933842420578}, {"id": 155, "seek": 79224, "start": 792.24, "end": 794.76, "text": " So the chance to be a boy or girl are even.", "tokens": [50364, 407, 264, 2931, 281, 312, 257, 3237, 420, 2013, 366, 754, 13, 50490], "temperature": 0.0, "avg_logprob": -0.23072999653063322, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.01799692027270794}, {"id": 156, "seek": 79224, "start": 794.76, "end": 800.0, "text": " So okay, boy, one half, girl, one half.", "tokens": [50490, 407, 1392, 11, 3237, 11, 472, 1922, 11, 2013, 11, 472, 1922, 13, 50752], "temperature": 0.0, "avg_logprob": -0.23072999653063322, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.01799692027270794}, {"id": 157, "seek": 79224, "start": 800.0, "end": 804.48, "text": " Mr Smith asked two children, at least one of them is a boy.", "tokens": [50752, 2221, 8538, 2351, 732, 2227, 11, 412, 1935, 472, 295, 552, 307, 257, 3237, 13, 50976], "temperature": 0.0, "avg_logprob": -0.23072999653063322, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.01799692027270794}, {"id": 158, "seek": 79224, "start": 804.48, "end": 808.52, "text": " What is the probability that both children are boys?", "tokens": [50976, 708, 307, 264, 8482, 300, 1293, 2227, 366, 6347, 30, 51178], "temperature": 0.0, "avg_logprob": -0.23072999653063322, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.01799692027270794}, {"id": 159, "seek": 79224, "start": 808.52, "end": 814.84, "text": " Many people and including myself, the first time I heard this I think, okay, the information", "tokens": [51178, 5126, 561, 293, 3009, 2059, 11, 264, 700, 565, 286, 2198, 341, 286, 519, 11, 1392, 11, 264, 1589, 51494], "temperature": 0.0, "avg_logprob": -0.23072999653063322, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.01799692027270794}, {"id": 160, "seek": 79224, "start": 814.84, "end": 816.8, "text": " give me no clues.", "tokens": [51494, 976, 385, 572, 20936, 13, 51592], "temperature": 0.0, "avg_logprob": -0.23072999653063322, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.01799692027270794}, {"id": 161, "seek": 79224, "start": 816.8, "end": 818.72, "text": " It's one half.", "tokens": [51592, 467, 311, 472, 1922, 13, 51688], "temperature": 0.0, "avg_logprob": -0.23072999653063322, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.01799692027270794}, {"id": 162, "seek": 81872, "start": 818.72, "end": 825.08, "text": " But if you calculate like this with Leah, so you define children as two, a joint of", "tokens": [50364, 583, 498, 291, 8873, 411, 341, 365, 38591, 11, 370, 291, 6964, 2227, 382, 732, 11, 257, 7225, 295, 50682], "temperature": 0.0, "avg_logprob": -0.19169293279233185, "compression_ratio": 1.6480446927374302, "no_speech_prob": 0.004798173904418945}, {"id": 163, "seek": 81872, "start": 825.08, "end": 836.5600000000001, "text": " two children and that you count the number of boys, calculate the conditional probability,", "tokens": [50682, 732, 2227, 293, 300, 291, 1207, 264, 1230, 295, 6347, 11, 8873, 264, 27708, 8482, 11, 51256], "temperature": 0.0, "avg_logprob": -0.19169293279233185, "compression_ratio": 1.6480446927374302, "no_speech_prob": 0.004798173904418945}, {"id": 164, "seek": 81872, "start": 836.5600000000001, "end": 840.72, "text": " the answer is one third actually.", "tokens": [51256, 264, 1867, 307, 472, 2636, 767, 13, 51464], "temperature": 0.0, "avg_logprob": -0.19169293279233185, "compression_ratio": 1.6480446927374302, "no_speech_prob": 0.004798173904418945}, {"id": 165, "seek": 81872, "start": 840.72, "end": 847.12, "text": " And what is interesting with Leah, you can understand why this is the answer by asking", "tokens": [51464, 400, 437, 307, 1880, 365, 38591, 11, 291, 393, 1223, 983, 341, 307, 264, 1867, 538, 3365, 51784], "temperature": 0.0, "avg_logprob": -0.19169293279233185, "compression_ratio": 1.6480446927374302, "no_speech_prob": 0.004798173904418945}, {"id": 166, "seek": 84712, "start": 847.12, "end": 850.36, "text": " Leah to show you all the combinations.", "tokens": [50364, 38591, 281, 855, 291, 439, 264, 21267, 13, 50526], "temperature": 0.0, "avg_logprob": -0.1540127007857613, "compression_ratio": 1.6632124352331605, "no_speech_prob": 0.15433916449546814}, {"id": 167, "seek": 84712, "start": 850.36, "end": 858.72, "text": " So here I show you the gender of all the children, the number of boys and given that", "tokens": [50526, 407, 510, 286, 855, 291, 264, 7898, 295, 439, 264, 2227, 11, 264, 1230, 295, 6347, 293, 2212, 300, 50944], "temperature": 0.0, "avg_logprob": -0.1540127007857613, "compression_ratio": 1.6632124352331605, "no_speech_prob": 0.15433916449546814}, {"id": 168, "seek": 84712, "start": 858.72, "end": 862.64, "text": " the number of boys is greater or equal to one.", "tokens": [50944, 264, 1230, 295, 6347, 307, 5044, 420, 2681, 281, 472, 13, 51140], "temperature": 0.0, "avg_logprob": -0.1540127007857613, "compression_ratio": 1.6632124352331605, "no_speech_prob": 0.15433916449546814}, {"id": 169, "seek": 84712, "start": 862.64, "end": 867.92, "text": " And we see here the answer is here and we understand better why it is one third.", "tokens": [51140, 400, 321, 536, 510, 264, 1867, 307, 510, 293, 321, 1223, 1101, 983, 309, 307, 472, 2636, 13, 51404], "temperature": 0.0, "avg_logprob": -0.1540127007857613, "compression_ratio": 1.6632124352331605, "no_speech_prob": 0.15433916449546814}, {"id": 170, "seek": 84712, "start": 867.92, "end": 868.92, "text": " Okay.", "tokens": [51404, 1033, 13, 51454], "temperature": 0.0, "avg_logprob": -0.1540127007857613, "compression_ratio": 1.6632124352331605, "no_speech_prob": 0.15433916449546814}, {"id": 171, "seek": 84712, "start": 868.92, "end": 873.6800000000001, "text": " It's a bit fast but you can do it at your own pace later.", "tokens": [51454, 467, 311, 257, 857, 2370, 457, 291, 393, 360, 309, 412, 428, 1065, 11638, 1780, 13, 51692], "temperature": 0.0, "avg_logprob": -0.1540127007857613, "compression_ratio": 1.6632124352331605, "no_speech_prob": 0.15433916449546814}, {"id": 172, "seek": 84712, "start": 873.6800000000001, "end": 875.08, "text": " Okay.", "tokens": [51692, 1033, 13, 51762], "temperature": 0.0, "avg_logprob": -0.1540127007857613, "compression_ratio": 1.6632124352331605, "no_speech_prob": 0.15433916449546814}, {"id": 173, "seek": 87508, "start": 875.08, "end": 882.64, "text": " What happens if you have more elaborate problem?", "tokens": [50364, 708, 2314, 498, 291, 362, 544, 20945, 1154, 30, 50742], "temperature": 0.0, "avg_logprob": -0.2368677703427597, "compression_ratio": 1.4772727272727273, "no_speech_prob": 0.03316468745470047}, {"id": 174, "seek": 87508, "start": 882.64, "end": 885.32, "text": " Like here we have several children.", "tokens": [50742, 1743, 510, 321, 362, 2940, 2227, 13, 50876], "temperature": 0.0, "avg_logprob": -0.2368677703427597, "compression_ratio": 1.4772727272727273, "no_speech_prob": 0.03316468745470047}, {"id": 175, "seek": 87508, "start": 885.32, "end": 889.12, "text": " The eldest is a boy and he's got three brothers at least.", "tokens": [50876, 440, 38096, 307, 257, 3237, 293, 415, 311, 658, 1045, 8452, 412, 1935, 13, 51066], "temperature": 0.0, "avg_logprob": -0.2368677703427597, "compression_ratio": 1.4772727272727273, "no_speech_prob": 0.03316468745470047}, {"id": 176, "seek": 87508, "start": 889.12, "end": 892.8000000000001, "text": " What is the probability that all children are boys?", "tokens": [51066, 708, 307, 264, 8482, 300, 439, 2227, 366, 6347, 30, 51250], "temperature": 0.0, "avg_logprob": -0.2368677703427597, "compression_ratio": 1.4772727272727273, "no_speech_prob": 0.03316468745470047}, {"id": 177, "seek": 87508, "start": 892.8000000000001, "end": 894.0400000000001, "text": " Okay.", "tokens": [51250, 1033, 13, 51312], "temperature": 0.0, "avg_logprob": -0.2368677703427597, "compression_ratio": 1.4772727272727273, "no_speech_prob": 0.03316468745470047}, {"id": 178, "seek": 87508, "start": 894.0400000000001, "end": 896.44, "text": " You can model this like this.", "tokens": [51312, 509, 393, 2316, 341, 411, 341, 13, 51432], "temperature": 0.0, "avg_logprob": -0.2368677703427597, "compression_ratio": 1.4772727272727273, "no_speech_prob": 0.03316468745470047}, {"id": 179, "seek": 87508, "start": 896.44, "end": 900.1600000000001, "text": " Here I create seven children.", "tokens": [51432, 1692, 286, 1884, 3407, 2227, 13, 51618], "temperature": 0.0, "avg_logprob": -0.2368677703427597, "compression_ratio": 1.4772727272727273, "no_speech_prob": 0.03316468745470047}, {"id": 180, "seek": 90016, "start": 900.16, "end": 909.28, "text": " And I put, so you see when you read this expression, it's quite close to the initial problem.", "tokens": [50364, 400, 286, 829, 11, 370, 291, 536, 562, 291, 1401, 341, 6114, 11, 309, 311, 1596, 1998, 281, 264, 5883, 1154, 13, 50820], "temperature": 0.0, "avg_logprob": -0.2040940901812385, "compression_ratio": 1.5215311004784688, "no_speech_prob": 0.03936411812901497}, {"id": 181, "seek": 90016, "start": 909.28, "end": 915.4399999999999, "text": " Of course you have to understand the elements of Leah to do that but after that it's quite", "tokens": [50820, 2720, 1164, 291, 362, 281, 1223, 264, 4959, 295, 38591, 281, 360, 300, 457, 934, 300, 309, 311, 1596, 51128], "temperature": 0.0, "avg_logprob": -0.2040940901812385, "compression_ratio": 1.5215311004784688, "no_speech_prob": 0.03936411812901497}, {"id": 182, "seek": 90016, "start": 915.4399999999999, "end": 916.76, "text": " easy to model.", "tokens": [51128, 1858, 281, 2316, 13, 51194], "temperature": 0.0, "avg_logprob": -0.2040940901812385, "compression_ratio": 1.5215311004784688, "no_speech_prob": 0.03936411812901497}, {"id": 183, "seek": 90016, "start": 916.76, "end": 919.76, "text": " The answer is one forty second.", "tokens": [51194, 440, 1867, 307, 472, 15815, 1150, 13, 51344], "temperature": 0.0, "avg_logprob": -0.2040940901812385, "compression_ratio": 1.5215311004784688, "no_speech_prob": 0.03936411812901497}, {"id": 184, "seek": 90016, "start": 919.76, "end": 929.64, "text": " Again it's possible to ask why it is so and here by joining you see that's okay, seven", "tokens": [51344, 3764, 309, 311, 1944, 281, 1029, 983, 309, 307, 370, 293, 510, 538, 5549, 291, 536, 300, 311, 1392, 11, 3407, 51838], "temperature": 0.0, "avg_logprob": -0.2040940901812385, "compression_ratio": 1.5215311004784688, "no_speech_prob": 0.03936411812901497}, {"id": 185, "seek": 92964, "start": 929.64, "end": 933.28, "text": " children is this part and the other are this.", "tokens": [50364, 2227, 307, 341, 644, 293, 264, 661, 366, 341, 13, 50546], "temperature": 0.0, "avg_logprob": -0.24277019500732422, "compression_ratio": 1.507936507936508, "no_speech_prob": 0.010566215962171555}, {"id": 186, "seek": 92964, "start": 933.28, "end": 936.52, "text": " So you can better understand why it is so.", "tokens": [50546, 407, 291, 393, 1101, 1223, 983, 309, 307, 370, 13, 50708], "temperature": 0.0, "avg_logprob": -0.24277019500732422, "compression_ratio": 1.507936507936508, "no_speech_prob": 0.010566215962171555}, {"id": 187, "seek": 92964, "start": 936.52, "end": 937.52, "text": " Okay.", "tokens": [50708, 1033, 13, 50758], "temperature": 0.0, "avg_logprob": -0.24277019500732422, "compression_ratio": 1.507936507936508, "no_speech_prob": 0.010566215962171555}, {"id": 188, "seek": 92964, "start": 937.52, "end": 942.4, "text": " I will drop this Monte Hall problem which is well known.", "tokens": [50758, 286, 486, 3270, 341, 38105, 5434, 1154, 597, 307, 731, 2570, 13, 51002], "temperature": 0.0, "avg_logprob": -0.24277019500732422, "compression_ratio": 1.507936507936508, "no_speech_prob": 0.010566215962171555}, {"id": 189, "seek": 92964, "start": 942.4, "end": 947.24, "text": " You can read that after the session offline.", "tokens": [51002, 509, 393, 1401, 300, 934, 264, 5481, 21857, 13, 51244], "temperature": 0.0, "avg_logprob": -0.24277019500732422, "compression_ratio": 1.507936507936508, "no_speech_prob": 0.010566215962171555}, {"id": 190, "seek": 92964, "start": 947.24, "end": 948.24, "text": " Okay.", "tokens": [51244, 1033, 13, 51294], "temperature": 0.0, "avg_logprob": -0.24277019500732422, "compression_ratio": 1.507936507936508, "no_speech_prob": 0.010566215962171555}, {"id": 191, "seek": 92964, "start": 948.24, "end": 951.3199999999999, "text": " Let's go back to the initial problem.", "tokens": [51294, 961, 311, 352, 646, 281, 264, 5883, 1154, 13, 51448], "temperature": 0.0, "avg_logprob": -0.24277019500732422, "compression_ratio": 1.507936507936508, "no_speech_prob": 0.010566215962171555}, {"id": 192, "seek": 92964, "start": 951.3199999999999, "end": 954.16, "text": " So okay.", "tokens": [51448, 407, 1392, 13, 51590], "temperature": 0.0, "avg_logprob": -0.24277019500732422, "compression_ratio": 1.507936507936508, "no_speech_prob": 0.010566215962171555}, {"id": 193, "seek": 92964, "start": 954.16, "end": 958.0, "text": " First I change the display options.", "tokens": [51590, 2386, 286, 1319, 264, 4674, 3956, 13, 51782], "temperature": 0.0, "avg_logprob": -0.24277019500732422, "compression_ratio": 1.507936507936508, "no_speech_prob": 0.010566215962171555}, {"id": 194, "seek": 95800, "start": 958.0, "end": 965.24, "text": " So the, first we define the pure probabilities like that.", "tokens": [50364, 407, 264, 11, 700, 321, 6964, 264, 6075, 33783, 411, 300, 13, 50726], "temperature": 0.0, "avg_logprob": -0.3112935543060303, "compression_ratio": 1.5360824742268042, "no_speech_prob": 0.002780409064143896}, {"id": 195, "seek": 95800, "start": 965.24, "end": 970.76, "text": " So here I ask Leah to display the probability in one line because it's more convenient in", "tokens": [50726, 407, 510, 286, 1029, 38591, 281, 4674, 264, 8482, 294, 472, 1622, 570, 309, 311, 544, 10851, 294, 51002], "temperature": 0.0, "avg_logprob": -0.3112935543060303, "compression_ratio": 1.5360824742268042, "no_speech_prob": 0.002780409064143896}, {"id": 196, "seek": 95800, "start": 970.76, "end": 973.24, "text": " this case and as a percentage.", "tokens": [51002, 341, 1389, 293, 382, 257, 9668, 13, 51126], "temperature": 0.0, "avg_logprob": -0.3112935543060303, "compression_ratio": 1.5360824742268042, "no_speech_prob": 0.002780409064143896}, {"id": 197, "seek": 95800, "start": 973.24, "end": 974.24, "text": " Okay.", "tokens": [51126, 1033, 13, 51176], "temperature": 0.0, "avg_logprob": -0.3112935543060303, "compression_ratio": 1.5360824742268042, "no_speech_prob": 0.002780409064143896}, {"id": 198, "seek": 95800, "start": 974.24, "end": 979.64, "text": " So we have like this and we see, okay, colon and mustard.", "tokens": [51176, 407, 321, 362, 411, 341, 293, 321, 536, 11, 1392, 11, 8255, 293, 23659, 13, 51446], "temperature": 0.0, "avg_logprob": -0.3112935543060303, "compression_ratio": 1.5360824742268042, "no_speech_prob": 0.002780409064143896}, {"id": 199, "seek": 95800, "start": 979.64, "end": 986.36, "text": " Our priority is the killer, the most likely the killer.", "tokens": [51446, 2621, 9365, 307, 264, 13364, 11, 264, 881, 3700, 264, 13364, 13, 51782], "temperature": 0.0, "avg_logprob": -0.3112935543060303, "compression_ratio": 1.5360824742268042, "no_speech_prob": 0.002780409064143896}, {"id": 200, "seek": 98636, "start": 987.36, "end": 988.36, "text": " Okay.", "tokens": [50414, 1033, 13, 50464], "temperature": 0.0, "avg_logprob": -0.22473472772642625, "compression_ratio": 1.671875, "no_speech_prob": 0.007585118990391493}, {"id": 201, "seek": 98636, "start": 988.36, "end": 994.72, "text": " Let's now try to write down the different information we have.", "tokens": [50464, 961, 311, 586, 853, 281, 2464, 760, 264, 819, 1589, 321, 362, 13, 50782], "temperature": 0.0, "avg_logprob": -0.22473472772642625, "compression_ratio": 1.671875, "no_speech_prob": 0.007585118990391493}, {"id": 202, "seek": 98636, "start": 994.72, "end": 998.44, "text": " So if Mrs. White is the killer she'll be absent with probability ninety percent.", "tokens": [50782, 407, 498, 9814, 13, 5552, 307, 264, 13364, 750, 603, 312, 25185, 365, 8482, 25063, 3043, 13, 50968], "temperature": 0.0, "avg_logprob": -0.22473472772642625, "compression_ratio": 1.671875, "no_speech_prob": 0.007585118990391493}, {"id": 203, "seek": 98636, "start": 998.44, "end": 1000.8000000000001, "text": " So I define here a variable.", "tokens": [50968, 407, 286, 6964, 510, 257, 7006, 13, 51086], "temperature": 0.0, "avg_logprob": -0.22473472772642625, "compression_ratio": 1.671875, "no_speech_prob": 0.007585118990391493}, {"id": 204, "seek": 98636, "start": 1000.8000000000001, "end": 1005.28, "text": " Mrs. White is absent using the if as we've seen before.", "tokens": [51086, 9814, 13, 5552, 307, 25185, 1228, 264, 498, 382, 321, 600, 1612, 949, 13, 51310], "temperature": 0.0, "avg_logprob": -0.22473472772642625, "compression_ratio": 1.671875, "no_speech_prob": 0.007585118990391493}, {"id": 205, "seek": 98636, "start": 1005.28, "end": 1013.44, "text": " I put the condition if the killer is Mrs. White then she'll be absent with ninety five", "tokens": [51310, 286, 829, 264, 4188, 498, 264, 13364, 307, 9814, 13, 5552, 550, 750, 603, 312, 25185, 365, 25063, 1732, 51718], "temperature": 0.0, "avg_logprob": -0.22473472772642625, "compression_ratio": 1.671875, "no_speech_prob": 0.007585118990391493}, {"id": 206, "seek": 101344, "start": 1013.44, "end": 1018.0400000000001, "text": " percent else twenty five, twenty percent.", "tokens": [50364, 3043, 1646, 7699, 1732, 11, 7699, 3043, 13, 50594], "temperature": 0.0, "avg_logprob": -0.26392080783843996, "compression_ratio": 1.549738219895288, "no_speech_prob": 0.0040205093100667}, {"id": 207, "seek": 101344, "start": 1018.0400000000001, "end": 1019.0400000000001, "text": " Sorry.", "tokens": [50594, 4919, 13, 50644], "temperature": 0.0, "avg_logprob": -0.26392080783843996, "compression_ratio": 1.549738219895288, "no_speech_prob": 0.0040205093100667}, {"id": 208, "seek": 101344, "start": 1019.0400000000001, "end": 1020.0400000000001, "text": " Okay.", "tokens": [50644, 1033, 13, 50694], "temperature": 0.0, "avg_logprob": -0.26392080783843996, "compression_ratio": 1.549738219895288, "no_speech_prob": 0.0040205093100667}, {"id": 209, "seek": 101344, "start": 1020.0400000000001, "end": 1024.52, "text": " This is the percentage that Mrs. White is absent.", "tokens": [50694, 639, 307, 264, 9668, 300, 9814, 13, 5552, 307, 25185, 13, 50918], "temperature": 0.0, "avg_logprob": -0.26392080783843996, "compression_ratio": 1.549738219895288, "no_speech_prob": 0.0040205093100667}, {"id": 210, "seek": 101344, "start": 1024.52, "end": 1029.04, "text": " But it's not very interesting because we, we, we are more interested about who is the", "tokens": [50918, 583, 309, 311, 406, 588, 1880, 570, 321, 11, 321, 11, 321, 366, 544, 3102, 466, 567, 307, 264, 51144], "temperature": 0.0, "avg_logprob": -0.26392080783843996, "compression_ratio": 1.549738219895288, "no_speech_prob": 0.0040205093100667}, {"id": 211, "seek": 101344, "start": 1029.04, "end": 1032.92, "text": " killer but we will see what will happen later.", "tokens": [51144, 13364, 457, 321, 486, 536, 437, 486, 1051, 1780, 13, 51338], "temperature": 0.0, "avg_logprob": -0.26392080783843996, "compression_ratio": 1.549738219895288, "no_speech_prob": 0.0040205093100667}, {"id": 212, "seek": 101344, "start": 1032.92, "end": 1041.3200000000002, "text": " And then we can continue and define other rules like this.", "tokens": [51338, 400, 550, 321, 393, 2354, 293, 6964, 661, 4474, 411, 341, 13, 51758], "temperature": 0.0, "avg_logprob": -0.26392080783843996, "compression_ratio": 1.549738219895288, "no_speech_prob": 0.0040205093100667}, {"id": 213, "seek": 104132, "start": 1041.32, "end": 1047.36, "text": " If Mrs. Peacock is innocent she knows who's the killer with probability seventy five percent.", "tokens": [50364, 759, 9814, 13, 2396, 326, 1560, 307, 13171, 750, 3255, 567, 311, 264, 13364, 365, 8482, 25662, 1732, 3043, 13, 50666], "temperature": 0.0, "avg_logprob": -0.18047829133918486, "compression_ratio": 1.7172774869109948, "no_speech_prob": 0.0472153015434742}, {"id": 214, "seek": 104132, "start": 1047.36, "end": 1053.6799999999998, "text": " So you see here there is a missing information which is the else part but we assume that", "tokens": [50666, 407, 291, 536, 510, 456, 307, 257, 5361, 1589, 597, 307, 264, 1646, 644, 457, 321, 6552, 300, 50982], "temperature": 0.0, "avg_logprob": -0.18047829133918486, "compression_ratio": 1.7172774869109948, "no_speech_prob": 0.0472153015434742}, {"id": 215, "seek": 104132, "start": 1053.6799999999998, "end": 1063.4399999999998, "text": " Mrs. Peacock is not insane and if she's the killer then she knows who's the killer hopefully.", "tokens": [50982, 9814, 13, 2396, 326, 1560, 307, 406, 10838, 293, 498, 750, 311, 264, 13364, 550, 750, 3255, 567, 311, 264, 13364, 4696, 13, 51470], "temperature": 0.0, "avg_logprob": -0.18047829133918486, "compression_ratio": 1.7172774869109948, "no_speech_prob": 0.0472153015434742}, {"id": 216, "seek": 104132, "start": 1063.4399999999998, "end": 1067.04, "text": " So I put here the else part as one hundred percent.", "tokens": [51470, 407, 286, 829, 510, 264, 1646, 644, 382, 472, 3262, 3043, 13, 51650], "temperature": 0.0, "avg_logprob": -0.18047829133918486, "compression_ratio": 1.7172774869109948, "no_speech_prob": 0.0472153015434742}, {"id": 217, "seek": 106704, "start": 1067.28, "end": 1068.28, "text": " Okay.", "tokens": [50376, 1033, 13, 50426], "temperature": 0.0, "avg_logprob": -0.22070457195413523, "compression_ratio": 1.5436893203883495, "no_speech_prob": 0.01692638359963894}, {"id": 218, "seek": 106704, "start": 1068.28, "end": 1073.48, "text": " And then we can elaborate on more complex information like this one.", "tokens": [50426, 400, 550, 321, 393, 20945, 322, 544, 3997, 1589, 411, 341, 472, 13, 50686], "temperature": 0.0, "avg_logprob": -0.22070457195413523, "compression_ratio": 1.5436893203883495, "no_speech_prob": 0.01692638359963894}, {"id": 219, "seek": 106704, "start": 1073.48, "end": 1074.48, "text": " Okay.", "tokens": [50686, 1033, 13, 50736], "temperature": 0.0, "avg_logprob": -0.22070457195413523, "compression_ratio": 1.5436893203883495, "no_speech_prob": 0.01692638359963894}, {"id": 220, "seek": 106704, "start": 1074.48, "end": 1080.76, "text": " I will not detail but you see again it's quite, when you see the statement, the", "tokens": [50736, 286, 486, 406, 2607, 457, 291, 536, 797, 309, 311, 1596, 11, 562, 291, 536, 264, 5629, 11, 264, 51050], "temperature": 0.0, "avg_logprob": -0.22070457195413523, "compression_ratio": 1.5436893203883495, "no_speech_prob": 0.01692638359963894}, {"id": 221, "seek": 106704, "start": 1080.76, "end": 1086.08, "text": " tradition in LIA it's quite straightforward.", "tokens": [51050, 6994, 294, 441, 6914, 309, 311, 1596, 15325, 13, 51316], "temperature": 0.0, "avg_logprob": -0.22070457195413523, "compression_ratio": 1.5436893203883495, "no_speech_prob": 0.01692638359963894}, {"id": 222, "seek": 106704, "start": 1086.08, "end": 1087.3999999999999, "text": " And the last one is here.", "tokens": [51316, 400, 264, 1036, 472, 307, 510, 13, 51382], "temperature": 0.0, "avg_logprob": -0.22070457195413523, "compression_ratio": 1.5436893203883495, "no_speech_prob": 0.01692638359963894}, {"id": 223, "seek": 106704, "start": 1087.3999999999999, "end": 1094.08, "text": " So what have we done here is to define what we call the Bayesian network which put the", "tokens": [51382, 407, 437, 362, 321, 1096, 510, 307, 281, 6964, 437, 321, 818, 264, 7840, 42434, 3209, 597, 829, 264, 51716], "temperature": 0.0, "avg_logprob": -0.22070457195413523, "compression_ratio": 1.5436893203883495, "no_speech_prob": 0.01692638359963894}, {"id": 224, "seek": 109408, "start": 1094.08, "end": 1097.84, "text": " relation between different random variables.", "tokens": [50364, 9721, 1296, 819, 4974, 9102, 13, 50552], "temperature": 0.0, "avg_logprob": -0.13171749599909377, "compression_ratio": 1.4795321637426901, "no_speech_prob": 0.007312310393899679}, {"id": 225, "seek": 109408, "start": 1097.84, "end": 1105.48, "text": " What is interesting with this kind of network is that if you get evidence about something", "tokens": [50552, 708, 307, 1880, 365, 341, 733, 295, 3209, 307, 300, 498, 291, 483, 4467, 466, 746, 50934], "temperature": 0.0, "avg_logprob": -0.13171749599909377, "compression_ratio": 1.4795321637426901, "no_speech_prob": 0.007312310393899679}, {"id": 226, "seek": 109408, "start": 1105.48, "end": 1113.6399999999999, "text": " you can go backwards and refine the probability to be the killer.", "tokens": [50934, 291, 393, 352, 12204, 293, 33906, 264, 8482, 281, 312, 264, 13364, 13, 51342], "temperature": 0.0, "avg_logprob": -0.13171749599909377, "compression_ratio": 1.4795321637426901, "no_speech_prob": 0.007312310393899679}, {"id": 227, "seek": 109408, "start": 1113.6399999999999, "end": 1118.32, "text": " So for that, okay, I define a list of evidence here.", "tokens": [51342, 407, 337, 300, 11, 1392, 11, 286, 6964, 257, 1329, 295, 4467, 510, 13, 51576], "temperature": 0.0, "avg_logprob": -0.13171749599909377, "compression_ratio": 1.4795321637426901, "no_speech_prob": 0.007312310393899679}, {"id": 228, "seek": 111832, "start": 1118.32, "end": 1126.4399999999998, "text": " So first of all it's empty and the conditional probability is the same as before because", "tokens": [50364, 407, 700, 295, 439, 309, 311, 6707, 293, 264, 27708, 8482, 307, 264, 912, 382, 949, 570, 50770], "temperature": 0.0, "avg_logprob": -0.19166476076299493, "compression_ratio": 1.6288659793814433, "no_speech_prob": 0.00807929690927267}, {"id": 229, "seek": 111832, "start": 1126.4399999999998, "end": 1127.84, "text": " I have no new evidence.", "tokens": [50770, 286, 362, 572, 777, 4467, 13, 50840], "temperature": 0.0, "avg_logprob": -0.19166476076299493, "compression_ratio": 1.6288659793814433, "no_speech_prob": 0.00807929690927267}, {"id": 230, "seek": 111832, "start": 1127.84, "end": 1132.56, "text": " So imagine now that Mrs. White is absent.", "tokens": [50840, 407, 3811, 586, 300, 9814, 13, 5552, 307, 25185, 13, 51076], "temperature": 0.0, "avg_logprob": -0.19166476076299493, "compression_ratio": 1.6288659793814433, "no_speech_prob": 0.00807929690927267}, {"id": 231, "seek": 111832, "start": 1132.56, "end": 1137.8799999999999, "text": " I can add it to the evidence and define a new conditional probability.", "tokens": [51076, 286, 393, 909, 309, 281, 264, 4467, 293, 6964, 257, 777, 27708, 8482, 13, 51342], "temperature": 0.0, "avg_logprob": -0.19166476076299493, "compression_ratio": 1.6288659793814433, "no_speech_prob": 0.00807929690927267}, {"id": 232, "seek": 111832, "start": 1137.8799999999999, "end": 1141.52, "text": " So you see it change a bit.", "tokens": [51342, 407, 291, 536, 309, 1319, 257, 857, 13, 51524], "temperature": 0.0, "avg_logprob": -0.19166476076299493, "compression_ratio": 1.6288659793814433, "no_speech_prob": 0.00807929690927267}, {"id": 233, "seek": 111832, "start": 1141.52, "end": 1144.72, "text": " Evidence two added to the previous one.", "tokens": [51524, 5689, 2778, 732, 3869, 281, 264, 3894, 472, 13, 51684], "temperature": 0.0, "avg_logprob": -0.19166476076299493, "compression_ratio": 1.6288659793814433, "no_speech_prob": 0.00807929690927267}, {"id": 234, "seek": 111832, "start": 1144.72, "end": 1146.4399999999998, "text": " Mrs. Peacock is drunk.", "tokens": [51684, 9814, 13, 2396, 326, 1560, 307, 11192, 13, 51770], "temperature": 0.0, "avg_logprob": -0.19166476076299493, "compression_ratio": 1.6288659793814433, "no_speech_prob": 0.00807929690927267}, {"id": 235, "seek": 114644, "start": 1146.56, "end": 1147.56, "text": " Okay.", "tokens": [50370, 1033, 13, 50420], "temperature": 0.0, "avg_logprob": -0.25559436984178496, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.016173921525478363}, {"id": 236, "seek": 114644, "start": 1147.56, "end": 1153.4, "text": " I add this information and I get new probability and so on.", "tokens": [50420, 286, 909, 341, 1589, 293, 286, 483, 777, 8482, 293, 370, 322, 13, 50712], "temperature": 0.0, "avg_logprob": -0.25559436984178496, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.016173921525478363}, {"id": 237, "seek": 114644, "start": 1153.4, "end": 1157.4, "text": " Professor Plum accuses Colin and Mustard.", "tokens": [50712, 8419, 2149, 449, 11168, 279, 29253, 293, 13252, 515, 13, 50912], "temperature": 0.0, "avg_logprob": -0.25559436984178496, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.016173921525478363}, {"id": 238, "seek": 114644, "start": 1157.4, "end": 1162.3200000000002, "text": " And finally we know that the killer is a woman.", "tokens": [50912, 400, 2721, 321, 458, 300, 264, 13364, 307, 257, 3059, 13, 51158], "temperature": 0.0, "avg_logprob": -0.25559436984178496, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.016173921525478363}, {"id": 239, "seek": 114644, "start": 1162.3200000000002, "end": 1168.1200000000001, "text": " So for that I use here the Python start with Mrs.", "tokens": [51158, 407, 337, 300, 286, 764, 510, 264, 15329, 722, 365, 9814, 13, 51448], "temperature": 0.0, "avg_logprob": -0.25559436984178496, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.016173921525478363}, {"id": 240, "seek": 114644, "start": 1168.1200000000001, "end": 1176.0, "text": " because it's a handy way to say given the suspects that the killer is a woman, I add", "tokens": [51448, 570, 309, 311, 257, 13239, 636, 281, 584, 2212, 264, 35667, 300, 264, 13364, 307, 257, 3059, 11, 286, 909, 51842], "temperature": 0.0, "avg_logprob": -0.25559436984178496, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.016173921525478363}, {"id": 241, "seek": 117600, "start": 1176.08, "end": 1185.64, "text": " it to the evidence like that and you see, okay, there is a new probability.", "tokens": [50368, 309, 281, 264, 4467, 411, 300, 293, 291, 536, 11, 1392, 11, 456, 307, 257, 777, 8482, 13, 50846], "temperature": 0.0, "avg_logprob": -0.2978710447038923, "compression_ratio": 1.3076923076923077, "no_speech_prob": 0.0044477470219135284}, {"id": 242, "seek": 117600, "start": 1185.64, "end": 1190.48, "text": " So there are just two suspects remaining, two women and Mrs.", "tokens": [50846, 407, 456, 366, 445, 732, 35667, 8877, 11, 732, 2266, 293, 9814, 13, 51088], "temperature": 0.0, "avg_logprob": -0.2978710447038923, "compression_ratio": 1.3076923076923077, "no_speech_prob": 0.0044477470219135284}, {"id": 243, "seek": 117600, "start": 1190.48, "end": 1195.12, "text": " White is likely the killer.", "tokens": [51088, 5552, 307, 3700, 264, 13364, 13, 51320], "temperature": 0.0, "avg_logprob": -0.2978710447038923, "compression_ratio": 1.3076923076923077, "no_speech_prob": 0.0044477470219135284}, {"id": 244, "seek": 117600, "start": 1195.12, "end": 1196.12, "text": " Okay.", "tokens": [51320, 1033, 13, 51370], "temperature": 0.0, "avg_logprob": -0.2978710447038923, "compression_ratio": 1.3076923076923077, "no_speech_prob": 0.0044477470219135284}, {"id": 245, "seek": 119612, "start": 1196.76, "end": 1201.76, "text": " Yeah.", "tokens": [50396, 865, 13, 50646], "temperature": 0.0, "avg_logprob": -0.2755468031939338, "compression_ratio": 1.4294117647058824, "no_speech_prob": 0.021502505987882614}, {"id": 246, "seek": 119612, "start": 1201.76, "end": 1210.28, "text": " Maybe you can consider this as a game but sometimes probability can play a very important", "tokens": [50646, 2704, 291, 393, 1949, 341, 382, 257, 1216, 457, 2171, 8482, 393, 862, 257, 588, 1021, 51072], "temperature": 0.0, "avg_logprob": -0.2755468031939338, "compression_ratio": 1.4294117647058824, "no_speech_prob": 0.021502505987882614}, {"id": 247, "seek": 119612, "start": 1210.28, "end": 1212.3999999999999, "text": " role in some trials.", "tokens": [51072, 3090, 294, 512, 12450, 13, 51178], "temperature": 0.0, "avg_logprob": -0.2755468031939338, "compression_ratio": 1.4294117647058824, "no_speech_prob": 0.021502505987882614}, {"id": 248, "seek": 119612, "start": 1212.3999999999999, "end": 1215.1999999999998, "text": " So long time ago there was the Dreyfus Affair.", "tokens": [51178, 407, 938, 565, 2057, 456, 390, 264, 413, 7950, 69, 301, 12840, 1246, 13, 51318], "temperature": 0.0, "avg_logprob": -0.2755468031939338, "compression_ratio": 1.4294117647058824, "no_speech_prob": 0.021502505987882614}, {"id": 249, "seek": 119612, "start": 1215.1999999999998, "end": 1224.3999999999999, "text": " There was a big flow of a so-called expert that makes a mistake in this affair.", "tokens": [51318, 821, 390, 257, 955, 3095, 295, 257, 370, 12, 11880, 5844, 300, 1669, 257, 6146, 294, 341, 22987, 13, 51778], "temperature": 0.0, "avg_logprob": -0.2755468031939338, "compression_ratio": 1.4294117647058824, "no_speech_prob": 0.021502505987882614}, {"id": 250, "seek": 122440, "start": 1224.4, "end": 1231.72, "text": " And also more recently, Selik Larch case where also there is a bad reasoning about probability.", "tokens": [50364, 400, 611, 544, 3938, 11, 10736, 1035, 441, 1178, 1389, 689, 611, 456, 307, 257, 1578, 21577, 466, 8482, 13, 50730], "temperature": 0.0, "avg_logprob": -0.3691516051421294, "compression_ratio": 1.427807486631016, "no_speech_prob": 0.013150989077985287}, {"id": 251, "seek": 122440, "start": 1231.72, "end": 1233.1200000000001, "text": " Okay.", "tokens": [50730, 1033, 13, 50800], "temperature": 0.0, "avg_logprob": -0.3691516051421294, "compression_ratio": 1.427807486631016, "no_speech_prob": 0.013150989077985287}, {"id": 252, "seek": 122440, "start": 1233.1200000000001, "end": 1238.3200000000002, "text": " So I want to mention also that Leah is able to do symbolic calculation.", "tokens": [50800, 407, 286, 528, 281, 2152, 611, 300, 38591, 307, 1075, 281, 360, 25755, 17108, 13, 51060], "temperature": 0.0, "avg_logprob": -0.3691516051421294, "compression_ratio": 1.427807486631016, "no_speech_prob": 0.013150989077985287}, {"id": 253, "seek": 122440, "start": 1238.3200000000002, "end": 1247.4, "text": " So by using the SIMPY module that maybe you know, so it's very easy.", "tokens": [51060, 407, 538, 1228, 264, 24738, 47, 56, 10088, 300, 1310, 291, 458, 11, 370, 309, 311, 588, 1858, 13, 51514], "temperature": 0.0, "avg_logprob": -0.3691516051421294, "compression_ratio": 1.427807486631016, "no_speech_prob": 0.013150989077985287}, {"id": 254, "seek": 122440, "start": 1247.4, "end": 1250.6000000000001, "text": " It's the same interface.", "tokens": [51514, 467, 311, 264, 912, 9226, 13, 51674], "temperature": 0.0, "avg_logprob": -0.3691516051421294, "compression_ratio": 1.427807486631016, "no_speech_prob": 0.013150989077985287}, {"id": 255, "seek": 125060, "start": 1250.6, "end": 1258.56, "text": " So instead of number you put variable name between quotes like this and you have probability", "tokens": [50364, 407, 2602, 295, 1230, 291, 829, 7006, 1315, 1296, 19963, 411, 341, 293, 291, 362, 8482, 50762], "temperature": 0.0, "avg_logprob": -0.21004087784711054, "compression_ratio": 1.4709302325581395, "no_speech_prob": 0.004474597983062267}, {"id": 256, "seek": 125060, "start": 1258.56, "end": 1261.32, "text": " defined with formula.", "tokens": [50762, 7642, 365, 8513, 13, 50900], "temperature": 0.0, "avg_logprob": -0.21004087784711054, "compression_ratio": 1.4709302325581395, "no_speech_prob": 0.004474597983062267}, {"id": 257, "seek": 125060, "start": 1261.32, "end": 1268.28, "text": " So you can redo all the same exercise and you will get formulas to be the killer, etc.", "tokens": [50900, 407, 291, 393, 29956, 439, 264, 912, 5380, 293, 291, 486, 483, 30546, 281, 312, 264, 13364, 11, 5183, 13, 51248], "temperature": 0.0, "avg_logprob": -0.21004087784711054, "compression_ratio": 1.4709302325581395, "no_speech_prob": 0.004474597983062267}, {"id": 258, "seek": 125060, "start": 1268.28, "end": 1269.9599999999998, "text": " So a small example here.", "tokens": [51248, 407, 257, 1359, 1365, 510, 13, 51332], "temperature": 0.0, "avg_logprob": -0.21004087784711054, "compression_ratio": 1.4709302325581395, "no_speech_prob": 0.004474597983062267}, {"id": 259, "seek": 125060, "start": 1269.9599999999998, "end": 1270.9599999999998, "text": " Okay.", "tokens": [51332, 1033, 13, 51382], "temperature": 0.0, "avg_logprob": -0.21004087784711054, "compression_ratio": 1.4709302325581395, "no_speech_prob": 0.004474597983062267}, {"id": 260, "seek": 125060, "start": 1270.9599999999998, "end": 1272.8, "text": " I don't detail here.", "tokens": [51382, 286, 500, 380, 2607, 510, 13, 51474], "temperature": 0.0, "avg_logprob": -0.21004087784711054, "compression_ratio": 1.4709302325581395, "no_speech_prob": 0.004474597983062267}, {"id": 261, "seek": 127280, "start": 1273.8, "end": 1287.08, "text": " It's a binomial function here with P and here I calculate a conditional probability", "tokens": [50414, 467, 311, 257, 5171, 47429, 2445, 510, 365, 430, 293, 510, 286, 8873, 257, 27708, 8482, 51078], "temperature": 0.0, "avg_logprob": -0.2669433169894748, "compression_ratio": 1.3358778625954197, "no_speech_prob": 0.06492482125759125}, {"id": 262, "seek": 127280, "start": 1287.08, "end": 1290.76, "text": " and it displays me a nice formula.", "tokens": [51078, 293, 309, 20119, 385, 257, 1481, 8513, 13, 51262], "temperature": 0.0, "avg_logprob": -0.2669433169894748, "compression_ratio": 1.3358778625954197, "no_speech_prob": 0.06492482125759125}, {"id": 263, "seek": 127280, "start": 1290.76, "end": 1295.8, "text": " So you can check offline if you want that it is correct.", "tokens": [51262, 407, 291, 393, 1520, 21857, 498, 291, 528, 300, 309, 307, 3006, 13, 51514], "temperature": 0.0, "avg_logprob": -0.2669433169894748, "compression_ratio": 1.3358778625954197, "no_speech_prob": 0.06492482125759125}, {"id": 264, "seek": 129580, "start": 1295.8, "end": 1296.96, "text": " Okay.", "tokens": [50364, 1033, 13, 50422], "temperature": 0.0, "avg_logprob": -0.17048560448412625, "compression_ratio": 1.3537414965986394, "no_speech_prob": 0.011841806583106518}, {"id": 265, "seek": 129580, "start": 1296.96, "end": 1307.52, "text": " I want just to finish about my bullshit generator which was made 15 years ago.", "tokens": [50422, 286, 528, 445, 281, 2413, 466, 452, 22676, 19265, 597, 390, 1027, 2119, 924, 2057, 13, 50950], "temperature": 0.0, "avg_logprob": -0.17048560448412625, "compression_ratio": 1.3537414965986394, "no_speech_prob": 0.011841806583106518}, {"id": 266, "seek": 129580, "start": 1307.52, "end": 1316.9199999999998, "text": " So here the goal is to produce sentences at random based on a list of words and a list", "tokens": [50950, 407, 510, 264, 3387, 307, 281, 5258, 16579, 412, 4974, 2361, 322, 257, 1329, 295, 2283, 293, 257, 1329, 51420], "temperature": 0.0, "avg_logprob": -0.17048560448412625, "compression_ratio": 1.3537414965986394, "no_speech_prob": 0.011841806583106518}, {"id": 267, "seek": 129580, "start": 1316.9199999999998, "end": 1321.36, "text": " of grammar rules like this.", "tokens": [51420, 295, 22317, 4474, 411, 341, 13, 51642], "temperature": 0.0, "avg_logprob": -0.17048560448412625, "compression_ratio": 1.3537414965986394, "no_speech_prob": 0.011841806583106518}, {"id": 268, "seek": 132136, "start": 1321.36, "end": 1330.08, "text": " Then you see that I put here a probability on each grammar rule so that the most simple", "tokens": [50364, 1396, 291, 536, 300, 286, 829, 510, 257, 8482, 322, 1184, 22317, 4978, 370, 300, 264, 881, 2199, 50800], "temperature": 0.0, "avg_logprob": -0.3417597198486328, "compression_ratio": 1.3255813953488371, "no_speech_prob": 0.013464282266795635}, {"id": 269, "seek": 132136, "start": 1330.08, "end": 1340.12, "text": " rule are used preferably to avoid to get to long sentences.", "tokens": [50800, 4978, 366, 1143, 45916, 281, 5042, 281, 483, 281, 938, 16579, 13, 51302], "temperature": 0.0, "avg_logprob": -0.3417597198486328, "compression_ratio": 1.3255813953488371, "no_speech_prob": 0.013464282266795635}, {"id": 270, "seek": 132136, "start": 1340.12, "end": 1341.12, "text": " So yeah.", "tokens": [51302, 407, 1338, 13, 51352], "temperature": 0.0, "avg_logprob": -0.3417597198486328, "compression_ratio": 1.3255813953488371, "no_speech_prob": 0.013464282266795635}, {"id": 271, "seek": 132136, "start": 1341.12, "end": 1342.12, "text": " Okay.", "tokens": [51352, 1033, 13, 51402], "temperature": 0.0, "avg_logprob": -0.3417597198486328, "compression_ratio": 1.3255813953488371, "no_speech_prob": 0.013464282266795635}, {"id": 272, "seek": 132136, "start": 1342.12, "end": 1350.6, "text": " I get...", "tokens": [51402, 286, 483, 485, 51826], "temperature": 0.0, "avg_logprob": -0.3417597198486328, "compression_ratio": 1.3255813953488371, "no_speech_prob": 0.013464282266795635}, {"id": 273, "seek": 135060, "start": 1350.6, "end": 1352.0, "text": " So it has produced...", "tokens": [50364, 407, 309, 575, 7126, 485, 50434], "temperature": 0.0, "avg_logprob": -0.5878068260524584, "compression_ratio": 1.2736842105263158, "no_speech_prob": 0.02711647003889084}, {"id": 274, "seek": 135060, "start": 1352.0, "end": 1356.6, "text": " I don't know why it's...", "tokens": [50434, 286, 500, 380, 458, 983, 309, 311, 485, 50664], "temperature": 0.0, "avg_logprob": -0.5878068260524584, "compression_ratio": 1.2736842105263158, "no_speech_prob": 0.02711647003889084}, {"id": 275, "seek": 135060, "start": 1356.6, "end": 1360.9599999999998, "text": " Okay.", "tokens": [50664, 1033, 13, 50882], "temperature": 0.0, "avg_logprob": -0.5878068260524584, "compression_ratio": 1.2736842105263158, "no_speech_prob": 0.02711647003889084}, {"id": 276, "seek": 135060, "start": 1360.9599999999998, "end": 1368.6, "text": " So maybe I don't know what happens but...", "tokens": [50882, 407, 1310, 286, 500, 380, 458, 437, 2314, 457, 485, 51264], "temperature": 0.0, "avg_logprob": -0.5878068260524584, "compression_ratio": 1.2736842105263158, "no_speech_prob": 0.02711647003889084}, {"id": 277, "seek": 135060, "start": 1368.6, "end": 1373.84, "text": " Okay.", "tokens": [51264, 1033, 13, 51526], "temperature": 0.0, "avg_logprob": -0.5878068260524584, "compression_ratio": 1.2736842105263158, "no_speech_prob": 0.02711647003889084}, {"id": 278, "seek": 135060, "start": 1373.84, "end": 1377.1999999999998, "text": " I restart my kernel.", "tokens": [51526, 286, 21022, 452, 28256, 13, 51694], "temperature": 0.0, "avg_logprob": -0.5878068260524584, "compression_ratio": 1.2736842105263158, "no_speech_prob": 0.02711647003889084}, {"id": 279, "seek": 137720, "start": 1378.2, "end": 1388.2, "text": " Normally it's supposed to speak and to write down sentences but...", "tokens": [50414, 17424, 309, 311, 3442, 281, 1710, 293, 281, 2464, 760, 16579, 457, 485, 50914], "temperature": 0.0, "avg_logprob": -0.5397694327614524, "compression_ratio": 1.1304347826086956, "no_speech_prob": 0.00787409394979477}, {"id": 280, "seek": 137720, "start": 1388.2, "end": 1391.68, "text": " Okay.", "tokens": [50914, 1033, 13, 51088], "temperature": 0.0, "avg_logprob": -0.5397694327614524, "compression_ratio": 1.1304347826086956, "no_speech_prob": 0.00787409394979477}, {"id": 281, "seek": 137720, "start": 1391.68, "end": 1397.28, "text": " Anyway.", "tokens": [51088, 5684, 13, 51368], "temperature": 0.0, "avg_logprob": -0.5397694327614524, "compression_ratio": 1.1304347826086956, "no_speech_prob": 0.00787409394979477}, {"id": 282, "seek": 137720, "start": 1397.28, "end": 1400.4, "text": " You can play that also.", "tokens": [51368, 509, 393, 862, 300, 611, 13, 51524], "temperature": 0.0, "avg_logprob": -0.5397694327614524, "compression_ratio": 1.1304347826086956, "no_speech_prob": 0.00787409394979477}, {"id": 283, "seek": 140040, "start": 1400.4, "end": 1407.6000000000001, "text": " The Python code is really small so you can try it at yourself.", "tokens": [50364, 440, 15329, 3089, 307, 534, 1359, 370, 291, 393, 853, 309, 412, 1803, 13, 50724], "temperature": 0.0, "avg_logprob": -0.3648008240593804, "compression_ratio": 0.9393939393939394, "no_speech_prob": 0.022952724248170853}, {"id": 284, "seek": 140760, "start": 1408.6, "end": 1410.6, "text": " Oh yeah.", "tokens": [50414, 876, 1338, 13, 50514], "temperature": 0.0, "avg_logprob": -0.6635565757751465, "compression_ratio": 1.0, "no_speech_prob": 0.03846516087651253}, {"id": 285, "seek": 140760, "start": 1410.6, "end": 1411.6, "text": " Okay.", "tokens": [50514, 1033, 13, 50564], "temperature": 0.0, "avg_logprob": -0.6635565757751465, "compression_ratio": 1.0, "no_speech_prob": 0.03846516087651253}, {"id": 286, "seek": 140760, "start": 1411.6, "end": 1419.6, "text": " Of course I didn't import LIA.", "tokens": [50564, 2720, 1164, 286, 994, 380, 974, 441, 6914, 13, 50964], "temperature": 0.0, "avg_logprob": -0.6635565757751465, "compression_ratio": 1.0, "no_speech_prob": 0.03846516087651253}, {"id": 287, "seek": 140760, "start": 1419.6, "end": 1425.6, "text": " Okay.", "tokens": [50964, 1033, 13, 51264], "temperature": 0.0, "avg_logprob": -0.6635565757751465, "compression_ratio": 1.0, "no_speech_prob": 0.03846516087651253}, {"id": 288, "seek": 140760, "start": 1425.6, "end": 1433.9599999999998, "text": " That's it.", "tokens": [51264, 663, 311, 309, 13, 51682], "temperature": 0.0, "avg_logprob": -0.6635565757751465, "compression_ratio": 1.0, "no_speech_prob": 0.03846516087651253}, {"id": 289, "seek": 143396, "start": 1433.96, "end": 1442.24, "text": " But anyway, sorry for the small interruptions but I think we don't have time for questions", "tokens": [50364, 583, 4033, 11, 2597, 337, 264, 1359, 12729, 626, 457, 286, 519, 321, 500, 380, 362, 565, 337, 1651, 50778], "temperature": 0.0, "avg_logprob": -0.27749842689150855, "compression_ratio": 1.5472972972972974, "no_speech_prob": 0.042125895619392395}, {"id": 290, "seek": 143396, "start": 1442.24, "end": 1443.24, "text": " or...", "tokens": [50778, 420, 485, 50828], "temperature": 0.0, "avg_logprob": -0.27749842689150855, "compression_ratio": 1.5472972972972974, "no_speech_prob": 0.042125895619392395}, {"id": 291, "seek": 143396, "start": 1443.24, "end": 1444.24, "text": " Maybe one question.", "tokens": [50828, 2704, 472, 1168, 13, 50878], "temperature": 0.0, "avg_logprob": -0.27749842689150855, "compression_ratio": 1.5472972972972974, "no_speech_prob": 0.042125895619392395}, {"id": 292, "seek": 143396, "start": 1444.24, "end": 1445.24, "text": " Maybe one question.", "tokens": [50878, 2704, 472, 1168, 13, 50928], "temperature": 0.0, "avg_logprob": -0.27749842689150855, "compression_ratio": 1.5472972972972974, "no_speech_prob": 0.042125895619392395}, {"id": 293, "seek": 143396, "start": 1445.24, "end": 1446.24, "text": " Okay.", "tokens": [50928, 1033, 13, 50978], "temperature": 0.0, "avg_logprob": -0.27749842689150855, "compression_ratio": 1.5472972972972974, "no_speech_prob": 0.042125895619392395}, {"id": 294, "seek": 143396, "start": 1446.24, "end": 1459.56, "text": " Thank you for the presentation.", "tokens": [50978, 1044, 291, 337, 264, 5860, 13, 51644], "temperature": 0.0, "avg_logprob": -0.27749842689150855, "compression_ratio": 1.5472972972972974, "no_speech_prob": 0.042125895619392395}, {"id": 295, "seek": 143396, "start": 1459.56, "end": 1462.8, "text": " I have indeed one question which is about performance.", "tokens": [51644, 286, 362, 6451, 472, 1168, 597, 307, 466, 3389, 13, 51806], "temperature": 0.0, "avg_logprob": -0.27749842689150855, "compression_ratio": 1.5472972972972974, "no_speech_prob": 0.042125895619392395}, {"id": 296, "seek": 146280, "start": 1462.8, "end": 1469.32, "text": " So do you have information about performance, your libraries compared to other libraries", "tokens": [50364, 407, 360, 291, 362, 1589, 466, 3389, 11, 428, 15148, 5347, 281, 661, 15148, 50690], "temperature": 0.0, "avg_logprob": -0.26830456382349915, "compression_ratio": 1.6515151515151516, "no_speech_prob": 0.04783133044838905}, {"id": 297, "seek": 146280, "start": 1469.32, "end": 1472.44, "text": " or yeah, what are your insights on that?", "tokens": [50690, 420, 1338, 11, 437, 366, 428, 14310, 322, 300, 30, 50846], "temperature": 0.0, "avg_logprob": -0.26830456382349915, "compression_ratio": 1.6515151515151516, "no_speech_prob": 0.04783133044838905}, {"id": 298, "seek": 146280, "start": 1472.44, "end": 1473.44, "text": " Yeah.", "tokens": [50846, 865, 13, 50896], "temperature": 0.0, "avg_logprob": -0.26830456382349915, "compression_ratio": 1.6515151515151516, "no_speech_prob": 0.04783133044838905}, {"id": 299, "seek": 146280, "start": 1473.44, "end": 1474.44, "text": " It's a good question.", "tokens": [50896, 467, 311, 257, 665, 1168, 13, 50946], "temperature": 0.0, "avg_logprob": -0.26830456382349915, "compression_ratio": 1.6515151515151516, "no_speech_prob": 0.04783133044838905}, {"id": 300, "seek": 146280, "start": 1474.44, "end": 1475.44, "text": " So okay.", "tokens": [50946, 407, 1392, 13, 50996], "temperature": 0.0, "avg_logprob": -0.26830456382349915, "compression_ratio": 1.6515151515151516, "no_speech_prob": 0.04783133044838905}, {"id": 301, "seek": 146280, "start": 1475.44, "end": 1480.6, "text": " It's not really the concern.", "tokens": [50996, 467, 311, 406, 534, 264, 3136, 13, 51254], "temperature": 0.0, "avg_logprob": -0.26830456382349915, "compression_ratio": 1.6515151515151516, "no_speech_prob": 0.04783133044838905}, {"id": 302, "seek": 146280, "start": 1480.6, "end": 1485.12, "text": " So here as you have seen the results are exact.", "tokens": [51254, 407, 510, 382, 291, 362, 1612, 264, 3542, 366, 1900, 13, 51480], "temperature": 0.0, "avg_logprob": -0.26830456382349915, "compression_ratio": 1.6515151515151516, "no_speech_prob": 0.04783133044838905}, {"id": 303, "seek": 146280, "start": 1485.12, "end": 1486.12, "text": " So okay.", "tokens": [51480, 407, 1392, 13, 51530], "temperature": 0.0, "avg_logprob": -0.26830456382349915, "compression_ratio": 1.6515151515151516, "no_speech_prob": 0.04783133044838905}, {"id": 304, "seek": 146280, "start": 1486.12, "end": 1489.68, "text": " As you have seen also it's quite fast.", "tokens": [51530, 1018, 291, 362, 1612, 611, 309, 311, 1596, 2370, 13, 51708], "temperature": 0.0, "avg_logprob": -0.26830456382349915, "compression_ratio": 1.6515151515151516, "no_speech_prob": 0.04783133044838905}, {"id": 305, "seek": 146280, "start": 1489.68, "end": 1491.8, "text": " So there are several optimizations.", "tokens": [51708, 407, 456, 366, 2940, 5028, 14455, 13, 51814], "temperature": 0.0, "avg_logprob": -0.26830456382349915, "compression_ratio": 1.6515151515151516, "no_speech_prob": 0.04783133044838905}, {"id": 306, "seek": 149180, "start": 1491.8, "end": 1495.48, "text": " I have no figures but okay.", "tokens": [50364, 286, 362, 572, 9624, 457, 1392, 13, 50548], "temperature": 0.0, "avg_logprob": -0.2813065444366841, "compression_ratio": 1.5248618784530388, "no_speech_prob": 0.07354380190372467}, {"id": 307, "seek": 149180, "start": 1495.48, "end": 1502.32, "text": " As you expect there are many problems which are very complex and for that LIA provides", "tokens": [50548, 1018, 291, 2066, 456, 366, 867, 2740, 597, 366, 588, 3997, 293, 337, 300, 441, 6914, 6417, 50890], "temperature": 0.0, "avg_logprob": -0.2813065444366841, "compression_ratio": 1.5248618784530388, "no_speech_prob": 0.07354380190372467}, {"id": 308, "seek": 149180, "start": 1502.32, "end": 1512.12, "text": " Monte Carlo several Monte Carlo algorithm that gives approximate results in a fair time.", "tokens": [50890, 38105, 45112, 2940, 38105, 45112, 9284, 300, 2709, 30874, 3542, 294, 257, 3143, 565, 13, 51380], "temperature": 0.0, "avg_logprob": -0.2813065444366841, "compression_ratio": 1.5248618784530388, "no_speech_prob": 0.07354380190372467}, {"id": 309, "seek": 149180, "start": 1512.12, "end": 1513.12, "text": " Yeah.", "tokens": [51380, 865, 13, 51430], "temperature": 0.0, "avg_logprob": -0.2813065444366841, "compression_ratio": 1.5248618784530388, "no_speech_prob": 0.07354380190372467}, {"id": 310, "seek": 149180, "start": 1513.12, "end": 1516.1599999999999, "text": " But I have no figures.", "tokens": [51430, 583, 286, 362, 572, 9624, 13, 51582], "temperature": 0.0, "avg_logprob": -0.2813065444366841, "compression_ratio": 1.5248618784530388, "no_speech_prob": 0.07354380190372467}, {"id": 311, "seek": 149180, "start": 1516.1599999999999, "end": 1517.1599999999999, "text": " Yeah.", "tokens": [51582, 865, 13, 51632], "temperature": 0.0, "avg_logprob": -0.2813065444366841, "compression_ratio": 1.5248618784530388, "no_speech_prob": 0.07354380190372467}, {"id": 312, "seek": 149180, "start": 1517.1599999999999, "end": 1518.1599999999999, "text": " Okay.", "tokens": [51632, 1033, 13, 51682], "temperature": 0.0, "avg_logprob": -0.2813065444366841, "compression_ratio": 1.5248618784530388, "no_speech_prob": 0.07354380190372467}, {"id": 313, "seek": 149180, "start": 1518.1599999999999, "end": 1519.1599999999999, "text": " Thank you.", "tokens": [51682, 1044, 291, 13, 51732], "temperature": 0.0, "avg_logprob": -0.2813065444366841, "compression_ratio": 1.5248618784530388, "no_speech_prob": 0.07354380190372467}, {"id": 314, "seek": 149180, "start": 1519.1599999999999, "end": 1520.1599999999999, "text": " Thank you very much.", "tokens": [51732, 1044, 291, 588, 709, 13, 51782], "temperature": 0.0, "avg_logprob": -0.2813065444366841, "compression_ratio": 1.5248618784530388, "no_speech_prob": 0.07354380190372467}, {"id": 315, "seek": 152016, "start": 1520.16, "end": 1520.66, "text": " Thank you very much.", "tokens": [50364, 1044, 291, 588, 709, 13, 50389], "temperature": 0.0, "avg_logprob": -0.6289758086204529, "compression_ratio": 0.7142857142857143, "no_speech_prob": 0.8645396828651428}], "language": "en"}