{"text": " Okay. Well, cool. Yeah. So, displayed at her. I like usually like a standing and jumping around, but here I've got to type. So, you forgive me for sitting down here. So, we'll talk about embeddable code playground specifically in a dogs. Let me ask how many of you prefer dull static dogs compared to interactive dogs? Because you probably have to maintain them. Oh, okay. Okay. I thought you are writing dogs. Yeah. Well, understood. Well, so, just to know who I'm, Peter Seitz, Anton is actually the author of the code we'll talk about, but unfortunately, he couldn't get a visa to come here. So, you stuck with me. But if you have any like a super advanced questions, there is Anton contacts and you can send it to him, he's very responsive guy. So, if you think about their more interactive, well, code playground, interactive scenarios, they generally better work for the explain the topics and also allowing to engage the reader. Maybe not all the readers, but I think the best ones, the most curious ones, which actually want to understand how things work. So, we'll look at three items in this short presentation. Their use cases, their approach, what we have in this open source project, and implementation. First, let's look at their tutorials. If you look at the tutorials, you often want to explain something by example. I think we can look at this very, let's say simple case, we are actually using some real live or the SAS out there, which is provides a very simple database where we can push some simple JSON object. We can go ahead and run it. Actually, what happens in this case, well, it does interaction as described above. Then sends their object to the database. Well, what we can also do is to go ahead and go ahead and to modify that and run. Then we can see this object was stored. Now, we want to demo the Cloud API. In this case, to play with it, we can go ahead and also use the get one to play with it somewhere. Let's say you have a second message and we have, and if you can say, is there like some message number 45? We can see, well, it's not there. Again, if you really want to experiment and play what works and how it works, that can be the very beautiful way to do it. Another cool way what we found it's being used is their release nodes. What we have in this case is this example. If you look at the Golang, they have just made recently very important changes, how the variables operate as related to coroutines. If you look in this case, that makes it look like a little bit counter-intuitive. We have coroutines called in the loop, and for some reason they are not showing different loop counters. Well, in Golang 1.22, that was fixed. If you guys want to showcase their feature in the release don and the commentations, but really let people to explore and put the holes, in this case I think that's a wonderful tool. I'm not sure about you, I often then read in some features, I do a lot of work with databases, and they say, hey, we implemented that new feature, and I wanted to put a hole, oh, did you implement that option, or does it work in this way? That is a very easy way to play with it if I would go in through with all their installation process, and so on and so forth. Another example we can see is some of their describing, some of their options in a documentation. Like if you think in this case as a corral, everybody could use corral, it has this wonderful JSON options, with this very cool, correct, but also very mouthful example, which we can also go ahead and provide example for. Say, hey, that is a JSON object, we post that to the server, that is what we get in return. This HTTP bin, that is actually another like well-known open source project, which essentially allows you to post something to that and then get in return, what exactly you posted with Othead, and so on and so forth, very convenient for debugging. What you can also do here in this case, if you are curious to say, well, interesting. So, corral has the support for JSON. Does it validates JSON, or just sends whatever stuff we have? Well, let's check it out. Well, we can see in this case, we are getting the error response back from the server, rather some sort of corral output, that means it doesn't. Again, that can be very helpful to get the user to explore kind of what he's not very certain, which may not be quite explained in this portion of documentation. Or we can also showcase example, what existed in the docs, how we can send the output from file. Pretty simple here. Okay. If you are looking at the deep dives, there may be some interesting in terms of more functionality. Going to a database, space where I spent a lot of my time, let's say we want to describe what is an absurd in SQL. All right, anybody heard what is absurd? Right, well, that is something like, we want to insert the data, but if it's out there, we want to update it. The very common. Okay, so we want to say, let's say we have this table out there, right? And we want to go ahead and use their MySQL insert or replace syntax, right? Then we want to, well, as I said, like to update one employee's salary and then also add another one, well, we can go ahead and run it. Like why use this as example here? Because what you can see is we are not showing everything in example, right? We are working with some sort of like a seed data which is, well, was pre-created as a part of a previous scenario, right? Which is very common. Here is also another example of the same thing, but with Postgres, right? Where we're using a different scenario, right? And you may ask, well, okay, this is how it works, but I know also the Postgres SQL has a syntax on conflict do nothing, right? So what would that be if that's what we do? Oh, well, in this case, we can see what the Emma's salary, right? Which was a conflict in row, was not changed. So again, we can play with those things. Okay, well, these are kind of setting landscape, I think, what things can be useful, but now let's look in terms of what is approach and how it works. Now, if you think about the tools and the doc creation, right? You would find what it is not easy to find the good technical writers, right? Or documentation offers, right? And they also can be rather, well, let's go like a selfish of a time, right? They don't want to do a lot of useless crap, right? In this case. So we want to make sure that writer experience is important, not just the reader experience, which we already defined, has one of those interactive playgrounds. So what approach we took in this project is saying how we can make it as sort of like a seamless as possible, right? We don't want to say, hey, you know what, you are going to create our interactive code playground in completely different tooling, right, separate from documentation, right? And then figure out is that going to live in the same version control, right, and so on and so forth, right? Or, you know, things like that. What we want in this case is to have your documentation, right, which was this, right? Just as easy as possible, add the ability to run and to edit and run, right? So you can say, hey, we added, you can see the run and edit here. And if I run, you can see what is the output of that documentation example is. So how can we approach that? So it is easy or integration which is easy on writing. Well, it's actually quite easy. So what we have is you are writing documentation in the same format as you got used to, right? Let's say maybe it's a markup language, as in this example, or something else. And then you can embed this like a code API widget. That widget itself will figure out the previous code block and make it interactive, right? So there is no, like, some special thing required, and that pretty much works in any documentation thing which already exists, right? So you can see that example here. So the code which existed here just gets interactive. So, well, of course, hello world is always easier, right? Let's look at some more complicated examples. One, I think, which is very important is the template approach, right? I think what I briefly mentioned already, if I want to show something like this, right? That is like a relatively, you know, complicated query, right? For that to be meaningful, I also need to pre-generate table in this case, which I probably do not want to have on my documentation thing. And this is designed done by providing a template. So a template in this case is basically something which is run before the scenario is done, right? And in this case, I can write some text and, hey, I created a table, but I'm not really specifically final comments because there's a irrelevant in this case. I populated with some data and then I have a code, the code which was created before, right? That is how template would look like. So I can highlight, right, where exactly in the context, I want to run that code which was, which is interactive part of the documentation. Okay, so here is another thing which you will find quite helpful. So if you are building some sort of tutorial, right, building the tutorial, right, you would often want to say, hey, there is actually multiple steps where I need the user to go through them one after another. And that is an example here. What you can see is what we are defining the function in a one-code block and then we are using that function in a in a another code block, right? We can, and I'll show you in a second, define dependency between those code blocks. That means when you are running this second section, the first section would always be run, like let me, I don't know, let's say break this code, right? For example, and then I can go ahead and run the second one. It says, oh, well, you know, things got broken, right, on the previous stuff, right? And how that works is what we identify, we refer to the first one as a cell number two, right? And then identify the second snippet as a cell which depends on a cell number two, right? That means pretty much that the content of that cell is going to be run. Then the second cell is run, right? Even if you, as users, don't click run, right? If you say, hey, I don't want to go through all those like five steps in tutorial, I want to start with step number six because that is where the real meet happens. You can do it, right? You can just jump in the middle. Okay. So finally, so how does that all things work? Well, there are actually a couple of ways it can work. One is we can have a browser playground and then a sandbox environment, right? Which is pretty much docker-based, right? And that's where we can use browser API, JavaScript and whatever. The second approach we can have also is web assembly, right? So if you can say, hey, you know what? We want no kind of serocomponent, right? It runs completely in a browser. We can do that, but probably in web assembly, it can be sometimes heavy, right? Especially saying, well, you know what? I want to showcase how, you know, like a Postgres operates when, you know, getting all that Postgres pulled in, the assembly started, right? That may not be the best experience, right? Especially with slower connections. So that is where docker, right, can be very helpful, right? So with docker, you can implement whatever you want and the setup of this service is an open source project, right? So you can roll your own as well. There is a variety of existing playgrounds which are supported at, you know, core API website, right? Which can get you started pretty quickly. Yes, so here are some examples, and I will of course share, well, slides if you actually slide there. The online, this is a live tutorial. You can see there's like a number of projects already started to use that with, you know, pretty good success. And you can see with core IP.org showcase that is where all the examples exist, right? Here are specific projects, right? There are kind of two sub-repositories. One is for JavaScript kind of client side, and other four, the server side, again, it's split because you may just want to use their client side if you're using like JavaScript or something where you don't need a server component. And yet, if you want to ask some more questions for Anton, right, or get some feedback, Antonz.org is his website. So that's all I had, and I would be happy to answer questions or get out of the way because I think I'm the last thing standing between you and your viewers. Yeah, we started with docs code, and now we've gone to code docs. Any questions? You don't understand, the back-end is also part of this project or not? Yes, yes, so in this case, code IP, that is your Docker back-end, right? Code IP JS, that's your, I think, so both of them are open source. What do you mean? Oh, you mean in terms of what people run, right, what kind of, so not right now.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 8.1, "text": " Okay. Well, cool.", "tokens": [50364, 1033, 13, 1042, 11, 1627, 13, 50769], "temperature": 0.0, "avg_logprob": -0.4506050540554908, "compression_ratio": 1.3676470588235294, "no_speech_prob": 0.5237373113632202}, {"id": 1, "seek": 0, "start": 8.1, "end": 11.52, "text": " Yeah. So, displayed at her.", "tokens": [50769, 865, 13, 407, 11, 16372, 412, 720, 13, 50940], "temperature": 0.0, "avg_logprob": -0.4506050540554908, "compression_ratio": 1.3676470588235294, "no_speech_prob": 0.5237373113632202}, {"id": 2, "seek": 0, "start": 11.52, "end": 15.4, "text": " I like usually like a standing and jumping around,", "tokens": [50940, 286, 411, 2673, 411, 257, 4877, 293, 11233, 926, 11, 51134], "temperature": 0.0, "avg_logprob": -0.4506050540554908, "compression_ratio": 1.3676470588235294, "no_speech_prob": 0.5237373113632202}, {"id": 3, "seek": 0, "start": 15.4, "end": 17.18, "text": " but here I've got to type.", "tokens": [51134, 457, 510, 286, 600, 658, 281, 2010, 13, 51223], "temperature": 0.0, "avg_logprob": -0.4506050540554908, "compression_ratio": 1.3676470588235294, "no_speech_prob": 0.5237373113632202}, {"id": 4, "seek": 0, "start": 17.18, "end": 21.92, "text": " So, you forgive me for sitting down here.", "tokens": [51223, 407, 11, 291, 10718, 385, 337, 3798, 760, 510, 13, 51460], "temperature": 0.0, "avg_logprob": -0.4506050540554908, "compression_ratio": 1.3676470588235294, "no_speech_prob": 0.5237373113632202}, {"id": 5, "seek": 0, "start": 21.92, "end": 25.82, "text": " So, we'll talk about", "tokens": [51460, 407, 11, 321, 603, 751, 466, 51655], "temperature": 0.0, "avg_logprob": -0.4506050540554908, "compression_ratio": 1.3676470588235294, "no_speech_prob": 0.5237373113632202}, {"id": 6, "seek": 2582, "start": 25.82, "end": 30.380000000000003, "text": " embeddable code playground specifically in a dogs.", "tokens": [50364, 12240, 67, 712, 3089, 24646, 4682, 294, 257, 7197, 13, 50592], "temperature": 0.0, "avg_logprob": -0.5094002895667905, "compression_ratio": 1.39375, "no_speech_prob": 0.13078923523426056}, {"id": 7, "seek": 2582, "start": 30.380000000000003, "end": 33.78, "text": " Let me ask how many of you", "tokens": [50592, 961, 385, 1029, 577, 867, 295, 291, 50762], "temperature": 0.0, "avg_logprob": -0.5094002895667905, "compression_ratio": 1.39375, "no_speech_prob": 0.13078923523426056}, {"id": 8, "seek": 2582, "start": 33.78, "end": 40.54, "text": " prefer dull static dogs compared to interactive dogs?", "tokens": [50762, 4382, 23471, 13437, 7197, 5347, 281, 15141, 7197, 30, 51100], "temperature": 0.0, "avg_logprob": -0.5094002895667905, "compression_ratio": 1.39375, "no_speech_prob": 0.13078923523426056}, {"id": 9, "seek": 2582, "start": 41.38, "end": 44.260000000000005, "text": " Because you probably have to maintain them.", "tokens": [51142, 1436, 291, 1391, 362, 281, 6909, 552, 13, 51286], "temperature": 0.0, "avg_logprob": -0.5094002895667905, "compression_ratio": 1.39375, "no_speech_prob": 0.13078923523426056}, {"id": 10, "seek": 2582, "start": 44.260000000000005, "end": 50.66, "text": " Oh, okay.", "tokens": [51286, 876, 11, 1392, 13, 51606], "temperature": 0.0, "avg_logprob": -0.5094002895667905, "compression_ratio": 1.39375, "no_speech_prob": 0.13078923523426056}, {"id": 11, "seek": 2582, "start": 50.66, "end": 52.66, "text": " Okay. I thought you are writing dogs.", "tokens": [51606, 1033, 13, 286, 1194, 291, 366, 3579, 7197, 13, 51706], "temperature": 0.0, "avg_logprob": -0.5094002895667905, "compression_ratio": 1.39375, "no_speech_prob": 0.13078923523426056}, {"id": 12, "seek": 5266, "start": 52.66, "end": 55.779999999999994, "text": " Yeah. Well, understood.", "tokens": [50364, 865, 13, 1042, 11, 7320, 13, 50520], "temperature": 0.0, "avg_logprob": -0.3737954074896655, "compression_ratio": 1.4588744588744589, "no_speech_prob": 0.09006375819444656}, {"id": 13, "seek": 5266, "start": 55.779999999999994, "end": 60.78, "text": " Well, so, just to know who I'm,", "tokens": [50520, 1042, 11, 370, 11, 445, 281, 458, 567, 286, 478, 11, 50770], "temperature": 0.0, "avg_logprob": -0.3737954074896655, "compression_ratio": 1.4588744588744589, "no_speech_prob": 0.09006375819444656}, {"id": 14, "seek": 5266, "start": 60.78, "end": 63.5, "text": " Peter Seitz, Anton is actually", "tokens": [50770, 6508, 1100, 6862, 11, 15291, 307, 767, 50906], "temperature": 0.0, "avg_logprob": -0.3737954074896655, "compression_ratio": 1.4588744588744589, "no_speech_prob": 0.09006375819444656}, {"id": 15, "seek": 5266, "start": 63.5, "end": 66.82, "text": " the author of the code we'll talk about,", "tokens": [50906, 264, 3793, 295, 264, 3089, 321, 603, 751, 466, 11, 51072], "temperature": 0.0, "avg_logprob": -0.3737954074896655, "compression_ratio": 1.4588744588744589, "no_speech_prob": 0.09006375819444656}, {"id": 16, "seek": 5266, "start": 66.82, "end": 70.82, "text": " but unfortunately, he couldn't get a visa to come here.", "tokens": [51072, 457, 7015, 11, 415, 2809, 380, 483, 257, 18589, 281, 808, 510, 13, 51272], "temperature": 0.0, "avg_logprob": -0.3737954074896655, "compression_ratio": 1.4588744588744589, "no_speech_prob": 0.09006375819444656}, {"id": 17, "seek": 5266, "start": 70.82, "end": 72.69999999999999, "text": " So, you stuck with me.", "tokens": [51272, 407, 11, 291, 5541, 365, 385, 13, 51366], "temperature": 0.0, "avg_logprob": -0.3737954074896655, "compression_ratio": 1.4588744588744589, "no_speech_prob": 0.09006375819444656}, {"id": 18, "seek": 5266, "start": 72.69999999999999, "end": 76.02, "text": " But if you have any like a super advanced questions,", "tokens": [51366, 583, 498, 291, 362, 604, 411, 257, 1687, 7339, 1651, 11, 51532], "temperature": 0.0, "avg_logprob": -0.3737954074896655, "compression_ratio": 1.4588744588744589, "no_speech_prob": 0.09006375819444656}, {"id": 19, "seek": 5266, "start": 76.02, "end": 79.42, "text": " there is Anton contacts and you can", "tokens": [51532, 456, 307, 15291, 15836, 293, 291, 393, 51702], "temperature": 0.0, "avg_logprob": -0.3737954074896655, "compression_ratio": 1.4588744588744589, "no_speech_prob": 0.09006375819444656}, {"id": 20, "seek": 5266, "start": 79.42, "end": 82.5, "text": " send it to him, he's very responsive guy.", "tokens": [51702, 2845, 309, 281, 796, 11, 415, 311, 588, 21826, 2146, 13, 51856], "temperature": 0.0, "avg_logprob": -0.3737954074896655, "compression_ratio": 1.4588744588744589, "no_speech_prob": 0.09006375819444656}, {"id": 21, "seek": 8250, "start": 82.5, "end": 85.06, "text": " So, if you think about", "tokens": [50364, 407, 11, 498, 291, 519, 466, 50492], "temperature": 0.0, "avg_logprob": -0.36285749295862707, "compression_ratio": 1.6020408163265305, "no_speech_prob": 0.0032050171867012978}, {"id": 22, "seek": 8250, "start": 85.06, "end": 91.46000000000001, "text": " their more interactive,", "tokens": [50492, 641, 544, 15141, 11, 50812], "temperature": 0.0, "avg_logprob": -0.36285749295862707, "compression_ratio": 1.6020408163265305, "no_speech_prob": 0.0032050171867012978}, {"id": 23, "seek": 8250, "start": 91.46000000000001, "end": 93.5, "text": " well, code playground,", "tokens": [50812, 731, 11, 3089, 24646, 11, 50914], "temperature": 0.0, "avg_logprob": -0.36285749295862707, "compression_ratio": 1.6020408163265305, "no_speech_prob": 0.0032050171867012978}, {"id": 24, "seek": 8250, "start": 93.5, "end": 96.46000000000001, "text": " interactive scenarios, they generally better work", "tokens": [50914, 15141, 15077, 11, 436, 5101, 1101, 589, 51062], "temperature": 0.0, "avg_logprob": -0.36285749295862707, "compression_ratio": 1.6020408163265305, "no_speech_prob": 0.0032050171867012978}, {"id": 25, "seek": 8250, "start": 96.46000000000001, "end": 101.98, "text": " for the explain the topics and also allowing to engage the reader.", "tokens": [51062, 337, 264, 2903, 264, 8378, 293, 611, 8293, 281, 4683, 264, 15149, 13, 51338], "temperature": 0.0, "avg_logprob": -0.36285749295862707, "compression_ratio": 1.6020408163265305, "no_speech_prob": 0.0032050171867012978}, {"id": 26, "seek": 8250, "start": 101.98, "end": 103.34, "text": " Maybe not all the readers,", "tokens": [51338, 2704, 406, 439, 264, 17147, 11, 51406], "temperature": 0.0, "avg_logprob": -0.36285749295862707, "compression_ratio": 1.6020408163265305, "no_speech_prob": 0.0032050171867012978}, {"id": 27, "seek": 8250, "start": 103.34, "end": 105.1, "text": " but I think the best ones,", "tokens": [51406, 457, 286, 519, 264, 1151, 2306, 11, 51494], "temperature": 0.0, "avg_logprob": -0.36285749295862707, "compression_ratio": 1.6020408163265305, "no_speech_prob": 0.0032050171867012978}, {"id": 28, "seek": 8250, "start": 105.1, "end": 106.32, "text": " the most curious ones,", "tokens": [51494, 264, 881, 6369, 2306, 11, 51555], "temperature": 0.0, "avg_logprob": -0.36285749295862707, "compression_ratio": 1.6020408163265305, "no_speech_prob": 0.0032050171867012978}, {"id": 29, "seek": 8250, "start": 106.32, "end": 110.7, "text": " which actually want to understand how things work.", "tokens": [51555, 597, 767, 528, 281, 1223, 577, 721, 589, 13, 51774], "temperature": 0.0, "avg_logprob": -0.36285749295862707, "compression_ratio": 1.6020408163265305, "no_speech_prob": 0.0032050171867012978}, {"id": 30, "seek": 11070, "start": 110.7, "end": 114.7, "text": " So, we'll look at three items in this short presentation.", "tokens": [50364, 407, 11, 321, 603, 574, 412, 1045, 4754, 294, 341, 2099, 5860, 13, 50564], "temperature": 0.0, "avg_logprob": -0.2605385158372962, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.006833458784967661}, {"id": 31, "seek": 11070, "start": 114.7, "end": 116.9, "text": " Their use cases, their approach,", "tokens": [50564, 6710, 764, 3331, 11, 641, 3109, 11, 50674], "temperature": 0.0, "avg_logprob": -0.2605385158372962, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.006833458784967661}, {"id": 32, "seek": 11070, "start": 116.9, "end": 119.58, "text": " what we have in this open source project,", "tokens": [50674, 437, 321, 362, 294, 341, 1269, 4009, 1716, 11, 50808], "temperature": 0.0, "avg_logprob": -0.2605385158372962, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.006833458784967661}, {"id": 33, "seek": 11070, "start": 119.58, "end": 122.5, "text": " and implementation.", "tokens": [50808, 293, 11420, 13, 50954], "temperature": 0.0, "avg_logprob": -0.2605385158372962, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.006833458784967661}, {"id": 34, "seek": 11070, "start": 122.5, "end": 128.14000000000001, "text": " First, let's look at their tutorials.", "tokens": [50954, 2386, 11, 718, 311, 574, 412, 641, 17616, 13, 51236], "temperature": 0.0, "avg_logprob": -0.2605385158372962, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.006833458784967661}, {"id": 35, "seek": 11070, "start": 128.14000000000001, "end": 129.78, "text": " If you look at the tutorials,", "tokens": [51236, 759, 291, 574, 412, 264, 17616, 11, 51318], "temperature": 0.0, "avg_logprob": -0.2605385158372962, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.006833458784967661}, {"id": 36, "seek": 11070, "start": 129.78, "end": 133.42000000000002, "text": " you often want to explain something by example.", "tokens": [51318, 291, 2049, 528, 281, 2903, 746, 538, 1365, 13, 51500], "temperature": 0.0, "avg_logprob": -0.2605385158372962, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.006833458784967661}, {"id": 37, "seek": 11070, "start": 133.42000000000002, "end": 135.66, "text": " I think we can look at this very,", "tokens": [51500, 286, 519, 321, 393, 574, 412, 341, 588, 11, 51612], "temperature": 0.0, "avg_logprob": -0.2605385158372962, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.006833458784967661}, {"id": 38, "seek": 11070, "start": 135.66, "end": 137.3, "text": " let's say simple case,", "tokens": [51612, 718, 311, 584, 2199, 1389, 11, 51694], "temperature": 0.0, "avg_logprob": -0.2605385158372962, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.006833458784967661}, {"id": 39, "seek": 13730, "start": 137.3, "end": 143.18, "text": " we are actually using some real live or the SAS out there,", "tokens": [50364, 321, 366, 767, 1228, 512, 957, 1621, 420, 264, 33441, 484, 456, 11, 50658], "temperature": 0.0, "avg_logprob": -0.34979643541223865, "compression_ratio": 1.4457142857142857, "no_speech_prob": 0.018890155479311943}, {"id": 40, "seek": 13730, "start": 143.18, "end": 146.62, "text": " which is provides a very simple database where we can", "tokens": [50658, 597, 307, 6417, 257, 588, 2199, 8149, 689, 321, 393, 50830], "temperature": 0.0, "avg_logprob": -0.34979643541223865, "compression_ratio": 1.4457142857142857, "no_speech_prob": 0.018890155479311943}, {"id": 41, "seek": 13730, "start": 146.62, "end": 151.62, "text": " push some simple JSON object.", "tokens": [50830, 2944, 512, 2199, 31828, 2657, 13, 51080], "temperature": 0.0, "avg_logprob": -0.34979643541223865, "compression_ratio": 1.4457142857142857, "no_speech_prob": 0.018890155479311943}, {"id": 42, "seek": 13730, "start": 151.62, "end": 155.38000000000002, "text": " We can go ahead and run it.", "tokens": [51080, 492, 393, 352, 2286, 293, 1190, 309, 13, 51268], "temperature": 0.0, "avg_logprob": -0.34979643541223865, "compression_ratio": 1.4457142857142857, "no_speech_prob": 0.018890155479311943}, {"id": 43, "seek": 13730, "start": 155.38000000000002, "end": 157.54000000000002, "text": " Actually, what happens in this case,", "tokens": [51268, 5135, 11, 437, 2314, 294, 341, 1389, 11, 51376], "temperature": 0.0, "avg_logprob": -0.34979643541223865, "compression_ratio": 1.4457142857142857, "no_speech_prob": 0.018890155479311943}, {"id": 44, "seek": 13730, "start": 157.54000000000002, "end": 166.78, "text": " well, it does interaction as described above.", "tokens": [51376, 731, 11, 309, 775, 9285, 382, 7619, 3673, 13, 51838], "temperature": 0.0, "avg_logprob": -0.34979643541223865, "compression_ratio": 1.4457142857142857, "no_speech_prob": 0.018890155479311943}, {"id": 45, "seek": 16678, "start": 166.78, "end": 171.46, "text": " Then sends their object to the database.", "tokens": [50364, 1396, 14790, 641, 2657, 281, 264, 8149, 13, 50598], "temperature": 0.0, "avg_logprob": -0.3683163324991862, "compression_ratio": 1.4336283185840708, "no_speech_prob": 0.011578873731195927}, {"id": 46, "seek": 16678, "start": 171.46, "end": 176.42000000000002, "text": " Well, what we can also do is to go ahead and", "tokens": [50598, 1042, 11, 437, 321, 393, 611, 360, 307, 281, 352, 2286, 293, 50846], "temperature": 0.0, "avg_logprob": -0.3683163324991862, "compression_ratio": 1.4336283185840708, "no_speech_prob": 0.011578873731195927}, {"id": 47, "seek": 16678, "start": 176.42000000000002, "end": 186.06, "text": " go ahead and to modify that and run.", "tokens": [50846, 352, 2286, 293, 281, 16927, 300, 293, 1190, 13, 51328], "temperature": 0.0, "avg_logprob": -0.3683163324991862, "compression_ratio": 1.4336283185840708, "no_speech_prob": 0.011578873731195927}, {"id": 48, "seek": 16678, "start": 186.06, "end": 194.78, "text": " Then we can see this object was stored.", "tokens": [51328, 1396, 321, 393, 536, 341, 2657, 390, 12187, 13, 51764], "temperature": 0.0, "avg_logprob": -0.3683163324991862, "compression_ratio": 1.4336283185840708, "no_speech_prob": 0.011578873731195927}, {"id": 49, "seek": 19478, "start": 194.78, "end": 197.98, "text": " Now, we want to demo the Cloud API.", "tokens": [50364, 823, 11, 321, 528, 281, 10723, 264, 8061, 9362, 13, 50524], "temperature": 0.0, "avg_logprob": -0.29939339377663354, "compression_ratio": 1.5193370165745856, "no_speech_prob": 0.041512615978717804}, {"id": 50, "seek": 19478, "start": 197.98, "end": 200.9, "text": " In this case, to play with it,", "tokens": [50524, 682, 341, 1389, 11, 281, 862, 365, 309, 11, 50670], "temperature": 0.0, "avg_logprob": -0.29939339377663354, "compression_ratio": 1.5193370165745856, "no_speech_prob": 0.041512615978717804}, {"id": 51, "seek": 19478, "start": 200.9, "end": 209.78, "text": " we can go ahead and also use the get one to play with it somewhere.", "tokens": [50670, 321, 393, 352, 2286, 293, 611, 764, 264, 483, 472, 281, 862, 365, 309, 4079, 13, 51114], "temperature": 0.0, "avg_logprob": -0.29939339377663354, "compression_ratio": 1.5193370165745856, "no_speech_prob": 0.041512615978717804}, {"id": 52, "seek": 19478, "start": 209.78, "end": 213.46, "text": " Let's say you have a second message and we have,", "tokens": [51114, 961, 311, 584, 291, 362, 257, 1150, 3636, 293, 321, 362, 11, 51298], "temperature": 0.0, "avg_logprob": -0.29939339377663354, "compression_ratio": 1.5193370165745856, "no_speech_prob": 0.041512615978717804}, {"id": 53, "seek": 19478, "start": 213.46, "end": 215.06, "text": " and if you can say,", "tokens": [51298, 293, 498, 291, 393, 584, 11, 51378], "temperature": 0.0, "avg_logprob": -0.29939339377663354, "compression_ratio": 1.5193370165745856, "no_speech_prob": 0.041512615978717804}, {"id": 54, "seek": 19478, "start": 215.06, "end": 219.14, "text": " is there like some message number 45?", "tokens": [51378, 307, 456, 411, 512, 3636, 1230, 6905, 30, 51582], "temperature": 0.0, "avg_logprob": -0.29939339377663354, "compression_ratio": 1.5193370165745856, "no_speech_prob": 0.041512615978717804}, {"id": 55, "seek": 19478, "start": 219.14, "end": 223.94, "text": " We can see, well, it's not there.", "tokens": [51582, 492, 393, 536, 11, 731, 11, 309, 311, 406, 456, 13, 51822], "temperature": 0.0, "avg_logprob": -0.29939339377663354, "compression_ratio": 1.5193370165745856, "no_speech_prob": 0.041512615978717804}, {"id": 56, "seek": 22394, "start": 223.94, "end": 229.62, "text": " Again, if you really want to experiment and play what works", "tokens": [50364, 3764, 11, 498, 291, 534, 528, 281, 5120, 293, 862, 437, 1985, 50648], "temperature": 0.0, "avg_logprob": -0.3184284903786399, "compression_ratio": 1.4191176470588236, "no_speech_prob": 0.006084826309233904}, {"id": 57, "seek": 22394, "start": 229.62, "end": 231.38, "text": " and how it works,", "tokens": [50648, 293, 577, 309, 1985, 11, 50736], "temperature": 0.0, "avg_logprob": -0.3184284903786399, "compression_ratio": 1.4191176470588236, "no_speech_prob": 0.006084826309233904}, {"id": 58, "seek": 22394, "start": 231.38, "end": 235.98, "text": " that can be the very beautiful way to do it.", "tokens": [50736, 300, 393, 312, 264, 588, 2238, 636, 281, 360, 309, 13, 50966], "temperature": 0.0, "avg_logprob": -0.3184284903786399, "compression_ratio": 1.4191176470588236, "no_speech_prob": 0.006084826309233904}, {"id": 59, "seek": 22394, "start": 235.98, "end": 242.38, "text": " Another cool way what we found it's being used", "tokens": [50966, 3996, 1627, 636, 437, 321, 1352, 309, 311, 885, 1143, 51286], "temperature": 0.0, "avg_logprob": -0.3184284903786399, "compression_ratio": 1.4191176470588236, "no_speech_prob": 0.006084826309233904}, {"id": 60, "seek": 22394, "start": 242.38, "end": 249.14, "text": " is their release nodes.", "tokens": [51286, 307, 641, 4374, 13891, 13, 51624], "temperature": 0.0, "avg_logprob": -0.3184284903786399, "compression_ratio": 1.4191176470588236, "no_speech_prob": 0.006084826309233904}, {"id": 61, "seek": 24914, "start": 249.33999999999997, "end": 253.85999999999999, "text": " What we have in this case is this example.", "tokens": [50374, 708, 321, 362, 294, 341, 1389, 307, 341, 1365, 13, 50600], "temperature": 0.0, "avg_logprob": -0.30476082695855033, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.05486277863383293}, {"id": 62, "seek": 24914, "start": 253.85999999999999, "end": 256.58, "text": " If you look at the Golang,", "tokens": [50600, 759, 291, 574, 412, 264, 36319, 656, 11, 50736], "temperature": 0.0, "avg_logprob": -0.30476082695855033, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.05486277863383293}, {"id": 63, "seek": 24914, "start": 256.58, "end": 260.34, "text": " they have just made recently very important changes,", "tokens": [50736, 436, 362, 445, 1027, 3938, 588, 1021, 2962, 11, 50924], "temperature": 0.0, "avg_logprob": -0.30476082695855033, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.05486277863383293}, {"id": 64, "seek": 24914, "start": 260.34, "end": 268.9, "text": " how the variables operate as related to coroutines.", "tokens": [50924, 577, 264, 9102, 9651, 382, 4077, 281, 1181, 346, 1652, 13, 51352], "temperature": 0.0, "avg_logprob": -0.30476082695855033, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.05486277863383293}, {"id": 65, "seek": 24914, "start": 268.9, "end": 270.38, "text": " If you look in this case,", "tokens": [51352, 759, 291, 574, 294, 341, 1389, 11, 51426], "temperature": 0.0, "avg_logprob": -0.30476082695855033, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.05486277863383293}, {"id": 66, "seek": 24914, "start": 270.38, "end": 276.14, "text": " that makes it look like a little bit counter-intuitive.", "tokens": [51426, 300, 1669, 309, 574, 411, 257, 707, 857, 5682, 12, 686, 48314, 13, 51714], "temperature": 0.0, "avg_logprob": -0.30476082695855033, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.05486277863383293}, {"id": 67, "seek": 27614, "start": 276.14, "end": 280.09999999999997, "text": " We have coroutines called in the loop,", "tokens": [50364, 492, 362, 1181, 346, 1652, 1219, 294, 264, 6367, 11, 50562], "temperature": 0.0, "avg_logprob": -0.3633778311989524, "compression_ratio": 1.4840425531914894, "no_speech_prob": 0.04544443637132645}, {"id": 68, "seek": 27614, "start": 280.09999999999997, "end": 287.97999999999996, "text": " and for some reason they are not showing different loop counters.", "tokens": [50562, 293, 337, 512, 1778, 436, 366, 406, 4099, 819, 6367, 39338, 13, 50956], "temperature": 0.0, "avg_logprob": -0.3633778311989524, "compression_ratio": 1.4840425531914894, "no_speech_prob": 0.04544443637132645}, {"id": 69, "seek": 27614, "start": 287.97999999999996, "end": 292.5, "text": " Well, in Golang 1.22, that was fixed.", "tokens": [50956, 1042, 11, 294, 36319, 656, 502, 13, 7490, 11, 300, 390, 6806, 13, 51182], "temperature": 0.0, "avg_logprob": -0.3633778311989524, "compression_ratio": 1.4840425531914894, "no_speech_prob": 0.04544443637132645}, {"id": 70, "seek": 27614, "start": 292.5, "end": 298.62, "text": " If you guys want to showcase their feature in the release", "tokens": [51182, 759, 291, 1074, 528, 281, 20388, 641, 4111, 294, 264, 4374, 51488], "temperature": 0.0, "avg_logprob": -0.3633778311989524, "compression_ratio": 1.4840425531914894, "no_speech_prob": 0.04544443637132645}, {"id": 71, "seek": 27614, "start": 298.62, "end": 299.82, "text": " don and the commentations,", "tokens": [51488, 500, 293, 264, 2871, 763, 11, 51548], "temperature": 0.0, "avg_logprob": -0.3633778311989524, "compression_ratio": 1.4840425531914894, "no_speech_prob": 0.04544443637132645}, {"id": 72, "seek": 27614, "start": 299.82, "end": 305.14, "text": " but really let people to explore and put the holes,", "tokens": [51548, 457, 534, 718, 561, 281, 6839, 293, 829, 264, 8118, 11, 51814], "temperature": 0.0, "avg_logprob": -0.3633778311989524, "compression_ratio": 1.4840425531914894, "no_speech_prob": 0.04544443637132645}, {"id": 73, "seek": 30514, "start": 305.14, "end": 308.21999999999997, "text": " in this case I think that's a wonderful tool.", "tokens": [50364, 294, 341, 1389, 286, 519, 300, 311, 257, 3715, 2290, 13, 50518], "temperature": 0.0, "avg_logprob": -0.3732870163456086, "compression_ratio": 1.7012448132780082, "no_speech_prob": 0.05847501754760742}, {"id": 74, "seek": 30514, "start": 308.21999999999997, "end": 309.74, "text": " I'm not sure about you,", "tokens": [50518, 286, 478, 406, 988, 466, 291, 11, 50594], "temperature": 0.0, "avg_logprob": -0.3732870163456086, "compression_ratio": 1.7012448132780082, "no_speech_prob": 0.05847501754760742}, {"id": 75, "seek": 30514, "start": 309.74, "end": 312.58, "text": " I often then read in some features,", "tokens": [50594, 286, 2049, 550, 1401, 294, 512, 4122, 11, 50736], "temperature": 0.0, "avg_logprob": -0.3732870163456086, "compression_ratio": 1.7012448132780082, "no_speech_prob": 0.05847501754760742}, {"id": 76, "seek": 30514, "start": 312.58, "end": 314.26, "text": " I do a lot of work with databases,", "tokens": [50736, 286, 360, 257, 688, 295, 589, 365, 22380, 11, 50820], "temperature": 0.0, "avg_logprob": -0.3732870163456086, "compression_ratio": 1.7012448132780082, "no_speech_prob": 0.05847501754760742}, {"id": 77, "seek": 30514, "start": 314.26, "end": 317.02, "text": " and they say, hey, we implemented that new feature,", "tokens": [50820, 293, 436, 584, 11, 4177, 11, 321, 12270, 300, 777, 4111, 11, 50958], "temperature": 0.0, "avg_logprob": -0.3732870163456086, "compression_ratio": 1.7012448132780082, "no_speech_prob": 0.05847501754760742}, {"id": 78, "seek": 30514, "start": 317.02, "end": 318.26, "text": " and I wanted to put a hole,", "tokens": [50958, 293, 286, 1415, 281, 829, 257, 5458, 11, 51020], "temperature": 0.0, "avg_logprob": -0.3732870163456086, "compression_ratio": 1.7012448132780082, "no_speech_prob": 0.05847501754760742}, {"id": 79, "seek": 30514, "start": 318.26, "end": 320.3, "text": " oh, did you implement that option,", "tokens": [51020, 1954, 11, 630, 291, 4445, 300, 3614, 11, 51122], "temperature": 0.0, "avg_logprob": -0.3732870163456086, "compression_ratio": 1.7012448132780082, "no_speech_prob": 0.05847501754760742}, {"id": 80, "seek": 30514, "start": 320.3, "end": 322.3, "text": " or does it work in this way?", "tokens": [51122, 420, 775, 309, 589, 294, 341, 636, 30, 51222], "temperature": 0.0, "avg_logprob": -0.3732870163456086, "compression_ratio": 1.7012448132780082, "no_speech_prob": 0.05847501754760742}, {"id": 81, "seek": 30514, "start": 322.3, "end": 326.3, "text": " That is a very easy way to play with it", "tokens": [51222, 663, 307, 257, 588, 1858, 636, 281, 862, 365, 309, 51422], "temperature": 0.0, "avg_logprob": -0.3732870163456086, "compression_ratio": 1.7012448132780082, "no_speech_prob": 0.05847501754760742}, {"id": 82, "seek": 30514, "start": 326.3, "end": 329.86, "text": " if I would go in through with all their installation process,", "tokens": [51422, 498, 286, 576, 352, 294, 807, 365, 439, 641, 13260, 1399, 11, 51600], "temperature": 0.0, "avg_logprob": -0.3732870163456086, "compression_ratio": 1.7012448132780082, "no_speech_prob": 0.05847501754760742}, {"id": 83, "seek": 30514, "start": 329.86, "end": 334.26, "text": " and so on and so forth.", "tokens": [51600, 293, 370, 322, 293, 370, 5220, 13, 51820], "temperature": 0.0, "avg_logprob": -0.3732870163456086, "compression_ratio": 1.7012448132780082, "no_speech_prob": 0.05847501754760742}, {"id": 84, "seek": 33426, "start": 334.74, "end": 340.86, "text": " Another example we can see is some of their describing,", "tokens": [50388, 3996, 1365, 321, 393, 536, 307, 512, 295, 641, 16141, 11, 50694], "temperature": 0.0, "avg_logprob": -0.3712190774770883, "compression_ratio": 1.4873417721518987, "no_speech_prob": 0.005194635596126318}, {"id": 85, "seek": 33426, "start": 340.86, "end": 347.34, "text": " some of their options in a documentation.", "tokens": [50694, 512, 295, 641, 3956, 294, 257, 14333, 13, 51018], "temperature": 0.0, "avg_logprob": -0.3712190774770883, "compression_ratio": 1.4873417721518987, "no_speech_prob": 0.005194635596126318}, {"id": 86, "seek": 33426, "start": 347.34, "end": 350.14, "text": " Like if you think in this case as a corral,", "tokens": [51018, 1743, 498, 291, 519, 294, 341, 1389, 382, 257, 1181, 2155, 11, 51158], "temperature": 0.0, "avg_logprob": -0.3712190774770883, "compression_ratio": 1.4873417721518987, "no_speech_prob": 0.005194635596126318}, {"id": 87, "seek": 33426, "start": 350.14, "end": 351.46, "text": " everybody could use corral,", "tokens": [51158, 2201, 727, 764, 1181, 2155, 11, 51224], "temperature": 0.0, "avg_logprob": -0.3712190774770883, "compression_ratio": 1.4873417721518987, "no_speech_prob": 0.005194635596126318}, {"id": 88, "seek": 33426, "start": 351.46, "end": 354.7, "text": " it has this wonderful JSON options,", "tokens": [51224, 309, 575, 341, 3715, 31828, 3956, 11, 51386], "temperature": 0.0, "avg_logprob": -0.3712190774770883, "compression_ratio": 1.4873417721518987, "no_speech_prob": 0.005194635596126318}, {"id": 89, "seek": 33426, "start": 354.7, "end": 359.5, "text": " with this very cool, correct,", "tokens": [51386, 365, 341, 588, 1627, 11, 3006, 11, 51626], "temperature": 0.0, "avg_logprob": -0.3712190774770883, "compression_ratio": 1.4873417721518987, "no_speech_prob": 0.005194635596126318}, {"id": 90, "seek": 35950, "start": 359.5, "end": 364.22, "text": " but also very mouthful example,", "tokens": [50364, 457, 611, 588, 4525, 906, 1365, 11, 50600], "temperature": 0.0, "avg_logprob": -0.32176624644886365, "compression_ratio": 1.4193548387096775, "no_speech_prob": 0.009062987752258778}, {"id": 91, "seek": 35950, "start": 364.22, "end": 369.86, "text": " which we can also go ahead and provide example for.", "tokens": [50600, 597, 321, 393, 611, 352, 2286, 293, 2893, 1365, 337, 13, 50882], "temperature": 0.0, "avg_logprob": -0.32176624644886365, "compression_ratio": 1.4193548387096775, "no_speech_prob": 0.009062987752258778}, {"id": 92, "seek": 35950, "start": 369.86, "end": 372.62, "text": " Say, hey, that is a JSON object,", "tokens": [50882, 6463, 11, 4177, 11, 300, 307, 257, 31828, 2657, 11, 51020], "temperature": 0.0, "avg_logprob": -0.32176624644886365, "compression_ratio": 1.4193548387096775, "no_speech_prob": 0.009062987752258778}, {"id": 93, "seek": 35950, "start": 372.62, "end": 375.74, "text": " we post that to the server,", "tokens": [51020, 321, 2183, 300, 281, 264, 7154, 11, 51176], "temperature": 0.0, "avg_logprob": -0.32176624644886365, "compression_ratio": 1.4193548387096775, "no_speech_prob": 0.009062987752258778}, {"id": 94, "seek": 35950, "start": 375.74, "end": 382.82, "text": " that is what we get in return.", "tokens": [51176, 300, 307, 437, 321, 483, 294, 2736, 13, 51530], "temperature": 0.0, "avg_logprob": -0.32176624644886365, "compression_ratio": 1.4193548387096775, "no_speech_prob": 0.009062987752258778}, {"id": 95, "seek": 35950, "start": 382.82, "end": 387.46, "text": " This HTTP bin, that is actually another like", "tokens": [51530, 639, 33283, 5171, 11, 300, 307, 767, 1071, 411, 51762], "temperature": 0.0, "avg_logprob": -0.32176624644886365, "compression_ratio": 1.4193548387096775, "no_speech_prob": 0.009062987752258778}, {"id": 96, "seek": 38746, "start": 387.58, "end": 389.46, "text": " well-known open source project,", "tokens": [50370, 731, 12, 6861, 1269, 4009, 1716, 11, 50464], "temperature": 0.0, "avg_logprob": -0.3112159990796856, "compression_ratio": 1.5240174672489082, "no_speech_prob": 0.004970313049852848}, {"id": 97, "seek": 38746, "start": 389.46, "end": 393.94, "text": " which essentially allows you to post something to that", "tokens": [50464, 597, 4476, 4045, 291, 281, 2183, 746, 281, 300, 50688], "temperature": 0.0, "avg_logprob": -0.3112159990796856, "compression_ratio": 1.5240174672489082, "no_speech_prob": 0.004970313049852848}, {"id": 98, "seek": 38746, "start": 393.94, "end": 395.85999999999996, "text": " and then get in return,", "tokens": [50688, 293, 550, 483, 294, 2736, 11, 50784], "temperature": 0.0, "avg_logprob": -0.3112159990796856, "compression_ratio": 1.5240174672489082, "no_speech_prob": 0.004970313049852848}, {"id": 99, "seek": 38746, "start": 395.85999999999996, "end": 399.29999999999995, "text": " what exactly you posted with Othead,", "tokens": [50784, 437, 2293, 291, 9437, 365, 422, 392, 2056, 11, 50956], "temperature": 0.0, "avg_logprob": -0.3112159990796856, "compression_ratio": 1.5240174672489082, "no_speech_prob": 0.004970313049852848}, {"id": 100, "seek": 38746, "start": 399.29999999999995, "end": 400.09999999999997, "text": " and so on and so forth,", "tokens": [50956, 293, 370, 322, 293, 370, 5220, 11, 50996], "temperature": 0.0, "avg_logprob": -0.3112159990796856, "compression_ratio": 1.5240174672489082, "no_speech_prob": 0.004970313049852848}, {"id": 101, "seek": 38746, "start": 400.09999999999997, "end": 405.7, "text": " very convenient for debugging.", "tokens": [50996, 588, 10851, 337, 45592, 13, 51276], "temperature": 0.0, "avg_logprob": -0.3112159990796856, "compression_ratio": 1.5240174672489082, "no_speech_prob": 0.004970313049852848}, {"id": 102, "seek": 38746, "start": 405.7, "end": 407.41999999999996, "text": " What you can also do here in this case,", "tokens": [51276, 708, 291, 393, 611, 360, 510, 294, 341, 1389, 11, 51362], "temperature": 0.0, "avg_logprob": -0.3112159990796856, "compression_ratio": 1.5240174672489082, "no_speech_prob": 0.004970313049852848}, {"id": 103, "seek": 38746, "start": 407.41999999999996, "end": 409.58, "text": " if you are curious to say, well, interesting.", "tokens": [51362, 498, 291, 366, 6369, 281, 584, 11, 731, 11, 1880, 13, 51470], "temperature": 0.0, "avg_logprob": -0.3112159990796856, "compression_ratio": 1.5240174672489082, "no_speech_prob": 0.004970313049852848}, {"id": 104, "seek": 38746, "start": 409.58, "end": 412.65999999999997, "text": " So, corral has the support for JSON.", "tokens": [51470, 407, 11, 1181, 2155, 575, 264, 1406, 337, 31828, 13, 51624], "temperature": 0.0, "avg_logprob": -0.3112159990796856, "compression_ratio": 1.5240174672489082, "no_speech_prob": 0.004970313049852848}, {"id": 105, "seek": 38746, "start": 412.65999999999997, "end": 415.78, "text": " Does it validates JSON,", "tokens": [51624, 4402, 309, 7363, 1024, 31828, 11, 51780], "temperature": 0.0, "avg_logprob": -0.3112159990796856, "compression_ratio": 1.5240174672489082, "no_speech_prob": 0.004970313049852848}, {"id": 106, "seek": 41578, "start": 416.41999999999996, "end": 419.21999999999997, "text": " or just sends whatever stuff we have?", "tokens": [50396, 420, 445, 14790, 2035, 1507, 321, 362, 30, 50536], "temperature": 0.0, "avg_logprob": -0.20932717225989517, "compression_ratio": 1.5774647887323943, "no_speech_prob": 0.008159337565302849}, {"id": 107, "seek": 41578, "start": 419.21999999999997, "end": 421.61999999999995, "text": " Well, let's check it out.", "tokens": [50536, 1042, 11, 718, 311, 1520, 309, 484, 13, 50656], "temperature": 0.0, "avg_logprob": -0.20932717225989517, "compression_ratio": 1.5774647887323943, "no_speech_prob": 0.008159337565302849}, {"id": 108, "seek": 41578, "start": 421.61999999999995, "end": 424.46, "text": " Well, we can see in this case,", "tokens": [50656, 1042, 11, 321, 393, 536, 294, 341, 1389, 11, 50798], "temperature": 0.0, "avg_logprob": -0.20932717225989517, "compression_ratio": 1.5774647887323943, "no_speech_prob": 0.008159337565302849}, {"id": 109, "seek": 41578, "start": 424.46, "end": 428.94, "text": " we are getting the error response back from the server,", "tokens": [50798, 321, 366, 1242, 264, 6713, 4134, 646, 490, 264, 7154, 11, 51022], "temperature": 0.0, "avg_logprob": -0.20932717225989517, "compression_ratio": 1.5774647887323943, "no_speech_prob": 0.008159337565302849}, {"id": 110, "seek": 41578, "start": 428.94, "end": 431.65999999999997, "text": " rather some sort of corral output,", "tokens": [51022, 2831, 512, 1333, 295, 1181, 2155, 5598, 11, 51158], "temperature": 0.0, "avg_logprob": -0.20932717225989517, "compression_ratio": 1.5774647887323943, "no_speech_prob": 0.008159337565302849}, {"id": 111, "seek": 41578, "start": 431.65999999999997, "end": 432.78, "text": " that means it doesn't.", "tokens": [51158, 300, 1355, 309, 1177, 380, 13, 51214], "temperature": 0.0, "avg_logprob": -0.20932717225989517, "compression_ratio": 1.5774647887323943, "no_speech_prob": 0.008159337565302849}, {"id": 112, "seek": 41578, "start": 432.78, "end": 437.29999999999995, "text": " Again, that can be very helpful to get the user to explore", "tokens": [51214, 3764, 11, 300, 393, 312, 588, 4961, 281, 483, 264, 4195, 281, 6839, 51440], "temperature": 0.0, "avg_logprob": -0.20932717225989517, "compression_ratio": 1.5774647887323943, "no_speech_prob": 0.008159337565302849}, {"id": 113, "seek": 41578, "start": 437.29999999999995, "end": 438.94, "text": " kind of what he's not very certain,", "tokens": [51440, 733, 295, 437, 415, 311, 406, 588, 1629, 11, 51522], "temperature": 0.0, "avg_logprob": -0.20932717225989517, "compression_ratio": 1.5774647887323943, "no_speech_prob": 0.008159337565302849}, {"id": 114, "seek": 41578, "start": 438.94, "end": 441.5, "text": " which may not be quite explained", "tokens": [51522, 597, 815, 406, 312, 1596, 8825, 51650], "temperature": 0.0, "avg_logprob": -0.20932717225989517, "compression_ratio": 1.5774647887323943, "no_speech_prob": 0.008159337565302849}, {"id": 115, "seek": 44150, "start": 441.9, "end": 446.7, "text": " in this portion of documentation.", "tokens": [50384, 294, 341, 8044, 295, 14333, 13, 50624], "temperature": 0.0, "avg_logprob": -0.3461618020500935, "compression_ratio": 1.4883720930232558, "no_speech_prob": 0.0019787601195275784}, {"id": 116, "seek": 44150, "start": 446.7, "end": 450.26, "text": " Or we can also showcase example,", "tokens": [50624, 1610, 321, 393, 611, 20388, 1365, 11, 50802], "temperature": 0.0, "avg_logprob": -0.3461618020500935, "compression_ratio": 1.4883720930232558, "no_speech_prob": 0.0019787601195275784}, {"id": 117, "seek": 44150, "start": 450.26, "end": 452.62, "text": " what existed in the docs,", "tokens": [50802, 437, 13135, 294, 264, 45623, 11, 50920], "temperature": 0.0, "avg_logprob": -0.3461618020500935, "compression_ratio": 1.4883720930232558, "no_speech_prob": 0.0019787601195275784}, {"id": 118, "seek": 44150, "start": 452.62, "end": 457.38, "text": " how we can send the output from file.", "tokens": [50920, 577, 321, 393, 2845, 264, 5598, 490, 3991, 13, 51158], "temperature": 0.0, "avg_logprob": -0.3461618020500935, "compression_ratio": 1.4883720930232558, "no_speech_prob": 0.0019787601195275784}, {"id": 119, "seek": 44150, "start": 457.38, "end": 459.42, "text": " Pretty simple here.", "tokens": [51158, 10693, 2199, 510, 13, 51260], "temperature": 0.0, "avg_logprob": -0.3461618020500935, "compression_ratio": 1.4883720930232558, "no_speech_prob": 0.0019787601195275784}, {"id": 120, "seek": 44150, "start": 459.42, "end": 464.38, "text": " Okay. If you are looking at the deep dives,", "tokens": [51260, 1033, 13, 759, 291, 366, 1237, 412, 264, 2452, 274, 1539, 11, 51508], "temperature": 0.0, "avg_logprob": -0.3461618020500935, "compression_ratio": 1.4883720930232558, "no_speech_prob": 0.0019787601195275784}, {"id": 121, "seek": 44150, "start": 464.38, "end": 467.5, "text": " there may be some interesting in terms of more functionality.", "tokens": [51508, 456, 815, 312, 512, 1880, 294, 2115, 295, 544, 14980, 13, 51664], "temperature": 0.0, "avg_logprob": -0.3461618020500935, "compression_ratio": 1.4883720930232558, "no_speech_prob": 0.0019787601195275784}, {"id": 122, "seek": 46750, "start": 467.5, "end": 468.98, "text": " Going to a database,", "tokens": [50364, 10963, 281, 257, 8149, 11, 50438], "temperature": 0.0, "avg_logprob": -0.21081939629748858, "compression_ratio": 1.6619718309859155, "no_speech_prob": 0.0237320177257061}, {"id": 123, "seek": 46750, "start": 468.98, "end": 472.38, "text": " space where I spent a lot of my time,", "tokens": [50438, 1901, 689, 286, 4418, 257, 688, 295, 452, 565, 11, 50608], "temperature": 0.0, "avg_logprob": -0.21081939629748858, "compression_ratio": 1.6619718309859155, "no_speech_prob": 0.0237320177257061}, {"id": 124, "seek": 46750, "start": 472.38, "end": 477.38, "text": " let's say we want to describe what is an absurd in SQL.", "tokens": [50608, 718, 311, 584, 321, 528, 281, 6786, 437, 307, 364, 19774, 294, 19200, 13, 50858], "temperature": 0.0, "avg_logprob": -0.21081939629748858, "compression_ratio": 1.6619718309859155, "no_speech_prob": 0.0237320177257061}, {"id": 125, "seek": 46750, "start": 478.9, "end": 481.54, "text": " All right, anybody heard what is absurd?", "tokens": [50934, 1057, 558, 11, 4472, 2198, 437, 307, 19774, 30, 51066], "temperature": 0.0, "avg_logprob": -0.21081939629748858, "compression_ratio": 1.6619718309859155, "no_speech_prob": 0.0237320177257061}, {"id": 126, "seek": 46750, "start": 481.54, "end": 483.46, "text": " Right, well, that is something like,", "tokens": [51066, 1779, 11, 731, 11, 300, 307, 746, 411, 11, 51162], "temperature": 0.0, "avg_logprob": -0.21081939629748858, "compression_ratio": 1.6619718309859155, "no_speech_prob": 0.0237320177257061}, {"id": 127, "seek": 46750, "start": 483.46, "end": 486.5, "text": " we want to insert the data,", "tokens": [51162, 321, 528, 281, 8969, 264, 1412, 11, 51314], "temperature": 0.0, "avg_logprob": -0.21081939629748858, "compression_ratio": 1.6619718309859155, "no_speech_prob": 0.0237320177257061}, {"id": 128, "seek": 46750, "start": 486.5, "end": 489.34, "text": " but if it's out there, we want to update it.", "tokens": [51314, 457, 498, 309, 311, 484, 456, 11, 321, 528, 281, 5623, 309, 13, 51456], "temperature": 0.0, "avg_logprob": -0.21081939629748858, "compression_ratio": 1.6619718309859155, "no_speech_prob": 0.0237320177257061}, {"id": 129, "seek": 46750, "start": 489.34, "end": 490.62, "text": " The very common.", "tokens": [51456, 440, 588, 2689, 13, 51520], "temperature": 0.0, "avg_logprob": -0.21081939629748858, "compression_ratio": 1.6619718309859155, "no_speech_prob": 0.0237320177257061}, {"id": 130, "seek": 46750, "start": 490.62, "end": 493.1, "text": " Okay, so we want to say,", "tokens": [51520, 1033, 11, 370, 321, 528, 281, 584, 11, 51644], "temperature": 0.0, "avg_logprob": -0.21081939629748858, "compression_ratio": 1.6619718309859155, "no_speech_prob": 0.0237320177257061}, {"id": 131, "seek": 46750, "start": 493.1, "end": 497.06, "text": " let's say we have this table out there, right?", "tokens": [51644, 718, 311, 584, 321, 362, 341, 3199, 484, 456, 11, 558, 30, 51842], "temperature": 0.0, "avg_logprob": -0.21081939629748858, "compression_ratio": 1.6619718309859155, "no_speech_prob": 0.0237320177257061}, {"id": 132, "seek": 49706, "start": 497.06, "end": 504.66, "text": " And we want to go ahead and use their MySQL insert or replace", "tokens": [50364, 400, 321, 528, 281, 352, 2286, 293, 764, 641, 1222, 39934, 8969, 420, 7406, 50744], "temperature": 0.0, "avg_logprob": -0.40680994669596354, "compression_ratio": 1.4879518072289157, "no_speech_prob": 0.013418835587799549}, {"id": 133, "seek": 49706, "start": 507.38, "end": 508.14, "text": " syntax, right?", "tokens": [50880, 28431, 11, 558, 30, 50918], "temperature": 0.0, "avg_logprob": -0.40680994669596354, "compression_ratio": 1.4879518072289157, "no_speech_prob": 0.013418835587799549}, {"id": 134, "seek": 49706, "start": 508.14, "end": 510.9, "text": " Then we want to, well, as I said,", "tokens": [50918, 1396, 321, 528, 281, 11, 731, 11, 382, 286, 848, 11, 51056], "temperature": 0.0, "avg_logprob": -0.40680994669596354, "compression_ratio": 1.4879518072289157, "no_speech_prob": 0.013418835587799549}, {"id": 135, "seek": 49706, "start": 510.9, "end": 518.58, "text": " like to update one employee's salary and then also add another", "tokens": [51056, 411, 281, 5623, 472, 10738, 311, 15360, 293, 550, 611, 909, 1071, 51440], "temperature": 0.0, "avg_logprob": -0.40680994669596354, "compression_ratio": 1.4879518072289157, "no_speech_prob": 0.013418835587799549}, {"id": 136, "seek": 49706, "start": 518.58, "end": 523.54, "text": " one, well, we can go ahead and run it.", "tokens": [51440, 472, 11, 731, 11, 321, 393, 352, 2286, 293, 1190, 309, 13, 51688], "temperature": 0.0, "avg_logprob": -0.40680994669596354, "compression_ratio": 1.4879518072289157, "no_speech_prob": 0.013418835587799549}, {"id": 137, "seek": 49706, "start": 523.54, "end": 525.34, "text": " Like why use this as example here?", "tokens": [51688, 1743, 983, 764, 341, 382, 1365, 510, 30, 51778], "temperature": 0.0, "avg_logprob": -0.40680994669596354, "compression_ratio": 1.4879518072289157, "no_speech_prob": 0.013418835587799549}, {"id": 138, "seek": 52534, "start": 526.22, "end": 530.38, "text": " Because what you can see is we are not showing everything in", "tokens": [50408, 1436, 437, 291, 393, 536, 307, 321, 366, 406, 4099, 1203, 294, 50616], "temperature": 0.0, "avg_logprob": -0.26264800238855107, "compression_ratio": 1.6442307692307692, "no_speech_prob": 0.006016059312969446}, {"id": 139, "seek": 52534, "start": 530.38, "end": 531.0600000000001, "text": " example, right?", "tokens": [50616, 1365, 11, 558, 30, 50650], "temperature": 0.0, "avg_logprob": -0.26264800238855107, "compression_ratio": 1.6442307692307692, "no_speech_prob": 0.006016059312969446}, {"id": 140, "seek": 52534, "start": 531.0600000000001, "end": 535.02, "text": " We are working with some sort of like a seed data which is,", "tokens": [50650, 492, 366, 1364, 365, 512, 1333, 295, 411, 257, 8871, 1412, 597, 307, 11, 50848], "temperature": 0.0, "avg_logprob": -0.26264800238855107, "compression_ratio": 1.6442307692307692, "no_speech_prob": 0.006016059312969446}, {"id": 141, "seek": 52534, "start": 538.1800000000001, "end": 541.26, "text": " well, was pre-created as a part of a previous scenario, right?", "tokens": [51006, 731, 11, 390, 659, 12, 66, 26559, 382, 257, 644, 295, 257, 3894, 9005, 11, 558, 30, 51160], "temperature": 0.0, "avg_logprob": -0.26264800238855107, "compression_ratio": 1.6442307692307692, "no_speech_prob": 0.006016059312969446}, {"id": 142, "seek": 52534, "start": 541.26, "end": 543.7, "text": " Which is very common.", "tokens": [51160, 3013, 307, 588, 2689, 13, 51282], "temperature": 0.0, "avg_logprob": -0.26264800238855107, "compression_ratio": 1.6442307692307692, "no_speech_prob": 0.006016059312969446}, {"id": 143, "seek": 52534, "start": 543.7, "end": 546.94, "text": " Here is also another example of the same thing,", "tokens": [51282, 1692, 307, 611, 1071, 1365, 295, 264, 912, 551, 11, 51444], "temperature": 0.0, "avg_logprob": -0.26264800238855107, "compression_ratio": 1.6442307692307692, "no_speech_prob": 0.006016059312969446}, {"id": 144, "seek": 52534, "start": 546.94, "end": 551.14, "text": " but with Postgres, right?", "tokens": [51444, 457, 365, 10223, 45189, 11, 558, 30, 51654], "temperature": 0.0, "avg_logprob": -0.26264800238855107, "compression_ratio": 1.6442307692307692, "no_speech_prob": 0.006016059312969446}, {"id": 145, "seek": 52534, "start": 551.14, "end": 553.38, "text": " Where we're using a different scenario, right?", "tokens": [51654, 2305, 321, 434, 1228, 257, 819, 9005, 11, 558, 30, 51766], "temperature": 0.0, "avg_logprob": -0.26264800238855107, "compression_ratio": 1.6442307692307692, "no_speech_prob": 0.006016059312969446}, {"id": 146, "seek": 55338, "start": 553.38, "end": 557.62, "text": " And you may ask, well, okay, this is how it works,", "tokens": [50364, 400, 291, 815, 1029, 11, 731, 11, 1392, 11, 341, 307, 577, 309, 1985, 11, 50576], "temperature": 0.0, "avg_logprob": -0.1887318261779181, "compression_ratio": 1.5211267605633803, "no_speech_prob": 0.007189170923084021}, {"id": 147, "seek": 55338, "start": 557.62, "end": 563.9, "text": " but I know also the Postgres SQL has a syntax on conflict", "tokens": [50576, 457, 286, 458, 611, 264, 10223, 45189, 19200, 575, 257, 28431, 322, 6596, 50890], "temperature": 0.0, "avg_logprob": -0.1887318261779181, "compression_ratio": 1.5211267605633803, "no_speech_prob": 0.007189170923084021}, {"id": 148, "seek": 55338, "start": 563.9, "end": 565.9, "text": " do nothing, right?", "tokens": [50890, 360, 1825, 11, 558, 30, 50990], "temperature": 0.0, "avg_logprob": -0.1887318261779181, "compression_ratio": 1.5211267605633803, "no_speech_prob": 0.007189170923084021}, {"id": 149, "seek": 55338, "start": 565.9, "end": 569.22, "text": " So what would that be if that's what we do?", "tokens": [50990, 407, 437, 576, 300, 312, 498, 300, 311, 437, 321, 360, 30, 51156], "temperature": 0.0, "avg_logprob": -0.1887318261779181, "compression_ratio": 1.5211267605633803, "no_speech_prob": 0.007189170923084021}, {"id": 150, "seek": 55338, "start": 569.22, "end": 573.7, "text": " Oh, well, in this case, we can see what the Emma's salary, right?", "tokens": [51156, 876, 11, 731, 11, 294, 341, 1389, 11, 321, 393, 536, 437, 264, 17124, 311, 15360, 11, 558, 30, 51380], "temperature": 0.0, "avg_logprob": -0.1887318261779181, "compression_ratio": 1.5211267605633803, "no_speech_prob": 0.007189170923084021}, {"id": 151, "seek": 55338, "start": 573.7, "end": 576.66, "text": " Which was a conflict in row, was not changed.", "tokens": [51380, 3013, 390, 257, 6596, 294, 5386, 11, 390, 406, 3105, 13, 51528], "temperature": 0.0, "avg_logprob": -0.1887318261779181, "compression_ratio": 1.5211267605633803, "no_speech_prob": 0.007189170923084021}, {"id": 152, "seek": 55338, "start": 576.66, "end": 581.42, "text": " So again, we can play with those things.", "tokens": [51528, 407, 797, 11, 321, 393, 862, 365, 729, 721, 13, 51766], "temperature": 0.0, "avg_logprob": -0.1887318261779181, "compression_ratio": 1.5211267605633803, "no_speech_prob": 0.007189170923084021}, {"id": 153, "seek": 58142, "start": 581.4599999999999, "end": 584.4599999999999, "text": " Okay, well, these are kind of setting landscape, I think,", "tokens": [50366, 1033, 11, 731, 11, 613, 366, 733, 295, 3287, 9661, 11, 286, 519, 11, 50516], "temperature": 0.0, "avg_logprob": -0.3083898417154948, "compression_ratio": 1.4804469273743017, "no_speech_prob": 0.004991765134036541}, {"id": 154, "seek": 58142, "start": 584.4599999999999, "end": 587.9399999999999, "text": " what things can be useful, but now let's look in terms of what", "tokens": [50516, 437, 721, 393, 312, 4420, 11, 457, 586, 718, 311, 574, 294, 2115, 295, 437, 50690], "temperature": 0.0, "avg_logprob": -0.3083898417154948, "compression_ratio": 1.4804469273743017, "no_speech_prob": 0.004991765134036541}, {"id": 155, "seek": 58142, "start": 587.9399999999999, "end": 594.38, "text": " is approach and how it works.", "tokens": [50690, 307, 3109, 293, 577, 309, 1985, 13, 51012], "temperature": 0.0, "avg_logprob": -0.3083898417154948, "compression_ratio": 1.4804469273743017, "no_speech_prob": 0.004991765134036541}, {"id": 156, "seek": 58142, "start": 594.38, "end": 600.74, "text": " Now, if you think about the tools and the doc creation, right?", "tokens": [51012, 823, 11, 498, 291, 519, 466, 264, 3873, 293, 264, 3211, 8016, 11, 558, 30, 51330], "temperature": 0.0, "avg_logprob": -0.3083898417154948, "compression_ratio": 1.4804469273743017, "no_speech_prob": 0.004991765134036541}, {"id": 157, "seek": 58142, "start": 600.74, "end": 608.14, "text": " You would find what it is not easy to find the good", "tokens": [51330, 509, 576, 915, 437, 309, 307, 406, 1858, 281, 915, 264, 665, 51700], "temperature": 0.0, "avg_logprob": -0.3083898417154948, "compression_ratio": 1.4804469273743017, "no_speech_prob": 0.004991765134036541}, {"id": 158, "seek": 60814, "start": 609.14, "end": 611.14, "text": " technical writers, right?", "tokens": [50414, 6191, 13491, 11, 558, 30, 50514], "temperature": 0.0, "avg_logprob": -0.31185595823986695, "compression_ratio": 1.6116071428571428, "no_speech_prob": 0.009050293825566769}, {"id": 159, "seek": 60814, "start": 611.14, "end": 613.14, "text": " Or documentation offers, right?", "tokens": [50514, 1610, 14333, 7736, 11, 558, 30, 50614], "temperature": 0.0, "avg_logprob": -0.31185595823986695, "compression_ratio": 1.6116071428571428, "no_speech_prob": 0.009050293825566769}, {"id": 160, "seek": 60814, "start": 613.14, "end": 619.14, "text": " And they also can be rather, well, let's go like a selfish", "tokens": [50614, 400, 436, 611, 393, 312, 2831, 11, 731, 11, 718, 311, 352, 411, 257, 19074, 50914], "temperature": 0.0, "avg_logprob": -0.31185595823986695, "compression_ratio": 1.6116071428571428, "no_speech_prob": 0.009050293825566769}, {"id": 161, "seek": 60814, "start": 619.14, "end": 620.14, "text": " of a time, right?", "tokens": [50914, 295, 257, 565, 11, 558, 30, 50964], "temperature": 0.0, "avg_logprob": -0.31185595823986695, "compression_ratio": 1.6116071428571428, "no_speech_prob": 0.009050293825566769}, {"id": 162, "seek": 60814, "start": 620.14, "end": 623.14, "text": " They don't want to do a lot of useless crap, right?", "tokens": [50964, 814, 500, 380, 528, 281, 360, 257, 688, 295, 14115, 12426, 11, 558, 30, 51114], "temperature": 0.0, "avg_logprob": -0.31185595823986695, "compression_ratio": 1.6116071428571428, "no_speech_prob": 0.009050293825566769}, {"id": 163, "seek": 60814, "start": 623.14, "end": 624.14, "text": " In this case.", "tokens": [51114, 682, 341, 1389, 13, 51164], "temperature": 0.0, "avg_logprob": -0.31185595823986695, "compression_ratio": 1.6116071428571428, "no_speech_prob": 0.009050293825566769}, {"id": 164, "seek": 60814, "start": 624.14, "end": 628.14, "text": " So we want to make sure that writer experience is important,", "tokens": [51164, 407, 321, 528, 281, 652, 988, 300, 9936, 1752, 307, 1021, 11, 51364], "temperature": 0.0, "avg_logprob": -0.31185595823986695, "compression_ratio": 1.6116071428571428, "no_speech_prob": 0.009050293825566769}, {"id": 165, "seek": 60814, "start": 628.14, "end": 632.14, "text": " not just the reader experience, which we already defined,", "tokens": [51364, 406, 445, 264, 15149, 1752, 11, 597, 321, 1217, 7642, 11, 51564], "temperature": 0.0, "avg_logprob": -0.31185595823986695, "compression_ratio": 1.6116071428571428, "no_speech_prob": 0.009050293825566769}, {"id": 166, "seek": 60814, "start": 632.14, "end": 637.14, "text": " has one of those interactive playgrounds.", "tokens": [51564, 575, 472, 295, 729, 15141, 24646, 82, 13, 51814], "temperature": 0.0, "avg_logprob": -0.31185595823986695, "compression_ratio": 1.6116071428571428, "no_speech_prob": 0.009050293825566769}, {"id": 167, "seek": 63714, "start": 638.14, "end": 642.14, "text": " So what approach we took in this project is saying how we can", "tokens": [50414, 407, 437, 3109, 321, 1890, 294, 341, 1716, 307, 1566, 577, 321, 393, 50614], "temperature": 0.0, "avg_logprob": -0.13764721887153492, "compression_ratio": 1.664092664092664, "no_speech_prob": 0.011538674123585224}, {"id": 168, "seek": 63714, "start": 642.14, "end": 647.14, "text": " make it as sort of like a seamless as possible, right?", "tokens": [50614, 652, 309, 382, 1333, 295, 411, 257, 28677, 382, 1944, 11, 558, 30, 50864], "temperature": 0.0, "avg_logprob": -0.13764721887153492, "compression_ratio": 1.664092664092664, "no_speech_prob": 0.011538674123585224}, {"id": 169, "seek": 63714, "start": 647.14, "end": 651.14, "text": " We don't want to say, hey, you know what, you are going to create", "tokens": [50864, 492, 500, 380, 528, 281, 584, 11, 4177, 11, 291, 458, 437, 11, 291, 366, 516, 281, 1884, 51064], "temperature": 0.0, "avg_logprob": -0.13764721887153492, "compression_ratio": 1.664092664092664, "no_speech_prob": 0.011538674123585224}, {"id": 170, "seek": 63714, "start": 651.14, "end": 655.14, "text": " our interactive code playground in completely different tooling,", "tokens": [51064, 527, 15141, 3089, 24646, 294, 2584, 819, 46593, 11, 51264], "temperature": 0.0, "avg_logprob": -0.13764721887153492, "compression_ratio": 1.664092664092664, "no_speech_prob": 0.011538674123585224}, {"id": 171, "seek": 63714, "start": 655.14, "end": 657.14, "text": " right, separate from documentation, right?", "tokens": [51264, 558, 11, 4994, 490, 14333, 11, 558, 30, 51364], "temperature": 0.0, "avg_logprob": -0.13764721887153492, "compression_ratio": 1.664092664092664, "no_speech_prob": 0.011538674123585224}, {"id": 172, "seek": 63714, "start": 657.14, "end": 661.14, "text": " And then figure out is that going to live in the same version", "tokens": [51364, 400, 550, 2573, 484, 307, 300, 516, 281, 1621, 294, 264, 912, 3037, 51564], "temperature": 0.0, "avg_logprob": -0.13764721887153492, "compression_ratio": 1.664092664092664, "no_speech_prob": 0.011538674123585224}, {"id": 173, "seek": 63714, "start": 661.14, "end": 663.14, "text": " control, right, and so on and so forth, right?", "tokens": [51564, 1969, 11, 558, 11, 293, 370, 322, 293, 370, 5220, 11, 558, 30, 51664], "temperature": 0.0, "avg_logprob": -0.13764721887153492, "compression_ratio": 1.664092664092664, "no_speech_prob": 0.011538674123585224}, {"id": 174, "seek": 63714, "start": 663.14, "end": 666.14, "text": " Or, you know, things like that.", "tokens": [51664, 1610, 11, 291, 458, 11, 721, 411, 300, 13, 51814], "temperature": 0.0, "avg_logprob": -0.13764721887153492, "compression_ratio": 1.664092664092664, "no_speech_prob": 0.011538674123585224}, {"id": 175, "seek": 66614, "start": 666.14, "end": 670.14, "text": " What we want in this case is to have your documentation, right,", "tokens": [50364, 708, 321, 528, 294, 341, 1389, 307, 281, 362, 428, 14333, 11, 558, 11, 50564], "temperature": 0.0, "avg_logprob": -0.1411096931684135, "compression_ratio": 1.6766169154228856, "no_speech_prob": 0.015602639876306057}, {"id": 176, "seek": 66614, "start": 670.14, "end": 673.14, "text": " which was this, right?", "tokens": [50564, 597, 390, 341, 11, 558, 30, 50714], "temperature": 0.0, "avg_logprob": -0.1411096931684135, "compression_ratio": 1.6766169154228856, "no_speech_prob": 0.015602639876306057}, {"id": 177, "seek": 66614, "start": 673.14, "end": 678.14, "text": " Just as easy as possible, add the ability to run and to edit", "tokens": [50714, 1449, 382, 1858, 382, 1944, 11, 909, 264, 3485, 281, 1190, 293, 281, 8129, 50964], "temperature": 0.0, "avg_logprob": -0.1411096931684135, "compression_ratio": 1.6766169154228856, "no_speech_prob": 0.015602639876306057}, {"id": 178, "seek": 66614, "start": 678.14, "end": 680.14, "text": " and run, right?", "tokens": [50964, 293, 1190, 11, 558, 30, 51064], "temperature": 0.0, "avg_logprob": -0.1411096931684135, "compression_ratio": 1.6766169154228856, "no_speech_prob": 0.015602639876306057}, {"id": 179, "seek": 66614, "start": 680.14, "end": 684.14, "text": " So you can say, hey, we added, you can see the run and edit here.", "tokens": [51064, 407, 291, 393, 584, 11, 4177, 11, 321, 3869, 11, 291, 393, 536, 264, 1190, 293, 8129, 510, 13, 51264], "temperature": 0.0, "avg_logprob": -0.1411096931684135, "compression_ratio": 1.6766169154228856, "no_speech_prob": 0.015602639876306057}, {"id": 180, "seek": 66614, "start": 684.14, "end": 687.14, "text": " And if I run, you can see what is the output of that", "tokens": [51264, 400, 498, 286, 1190, 11, 291, 393, 536, 437, 307, 264, 5598, 295, 300, 51414], "temperature": 0.0, "avg_logprob": -0.1411096931684135, "compression_ratio": 1.6766169154228856, "no_speech_prob": 0.015602639876306057}, {"id": 181, "seek": 66614, "start": 687.14, "end": 689.14, "text": " documentation example is.", "tokens": [51414, 14333, 1365, 307, 13, 51514], "temperature": 0.0, "avg_logprob": -0.1411096931684135, "compression_ratio": 1.6766169154228856, "no_speech_prob": 0.015602639876306057}, {"id": 182, "seek": 66614, "start": 689.14, "end": 692.14, "text": " So how can we approach that?", "tokens": [51514, 407, 577, 393, 321, 3109, 300, 30, 51664], "temperature": 0.0, "avg_logprob": -0.1411096931684135, "compression_ratio": 1.6766169154228856, "no_speech_prob": 0.015602639876306057}, {"id": 183, "seek": 69214, "start": 692.14, "end": 697.14, "text": " So it is easy or integration which is easy on writing.", "tokens": [50364, 407, 309, 307, 1858, 420, 10980, 597, 307, 1858, 322, 3579, 13, 50614], "temperature": 0.0, "avg_logprob": -0.12579996130439672, "compression_ratio": 1.5, "no_speech_prob": 0.003899655304849148}, {"id": 184, "seek": 69214, "start": 697.14, "end": 701.14, "text": " Well, it's actually quite easy.", "tokens": [50614, 1042, 11, 309, 311, 767, 1596, 1858, 13, 50814], "temperature": 0.0, "avg_logprob": -0.12579996130439672, "compression_ratio": 1.5, "no_speech_prob": 0.003899655304849148}, {"id": 185, "seek": 69214, "start": 701.14, "end": 706.14, "text": " So what we have is you are writing documentation in the same", "tokens": [50814, 407, 437, 321, 362, 307, 291, 366, 3579, 14333, 294, 264, 912, 51064], "temperature": 0.0, "avg_logprob": -0.12579996130439672, "compression_ratio": 1.5, "no_speech_prob": 0.003899655304849148}, {"id": 186, "seek": 69214, "start": 706.14, "end": 708.14, "text": " format as you got used to, right?", "tokens": [51064, 7877, 382, 291, 658, 1143, 281, 11, 558, 30, 51164], "temperature": 0.0, "avg_logprob": -0.12579996130439672, "compression_ratio": 1.5, "no_speech_prob": 0.003899655304849148}, {"id": 187, "seek": 69214, "start": 708.14, "end": 712.14, "text": " Let's say maybe it's a markup language, as in this example,", "tokens": [51164, 961, 311, 584, 1310, 309, 311, 257, 1491, 1010, 2856, 11, 382, 294, 341, 1365, 11, 51364], "temperature": 0.0, "avg_logprob": -0.12579996130439672, "compression_ratio": 1.5, "no_speech_prob": 0.003899655304849148}, {"id": 188, "seek": 69214, "start": 712.14, "end": 714.14, "text": " or something else.", "tokens": [51364, 420, 746, 1646, 13, 51464], "temperature": 0.0, "avg_logprob": -0.12579996130439672, "compression_ratio": 1.5, "no_speech_prob": 0.003899655304849148}, {"id": 189, "seek": 69214, "start": 714.14, "end": 721.14, "text": " And then you can embed this like a code API widget.", "tokens": [51464, 400, 550, 291, 393, 12240, 341, 411, 257, 3089, 9362, 34047, 13, 51814], "temperature": 0.0, "avg_logprob": -0.12579996130439672, "compression_ratio": 1.5, "no_speech_prob": 0.003899655304849148}, {"id": 190, "seek": 72114, "start": 721.14, "end": 728.14, "text": " That widget itself will figure out the previous code block", "tokens": [50364, 663, 34047, 2564, 486, 2573, 484, 264, 3894, 3089, 3461, 50714], "temperature": 0.0, "avg_logprob": -0.09673685016054095, "compression_ratio": 1.4576271186440677, "no_speech_prob": 0.003566198283806443}, {"id": 191, "seek": 72114, "start": 728.14, "end": 730.14, "text": " and make it interactive, right?", "tokens": [50714, 293, 652, 309, 15141, 11, 558, 30, 50814], "temperature": 0.0, "avg_logprob": -0.09673685016054095, "compression_ratio": 1.4576271186440677, "no_speech_prob": 0.003566198283806443}, {"id": 192, "seek": 72114, "start": 730.14, "end": 734.14, "text": " So there is no, like, some special thing required,", "tokens": [50814, 407, 456, 307, 572, 11, 411, 11, 512, 2121, 551, 4739, 11, 51014], "temperature": 0.0, "avg_logprob": -0.09673685016054095, "compression_ratio": 1.4576271186440677, "no_speech_prob": 0.003566198283806443}, {"id": 193, "seek": 72114, "start": 734.14, "end": 740.14, "text": " and that pretty much works in any documentation thing", "tokens": [51014, 293, 300, 1238, 709, 1985, 294, 604, 14333, 551, 51314], "temperature": 0.0, "avg_logprob": -0.09673685016054095, "compression_ratio": 1.4576271186440677, "no_speech_prob": 0.003566198283806443}, {"id": 194, "seek": 72114, "start": 740.14, "end": 744.14, "text": " which already exists, right?", "tokens": [51314, 597, 1217, 8198, 11, 558, 30, 51514], "temperature": 0.0, "avg_logprob": -0.09673685016054095, "compression_ratio": 1.4576271186440677, "no_speech_prob": 0.003566198283806443}, {"id": 195, "seek": 72114, "start": 744.14, "end": 747.14, "text": " So you can see that example here.", "tokens": [51514, 407, 291, 393, 536, 300, 1365, 510, 13, 51664], "temperature": 0.0, "avg_logprob": -0.09673685016054095, "compression_ratio": 1.4576271186440677, "no_speech_prob": 0.003566198283806443}, {"id": 196, "seek": 74714, "start": 747.14, "end": 758.14, "text": " So the code which existed here just gets interactive.", "tokens": [50364, 407, 264, 3089, 597, 13135, 510, 445, 2170, 15141, 13, 50914], "temperature": 0.0, "avg_logprob": -0.13605450045677922, "compression_ratio": 1.3652694610778444, "no_speech_prob": 0.006309026852250099}, {"id": 197, "seek": 74714, "start": 758.14, "end": 763.14, "text": " So, well, of course, hello world is always easier, right?", "tokens": [50914, 407, 11, 731, 11, 295, 1164, 11, 7751, 1002, 307, 1009, 3571, 11, 558, 30, 51164], "temperature": 0.0, "avg_logprob": -0.13605450045677922, "compression_ratio": 1.3652694610778444, "no_speech_prob": 0.006309026852250099}, {"id": 198, "seek": 74714, "start": 763.14, "end": 768.14, "text": " Let's look at some more complicated examples.", "tokens": [51164, 961, 311, 574, 412, 512, 544, 6179, 5110, 13, 51414], "temperature": 0.0, "avg_logprob": -0.13605450045677922, "compression_ratio": 1.3652694610778444, "no_speech_prob": 0.006309026852250099}, {"id": 199, "seek": 74714, "start": 768.14, "end": 773.14, "text": " One, I think, which is very important is the template", "tokens": [51414, 1485, 11, 286, 519, 11, 597, 307, 588, 1021, 307, 264, 12379, 51664], "temperature": 0.0, "avg_logprob": -0.13605450045677922, "compression_ratio": 1.3652694610778444, "no_speech_prob": 0.006309026852250099}, {"id": 200, "seek": 74714, "start": 773.14, "end": 774.14, "text": " approach, right?", "tokens": [51664, 3109, 11, 558, 30, 51714], "temperature": 0.0, "avg_logprob": -0.13605450045677922, "compression_ratio": 1.3652694610778444, "no_speech_prob": 0.006309026852250099}, {"id": 201, "seek": 77414, "start": 774.14, "end": 777.14, "text": " I think what I briefly mentioned already,", "tokens": [50364, 286, 519, 437, 286, 10515, 2835, 1217, 11, 50514], "temperature": 0.0, "avg_logprob": -0.12728997115250473, "compression_ratio": 1.5315315315315314, "no_speech_prob": 0.016725145280361176}, {"id": 202, "seek": 77414, "start": 777.14, "end": 780.14, "text": " if I want to show something like this, right?", "tokens": [50514, 498, 286, 528, 281, 855, 746, 411, 341, 11, 558, 30, 50664], "temperature": 0.0, "avg_logprob": -0.12728997115250473, "compression_ratio": 1.5315315315315314, "no_speech_prob": 0.016725145280361176}, {"id": 203, "seek": 77414, "start": 780.14, "end": 787.14, "text": " That is like a relatively, you know, complicated query, right?", "tokens": [50664, 663, 307, 411, 257, 7226, 11, 291, 458, 11, 6179, 14581, 11, 558, 30, 51014], "temperature": 0.0, "avg_logprob": -0.12728997115250473, "compression_ratio": 1.5315315315315314, "no_speech_prob": 0.016725145280361176}, {"id": 204, "seek": 77414, "start": 787.14, "end": 794.14, "text": " For that to be meaningful, I also need to pre-generate table", "tokens": [51014, 1171, 300, 281, 312, 10995, 11, 286, 611, 643, 281, 659, 12, 21848, 473, 3199, 51364], "temperature": 0.0, "avg_logprob": -0.12728997115250473, "compression_ratio": 1.5315315315315314, "no_speech_prob": 0.016725145280361176}, {"id": 205, "seek": 77414, "start": 794.14, "end": 797.14, "text": " in this case, which I probably do not want to have", "tokens": [51364, 294, 341, 1389, 11, 597, 286, 1391, 360, 406, 528, 281, 362, 51514], "temperature": 0.0, "avg_logprob": -0.12728997115250473, "compression_ratio": 1.5315315315315314, "no_speech_prob": 0.016725145280361176}, {"id": 206, "seek": 77414, "start": 797.14, "end": 799.14, "text": " on my documentation thing.", "tokens": [51514, 322, 452, 14333, 551, 13, 51614], "temperature": 0.0, "avg_logprob": -0.12728997115250473, "compression_ratio": 1.5315315315315314, "no_speech_prob": 0.016725145280361176}, {"id": 207, "seek": 77414, "start": 799.14, "end": 803.14, "text": " And this is designed done by providing a template.", "tokens": [51614, 400, 341, 307, 4761, 1096, 538, 6530, 257, 12379, 13, 51814], "temperature": 0.0, "avg_logprob": -0.12728997115250473, "compression_ratio": 1.5315315315315314, "no_speech_prob": 0.016725145280361176}, {"id": 208, "seek": 80314, "start": 803.14, "end": 807.14, "text": " So a template in this case is basically something which is", "tokens": [50364, 407, 257, 12379, 294, 341, 1389, 307, 1936, 746, 597, 307, 50564], "temperature": 0.0, "avg_logprob": -0.23992554859448506, "compression_ratio": 1.6431924882629108, "no_speech_prob": 0.006805552635341883}, {"id": 209, "seek": 80314, "start": 807.14, "end": 814.14, "text": " run before the scenario is done, right?", "tokens": [50564, 1190, 949, 264, 9005, 307, 1096, 11, 558, 30, 50914], "temperature": 0.0, "avg_logprob": -0.23992554859448506, "compression_ratio": 1.6431924882629108, "no_speech_prob": 0.006805552635341883}, {"id": 210, "seek": 80314, "start": 814.14, "end": 817.14, "text": " And in this case, I can write some text and, hey,", "tokens": [50914, 400, 294, 341, 1389, 11, 286, 393, 2464, 512, 2487, 293, 11, 4177, 11, 51064], "temperature": 0.0, "avg_logprob": -0.23992554859448506, "compression_ratio": 1.6431924882629108, "no_speech_prob": 0.006805552635341883}, {"id": 211, "seek": 80314, "start": 817.14, "end": 819.14, "text": " I created a table, but I'm not really specifically", "tokens": [51064, 286, 2942, 257, 3199, 11, 457, 286, 478, 406, 534, 4682, 51164], "temperature": 0.0, "avg_logprob": -0.23992554859448506, "compression_ratio": 1.6431924882629108, "no_speech_prob": 0.006805552635341883}, {"id": 212, "seek": 80314, "start": 819.14, "end": 821.14, "text": " final comments because there's a irrelevant in this case.", "tokens": [51164, 2572, 3053, 570, 456, 311, 257, 28682, 294, 341, 1389, 13, 51264], "temperature": 0.0, "avg_logprob": -0.23992554859448506, "compression_ratio": 1.6431924882629108, "no_speech_prob": 0.006805552635341883}, {"id": 213, "seek": 80314, "start": 821.14, "end": 826.14, "text": " I populated with some data and then I have a code,", "tokens": [51264, 286, 32998, 365, 512, 1412, 293, 550, 286, 362, 257, 3089, 11, 51514], "temperature": 0.0, "avg_logprob": -0.23992554859448506, "compression_ratio": 1.6431924882629108, "no_speech_prob": 0.006805552635341883}, {"id": 214, "seek": 80314, "start": 826.14, "end": 832.14, "text": " the code which was created before, right?", "tokens": [51514, 264, 3089, 597, 390, 2942, 949, 11, 558, 30, 51814], "temperature": 0.0, "avg_logprob": -0.23992554859448506, "compression_ratio": 1.6431924882629108, "no_speech_prob": 0.006805552635341883}, {"id": 215, "seek": 83214, "start": 832.14, "end": 837.14, "text": " That is how template would look like.", "tokens": [50364, 663, 307, 577, 12379, 576, 574, 411, 13, 50614], "temperature": 0.0, "avg_logprob": -0.1881779581308365, "compression_ratio": 1.4464285714285714, "no_speech_prob": 0.003361302427947521}, {"id": 216, "seek": 83214, "start": 837.14, "end": 844.14, "text": " So I can highlight, right, where exactly in the context,", "tokens": [50614, 407, 286, 393, 5078, 11, 558, 11, 689, 2293, 294, 264, 4319, 11, 50964], "temperature": 0.0, "avg_logprob": -0.1881779581308365, "compression_ratio": 1.4464285714285714, "no_speech_prob": 0.003361302427947521}, {"id": 217, "seek": 83214, "start": 844.14, "end": 849.14, "text": " I want to run that code which was,", "tokens": [50964, 286, 528, 281, 1190, 300, 3089, 597, 390, 11, 51214], "temperature": 0.0, "avg_logprob": -0.1881779581308365, "compression_ratio": 1.4464285714285714, "no_speech_prob": 0.003361302427947521}, {"id": 218, "seek": 83214, "start": 849.14, "end": 853.14, "text": " which is interactive part of the documentation.", "tokens": [51214, 597, 307, 15141, 644, 295, 264, 14333, 13, 51414], "temperature": 0.0, "avg_logprob": -0.1881779581308365, "compression_ratio": 1.4464285714285714, "no_speech_prob": 0.003361302427947521}, {"id": 219, "seek": 83214, "start": 853.14, "end": 861.14, "text": " Okay, so here is another thing which you will find quite helpful.", "tokens": [51414, 1033, 11, 370, 510, 307, 1071, 551, 597, 291, 486, 915, 1596, 4961, 13, 51814], "temperature": 0.0, "avg_logprob": -0.1881779581308365, "compression_ratio": 1.4464285714285714, "no_speech_prob": 0.003361302427947521}, {"id": 220, "seek": 86114, "start": 861.14, "end": 865.14, "text": " So if you are building some sort of tutorial, right,", "tokens": [50364, 407, 498, 291, 366, 2390, 512, 1333, 295, 7073, 11, 558, 11, 50564], "temperature": 0.0, "avg_logprob": -0.10049099507539169, "compression_ratio": 1.681159420289855, "no_speech_prob": 0.001827101456001401}, {"id": 221, "seek": 86114, "start": 865.14, "end": 868.14, "text": " building the tutorial, right, you would often want to say,", "tokens": [50564, 2390, 264, 7073, 11, 558, 11, 291, 576, 2049, 528, 281, 584, 11, 50714], "temperature": 0.0, "avg_logprob": -0.10049099507539169, "compression_ratio": 1.681159420289855, "no_speech_prob": 0.001827101456001401}, {"id": 222, "seek": 86114, "start": 868.14, "end": 875.14, "text": " hey, there is actually multiple steps where I need the user", "tokens": [50714, 4177, 11, 456, 307, 767, 3866, 4439, 689, 286, 643, 264, 4195, 51064], "temperature": 0.0, "avg_logprob": -0.10049099507539169, "compression_ratio": 1.681159420289855, "no_speech_prob": 0.001827101456001401}, {"id": 223, "seek": 86114, "start": 875.14, "end": 879.14, "text": " to go through them one after another.", "tokens": [51064, 281, 352, 807, 552, 472, 934, 1071, 13, 51264], "temperature": 0.0, "avg_logprob": -0.10049099507539169, "compression_ratio": 1.681159420289855, "no_speech_prob": 0.001827101456001401}, {"id": 224, "seek": 86114, "start": 879.14, "end": 881.14, "text": " And that is an example here.", "tokens": [51264, 400, 300, 307, 364, 1365, 510, 13, 51364], "temperature": 0.0, "avg_logprob": -0.10049099507539169, "compression_ratio": 1.681159420289855, "no_speech_prob": 0.001827101456001401}, {"id": 225, "seek": 86114, "start": 881.14, "end": 885.14, "text": " What you can see is what we are defining the function", "tokens": [51364, 708, 291, 393, 536, 307, 437, 321, 366, 17827, 264, 2445, 51564], "temperature": 0.0, "avg_logprob": -0.10049099507539169, "compression_ratio": 1.681159420289855, "no_speech_prob": 0.001827101456001401}, {"id": 226, "seek": 86114, "start": 885.14, "end": 890.14, "text": " in a one-code block and then we are using that function", "tokens": [51564, 294, 257, 472, 12, 22332, 3461, 293, 550, 321, 366, 1228, 300, 2445, 51814], "temperature": 0.0, "avg_logprob": -0.10049099507539169, "compression_ratio": 1.681159420289855, "no_speech_prob": 0.001827101456001401}, {"id": 227, "seek": 89014, "start": 891.14, "end": 894.14, "text": " in a in a another code block, right?", "tokens": [50414, 294, 257, 294, 257, 1071, 3089, 3461, 11, 558, 30, 50564], "temperature": 0.0, "avg_logprob": -0.1904425537377073, "compression_ratio": 1.6483050847457628, "no_speech_prob": 0.0039338963106274605}, {"id": 228, "seek": 89014, "start": 894.14, "end": 898.14, "text": " We can, and I'll show you in a second, define dependency", "tokens": [50564, 492, 393, 11, 293, 286, 603, 855, 291, 294, 257, 1150, 11, 6964, 33621, 50764], "temperature": 0.0, "avg_logprob": -0.1904425537377073, "compression_ratio": 1.6483050847457628, "no_speech_prob": 0.0039338963106274605}, {"id": 229, "seek": 89014, "start": 898.14, "end": 900.14, "text": " between those code blocks.", "tokens": [50764, 1296, 729, 3089, 8474, 13, 50864], "temperature": 0.0, "avg_logprob": -0.1904425537377073, "compression_ratio": 1.6483050847457628, "no_speech_prob": 0.0039338963106274605}, {"id": 230, "seek": 89014, "start": 900.14, "end": 904.14, "text": " That means when you are running this second section,", "tokens": [50864, 663, 1355, 562, 291, 366, 2614, 341, 1150, 3541, 11, 51064], "temperature": 0.0, "avg_logprob": -0.1904425537377073, "compression_ratio": 1.6483050847457628, "no_speech_prob": 0.0039338963106274605}, {"id": 231, "seek": 89014, "start": 904.14, "end": 907.14, "text": " the first section would always be run,", "tokens": [51064, 264, 700, 3541, 576, 1009, 312, 1190, 11, 51214], "temperature": 0.0, "avg_logprob": -0.1904425537377073, "compression_ratio": 1.6483050847457628, "no_speech_prob": 0.0039338963106274605}, {"id": 232, "seek": 89014, "start": 907.14, "end": 912.14, "text": " like let me, I don't know, let's say break this code, right?", "tokens": [51214, 411, 718, 385, 11, 286, 500, 380, 458, 11, 718, 311, 584, 1821, 341, 3089, 11, 558, 30, 51464], "temperature": 0.0, "avg_logprob": -0.1904425537377073, "compression_ratio": 1.6483050847457628, "no_speech_prob": 0.0039338963106274605}, {"id": 233, "seek": 89014, "start": 912.14, "end": 915.14, "text": " For example, and then I can go ahead and run the second one.", "tokens": [51464, 1171, 1365, 11, 293, 550, 286, 393, 352, 2286, 293, 1190, 264, 1150, 472, 13, 51614], "temperature": 0.0, "avg_logprob": -0.1904425537377073, "compression_ratio": 1.6483050847457628, "no_speech_prob": 0.0039338963106274605}, {"id": 234, "seek": 89014, "start": 915.14, "end": 919.14, "text": " It says, oh, well, you know, things got broken, right,", "tokens": [51614, 467, 1619, 11, 1954, 11, 731, 11, 291, 458, 11, 721, 658, 5463, 11, 558, 11, 51814], "temperature": 0.0, "avg_logprob": -0.1904425537377073, "compression_ratio": 1.6483050847457628, "no_speech_prob": 0.0039338963106274605}, {"id": 235, "seek": 91914, "start": 919.14, "end": 922.14, "text": " on the previous stuff, right?", "tokens": [50364, 322, 264, 3894, 1507, 11, 558, 30, 50514], "temperature": 0.0, "avg_logprob": -0.10315550827398533, "compression_ratio": 1.7083333333333333, "no_speech_prob": 0.008079898543655872}, {"id": 236, "seek": 91914, "start": 922.14, "end": 927.14, "text": " And how that works is what we identify,", "tokens": [50514, 400, 577, 300, 1985, 307, 437, 321, 5876, 11, 50764], "temperature": 0.0, "avg_logprob": -0.10315550827398533, "compression_ratio": 1.7083333333333333, "no_speech_prob": 0.008079898543655872}, {"id": 237, "seek": 91914, "start": 927.14, "end": 932.14, "text": " we refer to the first one as a cell number two, right?", "tokens": [50764, 321, 2864, 281, 264, 700, 472, 382, 257, 2815, 1230, 732, 11, 558, 30, 51014], "temperature": 0.0, "avg_logprob": -0.10315550827398533, "compression_ratio": 1.7083333333333333, "no_speech_prob": 0.008079898543655872}, {"id": 238, "seek": 91914, "start": 932.14, "end": 937.14, "text": " And then identify the second snippet as a cell", "tokens": [51014, 400, 550, 5876, 264, 1150, 35623, 302, 382, 257, 2815, 51264], "temperature": 0.0, "avg_logprob": -0.10315550827398533, "compression_ratio": 1.7083333333333333, "no_speech_prob": 0.008079898543655872}, {"id": 239, "seek": 91914, "start": 937.14, "end": 940.14, "text": " which depends on a cell number two, right?", "tokens": [51264, 597, 5946, 322, 257, 2815, 1230, 732, 11, 558, 30, 51414], "temperature": 0.0, "avg_logprob": -0.10315550827398533, "compression_ratio": 1.7083333333333333, "no_speech_prob": 0.008079898543655872}, {"id": 240, "seek": 91914, "start": 940.14, "end": 943.14, "text": " That means pretty much that the content of that cell", "tokens": [51414, 663, 1355, 1238, 709, 300, 264, 2701, 295, 300, 2815, 51564], "temperature": 0.0, "avg_logprob": -0.10315550827398533, "compression_ratio": 1.7083333333333333, "no_speech_prob": 0.008079898543655872}, {"id": 241, "seek": 91914, "start": 943.14, "end": 946.14, "text": " is going to be run.", "tokens": [51564, 307, 516, 281, 312, 1190, 13, 51714], "temperature": 0.0, "avg_logprob": -0.10315550827398533, "compression_ratio": 1.7083333333333333, "no_speech_prob": 0.008079898543655872}, {"id": 242, "seek": 94614, "start": 947.14, "end": 950.14, "text": " Then the second cell is run, right?", "tokens": [50414, 1396, 264, 1150, 2815, 307, 1190, 11, 558, 30, 50564], "temperature": 0.0, "avg_logprob": -0.1260533633532825, "compression_ratio": 1.5594713656387664, "no_speech_prob": 0.0010290717473253608}, {"id": 243, "seek": 94614, "start": 950.14, "end": 952.14, "text": " Even if you, as users, don't click run, right?", "tokens": [50564, 2754, 498, 291, 11, 382, 5022, 11, 500, 380, 2052, 1190, 11, 558, 30, 50664], "temperature": 0.0, "avg_logprob": -0.1260533633532825, "compression_ratio": 1.5594713656387664, "no_speech_prob": 0.0010290717473253608}, {"id": 244, "seek": 94614, "start": 952.14, "end": 955.14, "text": " If you say, hey, I don't want to go through", "tokens": [50664, 759, 291, 584, 11, 4177, 11, 286, 500, 380, 528, 281, 352, 807, 50814], "temperature": 0.0, "avg_logprob": -0.1260533633532825, "compression_ratio": 1.5594713656387664, "no_speech_prob": 0.0010290717473253608}, {"id": 245, "seek": 94614, "start": 955.14, "end": 957.14, "text": " all those like five steps in tutorial,", "tokens": [50814, 439, 729, 411, 1732, 4439, 294, 7073, 11, 50914], "temperature": 0.0, "avg_logprob": -0.1260533633532825, "compression_ratio": 1.5594713656387664, "no_speech_prob": 0.0010290717473253608}, {"id": 246, "seek": 94614, "start": 957.14, "end": 959.14, "text": " I want to start with step number six", "tokens": [50914, 286, 528, 281, 722, 365, 1823, 1230, 2309, 51014], "temperature": 0.0, "avg_logprob": -0.1260533633532825, "compression_ratio": 1.5594713656387664, "no_speech_prob": 0.0010290717473253608}, {"id": 247, "seek": 94614, "start": 959.14, "end": 961.14, "text": " because that is where the real meet happens.", "tokens": [51014, 570, 300, 307, 689, 264, 957, 1677, 2314, 13, 51114], "temperature": 0.0, "avg_logprob": -0.1260533633532825, "compression_ratio": 1.5594713656387664, "no_speech_prob": 0.0010290717473253608}, {"id": 248, "seek": 94614, "start": 961.14, "end": 963.14, "text": " You can do it, right?", "tokens": [51114, 509, 393, 360, 309, 11, 558, 30, 51214], "temperature": 0.0, "avg_logprob": -0.1260533633532825, "compression_ratio": 1.5594713656387664, "no_speech_prob": 0.0010290717473253608}, {"id": 249, "seek": 94614, "start": 963.14, "end": 965.14, "text": " You can just jump in the middle.", "tokens": [51214, 509, 393, 445, 3012, 294, 264, 2808, 13, 51314], "temperature": 0.0, "avg_logprob": -0.1260533633532825, "compression_ratio": 1.5594713656387664, "no_speech_prob": 0.0010290717473253608}, {"id": 250, "seek": 94614, "start": 965.14, "end": 966.14, "text": " Okay.", "tokens": [51314, 1033, 13, 51364], "temperature": 0.0, "avg_logprob": -0.1260533633532825, "compression_ratio": 1.5594713656387664, "no_speech_prob": 0.0010290717473253608}, {"id": 251, "seek": 94614, "start": 966.14, "end": 972.14, "text": " So finally, so how does that all things work?", "tokens": [51364, 407, 2721, 11, 370, 577, 775, 300, 439, 721, 589, 30, 51664], "temperature": 0.0, "avg_logprob": -0.1260533633532825, "compression_ratio": 1.5594713656387664, "no_speech_prob": 0.0010290717473253608}, {"id": 252, "seek": 97214, "start": 972.14, "end": 980.14, "text": " Well, there are actually a couple of ways it can work.", "tokens": [50364, 1042, 11, 456, 366, 767, 257, 1916, 295, 2098, 309, 393, 589, 13, 50764], "temperature": 0.0, "avg_logprob": -0.1546521033010175, "compression_ratio": 1.3846153846153846, "no_speech_prob": 0.014732122421264648}, {"id": 253, "seek": 97214, "start": 980.14, "end": 985.14, "text": " One is we can have a browser playground", "tokens": [50764, 1485, 307, 321, 393, 362, 257, 11185, 24646, 51014], "temperature": 0.0, "avg_logprob": -0.1546521033010175, "compression_ratio": 1.3846153846153846, "no_speech_prob": 0.014732122421264648}, {"id": 254, "seek": 97214, "start": 985.14, "end": 990.14, "text": " and then a sandbox environment, right?", "tokens": [51014, 293, 550, 257, 42115, 2823, 11, 558, 30, 51264], "temperature": 0.0, "avg_logprob": -0.1546521033010175, "compression_ratio": 1.3846153846153846, "no_speech_prob": 0.014732122421264648}, {"id": 255, "seek": 97214, "start": 990.14, "end": 997.14, "text": " Which is pretty much docker-based, right?", "tokens": [51264, 3013, 307, 1238, 709, 360, 9178, 12, 6032, 11, 558, 30, 51614], "temperature": 0.0, "avg_logprob": -0.1546521033010175, "compression_ratio": 1.3846153846153846, "no_speech_prob": 0.014732122421264648}, {"id": 256, "seek": 97214, "start": 997.14, "end": 1001.14, "text": " And that's where we can use browser API,", "tokens": [51614, 400, 300, 311, 689, 321, 393, 764, 11185, 9362, 11, 51814], "temperature": 0.0, "avg_logprob": -0.1546521033010175, "compression_ratio": 1.3846153846153846, "no_speech_prob": 0.014732122421264648}, {"id": 257, "seek": 100114, "start": 1001.14, "end": 1004.14, "text": " JavaScript and whatever.", "tokens": [50364, 15778, 293, 2035, 13, 50514], "temperature": 0.0, "avg_logprob": -0.16245645995533795, "compression_ratio": 1.6355555555555557, "no_speech_prob": 0.010610147379338741}, {"id": 258, "seek": 100114, "start": 1004.14, "end": 1009.14, "text": " The second approach we can have also is web assembly, right?", "tokens": [50514, 440, 1150, 3109, 321, 393, 362, 611, 307, 3670, 12103, 11, 558, 30, 50764], "temperature": 0.0, "avg_logprob": -0.16245645995533795, "compression_ratio": 1.6355555555555557, "no_speech_prob": 0.010610147379338741}, {"id": 259, "seek": 100114, "start": 1009.14, "end": 1011.14, "text": " So if you can say, hey, you know what?", "tokens": [50764, 407, 498, 291, 393, 584, 11, 4177, 11, 291, 458, 437, 30, 50864], "temperature": 0.0, "avg_logprob": -0.16245645995533795, "compression_ratio": 1.6355555555555557, "no_speech_prob": 0.010610147379338741}, {"id": 260, "seek": 100114, "start": 1011.14, "end": 1016.14, "text": " We want no kind of serocomponent, right?", "tokens": [50864, 492, 528, 572, 733, 295, 816, 905, 8586, 30365, 11, 558, 30, 51114], "temperature": 0.0, "avg_logprob": -0.16245645995533795, "compression_ratio": 1.6355555555555557, "no_speech_prob": 0.010610147379338741}, {"id": 261, "seek": 100114, "start": 1016.14, "end": 1019.14, "text": " It runs completely in a browser.", "tokens": [51114, 467, 6676, 2584, 294, 257, 11185, 13, 51264], "temperature": 0.0, "avg_logprob": -0.16245645995533795, "compression_ratio": 1.6355555555555557, "no_speech_prob": 0.010610147379338741}, {"id": 262, "seek": 100114, "start": 1019.14, "end": 1021.14, "text": " We can do that, but probably in web assembly,", "tokens": [51264, 492, 393, 360, 300, 11, 457, 1391, 294, 3670, 12103, 11, 51364], "temperature": 0.0, "avg_logprob": -0.16245645995533795, "compression_ratio": 1.6355555555555557, "no_speech_prob": 0.010610147379338741}, {"id": 263, "seek": 100114, "start": 1021.14, "end": 1023.14, "text": " it can be sometimes heavy, right?", "tokens": [51364, 309, 393, 312, 2171, 4676, 11, 558, 30, 51464], "temperature": 0.0, "avg_logprob": -0.16245645995533795, "compression_ratio": 1.6355555555555557, "no_speech_prob": 0.010610147379338741}, {"id": 264, "seek": 100114, "start": 1023.14, "end": 1025.1399999999999, "text": " Especially saying, well, you know what?", "tokens": [51464, 8545, 1566, 11, 731, 11, 291, 458, 437, 30, 51564], "temperature": 0.0, "avg_logprob": -0.16245645995533795, "compression_ratio": 1.6355555555555557, "no_speech_prob": 0.010610147379338741}, {"id": 265, "seek": 100114, "start": 1025.1399999999999, "end": 1028.1399999999999, "text": " I want to showcase how, you know, like a Postgres", "tokens": [51564, 286, 528, 281, 20388, 577, 11, 291, 458, 11, 411, 257, 10223, 45189, 51714], "temperature": 0.0, "avg_logprob": -0.16245645995533795, "compression_ratio": 1.6355555555555557, "no_speech_prob": 0.010610147379338741}, {"id": 266, "seek": 102814, "start": 1028.14, "end": 1032.14, "text": " operates when, you know, getting all that Postgres pulled in,", "tokens": [50364, 22577, 562, 11, 291, 458, 11, 1242, 439, 300, 10223, 45189, 7373, 294, 11, 50564], "temperature": 0.0, "avg_logprob": -0.15355653511850456, "compression_ratio": 1.5243243243243243, "no_speech_prob": 0.011302880011498928}, {"id": 267, "seek": 102814, "start": 1032.14, "end": 1034.14, "text": " the assembly started, right?", "tokens": [50564, 264, 12103, 1409, 11, 558, 30, 50664], "temperature": 0.0, "avg_logprob": -0.15355653511850456, "compression_ratio": 1.5243243243243243, "no_speech_prob": 0.011302880011498928}, {"id": 268, "seek": 102814, "start": 1034.14, "end": 1037.14, "text": " That may not be the best experience, right?", "tokens": [50664, 663, 815, 406, 312, 264, 1151, 1752, 11, 558, 30, 50814], "temperature": 0.0, "avg_logprob": -0.15355653511850456, "compression_ratio": 1.5243243243243243, "no_speech_prob": 0.011302880011498928}, {"id": 269, "seek": 102814, "start": 1037.14, "end": 1041.14, "text": " Especially with slower connections.", "tokens": [50814, 8545, 365, 14009, 9271, 13, 51014], "temperature": 0.0, "avg_logprob": -0.15355653511850456, "compression_ratio": 1.5243243243243243, "no_speech_prob": 0.011302880011498928}, {"id": 270, "seek": 102814, "start": 1041.14, "end": 1051.14, "text": " So that is where docker, right, can be very helpful, right?", "tokens": [51014, 407, 300, 307, 689, 360, 9178, 11, 558, 11, 393, 312, 588, 4961, 11, 558, 30, 51514], "temperature": 0.0, "avg_logprob": -0.15355653511850456, "compression_ratio": 1.5243243243243243, "no_speech_prob": 0.011302880011498928}, {"id": 271, "seek": 102814, "start": 1051.14, "end": 1057.14, "text": " So with docker, you can implement whatever you want", "tokens": [51514, 407, 365, 360, 9178, 11, 291, 393, 4445, 2035, 291, 528, 51814], "temperature": 0.0, "avg_logprob": -0.15355653511850456, "compression_ratio": 1.5243243243243243, "no_speech_prob": 0.011302880011498928}, {"id": 272, "seek": 105714, "start": 1057.14, "end": 1066.14, "text": " and the setup of this service is an open source project, right?", "tokens": [50364, 293, 264, 8657, 295, 341, 2643, 307, 364, 1269, 4009, 1716, 11, 558, 30, 50814], "temperature": 0.0, "avg_logprob": -0.16111422421639426, "compression_ratio": 1.3355704697986577, "no_speech_prob": 0.004138938616961241}, {"id": 273, "seek": 105714, "start": 1066.14, "end": 1069.14, "text": " So you can roll your own as well.", "tokens": [50814, 407, 291, 393, 3373, 428, 1065, 382, 731, 13, 50964], "temperature": 0.0, "avg_logprob": -0.16111422421639426, "compression_ratio": 1.3355704697986577, "no_speech_prob": 0.004138938616961241}, {"id": 274, "seek": 105714, "start": 1069.14, "end": 1074.14, "text": " There is a variety of existing playgrounds", "tokens": [50964, 821, 307, 257, 5673, 295, 6741, 24646, 82, 51214], "temperature": 0.0, "avg_logprob": -0.16111422421639426, "compression_ratio": 1.3355704697986577, "no_speech_prob": 0.004138938616961241}, {"id": 275, "seek": 105714, "start": 1074.14, "end": 1080.14, "text": " which are supported at, you know,", "tokens": [51214, 597, 366, 8104, 412, 11, 291, 458, 11, 51514], "temperature": 0.0, "avg_logprob": -0.16111422421639426, "compression_ratio": 1.3355704697986577, "no_speech_prob": 0.004138938616961241}, {"id": 276, "seek": 105714, "start": 1080.14, "end": 1081.14, "text": " core API website, right?", "tokens": [51514, 4965, 9362, 3144, 11, 558, 30, 51564], "temperature": 0.0, "avg_logprob": -0.16111422421639426, "compression_ratio": 1.3355704697986577, "no_speech_prob": 0.004138938616961241}, {"id": 277, "seek": 108114, "start": 1081.14, "end": 1087.14, "text": " Which can get you started pretty quickly.", "tokens": [50364, 3013, 393, 483, 291, 1409, 1238, 2661, 13, 50664], "temperature": 0.0, "avg_logprob": -0.25066036336562214, "compression_ratio": 1.4514285714285715, "no_speech_prob": 0.011879650875926018}, {"id": 278, "seek": 108114, "start": 1087.14, "end": 1091.14, "text": " Yes, so here are some examples,", "tokens": [50664, 1079, 11, 370, 510, 366, 512, 5110, 11, 50864], "temperature": 0.0, "avg_logprob": -0.25066036336562214, "compression_ratio": 1.4514285714285715, "no_speech_prob": 0.011879650875926018}, {"id": 279, "seek": 108114, "start": 1091.14, "end": 1097.14, "text": " and I will of course share, well, slides if you actually slide there.", "tokens": [50864, 293, 286, 486, 295, 1164, 2073, 11, 731, 11, 9788, 498, 291, 767, 4137, 456, 13, 51164], "temperature": 0.0, "avg_logprob": -0.25066036336562214, "compression_ratio": 1.4514285714285715, "no_speech_prob": 0.011879650875926018}, {"id": 280, "seek": 108114, "start": 1097.14, "end": 1101.14, "text": " The online, this is a live tutorial.", "tokens": [51164, 440, 2950, 11, 341, 307, 257, 1621, 7073, 13, 51364], "temperature": 0.0, "avg_logprob": -0.25066036336562214, "compression_ratio": 1.4514285714285715, "no_speech_prob": 0.011879650875926018}, {"id": 281, "seek": 108114, "start": 1101.14, "end": 1107.14, "text": " You can see there's like a number of projects already started to use that", "tokens": [51364, 509, 393, 536, 456, 311, 411, 257, 1230, 295, 4455, 1217, 1409, 281, 764, 300, 51664], "temperature": 0.0, "avg_logprob": -0.25066036336562214, "compression_ratio": 1.4514285714285715, "no_speech_prob": 0.011879650875926018}, {"id": 282, "seek": 110714, "start": 1107.14, "end": 1111.14, "text": " with, you know, pretty good success.", "tokens": [50364, 365, 11, 291, 458, 11, 1238, 665, 2245, 13, 50564], "temperature": 0.0, "avg_logprob": -0.21234728342079254, "compression_ratio": 1.4747474747474747, "no_speech_prob": 0.020393485203385353}, {"id": 283, "seek": 110714, "start": 1111.14, "end": 1122.14, "text": " And you can see with core IP.org showcase that is where all the examples exist, right?", "tokens": [50564, 400, 291, 393, 536, 365, 4965, 8671, 13, 4646, 20388, 300, 307, 689, 439, 264, 5110, 2514, 11, 558, 30, 51114], "temperature": 0.0, "avg_logprob": -0.21234728342079254, "compression_ratio": 1.4747474747474747, "no_speech_prob": 0.020393485203385353}, {"id": 284, "seek": 110714, "start": 1122.14, "end": 1125.14, "text": " Here are specific projects, right?", "tokens": [51114, 1692, 366, 2685, 4455, 11, 558, 30, 51264], "temperature": 0.0, "avg_logprob": -0.21234728342079254, "compression_ratio": 1.4747474747474747, "no_speech_prob": 0.020393485203385353}, {"id": 285, "seek": 110714, "start": 1125.14, "end": 1127.14, "text": " There are kind of two sub-repositories.", "tokens": [51264, 821, 366, 733, 295, 732, 1422, 12, 19919, 9598, 2083, 13, 51364], "temperature": 0.0, "avg_logprob": -0.21234728342079254, "compression_ratio": 1.4747474747474747, "no_speech_prob": 0.020393485203385353}, {"id": 286, "seek": 110714, "start": 1127.14, "end": 1131.14, "text": " One is for JavaScript kind of client side,", "tokens": [51364, 1485, 307, 337, 15778, 733, 295, 6423, 1252, 11, 51564], "temperature": 0.0, "avg_logprob": -0.21234728342079254, "compression_ratio": 1.4747474747474747, "no_speech_prob": 0.020393485203385353}, {"id": 287, "seek": 110714, "start": 1131.14, "end": 1134.14, "text": " and other four, the server side, again, it's split", "tokens": [51564, 293, 661, 1451, 11, 264, 7154, 1252, 11, 797, 11, 309, 311, 7472, 51714], "temperature": 0.0, "avg_logprob": -0.21234728342079254, "compression_ratio": 1.4747474747474747, "no_speech_prob": 0.020393485203385353}, {"id": 288, "seek": 113414, "start": 1134.14, "end": 1141.14, "text": " because you may just want to use their client side", "tokens": [50364, 570, 291, 815, 445, 528, 281, 764, 641, 6423, 1252, 50714], "temperature": 0.0, "avg_logprob": -0.12461241553811465, "compression_ratio": 1.4508670520231215, "no_speech_prob": 0.00919458456337452}, {"id": 289, "seek": 113414, "start": 1141.14, "end": 1143.14, "text": " if you're using like JavaScript or something", "tokens": [50714, 498, 291, 434, 1228, 411, 15778, 420, 746, 50814], "temperature": 0.0, "avg_logprob": -0.12461241553811465, "compression_ratio": 1.4508670520231215, "no_speech_prob": 0.00919458456337452}, {"id": 290, "seek": 113414, "start": 1143.14, "end": 1145.14, "text": " where you don't need a server component.", "tokens": [50814, 689, 291, 500, 380, 643, 257, 7154, 6542, 13, 50914], "temperature": 0.0, "avg_logprob": -0.12461241553811465, "compression_ratio": 1.4508670520231215, "no_speech_prob": 0.00919458456337452}, {"id": 291, "seek": 113414, "start": 1145.14, "end": 1151.14, "text": " And yet, if you want to ask some more questions for Anton, right,", "tokens": [50914, 400, 1939, 11, 498, 291, 528, 281, 1029, 512, 544, 1651, 337, 15291, 11, 558, 11, 51214], "temperature": 0.0, "avg_logprob": -0.12461241553811465, "compression_ratio": 1.4508670520231215, "no_speech_prob": 0.00919458456337452}, {"id": 292, "seek": 113414, "start": 1151.14, "end": 1158.14, "text": " or get some feedback, Antonz.org is his website.", "tokens": [51214, 420, 483, 512, 5824, 11, 15291, 89, 13, 4646, 307, 702, 3144, 13, 51564], "temperature": 0.0, "avg_logprob": -0.12461241553811465, "compression_ratio": 1.4508670520231215, "no_speech_prob": 0.00919458456337452}, {"id": 293, "seek": 115814, "start": 1158.14, "end": 1165.14, "text": " So that's all I had, and I would be happy to answer questions", "tokens": [50364, 407, 300, 311, 439, 286, 632, 11, 293, 286, 576, 312, 2055, 281, 1867, 1651, 50714], "temperature": 0.0, "avg_logprob": -0.26358096544132675, "compression_ratio": 1.497584541062802, "no_speech_prob": 0.013057606294751167}, {"id": 294, "seek": 115814, "start": 1165.14, "end": 1172.14, "text": " or get out of the way because I think I'm the last thing standing between you and your viewers.", "tokens": [50714, 420, 483, 484, 295, 264, 636, 570, 286, 519, 286, 478, 264, 1036, 551, 4877, 1296, 291, 293, 428, 8499, 13, 51064], "temperature": 0.0, "avg_logprob": -0.26358096544132675, "compression_ratio": 1.497584541062802, "no_speech_prob": 0.013057606294751167}, {"id": 295, "seek": 115814, "start": 1172.14, "end": 1179.14, "text": " Yeah, we started with docs code, and now we've gone to code docs.", "tokens": [51064, 865, 11, 321, 1409, 365, 45623, 3089, 11, 293, 586, 321, 600, 2780, 281, 3089, 45623, 13, 51414], "temperature": 0.0, "avg_logprob": -0.26358096544132675, "compression_ratio": 1.497584541062802, "no_speech_prob": 0.013057606294751167}, {"id": 296, "seek": 115814, "start": 1179.14, "end": 1182.14, "text": " Any questions?", "tokens": [51414, 2639, 1651, 30, 51564], "temperature": 0.0, "avg_logprob": -0.26358096544132675, "compression_ratio": 1.497584541062802, "no_speech_prob": 0.013057606294751167}, {"id": 297, "seek": 115814, "start": 1182.14, "end": 1186.14, "text": " You don't understand, the back-end is also part of this project or not?", "tokens": [51564, 509, 500, 380, 1223, 11, 264, 646, 12, 521, 307, 611, 644, 295, 341, 1716, 420, 406, 30, 51764], "temperature": 0.0, "avg_logprob": -0.26358096544132675, "compression_ratio": 1.497584541062802, "no_speech_prob": 0.013057606294751167}, {"id": 298, "seek": 118614, "start": 1186.14, "end": 1193.14, "text": " Yes, yes, so in this case, code IP, that is your Docker back-end, right?", "tokens": [50364, 1079, 11, 2086, 11, 370, 294, 341, 1389, 11, 3089, 8671, 11, 300, 307, 428, 33772, 646, 12, 521, 11, 558, 30, 50714], "temperature": 0.0, "avg_logprob": -0.26776831200782286, "compression_ratio": 1.219298245614035, "no_speech_prob": 0.046357739716768265}, {"id": 299, "seek": 118614, "start": 1193.14, "end": 1202.14, "text": " Code IP JS, that's your, I think, so both of them are open source.", "tokens": [50714, 15549, 8671, 33063, 11, 300, 311, 428, 11, 286, 519, 11, 370, 1293, 295, 552, 366, 1269, 4009, 13, 51164], "temperature": 0.0, "avg_logprob": -0.26776831200782286, "compression_ratio": 1.219298245614035, "no_speech_prob": 0.046357739716768265}, {"id": 300, "seek": 120214, "start": 1202.14, "end": 1218.14, "text": " What do you mean?", "tokens": [50364, 708, 360, 291, 914, 30, 51164], "temperature": 0.0, "avg_logprob": -0.5418896079063416, "compression_ratio": 0.68, "no_speech_prob": 0.30500397086143494}, {"id": 301, "seek": 123214, "start": 1232.14, "end": 1240.14, "text": " Oh, you mean in terms of what people run, right, what kind of, so not right now.", "tokens": [50414, 876, 11, 291, 914, 294, 2115, 295, 437, 561, 1190, 11, 558, 11, 437, 733, 295, 11, 370, 406, 558, 586, 13, 50764], "temperature": 0.0, "avg_logprob": -0.1838523292541504, "compression_ratio": 1.0810810810810811, "no_speech_prob": 0.4298042953014374}], "language": "en"}