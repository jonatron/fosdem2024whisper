{"text": " Okay, good morning everyone. My name is Arthur. I'm an assistant professor in Lyon, France. I'm here today to acquaint you with a little program called COSMA. I'm going to present the design choices behind it, touching on mostly two points. It's going to be a short presentation. The architecture of the program, which may interest you if you're working on interactive publications. And the features, which may interest you if you're a scientist or working with scientific data, and you have information management needs. So that should be every scientist. I'm presenting on behalf of the team, and first and foremost, my developer colleague, Guillaume, who is not here because he's on hiatus for a very happy family reason. And also my senior researcher colleagues who have a lot of knowledge and research colleagues who have advised us on the design of the application since the beginning. Okay, COSMA came as part of a research program on Paul H\u00f4tel\u00e9. I'm very happy to be mentioning H\u00f4tel\u00e9 here because he was born and died in Brussels. He was a famous Belgian figure. He was a pioneer of knowledge organization. He's recognized today as a precursor to information science. He was a pacifist, an internationalist, a feminist. He had also some flaws. He was a utopian. He had some sometimes a bit dated views on topics, but he's a very interesting figure. He's the one who popularized the word documentation, so that's that. His main idea, H\u00f4tel\u00e9, was to go beyond the book. What he wanted to do was extract all facts from publications and sort of organize them into universal encyclopedia. The idea was that universal access to knowledge would bring peace. That was the utopia. He worked all his life on tools to achieve this, including bibliography, classification schemes, index cards, and so on. There's a museum dedicated to him in Belgium, in Mons, so if you're in Belgium for a few days, I encourage you to go and visit it. So in 2018-2019, we worked on a map of H\u00f4tel\u00e9's professional network. It was our take on an idea that had been done before, which was to combine a graph view and also a card view, so like a little index card with metadata, but the note that you're currently selecting in the graph. And one day I asked Leone, can you make that for my research notes? Because at the time I was accumulating files that looked a bit like this, a bunch of plain text files with notes on specific things. These aren't actually my notes. I just borrowed Andy Matousiak's note for this presentation. Andy Matousiak is a researcher who's working on tools for thought, non-linear writing, etc. The idea is that you have files which reference each other with links, internal links, just like in a wiki, double brackets around the title or an identifier, if you prefer using an identifier. And so what Guillaume made is that he designed a prototype which became eventually COSMA, which renders these files into an HTML file. So yet another graph application, after all the graph applications that we've seen in the previous presentation about Giffy Lite. So this is an HTML file which contains a graph view. The rendering of each file in HTML and also a few navigational tools, an index, a small search box, etc. This could be anything. It could be any kind of knowledge base. It could be a glossary of terms. It could be a network of people, of concepts, of events. Really it doesn't matter. It's like a commonplace book or wiki or a zettelkasten, if you're familiar with that word. Even a mind map to some extent. Conceptually it's a bit like that. What distinguishes COSMA is that we have, well, the architecture and the fact that we designed it around scientific writing needs. So I'm going to describe briefly the architecture point and then I'll describe the features a little bit more. So it's purely a visualization program. You cannot edit data with it. It just reads plain text files. And most of the features are actually located in the exports. So this is actually COSMA. It's a command line application. And you use it to generate these HTML files. If you're familiar with Tiddly wiki, it's a bit like that. So it's a single HTML file which contains everything except Tiddly wiki. You can edit the data. This is read only. So it's less like a web application and more like a sort of augmented document. You can share this file, obviously. It's just an HTML file and people can open it in their browser. And the idea was that I was familiar with software like Jaffee and I always wanted to be able to share graph visualizations with colleagues or students, but not as static images, but as interactive things. And there are lots more options now that exist to do this. We just did this for little markdown files. So that's the brief point about architecture. The features, as I mentioned, they're related to information management needs. Everything is designed to encourage knowledge organizations. So categorizing things, classifying, indexing, tagging, relating things to one another. It's basically a memory aid, actually. It's not for graph analysis. It's more for network synthesis, so to assemble document graphs about things. And the way it encourages knowledge organization is to provide a few features that reward this knowledge work. So, for example, if you assign types to your notes, colors will appear and you will have filters to modify the display. So you can toggle, for example, one type. Here I've toggled the inside type, which was in orange. And it also and mostly encourages link-based knowledge organizations. So that's using links in the way you're describing the relations with things. And the way it rewards that is to provide contextualized backlinks. So that's the thing that's at the bottom right here. These are the incoming links. So you see here where this note has been cited, and most importantly, how it's been cited because you have the context, the surrounding paragraph that's here. So that's a contextualized backlinks. Not an idea that we invented, we just borrowed it from actually web pioneers. It's been going around for a long time. And in recent years, there's been a wave of tools for thought text editors in which you can create little notes, link them together, organize them, and they pretty much all have this feature. We just wanted a way to have it for scientific writing and also to be able to share it easily. Now the big thing that we did is we have the same feature, but for citations. So if you're working with bibliographic data, so you have maybe a raw JSON file, maybe more likely you're working with a reference manager like Zotero, N-node, Mandalay, etc. And if you're in your notes, your citing works. So for example, here on the right, I'm quoting the two references that you can see are stored in the file on the left. Well, Cosma will generate a bibliographic note, that's the dark gray one here. I haven't created a text file for this note, it's been generated automatically. And most importantly, it will show me the backlinks as well for the citations. So I can see where I've been citing which work and how in which context. I want to close on the idea of network synthesis very quickly in my dissertation. What I argue is that linking the simple act of relating two things to one another in hypertext, it's a knowledge organization process. So that expression is actually a thing in knowledge organization literature. It's classifying, indexing, tagging, basically any process that you do that organizes knowledge. And linking is a way to do a lot of that. Linking could be a way to index, to classify, to tag, to assign things to others. And most importantly to compose with links you can express new ideas, just like Lego. If you have a note on a concept and a note on another concept, and you just bring the two together in a sentence, this relates to that because this, this becomes a new idea, you express it in a new note, and that's ideation, the basic process of research. I'm going to skip very quickly all these examples that I had added because it'd be fun if there were some time for questions. And just to say that this process of synthesizing knowledge, this is why I titled the presentation Tool for Network Synthesis. Obviously in the process of research the first step is analysis. You start with an object, a phenomenon, and you start, and you try to decompose it to see the fundamental building blocks. But the goal is to take those fundamental units and sort of mash them together again to produce new things. And this tool is just that, it's just a tool to help with this process of knowledge synthesis, which is to assemble and expand over time these little document graphs. I'm saying document graphs because there's the expression knowledge graph. Knowledge graph is usually a set of descriptions in a database, and these are just little documents, so hence the word document graph. Right, I'm going to hand here, and if you have any questions. Thank you. Do we have any questions in the room? We have four minutes. A question about using graph-based and markdown-based, I don't think it improves the blocks or the accident. So the question was can we use this application to visualize nodes that would have been created with applications such as Obsidian or Luxik. A colleague actually wrote a little Obsidian to Cosma Converter because we have a data format which is close but not quite the same as Obsidian. Obviously you have to have a YAML header, the links have to be a certain way, etc. So there is a converter for, if you have nodes written with Obsidian, there's a converter out there to transform them into the format. I don't know that there's such a thing for Luxik. It's possible because it's just plain text, markdown, YAML, it's very easy to write, I think, a custom parser and convert it. Do you have time for one more question? Thanks for an interesting presentation. At all I'd really like to use in combination with Obsidian. I was wondering about the format of the nodes. You mentioned Zetl-Caston, which has a specific format and way of linking. There's permanent nodes, there's every node. Could you elaborate a bit on that, on what type of nodes would work well in this, not a synthesis, a way that you would use? Yeah, a repeating question. What type of format would be ideal to work with Cosma since there are many formats out there at Zetl-Caston? The type of nodes. Oh, the type of nodes. Atomic nodes. I've shown Andy Matushek's notes, he writes a lot about evergreen nodes and the principles behind evergreen nodes, things should be atomic, densely linked, and the titles of the nodes should describe one thing and maybe work almost like APIs. It could be a sentence that describes the idea. So that's the best sort of mental model. It's less suited for a daily log, for instance, than for a sort of conceptual knowledge base, again, where you try to relate events, concepts, people, etc. I hope I was clear. Thank you so much.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 5.0, "text": " Okay, good morning everyone.", "tokens": [50364, 1033, 11, 665, 2446, 1518, 13, 50614], "temperature": 0.0, "avg_logprob": -0.19655885883406096, "compression_ratio": 1.5403225806451613, "no_speech_prob": 0.22614705562591553}, {"id": 1, "seek": 0, "start": 5.0, "end": 6.0, "text": " My name is Arthur.", "tokens": [50614, 1222, 1315, 307, 19624, 13, 50664], "temperature": 0.0, "avg_logprob": -0.19655885883406096, "compression_ratio": 1.5403225806451613, "no_speech_prob": 0.22614705562591553}, {"id": 2, "seek": 0, "start": 6.0, "end": 8.0, "text": " I'm an assistant professor in Lyon, France.", "tokens": [50664, 286, 478, 364, 10994, 8304, 294, 12687, 266, 11, 6190, 13, 50764], "temperature": 0.0, "avg_logprob": -0.19655885883406096, "compression_ratio": 1.5403225806451613, "no_speech_prob": 0.22614705562591553}, {"id": 3, "seek": 0, "start": 8.0, "end": 13.0, "text": " I'm here today to acquaint you with a little program called COSMA.", "tokens": [50764, 286, 478, 510, 965, 281, 36954, 291, 365, 257, 707, 1461, 1219, 3002, 50, 9998, 13, 51014], "temperature": 0.0, "avg_logprob": -0.19655885883406096, "compression_ratio": 1.5403225806451613, "no_speech_prob": 0.22614705562591553}, {"id": 4, "seek": 0, "start": 13.0, "end": 16.0, "text": " I'm going to present the design choices behind it,", "tokens": [51014, 286, 478, 516, 281, 1974, 264, 1715, 7994, 2261, 309, 11, 51164], "temperature": 0.0, "avg_logprob": -0.19655885883406096, "compression_ratio": 1.5403225806451613, "no_speech_prob": 0.22614705562591553}, {"id": 5, "seek": 0, "start": 16.0, "end": 18.0, "text": " touching on mostly two points.", "tokens": [51164, 11175, 322, 5240, 732, 2793, 13, 51264], "temperature": 0.0, "avg_logprob": -0.19655885883406096, "compression_ratio": 1.5403225806451613, "no_speech_prob": 0.22614705562591553}, {"id": 6, "seek": 0, "start": 18.0, "end": 20.0, "text": " It's going to be a short presentation.", "tokens": [51264, 467, 311, 516, 281, 312, 257, 2099, 5860, 13, 51364], "temperature": 0.0, "avg_logprob": -0.19655885883406096, "compression_ratio": 1.5403225806451613, "no_speech_prob": 0.22614705562591553}, {"id": 7, "seek": 0, "start": 20.0, "end": 22.0, "text": " The architecture of the program,", "tokens": [51364, 440, 9482, 295, 264, 1461, 11, 51464], "temperature": 0.0, "avg_logprob": -0.19655885883406096, "compression_ratio": 1.5403225806451613, "no_speech_prob": 0.22614705562591553}, {"id": 8, "seek": 0, "start": 22.0, "end": 26.0, "text": " which may interest you if you're working on interactive publications.", "tokens": [51464, 597, 815, 1179, 291, 498, 291, 434, 1364, 322, 15141, 25618, 13, 51664], "temperature": 0.0, "avg_logprob": -0.19655885883406096, "compression_ratio": 1.5403225806451613, "no_speech_prob": 0.22614705562591553}, {"id": 9, "seek": 2600, "start": 27.0, "end": 31.0, "text": " And the features, which may interest you if you're a scientist", "tokens": [50414, 400, 264, 4122, 11, 597, 815, 1179, 291, 498, 291, 434, 257, 12662, 50614], "temperature": 0.0, "avg_logprob": -0.20907319760790058, "compression_ratio": 1.6015625, "no_speech_prob": 0.08145441859960556}, {"id": 10, "seek": 2600, "start": 31.0, "end": 33.0, "text": " or working with scientific data,", "tokens": [50614, 420, 1364, 365, 8134, 1412, 11, 50714], "temperature": 0.0, "avg_logprob": -0.20907319760790058, "compression_ratio": 1.6015625, "no_speech_prob": 0.08145441859960556}, {"id": 11, "seek": 2600, "start": 33.0, "end": 36.0, "text": " and you have information management needs.", "tokens": [50714, 293, 291, 362, 1589, 4592, 2203, 13, 50864], "temperature": 0.0, "avg_logprob": -0.20907319760790058, "compression_ratio": 1.6015625, "no_speech_prob": 0.08145441859960556}, {"id": 12, "seek": 2600, "start": 36.0, "end": 38.0, "text": " So that should be every scientist.", "tokens": [50864, 407, 300, 820, 312, 633, 12662, 13, 50964], "temperature": 0.0, "avg_logprob": -0.20907319760790058, "compression_ratio": 1.6015625, "no_speech_prob": 0.08145441859960556}, {"id": 13, "seek": 2600, "start": 38.0, "end": 41.0, "text": " I'm presenting on behalf of the team,", "tokens": [50964, 286, 478, 15578, 322, 9490, 295, 264, 1469, 11, 51114], "temperature": 0.0, "avg_logprob": -0.20907319760790058, "compression_ratio": 1.6015625, "no_speech_prob": 0.08145441859960556}, {"id": 14, "seek": 2600, "start": 41.0, "end": 45.0, "text": " and first and foremost, my developer colleague, Guillaume,", "tokens": [51114, 293, 700, 293, 18864, 11, 452, 10754, 13532, 11, 2694, 5291, 2540, 11, 51314], "temperature": 0.0, "avg_logprob": -0.20907319760790058, "compression_ratio": 1.6015625, "no_speech_prob": 0.08145441859960556}, {"id": 15, "seek": 2600, "start": 45.0, "end": 50.0, "text": " who is not here because he's on hiatus for a very happy family reason.", "tokens": [51314, 567, 307, 406, 510, 570, 415, 311, 322, 4879, 37926, 337, 257, 588, 2055, 1605, 1778, 13, 51564], "temperature": 0.0, "avg_logprob": -0.20907319760790058, "compression_ratio": 1.6015625, "no_speech_prob": 0.08145441859960556}, {"id": 16, "seek": 2600, "start": 50.0, "end": 55.0, "text": " And also my senior researcher colleagues who have a lot of knowledge", "tokens": [51564, 400, 611, 452, 7965, 21751, 7734, 567, 362, 257, 688, 295, 3601, 51814], "temperature": 0.0, "avg_logprob": -0.20907319760790058, "compression_ratio": 1.6015625, "no_speech_prob": 0.08145441859960556}, {"id": 17, "seek": 5500, "start": 55.0, "end": 59.0, "text": " and research colleagues who have advised us on the design of the application", "tokens": [50364, 293, 2132, 7734, 567, 362, 26269, 505, 322, 264, 1715, 295, 264, 3861, 50564], "temperature": 0.0, "avg_logprob": -0.10202667759914025, "compression_ratio": 1.51171875, "no_speech_prob": 0.013647353276610374}, {"id": 18, "seek": 5500, "start": 59.0, "end": 62.0, "text": " since the beginning.", "tokens": [50564, 1670, 264, 2863, 13, 50714], "temperature": 0.0, "avg_logprob": -0.10202667759914025, "compression_ratio": 1.51171875, "no_speech_prob": 0.013647353276610374}, {"id": 19, "seek": 5500, "start": 62.0, "end": 66.0, "text": " Okay, COSMA came as part of a research program on Paul H\u00f4tel\u00e9.", "tokens": [50714, 1033, 11, 3002, 50, 9998, 1361, 382, 644, 295, 257, 2132, 1461, 322, 4552, 389, 8775, 338, 526, 13, 50914], "temperature": 0.0, "avg_logprob": -0.10202667759914025, "compression_ratio": 1.51171875, "no_speech_prob": 0.013647353276610374}, {"id": 20, "seek": 5500, "start": 66.0, "end": 68.0, "text": " I'm very happy to be mentioning H\u00f4tel\u00e9 here", "tokens": [50914, 286, 478, 588, 2055, 281, 312, 18315, 389, 8775, 338, 526, 510, 51014], "temperature": 0.0, "avg_logprob": -0.10202667759914025, "compression_ratio": 1.51171875, "no_speech_prob": 0.013647353276610374}, {"id": 21, "seek": 5500, "start": 68.0, "end": 72.0, "text": " because he was born and died in Brussels.", "tokens": [51014, 570, 415, 390, 4232, 293, 4539, 294, 38717, 13, 51214], "temperature": 0.0, "avg_logprob": -0.10202667759914025, "compression_ratio": 1.51171875, "no_speech_prob": 0.013647353276610374}, {"id": 22, "seek": 5500, "start": 72.0, "end": 75.0, "text": " He was a famous Belgian figure.", "tokens": [51214, 634, 390, 257, 4618, 47127, 2573, 13, 51364], "temperature": 0.0, "avg_logprob": -0.10202667759914025, "compression_ratio": 1.51171875, "no_speech_prob": 0.013647353276610374}, {"id": 23, "seek": 5500, "start": 75.0, "end": 78.0, "text": " He was a pioneer of knowledge organization.", "tokens": [51364, 634, 390, 257, 37668, 295, 3601, 4475, 13, 51514], "temperature": 0.0, "avg_logprob": -0.10202667759914025, "compression_ratio": 1.51171875, "no_speech_prob": 0.013647353276610374}, {"id": 24, "seek": 5500, "start": 78.0, "end": 82.0, "text": " He's recognized today as a precursor to information science.", "tokens": [51514, 634, 311, 9823, 965, 382, 257, 41736, 284, 281, 1589, 3497, 13, 51714], "temperature": 0.0, "avg_logprob": -0.10202667759914025, "compression_ratio": 1.51171875, "no_speech_prob": 0.013647353276610374}, {"id": 25, "seek": 8200, "start": 82.0, "end": 86.0, "text": " He was a pacifist, an internationalist, a feminist.", "tokens": [50364, 634, 390, 257, 15165, 351, 468, 11, 364, 5058, 468, 11, 257, 26229, 13, 50564], "temperature": 0.0, "avg_logprob": -0.060744433843788984, "compression_ratio": 1.5977011494252873, "no_speech_prob": 0.08839336037635803}, {"id": 26, "seek": 8200, "start": 86.0, "end": 88.0, "text": " He had also some flaws.", "tokens": [50564, 634, 632, 611, 512, 27108, 13, 50664], "temperature": 0.0, "avg_logprob": -0.060744433843788984, "compression_ratio": 1.5977011494252873, "no_speech_prob": 0.08839336037635803}, {"id": 27, "seek": 8200, "start": 88.0, "end": 89.0, "text": " He was a utopian.", "tokens": [50664, 634, 390, 257, 2839, 38447, 13, 50714], "temperature": 0.0, "avg_logprob": -0.060744433843788984, "compression_ratio": 1.5977011494252873, "no_speech_prob": 0.08839336037635803}, {"id": 28, "seek": 8200, "start": 89.0, "end": 92.0, "text": " He had some sometimes a bit dated views on topics,", "tokens": [50714, 634, 632, 512, 2171, 257, 857, 23804, 6809, 322, 8378, 11, 50864], "temperature": 0.0, "avg_logprob": -0.060744433843788984, "compression_ratio": 1.5977011494252873, "no_speech_prob": 0.08839336037635803}, {"id": 29, "seek": 8200, "start": 92.0, "end": 94.0, "text": " but he's a very interesting figure.", "tokens": [50864, 457, 415, 311, 257, 588, 1880, 2573, 13, 50964], "temperature": 0.0, "avg_logprob": -0.060744433843788984, "compression_ratio": 1.5977011494252873, "no_speech_prob": 0.08839336037635803}, {"id": 30, "seek": 8200, "start": 94.0, "end": 99.0, "text": " He's the one who popularized the word documentation, so that's that.", "tokens": [50964, 634, 311, 264, 472, 567, 3743, 1602, 264, 1349, 14333, 11, 370, 300, 311, 300, 13, 51214], "temperature": 0.0, "avg_logprob": -0.060744433843788984, "compression_ratio": 1.5977011494252873, "no_speech_prob": 0.08839336037635803}, {"id": 31, "seek": 8200, "start": 99.0, "end": 102.0, "text": " His main idea, H\u00f4tel\u00e9, was to go beyond the book.", "tokens": [51214, 2812, 2135, 1558, 11, 389, 8775, 338, 526, 11, 390, 281, 352, 4399, 264, 1446, 13, 51364], "temperature": 0.0, "avg_logprob": -0.060744433843788984, "compression_ratio": 1.5977011494252873, "no_speech_prob": 0.08839336037635803}, {"id": 32, "seek": 8200, "start": 102.0, "end": 106.0, "text": " What he wanted to do was extract all facts from publications", "tokens": [51364, 708, 415, 1415, 281, 360, 390, 8947, 439, 9130, 490, 25618, 51564], "temperature": 0.0, "avg_logprob": -0.060744433843788984, "compression_ratio": 1.5977011494252873, "no_speech_prob": 0.08839336037635803}, {"id": 33, "seek": 8200, "start": 106.0, "end": 110.0, "text": " and sort of organize them into universal encyclopedia.", "tokens": [51564, 293, 1333, 295, 13859, 552, 666, 11455, 465, 34080, 47795, 13, 51764], "temperature": 0.0, "avg_logprob": -0.060744433843788984, "compression_ratio": 1.5977011494252873, "no_speech_prob": 0.08839336037635803}, {"id": 34, "seek": 11000, "start": 110.0, "end": 114.0, "text": " The idea was that universal access to knowledge would bring peace.", "tokens": [50364, 440, 1558, 390, 300, 11455, 2105, 281, 3601, 576, 1565, 4336, 13, 50564], "temperature": 0.0, "avg_logprob": -0.07739263576465649, "compression_ratio": 1.5201793721973094, "no_speech_prob": 0.001932372571900487}, {"id": 35, "seek": 11000, "start": 114.0, "end": 116.0, "text": " That was the utopia.", "tokens": [50564, 663, 390, 264, 2839, 22376, 13, 50664], "temperature": 0.0, "avg_logprob": -0.07739263576465649, "compression_ratio": 1.5201793721973094, "no_speech_prob": 0.001932372571900487}, {"id": 36, "seek": 11000, "start": 116.0, "end": 119.0, "text": " He worked all his life on tools to achieve this,", "tokens": [50664, 634, 2732, 439, 702, 993, 322, 3873, 281, 4584, 341, 11, 50814], "temperature": 0.0, "avg_logprob": -0.07739263576465649, "compression_ratio": 1.5201793721973094, "no_speech_prob": 0.001932372571900487}, {"id": 37, "seek": 11000, "start": 119.0, "end": 124.0, "text": " including bibliography, classification schemes, index cards, and so on.", "tokens": [50814, 3009, 34344, 5820, 11, 21538, 26954, 11, 8186, 5632, 11, 293, 370, 322, 13, 51064], "temperature": 0.0, "avg_logprob": -0.07739263576465649, "compression_ratio": 1.5201793721973094, "no_speech_prob": 0.001932372571900487}, {"id": 38, "seek": 11000, "start": 124.0, "end": 129.0, "text": " There's a museum dedicated to him in Belgium, in Mons,", "tokens": [51064, 821, 311, 257, 8441, 8374, 281, 796, 294, 28094, 11, 294, 376, 892, 11, 51314], "temperature": 0.0, "avg_logprob": -0.07739263576465649, "compression_ratio": 1.5201793721973094, "no_speech_prob": 0.001932372571900487}, {"id": 39, "seek": 11000, "start": 129.0, "end": 134.0, "text": " so if you're in Belgium for a few days, I encourage you to go and visit it.", "tokens": [51314, 370, 498, 291, 434, 294, 28094, 337, 257, 1326, 1708, 11, 286, 5373, 291, 281, 352, 293, 3441, 309, 13, 51564], "temperature": 0.0, "avg_logprob": -0.07739263576465649, "compression_ratio": 1.5201793721973094, "no_speech_prob": 0.001932372571900487}, {"id": 40, "seek": 13400, "start": 135.0, "end": 142.0, "text": " So in 2018-2019, we worked on a map of H\u00f4tel\u00e9's professional network.", "tokens": [50414, 407, 294, 6096, 12, 30620, 11, 321, 2732, 322, 257, 4471, 295, 389, 8775, 338, 526, 311, 4843, 3209, 13, 50764], "temperature": 0.0, "avg_logprob": -0.14822772084450236, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.004404459614306688}, {"id": 41, "seek": 13400, "start": 142.0, "end": 146.0, "text": " It was our take on an idea that had been done before,", "tokens": [50764, 467, 390, 527, 747, 322, 364, 1558, 300, 632, 668, 1096, 949, 11, 50964], "temperature": 0.0, "avg_logprob": -0.14822772084450236, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.004404459614306688}, {"id": 42, "seek": 13400, "start": 146.0, "end": 150.0, "text": " which was to combine a graph view and also a card view,", "tokens": [50964, 597, 390, 281, 10432, 257, 4295, 1910, 293, 611, 257, 2920, 1910, 11, 51164], "temperature": 0.0, "avg_logprob": -0.14822772084450236, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.004404459614306688}, {"id": 43, "seek": 13400, "start": 150.0, "end": 152.0, "text": " so like a little index card with metadata,", "tokens": [51164, 370, 411, 257, 707, 8186, 2920, 365, 26603, 11, 51264], "temperature": 0.0, "avg_logprob": -0.14822772084450236, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.004404459614306688}, {"id": 44, "seek": 13400, "start": 152.0, "end": 155.0, "text": " but the note that you're currently selecting in the graph.", "tokens": [51264, 457, 264, 3637, 300, 291, 434, 4362, 18182, 294, 264, 4295, 13, 51414], "temperature": 0.0, "avg_logprob": -0.14822772084450236, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.004404459614306688}, {"id": 45, "seek": 13400, "start": 155.0, "end": 161.0, "text": " And one day I asked Leone, can you make that for my research notes?", "tokens": [51414, 400, 472, 786, 286, 2351, 1456, 546, 11, 393, 291, 652, 300, 337, 452, 2132, 5570, 30, 51714], "temperature": 0.0, "avg_logprob": -0.14822772084450236, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.004404459614306688}, {"id": 46, "seek": 16100, "start": 161.0, "end": 165.0, "text": " Because at the time I was accumulating files that looked a bit like this,", "tokens": [50364, 1436, 412, 264, 565, 286, 390, 12989, 12162, 7098, 300, 2956, 257, 857, 411, 341, 11, 50564], "temperature": 0.0, "avg_logprob": -0.12009280976795014, "compression_ratio": 1.6290322580645162, "no_speech_prob": 0.02452901378273964}, {"id": 47, "seek": 16100, "start": 165.0, "end": 169.0, "text": " a bunch of plain text files with notes on specific things.", "tokens": [50564, 257, 3840, 295, 11121, 2487, 7098, 365, 5570, 322, 2685, 721, 13, 50764], "temperature": 0.0, "avg_logprob": -0.12009280976795014, "compression_ratio": 1.6290322580645162, "no_speech_prob": 0.02452901378273964}, {"id": 48, "seek": 16100, "start": 169.0, "end": 171.0, "text": " These aren't actually my notes.", "tokens": [50764, 1981, 3212, 380, 767, 452, 5570, 13, 50864], "temperature": 0.0, "avg_logprob": -0.12009280976795014, "compression_ratio": 1.6290322580645162, "no_speech_prob": 0.02452901378273964}, {"id": 49, "seek": 16100, "start": 171.0, "end": 175.0, "text": " I just borrowed Andy Matousiak's note for this presentation.", "tokens": [50864, 286, 445, 26805, 13285, 6789, 563, 72, 514, 311, 3637, 337, 341, 5860, 13, 51064], "temperature": 0.0, "avg_logprob": -0.12009280976795014, "compression_ratio": 1.6290322580645162, "no_speech_prob": 0.02452901378273964}, {"id": 50, "seek": 16100, "start": 175.0, "end": 179.0, "text": " Andy Matousiak is a researcher who's working on tools for thought,", "tokens": [51064, 13285, 6789, 563, 72, 514, 307, 257, 21751, 567, 311, 1364, 322, 3873, 337, 1194, 11, 51264], "temperature": 0.0, "avg_logprob": -0.12009280976795014, "compression_ratio": 1.6290322580645162, "no_speech_prob": 0.02452901378273964}, {"id": 51, "seek": 16100, "start": 179.0, "end": 182.0, "text": " non-linear writing, etc.", "tokens": [51264, 2107, 12, 28263, 3579, 11, 5183, 13, 51414], "temperature": 0.0, "avg_logprob": -0.12009280976795014, "compression_ratio": 1.6290322580645162, "no_speech_prob": 0.02452901378273964}, {"id": 52, "seek": 16100, "start": 182.0, "end": 189.0, "text": " The idea is that you have files which reference each other with links, internal links,", "tokens": [51414, 440, 1558, 307, 300, 291, 362, 7098, 597, 6408, 1184, 661, 365, 6123, 11, 6920, 6123, 11, 51764], "temperature": 0.0, "avg_logprob": -0.12009280976795014, "compression_ratio": 1.6290322580645162, "no_speech_prob": 0.02452901378273964}, {"id": 53, "seek": 18900, "start": 190.0, "end": 194.0, "text": " just like in a wiki, double brackets around the title or an identifier,", "tokens": [50414, 445, 411, 294, 257, 261, 9850, 11, 3834, 26179, 926, 264, 4876, 420, 364, 45690, 11, 50614], "temperature": 0.0, "avg_logprob": -0.1459426520005712, "compression_ratio": 1.6307692307692307, "no_speech_prob": 0.008191944099962711}, {"id": 54, "seek": 18900, "start": 194.0, "end": 197.0, "text": " if you prefer using an identifier.", "tokens": [50614, 498, 291, 4382, 1228, 364, 45690, 13, 50764], "temperature": 0.0, "avg_logprob": -0.1459426520005712, "compression_ratio": 1.6307692307692307, "no_speech_prob": 0.008191944099962711}, {"id": 55, "seek": 18900, "start": 197.0, "end": 201.0, "text": " And so what Guillaume made is that he designed a prototype", "tokens": [50764, 400, 370, 437, 2694, 5291, 2540, 1027, 307, 300, 415, 4761, 257, 19475, 50964], "temperature": 0.0, "avg_logprob": -0.1459426520005712, "compression_ratio": 1.6307692307692307, "no_speech_prob": 0.008191944099962711}, {"id": 56, "seek": 18900, "start": 201.0, "end": 207.0, "text": " which became eventually COSMA, which renders these files into an HTML file.", "tokens": [50964, 597, 3062, 4728, 3002, 50, 9998, 11, 597, 6125, 433, 613, 7098, 666, 364, 17995, 3991, 13, 51264], "temperature": 0.0, "avg_logprob": -0.1459426520005712, "compression_ratio": 1.6307692307692307, "no_speech_prob": 0.008191944099962711}, {"id": 57, "seek": 18900, "start": 207.0, "end": 209.0, "text": " So yet another graph application,", "tokens": [51264, 407, 1939, 1071, 4295, 3861, 11, 51364], "temperature": 0.0, "avg_logprob": -0.1459426520005712, "compression_ratio": 1.6307692307692307, "no_speech_prob": 0.008191944099962711}, {"id": 58, "seek": 18900, "start": 209.0, "end": 214.0, "text": " after all the graph applications that we've seen in the previous presentation about Giffy Lite.", "tokens": [51364, 934, 439, 264, 4295, 5821, 300, 321, 600, 1612, 294, 264, 3894, 5860, 466, 460, 3661, 88, 32986, 13, 51614], "temperature": 0.0, "avg_logprob": -0.1459426520005712, "compression_ratio": 1.6307692307692307, "no_speech_prob": 0.008191944099962711}, {"id": 59, "seek": 18900, "start": 214.0, "end": 218.0, "text": " So this is an HTML file which contains a graph view.", "tokens": [51614, 407, 341, 307, 364, 17995, 3991, 597, 8306, 257, 4295, 1910, 13, 51814], "temperature": 0.0, "avg_logprob": -0.1459426520005712, "compression_ratio": 1.6307692307692307, "no_speech_prob": 0.008191944099962711}, {"id": 60, "seek": 21800, "start": 218.0, "end": 224.0, "text": " The rendering of each file in HTML and also a few navigational tools,", "tokens": [50364, 440, 22407, 295, 1184, 3991, 294, 17995, 293, 611, 257, 1326, 7407, 1478, 3873, 11, 50664], "temperature": 0.0, "avg_logprob": -0.1043484838385331, "compression_ratio": 1.609442060085837, "no_speech_prob": 0.005254532676190138}, {"id": 61, "seek": 21800, "start": 224.0, "end": 229.0, "text": " an index, a small search box, etc.", "tokens": [50664, 364, 8186, 11, 257, 1359, 3164, 2424, 11, 5183, 13, 50914], "temperature": 0.0, "avg_logprob": -0.1043484838385331, "compression_ratio": 1.609442060085837, "no_speech_prob": 0.005254532676190138}, {"id": 62, "seek": 21800, "start": 229.0, "end": 231.0, "text": " This could be anything.", "tokens": [50914, 639, 727, 312, 1340, 13, 51014], "temperature": 0.0, "avg_logprob": -0.1043484838385331, "compression_ratio": 1.609442060085837, "no_speech_prob": 0.005254532676190138}, {"id": 63, "seek": 21800, "start": 231.0, "end": 233.0, "text": " It could be any kind of knowledge base.", "tokens": [51014, 467, 727, 312, 604, 733, 295, 3601, 3096, 13, 51114], "temperature": 0.0, "avg_logprob": -0.1043484838385331, "compression_ratio": 1.609442060085837, "no_speech_prob": 0.005254532676190138}, {"id": 64, "seek": 21800, "start": 233.0, "end": 235.0, "text": " It could be a glossary of terms.", "tokens": [51114, 467, 727, 312, 257, 19574, 822, 295, 2115, 13, 51214], "temperature": 0.0, "avg_logprob": -0.1043484838385331, "compression_ratio": 1.609442060085837, "no_speech_prob": 0.005254532676190138}, {"id": 65, "seek": 21800, "start": 235.0, "end": 238.0, "text": " It could be a network of people, of concepts, of events.", "tokens": [51214, 467, 727, 312, 257, 3209, 295, 561, 11, 295, 10392, 11, 295, 3931, 13, 51364], "temperature": 0.0, "avg_logprob": -0.1043484838385331, "compression_ratio": 1.609442060085837, "no_speech_prob": 0.005254532676190138}, {"id": 66, "seek": 21800, "start": 238.0, "end": 239.0, "text": " Really it doesn't matter.", "tokens": [51364, 4083, 309, 1177, 380, 1871, 13, 51414], "temperature": 0.0, "avg_logprob": -0.1043484838385331, "compression_ratio": 1.609442060085837, "no_speech_prob": 0.005254532676190138}, {"id": 67, "seek": 21800, "start": 239.0, "end": 245.0, "text": " It's like a commonplace book or wiki or a zettelkasten,", "tokens": [51414, 467, 311, 411, 257, 2689, 6742, 1446, 420, 261, 9850, 420, 257, 710, 3093, 338, 74, 47552, 11, 51714], "temperature": 0.0, "avg_logprob": -0.1043484838385331, "compression_ratio": 1.609442060085837, "no_speech_prob": 0.005254532676190138}, {"id": 68, "seek": 21800, "start": 245.0, "end": 247.0, "text": " if you're familiar with that word.", "tokens": [51714, 498, 291, 434, 4963, 365, 300, 1349, 13, 51814], "temperature": 0.0, "avg_logprob": -0.1043484838385331, "compression_ratio": 1.609442060085837, "no_speech_prob": 0.005254532676190138}, {"id": 69, "seek": 24700, "start": 247.0, "end": 249.0, "text": " Even a mind map to some extent.", "tokens": [50364, 2754, 257, 1575, 4471, 281, 512, 8396, 13, 50464], "temperature": 0.0, "avg_logprob": -0.08697673527881353, "compression_ratio": 1.5684647302904564, "no_speech_prob": 0.004049495793879032}, {"id": 70, "seek": 24700, "start": 249.0, "end": 251.0, "text": " Conceptually it's a bit like that.", "tokens": [50464, 47482, 671, 309, 311, 257, 857, 411, 300, 13, 50564], "temperature": 0.0, "avg_logprob": -0.08697673527881353, "compression_ratio": 1.5684647302904564, "no_speech_prob": 0.004049495793879032}, {"id": 71, "seek": 24700, "start": 251.0, "end": 257.0, "text": " What distinguishes COSMA is that we have, well, the architecture", "tokens": [50564, 708, 11365, 16423, 3002, 50, 9998, 307, 300, 321, 362, 11, 731, 11, 264, 9482, 50864], "temperature": 0.0, "avg_logprob": -0.08697673527881353, "compression_ratio": 1.5684647302904564, "no_speech_prob": 0.004049495793879032}, {"id": 72, "seek": 24700, "start": 257.0, "end": 261.0, "text": " and the fact that we designed it around scientific writing needs.", "tokens": [50864, 293, 264, 1186, 300, 321, 4761, 309, 926, 8134, 3579, 2203, 13, 51064], "temperature": 0.0, "avg_logprob": -0.08697673527881353, "compression_ratio": 1.5684647302904564, "no_speech_prob": 0.004049495793879032}, {"id": 73, "seek": 24700, "start": 261.0, "end": 265.0, "text": " So I'm going to describe briefly the architecture point", "tokens": [51064, 407, 286, 478, 516, 281, 6786, 10515, 264, 9482, 935, 51264], "temperature": 0.0, "avg_logprob": -0.08697673527881353, "compression_ratio": 1.5684647302904564, "no_speech_prob": 0.004049495793879032}, {"id": 74, "seek": 24700, "start": 265.0, "end": 268.0, "text": " and then I'll describe the features a little bit more.", "tokens": [51264, 293, 550, 286, 603, 6786, 264, 4122, 257, 707, 857, 544, 13, 51414], "temperature": 0.0, "avg_logprob": -0.08697673527881353, "compression_ratio": 1.5684647302904564, "no_speech_prob": 0.004049495793879032}, {"id": 75, "seek": 24700, "start": 268.0, "end": 272.0, "text": " So it's purely a visualization program.", "tokens": [51414, 407, 309, 311, 17491, 257, 25801, 1461, 13, 51614], "temperature": 0.0, "avg_logprob": -0.08697673527881353, "compression_ratio": 1.5684647302904564, "no_speech_prob": 0.004049495793879032}, {"id": 76, "seek": 24700, "start": 272.0, "end": 275.0, "text": " You cannot edit data with it.", "tokens": [51614, 509, 2644, 8129, 1412, 365, 309, 13, 51764], "temperature": 0.0, "avg_logprob": -0.08697673527881353, "compression_ratio": 1.5684647302904564, "no_speech_prob": 0.004049495793879032}, {"id": 77, "seek": 27500, "start": 275.0, "end": 278.0, "text": " It just reads plain text files.", "tokens": [50364, 467, 445, 15700, 11121, 2487, 7098, 13, 50514], "temperature": 0.0, "avg_logprob": -0.09455468437888405, "compression_ratio": 1.5435684647302905, "no_speech_prob": 0.005138436798006296}, {"id": 78, "seek": 27500, "start": 278.0, "end": 282.0, "text": " And most of the features are actually located in the exports.", "tokens": [50514, 400, 881, 295, 264, 4122, 366, 767, 6870, 294, 264, 31428, 13, 50714], "temperature": 0.0, "avg_logprob": -0.09455468437888405, "compression_ratio": 1.5435684647302905, "no_speech_prob": 0.005138436798006296}, {"id": 79, "seek": 27500, "start": 282.0, "end": 284.0, "text": " So this is actually COSMA.", "tokens": [50714, 407, 341, 307, 767, 3002, 50, 9998, 13, 50814], "temperature": 0.0, "avg_logprob": -0.09455468437888405, "compression_ratio": 1.5435684647302905, "no_speech_prob": 0.005138436798006296}, {"id": 80, "seek": 27500, "start": 284.0, "end": 286.0, "text": " It's a command line application.", "tokens": [50814, 467, 311, 257, 5622, 1622, 3861, 13, 50914], "temperature": 0.0, "avg_logprob": -0.09455468437888405, "compression_ratio": 1.5435684647302905, "no_speech_prob": 0.005138436798006296}, {"id": 81, "seek": 27500, "start": 286.0, "end": 292.0, "text": " And you use it to generate these HTML files.", "tokens": [50914, 400, 291, 764, 309, 281, 8460, 613, 17995, 7098, 13, 51214], "temperature": 0.0, "avg_logprob": -0.09455468437888405, "compression_ratio": 1.5435684647302905, "no_speech_prob": 0.005138436798006296}, {"id": 82, "seek": 27500, "start": 292.0, "end": 296.0, "text": " If you're familiar with Tiddly wiki, it's a bit like that.", "tokens": [51214, 759, 291, 434, 4963, 365, 314, 14273, 356, 261, 9850, 11, 309, 311, 257, 857, 411, 300, 13, 51414], "temperature": 0.0, "avg_logprob": -0.09455468437888405, "compression_ratio": 1.5435684647302905, "no_speech_prob": 0.005138436798006296}, {"id": 83, "seek": 27500, "start": 296.0, "end": 300.0, "text": " So it's a single HTML file which contains everything except Tiddly wiki.", "tokens": [51414, 407, 309, 311, 257, 2167, 17995, 3991, 597, 8306, 1203, 3993, 314, 14273, 356, 261, 9850, 13, 51614], "temperature": 0.0, "avg_logprob": -0.09455468437888405, "compression_ratio": 1.5435684647302905, "no_speech_prob": 0.005138436798006296}, {"id": 84, "seek": 27500, "start": 300.0, "end": 301.0, "text": " You can edit the data.", "tokens": [51614, 509, 393, 8129, 264, 1412, 13, 51664], "temperature": 0.0, "avg_logprob": -0.09455468437888405, "compression_ratio": 1.5435684647302905, "no_speech_prob": 0.005138436798006296}, {"id": 85, "seek": 27500, "start": 301.0, "end": 302.0, "text": " This is read only.", "tokens": [51664, 639, 307, 1401, 787, 13, 51714], "temperature": 0.0, "avg_logprob": -0.09455468437888405, "compression_ratio": 1.5435684647302905, "no_speech_prob": 0.005138436798006296}, {"id": 86, "seek": 30200, "start": 302.0, "end": 307.0, "text": " So it's less like a web application and more like a sort of augmented document.", "tokens": [50364, 407, 309, 311, 1570, 411, 257, 3670, 3861, 293, 544, 411, 257, 1333, 295, 36155, 4166, 13, 50614], "temperature": 0.0, "avg_logprob": -0.1052847405274709, "compression_ratio": 1.565040650406504, "no_speech_prob": 0.003056295681744814}, {"id": 87, "seek": 30200, "start": 307.0, "end": 309.0, "text": " You can share this file, obviously.", "tokens": [50614, 509, 393, 2073, 341, 3991, 11, 2745, 13, 50714], "temperature": 0.0, "avg_logprob": -0.1052847405274709, "compression_ratio": 1.565040650406504, "no_speech_prob": 0.003056295681744814}, {"id": 88, "seek": 30200, "start": 309.0, "end": 312.0, "text": " It's just an HTML file and people can open it in their browser.", "tokens": [50714, 467, 311, 445, 364, 17995, 3991, 293, 561, 393, 1269, 309, 294, 641, 11185, 13, 50864], "temperature": 0.0, "avg_logprob": -0.1052847405274709, "compression_ratio": 1.565040650406504, "no_speech_prob": 0.003056295681744814}, {"id": 89, "seek": 30200, "start": 312.0, "end": 316.0, "text": " And the idea was that I was familiar with software like Jaffee", "tokens": [50864, 400, 264, 1558, 390, 300, 286, 390, 4963, 365, 4722, 411, 508, 2518, 1653, 51064], "temperature": 0.0, "avg_logprob": -0.1052847405274709, "compression_ratio": 1.565040650406504, "no_speech_prob": 0.003056295681744814}, {"id": 90, "seek": 30200, "start": 316.0, "end": 321.0, "text": " and I always wanted to be able to share graph visualizations with colleagues", "tokens": [51064, 293, 286, 1009, 1415, 281, 312, 1075, 281, 2073, 4295, 5056, 14455, 365, 7734, 51314], "temperature": 0.0, "avg_logprob": -0.1052847405274709, "compression_ratio": 1.565040650406504, "no_speech_prob": 0.003056295681744814}, {"id": 91, "seek": 30200, "start": 321.0, "end": 328.0, "text": " or students, but not as static images, but as interactive things.", "tokens": [51314, 420, 1731, 11, 457, 406, 382, 13437, 5267, 11, 457, 382, 15141, 721, 13, 51664], "temperature": 0.0, "avg_logprob": -0.1052847405274709, "compression_ratio": 1.565040650406504, "no_speech_prob": 0.003056295681744814}, {"id": 92, "seek": 32800, "start": 328.0, "end": 333.0, "text": " And there are lots more options now that exist to do this.", "tokens": [50364, 400, 456, 366, 3195, 544, 3956, 586, 300, 2514, 281, 360, 341, 13, 50614], "temperature": 0.0, "avg_logprob": -0.09375873964224289, "compression_ratio": 1.4472361809045227, "no_speech_prob": 0.0028216508217155933}, {"id": 93, "seek": 32800, "start": 333.0, "end": 339.0, "text": " We just did this for little markdown files.", "tokens": [50614, 492, 445, 630, 341, 337, 707, 1491, 5093, 7098, 13, 50914], "temperature": 0.0, "avg_logprob": -0.09375873964224289, "compression_ratio": 1.4472361809045227, "no_speech_prob": 0.0028216508217155933}, {"id": 94, "seek": 32800, "start": 339.0, "end": 341.0, "text": " So that's the brief point about architecture.", "tokens": [50914, 407, 300, 311, 264, 5353, 935, 466, 9482, 13, 51014], "temperature": 0.0, "avg_logprob": -0.09375873964224289, "compression_ratio": 1.4472361809045227, "no_speech_prob": 0.0028216508217155933}, {"id": 95, "seek": 32800, "start": 341.0, "end": 347.0, "text": " The features, as I mentioned, they're related to information management needs.", "tokens": [51014, 440, 4122, 11, 382, 286, 2835, 11, 436, 434, 4077, 281, 1589, 4592, 2203, 13, 51314], "temperature": 0.0, "avg_logprob": -0.09375873964224289, "compression_ratio": 1.4472361809045227, "no_speech_prob": 0.0028216508217155933}, {"id": 96, "seek": 32800, "start": 347.0, "end": 351.0, "text": " Everything is designed to encourage knowledge organizations.", "tokens": [51314, 5471, 307, 4761, 281, 5373, 3601, 6150, 13, 51514], "temperature": 0.0, "avg_logprob": -0.09375873964224289, "compression_ratio": 1.4472361809045227, "no_speech_prob": 0.0028216508217155933}, {"id": 97, "seek": 35100, "start": 351.0, "end": 358.0, "text": " So categorizing things, classifying, indexing, tagging, relating things to one another.", "tokens": [50364, 407, 19250, 3319, 721, 11, 1508, 5489, 11, 8186, 278, 11, 6162, 3249, 11, 23968, 721, 281, 472, 1071, 13, 50714], "temperature": 0.0, "avg_logprob": -0.07955517655327207, "compression_ratio": 1.5852534562211982, "no_speech_prob": 0.28562551736831665}, {"id": 98, "seek": 35100, "start": 358.0, "end": 361.0, "text": " It's basically a memory aid, actually.", "tokens": [50714, 467, 311, 1936, 257, 4675, 9418, 11, 767, 13, 50864], "temperature": 0.0, "avg_logprob": -0.07955517655327207, "compression_ratio": 1.5852534562211982, "no_speech_prob": 0.28562551736831665}, {"id": 99, "seek": 35100, "start": 361.0, "end": 364.0, "text": " It's not for graph analysis.", "tokens": [50864, 467, 311, 406, 337, 4295, 5215, 13, 51014], "temperature": 0.0, "avg_logprob": -0.07955517655327207, "compression_ratio": 1.5852534562211982, "no_speech_prob": 0.28562551736831665}, {"id": 100, "seek": 35100, "start": 364.0, "end": 370.0, "text": " It's more for network synthesis, so to assemble document graphs about things.", "tokens": [51014, 467, 311, 544, 337, 3209, 30252, 11, 370, 281, 22364, 4166, 24877, 466, 721, 13, 51314], "temperature": 0.0, "avg_logprob": -0.07955517655327207, "compression_ratio": 1.5852534562211982, "no_speech_prob": 0.28562551736831665}, {"id": 101, "seek": 35100, "start": 370.0, "end": 375.0, "text": " And the way it encourages knowledge organization is to provide a few features", "tokens": [51314, 400, 264, 636, 309, 28071, 3601, 4475, 307, 281, 2893, 257, 1326, 4122, 51564], "temperature": 0.0, "avg_logprob": -0.07955517655327207, "compression_ratio": 1.5852534562211982, "no_speech_prob": 0.28562551736831665}, {"id": 102, "seek": 35100, "start": 375.0, "end": 378.0, "text": " that reward this knowledge work.", "tokens": [51564, 300, 7782, 341, 3601, 589, 13, 51714], "temperature": 0.0, "avg_logprob": -0.07955517655327207, "compression_ratio": 1.5852534562211982, "no_speech_prob": 0.28562551736831665}, {"id": 103, "seek": 37800, "start": 378.0, "end": 383.0, "text": " So, for example, if you assign types to your notes, colors will appear", "tokens": [50364, 407, 11, 337, 1365, 11, 498, 291, 6269, 3467, 281, 428, 5570, 11, 4577, 486, 4204, 50614], "temperature": 0.0, "avg_logprob": -0.0918841310726699, "compression_ratio": 1.6150442477876106, "no_speech_prob": 0.03491166979074478}, {"id": 104, "seek": 37800, "start": 383.0, "end": 387.0, "text": " and you will have filters to modify the display.", "tokens": [50614, 293, 291, 486, 362, 15995, 281, 16927, 264, 4674, 13, 50814], "temperature": 0.0, "avg_logprob": -0.0918841310726699, "compression_ratio": 1.6150442477876106, "no_speech_prob": 0.03491166979074478}, {"id": 105, "seek": 37800, "start": 387.0, "end": 389.0, "text": " So you can toggle, for example, one type.", "tokens": [50814, 407, 291, 393, 31225, 11, 337, 1365, 11, 472, 2010, 13, 50914], "temperature": 0.0, "avg_logprob": -0.0918841310726699, "compression_ratio": 1.6150442477876106, "no_speech_prob": 0.03491166979074478}, {"id": 106, "seek": 37800, "start": 389.0, "end": 393.0, "text": " Here I've toggled the inside type, which was in orange.", "tokens": [50914, 1692, 286, 600, 26911, 1493, 264, 1854, 2010, 11, 597, 390, 294, 7671, 13, 51114], "temperature": 0.0, "avg_logprob": -0.0918841310726699, "compression_ratio": 1.6150442477876106, "no_speech_prob": 0.03491166979074478}, {"id": 107, "seek": 37800, "start": 393.0, "end": 398.0, "text": " And it also and mostly encourages link-based knowledge organizations.", "tokens": [51114, 400, 309, 611, 293, 5240, 28071, 2113, 12, 6032, 3601, 6150, 13, 51364], "temperature": 0.0, "avg_logprob": -0.0918841310726699, "compression_ratio": 1.6150442477876106, "no_speech_prob": 0.03491166979074478}, {"id": 108, "seek": 37800, "start": 398.0, "end": 403.0, "text": " So that's using links in the way you're describing the relations with things.", "tokens": [51364, 407, 300, 311, 1228, 6123, 294, 264, 636, 291, 434, 16141, 264, 2299, 365, 721, 13, 51614], "temperature": 0.0, "avg_logprob": -0.0918841310726699, "compression_ratio": 1.6150442477876106, "no_speech_prob": 0.03491166979074478}, {"id": 109, "seek": 40300, "start": 404.0, "end": 408.0, "text": " And the way it rewards that is to provide contextualized backlinks.", "tokens": [50414, 400, 264, 636, 309, 17203, 300, 307, 281, 2893, 35526, 1602, 32449, 16431, 13, 50614], "temperature": 0.0, "avg_logprob": -0.11350149518988106, "compression_ratio": 1.7263681592039801, "no_speech_prob": 0.03948356583714485}, {"id": 110, "seek": 40300, "start": 408.0, "end": 411.0, "text": " So that's the thing that's at the bottom right here.", "tokens": [50614, 407, 300, 311, 264, 551, 300, 311, 412, 264, 2767, 558, 510, 13, 50764], "temperature": 0.0, "avg_logprob": -0.11350149518988106, "compression_ratio": 1.7263681592039801, "no_speech_prob": 0.03948356583714485}, {"id": 111, "seek": 40300, "start": 411.0, "end": 414.0, "text": " These are the incoming links.", "tokens": [50764, 1981, 366, 264, 22341, 6123, 13, 50914], "temperature": 0.0, "avg_logprob": -0.11350149518988106, "compression_ratio": 1.7263681592039801, "no_speech_prob": 0.03948356583714485}, {"id": 112, "seek": 40300, "start": 414.0, "end": 418.0, "text": " So you see here where this note has been cited, and most importantly,", "tokens": [50914, 407, 291, 536, 510, 689, 341, 3637, 575, 668, 30134, 11, 293, 881, 8906, 11, 51114], "temperature": 0.0, "avg_logprob": -0.11350149518988106, "compression_ratio": 1.7263681592039801, "no_speech_prob": 0.03948356583714485}, {"id": 113, "seek": 40300, "start": 418.0, "end": 426.0, "text": " how it's been cited because you have the context, the surrounding paragraph that's here.", "tokens": [51114, 577, 309, 311, 668, 30134, 570, 291, 362, 264, 4319, 11, 264, 11498, 18865, 300, 311, 510, 13, 51514], "temperature": 0.0, "avg_logprob": -0.11350149518988106, "compression_ratio": 1.7263681592039801, "no_speech_prob": 0.03948356583714485}, {"id": 114, "seek": 40300, "start": 426.0, "end": 428.0, "text": " So that's a contextualized backlinks.", "tokens": [51514, 407, 300, 311, 257, 35526, 1602, 32449, 16431, 13, 51614], "temperature": 0.0, "avg_logprob": -0.11350149518988106, "compression_ratio": 1.7263681592039801, "no_speech_prob": 0.03948356583714485}, {"id": 115, "seek": 42800, "start": 428.0, "end": 435.0, "text": " Not an idea that we invented, we just borrowed it from actually web pioneers.", "tokens": [50364, 1726, 364, 1558, 300, 321, 14479, 11, 321, 445, 26805, 309, 490, 767, 3670, 47381, 13, 50714], "temperature": 0.0, "avg_logprob": -0.07162841003720123, "compression_ratio": 1.578125, "no_speech_prob": 0.08654375374317169}, {"id": 116, "seek": 42800, "start": 435.0, "end": 439.0, "text": " It's been going around for a long time.", "tokens": [50714, 467, 311, 668, 516, 926, 337, 257, 938, 565, 13, 50914], "temperature": 0.0, "avg_logprob": -0.07162841003720123, "compression_ratio": 1.578125, "no_speech_prob": 0.08654375374317169}, {"id": 117, "seek": 42800, "start": 439.0, "end": 444.0, "text": " And in recent years, there's been a wave of tools for thought text editors", "tokens": [50914, 400, 294, 5162, 924, 11, 456, 311, 668, 257, 5772, 295, 3873, 337, 1194, 2487, 31446, 51164], "temperature": 0.0, "avg_logprob": -0.07162841003720123, "compression_ratio": 1.578125, "no_speech_prob": 0.08654375374317169}, {"id": 118, "seek": 42800, "start": 444.0, "end": 448.0, "text": " in which you can create little notes, link them together, organize them,", "tokens": [51164, 294, 597, 291, 393, 1884, 707, 5570, 11, 2113, 552, 1214, 11, 13859, 552, 11, 51364], "temperature": 0.0, "avg_logprob": -0.07162841003720123, "compression_ratio": 1.578125, "no_speech_prob": 0.08654375374317169}, {"id": 119, "seek": 42800, "start": 448.0, "end": 451.0, "text": " and they pretty much all have this feature.", "tokens": [51364, 293, 436, 1238, 709, 439, 362, 341, 4111, 13, 51514], "temperature": 0.0, "avg_logprob": -0.07162841003720123, "compression_ratio": 1.578125, "no_speech_prob": 0.08654375374317169}, {"id": 120, "seek": 42800, "start": 451.0, "end": 456.0, "text": " We just wanted a way to have it for scientific writing and also to be able to share it easily.", "tokens": [51514, 492, 445, 1415, 257, 636, 281, 362, 309, 337, 8134, 3579, 293, 611, 281, 312, 1075, 281, 2073, 309, 3612, 13, 51764], "temperature": 0.0, "avg_logprob": -0.07162841003720123, "compression_ratio": 1.578125, "no_speech_prob": 0.08654375374317169}, {"id": 121, "seek": 45600, "start": 457.0, "end": 461.0, "text": " Now the big thing that we did is we have the same feature, but for citations.", "tokens": [50414, 823, 264, 955, 551, 300, 321, 630, 307, 321, 362, 264, 912, 4111, 11, 457, 337, 4814, 763, 13, 50614], "temperature": 0.0, "avg_logprob": -0.15088472780974016, "compression_ratio": 1.6626984126984128, "no_speech_prob": 0.0011145180324092507}, {"id": 122, "seek": 45600, "start": 461.0, "end": 468.0, "text": " So if you're working with bibliographic data, so you have maybe a raw JSON file,", "tokens": [50614, 407, 498, 291, 434, 1364, 365, 34344, 12295, 1412, 11, 370, 291, 362, 1310, 257, 8936, 31828, 3991, 11, 50964], "temperature": 0.0, "avg_logprob": -0.15088472780974016, "compression_ratio": 1.6626984126984128, "no_speech_prob": 0.0011145180324092507}, {"id": 123, "seek": 45600, "start": 468.0, "end": 474.0, "text": " maybe more likely you're working with a reference manager like Zotero, N-node, Mandalay, etc.", "tokens": [50964, 1310, 544, 3700, 291, 434, 1364, 365, 257, 6408, 6598, 411, 1176, 310, 2032, 11, 426, 12, 77, 1429, 11, 15458, 35951, 11, 5183, 13, 51264], "temperature": 0.0, "avg_logprob": -0.15088472780974016, "compression_ratio": 1.6626984126984128, "no_speech_prob": 0.0011145180324092507}, {"id": 124, "seek": 45600, "start": 474.0, "end": 478.0, "text": " And if you're in your notes, your citing works.", "tokens": [51264, 400, 498, 291, 434, 294, 428, 5570, 11, 428, 48749, 1985, 13, 51464], "temperature": 0.0, "avg_logprob": -0.15088472780974016, "compression_ratio": 1.6626984126984128, "no_speech_prob": 0.0011145180324092507}, {"id": 125, "seek": 45600, "start": 478.0, "end": 485.0, "text": " So for example, here on the right, I'm quoting the two references that you can see are stored in the file on the left.", "tokens": [51464, 407, 337, 1365, 11, 510, 322, 264, 558, 11, 286, 478, 41552, 264, 732, 15400, 300, 291, 393, 536, 366, 12187, 294, 264, 3991, 322, 264, 1411, 13, 51814], "temperature": 0.0, "avg_logprob": -0.15088472780974016, "compression_ratio": 1.6626984126984128, "no_speech_prob": 0.0011145180324092507}, {"id": 126, "seek": 48500, "start": 486.0, "end": 492.0, "text": " Well, Cosma will generate a bibliographic note, that's the dark gray one here.", "tokens": [50414, 1042, 11, 15855, 1696, 486, 8460, 257, 34344, 12295, 3637, 11, 300, 311, 264, 2877, 10855, 472, 510, 13, 50714], "temperature": 0.0, "avg_logprob": -0.12034071227650583, "compression_ratio": 1.5121951219512195, "no_speech_prob": 0.006503180135041475}, {"id": 127, "seek": 48500, "start": 492.0, "end": 496.0, "text": " I haven't created a text file for this note, it's been generated automatically.", "tokens": [50714, 286, 2378, 380, 2942, 257, 2487, 3991, 337, 341, 3637, 11, 309, 311, 668, 10833, 6772, 13, 50914], "temperature": 0.0, "avg_logprob": -0.12034071227650583, "compression_ratio": 1.5121951219512195, "no_speech_prob": 0.006503180135041475}, {"id": 128, "seek": 48500, "start": 496.0, "end": 501.0, "text": " And most importantly, it will show me the backlinks as well for the citations.", "tokens": [50914, 400, 881, 8906, 11, 309, 486, 855, 385, 264, 32449, 16431, 382, 731, 337, 264, 4814, 763, 13, 51164], "temperature": 0.0, "avg_logprob": -0.12034071227650583, "compression_ratio": 1.5121951219512195, "no_speech_prob": 0.006503180135041475}, {"id": 129, "seek": 48500, "start": 501.0, "end": 506.0, "text": " So I can see where I've been citing which work and how in which context.", "tokens": [51164, 407, 286, 393, 536, 689, 286, 600, 668, 48749, 597, 589, 293, 577, 294, 597, 4319, 13, 51414], "temperature": 0.0, "avg_logprob": -0.12034071227650583, "compression_ratio": 1.5121951219512195, "no_speech_prob": 0.006503180135041475}, {"id": 130, "seek": 50600, "start": 507.0, "end": 516.0, "text": " I want to close on the idea of network synthesis very quickly in my dissertation.", "tokens": [50414, 286, 528, 281, 1998, 322, 264, 1558, 295, 3209, 30252, 588, 2661, 294, 452, 39555, 13, 50864], "temperature": 0.0, "avg_logprob": -0.08895040658804086, "compression_ratio": 1.5668449197860963, "no_speech_prob": 0.006841798312962055}, {"id": 131, "seek": 50600, "start": 516.0, "end": 522.0, "text": " What I argue is that linking the simple act of relating two things to one another in hypertext,", "tokens": [50864, 708, 286, 9695, 307, 300, 25775, 264, 2199, 605, 295, 23968, 732, 721, 281, 472, 1071, 294, 9848, 25111, 11, 51164], "temperature": 0.0, "avg_logprob": -0.08895040658804086, "compression_ratio": 1.5668449197860963, "no_speech_prob": 0.006841798312962055}, {"id": 132, "seek": 50600, "start": 522.0, "end": 524.0, "text": " it's a knowledge organization process.", "tokens": [51164, 309, 311, 257, 3601, 4475, 1399, 13, 51264], "temperature": 0.0, "avg_logprob": -0.08895040658804086, "compression_ratio": 1.5668449197860963, "no_speech_prob": 0.006841798312962055}, {"id": 133, "seek": 50600, "start": 524.0, "end": 528.0, "text": " So that expression is actually a thing in knowledge organization literature.", "tokens": [51264, 407, 300, 6114, 307, 767, 257, 551, 294, 3601, 4475, 10394, 13, 51464], "temperature": 0.0, "avg_logprob": -0.08895040658804086, "compression_ratio": 1.5668449197860963, "no_speech_prob": 0.006841798312962055}, {"id": 134, "seek": 52800, "start": 529.0, "end": 536.0, "text": " It's classifying, indexing, tagging, basically any process that you do that organizes knowledge.", "tokens": [50414, 467, 311, 1508, 5489, 11, 8186, 278, 11, 6162, 3249, 11, 1936, 604, 1399, 300, 291, 360, 300, 4645, 279, 3601, 13, 50764], "temperature": 0.0, "avg_logprob": -0.08266814162091511, "compression_ratio": 1.5854922279792747, "no_speech_prob": 0.23165950179100037}, {"id": 135, "seek": 52800, "start": 536.0, "end": 539.0, "text": " And linking is a way to do a lot of that.", "tokens": [50764, 400, 25775, 307, 257, 636, 281, 360, 257, 688, 295, 300, 13, 50914], "temperature": 0.0, "avg_logprob": -0.08266814162091511, "compression_ratio": 1.5854922279792747, "no_speech_prob": 0.23165950179100037}, {"id": 136, "seek": 52800, "start": 539.0, "end": 545.0, "text": " Linking could be a way to index, to classify, to tag, to assign things to others.", "tokens": [50914, 8466, 278, 727, 312, 257, 636, 281, 8186, 11, 281, 33872, 11, 281, 6162, 11, 281, 6269, 721, 281, 2357, 13, 51214], "temperature": 0.0, "avg_logprob": -0.08266814162091511, "compression_ratio": 1.5854922279792747, "no_speech_prob": 0.23165950179100037}, {"id": 137, "seek": 52800, "start": 545.0, "end": 552.0, "text": " And most importantly to compose with links you can express new ideas, just like Lego.", "tokens": [51214, 400, 881, 8906, 281, 35925, 365, 6123, 291, 393, 5109, 777, 3487, 11, 445, 411, 28761, 13, 51564], "temperature": 0.0, "avg_logprob": -0.08266814162091511, "compression_ratio": 1.5854922279792747, "no_speech_prob": 0.23165950179100037}, {"id": 138, "seek": 55200, "start": 552.0, "end": 557.0, "text": " If you have a note on a concept and a note on another concept,", "tokens": [50364, 759, 291, 362, 257, 3637, 322, 257, 3410, 293, 257, 3637, 322, 1071, 3410, 11, 50614], "temperature": 0.0, "avg_logprob": -0.11453876892725627, "compression_ratio": 1.6858407079646018, "no_speech_prob": 0.02324514649808407}, {"id": 139, "seek": 55200, "start": 557.0, "end": 561.0, "text": " and you just bring the two together in a sentence, this relates to that because this,", "tokens": [50614, 293, 291, 445, 1565, 264, 732, 1214, 294, 257, 8174, 11, 341, 16155, 281, 300, 570, 341, 11, 50814], "temperature": 0.0, "avg_logprob": -0.11453876892725627, "compression_ratio": 1.6858407079646018, "no_speech_prob": 0.02324514649808407}, {"id": 140, "seek": 55200, "start": 561.0, "end": 568.0, "text": " this becomes a new idea, you express it in a new note, and that's ideation, the basic process of research.", "tokens": [50814, 341, 3643, 257, 777, 1558, 11, 291, 5109, 309, 294, 257, 777, 3637, 11, 293, 300, 311, 1153, 399, 11, 264, 3875, 1399, 295, 2132, 13, 51164], "temperature": 0.0, "avg_logprob": -0.11453876892725627, "compression_ratio": 1.6858407079646018, "no_speech_prob": 0.02324514649808407}, {"id": 141, "seek": 55200, "start": 568.0, "end": 577.0, "text": " I'm going to skip very quickly all these examples that I had added because it'd be fun if there were some time for questions.", "tokens": [51164, 286, 478, 516, 281, 10023, 588, 2661, 439, 613, 5110, 300, 286, 632, 3869, 570, 309, 1116, 312, 1019, 498, 456, 645, 512, 565, 337, 1651, 13, 51614], "temperature": 0.0, "avg_logprob": -0.11453876892725627, "compression_ratio": 1.6858407079646018, "no_speech_prob": 0.02324514649808407}, {"id": 142, "seek": 57700, "start": 577.0, "end": 588.0, "text": " And just to say that this process of synthesizing knowledge, this is why I titled the presentation Tool for Network Synthesis.", "tokens": [50364, 400, 445, 281, 584, 300, 341, 1399, 295, 26617, 3319, 3601, 11, 341, 307, 983, 286, 19841, 264, 5860, 15934, 337, 12640, 318, 45601, 13, 50914], "temperature": 0.0, "avg_logprob": -0.11663513713412815, "compression_ratio": 1.5317073170731708, "no_speech_prob": 0.05265847221016884}, {"id": 143, "seek": 57700, "start": 588.0, "end": 592.0, "text": " Obviously in the process of research the first step is analysis.", "tokens": [50914, 7580, 294, 264, 1399, 295, 2132, 264, 700, 1823, 307, 5215, 13, 51114], "temperature": 0.0, "avg_logprob": -0.11663513713412815, "compression_ratio": 1.5317073170731708, "no_speech_prob": 0.05265847221016884}, {"id": 144, "seek": 57700, "start": 592.0, "end": 602.0, "text": " You start with an object, a phenomenon, and you start, and you try to decompose it to see the fundamental building blocks.", "tokens": [51114, 509, 722, 365, 364, 2657, 11, 257, 14029, 11, 293, 291, 722, 11, 293, 291, 853, 281, 22867, 541, 309, 281, 536, 264, 8088, 2390, 8474, 13, 51614], "temperature": 0.0, "avg_logprob": -0.11663513713412815, "compression_ratio": 1.5317073170731708, "no_speech_prob": 0.05265847221016884}, {"id": 145, "seek": 60200, "start": 602.0, "end": 609.0, "text": " But the goal is to take those fundamental units and sort of mash them together again to produce new things.", "tokens": [50364, 583, 264, 3387, 307, 281, 747, 729, 8088, 6815, 293, 1333, 295, 31344, 552, 1214, 797, 281, 5258, 777, 721, 13, 50714], "temperature": 0.0, "avg_logprob": -0.08220801664435345, "compression_ratio": 1.699588477366255, "no_speech_prob": 0.26437678933143616}, {"id": 146, "seek": 60200, "start": 609.0, "end": 616.0, "text": " And this tool is just that, it's just a tool to help with this process of knowledge synthesis,", "tokens": [50714, 400, 341, 2290, 307, 445, 300, 11, 309, 311, 445, 257, 2290, 281, 854, 365, 341, 1399, 295, 3601, 30252, 11, 51064], "temperature": 0.0, "avg_logprob": -0.08220801664435345, "compression_ratio": 1.699588477366255, "no_speech_prob": 0.26437678933143616}, {"id": 147, "seek": 60200, "start": 616.0, "end": 622.0, "text": " which is to assemble and expand over time these little document graphs.", "tokens": [51064, 597, 307, 281, 22364, 293, 5268, 670, 565, 613, 707, 4166, 24877, 13, 51364], "temperature": 0.0, "avg_logprob": -0.08220801664435345, "compression_ratio": 1.699588477366255, "no_speech_prob": 0.26437678933143616}, {"id": 148, "seek": 60200, "start": 622.0, "end": 626.0, "text": " I'm saying document graphs because there's the expression knowledge graph.", "tokens": [51364, 286, 478, 1566, 4166, 24877, 570, 456, 311, 264, 6114, 3601, 4295, 13, 51564], "temperature": 0.0, "avg_logprob": -0.08220801664435345, "compression_ratio": 1.699588477366255, "no_speech_prob": 0.26437678933143616}, {"id": 149, "seek": 60200, "start": 626.0, "end": 629.0, "text": " Knowledge graph is usually a set of descriptions in a database,", "tokens": [51564, 32906, 4295, 307, 2673, 257, 992, 295, 24406, 294, 257, 8149, 11, 51714], "temperature": 0.0, "avg_logprob": -0.08220801664435345, "compression_ratio": 1.699588477366255, "no_speech_prob": 0.26437678933143616}, {"id": 150, "seek": 62900, "start": 630.0, "end": 635.0, "text": " and these are just little documents, so hence the word document graph.", "tokens": [50414, 293, 613, 366, 445, 707, 8512, 11, 370, 16678, 264, 1349, 4166, 4295, 13, 50664], "temperature": 0.0, "avg_logprob": -0.17881695429484049, "compression_ratio": 1.2110091743119267, "no_speech_prob": 0.05699268728494644}, {"id": 151, "seek": 62900, "start": 635.0, "end": 639.0, "text": " Right, I'm going to hand here, and if you have any questions.", "tokens": [50664, 1779, 11, 286, 478, 516, 281, 1011, 510, 11, 293, 498, 291, 362, 604, 1651, 13, 50864], "temperature": 0.0, "avg_logprob": -0.17881695429484049, "compression_ratio": 1.2110091743119267, "no_speech_prob": 0.05699268728494644}, {"id": 152, "seek": 63900, "start": 639.0, "end": 644.0, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 50614], "temperature": 0.0, "avg_logprob": -0.4900703430175781, "compression_ratio": 1.2971014492753623, "no_speech_prob": 0.16640259325504303}, {"id": 153, "seek": 63900, "start": 644.0, "end": 649.0, "text": " Do we have any questions in the room? We have four minutes.", "tokens": [50614, 1144, 321, 362, 604, 1651, 294, 264, 1808, 30, 492, 362, 1451, 2077, 13, 50864], "temperature": 0.0, "avg_logprob": -0.4900703430175781, "compression_ratio": 1.2971014492753623, "no_speech_prob": 0.16640259325504303}, {"id": 154, "seek": 63900, "start": 649.0, "end": 658.0, "text": " A question about using graph-based and markdown-based, I don't think it improves the blocks or the accident.", "tokens": [50864, 316, 1168, 466, 1228, 4295, 12, 6032, 293, 1491, 5093, 12, 6032, 11, 286, 500, 380, 519, 309, 24771, 264, 8474, 420, 264, 6398, 13, 51314], "temperature": 0.0, "avg_logprob": -0.4900703430175781, "compression_ratio": 1.2971014492753623, "no_speech_prob": 0.16640259325504303}, {"id": 155, "seek": 65800, "start": 658.0, "end": 678.0, "text": " So the question was can we use this application to visualize nodes that would have been created with applications such as Obsidian or Luxik.", "tokens": [50364, 407, 264, 1168, 390, 393, 321, 764, 341, 3861, 281, 23273, 13891, 300, 576, 362, 668, 2942, 365, 5821, 1270, 382, 20707, 34681, 420, 25767, 1035, 13, 51364], "temperature": 0.0, "avg_logprob": -0.32103160119825797, "compression_ratio": 1.2727272727272727, "no_speech_prob": 0.06450748443603516}, {"id": 156, "seek": 67800, "start": 679.0, "end": 689.0, "text": " A colleague actually wrote a little Obsidian to Cosma Converter because we have a data format which is close but not quite the same as Obsidian.", "tokens": [50414, 316, 13532, 767, 4114, 257, 707, 20707, 34681, 281, 15855, 1696, 2656, 331, 391, 570, 321, 362, 257, 1412, 7877, 597, 307, 1998, 457, 406, 1596, 264, 912, 382, 20707, 34681, 13, 50914], "temperature": 0.0, "avg_logprob": -0.12464923649043827, "compression_ratio": 1.6605504587155964, "no_speech_prob": 0.6268406510353088}, {"id": 157, "seek": 67800, "start": 689.0, "end": 695.0, "text": " Obviously you have to have a YAML header, the links have to be a certain way, etc.", "tokens": [50914, 7580, 291, 362, 281, 362, 257, 398, 2865, 43, 23117, 11, 264, 6123, 362, 281, 312, 257, 1629, 636, 11, 5183, 13, 51214], "temperature": 0.0, "avg_logprob": -0.12464923649043827, "compression_ratio": 1.6605504587155964, "no_speech_prob": 0.6268406510353088}, {"id": 158, "seek": 67800, "start": 695.0, "end": 705.0, "text": " So there is a converter for, if you have nodes written with Obsidian, there's a converter out there to transform them into the format.", "tokens": [51214, 407, 456, 307, 257, 33905, 337, 11, 498, 291, 362, 13891, 3720, 365, 20707, 34681, 11, 456, 311, 257, 33905, 484, 456, 281, 4088, 552, 666, 264, 7877, 13, 51714], "temperature": 0.0, "avg_logprob": -0.12464923649043827, "compression_ratio": 1.6605504587155964, "no_speech_prob": 0.6268406510353088}, {"id": 159, "seek": 70500, "start": 706.0, "end": 709.0, "text": " I don't know that there's such a thing for Luxik.", "tokens": [50414, 286, 500, 380, 458, 300, 456, 311, 1270, 257, 551, 337, 25767, 1035, 13, 50564], "temperature": 0.0, "avg_logprob": -0.2193730460272895, "compression_ratio": 1.4383561643835616, "no_speech_prob": 0.14165548980236053}, {"id": 160, "seek": 70500, "start": 709.0, "end": 718.0, "text": " It's possible because it's just plain text, markdown, YAML, it's very easy to write, I think, a custom parser and convert it.", "tokens": [50564, 467, 311, 1944, 570, 309, 311, 445, 11121, 2487, 11, 1491, 5093, 11, 398, 2865, 43, 11, 309, 311, 588, 1858, 281, 2464, 11, 286, 519, 11, 257, 2375, 21156, 260, 293, 7620, 309, 13, 51014], "temperature": 0.0, "avg_logprob": -0.2193730460272895, "compression_ratio": 1.4383561643835616, "no_speech_prob": 0.14165548980236053}, {"id": 161, "seek": 70500, "start": 718.0, "end": 721.0, "text": " Do you have time for one more question?", "tokens": [51014, 1144, 291, 362, 565, 337, 472, 544, 1168, 30, 51164], "temperature": 0.0, "avg_logprob": -0.2193730460272895, "compression_ratio": 1.4383561643835616, "no_speech_prob": 0.14165548980236053}, {"id": 162, "seek": 70500, "start": 721.0, "end": 724.0, "text": " Thanks for an interesting presentation.", "tokens": [51164, 2561, 337, 364, 1880, 5860, 13, 51314], "temperature": 0.0, "avg_logprob": -0.2193730460272895, "compression_ratio": 1.4383561643835616, "no_speech_prob": 0.14165548980236053}, {"id": 163, "seek": 70500, "start": 724.0, "end": 727.0, "text": " At all I'd really like to use in combination with Obsidian.", "tokens": [51314, 1711, 439, 286, 1116, 534, 411, 281, 764, 294, 6562, 365, 20707, 34681, 13, 51464], "temperature": 0.0, "avg_logprob": -0.2193730460272895, "compression_ratio": 1.4383561643835616, "no_speech_prob": 0.14165548980236053}, {"id": 164, "seek": 72700, "start": 727.0, "end": 730.0, "text": " I was wondering about the format of the nodes.", "tokens": [50364, 286, 390, 6359, 466, 264, 7877, 295, 264, 13891, 13, 50514], "temperature": 0.0, "avg_logprob": -0.2636520579709845, "compression_ratio": 1.68503937007874, "no_speech_prob": 0.4064981937408447}, {"id": 165, "seek": 72700, "start": 730.0, "end": 734.0, "text": " You mentioned Zetl-Caston, which has a specific format and way of linking.", "tokens": [50514, 509, 2835, 1176, 302, 75, 12, 34, 525, 266, 11, 597, 575, 257, 2685, 7877, 293, 636, 295, 25775, 13, 50714], "temperature": 0.0, "avg_logprob": -0.2636520579709845, "compression_ratio": 1.68503937007874, "no_speech_prob": 0.4064981937408447}, {"id": 166, "seek": 72700, "start": 734.0, "end": 736.0, "text": " There's permanent nodes, there's every node.", "tokens": [50714, 821, 311, 10996, 13891, 11, 456, 311, 633, 9984, 13, 50814], "temperature": 0.0, "avg_logprob": -0.2636520579709845, "compression_ratio": 1.68503937007874, "no_speech_prob": 0.4064981937408447}, {"id": 167, "seek": 72700, "start": 736.0, "end": 745.0, "text": " Could you elaborate a bit on that, on what type of nodes would work well in this, not a synthesis, a way that you would use?", "tokens": [50814, 7497, 291, 20945, 257, 857, 322, 300, 11, 322, 437, 2010, 295, 13891, 576, 589, 731, 294, 341, 11, 406, 257, 30252, 11, 257, 636, 300, 291, 576, 764, 30, 51264], "temperature": 0.0, "avg_logprob": -0.2636520579709845, "compression_ratio": 1.68503937007874, "no_speech_prob": 0.4064981937408447}, {"id": 168, "seek": 72700, "start": 745.0, "end": 748.0, "text": " Yeah, a repeating question.", "tokens": [51264, 865, 11, 257, 18617, 1168, 13, 51414], "temperature": 0.0, "avg_logprob": -0.2636520579709845, "compression_ratio": 1.68503937007874, "no_speech_prob": 0.4064981937408447}, {"id": 169, "seek": 72700, "start": 748.0, "end": 755.0, "text": " What type of format would be ideal to work with Cosma since there are many formats out there at Zetl-Caston?", "tokens": [51414, 708, 2010, 295, 7877, 576, 312, 7157, 281, 589, 365, 15855, 1696, 1670, 456, 366, 867, 25879, 484, 456, 412, 1176, 302, 75, 12, 34, 525, 266, 30, 51764], "temperature": 0.0, "avg_logprob": -0.2636520579709845, "compression_ratio": 1.68503937007874, "no_speech_prob": 0.4064981937408447}, {"id": 170, "seek": 75500, "start": 756.0, "end": 758.0, "text": " The type of nodes.", "tokens": [50414, 440, 2010, 295, 13891, 13, 50514], "temperature": 0.0, "avg_logprob": -0.23811159016173564, "compression_ratio": 1.6021505376344085, "no_speech_prob": 0.059040118008852005}, {"id": 171, "seek": 75500, "start": 758.0, "end": 760.0, "text": " Oh, the type of nodes.", "tokens": [50514, 876, 11, 264, 2010, 295, 13891, 13, 50614], "temperature": 0.0, "avg_logprob": -0.23811159016173564, "compression_ratio": 1.6021505376344085, "no_speech_prob": 0.059040118008852005}, {"id": 172, "seek": 75500, "start": 760.0, "end": 764.0, "text": " Atomic nodes.", "tokens": [50614, 1711, 21401, 13891, 13, 50814], "temperature": 0.0, "avg_logprob": -0.23811159016173564, "compression_ratio": 1.6021505376344085, "no_speech_prob": 0.059040118008852005}, {"id": 173, "seek": 75500, "start": 764.0, "end": 771.0, "text": " I've shown Andy Matushek's notes, he writes a lot about evergreen nodes and the principles behind evergreen nodes,", "tokens": [50814, 286, 600, 4898, 13285, 6789, 301, 675, 74, 311, 5570, 11, 415, 13657, 257, 688, 466, 1562, 27399, 13891, 293, 264, 9156, 2261, 1562, 27399, 13891, 11, 51164], "temperature": 0.0, "avg_logprob": -0.23811159016173564, "compression_ratio": 1.6021505376344085, "no_speech_prob": 0.059040118008852005}, {"id": 174, "seek": 75500, "start": 771.0, "end": 783.0, "text": " things should be atomic, densely linked, and the titles of the nodes should describe one thing and maybe work almost like APIs.", "tokens": [51164, 721, 820, 312, 22275, 11, 24505, 736, 9408, 11, 293, 264, 12992, 295, 264, 13891, 820, 6786, 472, 551, 293, 1310, 589, 1920, 411, 21445, 13, 51764], "temperature": 0.0, "avg_logprob": -0.23811159016173564, "compression_ratio": 1.6021505376344085, "no_speech_prob": 0.059040118008852005}, {"id": 175, "seek": 78300, "start": 783.0, "end": 786.0, "text": " It could be a sentence that describes the idea.", "tokens": [50364, 467, 727, 312, 257, 8174, 300, 15626, 264, 1558, 13, 50514], "temperature": 0.0, "avg_logprob": -0.10054812675867325, "compression_ratio": 1.521505376344086, "no_speech_prob": 0.02683328464627266}, {"id": 176, "seek": 78300, "start": 786.0, "end": 788.0, "text": " So that's the best sort of mental model.", "tokens": [50514, 407, 300, 311, 264, 1151, 1333, 295, 4973, 2316, 13, 50614], "temperature": 0.0, "avg_logprob": -0.10054812675867325, "compression_ratio": 1.521505376344086, "no_speech_prob": 0.02683328464627266}, {"id": 177, "seek": 78300, "start": 788.0, "end": 801.0, "text": " It's less suited for a daily log, for instance, than for a sort of conceptual knowledge base, again, where you try to relate events, concepts, people, etc.", "tokens": [50614, 467, 311, 1570, 24736, 337, 257, 5212, 3565, 11, 337, 5197, 11, 813, 337, 257, 1333, 295, 24106, 3601, 3096, 11, 797, 11, 689, 291, 853, 281, 10961, 3931, 11, 10392, 11, 561, 11, 5183, 13, 51264], "temperature": 0.0, "avg_logprob": -0.10054812675867325, "compression_ratio": 1.521505376344086, "no_speech_prob": 0.02683328464627266}, {"id": 178, "seek": 78300, "start": 801.0, "end": 803.0, "text": " I hope I was clear.", "tokens": [51264, 286, 1454, 286, 390, 1850, 13, 51364], "temperature": 0.0, "avg_logprob": -0.10054812675867325, "compression_ratio": 1.521505376344086, "no_speech_prob": 0.02683328464627266}, {"id": 179, "seek": 78300, "start": 803.0, "end": 805.0, "text": " Thank you so much.", "tokens": [51364, 1044, 291, 370, 709, 13, 51464], "temperature": 0.0, "avg_logprob": -0.10054812675867325, "compression_ratio": 1.521505376344086, "no_speech_prob": 0.02683328464627266}], "language": "en"}