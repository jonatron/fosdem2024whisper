{"text": " Good morning everybody. Thank you for being so patient. I don't think I've ever had a full room with 24 minutes to go before the start of my talk before. So that is a very special experience. Thank you for sharing it with me. I unmuted, but thank you for checking. So I am going to talk to you today about OpenAPI. I'm going to try to give you something new that you could maybe take back and try, whether you haven't seen this before or whether you're just looking to level up your game a little bit. My name is Lorna. I work for Redockly. I'm VP Developer Experience there. I love APIs. My background is in software engineering. I've been a developer for most of my career. I've built APIs, integrated with APIs, worked for API producers, done API consultancy. Now I build the API tooling. It's, yeah, look, it's a thing that I enjoy and I'm happy that you are all here to share it with me. So let's start by talking about OpenAPI. OpenAPI, I know a lot of people raised their hands, but maybe it's new to some people. OpenAPI is an open standard. It's a way of describing your HTTP APIs in a format that aims to be both human and machine readable. What's nice about that is when we use a standard format, everybody uses the same format. And when that's an open format, it's developed in the open. You can be part of that development process and I'll talk a little bit more about the OpenAPI community at the end. You can see what's coming. You can join the meetings. You can follow the issues on GitHub. If you are using OpenAPI as a producer, as a consumer, if you make tooling for OpenAPI, there are no surprises. You know what's coming and you can be part of that. So it really improves our confidence on working with it. I think the most difficult thing about working with OpenAPI is it's just very verbose. It takes a lot of lines to describe what can be quite a simple thing. So I'm going to start by talking a bit about the structure of OpenAPI because I think when you can find your way around, you understand the map, it's much easier to work with it. So this is a representation of the things that you will find at the top level of an OpenAPI description. OpenAPI, which version of OpenAPI is this? Info, a bit of metadata about the API that this description describes. So here you'll find the title, probably some license information, some contact information, the version that we're on. All of that is in the info block. External docs. It's very easy. You publish an IAS developer website, you link to your API reference docs. If the user arrives on the reference docs, maybe from a search engine, is there a link back to that nice developer website that you made them? Check, because I feel like I've put this right on everything I've ever worked on. There is a security section and that will describe the authorization and authentication needs for the different that are used by the different endpoints in your API. We've got a service section, where is this API published? Tags allow you to attach metadata to individual endpoints. They're listed at the top level and then you can just use them where you need them. The paths section is where the real API documentation actually happens. This is what we think of as API docs. We have an entry for each endpoint describing what it does, the parameters that it accepts or how to shape the request and the response or responses that you can expect back. You'll also find web hooks here, so where you have an API that as well as receiving requests and returning responses, something happens and it sends you a response. You can describe those with web hooks. They're a little bit different to the request response feature. Those were added in 3.1, which, although it is the newest version of OpenAPI, is 3 years old, so wouldn't describe it as cutting edge. We also have here the components section. The components section allows us to describe things that we're going to use multiple times. If you use the same filtering, pagination, date format, if those are common patterns across your API, I mean, if they're not, we need to talk. But if you reuse those things, you can define them in the components section and reuse them. So knowing kind of, they can go in any order, but knowing where you are and where the other things are that you might need can make these very long documents navigable. OpenAPI descriptions are often thousands or tens of thousands of lines of code. My favorite test API description to use is the GitHub one. It's quarter of a million lines of YAML. Like, yeah, you need to know where you're going. Your tools can help you. But it's like carrying something that's not exactly heavy, but it's just a bit unwieldy. So let's drill into some of the detail. Here is just basically the top part of your OpenAPI description. We have a version. It's not very exciting. We have an info section. We've got a title. Give your API a unique and meaningful title. We have summary and description. A lot of OpenAPI elements have these two texty fields, the summary and the description. The difference, the summary is just text. It's short format. It's usually shown in a listing. The description supports markdown, specifically common mark. It's usually shown when we're looking at the detail. So if your API is shown in a catalog or in a list, it'll use the summary. And if you are viewing the API reference documentation, you'll probably see the whole description. And don't be afraid to use the markdown features for links and to really enrich what you do within your OpenAPI file. There's an info version field. And I think this is one thing that I see people getting confused with frequently. Info version is the version of the API description. So if you change this definition document, you're going to change the description field. Does your API info version need to match your API version? I don't really care. But if you change your description a lot, can you please bump the info version so that I know I don't have the latest version of this document? You lock it to your API version if that helps or don't. Maybe you haven't made any API changes, but you did add great descriptions, better examples or something else that changes the OpenAPI description of your API. Bump the version so I know I need to get the new one. Please add a license. Yeah. So this is like some nice fluffy rendering. I made this with Blockly. I hope that you like it. And I think it's just easier to look at than the real thing. This is the YAML version. And I can do 10 screens of YAML and I will be having a nice time, but I don't know if you will be having a nice time. So I brought you some pictures. But this is kind of the equivalent of seeing it in YAML. Like now imagine another 20,000 lines and you're starting to visualize how this thing looks. Okay, let's look a little bit at the paths. We have within the YAML path section, we have one block for each combination of URL and verb or method. So like I have one that is item endpoint, it's got a get operation. Got another one. I'm really good at naming things. Called things another URL which has both get and post. Those are different operations. They get their own description. If we drill into one, how's an operation ID? Fun fact, operation ID is optional in open API. It's technically optional. Honestly, you need it. It needs to be unique. Just get your linting to put that in. There's very few APIs where this isn't a useful thing to have and it's not like it's painful to do. We've got a description. You probably would have a summary as well. Won't all fit. I have added some tags to my endpoint. This is related to user and accounts. We might have user and orders or some other combination of tags here. You can have multiple tags. If there were request body requirements or parameters, those will be described here as well. And then we've got the responses. I've only got the 200 response here. It's very bad. You should always describe your 400 response errors. I got 200 response here. It's application JSON and it's just got a couple of fields in it. I'm going to drill into that in more detail. It's the same endpoint. More detail. Shuffled down a little bit. In my response, you can see I have a maybe you can't see actually because the font is quite small. This schema has a message and an event ID. I've got data types. I've got descriptions. And I've crucially got examples here. The examples are the magic because it lets the user know what kind of data will this be. You can tell me it's a string. But if your example is, I don't know, are you UID? I'm like, oh yeah, I know what that is. If you show me it's my username or you show me it's an ID, okay, I am just instinctively going to put the right thing in when I'm using those tools. If you use the same fields in other places and it's becoming increasingly standard that even if you're not reusing them, you'll often use the open API reference syntax to refer to them being stored somewhere else. So instead of defining each of the objects or elements of the response payload, you just refer to use a reference, dollar ref, to refer to that description and put the description in the components. So your path entry looks like this and then we have that detail down in the components section under schemers. So this gives you a very powerful reuse. The key to API experience is consistency. And so the reuse helps us to just, without thinking, get it right, get it the same, get it consistent and avoid having similar named fields that might take different timestamp formats or look identical but validate differently because our back end application didn't understand that they were the same thing. So that's the structure of open API but I really felt when I created those slides that I was missing the magic. The thing that brings me to this and makes me believe in open API as the powerhouse of our modern application development. And when I think about open API, I think about the things that I do with it and the things that it enables. You think about the way that you design your API, giving meaningful operation IDs for each endpoint and these can be used by the tools that consume your API description. Having great descriptions, naming things in such a way that developers don't need to come and read your documentation because they will know from the operation ID what it's going to do and it's very consistent. They feel at home. You describe your error responses even if I never publish my open API description. The fact that I wrote down the error responses makes my API better because I thought about what I wanted to do if something went wrong. I can validate my API and make sure that my open API is valid, is at the standard that I want and I can have my own linting rules as well. Operation ID is optional. Why? Not in my APIs. So I write my own rules. I say we use kebab case here. We use plurals here. We always define an error response. We make sure that our examples match our media types. These are the things that you can add with the additional linting rules. We can create documentation. That's great. You have an API. You should probably have some docs for it. We can also allow other people to pull the open API description and generate their own docs, keep it locally for reference. I have some accessibility needs. If you have an accessible API web-based documentation, I can just generate with something that works for me with my open API locally. It's ideal. Beyond this sort of entry level, there's some more things that I think we are not doing enough of in open API. You have an API. You describe it with open API. You lint it. You generate some docs. This is great. Please do these things. You are all awesome. The next level is how you deal with very complex API setups. If you work in a large organization with many microservices, how does that pipeline look? How do you keep them all meeting the same standards? How do you bring them together to publish as if you knew what you were doing to the user? Don't mind if you do or not, but you need to look like you do. How do you bundle those things together? If you have one enormous open API description, how do you collaborate on that when you are making changes, whether you are an API experience specialist, product owner, engineer, tech writer? How do we give you a clue that GitHub file is not maintained as a single quarter of a million line YAML file? Looking at how do you manage your files? What do you do with references? How do you split across manageable file chunks? Then how do you bring that together to ship downstream? Finally, what do those downstream tools look like? A lot of organizations, organizations come into open API because they want documentation. This is the beginning. We don't want to write a whole load of words. We just want to describe once with open API and then we can generate some documentation and we can generate it in different ways. Then for free, you start being able to get all these other benefits. You can generate some client SDKs. You can even generate your service stubs if you want. Lots of tools will automatically integrate with your API if you have a good standard open API description. So your API gateways and other integration platforms will just take it. But you can also start to automatically look at how do you describe sequences of API calls? How do you test your API? What does a mock server look like? Because you've described this API in so much detail that a tool can pretend to be it very easily. So there's a lot of pieces here that make up the ecosystem. Open API is kind of the seed from which the rest of the tree grows. For me, this is the magic. It's the interoperability. It's the way that we come back to maybe we generate some open API. It's terrible. So then we use overlays or decorators to add all the descriptions and examples. And maybe not all of these end points are public yet. So we just filter out the public ones to make the final open API and generate some docs. Maybe only some of them are available in the SDK. So we filter differently, make a new open API file, pass that down to the SDK's endpoint. Maybe the next generation of your client SDK has some new functionality. Well, that you start with the same source file or files and bring that together. So it's all about how do you not code, generate docs, but how do you create your open API? Don't have time for my design first rant. So I'm going to try and hold that in. However, your open API comes into the picture. How do you maintain and manage it successfully? How do you ensure the quality on it? How do you transform it and get it ready for all the outputs that you choose? There's just so much in this picture. Let's talk about some tools. Now, I've just linked open API.tools here. I'm not making any specific tools recommendations. That's for two reasons. One, this is a really hot area. There's new tools every week. There are different tools for different text acts. When you are ready for a new tool on that day and no sooner, you should go and look at the list and pick something. The second reason is I work for a tools vendor. I work there because I use their tools. I cannot possibly give you an impartial recommendation. I went to ReadDocley because they know me and I know them. I really don't know the other tools that well as a result. So don't listen to me for specific tools. I work on the ReadDocley stuff and I love it. You need an editor. There's basically two ways to go. You can use a programmer's editor, something like VS Code. Please add some plugins to help yourself. ReadDocley makes an open API plugin. Even if you just have some syntax highlight for YAML, the one that makes the indentations a different color helps me a lot in YAML. Find something that works for you. There are some graphical editors and if that's your thing, then go find one of those. You don't need to pick the same as your team because it's an interrupt format. You use whatever you want to collaborate. Try really hard not to lock your team into tools. Again, accessibility needs. I need to do it in Vim and of course I can. That's part of the magic. Open API governance, which is clearly not a tool, but let's skate over that. When you write, your API standards do not exist until you write them down. They are not standards until they exist somewhere that somebody else can look at them and they are consistently enforced. We have a lot of really good linting that can really help you, but the humans are always going to be in this review process. Find your most wise and thoughtful humans and invite them to be part of the review process. Naming is the thing that the machines genuinely cannot do for us and just the joined up thinking of being able to see things next to each other. As you introduce API standards, start small. Do not be tempted by other people's recommended rule sets, not even ours. Pick what works for you. Look at the recommended rule set, but then pick the things that you aspire to and can adhere to today and commit to reviewing every six months and building up the quality on your API. If you're retrofitting standards to an existing API, there will be things you cannot change now and that's okay, but you can set those rules for the new versions. If you don't know where to start on this, I am going to recommend Zalando. Have some brilliant public API standards and you could do worse than, okay, they have a lot. Start small, just pick your favourites out of theirs. It's a great place to start and your organisation will evolve as it goes along. Please put some linting in. The machines are genuinely good at this. They can help keep you straight. Is your open API valid? Does it have descriptions? Does it have examples? I've got one team that I work with where we have a whole API where the description for the access response is okay with a full stop and it turns out we enforced sentences. So it has to be at least one word and at least one full stop. Yeah, we did some work with them on that. Get some case conventions, some naming conventions and be really picky about what you include. I do this with Redockly CLI, so if you are using that, feel free to send me questions. If you use something else, I can't answer your questions, but good luck. Open API documentation. Read the docs for your docs tools. I see a lot of implementations where those functionalities exist in the tooling that you've used, but you haven't really dug into what it can do or looked at how you can extend or configure it. API reference documentation is evolving very quickly in a good way. There's a lot of new entrants in this market. I'm not sure if I'm supposed to be saying that we have a new product coming out later in the year that does this. It's beautiful, but you have lots and lots of options. Whatever you've picked, make sure you're making the most of it. And if you have something that's, oh, our, I don't want to malign any other tool families, but something which isn't specialist docs and it can render documentation is a great way to start. But because you have the open API format, you can use all of one tool set for one thing, something else for docs, something else for your SDK gen, like lots and lots of options. Open API, when you publish documentation, your documentation is part of the product. You should be deploying it often. It should be easy to deploy and redeploy. And make sure that you're treating it like a web product. Get some metrics, have a look at what's happening, see what people run into. If you have interactive docs, what are people calling the same endpoint all the time? Is it super popular or is it super confusing? Why is everyone here testing this thing? Have a look at those metrics because they can really help you understand your product. I want to talk a little bit about the open API community. This is something that I don't always include in my technical open API talks, but as far as them, it feels appropriate. It's an open standard. It's part of the Linux foundation. You can get, you can learn more about it on openapis.org. The GitHub repository is public. Everything happens there. We have a Slack group. It's very active. Also, public to sign up. And there's a weekly technical meeting. I will confess, it's not super friendly for Europe. I think it's 6 p.m. Central European time, 5 p.m. for me in the UK. Yeah. I'm trying to get to a critical mass of EU-based maintainers, and then we need to start mixing that up. But yeah. If it's unfriendly for Europe, it's sort of dinnertime. There's no hope at all for anyone east of here. So yeah, we need to fix that. But the open API community is currently growing its maintainer set. It's working on some new stuff. Like, this is a good time to get involved. We've also spun up some special interest groups. So just to kind of tease some of the headline activities within the open API project. The Workflows special interest group describes a sequence of API calls. So if you have, this has come from the travel industry. So where you need to find the flights, find the seats, ask the user, book a seat. None of those make sense by themselves. Workflows aims to give an extra level of description for that. Overlays is a special interest group that describes repeatable modifications to an open API. So if you have a generated open API that is just thin, you don't maintain good examples and good descriptions when you're generating from code, and lots of organizations struggle to get away from that Java doc workflow. Overlays can help for now, where you can get your open API and make the same changes every time to make the descriptions better and add examples, hide things, whatever. Open API 4.0. Code name, Moonwalk, why? Don't ask. Don't let engineers name things. Open API, Project Moonwalk, is committed to doing some sort of release this calendar year. So that is just starting. The high level goals are to give you a really simple upgrade from 3.1 upwards, so 3.0 you might want to go to 3.1, and to include a wider range of HTTP APIs. Open API is amazing for RESTful APIs. Okay for some other HTTP-ish, RESTful-ish ones. Moonwalk will include the RPCs and a wider family. So if you've struggled with open API, have another look in about a year. Yeah, open API, an open standard for API descriptions. If you're not using it, I hope you will now or feel like it's a thing that you can approach. If you are, maybe I've given you some ideas to go back and look at what you might change in your current workflow. I'm going to leave you with some resources and say thank you very much for your time. Okay, I'm allowed to take two questions. Would anyone like to take a question? Yes. This is a really good question. How do I feel about generating open API from code or code from open API both ways? Let's start at the beginning. A lot of organizations generate open API from their back-end server-side code. I don't like it. And the reason I don't like it is I think when you go code first, you're missing a design step. When you design first, you're thinking about it in the context of the rest of the API. You're more likely to get the naming right the first time because that implementation is not done by an engineer by themselves. So you ideally design first APIs. You propose the change to your open API with a pull request. You're wise people and you're amazing linting. Go a few iterations to get it perfect. Then we build it. And that's my ideal and that's why I prefer it. The other question, generating code from open API? Yes, go for it. I think we have this machine description and there's a lot of boilerplate. So we can go quite a long way to things like client SDKs from open API. When I talk about the transform step where you have an open API and you make it better, for docs, you're going to add examples and descriptions. For API gateways, SDK code gen, that sort of thing, you're going to add metadata here. You're going to give the type hints that the specific programming languages and text stacks need. And you're going to give extra information. You might not have that at design time, but if you think of it as a pipeline that splits off, you might want to add some extra magic from your standard open API to enhance it before you generate code from it. But generating code is typically fine. It will only be as good as your description is. And lots of those fields are optional. So cool. I am out of time. Thank you so much, everyone. I hope to see you during the event.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 15.120000000000001, "text": " Good morning everybody. Thank you for being so patient. I don't think I've ever had a", "tokens": [50364, 2205, 2446, 2201, 13, 1044, 291, 337, 885, 370, 4537, 13, 286, 500, 380, 519, 286, 600, 1562, 632, 257, 51120], "temperature": 0.0, "avg_logprob": -0.21489987857099893, "compression_ratio": 1.5085714285714287, "no_speech_prob": 0.28118643164634705}, {"id": 1, "seek": 0, "start": 15.120000000000001, "end": 20.44, "text": " full room with 24 minutes to go before the start of my talk before. So that is a very", "tokens": [51120, 1577, 1808, 365, 4022, 2077, 281, 352, 949, 264, 722, 295, 452, 751, 949, 13, 407, 300, 307, 257, 588, 51386], "temperature": 0.0, "avg_logprob": -0.21489987857099893, "compression_ratio": 1.5085714285714287, "no_speech_prob": 0.28118643164634705}, {"id": 2, "seek": 0, "start": 20.44, "end": 27.8, "text": " special experience. Thank you for sharing it with me. I unmuted, but thank you for checking.", "tokens": [51386, 2121, 1752, 13, 1044, 291, 337, 5414, 309, 365, 385, 13, 286, 19334, 4866, 11, 457, 1309, 291, 337, 8568, 13, 51754], "temperature": 0.0, "avg_logprob": -0.21489987857099893, "compression_ratio": 1.5085714285714287, "no_speech_prob": 0.28118643164634705}, {"id": 3, "seek": 2780, "start": 27.8, "end": 34.24, "text": " So I am going to talk to you today about OpenAPI. I'm going to try to give you something", "tokens": [50364, 407, 286, 669, 516, 281, 751, 281, 291, 965, 466, 7238, 4715, 40, 13, 286, 478, 516, 281, 853, 281, 976, 291, 746, 50686], "temperature": 0.0, "avg_logprob": -0.17384183406829834, "compression_ratio": 1.540084388185654, "no_speech_prob": 0.04620615020394325}, {"id": 4, "seek": 2780, "start": 34.24, "end": 39.52, "text": " new that you could maybe take back and try, whether you haven't seen this before or whether", "tokens": [50686, 777, 300, 291, 727, 1310, 747, 646, 293, 853, 11, 1968, 291, 2378, 380, 1612, 341, 949, 420, 1968, 50950], "temperature": 0.0, "avg_logprob": -0.17384183406829834, "compression_ratio": 1.540084388185654, "no_speech_prob": 0.04620615020394325}, {"id": 5, "seek": 2780, "start": 39.52, "end": 46.36, "text": " you're just looking to level up your game a little bit. My name is Lorna. I work for", "tokens": [50950, 291, 434, 445, 1237, 281, 1496, 493, 428, 1216, 257, 707, 857, 13, 1222, 1315, 307, 29358, 629, 13, 286, 589, 337, 51292], "temperature": 0.0, "avg_logprob": -0.17384183406829834, "compression_ratio": 1.540084388185654, "no_speech_prob": 0.04620615020394325}, {"id": 6, "seek": 2780, "start": 46.36, "end": 54.6, "text": " Redockly. I'm VP Developer Experience there. I love APIs. My background is in software engineering.", "tokens": [51292, 4477, 1560, 356, 13, 286, 478, 35812, 44915, 28503, 456, 13, 286, 959, 21445, 13, 1222, 3678, 307, 294, 4722, 7043, 13, 51704], "temperature": 0.0, "avg_logprob": -0.17384183406829834, "compression_ratio": 1.540084388185654, "no_speech_prob": 0.04620615020394325}, {"id": 7, "seek": 5460, "start": 54.6, "end": 61.72, "text": " I've been a developer for most of my career. I've built APIs, integrated with APIs, worked", "tokens": [50364, 286, 600, 668, 257, 10754, 337, 881, 295, 452, 3988, 13, 286, 600, 3094, 21445, 11, 10919, 365, 21445, 11, 2732, 50720], "temperature": 0.0, "avg_logprob": -0.1373719608082491, "compression_ratio": 1.543103448275862, "no_speech_prob": 0.017806945368647575}, {"id": 8, "seek": 5460, "start": 61.72, "end": 68.44, "text": " for API producers, done API consultancy. Now I build the API tooling. It's, yeah, look,", "tokens": [50720, 337, 9362, 16080, 11, 1096, 9362, 7189, 6717, 13, 823, 286, 1322, 264, 9362, 46593, 13, 467, 311, 11, 1338, 11, 574, 11, 51056], "temperature": 0.0, "avg_logprob": -0.1373719608082491, "compression_ratio": 1.543103448275862, "no_speech_prob": 0.017806945368647575}, {"id": 9, "seek": 5460, "start": 68.44, "end": 74.44, "text": " it's a thing that I enjoy and I'm happy that you are all here to share it with me. So let's", "tokens": [51056, 309, 311, 257, 551, 300, 286, 2103, 293, 286, 478, 2055, 300, 291, 366, 439, 510, 281, 2073, 309, 365, 385, 13, 407, 718, 311, 51356], "temperature": 0.0, "avg_logprob": -0.1373719608082491, "compression_ratio": 1.543103448275862, "no_speech_prob": 0.017806945368647575}, {"id": 10, "seek": 5460, "start": 74.44, "end": 81.8, "text": " start by talking about OpenAPI. OpenAPI, I know a lot of people raised their hands, but", "tokens": [51356, 722, 538, 1417, 466, 7238, 4715, 40, 13, 7238, 4715, 40, 11, 286, 458, 257, 688, 295, 561, 6005, 641, 2377, 11, 457, 51724], "temperature": 0.0, "avg_logprob": -0.1373719608082491, "compression_ratio": 1.543103448275862, "no_speech_prob": 0.017806945368647575}, {"id": 11, "seek": 8180, "start": 81.8, "end": 88.2, "text": " maybe it's new to some people. OpenAPI is an open standard. It's a way of describing", "tokens": [50364, 1310, 309, 311, 777, 281, 512, 561, 13, 7238, 4715, 40, 307, 364, 1269, 3832, 13, 467, 311, 257, 636, 295, 16141, 50684], "temperature": 0.0, "avg_logprob": -0.0933629187984743, "compression_ratio": 1.4640883977900552, "no_speech_prob": 0.01521978434175253}, {"id": 12, "seek": 8180, "start": 88.2, "end": 99.72, "text": " your HTTP APIs in a format that aims to be both human and machine readable. What's nice", "tokens": [50684, 428, 33283, 21445, 294, 257, 7877, 300, 24683, 281, 312, 1293, 1952, 293, 3479, 49857, 13, 708, 311, 1481, 51260], "temperature": 0.0, "avg_logprob": -0.0933629187984743, "compression_ratio": 1.4640883977900552, "no_speech_prob": 0.01521978434175253}, {"id": 13, "seek": 8180, "start": 99.72, "end": 106.28, "text": " about that is when we use a standard format, everybody uses the same format. And when that's", "tokens": [51260, 466, 300, 307, 562, 321, 764, 257, 3832, 7877, 11, 2201, 4960, 264, 912, 7877, 13, 400, 562, 300, 311, 51588], "temperature": 0.0, "avg_logprob": -0.0933629187984743, "compression_ratio": 1.4640883977900552, "no_speech_prob": 0.01521978434175253}, {"id": 14, "seek": 10628, "start": 106.36, "end": 112.96000000000001, "text": " an open format, it's developed in the open. You can be part of that development process", "tokens": [50368, 364, 1269, 7877, 11, 309, 311, 4743, 294, 264, 1269, 13, 509, 393, 312, 644, 295, 300, 3250, 1399, 50698], "temperature": 0.0, "avg_logprob": -0.09024536198583143, "compression_ratio": 1.751004016064257, "no_speech_prob": 0.15825015306472778}, {"id": 15, "seek": 10628, "start": 112.96000000000001, "end": 118.68, "text": " and I'll talk a little bit more about the OpenAPI community at the end. You can see", "tokens": [50698, 293, 286, 603, 751, 257, 707, 857, 544, 466, 264, 7238, 4715, 40, 1768, 412, 264, 917, 13, 509, 393, 536, 50984], "temperature": 0.0, "avg_logprob": -0.09024536198583143, "compression_ratio": 1.751004016064257, "no_speech_prob": 0.15825015306472778}, {"id": 16, "seek": 10628, "start": 118.68, "end": 123.2, "text": " what's coming. You can join the meetings. You can follow the issues on GitHub. If you", "tokens": [50984, 437, 311, 1348, 13, 509, 393, 3917, 264, 8410, 13, 509, 393, 1524, 264, 2663, 322, 23331, 13, 759, 291, 51210], "temperature": 0.0, "avg_logprob": -0.09024536198583143, "compression_ratio": 1.751004016064257, "no_speech_prob": 0.15825015306472778}, {"id": 17, "seek": 10628, "start": 123.2, "end": 130.6, "text": " are using OpenAPI as a producer, as a consumer, if you make tooling for OpenAPI, there are", "tokens": [51210, 366, 1228, 7238, 4715, 40, 382, 257, 12314, 11, 382, 257, 9711, 11, 498, 291, 652, 46593, 337, 7238, 4715, 40, 11, 456, 366, 51580], "temperature": 0.0, "avg_logprob": -0.09024536198583143, "compression_ratio": 1.751004016064257, "no_speech_prob": 0.15825015306472778}, {"id": 18, "seek": 10628, "start": 130.6, "end": 136.2, "text": " no surprises. You know what's coming and you can be part of that. So it really improves", "tokens": [51580, 572, 22655, 13, 509, 458, 437, 311, 1348, 293, 291, 393, 312, 644, 295, 300, 13, 407, 309, 534, 24771, 51860], "temperature": 0.0, "avg_logprob": -0.09024536198583143, "compression_ratio": 1.751004016064257, "no_speech_prob": 0.15825015306472778}, {"id": 19, "seek": 13620, "start": 136.2, "end": 143.95999999999998, "text": " our confidence on working with it. I think the most difficult thing about working with", "tokens": [50364, 527, 6687, 322, 1364, 365, 309, 13, 286, 519, 264, 881, 2252, 551, 466, 1364, 365, 50752], "temperature": 0.0, "avg_logprob": -0.08682594437530075, "compression_ratio": 1.4861878453038675, "no_speech_prob": 0.0008237952715717256}, {"id": 20, "seek": 13620, "start": 143.95999999999998, "end": 154.12, "text": " OpenAPI is it's just very verbose. It takes a lot of lines to describe what can be quite", "tokens": [50752, 7238, 4715, 40, 307, 309, 311, 445, 588, 9595, 541, 13, 467, 2516, 257, 688, 295, 3876, 281, 6786, 437, 393, 312, 1596, 51260], "temperature": 0.0, "avg_logprob": -0.08682594437530075, "compression_ratio": 1.4861878453038675, "no_speech_prob": 0.0008237952715717256}, {"id": 21, "seek": 13620, "start": 154.12, "end": 162.79999999999998, "text": " a simple thing. So I'm going to start by talking a bit about the structure of OpenAPI because", "tokens": [51260, 257, 2199, 551, 13, 407, 286, 478, 516, 281, 722, 538, 1417, 257, 857, 466, 264, 3877, 295, 7238, 4715, 40, 570, 51694], "temperature": 0.0, "avg_logprob": -0.08682594437530075, "compression_ratio": 1.4861878453038675, "no_speech_prob": 0.0008237952715717256}, {"id": 22, "seek": 16280, "start": 162.84, "end": 167.16000000000003, "text": " I think when you can find your way around, you understand the map, it's much easier to", "tokens": [50366, 286, 519, 562, 291, 393, 915, 428, 636, 926, 11, 291, 1223, 264, 4471, 11, 309, 311, 709, 3571, 281, 50582], "temperature": 0.0, "avg_logprob": -0.1249799318211053, "compression_ratio": 1.6431924882629108, "no_speech_prob": 0.008268565870821476}, {"id": 23, "seek": 16280, "start": 167.16000000000003, "end": 174.08, "text": " work with it. So this is a representation of the things that you will find at the top", "tokens": [50582, 589, 365, 309, 13, 407, 341, 307, 257, 10290, 295, 264, 721, 300, 291, 486, 915, 412, 264, 1192, 50928], "temperature": 0.0, "avg_logprob": -0.1249799318211053, "compression_ratio": 1.6431924882629108, "no_speech_prob": 0.008268565870821476}, {"id": 24, "seek": 16280, "start": 174.08, "end": 185.08, "text": " level of an OpenAPI description. OpenAPI, which version of OpenAPI is this? Info, a", "tokens": [50928, 1496, 295, 364, 7238, 4715, 40, 3855, 13, 7238, 4715, 40, 11, 597, 3037, 295, 7238, 4715, 40, 307, 341, 30, 11537, 78, 11, 257, 51478], "temperature": 0.0, "avg_logprob": -0.1249799318211053, "compression_ratio": 1.6431924882629108, "no_speech_prob": 0.008268565870821476}, {"id": 25, "seek": 16280, "start": 185.08, "end": 192.56, "text": " bit of metadata about the API that this description describes. So here you'll find the title,", "tokens": [51478, 857, 295, 26603, 466, 264, 9362, 300, 341, 3855, 15626, 13, 407, 510, 291, 603, 915, 264, 4876, 11, 51852], "temperature": 0.0, "avg_logprob": -0.1249799318211053, "compression_ratio": 1.6431924882629108, "no_speech_prob": 0.008268565870821476}, {"id": 26, "seek": 19256, "start": 192.6, "end": 197.92000000000002, "text": " probably some license information, some contact information, the version that we're on. All", "tokens": [50366, 1391, 512, 10476, 1589, 11, 512, 3385, 1589, 11, 264, 3037, 300, 321, 434, 322, 13, 1057, 50632], "temperature": 0.0, "avg_logprob": -0.22007771425468978, "compression_ratio": 1.6775700934579438, "no_speech_prob": 0.004458230920135975}, {"id": 27, "seek": 19256, "start": 197.92000000000002, "end": 205.72, "text": " of that is in the info block. External docs. It's very easy. You publish an IAS developer", "tokens": [50632, 295, 300, 307, 294, 264, 13614, 3461, 13, 48277, 45623, 13, 467, 311, 588, 1858, 13, 509, 11374, 364, 286, 3160, 10754, 51022], "temperature": 0.0, "avg_logprob": -0.22007771425468978, "compression_ratio": 1.6775700934579438, "no_speech_prob": 0.004458230920135975}, {"id": 28, "seek": 19256, "start": 205.72, "end": 210.64000000000001, "text": " website, you link to your API reference docs. If the user arrives on the reference docs,", "tokens": [51022, 3144, 11, 291, 2113, 281, 428, 9362, 6408, 45623, 13, 759, 264, 4195, 20116, 322, 264, 6408, 45623, 11, 51268], "temperature": 0.0, "avg_logprob": -0.22007771425468978, "compression_ratio": 1.6775700934579438, "no_speech_prob": 0.004458230920135975}, {"id": 29, "seek": 19256, "start": 210.64000000000001, "end": 215.76, "text": " maybe from a search engine, is there a link back to that nice developer website that you", "tokens": [51268, 1310, 490, 257, 3164, 2848, 11, 307, 456, 257, 2113, 646, 281, 300, 1481, 10754, 3144, 300, 291, 51524], "temperature": 0.0, "avg_logprob": -0.22007771425468978, "compression_ratio": 1.6775700934579438, "no_speech_prob": 0.004458230920135975}, {"id": 30, "seek": 21576, "start": 215.79999999999998, "end": 222.23999999999998, "text": " made them? Check, because I feel like I've put this right on everything I've ever worked", "tokens": [50366, 1027, 552, 30, 6881, 11, 570, 286, 841, 411, 286, 600, 829, 341, 558, 322, 1203, 286, 600, 1562, 2732, 50688], "temperature": 0.0, "avg_logprob": -0.20096144618758235, "compression_ratio": 1.5826086956521739, "no_speech_prob": 0.2819354832172394}, {"id": 31, "seek": 21576, "start": 222.23999999999998, "end": 229.92, "text": " on. There is a security section and that will describe the authorization and authentication", "tokens": [50688, 322, 13, 821, 307, 257, 3825, 3541, 293, 300, 486, 6786, 264, 33697, 293, 26643, 51072], "temperature": 0.0, "avg_logprob": -0.20096144618758235, "compression_ratio": 1.5826086956521739, "no_speech_prob": 0.2819354832172394}, {"id": 32, "seek": 21576, "start": 229.92, "end": 235.64, "text": " needs for the different that are used by the different endpoints in your API. We've got", "tokens": [51072, 2203, 337, 264, 819, 300, 366, 1143, 538, 264, 819, 917, 20552, 294, 428, 9362, 13, 492, 600, 658, 51358], "temperature": 0.0, "avg_logprob": -0.20096144618758235, "compression_ratio": 1.5826086956521739, "no_speech_prob": 0.2819354832172394}, {"id": 33, "seek": 21576, "start": 235.64, "end": 244.23999999999998, "text": " a service section, where is this API published? Tags allow you to attach metadata to individual", "tokens": [51358, 257, 2643, 3541, 11, 689, 307, 341, 9362, 6572, 30, 11204, 82, 2089, 291, 281, 5085, 26603, 281, 2609, 51788], "temperature": 0.0, "avg_logprob": -0.20096144618758235, "compression_ratio": 1.5826086956521739, "no_speech_prob": 0.2819354832172394}, {"id": 34, "seek": 24424, "start": 244.28, "end": 250.04000000000002, "text": " endpoints. They're listed at the top level and then you can just use them where you need", "tokens": [50366, 917, 20552, 13, 814, 434, 10052, 412, 264, 1192, 1496, 293, 550, 291, 393, 445, 764, 552, 689, 291, 643, 50654], "temperature": 0.0, "avg_logprob": -0.15356419726115902, "compression_ratio": 1.6495327102803738, "no_speech_prob": 0.0014215637929737568}, {"id": 35, "seek": 24424, "start": 250.04000000000002, "end": 259.64, "text": " them. The paths section is where the real API documentation actually happens. This is", "tokens": [50654, 552, 13, 440, 14518, 3541, 307, 689, 264, 957, 9362, 14333, 767, 2314, 13, 639, 307, 51134], "temperature": 0.0, "avg_logprob": -0.15356419726115902, "compression_ratio": 1.6495327102803738, "no_speech_prob": 0.0014215637929737568}, {"id": 36, "seek": 24424, "start": 259.64, "end": 266.56, "text": " what we think of as API docs. We have an entry for each endpoint describing what it does,", "tokens": [51134, 437, 321, 519, 295, 382, 9362, 45623, 13, 492, 362, 364, 8729, 337, 1184, 35795, 16141, 437, 309, 775, 11, 51480], "temperature": 0.0, "avg_logprob": -0.15356419726115902, "compression_ratio": 1.6495327102803738, "no_speech_prob": 0.0014215637929737568}, {"id": 37, "seek": 24424, "start": 266.56, "end": 272.88, "text": " the parameters that it accepts or how to shape the request and the response or responses", "tokens": [51480, 264, 9834, 300, 309, 33538, 420, 577, 281, 3909, 264, 5308, 293, 264, 4134, 420, 13019, 51796], "temperature": 0.0, "avg_logprob": -0.15356419726115902, "compression_ratio": 1.6495327102803738, "no_speech_prob": 0.0014215637929737568}, {"id": 38, "seek": 27288, "start": 272.92, "end": 279.88, "text": " that you can expect back. You'll also find web hooks here, so where you have an API that", "tokens": [50366, 300, 291, 393, 2066, 646, 13, 509, 603, 611, 915, 3670, 26485, 510, 11, 370, 689, 291, 362, 364, 9362, 300, 50714], "temperature": 0.0, "avg_logprob": -0.18873001547420726, "compression_ratio": 1.5884955752212389, "no_speech_prob": 0.0024912822991609573}, {"id": 39, "seek": 27288, "start": 281.96, "end": 288.08, "text": " as well as receiving requests and returning responses, something happens and it sends", "tokens": [50818, 382, 731, 382, 10040, 12475, 293, 12678, 13019, 11, 746, 2314, 293, 309, 14790, 51124], "temperature": 0.0, "avg_logprob": -0.18873001547420726, "compression_ratio": 1.5884955752212389, "no_speech_prob": 0.0024912822991609573}, {"id": 40, "seek": 27288, "start": 288.08, "end": 292.76, "text": " you a response. You can describe those with web hooks. They're a little bit different to", "tokens": [51124, 291, 257, 4134, 13, 509, 393, 6786, 729, 365, 3670, 26485, 13, 814, 434, 257, 707, 857, 819, 281, 51358], "temperature": 0.0, "avg_logprob": -0.18873001547420726, "compression_ratio": 1.5884955752212389, "no_speech_prob": 0.0024912822991609573}, {"id": 41, "seek": 27288, "start": 292.76, "end": 300.88, "text": " the request response feature. Those were added in 3.1, which, although it is the newest version", "tokens": [51358, 264, 5308, 4134, 4111, 13, 3950, 645, 3869, 294, 805, 13, 16, 11, 597, 11, 4878, 309, 307, 264, 17569, 3037, 51764], "temperature": 0.0, "avg_logprob": -0.18873001547420726, "compression_ratio": 1.5884955752212389, "no_speech_prob": 0.0024912822991609573}, {"id": 42, "seek": 30088, "start": 300.88, "end": 308.68, "text": " of OpenAPI, is 3 years old, so wouldn't describe it as cutting edge. We also have here the", "tokens": [50364, 295, 7238, 4715, 40, 11, 307, 805, 924, 1331, 11, 370, 2759, 380, 6786, 309, 382, 6492, 4691, 13, 492, 611, 362, 510, 264, 50754], "temperature": 0.0, "avg_logprob": -0.1673958094223686, "compression_ratio": 1.5682819383259912, "no_speech_prob": 0.004052949603646994}, {"id": 43, "seek": 30088, "start": 308.68, "end": 313.88, "text": " components section. The components section allows us to describe things that we're going", "tokens": [50754, 6677, 3541, 13, 440, 6677, 3541, 4045, 505, 281, 6786, 721, 300, 321, 434, 516, 51014], "temperature": 0.0, "avg_logprob": -0.1673958094223686, "compression_ratio": 1.5682819383259912, "no_speech_prob": 0.004052949603646994}, {"id": 44, "seek": 30088, "start": 313.88, "end": 322.2, "text": " to use multiple times. If you use the same filtering, pagination, date format, if those", "tokens": [51014, 281, 764, 3866, 1413, 13, 759, 291, 764, 264, 912, 30822, 11, 11812, 2486, 11, 4002, 7877, 11, 498, 729, 51430], "temperature": 0.0, "avg_logprob": -0.1673958094223686, "compression_ratio": 1.5682819383259912, "no_speech_prob": 0.004052949603646994}, {"id": 45, "seek": 30088, "start": 322.2, "end": 330.2, "text": " are common patterns across your API, I mean, if they're not, we need to talk. But if you", "tokens": [51430, 366, 2689, 8294, 2108, 428, 9362, 11, 286, 914, 11, 498, 436, 434, 406, 11, 321, 643, 281, 751, 13, 583, 498, 291, 51830], "temperature": 0.0, "avg_logprob": -0.1673958094223686, "compression_ratio": 1.5682819383259912, "no_speech_prob": 0.004052949603646994}, {"id": 46, "seek": 33020, "start": 330.24, "end": 336.28, "text": " reuse those things, you can define them in the components section and reuse them.", "tokens": [50366, 26225, 729, 721, 11, 291, 393, 6964, 552, 294, 264, 6677, 3541, 293, 26225, 552, 13, 50668], "temperature": 0.0, "avg_logprob": -0.20712452624217573, "compression_ratio": 1.672811059907834, "no_speech_prob": 0.002605872228741646}, {"id": 47, "seek": 33020, "start": 336.28, "end": 340.52, "text": " So knowing kind of, they can go in any order, but knowing where you are and where the other", "tokens": [50668, 407, 5276, 733, 295, 11, 436, 393, 352, 294, 604, 1668, 11, 457, 5276, 689, 291, 366, 293, 689, 264, 661, 50880], "temperature": 0.0, "avg_logprob": -0.20712452624217573, "compression_ratio": 1.672811059907834, "no_speech_prob": 0.002605872228741646}, {"id": 48, "seek": 33020, "start": 340.52, "end": 349.52, "text": " things are that you might need can make these very long documents navigable. OpenAPI descriptions", "tokens": [50880, 721, 366, 300, 291, 1062, 643, 393, 652, 613, 588, 938, 8512, 7407, 712, 13, 7238, 4715, 40, 24406, 51330], "temperature": 0.0, "avg_logprob": -0.20712452624217573, "compression_ratio": 1.672811059907834, "no_speech_prob": 0.002605872228741646}, {"id": 49, "seek": 33020, "start": 349.52, "end": 357.59999999999997, "text": " are often thousands or tens of thousands of lines of code. My favorite test API description", "tokens": [51330, 366, 2049, 5383, 420, 10688, 295, 5383, 295, 3876, 295, 3089, 13, 1222, 2954, 1500, 9362, 3855, 51734], "temperature": 0.0, "avg_logprob": -0.20712452624217573, "compression_ratio": 1.672811059907834, "no_speech_prob": 0.002605872228741646}, {"id": 50, "seek": 35760, "start": 357.6, "end": 364.6, "text": " to use is the GitHub one. It's quarter of a million lines of YAML. Like, yeah, you need", "tokens": [50364, 281, 764, 307, 264, 23331, 472, 13, 467, 311, 6555, 295, 257, 2459, 3876, 295, 398, 2865, 43, 13, 1743, 11, 1338, 11, 291, 643, 50714], "temperature": 0.0, "avg_logprob": -0.1956089683201002, "compression_ratio": 1.459090909090909, "no_speech_prob": 0.01022544875741005}, {"id": 51, "seek": 35760, "start": 365.40000000000003, "end": 369.84000000000003, "text": " to know where you're going. Your tools can help you. But it's like carrying something", "tokens": [50754, 281, 458, 689, 291, 434, 516, 13, 2260, 3873, 393, 854, 291, 13, 583, 309, 311, 411, 9792, 746, 50976], "temperature": 0.0, "avg_logprob": -0.1956089683201002, "compression_ratio": 1.459090909090909, "no_speech_prob": 0.01022544875741005}, {"id": 52, "seek": 35760, "start": 369.84000000000003, "end": 374.44, "text": " that's not exactly heavy, but it's just a bit unwieldy.", "tokens": [50976, 300, 311, 406, 2293, 4676, 11, 457, 309, 311, 445, 257, 857, 14853, 1789, 88, 13, 51206], "temperature": 0.0, "avg_logprob": -0.1956089683201002, "compression_ratio": 1.459090909090909, "no_speech_prob": 0.01022544875741005}, {"id": 53, "seek": 35760, "start": 374.44, "end": 381.44, "text": " So let's drill into some of the detail. Here is just basically the top part of your OpenAPI", "tokens": [51206, 407, 718, 311, 11392, 666, 512, 295, 264, 2607, 13, 1692, 307, 445, 1936, 264, 1192, 644, 295, 428, 7238, 4715, 40, 51556], "temperature": 0.0, "avg_logprob": -0.1956089683201002, "compression_ratio": 1.459090909090909, "no_speech_prob": 0.01022544875741005}, {"id": 54, "seek": 38144, "start": 381.44, "end": 388.44, "text": " description. We have a version. It's not very exciting. We have an info section. We've", "tokens": [50364, 3855, 13, 492, 362, 257, 3037, 13, 467, 311, 406, 588, 4670, 13, 492, 362, 364, 13614, 3541, 13, 492, 600, 50714], "temperature": 0.0, "avg_logprob": -0.20525550842285156, "compression_ratio": 1.6402439024390243, "no_speech_prob": 0.08006545156240463}, {"id": 55, "seek": 38144, "start": 390.24, "end": 397.24, "text": " got a title. Give your API a unique and meaningful title. We have summary and description. A", "tokens": [50804, 658, 257, 4876, 13, 5303, 428, 9362, 257, 3845, 293, 10995, 4876, 13, 492, 362, 12691, 293, 3855, 13, 316, 51154], "temperature": 0.0, "avg_logprob": -0.20525550842285156, "compression_ratio": 1.6402439024390243, "no_speech_prob": 0.08006545156240463}, {"id": 56, "seek": 38144, "start": 398.12, "end": 405.12, "text": " lot of OpenAPI elements have these two texty fields, the summary and the description. The", "tokens": [51198, 688, 295, 7238, 4715, 40, 4959, 362, 613, 732, 2487, 88, 7909, 11, 264, 12691, 293, 264, 3855, 13, 440, 51548], "temperature": 0.0, "avg_logprob": -0.20525550842285156, "compression_ratio": 1.6402439024390243, "no_speech_prob": 0.08006545156240463}, {"id": 57, "seek": 40512, "start": 405.28000000000003, "end": 412.28000000000003, "text": " difference, the summary is just text. It's short format. It's usually shown in a listing.", "tokens": [50372, 2649, 11, 264, 12691, 307, 445, 2487, 13, 467, 311, 2099, 7877, 13, 467, 311, 2673, 4898, 294, 257, 22161, 13, 50722], "temperature": 0.0, "avg_logprob": -0.19467126653435524, "compression_ratio": 1.65, "no_speech_prob": 0.004564900882542133}, {"id": 58, "seek": 40512, "start": 413.4, "end": 419.4, "text": " The description supports markdown, specifically common mark. It's usually shown when we're", "tokens": [50778, 440, 3855, 9346, 1491, 5093, 11, 4682, 2689, 1491, 13, 467, 311, 2673, 4898, 562, 321, 434, 51078], "temperature": 0.0, "avg_logprob": -0.19467126653435524, "compression_ratio": 1.65, "no_speech_prob": 0.004564900882542133}, {"id": 59, "seek": 40512, "start": 419.4, "end": 425.4, "text": " looking at the detail. So if your API is shown in a catalog or in a list, it'll use the", "tokens": [51078, 1237, 412, 264, 2607, 13, 407, 498, 428, 9362, 307, 4898, 294, 257, 19746, 420, 294, 257, 1329, 11, 309, 603, 764, 264, 51378], "temperature": 0.0, "avg_logprob": -0.19467126653435524, "compression_ratio": 1.65, "no_speech_prob": 0.004564900882542133}, {"id": 60, "seek": 40512, "start": 425.4, "end": 431.4, "text": " summary. And if you are viewing the API reference documentation, you'll probably see the whole", "tokens": [51378, 12691, 13, 400, 498, 291, 366, 17480, 264, 9362, 6408, 14333, 11, 291, 603, 1391, 536, 264, 1379, 51678], "temperature": 0.0, "avg_logprob": -0.19467126653435524, "compression_ratio": 1.65, "no_speech_prob": 0.004564900882542133}, {"id": 61, "seek": 43140, "start": 431.56, "end": 438.56, "text": " description. And don't be afraid to use the markdown features for links and to really", "tokens": [50372, 3855, 13, 400, 500, 380, 312, 4638, 281, 764, 264, 1491, 5093, 4122, 337, 6123, 293, 281, 534, 50722], "temperature": 0.0, "avg_logprob": -0.19858248610245555, "compression_ratio": 1.5482233502538072, "no_speech_prob": 0.002876788144931197}, {"id": 62, "seek": 43140, "start": 440.08, "end": 445.08, "text": " enrich what you do within your OpenAPI file.", "tokens": [50798, 18849, 437, 291, 360, 1951, 428, 7238, 4715, 40, 3991, 13, 51048], "temperature": 0.0, "avg_logprob": -0.19858248610245555, "compression_ratio": 1.5482233502538072, "no_speech_prob": 0.002876788144931197}, {"id": 63, "seek": 43140, "start": 445.08, "end": 452.08, "text": " There's an info version field. And I think this is one thing that I see people getting", "tokens": [51048, 821, 311, 364, 13614, 3037, 2519, 13, 400, 286, 519, 341, 307, 472, 551, 300, 286, 536, 561, 1242, 51398], "temperature": 0.0, "avg_logprob": -0.19858248610245555, "compression_ratio": 1.5482233502538072, "no_speech_prob": 0.002876788144931197}, {"id": 64, "seek": 43140, "start": 452.91999999999996, "end": 459.91999999999996, "text": " confused with frequently. Info version is the version of the API description. So if you", "tokens": [51440, 9019, 365, 10374, 13, 11537, 78, 3037, 307, 264, 3037, 295, 264, 9362, 3855, 13, 407, 498, 291, 51790], "temperature": 0.0, "avg_logprob": -0.19858248610245555, "compression_ratio": 1.5482233502538072, "no_speech_prob": 0.002876788144931197}, {"id": 65, "seek": 45992, "start": 460.92, "end": 467.92, "text": " change this definition document, you're going to change the description field. Does your", "tokens": [50414, 1319, 341, 7123, 4166, 11, 291, 434, 516, 281, 1319, 264, 3855, 2519, 13, 4402, 428, 50764], "temperature": 0.0, "avg_logprob": -0.16649366795331583, "compression_ratio": 1.7549019607843137, "no_speech_prob": 0.00201671221293509}, {"id": 66, "seek": 45992, "start": 469.48, "end": 476.48, "text": " API info version need to match your API version? I don't really care. But if you change your", "tokens": [50842, 9362, 13614, 3037, 643, 281, 2995, 428, 9362, 3037, 30, 286, 500, 380, 534, 1127, 13, 583, 498, 291, 1319, 428, 51192], "temperature": 0.0, "avg_logprob": -0.16649366795331583, "compression_ratio": 1.7549019607843137, "no_speech_prob": 0.00201671221293509}, {"id": 67, "seek": 45992, "start": 477.44, "end": 482.24, "text": " description a lot, can you please bump the info version so that I know I don't have the", "tokens": [51240, 3855, 257, 688, 11, 393, 291, 1767, 9961, 264, 13614, 3037, 370, 300, 286, 458, 286, 500, 380, 362, 264, 51480], "temperature": 0.0, "avg_logprob": -0.16649366795331583, "compression_ratio": 1.7549019607843137, "no_speech_prob": 0.00201671221293509}, {"id": 68, "seek": 45992, "start": 482.24, "end": 489.24, "text": " latest version of this document? You lock it to your API version if that helps or don't.", "tokens": [51480, 6792, 3037, 295, 341, 4166, 30, 509, 4017, 309, 281, 428, 9362, 3037, 498, 300, 3665, 420, 500, 380, 13, 51830], "temperature": 0.0, "avg_logprob": -0.16649366795331583, "compression_ratio": 1.7549019607843137, "no_speech_prob": 0.00201671221293509}, {"id": 69, "seek": 48924, "start": 489.52, "end": 495.32, "text": " Maybe you haven't made any API changes, but you did add great descriptions, better examples", "tokens": [50378, 2704, 291, 2378, 380, 1027, 604, 9362, 2962, 11, 457, 291, 630, 909, 869, 24406, 11, 1101, 5110, 50668], "temperature": 0.0, "avg_logprob": -0.13014650344848633, "compression_ratio": 1.5347826086956522, "no_speech_prob": 0.0020008431747555733}, {"id": 70, "seek": 48924, "start": 495.32, "end": 501.32, "text": " or something else that changes the OpenAPI description of your API. Bump the version", "tokens": [50668, 420, 746, 1646, 300, 2962, 264, 7238, 4715, 40, 3855, 295, 428, 9362, 13, 363, 1420, 264, 3037, 50968], "temperature": 0.0, "avg_logprob": -0.13014650344848633, "compression_ratio": 1.5347826086956522, "no_speech_prob": 0.0020008431747555733}, {"id": 71, "seek": 48924, "start": 501.32, "end": 508.32, "text": " so I know I need to get the new one. Please add a license. Yeah. So this is like some", "tokens": [50968, 370, 286, 458, 286, 643, 281, 483, 264, 777, 472, 13, 2555, 909, 257, 10476, 13, 865, 13, 407, 341, 307, 411, 512, 51318], "temperature": 0.0, "avg_logprob": -0.13014650344848633, "compression_ratio": 1.5347826086956522, "no_speech_prob": 0.0020008431747555733}, {"id": 72, "seek": 48924, "start": 509.24, "end": 515.0, "text": " nice fluffy rendering. I made this with Blockly. I hope that you like it. And I think it's", "tokens": [51364, 1481, 22778, 22407, 13, 286, 1027, 341, 365, 17500, 356, 13, 286, 1454, 300, 291, 411, 309, 13, 400, 286, 519, 309, 311, 51652], "temperature": 0.0, "avg_logprob": -0.13014650344848633, "compression_ratio": 1.5347826086956522, "no_speech_prob": 0.0020008431747555733}, {"id": 73, "seek": 51500, "start": 515.04, "end": 521.24, "text": " just easier to look at than the real thing. This is the YAML version. And I can do 10", "tokens": [50366, 445, 3571, 281, 574, 412, 813, 264, 957, 551, 13, 639, 307, 264, 398, 2865, 43, 3037, 13, 400, 286, 393, 360, 1266, 50676], "temperature": 0.0, "avg_logprob": -0.15590039237600858, "compression_ratio": 1.6185185185185185, "no_speech_prob": 0.007069564890116453}, {"id": 74, "seek": 51500, "start": 521.24, "end": 525.6, "text": " screens of YAML and I will be having a nice time, but I don't know if you will be having", "tokens": [50676, 11171, 295, 398, 2865, 43, 293, 286, 486, 312, 1419, 257, 1481, 565, 11, 457, 286, 500, 380, 458, 498, 291, 486, 312, 1419, 50894], "temperature": 0.0, "avg_logprob": -0.15590039237600858, "compression_ratio": 1.6185185185185185, "no_speech_prob": 0.007069564890116453}, {"id": 75, "seek": 51500, "start": 525.6, "end": 531.6, "text": " a nice time. So I brought you some pictures. But this is kind of the equivalent of seeing", "tokens": [50894, 257, 1481, 565, 13, 407, 286, 3038, 291, 512, 5242, 13, 583, 341, 307, 733, 295, 264, 10344, 295, 2577, 51194], "temperature": 0.0, "avg_logprob": -0.15590039237600858, "compression_ratio": 1.6185185185185185, "no_speech_prob": 0.007069564890116453}, {"id": 76, "seek": 51500, "start": 531.6, "end": 537.4, "text": " it in YAML. Like now imagine another 20,000 lines and you're starting to visualize how", "tokens": [51194, 309, 294, 398, 2865, 43, 13, 1743, 586, 3811, 1071, 945, 11, 1360, 3876, 293, 291, 434, 2891, 281, 23273, 577, 51484], "temperature": 0.0, "avg_logprob": -0.15590039237600858, "compression_ratio": 1.6185185185185185, "no_speech_prob": 0.007069564890116453}, {"id": 77, "seek": 51500, "start": 537.4, "end": 544.4, "text": " this thing looks. Okay, let's look a little bit at the paths. We have within the YAML", "tokens": [51484, 341, 551, 1542, 13, 1033, 11, 718, 311, 574, 257, 707, 857, 412, 264, 14518, 13, 492, 362, 1951, 264, 398, 2865, 43, 51834], "temperature": 0.0, "avg_logprob": -0.15590039237600858, "compression_ratio": 1.6185185185185185, "no_speech_prob": 0.007069564890116453}, {"id": 78, "seek": 54500, "start": 545.04, "end": 552.04, "text": " path section, we have one block for each combination of URL and verb or method. So like I have", "tokens": [50366, 3100, 3541, 11, 321, 362, 472, 3461, 337, 1184, 6562, 295, 12905, 293, 9595, 420, 3170, 13, 407, 411, 286, 362, 50716], "temperature": 0.0, "avg_logprob": -0.25601720809936523, "compression_ratio": 1.4598930481283423, "no_speech_prob": 0.0011445451527833939}, {"id": 79, "seek": 54500, "start": 555.64, "end": 561.12, "text": " one that is item endpoint, it's got a get operation. Got another one. I'm really good", "tokens": [50896, 472, 300, 307, 3174, 35795, 11, 309, 311, 658, 257, 483, 6916, 13, 5803, 1071, 472, 13, 286, 478, 534, 665, 51170], "temperature": 0.0, "avg_logprob": -0.25601720809936523, "compression_ratio": 1.4598930481283423, "no_speech_prob": 0.0011445451527833939}, {"id": 80, "seek": 54500, "start": 561.12, "end": 568.12, "text": " at naming things. Called things another URL which has both get and post. Those are different", "tokens": [51170, 412, 25290, 721, 13, 45001, 721, 1071, 12905, 597, 575, 1293, 483, 293, 2183, 13, 3950, 366, 819, 51520], "temperature": 0.0, "avg_logprob": -0.25601720809936523, "compression_ratio": 1.4598930481283423, "no_speech_prob": 0.0011445451527833939}, {"id": 81, "seek": 56812, "start": 568.64, "end": 575.64, "text": " operations. They get their own description. If we drill into one, how's an operation ID?", "tokens": [50390, 7705, 13, 814, 483, 641, 1065, 3855, 13, 759, 321, 11392, 666, 472, 11, 577, 311, 364, 6916, 7348, 30, 50740], "temperature": 0.0, "avg_logprob": -0.18439944246982007, "compression_ratio": 1.591743119266055, "no_speech_prob": 0.007388407364487648}, {"id": 82, "seek": 56812, "start": 577.32, "end": 584.32, "text": " Fun fact, operation ID is optional in open API. It's technically optional. Honestly,", "tokens": [50824, 11166, 1186, 11, 6916, 7348, 307, 17312, 294, 1269, 9362, 13, 467, 311, 12120, 17312, 13, 12348, 11, 51174], "temperature": 0.0, "avg_logprob": -0.18439944246982007, "compression_ratio": 1.591743119266055, "no_speech_prob": 0.007388407364487648}, {"id": 83, "seek": 56812, "start": 586.48, "end": 591.84, "text": " you need it. It needs to be unique. Just get your linting to put that in. There's very", "tokens": [51282, 291, 643, 309, 13, 467, 2203, 281, 312, 3845, 13, 1449, 483, 428, 287, 686, 278, 281, 829, 300, 294, 13, 821, 311, 588, 51550], "temperature": 0.0, "avg_logprob": -0.18439944246982007, "compression_ratio": 1.591743119266055, "no_speech_prob": 0.007388407364487648}, {"id": 84, "seek": 56812, "start": 591.84, "end": 597.24, "text": " few APIs where this isn't a useful thing to have and it's not like it's painful to do.", "tokens": [51550, 1326, 21445, 689, 341, 1943, 380, 257, 4420, 551, 281, 362, 293, 309, 311, 406, 411, 309, 311, 11697, 281, 360, 13, 51820], "temperature": 0.0, "avg_logprob": -0.18439944246982007, "compression_ratio": 1.591743119266055, "no_speech_prob": 0.007388407364487648}, {"id": 85, "seek": 59724, "start": 597.8, "end": 604.8, "text": " We've got a description. You probably would have a summary as well. Won't all fit. I have", "tokens": [50392, 492, 600, 658, 257, 3855, 13, 509, 1391, 576, 362, 257, 12691, 382, 731, 13, 14710, 380, 439, 3318, 13, 286, 362, 50742], "temperature": 0.0, "avg_logprob": -0.15271894498304886, "compression_ratio": 1.6079295154185023, "no_speech_prob": 0.0014272823464125395}, {"id": 86, "seek": 59724, "start": 604.88, "end": 610.6, "text": " added some tags to my endpoint. This is related to user and accounts. We might have user and", "tokens": [50746, 3869, 512, 18632, 281, 452, 35795, 13, 639, 307, 4077, 281, 4195, 293, 9402, 13, 492, 1062, 362, 4195, 293, 51032], "temperature": 0.0, "avg_logprob": -0.15271894498304886, "compression_ratio": 1.6079295154185023, "no_speech_prob": 0.0014272823464125395}, {"id": 87, "seek": 59724, "start": 610.6, "end": 617.6, "text": " orders or some other combination of tags here. You can have multiple tags. If there were", "tokens": [51032, 9470, 420, 512, 661, 6562, 295, 18632, 510, 13, 509, 393, 362, 3866, 18632, 13, 759, 456, 645, 51382], "temperature": 0.0, "avg_logprob": -0.15271894498304886, "compression_ratio": 1.6079295154185023, "no_speech_prob": 0.0014272823464125395}, {"id": 88, "seek": 59724, "start": 618.44, "end": 625.44, "text": " request body requirements or parameters, those will be described here as well. And then we've", "tokens": [51424, 5308, 1772, 7728, 420, 9834, 11, 729, 486, 312, 7619, 510, 382, 731, 13, 400, 550, 321, 600, 51774], "temperature": 0.0, "avg_logprob": -0.15271894498304886, "compression_ratio": 1.6079295154185023, "no_speech_prob": 0.0014272823464125395}, {"id": 89, "seek": 62544, "start": 626.44, "end": 633.44, "text": " got the responses. I've only got the 200 response here. It's very bad. You should always describe", "tokens": [50414, 658, 264, 13019, 13, 286, 600, 787, 658, 264, 2331, 4134, 510, 13, 467, 311, 588, 1578, 13, 509, 820, 1009, 6786, 50764], "temperature": 0.0, "avg_logprob": -0.20932640631993613, "compression_ratio": 1.6409090909090909, "no_speech_prob": 0.0023739305324852467}, {"id": 90, "seek": 62544, "start": 633.44, "end": 640.44, "text": " your 400 response errors. I got 200 response here. It's application JSON and it's just", "tokens": [50764, 428, 8423, 4134, 13603, 13, 286, 658, 2331, 4134, 510, 13, 467, 311, 3861, 31828, 293, 309, 311, 445, 51114], "temperature": 0.0, "avg_logprob": -0.20932640631993613, "compression_ratio": 1.6409090909090909, "no_speech_prob": 0.0023739305324852467}, {"id": 91, "seek": 62544, "start": 641.72, "end": 646.9200000000001, "text": " got a couple of fields in it. I'm going to drill into that in more detail. It's the same", "tokens": [51178, 658, 257, 1916, 295, 7909, 294, 309, 13, 286, 478, 516, 281, 11392, 666, 300, 294, 544, 2607, 13, 467, 311, 264, 912, 51438], "temperature": 0.0, "avg_logprob": -0.20932640631993613, "compression_ratio": 1.6409090909090909, "no_speech_prob": 0.0023739305324852467}, {"id": 92, "seek": 62544, "start": 646.9200000000001, "end": 653.9200000000001, "text": " endpoint. More detail. Shuffled down a little bit. In my response, you can see I have a", "tokens": [51438, 35795, 13, 5048, 2607, 13, 1160, 33974, 760, 257, 707, 857, 13, 682, 452, 4134, 11, 291, 393, 536, 286, 362, 257, 51788], "temperature": 0.0, "avg_logprob": -0.20932640631993613, "compression_ratio": 1.6409090909090909, "no_speech_prob": 0.0023739305324852467}, {"id": 93, "seek": 65392, "start": 654.52, "end": 659.8399999999999, "text": " maybe you can't see actually because the font is quite small. This schema has a message", "tokens": [50394, 1310, 291, 393, 380, 536, 767, 570, 264, 10703, 307, 1596, 1359, 13, 639, 34078, 575, 257, 3636, 50660], "temperature": 0.0, "avg_logprob": -0.2002859115600586, "compression_ratio": 1.5852534562211982, "no_speech_prob": 0.0034770281054079533}, {"id": 94, "seek": 65392, "start": 659.8399999999999, "end": 666.8399999999999, "text": " and an event ID. I've got data types. I've got descriptions. And I've crucially got", "tokens": [50660, 293, 364, 2280, 7348, 13, 286, 600, 658, 1412, 3467, 13, 286, 600, 658, 24406, 13, 400, 286, 600, 5140, 1909, 658, 51010], "temperature": 0.0, "avg_logprob": -0.2002859115600586, "compression_ratio": 1.5852534562211982, "no_speech_prob": 0.0034770281054079533}, {"id": 95, "seek": 65392, "start": 667.88, "end": 674.88, "text": " examples here. The examples are the magic because it lets the user know what kind of", "tokens": [51062, 5110, 510, 13, 440, 5110, 366, 264, 5585, 570, 309, 6653, 264, 4195, 458, 437, 733, 295, 51412], "temperature": 0.0, "avg_logprob": -0.2002859115600586, "compression_ratio": 1.5852534562211982, "no_speech_prob": 0.0034770281054079533}, {"id": 96, "seek": 65392, "start": 676.4799999999999, "end": 682.9599999999999, "text": " data will this be. You can tell me it's a string. But if your example is, I don't know,", "tokens": [51492, 1412, 486, 341, 312, 13, 509, 393, 980, 385, 309, 311, 257, 6798, 13, 583, 498, 428, 1365, 307, 11, 286, 500, 380, 458, 11, 51816], "temperature": 0.0, "avg_logprob": -0.2002859115600586, "compression_ratio": 1.5852534562211982, "no_speech_prob": 0.0034770281054079533}, {"id": 97, "seek": 68296, "start": 683.0400000000001, "end": 689.5400000000001, "text": " are you UID? I'm like, oh yeah, I know what that is. If you show me it's my username or", "tokens": [50368, 366, 291, 624, 2777, 30, 286, 478, 411, 11, 1954, 1338, 11, 286, 458, 437, 300, 307, 13, 759, 291, 855, 385, 309, 311, 452, 30351, 420, 50693], "temperature": 0.0, "avg_logprob": -0.19565094434298003, "compression_ratio": 1.5363128491620113, "no_speech_prob": 0.0030819273088127375}, {"id": 98, "seek": 68296, "start": 689.5400000000001, "end": 696.5400000000001, "text": " you show me it's an ID, okay, I am just instinctively going to put the right thing in when I'm using", "tokens": [50693, 291, 855, 385, 309, 311, 364, 7348, 11, 1392, 11, 286, 669, 445, 16556, 3413, 516, 281, 829, 264, 558, 551, 294, 562, 286, 478, 1228, 51043], "temperature": 0.0, "avg_logprob": -0.19565094434298003, "compression_ratio": 1.5363128491620113, "no_speech_prob": 0.0030819273088127375}, {"id": 99, "seek": 68296, "start": 696.5400000000001, "end": 703.5400000000001, "text": " those tools. If you use the same fields in other places and it's becoming increasingly", "tokens": [51043, 729, 3873, 13, 759, 291, 764, 264, 912, 7909, 294, 661, 3190, 293, 309, 311, 5617, 12980, 51393], "temperature": 0.0, "avg_logprob": -0.19565094434298003, "compression_ratio": 1.5363128491620113, "no_speech_prob": 0.0030819273088127375}, {"id": 100, "seek": 70354, "start": 703.86, "end": 710.86, "text": " standard that even if you're not reusing them, you'll often use the open API reference syntax", "tokens": [50380, 3832, 300, 754, 498, 291, 434, 406, 319, 7981, 552, 11, 291, 603, 2049, 764, 264, 1269, 9362, 6408, 28431, 50730], "temperature": 0.0, "avg_logprob": -0.20589093428391678, "compression_ratio": 1.5625, "no_speech_prob": 0.10277396440505981}, {"id": 101, "seek": 70354, "start": 713.9399999999999, "end": 720.9399999999999, "text": " to refer to them being stored somewhere else. So instead of defining each of the objects", "tokens": [50884, 281, 2864, 281, 552, 885, 12187, 4079, 1646, 13, 407, 2602, 295, 17827, 1184, 295, 264, 6565, 51234], "temperature": 0.0, "avg_logprob": -0.20589093428391678, "compression_ratio": 1.5625, "no_speech_prob": 0.10277396440505981}, {"id": 102, "seek": 70354, "start": 722.54, "end": 729.54, "text": " or elements of the response payload, you just refer to use a reference, dollar ref, to refer", "tokens": [51314, 420, 4959, 295, 264, 4134, 30918, 11, 291, 445, 2864, 281, 764, 257, 6408, 11, 7241, 1895, 11, 281, 2864, 51664], "temperature": 0.0, "avg_logprob": -0.20589093428391678, "compression_ratio": 1.5625, "no_speech_prob": 0.10277396440505981}, {"id": 103, "seek": 72954, "start": 729.98, "end": 734.9, "text": " to that description and put the description in the components. So your path entry looks", "tokens": [50386, 281, 300, 3855, 293, 829, 264, 3855, 294, 264, 6677, 13, 407, 428, 3100, 8729, 1542, 50632], "temperature": 0.0, "avg_logprob": -0.13368915376209078, "compression_ratio": 1.7047619047619047, "no_speech_prob": 0.0023618554696440697}, {"id": 104, "seek": 72954, "start": 734.9, "end": 741.18, "text": " like this and then we have that detail down in the components section under schemers.", "tokens": [50632, 411, 341, 293, 550, 321, 362, 300, 2607, 760, 294, 264, 6677, 3541, 833, 22627, 433, 13, 50946], "temperature": 0.0, "avg_logprob": -0.13368915376209078, "compression_ratio": 1.7047619047619047, "no_speech_prob": 0.0023618554696440697}, {"id": 105, "seek": 72954, "start": 741.18, "end": 748.18, "text": " So this gives you a very powerful reuse. The key to API experience is consistency. And", "tokens": [50946, 407, 341, 2709, 291, 257, 588, 4005, 26225, 13, 440, 2141, 281, 9362, 1752, 307, 14416, 13, 400, 51296], "temperature": 0.0, "avg_logprob": -0.13368915376209078, "compression_ratio": 1.7047619047619047, "no_speech_prob": 0.0023618554696440697}, {"id": 106, "seek": 72954, "start": 751.2199999999999, "end": 758.2199999999999, "text": " so the reuse helps us to just, without thinking, get it right, get it the same, get it consistent", "tokens": [51448, 370, 264, 26225, 3665, 505, 281, 445, 11, 1553, 1953, 11, 483, 309, 558, 11, 483, 309, 264, 912, 11, 483, 309, 8398, 51798], "temperature": 0.0, "avg_logprob": -0.13368915376209078, "compression_ratio": 1.7047619047619047, "no_speech_prob": 0.0023618554696440697}, {"id": 107, "seek": 75822, "start": 758.22, "end": 764.1800000000001, "text": " and avoid having similar named fields that might take different timestamp formats or", "tokens": [50364, 293, 5042, 1419, 2531, 4926, 7909, 300, 1062, 747, 819, 49108, 1215, 25879, 420, 50662], "temperature": 0.0, "avg_logprob": -0.1304526646931966, "compression_ratio": 1.56, "no_speech_prob": 0.0006174768786877394}, {"id": 108, "seek": 75822, "start": 764.1800000000001, "end": 769.98, "text": " look identical but validate differently because our back end application didn't understand", "tokens": [50662, 574, 14800, 457, 29562, 7614, 570, 527, 646, 917, 3861, 994, 380, 1223, 50952], "temperature": 0.0, "avg_logprob": -0.1304526646931966, "compression_ratio": 1.56, "no_speech_prob": 0.0006174768786877394}, {"id": 109, "seek": 75822, "start": 769.98, "end": 776.1800000000001, "text": " that they were the same thing. So that's the structure of open API but I really felt when", "tokens": [50952, 300, 436, 645, 264, 912, 551, 13, 407, 300, 311, 264, 3877, 295, 1269, 9362, 457, 286, 534, 2762, 562, 51262], "temperature": 0.0, "avg_logprob": -0.1304526646931966, "compression_ratio": 1.56, "no_speech_prob": 0.0006174768786877394}, {"id": 110, "seek": 75822, "start": 776.1800000000001, "end": 782.38, "text": " I created those slides that I was missing the magic. The thing that brings me to this", "tokens": [51262, 286, 2942, 729, 9788, 300, 286, 390, 5361, 264, 5585, 13, 440, 551, 300, 5607, 385, 281, 341, 51572], "temperature": 0.0, "avg_logprob": -0.1304526646931966, "compression_ratio": 1.56, "no_speech_prob": 0.0006174768786877394}, {"id": 111, "seek": 78238, "start": 782.38, "end": 789.38, "text": " and makes me believe in open API as the powerhouse of our modern application development. And", "tokens": [50364, 293, 1669, 385, 1697, 294, 1269, 9362, 382, 264, 1347, 6410, 295, 527, 4363, 3861, 3250, 13, 400, 50714], "temperature": 0.0, "avg_logprob": -0.1359757035970688, "compression_ratio": 1.6467065868263473, "no_speech_prob": 0.020252171903848648}, {"id": 112, "seek": 78238, "start": 790.42, "end": 797.18, "text": " when I think about open API, I think about the things that I do with it and the things", "tokens": [50766, 562, 286, 519, 466, 1269, 9362, 11, 286, 519, 466, 264, 721, 300, 286, 360, 365, 309, 293, 264, 721, 51104], "temperature": 0.0, "avg_logprob": -0.1359757035970688, "compression_ratio": 1.6467065868263473, "no_speech_prob": 0.020252171903848648}, {"id": 113, "seek": 78238, "start": 797.18, "end": 804.18, "text": " that it enables. You think about the way that you design your API, giving meaningful operation", "tokens": [51104, 300, 309, 17077, 13, 509, 519, 466, 264, 636, 300, 291, 1715, 428, 9362, 11, 2902, 10995, 6916, 51454], "temperature": 0.0, "avg_logprob": -0.1359757035970688, "compression_ratio": 1.6467065868263473, "no_speech_prob": 0.020252171903848648}, {"id": 114, "seek": 80418, "start": 805.18, "end": 812.18, "text": " IDs for each endpoint and these can be used by the tools that consume your API description.", "tokens": [50414, 48212, 337, 1184, 35795, 293, 613, 393, 312, 1143, 538, 264, 3873, 300, 14732, 428, 9362, 3855, 13, 50764], "temperature": 0.0, "avg_logprob": -0.20684746850894975, "compression_ratio": 1.5638766519823788, "no_speech_prob": 0.0425516702234745}, {"id": 115, "seek": 80418, "start": 812.18, "end": 819.18, "text": " Having great descriptions, naming things in such a way that developers don't need to come", "tokens": [50764, 10222, 869, 24406, 11, 25290, 721, 294, 1270, 257, 636, 300, 8849, 500, 380, 643, 281, 808, 51114], "temperature": 0.0, "avg_logprob": -0.20684746850894975, "compression_ratio": 1.5638766519823788, "no_speech_prob": 0.0425516702234745}, {"id": 116, "seek": 80418, "start": 819.18, "end": 823.9, "text": " and read your documentation because they will know from the operation ID what it's going", "tokens": [51114, 293, 1401, 428, 14333, 570, 436, 486, 458, 490, 264, 6916, 7348, 437, 309, 311, 516, 51350], "temperature": 0.0, "avg_logprob": -0.20684746850894975, "compression_ratio": 1.5638766519823788, "no_speech_prob": 0.0425516702234745}, {"id": 117, "seek": 80418, "start": 823.9, "end": 830.9, "text": " to do and it's very consistent. They feel at home. You describe your error responses", "tokens": [51350, 281, 360, 293, 309, 311, 588, 8398, 13, 814, 841, 412, 1280, 13, 509, 6786, 428, 6713, 13019, 51700], "temperature": 0.0, "avg_logprob": -0.20684746850894975, "compression_ratio": 1.5638766519823788, "no_speech_prob": 0.0425516702234745}, {"id": 118, "seek": 83090, "start": 831.62, "end": 837.66, "text": " even if I never publish my open API description. The fact that I wrote down the error responses", "tokens": [50400, 754, 498, 286, 1128, 11374, 452, 1269, 9362, 3855, 13, 440, 1186, 300, 286, 4114, 760, 264, 6713, 13019, 50702], "temperature": 0.0, "avg_logprob": -0.11133624182807075, "compression_ratio": 1.5701754385964912, "no_speech_prob": 0.006475382950156927}, {"id": 119, "seek": 83090, "start": 837.66, "end": 844.1, "text": " makes my API better because I thought about what I wanted to do if something went wrong.", "tokens": [50702, 1669, 452, 9362, 1101, 570, 286, 1194, 466, 437, 286, 1415, 281, 360, 498, 746, 1437, 2085, 13, 51024], "temperature": 0.0, "avg_logprob": -0.11133624182807075, "compression_ratio": 1.5701754385964912, "no_speech_prob": 0.006475382950156927}, {"id": 120, "seek": 83090, "start": 844.1, "end": 850.14, "text": " I can validate my API and make sure that my open API is valid, is at the standard that", "tokens": [51024, 286, 393, 29562, 452, 9362, 293, 652, 988, 300, 452, 1269, 9362, 307, 7363, 11, 307, 412, 264, 3832, 300, 51326], "temperature": 0.0, "avg_logprob": -0.11133624182807075, "compression_ratio": 1.5701754385964912, "no_speech_prob": 0.006475382950156927}, {"id": 121, "seek": 83090, "start": 850.14, "end": 857.14, "text": " I want and I can have my own linting rules as well. Operation ID is optional. Why? Not", "tokens": [51326, 286, 528, 293, 286, 393, 362, 452, 1065, 287, 686, 278, 4474, 382, 731, 13, 27946, 7348, 307, 17312, 13, 1545, 30, 1726, 51676], "temperature": 0.0, "avg_logprob": -0.11133624182807075, "compression_ratio": 1.5701754385964912, "no_speech_prob": 0.006475382950156927}, {"id": 122, "seek": 85714, "start": 857.9, "end": 864.9, "text": " in my APIs. So I write my own rules. I say we use kebab case here. We use plurals here.", "tokens": [50402, 294, 452, 21445, 13, 407, 286, 2464, 452, 1065, 4474, 13, 286, 584, 321, 764, 803, 24301, 1389, 510, 13, 492, 764, 499, 374, 1124, 510, 13, 50752], "temperature": 0.0, "avg_logprob": -0.1604134478467576, "compression_ratio": 1.5829596412556053, "no_speech_prob": 0.0025574644096195698}, {"id": 123, "seek": 85714, "start": 865.54, "end": 872.54, "text": " We always define an error response. We make sure that our examples match our media types.", "tokens": [50784, 492, 1009, 6964, 364, 6713, 4134, 13, 492, 652, 988, 300, 527, 5110, 2995, 527, 3021, 3467, 13, 51134], "temperature": 0.0, "avg_logprob": -0.1604134478467576, "compression_ratio": 1.5829596412556053, "no_speech_prob": 0.0025574644096195698}, {"id": 124, "seek": 85714, "start": 872.54, "end": 879.54, "text": " These are the things that you can add with the additional linting rules. We can create", "tokens": [51134, 1981, 366, 264, 721, 300, 291, 393, 909, 365, 264, 4497, 287, 686, 278, 4474, 13, 492, 393, 1884, 51484], "temperature": 0.0, "avg_logprob": -0.1604134478467576, "compression_ratio": 1.5829596412556053, "no_speech_prob": 0.0025574644096195698}, {"id": 125, "seek": 85714, "start": 880.18, "end": 886.58, "text": " documentation. That's great. You have an API. You should probably have some docs for it.", "tokens": [51516, 14333, 13, 663, 311, 869, 13, 509, 362, 364, 9362, 13, 509, 820, 1391, 362, 512, 45623, 337, 309, 13, 51836], "temperature": 0.0, "avg_logprob": -0.1604134478467576, "compression_ratio": 1.5829596412556053, "no_speech_prob": 0.0025574644096195698}, {"id": 126, "seek": 88658, "start": 886.82, "end": 893.58, "text": " We can also allow other people to pull the open API description and generate their own", "tokens": [50376, 492, 393, 611, 2089, 661, 561, 281, 2235, 264, 1269, 9362, 3855, 293, 8460, 641, 1065, 50714], "temperature": 0.0, "avg_logprob": -0.1809036612510681, "compression_ratio": 1.5662100456621004, "no_speech_prob": 0.0026163021102547646}, {"id": 127, "seek": 88658, "start": 893.58, "end": 899.0600000000001, "text": " docs, keep it locally for reference. I have some accessibility needs. If you have an accessible", "tokens": [50714, 45623, 11, 1066, 309, 16143, 337, 6408, 13, 286, 362, 512, 15002, 2203, 13, 759, 291, 362, 364, 9515, 50988], "temperature": 0.0, "avg_logprob": -0.1809036612510681, "compression_ratio": 1.5662100456621004, "no_speech_prob": 0.0026163021102547646}, {"id": 128, "seek": 88658, "start": 899.0600000000001, "end": 904.34, "text": " API web-based documentation, I can just generate with something that works for me with my", "tokens": [50988, 9362, 3670, 12, 6032, 14333, 11, 286, 393, 445, 8460, 365, 746, 300, 1985, 337, 385, 365, 452, 51252], "temperature": 0.0, "avg_logprob": -0.1809036612510681, "compression_ratio": 1.5662100456621004, "no_speech_prob": 0.0026163021102547646}, {"id": 129, "seek": 88658, "start": 904.34, "end": 911.34, "text": " open API locally. It's ideal. Beyond this sort of entry level, there's", "tokens": [51252, 1269, 9362, 16143, 13, 467, 311, 7157, 13, 19707, 341, 1333, 295, 8729, 1496, 11, 456, 311, 51602], "temperature": 0.0, "avg_logprob": -0.1809036612510681, "compression_ratio": 1.5662100456621004, "no_speech_prob": 0.0026163021102547646}, {"id": 130, "seek": 91134, "start": 911.34, "end": 918.1, "text": " some more things that I think we are not doing enough of in open API. You have an API. You", "tokens": [50364, 512, 544, 721, 300, 286, 519, 321, 366, 406, 884, 1547, 295, 294, 1269, 9362, 13, 509, 362, 364, 9362, 13, 509, 50702], "temperature": 0.0, "avg_logprob": -0.11814619420648931, "compression_ratio": 1.617117117117117, "no_speech_prob": 0.004316320642828941}, {"id": 131, "seek": 91134, "start": 918.1, "end": 922.6600000000001, "text": " describe it with open API. You lint it. You generate some docs. This is great. Please", "tokens": [50702, 6786, 309, 365, 1269, 9362, 13, 509, 287, 686, 309, 13, 509, 8460, 512, 45623, 13, 639, 307, 869, 13, 2555, 50930], "temperature": 0.0, "avg_logprob": -0.11814619420648931, "compression_ratio": 1.617117117117117, "no_speech_prob": 0.004316320642828941}, {"id": 132, "seek": 91134, "start": 922.6600000000001, "end": 929.6600000000001, "text": " do these things. You are all awesome. The next level is how you deal with very complex", "tokens": [50930, 360, 613, 721, 13, 509, 366, 439, 3476, 13, 440, 958, 1496, 307, 577, 291, 2028, 365, 588, 3997, 51280], "temperature": 0.0, "avg_logprob": -0.11814619420648931, "compression_ratio": 1.617117117117117, "no_speech_prob": 0.004316320642828941}, {"id": 133, "seek": 91134, "start": 931.98, "end": 938.98, "text": " API setups. If you work in a large organization with many microservices, how does that pipeline", "tokens": [51396, 9362, 46832, 13, 759, 291, 589, 294, 257, 2416, 4475, 365, 867, 15547, 47480, 11, 577, 775, 300, 15517, 51746], "temperature": 0.0, "avg_logprob": -0.11814619420648931, "compression_ratio": 1.617117117117117, "no_speech_prob": 0.004316320642828941}, {"id": 134, "seek": 93898, "start": 939.54, "end": 945.4200000000001, "text": " look? How do you keep them all meeting the same standards? How do you bring them together", "tokens": [50392, 574, 30, 1012, 360, 291, 1066, 552, 439, 3440, 264, 912, 7787, 30, 1012, 360, 291, 1565, 552, 1214, 50686], "temperature": 0.0, "avg_logprob": -0.1472874587436892, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.014601889997720718}, {"id": 135, "seek": 93898, "start": 945.4200000000001, "end": 950.7, "text": " to publish as if you knew what you were doing to the user? Don't mind if you do or not,", "tokens": [50686, 281, 11374, 382, 498, 291, 2586, 437, 291, 645, 884, 281, 264, 4195, 30, 1468, 380, 1575, 498, 291, 360, 420, 406, 11, 50950], "temperature": 0.0, "avg_logprob": -0.1472874587436892, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.014601889997720718}, {"id": 136, "seek": 93898, "start": 950.7, "end": 956.26, "text": " but you need to look like you do. How do you bundle those things together? If you have", "tokens": [50950, 457, 291, 643, 281, 574, 411, 291, 360, 13, 1012, 360, 291, 24438, 729, 721, 1214, 30, 759, 291, 362, 51228], "temperature": 0.0, "avg_logprob": -0.1472874587436892, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.014601889997720718}, {"id": 137, "seek": 93898, "start": 956.26, "end": 962.46, "text": " one enormous open API description, how do you collaborate on that when you are making", "tokens": [51228, 472, 11322, 1269, 9362, 3855, 11, 577, 360, 291, 18338, 322, 300, 562, 291, 366, 1455, 51538], "temperature": 0.0, "avg_logprob": -0.1472874587436892, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.014601889997720718}, {"id": 138, "seek": 93898, "start": 962.46, "end": 967.46, "text": " changes, whether you are an API experience specialist, product owner, engineer, tech", "tokens": [51538, 2962, 11, 1968, 291, 366, 364, 9362, 1752, 17008, 11, 1674, 7289, 11, 11403, 11, 7553, 51788], "temperature": 0.0, "avg_logprob": -0.1472874587436892, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.014601889997720718}, {"id": 139, "seek": 96746, "start": 967.5, "end": 973.4200000000001, "text": " writer? How do we give you a clue that GitHub file is not maintained as a single quarter", "tokens": [50366, 9936, 30, 1012, 360, 321, 976, 291, 257, 13602, 300, 23331, 3991, 307, 406, 17578, 382, 257, 2167, 6555, 50662], "temperature": 0.0, "avg_logprob": -0.1891337741505016, "compression_ratio": 1.5905172413793103, "no_speech_prob": 0.011072754859924316}, {"id": 140, "seek": 96746, "start": 973.4200000000001, "end": 980.4200000000001, "text": " of a million line YAML file? Looking at how do you manage your files? What do you do with", "tokens": [50662, 295, 257, 2459, 1622, 398, 2865, 43, 3991, 30, 11053, 412, 577, 360, 291, 3067, 428, 7098, 30, 708, 360, 291, 360, 365, 51012], "temperature": 0.0, "avg_logprob": -0.1891337741505016, "compression_ratio": 1.5905172413793103, "no_speech_prob": 0.011072754859924316}, {"id": 141, "seek": 96746, "start": 980.4200000000001, "end": 987.4200000000001, "text": " references? How do you split across manageable file chunks? Then how do you bring that together", "tokens": [51012, 15400, 30, 1012, 360, 291, 7472, 2108, 38798, 3991, 24004, 30, 1396, 577, 360, 291, 1565, 300, 1214, 51362], "temperature": 0.0, "avg_logprob": -0.1891337741505016, "compression_ratio": 1.5905172413793103, "no_speech_prob": 0.011072754859924316}, {"id": 142, "seek": 96746, "start": 987.4200000000001, "end": 994.4200000000001, "text": " to ship downstream? Finally, what do those downstream tools look like? A lot of organizations,", "tokens": [51362, 281, 5374, 30621, 30, 6288, 11, 437, 360, 729, 30621, 3873, 574, 411, 30, 316, 688, 295, 6150, 11, 51712], "temperature": 0.0, "avg_logprob": -0.1891337741505016, "compression_ratio": 1.5905172413793103, "no_speech_prob": 0.011072754859924316}, {"id": 143, "seek": 99746, "start": 998.02, "end": 1003.94, "text": " organizations come into open API because they want documentation. This is the beginning.", "tokens": [50392, 6150, 808, 666, 1269, 9362, 570, 436, 528, 14333, 13, 639, 307, 264, 2863, 13, 50688], "temperature": 0.0, "avg_logprob": -0.13894954919815064, "compression_ratio": 1.6587677725118484, "no_speech_prob": 0.026439979672431946}, {"id": 144, "seek": 99746, "start": 1003.94, "end": 1010.94, "text": " We don't want to write a whole load of words. We just want to describe once with open API", "tokens": [50688, 492, 500, 380, 528, 281, 2464, 257, 1379, 3677, 295, 2283, 13, 492, 445, 528, 281, 6786, 1564, 365, 1269, 9362, 51038], "temperature": 0.0, "avg_logprob": -0.13894954919815064, "compression_ratio": 1.6587677725118484, "no_speech_prob": 0.026439979672431946}, {"id": 145, "seek": 99746, "start": 1013.22, "end": 1017.62, "text": " and then we can generate some documentation and we can generate it in different ways.", "tokens": [51152, 293, 550, 321, 393, 8460, 512, 14333, 293, 321, 393, 8460, 309, 294, 819, 2098, 13, 51372], "temperature": 0.0, "avg_logprob": -0.13894954919815064, "compression_ratio": 1.6587677725118484, "no_speech_prob": 0.026439979672431946}, {"id": 146, "seek": 99746, "start": 1017.62, "end": 1023.98, "text": " Then for free, you start being able to get all these other benefits. You can generate", "tokens": [51372, 1396, 337, 1737, 11, 291, 722, 885, 1075, 281, 483, 439, 613, 661, 5311, 13, 509, 393, 8460, 51690], "temperature": 0.0, "avg_logprob": -0.13894954919815064, "compression_ratio": 1.6587677725118484, "no_speech_prob": 0.026439979672431946}, {"id": 147, "seek": 102398, "start": 1024.02, "end": 1030.7, "text": " some client SDKs. You can even generate your service stubs if you want. Lots of tools will", "tokens": [50366, 512, 6423, 37135, 82, 13, 509, 393, 754, 8460, 428, 2643, 342, 5432, 498, 291, 528, 13, 15908, 295, 3873, 486, 50700], "temperature": 0.0, "avg_logprob": -0.1647883521185981, "compression_ratio": 1.6118721461187215, "no_speech_prob": 0.01293126679956913}, {"id": 148, "seek": 102398, "start": 1030.7, "end": 1037.46, "text": " automatically integrate with your API if you have a good standard open API description.", "tokens": [50700, 6772, 13365, 365, 428, 9362, 498, 291, 362, 257, 665, 3832, 1269, 9362, 3855, 13, 51038], "temperature": 0.0, "avg_logprob": -0.1647883521185981, "compression_ratio": 1.6118721461187215, "no_speech_prob": 0.01293126679956913}, {"id": 149, "seek": 102398, "start": 1037.46, "end": 1044.46, "text": " So your API gateways and other integration platforms will just take it. But you can also", "tokens": [51038, 407, 428, 9362, 8539, 942, 293, 661, 10980, 9473, 486, 445, 747, 309, 13, 583, 291, 393, 611, 51388], "temperature": 0.0, "avg_logprob": -0.1647883521185981, "compression_ratio": 1.6118721461187215, "no_speech_prob": 0.01293126679956913}, {"id": 150, "seek": 102398, "start": 1044.66, "end": 1051.66, "text": " start to automatically look at how do you describe sequences of API calls? How do you", "tokens": [51398, 722, 281, 6772, 574, 412, 577, 360, 291, 6786, 22978, 295, 9362, 5498, 30, 1012, 360, 291, 51748], "temperature": 0.0, "avg_logprob": -0.1647883521185981, "compression_ratio": 1.6118721461187215, "no_speech_prob": 0.01293126679956913}, {"id": 151, "seek": 105166, "start": 1051.66, "end": 1057.22, "text": " test your API? What does a mock server look like? Because you've described this API in", "tokens": [50364, 1500, 428, 9362, 30, 708, 775, 257, 17362, 7154, 574, 411, 30, 1436, 291, 600, 7619, 341, 9362, 294, 50642], "temperature": 0.0, "avg_logprob": -0.12637478818175613, "compression_ratio": 1.5353982300884956, "no_speech_prob": 0.0140147740021348}, {"id": 152, "seek": 105166, "start": 1057.22, "end": 1064.22, "text": " so much detail that a tool can pretend to be it very easily. So there's a lot of pieces", "tokens": [50642, 370, 709, 2607, 300, 257, 2290, 393, 11865, 281, 312, 309, 588, 3612, 13, 407, 456, 311, 257, 688, 295, 3755, 50992], "temperature": 0.0, "avg_logprob": -0.12637478818175613, "compression_ratio": 1.5353982300884956, "no_speech_prob": 0.0140147740021348}, {"id": 153, "seek": 105166, "start": 1064.8600000000001, "end": 1071.8600000000001, "text": " here that make up the ecosystem. Open API is kind of the seed from which the rest of", "tokens": [51024, 510, 300, 652, 493, 264, 11311, 13, 7238, 9362, 307, 733, 295, 264, 8871, 490, 597, 264, 1472, 295, 51374], "temperature": 0.0, "avg_logprob": -0.12637478818175613, "compression_ratio": 1.5353982300884956, "no_speech_prob": 0.0140147740021348}, {"id": 154, "seek": 105166, "start": 1073.6200000000001, "end": 1080.5, "text": " the tree grows. For me, this is the magic. It's the interoperability. It's the way that", "tokens": [51462, 264, 4230, 13156, 13, 1171, 385, 11, 341, 307, 264, 5585, 13, 467, 311, 264, 728, 7192, 2310, 13, 467, 311, 264, 636, 300, 51806], "temperature": 0.0, "avg_logprob": -0.12637478818175613, "compression_ratio": 1.5353982300884956, "no_speech_prob": 0.0140147740021348}, {"id": 155, "seek": 108050, "start": 1080.5, "end": 1086.66, "text": " we come back to maybe we generate some open API. It's terrible. So then we use overlays", "tokens": [50364, 321, 808, 646, 281, 1310, 321, 8460, 512, 1269, 9362, 13, 467, 311, 6237, 13, 407, 550, 321, 764, 15986, 3772, 50672], "temperature": 0.0, "avg_logprob": -0.12634889795145857, "compression_ratio": 1.7098039215686274, "no_speech_prob": 0.005582657177001238}, {"id": 156, "seek": 108050, "start": 1086.66, "end": 1092.7, "text": " or decorators to add all the descriptions and examples. And maybe not all of these end", "tokens": [50672, 420, 7919, 3391, 281, 909, 439, 264, 24406, 293, 5110, 13, 400, 1310, 406, 439, 295, 613, 917, 50974], "temperature": 0.0, "avg_logprob": -0.12634889795145857, "compression_ratio": 1.7098039215686274, "no_speech_prob": 0.005582657177001238}, {"id": 157, "seek": 108050, "start": 1092.7, "end": 1098.22, "text": " points are public yet. So we just filter out the public ones to make the final open API", "tokens": [50974, 2793, 366, 1908, 1939, 13, 407, 321, 445, 6608, 484, 264, 1908, 2306, 281, 652, 264, 2572, 1269, 9362, 51250], "temperature": 0.0, "avg_logprob": -0.12634889795145857, "compression_ratio": 1.7098039215686274, "no_speech_prob": 0.005582657177001238}, {"id": 158, "seek": 108050, "start": 1098.22, "end": 1103.42, "text": " and generate some docs. Maybe only some of them are available in the SDK. So we filter", "tokens": [51250, 293, 8460, 512, 45623, 13, 2704, 787, 512, 295, 552, 366, 2435, 294, 264, 37135, 13, 407, 321, 6608, 51510], "temperature": 0.0, "avg_logprob": -0.12634889795145857, "compression_ratio": 1.7098039215686274, "no_speech_prob": 0.005582657177001238}, {"id": 159, "seek": 108050, "start": 1103.42, "end": 1109.26, "text": " differently, make a new open API file, pass that down to the SDK's endpoint. Maybe the", "tokens": [51510, 7614, 11, 652, 257, 777, 1269, 9362, 3991, 11, 1320, 300, 760, 281, 264, 37135, 311, 35795, 13, 2704, 264, 51802], "temperature": 0.0, "avg_logprob": -0.12634889795145857, "compression_ratio": 1.7098039215686274, "no_speech_prob": 0.005582657177001238}, {"id": 160, "seek": 110926, "start": 1109.26, "end": 1115.18, "text": " next generation of your client SDK has some new functionality. Well, that you start with", "tokens": [50364, 958, 5125, 295, 428, 6423, 37135, 575, 512, 777, 14980, 13, 1042, 11, 300, 291, 722, 365, 50660], "temperature": 0.0, "avg_logprob": -0.11685134587662943, "compression_ratio": 1.5675675675675675, "no_speech_prob": 0.0009808876784518361}, {"id": 161, "seek": 110926, "start": 1115.18, "end": 1122.18, "text": " the same source file or files and bring that together. So it's all about how do you not", "tokens": [50660, 264, 912, 4009, 3991, 420, 7098, 293, 1565, 300, 1214, 13, 407, 309, 311, 439, 466, 577, 360, 291, 406, 51010], "temperature": 0.0, "avg_logprob": -0.11685134587662943, "compression_ratio": 1.5675675675675675, "no_speech_prob": 0.0009808876784518361}, {"id": 162, "seek": 110926, "start": 1123.06, "end": 1129.66, "text": " code, generate docs, but how do you create your open API? Don't have time for my design", "tokens": [51054, 3089, 11, 8460, 45623, 11, 457, 577, 360, 291, 1884, 428, 1269, 9362, 30, 1468, 380, 362, 565, 337, 452, 1715, 51384], "temperature": 0.0, "avg_logprob": -0.11685134587662943, "compression_ratio": 1.5675675675675675, "no_speech_prob": 0.0009808876784518361}, {"id": 163, "seek": 110926, "start": 1129.66, "end": 1134.58, "text": " first rant. So I'm going to try and hold that in. However, your open API comes into", "tokens": [51384, 700, 45332, 13, 407, 286, 478, 516, 281, 853, 293, 1797, 300, 294, 13, 2908, 11, 428, 1269, 9362, 1487, 666, 51630], "temperature": 0.0, "avg_logprob": -0.11685134587662943, "compression_ratio": 1.5675675675675675, "no_speech_prob": 0.0009808876784518361}, {"id": 164, "seek": 113458, "start": 1134.62, "end": 1141.3, "text": " the picture. How do you maintain and manage it successfully? How do you ensure the quality", "tokens": [50366, 264, 3036, 13, 1012, 360, 291, 6909, 293, 3067, 309, 10727, 30, 1012, 360, 291, 5586, 264, 3125, 50700], "temperature": 0.0, "avg_logprob": -0.1249394416809082, "compression_ratio": 1.5, "no_speech_prob": 0.027510814368724823}, {"id": 165, "seek": 113458, "start": 1141.3, "end": 1148.3, "text": " on it? How do you transform it and get it ready for all the outputs that you choose?", "tokens": [50700, 322, 309, 30, 1012, 360, 291, 4088, 309, 293, 483, 309, 1919, 337, 439, 264, 23930, 300, 291, 2826, 30, 51050], "temperature": 0.0, "avg_logprob": -0.1249394416809082, "compression_ratio": 1.5, "no_speech_prob": 0.027510814368724823}, {"id": 166, "seek": 113458, "start": 1149.1, "end": 1156.1, "text": " There's just so much in this picture. Let's talk about some tools. Now, I've just linked", "tokens": [51090, 821, 311, 445, 370, 709, 294, 341, 3036, 13, 961, 311, 751, 466, 512, 3873, 13, 823, 11, 286, 600, 445, 9408, 51440], "temperature": 0.0, "avg_logprob": -0.1249394416809082, "compression_ratio": 1.5, "no_speech_prob": 0.027510814368724823}, {"id": 167, "seek": 115610, "start": 1156.3, "end": 1163.3, "text": " open API.tools here. I'm not making any specific tools recommendations. That's for two reasons.", "tokens": [50374, 1269, 9362, 13, 83, 29298, 510, 13, 286, 478, 406, 1455, 604, 2685, 3873, 10434, 13, 663, 311, 337, 732, 4112, 13, 50724], "temperature": 0.0, "avg_logprob": -0.20881166562929257, "compression_ratio": 1.6181818181818182, "no_speech_prob": 0.01668725162744522}, {"id": 168, "seek": 115610, "start": 1164.6599999999999, "end": 1171.06, "text": " One, this is a really hot area. There's new tools every week. There are different tools", "tokens": [50792, 1485, 11, 341, 307, 257, 534, 2368, 1859, 13, 821, 311, 777, 3873, 633, 1243, 13, 821, 366, 819, 3873, 51112], "temperature": 0.0, "avg_logprob": -0.20881166562929257, "compression_ratio": 1.6181818181818182, "no_speech_prob": 0.01668725162744522}, {"id": 169, "seek": 115610, "start": 1171.06, "end": 1176.06, "text": " for different text acts. When you are ready for a new tool on that day and no sooner,", "tokens": [51112, 337, 819, 2487, 10672, 13, 1133, 291, 366, 1919, 337, 257, 777, 2290, 322, 300, 786, 293, 572, 15324, 11, 51362], "temperature": 0.0, "avg_logprob": -0.20881166562929257, "compression_ratio": 1.6181818181818182, "no_speech_prob": 0.01668725162744522}, {"id": 170, "seek": 115610, "start": 1176.06, "end": 1181.4599999999998, "text": " you should go and look at the list and pick something. The second reason is I work for", "tokens": [51362, 291, 820, 352, 293, 574, 412, 264, 1329, 293, 1888, 746, 13, 440, 1150, 1778, 307, 286, 589, 337, 51632], "temperature": 0.0, "avg_logprob": -0.20881166562929257, "compression_ratio": 1.6181818181818182, "no_speech_prob": 0.01668725162744522}, {"id": 171, "seek": 118146, "start": 1181.5, "end": 1188.5, "text": " a tools vendor. I work there because I use their tools. I cannot possibly give you an", "tokens": [50366, 257, 3873, 24321, 13, 286, 589, 456, 570, 286, 764, 641, 3873, 13, 286, 2644, 6264, 976, 291, 364, 50716], "temperature": 0.0, "avg_logprob": -0.20104344016627262, "compression_ratio": 1.658878504672897, "no_speech_prob": 0.03169380873441696}, {"id": 172, "seek": 118146, "start": 1189.14, "end": 1195.64, "text": " impartial recommendation. I went to ReadDocley because they know me and I know them. I really", "tokens": [50748, 32177, 831, 11879, 13, 286, 1437, 281, 17604, 35, 905, 3420, 570, 436, 458, 385, 293, 286, 458, 552, 13, 286, 534, 51073], "temperature": 0.0, "avg_logprob": -0.20104344016627262, "compression_ratio": 1.658878504672897, "no_speech_prob": 0.03169380873441696}, {"id": 173, "seek": 118146, "start": 1195.64, "end": 1200.38, "text": " don't know the other tools that well as a result. So don't listen to me for specific", "tokens": [51073, 500, 380, 458, 264, 661, 3873, 300, 731, 382, 257, 1874, 13, 407, 500, 380, 2140, 281, 385, 337, 2685, 51310], "temperature": 0.0, "avg_logprob": -0.20104344016627262, "compression_ratio": 1.658878504672897, "no_speech_prob": 0.03169380873441696}, {"id": 174, "seek": 118146, "start": 1200.38, "end": 1207.38, "text": " tools. I work on the ReadDocley stuff and I love it. You need an editor. There's basically", "tokens": [51310, 3873, 13, 286, 589, 322, 264, 17604, 35, 905, 3420, 1507, 293, 286, 959, 309, 13, 509, 643, 364, 9839, 13, 821, 311, 1936, 51660], "temperature": 0.0, "avg_logprob": -0.20104344016627262, "compression_ratio": 1.658878504672897, "no_speech_prob": 0.03169380873441696}, {"id": 175, "seek": 120738, "start": 1208.38, "end": 1215.38, "text": " two ways to go. You can use a programmer's editor, something like VS Code. Please add", "tokens": [50414, 732, 2098, 281, 352, 13, 509, 393, 764, 257, 32116, 311, 9839, 11, 746, 411, 25091, 15549, 13, 2555, 909, 50764], "temperature": 0.0, "avg_logprob": -0.18347716861300997, "compression_ratio": 1.5021276595744681, "no_speech_prob": 0.004463108256459236}, {"id": 176, "seek": 120738, "start": 1215.46, "end": 1220.46, "text": " some plugins to help yourself. ReadDocley makes an open API plugin. Even if you just", "tokens": [50768, 512, 33759, 281, 854, 1803, 13, 17604, 35, 905, 3420, 1669, 364, 1269, 9362, 23407, 13, 2754, 498, 291, 445, 51018], "temperature": 0.0, "avg_logprob": -0.18347716861300997, "compression_ratio": 1.5021276595744681, "no_speech_prob": 0.004463108256459236}, {"id": 177, "seek": 120738, "start": 1220.46, "end": 1226.66, "text": " have some syntax highlight for YAML, the one that makes the indentations a different color", "tokens": [51018, 362, 512, 28431, 5078, 337, 398, 2865, 43, 11, 264, 472, 300, 1669, 264, 44494, 763, 257, 819, 2017, 51328], "temperature": 0.0, "avg_logprob": -0.18347716861300997, "compression_ratio": 1.5021276595744681, "no_speech_prob": 0.004463108256459236}, {"id": 178, "seek": 120738, "start": 1226.66, "end": 1233.66, "text": " helps me a lot in YAML. Find something that works for you. There are some graphical editors", "tokens": [51328, 3665, 385, 257, 688, 294, 398, 2865, 43, 13, 11809, 746, 300, 1985, 337, 291, 13, 821, 366, 512, 35942, 31446, 51678], "temperature": 0.0, "avg_logprob": -0.18347716861300997, "compression_ratio": 1.5021276595744681, "no_speech_prob": 0.004463108256459236}, {"id": 179, "seek": 123366, "start": 1234.46, "end": 1239.3400000000001, "text": " and if that's your thing, then go find one of those. You don't need to pick the same", "tokens": [50404, 293, 498, 300, 311, 428, 551, 11, 550, 352, 915, 472, 295, 729, 13, 509, 500, 380, 643, 281, 1888, 264, 912, 50648], "temperature": 0.0, "avg_logprob": -0.15091654594908369, "compression_ratio": 1.5474137931034482, "no_speech_prob": 0.02668583393096924}, {"id": 180, "seek": 123366, "start": 1239.3400000000001, "end": 1245.26, "text": " as your team because it's an interrupt format. You use whatever you want to collaborate. Try", "tokens": [50648, 382, 428, 1469, 570, 309, 311, 364, 12729, 7877, 13, 509, 764, 2035, 291, 528, 281, 18338, 13, 6526, 50944], "temperature": 0.0, "avg_logprob": -0.15091654594908369, "compression_ratio": 1.5474137931034482, "no_speech_prob": 0.02668583393096924}, {"id": 181, "seek": 123366, "start": 1245.26, "end": 1251.3400000000001, "text": " really hard not to lock your team into tools. Again, accessibility needs. I need to do it", "tokens": [50944, 534, 1152, 406, 281, 4017, 428, 1469, 666, 3873, 13, 3764, 11, 15002, 2203, 13, 286, 643, 281, 360, 309, 51248], "temperature": 0.0, "avg_logprob": -0.15091654594908369, "compression_ratio": 1.5474137931034482, "no_speech_prob": 0.02668583393096924}, {"id": 182, "seek": 123366, "start": 1251.3400000000001, "end": 1258.3400000000001, "text": " in Vim and of course I can. That's part of the magic. Open API governance, which is clearly", "tokens": [51248, 294, 691, 332, 293, 295, 1164, 286, 393, 13, 663, 311, 644, 295, 264, 5585, 13, 7238, 9362, 17449, 11, 597, 307, 4448, 51598], "temperature": 0.0, "avg_logprob": -0.15091654594908369, "compression_ratio": 1.5474137931034482, "no_speech_prob": 0.02668583393096924}, {"id": 183, "seek": 125834, "start": 1259.34, "end": 1266.34, "text": " not a tool, but let's skate over that. When you write, your API standards do not exist", "tokens": [50414, 406, 257, 2290, 11, 457, 718, 311, 18237, 670, 300, 13, 1133, 291, 2464, 11, 428, 9362, 7787, 360, 406, 2514, 50764], "temperature": 0.0, "avg_logprob": -0.12156904154810412, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.018322382122278214}, {"id": 184, "seek": 125834, "start": 1266.9399999999998, "end": 1273.54, "text": " until you write them down. They are not standards until they exist somewhere that somebody else", "tokens": [50794, 1826, 291, 2464, 552, 760, 13, 814, 366, 406, 7787, 1826, 436, 2514, 4079, 300, 2618, 1646, 51124], "temperature": 0.0, "avg_logprob": -0.12156904154810412, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.018322382122278214}, {"id": 185, "seek": 125834, "start": 1273.54, "end": 1280.54, "text": " can look at them and they are consistently enforced. We have a lot of really good linting", "tokens": [51124, 393, 574, 412, 552, 293, 436, 366, 14961, 40953, 13, 492, 362, 257, 688, 295, 534, 665, 287, 686, 278, 51474], "temperature": 0.0, "avg_logprob": -0.12156904154810412, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.018322382122278214}, {"id": 186, "seek": 125834, "start": 1280.8999999999999, "end": 1287.1399999999999, "text": " that can really help you, but the humans are always going to be in this review process.", "tokens": [51492, 300, 393, 534, 854, 291, 11, 457, 264, 6255, 366, 1009, 516, 281, 312, 294, 341, 3131, 1399, 13, 51804], "temperature": 0.0, "avg_logprob": -0.12156904154810412, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.018322382122278214}, {"id": 187, "seek": 128714, "start": 1287.14, "end": 1294.14, "text": " Find your most wise and thoughtful humans and invite them to be part of the review process.", "tokens": [50364, 11809, 428, 881, 10829, 293, 21566, 6255, 293, 7980, 552, 281, 312, 644, 295, 264, 3131, 1399, 13, 50714], "temperature": 0.0, "avg_logprob": -0.16112230741060696, "compression_ratio": 1.4946808510638299, "no_speech_prob": 0.011072269640862942}, {"id": 188, "seek": 128714, "start": 1296.46, "end": 1302.9, "text": " Naming is the thing that the machines genuinely cannot do for us and just the joined up thinking", "tokens": [50830, 426, 5184, 307, 264, 551, 300, 264, 8379, 17839, 2644, 360, 337, 505, 293, 445, 264, 6869, 493, 1953, 51152], "temperature": 0.0, "avg_logprob": -0.16112230741060696, "compression_ratio": 1.4946808510638299, "no_speech_prob": 0.011072269640862942}, {"id": 189, "seek": 128714, "start": 1302.9, "end": 1309.9, "text": " of being able to see things next to each other. As you introduce API standards, start small.", "tokens": [51152, 295, 885, 1075, 281, 536, 721, 958, 281, 1184, 661, 13, 1018, 291, 5366, 9362, 7787, 11, 722, 1359, 13, 51502], "temperature": 0.0, "avg_logprob": -0.16112230741060696, "compression_ratio": 1.4946808510638299, "no_speech_prob": 0.011072269640862942}, {"id": 190, "seek": 130990, "start": 1310.9, "end": 1317.38, "text": " Do not be tempted by other people's recommended rule sets, not even ours. Pick what works", "tokens": [50414, 1144, 406, 312, 29941, 538, 661, 561, 311, 9628, 4978, 6352, 11, 406, 754, 11896, 13, 14129, 437, 1985, 50738], "temperature": 0.0, "avg_logprob": -0.12157830526662428, "compression_ratio": 1.6143497757847534, "no_speech_prob": 0.11611229181289673}, {"id": 191, "seek": 130990, "start": 1317.38, "end": 1323.42, "text": " for you. Look at the recommended rule set, but then pick the things that you aspire to", "tokens": [50738, 337, 291, 13, 2053, 412, 264, 9628, 4978, 992, 11, 457, 550, 1888, 264, 721, 300, 291, 41224, 281, 51040], "temperature": 0.0, "avg_logprob": -0.12157830526662428, "compression_ratio": 1.6143497757847534, "no_speech_prob": 0.11611229181289673}, {"id": 192, "seek": 130990, "start": 1323.42, "end": 1329.38, "text": " and can adhere to today and commit to reviewing every six months and building up the quality", "tokens": [51040, 293, 393, 33584, 281, 965, 293, 5599, 281, 19576, 633, 2309, 2493, 293, 2390, 493, 264, 3125, 51338], "temperature": 0.0, "avg_logprob": -0.12157830526662428, "compression_ratio": 1.6143497757847534, "no_speech_prob": 0.11611229181289673}, {"id": 193, "seek": 130990, "start": 1329.38, "end": 1334.98, "text": " on your API. If you're retrofitting standards to an existing API, there will be things you", "tokens": [51338, 322, 428, 9362, 13, 759, 291, 434, 18820, 69, 2414, 7787, 281, 364, 6741, 9362, 11, 456, 486, 312, 721, 291, 51618], "temperature": 0.0, "avg_logprob": -0.12157830526662428, "compression_ratio": 1.6143497757847534, "no_speech_prob": 0.11611229181289673}, {"id": 194, "seek": 133498, "start": 1334.98, "end": 1341.66, "text": " cannot change now and that's okay, but you can set those rules for the new versions.", "tokens": [50364, 2644, 1319, 586, 293, 300, 311, 1392, 11, 457, 291, 393, 992, 729, 4474, 337, 264, 777, 9606, 13, 50698], "temperature": 0.0, "avg_logprob": -0.1819086179628477, "compression_ratio": 1.5278969957081545, "no_speech_prob": 0.03253108635544777}, {"id": 195, "seek": 133498, "start": 1341.66, "end": 1345.82, "text": " If you don't know where to start on this, I am going to recommend Zalando. Have some", "tokens": [50698, 759, 291, 500, 380, 458, 689, 281, 722, 322, 341, 11, 286, 669, 516, 281, 2748, 1176, 304, 1806, 13, 3560, 512, 50906], "temperature": 0.0, "avg_logprob": -0.1819086179628477, "compression_ratio": 1.5278969957081545, "no_speech_prob": 0.03253108635544777}, {"id": 196, "seek": 133498, "start": 1345.82, "end": 1352.82, "text": " brilliant public API standards and you could do worse than, okay, they have a lot. Start", "tokens": [50906, 10248, 1908, 9362, 7787, 293, 291, 727, 360, 5324, 813, 11, 1392, 11, 436, 362, 257, 688, 13, 6481, 51256], "temperature": 0.0, "avg_logprob": -0.1819086179628477, "compression_ratio": 1.5278969957081545, "no_speech_prob": 0.03253108635544777}, {"id": 197, "seek": 133498, "start": 1353.26, "end": 1358.38, "text": " small, just pick your favourites out of theirs. It's a great place to start and your organisation", "tokens": [51278, 1359, 11, 445, 1888, 428, 8182, 3324, 484, 295, 22760, 13, 467, 311, 257, 869, 1081, 281, 722, 293, 428, 18641, 51534], "temperature": 0.0, "avg_logprob": -0.1819086179628477, "compression_ratio": 1.5278969957081545, "no_speech_prob": 0.03253108635544777}, {"id": 198, "seek": 135838, "start": 1358.38, "end": 1365.38, "text": " will evolve as it goes along. Please put some linting in. The machines are genuinely good", "tokens": [50364, 486, 16693, 382, 309, 1709, 2051, 13, 2555, 829, 512, 287, 686, 278, 294, 13, 440, 8379, 366, 17839, 665, 50714], "temperature": 0.0, "avg_logprob": -0.14021481288952775, "compression_ratio": 1.5866666666666667, "no_speech_prob": 0.03118354268372059}, {"id": 199, "seek": 135838, "start": 1367.14, "end": 1373.3400000000001, "text": " at this. They can help keep you straight. Is your open API valid? Does it have descriptions?", "tokens": [50802, 412, 341, 13, 814, 393, 854, 1066, 291, 2997, 13, 1119, 428, 1269, 9362, 7363, 30, 4402, 309, 362, 24406, 30, 51112], "temperature": 0.0, "avg_logprob": -0.14021481288952775, "compression_ratio": 1.5866666666666667, "no_speech_prob": 0.03118354268372059}, {"id": 200, "seek": 135838, "start": 1373.3400000000001, "end": 1380.3400000000001, "text": " Does it have examples? I've got one team that I work with where we have a whole API where", "tokens": [51112, 4402, 309, 362, 5110, 30, 286, 600, 658, 472, 1469, 300, 286, 589, 365, 689, 321, 362, 257, 1379, 9362, 689, 51462], "temperature": 0.0, "avg_logprob": -0.14021481288952775, "compression_ratio": 1.5866666666666667, "no_speech_prob": 0.03118354268372059}, {"id": 201, "seek": 135838, "start": 1380.8600000000001, "end": 1387.5, "text": " the description for the access response is okay with a full stop and it turns out we", "tokens": [51488, 264, 3855, 337, 264, 2105, 4134, 307, 1392, 365, 257, 1577, 1590, 293, 309, 4523, 484, 321, 51820], "temperature": 0.0, "avg_logprob": -0.14021481288952775, "compression_ratio": 1.5866666666666667, "no_speech_prob": 0.03118354268372059}, {"id": 202, "seek": 138750, "start": 1387.54, "end": 1394.54, "text": " enforced sentences. So it has to be at least one word and at least one full stop. Yeah,", "tokens": [50366, 40953, 16579, 13, 407, 309, 575, 281, 312, 412, 1935, 472, 1349, 293, 412, 1935, 472, 1577, 1590, 13, 865, 11, 50716], "temperature": 0.0, "avg_logprob": -0.18673395848536228, "compression_ratio": 1.5772727272727274, "no_speech_prob": 0.009680725634098053}, {"id": 203, "seek": 138750, "start": 1396.3, "end": 1402.78, "text": " we did some work with them on that. Get some case conventions, some naming conventions", "tokens": [50804, 321, 630, 512, 589, 365, 552, 322, 300, 13, 3240, 512, 1389, 33520, 11, 512, 25290, 33520, 51128], "temperature": 0.0, "avg_logprob": -0.18673395848536228, "compression_ratio": 1.5772727272727274, "no_speech_prob": 0.009680725634098053}, {"id": 204, "seek": 138750, "start": 1402.78, "end": 1409.88, "text": " and be really picky about what you include. I do this with Redockly CLI, so if you are", "tokens": [51128, 293, 312, 534, 41099, 466, 437, 291, 4090, 13, 286, 360, 341, 365, 4477, 1560, 356, 12855, 40, 11, 370, 498, 291, 366, 51483], "temperature": 0.0, "avg_logprob": -0.18673395848536228, "compression_ratio": 1.5772727272727274, "no_speech_prob": 0.009680725634098053}, {"id": 205, "seek": 138750, "start": 1409.88, "end": 1413.74, "text": " using that, feel free to send me questions. If you use something else, I can't answer", "tokens": [51483, 1228, 300, 11, 841, 1737, 281, 2845, 385, 1651, 13, 759, 291, 764, 746, 1646, 11, 286, 393, 380, 1867, 51676], "temperature": 0.0, "avg_logprob": -0.18673395848536228, "compression_ratio": 1.5772727272727274, "no_speech_prob": 0.009680725634098053}, {"id": 206, "seek": 141374, "start": 1413.74, "end": 1420.74, "text": " your questions, but good luck. Open API documentation. Read the docs for your docs tools. I see a", "tokens": [50364, 428, 1651, 11, 457, 665, 3668, 13, 7238, 9362, 14333, 13, 17604, 264, 45623, 337, 428, 45623, 3873, 13, 286, 536, 257, 50714], "temperature": 0.0, "avg_logprob": -0.15461605698315065, "compression_ratio": 1.4840425531914894, "no_speech_prob": 0.028218092396855354}, {"id": 207, "seek": 141374, "start": 1425.1, "end": 1432.1, "text": " lot of implementations where those functionalities exist in the tooling that you've used, but", "tokens": [50932, 688, 295, 4445, 763, 689, 729, 11745, 1088, 2514, 294, 264, 46593, 300, 291, 600, 1143, 11, 457, 51282], "temperature": 0.0, "avg_logprob": -0.15461605698315065, "compression_ratio": 1.4840425531914894, "no_speech_prob": 0.028218092396855354}, {"id": 208, "seek": 141374, "start": 1433.1, "end": 1438.86, "text": " you haven't really dug into what it can do or looked at how you can extend or configure", "tokens": [51332, 291, 2378, 380, 534, 22954, 666, 437, 309, 393, 360, 420, 2956, 412, 577, 291, 393, 10101, 420, 22162, 51620], "temperature": 0.0, "avg_logprob": -0.15461605698315065, "compression_ratio": 1.4840425531914894, "no_speech_prob": 0.028218092396855354}, {"id": 209, "seek": 143886, "start": 1438.86, "end": 1445.4599999999998, "text": " it. API reference documentation is evolving very quickly in a good way. There's a lot", "tokens": [50364, 309, 13, 9362, 6408, 14333, 307, 21085, 588, 2661, 294, 257, 665, 636, 13, 821, 311, 257, 688, 50694], "temperature": 0.0, "avg_logprob": -0.12047897007154382, "compression_ratio": 1.6203007518796992, "no_speech_prob": 0.03971680998802185}, {"id": 210, "seek": 143886, "start": 1445.4599999999998, "end": 1449.78, "text": " of new entrants in this market. I'm not sure if I'm supposed to be saying that we have", "tokens": [50694, 295, 777, 8041, 1719, 294, 341, 2142, 13, 286, 478, 406, 988, 498, 286, 478, 3442, 281, 312, 1566, 300, 321, 362, 50910], "temperature": 0.0, "avg_logprob": -0.12047897007154382, "compression_ratio": 1.6203007518796992, "no_speech_prob": 0.03971680998802185}, {"id": 211, "seek": 143886, "start": 1449.78, "end": 1455.0, "text": " a new product coming out later in the year that does this. It's beautiful, but you have", "tokens": [50910, 257, 777, 1674, 1348, 484, 1780, 294, 264, 1064, 300, 775, 341, 13, 467, 311, 2238, 11, 457, 291, 362, 51171], "temperature": 0.0, "avg_logprob": -0.12047897007154382, "compression_ratio": 1.6203007518796992, "no_speech_prob": 0.03971680998802185}, {"id": 212, "seek": 143886, "start": 1455.0, "end": 1459.58, "text": " lots and lots of options. Whatever you've picked, make sure you're making the most", "tokens": [51171, 3195, 293, 3195, 295, 3956, 13, 8541, 291, 600, 6183, 11, 652, 988, 291, 434, 1455, 264, 881, 51400], "temperature": 0.0, "avg_logprob": -0.12047897007154382, "compression_ratio": 1.6203007518796992, "no_speech_prob": 0.03971680998802185}, {"id": 213, "seek": 143886, "start": 1459.58, "end": 1466.58, "text": " of it. And if you have something that's, oh, our, I don't want to malign any other tool", "tokens": [51400, 295, 309, 13, 400, 498, 291, 362, 746, 300, 311, 11, 1954, 11, 527, 11, 286, 500, 380, 528, 281, 2806, 788, 604, 661, 2290, 51750], "temperature": 0.0, "avg_logprob": -0.12047897007154382, "compression_ratio": 1.6203007518796992, "no_speech_prob": 0.03971680998802185}, {"id": 214, "seek": 146658, "start": 1466.6999999999998, "end": 1471.26, "text": " families, but something which isn't specialist docs and it can render documentation is a", "tokens": [50370, 4466, 11, 457, 746, 597, 1943, 380, 17008, 45623, 293, 309, 393, 15529, 14333, 307, 257, 50598], "temperature": 0.0, "avg_logprob": -0.13925574199262872, "compression_ratio": 1.6904761904761905, "no_speech_prob": 0.01212925836443901}, {"id": 215, "seek": 146658, "start": 1471.26, "end": 1477.6999999999998, "text": " great way to start. But because you have the open API format, you can use all of one tool", "tokens": [50598, 869, 636, 281, 722, 13, 583, 570, 291, 362, 264, 1269, 9362, 7877, 11, 291, 393, 764, 439, 295, 472, 2290, 50920], "temperature": 0.0, "avg_logprob": -0.13925574199262872, "compression_ratio": 1.6904761904761905, "no_speech_prob": 0.01212925836443901}, {"id": 216, "seek": 146658, "start": 1477.6999999999998, "end": 1484.02, "text": " set for one thing, something else for docs, something else for your SDK gen, like lots", "tokens": [50920, 992, 337, 472, 551, 11, 746, 1646, 337, 45623, 11, 746, 1646, 337, 428, 37135, 1049, 11, 411, 3195, 51236], "temperature": 0.0, "avg_logprob": -0.13925574199262872, "compression_ratio": 1.6904761904761905, "no_speech_prob": 0.01212925836443901}, {"id": 217, "seek": 146658, "start": 1484.02, "end": 1491.02, "text": " and lots of options. Open API, when you publish documentation, your documentation is part", "tokens": [51236, 293, 3195, 295, 3956, 13, 7238, 9362, 11, 562, 291, 11374, 14333, 11, 428, 14333, 307, 644, 51586], "temperature": 0.0, "avg_logprob": -0.13925574199262872, "compression_ratio": 1.6904761904761905, "no_speech_prob": 0.01212925836443901}, {"id": 218, "seek": 149102, "start": 1492.02, "end": 1499.02, "text": " of the product. You should be deploying it often. It should be easy to deploy and redeploy.", "tokens": [50414, 295, 264, 1674, 13, 509, 820, 312, 34198, 309, 2049, 13, 467, 820, 312, 1858, 281, 7274, 293, 14328, 2384, 13, 50764], "temperature": 0.0, "avg_logprob": -0.16537239354684813, "compression_ratio": 1.7318007662835249, "no_speech_prob": 0.021312909200787544}, {"id": 219, "seek": 149102, "start": 1499.02, "end": 1503.66, "text": " And make sure that you're treating it like a web product. Get some metrics, have a look", "tokens": [50764, 400, 652, 988, 300, 291, 434, 15083, 309, 411, 257, 3670, 1674, 13, 3240, 512, 16367, 11, 362, 257, 574, 50996], "temperature": 0.0, "avg_logprob": -0.16537239354684813, "compression_ratio": 1.7318007662835249, "no_speech_prob": 0.021312909200787544}, {"id": 220, "seek": 149102, "start": 1503.66, "end": 1509.26, "text": " at what's happening, see what people run into. If you have interactive docs, what are people", "tokens": [50996, 412, 437, 311, 2737, 11, 536, 437, 561, 1190, 666, 13, 759, 291, 362, 15141, 45623, 11, 437, 366, 561, 51276], "temperature": 0.0, "avg_logprob": -0.16537239354684813, "compression_ratio": 1.7318007662835249, "no_speech_prob": 0.021312909200787544}, {"id": 221, "seek": 149102, "start": 1509.26, "end": 1514.46, "text": " calling the same endpoint all the time? Is it super popular or is it super confusing?", "tokens": [51276, 5141, 264, 912, 35795, 439, 264, 565, 30, 1119, 309, 1687, 3743, 420, 307, 309, 1687, 13181, 30, 51536], "temperature": 0.0, "avg_logprob": -0.16537239354684813, "compression_ratio": 1.7318007662835249, "no_speech_prob": 0.021312909200787544}, {"id": 222, "seek": 149102, "start": 1514.46, "end": 1519.5, "text": " Why is everyone here testing this thing? Have a look at those metrics because they can really", "tokens": [51536, 1545, 307, 1518, 510, 4997, 341, 551, 30, 3560, 257, 574, 412, 729, 16367, 570, 436, 393, 534, 51788], "temperature": 0.0, "avg_logprob": -0.16537239354684813, "compression_ratio": 1.7318007662835249, "no_speech_prob": 0.021312909200787544}, {"id": 223, "seek": 151950, "start": 1519.5, "end": 1526.5, "text": " help you understand your product. I want to talk a little bit about the open API community.", "tokens": [50364, 854, 291, 1223, 428, 1674, 13, 286, 528, 281, 751, 257, 707, 857, 466, 264, 1269, 9362, 1768, 13, 50714], "temperature": 0.0, "avg_logprob": -0.15095382151396378, "compression_ratio": 1.518987341772152, "no_speech_prob": 0.01843256503343582}, {"id": 224, "seek": 151950, "start": 1526.78, "end": 1531.34, "text": " This is something that I don't always include in my technical open API talks, but as far", "tokens": [50728, 639, 307, 746, 300, 286, 500, 380, 1009, 4090, 294, 452, 6191, 1269, 9362, 6686, 11, 457, 382, 1400, 50956], "temperature": 0.0, "avg_logprob": -0.15095382151396378, "compression_ratio": 1.518987341772152, "no_speech_prob": 0.01843256503343582}, {"id": 225, "seek": 151950, "start": 1531.34, "end": 1538.34, "text": " as them, it feels appropriate. It's an open standard. It's part of the Linux foundation.", "tokens": [50956, 382, 552, 11, 309, 3417, 6854, 13, 467, 311, 364, 1269, 3832, 13, 467, 311, 644, 295, 264, 18734, 7030, 13, 51306], "temperature": 0.0, "avg_logprob": -0.15095382151396378, "compression_ratio": 1.518987341772152, "no_speech_prob": 0.01843256503343582}, {"id": 226, "seek": 151950, "start": 1539.22, "end": 1546.22, "text": " You can get, you can learn more about it on openapis.org. The GitHub repository is public.", "tokens": [51350, 509, 393, 483, 11, 291, 393, 1466, 544, 466, 309, 322, 1269, 569, 271, 13, 4646, 13, 440, 23331, 25841, 307, 1908, 13, 51700], "temperature": 0.0, "avg_logprob": -0.15095382151396378, "compression_ratio": 1.518987341772152, "no_speech_prob": 0.01843256503343582}, {"id": 227, "seek": 154622, "start": 1546.3, "end": 1551.6200000000001, "text": " Everything happens there. We have a Slack group. It's very active. Also, public to sign", "tokens": [50368, 5471, 2314, 456, 13, 492, 362, 257, 37211, 1594, 13, 467, 311, 588, 4967, 13, 2743, 11, 1908, 281, 1465, 50634], "temperature": 0.0, "avg_logprob": -0.19230617176402698, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.04787848889827728}, {"id": 228, "seek": 154622, "start": 1551.6200000000001, "end": 1556.34, "text": " up. And there's a weekly technical meeting. I will confess, it's not super friendly for", "tokens": [50634, 493, 13, 400, 456, 311, 257, 12460, 6191, 3440, 13, 286, 486, 19367, 11, 309, 311, 406, 1687, 9208, 337, 50870], "temperature": 0.0, "avg_logprob": -0.19230617176402698, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.04787848889827728}, {"id": 229, "seek": 154622, "start": 1556.34, "end": 1563.34, "text": " Europe. I think it's 6 p.m. Central European time, 5 p.m. for me in the UK. Yeah. I'm trying", "tokens": [50870, 3315, 13, 286, 519, 309, 311, 1386, 280, 13, 76, 13, 9701, 6473, 565, 11, 1025, 280, 13, 76, 13, 337, 385, 294, 264, 7051, 13, 865, 13, 286, 478, 1382, 51220], "temperature": 0.0, "avg_logprob": -0.19230617176402698, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.04787848889827728}, {"id": 230, "seek": 154622, "start": 1564.46, "end": 1569.42, "text": " to get to a critical mass of EU-based maintainers, and then we need to start mixing that up.", "tokens": [51276, 281, 483, 281, 257, 4924, 2758, 295, 10887, 12, 6032, 6909, 433, 11, 293, 550, 321, 643, 281, 722, 11983, 300, 493, 13, 51524], "temperature": 0.0, "avg_logprob": -0.19230617176402698, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.04787848889827728}, {"id": 231, "seek": 154622, "start": 1569.42, "end": 1573.8600000000001, "text": " But yeah. If it's unfriendly for Europe, it's sort of dinnertime. There's no hope at all", "tokens": [51524, 583, 1338, 13, 759, 309, 311, 3971, 4896, 356, 337, 3315, 11, 309, 311, 1333, 295, 3791, 77, 37923, 13, 821, 311, 572, 1454, 412, 439, 51746], "temperature": 0.0, "avg_logprob": -0.19230617176402698, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.04787848889827728}, {"id": 232, "seek": 157386, "start": 1573.9799999999998, "end": 1580.9799999999998, "text": " for anyone east of here. So yeah, we need to fix that. But the open API community is", "tokens": [50370, 337, 2878, 10648, 295, 510, 13, 407, 1338, 11, 321, 643, 281, 3191, 300, 13, 583, 264, 1269, 9362, 1768, 307, 50720], "temperature": 0.0, "avg_logprob": -0.14915430134740368, "compression_ratio": 1.4913793103448276, "no_speech_prob": 0.005105282180011272}, {"id": 233, "seek": 157386, "start": 1580.9799999999998, "end": 1585.4599999999998, "text": " currently growing its maintainer set. It's working on some new stuff. Like, this is a", "tokens": [50720, 4362, 4194, 1080, 6909, 260, 992, 13, 467, 311, 1364, 322, 512, 777, 1507, 13, 1743, 11, 341, 307, 257, 50944], "temperature": 0.0, "avg_logprob": -0.14915430134740368, "compression_ratio": 1.4913793103448276, "no_speech_prob": 0.005105282180011272}, {"id": 234, "seek": 157386, "start": 1585.4599999999998, "end": 1591.9599999999998, "text": " good time to get involved. We've also spun up some special interest groups. So just to", "tokens": [50944, 665, 565, 281, 483, 3288, 13, 492, 600, 611, 37038, 493, 512, 2121, 1179, 3935, 13, 407, 445, 281, 51269], "temperature": 0.0, "avg_logprob": -0.14915430134740368, "compression_ratio": 1.4913793103448276, "no_speech_prob": 0.005105282180011272}, {"id": 235, "seek": 157386, "start": 1591.9599999999998, "end": 1598.56, "text": " kind of tease some of the headline activities within the open API project. The Workflows", "tokens": [51269, 733, 295, 30444, 512, 295, 264, 28380, 5354, 1951, 264, 1269, 9362, 1716, 13, 440, 6603, 33229, 51599], "temperature": 0.0, "avg_logprob": -0.14915430134740368, "compression_ratio": 1.4913793103448276, "no_speech_prob": 0.005105282180011272}, {"id": 236, "seek": 159856, "start": 1598.56, "end": 1605.04, "text": " special interest group describes a sequence of API calls. So if you have, this has come", "tokens": [50364, 2121, 1179, 1594, 15626, 257, 8310, 295, 9362, 5498, 13, 407, 498, 291, 362, 11, 341, 575, 808, 50688], "temperature": 0.0, "avg_logprob": -0.13402030111729413, "compression_ratio": 1.6409090909090909, "no_speech_prob": 0.02673514373600483}, {"id": 237, "seek": 159856, "start": 1605.04, "end": 1610.44, "text": " from the travel industry. So where you need to find the flights, find the seats, ask the", "tokens": [50688, 490, 264, 3147, 3518, 13, 407, 689, 291, 643, 281, 915, 264, 21089, 11, 915, 264, 11069, 11, 1029, 264, 50958], "temperature": 0.0, "avg_logprob": -0.13402030111729413, "compression_ratio": 1.6409090909090909, "no_speech_prob": 0.02673514373600483}, {"id": 238, "seek": 159856, "start": 1610.44, "end": 1616.56, "text": " user, book a seat. None of those make sense by themselves. Workflows aims to give an extra", "tokens": [50958, 4195, 11, 1446, 257, 6121, 13, 14492, 295, 729, 652, 2020, 538, 2969, 13, 6603, 33229, 24683, 281, 976, 364, 2857, 51264], "temperature": 0.0, "avg_logprob": -0.13402030111729413, "compression_ratio": 1.6409090909090909, "no_speech_prob": 0.02673514373600483}, {"id": 239, "seek": 159856, "start": 1616.56, "end": 1623.56, "text": " level of description for that. Overlays is a special interest group that describes repeatable", "tokens": [51264, 1496, 295, 3855, 337, 300, 13, 4886, 75, 3772, 307, 257, 2121, 1179, 1594, 300, 15626, 7149, 712, 51614], "temperature": 0.0, "avg_logprob": -0.13402030111729413, "compression_ratio": 1.6409090909090909, "no_speech_prob": 0.02673514373600483}, {"id": 240, "seek": 162356, "start": 1624.56, "end": 1631.56, "text": " modifications to an open API. So if you have a generated open API that is just thin, you", "tokens": [50414, 26881, 281, 364, 1269, 9362, 13, 407, 498, 291, 362, 257, 10833, 1269, 9362, 300, 307, 445, 5862, 11, 291, 50764], "temperature": 0.0, "avg_logprob": -0.2084178924560547, "compression_ratio": 1.6157205240174672, "no_speech_prob": 0.012940329499542713}, {"id": 241, "seek": 162356, "start": 1632.56, "end": 1638.56, "text": " don't maintain good examples and good descriptions when you're generating from code, and lots", "tokens": [50814, 500, 380, 6909, 665, 5110, 293, 665, 24406, 562, 291, 434, 17746, 490, 3089, 11, 293, 3195, 51114], "temperature": 0.0, "avg_logprob": -0.2084178924560547, "compression_ratio": 1.6157205240174672, "no_speech_prob": 0.012940329499542713}, {"id": 242, "seek": 162356, "start": 1638.56, "end": 1644.56, "text": " of organizations struggle to get away from that Java doc workflow. Overlays can help for", "tokens": [51114, 295, 6150, 7799, 281, 483, 1314, 490, 300, 10745, 3211, 20993, 13, 4886, 75, 3772, 393, 854, 337, 51414], "temperature": 0.0, "avg_logprob": -0.2084178924560547, "compression_ratio": 1.6157205240174672, "no_speech_prob": 0.012940329499542713}, {"id": 243, "seek": 162356, "start": 1645.56, "end": 1650.56, "text": " now, where you can get your open API and make the same changes every time to make the descriptions", "tokens": [51464, 586, 11, 689, 291, 393, 483, 428, 1269, 9362, 293, 652, 264, 912, 2962, 633, 565, 281, 652, 264, 24406, 51714], "temperature": 0.0, "avg_logprob": -0.2084178924560547, "compression_ratio": 1.6157205240174672, "no_speech_prob": 0.012940329499542713}, {"id": 244, "seek": 165056, "start": 1650.56, "end": 1660.56, "text": " better and add examples, hide things, whatever. Open API 4.0. Code name, Moonwalk, why? Don't", "tokens": [50364, 1101, 293, 909, 5110, 11, 6479, 721, 11, 2035, 13, 7238, 9362, 1017, 13, 15, 13, 15549, 1315, 11, 10714, 12490, 11, 983, 30, 1468, 380, 50864], "temperature": 0.0, "avg_logprob": -0.1375697586271498, "compression_ratio": 1.4232804232804233, "no_speech_prob": 0.0017996104434132576}, {"id": 245, "seek": 165056, "start": 1660.56, "end": 1668.56, "text": " ask. Don't let engineers name things. Open API, Project Moonwalk, is committed to doing", "tokens": [50864, 1029, 13, 1468, 380, 718, 11955, 1315, 721, 13, 7238, 9362, 11, 9849, 10714, 12490, 11, 307, 7784, 281, 884, 51264], "temperature": 0.0, "avg_logprob": -0.1375697586271498, "compression_ratio": 1.4232804232804233, "no_speech_prob": 0.0017996104434132576}, {"id": 246, "seek": 165056, "start": 1668.56, "end": 1675.56, "text": " some sort of release this calendar year. So that is just starting. The high level goals", "tokens": [51264, 512, 1333, 295, 4374, 341, 12183, 1064, 13, 407, 300, 307, 445, 2891, 13, 440, 1090, 1496, 5493, 51614], "temperature": 0.0, "avg_logprob": -0.1375697586271498, "compression_ratio": 1.4232804232804233, "no_speech_prob": 0.0017996104434132576}, {"id": 247, "seek": 167556, "start": 1675.56, "end": 1682.56, "text": " are to give you a really simple upgrade from 3.1 upwards, so 3.0 you might want to go to", "tokens": [50364, 366, 281, 976, 291, 257, 534, 2199, 11484, 490, 805, 13, 16, 22167, 11, 370, 805, 13, 15, 291, 1062, 528, 281, 352, 281, 50714], "temperature": 0.0, "avg_logprob": -0.13443546760372999, "compression_ratio": 1.4324324324324325, "no_speech_prob": 0.053079940378665924}, {"id": 248, "seek": 167556, "start": 1682.56, "end": 1692.56, "text": " 3.1, and to include a wider range of HTTP APIs. Open API is amazing for RESTful APIs. Okay", "tokens": [50714, 805, 13, 16, 11, 293, 281, 4090, 257, 11842, 3613, 295, 33283, 21445, 13, 7238, 9362, 307, 2243, 337, 497, 14497, 906, 21445, 13, 1033, 51214], "temperature": 0.0, "avg_logprob": -0.13443546760372999, "compression_ratio": 1.4324324324324325, "no_speech_prob": 0.053079940378665924}, {"id": 249, "seek": 167556, "start": 1692.56, "end": 1700.56, "text": " for some other HTTP-ish, RESTful-ish ones. Moonwalk will include the RPCs and a wider", "tokens": [51214, 337, 512, 661, 33283, 12, 742, 11, 497, 14497, 906, 12, 742, 2306, 13, 10714, 12490, 486, 4090, 264, 497, 12986, 82, 293, 257, 11842, 51614], "temperature": 0.0, "avg_logprob": -0.13443546760372999, "compression_ratio": 1.4324324324324325, "no_speech_prob": 0.053079940378665924}, {"id": 250, "seek": 170056, "start": 1700.56, "end": 1707.56, "text": " family. So if you've struggled with open API, have another look in about a year. Yeah, open", "tokens": [50364, 1605, 13, 407, 498, 291, 600, 19023, 365, 1269, 9362, 11, 362, 1071, 574, 294, 466, 257, 1064, 13, 865, 11, 1269, 50714], "temperature": 0.0, "avg_logprob": -0.0968641694059077, "compression_ratio": 1.564102564102564, "no_speech_prob": 0.02923741191625595}, {"id": 251, "seek": 170056, "start": 1707.56, "end": 1714.56, "text": " API, an open standard for API descriptions. If you're not using it, I hope you will now", "tokens": [50714, 9362, 11, 364, 1269, 3832, 337, 9362, 24406, 13, 759, 291, 434, 406, 1228, 309, 11, 286, 1454, 291, 486, 586, 51064], "temperature": 0.0, "avg_logprob": -0.0968641694059077, "compression_ratio": 1.564102564102564, "no_speech_prob": 0.02923741191625595}, {"id": 252, "seek": 170056, "start": 1714.56, "end": 1719.56, "text": " or feel like it's a thing that you can approach. If you are, maybe I've given you some ideas", "tokens": [51064, 420, 841, 411, 309, 311, 257, 551, 300, 291, 393, 3109, 13, 759, 291, 366, 11, 1310, 286, 600, 2212, 291, 512, 3487, 51314], "temperature": 0.0, "avg_logprob": -0.0968641694059077, "compression_ratio": 1.564102564102564, "no_speech_prob": 0.02923741191625595}, {"id": 253, "seek": 170056, "start": 1719.56, "end": 1725.56, "text": " to go back and look at what you might change in your current workflow. I'm going to leave you", "tokens": [51314, 281, 352, 646, 293, 574, 412, 437, 291, 1062, 1319, 294, 428, 2190, 20993, 13, 286, 478, 516, 281, 1856, 291, 51614], "temperature": 0.0, "avg_logprob": -0.0968641694059077, "compression_ratio": 1.564102564102564, "no_speech_prob": 0.02923741191625595}, {"id": 254, "seek": 172556, "start": 1725.56, "end": 1737.56, "text": " with some resources and say thank you very much for your time. Okay, I'm allowed to take", "tokens": [50364, 365, 512, 3593, 293, 584, 1309, 291, 588, 709, 337, 428, 565, 13, 1033, 11, 286, 478, 4350, 281, 747, 50964], "temperature": 0.0, "avg_logprob": -0.11543964853092116, "compression_ratio": 1.3453237410071943, "no_speech_prob": 0.08069050312042236}, {"id": 255, "seek": 172556, "start": 1737.56, "end": 1749.56, "text": " two questions. Would anyone like to take a question? Yes. This is a really good question. How do I", "tokens": [50964, 732, 1651, 13, 6068, 2878, 411, 281, 747, 257, 1168, 30, 1079, 13, 639, 307, 257, 534, 665, 1168, 13, 1012, 360, 286, 51564], "temperature": 0.0, "avg_logprob": -0.11543964853092116, "compression_ratio": 1.3453237410071943, "no_speech_prob": 0.08069050312042236}, {"id": 256, "seek": 174956, "start": 1749.56, "end": 1759.56, "text": " feel about generating open API from code or code from open API both ways? Let's start at the", "tokens": [50364, 841, 466, 17746, 1269, 9362, 490, 3089, 420, 3089, 490, 1269, 9362, 1293, 2098, 30, 961, 311, 722, 412, 264, 50864], "temperature": 0.0, "avg_logprob": -0.1728498935699463, "compression_ratio": 1.3970588235294117, "no_speech_prob": 0.25536584854125977}, {"id": 257, "seek": 174956, "start": 1759.56, "end": 1768.56, "text": " beginning. A lot of organizations generate open API from their back-end server-side code. I don't", "tokens": [50864, 2863, 13, 316, 688, 295, 6150, 8460, 1269, 9362, 490, 641, 646, 12, 521, 7154, 12, 1812, 3089, 13, 286, 500, 380, 51314], "temperature": 0.0, "avg_logprob": -0.1728498935699463, "compression_ratio": 1.3970588235294117, "no_speech_prob": 0.25536584854125977}, {"id": 258, "seek": 176856, "start": 1768.56, "end": 1781.56, "text": " like it. And the reason I don't like it is I think when you go code first, you're missing a design", "tokens": [50364, 411, 309, 13, 400, 264, 1778, 286, 500, 380, 411, 309, 307, 286, 519, 562, 291, 352, 3089, 700, 11, 291, 434, 5361, 257, 1715, 51014], "temperature": 0.0, "avg_logprob": -0.08700377146402995, "compression_ratio": 1.620879120879121, "no_speech_prob": 0.20353180170059204}, {"id": 259, "seek": 176856, "start": 1781.56, "end": 1790.56, "text": " step. When you design first, you're thinking about it in the context of the rest of the API. You're", "tokens": [51014, 1823, 13, 1133, 291, 1715, 700, 11, 291, 434, 1953, 466, 309, 294, 264, 4319, 295, 264, 1472, 295, 264, 9362, 13, 509, 434, 51464], "temperature": 0.0, "avg_logprob": -0.08700377146402995, "compression_ratio": 1.620879120879121, "no_speech_prob": 0.20353180170059204}, {"id": 260, "seek": 176856, "start": 1790.56, "end": 1796.56, "text": " more likely to get the naming right the first time because that implementation is not done by an", "tokens": [51464, 544, 3700, 281, 483, 264, 25290, 558, 264, 700, 565, 570, 300, 11420, 307, 406, 1096, 538, 364, 51764], "temperature": 0.0, "avg_logprob": -0.08700377146402995, "compression_ratio": 1.620879120879121, "no_speech_prob": 0.20353180170059204}, {"id": 261, "seek": 179656, "start": 1796.56, "end": 1803.56, "text": " engineer by themselves. So you ideally design first APIs. You propose the change to your open", "tokens": [50364, 11403, 538, 2969, 13, 407, 291, 22915, 1715, 700, 21445, 13, 509, 17421, 264, 1319, 281, 428, 1269, 50714], "temperature": 0.0, "avg_logprob": -0.13856088272248857, "compression_ratio": 1.5725806451612903, "no_speech_prob": 0.14818696677684784}, {"id": 262, "seek": 179656, "start": 1803.56, "end": 1809.56, "text": " API with a pull request. You're wise people and you're amazing linting. Go a few iterations to get it", "tokens": [50714, 9362, 365, 257, 2235, 5308, 13, 509, 434, 10829, 561, 293, 291, 434, 2243, 287, 686, 278, 13, 1037, 257, 1326, 36540, 281, 483, 309, 51014], "temperature": 0.0, "avg_logprob": -0.13856088272248857, "compression_ratio": 1.5725806451612903, "no_speech_prob": 0.14818696677684784}, {"id": 263, "seek": 179656, "start": 1809.56, "end": 1816.56, "text": " perfect. Then we build it. And that's my ideal and that's why I prefer it. The other question,", "tokens": [51014, 2176, 13, 1396, 321, 1322, 309, 13, 400, 300, 311, 452, 7157, 293, 300, 311, 983, 286, 4382, 309, 13, 440, 661, 1168, 11, 51364], "temperature": 0.0, "avg_logprob": -0.13856088272248857, "compression_ratio": 1.5725806451612903, "no_speech_prob": 0.14818696677684784}, {"id": 264, "seek": 179656, "start": 1816.56, "end": 1825.56, "text": " generating code from open API? Yes, go for it. I think we have this machine description and there's", "tokens": [51364, 17746, 3089, 490, 1269, 9362, 30, 1079, 11, 352, 337, 309, 13, 286, 519, 321, 362, 341, 3479, 3855, 293, 456, 311, 51814], "temperature": 0.0, "avg_logprob": -0.13856088272248857, "compression_ratio": 1.5725806451612903, "no_speech_prob": 0.14818696677684784}, {"id": 265, "seek": 182556, "start": 1825.56, "end": 1835.56, "text": " a lot of boilerplate. So we can go quite a long way to things like client SDKs from open API. When I", "tokens": [50364, 257, 688, 295, 39228, 37008, 13, 407, 321, 393, 352, 1596, 257, 938, 636, 281, 721, 411, 6423, 37135, 82, 490, 1269, 9362, 13, 1133, 286, 50864], "temperature": 0.0, "avg_logprob": -0.09600489652609523, "compression_ratio": 1.448780487804878, "no_speech_prob": 0.04627625644207001}, {"id": 266, "seek": 182556, "start": 1835.56, "end": 1841.56, "text": " talk about the transform step where you have an open API and you make it better, for docs, you're", "tokens": [50864, 751, 466, 264, 4088, 1823, 689, 291, 362, 364, 1269, 9362, 293, 291, 652, 309, 1101, 11, 337, 45623, 11, 291, 434, 51164], "temperature": 0.0, "avg_logprob": -0.09600489652609523, "compression_ratio": 1.448780487804878, "no_speech_prob": 0.04627625644207001}, {"id": 267, "seek": 182556, "start": 1841.56, "end": 1848.56, "text": " going to add examples and descriptions. For API gateways, SDK code gen, that sort of thing, you're", "tokens": [51164, 516, 281, 909, 5110, 293, 24406, 13, 1171, 9362, 8539, 942, 11, 37135, 3089, 1049, 11, 300, 1333, 295, 551, 11, 291, 434, 51514], "temperature": 0.0, "avg_logprob": -0.09600489652609523, "compression_ratio": 1.448780487804878, "no_speech_prob": 0.04627625644207001}, {"id": 268, "seek": 184856, "start": 1848.56, "end": 1854.56, "text": " going to add metadata here. You're going to give the type hints that the specific programming languages", "tokens": [50364, 516, 281, 909, 26603, 510, 13, 509, 434, 516, 281, 976, 264, 2010, 27271, 300, 264, 2685, 9410, 8650, 50664], "temperature": 0.0, "avg_logprob": -0.09145974600186912, "compression_ratio": 1.691358024691358, "no_speech_prob": 0.2387918382883072}, {"id": 269, "seek": 184856, "start": 1854.56, "end": 1861.56, "text": " and text stacks need. And you're going to give extra information. You might not have that at design", "tokens": [50664, 293, 2487, 30792, 643, 13, 400, 291, 434, 516, 281, 976, 2857, 1589, 13, 509, 1062, 406, 362, 300, 412, 1715, 51014], "temperature": 0.0, "avg_logprob": -0.09145974600186912, "compression_ratio": 1.691358024691358, "no_speech_prob": 0.2387918382883072}, {"id": 270, "seek": 184856, "start": 1861.56, "end": 1868.56, "text": " time, but if you think of it as a pipeline that splits off, you might want to add some extra magic from", "tokens": [51014, 565, 11, 457, 498, 291, 519, 295, 309, 382, 257, 15517, 300, 37741, 766, 11, 291, 1062, 528, 281, 909, 512, 2857, 5585, 490, 51364], "temperature": 0.0, "avg_logprob": -0.09145974600186912, "compression_ratio": 1.691358024691358, "no_speech_prob": 0.2387918382883072}, {"id": 271, "seek": 184856, "start": 1868.56, "end": 1877.56, "text": " your standard open API to enhance it before you generate code from it. But generating code is typically", "tokens": [51364, 428, 3832, 1269, 9362, 281, 11985, 309, 949, 291, 8460, 3089, 490, 309, 13, 583, 17746, 3089, 307, 5850, 51814], "temperature": 0.0, "avg_logprob": -0.09145974600186912, "compression_ratio": 1.691358024691358, "no_speech_prob": 0.2387918382883072}, {"id": 272, "seek": 187756, "start": 1877.56, "end": 1884.56, "text": " fine. It will only be as good as your description is. And lots of those fields are optional. So cool. I am", "tokens": [50364, 2489, 13, 467, 486, 787, 312, 382, 665, 382, 428, 3855, 307, 13, 400, 3195, 295, 729, 7909, 366, 17312, 13, 407, 1627, 13, 286, 669, 50714], "temperature": 0.0, "avg_logprob": -0.10651992349063649, "compression_ratio": 1.362962962962963, "no_speech_prob": 0.09598051011562347}, {"id": 273, "seek": 187756, "start": 1884.56, "end": 1889.56, "text": " out of time. Thank you so much, everyone. I hope to see you during the event.", "tokens": [50714, 484, 295, 565, 13, 1044, 291, 370, 709, 11, 1518, 13, 286, 1454, 281, 536, 291, 1830, 264, 2280, 13, 50964], "temperature": 0.0, "avg_logprob": -0.10651992349063649, "compression_ratio": 1.362962962962963, "no_speech_prob": 0.09598051011562347}], "language": "en"}