{"text": " The Institute which tries to promote best practice in research software across the UK. And earlier this year we worked on this project called Cats, the Climate Aware Task Scheduler that we'd like to talk to you about today. So very simply the idea behind Cats is to try and time shift when we do our compute to the times when the carbon emissions of producing electricity are at their lowest. We are probably aiming this at smaller to mid-size HPC and HTC systems that are not 100% loaded and therefore we have that flexibility to time shift. If you've got a super busy system that's always at 100% then there's not much you can achieve by time shifting your compute. I'm sure that most of you are familiar with the very pressing need as to why this is important but carbon dioxide levels are now getting higher than we can tell they have ever been for the last 800,000 years. Before that our records are not so clear because we don't have things like ice cores readily available but it looks like this is very, very much human caused and because of burning fossil fuels and this is causing a rather dramatic and alarming increase in temperature. Very worryingly in 2023 we saw temperatures going dramatically off the scale and with a far bigger jump than we had seen in any prior year. We get to see if that trend is going to repeat last year but I don't know how many of you have been to Fozden before but for me this is the warmest Fozden I've ever been to and I think this is my fifth one. Most specifically in activation. Have I gone? No, that's going. Is that working? Yes. We don't want to set the world on fire from doing our computational work but that work is important and we would like to do it but having the most minimal impact we can while we do so. So our plan is, as I said, to time shift our compute to when electricity has the lower carbon intensity. We focus this very much on the UK because that's where at least most of us were based and where we met to come up with this idea. The UK has a very, very variable level of carbon intensity in its electricity. Some other countries are not so variable but we have quite a lot of wind power now and quite a bit of solar but it's always windy and it's not always sunny. Carbon intensity can actually vary from in some regions as low as zero grams of carbon dioxide per kilowatt hour to about 400. The average across the whole of the EU in 2022 was about 250. And we have some huge regional variations within the UK. Scotland is normally very green and very low carbon because it's got a lot of wind power, a lot of hydro, not that many people demanding it, not that much industry compared to England. And although it is interconnected into England, those interconnected are of limited capacity so all of that electricity can actually be made to other parts of the country. Conversely, the south of England has a very high population density and is very dependent on gas power still. It does have a bit of solar power because it's the sunniest part of the country and a little bit of wind but not so much as Scotland by any means. As we do have this relations connection, we have a lot of international interconnections now. A new one just came online to Denmark. Another new one came online to Norway a couple of years ago and an additional one to France. We've had another one to France since the 1980s and there's also interconnected Belgium, the Netherlands and Ireland. But again, those represent maybe 30% of typical generation capacity. Unfortunately in the UK we also have this great web API called carbonintensity.org.uk that provides us with regionalised forecasts for the next 48 hours with 30 minute time windows. And it has both JSON and XML APIs that will allow us to interrogate this data and very easily get hold of what our regional forecasts are and it will show us how things are performing both against the forecast and previous measurements. So just to give an example of some of the data we get out of this site, this is an example of a really good day in October last year where the whole country was green, which I think means under 75, no, maybe 100 grams of CO2 per kilowatt hour and about half the country is dark green, which means I think under 35. And we can see some of these regional variations. So just comparing two regions here, these are two regions where my employer has offices. So in the north Wales and Merseyside region, which is this one here, we had only grams of CO2 per kilowatt hour. In the south of England we had 92, which still for the south of England is very low. But if you look at it later, the situation had changed drastically and we now have 289 grams in the south and 235 in north Wales. So if we could have made sure our compute jobs ran on the 6th instead of the 9th, we could have reduced the amount of carbon being put into the atmosphere to run those jobs quite considerably. So just thinking about how much this might actually save us, imagine we have a fictional HPC or part of an HPC, which has 64 core AMD epic CPUs. There's 10 nodes, a 1280 cores in total. And we reckon each one of those will use about 255 watts fully loaded or 37.5 idle. So if we can bring that node down from full to idle, assuming we don't turn it off or suspend it or anything clever like that, then we're looking at around 217 watt per CPU saving. If we can timeshift from when the grid would be at 200 grams of CO2 per kilowatt hour to 50, that's 150. If we had a 12 hour job that used all those 1280 cores, that's around 50 kilowatt hours, which equates to about 7.5 kilograms of carbon dioxide, which is the same as driving a car 50 kilometers. So how many of us might consider not driving to work or not driving a 50 kilometer route because it might reduce the environmental impact? How many of our employers might also have a policy that says you shouldn't drive those kind of distances, you should take public transport? Well, why shouldn't we have the same policies for compute? If we can achieve similar savings, we should be doing that for our compute systems as well as for our travel. I'd just think about this across the wider world. There was a paper published in, I think, 2021, looking at the potential savings of doing time shifting for AI based jobs in cloud providers, just showing us the different levels of savings that could be achieved in different regions. So as you see, these vary quite dramatically from region to region, normally depending on how much renewable energy is available in that region and how bad the alternative is when they are not using renewable energy as well. Now, a lot of people might suggest, well, the grid is going to go net zero soon anyway. Is it really important to do this? And the UK has put out a set of future scenarios about how they might achieve their net zero transition. One of those scenarios, though, is where we don't actually achieve it. And it's not quite clear whether we're actually on that pathway or one of the more optimistic ones at the moment. But even if we do achieve this, and their target is by 2035, we should actually be near net zero, that's still another 11 years of us putting carbon dioxide into the atmosphere when we use electricity, when we could reduce that impact now if we do something with time shifting. So let's do something now instead of waiting 11 years for someone else to solve the problem and possibly not solve the problem in that time. There is also a financial incentive to do this. There are starting to be variable rate electricity tariffs that roughly reflect the carbon intensity because wind and solar power don't have any fuel costs, so they're much cheaper to offer. And if you've got your own electricity production like rooftop solar or your own wind farm, then there's also a saving to use that power, and it's normally better to use it than to export it and be paid normally quite poor rates for that export. So I'm now going to hand over to Appalachic who will talk more specifically about CATS and what it does. Checking, okay, seems to be working. Thanks Colin. So I've been introducing the climate error task schedule, and so CATS figures out the best time to start your HPC job, or really a job that you want to run in a laptop. The users need to submit run times, of course they need to have some idea of how long the job will take, and a postcode. So this graph shows for example that if you schedule a job to the optimal time, you can save your carbon footprint by 70%. So right now it's like a proof of concept, we haven't released version one yet. It was built in one day at these SSIs collaboration workshops. It's kind of a hackathon that we have every year. It won the first prize. So what it is is a Python script, and it targets the at scheduler, so the at scheduler on Linux and BSDs, schedules the starting time of a job. So if you want a thing to start at 6 in the morning, it's at 0600, and it will start the job then. So that's a very easy, simple way to integrate CATS into this scheduling system. So that's what we started with. So the limitation is of course that if your HPC is running at full load all the time, then it doesn't matter what you shift around because it will always be 100%. So it's really meant more for computing systems that are not on all the time, so time shifting will actually make a difference. Of course you'll need to know how long the job will take. Without that, this doesn't work at the moment. If it's an HPC, then other users might be trying to run at the same moment, so how do you do that sort of resuscitation? Currently, it only works in the UK because we're using the Carbon Intensity UK API. Of course, we open to pull requests for other APIs. If other countries have energy data, energy forecasting data, so far we have not found any free to use APIs. So if you know, please let us know. And of course, this is not the only thing you should do. You can use cooling or there's a lot of carbon, embodied carbon in the manufacturing cost of the server that things are running on. So that's probably why you have HPC refreshers because newer servers are much more efficient. So there's a lot of considerations, but in terms of what you as a user can do, I think this is a good place to start. So the way to use CATS is, it's a Python script, so you run it as a module, give it a job duration, give it a postcode. The postcode is a proxy for the location. And using this, it fetches data from the Carbon Intensity API and it calculates the optimal starting time for your job. So we return data in a format that can be passed to AT and it also gives additional data in JSON. So what the other feature of CATS is that it will try to inform the user about the carbon savings that take place when they're offsetting the time. So we do some estimates on how much carbon would be saved by using some year after specify configuration using like what kind of CPU or GPU you have, kind of power use efficiency and thermal design power. And using that, we have a simple formula that will calculate the amount of carbon that you would have saved by running it in this time that CATS wants you to run it rather than will right now. So this is a demo of CATS running. So we specify duration of 60 minutes. And this is RT1, which is redding. And it gives a time on 16th May, 1130. And it also shows you the amount of carbon saved. And that scheduled, so this is a last bit, you can run what you want as long as it takes around 60 minutes. Okay, that's it. So if you have any questions, please email us or put up an issue in our GitHub. And I skip the slide. So what we're doing is we are going to release vision on this month. We're cleaning the common line options. So right now we only support AT, but we also want to support SBAT, which is the Slurm command scheduler similar to AT. And so we'll clean on the command line options and we'll release a vision. But of course, going forward, we want to integrate with Slurm, which is the main scheduler for ACs. And the simplest method, of course, is SBAT, so the start time, the other option is green cues where you have cues that don't run 100% because again, with running 100%, you don't get the benefits of cats. So we have green cues which don't run 100% and also integrating carbon accounting. So Slurm has a plugin that allows you to look at the total power used in your job. So way to integrate carbon accounting into that would be great. That would require rewrites in C because Slurm plugins are in C. And we have got funding from the Software Sustainability Institute for a few months of developer time. So we're looking forward to making great progress and have something more polished soon. And yeah. And now, thank you. Thank you. Thank you, Kavain and Abish. We have time for some questions. Yes. Thank you for your last presentation. But my question is how often clusters are not load on 100%? Yes. I mean, that's a very good question. So I think we need to think about how these things will work moving forward. So we are talking with HBCs and I think this is more proof of concept and prototype to look at how these carbon footprints might be achieved. Obviously, if you do keep things 100% on time, then there is no point. But I think if we do move to a future where we don't move to a net zero grid soon, then we might see funders asking for carbon budgets or government putting carbon budgets just like your financial budget. And then you do want to see this. So it's more like playing the groundwork for what might come next and not for the current generation of HBCs. Any more questions? Sorry. I wasn't looking over there. Thank you very much. Couldn't you use also energy prices like energy stock prices for forecasting? Are they usually at least in Germany or lower when there's more renewable energy in the net? Thanks. Yeah, that's a good point that we'll look into. A good place to start with is to correlate, I guess, energy prices. Yeah, yeah, we'll do the care and look at carbon intensity. Thank you. Hi. I don't want to be Dell specific, but there's a web based tool from Dell called EIPT, Enterprise Infrastructure Planning Tool. You can configure servers with your particular build and you get their CO2 and power usage for various workloads, computational memory intensive and idle. And also Dell have a plugin for their IDRAX called Power Manager. You can take a rack or a group of workstations servers and turn down the energy capping dynamically. And that also works for Fujitsu and HPE servers for other brands. I wonder if you would like to extend your work into that rather than scheduling the jobs to turn down the power cap dynamically. That'd be quite possible. Thanks. Yeah, I was at a word that there was a carbon accounting plugin for Slurm already. So yes, ideally we have something that goes into Slurm and does the carbon accounting rather than having user-shadow jobs. That's definitely not optimal. So yeah, thanks. We'll look into that. Any more questions? Sorry. Are you also planning to integrate this into HD Condor? Sorry, could you repeat? Are you also planning to integrate this into HD Condor? It's another scheduling software? Not at the moment. At the moment we are focusing on Slurm, but once we have got something there we'll focus on other schedulers. Okay, thank you. Hi there. First of all, love it. So thanks very much for the talk. I'm looking forward to version one being released just to throw another thing out there that you could do. It'd be cool to have two locations and you can imagine an office having two offices in the UK and they're kind of deciding where to deploy that task. Maybe that extends even globally and you can choose where to run your task. Yeah, spatial shifting would be a nice thing to have. The problem with that is moving the data with it. You need to have the data in both locations or move the data in advance of the job starting. Anyone else? That's one over there. This is really just a comment. I made a calculation of how much commuting to work costs in terms of energy compared to what the supercomputers in that computing center are. Just to give you a perspective, usually when you go to work and go back home it's like the 100% that you can save here. So just to give in general to whenever you're doing such savings estimates, just be aware that tell your employer that just by working from home you can save that exact amount. Sorry, it's just a statement. Just a quick question on how CATS works. I don't recall if you got into detail about it, but does it use the API data for time series prediction or does it have some kind of internal calculation to do that? It tries to find the lowest carbon window in the forecast period. So if your job is going to be six hours it will try and find the lowest six hours in that period and schedule your job to that time period. Okay, but the predictions are already available. The predictions are not made by us. The predictions are available from the carbon intensity API. Thanks for the talk. I have one question. If you already saw an API which is called Wattime API, I think it does the same, but all over the world. I wasn't aware of that one, but that is very useful. We will look into that one. Hi there. One, two. You can hear me, right? Yeah. Hi, I'm Chris Adams from the Green Software Foundation. I'm curious about whether when you're doing this, if I know what jobs I did last year, is there a way for me to run any of this against, say, last year's worth of compute jobs to see what my savings could have been if I were to find something like this? Because a lot of this is forward-looking, but if I've got some data now, that will make it easier for me to make the case that this could create some meaningful savings inside my team or inside my organization. Yeah. Slurm normally has some accounting built in that logs when jobs ran, so that would give you the data that you'd need to go and do that. I think there's also a simulator available, which is something we want to look into in our next phase as to whether we can make use of that to do that kind of prediction, or not prediction analysis. I saw your talk last year, and that was actually some of the inspiration behind this. I think that's it. One more. Hi. I was wondering, we're also in the purchase of buy-in new cluster, and we have also raised this thing with the users. Turns out they don't really like this. The idea that there would be free resources in the cluster, and their job would not start immediately. Is this a cluster with people actually using the HPC clusters? So far, it's very hard. We're finding that from users, there's sort of a three-way split of some who care enough to definitely go out their way to do things, some who might use it if it was available, but aren't going to go out their way, and some who they want their science now, and they don't care what the carbon emissions are. I guess we can target the other two groups first, and the other third might get dragged out, kicking and screaming one day when carbon accounting comes in for them. Okay, can we thank the speakers again, please?", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 16.88, "text": " The Institute which tries to promote best practice in research software across the UK.", "tokens": [50364, 440, 9446, 597, 9898, 281, 9773, 1151, 3124, 294, 2132, 4722, 2108, 264, 7051, 13, 51208], "temperature": 0.0, "avg_logprob": -0.36038750868577224, "compression_ratio": 1.376543209876543, "no_speech_prob": 0.5117964148521423}, {"id": 1, "seek": 0, "start": 16.88, "end": 22.240000000000002, "text": " And earlier this year we worked on this project called Cats, the Climate Aware Task Scheduler", "tokens": [51208, 400, 3071, 341, 1064, 321, 2732, 322, 341, 1716, 1219, 40902, 11, 264, 27025, 43949, 30428, 44926, 26318, 51476], "temperature": 0.0, "avg_logprob": -0.36038750868577224, "compression_ratio": 1.376543209876543, "no_speech_prob": 0.5117964148521423}, {"id": 2, "seek": 0, "start": 22.240000000000002, "end": 26.04, "text": " that we'd like to talk to you about today.", "tokens": [51476, 300, 321, 1116, 411, 281, 751, 281, 291, 466, 965, 13, 51666], "temperature": 0.0, "avg_logprob": -0.36038750868577224, "compression_ratio": 1.376543209876543, "no_speech_prob": 0.5117964148521423}, {"id": 3, "seek": 2604, "start": 26.04, "end": 31.68, "text": " So very simply the idea behind Cats is to try and time shift when we do our compute", "tokens": [50364, 407, 588, 2935, 264, 1558, 2261, 40902, 307, 281, 853, 293, 565, 5513, 562, 321, 360, 527, 14722, 50646], "temperature": 0.0, "avg_logprob": -0.16289879351246114, "compression_ratio": 1.5625, "no_speech_prob": 0.4268069565296173}, {"id": 4, "seek": 2604, "start": 31.68, "end": 37.96, "text": " to the times when the carbon emissions of producing electricity are at their lowest.", "tokens": [50646, 281, 264, 1413, 562, 264, 5954, 14607, 295, 10501, 10356, 366, 412, 641, 12437, 13, 50960], "temperature": 0.0, "avg_logprob": -0.16289879351246114, "compression_ratio": 1.5625, "no_speech_prob": 0.4268069565296173}, {"id": 5, "seek": 2604, "start": 37.96, "end": 44.16, "text": " We are probably aiming this at smaller to mid-size HPC and HTC systems that are not", "tokens": [50960, 492, 366, 1391, 20253, 341, 412, 4356, 281, 2062, 12, 27553, 12557, 34, 293, 11751, 34, 3652, 300, 366, 406, 51270], "temperature": 0.0, "avg_logprob": -0.16289879351246114, "compression_ratio": 1.5625, "no_speech_prob": 0.4268069565296173}, {"id": 6, "seek": 2604, "start": 44.16, "end": 49.0, "text": " 100% loaded and therefore we have that flexibility to time shift.", "tokens": [51270, 2319, 4, 13210, 293, 4412, 321, 362, 300, 12635, 281, 565, 5513, 13, 51512], "temperature": 0.0, "avg_logprob": -0.16289879351246114, "compression_ratio": 1.5625, "no_speech_prob": 0.4268069565296173}, {"id": 7, "seek": 2604, "start": 49.0, "end": 52.84, "text": " If you've got a super busy system that's always at 100% then there's not much you", "tokens": [51512, 759, 291, 600, 658, 257, 1687, 5856, 1185, 300, 311, 1009, 412, 2319, 4, 550, 456, 311, 406, 709, 291, 51704], "temperature": 0.0, "avg_logprob": -0.16289879351246114, "compression_ratio": 1.5625, "no_speech_prob": 0.4268069565296173}, {"id": 8, "seek": 5284, "start": 52.84, "end": 57.96, "text": " can achieve by time shifting your compute.", "tokens": [50364, 393, 4584, 538, 565, 17573, 428, 14722, 13, 50620], "temperature": 0.0, "avg_logprob": -0.18128294896597813, "compression_ratio": 1.6192307692307693, "no_speech_prob": 0.1658276915550232}, {"id": 9, "seek": 5284, "start": 57.96, "end": 62.52, "text": " I'm sure that most of you are familiar with the very pressing need as to why this is important", "tokens": [50620, 286, 478, 988, 300, 881, 295, 291, 366, 4963, 365, 264, 588, 12417, 643, 382, 281, 983, 341, 307, 1021, 50848], "temperature": 0.0, "avg_logprob": -0.18128294896597813, "compression_ratio": 1.6192307692307693, "no_speech_prob": 0.1658276915550232}, {"id": 10, "seek": 5284, "start": 62.52, "end": 67.72, "text": " but carbon dioxide levels are now getting higher than we can tell they have ever been", "tokens": [50848, 457, 5954, 19590, 4358, 366, 586, 1242, 2946, 813, 321, 393, 980, 436, 362, 1562, 668, 51108], "temperature": 0.0, "avg_logprob": -0.18128294896597813, "compression_ratio": 1.6192307692307693, "no_speech_prob": 0.1658276915550232}, {"id": 11, "seek": 5284, "start": 67.72, "end": 70.12, "text": " for the last 800,000 years.", "tokens": [51108, 337, 264, 1036, 13083, 11, 1360, 924, 13, 51228], "temperature": 0.0, "avg_logprob": -0.18128294896597813, "compression_ratio": 1.6192307692307693, "no_speech_prob": 0.1658276915550232}, {"id": 12, "seek": 5284, "start": 70.12, "end": 74.04, "text": " Before that our records are not so clear because we don't have things like ice cores", "tokens": [51228, 4546, 300, 527, 7724, 366, 406, 370, 1850, 570, 321, 500, 380, 362, 721, 411, 4435, 24826, 51424], "temperature": 0.0, "avg_logprob": -0.18128294896597813, "compression_ratio": 1.6192307692307693, "no_speech_prob": 0.1658276915550232}, {"id": 13, "seek": 5284, "start": 74.04, "end": 79.68, "text": " readily available but it looks like this is very, very much human caused and because", "tokens": [51424, 26336, 2435, 457, 309, 1542, 411, 341, 307, 588, 11, 588, 709, 1952, 7008, 293, 570, 51706], "temperature": 0.0, "avg_logprob": -0.18128294896597813, "compression_ratio": 1.6192307692307693, "no_speech_prob": 0.1658276915550232}, {"id": 14, "seek": 7968, "start": 79.68, "end": 85.88000000000001, "text": " of burning fossil fuels and this is causing a rather dramatic and alarming increase in", "tokens": [50364, 295, 9488, 18737, 24616, 293, 341, 307, 9853, 257, 2831, 12023, 293, 44043, 3488, 294, 50674], "temperature": 0.0, "avg_logprob": -0.1620284536610479, "compression_ratio": 1.6704119850187267, "no_speech_prob": 0.6092460751533508}, {"id": 15, "seek": 7968, "start": 85.88000000000001, "end": 87.48, "text": " temperature.", "tokens": [50674, 4292, 13, 50754], "temperature": 0.0, "avg_logprob": -0.1620284536610479, "compression_ratio": 1.6704119850187267, "no_speech_prob": 0.6092460751533508}, {"id": 16, "seek": 7968, "start": 87.48, "end": 93.52000000000001, "text": " Very worryingly in 2023 we saw temperatures going dramatically off the scale and with", "tokens": [50754, 4372, 3292, 12163, 294, 44377, 321, 1866, 12633, 516, 17548, 766, 264, 4373, 293, 365, 51056], "temperature": 0.0, "avg_logprob": -0.1620284536610479, "compression_ratio": 1.6704119850187267, "no_speech_prob": 0.6092460751533508}, {"id": 17, "seek": 7968, "start": 93.52000000000001, "end": 97.60000000000001, "text": " a far bigger jump than we had seen in any prior year.", "tokens": [51056, 257, 1400, 3801, 3012, 813, 321, 632, 1612, 294, 604, 4059, 1064, 13, 51260], "temperature": 0.0, "avg_logprob": -0.1620284536610479, "compression_ratio": 1.6704119850187267, "no_speech_prob": 0.6092460751533508}, {"id": 18, "seek": 7968, "start": 97.60000000000001, "end": 100.92000000000002, "text": " We get to see if that trend is going to repeat last year but I don't know how many of you", "tokens": [51260, 492, 483, 281, 536, 498, 300, 6028, 307, 516, 281, 7149, 1036, 1064, 457, 286, 500, 380, 458, 577, 867, 295, 291, 51426], "temperature": 0.0, "avg_logprob": -0.1620284536610479, "compression_ratio": 1.6704119850187267, "no_speech_prob": 0.6092460751533508}, {"id": 19, "seek": 7968, "start": 100.92000000000002, "end": 104.84, "text": " have been to Fozden before but for me this is the warmest Fozden I've ever been to and", "tokens": [51426, 362, 668, 281, 8564, 89, 1556, 949, 457, 337, 385, 341, 307, 264, 4561, 377, 8564, 89, 1556, 286, 600, 1562, 668, 281, 293, 51622], "temperature": 0.0, "avg_logprob": -0.1620284536610479, "compression_ratio": 1.6704119850187267, "no_speech_prob": 0.6092460751533508}, {"id": 20, "seek": 7968, "start": 104.84, "end": 108.84, "text": " I think this is my fifth one.", "tokens": [51622, 286, 519, 341, 307, 452, 9266, 472, 13, 51822], "temperature": 0.0, "avg_logprob": -0.1620284536610479, "compression_ratio": 1.6704119850187267, "no_speech_prob": 0.6092460751533508}, {"id": 21, "seek": 10884, "start": 109.0, "end": 112.0, "text": " Most specifically in activation.", "tokens": [50372, 4534, 4682, 294, 24433, 13, 50522], "temperature": 0.0, "avg_logprob": -0.2457521646329672, "compression_ratio": 1.5657894736842106, "no_speech_prob": 0.2767782509326935}, {"id": 22, "seek": 10884, "start": 112.0, "end": 116.0, "text": " Have I gone?", "tokens": [50522, 3560, 286, 2780, 30, 50722], "temperature": 0.0, "avg_logprob": -0.2457521646329672, "compression_ratio": 1.5657894736842106, "no_speech_prob": 0.2767782509326935}, {"id": 23, "seek": 10884, "start": 116.0, "end": 120.0, "text": " No, that's going.", "tokens": [50722, 883, 11, 300, 311, 516, 13, 50922], "temperature": 0.0, "avg_logprob": -0.2457521646329672, "compression_ratio": 1.5657894736842106, "no_speech_prob": 0.2767782509326935}, {"id": 24, "seek": 10884, "start": 120.0, "end": 121.0, "text": " Is that working?", "tokens": [50922, 1119, 300, 1364, 30, 50972], "temperature": 0.0, "avg_logprob": -0.2457521646329672, "compression_ratio": 1.5657894736842106, "no_speech_prob": 0.2767782509326935}, {"id": 25, "seek": 10884, "start": 121.0, "end": 122.0, "text": " Yes.", "tokens": [50972, 1079, 13, 51022], "temperature": 0.0, "avg_logprob": -0.2457521646329672, "compression_ratio": 1.5657894736842106, "no_speech_prob": 0.2767782509326935}, {"id": 26, "seek": 10884, "start": 122.0, "end": 125.36, "text": " We don't want to set the world on fire from doing our computational work but that work", "tokens": [51022, 492, 500, 380, 528, 281, 992, 264, 1002, 322, 2610, 490, 884, 527, 28270, 589, 457, 300, 589, 51190], "temperature": 0.0, "avg_logprob": -0.2457521646329672, "compression_ratio": 1.5657894736842106, "no_speech_prob": 0.2767782509326935}, {"id": 27, "seek": 10884, "start": 125.36, "end": 130.48000000000002, "text": " is important and we would like to do it but having the most minimal impact we can while", "tokens": [51190, 307, 1021, 293, 321, 576, 411, 281, 360, 309, 457, 1419, 264, 881, 13206, 2712, 321, 393, 1339, 51446], "temperature": 0.0, "avg_logprob": -0.2457521646329672, "compression_ratio": 1.5657894736842106, "no_speech_prob": 0.2767782509326935}, {"id": 28, "seek": 10884, "start": 130.48000000000002, "end": 133.08, "text": " we do so.", "tokens": [51446, 321, 360, 370, 13, 51576], "temperature": 0.0, "avg_logprob": -0.2457521646329672, "compression_ratio": 1.5657894736842106, "no_speech_prob": 0.2767782509326935}, {"id": 29, "seek": 10884, "start": 133.08, "end": 137.72, "text": " So our plan is, as I said, to time shift our compute to when electricity has the lower", "tokens": [51576, 407, 527, 1393, 307, 11, 382, 286, 848, 11, 281, 565, 5513, 527, 14722, 281, 562, 10356, 575, 264, 3126, 51808], "temperature": 0.0, "avg_logprob": -0.2457521646329672, "compression_ratio": 1.5657894736842106, "no_speech_prob": 0.2767782509326935}, {"id": 30, "seek": 13772, "start": 137.76, "end": 139.76, "text": " carbon intensity.", "tokens": [50366, 5954, 13749, 13, 50466], "temperature": 0.0, "avg_logprob": -0.1577096149839204, "compression_ratio": 1.7669172932330828, "no_speech_prob": 0.1785338968038559}, {"id": 31, "seek": 13772, "start": 139.76, "end": 143.64, "text": " We focus this very much on the UK because that's where at least most of us were based", "tokens": [50466, 492, 1879, 341, 588, 709, 322, 264, 7051, 570, 300, 311, 689, 412, 1935, 881, 295, 505, 645, 2361, 50660], "temperature": 0.0, "avg_logprob": -0.1577096149839204, "compression_ratio": 1.7669172932330828, "no_speech_prob": 0.1785338968038559}, {"id": 32, "seek": 13772, "start": 143.64, "end": 145.76, "text": " and where we met to come up with this idea.", "tokens": [50660, 293, 689, 321, 1131, 281, 808, 493, 365, 341, 1558, 13, 50766], "temperature": 0.0, "avg_logprob": -0.1577096149839204, "compression_ratio": 1.7669172932330828, "no_speech_prob": 0.1785338968038559}, {"id": 33, "seek": 13772, "start": 145.76, "end": 151.28, "text": " The UK has a very, very variable level of carbon intensity in its electricity.", "tokens": [50766, 440, 7051, 575, 257, 588, 11, 588, 7006, 1496, 295, 5954, 13749, 294, 1080, 10356, 13, 51042], "temperature": 0.0, "avg_logprob": -0.1577096149839204, "compression_ratio": 1.7669172932330828, "no_speech_prob": 0.1785338968038559}, {"id": 34, "seek": 13772, "start": 151.28, "end": 155.88, "text": " Some other countries are not so variable but we have quite a lot of wind power now and", "tokens": [51042, 2188, 661, 3517, 366, 406, 370, 7006, 457, 321, 362, 1596, 257, 688, 295, 2468, 1347, 586, 293, 51272], "temperature": 0.0, "avg_logprob": -0.1577096149839204, "compression_ratio": 1.7669172932330828, "no_speech_prob": 0.1785338968038559}, {"id": 35, "seek": 13772, "start": 155.88, "end": 160.96, "text": " quite a bit of solar but it's always windy and it's not always sunny.", "tokens": [51272, 1596, 257, 857, 295, 7936, 457, 309, 311, 1009, 30330, 293, 309, 311, 406, 1009, 20412, 13, 51526], "temperature": 0.0, "avg_logprob": -0.1577096149839204, "compression_ratio": 1.7669172932330828, "no_speech_prob": 0.1785338968038559}, {"id": 36, "seek": 13772, "start": 160.96, "end": 165.07999999999998, "text": " Carbon intensity can actually vary from in some regions as low as zero grams of carbon", "tokens": [51526, 31453, 13749, 393, 767, 10559, 490, 294, 512, 10682, 382, 2295, 382, 4018, 11899, 295, 5954, 51732], "temperature": 0.0, "avg_logprob": -0.1577096149839204, "compression_ratio": 1.7669172932330828, "no_speech_prob": 0.1785338968038559}, {"id": 37, "seek": 16508, "start": 165.12, "end": 169.32000000000002, "text": " dioxide per kilowatt hour to about 400.", "tokens": [50366, 19590, 680, 41295, 1591, 1773, 281, 466, 8423, 13, 50576], "temperature": 0.0, "avg_logprob": -0.19546753378475415, "compression_ratio": 1.4848484848484849, "no_speech_prob": 0.0449930876493454}, {"id": 38, "seek": 16508, "start": 169.32000000000002, "end": 174.32000000000002, "text": " The average across the whole of the EU in 2022 was about 250.", "tokens": [50576, 440, 4274, 2108, 264, 1379, 295, 264, 10887, 294, 20229, 390, 466, 11650, 13, 50826], "temperature": 0.0, "avg_logprob": -0.19546753378475415, "compression_ratio": 1.4848484848484849, "no_speech_prob": 0.0449930876493454}, {"id": 39, "seek": 16508, "start": 174.32000000000002, "end": 181.32000000000002, "text": " And we have some huge regional variations within the UK.", "tokens": [50826, 400, 321, 362, 512, 2603, 10964, 17840, 1951, 264, 7051, 13, 51176], "temperature": 0.0, "avg_logprob": -0.19546753378475415, "compression_ratio": 1.4848484848484849, "no_speech_prob": 0.0449930876493454}, {"id": 40, "seek": 16508, "start": 181.92000000000002, "end": 187.72000000000003, "text": " Scotland is normally very green and very low carbon because it's got a lot of wind power,", "tokens": [51206, 11180, 307, 5646, 588, 3092, 293, 588, 2295, 5954, 570, 309, 311, 658, 257, 688, 295, 2468, 1347, 11, 51496], "temperature": 0.0, "avg_logprob": -0.19546753378475415, "compression_ratio": 1.4848484848484849, "no_speech_prob": 0.0449930876493454}, {"id": 41, "seek": 16508, "start": 187.72000000000003, "end": 194.72000000000003, "text": " a lot of hydro, not that many people demanding it, not that much industry compared to England.", "tokens": [51496, 257, 688, 295, 15435, 11, 406, 300, 867, 561, 19960, 309, 11, 406, 300, 709, 3518, 5347, 281, 8196, 13, 51846], "temperature": 0.0, "avg_logprob": -0.19546753378475415, "compression_ratio": 1.4848484848484849, "no_speech_prob": 0.0449930876493454}, {"id": 42, "seek": 19472, "start": 194.96, "end": 199.35999999999999, "text": " And although it is interconnected into England, those interconnected are of limited capacity", "tokens": [50376, 400, 4878, 309, 307, 36611, 666, 8196, 11, 729, 36611, 366, 295, 5567, 6042, 50596], "temperature": 0.0, "avg_logprob": -0.23234034392793299, "compression_ratio": 1.8013937282229966, "no_speech_prob": 0.003725252812728286}, {"id": 43, "seek": 19472, "start": 199.35999999999999, "end": 203.88, "text": " so all of that electricity can actually be made to other parts of the country.", "tokens": [50596, 370, 439, 295, 300, 10356, 393, 767, 312, 1027, 281, 661, 3166, 295, 264, 1941, 13, 50822], "temperature": 0.0, "avg_logprob": -0.23234034392793299, "compression_ratio": 1.8013937282229966, "no_speech_prob": 0.003725252812728286}, {"id": 44, "seek": 19472, "start": 203.88, "end": 209.04, "text": " Conversely, the south of England has a very high population density and is very dependent", "tokens": [50822, 33247, 736, 11, 264, 7377, 295, 8196, 575, 257, 588, 1090, 4415, 10305, 293, 307, 588, 12334, 51080], "temperature": 0.0, "avg_logprob": -0.23234034392793299, "compression_ratio": 1.8013937282229966, "no_speech_prob": 0.003725252812728286}, {"id": 45, "seek": 19472, "start": 209.04, "end": 210.84, "text": " on gas power still.", "tokens": [51080, 322, 4211, 1347, 920, 13, 51170], "temperature": 0.0, "avg_logprob": -0.23234034392793299, "compression_ratio": 1.8013937282229966, "no_speech_prob": 0.003725252812728286}, {"id": 46, "seek": 19472, "start": 210.84, "end": 215.16, "text": " It does have a bit of solar power because it's the sunniest part of the country and", "tokens": [51170, 467, 775, 362, 257, 857, 295, 7936, 1347, 570, 309, 311, 264, 3295, 38896, 644, 295, 264, 1941, 293, 51386], "temperature": 0.0, "avg_logprob": -0.23234034392793299, "compression_ratio": 1.8013937282229966, "no_speech_prob": 0.003725252812728286}, {"id": 47, "seek": 19472, "start": 215.16, "end": 219.2, "text": " a little bit of wind but not so much as Scotland by any means.", "tokens": [51386, 257, 707, 857, 295, 2468, 457, 406, 370, 709, 382, 11180, 538, 604, 1355, 13, 51588], "temperature": 0.0, "avg_logprob": -0.23234034392793299, "compression_ratio": 1.8013937282229966, "no_speech_prob": 0.003725252812728286}, {"id": 48, "seek": 19472, "start": 219.2, "end": 223.88, "text": " As we do have this relations connection, we have a lot of international interconnections", "tokens": [51588, 1018, 321, 360, 362, 341, 2299, 4984, 11, 321, 362, 257, 688, 295, 5058, 26253, 626, 51822], "temperature": 0.0, "avg_logprob": -0.23234034392793299, "compression_ratio": 1.8013937282229966, "no_speech_prob": 0.003725252812728286}, {"id": 49, "seek": 22388, "start": 223.92, "end": 224.92, "text": " now.", "tokens": [50366, 586, 13, 50416], "temperature": 0.0, "avg_logprob": -0.22123255588040494, "compression_ratio": 1.5610687022900764, "no_speech_prob": 0.1188688799738884}, {"id": 50, "seek": 22388, "start": 224.92, "end": 227.24, "text": " A new one just came online to Denmark.", "tokens": [50416, 316, 777, 472, 445, 1361, 2950, 281, 28065, 13, 50532], "temperature": 0.0, "avg_logprob": -0.22123255588040494, "compression_ratio": 1.5610687022900764, "no_speech_prob": 0.1188688799738884}, {"id": 51, "seek": 22388, "start": 227.24, "end": 231.0, "text": " Another new one came online to Norway a couple of years ago and an additional one to France.", "tokens": [50532, 3996, 777, 472, 1361, 2950, 281, 24354, 257, 1916, 295, 924, 2057, 293, 364, 4497, 472, 281, 6190, 13, 50720], "temperature": 0.0, "avg_logprob": -0.22123255588040494, "compression_ratio": 1.5610687022900764, "no_speech_prob": 0.1188688799738884}, {"id": 52, "seek": 22388, "start": 231.0, "end": 235.28, "text": " We've had another one to France since the 1980s and there's also interconnected Belgium,", "tokens": [50720, 492, 600, 632, 1071, 472, 281, 6190, 1670, 264, 13626, 82, 293, 456, 311, 611, 36611, 28094, 11, 50934], "temperature": 0.0, "avg_logprob": -0.22123255588040494, "compression_ratio": 1.5610687022900764, "no_speech_prob": 0.1188688799738884}, {"id": 53, "seek": 22388, "start": 235.28, "end": 237.56, "text": " the Netherlands and Ireland.", "tokens": [50934, 264, 20873, 293, 15880, 13, 51048], "temperature": 0.0, "avg_logprob": -0.22123255588040494, "compression_ratio": 1.5610687022900764, "no_speech_prob": 0.1188688799738884}, {"id": 54, "seek": 22388, "start": 237.56, "end": 244.56, "text": " But again, those represent maybe 30% of typical generation capacity.", "tokens": [51048, 583, 797, 11, 729, 2906, 1310, 2217, 4, 295, 7476, 5125, 6042, 13, 51398], "temperature": 0.0, "avg_logprob": -0.22123255588040494, "compression_ratio": 1.5610687022900764, "no_speech_prob": 0.1188688799738884}, {"id": 55, "seek": 22388, "start": 246.35999999999999, "end": 252.24, "text": " Unfortunately in the UK we also have this great web API called carbonintensity.org.uk", "tokens": [51488, 8590, 294, 264, 7051, 321, 611, 362, 341, 869, 3670, 9362, 1219, 5954, 686, 6859, 13, 4646, 13, 2034, 51782], "temperature": 0.0, "avg_logprob": -0.22123255588040494, "compression_ratio": 1.5610687022900764, "no_speech_prob": 0.1188688799738884}, {"id": 56, "seek": 25224, "start": 252.24, "end": 257.12, "text": " that provides us with regionalised forecasts for the next 48 hours with 30 minute time", "tokens": [50364, 300, 6417, 505, 365, 10964, 2640, 49421, 337, 264, 958, 11174, 2496, 365, 2217, 3456, 565, 50608], "temperature": 0.0, "avg_logprob": -0.17974032777728458, "compression_ratio": 1.6588235294117648, "no_speech_prob": 0.05845334380865097}, {"id": 57, "seek": 25224, "start": 257.12, "end": 258.12, "text": " windows.", "tokens": [50608, 9309, 13, 50658], "temperature": 0.0, "avg_logprob": -0.17974032777728458, "compression_ratio": 1.6588235294117648, "no_speech_prob": 0.05845334380865097}, {"id": 58, "seek": 25224, "start": 258.12, "end": 263.16, "text": " And it has both JSON and XML APIs that will allow us to interrogate this data and very", "tokens": [50658, 400, 309, 575, 1293, 31828, 293, 43484, 21445, 300, 486, 2089, 505, 281, 24871, 473, 341, 1412, 293, 588, 50910], "temperature": 0.0, "avg_logprob": -0.17974032777728458, "compression_ratio": 1.6588235294117648, "no_speech_prob": 0.05845334380865097}, {"id": 59, "seek": 25224, "start": 263.16, "end": 270.0, "text": " easily get hold of what our regional forecasts are and it will show us how things are performing", "tokens": [50910, 3612, 483, 1797, 295, 437, 527, 10964, 49421, 366, 293, 309, 486, 855, 505, 577, 721, 366, 10205, 51252], "temperature": 0.0, "avg_logprob": -0.17974032777728458, "compression_ratio": 1.6588235294117648, "no_speech_prob": 0.05845334380865097}, {"id": 60, "seek": 25224, "start": 270.0, "end": 275.04, "text": " both against the forecast and previous measurements.", "tokens": [51252, 1293, 1970, 264, 14330, 293, 3894, 15383, 13, 51504], "temperature": 0.0, "avg_logprob": -0.17974032777728458, "compression_ratio": 1.6588235294117648, "no_speech_prob": 0.05845334380865097}, {"id": 61, "seek": 25224, "start": 275.04, "end": 277.92, "text": " So just to give an example of some of the data we get out of this site, this is an example", "tokens": [51504, 407, 445, 281, 976, 364, 1365, 295, 512, 295, 264, 1412, 321, 483, 484, 295, 341, 3621, 11, 341, 307, 364, 1365, 51648], "temperature": 0.0, "avg_logprob": -0.17974032777728458, "compression_ratio": 1.6588235294117648, "no_speech_prob": 0.05845334380865097}, {"id": 62, "seek": 27792, "start": 277.92, "end": 283.44, "text": " of a really good day in October last year where the whole country was green, which I", "tokens": [50364, 295, 257, 534, 665, 786, 294, 7617, 1036, 1064, 689, 264, 1379, 1941, 390, 3092, 11, 597, 286, 50640], "temperature": 0.0, "avg_logprob": -0.17511440912882487, "compression_ratio": 1.567099567099567, "no_speech_prob": 0.5106288194656372}, {"id": 63, "seek": 27792, "start": 283.44, "end": 289.44, "text": " think means under 75, no, maybe 100 grams of CO2 per kilowatt hour and about half the", "tokens": [50640, 519, 1355, 833, 9562, 11, 572, 11, 1310, 2319, 11899, 295, 3002, 17, 680, 41295, 1591, 1773, 293, 466, 1922, 264, 50940], "temperature": 0.0, "avg_logprob": -0.17511440912882487, "compression_ratio": 1.567099567099567, "no_speech_prob": 0.5106288194656372}, {"id": 64, "seek": 27792, "start": 289.44, "end": 294.20000000000005, "text": " country is dark green, which means I think under 35.", "tokens": [50940, 1941, 307, 2877, 3092, 11, 597, 1355, 286, 519, 833, 6976, 13, 51178], "temperature": 0.0, "avg_logprob": -0.17511440912882487, "compression_ratio": 1.567099567099567, "no_speech_prob": 0.5106288194656372}, {"id": 65, "seek": 27792, "start": 294.20000000000005, "end": 295.64, "text": " And we can see some of these regional variations.", "tokens": [51178, 400, 321, 393, 536, 512, 295, 613, 10964, 17840, 13, 51250], "temperature": 0.0, "avg_logprob": -0.17511440912882487, "compression_ratio": 1.567099567099567, "no_speech_prob": 0.5106288194656372}, {"id": 66, "seek": 27792, "start": 295.64, "end": 301.04, "text": " So just comparing two regions here, these are two regions where my employer has offices.", "tokens": [51250, 407, 445, 15763, 732, 10682, 510, 11, 613, 366, 732, 10682, 689, 452, 16205, 575, 14434, 13, 51520], "temperature": 0.0, "avg_logprob": -0.17511440912882487, "compression_ratio": 1.567099567099567, "no_speech_prob": 0.5106288194656372}, {"id": 67, "seek": 30104, "start": 301.04, "end": 308.04, "text": " So in the north Wales and Merseyside region, which is this one here, we had only grams", "tokens": [50364, 407, 294, 264, 6830, 16495, 293, 6124, 405, 749, 482, 4458, 11, 597, 307, 341, 472, 510, 11, 321, 632, 787, 11899, 50714], "temperature": 0.0, "avg_logprob": -0.18642088462566508, "compression_ratio": 1.6349206349206349, "no_speech_prob": 0.4965806007385254}, {"id": 68, "seek": 30104, "start": 308.24, "end": 310.88, "text": " of CO2 per kilowatt hour.", "tokens": [50724, 295, 3002, 17, 680, 41295, 1591, 1773, 13, 50856], "temperature": 0.0, "avg_logprob": -0.18642088462566508, "compression_ratio": 1.6349206349206349, "no_speech_prob": 0.4965806007385254}, {"id": 69, "seek": 30104, "start": 310.88, "end": 315.44, "text": " In the south of England we had 92, which still for the south of England is very low.", "tokens": [50856, 682, 264, 7377, 295, 8196, 321, 632, 28225, 11, 597, 920, 337, 264, 7377, 295, 8196, 307, 588, 2295, 13, 51084], "temperature": 0.0, "avg_logprob": -0.18642088462566508, "compression_ratio": 1.6349206349206349, "no_speech_prob": 0.4965806007385254}, {"id": 70, "seek": 30104, "start": 315.44, "end": 320.52000000000004, "text": " But if you look at it later, the situation had changed drastically and we now have 289", "tokens": [51084, 583, 498, 291, 574, 412, 309, 1780, 11, 264, 2590, 632, 3105, 29673, 293, 321, 586, 362, 7562, 24, 51338], "temperature": 0.0, "avg_logprob": -0.18642088462566508, "compression_ratio": 1.6349206349206349, "no_speech_prob": 0.4965806007385254}, {"id": 71, "seek": 30104, "start": 320.52000000000004, "end": 325.12, "text": " grams in the south and 235 in north Wales.", "tokens": [51338, 11899, 294, 264, 7377, 293, 6673, 20, 294, 6830, 16495, 13, 51568], "temperature": 0.0, "avg_logprob": -0.18642088462566508, "compression_ratio": 1.6349206349206349, "no_speech_prob": 0.4965806007385254}, {"id": 72, "seek": 30104, "start": 325.12, "end": 329.40000000000003, "text": " So if we could have made sure our compute jobs ran on the 6th instead of the 9th, we", "tokens": [51568, 407, 498, 321, 727, 362, 1027, 988, 527, 14722, 4782, 5872, 322, 264, 1386, 392, 2602, 295, 264, 1722, 392, 11, 321, 51782], "temperature": 0.0, "avg_logprob": -0.18642088462566508, "compression_ratio": 1.6349206349206349, "no_speech_prob": 0.4965806007385254}, {"id": 73, "seek": 32940, "start": 329.44, "end": 334.59999999999997, "text": " could have reduced the amount of carbon being put into the atmosphere to run those jobs", "tokens": [50366, 727, 362, 9212, 264, 2372, 295, 5954, 885, 829, 666, 264, 8018, 281, 1190, 729, 4782, 50624], "temperature": 0.0, "avg_logprob": -0.20675366467768602, "compression_ratio": 1.4389312977099236, "no_speech_prob": 0.010391322895884514}, {"id": 74, "seek": 32940, "start": 334.59999999999997, "end": 337.79999999999995, "text": " quite considerably.", "tokens": [50624, 1596, 31308, 13, 50784], "temperature": 0.0, "avg_logprob": -0.20675366467768602, "compression_ratio": 1.4389312977099236, "no_speech_prob": 0.010391322895884514}, {"id": 75, "seek": 32940, "start": 337.79999999999995, "end": 341.47999999999996, "text": " So just thinking about how much this might actually save us, imagine we have a fictional", "tokens": [50784, 407, 445, 1953, 466, 577, 709, 341, 1062, 767, 3155, 505, 11, 3811, 321, 362, 257, 28911, 50968], "temperature": 0.0, "avg_logprob": -0.20675366467768602, "compression_ratio": 1.4389312977099236, "no_speech_prob": 0.010391322895884514}, {"id": 76, "seek": 32940, "start": 341.47999999999996, "end": 347.47999999999996, "text": " HPC or part of an HPC, which has 64 core AMD epic CPUs.", "tokens": [50968, 12557, 34, 420, 644, 295, 364, 12557, 34, 11, 597, 575, 12145, 4965, 34808, 13581, 13199, 82, 13, 51268], "temperature": 0.0, "avg_logprob": -0.20675366467768602, "compression_ratio": 1.4389312977099236, "no_speech_prob": 0.010391322895884514}, {"id": 77, "seek": 32940, "start": 347.47999999999996, "end": 351.71999999999997, "text": " There's 10 nodes, a 1280 cores in total.", "tokens": [51268, 821, 311, 1266, 13891, 11, 257, 2272, 4702, 24826, 294, 3217, 13, 51480], "temperature": 0.0, "avg_logprob": -0.20675366467768602, "compression_ratio": 1.4389312977099236, "no_speech_prob": 0.010391322895884514}, {"id": 78, "seek": 32940, "start": 351.71999999999997, "end": 357.79999999999995, "text": " And we reckon each one of those will use about 255 watts fully loaded or 37.5 idle.", "tokens": [51480, 400, 321, 29548, 1184, 472, 295, 729, 486, 764, 466, 3552, 20, 31247, 4498, 13210, 420, 13435, 13, 20, 30650, 13, 51784], "temperature": 0.0, "avg_logprob": -0.20675366467768602, "compression_ratio": 1.4389312977099236, "no_speech_prob": 0.010391322895884514}, {"id": 79, "seek": 35780, "start": 357.84000000000003, "end": 361.72, "text": " So if we can bring that node down from full to idle, assuming we don't turn it off or", "tokens": [50366, 407, 498, 321, 393, 1565, 300, 9984, 760, 490, 1577, 281, 30650, 11, 11926, 321, 500, 380, 1261, 309, 766, 420, 50560], "temperature": 0.0, "avg_logprob": -0.172506568967834, "compression_ratio": 1.6373239436619718, "no_speech_prob": 0.003943422809243202}, {"id": 80, "seek": 35780, "start": 361.72, "end": 368.52000000000004, "text": " suspend it or anything clever like that, then we're looking at around 217 watt per CPU saving.", "tokens": [50560, 42546, 309, 420, 1340, 13494, 411, 300, 11, 550, 321, 434, 1237, 412, 926, 5080, 22, 31556, 680, 13199, 6816, 13, 50900], "temperature": 0.0, "avg_logprob": -0.172506568967834, "compression_ratio": 1.6373239436619718, "no_speech_prob": 0.003943422809243202}, {"id": 81, "seek": 35780, "start": 368.52000000000004, "end": 372.36, "text": " If we can timeshift from when the grid would be at 200 grams of CO2 per kilowatt hour to", "tokens": [50900, 759, 321, 393, 1413, 71, 2008, 490, 562, 264, 10748, 576, 312, 412, 2331, 11899, 295, 3002, 17, 680, 41295, 1591, 1773, 281, 51092], "temperature": 0.0, "avg_logprob": -0.172506568967834, "compression_ratio": 1.6373239436619718, "no_speech_prob": 0.003943422809243202}, {"id": 82, "seek": 35780, "start": 372.36, "end": 374.96000000000004, "text": " 50, that's 150.", "tokens": [51092, 2625, 11, 300, 311, 8451, 13, 51222], "temperature": 0.0, "avg_logprob": -0.172506568967834, "compression_ratio": 1.6373239436619718, "no_speech_prob": 0.003943422809243202}, {"id": 83, "seek": 35780, "start": 374.96000000000004, "end": 380.40000000000003, "text": " If we had a 12 hour job that used all those 1280 cores, that's around 50 kilowatt hours,", "tokens": [51222, 759, 321, 632, 257, 2272, 1773, 1691, 300, 1143, 439, 729, 2272, 4702, 24826, 11, 300, 311, 926, 2625, 41295, 1591, 2496, 11, 51494], "temperature": 0.0, "avg_logprob": -0.172506568967834, "compression_ratio": 1.6373239436619718, "no_speech_prob": 0.003943422809243202}, {"id": 84, "seek": 35780, "start": 380.40000000000003, "end": 385.36, "text": " which equates to about 7.5 kilograms of carbon dioxide, which is the same as driving a car", "tokens": [51494, 597, 1267, 1024, 281, 466, 1614, 13, 20, 30690, 295, 5954, 19590, 11, 597, 307, 264, 912, 382, 4840, 257, 1032, 51742], "temperature": 0.0, "avg_logprob": -0.172506568967834, "compression_ratio": 1.6373239436619718, "no_speech_prob": 0.003943422809243202}, {"id": 85, "seek": 38536, "start": 385.40000000000003, "end": 388.08000000000004, "text": " 50 kilometers.", "tokens": [50366, 2625, 13904, 13, 50500], "temperature": 0.0, "avg_logprob": -0.18798011432994496, "compression_ratio": 1.7238805970149254, "no_speech_prob": 0.03838567063212395}, {"id": 86, "seek": 38536, "start": 388.08000000000004, "end": 392.88, "text": " So how many of us might consider not driving to work or not driving a 50 kilometer route", "tokens": [50500, 407, 577, 867, 295, 505, 1062, 1949, 406, 4840, 281, 589, 420, 406, 4840, 257, 2625, 33795, 7955, 50740], "temperature": 0.0, "avg_logprob": -0.18798011432994496, "compression_ratio": 1.7238805970149254, "no_speech_prob": 0.03838567063212395}, {"id": 87, "seek": 38536, "start": 392.88, "end": 395.04, "text": " because it might reduce the environmental impact?", "tokens": [50740, 570, 309, 1062, 5407, 264, 8303, 2712, 30, 50848], "temperature": 0.0, "avg_logprob": -0.18798011432994496, "compression_ratio": 1.7238805970149254, "no_speech_prob": 0.03838567063212395}, {"id": 88, "seek": 38536, "start": 395.04, "end": 398.72, "text": " How many of our employers might also have a policy that says you shouldn't drive those", "tokens": [50848, 1012, 867, 295, 527, 16744, 1062, 611, 362, 257, 3897, 300, 1619, 291, 4659, 380, 3332, 729, 51032], "temperature": 0.0, "avg_logprob": -0.18798011432994496, "compression_ratio": 1.7238805970149254, "no_speech_prob": 0.03838567063212395}, {"id": 89, "seek": 38536, "start": 398.72, "end": 400.92, "text": " kind of distances, you should take public transport?", "tokens": [51032, 733, 295, 22182, 11, 291, 820, 747, 1908, 5495, 30, 51142], "temperature": 0.0, "avg_logprob": -0.18798011432994496, "compression_ratio": 1.7238805970149254, "no_speech_prob": 0.03838567063212395}, {"id": 90, "seek": 38536, "start": 400.92, "end": 403.36, "text": " Well, why shouldn't we have the same policies for compute?", "tokens": [51142, 1042, 11, 983, 4659, 380, 321, 362, 264, 912, 7657, 337, 14722, 30, 51264], "temperature": 0.0, "avg_logprob": -0.18798011432994496, "compression_ratio": 1.7238805970149254, "no_speech_prob": 0.03838567063212395}, {"id": 91, "seek": 38536, "start": 403.36, "end": 407.08000000000004, "text": " If we can achieve similar savings, we should be doing that for our compute systems as well", "tokens": [51264, 759, 321, 393, 4584, 2531, 13454, 11, 321, 820, 312, 884, 300, 337, 527, 14722, 3652, 382, 731, 51450], "temperature": 0.0, "avg_logprob": -0.18798011432994496, "compression_ratio": 1.7238805970149254, "no_speech_prob": 0.03838567063212395}, {"id": 92, "seek": 38536, "start": 407.08000000000004, "end": 409.44, "text": " as for our travel.", "tokens": [51450, 382, 337, 527, 3147, 13, 51568], "temperature": 0.0, "avg_logprob": -0.18798011432994496, "compression_ratio": 1.7238805970149254, "no_speech_prob": 0.03838567063212395}, {"id": 93, "seek": 40944, "start": 410.44, "end": 413.76, "text": " I'd just think about this across the wider world.", "tokens": [50414, 286, 1116, 445, 519, 466, 341, 2108, 264, 11842, 1002, 13, 50580], "temperature": 0.0, "avg_logprob": -0.20020365247539446, "compression_ratio": 1.6357142857142857, "no_speech_prob": 0.01099658664315939}, {"id": 94, "seek": 40944, "start": 413.76, "end": 419.08, "text": " There was a paper published in, I think, 2021, looking at the potential savings of doing", "tokens": [50580, 821, 390, 257, 3035, 6572, 294, 11, 286, 519, 11, 7201, 11, 1237, 412, 264, 3995, 13454, 295, 884, 50846], "temperature": 0.0, "avg_logprob": -0.20020365247539446, "compression_ratio": 1.6357142857142857, "no_speech_prob": 0.01099658664315939}, {"id": 95, "seek": 40944, "start": 419.08, "end": 424.6, "text": " time shifting for AI based jobs in cloud providers, just showing us the different levels of savings", "tokens": [50846, 565, 17573, 337, 7318, 2361, 4782, 294, 4588, 11330, 11, 445, 4099, 505, 264, 819, 4358, 295, 13454, 51122], "temperature": 0.0, "avg_logprob": -0.20020365247539446, "compression_ratio": 1.6357142857142857, "no_speech_prob": 0.01099658664315939}, {"id": 96, "seek": 40944, "start": 424.6, "end": 426.72, "text": " that could be achieved in different regions.", "tokens": [51122, 300, 727, 312, 11042, 294, 819, 10682, 13, 51228], "temperature": 0.0, "avg_logprob": -0.20020365247539446, "compression_ratio": 1.6357142857142857, "no_speech_prob": 0.01099658664315939}, {"id": 97, "seek": 40944, "start": 426.72, "end": 430.32, "text": " So as you see, these vary quite dramatically from region to region, normally depending on", "tokens": [51228, 407, 382, 291, 536, 11, 613, 10559, 1596, 17548, 490, 4458, 281, 4458, 11, 5646, 5413, 322, 51408], "temperature": 0.0, "avg_logprob": -0.20020365247539446, "compression_ratio": 1.6357142857142857, "no_speech_prob": 0.01099658664315939}, {"id": 98, "seek": 40944, "start": 430.32, "end": 437.15999999999997, "text": " how much renewable energy is available in that region and how bad the alternative is", "tokens": [51408, 577, 709, 20938, 2281, 307, 2435, 294, 300, 4458, 293, 577, 1578, 264, 8535, 307, 51750], "temperature": 0.0, "avg_logprob": -0.20020365247539446, "compression_ratio": 1.6357142857142857, "no_speech_prob": 0.01099658664315939}, {"id": 99, "seek": 43716, "start": 437.20000000000005, "end": 441.92, "text": " when they are not using renewable energy as well.", "tokens": [50366, 562, 436, 366, 406, 1228, 20938, 2281, 382, 731, 13, 50602], "temperature": 0.0, "avg_logprob": -0.17027098391236378, "compression_ratio": 1.6559139784946237, "no_speech_prob": 0.07161225378513336}, {"id": 100, "seek": 43716, "start": 441.92, "end": 446.32000000000005, "text": " Now, a lot of people might suggest, well, the grid is going to go net zero soon anyway.", "tokens": [50602, 823, 11, 257, 688, 295, 561, 1062, 3402, 11, 731, 11, 264, 10748, 307, 516, 281, 352, 2533, 4018, 2321, 4033, 13, 50822], "temperature": 0.0, "avg_logprob": -0.17027098391236378, "compression_ratio": 1.6559139784946237, "no_speech_prob": 0.07161225378513336}, {"id": 101, "seek": 43716, "start": 446.32000000000005, "end": 448.44, "text": " Is it really important to do this?", "tokens": [50822, 1119, 309, 534, 1021, 281, 360, 341, 30, 50928], "temperature": 0.0, "avg_logprob": -0.17027098391236378, "compression_ratio": 1.6559139784946237, "no_speech_prob": 0.07161225378513336}, {"id": 102, "seek": 43716, "start": 448.44, "end": 454.88, "text": " And the UK has put out a set of future scenarios about how they might achieve their net zero", "tokens": [50928, 400, 264, 7051, 575, 829, 484, 257, 992, 295, 2027, 15077, 466, 577, 436, 1062, 4584, 641, 2533, 4018, 51250], "temperature": 0.0, "avg_logprob": -0.17027098391236378, "compression_ratio": 1.6559139784946237, "no_speech_prob": 0.07161225378513336}, {"id": 103, "seek": 43716, "start": 454.88, "end": 457.28000000000003, "text": " transition.", "tokens": [51250, 6034, 13, 51370], "temperature": 0.0, "avg_logprob": -0.17027098391236378, "compression_ratio": 1.6559139784946237, "no_speech_prob": 0.07161225378513336}, {"id": 104, "seek": 43716, "start": 457.28000000000003, "end": 460.24, "text": " One of those scenarios, though, is where we don't actually achieve it.", "tokens": [51370, 1485, 295, 729, 15077, 11, 1673, 11, 307, 689, 321, 500, 380, 767, 4584, 309, 13, 51518], "temperature": 0.0, "avg_logprob": -0.17027098391236378, "compression_ratio": 1.6559139784946237, "no_speech_prob": 0.07161225378513336}, {"id": 105, "seek": 43716, "start": 460.24, "end": 463.72, "text": " And it's not quite clear whether we're actually on that pathway or one of the more optimistic", "tokens": [51518, 400, 309, 311, 406, 1596, 1850, 1968, 321, 434, 767, 322, 300, 18590, 420, 472, 295, 264, 544, 19397, 51692], "temperature": 0.0, "avg_logprob": -0.17027098391236378, "compression_ratio": 1.6559139784946237, "no_speech_prob": 0.07161225378513336}, {"id": 106, "seek": 43716, "start": 463.72, "end": 465.6, "text": " ones at the moment.", "tokens": [51692, 2306, 412, 264, 1623, 13, 51786], "temperature": 0.0, "avg_logprob": -0.17027098391236378, "compression_ratio": 1.6559139784946237, "no_speech_prob": 0.07161225378513336}, {"id": 107, "seek": 46560, "start": 465.64000000000004, "end": 470.08000000000004, "text": " But even if we do achieve this, and their target is by 2035, we should actually be near", "tokens": [50366, 583, 754, 498, 321, 360, 4584, 341, 11, 293, 641, 3779, 307, 538, 945, 8794, 11, 321, 820, 767, 312, 2651, 50588], "temperature": 0.0, "avg_logprob": -0.09838898692812238, "compression_ratio": 1.6884057971014492, "no_speech_prob": 0.01012724544852972}, {"id": 108, "seek": 46560, "start": 470.08000000000004, "end": 477.32000000000005, "text": " net zero, that's still another 11 years of us putting carbon dioxide into the atmosphere", "tokens": [50588, 2533, 4018, 11, 300, 311, 920, 1071, 2975, 924, 295, 505, 3372, 5954, 19590, 666, 264, 8018, 50950], "temperature": 0.0, "avg_logprob": -0.09838898692812238, "compression_ratio": 1.6884057971014492, "no_speech_prob": 0.01012724544852972}, {"id": 109, "seek": 46560, "start": 477.32000000000005, "end": 482.72, "text": " when we use electricity, when we could reduce that impact now if we do something with time", "tokens": [50950, 562, 321, 764, 10356, 11, 562, 321, 727, 5407, 300, 2712, 586, 498, 321, 360, 746, 365, 565, 51220], "temperature": 0.0, "avg_logprob": -0.09838898692812238, "compression_ratio": 1.6884057971014492, "no_speech_prob": 0.01012724544852972}, {"id": 110, "seek": 46560, "start": 482.72, "end": 483.72, "text": " shifting.", "tokens": [51220, 17573, 13, 51270], "temperature": 0.0, "avg_logprob": -0.09838898692812238, "compression_ratio": 1.6884057971014492, "no_speech_prob": 0.01012724544852972}, {"id": 111, "seek": 46560, "start": 483.72, "end": 488.0, "text": " So let's do something now instead of waiting 11 years for someone else to solve the problem", "tokens": [51270, 407, 718, 311, 360, 746, 586, 2602, 295, 3806, 2975, 924, 337, 1580, 1646, 281, 5039, 264, 1154, 51484], "temperature": 0.0, "avg_logprob": -0.09838898692812238, "compression_ratio": 1.6884057971014492, "no_speech_prob": 0.01012724544852972}, {"id": 112, "seek": 46560, "start": 488.0, "end": 491.88, "text": " and possibly not solve the problem in that time.", "tokens": [51484, 293, 6264, 406, 5039, 264, 1154, 294, 300, 565, 13, 51678], "temperature": 0.0, "avg_logprob": -0.09838898692812238, "compression_ratio": 1.6884057971014492, "no_speech_prob": 0.01012724544852972}, {"id": 113, "seek": 46560, "start": 491.88, "end": 493.76000000000005, "text": " There is also a financial incentive to do this.", "tokens": [51678, 821, 307, 611, 257, 4669, 22346, 281, 360, 341, 13, 51772], "temperature": 0.0, "avg_logprob": -0.09838898692812238, "compression_ratio": 1.6884057971014492, "no_speech_prob": 0.01012724544852972}, {"id": 114, "seek": 49376, "start": 493.76, "end": 499.52, "text": " There are starting to be variable rate electricity tariffs that roughly reflect the carbon intensity", "tokens": [50364, 821, 366, 2891, 281, 312, 7006, 3314, 10356, 39661, 300, 9810, 5031, 264, 5954, 13749, 50652], "temperature": 0.0, "avg_logprob": -0.1401024539061267, "compression_ratio": 1.6833976833976834, "no_speech_prob": 0.06456367671489716}, {"id": 115, "seek": 49376, "start": 499.52, "end": 504.96, "text": " because wind and solar power don't have any fuel costs, so they're much cheaper to offer.", "tokens": [50652, 570, 2468, 293, 7936, 1347, 500, 380, 362, 604, 6616, 5497, 11, 370, 436, 434, 709, 12284, 281, 2626, 13, 50924], "temperature": 0.0, "avg_logprob": -0.1401024539061267, "compression_ratio": 1.6833976833976834, "no_speech_prob": 0.06456367671489716}, {"id": 116, "seek": 49376, "start": 504.96, "end": 509.92, "text": " And if you've got your own electricity production like rooftop solar or your own wind farm, then", "tokens": [50924, 400, 498, 291, 600, 658, 428, 1065, 10356, 4265, 411, 41027, 7936, 420, 428, 1065, 2468, 5421, 11, 550, 51172], "temperature": 0.0, "avg_logprob": -0.1401024539061267, "compression_ratio": 1.6833976833976834, "no_speech_prob": 0.06456367671489716}, {"id": 117, "seek": 49376, "start": 509.92, "end": 515.24, "text": " there's also a saving to use that power, and it's normally better to use it than to export", "tokens": [51172, 456, 311, 611, 257, 6816, 281, 764, 300, 1347, 11, 293, 309, 311, 5646, 1101, 281, 764, 309, 813, 281, 10725, 51438], "temperature": 0.0, "avg_logprob": -0.1401024539061267, "compression_ratio": 1.6833976833976834, "no_speech_prob": 0.06456367671489716}, {"id": 118, "seek": 49376, "start": 515.24, "end": 518.76, "text": " it and be paid normally quite poor rates for that export.", "tokens": [51438, 309, 293, 312, 4835, 5646, 1596, 4716, 6846, 337, 300, 10725, 13, 51614], "temperature": 0.0, "avg_logprob": -0.1401024539061267, "compression_ratio": 1.6833976833976834, "no_speech_prob": 0.06456367671489716}, {"id": 119, "seek": 51876, "start": 519.76, "end": 525.16, "text": " So I'm now going to hand over to Appalachic who will talk more specifically about CATS", "tokens": [50414, 407, 286, 478, 586, 516, 281, 1011, 670, 281, 3132, 304, 608, 299, 567, 486, 751, 544, 4682, 466, 41192, 50, 50684], "temperature": 0.0, "avg_logprob": -0.43450225608936255, "compression_ratio": 1.3771428571428572, "no_speech_prob": 0.011587467044591904}, {"id": 120, "seek": 51876, "start": 525.16, "end": 527.16, "text": " and what it does.", "tokens": [50684, 293, 437, 309, 775, 13, 50784], "temperature": 0.0, "avg_logprob": -0.43450225608936255, "compression_ratio": 1.3771428571428572, "no_speech_prob": 0.011587467044591904}, {"id": 121, "seek": 51876, "start": 533.16, "end": 536.16, "text": " Checking, okay, seems to be working.", "tokens": [51084, 6881, 278, 11, 1392, 11, 2544, 281, 312, 1364, 13, 51234], "temperature": 0.0, "avg_logprob": -0.43450225608936255, "compression_ratio": 1.3771428571428572, "no_speech_prob": 0.011587467044591904}, {"id": 122, "seek": 51876, "start": 536.16, "end": 537.68, "text": " Thanks Colin.", "tokens": [51234, 2561, 29253, 13, 51310], "temperature": 0.0, "avg_logprob": -0.43450225608936255, "compression_ratio": 1.3771428571428572, "no_speech_prob": 0.011587467044591904}, {"id": 123, "seek": 51876, "start": 537.68, "end": 544.64, "text": " So I've been introducing the climate error task schedule, and so CATS figures out the", "tokens": [51310, 407, 286, 600, 668, 15424, 264, 5659, 6713, 5633, 7567, 11, 293, 370, 41192, 50, 9624, 484, 264, 51658], "temperature": 0.0, "avg_logprob": -0.43450225608936255, "compression_ratio": 1.3771428571428572, "no_speech_prob": 0.011587467044591904}, {"id": 124, "seek": 54464, "start": 544.64, "end": 552.0, "text": " best time to start your HPC job, or really a job that you want to run in a laptop.", "tokens": [50364, 1151, 565, 281, 722, 428, 12557, 34, 1691, 11, 420, 534, 257, 1691, 300, 291, 528, 281, 1190, 294, 257, 10732, 13, 50732], "temperature": 0.0, "avg_logprob": -0.20526373788212124, "compression_ratio": 1.5305164319248827, "no_speech_prob": 0.1576402485370636}, {"id": 125, "seek": 54464, "start": 552.0, "end": 557.68, "text": " The users need to submit run times, of course they need to have some idea of how long the", "tokens": [50732, 440, 5022, 643, 281, 10315, 1190, 1413, 11, 295, 1164, 436, 643, 281, 362, 512, 1558, 295, 577, 938, 264, 51016], "temperature": 0.0, "avg_logprob": -0.20526373788212124, "compression_ratio": 1.5305164319248827, "no_speech_prob": 0.1576402485370636}, {"id": 126, "seek": 54464, "start": 557.68, "end": 561.36, "text": " job will take, and a postcode.", "tokens": [51016, 1691, 486, 747, 11, 293, 257, 2183, 22332, 13, 51200], "temperature": 0.0, "avg_logprob": -0.20526373788212124, "compression_ratio": 1.5305164319248827, "no_speech_prob": 0.1576402485370636}, {"id": 127, "seek": 54464, "start": 561.36, "end": 566.3199999999999, "text": " So this graph shows for example that if you schedule a job to the optimal time, you can", "tokens": [51200, 407, 341, 4295, 3110, 337, 1365, 300, 498, 291, 7567, 257, 1691, 281, 264, 16252, 565, 11, 291, 393, 51448], "temperature": 0.0, "avg_logprob": -0.20526373788212124, "compression_ratio": 1.5305164319248827, "no_speech_prob": 0.1576402485370636}, {"id": 128, "seek": 54464, "start": 566.3199999999999, "end": 571.52, "text": " save your carbon footprint by 70%.", "tokens": [51448, 3155, 428, 5954, 24222, 538, 5285, 6856, 51708], "temperature": 0.0, "avg_logprob": -0.20526373788212124, "compression_ratio": 1.5305164319248827, "no_speech_prob": 0.1576402485370636}, {"id": 129, "seek": 57152, "start": 571.52, "end": 577.3199999999999, "text": " So right now it's like a proof of concept, we haven't released version one yet.", "tokens": [50364, 407, 558, 586, 309, 311, 411, 257, 8177, 295, 3410, 11, 321, 2378, 380, 4736, 3037, 472, 1939, 13, 50654], "temperature": 0.0, "avg_logprob": -0.2504433599011651, "compression_ratio": 1.5522388059701493, "no_speech_prob": 0.04671522602438927}, {"id": 130, "seek": 57152, "start": 577.3199999999999, "end": 583.0799999999999, "text": " It was built in one day at these SSIs collaboration workshops.", "tokens": [50654, 467, 390, 3094, 294, 472, 786, 412, 613, 12238, 6802, 9363, 19162, 13, 50942], "temperature": 0.0, "avg_logprob": -0.2504433599011651, "compression_ratio": 1.5522388059701493, "no_speech_prob": 0.04671522602438927}, {"id": 131, "seek": 57152, "start": 583.0799999999999, "end": 587.3199999999999, "text": " It's kind of a hackathon that we have every year.", "tokens": [50942, 467, 311, 733, 295, 257, 10339, 18660, 300, 321, 362, 633, 1064, 13, 51154], "temperature": 0.0, "avg_logprob": -0.2504433599011651, "compression_ratio": 1.5522388059701493, "no_speech_prob": 0.04671522602438927}, {"id": 132, "seek": 57152, "start": 587.3199999999999, "end": 589.72, "text": " It won the first prize.", "tokens": [51154, 467, 1582, 264, 700, 12818, 13, 51274], "temperature": 0.0, "avg_logprob": -0.2504433599011651, "compression_ratio": 1.5522388059701493, "no_speech_prob": 0.04671522602438927}, {"id": 133, "seek": 57152, "start": 589.72, "end": 597.48, "text": " So what it is is a Python script, and it targets the at scheduler, so the at scheduler on Linux", "tokens": [51274, 407, 437, 309, 307, 307, 257, 15329, 5755, 11, 293, 309, 12911, 264, 412, 12000, 260, 11, 370, 264, 412, 12000, 260, 322, 18734, 51662], "temperature": 0.0, "avg_logprob": -0.2504433599011651, "compression_ratio": 1.5522388059701493, "no_speech_prob": 0.04671522602438927}, {"id": 134, "seek": 59748, "start": 597.48, "end": 602.88, "text": " and BSDs, schedules the starting time of a job.", "tokens": [50364, 293, 363, 23969, 82, 11, 28078, 264, 2891, 565, 295, 257, 1691, 13, 50634], "temperature": 0.0, "avg_logprob": -0.18769966729796758, "compression_ratio": 1.6121495327102804, "no_speech_prob": 0.01466297172009945}, {"id": 135, "seek": 59748, "start": 602.88, "end": 608.52, "text": " So if you want a thing to start at 6 in the morning, it's at 0600, and it will start the", "tokens": [50634, 407, 498, 291, 528, 257, 551, 281, 722, 412, 1386, 294, 264, 2446, 11, 309, 311, 412, 1958, 15707, 11, 293, 309, 486, 722, 264, 50916], "temperature": 0.0, "avg_logprob": -0.18769966729796758, "compression_ratio": 1.6121495327102804, "no_speech_prob": 0.01466297172009945}, {"id": 136, "seek": 59748, "start": 608.52, "end": 610.52, "text": " job then.", "tokens": [50916, 1691, 550, 13, 51016], "temperature": 0.0, "avg_logprob": -0.18769966729796758, "compression_ratio": 1.6121495327102804, "no_speech_prob": 0.01466297172009945}, {"id": 137, "seek": 59748, "start": 610.52, "end": 616.5600000000001, "text": " So that's a very easy, simple way to integrate CATS into this scheduling system.", "tokens": [51016, 407, 300, 311, 257, 588, 1858, 11, 2199, 636, 281, 13365, 41192, 50, 666, 341, 29055, 1185, 13, 51318], "temperature": 0.0, "avg_logprob": -0.18769966729796758, "compression_ratio": 1.6121495327102804, "no_speech_prob": 0.01466297172009945}, {"id": 138, "seek": 59748, "start": 616.5600000000001, "end": 621.16, "text": " So that's what we started with.", "tokens": [51318, 407, 300, 311, 437, 321, 1409, 365, 13, 51548], "temperature": 0.0, "avg_logprob": -0.18769966729796758, "compression_ratio": 1.6121495327102804, "no_speech_prob": 0.01466297172009945}, {"id": 139, "seek": 59748, "start": 621.16, "end": 626.8000000000001, "text": " So the limitation is of course that if your HPC is running at full load all the time,", "tokens": [51548, 407, 264, 27432, 307, 295, 1164, 300, 498, 428, 12557, 34, 307, 2614, 412, 1577, 3677, 439, 264, 565, 11, 51830], "temperature": 0.0, "avg_logprob": -0.18769966729796758, "compression_ratio": 1.6121495327102804, "no_speech_prob": 0.01466297172009945}, {"id": 140, "seek": 62680, "start": 626.8, "end": 633.1999999999999, "text": " then it doesn't matter what you shift around because it will always be 100%.", "tokens": [50364, 550, 309, 1177, 380, 1871, 437, 291, 5513, 926, 570, 309, 486, 1009, 312, 2319, 6856, 50684], "temperature": 0.0, "avg_logprob": -0.2002834485924762, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.0650230273604393}, {"id": 141, "seek": 62680, "start": 633.1999999999999, "end": 639.04, "text": " So it's really meant more for computing systems that are not on all the time, so time shifting", "tokens": [50684, 407, 309, 311, 534, 4140, 544, 337, 15866, 3652, 300, 366, 406, 322, 439, 264, 565, 11, 370, 565, 17573, 50976], "temperature": 0.0, "avg_logprob": -0.2002834485924762, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.0650230273604393}, {"id": 142, "seek": 62680, "start": 639.04, "end": 640.52, "text": " will actually make a difference.", "tokens": [50976, 486, 767, 652, 257, 2649, 13, 51050], "temperature": 0.0, "avg_logprob": -0.2002834485924762, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.0650230273604393}, {"id": 143, "seek": 62680, "start": 640.52, "end": 643.88, "text": " Of course you'll need to know how long the job will take.", "tokens": [51050, 2720, 1164, 291, 603, 643, 281, 458, 577, 938, 264, 1691, 486, 747, 13, 51218], "temperature": 0.0, "avg_logprob": -0.2002834485924762, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.0650230273604393}, {"id": 144, "seek": 62680, "start": 643.88, "end": 647.5999999999999, "text": " Without that, this doesn't work at the moment.", "tokens": [51218, 9129, 300, 11, 341, 1177, 380, 589, 412, 264, 1623, 13, 51404], "temperature": 0.0, "avg_logprob": -0.2002834485924762, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.0650230273604393}, {"id": 145, "seek": 62680, "start": 647.5999999999999, "end": 651.4799999999999, "text": " If it's an HPC, then other users might be trying to run at the same moment, so how do", "tokens": [51404, 759, 309, 311, 364, 12557, 34, 11, 550, 661, 5022, 1062, 312, 1382, 281, 1190, 412, 264, 912, 1623, 11, 370, 577, 360, 51598], "temperature": 0.0, "avg_logprob": -0.2002834485924762, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.0650230273604393}, {"id": 146, "seek": 62680, "start": 651.4799999999999, "end": 653.7199999999999, "text": " you do that sort of resuscitation?", "tokens": [51598, 291, 360, 300, 1333, 295, 725, 32601, 4614, 30, 51710], "temperature": 0.0, "avg_logprob": -0.2002834485924762, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.0650230273604393}, {"id": 147, "seek": 65372, "start": 653.72, "end": 659.72, "text": " Currently, it only works in the UK because we're using the Carbon Intensity UK API.", "tokens": [50364, 19964, 11, 309, 787, 1985, 294, 264, 7051, 570, 321, 434, 1228, 264, 31453, 5681, 6859, 7051, 9362, 13, 50664], "temperature": 0.0, "avg_logprob": -0.2245396323826002, "compression_ratio": 1.5529953917050692, "no_speech_prob": 0.012373764999210835}, {"id": 148, "seek": 65372, "start": 659.72, "end": 664.5600000000001, "text": " Of course, we open to pull requests for other APIs.", "tokens": [50664, 2720, 1164, 11, 321, 1269, 281, 2235, 12475, 337, 661, 21445, 13, 50906], "temperature": 0.0, "avg_logprob": -0.2245396323826002, "compression_ratio": 1.5529953917050692, "no_speech_prob": 0.012373764999210835}, {"id": 149, "seek": 65372, "start": 664.5600000000001, "end": 669.9200000000001, "text": " If other countries have energy data, energy forecasting data, so far we have not found", "tokens": [50906, 759, 661, 3517, 362, 2281, 1412, 11, 2281, 44331, 1412, 11, 370, 1400, 321, 362, 406, 1352, 51174], "temperature": 0.0, "avg_logprob": -0.2245396323826002, "compression_ratio": 1.5529953917050692, "no_speech_prob": 0.012373764999210835}, {"id": 150, "seek": 65372, "start": 669.9200000000001, "end": 672.08, "text": " any free to use APIs.", "tokens": [51174, 604, 1737, 281, 764, 21445, 13, 51282], "temperature": 0.0, "avg_logprob": -0.2245396323826002, "compression_ratio": 1.5529953917050692, "no_speech_prob": 0.012373764999210835}, {"id": 151, "seek": 65372, "start": 672.08, "end": 675.8000000000001, "text": " So if you know, please let us know.", "tokens": [51282, 407, 498, 291, 458, 11, 1767, 718, 505, 458, 13, 51468], "temperature": 0.0, "avg_logprob": -0.2245396323826002, "compression_ratio": 1.5529953917050692, "no_speech_prob": 0.012373764999210835}, {"id": 152, "seek": 65372, "start": 675.8000000000001, "end": 679.36, "text": " And of course, this is not the only thing you should do.", "tokens": [51468, 400, 295, 1164, 11, 341, 307, 406, 264, 787, 551, 291, 820, 360, 13, 51646], "temperature": 0.0, "avg_logprob": -0.2245396323826002, "compression_ratio": 1.5529953917050692, "no_speech_prob": 0.012373764999210835}, {"id": 153, "seek": 67936, "start": 679.36, "end": 688.76, "text": " You can use cooling or there's a lot of carbon, embodied carbon in the manufacturing cost of", "tokens": [50364, 509, 393, 764, 14785, 420, 456, 311, 257, 688, 295, 5954, 11, 42046, 5954, 294, 264, 11096, 2063, 295, 50834], "temperature": 0.0, "avg_logprob": -0.20066046714782715, "compression_ratio": 1.602803738317757, "no_speech_prob": 0.09890102595090866}, {"id": 154, "seek": 67936, "start": 688.76, "end": 691.64, "text": " the server that things are running on.", "tokens": [50834, 264, 7154, 300, 721, 366, 2614, 322, 13, 50978], "temperature": 0.0, "avg_logprob": -0.20066046714782715, "compression_ratio": 1.602803738317757, "no_speech_prob": 0.09890102595090866}, {"id": 155, "seek": 67936, "start": 691.64, "end": 697.92, "text": " So that's probably why you have HPC refreshers because newer servers are much more efficient.", "tokens": [50978, 407, 300, 311, 1391, 983, 291, 362, 12557, 34, 15134, 433, 570, 17628, 15909, 366, 709, 544, 7148, 13, 51292], "temperature": 0.0, "avg_logprob": -0.20066046714782715, "compression_ratio": 1.602803738317757, "no_speech_prob": 0.09890102595090866}, {"id": 156, "seek": 67936, "start": 697.92, "end": 702.6800000000001, "text": " So there's a lot of considerations, but in terms of what you as a user can do, I think", "tokens": [51292, 407, 456, 311, 257, 688, 295, 24070, 11, 457, 294, 2115, 295, 437, 291, 382, 257, 4195, 393, 360, 11, 286, 519, 51530], "temperature": 0.0, "avg_logprob": -0.20066046714782715, "compression_ratio": 1.602803738317757, "no_speech_prob": 0.09890102595090866}, {"id": 157, "seek": 67936, "start": 702.6800000000001, "end": 706.48, "text": " this is a good place to start.", "tokens": [51530, 341, 307, 257, 665, 1081, 281, 722, 13, 51720], "temperature": 0.0, "avg_logprob": -0.20066046714782715, "compression_ratio": 1.602803738317757, "no_speech_prob": 0.09890102595090866}, {"id": 158, "seek": 70648, "start": 706.6, "end": 714.12, "text": " So the way to use CATS is, it's a Python script, so you run it as a module, give it a job duration,", "tokens": [50370, 407, 264, 636, 281, 764, 41192, 50, 307, 11, 309, 311, 257, 15329, 5755, 11, 370, 291, 1190, 309, 382, 257, 10088, 11, 976, 309, 257, 1691, 16365, 11, 50746], "temperature": 0.0, "avg_logprob": -0.2397897877824416, "compression_ratio": 1.5857740585774058, "no_speech_prob": 0.006131324917078018}, {"id": 159, "seek": 70648, "start": 714.12, "end": 715.12, "text": " give it a postcode.", "tokens": [50746, 976, 309, 257, 2183, 22332, 13, 50796], "temperature": 0.0, "avg_logprob": -0.2397897877824416, "compression_ratio": 1.5857740585774058, "no_speech_prob": 0.006131324917078018}, {"id": 160, "seek": 70648, "start": 715.12, "end": 717.84, "text": " The postcode is a proxy for the location.", "tokens": [50796, 440, 2183, 22332, 307, 257, 29690, 337, 264, 4914, 13, 50932], "temperature": 0.0, "avg_logprob": -0.2397897877824416, "compression_ratio": 1.5857740585774058, "no_speech_prob": 0.006131324917078018}, {"id": 161, "seek": 70648, "start": 717.84, "end": 723.36, "text": " And using this, it fetches data from the Carbon Intensity API and it calculates the optimal", "tokens": [50932, 400, 1228, 341, 11, 309, 15136, 3781, 1412, 490, 264, 31453, 5681, 6859, 9362, 293, 309, 4322, 1024, 264, 16252, 51208], "temperature": 0.0, "avg_logprob": -0.2397897877824416, "compression_ratio": 1.5857740585774058, "no_speech_prob": 0.006131324917078018}, {"id": 162, "seek": 70648, "start": 723.36, "end": 726.64, "text": " starting time for your job.", "tokens": [51208, 2891, 565, 337, 428, 1691, 13, 51372], "temperature": 0.0, "avg_logprob": -0.2397897877824416, "compression_ratio": 1.5857740585774058, "no_speech_prob": 0.006131324917078018}, {"id": 163, "seek": 70648, "start": 726.64, "end": 734.28, "text": " So we return data in a format that can be passed to AT and it also gives additional data in", "tokens": [51372, 407, 321, 2736, 1412, 294, 257, 7877, 300, 393, 312, 4678, 281, 8872, 293, 309, 611, 2709, 4497, 1412, 294, 51754], "temperature": 0.0, "avg_logprob": -0.2397897877824416, "compression_ratio": 1.5857740585774058, "no_speech_prob": 0.006131324917078018}, {"id": 164, "seek": 70648, "start": 734.28, "end": 735.28, "text": " JSON.", "tokens": [51754, 31828, 13, 51804], "temperature": 0.0, "avg_logprob": -0.2397897877824416, "compression_ratio": 1.5857740585774058, "no_speech_prob": 0.006131324917078018}, {"id": 165, "seek": 73528, "start": 736.28, "end": 742.36, "text": " So what the other feature of CATS is that it will try to inform the user about the carbon", "tokens": [50414, 407, 437, 264, 661, 4111, 295, 41192, 50, 307, 300, 309, 486, 853, 281, 1356, 264, 4195, 466, 264, 5954, 50718], "temperature": 0.0, "avg_logprob": -0.20824645401595474, "compression_ratio": 1.5598086124401913, "no_speech_prob": 0.0017704705242067575}, {"id": 166, "seek": 73528, "start": 742.36, "end": 748.4, "text": " savings that take place when they're offsetting the time.", "tokens": [50718, 13454, 300, 747, 1081, 562, 436, 434, 18687, 783, 264, 565, 13, 51020], "temperature": 0.0, "avg_logprob": -0.20824645401595474, "compression_ratio": 1.5598086124401913, "no_speech_prob": 0.0017704705242067575}, {"id": 167, "seek": 73528, "start": 748.4, "end": 755.8, "text": " So we do some estimates on how much carbon would be saved by using some year after specify", "tokens": [51020, 407, 321, 360, 512, 20561, 322, 577, 709, 5954, 576, 312, 6624, 538, 1228, 512, 1064, 934, 16500, 51390], "temperature": 0.0, "avg_logprob": -0.20824645401595474, "compression_ratio": 1.5598086124401913, "no_speech_prob": 0.0017704705242067575}, {"id": 168, "seek": 73528, "start": 755.8, "end": 762.64, "text": " configuration using like what kind of CPU or GPU you have, kind of power use efficiency", "tokens": [51390, 11694, 1228, 411, 437, 733, 295, 13199, 420, 18407, 291, 362, 11, 733, 295, 1347, 764, 10493, 51732], "temperature": 0.0, "avg_logprob": -0.20824645401595474, "compression_ratio": 1.5598086124401913, "no_speech_prob": 0.0017704705242067575}, {"id": 169, "seek": 76264, "start": 762.64, "end": 765.52, "text": " and thermal design power.", "tokens": [50364, 293, 15070, 1715, 1347, 13, 50508], "temperature": 0.0, "avg_logprob": -0.2586916755227482, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.01036602072417736}, {"id": 170, "seek": 76264, "start": 765.52, "end": 771.3199999999999, "text": " And using that, we have a simple formula that will calculate the amount of carbon that you", "tokens": [50508, 400, 1228, 300, 11, 321, 362, 257, 2199, 8513, 300, 486, 8873, 264, 2372, 295, 5954, 300, 291, 50798], "temperature": 0.0, "avg_logprob": -0.2586916755227482, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.01036602072417736}, {"id": 171, "seek": 76264, "start": 771.3199999999999, "end": 777.56, "text": " would have saved by running it in this time that CATS wants you to run it rather than", "tokens": [50798, 576, 362, 6624, 538, 2614, 309, 294, 341, 565, 300, 41192, 50, 2738, 291, 281, 1190, 309, 2831, 813, 51110], "temperature": 0.0, "avg_logprob": -0.2586916755227482, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.01036602072417736}, {"id": 172, "seek": 76264, "start": 777.56, "end": 778.56, "text": " will right now.", "tokens": [51110, 486, 558, 586, 13, 51160], "temperature": 0.0, "avg_logprob": -0.2586916755227482, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.01036602072417736}, {"id": 173, "seek": 76264, "start": 782.56, "end": 787.68, "text": " So this is a demo of CATS running.", "tokens": [51360, 407, 341, 307, 257, 10723, 295, 41192, 50, 2614, 13, 51616], "temperature": 0.0, "avg_logprob": -0.2586916755227482, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.01036602072417736}, {"id": 174, "seek": 78768, "start": 787.7199999999999, "end": 792.64, "text": " So we specify duration of 60 minutes.", "tokens": [50366, 407, 321, 16500, 16365, 295, 4060, 2077, 13, 50612], "temperature": 0.0, "avg_logprob": -0.3184623718261719, "compression_ratio": 1.2196969696969697, "no_speech_prob": 0.005308281164616346}, {"id": 175, "seek": 78768, "start": 792.64, "end": 796.76, "text": " And this is RT1, which is redding.", "tokens": [50612, 400, 341, 307, 21797, 16, 11, 597, 307, 2182, 3584, 13, 50818], "temperature": 0.0, "avg_logprob": -0.3184623718261719, "compression_ratio": 1.2196969696969697, "no_speech_prob": 0.005308281164616346}, {"id": 176, "seek": 78768, "start": 796.76, "end": 804.2399999999999, "text": " And it gives a time on 16th May, 1130.", "tokens": [50818, 400, 309, 2709, 257, 565, 322, 3165, 392, 1891, 11, 2975, 3446, 13, 51192], "temperature": 0.0, "avg_logprob": -0.3184623718261719, "compression_ratio": 1.2196969696969697, "no_speech_prob": 0.005308281164616346}, {"id": 177, "seek": 78768, "start": 804.2399999999999, "end": 816.4799999999999, "text": " And it also shows you the amount of carbon saved.", "tokens": [51192, 400, 309, 611, 3110, 291, 264, 2372, 295, 5954, 6624, 13, 51804], "temperature": 0.0, "avg_logprob": -0.3184623718261719, "compression_ratio": 1.2196969696969697, "no_speech_prob": 0.005308281164616346}, {"id": 178, "seek": 81648, "start": 816.48, "end": 822.6, "text": " And that scheduled, so this is a last bit, you can run what you want as long as it takes", "tokens": [50364, 400, 300, 15678, 11, 370, 341, 307, 257, 1036, 857, 11, 291, 393, 1190, 437, 291, 528, 382, 938, 382, 309, 2516, 50670], "temperature": 0.0, "avg_logprob": -0.36795428179312445, "compression_ratio": 1.3532934131736527, "no_speech_prob": 0.010702735744416714}, {"id": 179, "seek": 81648, "start": 822.6, "end": 823.8000000000001, "text": " around 60 minutes.", "tokens": [50670, 926, 4060, 2077, 13, 50730], "temperature": 0.0, "avg_logprob": -0.36795428179312445, "compression_ratio": 1.3532934131736527, "no_speech_prob": 0.010702735744416714}, {"id": 180, "seek": 81648, "start": 832.2, "end": 834.64, "text": " Okay, that's it.", "tokens": [51150, 1033, 11, 300, 311, 309, 13, 51272], "temperature": 0.0, "avg_logprob": -0.36795428179312445, "compression_ratio": 1.3532934131736527, "no_speech_prob": 0.010702735744416714}, {"id": 181, "seek": 81648, "start": 834.64, "end": 842.76, "text": " So if you have any questions, please email us or put up an issue in our GitHub.", "tokens": [51272, 407, 498, 291, 362, 604, 1651, 11, 1767, 3796, 505, 420, 829, 493, 364, 2734, 294, 527, 23331, 13, 51678], "temperature": 0.0, "avg_logprob": -0.36795428179312445, "compression_ratio": 1.3532934131736527, "no_speech_prob": 0.010702735744416714}, {"id": 182, "seek": 81648, "start": 842.76, "end": 846.32, "text": " And I skip the slide.", "tokens": [51678, 400, 286, 10023, 264, 4137, 13, 51856], "temperature": 0.0, "avg_logprob": -0.36795428179312445, "compression_ratio": 1.3532934131736527, "no_speech_prob": 0.010702735744416714}, {"id": 183, "seek": 84632, "start": 847.1600000000001, "end": 852.0400000000001, "text": " So what we're doing is we are going to release vision on this month.", "tokens": [50406, 407, 437, 321, 434, 884, 307, 321, 366, 516, 281, 4374, 5201, 322, 341, 1618, 13, 50650], "temperature": 0.0, "avg_logprob": -0.3006141590622236, "compression_ratio": 1.7644444444444445, "no_speech_prob": 0.1723041981458664}, {"id": 184, "seek": 84632, "start": 852.0400000000001, "end": 853.6, "text": " We're cleaning the common line options.", "tokens": [50650, 492, 434, 8924, 264, 2689, 1622, 3956, 13, 50728], "temperature": 0.0, "avg_logprob": -0.3006141590622236, "compression_ratio": 1.7644444444444445, "no_speech_prob": 0.1723041981458664}, {"id": 185, "seek": 84632, "start": 853.6, "end": 859.5600000000001, "text": " So right now we only support AT, but we also want to support SBAT, which is the Slurm command", "tokens": [50728, 407, 558, 586, 321, 787, 1406, 8872, 11, 457, 321, 611, 528, 281, 1406, 26944, 2218, 11, 597, 307, 264, 6187, 26717, 5622, 51026], "temperature": 0.0, "avg_logprob": -0.3006141590622236, "compression_ratio": 1.7644444444444445, "no_speech_prob": 0.1723041981458664}, {"id": 186, "seek": 84632, "start": 859.5600000000001, "end": 861.88, "text": " scheduler similar to AT.", "tokens": [51026, 12000, 260, 2531, 281, 8872, 13, 51142], "temperature": 0.0, "avg_logprob": -0.3006141590622236, "compression_ratio": 1.7644444444444445, "no_speech_prob": 0.1723041981458664}, {"id": 187, "seek": 84632, "start": 861.88, "end": 868.12, "text": " And so we'll clean on the command line options and we'll release a vision.", "tokens": [51142, 400, 370, 321, 603, 2541, 322, 264, 5622, 1622, 3956, 293, 321, 603, 4374, 257, 5201, 13, 51454], "temperature": 0.0, "avg_logprob": -0.3006141590622236, "compression_ratio": 1.7644444444444445, "no_speech_prob": 0.1723041981458664}, {"id": 188, "seek": 84632, "start": 868.12, "end": 873.0, "text": " But of course, going forward, we want to integrate with Slurm, which is the main scheduler for", "tokens": [51454, 583, 295, 1164, 11, 516, 2128, 11, 321, 528, 281, 13365, 365, 6187, 26717, 11, 597, 307, 264, 2135, 12000, 260, 337, 51698], "temperature": 0.0, "avg_logprob": -0.3006141590622236, "compression_ratio": 1.7644444444444445, "no_speech_prob": 0.1723041981458664}, {"id": 189, "seek": 87300, "start": 873.0, "end": 874.0, "text": " ACs.", "tokens": [50364, 8157, 82, 13, 50414], "temperature": 0.0, "avg_logprob": -0.2522885249211238, "compression_ratio": 1.7351778656126482, "no_speech_prob": 0.09151680022478104}, {"id": 190, "seek": 87300, "start": 874.0, "end": 879.52, "text": " And the simplest method, of course, is SBAT, so the start time, the other option is green", "tokens": [50414, 400, 264, 22811, 3170, 11, 295, 1164, 11, 307, 26944, 2218, 11, 370, 264, 722, 565, 11, 264, 661, 3614, 307, 3092, 50690], "temperature": 0.0, "avg_logprob": -0.2522885249211238, "compression_ratio": 1.7351778656126482, "no_speech_prob": 0.09151680022478104}, {"id": 191, "seek": 87300, "start": 879.52, "end": 884.32, "text": " cues where you have cues that don't run 100% because again, with running 100%, you don't", "tokens": [50690, 32192, 689, 291, 362, 32192, 300, 500, 380, 1190, 2319, 4, 570, 797, 11, 365, 2614, 2319, 8923, 291, 500, 380, 50930], "temperature": 0.0, "avg_logprob": -0.2522885249211238, "compression_ratio": 1.7351778656126482, "no_speech_prob": 0.09151680022478104}, {"id": 192, "seek": 87300, "start": 884.32, "end": 888.12, "text": " get the benefits of cats.", "tokens": [50930, 483, 264, 5311, 295, 11111, 13, 51120], "temperature": 0.0, "avg_logprob": -0.2522885249211238, "compression_ratio": 1.7351778656126482, "no_speech_prob": 0.09151680022478104}, {"id": 193, "seek": 87300, "start": 888.12, "end": 892.52, "text": " So we have green cues which don't run 100% and also integrating carbon accounting.", "tokens": [51120, 407, 321, 362, 3092, 32192, 597, 500, 380, 1190, 2319, 4, 293, 611, 26889, 5954, 19163, 13, 51340], "temperature": 0.0, "avg_logprob": -0.2522885249211238, "compression_ratio": 1.7351778656126482, "no_speech_prob": 0.09151680022478104}, {"id": 194, "seek": 87300, "start": 892.52, "end": 899.08, "text": " So Slurm has a plugin that allows you to look at the total power used in your job.", "tokens": [51340, 407, 6187, 26717, 575, 257, 23407, 300, 4045, 291, 281, 574, 412, 264, 3217, 1347, 1143, 294, 428, 1691, 13, 51668], "temperature": 0.0, "avg_logprob": -0.2522885249211238, "compression_ratio": 1.7351778656126482, "no_speech_prob": 0.09151680022478104}, {"id": 195, "seek": 87300, "start": 899.08, "end": 902.56, "text": " So way to integrate carbon accounting into that would be great.", "tokens": [51668, 407, 636, 281, 13365, 5954, 19163, 666, 300, 576, 312, 869, 13, 51842], "temperature": 0.0, "avg_logprob": -0.2522885249211238, "compression_ratio": 1.7351778656126482, "no_speech_prob": 0.09151680022478104}, {"id": 196, "seek": 90256, "start": 902.92, "end": 907.88, "text": " That would require rewrites in C because Slurm plugins are in C.", "tokens": [50382, 663, 576, 3651, 319, 86, 30931, 294, 383, 570, 6187, 26717, 33759, 366, 294, 383, 13, 50630], "temperature": 0.0, "avg_logprob": -0.3186892472304307, "compression_ratio": 1.4702970297029703, "no_speech_prob": 0.005716286599636078}, {"id": 197, "seek": 90256, "start": 907.88, "end": 912.56, "text": " And we have got funding from the Software Sustainability Institute for a few months of developer time.", "tokens": [50630, 400, 321, 362, 658, 6137, 490, 264, 27428, 34407, 2310, 9446, 337, 257, 1326, 2493, 295, 10754, 565, 13, 50864], "temperature": 0.0, "avg_logprob": -0.3186892472304307, "compression_ratio": 1.4702970297029703, "no_speech_prob": 0.005716286599636078}, {"id": 198, "seek": 90256, "start": 912.56, "end": 920.4799999999999, "text": " So we're looking forward to making great progress and have something more polished soon.", "tokens": [50864, 407, 321, 434, 1237, 2128, 281, 1455, 869, 4205, 293, 362, 746, 544, 29079, 2321, 13, 51260], "temperature": 0.0, "avg_logprob": -0.3186892472304307, "compression_ratio": 1.4702970297029703, "no_speech_prob": 0.005716286599636078}, {"id": 199, "seek": 90256, "start": 920.4799999999999, "end": 923.5999999999999, "text": " And yeah.", "tokens": [51260, 400, 1338, 13, 51416], "temperature": 0.0, "avg_logprob": -0.3186892472304307, "compression_ratio": 1.4702970297029703, "no_speech_prob": 0.005716286599636078}, {"id": 200, "seek": 90256, "start": 923.5999999999999, "end": 925.5999999999999, "text": " And now, thank you.", "tokens": [51416, 400, 586, 11, 1309, 291, 13, 51516], "temperature": 0.0, "avg_logprob": -0.3186892472304307, "compression_ratio": 1.4702970297029703, "no_speech_prob": 0.005716286599636078}, {"id": 201, "seek": 90256, "start": 925.5999999999999, "end": 928.5999999999999, "text": " Thank you.", "tokens": [51516, 1044, 291, 13, 51666], "temperature": 0.0, "avg_logprob": -0.3186892472304307, "compression_ratio": 1.4702970297029703, "no_speech_prob": 0.005716286599636078}, {"id": 202, "seek": 92860, "start": 928.64, "end": 935.52, "text": " Thank you, Kavain and Abish.", "tokens": [50366, 1044, 291, 11, 591, 706, 491, 293, 2847, 742, 13, 50710], "temperature": 0.0, "avg_logprob": -0.38625681677529977, "compression_ratio": 1.4512820512820512, "no_speech_prob": 0.015638796612620354}, {"id": 203, "seek": 92860, "start": 935.52, "end": 937.52, "text": " We have time for some questions.", "tokens": [50710, 492, 362, 565, 337, 512, 1651, 13, 50810], "temperature": 0.0, "avg_logprob": -0.38625681677529977, "compression_ratio": 1.4512820512820512, "no_speech_prob": 0.015638796612620354}, {"id": 204, "seek": 92860, "start": 937.52, "end": 938.52, "text": " Yes.", "tokens": [50810, 1079, 13, 50860], "temperature": 0.0, "avg_logprob": -0.38625681677529977, "compression_ratio": 1.4512820512820512, "no_speech_prob": 0.015638796612620354}, {"id": 205, "seek": 92860, "start": 938.52, "end": 941.96, "text": " Thank you for your last presentation.", "tokens": [50860, 1044, 291, 337, 428, 1036, 5860, 13, 51032], "temperature": 0.0, "avg_logprob": -0.38625681677529977, "compression_ratio": 1.4512820512820512, "no_speech_prob": 0.015638796612620354}, {"id": 206, "seek": 92860, "start": 941.96, "end": 947.08, "text": " But my question is how often clusters are not load on 100%?", "tokens": [51032, 583, 452, 1168, 307, 577, 2049, 23313, 366, 406, 3677, 322, 2319, 4, 30, 51288], "temperature": 0.0, "avg_logprob": -0.38625681677529977, "compression_ratio": 1.4512820512820512, "no_speech_prob": 0.015638796612620354}, {"id": 207, "seek": 92860, "start": 947.08, "end": 948.08, "text": " Yes.", "tokens": [51288, 1079, 13, 51338], "temperature": 0.0, "avg_logprob": -0.38625681677529977, "compression_ratio": 1.4512820512820512, "no_speech_prob": 0.015638796612620354}, {"id": 208, "seek": 92860, "start": 948.08, "end": 950.6, "text": " I mean, that's a very good question.", "tokens": [51338, 286, 914, 11, 300, 311, 257, 588, 665, 1168, 13, 51464], "temperature": 0.0, "avg_logprob": -0.38625681677529977, "compression_ratio": 1.4512820512820512, "no_speech_prob": 0.015638796612620354}, {"id": 209, "seek": 92860, "start": 950.6, "end": 956.2, "text": " So I think we need to think about how these things will work moving forward.", "tokens": [51464, 407, 286, 519, 321, 643, 281, 519, 466, 577, 613, 721, 486, 589, 2684, 2128, 13, 51744], "temperature": 0.0, "avg_logprob": -0.38625681677529977, "compression_ratio": 1.4512820512820512, "no_speech_prob": 0.015638796612620354}, {"id": 210, "seek": 95620, "start": 956.2, "end": 961.72, "text": " So we are talking with HBCs and I think this is more proof of concept and prototype to", "tokens": [50364, 407, 321, 366, 1417, 365, 389, 7869, 82, 293, 286, 519, 341, 307, 544, 8177, 295, 3410, 293, 19475, 281, 50640], "temperature": 0.0, "avg_logprob": -0.20681063334147134, "compression_ratio": 1.5951417004048583, "no_speech_prob": 0.018119685351848602}, {"id": 211, "seek": 95620, "start": 961.72, "end": 965.48, "text": " look at how these carbon footprints might be achieved.", "tokens": [50640, 574, 412, 577, 613, 5954, 45715, 1062, 312, 11042, 13, 50828], "temperature": 0.0, "avg_logprob": -0.20681063334147134, "compression_ratio": 1.5951417004048583, "no_speech_prob": 0.018119685351848602}, {"id": 212, "seek": 95620, "start": 965.48, "end": 971.0, "text": " Obviously, if you do keep things 100% on time, then there is no point.", "tokens": [50828, 7580, 11, 498, 291, 360, 1066, 721, 2319, 4, 322, 565, 11, 550, 456, 307, 572, 935, 13, 51104], "temperature": 0.0, "avg_logprob": -0.20681063334147134, "compression_ratio": 1.5951417004048583, "no_speech_prob": 0.018119685351848602}, {"id": 213, "seek": 95620, "start": 971.0, "end": 978.6800000000001, "text": " But I think if we do move to a future where we don't move to a net zero grid soon, then", "tokens": [51104, 583, 286, 519, 498, 321, 360, 1286, 281, 257, 2027, 689, 321, 500, 380, 1286, 281, 257, 2533, 4018, 10748, 2321, 11, 550, 51488], "temperature": 0.0, "avg_logprob": -0.20681063334147134, "compression_ratio": 1.5951417004048583, "no_speech_prob": 0.018119685351848602}, {"id": 214, "seek": 95620, "start": 978.6800000000001, "end": 984.1600000000001, "text": " we might see funders asking for carbon budgets or government putting carbon budgets just like", "tokens": [51488, 321, 1062, 536, 2374, 433, 3365, 337, 5954, 26708, 420, 2463, 3372, 5954, 26708, 445, 411, 51762], "temperature": 0.0, "avg_logprob": -0.20681063334147134, "compression_ratio": 1.5951417004048583, "no_speech_prob": 0.018119685351848602}, {"id": 215, "seek": 98416, "start": 984.16, "end": 985.6, "text": " your financial budget.", "tokens": [50364, 428, 4669, 4706, 13, 50436], "temperature": 0.0, "avg_logprob": -0.3189514681824252, "compression_ratio": 1.6045627376425855, "no_speech_prob": 0.11925724893808365}, {"id": 216, "seek": 98416, "start": 985.6, "end": 986.8399999999999, "text": " And then you do want to see this.", "tokens": [50436, 400, 550, 291, 360, 528, 281, 536, 341, 13, 50498], "temperature": 0.0, "avg_logprob": -0.3189514681824252, "compression_ratio": 1.6045627376425855, "no_speech_prob": 0.11925724893808365}, {"id": 217, "seek": 98416, "start": 986.8399999999999, "end": 990.88, "text": " So it's more like playing the groundwork for what might come next and not for the current", "tokens": [50498, 407, 309, 311, 544, 411, 2433, 264, 2727, 1902, 337, 437, 1062, 808, 958, 293, 406, 337, 264, 2190, 50700], "temperature": 0.0, "avg_logprob": -0.3189514681824252, "compression_ratio": 1.6045627376425855, "no_speech_prob": 0.11925724893808365}, {"id": 218, "seek": 98416, "start": 990.88, "end": 992.88, "text": " generation of HBCs.", "tokens": [50700, 5125, 295, 389, 7869, 82, 13, 50800], "temperature": 0.0, "avg_logprob": -0.3189514681824252, "compression_ratio": 1.6045627376425855, "no_speech_prob": 0.11925724893808365}, {"id": 219, "seek": 98416, "start": 992.88, "end": 994.88, "text": " Any more questions?", "tokens": [50800, 2639, 544, 1651, 30, 50900], "temperature": 0.0, "avg_logprob": -0.3189514681824252, "compression_ratio": 1.6045627376425855, "no_speech_prob": 0.11925724893808365}, {"id": 220, "seek": 98416, "start": 994.88, "end": 995.88, "text": " Sorry.", "tokens": [50900, 4919, 13, 50950], "temperature": 0.0, "avg_logprob": -0.3189514681824252, "compression_ratio": 1.6045627376425855, "no_speech_prob": 0.11925724893808365}, {"id": 221, "seek": 98416, "start": 995.88, "end": 998.88, "text": " I wasn't looking over there.", "tokens": [50950, 286, 2067, 380, 1237, 670, 456, 13, 51100], "temperature": 0.0, "avg_logprob": -0.3189514681824252, "compression_ratio": 1.6045627376425855, "no_speech_prob": 0.11925724893808365}, {"id": 222, "seek": 98416, "start": 998.88, "end": 1003.56, "text": " Thank you very much.", "tokens": [51100, 1044, 291, 588, 709, 13, 51334], "temperature": 0.0, "avg_logprob": -0.3189514681824252, "compression_ratio": 1.6045627376425855, "no_speech_prob": 0.11925724893808365}, {"id": 223, "seek": 98416, "start": 1003.56, "end": 1007.6, "text": " Couldn't you use also energy prices like energy stock prices for forecasting?", "tokens": [51334, 35800, 380, 291, 764, 611, 2281, 7901, 411, 2281, 4127, 7901, 337, 44331, 30, 51536], "temperature": 0.0, "avg_logprob": -0.3189514681824252, "compression_ratio": 1.6045627376425855, "no_speech_prob": 0.11925724893808365}, {"id": 224, "seek": 98416, "start": 1007.6, "end": 1011.3199999999999, "text": " Are they usually at least in Germany or lower when there's more renewable energy in the", "tokens": [51536, 2014, 436, 2673, 412, 1935, 294, 7244, 420, 3126, 562, 456, 311, 544, 20938, 2281, 294, 264, 51722], "temperature": 0.0, "avg_logprob": -0.3189514681824252, "compression_ratio": 1.6045627376425855, "no_speech_prob": 0.11925724893808365}, {"id": 225, "seek": 98416, "start": 1011.3199999999999, "end": 1012.3199999999999, "text": " net?", "tokens": [51722, 2533, 30, 51772], "temperature": 0.0, "avg_logprob": -0.3189514681824252, "compression_ratio": 1.6045627376425855, "no_speech_prob": 0.11925724893808365}, {"id": 226, "seek": 98416, "start": 1012.3199999999999, "end": 1013.3199999999999, "text": " Thanks.", "tokens": [51772, 2561, 13, 51822], "temperature": 0.0, "avg_logprob": -0.3189514681824252, "compression_ratio": 1.6045627376425855, "no_speech_prob": 0.11925724893808365}, {"id": 227, "seek": 101332, "start": 1013.48, "end": 1016.88, "text": " Yeah, that's a good point that we'll look into.", "tokens": [50372, 865, 11, 300, 311, 257, 665, 935, 300, 321, 603, 574, 666, 13, 50542], "temperature": 0.0, "avg_logprob": -0.42935663588503575, "compression_ratio": 1.4744186046511627, "no_speech_prob": 0.032252587378025055}, {"id": 228, "seek": 101332, "start": 1016.88, "end": 1019.84, "text": " A good place to start with is to correlate, I guess, energy prices.", "tokens": [50542, 316, 665, 1081, 281, 722, 365, 307, 281, 48742, 11, 286, 2041, 11, 2281, 7901, 13, 50690], "temperature": 0.0, "avg_logprob": -0.42935663588503575, "compression_ratio": 1.4744186046511627, "no_speech_prob": 0.032252587378025055}, {"id": 229, "seek": 101332, "start": 1019.84, "end": 1026.1200000000001, "text": " Yeah, yeah, we'll do the care and look at carbon intensity.", "tokens": [50690, 865, 11, 1338, 11, 321, 603, 360, 264, 1127, 293, 574, 412, 5954, 13749, 13, 51004], "temperature": 0.0, "avg_logprob": -0.42935663588503575, "compression_ratio": 1.4744186046511627, "no_speech_prob": 0.032252587378025055}, {"id": 230, "seek": 101332, "start": 1026.1200000000001, "end": 1029.1200000000001, "text": " Thank you.", "tokens": [51004, 1044, 291, 13, 51154], "temperature": 0.0, "avg_logprob": -0.42935663588503575, "compression_ratio": 1.4744186046511627, "no_speech_prob": 0.032252587378025055}, {"id": 231, "seek": 101332, "start": 1029.1200000000001, "end": 1033.96, "text": " Hi.", "tokens": [51154, 2421, 13, 51396], "temperature": 0.0, "avg_logprob": -0.42935663588503575, "compression_ratio": 1.4744186046511627, "no_speech_prob": 0.032252587378025055}, {"id": 232, "seek": 101332, "start": 1033.96, "end": 1040.76, "text": " I don't want to be Dell specific, but there's a web based tool from Dell called EIPT, Enterprise", "tokens": [51396, 286, 500, 380, 528, 281, 312, 33319, 2685, 11, 457, 456, 311, 257, 3670, 2361, 2290, 490, 33319, 1219, 462, 9139, 51, 11, 26696, 51736], "temperature": 0.0, "avg_logprob": -0.42935663588503575, "compression_ratio": 1.4744186046511627, "no_speech_prob": 0.032252587378025055}, {"id": 233, "seek": 101332, "start": 1040.76, "end": 1041.96, "text": " Infrastructure Planning Tool.", "tokens": [51736, 38425, 2885, 29308, 15934, 13, 51796], "temperature": 0.0, "avg_logprob": -0.42935663588503575, "compression_ratio": 1.4744186046511627, "no_speech_prob": 0.032252587378025055}, {"id": 234, "seek": 104196, "start": 1042.0, "end": 1048.72, "text": " You can configure servers with your particular build and you get their CO2 and power usage", "tokens": [50366, 509, 393, 22162, 15909, 365, 428, 1729, 1322, 293, 291, 483, 641, 3002, 17, 293, 1347, 14924, 50702], "temperature": 0.0, "avg_logprob": -0.18819859263661143, "compression_ratio": 1.560483870967742, "no_speech_prob": 0.03820652514696121}, {"id": 235, "seek": 104196, "start": 1048.72, "end": 1052.72, "text": " for various workloads, computational memory intensive and idle.", "tokens": [50702, 337, 3683, 32452, 11, 28270, 4675, 18957, 293, 30650, 13, 50902], "temperature": 0.0, "avg_logprob": -0.18819859263661143, "compression_ratio": 1.560483870967742, "no_speech_prob": 0.03820652514696121}, {"id": 236, "seek": 104196, "start": 1052.72, "end": 1057.6000000000001, "text": " And also Dell have a plugin for their IDRAX called Power Manager.", "tokens": [50902, 400, 611, 33319, 362, 257, 23407, 337, 641, 7348, 3750, 55, 1219, 7086, 13821, 13, 51146], "temperature": 0.0, "avg_logprob": -0.18819859263661143, "compression_ratio": 1.560483870967742, "no_speech_prob": 0.03820652514696121}, {"id": 237, "seek": 104196, "start": 1057.6000000000001, "end": 1065.68, "text": " You can take a rack or a group of workstations servers and turn down the energy capping dynamically.", "tokens": [51146, 509, 393, 747, 257, 14788, 420, 257, 1594, 295, 589, 372, 763, 15909, 293, 1261, 760, 264, 2281, 1335, 3759, 43492, 13, 51550], "temperature": 0.0, "avg_logprob": -0.18819859263661143, "compression_ratio": 1.560483870967742, "no_speech_prob": 0.03820652514696121}, {"id": 238, "seek": 104196, "start": 1065.68, "end": 1069.32, "text": " And that also works for Fujitsu and HPE servers for other brands.", "tokens": [51550, 400, 300, 611, 1985, 337, 43915, 35711, 293, 389, 5208, 15909, 337, 661, 11324, 13, 51732], "temperature": 0.0, "avg_logprob": -0.18819859263661143, "compression_ratio": 1.560483870967742, "no_speech_prob": 0.03820652514696121}, {"id": 239, "seek": 106932, "start": 1069.32, "end": 1073.9199999999998, "text": " I wonder if you would like to extend your work into that rather than scheduling the", "tokens": [50364, 286, 2441, 498, 291, 576, 411, 281, 10101, 428, 589, 666, 300, 2831, 813, 29055, 264, 50594], "temperature": 0.0, "avg_logprob": -0.2956079969219133, "compression_ratio": 1.6556016597510372, "no_speech_prob": 0.005316730588674545}, {"id": 240, "seek": 106932, "start": 1073.9199999999998, "end": 1078.2, "text": " jobs to turn down the power cap dynamically.", "tokens": [50594, 4782, 281, 1261, 760, 264, 1347, 1410, 43492, 13, 50808], "temperature": 0.0, "avg_logprob": -0.2956079969219133, "compression_ratio": 1.6556016597510372, "no_speech_prob": 0.005316730588674545}, {"id": 241, "seek": 106932, "start": 1078.2, "end": 1079.2, "text": " That'd be quite possible.", "tokens": [50808, 663, 1116, 312, 1596, 1944, 13, 50858], "temperature": 0.0, "avg_logprob": -0.2956079969219133, "compression_ratio": 1.6556016597510372, "no_speech_prob": 0.005316730588674545}, {"id": 242, "seek": 106932, "start": 1079.2, "end": 1080.2, "text": " Thanks.", "tokens": [50858, 2561, 13, 50908], "temperature": 0.0, "avg_logprob": -0.2956079969219133, "compression_ratio": 1.6556016597510372, "no_speech_prob": 0.005316730588674545}, {"id": 243, "seek": 106932, "start": 1080.2, "end": 1088.08, "text": " Yeah, I was at a word that there was a carbon accounting plugin for Slurm already.", "tokens": [50908, 865, 11, 286, 390, 412, 257, 1349, 300, 456, 390, 257, 5954, 19163, 23407, 337, 6187, 26717, 1217, 13, 51302], "temperature": 0.0, "avg_logprob": -0.2956079969219133, "compression_ratio": 1.6556016597510372, "no_speech_prob": 0.005316730588674545}, {"id": 244, "seek": 106932, "start": 1088.08, "end": 1093.32, "text": " So yes, ideally we have something that goes into Slurm and does the carbon accounting", "tokens": [51302, 407, 2086, 11, 22915, 321, 362, 746, 300, 1709, 666, 6187, 26717, 293, 775, 264, 5954, 19163, 51564], "temperature": 0.0, "avg_logprob": -0.2956079969219133, "compression_ratio": 1.6556016597510372, "no_speech_prob": 0.005316730588674545}, {"id": 245, "seek": 106932, "start": 1093.32, "end": 1095.84, "text": " rather than having user-shadow jobs.", "tokens": [51564, 2831, 813, 1419, 4195, 12, 2716, 11528, 4782, 13, 51690], "temperature": 0.0, "avg_logprob": -0.2956079969219133, "compression_ratio": 1.6556016597510372, "no_speech_prob": 0.005316730588674545}, {"id": 246, "seek": 106932, "start": 1095.84, "end": 1097.52, "text": " That's definitely not optimal.", "tokens": [51690, 663, 311, 2138, 406, 16252, 13, 51774], "temperature": 0.0, "avg_logprob": -0.2956079969219133, "compression_ratio": 1.6556016597510372, "no_speech_prob": 0.005316730588674545}, {"id": 247, "seek": 109752, "start": 1097.52, "end": 1098.52, "text": " So yeah, thanks.", "tokens": [50364, 407, 1338, 11, 3231, 13, 50414], "temperature": 0.0, "avg_logprob": -0.31344745033665705, "compression_ratio": 1.7767441860465116, "no_speech_prob": 0.00697353994473815}, {"id": 248, "seek": 109752, "start": 1098.52, "end": 1099.52, "text": " We'll look into that.", "tokens": [50414, 492, 603, 574, 666, 300, 13, 50464], "temperature": 0.0, "avg_logprob": -0.31344745033665705, "compression_ratio": 1.7767441860465116, "no_speech_prob": 0.00697353994473815}, {"id": 249, "seek": 109752, "start": 1099.52, "end": 1102.52, "text": " Any more questions?", "tokens": [50464, 2639, 544, 1651, 30, 50614], "temperature": 0.0, "avg_logprob": -0.31344745033665705, "compression_ratio": 1.7767441860465116, "no_speech_prob": 0.00697353994473815}, {"id": 250, "seek": 109752, "start": 1102.52, "end": 1103.52, "text": " Sorry.", "tokens": [50614, 4919, 13, 50664], "temperature": 0.0, "avg_logprob": -0.31344745033665705, "compression_ratio": 1.7767441860465116, "no_speech_prob": 0.00697353994473815}, {"id": 251, "seek": 109752, "start": 1103.52, "end": 1108.04, "text": " Are you also planning to integrate this into HD Condor?", "tokens": [50664, 2014, 291, 611, 5038, 281, 13365, 341, 666, 12149, 21793, 284, 30, 50890], "temperature": 0.0, "avg_logprob": -0.31344745033665705, "compression_ratio": 1.7767441860465116, "no_speech_prob": 0.00697353994473815}, {"id": 252, "seek": 109752, "start": 1108.04, "end": 1110.04, "text": " Sorry, could you repeat?", "tokens": [50890, 4919, 11, 727, 291, 7149, 30, 50990], "temperature": 0.0, "avg_logprob": -0.31344745033665705, "compression_ratio": 1.7767441860465116, "no_speech_prob": 0.00697353994473815}, {"id": 253, "seek": 109752, "start": 1110.04, "end": 1113.8, "text": " Are you also planning to integrate this into HD Condor?", "tokens": [50990, 2014, 291, 611, 5038, 281, 13365, 341, 666, 12149, 21793, 284, 30, 51178], "temperature": 0.0, "avg_logprob": -0.31344745033665705, "compression_ratio": 1.7767441860465116, "no_speech_prob": 0.00697353994473815}, {"id": 254, "seek": 109752, "start": 1113.8, "end": 1118.52, "text": " It's another scheduling software?", "tokens": [51178, 467, 311, 1071, 29055, 4722, 30, 51414], "temperature": 0.0, "avg_logprob": -0.31344745033665705, "compression_ratio": 1.7767441860465116, "no_speech_prob": 0.00697353994473815}, {"id": 255, "seek": 109752, "start": 1118.52, "end": 1119.52, "text": " Not at the moment.", "tokens": [51414, 1726, 412, 264, 1623, 13, 51464], "temperature": 0.0, "avg_logprob": -0.31344745033665705, "compression_ratio": 1.7767441860465116, "no_speech_prob": 0.00697353994473815}, {"id": 256, "seek": 109752, "start": 1119.52, "end": 1123.2, "text": " At the moment we are focusing on Slurm, but once we have got something there we'll focus", "tokens": [51464, 1711, 264, 1623, 321, 366, 8416, 322, 6187, 26717, 11, 457, 1564, 321, 362, 658, 746, 456, 321, 603, 1879, 51648], "temperature": 0.0, "avg_logprob": -0.31344745033665705, "compression_ratio": 1.7767441860465116, "no_speech_prob": 0.00697353994473815}, {"id": 257, "seek": 109752, "start": 1123.2, "end": 1124.2, "text": " on other schedulers.", "tokens": [51648, 322, 661, 12000, 433, 13, 51698], "temperature": 0.0, "avg_logprob": -0.31344745033665705, "compression_ratio": 1.7767441860465116, "no_speech_prob": 0.00697353994473815}, {"id": 258, "seek": 109752, "start": 1124.2, "end": 1125.2, "text": " Okay, thank you.", "tokens": [51698, 1033, 11, 1309, 291, 13, 51748], "temperature": 0.0, "avg_logprob": -0.31344745033665705, "compression_ratio": 1.7767441860465116, "no_speech_prob": 0.00697353994473815}, {"id": 259, "seek": 112520, "start": 1125.2, "end": 1126.2, "text": " Hi there.", "tokens": [50364, 2421, 456, 13, 50414], "temperature": 0.0, "avg_logprob": -0.28649974691456764, "compression_ratio": 1.5528846153846154, "no_speech_prob": 0.06448152661323547}, {"id": 260, "seek": 112520, "start": 1126.2, "end": 1134.32, "text": " First of all, love it.", "tokens": [50414, 2386, 295, 439, 11, 959, 309, 13, 50820], "temperature": 0.0, "avg_logprob": -0.28649974691456764, "compression_ratio": 1.5528846153846154, "no_speech_prob": 0.06448152661323547}, {"id": 261, "seek": 112520, "start": 1134.32, "end": 1135.92, "text": " So thanks very much for the talk.", "tokens": [50820, 407, 3231, 588, 709, 337, 264, 751, 13, 50900], "temperature": 0.0, "avg_logprob": -0.28649974691456764, "compression_ratio": 1.5528846153846154, "no_speech_prob": 0.06448152661323547}, {"id": 262, "seek": 112520, "start": 1135.92, "end": 1140.3600000000001, "text": " I'm looking forward to version one being released just to throw another thing out there that", "tokens": [50900, 286, 478, 1237, 2128, 281, 3037, 472, 885, 4736, 445, 281, 3507, 1071, 551, 484, 456, 300, 51122], "temperature": 0.0, "avg_logprob": -0.28649974691456764, "compression_ratio": 1.5528846153846154, "no_speech_prob": 0.06448152661323547}, {"id": 263, "seek": 112520, "start": 1140.3600000000001, "end": 1141.3600000000001, "text": " you could do.", "tokens": [51122, 291, 727, 360, 13, 51172], "temperature": 0.0, "avg_logprob": -0.28649974691456764, "compression_ratio": 1.5528846153846154, "no_speech_prob": 0.06448152661323547}, {"id": 264, "seek": 112520, "start": 1141.3600000000001, "end": 1148.56, "text": " It'd be cool to have two locations and you can imagine an office having two offices in", "tokens": [51172, 467, 1116, 312, 1627, 281, 362, 732, 9253, 293, 291, 393, 3811, 364, 3398, 1419, 732, 14434, 294, 51532], "temperature": 0.0, "avg_logprob": -0.28649974691456764, "compression_ratio": 1.5528846153846154, "no_speech_prob": 0.06448152661323547}, {"id": 265, "seek": 112520, "start": 1148.56, "end": 1154.24, "text": " the UK and they're kind of deciding where to deploy that task.", "tokens": [51532, 264, 7051, 293, 436, 434, 733, 295, 17990, 689, 281, 7274, 300, 5633, 13, 51816], "temperature": 0.0, "avg_logprob": -0.28649974691456764, "compression_ratio": 1.5528846153846154, "no_speech_prob": 0.06448152661323547}, {"id": 266, "seek": 115424, "start": 1155.24, "end": 1159.4, "text": " Maybe that extends even globally and you can choose where to run your task.", "tokens": [50414, 2704, 300, 26448, 754, 18958, 293, 291, 393, 2826, 689, 281, 1190, 428, 5633, 13, 50622], "temperature": 0.0, "avg_logprob": -0.2819315592447917, "compression_ratio": 1.5694444444444444, "no_speech_prob": 0.07568789273500443}, {"id": 267, "seek": 115424, "start": 1159.4, "end": 1161.64, "text": " Yeah, spatial shifting would be a nice thing to have.", "tokens": [50622, 865, 11, 23598, 17573, 576, 312, 257, 1481, 551, 281, 362, 13, 50734], "temperature": 0.0, "avg_logprob": -0.2819315592447917, "compression_ratio": 1.5694444444444444, "no_speech_prob": 0.07568789273500443}, {"id": 268, "seek": 115424, "start": 1161.64, "end": 1163.48, "text": " The problem with that is moving the data with it.", "tokens": [50734, 440, 1154, 365, 300, 307, 2684, 264, 1412, 365, 309, 13, 50826], "temperature": 0.0, "avg_logprob": -0.2819315592447917, "compression_ratio": 1.5694444444444444, "no_speech_prob": 0.07568789273500443}, {"id": 269, "seek": 115424, "start": 1163.48, "end": 1170.16, "text": " You need to have the data in both locations or move the data in advance of the job starting.", "tokens": [50826, 509, 643, 281, 362, 264, 1412, 294, 1293, 9253, 420, 1286, 264, 1412, 294, 7295, 295, 264, 1691, 2891, 13, 51160], "temperature": 0.0, "avg_logprob": -0.2819315592447917, "compression_ratio": 1.5694444444444444, "no_speech_prob": 0.07568789273500443}, {"id": 270, "seek": 115424, "start": 1170.16, "end": 1171.16, "text": " Anyone else?", "tokens": [51160, 14643, 1646, 30, 51210], "temperature": 0.0, "avg_logprob": -0.2819315592447917, "compression_ratio": 1.5694444444444444, "no_speech_prob": 0.07568789273500443}, {"id": 271, "seek": 115424, "start": 1171.16, "end": 1173.76, "text": " That's one over there.", "tokens": [51210, 663, 311, 472, 670, 456, 13, 51340], "temperature": 0.0, "avg_logprob": -0.2819315592447917, "compression_ratio": 1.5694444444444444, "no_speech_prob": 0.07568789273500443}, {"id": 272, "seek": 115424, "start": 1173.76, "end": 1177.48, "text": " This is really just a comment.", "tokens": [51340, 639, 307, 534, 445, 257, 2871, 13, 51526], "temperature": 0.0, "avg_logprob": -0.2819315592447917, "compression_ratio": 1.5694444444444444, "no_speech_prob": 0.07568789273500443}, {"id": 273, "seek": 117748, "start": 1177.48, "end": 1185.4, "text": " I made a calculation of how much commuting to work costs in terms of energy compared", "tokens": [50364, 286, 1027, 257, 17108, 295, 577, 709, 800, 10861, 281, 589, 5497, 294, 2115, 295, 2281, 5347, 50760], "temperature": 0.0, "avg_logprob": -0.2163510105826638, "compression_ratio": 1.6175115207373272, "no_speech_prob": 0.4590214192867279}, {"id": 274, "seek": 117748, "start": 1185.4, "end": 1191.32, "text": " to what the supercomputers in that computing center are.", "tokens": [50760, 281, 437, 264, 27839, 2582, 433, 294, 300, 15866, 3056, 366, 13, 51056], "temperature": 0.0, "avg_logprob": -0.2163510105826638, "compression_ratio": 1.6175115207373272, "no_speech_prob": 0.4590214192867279}, {"id": 275, "seek": 117748, "start": 1191.32, "end": 1195.44, "text": " Just to give you a perspective, usually when you go to work and go back home it's like", "tokens": [51056, 1449, 281, 976, 291, 257, 4585, 11, 2673, 562, 291, 352, 281, 589, 293, 352, 646, 1280, 309, 311, 411, 51262], "temperature": 0.0, "avg_logprob": -0.2163510105826638, "compression_ratio": 1.6175115207373272, "no_speech_prob": 0.4590214192867279}, {"id": 276, "seek": 117748, "start": 1195.44, "end": 1197.76, "text": " the 100% that you can save here.", "tokens": [51262, 264, 2319, 4, 300, 291, 393, 3155, 510, 13, 51378], "temperature": 0.0, "avg_logprob": -0.2163510105826638, "compression_ratio": 1.6175115207373272, "no_speech_prob": 0.4590214192867279}, {"id": 277, "seek": 117748, "start": 1197.76, "end": 1203.3600000000001, "text": " So just to give in general to whenever you're doing such savings estimates, just be aware", "tokens": [51378, 407, 445, 281, 976, 294, 2674, 281, 5699, 291, 434, 884, 1270, 13454, 20561, 11, 445, 312, 3650, 51658], "temperature": 0.0, "avg_logprob": -0.2163510105826638, "compression_ratio": 1.6175115207373272, "no_speech_prob": 0.4590214192867279}, {"id": 278, "seek": 120336, "start": 1203.36, "end": 1209.7199999999998, "text": " that tell your employer that just by working from home you can save that exact amount.", "tokens": [50364, 300, 980, 428, 16205, 300, 445, 538, 1364, 490, 1280, 291, 393, 3155, 300, 1900, 2372, 13, 50682], "temperature": 0.0, "avg_logprob": -0.4934727868368459, "compression_ratio": 1.2661290322580645, "no_speech_prob": 0.011435900814831257}, {"id": 279, "seek": 120336, "start": 1209.7199999999998, "end": 1212.7199999999998, "text": " Sorry, it's just a statement.", "tokens": [50682, 4919, 11, 309, 311, 445, 257, 5629, 13, 50832], "temperature": 0.0, "avg_logprob": -0.4934727868368459, "compression_ratio": 1.2661290322580645, "no_speech_prob": 0.011435900814831257}, {"id": 280, "seek": 120336, "start": 1222.9199999999998, "end": 1228.6399999999999, "text": " Just a quick question on how CATS works.", "tokens": [51342, 1449, 257, 1702, 1168, 322, 577, 41192, 50, 1985, 13, 51628], "temperature": 0.0, "avg_logprob": -0.4934727868368459, "compression_ratio": 1.2661290322580645, "no_speech_prob": 0.011435900814831257}, {"id": 281, "seek": 122864, "start": 1228.72, "end": 1235.48, "text": " I don't recall if you got into detail about it, but does it use the API data for time", "tokens": [50368, 286, 500, 380, 9901, 498, 291, 658, 666, 2607, 466, 309, 11, 457, 775, 309, 764, 264, 9362, 1412, 337, 565, 50706], "temperature": 0.0, "avg_logprob": -0.17956068909283981, "compression_ratio": 1.7355371900826446, "no_speech_prob": 0.05574781447649002}, {"id": 282, "seek": 122864, "start": 1235.48, "end": 1243.44, "text": " series prediction or does it have some kind of internal calculation to do that?", "tokens": [50706, 2638, 17630, 420, 775, 309, 362, 512, 733, 295, 6920, 17108, 281, 360, 300, 30, 51104], "temperature": 0.0, "avg_logprob": -0.17956068909283981, "compression_ratio": 1.7355371900826446, "no_speech_prob": 0.05574781447649002}, {"id": 283, "seek": 122864, "start": 1243.44, "end": 1247.48, "text": " It tries to find the lowest carbon window in the forecast period.", "tokens": [51104, 467, 9898, 281, 915, 264, 12437, 5954, 4910, 294, 264, 14330, 2896, 13, 51306], "temperature": 0.0, "avg_logprob": -0.17956068909283981, "compression_ratio": 1.7355371900826446, "no_speech_prob": 0.05574781447649002}, {"id": 284, "seek": 122864, "start": 1247.48, "end": 1251.48, "text": " So if your job is going to be six hours it will try and find the lowest six hours in", "tokens": [51306, 407, 498, 428, 1691, 307, 516, 281, 312, 2309, 2496, 309, 486, 853, 293, 915, 264, 12437, 2309, 2496, 294, 51506], "temperature": 0.0, "avg_logprob": -0.17956068909283981, "compression_ratio": 1.7355371900826446, "no_speech_prob": 0.05574781447649002}, {"id": 285, "seek": 122864, "start": 1251.48, "end": 1254.3600000000001, "text": " that period and schedule your job to that time period.", "tokens": [51506, 300, 2896, 293, 7567, 428, 1691, 281, 300, 565, 2896, 13, 51650], "temperature": 0.0, "avg_logprob": -0.17956068909283981, "compression_ratio": 1.7355371900826446, "no_speech_prob": 0.05574781447649002}, {"id": 286, "seek": 122864, "start": 1254.3600000000001, "end": 1257.2800000000002, "text": " Okay, but the predictions are already available.", "tokens": [51650, 1033, 11, 457, 264, 21264, 366, 1217, 2435, 13, 51796], "temperature": 0.0, "avg_logprob": -0.17956068909283981, "compression_ratio": 1.7355371900826446, "no_speech_prob": 0.05574781447649002}, {"id": 287, "seek": 125728, "start": 1257.6399999999999, "end": 1258.84, "text": " The predictions are not made by us.", "tokens": [50382, 440, 21264, 366, 406, 1027, 538, 505, 13, 50442], "temperature": 0.0, "avg_logprob": -0.47324065158241674, "compression_ratio": 1.3142857142857143, "no_speech_prob": 0.003910898696631193}, {"id": 288, "seek": 125728, "start": 1258.84, "end": 1261.44, "text": " The predictions are available from the carbon intensity API.", "tokens": [50442, 440, 21264, 366, 2435, 490, 264, 5954, 13749, 9362, 13, 50572], "temperature": 0.0, "avg_logprob": -0.47324065158241674, "compression_ratio": 1.3142857142857143, "no_speech_prob": 0.003910898696631193}, {"id": 289, "seek": 125728, "start": 1273.44, "end": 1276.6399999999999, "text": " Thanks for the talk.", "tokens": [51172, 2561, 337, 264, 751, 13, 51332], "temperature": 0.0, "avg_logprob": -0.47324065158241674, "compression_ratio": 1.3142857142857143, "no_speech_prob": 0.003910898696631193}, {"id": 290, "seek": 125728, "start": 1276.6399999999999, "end": 1278.08, "text": " I have one question.", "tokens": [51332, 286, 362, 472, 1168, 13, 51404], "temperature": 0.0, "avg_logprob": -0.47324065158241674, "compression_ratio": 1.3142857142857143, "no_speech_prob": 0.003910898696631193}, {"id": 291, "seek": 127808, "start": 1278.1599999999999, "end": 1290.12, "text": " If you already saw an API which is called Wattime API, I think it does the same, but", "tokens": [50368, 759, 291, 1217, 1866, 364, 9362, 597, 307, 1219, 343, 1591, 1312, 9362, 11, 286, 519, 309, 775, 264, 912, 11, 457, 50966], "temperature": 0.0, "avg_logprob": -0.3444181074175918, "compression_ratio": 1.3703703703703705, "no_speech_prob": 0.018560636788606644}, {"id": 292, "seek": 127808, "start": 1290.12, "end": 1291.9199999999998, "text": " all over the world.", "tokens": [50966, 439, 670, 264, 1002, 13, 51056], "temperature": 0.0, "avg_logprob": -0.3444181074175918, "compression_ratio": 1.3703703703703705, "no_speech_prob": 0.018560636788606644}, {"id": 293, "seek": 127808, "start": 1291.9199999999998, "end": 1294.96, "text": " I wasn't aware of that one, but that is very useful.", "tokens": [51056, 286, 2067, 380, 3650, 295, 300, 472, 11, 457, 300, 307, 588, 4420, 13, 51208], "temperature": 0.0, "avg_logprob": -0.3444181074175918, "compression_ratio": 1.3703703703703705, "no_speech_prob": 0.018560636788606644}, {"id": 294, "seek": 127808, "start": 1294.96, "end": 1296.56, "text": " We will look into that one.", "tokens": [51208, 492, 486, 574, 666, 300, 472, 13, 51288], "temperature": 0.0, "avg_logprob": -0.3444181074175918, "compression_ratio": 1.3703703703703705, "no_speech_prob": 0.018560636788606644}, {"id": 295, "seek": 130808, "start": 1309.08, "end": 1311.08, "text": " Hi there.", "tokens": [50414, 2421, 456, 13, 50514], "temperature": 0.0, "avg_logprob": -0.22116250258225661, "compression_ratio": 1.5574912891986064, "no_speech_prob": 0.2685488164424896}, {"id": 296, "seek": 130808, "start": 1311.08, "end": 1312.08, "text": " One, two.", "tokens": [50514, 1485, 11, 732, 13, 50564], "temperature": 0.0, "avg_logprob": -0.22116250258225661, "compression_ratio": 1.5574912891986064, "no_speech_prob": 0.2685488164424896}, {"id": 297, "seek": 130808, "start": 1312.08, "end": 1313.08, "text": " You can hear me, right?", "tokens": [50564, 509, 393, 1568, 385, 11, 558, 30, 50614], "temperature": 0.0, "avg_logprob": -0.22116250258225661, "compression_ratio": 1.5574912891986064, "no_speech_prob": 0.2685488164424896}, {"id": 298, "seek": 130808, "start": 1313.08, "end": 1314.08, "text": " Yeah.", "tokens": [50614, 865, 13, 50664], "temperature": 0.0, "avg_logprob": -0.22116250258225661, "compression_ratio": 1.5574912891986064, "no_speech_prob": 0.2685488164424896}, {"id": 299, "seek": 130808, "start": 1314.08, "end": 1316.56, "text": " Hi, I'm Chris Adams from the Green Software Foundation.", "tokens": [50664, 2421, 11, 286, 478, 6688, 25214, 490, 264, 6969, 27428, 10335, 13, 50788], "temperature": 0.0, "avg_logprob": -0.22116250258225661, "compression_ratio": 1.5574912891986064, "no_speech_prob": 0.2685488164424896}, {"id": 300, "seek": 130808, "start": 1316.56, "end": 1321.36, "text": " I'm curious about whether when you're doing this, if I know what jobs I did last year,", "tokens": [50788, 286, 478, 6369, 466, 1968, 562, 291, 434, 884, 341, 11, 498, 286, 458, 437, 4782, 286, 630, 1036, 1064, 11, 51028], "temperature": 0.0, "avg_logprob": -0.22116250258225661, "compression_ratio": 1.5574912891986064, "no_speech_prob": 0.2685488164424896}, {"id": 301, "seek": 130808, "start": 1321.36, "end": 1325.8799999999999, "text": " is there a way for me to run any of this against, say, last year's worth of compute jobs to", "tokens": [51028, 307, 456, 257, 636, 337, 385, 281, 1190, 604, 295, 341, 1970, 11, 584, 11, 1036, 1064, 311, 3163, 295, 14722, 4782, 281, 51254], "temperature": 0.0, "avg_logprob": -0.22116250258225661, "compression_ratio": 1.5574912891986064, "no_speech_prob": 0.2685488164424896}, {"id": 302, "seek": 130808, "start": 1325.8799999999999, "end": 1330.1599999999999, "text": " see what my savings could have been if I were to find something like this?", "tokens": [51254, 536, 437, 452, 13454, 727, 362, 668, 498, 286, 645, 281, 915, 746, 411, 341, 30, 51468], "temperature": 0.0, "avg_logprob": -0.22116250258225661, "compression_ratio": 1.5574912891986064, "no_speech_prob": 0.2685488164424896}, {"id": 303, "seek": 130808, "start": 1330.1599999999999, "end": 1334.12, "text": " Because a lot of this is forward-looking, but if I've got some data now, that will make", "tokens": [51468, 1436, 257, 688, 295, 341, 307, 2128, 12, 16129, 11, 457, 498, 286, 600, 658, 512, 1412, 586, 11, 300, 486, 652, 51666], "temperature": 0.0, "avg_logprob": -0.22116250258225661, "compression_ratio": 1.5574912891986064, "no_speech_prob": 0.2685488164424896}, {"id": 304, "seek": 133412, "start": 1334.1599999999999, "end": 1338.52, "text": " it easier for me to make the case that this could create some meaningful savings inside", "tokens": [50366, 309, 3571, 337, 385, 281, 652, 264, 1389, 300, 341, 727, 1884, 512, 10995, 13454, 1854, 50584], "temperature": 0.0, "avg_logprob": -0.21580072010264678, "compression_ratio": 1.7484076433121019, "no_speech_prob": 0.060750868171453476}, {"id": 305, "seek": 133412, "start": 1338.52, "end": 1340.6, "text": " my team or inside my organization.", "tokens": [50584, 452, 1469, 420, 1854, 452, 4475, 13, 50688], "temperature": 0.0, "avg_logprob": -0.21580072010264678, "compression_ratio": 1.7484076433121019, "no_speech_prob": 0.060750868171453476}, {"id": 306, "seek": 133412, "start": 1340.6, "end": 1341.6, "text": " Yeah.", "tokens": [50688, 865, 13, 50738], "temperature": 0.0, "avg_logprob": -0.21580072010264678, "compression_ratio": 1.7484076433121019, "no_speech_prob": 0.060750868171453476}, {"id": 307, "seek": 133412, "start": 1341.6, "end": 1345.6399999999999, "text": " Slurm normally has some accounting built in that logs when jobs ran, so that would give", "tokens": [50738, 6187, 26717, 5646, 575, 512, 19163, 3094, 294, 300, 20820, 562, 4782, 5872, 11, 370, 300, 576, 976, 50940], "temperature": 0.0, "avg_logprob": -0.21580072010264678, "compression_ratio": 1.7484076433121019, "no_speech_prob": 0.060750868171453476}, {"id": 308, "seek": 133412, "start": 1345.6399999999999, "end": 1348.32, "text": " you the data that you'd need to go and do that.", "tokens": [50940, 291, 264, 1412, 300, 291, 1116, 643, 281, 352, 293, 360, 300, 13, 51074], "temperature": 0.0, "avg_logprob": -0.21580072010264678, "compression_ratio": 1.7484076433121019, "no_speech_prob": 0.060750868171453476}, {"id": 309, "seek": 133412, "start": 1348.32, "end": 1351.2399999999998, "text": " I think there's also a simulator available, which is something we want to look into in", "tokens": [51074, 286, 519, 456, 311, 611, 257, 32974, 2435, 11, 597, 307, 746, 321, 528, 281, 574, 666, 294, 51220], "temperature": 0.0, "avg_logprob": -0.21580072010264678, "compression_ratio": 1.7484076433121019, "no_speech_prob": 0.060750868171453476}, {"id": 310, "seek": 133412, "start": 1351.2399999999998, "end": 1355.56, "text": " our next phase as to whether we can make use of that to do that kind of prediction, or", "tokens": [51220, 527, 958, 5574, 382, 281, 1968, 321, 393, 652, 764, 295, 300, 281, 360, 300, 733, 295, 17630, 11, 420, 51436], "temperature": 0.0, "avg_logprob": -0.21580072010264678, "compression_ratio": 1.7484076433121019, "no_speech_prob": 0.060750868171453476}, {"id": 311, "seek": 133412, "start": 1355.56, "end": 1357.56, "text": " not prediction analysis.", "tokens": [51436, 406, 17630, 5215, 13, 51536], "temperature": 0.0, "avg_logprob": -0.21580072010264678, "compression_ratio": 1.7484076433121019, "no_speech_prob": 0.060750868171453476}, {"id": 312, "seek": 133412, "start": 1357.56, "end": 1362.1999999999998, "text": " I saw your talk last year, and that was actually some of the inspiration behind this.", "tokens": [51536, 286, 1866, 428, 751, 1036, 1064, 11, 293, 300, 390, 767, 512, 295, 264, 10249, 2261, 341, 13, 51768], "temperature": 0.0, "avg_logprob": -0.21580072010264678, "compression_ratio": 1.7484076433121019, "no_speech_prob": 0.060750868171453476}, {"id": 313, "seek": 136220, "start": 1362.2, "end": 1369.2, "text": " I think that's it.", "tokens": [50364, 286, 519, 300, 311, 309, 13, 50714], "temperature": 0.0, "avg_logprob": -0.3422914327577103, "compression_ratio": 1.5287958115183247, "no_speech_prob": 0.02028219774365425}, {"id": 314, "seek": 136220, "start": 1369.2, "end": 1372.2, "text": " One more.", "tokens": [50714, 1485, 544, 13, 50864], "temperature": 0.0, "avg_logprob": -0.3422914327577103, "compression_ratio": 1.5287958115183247, "no_speech_prob": 0.02028219774365425}, {"id": 315, "seek": 136220, "start": 1372.2, "end": 1374.2, "text": " Hi.", "tokens": [50864, 2421, 13, 50964], "temperature": 0.0, "avg_logprob": -0.3422914327577103, "compression_ratio": 1.5287958115183247, "no_speech_prob": 0.02028219774365425}, {"id": 316, "seek": 136220, "start": 1374.2, "end": 1377.96, "text": " I was wondering, we're also in the purchase of buy-in new cluster, and we have also raised", "tokens": [50964, 286, 390, 6359, 11, 321, 434, 611, 294, 264, 8110, 295, 2256, 12, 259, 777, 13630, 11, 293, 321, 362, 611, 6005, 51152], "temperature": 0.0, "avg_logprob": -0.3422914327577103, "compression_ratio": 1.5287958115183247, "no_speech_prob": 0.02028219774365425}, {"id": 317, "seek": 136220, "start": 1377.96, "end": 1380.96, "text": " this thing with the users.", "tokens": [51152, 341, 551, 365, 264, 5022, 13, 51302], "temperature": 0.0, "avg_logprob": -0.3422914327577103, "compression_ratio": 1.5287958115183247, "no_speech_prob": 0.02028219774365425}, {"id": 318, "seek": 136220, "start": 1380.96, "end": 1382.8, "text": " Turns out they don't really like this.", "tokens": [51302, 29524, 484, 436, 500, 380, 534, 411, 341, 13, 51394], "temperature": 0.0, "avg_logprob": -0.3422914327577103, "compression_ratio": 1.5287958115183247, "no_speech_prob": 0.02028219774365425}, {"id": 319, "seek": 136220, "start": 1382.8, "end": 1387.68, "text": " The idea that there would be free resources in the cluster, and their job would not start", "tokens": [51394, 440, 1558, 300, 456, 576, 312, 1737, 3593, 294, 264, 13630, 11, 293, 641, 1691, 576, 406, 722, 51638], "temperature": 0.0, "avg_logprob": -0.3422914327577103, "compression_ratio": 1.5287958115183247, "no_speech_prob": 0.02028219774365425}, {"id": 320, "seek": 136220, "start": 1387.68, "end": 1388.68, "text": " immediately.", "tokens": [51638, 4258, 13, 51688], "temperature": 0.0, "avg_logprob": -0.3422914327577103, "compression_ratio": 1.5287958115183247, "no_speech_prob": 0.02028219774365425}, {"id": 321, "seek": 138868, "start": 1388.68, "end": 1392.28, "text": " Is this a cluster with people actually using the HPC clusters?", "tokens": [50364, 1119, 341, 257, 13630, 365, 561, 767, 1228, 264, 12557, 34, 23313, 30, 50544], "temperature": 0.0, "avg_logprob": -0.2739430684891958, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.12396711856126785}, {"id": 322, "seek": 138868, "start": 1392.28, "end": 1395.28, "text": " So far, it's very hard.", "tokens": [50544, 407, 1400, 11, 309, 311, 588, 1152, 13, 50694], "temperature": 0.0, "avg_logprob": -0.2739430684891958, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.12396711856126785}, {"id": 323, "seek": 138868, "start": 1395.28, "end": 1400.3200000000002, "text": " We're finding that from users, there's sort of a three-way split of some who care enough", "tokens": [50694, 492, 434, 5006, 300, 490, 5022, 11, 456, 311, 1333, 295, 257, 1045, 12, 676, 7472, 295, 512, 567, 1127, 1547, 50946], "temperature": 0.0, "avg_logprob": -0.2739430684891958, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.12396711856126785}, {"id": 324, "seek": 138868, "start": 1400.3200000000002, "end": 1404.96, "text": " to definitely go out their way to do things, some who might use it if it was available,", "tokens": [50946, 281, 2138, 352, 484, 641, 636, 281, 360, 721, 11, 512, 567, 1062, 764, 309, 498, 309, 390, 2435, 11, 51178], "temperature": 0.0, "avg_logprob": -0.2739430684891958, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.12396711856126785}, {"id": 325, "seek": 138868, "start": 1404.96, "end": 1408.96, "text": " but aren't going to go out their way, and some who they want their science now, and", "tokens": [51178, 457, 3212, 380, 516, 281, 352, 484, 641, 636, 11, 293, 512, 567, 436, 528, 641, 3497, 586, 11, 293, 51378], "temperature": 0.0, "avg_logprob": -0.2739430684891958, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.12396711856126785}, {"id": 326, "seek": 138868, "start": 1408.96, "end": 1411.24, "text": " they don't care what the carbon emissions are.", "tokens": [51378, 436, 500, 380, 1127, 437, 264, 5954, 14607, 366, 13, 51492], "temperature": 0.0, "avg_logprob": -0.2739430684891958, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.12396711856126785}, {"id": 327, "seek": 138868, "start": 1411.24, "end": 1415.2, "text": " I guess we can target the other two groups first, and the other third might get dragged", "tokens": [51492, 286, 2041, 321, 393, 3779, 264, 661, 732, 3935, 700, 11, 293, 264, 661, 2636, 1062, 483, 25717, 51690], "temperature": 0.0, "avg_logprob": -0.2739430684891958, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.12396711856126785}, {"id": 328, "seek": 141520, "start": 1415.24, "end": 1419.24, "text": " out, kicking and screaming one day when carbon accounting comes in for them.", "tokens": [50366, 484, 11, 19137, 293, 12636, 472, 786, 562, 5954, 19163, 1487, 294, 337, 552, 13, 50566], "temperature": 0.0, "avg_logprob": -0.3918429651568013, "compression_ratio": 1.2178217821782178, "no_speech_prob": 0.1363709717988968}, {"id": 329, "seek": 141520, "start": 1419.24, "end": 1423.24, "text": " Okay, can we thank the speakers again, please?", "tokens": [50566, 1033, 11, 393, 321, 1309, 264, 9518, 797, 11, 1767, 30, 50766], "temperature": 0.0, "avg_logprob": -0.3918429651568013, "compression_ratio": 1.2178217821782178, "no_speech_prob": 0.1363709717988968}], "language": "en"}