{"text": " All right, so yeah, what's possible in observability when we have frame pointers is kind of the talk. But let's start out with like a kind of like actual use case of observability, right? So we have these workloads. We can like graph the CPU cores and we can see some things happening and we might be wondering what's actually happening at these spikes, right? And we can use profiling, I guess, to figure out what happens at these individual spikes just to like understand, okay, like in this scenario this was happening in another scenario or like at another time something else happened. We can like get profiles manually and compare them or we do something called continuous profiling where we just like all the time over time, yeah, profile, hopefully a little overhead we can even do it in production or not hopefully, but it's a reality. We can do it in production, right? So we can then store all of these profiles and over time kind of like ask questions when we want to in retrospect and we don't have to worry about missing data points and we have kind of the security or yeah, the ease of use that we can just click on some spike and then get a frame graph or in this case an icicle graph because it's like top down and not the other way around. We call it icicle graphs and you can see all the stack traces and you can like instrument very nicely, introspect what's happening and I don't have a slide for this but we can also kind of like this flame graphs and then we can see in like red where things got worse and in green usually where things gotten better and it's pretty obvious most of the time if you have such a big spike like that's right the point where we need to look in such a flame graph and where we need to like check out what's happening in the code. So yeah, that's kind of a pretty good use case for observability, right? But yeah, what our frame point is but before we come to that quick introduction I'm Matthias L\u00e4uwe, I'm a senior software engineer at Polar Signals, I work on Parker which is like the open source project doing a bunch of these things but I also work on Thanos, Prometheus and lots of other open source monitoring projects. Yeah and hey everyone, I'm John Seger, I'm VP of Engineering at Canonical, I have a kind of interesting journey to open source but at the moment I am leading the development of Juju and a whole suite of kind of enterprise apps which we call Charm so if you want to get access to like the best Postgres on your infrastructure or the best MySQL or the Grafana stack or Parker or you want to build an identity stack with ORI and with OpenFGA and products like that, that's kind of the effort that I'm leading. The orchestrator is called Juju, it's been around a really long time, Charm's all written in Python and we're kind of building out a big catalogue of operators that allow you to not just deploy those things but actually compose them all together and integrate them in a really common way irrespective of whether your infrastructure happens to be bare metal or Kubernetes or VMs or on EC2 or on Azure or some combination of the whole lot so that's kind of what I'm up to at the moment. Awesome, yeah and I'm looking forward to hearing more from you but before I do that, let's talk about profiling again or like what profiling data is made up of and you can see these like points in time just T1, T2, T3, at some point in time, we basically want to look at the current stack trace or what the program state looks like and we can see that like at T1 we had ABCD, at T2 we had ABCNE so slightly different and then at T3 we had the same thing again so kind of like just for the sake of the demo or the example, one was like executed twice so maybe it was like executed 20 milliseconds in total and the other one 10 milliseconds so we kind of like count how often we see these stacks and then kind of can make assumption on how much it is running and this is kind of like a sampled profiling profiler, it basically only like every so often looks at these stack traces but over time we can really nicely like see the big picture of things happening. The good thing is because it's only happening so often the overhead is pretty low which again I touched on earlier for our use case figuring out what's going on, it's pretty nice due to being pretty low overhead. So how do we get to these stack traces, how can we see these stacks that we then get all the memory addresses for and then we can like nicely format them using the function names for example in the icicle graphs. So the best case and that's kind of the whole point of the talk right are frame pointers and frame pointers looking at this bit of C code it's hopefully not too daunting in a monitoring observability room but we can see we have the main function at the bottom and that calls a function and so on the functions call each other and then at the very top it just goes into an endless loop. And kind of the important part in all of this is looking at the assembly on the right hand side we can see that okay I omitted like the main function and the a1 but then we can see b1 and we can see that at the very beginning we are pushing and moving some registers around and those are actually the instructions to push the frame pointer onto the stack and then we are calling the next function right and the pushing of the registers so that we know once the next function is done executing we can come back to exactly that previous function and continue executing. The one thing I want to mention here is in the past there were a couple of discussions about the overhead of using frame pointer so we have the push and move instructions and then once the function is done it needs to pop that frame pointer so there were a couple of extra assembly steps involved especially on 30 bit systems it wasn't great performance wise but I think unless you are a really really special case it should be fine for almost all workloads even in production and that's kind of the point of this so basically our binary on the left hand side we can see our set up frame pointer so that's kind of the first instruction that our assembly is executing it is putting the frame pointer onto the stack before then going and doing the actual call to the next function right and before doing that we have to add the return address to our stack so that once the function that we are calling is done we know where to continue in our current function right so we need to know where like this other code we need to execute after calling the function we are calling right now where we need to continue so that's why we have the return address and we then actually do the function preamble and we run that function and eventually we return the function we are at the pointer that then actually tells us where to go back to right so the function that we called eventually returns and we want to go back to the original function however we are then executing after that function call right so previously we were can you see my mouse no we were over here and now we returned like one step and after that right because we don't want to call that function again going into an endless loop we want to continue afterwards however we want to know what called us right so basically what we want to do is whenever we have a stack we want to know which function called us and do that all the way such that we eventually end up in the main function and we know all the functions that we see that we have on the stack up to the point where we are now basically that's kind of like working the stack here and the really really cool thing is we can do this in ebpf so I don't know how many attend the previous talk ebpf kind of a hot topic right now for us it's really really cool because what we can do is write a small program in a C dialect and then get that through the verifier and compile it into ebpf code and then load that into the Linux corner and the way it works is then we actually don't use syscalls like the slide originally says but what we then do is like tell the Linux corner to every so often run this snippet of ebpf code and what we do is do the same things like stack unwinding that you are stack walking that I told you about like two slides ago so essentially what we do is we start or we start in ebpf we get kind of the context we get the current stack pointer and we look at the leaf of the stack so like kind of the very top like the currently executed function and we can then use that to essentially read that instruction pointer and from there get the frame pointer and the special occasion here is the instruction pointer has to be the return address minus one because of the thing I just told you about two slides ago right so basically that's how we can then know where we were called from and we do that all the time up until at the end we do that we get an instruction pointer or that zero so this one then means basically we reach the end of the stack and we know we can terminate or we reach the end of that stack trace. In between for profiling you can see over here we do something with the stack with the frame and what we actually do is we kind of like just get the memory address of that executed function and we basically have an array of all the frames that were executed at the end and have the memory addresses and those memory addresses we can then use to get the function names for that function. So having frame pointers in ebpf makes regular profiling super easy and we can then do profiling super simple we don't have to worry about like special compiler configurations because we can just assume that frame pointers are here for us to then basically use them to figure out the entire stack of the currently executing function. There are ways to do exactly that without frame pointers and shout out I think it was in this very room one year ago there was a talk by Javier and by Charlie who were talking about stack unwinding without frame pointers using Dwarf I highly recommend it it's really really interesting but yeah something for another time and then obviously not only like the profiling use case but if we have frame pointers in the executables in those executing stacks we can also use all the other debugging tools right not only for profiling we can use the bcc tools bpf trace perf etc and they also have the kind of same benefits. So essentially what that means is that the possibilities really become a lot more broad and open or like we can do a lot more things because we only have these like two memory reads and for example in bpf trace we can use the like one liner here to essentially also build a really simple but working profiler that uses the use stack to get the user space stack unwinding and count how often it sees things and that's super cheap then but also like the go execution trace actually traces everything that's happening and because unwinding is so has so little overhead we can also do things like that and once we have profiles continue and kind of like the performance aspect we can do something called profile guided optimizations and just making profiling so cheap that's something where I think a lot of innovation is also going to happen in the future and some outlook like some super new papers the context sensitive sample based profile guided optimization so something we are super excited about because yeah it will allow a lot more things to happen as well but maybe another Boston talk is going to happen about that in a year or two so bringing frame pointer to the masses I'm super excited to have John talk. Hey all right so I'm here to tell you about now we've seen all of the cool stuff you can do when you have frame pointers how we at Canonical are going to make this available to all of you much more easily and so if you didn't see this on an outside our blog a couple of months ago we have decided that from 2404 LTS we're going to enable frame pointers for the entire Ubuntu archive on 64 bit platforms. The caveat on 64 bit is because back in the day 32 bit CPUs obviously had far fewer registers and so sacrificing a register to hold the frame pointer came with a much higher performance overhead in reality these days with 64 bit you're looking at on average kind of less than 1% unless you're in a very specific group so if you're doing like turbo pants on head HPC stuff or high frequency trading or real time things where kind of that like 1% could really really matter perhaps this isn't for you and we can make exceptions in the archive for those packages but in general for 2404 you can expect to see frame pointers for the entire archive through main and universe etc. This is pretty exciting because the LTS I probably need to tell you is going to be installed on many many millions of machines right and then supported for at least 10 years by Canonical so this is going to make a big impact for people who need these things. This stuff is often already enabled by the hyperscalers so people like Amazon, people like Netflix, people like Microsoft are already doing this in production and now you kind of get it for free as well just by using Ubuntu. So I mentioned there will be some you know pretty much negligible barely noticeable for nearly all use case performance impact we're kind of willing to wear that because what it actually enables in the medium term is for us to do a lot of work on our distribution right so we're in the process now of running benchmarks on a kind of pre frame pointer Ubuntu and a post frame pointer Ubuntu ready for the release and that will hopefully help as I identify any outliers so if we hit certain packages where we feel like the performance hit is too much then we will disable it for the first release for 24.04 or we will try and work out what other optimizations we might make to that package to make it work better with the frame pointers enabled. So this will really really help I think downstreams to enable or to gain the benefit of frame pointers and optimize their own workloads. If you are someone who just uses Ubuntu as a platform and you build your own code and let's say you use Python or you use go or use no JS or whatever suddenly those big holes in your frame graph graphs are just going to disappear when you move to 24.04 without you having to do anything. This is really just the start which when I make 24.04 a really focused release on kind of performance engineering and performance itself so what does that actually mean having the frame pointers is one thing but you also need the tooling to actually utilize the frame pointers and kind of inspect the stack and the folks at PoloSignals with Parker are one part of that but we are also looking to include tools like BPF Trace and SysStat and the Perf Tools on Stable by default in Ubuntu. Not in every single image so those of you that are about to screen map me because you use the minimal image or you ship 100,000 container images a month and you don't want to ship BPF Trace and all of them don't panic we are essentially going to enable all of these tools by default anywhere where we ship a kernel. So a Ubuntu server image, a full size server image that doesn't include lexd images, it doesn't include OCI images but if you install Ubuntu on a server or in a VM you will have BPF Trace by default, you will have SysStat by default. Essentially a huge majority of the tools that Brendan Gregg describes as crisis tools will be there by default and the reason that is super important is because if your system is in crisis it doesn't matter whether the tools are in the archive. If your system is right on the edge and then you hit the system with a whole bunch of network IO and disk IO to go and get a package from the archives it is potentially going to put that system over the edge. It may not even work in production, the system may not have access to the package archives and so you just need those tools to be there and we are going to make sure that happens. For places where we don't ship a kernel all of these tools will get wrapped up in a new meta package so if you do want it in your lexd containers, if you do want it in your container images, in your debug images then you will just be able to see it really really easily with a single meta package. We are looking at what other compiler optimizations we can make across the archive as well so this might look like rolling out GCC03 for a huge part of the archive, we are not going to do that in one big bang go because there are some trade offs there and we are also looking at essentially not maintaining a low latency kernel and a generic kernel and just shipping the low latency package by default. None of these are firm, 100% definitely going to happen in 24.04, these are the goals we are working towards before the release in April. Finally, some of you may have seen we have been doing some work on working out how to get Ubuntu and the archive to take advantage of the newer instruction sets, AMD64 v3, AMD64 v4, v5. We actually have a build of the entire archive that uses AMD64 v3, you can get it in a PPA and test it in benchmark, it is faster like TLDR but we need to do a bunch of upstream working apps to work out how we can essentially kind of multiplex that right so that you still just go ubuntu.com slash download, download an AMD64 ISO and it does the right thing without you having a massive long list of different instruction sets to choose from for AMD64 so that work is coming but probably won't land for 24.04. We also continue to introduce new patches into things like GNOME, we are still trying to get the GNOME triple buffering stuff landed ready for 24.04 which gives a much smoother experience on the desktop as well. This runs really from Ubuntu server right up through to Ubuntu desktop and these tools will be available to desktop users too. You as a developer on Ubuntu should have access to the same debugging tools that you find in your production workloads in our opinion. On a side note, we are trying to do this at a really big scale at Canonical, we are hiring practice leads that will sit in a central team to build processes and tools and essentially give advice across our 40 or so products and we are also hiring dedicated performance engineers for every single team whether that team be doing Go, Python, NodeJSC or whatever. If you are interested in that talk to me afterwards, check out Canonical.com slash careers, there is a couple of Canonical folks in here as well who you can talk to. If performance is your thing and you want to come and make use of frame pointers and make Ubuntu blazing fast then that is always an option to you. Finally, from my side, we have done a bit of work with Polar Signals, they have been helping us along this way. We have snap packages and charms available for Parker both for the agent and the server. On any Ubuntu machine you can see this in a cloud in it file with a single line. You can snap and store the Parker agent, give it a single config with a token and start continuous profiling out into Polar Signals cloud or you can host this over infrastructure yourself on machines, on Kubernetes, on containers, whatever it is with Juju. We will continue to make improvements to that over time. It is a super easy way to get hold of this nice continuous profiling hotness in Ubuntu. That is it, get in touch. Thank you very much for that. Looking forward to the Ubuntu release. Are there any questions? Questions anyone? Once, twice, nobody? Okay, then thanks again and next up we have QuickWit I think in 20 minutes. Thank you, bye. Cheers.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 10.74, "text": " All right, so yeah, what's possible in observability when we have frame pointers is kind of the", "tokens": [50364, 1057, 558, 11, 370, 1338, 11, 437, 311, 1944, 294, 9951, 2310, 562, 321, 362, 3920, 44548, 307, 733, 295, 264, 50901], "temperature": 0.0, "avg_logprob": -0.2388804471945461, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.12435542792081833}, {"id": 1, "seek": 0, "start": 10.74, "end": 12.44, "text": " talk.", "tokens": [50901, 751, 13, 50986], "temperature": 0.0, "avg_logprob": -0.2388804471945461, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.12435542792081833}, {"id": 2, "seek": 0, "start": 12.44, "end": 18.8, "text": " But let's start out with like a kind of like actual use case of observability, right?", "tokens": [50986, 583, 718, 311, 722, 484, 365, 411, 257, 733, 295, 411, 3539, 764, 1389, 295, 9951, 2310, 11, 558, 30, 51304], "temperature": 0.0, "avg_logprob": -0.2388804471945461, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.12435542792081833}, {"id": 3, "seek": 0, "start": 18.8, "end": 21.04, "text": " So we have these workloads.", "tokens": [51304, 407, 321, 362, 613, 32452, 13, 51416], "temperature": 0.0, "avg_logprob": -0.2388804471945461, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.12435542792081833}, {"id": 4, "seek": 0, "start": 21.04, "end": 27.68, "text": " We can like graph the CPU cores and we can see some things happening and we might be", "tokens": [51416, 492, 393, 411, 4295, 264, 13199, 24826, 293, 321, 393, 536, 512, 721, 2737, 293, 321, 1062, 312, 51748], "temperature": 0.0, "avg_logprob": -0.2388804471945461, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.12435542792081833}, {"id": 5, "seek": 2768, "start": 27.68, "end": 31.48, "text": " wondering what's actually happening at these spikes, right?", "tokens": [50364, 6359, 437, 311, 767, 2737, 412, 613, 28997, 11, 558, 30, 50554], "temperature": 0.0, "avg_logprob": -0.17779280191444488, "compression_ratio": 1.7453703703703705, "no_speech_prob": 0.01847873069345951}, {"id": 6, "seek": 2768, "start": 31.48, "end": 37.76, "text": " And we can use profiling, I guess, to figure out what happens at these individual spikes", "tokens": [50554, 400, 321, 393, 764, 1740, 4883, 11, 286, 2041, 11, 281, 2573, 484, 437, 2314, 412, 613, 2609, 28997, 50868], "temperature": 0.0, "avg_logprob": -0.17779280191444488, "compression_ratio": 1.7453703703703705, "no_speech_prob": 0.01847873069345951}, {"id": 7, "seek": 2768, "start": 37.76, "end": 43.24, "text": " just to like understand, okay, like in this scenario this was happening in another scenario", "tokens": [50868, 445, 281, 411, 1223, 11, 1392, 11, 411, 294, 341, 9005, 341, 390, 2737, 294, 1071, 9005, 51142], "temperature": 0.0, "avg_logprob": -0.17779280191444488, "compression_ratio": 1.7453703703703705, "no_speech_prob": 0.01847873069345951}, {"id": 8, "seek": 2768, "start": 43.24, "end": 46.0, "text": " or like at another time something else happened.", "tokens": [51142, 420, 411, 412, 1071, 565, 746, 1646, 2011, 13, 51280], "temperature": 0.0, "avg_logprob": -0.17779280191444488, "compression_ratio": 1.7453703703703705, "no_speech_prob": 0.01847873069345951}, {"id": 9, "seek": 2768, "start": 46.0, "end": 51.92, "text": " We can like get profiles manually and compare them or we do something called continuous", "tokens": [51280, 492, 393, 411, 483, 23693, 16945, 293, 6794, 552, 420, 321, 360, 746, 1219, 10957, 51576], "temperature": 0.0, "avg_logprob": -0.17779280191444488, "compression_ratio": 1.7453703703703705, "no_speech_prob": 0.01847873069345951}, {"id": 10, "seek": 5192, "start": 51.92, "end": 59.32, "text": " profiling where we just like all the time over time, yeah, profile, hopefully a little", "tokens": [50364, 1740, 4883, 689, 321, 445, 411, 439, 264, 565, 670, 565, 11, 1338, 11, 7964, 11, 4696, 257, 707, 50734], "temperature": 0.0, "avg_logprob": -0.16893792659678358, "compression_ratio": 1.7077625570776256, "no_speech_prob": 0.012810120359063148}, {"id": 11, "seek": 5192, "start": 59.32, "end": 64.04, "text": " overhead we can even do it in production or not hopefully, but it's a reality.", "tokens": [50734, 19922, 321, 393, 754, 360, 309, 294, 4265, 420, 406, 4696, 11, 457, 309, 311, 257, 4103, 13, 50970], "temperature": 0.0, "avg_logprob": -0.16893792659678358, "compression_ratio": 1.7077625570776256, "no_speech_prob": 0.012810120359063148}, {"id": 12, "seek": 5192, "start": 64.04, "end": 65.72, "text": " We can do it in production, right?", "tokens": [50970, 492, 393, 360, 309, 294, 4265, 11, 558, 30, 51054], "temperature": 0.0, "avg_logprob": -0.16893792659678358, "compression_ratio": 1.7077625570776256, "no_speech_prob": 0.012810120359063148}, {"id": 13, "seek": 5192, "start": 65.72, "end": 73.48, "text": " So we can then store all of these profiles and over time kind of like ask questions when", "tokens": [51054, 407, 321, 393, 550, 3531, 439, 295, 613, 23693, 293, 670, 565, 733, 295, 411, 1029, 1651, 562, 51442], "temperature": 0.0, "avg_logprob": -0.16893792659678358, "compression_ratio": 1.7077625570776256, "no_speech_prob": 0.012810120359063148}, {"id": 14, "seek": 5192, "start": 73.48, "end": 79.68, "text": " we want to in retrospect and we don't have to worry about missing data points and we", "tokens": [51442, 321, 528, 281, 294, 34997, 293, 321, 500, 380, 362, 281, 3292, 466, 5361, 1412, 2793, 293, 321, 51752], "temperature": 0.0, "avg_logprob": -0.16893792659678358, "compression_ratio": 1.7077625570776256, "no_speech_prob": 0.012810120359063148}, {"id": 15, "seek": 7968, "start": 79.68, "end": 87.08000000000001, "text": " have kind of the security or yeah, the ease of use that we can just click on some spike", "tokens": [50364, 362, 733, 295, 264, 3825, 420, 1338, 11, 264, 12708, 295, 764, 300, 321, 393, 445, 2052, 322, 512, 21053, 50734], "temperature": 0.0, "avg_logprob": -0.144347152324638, "compression_ratio": 1.6695652173913043, "no_speech_prob": 0.06172478571534157}, {"id": 16, "seek": 7968, "start": 87.08000000000001, "end": 93.44000000000001, "text": " and then get a frame graph or in this case an icicle graph because it's like top down", "tokens": [50734, 293, 550, 483, 257, 3920, 4295, 420, 294, 341, 1389, 364, 4376, 3520, 4295, 570, 309, 311, 411, 1192, 760, 51052], "temperature": 0.0, "avg_logprob": -0.144347152324638, "compression_ratio": 1.6695652173913043, "no_speech_prob": 0.06172478571534157}, {"id": 17, "seek": 7968, "start": 93.44000000000001, "end": 95.0, "text": " and not the other way around.", "tokens": [51052, 293, 406, 264, 661, 636, 926, 13, 51130], "temperature": 0.0, "avg_logprob": -0.144347152324638, "compression_ratio": 1.6695652173913043, "no_speech_prob": 0.06172478571534157}, {"id": 18, "seek": 7968, "start": 95.0, "end": 101.04, "text": " We call it icicle graphs and you can see all the stack traces and you can like instrument", "tokens": [51130, 492, 818, 309, 4376, 3520, 24877, 293, 291, 393, 536, 439, 264, 8630, 26076, 293, 291, 393, 411, 7198, 51432], "temperature": 0.0, "avg_logprob": -0.144347152324638, "compression_ratio": 1.6695652173913043, "no_speech_prob": 0.06172478571534157}, {"id": 19, "seek": 7968, "start": 101.04, "end": 107.12, "text": " very nicely, introspect what's happening and I don't have a slide for this but we can also", "tokens": [51432, 588, 9594, 11, 560, 28713, 437, 311, 2737, 293, 286, 500, 380, 362, 257, 4137, 337, 341, 457, 321, 393, 611, 51736], "temperature": 0.0, "avg_logprob": -0.144347152324638, "compression_ratio": 1.6695652173913043, "no_speech_prob": 0.06172478571534157}, {"id": 20, "seek": 10712, "start": 107.16000000000001, "end": 111.64, "text": " kind of like this flame graphs and then we can see in like red where things got worse", "tokens": [50366, 733, 295, 411, 341, 13287, 24877, 293, 550, 321, 393, 536, 294, 411, 2182, 689, 721, 658, 5324, 50590], "temperature": 0.0, "avg_logprob": -0.16610260009765626, "compression_ratio": 1.7789473684210526, "no_speech_prob": 0.022934937849640846}, {"id": 21, "seek": 10712, "start": 111.64, "end": 116.92, "text": " and in green usually where things gotten better and it's pretty obvious most of the time if", "tokens": [50590, 293, 294, 3092, 2673, 689, 721, 5768, 1101, 293, 309, 311, 1238, 6322, 881, 295, 264, 565, 498, 50854], "temperature": 0.0, "avg_logprob": -0.16610260009765626, "compression_ratio": 1.7789473684210526, "no_speech_prob": 0.022934937849640846}, {"id": 22, "seek": 10712, "start": 116.92, "end": 121.0, "text": " you have such a big spike like that's right the point where we need to look in such a", "tokens": [50854, 291, 362, 1270, 257, 955, 21053, 411, 300, 311, 558, 264, 935, 689, 321, 643, 281, 574, 294, 1270, 257, 51058], "temperature": 0.0, "avg_logprob": -0.16610260009765626, "compression_ratio": 1.7789473684210526, "no_speech_prob": 0.022934937849640846}, {"id": 23, "seek": 10712, "start": 121.0, "end": 125.56, "text": " flame graph and where we need to like check out what's happening in the code.", "tokens": [51058, 13287, 4295, 293, 689, 321, 643, 281, 411, 1520, 484, 437, 311, 2737, 294, 264, 3089, 13, 51286], "temperature": 0.0, "avg_logprob": -0.16610260009765626, "compression_ratio": 1.7789473684210526, "no_speech_prob": 0.022934937849640846}, {"id": 24, "seek": 10712, "start": 125.56, "end": 130.56, "text": " So yeah, that's kind of a pretty good use case for observability, right?", "tokens": [51286, 407, 1338, 11, 300, 311, 733, 295, 257, 1238, 665, 764, 1389, 337, 9951, 2310, 11, 558, 30, 51536], "temperature": 0.0, "avg_logprob": -0.16610260009765626, "compression_ratio": 1.7789473684210526, "no_speech_prob": 0.022934937849640846}, {"id": 25, "seek": 10712, "start": 130.56, "end": 135.04000000000002, "text": " But yeah, what our frame point is but before we come to that quick introduction I'm Matthias", "tokens": [51536, 583, 1338, 11, 437, 527, 3920, 935, 307, 457, 949, 321, 808, 281, 300, 1702, 9339, 286, 478, 11327, 4609, 51760], "temperature": 0.0, "avg_logprob": -0.16610260009765626, "compression_ratio": 1.7789473684210526, "no_speech_prob": 0.022934937849640846}, {"id": 26, "seek": 13504, "start": 135.07999999999998, "end": 139.6, "text": " L\u00e4uwe, I'm a senior software engineer at Polar Signals, I work on Parker which is like", "tokens": [50366, 441, 737, 84, 826, 11, 286, 478, 257, 7965, 4722, 11403, 412, 3635, 289, 13515, 1124, 11, 286, 589, 322, 20155, 597, 307, 411, 50592], "temperature": 0.0, "avg_logprob": -0.2166381987514875, "compression_ratio": 1.699421965317919, "no_speech_prob": 0.032865528017282486}, {"id": 27, "seek": 13504, "start": 139.6, "end": 143.76, "text": " the open source project doing a bunch of these things but I also work on Thanos, Prometheus", "tokens": [50592, 264, 1269, 4009, 1716, 884, 257, 3840, 295, 613, 721, 457, 286, 611, 589, 322, 35993, 11, 2114, 649, 42209, 50800], "temperature": 0.0, "avg_logprob": -0.2166381987514875, "compression_ratio": 1.699421965317919, "no_speech_prob": 0.032865528017282486}, {"id": 28, "seek": 13504, "start": 143.76, "end": 147.79999999999998, "text": " and lots of other open source monitoring projects.", "tokens": [50800, 293, 3195, 295, 661, 1269, 4009, 11028, 4455, 13, 51002], "temperature": 0.0, "avg_logprob": -0.2166381987514875, "compression_ratio": 1.699421965317919, "no_speech_prob": 0.032865528017282486}, {"id": 29, "seek": 13504, "start": 147.79999999999998, "end": 152.2, "text": " Yeah and hey everyone, I'm John Seger, I'm VP of Engineering at Canonical, I have a kind", "tokens": [51002, 865, 293, 4177, 1518, 11, 286, 478, 2619, 1100, 1321, 11, 286, 478, 35812, 295, 16215, 412, 27666, 804, 11, 286, 362, 257, 733, 51222], "temperature": 0.0, "avg_logprob": -0.2166381987514875, "compression_ratio": 1.699421965317919, "no_speech_prob": 0.032865528017282486}, {"id": 30, "seek": 13504, "start": 152.2, "end": 155.35999999999999, "text": " of interesting journey to open source but at the moment I am leading the development", "tokens": [51222, 295, 1880, 4671, 281, 1269, 4009, 457, 412, 264, 1623, 286, 669, 5775, 264, 3250, 51380], "temperature": 0.0, "avg_logprob": -0.2166381987514875, "compression_ratio": 1.699421965317919, "no_speech_prob": 0.032865528017282486}, {"id": 31, "seek": 13504, "start": 155.35999999999999, "end": 160.2, "text": " of Juju and a whole suite of kind of enterprise apps which we call Charm so if you want to", "tokens": [51380, 295, 508, 45652, 293, 257, 1379, 14205, 295, 733, 295, 14132, 7733, 597, 321, 818, 4327, 76, 370, 498, 291, 528, 281, 51622], "temperature": 0.0, "avg_logprob": -0.2166381987514875, "compression_ratio": 1.699421965317919, "no_speech_prob": 0.032865528017282486}, {"id": 32, "seek": 13504, "start": 160.2, "end": 164.95999999999998, "text": " get access to like the best Postgres on your infrastructure or the best MySQL or the Grafana", "tokens": [51622, 483, 2105, 281, 411, 264, 1151, 10223, 45189, 322, 428, 6896, 420, 264, 1151, 1222, 39934, 420, 264, 8985, 69, 2095, 51860], "temperature": 0.0, "avg_logprob": -0.2166381987514875, "compression_ratio": 1.699421965317919, "no_speech_prob": 0.032865528017282486}, {"id": 33, "seek": 16496, "start": 165.0, "end": 169.88, "text": " stack or Parker or you want to build an identity stack with ORI and with OpenFGA and products", "tokens": [50366, 8630, 420, 20155, 420, 291, 528, 281, 1322, 364, 6575, 8630, 365, 422, 5577, 293, 365, 7238, 37, 12570, 293, 3383, 50610], "temperature": 0.0, "avg_logprob": -0.15812642121117962, "compression_ratio": 1.6449511400651466, "no_speech_prob": 0.018367107957601547}, {"id": 34, "seek": 16496, "start": 169.88, "end": 173.48000000000002, "text": " like that, that's kind of the effort that I'm leading.", "tokens": [50610, 411, 300, 11, 300, 311, 733, 295, 264, 4630, 300, 286, 478, 5775, 13, 50790], "temperature": 0.0, "avg_logprob": -0.15812642121117962, "compression_ratio": 1.6449511400651466, "no_speech_prob": 0.018367107957601547}, {"id": 35, "seek": 16496, "start": 173.48000000000002, "end": 176.60000000000002, "text": " The orchestrator is called Juju, it's been around a really long time, Charm's all written", "tokens": [50790, 440, 14161, 19802, 307, 1219, 508, 45652, 11, 309, 311, 668, 926, 257, 534, 938, 565, 11, 4327, 76, 311, 439, 3720, 50946], "temperature": 0.0, "avg_logprob": -0.15812642121117962, "compression_ratio": 1.6449511400651466, "no_speech_prob": 0.018367107957601547}, {"id": 36, "seek": 16496, "start": 176.60000000000002, "end": 180.16, "text": " in Python and we're kind of building out a big catalogue of operators that allow you", "tokens": [50946, 294, 15329, 293, 321, 434, 733, 295, 2390, 484, 257, 955, 13192, 7213, 295, 19077, 300, 2089, 291, 51124], "temperature": 0.0, "avg_logprob": -0.15812642121117962, "compression_ratio": 1.6449511400651466, "no_speech_prob": 0.018367107957601547}, {"id": 37, "seek": 16496, "start": 180.16, "end": 184.76000000000002, "text": " to not just deploy those things but actually compose them all together and integrate them", "tokens": [51124, 281, 406, 445, 7274, 729, 721, 457, 767, 35925, 552, 439, 1214, 293, 13365, 552, 51354], "temperature": 0.0, "avg_logprob": -0.15812642121117962, "compression_ratio": 1.6449511400651466, "no_speech_prob": 0.018367107957601547}, {"id": 38, "seek": 16496, "start": 184.76000000000002, "end": 188.92000000000002, "text": " in a really common way irrespective of whether your infrastructure happens to be bare metal", "tokens": [51354, 294, 257, 534, 2689, 636, 3418, 19575, 488, 295, 1968, 428, 6896, 2314, 281, 312, 6949, 5760, 51562], "temperature": 0.0, "avg_logprob": -0.15812642121117962, "compression_ratio": 1.6449511400651466, "no_speech_prob": 0.018367107957601547}, {"id": 39, "seek": 18892, "start": 188.95999999999998, "end": 195.44, "text": " or Kubernetes or VMs or on EC2 or on Azure or some combination of the whole lot so that's", "tokens": [50366, 420, 23145, 420, 18038, 82, 420, 322, 19081, 17, 420, 322, 11969, 420, 512, 6562, 295, 264, 1379, 688, 370, 300, 311, 50690], "temperature": 0.0, "avg_logprob": -0.22125157288142613, "compression_ratio": 1.5793650793650793, "no_speech_prob": 0.1011064201593399}, {"id": 40, "seek": 18892, "start": 195.44, "end": 197.6, "text": " kind of what I'm up to at the moment.", "tokens": [50690, 733, 295, 437, 286, 478, 493, 281, 412, 264, 1623, 13, 50798], "temperature": 0.0, "avg_logprob": -0.22125157288142613, "compression_ratio": 1.5793650793650793, "no_speech_prob": 0.1011064201593399}, {"id": 41, "seek": 18892, "start": 197.6, "end": 202.23999999999998, "text": " Awesome, yeah and I'm looking forward to hearing more from you but before I do that, let's", "tokens": [50798, 10391, 11, 1338, 293, 286, 478, 1237, 2128, 281, 4763, 544, 490, 291, 457, 949, 286, 360, 300, 11, 718, 311, 51030], "temperature": 0.0, "avg_logprob": -0.22125157288142613, "compression_ratio": 1.5793650793650793, "no_speech_prob": 0.1011064201593399}, {"id": 42, "seek": 18892, "start": 202.23999999999998, "end": 208.11999999999998, "text": " talk about profiling again or like what profiling data is made up of and you can see these", "tokens": [51030, 751, 466, 1740, 4883, 797, 420, 411, 437, 1740, 4883, 1412, 307, 1027, 493, 295, 293, 291, 393, 536, 613, 51324], "temperature": 0.0, "avg_logprob": -0.22125157288142613, "compression_ratio": 1.5793650793650793, "no_speech_prob": 0.1011064201593399}, {"id": 43, "seek": 18892, "start": 208.11999999999998, "end": 216.11999999999998, "text": " like points in time just T1, T2, T3, at some point in time, we basically want to look at", "tokens": [51324, 411, 2793, 294, 565, 445, 314, 16, 11, 314, 17, 11, 314, 18, 11, 412, 512, 935, 294, 565, 11, 321, 1936, 528, 281, 574, 412, 51724], "temperature": 0.0, "avg_logprob": -0.22125157288142613, "compression_ratio": 1.5793650793650793, "no_speech_prob": 0.1011064201593399}, {"id": 44, "seek": 21612, "start": 216.64000000000001, "end": 221.8, "text": " the current stack trace or what the program state looks like and we can see that like", "tokens": [50390, 264, 2190, 8630, 13508, 420, 437, 264, 1461, 1785, 1542, 411, 293, 321, 393, 536, 300, 411, 50648], "temperature": 0.0, "avg_logprob": -0.18377787133921747, "compression_ratio": 1.7149532710280373, "no_speech_prob": 0.044351257383823395}, {"id": 45, "seek": 21612, "start": 221.8, "end": 228.8, "text": " at T1 we had ABCD, at T2 we had ABCNE so slightly different and then at T3 we had the same thing", "tokens": [50648, 412, 314, 16, 321, 632, 22342, 35, 11, 412, 314, 17, 321, 632, 22342, 15988, 370, 4748, 819, 293, 550, 412, 314, 18, 321, 632, 264, 912, 551, 50998], "temperature": 0.0, "avg_logprob": -0.18377787133921747, "compression_ratio": 1.7149532710280373, "no_speech_prob": 0.044351257383823395}, {"id": 46, "seek": 21612, "start": 230.28, "end": 235.64000000000001, "text": " again so kind of like just for the sake of the demo or the example, one was like executed", "tokens": [51072, 797, 370, 733, 295, 411, 445, 337, 264, 9717, 295, 264, 10723, 420, 264, 1365, 11, 472, 390, 411, 17577, 51340], "temperature": 0.0, "avg_logprob": -0.18377787133921747, "compression_ratio": 1.7149532710280373, "no_speech_prob": 0.044351257383823395}, {"id": 47, "seek": 21612, "start": 235.64000000000001, "end": 240.08, "text": " twice so maybe it was like executed 20 milliseconds in total and the other one 10 milliseconds", "tokens": [51340, 6091, 370, 1310, 309, 390, 411, 17577, 945, 34184, 294, 3217, 293, 264, 661, 472, 1266, 34184, 51562], "temperature": 0.0, "avg_logprob": -0.18377787133921747, "compression_ratio": 1.7149532710280373, "no_speech_prob": 0.044351257383823395}, {"id": 48, "seek": 24008, "start": 240.16000000000003, "end": 246.4, "text": " so we kind of like count how often we see these stacks and then kind of can make assumption", "tokens": [50368, 370, 321, 733, 295, 411, 1207, 577, 2049, 321, 536, 613, 30792, 293, 550, 733, 295, 393, 652, 15302, 50680], "temperature": 0.0, "avg_logprob": -0.18208112319310507, "compression_ratio": 1.7929515418502202, "no_speech_prob": 0.04199652746319771}, {"id": 49, "seek": 24008, "start": 246.4, "end": 253.4, "text": " on how much it is running and this is kind of like a sampled profiling profiler, it basically", "tokens": [50680, 322, 577, 709, 309, 307, 2614, 293, 341, 307, 733, 295, 411, 257, 3247, 15551, 1740, 4883, 1740, 5441, 11, 309, 1936, 51030], "temperature": 0.0, "avg_logprob": -0.18208112319310507, "compression_ratio": 1.7929515418502202, "no_speech_prob": 0.04199652746319771}, {"id": 50, "seek": 24008, "start": 254.04000000000002, "end": 259.76, "text": " only like every so often looks at these stack traces but over time we can really nicely", "tokens": [51062, 787, 411, 633, 370, 2049, 1542, 412, 613, 8630, 26076, 457, 670, 565, 321, 393, 534, 9594, 51348], "temperature": 0.0, "avg_logprob": -0.18208112319310507, "compression_ratio": 1.7929515418502202, "no_speech_prob": 0.04199652746319771}, {"id": 51, "seek": 24008, "start": 259.76, "end": 263.24, "text": " like see the big picture of things happening.", "tokens": [51348, 411, 536, 264, 955, 3036, 295, 721, 2737, 13, 51522], "temperature": 0.0, "avg_logprob": -0.18208112319310507, "compression_ratio": 1.7929515418502202, "no_speech_prob": 0.04199652746319771}, {"id": 52, "seek": 24008, "start": 263.24, "end": 267.16, "text": " The good thing is because it's only happening so often the overhead is pretty low which", "tokens": [51522, 440, 665, 551, 307, 570, 309, 311, 787, 2737, 370, 2049, 264, 19922, 307, 1238, 2295, 597, 51718], "temperature": 0.0, "avg_logprob": -0.18208112319310507, "compression_ratio": 1.7929515418502202, "no_speech_prob": 0.04199652746319771}, {"id": 53, "seek": 26716, "start": 267.24, "end": 273.8, "text": " again I touched on earlier for our use case figuring out what's going on, it's pretty nice", "tokens": [50368, 797, 286, 9828, 322, 3071, 337, 527, 764, 1389, 15213, 484, 437, 311, 516, 322, 11, 309, 311, 1238, 1481, 50696], "temperature": 0.0, "avg_logprob": -0.2064317294529506, "compression_ratio": 1.6201923076923077, "no_speech_prob": 0.004322964232414961}, {"id": 54, "seek": 26716, "start": 273.8, "end": 277.0, "text": " due to being pretty low overhead.", "tokens": [50696, 3462, 281, 885, 1238, 2295, 19922, 13, 50856], "temperature": 0.0, "avg_logprob": -0.2064317294529506, "compression_ratio": 1.6201923076923077, "no_speech_prob": 0.004322964232414961}, {"id": 55, "seek": 26716, "start": 277.0, "end": 282.92, "text": " So how do we get to these stack traces, how can we see these stacks that we then get all", "tokens": [50856, 407, 577, 360, 321, 483, 281, 613, 8630, 26076, 11, 577, 393, 321, 536, 613, 30792, 300, 321, 550, 483, 439, 51152], "temperature": 0.0, "avg_logprob": -0.2064317294529506, "compression_ratio": 1.6201923076923077, "no_speech_prob": 0.004322964232414961}, {"id": 56, "seek": 26716, "start": 282.92, "end": 288.48, "text": " the memory addresses for and then we can like nicely format them using the function names", "tokens": [51152, 264, 4675, 16862, 337, 293, 550, 321, 393, 411, 9594, 7877, 552, 1228, 264, 2445, 5288, 51430], "temperature": 0.0, "avg_logprob": -0.2064317294529506, "compression_ratio": 1.6201923076923077, "no_speech_prob": 0.004322964232414961}, {"id": 57, "seek": 26716, "start": 288.48, "end": 290.6, "text": " for example in the icicle graphs.", "tokens": [51430, 337, 1365, 294, 264, 4376, 3520, 24877, 13, 51536], "temperature": 0.0, "avg_logprob": -0.2064317294529506, "compression_ratio": 1.6201923076923077, "no_speech_prob": 0.004322964232414961}, {"id": 58, "seek": 29060, "start": 290.64000000000004, "end": 297.44, "text": " So the best case and that's kind of the whole point of the talk right are frame pointers", "tokens": [50366, 407, 264, 1151, 1389, 293, 300, 311, 733, 295, 264, 1379, 935, 295, 264, 751, 558, 366, 3920, 44548, 50706], "temperature": 0.0, "avg_logprob": -0.17236150029193925, "compression_ratio": 1.7738693467336684, "no_speech_prob": 0.017941880971193314}, {"id": 59, "seek": 29060, "start": 297.44, "end": 304.44, "text": " and frame pointers looking at this bit of C code it's hopefully not too daunting in", "tokens": [50706, 293, 3920, 44548, 1237, 412, 341, 857, 295, 383, 3089, 309, 311, 4696, 406, 886, 37657, 294, 51056], "temperature": 0.0, "avg_logprob": -0.17236150029193925, "compression_ratio": 1.7738693467336684, "no_speech_prob": 0.017941880971193314}, {"id": 60, "seek": 29060, "start": 305.0, "end": 309.32000000000005, "text": " a monitoring observability room but we can see we have the main function at the bottom", "tokens": [51084, 257, 11028, 9951, 2310, 1808, 457, 321, 393, 536, 321, 362, 264, 2135, 2445, 412, 264, 2767, 51300], "temperature": 0.0, "avg_logprob": -0.17236150029193925, "compression_ratio": 1.7738693467336684, "no_speech_prob": 0.017941880971193314}, {"id": 61, "seek": 29060, "start": 309.32000000000005, "end": 314.96000000000004, "text": " and that calls a function and so on the functions call each other and then at the very top it", "tokens": [51300, 293, 300, 5498, 257, 2445, 293, 370, 322, 264, 6828, 818, 1184, 661, 293, 550, 412, 264, 588, 1192, 309, 51582], "temperature": 0.0, "avg_logprob": -0.17236150029193925, "compression_ratio": 1.7738693467336684, "no_speech_prob": 0.017941880971193314}, {"id": 62, "seek": 31496, "start": 315.0, "end": 317.4, "text": " just goes into an endless loop.", "tokens": [50366, 445, 1709, 666, 364, 16144, 6367, 13, 50486], "temperature": 0.0, "avg_logprob": -0.17139785847765335, "compression_ratio": 1.7256637168141593, "no_speech_prob": 0.04730582237243652}, {"id": 63, "seek": 31496, "start": 317.4, "end": 322.96, "text": " And kind of the important part in all of this is looking at the assembly on the right hand", "tokens": [50486, 400, 733, 295, 264, 1021, 644, 294, 439, 295, 341, 307, 1237, 412, 264, 12103, 322, 264, 558, 1011, 50764], "temperature": 0.0, "avg_logprob": -0.17139785847765335, "compression_ratio": 1.7256637168141593, "no_speech_prob": 0.04730582237243652}, {"id": 64, "seek": 31496, "start": 322.96, "end": 329.96, "text": " side we can see that okay I omitted like the main function and the a1 but then we can see", "tokens": [50764, 1252, 321, 393, 536, 300, 1392, 286, 3406, 3944, 411, 264, 2135, 2445, 293, 264, 257, 16, 457, 550, 321, 393, 536, 51114], "temperature": 0.0, "avg_logprob": -0.17139785847765335, "compression_ratio": 1.7256637168141593, "no_speech_prob": 0.04730582237243652}, {"id": 65, "seek": 31496, "start": 329.96, "end": 336.71999999999997, "text": " b1 and we can see that at the very beginning we are pushing and moving some registers around", "tokens": [51114, 272, 16, 293, 321, 393, 536, 300, 412, 264, 588, 2863, 321, 366, 7380, 293, 2684, 512, 38351, 926, 51452], "temperature": 0.0, "avg_logprob": -0.17139785847765335, "compression_ratio": 1.7256637168141593, "no_speech_prob": 0.04730582237243652}, {"id": 66, "seek": 31496, "start": 336.71999999999997, "end": 341.67999999999995, "text": " and those are actually the instructions to push the frame pointer onto the stack and", "tokens": [51452, 293, 729, 366, 767, 264, 9415, 281, 2944, 264, 3920, 23918, 3911, 264, 8630, 293, 51700], "temperature": 0.0, "avg_logprob": -0.17139785847765335, "compression_ratio": 1.7256637168141593, "no_speech_prob": 0.04730582237243652}, {"id": 67, "seek": 34168, "start": 341.68, "end": 348.56, "text": " then we are calling the next function right and the pushing of the registers so that we", "tokens": [50364, 550, 321, 366, 5141, 264, 958, 2445, 558, 293, 264, 7380, 295, 264, 38351, 370, 300, 321, 50708], "temperature": 0.0, "avg_logprob": -0.14449698997266364, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0009536776342429221}, {"id": 68, "seek": 34168, "start": 348.56, "end": 355.56, "text": " know once the next function is done executing we can come back to exactly that previous", "tokens": [50708, 458, 1564, 264, 958, 2445, 307, 1096, 32368, 321, 393, 808, 646, 281, 2293, 300, 3894, 51058], "temperature": 0.0, "avg_logprob": -0.14449698997266364, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0009536776342429221}, {"id": 69, "seek": 34168, "start": 355.68, "end": 361.0, "text": " function and continue executing.", "tokens": [51064, 2445, 293, 2354, 32368, 13, 51330], "temperature": 0.0, "avg_logprob": -0.14449698997266364, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0009536776342429221}, {"id": 70, "seek": 34168, "start": 361.0, "end": 367.2, "text": " The one thing I want to mention here is in the past there were a couple of discussions", "tokens": [51330, 440, 472, 551, 286, 528, 281, 2152, 510, 307, 294, 264, 1791, 456, 645, 257, 1916, 295, 11088, 51640], "temperature": 0.0, "avg_logprob": -0.14449698997266364, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0009536776342429221}, {"id": 71, "seek": 36720, "start": 367.2, "end": 372.71999999999997, "text": " about the overhead of using frame pointer so we have the push and move instructions", "tokens": [50364, 466, 264, 19922, 295, 1228, 3920, 23918, 370, 321, 362, 264, 2944, 293, 1286, 9415, 50640], "temperature": 0.0, "avg_logprob": -0.14482317368189493, "compression_ratio": 1.7038461538461538, "no_speech_prob": 0.005132673308253288}, {"id": 72, "seek": 36720, "start": 372.71999999999997, "end": 378.47999999999996, "text": " and then once the function is done it needs to pop that frame pointer so there were a", "tokens": [50640, 293, 550, 1564, 264, 2445, 307, 1096, 309, 2203, 281, 1665, 300, 3920, 23918, 370, 456, 645, 257, 50928], "temperature": 0.0, "avg_logprob": -0.14482317368189493, "compression_ratio": 1.7038461538461538, "no_speech_prob": 0.005132673308253288}, {"id": 73, "seek": 36720, "start": 378.47999999999996, "end": 385.48, "text": " couple of extra assembly steps involved especially on 30 bit systems it wasn't great performance", "tokens": [50928, 1916, 295, 2857, 12103, 4439, 3288, 2318, 322, 2217, 857, 3652, 309, 2067, 380, 869, 3389, 51278], "temperature": 0.0, "avg_logprob": -0.14482317368189493, "compression_ratio": 1.7038461538461538, "no_speech_prob": 0.005132673308253288}, {"id": 74, "seek": 36720, "start": 385.76, "end": 391.03999999999996, "text": " wise but I think unless you are a really really special case it should be fine for almost", "tokens": [51292, 10829, 457, 286, 519, 5969, 291, 366, 257, 534, 534, 2121, 1389, 309, 820, 312, 2489, 337, 1920, 51556], "temperature": 0.0, "avg_logprob": -0.14482317368189493, "compression_ratio": 1.7038461538461538, "no_speech_prob": 0.005132673308253288}, {"id": 75, "seek": 36720, "start": 391.03999999999996, "end": 396.2, "text": " all workloads even in production and that's kind of the point of this so basically our", "tokens": [51556, 439, 32452, 754, 294, 4265, 293, 300, 311, 733, 295, 264, 935, 295, 341, 370, 1936, 527, 51814], "temperature": 0.0, "avg_logprob": -0.14482317368189493, "compression_ratio": 1.7038461538461538, "no_speech_prob": 0.005132673308253288}, {"id": 76, "seek": 39620, "start": 396.2, "end": 402.64, "text": " binary on the left hand side we can see our set up frame pointer so that's kind of the", "tokens": [50364, 17434, 322, 264, 1411, 1011, 1252, 321, 393, 536, 527, 992, 493, 3920, 23918, 370, 300, 311, 733, 295, 264, 50686], "temperature": 0.0, "avg_logprob": -0.13165338039398194, "compression_ratio": 1.8256410256410256, "no_speech_prob": 0.0029774873983114958}, {"id": 77, "seek": 39620, "start": 402.64, "end": 409.12, "text": " first instruction that our assembly is executing it is putting the frame pointer onto the stack", "tokens": [50686, 700, 10951, 300, 527, 12103, 307, 32368, 309, 307, 3372, 264, 3920, 23918, 3911, 264, 8630, 51010], "temperature": 0.0, "avg_logprob": -0.13165338039398194, "compression_ratio": 1.8256410256410256, "no_speech_prob": 0.0029774873983114958}, {"id": 78, "seek": 39620, "start": 409.12, "end": 416.12, "text": " before then going and doing the actual call to the next function right and before doing", "tokens": [51010, 949, 550, 516, 293, 884, 264, 3539, 818, 281, 264, 958, 2445, 558, 293, 949, 884, 51360], "temperature": 0.0, "avg_logprob": -0.13165338039398194, "compression_ratio": 1.8256410256410256, "no_speech_prob": 0.0029774873983114958}, {"id": 79, "seek": 39620, "start": 416.2, "end": 421.88, "text": " that we have to add the return address to our stack so that once the function that we", "tokens": [51364, 300, 321, 362, 281, 909, 264, 2736, 2985, 281, 527, 8630, 370, 300, 1564, 264, 2445, 300, 321, 51648], "temperature": 0.0, "avg_logprob": -0.13165338039398194, "compression_ratio": 1.8256410256410256, "no_speech_prob": 0.0029774873983114958}, {"id": 80, "seek": 42188, "start": 421.92, "end": 428.2, "text": " are calling is done we know where to continue in our current function right so we need to", "tokens": [50366, 366, 5141, 307, 1096, 321, 458, 689, 281, 2354, 294, 527, 2190, 2445, 558, 370, 321, 643, 281, 50680], "temperature": 0.0, "avg_logprob": -0.12449999700618695, "compression_ratio": 1.9661016949152543, "no_speech_prob": 0.022554636001586914}, {"id": 81, "seek": 42188, "start": 428.2, "end": 433.36, "text": " know where like this other code we need to execute after calling the function we are", "tokens": [50680, 458, 689, 411, 341, 661, 3089, 321, 643, 281, 14483, 934, 5141, 264, 2445, 321, 366, 50938], "temperature": 0.0, "avg_logprob": -0.12449999700618695, "compression_ratio": 1.9661016949152543, "no_speech_prob": 0.022554636001586914}, {"id": 82, "seek": 42188, "start": 433.36, "end": 440.36, "text": " calling right now where we need to continue so that's why we have the return address", "tokens": [50938, 5141, 558, 586, 689, 321, 643, 281, 2354, 370, 300, 311, 983, 321, 362, 264, 2736, 2985, 51288], "temperature": 0.0, "avg_logprob": -0.12449999700618695, "compression_ratio": 1.9661016949152543, "no_speech_prob": 0.022554636001586914}, {"id": 83, "seek": 42188, "start": 440.6, "end": 447.6, "text": " and we then actually do the function preamble and we run that function and eventually we", "tokens": [51300, 293, 321, 550, 767, 360, 264, 2445, 659, 335, 638, 293, 321, 1190, 300, 2445, 293, 4728, 321, 51650], "temperature": 0.0, "avg_logprob": -0.12449999700618695, "compression_ratio": 1.9661016949152543, "no_speech_prob": 0.022554636001586914}, {"id": 84, "seek": 44760, "start": 447.6, "end": 454.6, "text": " return the function we are at the pointer that then actually tells us where to go back", "tokens": [50364, 2736, 264, 2445, 321, 366, 412, 264, 23918, 300, 550, 767, 5112, 505, 689, 281, 352, 646, 50714], "temperature": 0.0, "avg_logprob": -0.19507580537062424, "compression_ratio": 1.9243243243243244, "no_speech_prob": 0.009545189328491688}, {"id": 85, "seek": 44760, "start": 454.6, "end": 461.6, "text": " to right so the function that we called eventually returns and we want to go back to the original", "tokens": [50714, 281, 558, 370, 264, 2445, 300, 321, 1219, 4728, 11247, 293, 321, 528, 281, 352, 646, 281, 264, 3380, 51064], "temperature": 0.0, "avg_logprob": -0.19507580537062424, "compression_ratio": 1.9243243243243244, "no_speech_prob": 0.009545189328491688}, {"id": 86, "seek": 44760, "start": 461.76000000000005, "end": 468.76000000000005, "text": " function however we are then executing after that function call right so previously we", "tokens": [51072, 2445, 4461, 321, 366, 550, 32368, 934, 300, 2445, 818, 558, 370, 8046, 321, 51422], "temperature": 0.0, "avg_logprob": -0.19507580537062424, "compression_ratio": 1.9243243243243244, "no_speech_prob": 0.009545189328491688}, {"id": 87, "seek": 44760, "start": 468.96000000000004, "end": 475.96000000000004, "text": " were can you see my mouse no we were over here and now we returned like one step and", "tokens": [51432, 645, 393, 291, 536, 452, 9719, 572, 321, 645, 670, 510, 293, 586, 321, 8752, 411, 472, 1823, 293, 51782], "temperature": 0.0, "avg_logprob": -0.19507580537062424, "compression_ratio": 1.9243243243243244, "no_speech_prob": 0.009545189328491688}, {"id": 88, "seek": 47760, "start": 477.68, "end": 481.88, "text": " after that right because we don't want to call that function again going into an endless", "tokens": [50368, 934, 300, 558, 570, 321, 500, 380, 528, 281, 818, 300, 2445, 797, 516, 666, 364, 16144, 50578], "temperature": 0.0, "avg_logprob": -0.13466731611504612, "compression_ratio": 1.9358288770053476, "no_speech_prob": 0.004894530400633812}, {"id": 89, "seek": 47760, "start": 481.88, "end": 488.88, "text": " loop we want to continue afterwards however we want to know what called us right so basically", "tokens": [50578, 6367, 321, 528, 281, 2354, 10543, 4461, 321, 528, 281, 458, 437, 1219, 505, 558, 370, 1936, 50928], "temperature": 0.0, "avg_logprob": -0.13466731611504612, "compression_ratio": 1.9358288770053476, "no_speech_prob": 0.004894530400633812}, {"id": 90, "seek": 47760, "start": 489.68, "end": 495.88, "text": " what we want to do is whenever we have a stack we want to know which function called us and", "tokens": [50968, 437, 321, 528, 281, 360, 307, 5699, 321, 362, 257, 8630, 321, 528, 281, 458, 597, 2445, 1219, 505, 293, 51278], "temperature": 0.0, "avg_logprob": -0.13466731611504612, "compression_ratio": 1.9358288770053476, "no_speech_prob": 0.004894530400633812}, {"id": 91, "seek": 47760, "start": 495.88, "end": 500.88, "text": " do that all the way such that we eventually end up in the main function and we know all", "tokens": [51278, 360, 300, 439, 264, 636, 1270, 300, 321, 4728, 917, 493, 294, 264, 2135, 2445, 293, 321, 458, 439, 51528], "temperature": 0.0, "avg_logprob": -0.13466731611504612, "compression_ratio": 1.9358288770053476, "no_speech_prob": 0.004894530400633812}, {"id": 92, "seek": 50088, "start": 500.88, "end": 507.88, "text": " the functions that we see that we have on the stack up to the point where we are now", "tokens": [50364, 264, 6828, 300, 321, 536, 300, 321, 362, 322, 264, 8630, 493, 281, 264, 935, 689, 321, 366, 586, 50714], "temperature": 0.0, "avg_logprob": -0.1864007885536451, "compression_ratio": 1.7916666666666667, "no_speech_prob": 0.06538723409175873}, {"id": 93, "seek": 50088, "start": 508.15999999999997, "end": 513.36, "text": " basically that's kind of like working the stack here and the really really cool thing", "tokens": [50728, 1936, 300, 311, 733, 295, 411, 1364, 264, 8630, 510, 293, 264, 534, 534, 1627, 551, 50988], "temperature": 0.0, "avg_logprob": -0.1864007885536451, "compression_ratio": 1.7916666666666667, "no_speech_prob": 0.06538723409175873}, {"id": 94, "seek": 50088, "start": 513.36, "end": 520.36, "text": " is we can do this in ebpf so I don't know how many attend the previous talk ebpf kind", "tokens": [50988, 307, 321, 393, 360, 341, 294, 308, 65, 25302, 370, 286, 500, 380, 458, 577, 867, 6888, 264, 3894, 751, 308, 65, 25302, 733, 51338], "temperature": 0.0, "avg_logprob": -0.1864007885536451, "compression_ratio": 1.7916666666666667, "no_speech_prob": 0.06538723409175873}, {"id": 95, "seek": 50088, "start": 521.0, "end": 525.88, "text": " of a hot topic right now for us it's really really cool because what we can do is write", "tokens": [51370, 295, 257, 2368, 4829, 558, 586, 337, 505, 309, 311, 534, 534, 1627, 570, 437, 321, 393, 360, 307, 2464, 51614], "temperature": 0.0, "avg_logprob": -0.1864007885536451, "compression_ratio": 1.7916666666666667, "no_speech_prob": 0.06538723409175873}, {"id": 96, "seek": 52588, "start": 525.88, "end": 532.88, "text": " a small program in a C dialect and then get that through the verifier and compile it into", "tokens": [50364, 257, 1359, 1461, 294, 257, 383, 24652, 293, 550, 483, 300, 807, 264, 1306, 9902, 293, 31413, 309, 666, 50714], "temperature": 0.0, "avg_logprob": -0.17973711157357822, "compression_ratio": 1.7684729064039408, "no_speech_prob": 0.17346110939979553}, {"id": 97, "seek": 52588, "start": 533.64, "end": 540.64, "text": " ebpf code and then load that into the Linux corner and the way it works is then we actually", "tokens": [50752, 308, 65, 25302, 3089, 293, 550, 3677, 300, 666, 264, 18734, 4538, 293, 264, 636, 309, 1985, 307, 550, 321, 767, 51102], "temperature": 0.0, "avg_logprob": -0.17973711157357822, "compression_ratio": 1.7684729064039408, "no_speech_prob": 0.17346110939979553}, {"id": 98, "seek": 52588, "start": 541.04, "end": 547.0, "text": " don't use syscalls like the slide originally says but what we then do is like tell the", "tokens": [51122, 500, 380, 764, 262, 749, 66, 39655, 411, 264, 4137, 7993, 1619, 457, 437, 321, 550, 360, 307, 411, 980, 264, 51420], "temperature": 0.0, "avg_logprob": -0.17973711157357822, "compression_ratio": 1.7684729064039408, "no_speech_prob": 0.17346110939979553}, {"id": 99, "seek": 52588, "start": 547.0, "end": 554.0, "text": " Linux corner to every so often run this snippet of ebpf code and what we do is do the same", "tokens": [51420, 18734, 4538, 281, 633, 370, 2049, 1190, 341, 35623, 302, 295, 308, 65, 25302, 3089, 293, 437, 321, 360, 307, 360, 264, 912, 51770], "temperature": 0.0, "avg_logprob": -0.17973711157357822, "compression_ratio": 1.7684729064039408, "no_speech_prob": 0.17346110939979553}, {"id": 100, "seek": 55588, "start": 555.88, "end": 562.88, "text": " things like stack unwinding that you are stack walking that I told you about like two slides", "tokens": [50364, 721, 411, 8630, 14853, 9245, 300, 291, 366, 8630, 4494, 300, 286, 1907, 291, 466, 411, 732, 9788, 50714], "temperature": 0.0, "avg_logprob": -0.20643593544183775, "compression_ratio": 1.9052631578947368, "no_speech_prob": 0.004189321771264076}, {"id": 101, "seek": 55588, "start": 563.28, "end": 569.64, "text": " ago so essentially what we do is we start or we start in ebpf we get kind of the context", "tokens": [50734, 2057, 370, 4476, 437, 321, 360, 307, 321, 722, 420, 321, 722, 294, 308, 65, 25302, 321, 483, 733, 295, 264, 4319, 51052], "temperature": 0.0, "avg_logprob": -0.20643593544183775, "compression_ratio": 1.9052631578947368, "no_speech_prob": 0.004189321771264076}, {"id": 102, "seek": 55588, "start": 569.64, "end": 575.12, "text": " we get the current stack pointer and we look at the leaf of the stack so like kind of the", "tokens": [51052, 321, 483, 264, 2190, 8630, 23918, 293, 321, 574, 412, 264, 10871, 295, 264, 8630, 370, 411, 733, 295, 264, 51326], "temperature": 0.0, "avg_logprob": -0.20643593544183775, "compression_ratio": 1.9052631578947368, "no_speech_prob": 0.004189321771264076}, {"id": 103, "seek": 55588, "start": 575.12, "end": 582.12, "text": " very top like the currently executed function and we can then use that to essentially read", "tokens": [51326, 588, 1192, 411, 264, 4362, 17577, 2445, 293, 321, 393, 550, 764, 300, 281, 4476, 1401, 51676], "temperature": 0.0, "avg_logprob": -0.20643593544183775, "compression_ratio": 1.9052631578947368, "no_speech_prob": 0.004189321771264076}, {"id": 104, "seek": 58212, "start": 583.12, "end": 590.12, "text": " that instruction pointer and from there get the frame pointer and the special occasion", "tokens": [50414, 300, 10951, 23918, 293, 490, 456, 483, 264, 3920, 23918, 293, 264, 2121, 9674, 50764], "temperature": 0.0, "avg_logprob": -0.1859575662857447, "compression_ratio": 1.7794871794871794, "no_speech_prob": 0.0066561768762767315}, {"id": 105, "seek": 58212, "start": 592.24, "end": 598.24, "text": " here is the instruction pointer has to be the return address minus one because of the", "tokens": [50870, 510, 307, 264, 10951, 23918, 575, 281, 312, 264, 2736, 2985, 3175, 472, 570, 295, 264, 51170], "temperature": 0.0, "avg_logprob": -0.1859575662857447, "compression_ratio": 1.7794871794871794, "no_speech_prob": 0.0066561768762767315}, {"id": 106, "seek": 58212, "start": 598.24, "end": 604.6, "text": " thing I just told you about two slides ago right so basically that's how we can then", "tokens": [51170, 551, 286, 445, 1907, 291, 466, 732, 9788, 2057, 558, 370, 1936, 300, 311, 577, 321, 393, 550, 51488], "temperature": 0.0, "avg_logprob": -0.1859575662857447, "compression_ratio": 1.7794871794871794, "no_speech_prob": 0.0066561768762767315}, {"id": 107, "seek": 58212, "start": 604.6, "end": 611.6, "text": " know where we were called from and we do that all the time up until at the end we do that", "tokens": [51488, 458, 689, 321, 645, 1219, 490, 293, 321, 360, 300, 439, 264, 565, 493, 1826, 412, 264, 917, 321, 360, 300, 51838], "temperature": 0.0, "avg_logprob": -0.1859575662857447, "compression_ratio": 1.7794871794871794, "no_speech_prob": 0.0066561768762767315}, {"id": 108, "seek": 61212, "start": 612.2, "end": 619.2, "text": " we get an instruction pointer or that zero so this one then means basically we reach", "tokens": [50368, 321, 483, 364, 10951, 23918, 420, 300, 4018, 370, 341, 472, 550, 1355, 1936, 321, 2524, 50718], "temperature": 0.0, "avg_logprob": -0.15067949856028837, "compression_ratio": 1.7281553398058251, "no_speech_prob": 0.0016200372483581305}, {"id": 109, "seek": 61212, "start": 619.28, "end": 626.28, "text": " the end of the stack and we know we can terminate or we reach the end of that stack trace.", "tokens": [50722, 264, 917, 295, 264, 8630, 293, 321, 458, 321, 393, 10761, 473, 420, 321, 2524, 264, 917, 295, 300, 8630, 13508, 13, 51072], "temperature": 0.0, "avg_logprob": -0.15067949856028837, "compression_ratio": 1.7281553398058251, "no_speech_prob": 0.0016200372483581305}, {"id": 110, "seek": 61212, "start": 626.48, "end": 633.48, "text": " In between for profiling you can see over here we do something with the stack with the", "tokens": [51082, 682, 1296, 337, 1740, 4883, 291, 393, 536, 670, 510, 321, 360, 746, 365, 264, 8630, 365, 264, 51432], "temperature": 0.0, "avg_logprob": -0.15067949856028837, "compression_ratio": 1.7281553398058251, "no_speech_prob": 0.0016200372483581305}, {"id": 111, "seek": 61212, "start": 634.52, "end": 639.84, "text": " frame and what we actually do is we kind of like just get the memory address of that executed", "tokens": [51484, 3920, 293, 437, 321, 767, 360, 307, 321, 733, 295, 411, 445, 483, 264, 4675, 2985, 295, 300, 17577, 51750], "temperature": 0.0, "avg_logprob": -0.15067949856028837, "compression_ratio": 1.7281553398058251, "no_speech_prob": 0.0016200372483581305}, {"id": 112, "seek": 63984, "start": 639.84, "end": 646.48, "text": " function and we basically have an array of all the frames that were executed at the end", "tokens": [50364, 2445, 293, 321, 1936, 362, 364, 10225, 295, 439, 264, 12083, 300, 645, 17577, 412, 264, 917, 50696], "temperature": 0.0, "avg_logprob": -0.11484447526343075, "compression_ratio": 1.7761194029850746, "no_speech_prob": 0.0018902397714555264}, {"id": 113, "seek": 63984, "start": 646.48, "end": 652.84, "text": " and have the memory addresses and those memory addresses we can then use to get the function", "tokens": [50696, 293, 362, 264, 4675, 16862, 293, 729, 4675, 16862, 321, 393, 550, 764, 281, 483, 264, 2445, 51014], "temperature": 0.0, "avg_logprob": -0.11484447526343075, "compression_ratio": 1.7761194029850746, "no_speech_prob": 0.0018902397714555264}, {"id": 114, "seek": 63984, "start": 652.84, "end": 659.84, "text": " names for that function. So having frame pointers in ebpf makes regular profiling", "tokens": [51014, 5288, 337, 300, 2445, 13, 407, 1419, 3920, 44548, 294, 308, 65, 25302, 1669, 3890, 1740, 4883, 51364], "temperature": 0.0, "avg_logprob": -0.11484447526343075, "compression_ratio": 1.7761194029850746, "no_speech_prob": 0.0018902397714555264}, {"id": 115, "seek": 63984, "start": 660.08, "end": 667.08, "text": " super easy and we can then do profiling super simple we don't have to worry about like special", "tokens": [51376, 1687, 1858, 293, 321, 393, 550, 360, 1740, 4883, 1687, 2199, 321, 500, 380, 362, 281, 3292, 466, 411, 2121, 51726], "temperature": 0.0, "avg_logprob": -0.11484447526343075, "compression_ratio": 1.7761194029850746, "no_speech_prob": 0.0018902397714555264}, {"id": 116, "seek": 66708, "start": 668.0, "end": 675.0, "text": " compiler configurations because we can just assume that frame pointers are here for us", "tokens": [50410, 31958, 31493, 570, 321, 393, 445, 6552, 300, 3920, 44548, 366, 510, 337, 505, 50760], "temperature": 0.0, "avg_logprob": -0.16730543283315805, "compression_ratio": 1.6451612903225807, "no_speech_prob": 0.003933904692530632}, {"id": 117, "seek": 66708, "start": 675.0, "end": 682.0, "text": " to then basically use them to figure out the entire stack of the currently executing function.", "tokens": [50760, 281, 550, 1936, 764, 552, 281, 2573, 484, 264, 2302, 8630, 295, 264, 4362, 32368, 2445, 13, 51110], "temperature": 0.0, "avg_logprob": -0.16730543283315805, "compression_ratio": 1.6451612903225807, "no_speech_prob": 0.003933904692530632}, {"id": 118, "seek": 66708, "start": 683.5600000000001, "end": 689.24, "text": " There are ways to do exactly that without frame pointers and shout out I think it was", "tokens": [51188, 821, 366, 2098, 281, 360, 2293, 300, 1553, 3920, 44548, 293, 8043, 484, 286, 519, 309, 390, 51472], "temperature": 0.0, "avg_logprob": -0.16730543283315805, "compression_ratio": 1.6451612903225807, "no_speech_prob": 0.003933904692530632}, {"id": 119, "seek": 66708, "start": 689.24, "end": 695.5600000000001, "text": " in this very room one year ago there was a talk by Javier and by Charlie who were talking", "tokens": [51472, 294, 341, 588, 1808, 472, 1064, 2057, 456, 390, 257, 751, 538, 508, 25384, 293, 538, 13754, 567, 645, 1417, 51788], "temperature": 0.0, "avg_logprob": -0.16730543283315805, "compression_ratio": 1.6451612903225807, "no_speech_prob": 0.003933904692530632}, {"id": 120, "seek": 69556, "start": 695.56, "end": 701.88, "text": " about stack unwinding without frame pointers using Dwarf I highly recommend it it's really", "tokens": [50364, 466, 8630, 14853, 9245, 1553, 3920, 44548, 1228, 413, 6925, 69, 286, 5405, 2748, 309, 309, 311, 534, 50680], "temperature": 0.0, "avg_logprob": -0.17778905868530273, "compression_ratio": 1.785425101214575, "no_speech_prob": 0.012966855429112911}, {"id": 121, "seek": 69556, "start": 701.88, "end": 708.04, "text": " really interesting but yeah something for another time and then obviously not only like", "tokens": [50680, 534, 1880, 457, 1338, 746, 337, 1071, 565, 293, 550, 2745, 406, 787, 411, 50988], "temperature": 0.0, "avg_logprob": -0.17778905868530273, "compression_ratio": 1.785425101214575, "no_speech_prob": 0.012966855429112911}, {"id": 122, "seek": 69556, "start": 708.04, "end": 713.7199999999999, "text": " the profiling use case but if we have frame pointers in the executables in those executing", "tokens": [50988, 264, 1740, 4883, 764, 1389, 457, 498, 321, 362, 3920, 44548, 294, 264, 7568, 2965, 294, 729, 32368, 51272], "temperature": 0.0, "avg_logprob": -0.17778905868530273, "compression_ratio": 1.785425101214575, "no_speech_prob": 0.012966855429112911}, {"id": 123, "seek": 69556, "start": 713.7199999999999, "end": 718.1999999999999, "text": " stacks we can also use all the other debugging tools right not only for profiling we can", "tokens": [51272, 30792, 321, 393, 611, 764, 439, 264, 661, 45592, 3873, 558, 406, 787, 337, 1740, 4883, 321, 393, 51496], "temperature": 0.0, "avg_logprob": -0.17778905868530273, "compression_ratio": 1.785425101214575, "no_speech_prob": 0.012966855429112911}, {"id": 124, "seek": 69556, "start": 718.1999999999999, "end": 724.9599999999999, "text": " use the bcc tools bpf trace perf etc and they also have the kind of same benefits.", "tokens": [51496, 764, 264, 272, 1914, 3873, 272, 25302, 13508, 13826, 5183, 293, 436, 611, 362, 264, 733, 295, 912, 5311, 13, 51834], "temperature": 0.0, "avg_logprob": -0.17778905868530273, "compression_ratio": 1.785425101214575, "no_speech_prob": 0.012966855429112911}, {"id": 125, "seek": 72496, "start": 725.0, "end": 732.0, "text": " So essentially what that means is that the possibilities really become a lot more broad", "tokens": [50366, 407, 4476, 437, 300, 1355, 307, 300, 264, 12178, 534, 1813, 257, 688, 544, 4152, 50716], "temperature": 0.0, "avg_logprob": -0.16994767130157093, "compression_ratio": 1.7611940298507462, "no_speech_prob": 0.001406991039402783}, {"id": 126, "seek": 72496, "start": 732.32, "end": 737.2800000000001, "text": " and open or like we can do a lot more things because we only have these like two memory", "tokens": [50732, 293, 1269, 420, 411, 321, 393, 360, 257, 688, 544, 721, 570, 321, 787, 362, 613, 411, 732, 4675, 50980], "temperature": 0.0, "avg_logprob": -0.16994767130157093, "compression_ratio": 1.7611940298507462, "no_speech_prob": 0.001406991039402783}, {"id": 127, "seek": 72496, "start": 737.2800000000001, "end": 744.2800000000001, "text": " reads and for example in bpf trace we can use the like one liner here to essentially", "tokens": [50980, 15700, 293, 337, 1365, 294, 272, 25302, 13508, 321, 393, 764, 264, 411, 472, 24468, 510, 281, 4476, 51330], "temperature": 0.0, "avg_logprob": -0.16994767130157093, "compression_ratio": 1.7611940298507462, "no_speech_prob": 0.001406991039402783}, {"id": 128, "seek": 72496, "start": 745.2800000000001, "end": 752.2800000000001, "text": " also build a really simple but working profiler that uses the use stack to get the user space", "tokens": [51380, 611, 1322, 257, 534, 2199, 457, 1364, 1740, 5441, 300, 4960, 264, 764, 8630, 281, 483, 264, 4195, 1901, 51730], "temperature": 0.0, "avg_logprob": -0.16994767130157093, "compression_ratio": 1.7611940298507462, "no_speech_prob": 0.001406991039402783}, {"id": 129, "seek": 75228, "start": 753.28, "end": 760.28, "text": " stack unwinding and count how often it sees things and that's super cheap then but also", "tokens": [50414, 8630, 14853, 9245, 293, 1207, 577, 2049, 309, 8194, 721, 293, 300, 311, 1687, 7084, 550, 457, 611, 50764], "temperature": 0.0, "avg_logprob": -0.22477320620888158, "compression_ratio": 1.7772277227722773, "no_speech_prob": 0.009242277592420578}, {"id": 130, "seek": 75228, "start": 760.28, "end": 765.68, "text": " like the go execution trace actually traces everything that's happening and because unwinding", "tokens": [50764, 411, 264, 352, 15058, 13508, 767, 26076, 1203, 300, 311, 2737, 293, 570, 14853, 9245, 51034], "temperature": 0.0, "avg_logprob": -0.22477320620888158, "compression_ratio": 1.7772277227722773, "no_speech_prob": 0.009242277592420578}, {"id": 131, "seek": 75228, "start": 765.68, "end": 772.1999999999999, "text": " is so has so little overhead we can also do things like that and once we have profiles", "tokens": [51034, 307, 370, 575, 370, 707, 19922, 321, 393, 611, 360, 721, 411, 300, 293, 1564, 321, 362, 23693, 51360], "temperature": 0.0, "avg_logprob": -0.22477320620888158, "compression_ratio": 1.7772277227722773, "no_speech_prob": 0.009242277592420578}, {"id": 132, "seek": 75228, "start": 772.1999999999999, "end": 776.76, "text": " continue and kind of like the performance aspect we can do something called profile guided", "tokens": [51360, 2354, 293, 733, 295, 411, 264, 3389, 4171, 321, 393, 360, 746, 1219, 7964, 19663, 51588], "temperature": 0.0, "avg_logprob": -0.22477320620888158, "compression_ratio": 1.7772277227722773, "no_speech_prob": 0.009242277592420578}, {"id": 133, "seek": 77676, "start": 776.76, "end": 783.76, "text": " optimizations and just making profiling so cheap that's something where I think a lot", "tokens": [50364, 5028, 14455, 293, 445, 1455, 1740, 4883, 370, 7084, 300, 311, 746, 689, 286, 519, 257, 688, 50714], "temperature": 0.0, "avg_logprob": -0.13589545472027503, "compression_ratio": 1.7009803921568627, "no_speech_prob": 0.021835491061210632}, {"id": 134, "seek": 77676, "start": 784.28, "end": 789.88, "text": " of innovation is also going to happen in the future and some outlook like some super new", "tokens": [50740, 295, 8504, 307, 611, 516, 281, 1051, 294, 264, 2027, 293, 512, 26650, 411, 512, 1687, 777, 51020], "temperature": 0.0, "avg_logprob": -0.13589545472027503, "compression_ratio": 1.7009803921568627, "no_speech_prob": 0.021835491061210632}, {"id": 135, "seek": 77676, "start": 789.88, "end": 796.88, "text": " papers the context sensitive sample based profile guided optimization so something we", "tokens": [51020, 10577, 264, 4319, 9477, 6889, 2361, 7964, 19663, 19618, 370, 746, 321, 51370], "temperature": 0.0, "avg_logprob": -0.13589545472027503, "compression_ratio": 1.7009803921568627, "no_speech_prob": 0.021835491061210632}, {"id": 136, "seek": 77676, "start": 797.16, "end": 804.16, "text": " are super excited about because yeah it will allow a lot more things to happen as well", "tokens": [51384, 366, 1687, 2919, 466, 570, 1338, 309, 486, 2089, 257, 688, 544, 721, 281, 1051, 382, 731, 51734], "temperature": 0.0, "avg_logprob": -0.13589545472027503, "compression_ratio": 1.7009803921568627, "no_speech_prob": 0.021835491061210632}, {"id": 137, "seek": 80416, "start": 804.3199999999999, "end": 809.88, "text": " but maybe another Boston talk is going to happen about that in a year or two so bringing", "tokens": [50372, 457, 1310, 1071, 12333, 751, 307, 516, 281, 1051, 466, 300, 294, 257, 1064, 420, 732, 370, 5062, 50650], "temperature": 0.0, "avg_logprob": -0.2037070116658849, "compression_ratio": 1.7171717171717171, "no_speech_prob": 0.010593447834253311}, {"id": 138, "seek": 80416, "start": 809.88, "end": 812.88, "text": " frame pointer to the masses I'm super excited to have John talk.", "tokens": [50650, 3920, 23918, 281, 264, 23935, 286, 478, 1687, 2919, 281, 362, 2619, 751, 13, 50800], "temperature": 0.0, "avg_logprob": -0.2037070116658849, "compression_ratio": 1.7171717171717171, "no_speech_prob": 0.010593447834253311}, {"id": 139, "seek": 80416, "start": 812.88, "end": 817.48, "text": " Hey all right so I'm here to tell you about now we've seen all of the cool stuff you can", "tokens": [50800, 1911, 439, 558, 370, 286, 478, 510, 281, 980, 291, 466, 586, 321, 600, 1612, 439, 295, 264, 1627, 1507, 291, 393, 51030], "temperature": 0.0, "avg_logprob": -0.2037070116658849, "compression_ratio": 1.7171717171717171, "no_speech_prob": 0.010593447834253311}, {"id": 140, "seek": 80416, "start": 817.48, "end": 821.88, "text": " do when you have frame pointers how we at Canonical are going to make this available", "tokens": [51030, 360, 562, 291, 362, 3920, 44548, 577, 321, 412, 27666, 804, 366, 516, 281, 652, 341, 2435, 51250], "temperature": 0.0, "avg_logprob": -0.2037070116658849, "compression_ratio": 1.7171717171717171, "no_speech_prob": 0.010593447834253311}, {"id": 141, "seek": 80416, "start": 821.88, "end": 827.0799999999999, "text": " to all of you much more easily and so if you didn't see this on an outside our blog a couple", "tokens": [51250, 281, 439, 295, 291, 709, 544, 3612, 293, 370, 498, 291, 994, 380, 536, 341, 322, 364, 2380, 527, 6968, 257, 1916, 51510], "temperature": 0.0, "avg_logprob": -0.2037070116658849, "compression_ratio": 1.7171717171717171, "no_speech_prob": 0.010593447834253311}, {"id": 142, "seek": 80416, "start": 827.0799999999999, "end": 832.0, "text": " of months ago we have decided that from 2404 LTS we're going to enable frame pointers for", "tokens": [51510, 295, 2493, 2057, 321, 362, 3047, 300, 490, 4022, 14565, 441, 7327, 321, 434, 516, 281, 9528, 3920, 44548, 337, 51756], "temperature": 0.0, "avg_logprob": -0.2037070116658849, "compression_ratio": 1.7171717171717171, "no_speech_prob": 0.010593447834253311}, {"id": 143, "seek": 83200, "start": 832.0, "end": 835.4, "text": " the entire Ubuntu archive on 64 bit platforms.", "tokens": [50364, 264, 2302, 30230, 45605, 23507, 322, 12145, 857, 9473, 13, 50534], "temperature": 0.0, "avg_logprob": -0.13800674829727563, "compression_ratio": 1.6566666666666667, "no_speech_prob": 0.0990615040063858}, {"id": 144, "seek": 83200, "start": 835.4, "end": 841.12, "text": " The caveat on 64 bit is because back in the day 32 bit CPUs obviously had far fewer registers", "tokens": [50534, 440, 43012, 322, 12145, 857, 307, 570, 646, 294, 264, 786, 8858, 857, 13199, 82, 2745, 632, 1400, 13366, 38351, 50820], "temperature": 0.0, "avg_logprob": -0.13800674829727563, "compression_ratio": 1.6566666666666667, "no_speech_prob": 0.0990615040063858}, {"id": 145, "seek": 83200, "start": 841.12, "end": 845.16, "text": " and so sacrificing a register to hold the frame pointer came with a much higher performance", "tokens": [50820, 293, 370, 42294, 257, 7280, 281, 1797, 264, 3920, 23918, 1361, 365, 257, 709, 2946, 3389, 51022], "temperature": 0.0, "avg_logprob": -0.13800674829727563, "compression_ratio": 1.6566666666666667, "no_speech_prob": 0.0990615040063858}, {"id": 146, "seek": 83200, "start": 845.16, "end": 849.56, "text": " overhead in reality these days with 64 bit you're looking at on average kind of less", "tokens": [51022, 19922, 294, 4103, 613, 1708, 365, 12145, 857, 291, 434, 1237, 412, 322, 4274, 733, 295, 1570, 51242], "temperature": 0.0, "avg_logprob": -0.13800674829727563, "compression_ratio": 1.6566666666666667, "no_speech_prob": 0.0990615040063858}, {"id": 147, "seek": 83200, "start": 849.56, "end": 854.68, "text": " than 1% unless you're in a very specific group so if you're doing like turbo pants on head", "tokens": [51242, 813, 502, 4, 5969, 291, 434, 294, 257, 588, 2685, 1594, 370, 498, 291, 434, 884, 411, 20902, 10082, 322, 1378, 51498], "temperature": 0.0, "avg_logprob": -0.13800674829727563, "compression_ratio": 1.6566666666666667, "no_speech_prob": 0.0990615040063858}, {"id": 148, "seek": 83200, "start": 854.68, "end": 860.12, "text": " HPC stuff or high frequency trading or real time things where kind of that like 1% could", "tokens": [51498, 12557, 34, 1507, 420, 1090, 7893, 9529, 420, 957, 565, 721, 689, 733, 295, 300, 411, 502, 4, 727, 51770], "temperature": 0.0, "avg_logprob": -0.13800674829727563, "compression_ratio": 1.6566666666666667, "no_speech_prob": 0.0990615040063858}, {"id": 149, "seek": 86012, "start": 860.12, "end": 863.68, "text": " really really matter perhaps this isn't for you and we can make exceptions in the archive", "tokens": [50364, 534, 534, 1871, 4317, 341, 1943, 380, 337, 291, 293, 321, 393, 652, 22847, 294, 264, 23507, 50542], "temperature": 0.0, "avg_logprob": -0.15539210392878605, "compression_ratio": 1.716012084592145, "no_speech_prob": 0.025450371205806732}, {"id": 150, "seek": 86012, "start": 863.68, "end": 867.8, "text": " for those packages but in general for 2404 you can expect to see frame pointers for the", "tokens": [50542, 337, 729, 17401, 457, 294, 2674, 337, 4022, 14565, 291, 393, 2066, 281, 536, 3920, 44548, 337, 264, 50748], "temperature": 0.0, "avg_logprob": -0.15539210392878605, "compression_ratio": 1.716012084592145, "no_speech_prob": 0.025450371205806732}, {"id": 151, "seek": 86012, "start": 867.8, "end": 871.5600000000001, "text": " entire archive through main and universe etc.", "tokens": [50748, 2302, 23507, 807, 2135, 293, 6445, 5183, 13, 50936], "temperature": 0.0, "avg_logprob": -0.15539210392878605, "compression_ratio": 1.716012084592145, "no_speech_prob": 0.025450371205806732}, {"id": 152, "seek": 86012, "start": 871.5600000000001, "end": 874.36, "text": " This is pretty exciting because the LTS I probably need to tell you is going to be installed", "tokens": [50936, 639, 307, 1238, 4670, 570, 264, 441, 7327, 286, 1391, 643, 281, 980, 291, 307, 516, 281, 312, 8899, 51076], "temperature": 0.0, "avg_logprob": -0.15539210392878605, "compression_ratio": 1.716012084592145, "no_speech_prob": 0.025450371205806732}, {"id": 153, "seek": 86012, "start": 874.36, "end": 880.0, "text": " on many many millions of machines right and then supported for at least 10 years by Canonical", "tokens": [51076, 322, 867, 867, 6803, 295, 8379, 558, 293, 550, 8104, 337, 412, 1935, 1266, 924, 538, 27666, 804, 51358], "temperature": 0.0, "avg_logprob": -0.15539210392878605, "compression_ratio": 1.716012084592145, "no_speech_prob": 0.025450371205806732}, {"id": 154, "seek": 86012, "start": 880.0, "end": 883.6, "text": " so this is going to make a big impact for people who need these things.", "tokens": [51358, 370, 341, 307, 516, 281, 652, 257, 955, 2712, 337, 561, 567, 643, 613, 721, 13, 51538], "temperature": 0.0, "avg_logprob": -0.15539210392878605, "compression_ratio": 1.716012084592145, "no_speech_prob": 0.025450371205806732}, {"id": 155, "seek": 86012, "start": 883.6, "end": 887.36, "text": " This stuff is often already enabled by the hyperscalers so people like Amazon, people", "tokens": [51538, 639, 1507, 307, 2049, 1217, 15172, 538, 264, 7420, 433, 9895, 433, 370, 561, 411, 6795, 11, 561, 51726], "temperature": 0.0, "avg_logprob": -0.15539210392878605, "compression_ratio": 1.716012084592145, "no_speech_prob": 0.025450371205806732}, {"id": 156, "seek": 88736, "start": 887.4, "end": 890.44, "text": " like Netflix, people like Microsoft are already doing this in production and now you kind", "tokens": [50366, 411, 12778, 11, 561, 411, 8116, 366, 1217, 884, 341, 294, 4265, 293, 586, 291, 733, 50518], "temperature": 0.0, "avg_logprob": -0.12689395384355026, "compression_ratio": 1.7283582089552239, "no_speech_prob": 0.07042630761861801}, {"id": 157, "seek": 88736, "start": 890.44, "end": 894.04, "text": " of get it for free as well just by using Ubuntu.", "tokens": [50518, 295, 483, 309, 337, 1737, 382, 731, 445, 538, 1228, 30230, 45605, 13, 50698], "temperature": 0.0, "avg_logprob": -0.12689395384355026, "compression_ratio": 1.7283582089552239, "no_speech_prob": 0.07042630761861801}, {"id": 158, "seek": 88736, "start": 894.04, "end": 898.44, "text": " So I mentioned there will be some you know pretty much negligible barely noticeable for", "tokens": [50698, 407, 286, 2835, 456, 486, 312, 512, 291, 458, 1238, 709, 32570, 964, 10268, 26041, 337, 50918], "temperature": 0.0, "avg_logprob": -0.12689395384355026, "compression_ratio": 1.7283582089552239, "no_speech_prob": 0.07042630761861801}, {"id": 159, "seek": 88736, "start": 898.44, "end": 902.16, "text": " nearly all use case performance impact we're kind of willing to wear that because what", "tokens": [50918, 6217, 439, 764, 1389, 3389, 2712, 321, 434, 733, 295, 4950, 281, 3728, 300, 570, 437, 51104], "temperature": 0.0, "avg_logprob": -0.12689395384355026, "compression_ratio": 1.7283582089552239, "no_speech_prob": 0.07042630761861801}, {"id": 160, "seek": 88736, "start": 902.16, "end": 905.76, "text": " it actually enables in the medium term is for us to do a lot of work on our distribution", "tokens": [51104, 309, 767, 17077, 294, 264, 6399, 1433, 307, 337, 505, 281, 360, 257, 688, 295, 589, 322, 527, 7316, 51284], "temperature": 0.0, "avg_logprob": -0.12689395384355026, "compression_ratio": 1.7283582089552239, "no_speech_prob": 0.07042630761861801}, {"id": 161, "seek": 88736, "start": 905.76, "end": 910.12, "text": " right so we're in the process now of running benchmarks on a kind of pre frame pointer", "tokens": [51284, 558, 370, 321, 434, 294, 264, 1399, 586, 295, 2614, 43751, 322, 257, 733, 295, 659, 3920, 23918, 51502], "temperature": 0.0, "avg_logprob": -0.12689395384355026, "compression_ratio": 1.7283582089552239, "no_speech_prob": 0.07042630761861801}, {"id": 162, "seek": 88736, "start": 910.12, "end": 914.0, "text": " Ubuntu and a post frame pointer Ubuntu ready for the release and that will hopefully help", "tokens": [51502, 30230, 45605, 293, 257, 2183, 3920, 23918, 30230, 45605, 1919, 337, 264, 4374, 293, 300, 486, 4696, 854, 51696], "temperature": 0.0, "avg_logprob": -0.12689395384355026, "compression_ratio": 1.7283582089552239, "no_speech_prob": 0.07042630761861801}, {"id": 163, "seek": 91400, "start": 914.04, "end": 918.96, "text": " as I identify any outliers so if we hit certain packages where we feel like the performance", "tokens": [50366, 382, 286, 5876, 604, 484, 23646, 370, 498, 321, 2045, 1629, 17401, 689, 321, 841, 411, 264, 3389, 50612], "temperature": 0.0, "avg_logprob": -0.2124378450455204, "compression_ratio": 1.744186046511628, "no_speech_prob": 0.11257026344537735}, {"id": 164, "seek": 91400, "start": 918.96, "end": 923.2, "text": " hit is too much then we will disable it for the first release for 24.04 or we will try", "tokens": [50612, 2045, 307, 886, 709, 550, 321, 486, 28362, 309, 337, 264, 700, 4374, 337, 4022, 13, 14565, 420, 321, 486, 853, 50824], "temperature": 0.0, "avg_logprob": -0.2124378450455204, "compression_ratio": 1.744186046511628, "no_speech_prob": 0.11257026344537735}, {"id": 165, "seek": 91400, "start": 923.2, "end": 927.52, "text": " and work out what other optimizations we might make to that package to make it work better", "tokens": [50824, 293, 589, 484, 437, 661, 5028, 14455, 321, 1062, 652, 281, 300, 7372, 281, 652, 309, 589, 1101, 51040], "temperature": 0.0, "avg_logprob": -0.2124378450455204, "compression_ratio": 1.744186046511628, "no_speech_prob": 0.11257026344537735}, {"id": 166, "seek": 91400, "start": 927.52, "end": 930.44, "text": " with the frame pointers enabled.", "tokens": [51040, 365, 264, 3920, 44548, 15172, 13, 51186], "temperature": 0.0, "avg_logprob": -0.2124378450455204, "compression_ratio": 1.744186046511628, "no_speech_prob": 0.11257026344537735}, {"id": 167, "seek": 91400, "start": 930.44, "end": 936.12, "text": " So this will really really help I think downstreams to enable or to gain the benefit of frame", "tokens": [51186, 407, 341, 486, 534, 534, 854, 286, 519, 30621, 82, 281, 9528, 420, 281, 6052, 264, 5121, 295, 3920, 51470], "temperature": 0.0, "avg_logprob": -0.2124378450455204, "compression_ratio": 1.744186046511628, "no_speech_prob": 0.11257026344537735}, {"id": 168, "seek": 91400, "start": 936.12, "end": 937.88, "text": " pointers and optimize their own workloads.", "tokens": [51470, 44548, 293, 19719, 641, 1065, 32452, 13, 51558], "temperature": 0.0, "avg_logprob": -0.2124378450455204, "compression_ratio": 1.744186046511628, "no_speech_prob": 0.11257026344537735}, {"id": 169, "seek": 91400, "start": 937.88, "end": 941.6, "text": " If you are someone who just uses Ubuntu as a platform and you build your own code and", "tokens": [51558, 759, 291, 366, 1580, 567, 445, 4960, 30230, 45605, 382, 257, 3663, 293, 291, 1322, 428, 1065, 3089, 293, 51744], "temperature": 0.0, "avg_logprob": -0.2124378450455204, "compression_ratio": 1.744186046511628, "no_speech_prob": 0.11257026344537735}, {"id": 170, "seek": 94160, "start": 941.6800000000001, "end": 947.0, "text": " let's say you use Python or you use go or use no JS or whatever suddenly those big holes", "tokens": [50368, 718, 311, 584, 291, 764, 15329, 420, 291, 764, 352, 420, 764, 572, 33063, 420, 2035, 5800, 729, 955, 8118, 50634], "temperature": 0.0, "avg_logprob": -0.21551560985949614, "compression_ratio": 1.8143322475570032, "no_speech_prob": 0.01036097016185522}, {"id": 171, "seek": 94160, "start": 947.0, "end": 950.4, "text": " in your frame graph graphs are just going to disappear when you move to 24.04 without", "tokens": [50634, 294, 428, 3920, 4295, 24877, 366, 445, 516, 281, 11596, 562, 291, 1286, 281, 4022, 13, 14565, 1553, 50804], "temperature": 0.0, "avg_logprob": -0.21551560985949614, "compression_ratio": 1.8143322475570032, "no_speech_prob": 0.01036097016185522}, {"id": 172, "seek": 94160, "start": 950.4, "end": 953.5600000000001, "text": " you having to do anything.", "tokens": [50804, 291, 1419, 281, 360, 1340, 13, 50962], "temperature": 0.0, "avg_logprob": -0.21551560985949614, "compression_ratio": 1.8143322475570032, "no_speech_prob": 0.01036097016185522}, {"id": 173, "seek": 94160, "start": 953.5600000000001, "end": 957.28, "text": " This is really just the start which when I make 24.04 a really focused release on kind", "tokens": [50962, 639, 307, 534, 445, 264, 722, 597, 562, 286, 652, 4022, 13, 14565, 257, 534, 5178, 4374, 322, 733, 51148], "temperature": 0.0, "avg_logprob": -0.21551560985949614, "compression_ratio": 1.8143322475570032, "no_speech_prob": 0.01036097016185522}, {"id": 174, "seek": 94160, "start": 957.28, "end": 961.36, "text": " of performance engineering and performance itself so what does that actually mean having", "tokens": [51148, 295, 3389, 7043, 293, 3389, 2564, 370, 437, 775, 300, 767, 914, 1419, 51352], "temperature": 0.0, "avg_logprob": -0.21551560985949614, "compression_ratio": 1.8143322475570032, "no_speech_prob": 0.01036097016185522}, {"id": 175, "seek": 94160, "start": 961.36, "end": 964.8000000000001, "text": " the frame pointers is one thing but you also need the tooling to actually utilize the frame", "tokens": [51352, 264, 3920, 44548, 307, 472, 551, 457, 291, 611, 643, 264, 46593, 281, 767, 16117, 264, 3920, 51524], "temperature": 0.0, "avg_logprob": -0.21551560985949614, "compression_ratio": 1.8143322475570032, "no_speech_prob": 0.01036097016185522}, {"id": 176, "seek": 94160, "start": 964.8000000000001, "end": 968.96, "text": " pointers and kind of inspect the stack and the folks at PoloSignals with Parker are one", "tokens": [51524, 44548, 293, 733, 295, 15018, 264, 8630, 293, 264, 4024, 412, 3635, 78, 50, 788, 1124, 365, 20155, 366, 472, 51732], "temperature": 0.0, "avg_logprob": -0.21551560985949614, "compression_ratio": 1.8143322475570032, "no_speech_prob": 0.01036097016185522}, {"id": 177, "seek": 96896, "start": 969.0400000000001, "end": 974.4000000000001, "text": " part of that but we are also looking to include tools like BPF Trace and SysStat and the Perf", "tokens": [50368, 644, 295, 300, 457, 321, 366, 611, 1237, 281, 4090, 3873, 411, 40533, 37, 1765, 617, 293, 318, 749, 4520, 267, 293, 264, 3026, 69, 50636], "temperature": 0.0, "avg_logprob": -0.2118930010728433, "compression_ratio": 1.7892976588628762, "no_speech_prob": 0.21486246585845947}, {"id": 178, "seek": 96896, "start": 974.4000000000001, "end": 977.48, "text": " Tools on Stable by default in Ubuntu.", "tokens": [50636, 30302, 322, 745, 712, 538, 7576, 294, 30230, 45605, 13, 50790], "temperature": 0.0, "avg_logprob": -0.2118930010728433, "compression_ratio": 1.7892976588628762, "no_speech_prob": 0.21486246585845947}, {"id": 179, "seek": 96896, "start": 977.48, "end": 980.64, "text": " Not in every single image so those of you that are about to screen map me because you", "tokens": [50790, 1726, 294, 633, 2167, 3256, 370, 729, 295, 291, 300, 366, 466, 281, 2568, 4471, 385, 570, 291, 50948], "temperature": 0.0, "avg_logprob": -0.2118930010728433, "compression_ratio": 1.7892976588628762, "no_speech_prob": 0.21486246585845947}, {"id": 180, "seek": 96896, "start": 980.64, "end": 984.32, "text": " use the minimal image or you ship 100,000 container images a month and you don't want", "tokens": [50948, 764, 264, 13206, 3256, 420, 291, 5374, 2319, 11, 1360, 10129, 5267, 257, 1618, 293, 291, 500, 380, 528, 51132], "temperature": 0.0, "avg_logprob": -0.2118930010728433, "compression_ratio": 1.7892976588628762, "no_speech_prob": 0.21486246585845947}, {"id": 181, "seek": 96896, "start": 984.32, "end": 989.0400000000001, "text": " to ship BPF Trace and all of them don't panic we are essentially going to enable all of", "tokens": [51132, 281, 5374, 40533, 37, 1765, 617, 293, 439, 295, 552, 500, 380, 14783, 321, 366, 4476, 516, 281, 9528, 439, 295, 51368], "temperature": 0.0, "avg_logprob": -0.2118930010728433, "compression_ratio": 1.7892976588628762, "no_speech_prob": 0.21486246585845947}, {"id": 182, "seek": 96896, "start": 989.0400000000001, "end": 992.08, "text": " these tools by default anywhere where we ship a kernel.", "tokens": [51368, 613, 3873, 538, 7576, 4992, 689, 321, 5374, 257, 28256, 13, 51520], "temperature": 0.0, "avg_logprob": -0.2118930010728433, "compression_ratio": 1.7892976588628762, "no_speech_prob": 0.21486246585845947}, {"id": 183, "seek": 96896, "start": 992.08, "end": 995.84, "text": " So a Ubuntu server image, a full size server image that doesn't include lexd images, it", "tokens": [51520, 407, 257, 30230, 45605, 7154, 3256, 11, 257, 1577, 2744, 7154, 3256, 300, 1177, 380, 4090, 476, 87, 67, 5267, 11, 309, 51708], "temperature": 0.0, "avg_logprob": -0.2118930010728433, "compression_ratio": 1.7892976588628762, "no_speech_prob": 0.21486246585845947}, {"id": 184, "seek": 99584, "start": 995.9200000000001, "end": 1000.5600000000001, "text": " doesn't include OCI images but if you install Ubuntu on a server or in a VM you will have", "tokens": [50368, 1177, 380, 4090, 422, 25240, 5267, 457, 498, 291, 3625, 30230, 45605, 322, 257, 7154, 420, 294, 257, 18038, 291, 486, 362, 50600], "temperature": 0.0, "avg_logprob": -0.15935274418568451, "compression_ratio": 1.8206686930091185, "no_speech_prob": 0.017352979630231857}, {"id": 185, "seek": 99584, "start": 1000.5600000000001, "end": 1004.0, "text": " BPF Trace by default, you will have SysStat by default.", "tokens": [50600, 40533, 37, 1765, 617, 538, 7576, 11, 291, 486, 362, 318, 749, 4520, 267, 538, 7576, 13, 50772], "temperature": 0.0, "avg_logprob": -0.15935274418568451, "compression_ratio": 1.8206686930091185, "no_speech_prob": 0.017352979630231857}, {"id": 186, "seek": 99584, "start": 1004.0, "end": 1008.2800000000001, "text": " Essentially a huge majority of the tools that Brendan Gregg describes as crisis tools will", "tokens": [50772, 23596, 257, 2603, 6286, 295, 264, 3873, 300, 48484, 14986, 1615, 15626, 382, 5869, 3873, 486, 50986], "temperature": 0.0, "avg_logprob": -0.15935274418568451, "compression_ratio": 1.8206686930091185, "no_speech_prob": 0.017352979630231857}, {"id": 187, "seek": 99584, "start": 1008.2800000000001, "end": 1012.2800000000001, "text": " be there by default and the reason that is super important is because if your system", "tokens": [50986, 312, 456, 538, 7576, 293, 264, 1778, 300, 307, 1687, 1021, 307, 570, 498, 428, 1185, 51186], "temperature": 0.0, "avg_logprob": -0.15935274418568451, "compression_ratio": 1.8206686930091185, "no_speech_prob": 0.017352979630231857}, {"id": 188, "seek": 99584, "start": 1012.2800000000001, "end": 1015.6800000000001, "text": " is in crisis it doesn't matter whether the tools are in the archive.", "tokens": [51186, 307, 294, 5869, 309, 1177, 380, 1871, 1968, 264, 3873, 366, 294, 264, 23507, 13, 51356], "temperature": 0.0, "avg_logprob": -0.15935274418568451, "compression_ratio": 1.8206686930091185, "no_speech_prob": 0.017352979630231857}, {"id": 189, "seek": 99584, "start": 1015.6800000000001, "end": 1019.2, "text": " If your system is right on the edge and then you hit the system with a whole bunch of network", "tokens": [51356, 759, 428, 1185, 307, 558, 322, 264, 4691, 293, 550, 291, 2045, 264, 1185, 365, 257, 1379, 3840, 295, 3209, 51532], "temperature": 0.0, "avg_logprob": -0.15935274418568451, "compression_ratio": 1.8206686930091185, "no_speech_prob": 0.017352979630231857}, {"id": 190, "seek": 99584, "start": 1019.2, "end": 1023.2800000000001, "text": " IO and disk IO to go and get a package from the archives it is potentially going to put", "tokens": [51532, 39839, 293, 12355, 39839, 281, 352, 293, 483, 257, 7372, 490, 264, 25607, 309, 307, 7263, 516, 281, 829, 51736], "temperature": 0.0, "avg_logprob": -0.15935274418568451, "compression_ratio": 1.8206686930091185, "no_speech_prob": 0.017352979630231857}, {"id": 191, "seek": 99584, "start": 1023.2800000000001, "end": 1024.28, "text": " that system over the edge.", "tokens": [51736, 300, 1185, 670, 264, 4691, 13, 51786], "temperature": 0.0, "avg_logprob": -0.15935274418568451, "compression_ratio": 1.8206686930091185, "no_speech_prob": 0.017352979630231857}, {"id": 192, "seek": 102428, "start": 1024.28, "end": 1029.04, "text": " It may not even work in production, the system may not have access to the package archives", "tokens": [50364, 467, 815, 406, 754, 589, 294, 4265, 11, 264, 1185, 815, 406, 362, 2105, 281, 264, 7372, 25607, 50602], "temperature": 0.0, "avg_logprob": -0.15934031686665098, "compression_ratio": 1.851123595505618, "no_speech_prob": 0.10552909970283508}, {"id": 193, "seek": 102428, "start": 1029.04, "end": 1032.52, "text": " and so you just need those tools to be there and we are going to make sure that happens.", "tokens": [50602, 293, 370, 291, 445, 643, 729, 3873, 281, 312, 456, 293, 321, 366, 516, 281, 652, 988, 300, 2314, 13, 50776], "temperature": 0.0, "avg_logprob": -0.15934031686665098, "compression_ratio": 1.851123595505618, "no_speech_prob": 0.10552909970283508}, {"id": 194, "seek": 102428, "start": 1032.52, "end": 1035.6, "text": " For places where we don't ship a kernel all of these tools will get wrapped up in a new", "tokens": [50776, 1171, 3190, 689, 321, 500, 380, 5374, 257, 28256, 439, 295, 613, 3873, 486, 483, 14226, 493, 294, 257, 777, 50930], "temperature": 0.0, "avg_logprob": -0.15934031686665098, "compression_ratio": 1.851123595505618, "no_speech_prob": 0.10552909970283508}, {"id": 195, "seek": 102428, "start": 1035.6, "end": 1039.24, "text": " meta package so if you do want it in your lexd containers, if you do want it in your", "tokens": [50930, 19616, 7372, 370, 498, 291, 360, 528, 309, 294, 428, 476, 87, 67, 17089, 11, 498, 291, 360, 528, 309, 294, 428, 51112], "temperature": 0.0, "avg_logprob": -0.15934031686665098, "compression_ratio": 1.851123595505618, "no_speech_prob": 0.10552909970283508}, {"id": 196, "seek": 102428, "start": 1039.24, "end": 1042.36, "text": " container images, in your debug images then you will just be able to see it really really", "tokens": [51112, 10129, 5267, 11, 294, 428, 24083, 5267, 550, 291, 486, 445, 312, 1075, 281, 536, 309, 534, 534, 51268], "temperature": 0.0, "avg_logprob": -0.15934031686665098, "compression_ratio": 1.851123595505618, "no_speech_prob": 0.10552909970283508}, {"id": 197, "seek": 102428, "start": 1042.36, "end": 1045.04, "text": " easily with a single meta package.", "tokens": [51268, 3612, 365, 257, 2167, 19616, 7372, 13, 51402], "temperature": 0.0, "avg_logprob": -0.15934031686665098, "compression_ratio": 1.851123595505618, "no_speech_prob": 0.10552909970283508}, {"id": 198, "seek": 102428, "start": 1045.04, "end": 1048.8, "text": " We are looking at what other compiler optimizations we can make across the archive as well so", "tokens": [51402, 492, 366, 1237, 412, 437, 661, 31958, 5028, 14455, 321, 393, 652, 2108, 264, 23507, 382, 731, 370, 51590], "temperature": 0.0, "avg_logprob": -0.15934031686665098, "compression_ratio": 1.851123595505618, "no_speech_prob": 0.10552909970283508}, {"id": 199, "seek": 102428, "start": 1048.8, "end": 1052.92, "text": " this might look like rolling out GCC03 for a huge part of the archive, we are not going", "tokens": [51590, 341, 1062, 574, 411, 9439, 484, 460, 11717, 11592, 337, 257, 2603, 644, 295, 264, 23507, 11, 321, 366, 406, 516, 51796], "temperature": 0.0, "avg_logprob": -0.15934031686665098, "compression_ratio": 1.851123595505618, "no_speech_prob": 0.10552909970283508}, {"id": 200, "seek": 105292, "start": 1052.96, "end": 1057.96, "text": " to do that in one big bang go because there are some trade offs there and we are also", "tokens": [50366, 281, 360, 300, 294, 472, 955, 8550, 352, 570, 456, 366, 512, 4923, 39457, 456, 293, 321, 366, 611, 50616], "temperature": 0.0, "avg_logprob": -0.22407021155724158, "compression_ratio": 1.7070063694267517, "no_speech_prob": 0.10456456243991852}, {"id": 201, "seek": 105292, "start": 1057.96, "end": 1062.5600000000002, "text": " looking at essentially not maintaining a low latency kernel and a generic kernel and just", "tokens": [50616, 1237, 412, 4476, 406, 14916, 257, 2295, 27043, 28256, 293, 257, 19577, 28256, 293, 445, 50846], "temperature": 0.0, "avg_logprob": -0.22407021155724158, "compression_ratio": 1.7070063694267517, "no_speech_prob": 0.10456456243991852}, {"id": 202, "seek": 105292, "start": 1062.5600000000002, "end": 1065.3200000000002, "text": " shipping the low latency package by default.", "tokens": [50846, 14122, 264, 2295, 27043, 7372, 538, 7576, 13, 50984], "temperature": 0.0, "avg_logprob": -0.22407021155724158, "compression_ratio": 1.7070063694267517, "no_speech_prob": 0.10456456243991852}, {"id": 203, "seek": 105292, "start": 1065.3200000000002, "end": 1069.2, "text": " None of these are firm, 100% definitely going to happen in 24.04, these are the goals we", "tokens": [50984, 14492, 295, 613, 366, 6174, 11, 2319, 4, 2138, 516, 281, 1051, 294, 4022, 13, 14565, 11, 613, 366, 264, 5493, 321, 51178], "temperature": 0.0, "avg_logprob": -0.22407021155724158, "compression_ratio": 1.7070063694267517, "no_speech_prob": 0.10456456243991852}, {"id": 204, "seek": 105292, "start": 1069.2, "end": 1071.68, "text": " are working towards before the release in April.", "tokens": [51178, 366, 1364, 3030, 949, 264, 4374, 294, 6929, 13, 51302], "temperature": 0.0, "avg_logprob": -0.22407021155724158, "compression_ratio": 1.7070063694267517, "no_speech_prob": 0.10456456243991852}, {"id": 205, "seek": 105292, "start": 1071.68, "end": 1075.68, "text": " Finally, some of you may have seen we have been doing some work on working out how to", "tokens": [51302, 6288, 11, 512, 295, 291, 815, 362, 1612, 321, 362, 668, 884, 512, 589, 322, 1364, 484, 577, 281, 51502], "temperature": 0.0, "avg_logprob": -0.22407021155724158, "compression_ratio": 1.7070063694267517, "no_speech_prob": 0.10456456243991852}, {"id": 206, "seek": 105292, "start": 1075.68, "end": 1082.52, "text": " get Ubuntu and the archive to take advantage of the newer instruction sets, AMD64 v3, AMD64", "tokens": [51502, 483, 30230, 45605, 293, 264, 23507, 281, 747, 5002, 295, 264, 17628, 10951, 6352, 11, 34808, 19395, 371, 18, 11, 34808, 19395, 51844], "temperature": 0.0, "avg_logprob": -0.22407021155724158, "compression_ratio": 1.7070063694267517, "no_speech_prob": 0.10456456243991852}, {"id": 207, "seek": 108252, "start": 1082.92, "end": 1084.48, "text": " v4, v5.", "tokens": [50384, 371, 19, 11, 371, 20, 13, 50462], "temperature": 0.0, "avg_logprob": -0.1908008326654849, "compression_ratio": 1.6055900621118013, "no_speech_prob": 0.010560330003499985}, {"id": 208, "seek": 108252, "start": 1084.48, "end": 1089.04, "text": " We actually have a build of the entire archive that uses AMD64 v3, you can get it in a PPA", "tokens": [50462, 492, 767, 362, 257, 1322, 295, 264, 2302, 23507, 300, 4960, 34808, 19395, 371, 18, 11, 291, 393, 483, 309, 294, 257, 430, 10297, 50690], "temperature": 0.0, "avg_logprob": -0.1908008326654849, "compression_ratio": 1.6055900621118013, "no_speech_prob": 0.010560330003499985}, {"id": 209, "seek": 108252, "start": 1089.04, "end": 1093.68, "text": " and test it in benchmark, it is faster like TLDR but we need to do a bunch of upstream", "tokens": [50690, 293, 1500, 309, 294, 18927, 11, 309, 307, 4663, 411, 40277, 9301, 457, 321, 643, 281, 360, 257, 3840, 295, 33915, 50922], "temperature": 0.0, "avg_logprob": -0.1908008326654849, "compression_ratio": 1.6055900621118013, "no_speech_prob": 0.010560330003499985}, {"id": 210, "seek": 108252, "start": 1093.68, "end": 1097.28, "text": " working apps to work out how we can essentially kind of multiplex that right so that you", "tokens": [50922, 1364, 7733, 281, 589, 484, 577, 321, 393, 4476, 733, 295, 3311, 2021, 300, 558, 370, 300, 291, 51102], "temperature": 0.0, "avg_logprob": -0.1908008326654849, "compression_ratio": 1.6055900621118013, "no_speech_prob": 0.010560330003499985}, {"id": 211, "seek": 108252, "start": 1097.28, "end": 1102.52, "text": " still just go ubuntu.com slash download, download an AMD64 ISO and it does the right", "tokens": [51102, 920, 445, 352, 26709, 45605, 13, 1112, 17330, 5484, 11, 5484, 364, 34808, 19395, 25042, 293, 309, 775, 264, 558, 51364], "temperature": 0.0, "avg_logprob": -0.1908008326654849, "compression_ratio": 1.6055900621118013, "no_speech_prob": 0.010560330003499985}, {"id": 212, "seek": 108252, "start": 1102.52, "end": 1107.2, "text": " thing without you having a massive long list of different instruction sets to choose from", "tokens": [51364, 551, 1553, 291, 1419, 257, 5994, 938, 1329, 295, 819, 10951, 6352, 281, 2826, 490, 51598], "temperature": 0.0, "avg_logprob": -0.1908008326654849, "compression_ratio": 1.6055900621118013, "no_speech_prob": 0.010560330003499985}, {"id": 213, "seek": 108252, "start": 1107.2, "end": 1111.96, "text": " for AMD64 so that work is coming but probably won't land for 24.04.", "tokens": [51598, 337, 34808, 19395, 370, 300, 589, 307, 1348, 457, 1391, 1582, 380, 2117, 337, 4022, 13, 14565, 13, 51836], "temperature": 0.0, "avg_logprob": -0.1908008326654849, "compression_ratio": 1.6055900621118013, "no_speech_prob": 0.010560330003499985}, {"id": 214, "seek": 111196, "start": 1112.0, "end": 1116.2, "text": " We also continue to introduce new patches into things like GNOME, we are still trying", "tokens": [50366, 492, 611, 2354, 281, 5366, 777, 26531, 666, 721, 411, 46411, 23344, 11, 321, 366, 920, 1382, 50576], "temperature": 0.0, "avg_logprob": -0.16766835661495433, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.025997577235102654}, {"id": 215, "seek": 111196, "start": 1116.2, "end": 1121.08, "text": " to get the GNOME triple buffering stuff landed ready for 24.04 which gives a much smoother", "tokens": [50576, 281, 483, 264, 46411, 23344, 15508, 9204, 1794, 1507, 15336, 1919, 337, 4022, 13, 14565, 597, 2709, 257, 709, 28640, 50820], "temperature": 0.0, "avg_logprob": -0.16766835661495433, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.025997577235102654}, {"id": 216, "seek": 111196, "start": 1121.08, "end": 1123.24, "text": " experience on the desktop as well.", "tokens": [50820, 1752, 322, 264, 14502, 382, 731, 13, 50928], "temperature": 0.0, "avg_logprob": -0.16766835661495433, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.025997577235102654}, {"id": 217, "seek": 111196, "start": 1123.24, "end": 1127.08, "text": " This runs really from Ubuntu server right up through to Ubuntu desktop and these tools", "tokens": [50928, 639, 6676, 534, 490, 30230, 45605, 7154, 558, 493, 807, 281, 30230, 45605, 14502, 293, 613, 3873, 51120], "temperature": 0.0, "avg_logprob": -0.16766835661495433, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.025997577235102654}, {"id": 218, "seek": 111196, "start": 1127.08, "end": 1129.04, "text": " will be available to desktop users too.", "tokens": [51120, 486, 312, 2435, 281, 14502, 5022, 886, 13, 51218], "temperature": 0.0, "avg_logprob": -0.16766835661495433, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.025997577235102654}, {"id": 219, "seek": 111196, "start": 1129.04, "end": 1132.92, "text": " You as a developer on Ubuntu should have access to the same debugging tools that you find in", "tokens": [51218, 509, 382, 257, 10754, 322, 30230, 45605, 820, 362, 2105, 281, 264, 912, 45592, 3873, 300, 291, 915, 294, 51412], "temperature": 0.0, "avg_logprob": -0.16766835661495433, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.025997577235102654}, {"id": 220, "seek": 111196, "start": 1132.92, "end": 1137.1200000000001, "text": " your production workloads in our opinion.", "tokens": [51412, 428, 4265, 32452, 294, 527, 4800, 13, 51622], "temperature": 0.0, "avg_logprob": -0.16766835661495433, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.025997577235102654}, {"id": 221, "seek": 111196, "start": 1137.1200000000001, "end": 1140.48, "text": " On a side note, we are trying to do this at a really big scale at Canonical, we are hiring", "tokens": [51622, 1282, 257, 1252, 3637, 11, 321, 366, 1382, 281, 360, 341, 412, 257, 534, 955, 4373, 412, 27666, 804, 11, 321, 366, 15335, 51790], "temperature": 0.0, "avg_logprob": -0.16766835661495433, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.025997577235102654}, {"id": 222, "seek": 114048, "start": 1140.52, "end": 1144.52, "text": " practice leads that will sit in a central team to build processes and tools and essentially", "tokens": [50366, 3124, 6689, 300, 486, 1394, 294, 257, 5777, 1469, 281, 1322, 7555, 293, 3873, 293, 4476, 50566], "temperature": 0.0, "avg_logprob": -0.1944091267829394, "compression_ratio": 1.694767441860465, "no_speech_prob": 0.051436811685562134}, {"id": 223, "seek": 114048, "start": 1144.52, "end": 1148.64, "text": " give advice across our 40 or so products and we are also hiring dedicated performance", "tokens": [50566, 976, 5192, 2108, 527, 3356, 420, 370, 3383, 293, 321, 366, 611, 15335, 8374, 3389, 50772], "temperature": 0.0, "avg_logprob": -0.1944091267829394, "compression_ratio": 1.694767441860465, "no_speech_prob": 0.051436811685562134}, {"id": 224, "seek": 114048, "start": 1148.64, "end": 1154.3600000000001, "text": " engineers for every single team whether that team be doing Go, Python, NodeJSC or whatever.", "tokens": [50772, 11955, 337, 633, 2167, 1469, 1968, 300, 1469, 312, 884, 1037, 11, 15329, 11, 38640, 41, 20839, 420, 2035, 13, 51058], "temperature": 0.0, "avg_logprob": -0.1944091267829394, "compression_ratio": 1.694767441860465, "no_speech_prob": 0.051436811685562134}, {"id": 225, "seek": 114048, "start": 1154.3600000000001, "end": 1158.48, "text": " If you are interested in that talk to me afterwards, check out Canonical.com slash careers, there", "tokens": [51058, 759, 291, 366, 3102, 294, 300, 751, 281, 385, 10543, 11, 1520, 484, 27666, 804, 13, 1112, 17330, 16409, 11, 456, 51264], "temperature": 0.0, "avg_logprob": -0.1944091267829394, "compression_ratio": 1.694767441860465, "no_speech_prob": 0.051436811685562134}, {"id": 226, "seek": 114048, "start": 1158.48, "end": 1161.04, "text": " is a couple of Canonical folks in here as well who you can talk to.", "tokens": [51264, 307, 257, 1916, 295, 27666, 804, 4024, 294, 510, 382, 731, 567, 291, 393, 751, 281, 13, 51392], "temperature": 0.0, "avg_logprob": -0.1944091267829394, "compression_ratio": 1.694767441860465, "no_speech_prob": 0.051436811685562134}, {"id": 227, "seek": 114048, "start": 1161.04, "end": 1163.72, "text": " If performance is your thing and you want to come and make use of frame pointers and", "tokens": [51392, 759, 3389, 307, 428, 551, 293, 291, 528, 281, 808, 293, 652, 764, 295, 3920, 44548, 293, 51526], "temperature": 0.0, "avg_logprob": -0.1944091267829394, "compression_ratio": 1.694767441860465, "no_speech_prob": 0.051436811685562134}, {"id": 228, "seek": 114048, "start": 1163.72, "end": 1169.16, "text": " make Ubuntu blazing fast then that is always an option to you.", "tokens": [51526, 652, 30230, 45605, 16379, 8781, 2370, 550, 300, 307, 1009, 364, 3614, 281, 291, 13, 51798], "temperature": 0.0, "avg_logprob": -0.1944091267829394, "compression_ratio": 1.694767441860465, "no_speech_prob": 0.051436811685562134}, {"id": 229, "seek": 116916, "start": 1169.24, "end": 1172.8400000000001, "text": " Finally, from my side, we have done a bit of work with Polar Signals, they have been", "tokens": [50368, 6288, 11, 490, 452, 1252, 11, 321, 362, 1096, 257, 857, 295, 589, 365, 3635, 289, 13515, 1124, 11, 436, 362, 668, 50548], "temperature": 0.0, "avg_logprob": -0.2390636781445977, "compression_ratio": 1.7655786350148368, "no_speech_prob": 0.27237436175346375}, {"id": 230, "seek": 116916, "start": 1172.8400000000001, "end": 1174.3200000000002, "text": " helping us along this way.", "tokens": [50548, 4315, 505, 2051, 341, 636, 13, 50622], "temperature": 0.0, "avg_logprob": -0.2390636781445977, "compression_ratio": 1.7655786350148368, "no_speech_prob": 0.27237436175346375}, {"id": 231, "seek": 116916, "start": 1174.3200000000002, "end": 1178.68, "text": " We have snap packages and charms available for Parker both for the agent and the server.", "tokens": [50622, 492, 362, 13650, 17401, 293, 41383, 2435, 337, 20155, 1293, 337, 264, 9461, 293, 264, 7154, 13, 50840], "temperature": 0.0, "avg_logprob": -0.2390636781445977, "compression_ratio": 1.7655786350148368, "no_speech_prob": 0.27237436175346375}, {"id": 232, "seek": 116916, "start": 1178.68, "end": 1182.76, "text": " On any Ubuntu machine you can see this in a cloud in it file with a single line.", "tokens": [50840, 1282, 604, 30230, 45605, 3479, 291, 393, 536, 341, 294, 257, 4588, 294, 309, 3991, 365, 257, 2167, 1622, 13, 51044], "temperature": 0.0, "avg_logprob": -0.2390636781445977, "compression_ratio": 1.7655786350148368, "no_speech_prob": 0.27237436175346375}, {"id": 233, "seek": 116916, "start": 1182.76, "end": 1186.72, "text": " You can snap and store the Parker agent, give it a single config with a token and start continuous", "tokens": [51044, 509, 393, 13650, 293, 3531, 264, 20155, 9461, 11, 976, 309, 257, 2167, 6662, 365, 257, 14862, 293, 722, 10957, 51242], "temperature": 0.0, "avg_logprob": -0.2390636781445977, "compression_ratio": 1.7655786350148368, "no_speech_prob": 0.27237436175346375}, {"id": 234, "seek": 116916, "start": 1186.72, "end": 1191.6000000000001, "text": " profiling out into Polar Signals cloud or you can host this over infrastructure yourself", "tokens": [51242, 1740, 4883, 484, 666, 3635, 289, 13515, 1124, 4588, 420, 291, 393, 3975, 341, 670, 6896, 1803, 51486], "temperature": 0.0, "avg_logprob": -0.2390636781445977, "compression_ratio": 1.7655786350148368, "no_speech_prob": 0.27237436175346375}, {"id": 235, "seek": 116916, "start": 1191.6000000000001, "end": 1195.72, "text": " on machines, on Kubernetes, on containers, whatever it is with Juju.", "tokens": [51486, 322, 8379, 11, 322, 23145, 11, 322, 17089, 11, 2035, 309, 307, 365, 508, 45652, 13, 51692], "temperature": 0.0, "avg_logprob": -0.2390636781445977, "compression_ratio": 1.7655786350148368, "no_speech_prob": 0.27237436175346375}, {"id": 236, "seek": 116916, "start": 1195.72, "end": 1198.64, "text": " We will continue to make improvements to that over time.", "tokens": [51692, 492, 486, 2354, 281, 652, 13797, 281, 300, 670, 565, 13, 51838], "temperature": 0.0, "avg_logprob": -0.2390636781445977, "compression_ratio": 1.7655786350148368, "no_speech_prob": 0.27237436175346375}, {"id": 237, "seek": 119864, "start": 1198.68, "end": 1205.16, "text": " It is a super easy way to get hold of this nice continuous profiling hotness in Ubuntu.", "tokens": [50366, 467, 307, 257, 1687, 1858, 636, 281, 483, 1797, 295, 341, 1481, 10957, 1740, 4883, 2368, 1287, 294, 30230, 45605, 13, 50690], "temperature": 0.0, "avg_logprob": -0.4138155850497159, "compression_ratio": 1.40625, "no_speech_prob": 0.021299272775650024}, {"id": 238, "seek": 119864, "start": 1205.16, "end": 1207.16, "text": " That is it, get in touch.", "tokens": [50690, 663, 307, 309, 11, 483, 294, 2557, 13, 50790], "temperature": 0.0, "avg_logprob": -0.4138155850497159, "compression_ratio": 1.40625, "no_speech_prob": 0.021299272775650024}, {"id": 239, "seek": 119864, "start": 1215.68, "end": 1217.76, "text": " Thank you very much for that.", "tokens": [51216, 1044, 291, 588, 709, 337, 300, 13, 51320], "temperature": 0.0, "avg_logprob": -0.4138155850497159, "compression_ratio": 1.40625, "no_speech_prob": 0.021299272775650024}, {"id": 240, "seek": 119864, "start": 1217.76, "end": 1220.0, "text": " Looking forward to the Ubuntu release.", "tokens": [51320, 11053, 2128, 281, 264, 30230, 45605, 4374, 13, 51432], "temperature": 0.0, "avg_logprob": -0.4138155850497159, "compression_ratio": 1.40625, "no_speech_prob": 0.021299272775650024}, {"id": 241, "seek": 119864, "start": 1220.0, "end": 1225.5200000000002, "text": " Are there any questions?", "tokens": [51432, 2014, 456, 604, 1651, 30, 51708], "temperature": 0.0, "avg_logprob": -0.4138155850497159, "compression_ratio": 1.40625, "no_speech_prob": 0.021299272775650024}, {"id": 242, "seek": 119864, "start": 1225.5200000000002, "end": 1226.5200000000002, "text": " Questions anyone?", "tokens": [51708, 27738, 2878, 30, 51758], "temperature": 0.0, "avg_logprob": -0.4138155850497159, "compression_ratio": 1.40625, "no_speech_prob": 0.021299272775650024}, {"id": 243, "seek": 122652, "start": 1227.52, "end": 1232.52, "text": " Once, twice, nobody?", "tokens": [50414, 3443, 11, 6091, 11, 5079, 30, 50664], "temperature": 0.0, "avg_logprob": -0.4363638715046208, "compression_ratio": 1.0810810810810811, "no_speech_prob": 0.03495733439922333}, {"id": 244, "seek": 122652, "start": 1232.52, "end": 1240.52, "text": " Okay, then thanks again and next up we have QuickWit I think in 20 minutes.", "tokens": [50664, 1033, 11, 550, 3231, 797, 293, 958, 493, 321, 362, 12101, 54, 270, 286, 519, 294, 945, 2077, 13, 51064], "temperature": 0.0, "avg_logprob": -0.4363638715046208, "compression_ratio": 1.0810810810810811, "no_speech_prob": 0.03495733439922333}, {"id": 245, "seek": 122652, "start": 1240.52, "end": 1241.52, "text": " Thank you, bye.", "tokens": [51064, 1044, 291, 11, 6543, 13, 51114], "temperature": 0.0, "avg_logprob": -0.4363638715046208, "compression_ratio": 1.0810810810810811, "no_speech_prob": 0.03495733439922333}, {"id": 246, "seek": 122652, "start": 1241.52, "end": 1242.52, "text": " Cheers.", "tokens": [51114, 13006, 13, 51164], "temperature": 0.0, "avg_logprob": -0.4363638715046208, "compression_ratio": 1.0810810810810811, "no_speech_prob": 0.03495733439922333}], "language": "en"}