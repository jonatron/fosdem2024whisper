{"text": " Okay, then let's get started. So we have one on stage James Loden, yet again about Bitcoin. Some of you will remember from your compiler classes maybe, or from other words. He's one of the team working on a Kobo front end in GCC. And now you may think, okay, Kobo is what my grandfather used maybe or something. But Kobo is still alive. Did it have a new standard release recently? Yeah, 23. There you go. And you use it. Diversity in programming languages. You use it every day indirectly probably for financial transactions. You may well have used it this morning. I tend to think that the three years I've spent on this is a lot of work. But I've learned today to appreciate how much other work has gone in to the thing that we are contributing to. We set out some years ago to add to we decided it's time for a real free Kobo compiler. And I proposed we should add it to GCC and that is what led to this presentation. I'm going to talk to you about why that is a good idea and why I had no idea what I was getting into and what I've learned in the process. All of the large firms, I would say, in the 1970s and 80s wrote their Books and Records software in Kobo and that's how we run our financial businesses everywhere in the world yet now. The chances are that your ATM transaction yesterday went through a Kobo program that was written in 1980 or so. There are estimated to be billions of lines in use still today. And there was a period some years ago in the 90s when some Kobo applications, for example, were moved to Java because that was the new thing. Those were the easy programs. The hard ones are one mass of spaghetti that you don't even want to know what it looks like. And the only way you can move it to a new system is by taking that source code and making it run on a different computer. You're never going to re-engineer it. If it were, I wouldn't be here. The banks or any of these institutions spend a fortune running their proprietary systems on emulations provided by vendors for machines they haven't made for decades. That costs a lot of money. I just want 10% of that money. So this is an ongoing thing. We're working now actually with someone else to go into more detail later. This idea is you just take the code as you find it, however it may be, you compile it and you run it into a different machine. So we are targeting ISO as a standard because you have to go somewhere plus whatever additions are needed by some particular house to build what they need for their purposes. It's so old, Bacchus now hasn't started yet. So yes, we have a grammar. No, it was not defined for anything like an LALR machine. So it is an all-encompassing thing, but there is no place to go to get a library, a standard library. When COPL was defined originally there were no functions, there was no recursion, there were no local variables. Your program had stuff, they worked on it and produced things. It's also a gigantic language because it takes all of the problems that you have as an application programmer and puts it in the compiler. So if you want to convert something there's no printf string. You just move your variable from one thing to another, that's a compiler job. It's very fast because if you aren't doing anything in particular to check for say runtime errors, right, like length of the variable or something, that's the default behavior because 1957, we run as quick as C at the bottom. There are other features that can slow it down, but that's to take care of things that you would like to take care of, like that I write to a place that doesn't belong to me. Somebody suggested that C++ is an easy language to compile and I think there's reason to believe that's true. This is a big language. And that's not the biggest one. I checked Ganooko Bowl recently. Their sizes are about twice that now, those numbers in terms of terminals and rules inside the grammar. And this is just one of the verbs. You don't just name the things past the arguments, you say by which way you want to do it. And if something goes wrong, you have a way to capture that too. That's also handled inside the system. It's not try and catch, but it's another such exception system. Yeah, it's work. So, yeah, I've been doing this for a while. That's the price tag on my version of C programming language. I entered into this saying, okay, we're going to write a compiler. And I understood at the beginning it was just the front end. It turns out that my work is chapter four, section four. Everything else is the compiler. And I had to, I entered into this not really knowing, oh, 15 minutes, okay, that's good. Not really knowing what this was going to mean. And so, and I had never written such a thing as I'm working on now. I had used Bison for smaller tasks. But I didn't really, you know how it is, right? You start out trying to figure out how to do something. That's where that's the way I worked on it. And the there's some distance between knowing what you have to do, reading about how it's done, and then actually getting there. And this is the sort of answer I had to find my way through in order to learn what we were doing. And there's plenty and how to say this, there is no Royal Road, meaning to say, no one will tell you how to do this. All you can do is pick up the pieces and plow through it. I recommend as a life proposition that you begin every problem by knowing the complete domain, the problem domain perfectly, and the tools you're going to need perfectly. That I think you can guarantee will lead to success. In my case, I substituted what most programmers have, which is 90% of programmers think that they're above average. So why not just do that? There is a relatively small number of people in the in the Bison world. It's not a it was not has not been easy, I don't think as a person using that project to find people who can help me understand how to solve the problems I'm having. So that that's just a qualifier for like what's life like in the in the world of a guy who's writing a parser. Also, I had to learn that the Bison and Flex, the Lexar and the parser. It's really an odd thing in our world where you've got two projects that I don't know to what degree they talk to each other. They communicate and cooperate. It's not evident from what I've seen that there's very much communication like that. And but they share global variables. They share functions. They talk about each other a little bit. But they don't say the same things. So that was a that's a stumbling block that I have no idea how to solve. But I think it's a it's a gap in in the world that we work in. When you are writing your parser, there are two levels you're working in or maybe more. You are defining the metadata for your for your language in C. And then you're using C to tell Bob Dubner to generate the code for that stuff, please. So it was not clear when I began. And it's still a little bit fuzzy for me where those definitions have to lie and why it's sometimes difficult to understand why Bison doesn't understand what we're talking about. But I have found that we were able to solve almost all the problems in in the Kobo grammar, just using good old precedence, that is to say, you're always defining one thing in terms of another. If you are, you know, you could it's a little bit like a make file, right? It's work your way up to the left. And then what do I spend my do my day, my day I spend tracing, I just looking at the results. What did the machine do? We move from state here to state there, we have this, we're looking for that. It's not there. Oh, that's the error. Okay. I also discovered that if you read these books at the beginning, they say, Oh, well, we have identifiers, how do we change how we know how do we distinguish a function name from a variable name? Well, in my case, the function names are all defined. They're all statements, it's call, it's, it's read, it's, it's inspect. So I don't have that I know the names. And I know all my variable names, because Kobal has four sections and one of them is the data section of us where you put your variable names. So those are all. So I didn't have the problem of here's a string, I'll pass that off to the parser and let him figure out like I could support them out and have different kinds of tokens for different individual pieces. And that's this magic in that that's what you want to do. The more types you got, the less you're going to have to worry. Bison itself is a complex beast. It's not clear to me who's at the helm. There are a lot of pieces being added in different ways to do different things. And they all look very interesting. I just don't know which ones I want. I learned that there were some things that were quite useful. And, and then not. So if you have an optional term in the grammar, and you, and that thing, you know, obviously can be substituted for the thing that could be there, then, then you can use the precedent thing to to convert the empty version of it to the same presidents as the thing that is that would be there if it was present. That worked great. If you have a conflict and you simply say, Oh, well, that rule needs higher presidents than the other one. Very often that won't work. Somebody in this room might be able to tell me why. But I that has has been a dead end more than once. There were a lot of work went into Bison counter examples. It's something that I think someone spent a lot of time on. I myself have tried that feature several times hoping for a magic solution, because I use those need those frequently. But eventually I've come to find that, at least for myself, it doesn't help me that much. It's it you all it does is produce for you the path that you can actually trace through yourself back through the report. If you look at the state machine. So yes, it could be resolved different ways. Sometimes it helps me to think, doesn't matter. It's okay, we can take this shift. We don't have to worry about the reduce. I did try to run the graph on my grammar. I never saw it never came back. It did. I gave it 24 hours, but I never got an answer. So I'm not sure why that features there. I guess as a tutorial thing, if you had a seven line grammar and you want to understand how things operate. But I had to went my way through all of the different things that it could do this feature set that I was talking about is and I don't know the answer. Why I only know the answer I found. And I think that's true when you're in a complex environment, you just pick the pieces that work for you. And that's how you land there. So Tim toad, you will remember that from Pearl, there's more than one way to do it. There you can put options into the grammar itself or you can put options on the command line. I chose the to think that you could probably run the same source file with different options. So why put them in the source file put them on the command line so you can choose it. That's that's the route I went down. But there are pure parsers, you can push them, you can use the gc++ interfaces, you've got the general something. Parcer, you've got different versions of parsers that can be produced from the same text file. And you have YAC emulation. And so I had to like, decide what not to use. And I think what we want to do is fairly vanilla. There is a really cool feature though of the way they've separated out the pieces of C code that have to go into the grammar. And they don't do a great job if you ask me of describing how that works. But these these things of separating out what the early part of the the metaflight metadata needs in order to describe the data as versus the way we're going to generate the code. That requires and provides is very, very useful. And locations, you can't write a debugger if you don't have locations. So I would recommend if perhaps I'll send this to the bison folks that you you separate out your code that's going to the pieces that you need into different files and use those brackets to to to tell by some what the way they belong. It's really handy actually if you got enough C code in your in your YAC file to put it in some include somewhere because your editor will make you a lot happier. If you use these two, if you use a if you've got a printer type for every element, every semantic type in your union, then you get nice outputs like this. And there ought to be a rule that says, or there'll even ought to be a warning that says, Hey, you define a type where's the string for it? How come I can't see what this looks like? You're going to want it. And that's what you see here is a reduction for the varying part of the perform a part of the one of the four types of loops. And we know we know that we've got some keywords we've got varying we have from we have we were it's coming from a numeric display that's a bunch of digits in a row that we can use like a number. And and it's got a name. And this was tricky because names don't usually have hyphens in them when you get to the assembler. And there's a literal so that that was a that was probably a three or something. And boom, and so I'm able to look at this trace and refer right back to the source code and see the pieces that are are being operated on. Do not open up your debugger on the outputted on the on the object file that is compiled from the seek that was generated by the bison. You just won't like it. You don't run GDB on make. You don't run GDB on on that either. It's just awful. The what you do want to know is what the rules mean. You're using a system that is declarative. So you have to think about what the rule says and how they operate. That's the way you get to to the answer. And I think I'm just about done except to ask you to help me solve my problem. What you see here is what you would like to write in a lot of languages, right? The second thing is much more easily typed as the first thing, but it easily parsed. I'm on version eight of my my test for that one because when you get to see you don't know if C belongs to be as means it's relating back to a or whether C is going to be followed by a relational operator and be just an ordinary expansion. So you hit that spot and you think what I need is L. R. Two, but I don't have it. So but maybe there's someone here who does know. So that's why I'm here and I'm done. Thank you very much. I'm glad you asked that question. The man asked why didn't I write a handwritten parser. And the reason is because bison has saved my bacon. The the I don't know how to do that. I do know this many times every week, not every day, but every week. The the the bison output tells me I have an ambiguity in the grammar. I'm not that can't be parsed. It finds the mistakes that I would be putting in freely if I was writing it by hand. Any more questions? Or suggestions for this issue? I'm I'm here all day.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 14.44, "text": " Okay, then let's get started. So we have one on stage James Loden, yet again about", "tokens": [50364, 1033, 11, 550, 718, 311, 483, 1409, 13, 407, 321, 362, 472, 322, 3233, 5678, 441, 33482, 11, 1939, 797, 466, 51086], "temperature": 0.0, "avg_logprob": -0.43613634882746516, "compression_ratio": 1.413978494623656, "no_speech_prob": 0.6803304553031921}, {"id": 1, "seek": 0, "start": 14.44, "end": 22.76, "text": " Bitcoin. Some of you will remember from your compiler classes maybe, or from other words.", "tokens": [51086, 11414, 13, 2188, 295, 291, 486, 1604, 490, 428, 31958, 5359, 1310, 11, 420, 490, 661, 2283, 13, 51502], "temperature": 0.0, "avg_logprob": -0.43613634882746516, "compression_ratio": 1.413978494623656, "no_speech_prob": 0.6803304553031921}, {"id": 2, "seek": 0, "start": 22.76, "end": 28.240000000000002, "text": " He's one of the team working on a Kobo front end in GCC. And now you may think, okay, Kobo", "tokens": [51502, 634, 311, 472, 295, 264, 1469, 1364, 322, 257, 46353, 78, 1868, 917, 294, 460, 11717, 13, 400, 586, 291, 815, 519, 11, 1392, 11, 46353, 78, 51776], "temperature": 0.0, "avg_logprob": -0.43613634882746516, "compression_ratio": 1.413978494623656, "no_speech_prob": 0.6803304553031921}, {"id": 3, "seek": 2824, "start": 28.24, "end": 35.72, "text": " is what my grandfather used maybe or something. But Kobo is still alive. Did it have a new", "tokens": [50364, 307, 437, 452, 14754, 1143, 1310, 420, 746, 13, 583, 46353, 78, 307, 920, 5465, 13, 2589, 309, 362, 257, 777, 50738], "temperature": 0.0, "avg_logprob": -0.36278125643730164, "compression_ratio": 1.40625, "no_speech_prob": 0.14722862839698792}, {"id": 4, "seek": 2824, "start": 35.72, "end": 47.76, "text": " standard release recently? Yeah, 23. There you go. And you use it. Diversity in programming", "tokens": [50738, 3832, 4374, 3938, 30, 865, 11, 6673, 13, 821, 291, 352, 13, 400, 291, 764, 309, 13, 44187, 294, 9410, 51340], "temperature": 0.0, "avg_logprob": -0.36278125643730164, "compression_ratio": 1.40625, "no_speech_prob": 0.14722862839698792}, {"id": 5, "seek": 2824, "start": 47.76, "end": 52.519999999999996, "text": " languages. You use it every day indirectly probably for financial transactions. You may", "tokens": [51340, 8650, 13, 509, 764, 309, 633, 786, 37779, 1391, 337, 4669, 16856, 13, 509, 815, 51578], "temperature": 0.0, "avg_logprob": -0.36278125643730164, "compression_ratio": 1.40625, "no_speech_prob": 0.14722862839698792}, {"id": 6, "seek": 5252, "start": 52.56, "end": 60.400000000000006, "text": " well have used it this morning. I tend to think that the three years I've spent on this is a lot", "tokens": [50366, 731, 362, 1143, 309, 341, 2446, 13, 286, 3928, 281, 519, 300, 264, 1045, 924, 286, 600, 4418, 322, 341, 307, 257, 688, 50758], "temperature": 0.0, "avg_logprob": -0.13865068796518687, "compression_ratio": 1.5519125683060109, "no_speech_prob": 0.00870506651699543}, {"id": 7, "seek": 5252, "start": 60.400000000000006, "end": 68.48, "text": " of work. But I've learned today to appreciate how much other work has gone in to the thing that", "tokens": [50758, 295, 589, 13, 583, 286, 600, 3264, 965, 281, 4449, 577, 709, 661, 589, 575, 2780, 294, 281, 264, 551, 300, 51162], "temperature": 0.0, "avg_logprob": -0.13865068796518687, "compression_ratio": 1.5519125683060109, "no_speech_prob": 0.00870506651699543}, {"id": 8, "seek": 5252, "start": 68.48, "end": 78.52000000000001, "text": " we are contributing to. We set out some years ago to add to we decided it's time for a real", "tokens": [51162, 321, 366, 19270, 281, 13, 492, 992, 484, 512, 924, 2057, 281, 909, 281, 321, 3047, 309, 311, 565, 337, 257, 957, 51664], "temperature": 0.0, "avg_logprob": -0.13865068796518687, "compression_ratio": 1.5519125683060109, "no_speech_prob": 0.00870506651699543}, {"id": 9, "seek": 7852, "start": 79.24, "end": 85.96, "text": " free Kobo compiler. And I proposed we should add it to GCC and that is what led to this", "tokens": [50400, 1737, 46353, 78, 31958, 13, 400, 286, 10348, 321, 820, 909, 309, 281, 460, 11717, 293, 300, 307, 437, 4684, 281, 341, 50736], "temperature": 0.0, "avg_logprob": -0.1586582158741198, "compression_ratio": 1.5136612021857923, "no_speech_prob": 0.01242427621036768}, {"id": 10, "seek": 7852, "start": 85.96, "end": 93.03999999999999, "text": " presentation. I'm going to talk to you about why that is a good idea and why I had no idea what", "tokens": [50736, 5860, 13, 286, 478, 516, 281, 751, 281, 291, 466, 983, 300, 307, 257, 665, 1558, 293, 983, 286, 632, 572, 1558, 437, 51090], "temperature": 0.0, "avg_logprob": -0.1586582158741198, "compression_ratio": 1.5136612021857923, "no_speech_prob": 0.01242427621036768}, {"id": 11, "seek": 7852, "start": 93.03999999999999, "end": 103.28, "text": " I was getting into and what I've learned in the process. All of the large firms, I would say,", "tokens": [51090, 286, 390, 1242, 666, 293, 437, 286, 600, 3264, 294, 264, 1399, 13, 1057, 295, 264, 2416, 18055, 11, 286, 576, 584, 11, 51602], "temperature": 0.0, "avg_logprob": -0.1586582158741198, "compression_ratio": 1.5136612021857923, "no_speech_prob": 0.01242427621036768}, {"id": 12, "seek": 10328, "start": 103.72, "end": 110.24, "text": " in the 1970s and 80s wrote their Books and Records software in Kobo and that's how we run our", "tokens": [50386, 294, 264, 14577, 82, 293, 4688, 82, 4114, 641, 33843, 293, 31928, 4722, 294, 46353, 78, 293, 300, 311, 577, 321, 1190, 527, 50712], "temperature": 0.0, "avg_logprob": -0.136673832987691, "compression_ratio": 1.5591836734693878, "no_speech_prob": 0.03208210691809654}, {"id": 13, "seek": 10328, "start": 110.24, "end": 116.08, "text": " financial businesses everywhere in the world yet now. The chances are that your ATM transaction", "tokens": [50712, 4669, 6011, 5315, 294, 264, 1002, 1939, 586, 13, 440, 10486, 366, 300, 428, 46455, 14425, 51004], "temperature": 0.0, "avg_logprob": -0.136673832987691, "compression_ratio": 1.5591836734693878, "no_speech_prob": 0.03208210691809654}, {"id": 14, "seek": 10328, "start": 116.08, "end": 123.12, "text": " yesterday went through a Kobo program that was written in 1980 or so. There are estimated to be", "tokens": [51004, 5186, 1437, 807, 257, 46353, 78, 1461, 300, 390, 3720, 294, 13626, 420, 370, 13, 821, 366, 14109, 281, 312, 51356], "temperature": 0.0, "avg_logprob": -0.136673832987691, "compression_ratio": 1.5591836734693878, "no_speech_prob": 0.03208210691809654}, {"id": 15, "seek": 10328, "start": 123.12, "end": 130.72, "text": " billions of lines in use still today. And there was a period some years ago in the 90s when some", "tokens": [51356, 17375, 295, 3876, 294, 764, 920, 965, 13, 400, 456, 390, 257, 2896, 512, 924, 2057, 294, 264, 4289, 82, 562, 512, 51736], "temperature": 0.0, "avg_logprob": -0.136673832987691, "compression_ratio": 1.5591836734693878, "no_speech_prob": 0.03208210691809654}, {"id": 16, "seek": 13072, "start": 130.8, "end": 136.44, "text": " Kobo applications, for example, were moved to Java because that was the new thing. Those were the", "tokens": [50368, 46353, 78, 5821, 11, 337, 1365, 11, 645, 4259, 281, 10745, 570, 300, 390, 264, 777, 551, 13, 3950, 645, 264, 50650], "temperature": 0.0, "avg_logprob": -0.11079521179199218, "compression_ratio": 1.5708502024291497, "no_speech_prob": 0.006901896093040705}, {"id": 17, "seek": 13072, "start": 136.44, "end": 142.0, "text": " easy programs. The hard ones are one mass of spaghetti that you don't even want to know what", "tokens": [50650, 1858, 4268, 13, 440, 1152, 2306, 366, 472, 2758, 295, 28556, 300, 291, 500, 380, 754, 528, 281, 458, 437, 50928], "temperature": 0.0, "avg_logprob": -0.11079521179199218, "compression_ratio": 1.5708502024291497, "no_speech_prob": 0.006901896093040705}, {"id": 18, "seek": 13072, "start": 142.0, "end": 147.84, "text": " it looks like. And the only way you can move it to a new system is by taking that source code and", "tokens": [50928, 309, 1542, 411, 13, 400, 264, 787, 636, 291, 393, 1286, 309, 281, 257, 777, 1185, 307, 538, 1940, 300, 4009, 3089, 293, 51220], "temperature": 0.0, "avg_logprob": -0.11079521179199218, "compression_ratio": 1.5708502024291497, "no_speech_prob": 0.006901896093040705}, {"id": 19, "seek": 13072, "start": 147.84, "end": 152.76, "text": " making it run on a different computer. You're never going to re-engineer it. If it were, I wouldn't", "tokens": [51220, 1455, 309, 1190, 322, 257, 819, 3820, 13, 509, 434, 1128, 516, 281, 319, 12, 25609, 260, 309, 13, 759, 309, 645, 11, 286, 2759, 380, 51466], "temperature": 0.0, "avg_logprob": -0.11079521179199218, "compression_ratio": 1.5708502024291497, "no_speech_prob": 0.006901896093040705}, {"id": 20, "seek": 15276, "start": 152.79999999999998, "end": 163.35999999999999, "text": " be here. The banks or any of these institutions spend a fortune running their proprietary systems on", "tokens": [50366, 312, 510, 13, 440, 10237, 420, 604, 295, 613, 8142, 3496, 257, 16531, 2614, 641, 38992, 3652, 322, 50894], "temperature": 0.0, "avg_logprob": -0.17909191930016807, "compression_ratio": 1.4130434782608696, "no_speech_prob": 0.10661439597606659}, {"id": 21, "seek": 15276, "start": 163.35999999999999, "end": 170.51999999999998, "text": " emulations provided by vendors for machines they haven't made for decades. That costs a lot of", "tokens": [50894, 846, 4136, 5649, 538, 22056, 337, 8379, 436, 2378, 380, 1027, 337, 7878, 13, 663, 5497, 257, 688, 295, 51252], "temperature": 0.0, "avg_logprob": -0.17909191930016807, "compression_ratio": 1.4130434782608696, "no_speech_prob": 0.10661439597606659}, {"id": 22, "seek": 17052, "start": 171.16, "end": 184.52, "text": " money. I just want 10% of that money. So this is an ongoing thing. We're working now actually with", "tokens": [50396, 1460, 13, 286, 445, 528, 1266, 4, 295, 300, 1460, 13, 407, 341, 307, 364, 10452, 551, 13, 492, 434, 1364, 586, 767, 365, 51064], "temperature": 0.0, "avg_logprob": -0.21831891475579676, "compression_ratio": 1.4924623115577889, "no_speech_prob": 0.3072018027305603}, {"id": 23, "seek": 17052, "start": 184.52, "end": 190.68, "text": " someone else to go into more detail later. This idea is you just take the code as you find it, however", "tokens": [51064, 1580, 1646, 281, 352, 666, 544, 2607, 1780, 13, 639, 1558, 307, 291, 445, 747, 264, 3089, 382, 291, 915, 309, 11, 4461, 51372], "temperature": 0.0, "avg_logprob": -0.21831891475579676, "compression_ratio": 1.4924623115577889, "no_speech_prob": 0.3072018027305603}, {"id": 24, "seek": 17052, "start": 190.68, "end": 197.56, "text": " it may be, you compile it and you run it into a different machine. So we are targeting ISO as a", "tokens": [51372, 309, 815, 312, 11, 291, 31413, 309, 293, 291, 1190, 309, 666, 257, 819, 3479, 13, 407, 321, 366, 17918, 25042, 382, 257, 51716], "temperature": 0.0, "avg_logprob": -0.21831891475579676, "compression_ratio": 1.4924623115577889, "no_speech_prob": 0.3072018027305603}, {"id": 25, "seek": 19756, "start": 197.6, "end": 202.96, "text": " standard because you have to go somewhere plus whatever additions are needed by some particular", "tokens": [50366, 3832, 570, 291, 362, 281, 352, 4079, 1804, 2035, 35113, 366, 2978, 538, 512, 1729, 50634], "temperature": 0.0, "avg_logprob": -0.2429843478732639, "compression_ratio": 1.4329896907216495, "no_speech_prob": 0.0020504361018538475}, {"id": 26, "seek": 19756, "start": 202.96, "end": 212.4, "text": " house to build what they need for their purposes. It's so old, Bacchus now hasn't started yet.", "tokens": [50634, 1782, 281, 1322, 437, 436, 643, 337, 641, 9932, 13, 467, 311, 370, 1331, 11, 363, 326, 339, 301, 586, 6132, 380, 1409, 1939, 13, 51106], "temperature": 0.0, "avg_logprob": -0.2429843478732639, "compression_ratio": 1.4329896907216495, "no_speech_prob": 0.0020504361018538475}, {"id": 27, "seek": 19756, "start": 212.4, "end": 226.84, "text": " So yes, we have a grammar. No, it was not defined for anything like an LALR machine. So", "tokens": [51106, 407, 2086, 11, 321, 362, 257, 22317, 13, 883, 11, 309, 390, 406, 7642, 337, 1340, 411, 364, 441, 3427, 49, 3479, 13, 407, 51828], "temperature": 0.0, "avg_logprob": -0.2429843478732639, "compression_ratio": 1.4329896907216495, "no_speech_prob": 0.0020504361018538475}, {"id": 28, "seek": 22684, "start": 227.64000000000001, "end": 233.68, "text": " it is an all-encompassing thing, but there is no place to go to get a library, a standard library.", "tokens": [50404, 309, 307, 364, 439, 12, 268, 25052, 278, 551, 11, 457, 456, 307, 572, 1081, 281, 352, 281, 483, 257, 6405, 11, 257, 3832, 6405, 13, 50706], "temperature": 0.0, "avg_logprob": -0.22592787120653235, "compression_ratio": 1.6, "no_speech_prob": 0.001098217093385756}, {"id": 29, "seek": 22684, "start": 235.68, "end": 241.44, "text": " When COPL was defined originally there were no functions, there was no recursion, there were no", "tokens": [50806, 1133, 3002, 21593, 390, 7642, 7993, 456, 645, 572, 6828, 11, 456, 390, 572, 20560, 313, 11, 456, 645, 572, 51094], "temperature": 0.0, "avg_logprob": -0.22592787120653235, "compression_ratio": 1.6, "no_speech_prob": 0.001098217093385756}, {"id": 30, "seek": 22684, "start": 241.44, "end": 249.92000000000002, "text": " local variables. Your program had stuff, they worked on it and produced things. It's also a", "tokens": [51094, 2654, 9102, 13, 2260, 1461, 632, 1507, 11, 436, 2732, 322, 309, 293, 7126, 721, 13, 467, 311, 611, 257, 51518], "temperature": 0.0, "avg_logprob": -0.22592787120653235, "compression_ratio": 1.6, "no_speech_prob": 0.001098217093385756}, {"id": 31, "seek": 22684, "start": 249.92000000000002, "end": 255.48000000000002, "text": " gigantic language because it takes all of the problems that you have as an application programmer", "tokens": [51518, 26800, 2856, 570, 309, 2516, 439, 295, 264, 2740, 300, 291, 362, 382, 364, 3861, 32116, 51796], "temperature": 0.0, "avg_logprob": -0.22592787120653235, "compression_ratio": 1.6, "no_speech_prob": 0.001098217093385756}, {"id": 32, "seek": 25548, "start": 255.56, "end": 260.8, "text": " and puts it in the compiler. So if you want to convert something there's no printf string. You", "tokens": [50368, 293, 8137, 309, 294, 264, 31958, 13, 407, 498, 291, 528, 281, 7620, 746, 456, 311, 572, 4482, 69, 6798, 13, 509, 50630], "temperature": 0.0, "avg_logprob": -0.18106129294947573, "compression_ratio": 1.6147540983606556, "no_speech_prob": 0.0019873359706252813}, {"id": 33, "seek": 25548, "start": 260.8, "end": 267.8, "text": " just move your variable from one thing to another, that's a compiler job. It's very fast because if", "tokens": [50630, 445, 1286, 428, 7006, 490, 472, 551, 281, 1071, 11, 300, 311, 257, 31958, 1691, 13, 467, 311, 588, 2370, 570, 498, 50980], "temperature": 0.0, "avg_logprob": -0.18106129294947573, "compression_ratio": 1.6147540983606556, "no_speech_prob": 0.0019873359706252813}, {"id": 34, "seek": 25548, "start": 267.8, "end": 274.8, "text": " you aren't doing anything in particular to check for say runtime errors, right, like length of the", "tokens": [50980, 291, 3212, 380, 884, 1340, 294, 1729, 281, 1520, 337, 584, 34474, 13603, 11, 558, 11, 411, 4641, 295, 264, 51330], "temperature": 0.0, "avg_logprob": -0.18106129294947573, "compression_ratio": 1.6147540983606556, "no_speech_prob": 0.0019873359706252813}, {"id": 35, "seek": 25548, "start": 274.8, "end": 284.68, "text": " variable or something, that's the default behavior because 1957, we run as quick as C at the bottom.", "tokens": [51330, 7006, 420, 746, 11, 300, 311, 264, 7576, 5223, 570, 46256, 11, 321, 1190, 382, 1702, 382, 383, 412, 264, 2767, 13, 51824], "temperature": 0.0, "avg_logprob": -0.18106129294947573, "compression_ratio": 1.6147540983606556, "no_speech_prob": 0.0019873359706252813}, {"id": 36, "seek": 28548, "start": 285.52000000000004, "end": 289.16, "text": " There are other features that can slow it down, but that's to take care of things that you would", "tokens": [50366, 821, 366, 661, 4122, 300, 393, 2964, 309, 760, 11, 457, 300, 311, 281, 747, 1127, 295, 721, 300, 291, 576, 50548], "temperature": 0.0, "avg_logprob": -0.21025375525156656, "compression_ratio": 1.6288209606986899, "no_speech_prob": 0.00020341524214018136}, {"id": 37, "seek": 28548, "start": 289.16, "end": 292.28000000000003, "text": " like to take care of, like that I write to a place that doesn't belong to me.", "tokens": [50548, 411, 281, 747, 1127, 295, 11, 411, 300, 286, 2464, 281, 257, 1081, 300, 1177, 380, 5784, 281, 385, 13, 50704], "temperature": 0.0, "avg_logprob": -0.21025375525156656, "compression_ratio": 1.6288209606986899, "no_speech_prob": 0.00020341524214018136}, {"id": 38, "seek": 28548, "start": 295.24, "end": 302.24, "text": " Somebody suggested that C++ is an easy language to compile and I think there's reason to believe", "tokens": [50852, 13463, 10945, 300, 383, 25472, 307, 364, 1858, 2856, 281, 31413, 293, 286, 519, 456, 311, 1778, 281, 1697, 51202], "temperature": 0.0, "avg_logprob": -0.21025375525156656, "compression_ratio": 1.6288209606986899, "no_speech_prob": 0.00020341524214018136}, {"id": 39, "seek": 28548, "start": 302.24, "end": 313.76, "text": " that's true. This is a big language. And that's not the biggest one. I checked Ganooko Bowl recently.", "tokens": [51202, 300, 311, 2074, 13, 639, 307, 257, 955, 2856, 13, 400, 300, 311, 406, 264, 3880, 472, 13, 286, 10033, 19461, 1212, 78, 25044, 3938, 13, 51778], "temperature": 0.0, "avg_logprob": -0.21025375525156656, "compression_ratio": 1.6288209606986899, "no_speech_prob": 0.00020341524214018136}, {"id": 40, "seek": 31376, "start": 314.52, "end": 320.88, "text": " Their sizes are about twice that now, those numbers in terms of terminals and rules inside the grammar.", "tokens": [50402, 6710, 11602, 366, 466, 6091, 300, 586, 11, 729, 3547, 294, 2115, 295, 38579, 293, 4474, 1854, 264, 22317, 13, 50720], "temperature": 0.0, "avg_logprob": -0.20809797807173294, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0030749388970434666}, {"id": 41, "seek": 31376, "start": 323.24, "end": 329.92, "text": " And this is just one of the verbs. You don't just name the things past the arguments, you say by which", "tokens": [50838, 400, 341, 307, 445, 472, 295, 264, 30051, 13, 509, 500, 380, 445, 1315, 264, 721, 1791, 264, 12869, 11, 291, 584, 538, 597, 51172], "temperature": 0.0, "avg_logprob": -0.20809797807173294, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0030749388970434666}, {"id": 42, "seek": 31376, "start": 329.92, "end": 336.76, "text": " way you want to do it. And if something goes wrong, you have a way to capture that too. That's also", "tokens": [51172, 636, 291, 528, 281, 360, 309, 13, 400, 498, 746, 1709, 2085, 11, 291, 362, 257, 636, 281, 7983, 300, 886, 13, 663, 311, 611, 51514], "temperature": 0.0, "avg_logprob": -0.20809797807173294, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0030749388970434666}, {"id": 43, "seek": 33676, "start": 336.76, "end": 342.71999999999997, "text": " handled inside the system. It's not try and catch, but it's another such exception system.", "tokens": [50364, 18033, 1854, 264, 1185, 13, 467, 311, 406, 853, 293, 3745, 11, 457, 309, 311, 1071, 1270, 11183, 1185, 13, 50662], "temperature": 0.0, "avg_logprob": -0.20129732081764623, "compression_ratio": 1.4659685863874345, "no_speech_prob": 0.07473538815975189}, {"id": 44, "seek": 33676, "start": 342.71999999999997, "end": 357.12, "text": " Yeah, it's work. So, yeah, I've been doing this for a while. That's the price tag on my version of", "tokens": [50662, 865, 11, 309, 311, 589, 13, 407, 11, 1338, 11, 286, 600, 668, 884, 341, 337, 257, 1339, 13, 663, 311, 264, 3218, 6162, 322, 452, 3037, 295, 51382], "temperature": 0.0, "avg_logprob": -0.20129732081764623, "compression_ratio": 1.4659685863874345, "no_speech_prob": 0.07473538815975189}, {"id": 45, "seek": 33676, "start": 357.12, "end": 366.71999999999997, "text": " C programming language. I entered into this saying, okay, we're going to write a compiler.", "tokens": [51382, 383, 9410, 2856, 13, 286, 9065, 666, 341, 1566, 11, 1392, 11, 321, 434, 516, 281, 2464, 257, 31958, 13, 51862], "temperature": 0.0, "avg_logprob": -0.20129732081764623, "compression_ratio": 1.4659685863874345, "no_speech_prob": 0.07473538815975189}, {"id": 46, "seek": 36672, "start": 367.52000000000004, "end": 372.6, "text": " And I understood at the beginning it was just the front end. It turns out that my work is chapter", "tokens": [50404, 400, 286, 7320, 412, 264, 2863, 309, 390, 445, 264, 1868, 917, 13, 467, 4523, 484, 300, 452, 589, 307, 7187, 50658], "temperature": 0.0, "avg_logprob": -0.20035438279847842, "compression_ratio": 1.4870466321243523, "no_speech_prob": 0.000391885987482965}, {"id": 47, "seek": 36672, "start": 372.6, "end": 383.84000000000003, "text": " four, section four. Everything else is the compiler. And I had to, I entered into this not really", "tokens": [50658, 1451, 11, 3541, 1451, 13, 5471, 1646, 307, 264, 31958, 13, 400, 286, 632, 281, 11, 286, 9065, 666, 341, 406, 534, 51220], "temperature": 0.0, "avg_logprob": -0.20035438279847842, "compression_ratio": 1.4870466321243523, "no_speech_prob": 0.000391885987482965}, {"id": 48, "seek": 36672, "start": 383.84000000000003, "end": 389.52000000000004, "text": " knowing, oh, 15 minutes, okay, that's good. Not really knowing what this was going to mean.", "tokens": [51220, 5276, 11, 1954, 11, 2119, 2077, 11, 1392, 11, 300, 311, 665, 13, 1726, 534, 5276, 437, 341, 390, 516, 281, 914, 13, 51504], "temperature": 0.0, "avg_logprob": -0.20035438279847842, "compression_ratio": 1.4870466321243523, "no_speech_prob": 0.000391885987482965}, {"id": 49, "seek": 38952, "start": 390.35999999999996, "end": 400.28, "text": " And so, and I had never written such a thing as I'm working on now. I had used Bison for smaller", "tokens": [50406, 400, 370, 11, 293, 286, 632, 1128, 3720, 1270, 257, 551, 382, 286, 478, 1364, 322, 586, 13, 286, 632, 1143, 363, 2770, 337, 4356, 50902], "temperature": 0.0, "avg_logprob": -0.203841233253479, "compression_ratio": 1.4820512820512821, "no_speech_prob": 0.0022517244797199965}, {"id": 50, "seek": 38952, "start": 400.28, "end": 407.47999999999996, "text": " tasks. But I didn't really, you know how it is, right? You start out trying to figure out how to", "tokens": [50902, 9608, 13, 583, 286, 994, 380, 534, 11, 291, 458, 577, 309, 307, 11, 558, 30, 509, 722, 484, 1382, 281, 2573, 484, 577, 281, 51262], "temperature": 0.0, "avg_logprob": -0.203841233253479, "compression_ratio": 1.4820512820512821, "no_speech_prob": 0.0022517244797199965}, {"id": 51, "seek": 38952, "start": 407.47999999999996, "end": 412.79999999999995, "text": " do something. That's where that's the way I worked on it. And the there's some distance between", "tokens": [51262, 360, 746, 13, 663, 311, 689, 300, 311, 264, 636, 286, 2732, 322, 309, 13, 400, 264, 456, 311, 512, 4560, 1296, 51528], "temperature": 0.0, "avg_logprob": -0.203841233253479, "compression_ratio": 1.4820512820512821, "no_speech_prob": 0.0022517244797199965}, {"id": 52, "seek": 41280, "start": 413.8, "end": 420.56, "text": " knowing what you have to do, reading about how it's done, and then actually getting there. And this", "tokens": [50414, 5276, 437, 291, 362, 281, 360, 11, 3760, 466, 577, 309, 311, 1096, 11, 293, 550, 767, 1242, 456, 13, 400, 341, 50752], "temperature": 0.0, "avg_logprob": -0.15259496982281023, "compression_ratio": 1.6751054852320675, "no_speech_prob": 0.04335338622331619}, {"id": 53, "seek": 41280, "start": 420.56, "end": 427.56, "text": " is the sort of answer I had to find my way through in order to learn what we were doing. And there's", "tokens": [50752, 307, 264, 1333, 295, 1867, 286, 632, 281, 915, 452, 636, 807, 294, 1668, 281, 1466, 437, 321, 645, 884, 13, 400, 456, 311, 51102], "temperature": 0.0, "avg_logprob": -0.15259496982281023, "compression_ratio": 1.6751054852320675, "no_speech_prob": 0.04335338622331619}, {"id": 54, "seek": 41280, "start": 427.56, "end": 434.84000000000003, "text": " plenty and how to say this, there is no Royal Road, meaning to say, no one will tell you how to do", "tokens": [51102, 7140, 293, 577, 281, 584, 341, 11, 456, 307, 572, 12717, 11507, 11, 3620, 281, 584, 11, 572, 472, 486, 980, 291, 577, 281, 360, 51466], "temperature": 0.0, "avg_logprob": -0.15259496982281023, "compression_ratio": 1.6751054852320675, "no_speech_prob": 0.04335338622331619}, {"id": 55, "seek": 41280, "start": 434.84000000000003, "end": 441.76, "text": " this. All you can do is pick up the pieces and plow through it. I recommend as a life proposition", "tokens": [51466, 341, 13, 1057, 291, 393, 360, 307, 1888, 493, 264, 3755, 293, 499, 305, 807, 309, 13, 286, 2748, 382, 257, 993, 24830, 51812], "temperature": 0.0, "avg_logprob": -0.15259496982281023, "compression_ratio": 1.6751054852320675, "no_speech_prob": 0.04335338622331619}, {"id": 56, "seek": 44176, "start": 442.12, "end": 448.36, "text": " that you begin every problem by knowing the complete domain, the problem domain perfectly, and the", "tokens": [50382, 300, 291, 1841, 633, 1154, 538, 5276, 264, 3566, 9274, 11, 264, 1154, 9274, 6239, 11, 293, 264, 50694], "temperature": 0.0, "avg_logprob": -0.12998629140329884, "compression_ratio": 1.5877551020408163, "no_speech_prob": 0.0012060283916071057}, {"id": 57, "seek": 44176, "start": 448.36, "end": 454.28, "text": " tools you're going to need perfectly. That I think you can guarantee will lead to success. In my case,", "tokens": [50694, 3873, 291, 434, 516, 281, 643, 6239, 13, 663, 286, 519, 291, 393, 10815, 486, 1477, 281, 2245, 13, 682, 452, 1389, 11, 50990], "temperature": 0.0, "avg_logprob": -0.12998629140329884, "compression_ratio": 1.5877551020408163, "no_speech_prob": 0.0012060283916071057}, {"id": 58, "seek": 44176, "start": 454.28, "end": 459.24, "text": " I substituted what most programmers have, which is 90% of programmers think that they're above", "tokens": [50990, 286, 26441, 4866, 437, 881, 41504, 362, 11, 597, 307, 4289, 4, 295, 41504, 519, 300, 436, 434, 3673, 51238], "temperature": 0.0, "avg_logprob": -0.12998629140329884, "compression_ratio": 1.5877551020408163, "no_speech_prob": 0.0012060283916071057}, {"id": 59, "seek": 44176, "start": 459.24, "end": 469.56, "text": " average. So why not just do that? There is a relatively small number of people in the in the", "tokens": [51238, 4274, 13, 407, 983, 406, 445, 360, 300, 30, 821, 307, 257, 7226, 1359, 1230, 295, 561, 294, 264, 294, 264, 51754], "temperature": 0.0, "avg_logprob": -0.12998629140329884, "compression_ratio": 1.5877551020408163, "no_speech_prob": 0.0012060283916071057}, {"id": 60, "seek": 46956, "start": 469.8, "end": 478.2, "text": " Bison world. It's not a it was not has not been easy, I don't think as a person using that project to", "tokens": [50376, 363, 2770, 1002, 13, 467, 311, 406, 257, 309, 390, 406, 575, 406, 668, 1858, 11, 286, 500, 380, 519, 382, 257, 954, 1228, 300, 1716, 281, 50796], "temperature": 0.0, "avg_logprob": -0.15717508652630974, "compression_ratio": 1.5276381909547738, "no_speech_prob": 0.003592302557080984}, {"id": 61, "seek": 46956, "start": 478.2, "end": 487.24, "text": " find people who can help me understand how to solve the problems I'm having. So that that's just a", "tokens": [50796, 915, 561, 567, 393, 854, 385, 1223, 577, 281, 5039, 264, 2740, 286, 478, 1419, 13, 407, 300, 300, 311, 445, 257, 51248], "temperature": 0.0, "avg_logprob": -0.15717508652630974, "compression_ratio": 1.5276381909547738, "no_speech_prob": 0.003592302557080984}, {"id": 62, "seek": 46956, "start": 487.28, "end": 496.04, "text": " qualifier for like what's life like in the in the world of a guy who's writing a parser. Also, I had to", "tokens": [51250, 4101, 9902, 337, 411, 437, 311, 993, 411, 294, 264, 294, 264, 1002, 295, 257, 2146, 567, 311, 3579, 257, 21156, 260, 13, 2743, 11, 286, 632, 281, 51688], "temperature": 0.0, "avg_logprob": -0.15717508652630974, "compression_ratio": 1.5276381909547738, "no_speech_prob": 0.003592302557080984}, {"id": 63, "seek": 49604, "start": 496.12, "end": 504.44, "text": " learn that the Bison and Flex, the Lexar and the parser. It's really an odd thing in our world where", "tokens": [50368, 1466, 300, 264, 363, 2770, 293, 29208, 11, 264, 24086, 289, 293, 264, 21156, 260, 13, 467, 311, 534, 364, 7401, 551, 294, 527, 1002, 689, 50784], "temperature": 0.0, "avg_logprob": -0.16966318155263926, "compression_ratio": 1.5226130653266332, "no_speech_prob": 0.007005415856838226}, {"id": 64, "seek": 49604, "start": 504.44, "end": 514.4, "text": " you've got two projects that I don't know to what degree they talk to each other. They communicate and", "tokens": [50784, 291, 600, 658, 732, 4455, 300, 286, 500, 380, 458, 281, 437, 4314, 436, 751, 281, 1184, 661, 13, 814, 7890, 293, 51282], "temperature": 0.0, "avg_logprob": -0.16966318155263926, "compression_ratio": 1.5226130653266332, "no_speech_prob": 0.007005415856838226}, {"id": 65, "seek": 49604, "start": 514.4, "end": 521.0, "text": " cooperate. It's not evident from what I've seen that there's very much communication like that. And", "tokens": [51282, 26667, 13, 467, 311, 406, 16371, 490, 437, 286, 600, 1612, 300, 456, 311, 588, 709, 6101, 411, 300, 13, 400, 51612], "temperature": 0.0, "avg_logprob": -0.16966318155263926, "compression_ratio": 1.5226130653266332, "no_speech_prob": 0.007005415856838226}, {"id": 66, "seek": 52100, "start": 521.68, "end": 530.88, "text": " but they share global variables. They share functions. They talk about each other a little bit. But they", "tokens": [50398, 457, 436, 2073, 4338, 9102, 13, 814, 2073, 6828, 13, 814, 751, 466, 1184, 661, 257, 707, 857, 13, 583, 436, 50858], "temperature": 0.0, "avg_logprob": -0.15189830462137857, "compression_ratio": 1.61139896373057, "no_speech_prob": 0.0016740449937060475}, {"id": 67, "seek": 52100, "start": 530.88, "end": 537.08, "text": " don't say the same things. So that was a that's a stumbling block that I have no idea how to solve. But I", "tokens": [50858, 500, 380, 584, 264, 912, 721, 13, 407, 300, 390, 257, 300, 311, 257, 342, 14188, 3461, 300, 286, 362, 572, 1558, 577, 281, 5039, 13, 583, 286, 51168], "temperature": 0.0, "avg_logprob": -0.15189830462137857, "compression_ratio": 1.61139896373057, "no_speech_prob": 0.0016740449937060475}, {"id": 68, "seek": 52100, "start": 537.08, "end": 548.72, "text": " think it's a it's a gap in in the world that we work in. When you are writing your parser, there are", "tokens": [51168, 519, 309, 311, 257, 309, 311, 257, 7417, 294, 294, 264, 1002, 300, 321, 589, 294, 13, 1133, 291, 366, 3579, 428, 21156, 260, 11, 456, 366, 51750], "temperature": 0.0, "avg_logprob": -0.15189830462137857, "compression_ratio": 1.61139896373057, "no_speech_prob": 0.0016740449937060475}, {"id": 69, "seek": 54872, "start": 548.84, "end": 559.8000000000001, "text": " two levels you're working in or maybe more. You are defining the metadata for your for your language in C.", "tokens": [50370, 732, 4358, 291, 434, 1364, 294, 420, 1310, 544, 13, 509, 366, 17827, 264, 26603, 337, 428, 337, 428, 2856, 294, 383, 13, 50918], "temperature": 0.0, "avg_logprob": -0.178046809302436, "compression_ratio": 1.395973154362416, "no_speech_prob": 0.0044661108404397964}, {"id": 70, "seek": 54872, "start": 559.9200000000001, "end": 572.72, "text": " And then you're using C to tell Bob Dubner to generate the code for that stuff, please. So it was not", "tokens": [50924, 400, 550, 291, 434, 1228, 383, 281, 980, 6085, 16488, 1193, 281, 8460, 264, 3089, 337, 300, 1507, 11, 1767, 13, 407, 309, 390, 406, 51564], "temperature": 0.0, "avg_logprob": -0.178046809302436, "compression_ratio": 1.395973154362416, "no_speech_prob": 0.0044661108404397964}, {"id": 71, "seek": 57272, "start": 572.84, "end": 580.36, "text": " clear when I began. And it's still a little bit fuzzy for me where those definitions have to lie and why it's", "tokens": [50370, 1850, 562, 286, 4283, 13, 400, 309, 311, 920, 257, 707, 857, 34710, 337, 385, 689, 729, 21988, 362, 281, 4544, 293, 983, 309, 311, 50746], "temperature": 0.0, "avg_logprob": -0.16710759431887895, "compression_ratio": 1.5497630331753554, "no_speech_prob": 0.0209483802318573}, {"id": 72, "seek": 57272, "start": 581.1600000000001, "end": 590.0, "text": " sometimes difficult to understand why Bison doesn't understand what we're talking about. But I have found", "tokens": [50786, 2171, 2252, 281, 1223, 983, 363, 2770, 1177, 380, 1223, 437, 321, 434, 1417, 466, 13, 583, 286, 362, 1352, 51228], "temperature": 0.0, "avg_logprob": -0.16710759431887895, "compression_ratio": 1.5497630331753554, "no_speech_prob": 0.0209483802318573}, {"id": 73, "seek": 57272, "start": 590.0400000000001, "end": 598.64, "text": " that we were able to solve almost all the problems in in the Kobo grammar, just using good old precedence, that", "tokens": [51230, 300, 321, 645, 1075, 281, 5039, 1920, 439, 264, 2740, 294, 294, 264, 46353, 78, 22317, 11, 445, 1228, 665, 1331, 16969, 655, 11, 300, 51660], "temperature": 0.0, "avg_logprob": -0.16710759431887895, "compression_ratio": 1.5497630331753554, "no_speech_prob": 0.0209483802318573}, {"id": 74, "seek": 59864, "start": 598.68, "end": 605.36, "text": " is to say, you're always defining one thing in terms of another. If you are, you know, you could it's a little bit", "tokens": [50366, 307, 281, 584, 11, 291, 434, 1009, 17827, 472, 551, 294, 2115, 295, 1071, 13, 759, 291, 366, 11, 291, 458, 11, 291, 727, 309, 311, 257, 707, 857, 50700], "temperature": 0.0, "avg_logprob": -0.16444867051492526, "compression_ratio": 1.6826568265682658, "no_speech_prob": 0.039029233157634735}, {"id": 75, "seek": 59864, "start": 605.36, "end": 612.92, "text": " like a make file, right? It's work your way up to the left. And then what do I spend my do my day, my day I spend", "tokens": [50700, 411, 257, 652, 3991, 11, 558, 30, 467, 311, 589, 428, 636, 493, 281, 264, 1411, 13, 400, 550, 437, 360, 286, 3496, 452, 360, 452, 786, 11, 452, 786, 286, 3496, 51078], "temperature": 0.0, "avg_logprob": -0.16444867051492526, "compression_ratio": 1.6826568265682658, "no_speech_prob": 0.039029233157634735}, {"id": 76, "seek": 59864, "start": 612.92, "end": 618.24, "text": " tracing, I just looking at the results. What did the machine do? We move from state here to state there, we have", "tokens": [51078, 25262, 11, 286, 445, 1237, 412, 264, 3542, 13, 708, 630, 264, 3479, 360, 30, 492, 1286, 490, 1785, 510, 281, 1785, 456, 11, 321, 362, 51344], "temperature": 0.0, "avg_logprob": -0.16444867051492526, "compression_ratio": 1.6826568265682658, "no_speech_prob": 0.039029233157634735}, {"id": 77, "seek": 59864, "start": 618.24, "end": 627.3199999999999, "text": " this, we're looking for that. It's not there. Oh, that's the error. Okay. I also discovered that if you read these", "tokens": [51344, 341, 11, 321, 434, 1237, 337, 300, 13, 467, 311, 406, 456, 13, 876, 11, 300, 311, 264, 6713, 13, 1033, 13, 286, 611, 6941, 300, 498, 291, 1401, 613, 51798], "temperature": 0.0, "avg_logprob": -0.16444867051492526, "compression_ratio": 1.6826568265682658, "no_speech_prob": 0.039029233157634735}, {"id": 78, "seek": 62732, "start": 627.36, "end": 632.8000000000001, "text": " books at the beginning, they say, Oh, well, we have identifiers, how do we change how we know how do we distinguish a", "tokens": [50366, 3642, 412, 264, 2863, 11, 436, 584, 11, 876, 11, 731, 11, 321, 362, 2473, 23463, 11, 577, 360, 321, 1319, 577, 321, 458, 577, 360, 321, 20206, 257, 50638], "temperature": 0.0, "avg_logprob": -0.17061920166015626, "compression_ratio": 1.7709923664122138, "no_speech_prob": 0.004330278839915991}, {"id": 79, "seek": 62732, "start": 632.96, "end": 640.44, "text": " function name from a variable name? Well, in my case, the function names are all defined. They're all statements,", "tokens": [50646, 2445, 1315, 490, 257, 7006, 1315, 30, 1042, 11, 294, 452, 1389, 11, 264, 2445, 5288, 366, 439, 7642, 13, 814, 434, 439, 12363, 11, 51020], "temperature": 0.0, "avg_logprob": -0.17061920166015626, "compression_ratio": 1.7709923664122138, "no_speech_prob": 0.004330278839915991}, {"id": 80, "seek": 62732, "start": 640.44, "end": 651.48, "text": " it's call, it's, it's read, it's, it's inspect. So I don't have that I know the names. And I know all my variable", "tokens": [51020, 309, 311, 818, 11, 309, 311, 11, 309, 311, 1401, 11, 309, 311, 11, 309, 311, 15018, 13, 407, 286, 500, 380, 362, 300, 286, 458, 264, 5288, 13, 400, 286, 458, 439, 452, 7006, 51572], "temperature": 0.0, "avg_logprob": -0.17061920166015626, "compression_ratio": 1.7709923664122138, "no_speech_prob": 0.004330278839915991}, {"id": 81, "seek": 62732, "start": 651.48, "end": 656.32, "text": " names, because Kobal has four sections and one of them is the data section of us where you put your variable names. So", "tokens": [51572, 5288, 11, 570, 46353, 304, 575, 1451, 10863, 293, 472, 295, 552, 307, 264, 1412, 3541, 295, 505, 689, 291, 829, 428, 7006, 5288, 13, 407, 51814], "temperature": 0.0, "avg_logprob": -0.17061920166015626, "compression_ratio": 1.7709923664122138, "no_speech_prob": 0.004330278839915991}, {"id": 82, "seek": 65632, "start": 656.5600000000001, "end": 663.48, "text": " those are all. So I didn't have the problem of here's a string, I'll pass that off to the parser and let him figure", "tokens": [50376, 729, 366, 439, 13, 407, 286, 994, 380, 362, 264, 1154, 295, 510, 311, 257, 6798, 11, 286, 603, 1320, 300, 766, 281, 264, 21156, 260, 293, 718, 796, 2573, 50722], "temperature": 0.0, "avg_logprob": -0.1155337883254229, "compression_ratio": 1.641304347826087, "no_speech_prob": 0.0008829908911138773}, {"id": 83, "seek": 65632, "start": 663.48, "end": 669.84, "text": " out like I could support them out and have different kinds of tokens for different individual pieces. And that's", "tokens": [50722, 484, 411, 286, 727, 1406, 552, 484, 293, 362, 819, 3685, 295, 22667, 337, 819, 2609, 3755, 13, 400, 300, 311, 51040], "temperature": 0.0, "avg_logprob": -0.1155337883254229, "compression_ratio": 1.641304347826087, "no_speech_prob": 0.0008829908911138773}, {"id": 84, "seek": 65632, "start": 669.84, "end": 674.88, "text": " this magic in that that's what you want to do. The more types you got, the less you're going to have to worry.", "tokens": [51040, 341, 5585, 294, 300, 300, 311, 437, 291, 528, 281, 360, 13, 440, 544, 3467, 291, 658, 11, 264, 1570, 291, 434, 516, 281, 362, 281, 3292, 13, 51292], "temperature": 0.0, "avg_logprob": -0.1155337883254229, "compression_ratio": 1.641304347826087, "no_speech_prob": 0.0008829908911138773}, {"id": 85, "seek": 65632, "start": 677.0400000000001, "end": 685.8000000000001, "text": " Bison itself is a complex beast. It's not clear to me who's at the helm. There are a lot of pieces being added in", "tokens": [51400, 363, 2770, 2564, 307, 257, 3997, 13464, 13, 467, 311, 406, 1850, 281, 385, 567, 311, 412, 264, 29554, 13, 821, 366, 257, 688, 295, 3755, 885, 3869, 294, 51838], "temperature": 0.0, "avg_logprob": -0.1155337883254229, "compression_ratio": 1.641304347826087, "no_speech_prob": 0.0008829908911138773}, {"id": 86, "seek": 68580, "start": 685.8, "end": 695.92, "text": " different ways to do different things. And they all look very interesting. I just don't know which ones I want. I", "tokens": [50364, 819, 2098, 281, 360, 819, 721, 13, 400, 436, 439, 574, 588, 1880, 13, 286, 445, 500, 380, 458, 597, 2306, 286, 528, 13, 286, 50870], "temperature": 0.0, "avg_logprob": -0.10778333948946547, "compression_ratio": 1.650943396226415, "no_speech_prob": 0.0005883026169613004}, {"id": 87, "seek": 68580, "start": 695.92, "end": 704.9599999999999, "text": " learned that there were some things that were quite useful. And, and then not. So if you have an optional term in the", "tokens": [50870, 3264, 300, 456, 645, 512, 721, 300, 645, 1596, 4420, 13, 400, 11, 293, 550, 406, 13, 407, 498, 291, 362, 364, 17312, 1433, 294, 264, 51322], "temperature": 0.0, "avg_logprob": -0.10778333948946547, "compression_ratio": 1.650943396226415, "no_speech_prob": 0.0005883026169613004}, {"id": 88, "seek": 68580, "start": 704.9599999999999, "end": 711.56, "text": " grammar, and you, and that thing, you know, obviously can be substituted for the thing that could be there, then, then", "tokens": [51322, 22317, 11, 293, 291, 11, 293, 300, 551, 11, 291, 458, 11, 2745, 393, 312, 26441, 4866, 337, 264, 551, 300, 727, 312, 456, 11, 550, 11, 550, 51652], "temperature": 0.0, "avg_logprob": -0.10778333948946547, "compression_ratio": 1.650943396226415, "no_speech_prob": 0.0005883026169613004}, {"id": 89, "seek": 71156, "start": 711.56, "end": 718.3599999999999, "text": " you can use the precedent thing to to convert the empty version of it to the same presidents as the thing that is", "tokens": [50364, 291, 393, 764, 264, 37388, 551, 281, 281, 7620, 264, 6707, 3037, 295, 309, 281, 264, 912, 27611, 382, 264, 551, 300, 307, 50704], "temperature": 0.0, "avg_logprob": -0.17515734444677303, "compression_ratio": 1.6838235294117647, "no_speech_prob": 0.0032721571624279022}, {"id": 90, "seek": 71156, "start": 718.9599999999999, "end": 726.04, "text": " that would be there if it was present. That worked great. If you have a conflict and you simply say, Oh, well, that", "tokens": [50734, 300, 576, 312, 456, 498, 309, 390, 1974, 13, 663, 2732, 869, 13, 759, 291, 362, 257, 6596, 293, 291, 2935, 584, 11, 876, 11, 731, 11, 300, 51088], "temperature": 0.0, "avg_logprob": -0.17515734444677303, "compression_ratio": 1.6838235294117647, "no_speech_prob": 0.0032721571624279022}, {"id": 91, "seek": 71156, "start": 726.04, "end": 730.76, "text": " rule needs higher presidents than the other one. Very often that won't work. Somebody in this room might be able to tell", "tokens": [51088, 4978, 2203, 2946, 27611, 813, 264, 661, 472, 13, 4372, 2049, 300, 1582, 380, 589, 13, 13463, 294, 341, 1808, 1062, 312, 1075, 281, 980, 51324], "temperature": 0.0, "avg_logprob": -0.17515734444677303, "compression_ratio": 1.6838235294117647, "no_speech_prob": 0.0032721571624279022}, {"id": 92, "seek": 71156, "start": 730.76, "end": 738.06, "text": " me why. But I that has has been a dead end more than once. There were a lot of work went into Bison counter", "tokens": [51324, 385, 983, 13, 583, 286, 300, 575, 575, 668, 257, 3116, 917, 544, 813, 1564, 13, 821, 645, 257, 688, 295, 589, 1437, 666, 363, 2770, 5682, 51689], "temperature": 0.0, "avg_logprob": -0.17515734444677303, "compression_ratio": 1.6838235294117647, "no_speech_prob": 0.0032721571624279022}, {"id": 93, "seek": 73806, "start": 738.06, "end": 748.18, "text": " examples. It's something that I think someone spent a lot of time on. I myself have tried that feature several times hoping for a", "tokens": [50364, 5110, 13, 467, 311, 746, 300, 286, 519, 1580, 4418, 257, 688, 295, 565, 322, 13, 286, 2059, 362, 3031, 300, 4111, 2940, 1413, 7159, 337, 257, 50870], "temperature": 0.0, "avg_logprob": -0.13727208469690902, "compression_ratio": 1.645021645021645, "no_speech_prob": 0.0060940273106098175}, {"id": 94, "seek": 73806, "start": 748.18, "end": 757.8599999999999, "text": " magic solution, because I use those need those frequently. But eventually I've come to find that, at least for myself, it", "tokens": [50870, 5585, 3827, 11, 570, 286, 764, 729, 643, 729, 10374, 13, 583, 4728, 286, 600, 808, 281, 915, 300, 11, 412, 1935, 337, 2059, 11, 309, 51354], "temperature": 0.0, "avg_logprob": -0.13727208469690902, "compression_ratio": 1.645021645021645, "no_speech_prob": 0.0060940273106098175}, {"id": 95, "seek": 73806, "start": 757.8599999999999, "end": 765.38, "text": " doesn't help me that much. It's it you all it does is produce for you the path that you can actually trace through yourself back", "tokens": [51354, 1177, 380, 854, 385, 300, 709, 13, 467, 311, 309, 291, 439, 309, 775, 307, 5258, 337, 291, 264, 3100, 300, 291, 393, 767, 13508, 807, 1803, 646, 51730], "temperature": 0.0, "avg_logprob": -0.13727208469690902, "compression_ratio": 1.645021645021645, "no_speech_prob": 0.0060940273106098175}, {"id": 96, "seek": 76538, "start": 765.42, "end": 773.02, "text": " through the report. If you look at the state machine. So yes, it could be resolved different ways. Sometimes it helps me to think,", "tokens": [50366, 807, 264, 2275, 13, 759, 291, 574, 412, 264, 1785, 3479, 13, 407, 2086, 11, 309, 727, 312, 20772, 819, 2098, 13, 4803, 309, 3665, 385, 281, 519, 11, 50746], "temperature": 0.0, "avg_logprob": -0.17968221271739288, "compression_ratio": 1.4406779661016949, "no_speech_prob": 0.020951448008418083}, {"id": 97, "seek": 76538, "start": 773.5, "end": 781.26, "text": " doesn't matter. It's okay, we can take this shift. We don't have to worry about the reduce. I did try to run the graph on my", "tokens": [50770, 1177, 380, 1871, 13, 467, 311, 1392, 11, 321, 393, 747, 341, 5513, 13, 492, 500, 380, 362, 281, 3292, 466, 264, 5407, 13, 286, 630, 853, 281, 1190, 264, 4295, 322, 452, 51158], "temperature": 0.0, "avg_logprob": -0.17968221271739288, "compression_ratio": 1.4406779661016949, "no_speech_prob": 0.020951448008418083}, {"id": 98, "seek": 78126, "start": 781.26, "end": 795.66, "text": " grammar. I never saw it never came back. It did. I gave it 24 hours, but I never got an answer. So I'm not sure why that", "tokens": [50364, 22317, 13, 286, 1128, 1866, 309, 1128, 1361, 646, 13, 467, 630, 13, 286, 2729, 309, 4022, 2496, 11, 457, 286, 1128, 658, 364, 1867, 13, 407, 286, 478, 406, 988, 983, 300, 51084], "temperature": 0.0, "avg_logprob": -0.22327514316724695, "compression_ratio": 1.5029239766081872, "no_speech_prob": 0.13469277322292328}, {"id": 99, "seek": 78126, "start": 795.66, "end": 807.98, "text": " features there. I guess as a tutorial thing, if you had a seven line grammar and you want to understand how things operate. But I had to", "tokens": [51084, 4122, 456, 13, 286, 2041, 382, 257, 7073, 551, 11, 498, 291, 632, 257, 3407, 1622, 22317, 293, 291, 528, 281, 1223, 577, 721, 9651, 13, 583, 286, 632, 281, 51700], "temperature": 0.0, "avg_logprob": -0.22327514316724695, "compression_ratio": 1.5029239766081872, "no_speech_prob": 0.13469277322292328}, {"id": 100, "seek": 80798, "start": 807.98, "end": 815.3000000000001, "text": " went my way through all of the different things that it could do this feature set that I was talking about is and I don't know the answer.", "tokens": [50364, 1437, 452, 636, 807, 439, 295, 264, 819, 721, 300, 309, 727, 360, 341, 4111, 992, 300, 286, 390, 1417, 466, 307, 293, 286, 500, 380, 458, 264, 1867, 13, 50730], "temperature": 0.0, "avg_logprob": -0.2055423844535396, "compression_ratio": 1.64453125, "no_speech_prob": 0.008059958927333355}, {"id": 101, "seek": 80798, "start": 815.34, "end": 821.02, "text": " Why I only know the answer I found. And I think that's true when you're in a complex environment, you just pick the pieces that work for you.", "tokens": [50732, 1545, 286, 787, 458, 264, 1867, 286, 1352, 13, 400, 286, 519, 300, 311, 2074, 562, 291, 434, 294, 257, 3997, 2823, 11, 291, 445, 1888, 264, 3755, 300, 589, 337, 291, 13, 51016], "temperature": 0.0, "avg_logprob": -0.2055423844535396, "compression_ratio": 1.64453125, "no_speech_prob": 0.008059958927333355}, {"id": 102, "seek": 80798, "start": 821.02, "end": 829.66, "text": " And that's how you land there. So Tim toad, you will remember that from Pearl, there's more than one way to do it. There you can put options", "tokens": [51016, 400, 300, 311, 577, 291, 2117, 456, 13, 407, 7172, 281, 345, 11, 291, 486, 1604, 300, 490, 24639, 11, 456, 311, 544, 813, 472, 636, 281, 360, 309, 13, 821, 291, 393, 829, 3956, 51448], "temperature": 0.0, "avg_logprob": -0.2055423844535396, "compression_ratio": 1.64453125, "no_speech_prob": 0.008059958927333355}, {"id": 103, "seek": 82966, "start": 829.66, "end": 839.74, "text": " into the grammar itself or you can put options on the command line. I chose the to think that you could probably run the same source file with", "tokens": [50364, 666, 264, 22317, 2564, 420, 291, 393, 829, 3956, 322, 264, 5622, 1622, 13, 286, 5111, 264, 281, 519, 300, 291, 727, 1391, 1190, 264, 912, 4009, 3991, 365, 50868], "temperature": 0.0, "avg_logprob": -0.1747148864123286, "compression_ratio": 1.7927927927927927, "no_speech_prob": 0.5501494407653809}, {"id": 104, "seek": 82966, "start": 839.74, "end": 846.54, "text": " different options. So why put them in the source file put them on the command line so you can choose it. That's that's the route I went down. But", "tokens": [50868, 819, 3956, 13, 407, 983, 829, 552, 294, 264, 4009, 3991, 829, 552, 322, 264, 5622, 1622, 370, 291, 393, 2826, 309, 13, 663, 311, 300, 311, 264, 7955, 286, 1437, 760, 13, 583, 51208], "temperature": 0.0, "avg_logprob": -0.1747148864123286, "compression_ratio": 1.7927927927927927, "no_speech_prob": 0.5501494407653809}, {"id": 105, "seek": 82966, "start": 846.54, "end": 853.66, "text": " there are pure parsers, you can push them, you can use the gc++ interfaces, you've got the general something.", "tokens": [51208, 456, 366, 6075, 21156, 433, 11, 291, 393, 2944, 552, 11, 291, 393, 764, 264, 290, 66, 25472, 28416, 11, 291, 600, 658, 264, 2674, 746, 13, 51564], "temperature": 0.0, "avg_logprob": -0.1747148864123286, "compression_ratio": 1.7927927927927927, "no_speech_prob": 0.5501494407653809}, {"id": 106, "seek": 85366, "start": 854.06, "end": 866.86, "text": " Parcer, you've got different versions of parsers that can be produced from the same text file. And you have YAC emulation. And so I had to like, decide what not to use.", "tokens": [50384, 3457, 1776, 11, 291, 600, 658, 819, 9606, 295, 21156, 433, 300, 393, 312, 7126, 490, 264, 912, 2487, 3991, 13, 400, 291, 362, 398, 4378, 846, 2776, 13, 400, 370, 286, 632, 281, 411, 11, 4536, 437, 406, 281, 764, 13, 51024], "temperature": 0.0, "avg_logprob": -0.2818866159724093, "compression_ratio": 1.528888888888889, "no_speech_prob": 0.01001109927892685}, {"id": 107, "seek": 85366, "start": 866.86, "end": 877.5, "text": " And I think what we want to do is fairly vanilla. There is a really cool feature though of the way they've separated out the pieces of C code that have to go into the grammar.", "tokens": [51024, 400, 286, 519, 437, 321, 528, 281, 360, 307, 6457, 17528, 13, 821, 307, 257, 534, 1627, 4111, 1673, 295, 264, 636, 436, 600, 12005, 484, 264, 3755, 295, 383, 3089, 300, 362, 281, 352, 666, 264, 22317, 13, 51556], "temperature": 0.0, "avg_logprob": -0.2818866159724093, "compression_ratio": 1.528888888888889, "no_speech_prob": 0.01001109927892685}, {"id": 108, "seek": 87750, "start": 878.46, "end": 895.5, "text": " And they don't do a great job if you ask me of describing how that works. But these these things of separating out what the early part of the the metaflight metadata needs in order to describe the data as versus the way we're going to generate the code.", "tokens": [50412, 400, 436, 500, 380, 360, 257, 869, 1691, 498, 291, 1029, 385, 295, 16141, 577, 300, 1985, 13, 583, 613, 613, 721, 295, 29279, 484, 437, 264, 2440, 644, 295, 264, 264, 1131, 2792, 2764, 26603, 2203, 294, 1668, 281, 6786, 264, 1412, 382, 5717, 264, 636, 321, 434, 516, 281, 8460, 264, 3089, 13, 51264], "temperature": 0.0, "avg_logprob": -0.2840572939080707, "compression_ratio": 1.5617283950617284, "no_speech_prob": 0.004537151660770178}, {"id": 109, "seek": 89550, "start": 896.46, "end": 921.5, "text": " That requires and provides is very, very useful. And locations, you can't write a debugger if you don't have locations. So I would recommend if perhaps I'll send this to the bison folks that you you separate out your code that's going to the pieces that you need into different files and use those", "tokens": [50412, 663, 7029, 293, 6417, 307, 588, 11, 588, 4420, 13, 400, 9253, 11, 291, 393, 380, 2464, 257, 24083, 1321, 498, 291, 500, 380, 362, 9253, 13, 407, 286, 576, 2748, 498, 4317, 286, 603, 2845, 341, 281, 264, 272, 2770, 4024, 300, 291, 291, 4994, 484, 428, 3089, 300, 311, 516, 281, 264, 3755, 300, 291, 643, 666, 819, 7098, 293, 764, 729, 51664], "temperature": 0.0, "avg_logprob": -0.24118732003604665, "compression_ratio": 1.5309278350515463, "no_speech_prob": 0.2656421959400177}, {"id": 110, "seek": 92150, "start": 922.46, "end": 936.46, "text": " brackets to to to tell by some what the way they belong. It's really handy actually if you got enough C code in your in your YAC file to put it in some include somewhere because your editor will make you a lot happier.", "tokens": [50412, 26179, 281, 281, 281, 980, 538, 512, 437, 264, 636, 436, 5784, 13, 467, 311, 534, 13239, 767, 498, 291, 658, 1547, 383, 3089, 294, 428, 294, 428, 398, 4378, 3991, 281, 829, 309, 294, 512, 4090, 4079, 570, 428, 9839, 486, 652, 291, 257, 688, 20423, 13, 51112], "temperature": 0.0, "avg_logprob": -0.24285028531001165, "compression_ratio": 1.4437086092715232, "no_speech_prob": 0.028860025107860565}, {"id": 111, "seek": 93646, "start": 936.46, "end": 964.46, "text": " If you use these two, if you use a if you've got a printer type for every element, every semantic type in your union, then you get nice outputs like this. And there ought to be a rule that says, or there'll even ought to be a warning that says, Hey, you define a type where's the string for it? How come I can't see what this looks like? You're going to want it. And that's what you see here is a reduction for the varying part of the perform a part of the", "tokens": [50412, 759, 291, 764, 613, 732, 11, 498, 291, 764, 257, 498, 291, 600, 658, 257, 16671, 2010, 337, 633, 4478, 11, 633, 47982, 2010, 294, 428, 11671, 11, 550, 291, 483, 1481, 23930, 411, 341, 13, 400, 456, 13416, 281, 312, 257, 4978, 300, 1619, 11, 420, 456, 603, 754, 13416, 281, 312, 257, 9164, 300, 1619, 11, 1911, 11, 291, 6964, 257, 2010, 689, 311, 264, 6798, 337, 309, 30, 1012, 808, 286, 393, 380, 536, 437, 341, 1542, 411, 30, 509, 434, 516, 281, 528, 309, 13, 400, 300, 311, 437, 291, 536, 510, 307, 257, 11004, 337, 264, 22984, 644, 295, 264, 2042, 257, 644, 295, 264, 51764], "temperature": 0.0, "avg_logprob": -0.2603675369667796, "compression_ratio": 1.7882352941176471, "no_speech_prob": 0.06093994900584221}, {"id": 112, "seek": 96646, "start": 966.46, "end": 996.4200000000001, "text": " one of the four types of loops. And we know we know that we've got some keywords we've got varying we have from we have we were it's coming from a numeric display that's a bunch of digits in a row that we can use like a number. And and it's got a name. And this was tricky because names don't usually have hyphens in them when you get to the assembler. And there's a literal so that that was a that was probably a three or something. And boom, and so I'm able to look at this trace and refer right", "tokens": [50364, 472, 295, 264, 1451, 3467, 295, 16121, 13, 400, 321, 458, 321, 458, 300, 321, 600, 658, 512, 21009, 321, 600, 658, 22984, 321, 362, 490, 321, 362, 321, 645, 309, 311, 1348, 490, 257, 7866, 299, 4674, 300, 311, 257, 3840, 295, 27011, 294, 257, 5386, 300, 321, 393, 764, 411, 257, 1230, 13, 400, 293, 309, 311, 658, 257, 1315, 13, 400, 341, 390, 12414, 570, 5288, 500, 380, 2673, 362, 2477, 950, 694, 294, 552, 562, 291, 483, 281, 264, 8438, 1918, 13, 400, 456, 311, 257, 20411, 370, 300, 300, 390, 257, 300, 390, 1391, 257, 1045, 420, 746, 13, 400, 9351, 11, 293, 370, 286, 478, 1075, 281, 574, 412, 341, 13508, 293, 2864, 558, 51862], "temperature": 0.0, "avg_logprob": -0.12943460107818852, "compression_ratio": 1.8007246376811594, "no_speech_prob": 0.09385964274406433}, {"id": 113, "seek": 99646, "start": 996.46, "end": 1026.46, "text": " back to the source code and see the pieces that are are being operated on. Do not open up your debugger on the outputted on the on the object file that is compiled from the seek that was generated by the bison. You just won't like it. You don't run GDB on make. You don't run GDB on on that either. It's just awful. The what you do want to know is what the rules mean. You're using a system that is", "tokens": [50364, 646, 281, 264, 4009, 3089, 293, 536, 264, 3755, 300, 366, 366, 885, 20826, 322, 13, 1144, 406, 1269, 493, 428, 24083, 1321, 322, 264, 5598, 14727, 322, 264, 322, 264, 2657, 3991, 300, 307, 36548, 490, 264, 8075, 300, 390, 10833, 538, 264, 272, 2770, 13, 509, 445, 1582, 380, 411, 309, 13, 509, 500, 380, 1190, 460, 27735, 322, 652, 13, 509, 500, 380, 1190, 460, 27735, 322, 322, 300, 2139, 13, 467, 311, 445, 11232, 13, 440, 437, 291, 360, 528, 281, 458, 307, 437, 264, 4474, 914, 13, 509, 434, 1228, 257, 1185, 300, 307], "temperature": 0.0, "avg_logprob": -0.15081650195735516, "compression_ratio": 1.7304347826086957, "no_speech_prob": 0.02755589969456196}, {"id": 114, "seek": 102646, "start": 1026.46, "end": 1055.46, "text": " declarative. So you have to think about what the rule says and how they operate. That's the way you get to to the answer. And I think I'm just about done except to ask you to help me solve my problem. What you see here is what you would like to write in a lot of languages, right? The second thing is much more easily typed as the first thing, but it easily parsed. I'm on version eight of my", "tokens": [50364, 16694, 1166, 13, 407, 291, 362, 281, 519, 466, 437, 264, 4978, 1619, 293, 577, 436, 9651, 13, 663, 311, 264, 636, 291, 483, 281, 281, 264, 1867, 13, 400, 286, 519, 286, 478, 445, 466, 1096, 3993, 281, 1029, 291, 281, 854, 385, 5039, 452, 1154, 13, 708, 291, 536, 510, 307, 437, 291, 576, 411, 281, 2464, 294, 257, 688, 295, 8650, 11, 558, 30, 440, 1150, 551, 307, 709, 544, 3612, 33941, 382, 264, 700, 551, 11, 457, 309, 3612, 21156, 292, 13, 286, 478, 322, 3037, 3180, 295, 452, 51814], "temperature": 0.0, "avg_logprob": -0.15700962617225253, "compression_ratio": 1.5934959349593496, "no_speech_prob": 0.01204601489007473}, {"id": 115, "seek": 105546, "start": 1056.46, "end": 1077.46, "text": " my test for that one because when you get to see you don't know if C belongs to be as means it's relating back to a or whether C is going to be followed by a relational operator and be just an ordinary expansion. So you hit that spot and you think what I need is L.", "tokens": [50414, 452, 1500, 337, 300, 472, 570, 562, 291, 483, 281, 536, 291, 500, 380, 458, 498, 383, 12953, 281, 312, 382, 1355, 309, 311, 23968, 646, 281, 257, 420, 1968, 383, 307, 516, 281, 312, 6263, 538, 257, 38444, 12973, 293, 312, 445, 364, 10547, 11260, 13, 407, 291, 2045, 300, 4008, 293, 291, 519, 437, 286, 643, 307, 441, 13, 51464], "temperature": 0.0, "avg_logprob": -0.24280882615309496, "compression_ratio": 1.5056818181818181, "no_speech_prob": 0.05338599532842636}, {"id": 116, "seek": 107746, "start": 1077.46, "end": 1078.46, "text": " R.", "tokens": [50364, 497, 13, 50414], "temperature": 0.0, "avg_logprob": -0.2694358392195268, "compression_ratio": 1.25, "no_speech_prob": 0.3903692066669464}, {"id": 117, "seek": 107746, "start": 1078.46, "end": 1086.46, "text": " Two, but I don't have it. So but maybe there's someone here who does know. So that's why I'm here and I'm done. Thank you very much.", "tokens": [50414, 4453, 11, 457, 286, 500, 380, 362, 309, 13, 407, 457, 1310, 456, 311, 1580, 510, 567, 775, 458, 13, 407, 300, 311, 983, 286, 478, 510, 293, 286, 478, 1096, 13, 1044, 291, 588, 709, 13, 50814], "temperature": 0.0, "avg_logprob": -0.2694358392195268, "compression_ratio": 1.25, "no_speech_prob": 0.3903692066669464}, {"id": 118, "seek": 110746, "start": 1107.46, "end": 1134.46, "text": " I'm glad you asked that question. The man asked why didn't I write a handwritten parser. And the reason is because bison has saved my bacon. The the I don't know how to do that. I do know this many times every week, not every day, but every week.", "tokens": [50364, 286, 478, 5404, 291, 2351, 300, 1168, 13, 440, 587, 2351, 983, 994, 380, 286, 2464, 257, 1011, 26859, 21156, 260, 13, 400, 264, 1778, 307, 570, 272, 2770, 575, 6624, 452, 16400, 13, 440, 264, 286, 500, 380, 458, 577, 281, 360, 300, 13, 286, 360, 458, 341, 867, 1413, 633, 1243, 11, 406, 633, 786, 11, 457, 633, 1243, 13, 51714], "temperature": 0.0, "avg_logprob": -0.18032610055172082, "compression_ratio": 1.5, "no_speech_prob": 0.13465777039527893}, {"id": 119, "seek": 113446, "start": 1134.46, "end": 1147.46, "text": " The the the bison output tells me I have an ambiguity in the grammar. I'm not that can't be parsed. It finds the mistakes that I would be putting in freely if I was writing it by hand.", "tokens": [50364, 440, 264, 264, 272, 2770, 5598, 5112, 385, 286, 362, 364, 46519, 294, 264, 22317, 13, 286, 478, 406, 300, 393, 380, 312, 21156, 292, 13, 467, 10704, 264, 8038, 300, 286, 576, 312, 3372, 294, 16433, 498, 286, 390, 3579, 309, 538, 1011, 13, 51014], "temperature": 0.0, "avg_logprob": -0.1566906278095548, "compression_ratio": 1.4417177914110428, "no_speech_prob": 0.019710326567292213}, {"id": 120, "seek": 113446, "start": 1153.46, "end": 1154.46, "text": " Any more questions?", "tokens": [51314, 2639, 544, 1651, 30, 51364], "temperature": 0.0, "avg_logprob": -0.1566906278095548, "compression_ratio": 1.4417177914110428, "no_speech_prob": 0.019710326567292213}, {"id": 121, "seek": 113446, "start": 1156.46, "end": 1159.46, "text": " Or suggestions for this issue?", "tokens": [51464, 1610, 13396, 337, 341, 2734, 30, 51614], "temperature": 0.0, "avg_logprob": -0.1566906278095548, "compression_ratio": 1.4417177914110428, "no_speech_prob": 0.019710326567292213}, {"id": 122, "seek": 115946, "start": 1159.46, "end": 1162.46, "text": " I'm I'm here all day.", "tokens": [50414, 286, 478, 286, 478, 510, 439, 786, 13, 50514], "temperature": 0.0, "avg_logprob": -0.24473034251819958, "compression_ratio": 0.7777777777777778, "no_speech_prob": 0.17481733858585358}], "language": "en"}