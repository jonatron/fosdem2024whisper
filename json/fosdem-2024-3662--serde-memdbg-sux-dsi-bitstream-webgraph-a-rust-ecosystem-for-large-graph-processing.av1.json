{"text": " Hi everybody, we're just about to have our next talk, who will be Sebastiano Vigna, who will be talking about a Rust ecosystem for large graph processing. Sebastiano? Thank you. Okay. Okay. How many Rust programmers here? Well, some. How many Rust programmers who handle large data structures, like those of gigabytes? A few. Okay. The first group is reasonably interested. The second group is more interested. The rest of the people can't sleep. I'm not offended. You can use the computer. It will be very, very boring. So okay, let me introduce why. Okay. What I'm doing is just announcing a few crates we are distributing that do very specific thing related to large-scale data analytics. And the original of this is a framework for graph compression that has been around for around 20 years. And that's being used by the community around the WWW, the web conf, the largest conference on the web in general, academic conference. For the last 20 years, there are many data sets that are distributed in this format that are utilised and so on. There are a lot of journals. And in 2011, it was used to measure the degrees of separation on Facebook, if you remember it, maybe you're too young. But it was quite a feat at that time because, I mean, it was for 15 years ago and Facebook was still rather large. But we were able at that time to represent the entire Facebook graph in just 211 gigabytes, which made it possible to run some pretty nice algorithm to compute this and distribution. Maybe in this community, I should mention that in the late, I started to do free software in the late 80s on the Amiga. Okay. So nobody remembers what it is, but I have some history with the free software movement as well. So at some point, we decided to move to Rust for the obvious reasons, like it's a high-performance, safe language. But, okay, all I said is in Java. It was written in Java, started in the 80s and of the 90s. And at that time, it seemed a very good idea. Okay. Then things happened like arrays are at most two billion elements. And if you have graphs with 50 billion elements, you cannot even index the notes, which gets very, very annoying. And today, anything this size is done using memory mapping. I mean, if you go to Facebook, Google, whatever, all the large structures are there in memory, but usually they're just memory mapped because you don't want to start up time. If you load in memory a graph that is half a terabyte, you wait minutes, whatever the platform you are on. But if you can memory map it, this time is amortized along the visit of the graph, for instance. Okay. And we actually need to represent very large graph. If you ever use Java, the access to memory mapping facility, I will not say words because they would not be proper in this particular situation. There are really lazy iterators. If you're written in Java and iterator, you know what I mean. And okay, so we, to do this, we needed to port a number of ideas from a Java library and to develop a few new things. So the first thing is absurdity, weird name. So it's a framework from epsilon copy, serialization, deserialization. So you might know what is zero copy, serialization, deserialization, means that you serialize something and then you use the memory, actually in the state it is, to represent the object internally. Okay. So there is no deserialization. You don't build a new object. The piece of memory is directly used as it is. And this is how things work, as I said, in all these organizations that have large indices, Facebook, Amazon, whatever you want. I mean, the index is on disk, it's memory mapped as it is. It's not deserialized in any proper sense. There are a few frameworks like abomination that do this kind of things in Rust, but they all have problems for us. The first one is the oldest one by Frank McSherry, writes into the serialized object. So if you want to memory map a file, that's out of question. You might know it is from the people that do the internalization library. Nice idea, but it has a huge impact on performance. It does some kind of runtime resolution of the access to vectors. And then there is Archive, you might be familiar with, which too does some relative memory that is differentiation. And also the structure you deserialize is completely different from the one you serialize. So you have to delegate all the methods and then each time you change one, you have to change the other. Not very practical. So what we did was develop this framework, which requires a little bit of collaboration from the underlying struct. But the basic idea is that you serialize something and then you epsilon copy deserialize it. So you access it, you allocate a very small amount of memory and then the rest comes directly from the disk without any intervention. And the way we do it, we remap vectors essentially. You build a structure with a vector, but when you deserialize it, it has a reference to a slice. In this way, we just have to allocate the actual struct that you want to deserialize, but then anything that is a pointer inside just point to the original memory. So epsilon copy, the idea is that it's not a zero copy because we did a little bit of copying, epsilon copy, a very small amount. But the advantage is that now you have exactly the structure that you serialize. It's exactly that structure with all its methods. The only thing you have to do, if you have vectors, there must be a type parameter and you must write the access method for as a left to a slice. Of course, when writing, you write for a vector, but when you read, you read it from a slice. This is the collaboration you need. But then, completed transparently, like you can do it with basic type. You store a vector and then you memory map it and that's it. And what you get in T is a reference to a slice. More precisely, something that derives to a slice, to a reference to a slice. And again, you work essentially transparently with respect to the framework. Unlike the other cases, and since there is nothing intervening, resolving the pointers, there is no dynamic resolution, everything is done at this realization time, zero impact on performance. The performance is exactly the one of the original structure. We use this to map massive immutable data structure like representation of sequences of sets and so on that are like those of gigabytes, 100 gigabytes on disk directly on memory, without any load time. So if you handle large immutable data structures, that could be for you. Memdology, that's a very small crate, but it's a problem we had. Okay, it's a high performance memory occupancy detector, which sounds ridiculous when you say it because, well, it does as to measure the memory occupied. It's not so easy because if you use the one that are around, so it is like a large vector and few other things, this is the amount of a located memory. These are the three more common frameworks, sorry, crates that do that, and this is the amount of time that they take, and this is the amount of time we take. So the reason is that without some infrastructure similar to the one of absurdity, you have to iterate through collections to measure the space occupied. And if you iterate through a billion element collection, it will take a lot of time. So we routinely measure the space and occupancy of things that are like 50 gigabytes, it will take eight minutes. So we develop this if you need to measure the actual occupation memory, not stack occupation, the actual occupation in memory of something large, try MDBG. Also, as a nice, it does you a print out of the structure with the old memory occupancy. It's important for us because we do all the time this succinct data structure that have various components and we need to know the relative size. So this is only if you have very large data structures. They are small, you can iterate, no problem. Succ is an ongoing problem, ongoing problem, yeah, it's an ongoing problem. I won't say an ingrate, but it's actually kind of an ongoing problem. And it's a part of an existing C++ project and Java project about succinct data structures. You might know what they are. If you don't, no problem, you don't need this crate, but they're very fashionable now. There is one crate at least that does this, but we wanted to have something more sophisticated. So if you're interested in Elias Fano representation of monotone sequences, ranking, selection, and so on, please have a look. This is really getting to existence, but we like to have feedback. Fungal piece bit streams, very, very high performance bit stream with read and write by word and support for big and little Indian files and a lot of instantaneous code, gamma, gamma, delta, go long, and so on. This is kind of cosy you'd like in MPEG or so on, but we use it to do graph compression and we spend a lot of time to optimize every single shift and move and also to give you scripts to just run and we massively test all parameters you can configure on your architecture so you can choose how to optimize the speed of the coding and the coding specifically on your architecture. Like which word size to use to pick up stuff from memory, using the coding tables or not, and so on. And this comes from quite a long experience in doing this with web graph. So if you're interested in writing this instantaneous code for compression, you should have a look at this IBS stream just to tell you a gamma code is ready in less than two thousand seconds. So I think this is pretty nice. Okay, the last piece which is probably the more specific, so you might less be interested in is web graph. So web graph is a framework to represent very large graphs in a compressed form. So typically snapshot of the web are represented in about one to two bits per link. The software heritage graph which is a graph with about half a trillion edges, it's three bits per link, Wikipedia costs 10 bits per link, it depends on the structure of the graph. But usually in particular the graph is redundant, you can represent data in 10, 20, even 50 times less than you do with a redundant version. It's a rough sport of the Java version and of course we use the SIB stream for instantaneous code and sucks for pointers in the big stream. And just to give you a very simple example, the software heritage graph is 34 billion nodes and a little bit more than half a trillion arcs and you can do a BFV visit single thread in three hours. It's very nice. Okay, you have to notice half a trillion edges. The ergonomics of the whole thing is incredibly better than Java. Just having real iterators changes completely the game because it's much more natural that what we had. And this is all the others are crates that you can download and use that are pretty stable. This is still on GitHub because it's a lot of code, a lot of optimization. We just merged into main the last big chunk of modification, the API should be stable by now. But this is very specialized. I mean unless you have graphs with hundreds of billions, half a trillion arcs, for instance, this biologist did this huge data set with a trillion protein-protein similarity edges and they did it with web graph because if you need a trillion edge and you need to distribute it and analyze it on a standard hardware, not a massive supercomputer, you do it using compression. There is also support for labels on the edges that you can enumerate and it's much better in the new version than in the old one. And one thing that we had to fight a lot against is lenders. So if you're familiar, I don't feel familiar with a lender idea. It's generally an idea and a number of crates for Rust. Lenders are iterators whose return object depends on the iterator itself. So iterators in Rust are thoughts that give you values and you can take the values and use them. But in all this kind of batch processing for graphs, you iterate on the graph and you cannot look at two nodes at the same time. There is a sequential iteration which goes through a file or a sorting of labels. So you need to be able to say, okay, this is the next batch of successor, use it, but I won't give you the next one until you finish with this one. To do this, you need to use essentially generic associated type. Not really that. We use higher order trade bounds. But you need to impose that each call to next can be made only when the previous one went out of scope. So you cannot do two calls to next in a row. And this is called a lender. There are a few crates that implement lenders now which have, say, almost feature parity with iterator, but the fact is that presently they work because of bug in the borrower checker. So the borrower checker doesn't check certain things that if fixed would make all these lender crates not work. And at that point, we would be in really deep shit because we have no idea how to do this other than the way we're doing it. In fact, we're even in a situation where we have a chain of an iterator returning iterators and the final value depend on state on the initials thing. So there is a propagation of bounds of on lifetime that goes through two different types. And that gives me headache each time I look at it. And in fact, I didn't even invent it. I asked on Rust forum and they said, I have this completely crazy situation. What can I do? And a very nice guy wrote a type like this with 25 different implied type bounds and now it works. But let's hope it continues to work. But this is just to say we need a little bit more borrowing in Rust than there is now to make this work properly because it has been a little bit of a pain to get something like an iterator in which the return value depend on the iterating object. In the last thing, if anybody know how to get one thing done, index get. Since 2015, it's been sitting in the issues of Rust to have an index trait that gives you a value, not a reference. Because index give you a reference. Now, index give you a reference is fine. But if you do compress, succinct, any kind of implicit data structure, index giving you a reference is a pain in the ass. Because you don't have the data. They are implicitly represented. You need the trait that giving two nice square brackets will give a value, not a reference. And then you can enter the world of modern implicit data structure. So if you know anybody who can implement this, convince someone in compiler team to get done with this, you please do it. I'm over. Thank you. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 16.0, "text": " Hi everybody, we're just about to have our next talk, who will be Sebastiano Vigna, who", "tokens": [50364, 2421, 2201, 11, 321, 434, 445, 466, 281, 362, 527, 958, 751, 11, 567, 486, 312, 22374, 525, 6254, 691, 328, 629, 11, 567, 51164], "temperature": 0.0, "avg_logprob": -0.3671576182047526, "compression_ratio": 1.4350649350649352, "no_speech_prob": 0.46061575412750244}, {"id": 1, "seek": 0, "start": 16.0, "end": 19.96, "text": " will be talking about a Rust ecosystem for large graph processing.", "tokens": [51164, 486, 312, 1417, 466, 257, 34952, 11311, 337, 2416, 4295, 9007, 13, 51362], "temperature": 0.0, "avg_logprob": -0.3671576182047526, "compression_ratio": 1.4350649350649352, "no_speech_prob": 0.46061575412750244}, {"id": 2, "seek": 0, "start": 19.96, "end": 20.96, "text": " Sebastiano?", "tokens": [51362, 22374, 525, 6254, 30, 51412], "temperature": 0.0, "avg_logprob": -0.3671576182047526, "compression_ratio": 1.4350649350649352, "no_speech_prob": 0.46061575412750244}, {"id": 3, "seek": 0, "start": 20.96, "end": 21.96, "text": " Thank you.", "tokens": [51412, 1044, 291, 13, 51462], "temperature": 0.0, "avg_logprob": -0.3671576182047526, "compression_ratio": 1.4350649350649352, "no_speech_prob": 0.46061575412750244}, {"id": 4, "seek": 0, "start": 21.96, "end": 22.96, "text": " Okay.", "tokens": [51462, 1033, 13, 51512], "temperature": 0.0, "avg_logprob": -0.3671576182047526, "compression_ratio": 1.4350649350649352, "no_speech_prob": 0.46061575412750244}, {"id": 5, "seek": 0, "start": 22.96, "end": 23.96, "text": " Okay.", "tokens": [51512, 1033, 13, 51562], "temperature": 0.0, "avg_logprob": -0.3671576182047526, "compression_ratio": 1.4350649350649352, "no_speech_prob": 0.46061575412750244}, {"id": 6, "seek": 0, "start": 23.96, "end": 28.12, "text": " How many Rust programmers here?", "tokens": [51562, 1012, 867, 34952, 41504, 510, 30, 51770], "temperature": 0.0, "avg_logprob": -0.3671576182047526, "compression_ratio": 1.4350649350649352, "no_speech_prob": 0.46061575412750244}, {"id": 7, "seek": 2812, "start": 28.12, "end": 29.84, "text": " Well, some.", "tokens": [50364, 1042, 11, 512, 13, 50450], "temperature": 0.0, "avg_logprob": -0.2265586709617672, "compression_ratio": 1.606164383561644, "no_speech_prob": 0.051031287759542465}, {"id": 8, "seek": 2812, "start": 29.84, "end": 34.24, "text": " How many Rust programmers who handle large data structures, like those of gigabytes?", "tokens": [50450, 1012, 867, 34952, 41504, 567, 4813, 2416, 1412, 9227, 11, 411, 729, 295, 42741, 30, 50670], "temperature": 0.0, "avg_logprob": -0.2265586709617672, "compression_ratio": 1.606164383561644, "no_speech_prob": 0.051031287759542465}, {"id": 9, "seek": 2812, "start": 34.24, "end": 35.24, "text": " A few.", "tokens": [50670, 316, 1326, 13, 50720], "temperature": 0.0, "avg_logprob": -0.2265586709617672, "compression_ratio": 1.606164383561644, "no_speech_prob": 0.051031287759542465}, {"id": 10, "seek": 2812, "start": 35.24, "end": 36.24, "text": " Okay.", "tokens": [50720, 1033, 13, 50770], "temperature": 0.0, "avg_logprob": -0.2265586709617672, "compression_ratio": 1.606164383561644, "no_speech_prob": 0.051031287759542465}, {"id": 11, "seek": 2812, "start": 36.24, "end": 38.8, "text": " The first group is reasonably interested.", "tokens": [50770, 440, 700, 1594, 307, 23551, 3102, 13, 50898], "temperature": 0.0, "avg_logprob": -0.2265586709617672, "compression_ratio": 1.606164383561644, "no_speech_prob": 0.051031287759542465}, {"id": 12, "seek": 2812, "start": 38.8, "end": 40.68, "text": " The second group is more interested.", "tokens": [50898, 440, 1150, 1594, 307, 544, 3102, 13, 50992], "temperature": 0.0, "avg_logprob": -0.2265586709617672, "compression_ratio": 1.606164383561644, "no_speech_prob": 0.051031287759542465}, {"id": 13, "seek": 2812, "start": 40.68, "end": 41.96, "text": " The rest of the people can't sleep.", "tokens": [50992, 440, 1472, 295, 264, 561, 393, 380, 2817, 13, 51056], "temperature": 0.0, "avg_logprob": -0.2265586709617672, "compression_ratio": 1.606164383561644, "no_speech_prob": 0.051031287759542465}, {"id": 14, "seek": 2812, "start": 41.96, "end": 42.96, "text": " I'm not offended.", "tokens": [51056, 286, 478, 406, 26776, 13, 51106], "temperature": 0.0, "avg_logprob": -0.2265586709617672, "compression_ratio": 1.606164383561644, "no_speech_prob": 0.051031287759542465}, {"id": 15, "seek": 2812, "start": 42.96, "end": 43.96, "text": " You can use the computer.", "tokens": [51106, 509, 393, 764, 264, 3820, 13, 51156], "temperature": 0.0, "avg_logprob": -0.2265586709617672, "compression_ratio": 1.606164383561644, "no_speech_prob": 0.051031287759542465}, {"id": 16, "seek": 2812, "start": 43.96, "end": 46.36, "text": " It will be very, very boring.", "tokens": [51156, 467, 486, 312, 588, 11, 588, 9989, 13, 51276], "temperature": 0.0, "avg_logprob": -0.2265586709617672, "compression_ratio": 1.606164383561644, "no_speech_prob": 0.051031287759542465}, {"id": 17, "seek": 2812, "start": 46.36, "end": 47.84, "text": " So okay, let me introduce why.", "tokens": [51276, 407, 1392, 11, 718, 385, 5366, 983, 13, 51350], "temperature": 0.0, "avg_logprob": -0.2265586709617672, "compression_ratio": 1.606164383561644, "no_speech_prob": 0.051031287759542465}, {"id": 18, "seek": 2812, "start": 47.84, "end": 48.84, "text": " Okay.", "tokens": [51350, 1033, 13, 51400], "temperature": 0.0, "avg_logprob": -0.2265586709617672, "compression_ratio": 1.606164383561644, "no_speech_prob": 0.051031287759542465}, {"id": 19, "seek": 2812, "start": 48.84, "end": 52.760000000000005, "text": " What I'm doing is just announcing a few crates we are distributing that do very specific", "tokens": [51400, 708, 286, 478, 884, 307, 445, 28706, 257, 1326, 941, 1024, 321, 366, 41406, 300, 360, 588, 2685, 51596], "temperature": 0.0, "avg_logprob": -0.2265586709617672, "compression_ratio": 1.606164383561644, "no_speech_prob": 0.051031287759542465}, {"id": 20, "seek": 2812, "start": 52.760000000000005, "end": 56.760000000000005, "text": " thing related to large-scale data analytics.", "tokens": [51596, 551, 4077, 281, 2416, 12, 20033, 1412, 15370, 13, 51796], "temperature": 0.0, "avg_logprob": -0.2265586709617672, "compression_ratio": 1.606164383561644, "no_speech_prob": 0.051031287759542465}, {"id": 21, "seek": 5676, "start": 56.76, "end": 61.32, "text": " And the original of this is a framework for graph compression that has been around for", "tokens": [50364, 400, 264, 3380, 295, 341, 307, 257, 8388, 337, 4295, 19355, 300, 575, 668, 926, 337, 50592], "temperature": 0.0, "avg_logprob": -0.2943663516287076, "compression_ratio": 1.703971119133574, "no_speech_prob": 0.12029251456260681}, {"id": 22, "seek": 5676, "start": 61.32, "end": 63.4, "text": " around 20 years.", "tokens": [50592, 926, 945, 924, 13, 50696], "temperature": 0.0, "avg_logprob": -0.2943663516287076, "compression_ratio": 1.703971119133574, "no_speech_prob": 0.12029251456260681}, {"id": 23, "seek": 5676, "start": 63.4, "end": 68.2, "text": " And that's being used by the community around the WWW, the web conf, the largest conference", "tokens": [50696, 400, 300, 311, 885, 1143, 538, 264, 1768, 926, 264, 12040, 54, 11, 264, 3670, 1497, 11, 264, 6443, 7586, 50936], "temperature": 0.0, "avg_logprob": -0.2943663516287076, "compression_ratio": 1.703971119133574, "no_speech_prob": 0.12029251456260681}, {"id": 24, "seek": 5676, "start": 68.2, "end": 73.88, "text": " on the web in general, academic conference.", "tokens": [50936, 322, 264, 3670, 294, 2674, 11, 7778, 7586, 13, 51220], "temperature": 0.0, "avg_logprob": -0.2943663516287076, "compression_ratio": 1.703971119133574, "no_speech_prob": 0.12029251456260681}, {"id": 25, "seek": 5676, "start": 73.88, "end": 77.72, "text": " For the last 20 years, there are many data sets that are distributed in this format that", "tokens": [51220, 1171, 264, 1036, 945, 924, 11, 456, 366, 867, 1412, 6352, 300, 366, 12631, 294, 341, 7877, 300, 51412], "temperature": 0.0, "avg_logprob": -0.2943663516287076, "compression_ratio": 1.703971119133574, "no_speech_prob": 0.12029251456260681}, {"id": 26, "seek": 5676, "start": 77.72, "end": 79.2, "text": " are utilised and so on.", "tokens": [51412, 366, 4976, 2640, 293, 370, 322, 13, 51486], "temperature": 0.0, "avg_logprob": -0.2943663516287076, "compression_ratio": 1.703971119133574, "no_speech_prob": 0.12029251456260681}, {"id": 27, "seek": 5676, "start": 79.2, "end": 81.2, "text": " There are a lot of journals.", "tokens": [51486, 821, 366, 257, 688, 295, 29621, 13, 51586], "temperature": 0.0, "avg_logprob": -0.2943663516287076, "compression_ratio": 1.703971119133574, "no_speech_prob": 0.12029251456260681}, {"id": 28, "seek": 5676, "start": 81.2, "end": 86.08, "text": " And in 2011, it was used to measure the degrees of separation on Facebook, if you remember", "tokens": [51586, 400, 294, 10154, 11, 309, 390, 1143, 281, 3481, 264, 5310, 295, 14634, 322, 4384, 11, 498, 291, 1604, 51830], "temperature": 0.0, "avg_logprob": -0.2943663516287076, "compression_ratio": 1.703971119133574, "no_speech_prob": 0.12029251456260681}, {"id": 29, "seek": 8608, "start": 86.08, "end": 87.32, "text": " it, maybe you're too young.", "tokens": [50364, 309, 11, 1310, 291, 434, 886, 2037, 13, 50426], "temperature": 0.0, "avg_logprob": -0.1944966523543648, "compression_ratio": 1.679127725856698, "no_speech_prob": 0.12361899018287659}, {"id": 30, "seek": 8608, "start": 87.32, "end": 91.52, "text": " But it was quite a feat at that time because, I mean, it was for 15 years ago and Facebook", "tokens": [50426, 583, 309, 390, 1596, 257, 15425, 412, 300, 565, 570, 11, 286, 914, 11, 309, 390, 337, 2119, 924, 2057, 293, 4384, 50636], "temperature": 0.0, "avg_logprob": -0.1944966523543648, "compression_ratio": 1.679127725856698, "no_speech_prob": 0.12361899018287659}, {"id": 31, "seek": 8608, "start": 91.52, "end": 93.32, "text": " was still rather large.", "tokens": [50636, 390, 920, 2831, 2416, 13, 50726], "temperature": 0.0, "avg_logprob": -0.1944966523543648, "compression_ratio": 1.679127725856698, "no_speech_prob": 0.12361899018287659}, {"id": 32, "seek": 8608, "start": 93.32, "end": 98.8, "text": " But we were able at that time to represent the entire Facebook graph in just 211 gigabytes,", "tokens": [50726, 583, 321, 645, 1075, 412, 300, 565, 281, 2906, 264, 2302, 4384, 4295, 294, 445, 5080, 16, 42741, 11, 51000], "temperature": 0.0, "avg_logprob": -0.1944966523543648, "compression_ratio": 1.679127725856698, "no_speech_prob": 0.12361899018287659}, {"id": 33, "seek": 8608, "start": 98.8, "end": 104.88, "text": " which made it possible to run some pretty nice algorithm to compute this and distribution.", "tokens": [51000, 597, 1027, 309, 1944, 281, 1190, 512, 1238, 1481, 9284, 281, 14722, 341, 293, 7316, 13, 51304], "temperature": 0.0, "avg_logprob": -0.1944966523543648, "compression_ratio": 1.679127725856698, "no_speech_prob": 0.12361899018287659}, {"id": 34, "seek": 8608, "start": 104.88, "end": 108.56, "text": " Maybe in this community, I should mention that in the late, I started to do free software", "tokens": [51304, 2704, 294, 341, 1768, 11, 286, 820, 2152, 300, 294, 264, 3469, 11, 286, 1409, 281, 360, 1737, 4722, 51488], "temperature": 0.0, "avg_logprob": -0.1944966523543648, "compression_ratio": 1.679127725856698, "no_speech_prob": 0.12361899018287659}, {"id": 35, "seek": 8608, "start": 108.56, "end": 110.56, "text": " in the late 80s on the Amiga.", "tokens": [51488, 294, 264, 3469, 4688, 82, 322, 264, 2012, 9900, 13, 51588], "temperature": 0.0, "avg_logprob": -0.1944966523543648, "compression_ratio": 1.679127725856698, "no_speech_prob": 0.12361899018287659}, {"id": 36, "seek": 8608, "start": 110.56, "end": 111.56, "text": " Okay.", "tokens": [51588, 1033, 13, 51638], "temperature": 0.0, "avg_logprob": -0.1944966523543648, "compression_ratio": 1.679127725856698, "no_speech_prob": 0.12361899018287659}, {"id": 37, "seek": 8608, "start": 111.56, "end": 115.52, "text": " So nobody remembers what it is, but I have some history with the free software movement", "tokens": [51638, 407, 5079, 26228, 437, 309, 307, 11, 457, 286, 362, 512, 2503, 365, 264, 1737, 4722, 3963, 51836], "temperature": 0.0, "avg_logprob": -0.1944966523543648, "compression_ratio": 1.679127725856698, "no_speech_prob": 0.12361899018287659}, {"id": 38, "seek": 11552, "start": 115.52, "end": 116.67999999999999, "text": " as well.", "tokens": [50364, 382, 731, 13, 50422], "temperature": 0.0, "avg_logprob": -0.2376948723426232, "compression_ratio": 1.5809859154929577, "no_speech_prob": 0.1634395867586136}, {"id": 39, "seek": 11552, "start": 116.67999999999999, "end": 122.16, "text": " So at some point, we decided to move to Rust for the obvious reasons, like it's a high-performance,", "tokens": [50422, 407, 412, 512, 935, 11, 321, 3047, 281, 1286, 281, 34952, 337, 264, 6322, 4112, 11, 411, 309, 311, 257, 1090, 12, 50242, 11, 50696], "temperature": 0.0, "avg_logprob": -0.2376948723426232, "compression_ratio": 1.5809859154929577, "no_speech_prob": 0.1634395867586136}, {"id": 40, "seek": 11552, "start": 122.16, "end": 123.16, "text": " safe language.", "tokens": [50696, 3273, 2856, 13, 50746], "temperature": 0.0, "avg_logprob": -0.2376948723426232, "compression_ratio": 1.5809859154929577, "no_speech_prob": 0.1634395867586136}, {"id": 41, "seek": 11552, "start": 123.16, "end": 125.47999999999999, "text": " But, okay, all I said is in Java.", "tokens": [50746, 583, 11, 1392, 11, 439, 286, 848, 307, 294, 10745, 13, 50862], "temperature": 0.0, "avg_logprob": -0.2376948723426232, "compression_ratio": 1.5809859154929577, "no_speech_prob": 0.1634395867586136}, {"id": 42, "seek": 11552, "start": 125.47999999999999, "end": 129.16, "text": " It was written in Java, started in the 80s and of the 90s.", "tokens": [50862, 467, 390, 3720, 294, 10745, 11, 1409, 294, 264, 4688, 82, 293, 295, 264, 4289, 82, 13, 51046], "temperature": 0.0, "avg_logprob": -0.2376948723426232, "compression_ratio": 1.5809859154929577, "no_speech_prob": 0.1634395867586136}, {"id": 43, "seek": 11552, "start": 129.16, "end": 132.0, "text": " And at that time, it seemed a very good idea.", "tokens": [51046, 400, 412, 300, 565, 11, 309, 6576, 257, 588, 665, 1558, 13, 51188], "temperature": 0.0, "avg_logprob": -0.2376948723426232, "compression_ratio": 1.5809859154929577, "no_speech_prob": 0.1634395867586136}, {"id": 44, "seek": 11552, "start": 132.0, "end": 133.0, "text": " Okay.", "tokens": [51188, 1033, 13, 51238], "temperature": 0.0, "avg_logprob": -0.2376948723426232, "compression_ratio": 1.5809859154929577, "no_speech_prob": 0.1634395867586136}, {"id": 45, "seek": 11552, "start": 133.0, "end": 137.12, "text": " Then things happened like arrays are at most two billion elements.", "tokens": [51238, 1396, 721, 2011, 411, 41011, 366, 412, 881, 732, 5218, 4959, 13, 51444], "temperature": 0.0, "avg_logprob": -0.2376948723426232, "compression_ratio": 1.5809859154929577, "no_speech_prob": 0.1634395867586136}, {"id": 46, "seek": 11552, "start": 137.12, "end": 141.84, "text": " And if you have graphs with 50 billion elements, you cannot even index the notes, which gets", "tokens": [51444, 400, 498, 291, 362, 24877, 365, 2625, 5218, 4959, 11, 291, 2644, 754, 8186, 264, 5570, 11, 597, 2170, 51680], "temperature": 0.0, "avg_logprob": -0.2376948723426232, "compression_ratio": 1.5809859154929577, "no_speech_prob": 0.1634395867586136}, {"id": 47, "seek": 11552, "start": 141.84, "end": 144.72, "text": " very, very annoying.", "tokens": [51680, 588, 11, 588, 11304, 13, 51824], "temperature": 0.0, "avg_logprob": -0.2376948723426232, "compression_ratio": 1.5809859154929577, "no_speech_prob": 0.1634395867586136}, {"id": 48, "seek": 14472, "start": 144.72, "end": 148.28, "text": " And today, anything this size is done using memory mapping.", "tokens": [50364, 400, 965, 11, 1340, 341, 2744, 307, 1096, 1228, 4675, 18350, 13, 50542], "temperature": 0.0, "avg_logprob": -0.15055449803670248, "compression_ratio": 1.6986301369863013, "no_speech_prob": 0.10255366563796997}, {"id": 49, "seek": 14472, "start": 148.28, "end": 153.32, "text": " I mean, if you go to Facebook, Google, whatever, all the large structures are there in memory,", "tokens": [50542, 286, 914, 11, 498, 291, 352, 281, 4384, 11, 3329, 11, 2035, 11, 439, 264, 2416, 9227, 366, 456, 294, 4675, 11, 50794], "temperature": 0.0, "avg_logprob": -0.15055449803670248, "compression_ratio": 1.6986301369863013, "no_speech_prob": 0.10255366563796997}, {"id": 50, "seek": 14472, "start": 153.32, "end": 157.36, "text": " but usually they're just memory mapped because you don't want to start up time.", "tokens": [50794, 457, 2673, 436, 434, 445, 4675, 33318, 570, 291, 500, 380, 528, 281, 722, 493, 565, 13, 50996], "temperature": 0.0, "avg_logprob": -0.15055449803670248, "compression_ratio": 1.6986301369863013, "no_speech_prob": 0.10255366563796997}, {"id": 51, "seek": 14472, "start": 157.36, "end": 162.84, "text": " If you load in memory a graph that is half a terabyte, you wait minutes, whatever the", "tokens": [50996, 759, 291, 3677, 294, 4675, 257, 4295, 300, 307, 1922, 257, 1796, 34529, 11, 291, 1699, 2077, 11, 2035, 264, 51270], "temperature": 0.0, "avg_logprob": -0.15055449803670248, "compression_ratio": 1.6986301369863013, "no_speech_prob": 0.10255366563796997}, {"id": 52, "seek": 14472, "start": 162.84, "end": 163.84, "text": " platform you are on.", "tokens": [51270, 3663, 291, 366, 322, 13, 51320], "temperature": 0.0, "avg_logprob": -0.15055449803670248, "compression_ratio": 1.6986301369863013, "no_speech_prob": 0.10255366563796997}, {"id": 53, "seek": 14472, "start": 163.84, "end": 168.0, "text": " But if you can memory map it, this time is amortized along the visit of the graph, for", "tokens": [51320, 583, 498, 291, 393, 4675, 4471, 309, 11, 341, 565, 307, 669, 477, 1602, 2051, 264, 3441, 295, 264, 4295, 11, 337, 51528], "temperature": 0.0, "avg_logprob": -0.15055449803670248, "compression_ratio": 1.6986301369863013, "no_speech_prob": 0.10255366563796997}, {"id": 54, "seek": 14472, "start": 168.0, "end": 169.0, "text": " instance.", "tokens": [51528, 5197, 13, 51578], "temperature": 0.0, "avg_logprob": -0.15055449803670248, "compression_ratio": 1.6986301369863013, "no_speech_prob": 0.10255366563796997}, {"id": 55, "seek": 14472, "start": 169.0, "end": 170.0, "text": " Okay.", "tokens": [51578, 1033, 13, 51628], "temperature": 0.0, "avg_logprob": -0.15055449803670248, "compression_ratio": 1.6986301369863013, "no_speech_prob": 0.10255366563796997}, {"id": 56, "seek": 14472, "start": 170.0, "end": 172.88, "text": " And we actually need to represent very large graph.", "tokens": [51628, 400, 321, 767, 643, 281, 2906, 588, 2416, 4295, 13, 51772], "temperature": 0.0, "avg_logprob": -0.15055449803670248, "compression_ratio": 1.6986301369863013, "no_speech_prob": 0.10255366563796997}, {"id": 57, "seek": 17288, "start": 172.88, "end": 179.07999999999998, "text": " If you ever use Java, the access to memory mapping facility, I will not say words because", "tokens": [50364, 759, 291, 1562, 764, 10745, 11, 264, 2105, 281, 4675, 18350, 8973, 11, 286, 486, 406, 584, 2283, 570, 50674], "temperature": 0.0, "avg_logprob": -0.21009119716259317, "compression_ratio": 1.558139534883721, "no_speech_prob": 0.09985800832509995}, {"id": 58, "seek": 17288, "start": 179.07999999999998, "end": 184.6, "text": " they would not be proper in this particular situation.", "tokens": [50674, 436, 576, 406, 312, 2296, 294, 341, 1729, 2590, 13, 50950], "temperature": 0.0, "avg_logprob": -0.21009119716259317, "compression_ratio": 1.558139534883721, "no_speech_prob": 0.09985800832509995}, {"id": 59, "seek": 17288, "start": 184.6, "end": 186.51999999999998, "text": " There are really lazy iterators.", "tokens": [50950, 821, 366, 534, 14847, 17138, 3391, 13, 51046], "temperature": 0.0, "avg_logprob": -0.21009119716259317, "compression_ratio": 1.558139534883721, "no_speech_prob": 0.09985800832509995}, {"id": 60, "seek": 17288, "start": 186.51999999999998, "end": 189.56, "text": " If you're written in Java and iterator, you know what I mean.", "tokens": [51046, 759, 291, 434, 3720, 294, 10745, 293, 17138, 1639, 11, 291, 458, 437, 286, 914, 13, 51198], "temperature": 0.0, "avg_logprob": -0.21009119716259317, "compression_ratio": 1.558139534883721, "no_speech_prob": 0.09985800832509995}, {"id": 61, "seek": 17288, "start": 189.56, "end": 194.76, "text": " And okay, so we, to do this, we needed to port a number of ideas from a Java library", "tokens": [51198, 400, 1392, 11, 370, 321, 11, 281, 360, 341, 11, 321, 2978, 281, 2436, 257, 1230, 295, 3487, 490, 257, 10745, 6405, 51458], "temperature": 0.0, "avg_logprob": -0.21009119716259317, "compression_ratio": 1.558139534883721, "no_speech_prob": 0.09985800832509995}, {"id": 62, "seek": 17288, "start": 194.76, "end": 196.28, "text": " and to develop a few new things.", "tokens": [51458, 293, 281, 1499, 257, 1326, 777, 721, 13, 51534], "temperature": 0.0, "avg_logprob": -0.21009119716259317, "compression_ratio": 1.558139534883721, "no_speech_prob": 0.09985800832509995}, {"id": 63, "seek": 17288, "start": 196.28, "end": 200.28, "text": " So the first thing is absurdity, weird name.", "tokens": [51534, 407, 264, 700, 551, 307, 19774, 507, 11, 3657, 1315, 13, 51734], "temperature": 0.0, "avg_logprob": -0.21009119716259317, "compression_ratio": 1.558139534883721, "no_speech_prob": 0.09985800832509995}, {"id": 64, "seek": 20028, "start": 200.28, "end": 204.28, "text": " So it's a framework from epsilon copy, serialization, deserialization.", "tokens": [50364, 407, 309, 311, 257, 8388, 490, 17889, 5055, 11, 17436, 2144, 11, 730, 260, 831, 2144, 13, 50564], "temperature": 0.0, "avg_logprob": -0.17181527064396784, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.05060230568051338}, {"id": 65, "seek": 20028, "start": 204.28, "end": 209.6, "text": " So you might know what is zero copy, serialization, deserialization, means that you serialize", "tokens": [50564, 407, 291, 1062, 458, 437, 307, 4018, 5055, 11, 17436, 2144, 11, 730, 260, 831, 2144, 11, 1355, 300, 291, 17436, 1125, 50830], "temperature": 0.0, "avg_logprob": -0.17181527064396784, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.05060230568051338}, {"id": 66, "seek": 20028, "start": 209.6, "end": 214.92000000000002, "text": " something and then you use the memory, actually in the state it is, to represent the object", "tokens": [50830, 746, 293, 550, 291, 764, 264, 4675, 11, 767, 294, 264, 1785, 309, 307, 11, 281, 2906, 264, 2657, 51096], "temperature": 0.0, "avg_logprob": -0.17181527064396784, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.05060230568051338}, {"id": 67, "seek": 20028, "start": 214.92000000000002, "end": 215.92000000000002, "text": " internally.", "tokens": [51096, 19501, 13, 51146], "temperature": 0.0, "avg_logprob": -0.17181527064396784, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.05060230568051338}, {"id": 68, "seek": 20028, "start": 215.92000000000002, "end": 216.92000000000002, "text": " Okay.", "tokens": [51146, 1033, 13, 51196], "temperature": 0.0, "avg_logprob": -0.17181527064396784, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.05060230568051338}, {"id": 69, "seek": 20028, "start": 216.92000000000002, "end": 218.08, "text": " So there is no deserialization.", "tokens": [51196, 407, 456, 307, 572, 730, 260, 831, 2144, 13, 51254], "temperature": 0.0, "avg_logprob": -0.17181527064396784, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.05060230568051338}, {"id": 70, "seek": 20028, "start": 218.08, "end": 219.76, "text": " You don't build a new object.", "tokens": [51254, 509, 500, 380, 1322, 257, 777, 2657, 13, 51338], "temperature": 0.0, "avg_logprob": -0.17181527064396784, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.05060230568051338}, {"id": 71, "seek": 20028, "start": 219.76, "end": 223.08, "text": " The piece of memory is directly used as it is.", "tokens": [51338, 440, 2522, 295, 4675, 307, 3838, 1143, 382, 309, 307, 13, 51504], "temperature": 0.0, "avg_logprob": -0.17181527064396784, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.05060230568051338}, {"id": 72, "seek": 20028, "start": 223.08, "end": 228.56, "text": " And this is how things work, as I said, in all these organizations that have large indices,", "tokens": [51504, 400, 341, 307, 577, 721, 589, 11, 382, 286, 848, 11, 294, 439, 613, 6150, 300, 362, 2416, 43840, 11, 51778], "temperature": 0.0, "avg_logprob": -0.17181527064396784, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.05060230568051338}, {"id": 73, "seek": 22856, "start": 229.0, "end": 230.44, "text": " Facebook, Amazon, whatever you want.", "tokens": [50386, 4384, 11, 6795, 11, 2035, 291, 528, 13, 50458], "temperature": 0.0, "avg_logprob": -0.18663887355638586, "compression_ratio": 1.5482625482625483, "no_speech_prob": 0.1692560464143753}, {"id": 74, "seek": 22856, "start": 230.44, "end": 234.12, "text": " I mean, the index is on disk, it's memory mapped as it is.", "tokens": [50458, 286, 914, 11, 264, 8186, 307, 322, 12355, 11, 309, 311, 4675, 33318, 382, 309, 307, 13, 50642], "temperature": 0.0, "avg_logprob": -0.18663887355638586, "compression_ratio": 1.5482625482625483, "no_speech_prob": 0.1692560464143753}, {"id": 75, "seek": 22856, "start": 234.12, "end": 237.12, "text": " It's not deserialized in any proper sense.", "tokens": [50642, 467, 311, 406, 730, 260, 831, 1602, 294, 604, 2296, 2020, 13, 50792], "temperature": 0.0, "avg_logprob": -0.18663887355638586, "compression_ratio": 1.5482625482625483, "no_speech_prob": 0.1692560464143753}, {"id": 76, "seek": 22856, "start": 237.12, "end": 245.12, "text": " There are a few frameworks like abomination that do this kind of things in Rust, but they", "tokens": [50792, 821, 366, 257, 1326, 29834, 411, 410, 46970, 300, 360, 341, 733, 295, 721, 294, 34952, 11, 457, 436, 51192], "temperature": 0.0, "avg_logprob": -0.18663887355638586, "compression_ratio": 1.5482625482625483, "no_speech_prob": 0.1692560464143753}, {"id": 77, "seek": 22856, "start": 245.12, "end": 246.88, "text": " all have problems for us.", "tokens": [51192, 439, 362, 2740, 337, 505, 13, 51280], "temperature": 0.0, "avg_logprob": -0.18663887355638586, "compression_ratio": 1.5482625482625483, "no_speech_prob": 0.1692560464143753}, {"id": 78, "seek": 22856, "start": 246.88, "end": 252.4, "text": " The first one is the oldest one by Frank McSherry, writes into the serialized object.", "tokens": [51280, 440, 700, 472, 307, 264, 14026, 472, 538, 6823, 4050, 50, 511, 627, 11, 13657, 666, 264, 17436, 1602, 2657, 13, 51556], "temperature": 0.0, "avg_logprob": -0.18663887355638586, "compression_ratio": 1.5482625482625483, "no_speech_prob": 0.1692560464143753}, {"id": 79, "seek": 22856, "start": 252.4, "end": 256.8, "text": " So if you want to memory map a file, that's out of question.", "tokens": [51556, 407, 498, 291, 528, 281, 4675, 4471, 257, 3991, 11, 300, 311, 484, 295, 1168, 13, 51776], "temperature": 0.0, "avg_logprob": -0.18663887355638586, "compression_ratio": 1.5482625482625483, "no_speech_prob": 0.1692560464143753}, {"id": 80, "seek": 25680, "start": 257.16, "end": 260.40000000000003, "text": " You might know it is from the people that do the internalization library.", "tokens": [50382, 509, 1062, 458, 309, 307, 490, 264, 561, 300, 360, 264, 6920, 2144, 6405, 13, 50544], "temperature": 0.0, "avg_logprob": -0.24829080862592356, "compression_ratio": 1.75503355704698, "no_speech_prob": 0.05376844480633736}, {"id": 81, "seek": 25680, "start": 260.40000000000003, "end": 263.88, "text": " Nice idea, but it has a huge impact on performance.", "tokens": [50544, 5490, 1558, 11, 457, 309, 575, 257, 2603, 2712, 322, 3389, 13, 50718], "temperature": 0.0, "avg_logprob": -0.24829080862592356, "compression_ratio": 1.75503355704698, "no_speech_prob": 0.05376844480633736}, {"id": 82, "seek": 25680, "start": 263.88, "end": 267.92, "text": " It does some kind of runtime resolution of the access to vectors.", "tokens": [50718, 467, 775, 512, 733, 295, 34474, 8669, 295, 264, 2105, 281, 18875, 13, 50920], "temperature": 0.0, "avg_logprob": -0.24829080862592356, "compression_ratio": 1.75503355704698, "no_speech_prob": 0.05376844480633736}, {"id": 83, "seek": 25680, "start": 267.92, "end": 272.52000000000004, "text": " And then there is Archive, you might be familiar with, which too does some relative memory", "tokens": [50920, 400, 550, 456, 307, 10984, 488, 11, 291, 1062, 312, 4963, 365, 11, 597, 886, 775, 512, 4972, 4675, 51150], "temperature": 0.0, "avg_logprob": -0.24829080862592356, "compression_ratio": 1.75503355704698, "no_speech_prob": 0.05376844480633736}, {"id": 84, "seek": 25680, "start": 272.52000000000004, "end": 273.76, "text": " that is differentiation.", "tokens": [51150, 300, 307, 38902, 13, 51212], "temperature": 0.0, "avg_logprob": -0.24829080862592356, "compression_ratio": 1.75503355704698, "no_speech_prob": 0.05376844480633736}, {"id": 85, "seek": 25680, "start": 273.76, "end": 278.12, "text": " And also the structure you deserialize is completely different from the one you serialize.", "tokens": [51212, 400, 611, 264, 3877, 291, 730, 260, 831, 1125, 307, 2584, 819, 490, 264, 472, 291, 17436, 1125, 13, 51430], "temperature": 0.0, "avg_logprob": -0.24829080862592356, "compression_ratio": 1.75503355704698, "no_speech_prob": 0.05376844480633736}, {"id": 86, "seek": 25680, "start": 278.12, "end": 282.2, "text": " So you have to delegate all the methods and then each time you change one, you have to", "tokens": [51430, 407, 291, 362, 281, 40999, 439, 264, 7150, 293, 550, 1184, 565, 291, 1319, 472, 11, 291, 362, 281, 51634], "temperature": 0.0, "avg_logprob": -0.24829080862592356, "compression_ratio": 1.75503355704698, "no_speech_prob": 0.05376844480633736}, {"id": 87, "seek": 25680, "start": 282.2, "end": 283.6, "text": " change the other.", "tokens": [51634, 1319, 264, 661, 13, 51704], "temperature": 0.0, "avg_logprob": -0.24829080862592356, "compression_ratio": 1.75503355704698, "no_speech_prob": 0.05376844480633736}, {"id": 88, "seek": 25680, "start": 283.6, "end": 284.96000000000004, "text": " Not very practical.", "tokens": [51704, 1726, 588, 8496, 13, 51772], "temperature": 0.0, "avg_logprob": -0.24829080862592356, "compression_ratio": 1.75503355704698, "no_speech_prob": 0.05376844480633736}, {"id": 89, "seek": 28496, "start": 284.96, "end": 289.59999999999997, "text": " So what we did was develop this framework, which requires a little bit of collaboration", "tokens": [50364, 407, 437, 321, 630, 390, 1499, 341, 8388, 11, 597, 7029, 257, 707, 857, 295, 9363, 50596], "temperature": 0.0, "avg_logprob": -0.11834479941696417, "compression_ratio": 1.698961937716263, "no_speech_prob": 0.007660347037017345}, {"id": 90, "seek": 28496, "start": 289.59999999999997, "end": 291.08, "text": " from the underlying struct.", "tokens": [50596, 490, 264, 14217, 6594, 13, 50670], "temperature": 0.0, "avg_logprob": -0.11834479941696417, "compression_ratio": 1.698961937716263, "no_speech_prob": 0.007660347037017345}, {"id": 91, "seek": 28496, "start": 291.08, "end": 296.28, "text": " But the basic idea is that you serialize something and then you epsilon copy deserialize it.", "tokens": [50670, 583, 264, 3875, 1558, 307, 300, 291, 17436, 1125, 746, 293, 550, 291, 17889, 5055, 730, 260, 831, 1125, 309, 13, 50930], "temperature": 0.0, "avg_logprob": -0.11834479941696417, "compression_ratio": 1.698961937716263, "no_speech_prob": 0.007660347037017345}, {"id": 92, "seek": 28496, "start": 296.28, "end": 301.79999999999995, "text": " So you access it, you allocate a very small amount of memory and then the rest comes directly", "tokens": [50930, 407, 291, 2105, 309, 11, 291, 35713, 257, 588, 1359, 2372, 295, 4675, 293, 550, 264, 1472, 1487, 3838, 51206], "temperature": 0.0, "avg_logprob": -0.11834479941696417, "compression_ratio": 1.698961937716263, "no_speech_prob": 0.007660347037017345}, {"id": 93, "seek": 28496, "start": 301.79999999999995, "end": 304.15999999999997, "text": " from the disk without any intervention.", "tokens": [51206, 490, 264, 12355, 1553, 604, 13176, 13, 51324], "temperature": 0.0, "avg_logprob": -0.11834479941696417, "compression_ratio": 1.698961937716263, "no_speech_prob": 0.007660347037017345}, {"id": 94, "seek": 28496, "start": 304.15999999999997, "end": 308.59999999999997, "text": " And the way we do it, we remap vectors essentially.", "tokens": [51324, 400, 264, 636, 321, 360, 309, 11, 321, 890, 569, 18875, 4476, 13, 51546], "temperature": 0.0, "avg_logprob": -0.11834479941696417, "compression_ratio": 1.698961937716263, "no_speech_prob": 0.007660347037017345}, {"id": 95, "seek": 28496, "start": 308.59999999999997, "end": 313.67999999999995, "text": " You build a structure with a vector, but when you deserialize it, it has a reference to a slice.", "tokens": [51546, 509, 1322, 257, 3877, 365, 257, 8062, 11, 457, 562, 291, 730, 260, 831, 1125, 309, 11, 309, 575, 257, 6408, 281, 257, 13153, 13, 51800], "temperature": 0.0, "avg_logprob": -0.11834479941696417, "compression_ratio": 1.698961937716263, "no_speech_prob": 0.007660347037017345}, {"id": 96, "seek": 31368, "start": 313.72, "end": 319.40000000000003, "text": " In this way, we just have to allocate the actual struct that you want to deserialize,", "tokens": [50366, 682, 341, 636, 11, 321, 445, 362, 281, 35713, 264, 3539, 6594, 300, 291, 528, 281, 730, 260, 831, 1125, 11, 50650], "temperature": 0.0, "avg_logprob": -0.164500214332758, "compression_ratio": 1.8056537102473498, "no_speech_prob": 0.010935273952782154}, {"id": 97, "seek": 31368, "start": 319.40000000000003, "end": 324.36, "text": " but then anything that is a pointer inside just point to the original memory.", "tokens": [50650, 457, 550, 1340, 300, 307, 257, 23918, 1854, 445, 935, 281, 264, 3380, 4675, 13, 50898], "temperature": 0.0, "avg_logprob": -0.164500214332758, "compression_ratio": 1.8056537102473498, "no_speech_prob": 0.010935273952782154}, {"id": 98, "seek": 31368, "start": 324.36, "end": 328.36, "text": " So epsilon copy, the idea is that it's not a zero copy because we did a little bit of", "tokens": [50898, 407, 17889, 5055, 11, 264, 1558, 307, 300, 309, 311, 406, 257, 4018, 5055, 570, 321, 630, 257, 707, 857, 295, 51098], "temperature": 0.0, "avg_logprob": -0.164500214332758, "compression_ratio": 1.8056537102473498, "no_speech_prob": 0.010935273952782154}, {"id": 99, "seek": 31368, "start": 328.36, "end": 331.72, "text": " copying, epsilon copy, a very small amount.", "tokens": [51098, 27976, 11, 17889, 5055, 11, 257, 588, 1359, 2372, 13, 51266], "temperature": 0.0, "avg_logprob": -0.164500214332758, "compression_ratio": 1.8056537102473498, "no_speech_prob": 0.010935273952782154}, {"id": 100, "seek": 31368, "start": 331.72, "end": 335.08, "text": " But the advantage is that now you have exactly the structure that you serialize.", "tokens": [51266, 583, 264, 5002, 307, 300, 586, 291, 362, 2293, 264, 3877, 300, 291, 17436, 1125, 13, 51434], "temperature": 0.0, "avg_logprob": -0.164500214332758, "compression_ratio": 1.8056537102473498, "no_speech_prob": 0.010935273952782154}, {"id": 101, "seek": 31368, "start": 335.08, "end": 337.68, "text": " It's exactly that structure with all its methods.", "tokens": [51434, 467, 311, 2293, 300, 3877, 365, 439, 1080, 7150, 13, 51564], "temperature": 0.0, "avg_logprob": -0.164500214332758, "compression_ratio": 1.8056537102473498, "no_speech_prob": 0.010935273952782154}, {"id": 102, "seek": 31368, "start": 337.68, "end": 342.24, "text": " The only thing you have to do, if you have vectors, there must be a type parameter and", "tokens": [51564, 440, 787, 551, 291, 362, 281, 360, 11, 498, 291, 362, 18875, 11, 456, 1633, 312, 257, 2010, 13075, 293, 51792], "temperature": 0.0, "avg_logprob": -0.164500214332758, "compression_ratio": 1.8056537102473498, "no_speech_prob": 0.010935273952782154}, {"id": 103, "seek": 34224, "start": 342.24, "end": 346.76, "text": " you must write the access method for as a left to a slice.", "tokens": [50364, 291, 1633, 2464, 264, 2105, 3170, 337, 382, 257, 1411, 281, 257, 13153, 13, 50590], "temperature": 0.0, "avg_logprob": -0.17170677185058594, "compression_ratio": 1.766798418972332, "no_speech_prob": 0.009277025237679482}, {"id": 104, "seek": 34224, "start": 346.76, "end": 350.32, "text": " Of course, when writing, you write for a vector, but when you read, you read it from", "tokens": [50590, 2720, 1164, 11, 562, 3579, 11, 291, 2464, 337, 257, 8062, 11, 457, 562, 291, 1401, 11, 291, 1401, 309, 490, 50768], "temperature": 0.0, "avg_logprob": -0.17170677185058594, "compression_ratio": 1.766798418972332, "no_speech_prob": 0.009277025237679482}, {"id": 105, "seek": 34224, "start": 350.32, "end": 351.32, "text": " a slice.", "tokens": [50768, 257, 13153, 13, 50818], "temperature": 0.0, "avg_logprob": -0.17170677185058594, "compression_ratio": 1.766798418972332, "no_speech_prob": 0.009277025237679482}, {"id": 106, "seek": 34224, "start": 351.32, "end": 352.72, "text": " This is the collaboration you need.", "tokens": [50818, 639, 307, 264, 9363, 291, 643, 13, 50888], "temperature": 0.0, "avg_logprob": -0.17170677185058594, "compression_ratio": 1.766798418972332, "no_speech_prob": 0.009277025237679482}, {"id": 107, "seek": 34224, "start": 352.72, "end": 358.08, "text": " But then, completed transparently, like you can do it with basic type.", "tokens": [50888, 583, 550, 11, 7365, 7132, 6420, 11, 411, 291, 393, 360, 309, 365, 3875, 2010, 13, 51156], "temperature": 0.0, "avg_logprob": -0.17170677185058594, "compression_ratio": 1.766798418972332, "no_speech_prob": 0.009277025237679482}, {"id": 108, "seek": 34224, "start": 358.08, "end": 361.24, "text": " You store a vector and then you memory map it and that's it.", "tokens": [51156, 509, 3531, 257, 8062, 293, 550, 291, 4675, 4471, 309, 293, 300, 311, 309, 13, 51314], "temperature": 0.0, "avg_logprob": -0.17170677185058594, "compression_ratio": 1.766798418972332, "no_speech_prob": 0.009277025237679482}, {"id": 109, "seek": 34224, "start": 361.24, "end": 365.28000000000003, "text": " And what you get in T is a reference to a slice.", "tokens": [51314, 400, 437, 291, 483, 294, 314, 307, 257, 6408, 281, 257, 13153, 13, 51516], "temperature": 0.0, "avg_logprob": -0.17170677185058594, "compression_ratio": 1.766798418972332, "no_speech_prob": 0.009277025237679482}, {"id": 110, "seek": 34224, "start": 365.28000000000003, "end": 369.96000000000004, "text": " More precisely, something that derives to a slice, to a reference to a slice.", "tokens": [51516, 5048, 13402, 11, 746, 300, 1163, 1539, 281, 257, 13153, 11, 281, 257, 6408, 281, 257, 13153, 13, 51750], "temperature": 0.0, "avg_logprob": -0.17170677185058594, "compression_ratio": 1.766798418972332, "no_speech_prob": 0.009277025237679482}, {"id": 111, "seek": 36996, "start": 369.96, "end": 375.76, "text": " And again, you work essentially transparently with respect to the framework.", "tokens": [50364, 400, 797, 11, 291, 589, 4476, 7132, 6420, 365, 3104, 281, 264, 8388, 13, 50654], "temperature": 0.0, "avg_logprob": -0.2832790752788922, "compression_ratio": 1.7465753424657535, "no_speech_prob": 0.005608382169157267}, {"id": 112, "seek": 36996, "start": 375.76, "end": 381.03999999999996, "text": " Unlike the other cases, and since there is nothing intervening, resolving the pointers,", "tokens": [50654, 17657, 264, 661, 3331, 11, 293, 1670, 456, 307, 1825, 17104, 278, 11, 49940, 264, 44548, 11, 50918], "temperature": 0.0, "avg_logprob": -0.2832790752788922, "compression_ratio": 1.7465753424657535, "no_speech_prob": 0.005608382169157267}, {"id": 113, "seek": 36996, "start": 381.03999999999996, "end": 385.15999999999997, "text": " there is no dynamic resolution, everything is done at this realization time, zero impact", "tokens": [50918, 456, 307, 572, 8546, 8669, 11, 1203, 307, 1096, 412, 341, 25138, 565, 11, 4018, 2712, 51124], "temperature": 0.0, "avg_logprob": -0.2832790752788922, "compression_ratio": 1.7465753424657535, "no_speech_prob": 0.005608382169157267}, {"id": 114, "seek": 36996, "start": 385.15999999999997, "end": 386.15999999999997, "text": " on performance.", "tokens": [51124, 322, 3389, 13, 51174], "temperature": 0.0, "avg_logprob": -0.2832790752788922, "compression_ratio": 1.7465753424657535, "no_speech_prob": 0.005608382169157267}, {"id": 115, "seek": 36996, "start": 386.15999999999997, "end": 388.79999999999995, "text": " The performance is exactly the one of the original structure.", "tokens": [51174, 440, 3389, 307, 2293, 264, 472, 295, 264, 3380, 3877, 13, 51306], "temperature": 0.0, "avg_logprob": -0.2832790752788922, "compression_ratio": 1.7465753424657535, "no_speech_prob": 0.005608382169157267}, {"id": 116, "seek": 36996, "start": 388.79999999999995, "end": 394.12, "text": " We use this to map massive immutable data structure like representation of sequences", "tokens": [51306, 492, 764, 341, 281, 4471, 5994, 3397, 32148, 1412, 3877, 411, 10290, 295, 22978, 51572], "temperature": 0.0, "avg_logprob": -0.2832790752788922, "compression_ratio": 1.7465753424657535, "no_speech_prob": 0.005608382169157267}, {"id": 117, "seek": 36996, "start": 394.12, "end": 399.91999999999996, "text": " of sets and so on that are like those of gigabytes, 100 gigabytes on disk directly on memory,", "tokens": [51572, 295, 6352, 293, 370, 322, 300, 366, 411, 729, 295, 42741, 11, 2319, 42741, 322, 12355, 3838, 322, 4675, 11, 51862], "temperature": 0.0, "avg_logprob": -0.2832790752788922, "compression_ratio": 1.7465753424657535, "no_speech_prob": 0.005608382169157267}, {"id": 118, "seek": 39992, "start": 400.88, "end": 402.04, "text": " without any load time.", "tokens": [50412, 1553, 604, 3677, 565, 13, 50470], "temperature": 0.0, "avg_logprob": -0.2873551580641005, "compression_ratio": 1.6330645161290323, "no_speech_prob": 0.022101018577814102}, {"id": 119, "seek": 39992, "start": 402.04, "end": 407.84000000000003, "text": " So if you handle large immutable data structures, that could be for you.", "tokens": [50470, 407, 498, 291, 4813, 2416, 3397, 32148, 1412, 9227, 11, 300, 727, 312, 337, 291, 13, 50760], "temperature": 0.0, "avg_logprob": -0.2873551580641005, "compression_ratio": 1.6330645161290323, "no_speech_prob": 0.022101018577814102}, {"id": 120, "seek": 39992, "start": 407.84000000000003, "end": 411.84000000000003, "text": " Memdology, that's a very small crate, but it's a problem we had.", "tokens": [50760, 8731, 67, 1793, 11, 300, 311, 257, 588, 1359, 42426, 11, 457, 309, 311, 257, 1154, 321, 632, 13, 50960], "temperature": 0.0, "avg_logprob": -0.2873551580641005, "compression_ratio": 1.6330645161290323, "no_speech_prob": 0.022101018577814102}, {"id": 121, "seek": 39992, "start": 411.84000000000003, "end": 417.48, "text": " Okay, it's a high performance memory occupancy detector, which sounds ridiculous when you", "tokens": [50960, 1033, 11, 309, 311, 257, 1090, 3389, 4675, 8073, 6717, 25712, 11, 597, 3263, 11083, 562, 291, 51242], "temperature": 0.0, "avg_logprob": -0.2873551580641005, "compression_ratio": 1.6330645161290323, "no_speech_prob": 0.022101018577814102}, {"id": 122, "seek": 39992, "start": 417.48, "end": 422.92, "text": " say it because, well, it does as to measure the memory occupied.", "tokens": [51242, 584, 309, 570, 11, 731, 11, 309, 775, 382, 281, 3481, 264, 4675, 19629, 13, 51514], "temperature": 0.0, "avg_logprob": -0.2873551580641005, "compression_ratio": 1.6330645161290323, "no_speech_prob": 0.022101018577814102}, {"id": 123, "seek": 39992, "start": 422.92, "end": 429.84000000000003, "text": " It's not so easy because if you use the one that are around, so it is like a large vector", "tokens": [51514, 467, 311, 406, 370, 1858, 570, 498, 291, 764, 264, 472, 300, 366, 926, 11, 370, 309, 307, 411, 257, 2416, 8062, 51860], "temperature": 0.0, "avg_logprob": -0.2873551580641005, "compression_ratio": 1.6330645161290323, "no_speech_prob": 0.022101018577814102}, {"id": 124, "seek": 42984, "start": 429.96, "end": 432.76, "text": " and few other things, this is the amount of a located memory.", "tokens": [50370, 293, 1326, 661, 721, 11, 341, 307, 264, 2372, 295, 257, 6870, 4675, 13, 50510], "temperature": 0.0, "avg_logprob": -0.2083608610136015, "compression_ratio": 1.8658536585365855, "no_speech_prob": 0.008218799717724323}, {"id": 125, "seek": 42984, "start": 432.76, "end": 437.84, "text": " These are the three more common frameworks, sorry, crates that do that, and this is the", "tokens": [50510, 1981, 366, 264, 1045, 544, 2689, 29834, 11, 2597, 11, 941, 1024, 300, 360, 300, 11, 293, 341, 307, 264, 50764], "temperature": 0.0, "avg_logprob": -0.2083608610136015, "compression_ratio": 1.8658536585365855, "no_speech_prob": 0.008218799717724323}, {"id": 126, "seek": 42984, "start": 437.84, "end": 442.35999999999996, "text": " amount of time that they take, and this is the amount of time we take.", "tokens": [50764, 2372, 295, 565, 300, 436, 747, 11, 293, 341, 307, 264, 2372, 295, 565, 321, 747, 13, 50990], "temperature": 0.0, "avg_logprob": -0.2083608610136015, "compression_ratio": 1.8658536585365855, "no_speech_prob": 0.008218799717724323}, {"id": 127, "seek": 42984, "start": 442.35999999999996, "end": 447.88, "text": " So the reason is that without some infrastructure similar to the one of absurdity, you have", "tokens": [50990, 407, 264, 1778, 307, 300, 1553, 512, 6896, 2531, 281, 264, 472, 295, 19774, 507, 11, 291, 362, 51266], "temperature": 0.0, "avg_logprob": -0.2083608610136015, "compression_ratio": 1.8658536585365855, "no_speech_prob": 0.008218799717724323}, {"id": 128, "seek": 42984, "start": 447.88, "end": 451.84, "text": " to iterate through collections to measure the space occupied.", "tokens": [51266, 281, 44497, 807, 16641, 281, 3481, 264, 1901, 19629, 13, 51464], "temperature": 0.0, "avg_logprob": -0.2083608610136015, "compression_ratio": 1.8658536585365855, "no_speech_prob": 0.008218799717724323}, {"id": 129, "seek": 42984, "start": 451.84, "end": 456.08, "text": " And if you iterate through a billion element collection, it will take a lot of time.", "tokens": [51464, 400, 498, 291, 44497, 807, 257, 5218, 4478, 5765, 11, 309, 486, 747, 257, 688, 295, 565, 13, 51676], "temperature": 0.0, "avg_logprob": -0.2083608610136015, "compression_ratio": 1.8658536585365855, "no_speech_prob": 0.008218799717724323}, {"id": 130, "seek": 45608, "start": 456.08, "end": 461.28, "text": " So we routinely measure the space and occupancy of things that are like 50 gigabytes, it will", "tokens": [50364, 407, 321, 40443, 3481, 264, 1901, 293, 8073, 6717, 295, 721, 300, 366, 411, 2625, 42741, 11, 309, 486, 50624], "temperature": 0.0, "avg_logprob": -0.28545104480180583, "compression_ratio": 1.7379310344827585, "no_speech_prob": 0.012118271552026272}, {"id": 131, "seek": 45608, "start": 461.28, "end": 462.52, "text": " take eight minutes.", "tokens": [50624, 747, 3180, 2077, 13, 50686], "temperature": 0.0, "avg_logprob": -0.28545104480180583, "compression_ratio": 1.7379310344827585, "no_speech_prob": 0.012118271552026272}, {"id": 132, "seek": 45608, "start": 462.52, "end": 466.91999999999996, "text": " So we develop this if you need to measure the actual occupation memory, not stack occupation,", "tokens": [50686, 407, 321, 1499, 341, 498, 291, 643, 281, 3481, 264, 3539, 24482, 4675, 11, 406, 8630, 24482, 11, 50906], "temperature": 0.0, "avg_logprob": -0.28545104480180583, "compression_ratio": 1.7379310344827585, "no_speech_prob": 0.012118271552026272}, {"id": 133, "seek": 45608, "start": 466.91999999999996, "end": 471.47999999999996, "text": " the actual occupation in memory of something large, try MDBG.", "tokens": [50906, 264, 3539, 24482, 294, 4675, 295, 746, 2416, 11, 853, 22521, 33, 38, 13, 51134], "temperature": 0.0, "avg_logprob": -0.28545104480180583, "compression_ratio": 1.7379310344827585, "no_speech_prob": 0.012118271552026272}, {"id": 134, "seek": 45608, "start": 471.47999999999996, "end": 476.96, "text": " Also, as a nice, it does you a print out of the structure with the old memory occupancy.", "tokens": [51134, 2743, 11, 382, 257, 1481, 11, 309, 775, 291, 257, 4482, 484, 295, 264, 3877, 365, 264, 1331, 4675, 8073, 6717, 13, 51408], "temperature": 0.0, "avg_logprob": -0.28545104480180583, "compression_ratio": 1.7379310344827585, "no_speech_prob": 0.012118271552026272}, {"id": 135, "seek": 45608, "start": 476.96, "end": 481.68, "text": " It's important for us because we do all the time this succinct data structure that have", "tokens": [51408, 467, 311, 1021, 337, 505, 570, 321, 360, 439, 264, 565, 341, 21578, 5460, 1412, 3877, 300, 362, 51644], "temperature": 0.0, "avg_logprob": -0.28545104480180583, "compression_ratio": 1.7379310344827585, "no_speech_prob": 0.012118271552026272}, {"id": 136, "seek": 45608, "start": 481.68, "end": 484.71999999999997, "text": " various components and we need to know the relative size.", "tokens": [51644, 3683, 6677, 293, 321, 643, 281, 458, 264, 4972, 2744, 13, 51796], "temperature": 0.0, "avg_logprob": -0.28545104480180583, "compression_ratio": 1.7379310344827585, "no_speech_prob": 0.012118271552026272}, {"id": 137, "seek": 48472, "start": 484.72, "end": 487.72, "text": " So this is only if you have very large data structures.", "tokens": [50364, 407, 341, 307, 787, 498, 291, 362, 588, 2416, 1412, 9227, 13, 50514], "temperature": 0.0, "avg_logprob": -0.22150738008560672, "compression_ratio": 1.8801652892561984, "no_speech_prob": 0.03336956351995468}, {"id": 138, "seek": 48472, "start": 487.72, "end": 491.56, "text": " They are small, you can iterate, no problem.", "tokens": [50514, 814, 366, 1359, 11, 291, 393, 44497, 11, 572, 1154, 13, 50706], "temperature": 0.0, "avg_logprob": -0.22150738008560672, "compression_ratio": 1.8801652892561984, "no_speech_prob": 0.03336956351995468}, {"id": 139, "seek": 48472, "start": 491.56, "end": 495.48, "text": " Succ is an ongoing problem, ongoing problem, yeah, it's an ongoing problem.", "tokens": [50706, 318, 39407, 307, 364, 10452, 1154, 11, 10452, 1154, 11, 1338, 11, 309, 311, 364, 10452, 1154, 13, 50902], "temperature": 0.0, "avg_logprob": -0.22150738008560672, "compression_ratio": 1.8801652892561984, "no_speech_prob": 0.03336956351995468}, {"id": 140, "seek": 48472, "start": 495.48, "end": 499.76000000000005, "text": " I won't say an ingrate, but it's actually kind of an ongoing problem.", "tokens": [50902, 286, 1582, 380, 584, 364, 3957, 4404, 11, 457, 309, 311, 767, 733, 295, 364, 10452, 1154, 13, 51116], "temperature": 0.0, "avg_logprob": -0.22150738008560672, "compression_ratio": 1.8801652892561984, "no_speech_prob": 0.03336956351995468}, {"id": 141, "seek": 48472, "start": 499.76000000000005, "end": 506.36, "text": " And it's a part of an existing C++ project and Java project about succinct data structures.", "tokens": [51116, 400, 309, 311, 257, 644, 295, 364, 6741, 383, 25472, 1716, 293, 10745, 1716, 466, 21578, 5460, 1412, 9227, 13, 51446], "temperature": 0.0, "avg_logprob": -0.22150738008560672, "compression_ratio": 1.8801652892561984, "no_speech_prob": 0.03336956351995468}, {"id": 142, "seek": 48472, "start": 506.36, "end": 507.52000000000004, "text": " You might know what they are.", "tokens": [51446, 509, 1062, 458, 437, 436, 366, 13, 51504], "temperature": 0.0, "avg_logprob": -0.22150738008560672, "compression_ratio": 1.8801652892561984, "no_speech_prob": 0.03336956351995468}, {"id": 143, "seek": 48472, "start": 507.52000000000004, "end": 512.44, "text": " If you don't, no problem, you don't need this crate, but they're very fashionable now.", "tokens": [51504, 759, 291, 500, 380, 11, 572, 1154, 11, 291, 500, 380, 643, 341, 42426, 11, 457, 436, 434, 588, 40735, 586, 13, 51750], "temperature": 0.0, "avg_logprob": -0.22150738008560672, "compression_ratio": 1.8801652892561984, "no_speech_prob": 0.03336956351995468}, {"id": 144, "seek": 51244, "start": 512.44, "end": 517.7600000000001, "text": " There is one crate at least that does this, but we wanted to have something more sophisticated.", "tokens": [50364, 821, 307, 472, 42426, 412, 1935, 300, 775, 341, 11, 457, 321, 1415, 281, 362, 746, 544, 16950, 13, 50630], "temperature": 0.0, "avg_logprob": -0.2720016561528688, "compression_ratio": 1.6051502145922747, "no_speech_prob": 0.08273546397686005}, {"id": 145, "seek": 51244, "start": 517.7600000000001, "end": 522.6800000000001, "text": " So if you're interested in Elias Fano representation of monotone sequences, ranking, selection,", "tokens": [50630, 407, 498, 291, 434, 3102, 294, 16943, 296, 479, 3730, 10290, 295, 1108, 310, 546, 22978, 11, 17833, 11, 9450, 11, 50876], "temperature": 0.0, "avg_logprob": -0.2720016561528688, "compression_ratio": 1.6051502145922747, "no_speech_prob": 0.08273546397686005}, {"id": 146, "seek": 51244, "start": 522.6800000000001, "end": 524.32, "text": " and so on, please have a look.", "tokens": [50876, 293, 370, 322, 11, 1767, 362, 257, 574, 13, 50958], "temperature": 0.0, "avg_logprob": -0.2720016561528688, "compression_ratio": 1.6051502145922747, "no_speech_prob": 0.08273546397686005}, {"id": 147, "seek": 51244, "start": 524.32, "end": 531.36, "text": " This is really getting to existence, but we like to have feedback.", "tokens": [50958, 639, 307, 534, 1242, 281, 9123, 11, 457, 321, 411, 281, 362, 5824, 13, 51310], "temperature": 0.0, "avg_logprob": -0.2720016561528688, "compression_ratio": 1.6051502145922747, "no_speech_prob": 0.08273546397686005}, {"id": 148, "seek": 51244, "start": 531.36, "end": 537.9200000000001, "text": " Fungal piece bit streams, very, very high performance bit stream with read and write", "tokens": [51310, 479, 1063, 304, 2522, 857, 15842, 11, 588, 11, 588, 1090, 3389, 857, 4309, 365, 1401, 293, 2464, 51638], "temperature": 0.0, "avg_logprob": -0.2720016561528688, "compression_ratio": 1.6051502145922747, "no_speech_prob": 0.08273546397686005}, {"id": 149, "seek": 53792, "start": 537.92, "end": 546.0, "text": " by word and support for big and little Indian files and a lot of instantaneous code, gamma,", "tokens": [50364, 538, 1349, 293, 1406, 337, 955, 293, 707, 6427, 7098, 293, 257, 688, 295, 45596, 3089, 11, 15546, 11, 50768], "temperature": 0.0, "avg_logprob": -0.2642105139938055, "compression_ratio": 1.6008064516129032, "no_speech_prob": 0.3461616635322571}, {"id": 150, "seek": 53792, "start": 546.0, "end": 547.4, "text": " gamma, delta, go long, and so on.", "tokens": [50768, 15546, 11, 8289, 11, 352, 938, 11, 293, 370, 322, 13, 50838], "temperature": 0.0, "avg_logprob": -0.2642105139938055, "compression_ratio": 1.6008064516129032, "no_speech_prob": 0.3461616635322571}, {"id": 151, "seek": 53792, "start": 547.4, "end": 552.56, "text": " This is kind of cosy you'd like in MPEG or so on, but we use it to do graph compression", "tokens": [50838, 639, 307, 733, 295, 3792, 88, 291, 1116, 411, 294, 376, 5208, 38, 420, 370, 322, 11, 457, 321, 764, 309, 281, 360, 4295, 19355, 51096], "temperature": 0.0, "avg_logprob": -0.2642105139938055, "compression_ratio": 1.6008064516129032, "no_speech_prob": 0.3461616635322571}, {"id": 152, "seek": 53792, "start": 552.56, "end": 559.76, "text": " and we spend a lot of time to optimize every single shift and move and also to give you", "tokens": [51096, 293, 321, 3496, 257, 688, 295, 565, 281, 19719, 633, 2167, 5513, 293, 1286, 293, 611, 281, 976, 291, 51456], "temperature": 0.0, "avg_logprob": -0.2642105139938055, "compression_ratio": 1.6008064516129032, "no_speech_prob": 0.3461616635322571}, {"id": 153, "seek": 53792, "start": 559.76, "end": 567.1999999999999, "text": " scripts to just run and we massively test all parameters you can configure on your architecture", "tokens": [51456, 23294, 281, 445, 1190, 293, 321, 29379, 1500, 439, 9834, 291, 393, 22162, 322, 428, 9482, 51828], "temperature": 0.0, "avg_logprob": -0.2642105139938055, "compression_ratio": 1.6008064516129032, "no_speech_prob": 0.3461616635322571}, {"id": 154, "seek": 56720, "start": 567.2, "end": 572.5200000000001, "text": " so you can choose how to optimize the speed of the coding and the coding specifically", "tokens": [50364, 370, 291, 393, 2826, 577, 281, 19719, 264, 3073, 295, 264, 17720, 293, 264, 17720, 4682, 50630], "temperature": 0.0, "avg_logprob": -0.20990009098262577, "compression_ratio": 1.6212765957446809, "no_speech_prob": 0.00938272662460804}, {"id": 155, "seek": 56720, "start": 572.5200000000001, "end": 575.72, "text": " on your architecture.", "tokens": [50630, 322, 428, 9482, 13, 50790], "temperature": 0.0, "avg_logprob": -0.20990009098262577, "compression_ratio": 1.6212765957446809, "no_speech_prob": 0.00938272662460804}, {"id": 156, "seek": 56720, "start": 575.72, "end": 581.96, "text": " Like which word size to use to pick up stuff from memory, using the coding tables or not,", "tokens": [50790, 1743, 597, 1349, 2744, 281, 764, 281, 1888, 493, 1507, 490, 4675, 11, 1228, 264, 17720, 8020, 420, 406, 11, 51102], "temperature": 0.0, "avg_logprob": -0.20990009098262577, "compression_ratio": 1.6212765957446809, "no_speech_prob": 0.00938272662460804}, {"id": 157, "seek": 56720, "start": 581.96, "end": 582.96, "text": " and so on.", "tokens": [51102, 293, 370, 322, 13, 51152], "temperature": 0.0, "avg_logprob": -0.20990009098262577, "compression_ratio": 1.6212765957446809, "no_speech_prob": 0.00938272662460804}, {"id": 158, "seek": 56720, "start": 582.96, "end": 588.9200000000001, "text": " And this comes from quite a long experience in doing this with web graph.", "tokens": [51152, 400, 341, 1487, 490, 1596, 257, 938, 1752, 294, 884, 341, 365, 3670, 4295, 13, 51450], "temperature": 0.0, "avg_logprob": -0.20990009098262577, "compression_ratio": 1.6212765957446809, "no_speech_prob": 0.00938272662460804}, {"id": 159, "seek": 56720, "start": 588.9200000000001, "end": 592.48, "text": " So if you're interested in writing this instantaneous code for compression, you should have a look", "tokens": [51450, 407, 498, 291, 434, 3102, 294, 3579, 341, 45596, 3089, 337, 19355, 11, 291, 820, 362, 257, 574, 51628], "temperature": 0.0, "avg_logprob": -0.20990009098262577, "compression_ratio": 1.6212765957446809, "no_speech_prob": 0.00938272662460804}, {"id": 160, "seek": 59248, "start": 592.48, "end": 597.9200000000001, "text": " at this IBS stream just to tell you a gamma code is ready in less than two thousand seconds.", "tokens": [50364, 412, 341, 286, 8176, 4309, 445, 281, 980, 291, 257, 15546, 3089, 307, 1919, 294, 1570, 813, 732, 4714, 3949, 13, 50636], "temperature": 0.0, "avg_logprob": -0.2560107876556088, "compression_ratio": 1.6229508196721312, "no_speech_prob": 0.028938477858901024}, {"id": 161, "seek": 59248, "start": 597.9200000000001, "end": 601.0, "text": " So I think this is pretty nice.", "tokens": [50636, 407, 286, 519, 341, 307, 1238, 1481, 13, 50790], "temperature": 0.0, "avg_logprob": -0.2560107876556088, "compression_ratio": 1.6229508196721312, "no_speech_prob": 0.028938477858901024}, {"id": 162, "seek": 59248, "start": 601.0, "end": 607.5600000000001, "text": " Okay, the last piece which is probably the more specific, so you might less be interested", "tokens": [50790, 1033, 11, 264, 1036, 2522, 597, 307, 1391, 264, 544, 2685, 11, 370, 291, 1062, 1570, 312, 3102, 51118], "temperature": 0.0, "avg_logprob": -0.2560107876556088, "compression_ratio": 1.6229508196721312, "no_speech_prob": 0.028938477858901024}, {"id": 163, "seek": 59248, "start": 607.5600000000001, "end": 609.28, "text": " in is web graph.", "tokens": [51118, 294, 307, 3670, 4295, 13, 51204], "temperature": 0.0, "avg_logprob": -0.2560107876556088, "compression_ratio": 1.6229508196721312, "no_speech_prob": 0.028938477858901024}, {"id": 164, "seek": 59248, "start": 609.28, "end": 614.88, "text": " So web graph is a framework to represent very large graphs in a compressed form.", "tokens": [51204, 407, 3670, 4295, 307, 257, 8388, 281, 2906, 588, 2416, 24877, 294, 257, 30353, 1254, 13, 51484], "temperature": 0.0, "avg_logprob": -0.2560107876556088, "compression_ratio": 1.6229508196721312, "no_speech_prob": 0.028938477858901024}, {"id": 165, "seek": 59248, "start": 614.88, "end": 620.0, "text": " So typically snapshot of the web are represented in about one to two bits per link.", "tokens": [51484, 407, 5850, 30163, 295, 264, 3670, 366, 10379, 294, 466, 472, 281, 732, 9239, 680, 2113, 13, 51740], "temperature": 0.0, "avg_logprob": -0.2560107876556088, "compression_ratio": 1.6229508196721312, "no_speech_prob": 0.028938477858901024}, {"id": 166, "seek": 62000, "start": 620.0, "end": 624.4, "text": " The software heritage graph which is a graph with about half a trillion edges, it's three", "tokens": [50364, 440, 4722, 16040, 4295, 597, 307, 257, 4295, 365, 466, 1922, 257, 18723, 8819, 11, 309, 311, 1045, 50584], "temperature": 0.0, "avg_logprob": -0.2700014495849609, "compression_ratio": 1.6299212598425197, "no_speech_prob": 0.04072464630007744}, {"id": 167, "seek": 62000, "start": 624.4, "end": 629.0, "text": " bits per link, Wikipedia costs 10 bits per link, it depends on the structure of the graph.", "tokens": [50584, 9239, 680, 2113, 11, 28999, 5497, 1266, 9239, 680, 2113, 11, 309, 5946, 322, 264, 3877, 295, 264, 4295, 13, 50814], "temperature": 0.0, "avg_logprob": -0.2700014495849609, "compression_ratio": 1.6299212598425197, "no_speech_prob": 0.04072464630007744}, {"id": 168, "seek": 62000, "start": 629.0, "end": 634.68, "text": " But usually in particular the graph is redundant, you can represent data in 10, 20, even 50", "tokens": [50814, 583, 2673, 294, 1729, 264, 4295, 307, 40997, 11, 291, 393, 2906, 1412, 294, 1266, 11, 945, 11, 754, 2625, 51098], "temperature": 0.0, "avg_logprob": -0.2700014495849609, "compression_ratio": 1.6299212598425197, "no_speech_prob": 0.04072464630007744}, {"id": 169, "seek": 62000, "start": 634.68, "end": 641.6, "text": " times less than you do with a redundant version.", "tokens": [51098, 1413, 1570, 813, 291, 360, 365, 257, 40997, 3037, 13, 51444], "temperature": 0.0, "avg_logprob": -0.2700014495849609, "compression_ratio": 1.6299212598425197, "no_speech_prob": 0.04072464630007744}, {"id": 170, "seek": 62000, "start": 641.6, "end": 646.44, "text": " It's a rough sport of the Java version and of course we use the SIB stream for instantaneous", "tokens": [51444, 467, 311, 257, 5903, 7282, 295, 264, 10745, 3037, 293, 295, 1164, 321, 764, 264, 318, 39081, 4309, 337, 45596, 51686], "temperature": 0.0, "avg_logprob": -0.2700014495849609, "compression_ratio": 1.6299212598425197, "no_speech_prob": 0.04072464630007744}, {"id": 171, "seek": 64644, "start": 646.44, "end": 650.7600000000001, "text": " code and sucks for pointers in the big stream.", "tokens": [50364, 3089, 293, 15846, 337, 44548, 294, 264, 955, 4309, 13, 50580], "temperature": 0.0, "avg_logprob": -0.2382922317042495, "compression_ratio": 1.5541666666666667, "no_speech_prob": 0.07145149260759354}, {"id": 172, "seek": 64644, "start": 650.7600000000001, "end": 655.9200000000001, "text": " And just to give you a very simple example, the software heritage graph is 34 billion", "tokens": [50580, 400, 445, 281, 976, 291, 257, 588, 2199, 1365, 11, 264, 4722, 16040, 4295, 307, 12790, 5218, 50838], "temperature": 0.0, "avg_logprob": -0.2382922317042495, "compression_ratio": 1.5541666666666667, "no_speech_prob": 0.07145149260759354}, {"id": 173, "seek": 64644, "start": 655.9200000000001, "end": 661.6800000000001, "text": " nodes and a little bit more than half a trillion arcs and you can do a BFV visit single thread", "tokens": [50838, 13891, 293, 257, 707, 857, 544, 813, 1922, 257, 18723, 10346, 82, 293, 291, 393, 360, 257, 363, 37, 53, 3441, 2167, 7207, 51126], "temperature": 0.0, "avg_logprob": -0.2382922317042495, "compression_ratio": 1.5541666666666667, "no_speech_prob": 0.07145149260759354}, {"id": 174, "seek": 64644, "start": 661.6800000000001, "end": 664.1600000000001, "text": " in three hours.", "tokens": [51126, 294, 1045, 2496, 13, 51250], "temperature": 0.0, "avg_logprob": -0.2382922317042495, "compression_ratio": 1.5541666666666667, "no_speech_prob": 0.07145149260759354}, {"id": 175, "seek": 64644, "start": 664.1600000000001, "end": 665.32, "text": " It's very nice.", "tokens": [51250, 467, 311, 588, 1481, 13, 51308], "temperature": 0.0, "avg_logprob": -0.2382922317042495, "compression_ratio": 1.5541666666666667, "no_speech_prob": 0.07145149260759354}, {"id": 176, "seek": 64644, "start": 665.32, "end": 671.2, "text": " Okay, you have to notice half a trillion edges.", "tokens": [51308, 1033, 11, 291, 362, 281, 3449, 1922, 257, 18723, 8819, 13, 51602], "temperature": 0.0, "avg_logprob": -0.2382922317042495, "compression_ratio": 1.5541666666666667, "no_speech_prob": 0.07145149260759354}, {"id": 177, "seek": 64644, "start": 671.2, "end": 674.7600000000001, "text": " The ergonomics of the whole thing is incredibly better than Java.", "tokens": [51602, 440, 42735, 29884, 295, 264, 1379, 551, 307, 6252, 1101, 813, 10745, 13, 51780], "temperature": 0.0, "avg_logprob": -0.2382922317042495, "compression_ratio": 1.5541666666666667, "no_speech_prob": 0.07145149260759354}, {"id": 178, "seek": 67476, "start": 674.76, "end": 679.96, "text": " Just having real iterators changes completely the game because it's much more natural that", "tokens": [50364, 1449, 1419, 957, 17138, 3391, 2962, 2584, 264, 1216, 570, 309, 311, 709, 544, 3303, 300, 50624], "temperature": 0.0, "avg_logprob": -0.23088895797729492, "compression_ratio": 1.5823293172690762, "no_speech_prob": 0.2011508345603943}, {"id": 179, "seek": 67476, "start": 679.96, "end": 681.48, "text": " what we had.", "tokens": [50624, 437, 321, 632, 13, 50700], "temperature": 0.0, "avg_logprob": -0.23088895797729492, "compression_ratio": 1.5823293172690762, "no_speech_prob": 0.2011508345603943}, {"id": 180, "seek": 67476, "start": 681.48, "end": 687.28, "text": " And this is all the others are crates that you can download and use that are pretty stable.", "tokens": [50700, 400, 341, 307, 439, 264, 2357, 366, 941, 1024, 300, 291, 393, 5484, 293, 764, 300, 366, 1238, 8351, 13, 50990], "temperature": 0.0, "avg_logprob": -0.23088895797729492, "compression_ratio": 1.5823293172690762, "no_speech_prob": 0.2011508345603943}, {"id": 181, "seek": 67476, "start": 687.28, "end": 691.48, "text": " This is still on GitHub because it's a lot of code, a lot of optimization.", "tokens": [50990, 639, 307, 920, 322, 23331, 570, 309, 311, 257, 688, 295, 3089, 11, 257, 688, 295, 19618, 13, 51200], "temperature": 0.0, "avg_logprob": -0.23088895797729492, "compression_ratio": 1.5823293172690762, "no_speech_prob": 0.2011508345603943}, {"id": 182, "seek": 67476, "start": 691.48, "end": 697.72, "text": " We just merged into main the last big chunk of modification, the API should be stable", "tokens": [51200, 492, 445, 36427, 666, 2135, 264, 1036, 955, 16635, 295, 26747, 11, 264, 9362, 820, 312, 8351, 51512], "temperature": 0.0, "avg_logprob": -0.23088895797729492, "compression_ratio": 1.5823293172690762, "no_speech_prob": 0.2011508345603943}, {"id": 183, "seek": 67476, "start": 697.72, "end": 698.92, "text": " by now.", "tokens": [51512, 538, 586, 13, 51572], "temperature": 0.0, "avg_logprob": -0.23088895797729492, "compression_ratio": 1.5823293172690762, "no_speech_prob": 0.2011508345603943}, {"id": 184, "seek": 67476, "start": 698.92, "end": 700.04, "text": " But this is very specialized.", "tokens": [51572, 583, 341, 307, 588, 19813, 13, 51628], "temperature": 0.0, "avg_logprob": -0.23088895797729492, "compression_ratio": 1.5823293172690762, "no_speech_prob": 0.2011508345603943}, {"id": 185, "seek": 70004, "start": 700.04, "end": 705.04, "text": " I mean unless you have graphs with hundreds of billions, half a trillion arcs, for instance,", "tokens": [50364, 286, 914, 5969, 291, 362, 24877, 365, 6779, 295, 17375, 11, 1922, 257, 18723, 10346, 82, 11, 337, 5197, 11, 50614], "temperature": 0.0, "avg_logprob": -0.19746311290844068, "compression_ratio": 1.7471698113207548, "no_speech_prob": 0.026100214570760727}, {"id": 186, "seek": 70004, "start": 705.04, "end": 711.76, "text": " this biologist did this huge data set with a trillion protein-protein similarity edges", "tokens": [50614, 341, 3228, 9201, 630, 341, 2603, 1412, 992, 365, 257, 18723, 7944, 12, 1424, 1370, 259, 32194, 8819, 50950], "temperature": 0.0, "avg_logprob": -0.19746311290844068, "compression_ratio": 1.7471698113207548, "no_speech_prob": 0.026100214570760727}, {"id": 187, "seek": 70004, "start": 711.76, "end": 715.3199999999999, "text": " and they did it with web graph because if you need a trillion edge and you need to distribute", "tokens": [50950, 293, 436, 630, 309, 365, 3670, 4295, 570, 498, 291, 643, 257, 18723, 4691, 293, 291, 643, 281, 20594, 51128], "temperature": 0.0, "avg_logprob": -0.19746311290844068, "compression_ratio": 1.7471698113207548, "no_speech_prob": 0.026100214570760727}, {"id": 188, "seek": 70004, "start": 715.3199999999999, "end": 721.12, "text": " it and analyze it on a standard hardware, not a massive supercomputer, you do it using", "tokens": [51128, 309, 293, 12477, 309, 322, 257, 3832, 8837, 11, 406, 257, 5994, 36708, 11, 291, 360, 309, 1228, 51418], "temperature": 0.0, "avg_logprob": -0.19746311290844068, "compression_ratio": 1.7471698113207548, "no_speech_prob": 0.026100214570760727}, {"id": 189, "seek": 70004, "start": 721.12, "end": 723.3199999999999, "text": " compression.", "tokens": [51418, 19355, 13, 51528], "temperature": 0.0, "avg_logprob": -0.19746311290844068, "compression_ratio": 1.7471698113207548, "no_speech_prob": 0.026100214570760727}, {"id": 190, "seek": 70004, "start": 723.3199999999999, "end": 727.4399999999999, "text": " There is also support for labels on the edges that you can enumerate and it's much better", "tokens": [51528, 821, 307, 611, 1406, 337, 16949, 322, 264, 8819, 300, 291, 393, 465, 15583, 473, 293, 309, 311, 709, 1101, 51734], "temperature": 0.0, "avg_logprob": -0.19746311290844068, "compression_ratio": 1.7471698113207548, "no_speech_prob": 0.026100214570760727}, {"id": 191, "seek": 72744, "start": 727.44, "end": 732.8800000000001, "text": " in the new version than in the old one.", "tokens": [50364, 294, 264, 777, 3037, 813, 294, 264, 1331, 472, 13, 50636], "temperature": 0.0, "avg_logprob": -0.2211246257875024, "compression_ratio": 1.528497409326425, "no_speech_prob": 0.24201151728630066}, {"id": 192, "seek": 72744, "start": 732.8800000000001, "end": 737.7600000000001, "text": " And one thing that we had to fight a lot against is lenders.", "tokens": [50636, 400, 472, 551, 300, 321, 632, 281, 2092, 257, 688, 1970, 307, 287, 16292, 13, 50880], "temperature": 0.0, "avg_logprob": -0.2211246257875024, "compression_ratio": 1.528497409326425, "no_speech_prob": 0.24201151728630066}, {"id": 193, "seek": 72744, "start": 737.7600000000001, "end": 742.1600000000001, "text": " So if you're familiar, I don't feel familiar with a lender idea.", "tokens": [50880, 407, 498, 291, 434, 4963, 11, 286, 500, 380, 841, 4963, 365, 257, 47500, 1558, 13, 51100], "temperature": 0.0, "avg_logprob": -0.2211246257875024, "compression_ratio": 1.528497409326425, "no_speech_prob": 0.24201151728630066}, {"id": 194, "seek": 72744, "start": 742.1600000000001, "end": 746.9200000000001, "text": " It's generally an idea and a number of crates for Rust.", "tokens": [51100, 467, 311, 5101, 364, 1558, 293, 257, 1230, 295, 941, 1024, 337, 34952, 13, 51338], "temperature": 0.0, "avg_logprob": -0.2211246257875024, "compression_ratio": 1.528497409326425, "no_speech_prob": 0.24201151728630066}, {"id": 195, "seek": 72744, "start": 746.9200000000001, "end": 754.2, "text": " Lenders are iterators whose return object depends on the iterator itself.", "tokens": [51338, 441, 16292, 366, 17138, 3391, 6104, 2736, 2657, 5946, 322, 264, 17138, 1639, 2564, 13, 51702], "temperature": 0.0, "avg_logprob": -0.2211246257875024, "compression_ratio": 1.528497409326425, "no_speech_prob": 0.24201151728630066}, {"id": 196, "seek": 75420, "start": 754.2, "end": 759.24, "text": " So iterators in Rust are thoughts that give you values and you can take the values and", "tokens": [50364, 407, 17138, 3391, 294, 34952, 366, 4598, 300, 976, 291, 4190, 293, 291, 393, 747, 264, 4190, 293, 50616], "temperature": 0.0, "avg_logprob": -0.1379543753231273, "compression_ratio": 1.7234848484848484, "no_speech_prob": 0.1320389062166214}, {"id": 197, "seek": 75420, "start": 759.24, "end": 760.24, "text": " use them.", "tokens": [50616, 764, 552, 13, 50666], "temperature": 0.0, "avg_logprob": -0.1379543753231273, "compression_ratio": 1.7234848484848484, "no_speech_prob": 0.1320389062166214}, {"id": 198, "seek": 75420, "start": 760.24, "end": 765.36, "text": " But in all this kind of batch processing for graphs, you iterate on the graph and you cannot", "tokens": [50666, 583, 294, 439, 341, 733, 295, 15245, 9007, 337, 24877, 11, 291, 44497, 322, 264, 4295, 293, 291, 2644, 50922], "temperature": 0.0, "avg_logprob": -0.1379543753231273, "compression_ratio": 1.7234848484848484, "no_speech_prob": 0.1320389062166214}, {"id": 199, "seek": 75420, "start": 765.36, "end": 767.32, "text": " look at two nodes at the same time.", "tokens": [50922, 574, 412, 732, 13891, 412, 264, 912, 565, 13, 51020], "temperature": 0.0, "avg_logprob": -0.1379543753231273, "compression_ratio": 1.7234848484848484, "no_speech_prob": 0.1320389062166214}, {"id": 200, "seek": 75420, "start": 767.32, "end": 771.72, "text": " There is a sequential iteration which goes through a file or a sorting of labels.", "tokens": [51020, 821, 307, 257, 42881, 24784, 597, 1709, 807, 257, 3991, 420, 257, 32411, 295, 16949, 13, 51240], "temperature": 0.0, "avg_logprob": -0.1379543753231273, "compression_ratio": 1.7234848484848484, "no_speech_prob": 0.1320389062166214}, {"id": 201, "seek": 75420, "start": 771.72, "end": 777.0, "text": " So you need to be able to say, okay, this is the next batch of successor, use it, but I", "tokens": [51240, 407, 291, 643, 281, 312, 1075, 281, 584, 11, 1392, 11, 341, 307, 264, 958, 15245, 295, 31864, 11, 764, 309, 11, 457, 286, 51504], "temperature": 0.0, "avg_logprob": -0.1379543753231273, "compression_ratio": 1.7234848484848484, "no_speech_prob": 0.1320389062166214}, {"id": 202, "seek": 75420, "start": 777.0, "end": 780.96, "text": " won't give you the next one until you finish with this one.", "tokens": [51504, 1582, 380, 976, 291, 264, 958, 472, 1826, 291, 2413, 365, 341, 472, 13, 51702], "temperature": 0.0, "avg_logprob": -0.1379543753231273, "compression_ratio": 1.7234848484848484, "no_speech_prob": 0.1320389062166214}, {"id": 203, "seek": 78096, "start": 780.96, "end": 785.4000000000001, "text": " To do this, you need to use essentially generic associated type.", "tokens": [50364, 1407, 360, 341, 11, 291, 643, 281, 764, 4476, 19577, 6615, 2010, 13, 50586], "temperature": 0.0, "avg_logprob": -0.16386117287052487, "compression_ratio": 1.6050420168067228, "no_speech_prob": 0.09077702462673187}, {"id": 204, "seek": 78096, "start": 785.4000000000001, "end": 786.4000000000001, "text": " Not really that.", "tokens": [50586, 1726, 534, 300, 13, 50636], "temperature": 0.0, "avg_logprob": -0.16386117287052487, "compression_ratio": 1.6050420168067228, "no_speech_prob": 0.09077702462673187}, {"id": 205, "seek": 78096, "start": 786.4000000000001, "end": 788.8000000000001, "text": " We use higher order trade bounds.", "tokens": [50636, 492, 764, 2946, 1668, 4923, 29905, 13, 50756], "temperature": 0.0, "avg_logprob": -0.16386117287052487, "compression_ratio": 1.6050420168067228, "no_speech_prob": 0.09077702462673187}, {"id": 206, "seek": 78096, "start": 788.8000000000001, "end": 796.1600000000001, "text": " But you need to impose that each call to next can be made only when the previous one went", "tokens": [50756, 583, 291, 643, 281, 26952, 300, 1184, 818, 281, 958, 393, 312, 1027, 787, 562, 264, 3894, 472, 1437, 51124], "temperature": 0.0, "avg_logprob": -0.16386117287052487, "compression_ratio": 1.6050420168067228, "no_speech_prob": 0.09077702462673187}, {"id": 207, "seek": 78096, "start": 796.1600000000001, "end": 797.1600000000001, "text": " out of scope.", "tokens": [51124, 484, 295, 11923, 13, 51174], "temperature": 0.0, "avg_logprob": -0.16386117287052487, "compression_ratio": 1.6050420168067228, "no_speech_prob": 0.09077702462673187}, {"id": 208, "seek": 78096, "start": 797.1600000000001, "end": 800.32, "text": " So you cannot do two calls to next in a row.", "tokens": [51174, 407, 291, 2644, 360, 732, 5498, 281, 958, 294, 257, 5386, 13, 51332], "temperature": 0.0, "avg_logprob": -0.16386117287052487, "compression_ratio": 1.6050420168067228, "no_speech_prob": 0.09077702462673187}, {"id": 209, "seek": 78096, "start": 800.32, "end": 802.8000000000001, "text": " And this is called a lender.", "tokens": [51332, 400, 341, 307, 1219, 257, 47500, 13, 51456], "temperature": 0.0, "avg_logprob": -0.16386117287052487, "compression_ratio": 1.6050420168067228, "no_speech_prob": 0.09077702462673187}, {"id": 210, "seek": 78096, "start": 802.8000000000001, "end": 808.84, "text": " There are a few crates that implement lenders now which have, say, almost feature parity", "tokens": [51456, 821, 366, 257, 1326, 941, 1024, 300, 4445, 287, 16292, 586, 597, 362, 11, 584, 11, 1920, 4111, 44747, 51758], "temperature": 0.0, "avg_logprob": -0.16386117287052487, "compression_ratio": 1.6050420168067228, "no_speech_prob": 0.09077702462673187}, {"id": 211, "seek": 80884, "start": 808.84, "end": 816.2, "text": " with iterator, but the fact is that presently they work because of bug in the borrower", "tokens": [50364, 365, 17138, 1639, 11, 457, 264, 1186, 307, 300, 1974, 356, 436, 589, 570, 295, 7426, 294, 264, 14828, 81, 968, 50732], "temperature": 0.0, "avg_logprob": -0.20442847795383903, "compression_ratio": 1.6435643564356435, "no_speech_prob": 0.06919365376234055}, {"id": 212, "seek": 80884, "start": 816.2, "end": 817.2, "text": " checker.", "tokens": [50732, 1520, 260, 13, 50782], "temperature": 0.0, "avg_logprob": -0.20442847795383903, "compression_ratio": 1.6435643564356435, "no_speech_prob": 0.06919365376234055}, {"id": 213, "seek": 80884, "start": 817.2, "end": 822.88, "text": " So the borrower checker doesn't check certain things that if fixed would make all these", "tokens": [50782, 407, 264, 14828, 81, 968, 1520, 260, 1177, 380, 1520, 1629, 721, 300, 498, 6806, 576, 652, 439, 613, 51066], "temperature": 0.0, "avg_logprob": -0.20442847795383903, "compression_ratio": 1.6435643564356435, "no_speech_prob": 0.06919365376234055}, {"id": 214, "seek": 80884, "start": 822.88, "end": 825.0, "text": " lender crates not work.", "tokens": [51066, 47500, 941, 1024, 406, 589, 13, 51172], "temperature": 0.0, "avg_logprob": -0.20442847795383903, "compression_ratio": 1.6435643564356435, "no_speech_prob": 0.06919365376234055}, {"id": 215, "seek": 80884, "start": 825.0, "end": 830.36, "text": " And at that point, we would be in really deep shit because we have no idea how to do this", "tokens": [51172, 400, 412, 300, 935, 11, 321, 576, 312, 294, 534, 2452, 4611, 570, 321, 362, 572, 1558, 577, 281, 360, 341, 51440], "temperature": 0.0, "avg_logprob": -0.20442847795383903, "compression_ratio": 1.6435643564356435, "no_speech_prob": 0.06919365376234055}, {"id": 216, "seek": 80884, "start": 830.36, "end": 832.44, "text": " other than the way we're doing it.", "tokens": [51440, 661, 813, 264, 636, 321, 434, 884, 309, 13, 51544], "temperature": 0.0, "avg_logprob": -0.20442847795383903, "compression_ratio": 1.6435643564356435, "no_speech_prob": 0.06919365376234055}, {"id": 217, "seek": 83244, "start": 832.44, "end": 839.9200000000001, "text": " In fact, we're even in a situation where we have a chain of an iterator returning iterators", "tokens": [50364, 682, 1186, 11, 321, 434, 754, 294, 257, 2590, 689, 321, 362, 257, 5021, 295, 364, 17138, 1639, 12678, 17138, 3391, 50738], "temperature": 0.0, "avg_logprob": -0.2342963863063503, "compression_ratio": 1.6381322957198443, "no_speech_prob": 0.0616072453558445}, {"id": 218, "seek": 83244, "start": 839.9200000000001, "end": 842.8000000000001, "text": " and the final value depend on state on the initials thing.", "tokens": [50738, 293, 264, 2572, 2158, 5672, 322, 1785, 322, 264, 5883, 82, 551, 13, 50882], "temperature": 0.0, "avg_logprob": -0.2342963863063503, "compression_ratio": 1.6381322957198443, "no_speech_prob": 0.0616072453558445}, {"id": 219, "seek": 83244, "start": 842.8000000000001, "end": 848.5600000000001, "text": " So there is a propagation of bounds of on lifetime that goes through two different types.", "tokens": [50882, 407, 456, 307, 257, 38377, 295, 29905, 295, 322, 11364, 300, 1709, 807, 732, 819, 3467, 13, 51170], "temperature": 0.0, "avg_logprob": -0.2342963863063503, "compression_ratio": 1.6381322957198443, "no_speech_prob": 0.0616072453558445}, {"id": 220, "seek": 83244, "start": 848.5600000000001, "end": 851.44, "text": " And that gives me headache each time I look at it.", "tokens": [51170, 400, 300, 2709, 385, 23520, 1184, 565, 286, 574, 412, 309, 13, 51314], "temperature": 0.0, "avg_logprob": -0.2342963863063503, "compression_ratio": 1.6381322957198443, "no_speech_prob": 0.0616072453558445}, {"id": 221, "seek": 83244, "start": 851.44, "end": 852.72, "text": " And in fact, I didn't even invent it.", "tokens": [51314, 400, 294, 1186, 11, 286, 994, 380, 754, 7962, 309, 13, 51378], "temperature": 0.0, "avg_logprob": -0.2342963863063503, "compression_ratio": 1.6381322957198443, "no_speech_prob": 0.0616072453558445}, {"id": 222, "seek": 83244, "start": 852.72, "end": 856.48, "text": " I asked on Rust forum and they said, I have this completely crazy situation.", "tokens": [51378, 286, 2351, 322, 34952, 17542, 293, 436, 848, 11, 286, 362, 341, 2584, 3219, 2590, 13, 51566], "temperature": 0.0, "avg_logprob": -0.2342963863063503, "compression_ratio": 1.6381322957198443, "no_speech_prob": 0.0616072453558445}, {"id": 223, "seek": 83244, "start": 856.48, "end": 857.48, "text": " What can I do?", "tokens": [51566, 708, 393, 286, 360, 30, 51616], "temperature": 0.0, "avg_logprob": -0.2342963863063503, "compression_ratio": 1.6381322957198443, "no_speech_prob": 0.0616072453558445}, {"id": 224, "seek": 85748, "start": 857.48, "end": 863.52, "text": " And a very nice guy wrote a type like this with 25 different implied type bounds and now", "tokens": [50364, 400, 257, 588, 1481, 2146, 4114, 257, 2010, 411, 341, 365, 3552, 819, 32614, 2010, 29905, 293, 586, 50666], "temperature": 0.0, "avg_logprob": -0.1638834058623953, "compression_ratio": 1.6160337552742616, "no_speech_prob": 0.043940186500549316}, {"id": 225, "seek": 85748, "start": 863.52, "end": 864.52, "text": " it works.", "tokens": [50666, 309, 1985, 13, 50716], "temperature": 0.0, "avg_logprob": -0.1638834058623953, "compression_ratio": 1.6160337552742616, "no_speech_prob": 0.043940186500549316}, {"id": 226, "seek": 85748, "start": 864.52, "end": 866.72, "text": " But let's hope it continues to work.", "tokens": [50716, 583, 718, 311, 1454, 309, 6515, 281, 589, 13, 50826], "temperature": 0.0, "avg_logprob": -0.1638834058623953, "compression_ratio": 1.6160337552742616, "no_speech_prob": 0.043940186500549316}, {"id": 227, "seek": 85748, "start": 866.72, "end": 872.28, "text": " But this is just to say we need a little bit more borrowing in Rust than there is now to", "tokens": [50826, 583, 341, 307, 445, 281, 584, 321, 643, 257, 707, 857, 544, 35024, 294, 34952, 813, 456, 307, 586, 281, 51104], "temperature": 0.0, "avg_logprob": -0.1638834058623953, "compression_ratio": 1.6160337552742616, "no_speech_prob": 0.043940186500549316}, {"id": 228, "seek": 85748, "start": 872.28, "end": 876.9200000000001, "text": " make this work properly because it has been a little bit of a pain to get something like", "tokens": [51104, 652, 341, 589, 6108, 570, 309, 575, 668, 257, 707, 857, 295, 257, 1822, 281, 483, 746, 411, 51336], "temperature": 0.0, "avg_logprob": -0.1638834058623953, "compression_ratio": 1.6160337552742616, "no_speech_prob": 0.043940186500549316}, {"id": 229, "seek": 85748, "start": 876.9200000000001, "end": 883.96, "text": " an iterator in which the return value depend on the iterating object.", "tokens": [51336, 364, 17138, 1639, 294, 597, 264, 2736, 2158, 5672, 322, 264, 17138, 990, 2657, 13, 51688], "temperature": 0.0, "avg_logprob": -0.1638834058623953, "compression_ratio": 1.6160337552742616, "no_speech_prob": 0.043940186500549316}, {"id": 230, "seek": 88396, "start": 883.96, "end": 890.6800000000001, "text": " In the last thing, if anybody know how to get one thing done, index get.", "tokens": [50364, 682, 264, 1036, 551, 11, 498, 4472, 458, 577, 281, 483, 472, 551, 1096, 11, 8186, 483, 13, 50700], "temperature": 0.0, "avg_logprob": -0.19277459177477607, "compression_ratio": 1.7796610169491525, "no_speech_prob": 0.1119997650384903}, {"id": 231, "seek": 88396, "start": 890.6800000000001, "end": 897.88, "text": " Since 2015, it's been sitting in the issues of Rust to have an index trait that gives", "tokens": [50700, 4162, 7546, 11, 309, 311, 668, 3798, 294, 264, 2663, 295, 34952, 281, 362, 364, 8186, 22538, 300, 2709, 51060], "temperature": 0.0, "avg_logprob": -0.19277459177477607, "compression_ratio": 1.7796610169491525, "no_speech_prob": 0.1119997650384903}, {"id": 232, "seek": 88396, "start": 897.88, "end": 900.2800000000001, "text": " you a value, not a reference.", "tokens": [51060, 291, 257, 2158, 11, 406, 257, 6408, 13, 51180], "temperature": 0.0, "avg_logprob": -0.19277459177477607, "compression_ratio": 1.7796610169491525, "no_speech_prob": 0.1119997650384903}, {"id": 233, "seek": 88396, "start": 900.2800000000001, "end": 901.5600000000001, "text": " Because index give you a reference.", "tokens": [51180, 1436, 8186, 976, 291, 257, 6408, 13, 51244], "temperature": 0.0, "avg_logprob": -0.19277459177477607, "compression_ratio": 1.7796610169491525, "no_speech_prob": 0.1119997650384903}, {"id": 234, "seek": 88396, "start": 901.5600000000001, "end": 904.76, "text": " Now, index give you a reference is fine.", "tokens": [51244, 823, 11, 8186, 976, 291, 257, 6408, 307, 2489, 13, 51404], "temperature": 0.0, "avg_logprob": -0.19277459177477607, "compression_ratio": 1.7796610169491525, "no_speech_prob": 0.1119997650384903}, {"id": 235, "seek": 88396, "start": 904.76, "end": 910.1600000000001, "text": " But if you do compress, succinct, any kind of implicit data structure, index giving you", "tokens": [51404, 583, 498, 291, 360, 14778, 11, 21578, 5460, 11, 604, 733, 295, 26947, 1412, 3877, 11, 8186, 2902, 291, 51674], "temperature": 0.0, "avg_logprob": -0.19277459177477607, "compression_ratio": 1.7796610169491525, "no_speech_prob": 0.1119997650384903}, {"id": 236, "seek": 88396, "start": 910.1600000000001, "end": 912.44, "text": " a reference is a pain in the ass.", "tokens": [51674, 257, 6408, 307, 257, 1822, 294, 264, 1256, 13, 51788], "temperature": 0.0, "avg_logprob": -0.19277459177477607, "compression_ratio": 1.7796610169491525, "no_speech_prob": 0.1119997650384903}, {"id": 237, "seek": 88396, "start": 912.44, "end": 913.8000000000001, "text": " Because you don't have the data.", "tokens": [51788, 1436, 291, 500, 380, 362, 264, 1412, 13, 51856], "temperature": 0.0, "avg_logprob": -0.19277459177477607, "compression_ratio": 1.7796610169491525, "no_speech_prob": 0.1119997650384903}, {"id": 238, "seek": 91380, "start": 913.8, "end": 914.8, "text": " They are implicitly represented.", "tokens": [50364, 814, 366, 26947, 356, 10379, 13, 50414], "temperature": 0.0, "avg_logprob": -0.2378271914076531, "compression_ratio": 1.5296803652968036, "no_speech_prob": 0.039209429174661636}, {"id": 239, "seek": 91380, "start": 914.8, "end": 921.4, "text": " You need the trait that giving two nice square brackets will give a value, not a reference.", "tokens": [50414, 509, 643, 264, 22538, 300, 2902, 732, 1481, 3732, 26179, 486, 976, 257, 2158, 11, 406, 257, 6408, 13, 50744], "temperature": 0.0, "avg_logprob": -0.2378271914076531, "compression_ratio": 1.5296803652968036, "no_speech_prob": 0.039209429174661636}, {"id": 240, "seek": 91380, "start": 921.4, "end": 925.68, "text": " And then you can enter the world of modern implicit data structure.", "tokens": [50744, 400, 550, 291, 393, 3242, 264, 1002, 295, 4363, 26947, 1412, 3877, 13, 50958], "temperature": 0.0, "avg_logprob": -0.2378271914076531, "compression_ratio": 1.5296803652968036, "no_speech_prob": 0.039209429174661636}, {"id": 241, "seek": 91380, "start": 925.68, "end": 930.28, "text": " So if you know anybody who can implement this, convince someone in compiler team to get done", "tokens": [50958, 407, 498, 291, 458, 4472, 567, 393, 4445, 341, 11, 13447, 1580, 294, 31958, 1469, 281, 483, 1096, 51188], "temperature": 0.0, "avg_logprob": -0.2378271914076531, "compression_ratio": 1.5296803652968036, "no_speech_prob": 0.039209429174661636}, {"id": 242, "seek": 91380, "start": 930.28, "end": 931.7199999999999, "text": " with this, you please do it.", "tokens": [51188, 365, 341, 11, 291, 1767, 360, 309, 13, 51260], "temperature": 0.0, "avg_logprob": -0.2378271914076531, "compression_ratio": 1.5296803652968036, "no_speech_prob": 0.039209429174661636}, {"id": 243, "seek": 91380, "start": 931.7199999999999, "end": 932.7199999999999, "text": " I'm over.", "tokens": [51260, 286, 478, 670, 13, 51310], "temperature": 0.0, "avg_logprob": -0.2378271914076531, "compression_ratio": 1.5296803652968036, "no_speech_prob": 0.039209429174661636}, {"id": 244, "seek": 91380, "start": 932.7199999999999, "end": 933.7199999999999, "text": " Thank you.", "tokens": [51310, 1044, 291, 13, 51360], "temperature": 0.0, "avg_logprob": -0.2378271914076531, "compression_ratio": 1.5296803652968036, "no_speech_prob": 0.039209429174661636}, {"id": 245, "seek": 93372, "start": 933.72, "end": 945.72, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 50964], "temperature": 0.0, "avg_logprob": -0.8696649074554443, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.9538348317146301}], "language": "en"}