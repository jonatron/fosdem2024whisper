{"text": " Hello. This talk is about collaboration with Julia from India. Before this collaboration I was alone and I was left in a room with 100,000 lines of C code which had to remain C and had to be optimized somehow. How many of you here ever had such a situation? Perhaps somebody? One, two, three, perhaps more. Good. And usually, well, you understand that this was not my code, so I had to modify it. It was the code from people, from many people who worked in bars and produced code which had a lot of loops which do number crunching. Those loops have touch numerical quantities and actually had a kind of structure that you see here. You might recognize. So the layout, the data layout here is called array of structures. So who would say, oh, I have an optimization for this case from your mind. Which is this optimization? The most obvious one. So shout. Okay. It's my role to say it. Well, to change the layout into not, sorry, arrays of structures, but structures of arrays. So this is like a transposition but brings like an improvement in performance of, let's say, two, three, four, depending a bit on many conditions. So changing the layout of the code and also the expressions from what you see here to what you see here might have such a positive effect on performance. But how to do this if you have 100,000 lines of C code which has to stay C? Do you cobble together a few scripts? Yeah, why not? But perhaps you then come at some point whining that doesn't work. So you revert to, oh, you revert perhaps to using some high level transpiler. Yes, perhaps, but it's complicated. Well, I went that way. But I chosen another transpiler which is called coxinell. Coxinell has been written with the idea of matching, so finding bugs in the C code of the Linux kernel and erasing those bugs. But I found out that coxinell, I think, was also a good tool for factoring large amounts of C code, especially in manipulating expressions within statements. So expressions, once they are matched in statements, can be also changed. So coxinell has this pattern language that you see here, which is not in terms of patterns of text. Those patterns are in terms of the abstract syntax tree, which gets built on the top of syntactical elements of the C language, which are being, which is being parsed here. And those entities, the syntactical entities of the C language are of, you have control of them. So let's look at this key slide here. So we identify, match identifiers, tree identifiers, and we also give constraints. Like the first identifier Q, which can occur in the code, has to be, has to look like PRSR. The second one has to be P. The third one can be one of those two ones. So it's like you give constraints that has to be respected. And then the red line here, the minus line, which you see here, has to be found in the code. In the arbitrarily complex expressions or statements, such a form must be found. And once such a form is being found, only then such a change occurs. So you see this change? It's also expressed in terms of what has been already found. So you can be very precise if you want. And what you see here on the right panel is an entire program without, with one line changed from what you see here, red to what you see here, blue. So this is, of course, construed example to show you that this teeny rule here can syntactically go over your arbitrary large code and do really a lot of changes here. The complicated part comes if you want to be, if your code doesn't have regularities, so it's messy. But yeah, but if it's tidy enough, you can do a lot of things. And we're working on new HPC oriented features in coxinell in this system. So what does HPC revolves around nowadays? GPUs, modern C++ and modern OpenMP. So this is what we target. And these are three slides now I will be showing you just to give you a taste of some key elements we have been putting in the last times. So if you know the CUDA from NVIDIA, API or language extensions, then you will recognize that here we have some keywords, some the Chevron, kernel, call syntax, which we support. So this is not standard C or C++. We're supporting this. So we're putting this language support into the coxinell tool to allow you perhaps to change your existing code. So to write rules on your huge code, because if it would not be huge, you would be doing this by hand, right? But if it's huge, you want a tool for power, for the factoring. And this is what we want to provide you. To, yeah, to derive perhaps a CUDA kernel code from your CPU code. If you have in mind the regularities and the changes that you need, and you can express them with this language, I like C++ 23 introduces multi-index operators with square brackets, for instance. So this is now also possible if it's of use. It can be of use, for instance, with cocos heavily. So this can help you to transition perhaps to cocos if you really want. And just to, again, I want to, these are expressions and they act on statements. So you have to imagine that this can occur in arbitrarily nested statements. So complicated thing is like the one that you have seen at the beginning of the presentation. And it's up to you to create like chains of rules, which express the logical dependencies between the things which you want to match and the things which you want to introduce in the code. So if the code is messy, it will be more difficult. If your code is tidy enough, you can do extremely powerful things like also experiments with performance. Let's say, oh, what happens if I change in my entire code base from this style of arranging things, and this this style of arranging things. Then such experiments might be enabled here. And perhaps you don't, you're not perhaps obliged into using overly complicated APIs from portable, yeah, from some vendors. Yes. So, oh, sorry. One last example slide. You can even use coxinell to declutter code. So here we are removing hand unrolled code. So such a pattern recognizes, but I mean, I have written on purpose, recognize some hand unrolled code, removes it, and just introduce one pragma from openMP, which says, hey, unroll this. And this is a standardized pragma. So it's not like GCC, unroll, Intel, unroll. No. This is finally, since a couple of years, we have this pragma. So let's say, if you know how to declutter your code, you have rules in your head, you can implement them here, and have some formal, an informal method for restructuring your code. Good. So you know what we are doing lately. So we are developing further material and use cases, language support, some small things and large things. And yeah, that's it. So this work has been supported by the Gauss Supercomputing Center project, by a collaboration between Bavarian Germany and France. And if you are tough, you will go through this tutorial, which I created a few years ago. Yeah, and you can stay tuned with our developments with Coxinell, or you can also come to W\u00fcrzburg in one month to attend our short introductory tutorial into Coxinell. And if you want to read our six-page use case article, I really recommend it because it's more deductical than this 10-minute lightning talk. That's everything. Thank you very much, Michele. We have time for one question. JP in the back, again. Thank you so much. Hey, cool talk. Great, great thing. I love Coxinell. I have it right on the top of my list that I want to work with. The question is, can I express more constraints than just symbols and identifiers in these rules, like types or like lexical things? So what are the things that I can express in terms of this rule should only apply if? So for sure, context? So whatever you write as context, it gets matched. But if it comes to the rule part of those patches, which we have seen, the top part, you have seen identifier and something. Yeah, you have also type and other words for function parameters, for positions, for symbols. So there are a lot of them. And the important part is that the code is being parsed in the first place. Because once we support your language constructs, we parse your code, then you write a rule which can be, which is really the code which we have to match. So Coxinell is different parsers. It has different parsers. We parse your code first, we parse the root first, and then we look for a match. We are able to parse that. Any construct can be modified. This is the point. Any construct. So even within a template, you want to change something systematically. Yes. Okay, cool. Yes, thank you. Okay, we're doing", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 14.88, "text": " Hello. This talk is about collaboration with Julia from India. Before this collaboration", "tokens": [50364, 2425, 13, 639, 751, 307, 466, 9363, 365, 18551, 490, 5282, 13, 4546, 341, 9363, 51108], "temperature": 0.0, "avg_logprob": -0.3022747039794922, "compression_ratio": 1.3488372093023255, "no_speech_prob": 0.3949674069881439}, {"id": 1, "seek": 0, "start": 14.88, "end": 24.04, "text": " I was alone and I was left in a room with 100,000 lines of C code which had to remain", "tokens": [51108, 286, 390, 3312, 293, 286, 390, 1411, 294, 257, 1808, 365, 2319, 11, 1360, 3876, 295, 383, 3089, 597, 632, 281, 6222, 51566], "temperature": 0.0, "avg_logprob": -0.3022747039794922, "compression_ratio": 1.3488372093023255, "no_speech_prob": 0.3949674069881439}, {"id": 2, "seek": 2404, "start": 24.04, "end": 32.48, "text": " C and had to be optimized somehow. How many of you here ever had such a situation? Perhaps", "tokens": [50364, 383, 293, 632, 281, 312, 26941, 6063, 13, 1012, 867, 295, 291, 510, 1562, 632, 1270, 257, 2590, 30, 10517, 50786], "temperature": 0.0, "avg_logprob": -0.2815507458102319, "compression_ratio": 1.5411255411255411, "no_speech_prob": 0.5915219783782959}, {"id": 3, "seek": 2404, "start": 32.48, "end": 39.12, "text": " somebody? One, two, three, perhaps more. Good. And usually, well, you understand that this", "tokens": [50786, 2618, 30, 1485, 11, 732, 11, 1045, 11, 4317, 544, 13, 2205, 13, 400, 2673, 11, 731, 11, 291, 1223, 300, 341, 51118], "temperature": 0.0, "avg_logprob": -0.2815507458102319, "compression_ratio": 1.5411255411255411, "no_speech_prob": 0.5915219783782959}, {"id": 4, "seek": 2404, "start": 39.12, "end": 44.76, "text": " was not my code, so I had to modify it. It was the code from people, from many people", "tokens": [51118, 390, 406, 452, 3089, 11, 370, 286, 632, 281, 16927, 309, 13, 467, 390, 264, 3089, 490, 561, 11, 490, 867, 561, 51400], "temperature": 0.0, "avg_logprob": -0.2815507458102319, "compression_ratio": 1.5411255411255411, "no_speech_prob": 0.5915219783782959}, {"id": 5, "seek": 2404, "start": 44.76, "end": 54.0, "text": " who worked in bars and produced code which had a lot of loops which do number crunching.", "tokens": [51400, 567, 2732, 294, 10228, 293, 7126, 3089, 597, 632, 257, 688, 295, 16121, 597, 360, 1230, 13386, 278, 13, 51862], "temperature": 0.0, "avg_logprob": -0.2815507458102319, "compression_ratio": 1.5411255411255411, "no_speech_prob": 0.5915219783782959}, {"id": 6, "seek": 5400, "start": 54.12, "end": 64.0, "text": " Those loops have touch numerical quantities and actually had a kind of structure that", "tokens": [50370, 3950, 16121, 362, 2557, 29054, 22927, 293, 767, 632, 257, 733, 295, 3877, 300, 50864], "temperature": 0.0, "avg_logprob": -0.30193091977027153, "compression_ratio": 1.5057471264367817, "no_speech_prob": 0.05634474381804466}, {"id": 7, "seek": 5400, "start": 64.0, "end": 73.88, "text": " you see here. You might recognize. So the layout, the data layout here is called array", "tokens": [50864, 291, 536, 510, 13, 509, 1062, 5521, 13, 407, 264, 13333, 11, 264, 1412, 13333, 510, 307, 1219, 10225, 51358], "temperature": 0.0, "avg_logprob": -0.30193091977027153, "compression_ratio": 1.5057471264367817, "no_speech_prob": 0.05634474381804466}, {"id": 8, "seek": 5400, "start": 73.88, "end": 83.2, "text": " of structures. So who would say, oh, I have an optimization for this case from your mind.", "tokens": [51358, 295, 9227, 13, 407, 567, 576, 584, 11, 1954, 11, 286, 362, 364, 19618, 337, 341, 1389, 490, 428, 1575, 13, 51824], "temperature": 0.0, "avg_logprob": -0.30193091977027153, "compression_ratio": 1.5057471264367817, "no_speech_prob": 0.05634474381804466}, {"id": 9, "seek": 8320, "start": 83.2, "end": 93.92, "text": " Which is this optimization? The most obvious one. So shout. Okay. It's my role to say it.", "tokens": [50364, 3013, 307, 341, 19618, 30, 440, 881, 6322, 472, 13, 407, 8043, 13, 1033, 13, 467, 311, 452, 3090, 281, 584, 309, 13, 50900], "temperature": 0.0, "avg_logprob": -0.2551644643147786, "compression_ratio": 1.454054054054054, "no_speech_prob": 0.011292677372694016}, {"id": 10, "seek": 8320, "start": 93.92, "end": 103.32000000000001, "text": " Well, to change the layout into not, sorry, arrays of structures, but structures of arrays.", "tokens": [50900, 1042, 11, 281, 1319, 264, 13333, 666, 406, 11, 2597, 11, 41011, 295, 9227, 11, 457, 9227, 295, 41011, 13, 51370], "temperature": 0.0, "avg_logprob": -0.2551644643147786, "compression_ratio": 1.454054054054054, "no_speech_prob": 0.011292677372694016}, {"id": 11, "seek": 8320, "start": 103.32000000000001, "end": 107.76, "text": " So this is like a transposition but brings like an improvement in performance of, let's", "tokens": [51370, 407, 341, 307, 411, 257, 7132, 5830, 457, 5607, 411, 364, 10444, 294, 3389, 295, 11, 718, 311, 51592], "temperature": 0.0, "avg_logprob": -0.2551644643147786, "compression_ratio": 1.454054054054054, "no_speech_prob": 0.011292677372694016}, {"id": 12, "seek": 10776, "start": 107.84, "end": 114.4, "text": " say, two, three, four, depending a bit on many conditions. So changing the layout of the code", "tokens": [50368, 584, 11, 732, 11, 1045, 11, 1451, 11, 5413, 257, 857, 322, 867, 4487, 13, 407, 4473, 264, 13333, 295, 264, 3089, 50696], "temperature": 0.0, "avg_logprob": -0.18234716142926896, "compression_ratio": 1.594142259414226, "no_speech_prob": 0.032359711825847626}, {"id": 13, "seek": 10776, "start": 114.4, "end": 121.68, "text": " and also the expressions from what you see here to what you see here might have such a positive", "tokens": [50696, 293, 611, 264, 15277, 490, 437, 291, 536, 510, 281, 437, 291, 536, 510, 1062, 362, 1270, 257, 3353, 51060], "temperature": 0.0, "avg_logprob": -0.18234716142926896, "compression_ratio": 1.594142259414226, "no_speech_prob": 0.032359711825847626}, {"id": 14, "seek": 10776, "start": 121.68, "end": 129.92000000000002, "text": " effect on performance. But how to do this if you have 100,000 lines of C code which has to stay C?", "tokens": [51060, 1802, 322, 3389, 13, 583, 577, 281, 360, 341, 498, 291, 362, 2319, 11, 1360, 3876, 295, 383, 3089, 597, 575, 281, 1754, 383, 30, 51472], "temperature": 0.0, "avg_logprob": -0.18234716142926896, "compression_ratio": 1.594142259414226, "no_speech_prob": 0.032359711825847626}, {"id": 15, "seek": 10776, "start": 129.92000000000002, "end": 137.36, "text": " Do you cobble together a few scripts? Yeah, why not? But perhaps you then come at some point", "tokens": [51472, 1144, 291, 598, 10387, 1214, 257, 1326, 23294, 30, 865, 11, 983, 406, 30, 583, 4317, 291, 550, 808, 412, 512, 935, 51844], "temperature": 0.0, "avg_logprob": -0.18234716142926896, "compression_ratio": 1.594142259414226, "no_speech_prob": 0.032359711825847626}, {"id": 16, "seek": 13736, "start": 137.44000000000003, "end": 144.72000000000003, "text": " whining that doesn't work. So you revert to, oh, you revert perhaps to using some high level", "tokens": [50368, 315, 1760, 300, 1177, 380, 589, 13, 407, 291, 319, 3281, 281, 11, 1954, 11, 291, 319, 3281, 4317, 281, 1228, 512, 1090, 1496, 50732], "temperature": 0.0, "avg_logprob": -0.24105284214019776, "compression_ratio": 1.484375, "no_speech_prob": 0.02225409634411335}, {"id": 17, "seek": 13736, "start": 144.72000000000003, "end": 152.24, "text": " transpiler. Yes, perhaps, but it's complicated. Well, I went that way. But I chosen another", "tokens": [50732, 7132, 5441, 13, 1079, 11, 4317, 11, 457, 309, 311, 6179, 13, 1042, 11, 286, 1437, 300, 636, 13, 583, 286, 8614, 1071, 51108], "temperature": 0.0, "avg_logprob": -0.24105284214019776, "compression_ratio": 1.484375, "no_speech_prob": 0.02225409634411335}, {"id": 18, "seek": 13736, "start": 152.24, "end": 160.88000000000002, "text": " transpiler which is called coxinell. Coxinell has been written with the idea of matching, so finding", "tokens": [51108, 7132, 5441, 597, 307, 1219, 598, 87, 533, 285, 13, 3066, 87, 533, 285, 575, 668, 3720, 365, 264, 1558, 295, 14324, 11, 370, 5006, 51540], "temperature": 0.0, "avg_logprob": -0.24105284214019776, "compression_ratio": 1.484375, "no_speech_prob": 0.02225409634411335}, {"id": 19, "seek": 16088, "start": 160.88, "end": 168.79999999999998, "text": " bugs in the C code of the Linux kernel and erasing those bugs. But I found out that coxinell,", "tokens": [50364, 15120, 294, 264, 383, 3089, 295, 264, 18734, 28256, 293, 1189, 3349, 729, 15120, 13, 583, 286, 1352, 484, 300, 598, 87, 533, 285, 11, 50760], "temperature": 0.0, "avg_logprob": -0.09817475166873656, "compression_ratio": 1.5135135135135136, "no_speech_prob": 0.046509891748428345}, {"id": 20, "seek": 16088, "start": 168.79999999999998, "end": 175.92, "text": " I think, was also a good tool for factoring large amounts of C code, especially in manipulating", "tokens": [50760, 286, 519, 11, 390, 611, 257, 665, 2290, 337, 1186, 3662, 2416, 11663, 295, 383, 3089, 11, 2318, 294, 40805, 51116], "temperature": 0.0, "avg_logprob": -0.09817475166873656, "compression_ratio": 1.5135135135135136, "no_speech_prob": 0.046509891748428345}, {"id": 21, "seek": 16088, "start": 175.92, "end": 185.68, "text": " expressions within statements. So expressions, once they are matched in statements, can be", "tokens": [51116, 15277, 1951, 12363, 13, 407, 15277, 11, 1564, 436, 366, 21447, 294, 12363, 11, 393, 312, 51604], "temperature": 0.0, "avg_logprob": -0.09817475166873656, "compression_ratio": 1.5135135135135136, "no_speech_prob": 0.046509891748428345}, {"id": 22, "seek": 18568, "start": 186.56, "end": 193.68, "text": " also changed. So coxinell has this pattern language that you see here, which is not in terms of", "tokens": [50408, 611, 3105, 13, 407, 598, 87, 533, 285, 575, 341, 5102, 2856, 300, 291, 536, 510, 11, 597, 307, 406, 294, 2115, 295, 50764], "temperature": 0.0, "avg_logprob": -0.10570614402358597, "compression_ratio": 1.7365269461077844, "no_speech_prob": 0.0537097342312336}, {"id": 23, "seek": 18568, "start": 193.68, "end": 203.28, "text": " patterns of text. Those patterns are in terms of the abstract syntax tree, which gets built on the", "tokens": [50764, 8294, 295, 2487, 13, 3950, 8294, 366, 294, 2115, 295, 264, 12649, 28431, 4230, 11, 597, 2170, 3094, 322, 264, 51244], "temperature": 0.0, "avg_logprob": -0.10570614402358597, "compression_ratio": 1.7365269461077844, "no_speech_prob": 0.0537097342312336}, {"id": 24, "seek": 18568, "start": 203.28, "end": 211.76000000000002, "text": " top of syntactical elements of the C language, which are being, which is being parsed here. And", "tokens": [51244, 1192, 295, 23980, 578, 804, 4959, 295, 264, 383, 2856, 11, 597, 366, 885, 11, 597, 307, 885, 21156, 292, 510, 13, 400, 51668], "temperature": 0.0, "avg_logprob": -0.10570614402358597, "compression_ratio": 1.7365269461077844, "no_speech_prob": 0.0537097342312336}, {"id": 25, "seek": 21176, "start": 211.76, "end": 219.2, "text": " those entities, the syntactical entities of the C language are of, you have control of them. So", "tokens": [50364, 729, 16667, 11, 264, 23980, 578, 804, 16667, 295, 264, 383, 2856, 366, 295, 11, 291, 362, 1969, 295, 552, 13, 407, 50736], "temperature": 0.0, "avg_logprob": -0.1912341799054827, "compression_ratio": 1.6333333333333333, "no_speech_prob": 0.03843109682202339}, {"id": 26, "seek": 21176, "start": 220.0, "end": 227.84, "text": " let's look at this key slide here. So we identify, match identifiers, tree identifiers, and we also", "tokens": [50776, 718, 311, 574, 412, 341, 2141, 4137, 510, 13, 407, 321, 5876, 11, 2995, 2473, 23463, 11, 4230, 2473, 23463, 11, 293, 321, 611, 51168], "temperature": 0.0, "avg_logprob": -0.1912341799054827, "compression_ratio": 1.6333333333333333, "no_speech_prob": 0.03843109682202339}, {"id": 27, "seek": 21176, "start": 227.84, "end": 235.76, "text": " give constraints. Like the first identifier Q, which can occur in the code, has to be, has to look", "tokens": [51168, 976, 18491, 13, 1743, 264, 700, 45690, 1249, 11, 597, 393, 5160, 294, 264, 3089, 11, 575, 281, 312, 11, 575, 281, 574, 51564], "temperature": 0.0, "avg_logprob": -0.1912341799054827, "compression_ratio": 1.6333333333333333, "no_speech_prob": 0.03843109682202339}, {"id": 28, "seek": 23576, "start": 235.76, "end": 242.88, "text": " like PRSR. The second one has to be P. The third one can be one of those two ones. So it's like", "tokens": [50364, 411, 11568, 50, 49, 13, 440, 1150, 472, 575, 281, 312, 430, 13, 440, 2636, 472, 393, 312, 472, 295, 729, 732, 2306, 13, 407, 309, 311, 411, 50720], "temperature": 0.0, "avg_logprob": -0.11093367063082181, "compression_ratio": 1.7092511013215859, "no_speech_prob": 0.060591958463191986}, {"id": 29, "seek": 23576, "start": 242.88, "end": 248.0, "text": " you give constraints that has to be respected. And then the red line here, the minus line, which", "tokens": [50720, 291, 976, 18491, 300, 575, 281, 312, 20020, 13, 400, 550, 264, 2182, 1622, 510, 11, 264, 3175, 1622, 11, 597, 50976], "temperature": 0.0, "avg_logprob": -0.11093367063082181, "compression_ratio": 1.7092511013215859, "no_speech_prob": 0.060591958463191986}, {"id": 30, "seek": 23576, "start": 248.0, "end": 255.2, "text": " you see here, has to be found in the code. In the arbitrarily complex expressions or statements,", "tokens": [50976, 291, 536, 510, 11, 575, 281, 312, 1352, 294, 264, 3089, 13, 682, 264, 19071, 3289, 3997, 15277, 420, 12363, 11, 51336], "temperature": 0.0, "avg_logprob": -0.11093367063082181, "compression_ratio": 1.7092511013215859, "no_speech_prob": 0.060591958463191986}, {"id": 31, "seek": 23576, "start": 255.2, "end": 265.03999999999996, "text": " such a form must be found. And once such a form is being found, only then such a change occurs. So", "tokens": [51336, 1270, 257, 1254, 1633, 312, 1352, 13, 400, 1564, 1270, 257, 1254, 307, 885, 1352, 11, 787, 550, 1270, 257, 1319, 11843, 13, 407, 51828], "temperature": 0.0, "avg_logprob": -0.11093367063082181, "compression_ratio": 1.7092511013215859, "no_speech_prob": 0.060591958463191986}, {"id": 32, "seek": 26504, "start": 265.12, "end": 272.16, "text": " you see this change? It's also expressed in terms of what has been already found. So you can be very", "tokens": [50368, 291, 536, 341, 1319, 30, 467, 311, 611, 12675, 294, 2115, 295, 437, 575, 668, 1217, 1352, 13, 407, 291, 393, 312, 588, 50720], "temperature": 0.0, "avg_logprob": -0.13817660839526685, "compression_ratio": 1.5923913043478262, "no_speech_prob": 0.020396960899233818}, {"id": 33, "seek": 26504, "start": 272.16, "end": 279.44, "text": " precise if you want. And what you see here on the right panel is an entire program without, with", "tokens": [50720, 13600, 498, 291, 528, 13, 400, 437, 291, 536, 510, 322, 264, 558, 4831, 307, 364, 2302, 1461, 1553, 11, 365, 51084], "temperature": 0.0, "avg_logprob": -0.13817660839526685, "compression_ratio": 1.5923913043478262, "no_speech_prob": 0.020396960899233818}, {"id": 34, "seek": 26504, "start": 280.0, "end": 287.12, "text": " one line changed from what you see here, red to what you see here, blue. So this is, of course,", "tokens": [51112, 472, 1622, 3105, 490, 437, 291, 536, 510, 11, 2182, 281, 437, 291, 536, 510, 11, 3344, 13, 407, 341, 307, 11, 295, 1164, 11, 51468], "temperature": 0.0, "avg_logprob": -0.13817660839526685, "compression_ratio": 1.5923913043478262, "no_speech_prob": 0.020396960899233818}, {"id": 35, "seek": 28712, "start": 287.76, "end": 297.92, "text": " construed example to show you that this teeny rule here can syntactically go over your arbitrary", "tokens": [50396, 12946, 292, 1365, 281, 855, 291, 300, 341, 48232, 4978, 510, 393, 23980, 578, 984, 352, 670, 428, 23211, 50904], "temperature": 0.0, "avg_logprob": -0.10503615559758367, "compression_ratio": 1.5157894736842106, "no_speech_prob": 0.05225370451807976}, {"id": 36, "seek": 28712, "start": 297.92, "end": 306.08, "text": " large code and do really a lot of changes here. The complicated part comes if you want to be,", "tokens": [50904, 2416, 3089, 293, 360, 534, 257, 688, 295, 2962, 510, 13, 440, 6179, 644, 1487, 498, 291, 528, 281, 312, 11, 51312], "temperature": 0.0, "avg_logprob": -0.10503615559758367, "compression_ratio": 1.5157894736842106, "no_speech_prob": 0.05225370451807976}, {"id": 37, "seek": 28712, "start": 306.08, "end": 315.2, "text": " if your code doesn't have regularities, so it's messy. But yeah, but if it's tidy enough, you can", "tokens": [51312, 498, 428, 3089, 1177, 380, 362, 3890, 1088, 11, 370, 309, 311, 16191, 13, 583, 1338, 11, 457, 498, 309, 311, 34646, 1547, 11, 291, 393, 51768], "temperature": 0.0, "avg_logprob": -0.10503615559758367, "compression_ratio": 1.5157894736842106, "no_speech_prob": 0.05225370451807976}, {"id": 38, "seek": 31520, "start": 315.2, "end": 322.96, "text": " do a lot of things. And we're working on new HPC oriented features in coxinell in this system.", "tokens": [50364, 360, 257, 688, 295, 721, 13, 400, 321, 434, 1364, 322, 777, 12557, 34, 21841, 4122, 294, 598, 87, 533, 285, 294, 341, 1185, 13, 50752], "temperature": 0.0, "avg_logprob": -0.149129807194577, "compression_ratio": 1.4158415841584158, "no_speech_prob": 0.07240244001150131}, {"id": 39, "seek": 31520, "start": 322.96, "end": 333.2, "text": " So what does HPC revolves around nowadays? GPUs, modern C++ and modern OpenMP. So this is what", "tokens": [50752, 407, 437, 775, 12557, 34, 47934, 926, 13434, 30, 18407, 82, 11, 4363, 383, 25472, 293, 4363, 7238, 12224, 13, 407, 341, 307, 437, 51264], "temperature": 0.0, "avg_logprob": -0.149129807194577, "compression_ratio": 1.4158415841584158, "no_speech_prob": 0.07240244001150131}, {"id": 40, "seek": 31520, "start": 333.2, "end": 339.2, "text": " we target. And these are three slides now I will be showing you just to give you a taste of some", "tokens": [51264, 321, 3779, 13, 400, 613, 366, 1045, 9788, 586, 286, 486, 312, 4099, 291, 445, 281, 976, 291, 257, 3939, 295, 512, 51564], "temperature": 0.0, "avg_logprob": -0.149129807194577, "compression_ratio": 1.4158415841584158, "no_speech_prob": 0.07240244001150131}, {"id": 41, "seek": 33920, "start": 339.2, "end": 347.28, "text": " key elements we have been putting in the last times. So if you know the CUDA from NVIDIA, API or", "tokens": [50364, 2141, 4959, 321, 362, 668, 3372, 294, 264, 1036, 1413, 13, 407, 498, 291, 458, 264, 29777, 7509, 490, 426, 3958, 6914, 11, 9362, 420, 50768], "temperature": 0.0, "avg_logprob": -0.16262954172461924, "compression_ratio": 1.5755102040816327, "no_speech_prob": 0.09603767096996307}, {"id": 42, "seek": 33920, "start": 347.28, "end": 354.24, "text": " language extensions, then you will recognize that here we have some keywords, some the Chevron,", "tokens": [50768, 2856, 25129, 11, 550, 291, 486, 5521, 300, 510, 321, 362, 512, 21009, 11, 512, 264, 44236, 2044, 11, 51116], "temperature": 0.0, "avg_logprob": -0.16262954172461924, "compression_ratio": 1.5755102040816327, "no_speech_prob": 0.09603767096996307}, {"id": 43, "seek": 33920, "start": 354.24, "end": 361.12, "text": " kernel, call syntax, which we support. So this is not standard C or C++. We're supporting this. So", "tokens": [51116, 28256, 11, 818, 28431, 11, 597, 321, 1406, 13, 407, 341, 307, 406, 3832, 383, 420, 383, 25472, 13, 492, 434, 7231, 341, 13, 407, 51460], "temperature": 0.0, "avg_logprob": -0.16262954172461924, "compression_ratio": 1.5755102040816327, "no_speech_prob": 0.09603767096996307}, {"id": 44, "seek": 33920, "start": 361.12, "end": 368.4, "text": " we're putting this language support into the coxinell tool to allow you perhaps to change your", "tokens": [51460, 321, 434, 3372, 341, 2856, 1406, 666, 264, 598, 87, 533, 285, 2290, 281, 2089, 291, 4317, 281, 1319, 428, 51824], "temperature": 0.0, "avg_logprob": -0.16262954172461924, "compression_ratio": 1.5755102040816327, "no_speech_prob": 0.09603767096996307}, {"id": 45, "seek": 36840, "start": 368.4, "end": 373.84, "text": " existing code. So to write rules on your huge code, because if it would not be huge, you would", "tokens": [50364, 6741, 3089, 13, 407, 281, 2464, 4474, 322, 428, 2603, 3089, 11, 570, 498, 309, 576, 406, 312, 2603, 11, 291, 576, 50636], "temperature": 0.0, "avg_logprob": -0.12381312960670107, "compression_ratio": 1.5877551020408163, "no_speech_prob": 0.027990933507680893}, {"id": 46, "seek": 36840, "start": 373.84, "end": 378.64, "text": " be doing this by hand, right? But if it's huge, you want a tool for power, for the factoring. And", "tokens": [50636, 312, 884, 341, 538, 1011, 11, 558, 30, 583, 498, 309, 311, 2603, 11, 291, 528, 257, 2290, 337, 1347, 11, 337, 264, 1186, 3662, 13, 400, 50876], "temperature": 0.0, "avg_logprob": -0.12381312960670107, "compression_ratio": 1.5877551020408163, "no_speech_prob": 0.027990933507680893}, {"id": 47, "seek": 36840, "start": 378.64, "end": 385.59999999999997, "text": " this is what we want to provide you. To, yeah, to derive perhaps a CUDA kernel code from your CPU", "tokens": [50876, 341, 307, 437, 321, 528, 281, 2893, 291, 13, 1407, 11, 1338, 11, 281, 28446, 4317, 257, 29777, 7509, 28256, 3089, 490, 428, 13199, 51224], "temperature": 0.0, "avg_logprob": -0.12381312960670107, "compression_ratio": 1.5877551020408163, "no_speech_prob": 0.027990933507680893}, {"id": 48, "seek": 36840, "start": 385.59999999999997, "end": 390.4, "text": " code. If you have in mind the regularities and the changes that you need, and you can express them", "tokens": [51224, 3089, 13, 759, 291, 362, 294, 1575, 264, 3890, 1088, 293, 264, 2962, 300, 291, 643, 11, 293, 291, 393, 5109, 552, 51464], "temperature": 0.0, "avg_logprob": -0.12381312960670107, "compression_ratio": 1.5877551020408163, "no_speech_prob": 0.027990933507680893}, {"id": 49, "seek": 39040, "start": 390.4, "end": 400.15999999999997, "text": " with this language, I like C++ 23 introduces multi-index operators with square brackets, for", "tokens": [50364, 365, 341, 2856, 11, 286, 411, 383, 25472, 6673, 31472, 4825, 12, 471, 3121, 19077, 365, 3732, 26179, 11, 337, 50852], "temperature": 0.0, "avg_logprob": -0.19421029702211037, "compression_ratio": 1.4923076923076923, "no_speech_prob": 0.06615763157606125}, {"id": 50, "seek": 39040, "start": 400.15999999999997, "end": 408.08, "text": " instance. So this is now also possible if it's of use. It can be of use, for instance, with cocos", "tokens": [50852, 5197, 13, 407, 341, 307, 586, 611, 1944, 498, 309, 311, 295, 764, 13, 467, 393, 312, 295, 764, 11, 337, 5197, 11, 365, 598, 6877, 51248], "temperature": 0.0, "avg_logprob": -0.19421029702211037, "compression_ratio": 1.4923076923076923, "no_speech_prob": 0.06615763157606125}, {"id": 51, "seek": 39040, "start": 408.71999999999997, "end": 414.88, "text": " heavily. So this can help you to transition perhaps to cocos if you really want. And just to, again,", "tokens": [51280, 10950, 13, 407, 341, 393, 854, 291, 281, 6034, 4317, 281, 598, 6877, 498, 291, 534, 528, 13, 400, 445, 281, 11, 797, 11, 51588], "temperature": 0.0, "avg_logprob": -0.19421029702211037, "compression_ratio": 1.4923076923076923, "no_speech_prob": 0.06615763157606125}, {"id": 52, "seek": 41488, "start": 414.88, "end": 423.52, "text": " I want to, these are expressions and they act on statements. So you have to imagine that this can", "tokens": [50364, 286, 528, 281, 11, 613, 366, 15277, 293, 436, 605, 322, 12363, 13, 407, 291, 362, 281, 3811, 300, 341, 393, 50796], "temperature": 0.0, "avg_logprob": -0.1318882942199707, "compression_ratio": 1.7723214285714286, "no_speech_prob": 0.03257893770933151}, {"id": 53, "seek": 41488, "start": 423.52, "end": 428.8, "text": " occur in arbitrarily nested statements. So complicated thing is like the one that you have seen at the", "tokens": [50796, 5160, 294, 19071, 3289, 15646, 292, 12363, 13, 407, 6179, 551, 307, 411, 264, 472, 300, 291, 362, 1612, 412, 264, 51060], "temperature": 0.0, "avg_logprob": -0.1318882942199707, "compression_ratio": 1.7723214285714286, "no_speech_prob": 0.03257893770933151}, {"id": 54, "seek": 41488, "start": 428.8, "end": 438.15999999999997, "text": " beginning of the presentation. And it's up to you to create like chains of rules, which express the", "tokens": [51060, 2863, 295, 264, 5860, 13, 400, 309, 311, 493, 281, 291, 281, 1884, 411, 12626, 295, 4474, 11, 597, 5109, 264, 51528], "temperature": 0.0, "avg_logprob": -0.1318882942199707, "compression_ratio": 1.7723214285714286, "no_speech_prob": 0.03257893770933151}, {"id": 55, "seek": 41488, "start": 438.15999999999997, "end": 442.96, "text": " logical dependencies between the things which you want to match and the things which you want to", "tokens": [51528, 14978, 36606, 1296, 264, 721, 597, 291, 528, 281, 2995, 293, 264, 721, 597, 291, 528, 281, 51768], "temperature": 0.0, "avg_logprob": -0.1318882942199707, "compression_ratio": 1.7723214285714286, "no_speech_prob": 0.03257893770933151}, {"id": 56, "seek": 44296, "start": 442.96, "end": 449.76, "text": " introduce in the code. So if the code is messy, it will be more difficult. If your code is tidy enough,", "tokens": [50364, 5366, 294, 264, 3089, 13, 407, 498, 264, 3089, 307, 16191, 11, 309, 486, 312, 544, 2252, 13, 759, 428, 3089, 307, 34646, 1547, 11, 50704], "temperature": 0.0, "avg_logprob": -0.1668301744663969, "compression_ratio": 1.6695278969957081, "no_speech_prob": 0.04667510464787483}, {"id": 57, "seek": 44296, "start": 449.76, "end": 454.0, "text": " you can do extremely powerful things like also experiments with performance. Let's say, oh,", "tokens": [50704, 291, 393, 360, 4664, 4005, 721, 411, 611, 12050, 365, 3389, 13, 961, 311, 584, 11, 1954, 11, 50916], "temperature": 0.0, "avg_logprob": -0.1668301744663969, "compression_ratio": 1.6695278969957081, "no_speech_prob": 0.04667510464787483}, {"id": 58, "seek": 44296, "start": 454.0, "end": 459.76, "text": " what happens if I change in my entire code base from this style of arranging things, and this", "tokens": [50916, 437, 2314, 498, 286, 1319, 294, 452, 2302, 3089, 3096, 490, 341, 3758, 295, 5539, 9741, 721, 11, 293, 341, 51204], "temperature": 0.0, "avg_logprob": -0.1668301744663969, "compression_ratio": 1.6695278969957081, "no_speech_prob": 0.04667510464787483}, {"id": 59, "seek": 44296, "start": 459.76, "end": 465.44, "text": " this style of arranging things. Then such experiments might be enabled here. And perhaps you don't,", "tokens": [51204, 341, 3758, 295, 5539, 9741, 721, 13, 1396, 1270, 12050, 1062, 312, 15172, 510, 13, 400, 4317, 291, 500, 380, 11, 51488], "temperature": 0.0, "avg_logprob": -0.1668301744663969, "compression_ratio": 1.6695278969957081, "no_speech_prob": 0.04667510464787483}, {"id": 60, "seek": 46544, "start": 465.52, "end": 475.6, "text": " you're not perhaps obliged into using overly complicated APIs from portable, yeah, from some", "tokens": [50368, 291, 434, 406, 4317, 47194, 666, 1228, 24324, 6179, 21445, 490, 21800, 11, 1338, 11, 490, 512, 50872], "temperature": 0.0, "avg_logprob": -0.17878194859153346, "compression_ratio": 1.4334975369458127, "no_speech_prob": 0.028536058962345123}, {"id": 61, "seek": 46544, "start": 475.6, "end": 483.92, "text": " vendors. Yes. So, oh, sorry. One last example slide. You can even use coxinell to declutter code. So", "tokens": [50872, 22056, 13, 1079, 13, 407, 11, 1954, 11, 2597, 13, 1485, 1036, 1365, 4137, 13, 509, 393, 754, 764, 598, 87, 533, 285, 281, 7488, 9947, 3089, 13, 407, 51288], "temperature": 0.0, "avg_logprob": -0.17878194859153346, "compression_ratio": 1.4334975369458127, "no_speech_prob": 0.028536058962345123}, {"id": 62, "seek": 46544, "start": 483.92, "end": 494.24, "text": " here we are removing hand unrolled code. So such a pattern recognizes, but I mean, I have written", "tokens": [51288, 510, 321, 366, 12720, 1011, 517, 28850, 3089, 13, 407, 1270, 257, 5102, 26564, 11, 457, 286, 914, 11, 286, 362, 3720, 51804], "temperature": 0.0, "avg_logprob": -0.17878194859153346, "compression_ratio": 1.4334975369458127, "no_speech_prob": 0.028536058962345123}, {"id": 63, "seek": 49424, "start": 494.72, "end": 500.8, "text": " on purpose, recognize some hand unrolled code, removes it, and just introduce one pragma from", "tokens": [50388, 322, 4334, 11, 5521, 512, 1011, 517, 28850, 3089, 11, 30445, 309, 11, 293, 445, 5366, 472, 33394, 1696, 490, 50692], "temperature": 0.0, "avg_logprob": -0.21510601750126593, "compression_ratio": 1.694736842105263, "no_speech_prob": 0.024884577840566635}, {"id": 64, "seek": 49424, "start": 500.8, "end": 507.6, "text": " openMP, which says, hey, unroll this. And this is a standardized pragma. So it's not like GCC,", "tokens": [50692, 1269, 12224, 11, 597, 1619, 11, 4177, 11, 517, 3970, 341, 13, 400, 341, 307, 257, 31677, 33394, 1696, 13, 407, 309, 311, 406, 411, 460, 11717, 11, 51032], "temperature": 0.0, "avg_logprob": -0.21510601750126593, "compression_ratio": 1.694736842105263, "no_speech_prob": 0.024884577840566635}, {"id": 65, "seek": 49424, "start": 507.6, "end": 513.12, "text": " unroll, Intel, unroll. No. This is finally, since a couple of years, we have this pragma. So let's", "tokens": [51032, 517, 3970, 11, 19762, 11, 517, 3970, 13, 883, 13, 639, 307, 2721, 11, 1670, 257, 1916, 295, 924, 11, 321, 362, 341, 33394, 1696, 13, 407, 718, 311, 51308], "temperature": 0.0, "avg_logprob": -0.21510601750126593, "compression_ratio": 1.694736842105263, "no_speech_prob": 0.024884577840566635}, {"id": 66, "seek": 49424, "start": 513.12, "end": 518.32, "text": " say, if you know how to declutter your code, you have rules in your head, you can implement them here,", "tokens": [51308, 584, 11, 498, 291, 458, 577, 281, 7488, 9947, 428, 3089, 11, 291, 362, 4474, 294, 428, 1378, 11, 291, 393, 4445, 552, 510, 11, 51568], "temperature": 0.0, "avg_logprob": -0.21510601750126593, "compression_ratio": 1.694736842105263, "no_speech_prob": 0.024884577840566635}, {"id": 67, "seek": 49424, "start": 518.32, "end": 523.04, "text": " and have some formal, an informal method for restructuring your code. Good. So you know what", "tokens": [51568, 293, 362, 512, 9860, 11, 364, 24342, 3170, 337, 1472, 1757, 1345, 428, 3089, 13, 2205, 13, 407, 291, 458, 437, 51804], "temperature": 0.0, "avg_logprob": -0.21510601750126593, "compression_ratio": 1.694736842105263, "no_speech_prob": 0.024884577840566635}, {"id": 68, "seek": 52304, "start": 523.04, "end": 529.8399999999999, "text": " we are doing lately. So we are developing further material and use cases, language support, some", "tokens": [50364, 321, 366, 884, 12881, 13, 407, 321, 366, 6416, 3052, 2527, 293, 764, 3331, 11, 2856, 1406, 11, 512, 50704], "temperature": 0.0, "avg_logprob": -0.18984408939585967, "compression_ratio": 1.4583333333333333, "no_speech_prob": 0.03301990032196045}, {"id": 69, "seek": 52304, "start": 529.8399999999999, "end": 537.36, "text": " small things and large things. And yeah, that's it. So this work has been supported by the", "tokens": [50704, 1359, 721, 293, 2416, 721, 13, 400, 1338, 11, 300, 311, 309, 13, 407, 341, 589, 575, 668, 8104, 538, 264, 51080], "temperature": 0.0, "avg_logprob": -0.18984408939585967, "compression_ratio": 1.4583333333333333, "no_speech_prob": 0.03301990032196045}, {"id": 70, "seek": 52304, "start": 537.36, "end": 545.36, "text": " Gauss Supercomputing Center project, by a collaboration between Bavarian Germany and France.", "tokens": [51080, 10384, 2023, 4548, 1112, 2582, 278, 5169, 1716, 11, 538, 257, 9363, 1296, 363, 706, 10652, 7244, 293, 6190, 13, 51480], "temperature": 0.0, "avg_logprob": -0.18984408939585967, "compression_ratio": 1.4583333333333333, "no_speech_prob": 0.03301990032196045}, {"id": 71, "seek": 54536, "start": 546.32, "end": 553.12, "text": " And if you are tough, you will go through this tutorial, which I created a few years ago.", "tokens": [50412, 400, 498, 291, 366, 4930, 11, 291, 486, 352, 807, 341, 7073, 11, 597, 286, 2942, 257, 1326, 924, 2057, 13, 50752], "temperature": 0.0, "avg_logprob": -0.1640451086892022, "compression_ratio": 1.4917127071823204, "no_speech_prob": 0.04001076519489288}, {"id": 72, "seek": 54536, "start": 556.08, "end": 561.28, "text": " Yeah, and you can stay tuned with our developments with Coxinell, or you can also come to", "tokens": [50900, 865, 11, 293, 291, 393, 1754, 10870, 365, 527, 20862, 365, 3066, 87, 533, 285, 11, 420, 291, 393, 611, 808, 281, 51160], "temperature": 0.0, "avg_logprob": -0.1640451086892022, "compression_ratio": 1.4917127071823204, "no_speech_prob": 0.04001076519489288}, {"id": 73, "seek": 54536, "start": 561.28, "end": 570.16, "text": " W\u00fcrzburg in one month to attend our short introductory tutorial into Coxinell. And if you", "tokens": [51160, 43846, 89, 8342, 294, 472, 1618, 281, 6888, 527, 2099, 39048, 7073, 666, 3066, 87, 533, 285, 13, 400, 498, 291, 51604], "temperature": 0.0, "avg_logprob": -0.1640451086892022, "compression_ratio": 1.4917127071823204, "no_speech_prob": 0.04001076519489288}, {"id": 74, "seek": 57016, "start": 570.24, "end": 574.0799999999999, "text": " want to read our six-page use case article, I really recommend it because", "tokens": [50368, 528, 281, 1401, 527, 2309, 12, 15161, 764, 1389, 7222, 11, 286, 534, 2748, 309, 570, 50560], "temperature": 0.0, "avg_logprob": -0.21743706733949722, "compression_ratio": 1.346820809248555, "no_speech_prob": 0.11554612964391708}, {"id": 75, "seek": 57016, "start": 576.0799999999999, "end": 581.76, "text": " it's more deductical than this 10-minute lightning talk. That's everything.", "tokens": [50660, 309, 311, 544, 31513, 804, 813, 341, 1266, 12, 18256, 16589, 751, 13, 663, 311, 1203, 13, 50944], "temperature": 0.0, "avg_logprob": -0.21743706733949722, "compression_ratio": 1.346820809248555, "no_speech_prob": 0.11554612964391708}, {"id": 76, "seek": 57016, "start": 589.12, "end": 596.3199999999999, "text": " Thank you very much, Michele. We have time for one question. JP in the back, again.", "tokens": [51312, 1044, 291, 588, 709, 11, 3392, 16884, 13, 492, 362, 565, 337, 472, 1168, 13, 34336, 294, 264, 646, 11, 797, 13, 51672], "temperature": 0.0, "avg_logprob": -0.21743706733949722, "compression_ratio": 1.346820809248555, "no_speech_prob": 0.11554612964391708}, {"id": 77, "seek": 60016, "start": 600.4, "end": 606.16, "text": " Thank you so much. Hey, cool talk. Great, great thing. I love Coxinell. I have it right on the", "tokens": [50376, 1044, 291, 370, 709, 13, 1911, 11, 1627, 751, 13, 3769, 11, 869, 551, 13, 286, 959, 3066, 87, 533, 285, 13, 286, 362, 309, 558, 322, 264, 50664], "temperature": 0.0, "avg_logprob": -0.12033645705421372, "compression_ratio": 1.5537190082644627, "no_speech_prob": 0.050847701728343964}, {"id": 78, "seek": 60016, "start": 606.16, "end": 612.48, "text": " top of my list that I want to work with. The question is, can I express more constraints than", "tokens": [50664, 1192, 295, 452, 1329, 300, 286, 528, 281, 589, 365, 13, 440, 1168, 307, 11, 393, 286, 5109, 544, 18491, 813, 50980], "temperature": 0.0, "avg_logprob": -0.12033645705421372, "compression_ratio": 1.5537190082644627, "no_speech_prob": 0.050847701728343964}, {"id": 79, "seek": 60016, "start": 612.48, "end": 620.88, "text": " just symbols and identifiers in these rules, like types or like lexical things? So what are the", "tokens": [50980, 445, 16944, 293, 2473, 23463, 294, 613, 4474, 11, 411, 3467, 420, 411, 476, 87, 804, 721, 30, 407, 437, 366, 264, 51400], "temperature": 0.0, "avg_logprob": -0.12033645705421372, "compression_ratio": 1.5537190082644627, "no_speech_prob": 0.050847701728343964}, {"id": 80, "seek": 60016, "start": 620.88, "end": 629.28, "text": " things that I can express in terms of this rule should only apply if? So for sure, context?", "tokens": [51400, 721, 300, 286, 393, 5109, 294, 2115, 295, 341, 4978, 820, 787, 3079, 498, 30, 407, 337, 988, 11, 4319, 30, 51820], "temperature": 0.0, "avg_logprob": -0.12033645705421372, "compression_ratio": 1.5537190082644627, "no_speech_prob": 0.050847701728343964}, {"id": 81, "seek": 63016, "start": 630.16, "end": 638.56, "text": " So whatever you write as context, it gets matched. But if it comes to the rule part of those", "tokens": [50364, 407, 2035, 291, 2464, 382, 4319, 11, 309, 2170, 21447, 13, 583, 498, 309, 1487, 281, 264, 4978, 644, 295, 729, 50784], "temperature": 0.0, "avg_logprob": -0.19021707110934788, "compression_ratio": 1.564516129032258, "no_speech_prob": 0.018556617200374603}, {"id": 82, "seek": 63016, "start": 638.56, "end": 643.68, "text": " patches, which we have seen, the top part, you have seen identifier and something. Yeah, you have", "tokens": [50784, 26531, 11, 597, 321, 362, 1612, 11, 264, 1192, 644, 11, 291, 362, 1612, 45690, 293, 746, 13, 865, 11, 291, 362, 51040], "temperature": 0.0, "avg_logprob": -0.19021707110934788, "compression_ratio": 1.564516129032258, "no_speech_prob": 0.018556617200374603}, {"id": 83, "seek": 63016, "start": 643.68, "end": 658.16, "text": " also type and other words for function parameters, for positions, for symbols. So there are a lot of", "tokens": [51040, 611, 2010, 293, 661, 2283, 337, 2445, 9834, 11, 337, 8432, 11, 337, 16944, 13, 407, 456, 366, 257, 688, 295, 51764], "temperature": 0.0, "avg_logprob": -0.19021707110934788, "compression_ratio": 1.564516129032258, "no_speech_prob": 0.018556617200374603}, {"id": 84, "seek": 65816, "start": 658.16, "end": 665.92, "text": " them. And the important part is that the code is being parsed in the first place. Because once we", "tokens": [50364, 552, 13, 400, 264, 1021, 644, 307, 300, 264, 3089, 307, 885, 21156, 292, 294, 264, 700, 1081, 13, 1436, 1564, 321, 50752], "temperature": 0.0, "avg_logprob": -0.15884940688674515, "compression_ratio": 1.5769230769230769, "no_speech_prob": 0.08201194554567337}, {"id": 85, "seek": 65816, "start": 665.92, "end": 675.36, "text": " support your language constructs, we parse your code, then you write a rule which can be, which", "tokens": [50752, 1406, 428, 2856, 7690, 82, 11, 321, 48377, 428, 3089, 11, 550, 291, 2464, 257, 4978, 597, 393, 312, 11, 597, 51224], "temperature": 0.0, "avg_logprob": -0.15884940688674515, "compression_ratio": 1.5769230769230769, "no_speech_prob": 0.08201194554567337}, {"id": 86, "seek": 65816, "start": 675.36, "end": 682.0, "text": " is really the code which we have to match. So Coxinell is different parsers. It has different", "tokens": [51224, 307, 534, 264, 3089, 597, 321, 362, 281, 2995, 13, 407, 3066, 87, 533, 285, 307, 819, 21156, 433, 13, 467, 575, 819, 51556], "temperature": 0.0, "avg_logprob": -0.15884940688674515, "compression_ratio": 1.5769230769230769, "no_speech_prob": 0.08201194554567337}, {"id": 87, "seek": 68200, "start": 682.0, "end": 686.48, "text": " parsers. We parse your code first, we parse the root first, and then we look for a match.", "tokens": [50364, 21156, 433, 13, 492, 48377, 428, 3089, 700, 11, 321, 48377, 264, 5593, 700, 11, 293, 550, 321, 574, 337, 257, 2995, 13, 50588], "temperature": 0.0, "avg_logprob": -0.2266090344160031, "compression_ratio": 1.5543478260869565, "no_speech_prob": 0.056634675711393356}, {"id": 88, "seek": 68200, "start": 688.72, "end": 693.84, "text": " We are able to parse that. Any construct can be modified. This is the point. Any construct.", "tokens": [50700, 492, 366, 1075, 281, 48377, 300, 13, 2639, 7690, 393, 312, 15873, 13, 639, 307, 264, 935, 13, 2639, 7690, 13, 50956], "temperature": 0.0, "avg_logprob": -0.2266090344160031, "compression_ratio": 1.5543478260869565, "no_speech_prob": 0.056634675711393356}, {"id": 89, "seek": 68200, "start": 694.72, "end": 699.52, "text": " So even within a template, you want to change something systematically. Yes.", "tokens": [51000, 407, 754, 1951, 257, 12379, 11, 291, 528, 281, 1319, 746, 39531, 13, 1079, 13, 51240], "temperature": 0.0, "avg_logprob": -0.2266090344160031, "compression_ratio": 1.5543478260869565, "no_speech_prob": 0.056634675711393356}, {"id": 90, "seek": 68200, "start": 700.48, "end": 702.16, "text": " Okay, cool. Yes, thank you.", "tokens": [51288, 1033, 11, 1627, 13, 1079, 11, 1309, 291, 13, 51372], "temperature": 0.0, "avg_logprob": -0.2266090344160031, "compression_ratio": 1.5543478260869565, "no_speech_prob": 0.056634675711393356}, {"id": 91, "seek": 70216, "start": 702.16, "end": 710.88, "text": " Okay, we're doing", "tokens": [50392, 1033, 11, 321, 434, 884, 50800], "temperature": 0.0, "avg_logprob": -0.544909656047821, "compression_ratio": 0.68, "no_speech_prob": 0.4377058148384094}], "language": "en"}