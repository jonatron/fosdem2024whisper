{"text": " Thank you. This is a QR code for the slides and also all of the talks I reference in this talk. And yeah, thank you Theo for organizing the poll in Raku Devroom. I'm going to talk about, you can all hear me okay? Yeah, perfect. I'm going to talk about Pearl at PayProp, which is a company I work for, an established company, been around for almost 25 years now. And briefly about me, I don't normally do this, but I see a few faces I don't recognize and I'm sure people don't recognize me as well, so I thought I would do this. I'm a senior dev and head of processing at PayProp. I've been there for 10 years. I've been a developer for just over 20 years. I've worked with various languages, but mostly Pearl. But I've only worked for three companies in the time I've been in that 20 years, so I've kind of seen tech stacks grow and shrink and change. I'm a C-Pone contributor, so Lijo, I'm a C-Pone, Meta-C-Pone. And I'm a London and Swiss Pearl and Raku workshop organizer, so come and talk to me if you're interested in any of those. We're searching for a venue for this year's London Pearl workshop, so if you have any ideas, come and talk to me. And I'm a regular speaker at other Pearl workshops and conferences, and often I'm helping out with the video. And I occasionally blog on Pearl. I prefer to do long form articles rather than technical kind of, this is how you use this module kind of posts. And I run the Pearl events Instagram account, but that's about the limit of my social media interaction. And I'm a Fosdum Newsbie, so my first time here. We usually have a work event that runs at this time of year, so it always clashes with Fosdum, so I've never managed to make it, so this is the first time it hasn't clashed with Fosdum. So about paper op. That's what kind of what we look like, the public facing part of the site at least. We're a payment and reconciliation platform for the residential letting industry. And we kind of, our core business value is we turn things like this, and this is one of the nicer ones to deal with. This is a Swift format into things like this. So we put interfaces and automation on tank consuming payment reconciliation flows. And this literally saves our customers hours, days, weeks of time, so we're really, really useful to them. The key night of you might see CGI bin script.cgi in that URL. So yeah, we've been around for over 20 years, so we have some old code, bit of an understatement in places. But the pearl we are using is relatively modern, 532. And we build our own pearl, and we don't use the vendor supplied pearl or the system pearl. We don't do anything special with it. We could in theory compile it with different flags, but we don't do that. So we get the defaults, which means we don't get things like iThreads, because if you use vendor supplied pearl, you get things you probably don't need. Yeah, the key is that it's not the system pearl. So we're not kind of tied to any particular version of an OS or package or whatever. And we can apply updates and patches as necessary. We should be on 538 by now. We tend to trail a major version. I've been spread a bit thin, so we haven't managed to get to latest, but that's on the roadmap for this year. Yeah, and it gives us dependency control, which is critical. If you've been paying attention the last couple of weeks, there's been a couple of critical CVEs against a couple of spreadsheet passing modules, so we could get those updates out quite quickly. Loose coupling, so yeah, like I said, not tied to the OS or anything like that. And the key is it's everywhere. So we have the same version of pearl, the same version of modules from dev through CI staging demo all the way to production. So otherwise you get interesting debugging problems. And while the issues and challenges around that, well, probably the ones you've all heard, you know, still use pearl or even what is pearl, and the bus factor, which is, you know, becoming a problem with some of the pearl dependencies. So yeah, it's a 20-year-old, 22-year-old app, so we are in the process of migrating from CGI.pm to Modulicious. A 20-year-old app has some legacy, a bit of an understatement really. This is an ongoing task, and we're about two-thirds complete in terms of number of requests to the site. We have a lot more pages than we really use after 20 years. Kind of inevitably happens that people write features and functionality that end up not being used, and we've got hundreds of pages, and really only 20% of them are actively used. So a lot of them will never actually end up getting converted. And one of the ways we did this in one of our other apps is using this plugin from Modulicious. And we decided not to do this with PayProp because we're using Apache on the front end anyway, so we can kind of proxy to a Modulicious server or just run exec CGI if it's CGI script. So we're not doing a kind of serving the CGI scripts from Modulicious using a plugin. There's no real value there, to be honest. So that's kind of what the setup is. I actually gave a talk about this almost a decade ago, so there's a link there to that talk, which has some suggestions for how you can do this if you're using CGI. You want to use Modulicious, what the options are. But it was 10 years ago, so it's a little bit out of date now, because Modulicious moves fast, and it is one of the challenges in using it because they say that you can always count on backwards compatibility, but they will deprecate and remove features within a three-month window, which is not really backwards compatibility. So you just have to be aware that if you haven't done an update in a while, things might break. And we're adding an ORM. And I know this can be a contentious issue, which I kind of find surprising. I'm just title writing this kind of stuff. And this is a simplified, about as simple as the query you can do. So you select some columns from the table, prepare the query, make sure you have the error handling, execute it, grab a hash ref. I just want to write that more descriptive. All the stuff we can get for free is there. And we can still drop down to vanilla SQL if we want. And we do do that. We have some pretty hairy reporting queries, and we're not writing them in ORM speak, because they're big enough already. If you start using the DSL of your ORM, they become an obfuscation. And the reason we're doing that is it allows us to kind of isolate some of the legacy issues in the schema. Again, 20-year-old app, organically growing schema, you can have some issues like this. And we can kind of nicely abstract them away in the ORM that we're using. Put this down as stuff hack and use says, you know, just fix your schema and things will break and you might see it. And it's like, no, we're not going to risk the business by breaking stuff. We don't move fast and break things. You know, we want to keep our customers happy. And then another suggestion is, well, why don't you write your own? But why would you do that? You know, we could abstract all our logic into an ORM, but it'd be half done one full of the bugs that all of the available ones have kind of already ironed out anyway. And yeah, we're using DRX class. Very feature-rich, but not dogmatic about its use. It's like, say, you can use it in ways you want to use it. Some of the issues and challenges around that, well, there's a learning curve, a big learning curve, especially if you haven't used an ORM before. But the manual is very good. Lots of stuff on the web you can find about how to do, you know, quite bespoke things with it. Currently, I say unmaintained, I would say stable rather than maintained. There are talks happening to kind of address this because it's a backlog of patches that could be applied and that kind of thing. And I did talk about this, I want to say, six years ago, using a legacy schema with the big class and how you can address some of those issues that you might have in your schema. Business objects, the model. So the older code is kind of a procedural mashup of business logic, database access, new logic, and so on. So it's all kind of smushed into the same layer. The newer code we're factoring into business objects. And the key is that the business objects are our model. Our ORM is not our model. People often kind of conflate the two. And the reason we're doing it is to get all of this stuff. If you're doing object-oriented coding properly, you get all of this really nice stuff. It's not just calling a method on an instance of a class. You get really powerful, useful things. And we're using Moose. And we were previously using mouse, but we're kind of moving to Moose reasons that I won't go into here. Karina is one to eventually look at. That's been added to the core in 538, the early version. Ovid's going to talk about that a bit later, so I won't go into that too much. But just a quick example, this is kind of the thing we're doing. We're dealing with payments, so we have this incoming payment class, and it has an attribute that references a bank statement, so we're having type constraints. So we can properly constrain that it has to be an object of this type with an ID, and we can throw a useful exception if we try and put something in there that shouldn't be in there. And then we can use the tell-on-ask principle. We can say fail that payment, and then the logic is in one place. And we're throwing exceptions if things aren't in the right state, and then we're delegating to the bank statement object to then fail its payment. So it's all nicely isolated, easy to test. So yeah, Moose, again, what are the issues and the challenges? Well again, the learning curve, if you've not used much object-oriented programming, this is a big paradigm shift. But I think it's worth it, because I think Moose is one of the best object systems available across any language. And then you add the mop, meta-object programming, and you can use introspection and everything. Pearl's very powerful about introspection. And there's been multi-day courses at Pearl Conference that's talking about Moose, so it's impossible for me to even scratch the surface in a small section of a 20-minute talk. People often talk about the slow startup if you're using some of these frameworks and systems, but if it's in a persistent process, a modulator server, that's not an issue. You load it once, it's loaded. If it's on the command line, well yeah, it used to be slow, but now it's things have caught up, and you're probably running those command line scripts once in a blue moon anyway. CGI scripts, we do use some of this, but we lazy load. So these are pages that are taking a couple of seconds to run their commands anyway, so the compile time of loading some of those subjects is a tiny percentage of that anyway. Yeah, mutable state, that's my technical debt. It's one of the things you learn, you know, mutable state is bad, so all our new code and your objects are immutable objects. Refactoring and regression testing, and I'm talking about beyond unit and integration testing because that's kind of the easy stuff. We're adding this for all new code, and mind we do refactoring, we're making sure there's test coverage there and addressing any gaps. But what about those critical business scripts that have existed forever and have no test coverage and basically run the business? I mean, how do you adjust bootstrapping problem of refactoring so you can work easy with them but there's no tests, but you don't want to refactor them because there's no tests, it's kind of a catch-22 situation. Well, this is Pearl, so we've got some useful features we can use to work around that. One of the frameworks we've come up with is we are creating override libraries that we pass into scripts that allows us to override various functions at various times in the lifecycle of that script that runs. So here we are overriding the call to file slippers read text method by saying run this script with this override library path and then we have these various blocks that will override calls so we can kind of monkey patch things. So we can add as much test coverage as we need and then start changing the script. So that's kind of an example of how we do it, a bit down in the weeds, but I would encourage you to watch this talk by Nick. He talked about this at the Pearl and Racket conference last year. It goes into all the details of how you can do this, which blocks you can use to run when, how it works and some of the issues around doing that because you're actually adding technical debt when you do this, but we need that test coverage there. So the aim is get the test coverage in place, the fact of the scripts, the fact of the test coverage, we're in a better place. This has been critical for some of the scripts we have because I mean they literally run the business and they literally have no test coverage while they have test coverage now. Like I said, we don't move fast and break things. Contributing to C pan. So yeah, we actively encourage contributions to C pan. These are all the distributions that we've either written or taken over maintenance of in the last decade, which is the time I've been a pay prop. Stuff like some modulus plugins. So there's this plugin for NMIT, modulus that allows you to profile your routes using NMIT prof. It's really useful. I wrote some of this OAuth 2 server stuff. If you've ever used OAuth 2 and tried to implement server side stuff, it's a fun game. That hopefully makes it a bit easier. Third party payment libraries. We interact with third party payment providers so we've written some stuff. Go Caldlis do direct debit in the UK. TrueLayer is a new opencomer. They're using the open banking spec so I think they're going to get quite big in the coming years. And other stuff, so we maintain CGI.pm because we still have CGI scripts. We can maintain un-maintained libraries, Google Maps stuff and all that kind of stuff. The issues and challenges around that, well, the pool of contributors to C pan is shrinking. Libraries for newer services and APIs don't exist. Often you'll find third party libraries for languages except Pearl, which is a shame. Modern APIs are restful and easy to create a third party library for. We're happy to throw somebody at it for a week or two, which is what we did with the TrueLayer one. They threw me at it for a week and there's one on C pan. Navigating around IP issues, well, that encourages to decouple our code. So that's actually quite a good thing. And finally, hiring devs new to Pearl. I say Pearl has been on the plateau of productivity for quite a while. Those that left it a long time ago don't know the current ecosystem. But more than a generation removed from even Pearl 5. Pearl 1 was released in 1987 and actually probably Larry was prototyping it a long time before that. 510, which can be considered modern Pearl, there are people starting a university now that were born after 510 came out. But it's still in a lot of places and I know that because we've interviewed people. Some of these users can't talk about it. Banks, the fangs, I won't emphasize which letter in the fangs, but we know there's people using Pearl in these places. So I think the rumors of Pearl's demise are greatly exaggerated, but it's kind of a known unknown at this point. And it's still be using Greenfield projects, so the system that Fosdham used to review, annotate, cut, process, transcode and publish all of their videos runs on modern Pearl. So over a thousand videos this weekend are going through a modern Pearl system. And its popularity is kind of normalized over the last two decades, I think. So it's had to find Pearl developers. But newcomers don't have preconceptions. That's my experience of interviewing anyway. I think those under 30 either haven't heard of the language or haven't used it. And those who don't want to use it self-select out of the process anyway. Because we are explicit that we use Pearl in our job specs. We just don't require it unless we're hiring a senior Pearl developer. And I find modern Pearl is an interesting and enjoyable language to work with. Working with legacy code is not specifically a Pearl thing. And we make sure to do all of this stuff, because you should be doing all of this stuff. And we're finding in a distributed work environment you need to do all of this stuff. I've not really talked about this much in the past, but I have written blog posts. So check out the blog posts if you're interested. And the key is that you can still be very experienced, but still a newcomer. And that's absolutely fine. And I think it's actually beneficial to the ecosystem and the community. So if you are, please speak up. You want to hear from you. And that's it. I don't think I have time for questions. So thank you very much. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 2.0, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 50464], "temperature": 0.0, "avg_logprob": -0.5111582735751538, "compression_ratio": 1.2777777777777777, "no_speech_prob": 0.3685417175292969}, {"id": 1, "seek": 0, "start": 2.0, "end": 21.36, "text": " This is a QR code for the slides and also all of the talks I reference in this talk.", "tokens": [50464, 639, 307, 257, 32784, 3089, 337, 264, 9788, 293, 611, 439, 295, 264, 6686, 286, 6408, 294, 341, 751, 13, 51432], "temperature": 0.0, "avg_logprob": -0.5111582735751538, "compression_ratio": 1.2777777777777777, "no_speech_prob": 0.3685417175292969}, {"id": 2, "seek": 0, "start": 21.36, "end": 27.36, "text": " And yeah, thank you Theo for organizing the poll in Raku Devroom.", "tokens": [51432, 400, 1338, 11, 1309, 291, 42519, 337, 17608, 264, 6418, 294, 497, 15803, 9096, 2861, 13, 51732], "temperature": 0.0, "avg_logprob": -0.5111582735751538, "compression_ratio": 1.2777777777777777, "no_speech_prob": 0.3685417175292969}, {"id": 3, "seek": 2736, "start": 27.36, "end": 29.88, "text": " I'm going to talk about, you can all hear me okay?", "tokens": [50364, 286, 478, 516, 281, 751, 466, 11, 291, 393, 439, 1568, 385, 1392, 30, 50490], "temperature": 0.0, "avg_logprob": -0.20233554527407788, "compression_ratio": 1.6613545816733069, "no_speech_prob": 0.8032585382461548}, {"id": 4, "seek": 2736, "start": 29.88, "end": 31.24, "text": " Yeah, perfect.", "tokens": [50490, 865, 11, 2176, 13, 50558], "temperature": 0.0, "avg_logprob": -0.20233554527407788, "compression_ratio": 1.6613545816733069, "no_speech_prob": 0.8032585382461548}, {"id": 5, "seek": 2736, "start": 31.24, "end": 36.36, "text": " I'm going to talk about Pearl at PayProp, which is a company I work for, an established company,", "tokens": [50558, 286, 478, 516, 281, 751, 466, 24639, 412, 11431, 47, 1513, 11, 597, 307, 257, 2237, 286, 589, 337, 11, 364, 7545, 2237, 11, 50814], "temperature": 0.0, "avg_logprob": -0.20233554527407788, "compression_ratio": 1.6613545816733069, "no_speech_prob": 0.8032585382461548}, {"id": 6, "seek": 2736, "start": 36.36, "end": 40.56, "text": " been around for almost 25 years now.", "tokens": [50814, 668, 926, 337, 1920, 3552, 924, 586, 13, 51024], "temperature": 0.0, "avg_logprob": -0.20233554527407788, "compression_ratio": 1.6613545816733069, "no_speech_prob": 0.8032585382461548}, {"id": 7, "seek": 2736, "start": 40.56, "end": 45.760000000000005, "text": " And briefly about me, I don't normally do this, but I see a few faces I don't recognize", "tokens": [51024, 400, 10515, 466, 385, 11, 286, 500, 380, 5646, 360, 341, 11, 457, 286, 536, 257, 1326, 8475, 286, 500, 380, 5521, 51284], "temperature": 0.0, "avg_logprob": -0.20233554527407788, "compression_ratio": 1.6613545816733069, "no_speech_prob": 0.8032585382461548}, {"id": 8, "seek": 2736, "start": 45.760000000000005, "end": 50.519999999999996, "text": " and I'm sure people don't recognize me as well, so I thought I would do this.", "tokens": [51284, 293, 286, 478, 988, 561, 500, 380, 5521, 385, 382, 731, 11, 370, 286, 1194, 286, 576, 360, 341, 13, 51522], "temperature": 0.0, "avg_logprob": -0.20233554527407788, "compression_ratio": 1.6613545816733069, "no_speech_prob": 0.8032585382461548}, {"id": 9, "seek": 2736, "start": 50.519999999999996, "end": 55.239999999999995, "text": " I'm a senior dev and head of processing at PayProp.", "tokens": [51522, 286, 478, 257, 7965, 1905, 293, 1378, 295, 9007, 412, 11431, 47, 1513, 13, 51758], "temperature": 0.0, "avg_logprob": -0.20233554527407788, "compression_ratio": 1.6613545816733069, "no_speech_prob": 0.8032585382461548}, {"id": 10, "seek": 5524, "start": 55.24, "end": 58.08, "text": " I've been there for 10 years.", "tokens": [50364, 286, 600, 668, 456, 337, 1266, 924, 13, 50506], "temperature": 0.0, "avg_logprob": -0.21112030744552612, "compression_ratio": 1.685483870967742, "no_speech_prob": 0.08129199594259262}, {"id": 11, "seek": 5524, "start": 58.08, "end": 60.760000000000005, "text": " I've been a developer for just over 20 years.", "tokens": [50506, 286, 600, 668, 257, 10754, 337, 445, 670, 945, 924, 13, 50640], "temperature": 0.0, "avg_logprob": -0.21112030744552612, "compression_ratio": 1.685483870967742, "no_speech_prob": 0.08129199594259262}, {"id": 12, "seek": 5524, "start": 60.760000000000005, "end": 63.92, "text": " I've worked with various languages, but mostly Pearl.", "tokens": [50640, 286, 600, 2732, 365, 3683, 8650, 11, 457, 5240, 24639, 13, 50798], "temperature": 0.0, "avg_logprob": -0.21112030744552612, "compression_ratio": 1.685483870967742, "no_speech_prob": 0.08129199594259262}, {"id": 13, "seek": 5524, "start": 63.92, "end": 67.36, "text": " But I've only worked for three companies in the time I've been in that 20 years, so I've", "tokens": [50798, 583, 286, 600, 787, 2732, 337, 1045, 3431, 294, 264, 565, 286, 600, 668, 294, 300, 945, 924, 11, 370, 286, 600, 50970], "temperature": 0.0, "avg_logprob": -0.21112030744552612, "compression_ratio": 1.685483870967742, "no_speech_prob": 0.08129199594259262}, {"id": 14, "seek": 5524, "start": 67.36, "end": 72.84, "text": " kind of seen tech stacks grow and shrink and change.", "tokens": [50970, 733, 295, 1612, 7553, 30792, 1852, 293, 23060, 293, 1319, 13, 51244], "temperature": 0.0, "avg_logprob": -0.21112030744552612, "compression_ratio": 1.685483870967742, "no_speech_prob": 0.08129199594259262}, {"id": 15, "seek": 5524, "start": 72.84, "end": 78.84, "text": " I'm a C-Pone contributor, so Lijo, I'm a C-Pone, Meta-C-Pone.", "tokens": [51244, 286, 478, 257, 383, 12, 47, 546, 42859, 11, 370, 441, 24510, 11, 286, 478, 257, 383, 12, 47, 546, 11, 6377, 64, 12, 34, 12, 47, 546, 13, 51544], "temperature": 0.0, "avg_logprob": -0.21112030744552612, "compression_ratio": 1.685483870967742, "no_speech_prob": 0.08129199594259262}, {"id": 16, "seek": 5524, "start": 78.84, "end": 83.52000000000001, "text": " And I'm a London and Swiss Pearl and Raku workshop organizer, so come and talk to me", "tokens": [51544, 400, 286, 478, 257, 7042, 293, 21965, 24639, 293, 497, 15803, 13541, 41363, 11, 370, 808, 293, 751, 281, 385, 51778], "temperature": 0.0, "avg_logprob": -0.21112030744552612, "compression_ratio": 1.685483870967742, "no_speech_prob": 0.08129199594259262}, {"id": 17, "seek": 8352, "start": 83.52, "end": 85.67999999999999, "text": " if you're interested in any of those.", "tokens": [50364, 498, 291, 434, 3102, 294, 604, 295, 729, 13, 50472], "temperature": 0.0, "avg_logprob": -0.20775943332248265, "compression_ratio": 1.6411290322580645, "no_speech_prob": 0.22250023484230042}, {"id": 18, "seek": 8352, "start": 85.67999999999999, "end": 89.11999999999999, "text": " We're searching for a venue for this year's London Pearl workshop, so if you have any", "tokens": [50472, 492, 434, 10808, 337, 257, 21645, 337, 341, 1064, 311, 7042, 24639, 13541, 11, 370, 498, 291, 362, 604, 50644], "temperature": 0.0, "avg_logprob": -0.20775943332248265, "compression_ratio": 1.6411290322580645, "no_speech_prob": 0.22250023484230042}, {"id": 19, "seek": 8352, "start": 89.11999999999999, "end": 93.6, "text": " ideas, come and talk to me.", "tokens": [50644, 3487, 11, 808, 293, 751, 281, 385, 13, 50868], "temperature": 0.0, "avg_logprob": -0.20775943332248265, "compression_ratio": 1.6411290322580645, "no_speech_prob": 0.22250023484230042}, {"id": 20, "seek": 8352, "start": 93.6, "end": 98.16, "text": " And I'm a regular speaker at other Pearl workshops and conferences, and often I'm helping out", "tokens": [50868, 400, 286, 478, 257, 3890, 8145, 412, 661, 24639, 19162, 293, 22032, 11, 293, 2049, 286, 478, 4315, 484, 51096], "temperature": 0.0, "avg_logprob": -0.20775943332248265, "compression_ratio": 1.6411290322580645, "no_speech_prob": 0.22250023484230042}, {"id": 21, "seek": 8352, "start": 98.16, "end": 101.16, "text": " with the video.", "tokens": [51096, 365, 264, 960, 13, 51246], "temperature": 0.0, "avg_logprob": -0.20775943332248265, "compression_ratio": 1.6411290322580645, "no_speech_prob": 0.22250023484230042}, {"id": 22, "seek": 8352, "start": 101.16, "end": 102.64, "text": " And I occasionally blog on Pearl.", "tokens": [51246, 400, 286, 16895, 6968, 322, 24639, 13, 51320], "temperature": 0.0, "avg_logprob": -0.20775943332248265, "compression_ratio": 1.6411290322580645, "no_speech_prob": 0.22250023484230042}, {"id": 23, "seek": 8352, "start": 102.64, "end": 108.47999999999999, "text": " I prefer to do long form articles rather than technical kind of, this is how you use this", "tokens": [51320, 286, 4382, 281, 360, 938, 1254, 11290, 2831, 813, 6191, 733, 295, 11, 341, 307, 577, 291, 764, 341, 51612], "temperature": 0.0, "avg_logprob": -0.20775943332248265, "compression_ratio": 1.6411290322580645, "no_speech_prob": 0.22250023484230042}, {"id": 24, "seek": 8352, "start": 108.47999999999999, "end": 110.47999999999999, "text": " module kind of posts.", "tokens": [51612, 10088, 733, 295, 12300, 13, 51712], "temperature": 0.0, "avg_logprob": -0.20775943332248265, "compression_ratio": 1.6411290322580645, "no_speech_prob": 0.22250023484230042}, {"id": 25, "seek": 11048, "start": 111.48, "end": 116.28, "text": " And I run the Pearl events Instagram account, but that's about the limit of my social media", "tokens": [50414, 400, 286, 1190, 264, 24639, 3931, 5281, 2696, 11, 457, 300, 311, 466, 264, 4948, 295, 452, 2093, 3021, 50654], "temperature": 0.0, "avg_logprob": -0.21624027598987927, "compression_ratio": 1.5982142857142858, "no_speech_prob": 0.08022992312908173}, {"id": 26, "seek": 11048, "start": 116.28, "end": 117.28, "text": " interaction.", "tokens": [50654, 9285, 13, 50704], "temperature": 0.0, "avg_logprob": -0.21624027598987927, "compression_ratio": 1.5982142857142858, "no_speech_prob": 0.08022992312908173}, {"id": 27, "seek": 11048, "start": 117.28, "end": 122.56, "text": " And I'm a Fosdum Newsbie, so my first time here.", "tokens": [50704, 400, 286, 478, 257, 479, 329, 67, 449, 7987, 7392, 11, 370, 452, 700, 565, 510, 13, 50968], "temperature": 0.0, "avg_logprob": -0.21624027598987927, "compression_ratio": 1.5982142857142858, "no_speech_prob": 0.08022992312908173}, {"id": 28, "seek": 11048, "start": 122.56, "end": 126.92, "text": " We usually have a work event that runs at this time of year, so it always clashes with", "tokens": [50968, 492, 2673, 362, 257, 589, 2280, 300, 6676, 412, 341, 565, 295, 1064, 11, 370, 309, 1009, 596, 12808, 365, 51186], "temperature": 0.0, "avg_logprob": -0.21624027598987927, "compression_ratio": 1.5982142857142858, "no_speech_prob": 0.08022992312908173}, {"id": 29, "seek": 11048, "start": 126.92, "end": 130.68, "text": " Fosdum, so I've never managed to make it, so this is the first time it hasn't clashed", "tokens": [51186, 479, 329, 67, 449, 11, 370, 286, 600, 1128, 6453, 281, 652, 309, 11, 370, 341, 307, 264, 700, 565, 309, 6132, 380, 596, 12219, 51374], "temperature": 0.0, "avg_logprob": -0.21624027598987927, "compression_ratio": 1.5982142857142858, "no_speech_prob": 0.08022992312908173}, {"id": 30, "seek": 11048, "start": 130.68, "end": 135.64000000000001, "text": " with Fosdum.", "tokens": [51374, 365, 479, 329, 67, 449, 13, 51622], "temperature": 0.0, "avg_logprob": -0.21624027598987927, "compression_ratio": 1.5982142857142858, "no_speech_prob": 0.08022992312908173}, {"id": 31, "seek": 11048, "start": 135.64000000000001, "end": 136.76, "text": " So about paper op.", "tokens": [51622, 407, 466, 3035, 999, 13, 51678], "temperature": 0.0, "avg_logprob": -0.21624027598987927, "compression_ratio": 1.5982142857142858, "no_speech_prob": 0.08022992312908173}, {"id": 32, "seek": 13676, "start": 137.76, "end": 141.64, "text": " That's what kind of what we look like, the public facing part of the site at least.", "tokens": [50414, 663, 311, 437, 733, 295, 437, 321, 574, 411, 11, 264, 1908, 7170, 644, 295, 264, 3621, 412, 1935, 13, 50608], "temperature": 0.0, "avg_logprob": -0.20861657843532333, "compression_ratio": 1.6, "no_speech_prob": 0.19973443448543549}, {"id": 33, "seek": 13676, "start": 141.64, "end": 147.84, "text": " We're a payment and reconciliation platform for the residential letting industry.", "tokens": [50608, 492, 434, 257, 10224, 293, 31281, 3663, 337, 264, 17389, 8295, 3518, 13, 50918], "temperature": 0.0, "avg_logprob": -0.20861657843532333, "compression_ratio": 1.6, "no_speech_prob": 0.19973443448543549}, {"id": 34, "seek": 13676, "start": 147.84, "end": 154.12, "text": " And we kind of, our core business value is we turn things like this, and this is one", "tokens": [50918, 400, 321, 733, 295, 11, 527, 4965, 1606, 2158, 307, 321, 1261, 721, 411, 341, 11, 293, 341, 307, 472, 51232], "temperature": 0.0, "avg_logprob": -0.20861657843532333, "compression_ratio": 1.6, "no_speech_prob": 0.19973443448543549}, {"id": 35, "seek": 13676, "start": 154.12, "end": 155.51999999999998, "text": " of the nicer ones to deal with.", "tokens": [51232, 295, 264, 22842, 2306, 281, 2028, 365, 13, 51302], "temperature": 0.0, "avg_logprob": -0.20861657843532333, "compression_ratio": 1.6, "no_speech_prob": 0.19973443448543549}, {"id": 36, "seek": 13676, "start": 155.51999999999998, "end": 160.95999999999998, "text": " This is a Swift format into things like this.", "tokens": [51302, 639, 307, 257, 25539, 7877, 666, 721, 411, 341, 13, 51574], "temperature": 0.0, "avg_logprob": -0.20861657843532333, "compression_ratio": 1.6, "no_speech_prob": 0.19973443448543549}, {"id": 37, "seek": 16096, "start": 160.96, "end": 167.8, "text": " So we put interfaces and automation on tank consuming payment reconciliation flows.", "tokens": [50364, 407, 321, 829, 28416, 293, 17769, 322, 5466, 19867, 10224, 31281, 12867, 13, 50706], "temperature": 0.0, "avg_logprob": -0.22085370620091757, "compression_ratio": 1.4795081967213115, "no_speech_prob": 0.049475524574518204}, {"id": 38, "seek": 16096, "start": 167.8, "end": 174.04000000000002, "text": " And this literally saves our customers hours, days, weeks of time, so we're really, really", "tokens": [50706, 400, 341, 3736, 19155, 527, 4581, 2496, 11, 1708, 11, 3259, 295, 565, 11, 370, 321, 434, 534, 11, 534, 51018], "temperature": 0.0, "avg_logprob": -0.22085370620091757, "compression_ratio": 1.4795081967213115, "no_speech_prob": 0.049475524574518204}, {"id": 39, "seek": 16096, "start": 174.04000000000002, "end": 175.04000000000002, "text": " useful to them.", "tokens": [51018, 4420, 281, 552, 13, 51068], "temperature": 0.0, "avg_logprob": -0.22085370620091757, "compression_ratio": 1.4795081967213115, "no_speech_prob": 0.049475524574518204}, {"id": 40, "seek": 16096, "start": 175.04000000000002, "end": 180.88, "text": " The key night of you might see CGI bin script.cgi in that URL.", "tokens": [51068, 440, 2141, 1818, 295, 291, 1062, 536, 48448, 5171, 5755, 13, 66, 7834, 294, 300, 12905, 13, 51360], "temperature": 0.0, "avg_logprob": -0.22085370620091757, "compression_ratio": 1.4795081967213115, "no_speech_prob": 0.049475524574518204}, {"id": 41, "seek": 16096, "start": 180.88, "end": 186.64000000000001, "text": " So yeah, we've been around for over 20 years, so we have some old code, bit of an understatement", "tokens": [51360, 407, 1338, 11, 321, 600, 668, 926, 337, 670, 945, 924, 11, 370, 321, 362, 512, 1331, 3089, 11, 857, 295, 364, 833, 19435, 1712, 51648], "temperature": 0.0, "avg_logprob": -0.22085370620091757, "compression_ratio": 1.4795081967213115, "no_speech_prob": 0.049475524574518204}, {"id": 42, "seek": 16096, "start": 186.64000000000001, "end": 188.76000000000002, "text": " in places.", "tokens": [51648, 294, 3190, 13, 51754], "temperature": 0.0, "avg_logprob": -0.22085370620091757, "compression_ratio": 1.4795081967213115, "no_speech_prob": 0.049475524574518204}, {"id": 43, "seek": 18876, "start": 188.76, "end": 194.92, "text": " But the pearl we are using is relatively modern, 532.", "tokens": [50364, 583, 264, 20287, 321, 366, 1228, 307, 7226, 4363, 11, 1025, 11440, 13, 50672], "temperature": 0.0, "avg_logprob": -0.16774086479668146, "compression_ratio": 1.7226890756302522, "no_speech_prob": 0.009443465620279312}, {"id": 44, "seek": 18876, "start": 194.92, "end": 200.32, "text": " And we build our own pearl, and we don't use the vendor supplied pearl or the system pearl.", "tokens": [50672, 400, 321, 1322, 527, 1065, 20287, 11, 293, 321, 500, 380, 764, 264, 24321, 27625, 20287, 420, 264, 1185, 20287, 13, 50942], "temperature": 0.0, "avg_logprob": -0.16774086479668146, "compression_ratio": 1.7226890756302522, "no_speech_prob": 0.009443465620279312}, {"id": 45, "seek": 18876, "start": 200.32, "end": 202.04, "text": " We don't do anything special with it.", "tokens": [50942, 492, 500, 380, 360, 1340, 2121, 365, 309, 13, 51028], "temperature": 0.0, "avg_logprob": -0.16774086479668146, "compression_ratio": 1.7226890756302522, "no_speech_prob": 0.009443465620279312}, {"id": 46, "seek": 18876, "start": 202.04, "end": 207.16, "text": " We could in theory compile it with different flags, but we don't do that.", "tokens": [51028, 492, 727, 294, 5261, 31413, 309, 365, 819, 23265, 11, 457, 321, 500, 380, 360, 300, 13, 51284], "temperature": 0.0, "avg_logprob": -0.16774086479668146, "compression_ratio": 1.7226890756302522, "no_speech_prob": 0.009443465620279312}, {"id": 47, "seek": 18876, "start": 207.16, "end": 211.79999999999998, "text": " So we get the defaults, which means we don't get things like iThreads, because if you use", "tokens": [51284, 407, 321, 483, 264, 7576, 82, 11, 597, 1355, 321, 500, 380, 483, 721, 411, 741, 2434, 2538, 82, 11, 570, 498, 291, 764, 51516], "temperature": 0.0, "avg_logprob": -0.16774086479668146, "compression_ratio": 1.7226890756302522, "no_speech_prob": 0.009443465620279312}, {"id": 48, "seek": 18876, "start": 211.79999999999998, "end": 215.76, "text": " vendor supplied pearl, you get things you probably don't need.", "tokens": [51516, 24321, 27625, 20287, 11, 291, 483, 721, 291, 1391, 500, 380, 643, 13, 51714], "temperature": 0.0, "avg_logprob": -0.16774086479668146, "compression_ratio": 1.7226890756302522, "no_speech_prob": 0.009443465620279312}, {"id": 49, "seek": 21576, "start": 216.76, "end": 220.28, "text": " Yeah, the key is that it's not the system pearl.", "tokens": [50414, 865, 11, 264, 2141, 307, 300, 309, 311, 406, 264, 1185, 20287, 13, 50590], "temperature": 0.0, "avg_logprob": -0.18731996851059998, "compression_ratio": 1.495798319327731, "no_speech_prob": 0.014832575805485249}, {"id": 50, "seek": 21576, "start": 220.28, "end": 225.95999999999998, "text": " So we're not kind of tied to any particular version of an OS or package or whatever.", "tokens": [50590, 407, 321, 434, 406, 733, 295, 9601, 281, 604, 1729, 3037, 295, 364, 12731, 420, 7372, 420, 2035, 13, 50874], "temperature": 0.0, "avg_logprob": -0.18731996851059998, "compression_ratio": 1.495798319327731, "no_speech_prob": 0.014832575805485249}, {"id": 51, "seek": 21576, "start": 225.95999999999998, "end": 230.56, "text": " And we can apply updates and patches as necessary.", "tokens": [50874, 400, 321, 393, 3079, 9205, 293, 26531, 382, 4818, 13, 51104], "temperature": 0.0, "avg_logprob": -0.18731996851059998, "compression_ratio": 1.495798319327731, "no_speech_prob": 0.014832575805485249}, {"id": 52, "seek": 21576, "start": 230.56, "end": 232.68, "text": " We should be on 538 by now.", "tokens": [51104, 492, 820, 312, 322, 1025, 12625, 538, 586, 13, 51210], "temperature": 0.0, "avg_logprob": -0.18731996851059998, "compression_ratio": 1.495798319327731, "no_speech_prob": 0.014832575805485249}, {"id": 53, "seek": 21576, "start": 232.68, "end": 235.16, "text": " We tend to trail a major version.", "tokens": [51210, 492, 3928, 281, 9924, 257, 2563, 3037, 13, 51334], "temperature": 0.0, "avg_logprob": -0.18731996851059998, "compression_ratio": 1.495798319327731, "no_speech_prob": 0.014832575805485249}, {"id": 54, "seek": 21576, "start": 235.16, "end": 239.6, "text": " I've been spread a bit thin, so we haven't managed to get to latest, but that's on the", "tokens": [51334, 286, 600, 668, 3974, 257, 857, 5862, 11, 370, 321, 2378, 380, 6453, 281, 483, 281, 6792, 11, 457, 300, 311, 322, 264, 51556], "temperature": 0.0, "avg_logprob": -0.18731996851059998, "compression_ratio": 1.495798319327731, "no_speech_prob": 0.014832575805485249}, {"id": 55, "seek": 21576, "start": 239.6, "end": 241.35999999999999, "text": " roadmap for this year.", "tokens": [51556, 35738, 337, 341, 1064, 13, 51644], "temperature": 0.0, "avg_logprob": -0.18731996851059998, "compression_ratio": 1.495798319327731, "no_speech_prob": 0.014832575805485249}, {"id": 56, "seek": 24136, "start": 242.36, "end": 246.16000000000003, "text": " Yeah, and it gives us dependency control, which is critical.", "tokens": [50414, 865, 11, 293, 309, 2709, 505, 33621, 1969, 11, 597, 307, 4924, 13, 50604], "temperature": 0.0, "avg_logprob": -0.23594055573145548, "compression_ratio": 1.5485232067510548, "no_speech_prob": 0.004841586574912071}, {"id": 57, "seek": 24136, "start": 246.16000000000003, "end": 249.88000000000002, "text": " If you've been paying attention the last couple of weeks, there's been a couple of", "tokens": [50604, 759, 291, 600, 668, 6229, 3202, 264, 1036, 1916, 295, 3259, 11, 456, 311, 668, 257, 1916, 295, 50790], "temperature": 0.0, "avg_logprob": -0.23594055573145548, "compression_ratio": 1.5485232067510548, "no_speech_prob": 0.004841586574912071}, {"id": 58, "seek": 24136, "start": 249.88000000000002, "end": 256.40000000000003, "text": " critical CVEs against a couple of spreadsheet passing modules, so we could get those updates", "tokens": [50790, 4924, 383, 7540, 82, 1970, 257, 1916, 295, 27733, 8437, 16679, 11, 370, 321, 727, 483, 729, 9205, 51116], "temperature": 0.0, "avg_logprob": -0.23594055573145548, "compression_ratio": 1.5485232067510548, "no_speech_prob": 0.004841586574912071}, {"id": 59, "seek": 24136, "start": 256.40000000000003, "end": 257.64, "text": " out quite quickly.", "tokens": [51116, 484, 1596, 2661, 13, 51178], "temperature": 0.0, "avg_logprob": -0.23594055573145548, "compression_ratio": 1.5485232067510548, "no_speech_prob": 0.004841586574912071}, {"id": 60, "seek": 24136, "start": 259.64, "end": 265.40000000000003, "text": " Loose coupling, so yeah, like I said, not tied to the OS or anything like that.", "tokens": [51278, 6130, 541, 37447, 11, 370, 1338, 11, 411, 286, 848, 11, 406, 9601, 281, 264, 12731, 420, 1340, 411, 300, 13, 51566], "temperature": 0.0, "avg_logprob": -0.23594055573145548, "compression_ratio": 1.5485232067510548, "no_speech_prob": 0.004841586574912071}, {"id": 61, "seek": 24136, "start": 265.40000000000003, "end": 266.72, "text": " And the key is it's everywhere.", "tokens": [51566, 400, 264, 2141, 307, 309, 311, 5315, 13, 51632], "temperature": 0.0, "avg_logprob": -0.23594055573145548, "compression_ratio": 1.5485232067510548, "no_speech_prob": 0.004841586574912071}, {"id": 62, "seek": 26672, "start": 266.72, "end": 271.68, "text": " So we have the same version of pearl, the same version of modules from dev through CI", "tokens": [50364, 407, 321, 362, 264, 912, 3037, 295, 20287, 11, 264, 912, 3037, 295, 16679, 490, 1905, 807, 37777, 50612], "temperature": 0.0, "avg_logprob": -0.3161492347717285, "compression_ratio": 1.6199095022624435, "no_speech_prob": 0.0036743509117513895}, {"id": 63, "seek": 26672, "start": 271.68, "end": 274.48, "text": " staging demo all the way to production.", "tokens": [50612, 41085, 10723, 439, 264, 636, 281, 4265, 13, 50752], "temperature": 0.0, "avg_logprob": -0.3161492347717285, "compression_ratio": 1.6199095022624435, "no_speech_prob": 0.0036743509117513895}, {"id": 64, "seek": 26672, "start": 274.48, "end": 278.8, "text": " So otherwise you get interesting debugging problems.", "tokens": [50752, 407, 5911, 291, 483, 1880, 45592, 2740, 13, 50968], "temperature": 0.0, "avg_logprob": -0.3161492347717285, "compression_ratio": 1.6199095022624435, "no_speech_prob": 0.0036743509117513895}, {"id": 65, "seek": 26672, "start": 278.8, "end": 285.96000000000004, "text": " And while the issues and challenges around that, well, probably the ones you've all heard,", "tokens": [50968, 400, 1339, 264, 2663, 293, 4759, 926, 300, 11, 731, 11, 1391, 264, 2306, 291, 600, 439, 2198, 11, 51326], "temperature": 0.0, "avg_logprob": -0.3161492347717285, "compression_ratio": 1.6199095022624435, "no_speech_prob": 0.0036743509117513895}, {"id": 66, "seek": 26672, "start": 285.96000000000004, "end": 292.6, "text": " you know, still use pearl or even what is pearl, and the bus factor, which is, you know,", "tokens": [51326, 291, 458, 11, 920, 764, 20287, 420, 754, 437, 307, 20287, 11, 293, 264, 1255, 5952, 11, 597, 307, 11, 291, 458, 11, 51658], "temperature": 0.0, "avg_logprob": -0.3161492347717285, "compression_ratio": 1.6199095022624435, "no_speech_prob": 0.0036743509117513895}, {"id": 67, "seek": 29260, "start": 292.64000000000004, "end": 296.44, "text": " becoming a problem with some of the pearl dependencies.", "tokens": [50366, 5617, 257, 1154, 365, 512, 295, 264, 20287, 36606, 13, 50556], "temperature": 0.0, "avg_logprob": -0.2425974346342541, "compression_ratio": 1.4805194805194806, "no_speech_prob": 0.07872982323169708}, {"id": 68, "seek": 29260, "start": 299.0, "end": 303.44, "text": " So yeah, it's a 20-year-old, 22-year-old app, so we are in the process of migrating", "tokens": [50684, 407, 1338, 11, 309, 311, 257, 945, 12, 5294, 12, 2641, 11, 5853, 12, 5294, 12, 2641, 724, 11, 370, 321, 366, 294, 264, 1399, 295, 6186, 8754, 50906], "temperature": 0.0, "avg_logprob": -0.2425974346342541, "compression_ratio": 1.4805194805194806, "no_speech_prob": 0.07872982323169708}, {"id": 69, "seek": 29260, "start": 303.44, "end": 305.64000000000004, "text": " from CGI.pm to Modulicious.", "tokens": [50906, 490, 48448, 13, 14395, 281, 6583, 425, 3784, 13, 51016], "temperature": 0.0, "avg_logprob": -0.2425974346342541, "compression_ratio": 1.4805194805194806, "no_speech_prob": 0.07872982323169708}, {"id": 70, "seek": 29260, "start": 305.64000000000004, "end": 312.04, "text": " A 20-year-old app has some legacy, a bit of an understatement really.", "tokens": [51016, 316, 945, 12, 5294, 12, 2641, 724, 575, 512, 11711, 11, 257, 857, 295, 364, 833, 19435, 1712, 534, 13, 51336], "temperature": 0.0, "avg_logprob": -0.2425974346342541, "compression_ratio": 1.4805194805194806, "no_speech_prob": 0.07872982323169708}, {"id": 71, "seek": 29260, "start": 312.04, "end": 317.52000000000004, "text": " This is an ongoing task, and we're about two-thirds complete in terms of number of requests to", "tokens": [51336, 639, 307, 364, 10452, 5633, 11, 293, 321, 434, 466, 732, 12, 38507, 3566, 294, 2115, 295, 1230, 295, 12475, 281, 51610], "temperature": 0.0, "avg_logprob": -0.2425974346342541, "compression_ratio": 1.4805194805194806, "no_speech_prob": 0.07872982323169708}, {"id": 72, "seek": 29260, "start": 317.52000000000004, "end": 318.64000000000004, "text": " the site.", "tokens": [51610, 264, 3621, 13, 51666], "temperature": 0.0, "avg_logprob": -0.2425974346342541, "compression_ratio": 1.4805194805194806, "no_speech_prob": 0.07872982323169708}, {"id": 73, "seek": 31864, "start": 319.64, "end": 325.84, "text": " We have a lot more pages than we really use after 20 years.", "tokens": [50414, 492, 362, 257, 688, 544, 7183, 813, 321, 534, 764, 934, 945, 924, 13, 50724], "temperature": 0.0, "avg_logprob": -0.1691455841064453, "compression_ratio": 1.6178861788617886, "no_speech_prob": 0.0050424025394022465}, {"id": 74, "seek": 31864, "start": 325.84, "end": 331.2, "text": " Kind of inevitably happens that people write features and functionality that end up not", "tokens": [50724, 9242, 295, 28171, 2314, 300, 561, 2464, 4122, 293, 14980, 300, 917, 493, 406, 50992], "temperature": 0.0, "avg_logprob": -0.1691455841064453, "compression_ratio": 1.6178861788617886, "no_speech_prob": 0.0050424025394022465}, {"id": 75, "seek": 31864, "start": 331.2, "end": 337.15999999999997, "text": " being used, and we've got hundreds of pages, and really only 20% of them are actively used.", "tokens": [50992, 885, 1143, 11, 293, 321, 600, 658, 6779, 295, 7183, 11, 293, 534, 787, 945, 4, 295, 552, 366, 13022, 1143, 13, 51290], "temperature": 0.0, "avg_logprob": -0.1691455841064453, "compression_ratio": 1.6178861788617886, "no_speech_prob": 0.0050424025394022465}, {"id": 76, "seek": 31864, "start": 337.15999999999997, "end": 341.84, "text": " So a lot of them will never actually end up getting converted.", "tokens": [51290, 407, 257, 688, 295, 552, 486, 1128, 767, 917, 493, 1242, 16424, 13, 51524], "temperature": 0.0, "avg_logprob": -0.1691455841064453, "compression_ratio": 1.6178861788617886, "no_speech_prob": 0.0050424025394022465}, {"id": 77, "seek": 31864, "start": 341.84, "end": 346.76, "text": " And one of the ways we did this in one of our other apps is using this plugin from Modulicious.", "tokens": [51524, 400, 472, 295, 264, 2098, 321, 630, 341, 294, 472, 295, 527, 661, 7733, 307, 1228, 341, 23407, 490, 6583, 425, 3784, 13, 51770], "temperature": 0.0, "avg_logprob": -0.1691455841064453, "compression_ratio": 1.6178861788617886, "no_speech_prob": 0.0050424025394022465}, {"id": 78, "seek": 34676, "start": 346.76, "end": 353.2, "text": " And we decided not to do this with PayProp because we're using Apache on the front end", "tokens": [50364, 400, 321, 3047, 406, 281, 360, 341, 365, 11431, 47, 1513, 570, 321, 434, 1228, 46597, 322, 264, 1868, 917, 50686], "temperature": 0.0, "avg_logprob": -0.19925415272615393, "compression_ratio": 1.579185520361991, "no_speech_prob": 0.006061517167836428}, {"id": 79, "seek": 34676, "start": 353.2, "end": 360.8, "text": " anyway, so we can kind of proxy to a Modulicious server or just run exec CGI if it's CGI script.", "tokens": [50686, 4033, 11, 370, 321, 393, 733, 295, 29690, 281, 257, 6583, 425, 3784, 7154, 420, 445, 1190, 4454, 48448, 498, 309, 311, 48448, 5755, 13, 51066], "temperature": 0.0, "avg_logprob": -0.19925415272615393, "compression_ratio": 1.579185520361991, "no_speech_prob": 0.006061517167836428}, {"id": 80, "seek": 34676, "start": 360.8, "end": 365.92, "text": " So we're not doing a kind of serving the CGI scripts from Modulicious using a plugin.", "tokens": [51066, 407, 321, 434, 406, 884, 257, 733, 295, 8148, 264, 48448, 23294, 490, 6583, 425, 3784, 1228, 257, 23407, 13, 51322], "temperature": 0.0, "avg_logprob": -0.19925415272615393, "compression_ratio": 1.579185520361991, "no_speech_prob": 0.006061517167836428}, {"id": 81, "seek": 34676, "start": 365.92, "end": 368.88, "text": " There's no real value there, to be honest.", "tokens": [51322, 821, 311, 572, 957, 2158, 456, 11, 281, 312, 3245, 13, 51470], "temperature": 0.0, "avg_logprob": -0.19925415272615393, "compression_ratio": 1.579185520361991, "no_speech_prob": 0.006061517167836428}, {"id": 82, "seek": 34676, "start": 368.88, "end": 371.28, "text": " So that's kind of what the setup is.", "tokens": [51470, 407, 300, 311, 733, 295, 437, 264, 8657, 307, 13, 51590], "temperature": 0.0, "avg_logprob": -0.19925415272615393, "compression_ratio": 1.579185520361991, "no_speech_prob": 0.006061517167836428}, {"id": 83, "seek": 37128, "start": 372.28, "end": 378.79999999999995, "text": " I actually gave a talk about this almost a decade ago, so there's a link there to that talk,", "tokens": [50414, 286, 767, 2729, 257, 751, 466, 341, 1920, 257, 10378, 2057, 11, 370, 456, 311, 257, 2113, 456, 281, 300, 751, 11, 50740], "temperature": 0.0, "avg_logprob": -0.18242317775510392, "compression_ratio": 1.6337448559670782, "no_speech_prob": 0.002811273094266653}, {"id": 84, "seek": 37128, "start": 378.79999999999995, "end": 383.03999999999996, "text": " which has some suggestions for how you can do this if you're using CGI.", "tokens": [50740, 597, 575, 512, 13396, 337, 577, 291, 393, 360, 341, 498, 291, 434, 1228, 48448, 13, 50952], "temperature": 0.0, "avg_logprob": -0.18242317775510392, "compression_ratio": 1.6337448559670782, "no_speech_prob": 0.002811273094266653}, {"id": 85, "seek": 37128, "start": 383.03999999999996, "end": 386.23999999999995, "text": " You want to use Modulicious, what the options are.", "tokens": [50952, 509, 528, 281, 764, 6583, 425, 3784, 11, 437, 264, 3956, 366, 13, 51112], "temperature": 0.0, "avg_logprob": -0.18242317775510392, "compression_ratio": 1.6337448559670782, "no_speech_prob": 0.002811273094266653}, {"id": 86, "seek": 37128, "start": 386.23999999999995, "end": 392.55999999999995, "text": " But it was 10 years ago, so it's a little bit out of date now, because Modulicious moves", "tokens": [51112, 583, 309, 390, 1266, 924, 2057, 11, 370, 309, 311, 257, 707, 857, 484, 295, 4002, 586, 11, 570, 6583, 425, 3784, 6067, 51428], "temperature": 0.0, "avg_logprob": -0.18242317775510392, "compression_ratio": 1.6337448559670782, "no_speech_prob": 0.002811273094266653}, {"id": 87, "seek": 37128, "start": 392.55999999999995, "end": 400.79999999999995, "text": " fast, and it is one of the challenges in using it because they say that you can always count", "tokens": [51428, 2370, 11, 293, 309, 307, 472, 295, 264, 4759, 294, 1228, 309, 570, 436, 584, 300, 291, 393, 1009, 1207, 51840], "temperature": 0.0, "avg_logprob": -0.18242317775510392, "compression_ratio": 1.6337448559670782, "no_speech_prob": 0.002811273094266653}, {"id": 88, "seek": 40080, "start": 400.8, "end": 405.96000000000004, "text": " on backwards compatibility, but they will deprecate and remove features within a three-month", "tokens": [50364, 322, 12204, 34237, 11, 457, 436, 486, 1367, 13867, 473, 293, 4159, 4122, 1951, 257, 1045, 12, 23534, 50622], "temperature": 0.0, "avg_logprob": -0.1855165741660378, "compression_ratio": 1.559090909090909, "no_speech_prob": 0.04086235165596008}, {"id": 89, "seek": 40080, "start": 405.96000000000004, "end": 409.40000000000003, "text": " window, which is not really backwards compatibility.", "tokens": [50622, 4910, 11, 597, 307, 406, 534, 12204, 34237, 13, 50794], "temperature": 0.0, "avg_logprob": -0.1855165741660378, "compression_ratio": 1.559090909090909, "no_speech_prob": 0.04086235165596008}, {"id": 90, "seek": 40080, "start": 409.40000000000003, "end": 415.52000000000004, "text": " So you just have to be aware that if you haven't done an update in a while, things might break.", "tokens": [50794, 407, 291, 445, 362, 281, 312, 3650, 300, 498, 291, 2378, 380, 1096, 364, 5623, 294, 257, 1339, 11, 721, 1062, 1821, 13, 51100], "temperature": 0.0, "avg_logprob": -0.1855165741660378, "compression_ratio": 1.559090909090909, "no_speech_prob": 0.04086235165596008}, {"id": 91, "seek": 40080, "start": 419.12, "end": 421.24, "text": " And we're adding an ORM.", "tokens": [51280, 400, 321, 434, 5127, 364, 19654, 44, 13, 51386], "temperature": 0.0, "avg_logprob": -0.1855165741660378, "compression_ratio": 1.559090909090909, "no_speech_prob": 0.04086235165596008}, {"id": 92, "seek": 40080, "start": 421.24, "end": 426.6, "text": " And I know this can be a contentious issue, which I kind of find surprising.", "tokens": [51386, 400, 286, 458, 341, 393, 312, 257, 2701, 851, 2734, 11, 597, 286, 733, 295, 915, 8830, 13, 51654], "temperature": 0.0, "avg_logprob": -0.1855165741660378, "compression_ratio": 1.559090909090909, "no_speech_prob": 0.04086235165596008}, {"id": 93, "seek": 42660, "start": 426.6, "end": 430.12, "text": " I'm just title writing this kind of stuff.", "tokens": [50364, 286, 478, 445, 4876, 3579, 341, 733, 295, 1507, 13, 50540], "temperature": 0.0, "avg_logprob": -0.238527598006002, "compression_ratio": 1.5424528301886793, "no_speech_prob": 0.011633682996034622}, {"id": 94, "seek": 42660, "start": 430.12, "end": 435.52000000000004, "text": " And this is a simplified, about as simple as the query you can do.", "tokens": [50540, 400, 341, 307, 257, 26335, 11, 466, 382, 2199, 382, 264, 14581, 291, 393, 360, 13, 50810], "temperature": 0.0, "avg_logprob": -0.238527598006002, "compression_ratio": 1.5424528301886793, "no_speech_prob": 0.011633682996034622}, {"id": 95, "seek": 42660, "start": 435.52000000000004, "end": 439.88, "text": " So you select some columns from the table, prepare the query, make sure you have the error handling,", "tokens": [50810, 407, 291, 3048, 512, 13766, 490, 264, 3199, 11, 5940, 264, 14581, 11, 652, 988, 291, 362, 264, 6713, 13175, 11, 51028], "temperature": 0.0, "avg_logprob": -0.238527598006002, "compression_ratio": 1.5424528301886793, "no_speech_prob": 0.011633682996034622}, {"id": 96, "seek": 42660, "start": 439.88, "end": 442.24, "text": " execute it, grab a hash ref.", "tokens": [51028, 14483, 309, 11, 4444, 257, 22019, 1895, 13, 51146], "temperature": 0.0, "avg_logprob": -0.238527598006002, "compression_ratio": 1.5424528301886793, "no_speech_prob": 0.011633682996034622}, {"id": 97, "seek": 42660, "start": 442.24, "end": 450.0, "text": " I just want to write that more descriptive.", "tokens": [51146, 286, 445, 528, 281, 2464, 300, 544, 42585, 13, 51534], "temperature": 0.0, "avg_logprob": -0.238527598006002, "compression_ratio": 1.5424528301886793, "no_speech_prob": 0.011633682996034622}, {"id": 98, "seek": 42660, "start": 450.0, "end": 456.12, "text": " All the stuff we can get for free is there.", "tokens": [51534, 1057, 264, 1507, 321, 393, 483, 337, 1737, 307, 456, 13, 51840], "temperature": 0.0, "avg_logprob": -0.238527598006002, "compression_ratio": 1.5424528301886793, "no_speech_prob": 0.011633682996034622}, {"id": 99, "seek": 45612, "start": 456.16, "end": 458.56, "text": " And we can still drop down to vanilla SQL if we want.", "tokens": [50366, 400, 321, 393, 920, 3270, 760, 281, 17528, 19200, 498, 321, 528, 13, 50486], "temperature": 0.0, "avg_logprob": -0.19365140633989675, "compression_ratio": 1.6013986013986015, "no_speech_prob": 0.00344446231611073}, {"id": 100, "seek": 45612, "start": 458.56, "end": 459.56, "text": " And we do do that.", "tokens": [50486, 400, 321, 360, 360, 300, 13, 50536], "temperature": 0.0, "avg_logprob": -0.19365140633989675, "compression_ratio": 1.6013986013986015, "no_speech_prob": 0.00344446231611073}, {"id": 101, "seek": 45612, "start": 459.56, "end": 465.2, "text": " We have some pretty hairy reporting queries, and we're not writing them in ORM speak, because", "tokens": [50536, 492, 362, 512, 1238, 42346, 10031, 24109, 11, 293, 321, 434, 406, 3579, 552, 294, 19654, 44, 1710, 11, 570, 50818], "temperature": 0.0, "avg_logprob": -0.19365140633989675, "compression_ratio": 1.6013986013986015, "no_speech_prob": 0.00344446231611073}, {"id": 102, "seek": 45612, "start": 465.2, "end": 466.96, "text": " they're big enough already.", "tokens": [50818, 436, 434, 955, 1547, 1217, 13, 50906], "temperature": 0.0, "avg_logprob": -0.19365140633989675, "compression_ratio": 1.6013986013986015, "no_speech_prob": 0.00344446231611073}, {"id": 103, "seek": 45612, "start": 466.96, "end": 475.08, "text": " If you start using the DSL of your ORM, they become an obfuscation.", "tokens": [50906, 759, 291, 722, 1228, 264, 15816, 43, 295, 428, 19654, 44, 11, 436, 1813, 364, 1111, 69, 32601, 399, 13, 51312], "temperature": 0.0, "avg_logprob": -0.19365140633989675, "compression_ratio": 1.6013986013986015, "no_speech_prob": 0.00344446231611073}, {"id": 104, "seek": 45612, "start": 475.08, "end": 480.72, "text": " And the reason we're doing that is it allows us to kind of isolate some of the legacy issues", "tokens": [51312, 400, 264, 1778, 321, 434, 884, 300, 307, 309, 4045, 505, 281, 733, 295, 25660, 512, 295, 264, 11711, 2663, 51594], "temperature": 0.0, "avg_logprob": -0.19365140633989675, "compression_ratio": 1.6013986013986015, "no_speech_prob": 0.00344446231611073}, {"id": 105, "seek": 45612, "start": 480.72, "end": 481.72, "text": " in the schema.", "tokens": [51594, 294, 264, 34078, 13, 51644], "temperature": 0.0, "avg_logprob": -0.19365140633989675, "compression_ratio": 1.6013986013986015, "no_speech_prob": 0.00344446231611073}, {"id": 106, "seek": 45612, "start": 481.72, "end": 485.8, "text": " Again, 20-year-old app, organically growing schema, you can have some issues like this.", "tokens": [51644, 3764, 11, 945, 12, 5294, 12, 2641, 724, 11, 1798, 984, 4194, 34078, 11, 291, 393, 362, 512, 2663, 411, 341, 13, 51848], "temperature": 0.0, "avg_logprob": -0.19365140633989675, "compression_ratio": 1.6013986013986015, "no_speech_prob": 0.00344446231611073}, {"id": 107, "seek": 48580, "start": 486.8, "end": 493.12, "text": " And we can kind of nicely abstract them away in the ORM that we're using.", "tokens": [50414, 400, 321, 393, 733, 295, 9594, 12649, 552, 1314, 294, 264, 19654, 44, 300, 321, 434, 1228, 13, 50730], "temperature": 0.0, "avg_logprob": -0.19193622983735184, "compression_ratio": 1.5916030534351144, "no_speech_prob": 0.003383625065907836}, {"id": 108, "seek": 48580, "start": 493.12, "end": 499.2, "text": " Put this down as stuff hack and use says, you know, just fix your schema and things will", "tokens": [50730, 4935, 341, 760, 382, 1507, 10339, 293, 764, 1619, 11, 291, 458, 11, 445, 3191, 428, 34078, 293, 721, 486, 51034], "temperature": 0.0, "avg_logprob": -0.19193622983735184, "compression_ratio": 1.5916030534351144, "no_speech_prob": 0.003383625065907836}, {"id": 109, "seek": 48580, "start": 499.2, "end": 500.76, "text": " break and you might see it.", "tokens": [51034, 1821, 293, 291, 1062, 536, 309, 13, 51112], "temperature": 0.0, "avg_logprob": -0.19193622983735184, "compression_ratio": 1.5916030534351144, "no_speech_prob": 0.003383625065907836}, {"id": 110, "seek": 48580, "start": 500.76, "end": 505.76, "text": " And it's like, no, we're not going to risk the business by breaking stuff.", "tokens": [51112, 400, 309, 311, 411, 11, 572, 11, 321, 434, 406, 516, 281, 3148, 264, 1606, 538, 7697, 1507, 13, 51362], "temperature": 0.0, "avg_logprob": -0.19193622983735184, "compression_ratio": 1.5916030534351144, "no_speech_prob": 0.003383625065907836}, {"id": 111, "seek": 48580, "start": 505.76, "end": 507.32, "text": " We don't move fast and break things.", "tokens": [51362, 492, 500, 380, 1286, 2370, 293, 1821, 721, 13, 51440], "temperature": 0.0, "avg_logprob": -0.19193622983735184, "compression_ratio": 1.5916030534351144, "no_speech_prob": 0.003383625065907836}, {"id": 112, "seek": 48580, "start": 507.32, "end": 510.96000000000004, "text": " You know, we want to keep our customers happy.", "tokens": [51440, 509, 458, 11, 321, 528, 281, 1066, 527, 4581, 2055, 13, 51622], "temperature": 0.0, "avg_logprob": -0.19193622983735184, "compression_ratio": 1.5916030534351144, "no_speech_prob": 0.003383625065907836}, {"id": 113, "seek": 48580, "start": 510.96000000000004, "end": 514.16, "text": " And then another suggestion is, well, why don't you write your own?", "tokens": [51622, 400, 550, 1071, 16541, 307, 11, 731, 11, 983, 500, 380, 291, 2464, 428, 1065, 30, 51782], "temperature": 0.0, "avg_logprob": -0.19193622983735184, "compression_ratio": 1.5916030534351144, "no_speech_prob": 0.003383625065907836}, {"id": 114, "seek": 51416, "start": 514.16, "end": 516.04, "text": " But why would you do that?", "tokens": [50364, 583, 983, 576, 291, 360, 300, 30, 50458], "temperature": 0.0, "avg_logprob": -0.28502333397958796, "compression_ratio": 1.4889867841409692, "no_speech_prob": 0.001983567839488387}, {"id": 115, "seek": 51416, "start": 516.04, "end": 521.24, "text": " You know, we could abstract all our logic into an ORM, but it'd be half done one full of", "tokens": [50458, 509, 458, 11, 321, 727, 12649, 439, 527, 9952, 666, 364, 19654, 44, 11, 457, 309, 1116, 312, 1922, 1096, 472, 1577, 295, 50718], "temperature": 0.0, "avg_logprob": -0.28502333397958796, "compression_ratio": 1.4889867841409692, "no_speech_prob": 0.001983567839488387}, {"id": 116, "seek": 51416, "start": 521.24, "end": 524.76, "text": " the bugs that all of the available ones have kind of already ironed out anyway.", "tokens": [50718, 264, 15120, 300, 439, 295, 264, 2435, 2306, 362, 733, 295, 1217, 6497, 292, 484, 4033, 13, 50894], "temperature": 0.0, "avg_logprob": -0.28502333397958796, "compression_ratio": 1.4889867841409692, "no_speech_prob": 0.001983567839488387}, {"id": 117, "seek": 51416, "start": 524.76, "end": 532.0, "text": " And yeah, we're using DRX class.", "tokens": [50894, 400, 1338, 11, 321, 434, 1228, 12118, 55, 1508, 13, 51256], "temperature": 0.0, "avg_logprob": -0.28502333397958796, "compression_ratio": 1.4889867841409692, "no_speech_prob": 0.001983567839488387}, {"id": 118, "seek": 51416, "start": 532.0, "end": 535.88, "text": " Very feature-rich, but not dogmatic about its use.", "tokens": [51256, 4372, 4111, 12, 10794, 11, 457, 406, 3000, 25915, 466, 1080, 764, 13, 51450], "temperature": 0.0, "avg_logprob": -0.28502333397958796, "compression_ratio": 1.4889867841409692, "no_speech_prob": 0.001983567839488387}, {"id": 119, "seek": 51416, "start": 535.88, "end": 543.0, "text": " It's like, say, you can use it in ways you want to use it.", "tokens": [51450, 467, 311, 411, 11, 584, 11, 291, 393, 764, 309, 294, 2098, 291, 528, 281, 764, 309, 13, 51806], "temperature": 0.0, "avg_logprob": -0.28502333397958796, "compression_ratio": 1.4889867841409692, "no_speech_prob": 0.001983567839488387}, {"id": 120, "seek": 54300, "start": 543.0, "end": 548.64, "text": " Some of the issues and challenges around that, well, there's a learning curve, a big learning", "tokens": [50364, 2188, 295, 264, 2663, 293, 4759, 926, 300, 11, 731, 11, 456, 311, 257, 2539, 7605, 11, 257, 955, 2539, 50646], "temperature": 0.0, "avg_logprob": -0.21302211390132397, "compression_ratio": 1.568840579710145, "no_speech_prob": 0.032352421432733536}, {"id": 121, "seek": 54300, "start": 548.64, "end": 552.36, "text": " curve, especially if you haven't used an ORM before.", "tokens": [50646, 7605, 11, 2318, 498, 291, 2378, 380, 1143, 364, 19654, 44, 949, 13, 50832], "temperature": 0.0, "avg_logprob": -0.21302211390132397, "compression_ratio": 1.568840579710145, "no_speech_prob": 0.032352421432733536}, {"id": 122, "seek": 54300, "start": 552.36, "end": 554.2, "text": " But the manual is very good.", "tokens": [50832, 583, 264, 9688, 307, 588, 665, 13, 50924], "temperature": 0.0, "avg_logprob": -0.21302211390132397, "compression_ratio": 1.568840579710145, "no_speech_prob": 0.032352421432733536}, {"id": 123, "seek": 54300, "start": 554.2, "end": 558.28, "text": " Lots of stuff on the web you can find about how to do, you know, quite bespoke things", "tokens": [50924, 15908, 295, 1507, 322, 264, 3670, 291, 393, 915, 466, 577, 281, 360, 11, 291, 458, 11, 1596, 4097, 48776, 721, 51128], "temperature": 0.0, "avg_logprob": -0.21302211390132397, "compression_ratio": 1.568840579710145, "no_speech_prob": 0.032352421432733536}, {"id": 124, "seek": 54300, "start": 558.28, "end": 559.28, "text": " with it.", "tokens": [51128, 365, 309, 13, 51178], "temperature": 0.0, "avg_logprob": -0.21302211390132397, "compression_ratio": 1.568840579710145, "no_speech_prob": 0.032352421432733536}, {"id": 125, "seek": 54300, "start": 559.28, "end": 566.2, "text": " Currently, I say unmaintained, I would say stable rather than maintained.", "tokens": [51178, 19964, 11, 286, 584, 19334, 5114, 3563, 11, 286, 576, 584, 8351, 2831, 813, 17578, 13, 51524], "temperature": 0.0, "avg_logprob": -0.21302211390132397, "compression_ratio": 1.568840579710145, "no_speech_prob": 0.032352421432733536}, {"id": 126, "seek": 54300, "start": 566.2, "end": 571.6, "text": " There are talks happening to kind of address this because it's a backlog of patches that", "tokens": [51524, 821, 366, 6686, 2737, 281, 733, 295, 2985, 341, 570, 309, 311, 257, 47364, 295, 26531, 300, 51794], "temperature": 0.0, "avg_logprob": -0.21302211390132397, "compression_ratio": 1.568840579710145, "no_speech_prob": 0.032352421432733536}, {"id": 127, "seek": 57160, "start": 571.6, "end": 574.52, "text": " could be applied and that kind of thing.", "tokens": [50364, 727, 312, 6456, 293, 300, 733, 295, 551, 13, 50510], "temperature": 0.0, "avg_logprob": -0.17739941353021665, "compression_ratio": 1.5781990521327014, "no_speech_prob": 0.07080300897359848}, {"id": 128, "seek": 57160, "start": 574.52, "end": 580.88, "text": " And I did talk about this, I want to say, six years ago, using a legacy schema with the", "tokens": [50510, 400, 286, 630, 751, 466, 341, 11, 286, 528, 281, 584, 11, 2309, 924, 2057, 11, 1228, 257, 11711, 34078, 365, 264, 50828], "temperature": 0.0, "avg_logprob": -0.17739941353021665, "compression_ratio": 1.5781990521327014, "no_speech_prob": 0.07080300897359848}, {"id": 129, "seek": 57160, "start": 580.88, "end": 589.48, "text": " big class and how you can address some of those issues that you might have in your schema.", "tokens": [50828, 955, 1508, 293, 577, 291, 393, 2985, 512, 295, 729, 2663, 300, 291, 1062, 362, 294, 428, 34078, 13, 51258], "temperature": 0.0, "avg_logprob": -0.17739941353021665, "compression_ratio": 1.5781990521327014, "no_speech_prob": 0.07080300897359848}, {"id": 130, "seek": 57160, "start": 589.48, "end": 592.72, "text": " Business objects, the model.", "tokens": [51258, 10715, 6565, 11, 264, 2316, 13, 51420], "temperature": 0.0, "avg_logprob": -0.17739941353021665, "compression_ratio": 1.5781990521327014, "no_speech_prob": 0.07080300897359848}, {"id": 131, "seek": 57160, "start": 592.72, "end": 598.1600000000001, "text": " So the older code is kind of a procedural mashup of business logic, database access,", "tokens": [51420, 407, 264, 4906, 3089, 307, 733, 295, 257, 43951, 31344, 1010, 295, 1606, 9952, 11, 8149, 2105, 11, 51692], "temperature": 0.0, "avg_logprob": -0.17739941353021665, "compression_ratio": 1.5781990521327014, "no_speech_prob": 0.07080300897359848}, {"id": 132, "seek": 59816, "start": 598.16, "end": 600.4, "text": " new logic, and so on.", "tokens": [50364, 777, 9952, 11, 293, 370, 322, 13, 50476], "temperature": 0.0, "avg_logprob": -0.18242692525407908, "compression_ratio": 1.7117903930131004, "no_speech_prob": 0.05353481322526932}, {"id": 133, "seek": 59816, "start": 600.4, "end": 603.88, "text": " So it's all kind of smushed into the same layer.", "tokens": [50476, 407, 309, 311, 439, 733, 295, 899, 1498, 292, 666, 264, 912, 4583, 13, 50650], "temperature": 0.0, "avg_logprob": -0.18242692525407908, "compression_ratio": 1.7117903930131004, "no_speech_prob": 0.05353481322526932}, {"id": 134, "seek": 59816, "start": 603.88, "end": 606.3199999999999, "text": " The newer code we're factoring into business objects.", "tokens": [50650, 440, 17628, 3089, 321, 434, 1186, 3662, 666, 1606, 6565, 13, 50772], "temperature": 0.0, "avg_logprob": -0.18242692525407908, "compression_ratio": 1.7117903930131004, "no_speech_prob": 0.05353481322526932}, {"id": 135, "seek": 59816, "start": 606.3199999999999, "end": 609.7199999999999, "text": " And the key is that the business objects are our model.", "tokens": [50772, 400, 264, 2141, 307, 300, 264, 1606, 6565, 366, 527, 2316, 13, 50942], "temperature": 0.0, "avg_logprob": -0.18242692525407908, "compression_ratio": 1.7117903930131004, "no_speech_prob": 0.05353481322526932}, {"id": 136, "seek": 59816, "start": 609.7199999999999, "end": 611.92, "text": " Our ORM is not our model.", "tokens": [50942, 2621, 19654, 44, 307, 406, 527, 2316, 13, 51052], "temperature": 0.0, "avg_logprob": -0.18242692525407908, "compression_ratio": 1.7117903930131004, "no_speech_prob": 0.05353481322526932}, {"id": 137, "seek": 59816, "start": 611.92, "end": 616.24, "text": " People often kind of conflate the two.", "tokens": [51052, 3432, 2049, 733, 295, 1497, 17593, 264, 732, 13, 51268], "temperature": 0.0, "avg_logprob": -0.18242692525407908, "compression_ratio": 1.7117903930131004, "no_speech_prob": 0.05353481322526932}, {"id": 138, "seek": 59816, "start": 616.24, "end": 621.92, "text": " And the reason we're doing it is to get all of this stuff.", "tokens": [51268, 400, 264, 1778, 321, 434, 884, 309, 307, 281, 483, 439, 295, 341, 1507, 13, 51552], "temperature": 0.0, "avg_logprob": -0.18242692525407908, "compression_ratio": 1.7117903930131004, "no_speech_prob": 0.05353481322526932}, {"id": 139, "seek": 59816, "start": 621.92, "end": 625.68, "text": " If you're doing object-oriented coding properly, you get all of this really nice stuff.", "tokens": [51552, 759, 291, 434, 884, 2657, 12, 27414, 17720, 6108, 11, 291, 483, 439, 295, 341, 534, 1481, 1507, 13, 51740], "temperature": 0.0, "avg_logprob": -0.18242692525407908, "compression_ratio": 1.7117903930131004, "no_speech_prob": 0.05353481322526932}, {"id": 140, "seek": 62568, "start": 625.68, "end": 628.88, "text": " It's not just calling a method on an instance of a class.", "tokens": [50364, 467, 311, 406, 445, 5141, 257, 3170, 322, 364, 5197, 295, 257, 1508, 13, 50524], "temperature": 0.0, "avg_logprob": -0.25287368449758973, "compression_ratio": 1.4837209302325582, "no_speech_prob": 0.04393695294857025}, {"id": 141, "seek": 62568, "start": 628.88, "end": 635.92, "text": " You get really powerful, useful things.", "tokens": [50524, 509, 483, 534, 4005, 11, 4420, 721, 13, 50876], "temperature": 0.0, "avg_logprob": -0.25287368449758973, "compression_ratio": 1.4837209302325582, "no_speech_prob": 0.04393695294857025}, {"id": 142, "seek": 62568, "start": 635.92, "end": 638.8, "text": " And we're using Moose.", "tokens": [50876, 400, 321, 434, 1228, 3335, 541, 13, 51020], "temperature": 0.0, "avg_logprob": -0.25287368449758973, "compression_ratio": 1.4837209302325582, "no_speech_prob": 0.04393695294857025}, {"id": 143, "seek": 62568, "start": 638.8, "end": 644.3599999999999, "text": " And we were previously using mouse, but we're kind of moving to Moose reasons that I won't", "tokens": [51020, 400, 321, 645, 8046, 1228, 9719, 11, 457, 321, 434, 733, 295, 2684, 281, 3335, 541, 4112, 300, 286, 1582, 380, 51298], "temperature": 0.0, "avg_logprob": -0.25287368449758973, "compression_ratio": 1.4837209302325582, "no_speech_prob": 0.04393695294857025}, {"id": 144, "seek": 62568, "start": 644.3599999999999, "end": 646.2399999999999, "text": " go into here.", "tokens": [51298, 352, 666, 510, 13, 51392], "temperature": 0.0, "avg_logprob": -0.25287368449758973, "compression_ratio": 1.4837209302325582, "no_speech_prob": 0.04393695294857025}, {"id": 145, "seek": 62568, "start": 646.2399999999999, "end": 648.8399999999999, "text": " Karina is one to eventually look at.", "tokens": [51392, 8009, 1426, 307, 472, 281, 4728, 574, 412, 13, 51522], "temperature": 0.0, "avg_logprob": -0.25287368449758973, "compression_ratio": 1.4837209302325582, "no_speech_prob": 0.04393695294857025}, {"id": 146, "seek": 62568, "start": 648.8399999999999, "end": 653.4, "text": " That's been added to the core in 538, the early version.", "tokens": [51522, 663, 311, 668, 3869, 281, 264, 4965, 294, 1025, 12625, 11, 264, 2440, 3037, 13, 51750], "temperature": 0.0, "avg_logprob": -0.25287368449758973, "compression_ratio": 1.4837209302325582, "no_speech_prob": 0.04393695294857025}, {"id": 147, "seek": 65340, "start": 654.4, "end": 660.28, "text": " Ovid's going to talk about that a bit later, so I won't go into that too much.", "tokens": [50414, 422, 6833, 311, 516, 281, 751, 466, 300, 257, 857, 1780, 11, 370, 286, 1582, 380, 352, 666, 300, 886, 709, 13, 50708], "temperature": 0.0, "avg_logprob": -0.16928924002298495, "compression_ratio": 1.6914893617021276, "no_speech_prob": 0.01535431481897831}, {"id": 148, "seek": 65340, "start": 660.28, "end": 663.3199999999999, "text": " But just a quick example, this is kind of the thing we're doing.", "tokens": [50708, 583, 445, 257, 1702, 1365, 11, 341, 307, 733, 295, 264, 551, 321, 434, 884, 13, 50860], "temperature": 0.0, "avg_logprob": -0.16928924002298495, "compression_ratio": 1.6914893617021276, "no_speech_prob": 0.01535431481897831}, {"id": 149, "seek": 65340, "start": 663.3199999999999, "end": 667.84, "text": " We're dealing with payments, so we have this incoming payment class, and it has an attribute", "tokens": [50860, 492, 434, 6260, 365, 14348, 11, 370, 321, 362, 341, 22341, 10224, 1508, 11, 293, 309, 575, 364, 19667, 51086], "temperature": 0.0, "avg_logprob": -0.16928924002298495, "compression_ratio": 1.6914893617021276, "no_speech_prob": 0.01535431481897831}, {"id": 150, "seek": 65340, "start": 667.84, "end": 673.8, "text": " that references a bank statement, so we're having type constraints.", "tokens": [51086, 300, 15400, 257, 3765, 5629, 11, 370, 321, 434, 1419, 2010, 18491, 13, 51384], "temperature": 0.0, "avg_logprob": -0.16928924002298495, "compression_ratio": 1.6914893617021276, "no_speech_prob": 0.01535431481897831}, {"id": 151, "seek": 65340, "start": 673.8, "end": 677.92, "text": " So we can properly constrain that it has to be an object of this type with an ID, and", "tokens": [51384, 407, 321, 393, 6108, 1817, 7146, 300, 309, 575, 281, 312, 364, 2657, 295, 341, 2010, 365, 364, 7348, 11, 293, 51590], "temperature": 0.0, "avg_logprob": -0.16928924002298495, "compression_ratio": 1.6914893617021276, "no_speech_prob": 0.01535431481897831}, {"id": 152, "seek": 65340, "start": 677.92, "end": 681.0799999999999, "text": " we can throw a useful exception if we try and put something in there that shouldn't be", "tokens": [51590, 321, 393, 3507, 257, 4420, 11183, 498, 321, 853, 293, 829, 746, 294, 456, 300, 4659, 380, 312, 51748], "temperature": 0.0, "avg_logprob": -0.16928924002298495, "compression_ratio": 1.6914893617021276, "no_speech_prob": 0.01535431481897831}, {"id": 153, "seek": 68108, "start": 681.08, "end": 684.5200000000001, "text": " in there.", "tokens": [50364, 294, 456, 13, 50536], "temperature": 0.0, "avg_logprob": -0.20547758858158904, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.006833918392658234}, {"id": 154, "seek": 68108, "start": 684.5200000000001, "end": 686.48, "text": " And then we can use the tell-on-ask principle.", "tokens": [50536, 400, 550, 321, 393, 764, 264, 980, 12, 266, 12, 3863, 8665, 13, 50634], "temperature": 0.0, "avg_logprob": -0.20547758858158904, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.006833918392658234}, {"id": 155, "seek": 68108, "start": 686.48, "end": 692.12, "text": " We can say fail that payment, and then the logic is in one place.", "tokens": [50634, 492, 393, 584, 3061, 300, 10224, 11, 293, 550, 264, 9952, 307, 294, 472, 1081, 13, 50916], "temperature": 0.0, "avg_logprob": -0.20547758858158904, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.006833918392658234}, {"id": 156, "seek": 68108, "start": 692.12, "end": 696.32, "text": " And we're throwing exceptions if things aren't in the right state, and then we're delegating", "tokens": [50916, 400, 321, 434, 10238, 22847, 498, 721, 3212, 380, 294, 264, 558, 1785, 11, 293, 550, 321, 434, 15824, 990, 51126], "temperature": 0.0, "avg_logprob": -0.20547758858158904, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.006833918392658234}, {"id": 157, "seek": 68108, "start": 696.32, "end": 699.8000000000001, "text": " to the bank statement object to then fail its payment.", "tokens": [51126, 281, 264, 3765, 5629, 2657, 281, 550, 3061, 1080, 10224, 13, 51300], "temperature": 0.0, "avg_logprob": -0.20547758858158904, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.006833918392658234}, {"id": 158, "seek": 68108, "start": 699.8000000000001, "end": 706.84, "text": " So it's all nicely isolated, easy to test.", "tokens": [51300, 407, 309, 311, 439, 9594, 14621, 11, 1858, 281, 1500, 13, 51652], "temperature": 0.0, "avg_logprob": -0.20547758858158904, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.006833918392658234}, {"id": 159, "seek": 68108, "start": 706.84, "end": 709.0400000000001, "text": " So yeah, Moose, again, what are the issues and the challenges?", "tokens": [51652, 407, 1338, 11, 3335, 541, 11, 797, 11, 437, 366, 264, 2663, 293, 264, 4759, 30, 51762], "temperature": 0.0, "avg_logprob": -0.20547758858158904, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.006833918392658234}, {"id": 160, "seek": 70904, "start": 709.04, "end": 713.24, "text": " Well again, the learning curve, if you've not used much object-oriented programming,", "tokens": [50364, 1042, 797, 11, 264, 2539, 7605, 11, 498, 291, 600, 406, 1143, 709, 2657, 12, 27414, 9410, 11, 50574], "temperature": 0.0, "avg_logprob": -0.22077356535812903, "compression_ratio": 1.6389891696750902, "no_speech_prob": 0.054133325815200806}, {"id": 161, "seek": 70904, "start": 713.24, "end": 716.64, "text": " this is a big paradigm shift.", "tokens": [50574, 341, 307, 257, 955, 24709, 5513, 13, 50744], "temperature": 0.0, "avg_logprob": -0.22077356535812903, "compression_ratio": 1.6389891696750902, "no_speech_prob": 0.054133325815200806}, {"id": 162, "seek": 70904, "start": 716.64, "end": 720.36, "text": " But I think it's worth it, because I think Moose is one of the best object systems available", "tokens": [50744, 583, 286, 519, 309, 311, 3163, 309, 11, 570, 286, 519, 3335, 541, 307, 472, 295, 264, 1151, 2657, 3652, 2435, 50930], "temperature": 0.0, "avg_logprob": -0.22077356535812903, "compression_ratio": 1.6389891696750902, "no_speech_prob": 0.054133325815200806}, {"id": 163, "seek": 70904, "start": 720.36, "end": 722.68, "text": " across any language.", "tokens": [50930, 2108, 604, 2856, 13, 51046], "temperature": 0.0, "avg_logprob": -0.22077356535812903, "compression_ratio": 1.6389891696750902, "no_speech_prob": 0.054133325815200806}, {"id": 164, "seek": 70904, "start": 722.68, "end": 728.64, "text": " And then you add the mop, meta-object programming, and you can use introspection and everything.", "tokens": [51046, 400, 550, 291, 909, 264, 48106, 11, 19616, 12, 41070, 9410, 11, 293, 291, 393, 764, 560, 2635, 19997, 293, 1203, 13, 51344], "temperature": 0.0, "avg_logprob": -0.22077356535812903, "compression_ratio": 1.6389891696750902, "no_speech_prob": 0.054133325815200806}, {"id": 165, "seek": 70904, "start": 728.64, "end": 732.7199999999999, "text": " Pearl's very powerful about introspection.", "tokens": [51344, 24639, 311, 588, 4005, 466, 560, 2635, 19997, 13, 51548], "temperature": 0.0, "avg_logprob": -0.22077356535812903, "compression_ratio": 1.6389891696750902, "no_speech_prob": 0.054133325815200806}, {"id": 166, "seek": 70904, "start": 732.7199999999999, "end": 735.48, "text": " And there's been multi-day courses at Pearl Conference that's talking about Moose, so", "tokens": [51548, 400, 456, 311, 668, 4825, 12, 810, 7712, 412, 24639, 22131, 300, 311, 1417, 466, 3335, 541, 11, 370, 51686], "temperature": 0.0, "avg_logprob": -0.22077356535812903, "compression_ratio": 1.6389891696750902, "no_speech_prob": 0.054133325815200806}, {"id": 167, "seek": 73548, "start": 735.48, "end": 740.12, "text": " it's impossible for me to even scratch the surface in a small section of a 20-minute", "tokens": [50364, 309, 311, 6243, 337, 385, 281, 754, 8459, 264, 3753, 294, 257, 1359, 3541, 295, 257, 945, 12, 18256, 50596], "temperature": 0.0, "avg_logprob": -0.18359642028808593, "compression_ratio": 1.5726141078838174, "no_speech_prob": 0.25892940163612366}, {"id": 168, "seek": 73548, "start": 740.12, "end": 743.72, "text": " talk.", "tokens": [50596, 751, 13, 50776], "temperature": 0.0, "avg_logprob": -0.18359642028808593, "compression_ratio": 1.5726141078838174, "no_speech_prob": 0.25892940163612366}, {"id": 169, "seek": 73548, "start": 743.72, "end": 747.52, "text": " People often talk about the slow startup if you're using some of these frameworks and", "tokens": [50776, 3432, 2049, 751, 466, 264, 2964, 18578, 498, 291, 434, 1228, 512, 295, 613, 29834, 293, 50966], "temperature": 0.0, "avg_logprob": -0.18359642028808593, "compression_ratio": 1.5726141078838174, "no_speech_prob": 0.25892940163612366}, {"id": 170, "seek": 73548, "start": 747.52, "end": 752.4, "text": " systems, but if it's in a persistent process, a modulator server, that's not an issue.", "tokens": [50966, 3652, 11, 457, 498, 309, 311, 294, 257, 24315, 1399, 11, 257, 1072, 16381, 7154, 11, 300, 311, 406, 364, 2734, 13, 51210], "temperature": 0.0, "avg_logprob": -0.18359642028808593, "compression_ratio": 1.5726141078838174, "no_speech_prob": 0.25892940163612366}, {"id": 171, "seek": 73548, "start": 752.4, "end": 755.1, "text": " You load it once, it's loaded.", "tokens": [51210, 509, 3677, 309, 1564, 11, 309, 311, 13210, 13, 51345], "temperature": 0.0, "avg_logprob": -0.18359642028808593, "compression_ratio": 1.5726141078838174, "no_speech_prob": 0.25892940163612366}, {"id": 172, "seek": 73548, "start": 755.1, "end": 759.32, "text": " If it's on the command line, well yeah, it used to be slow, but now it's things have", "tokens": [51345, 759, 309, 311, 322, 264, 5622, 1622, 11, 731, 1338, 11, 309, 1143, 281, 312, 2964, 11, 457, 586, 309, 311, 721, 362, 51556], "temperature": 0.0, "avg_logprob": -0.18359642028808593, "compression_ratio": 1.5726141078838174, "no_speech_prob": 0.25892940163612366}, {"id": 173, "seek": 75932, "start": 759.32, "end": 766.4000000000001, "text": " caught up, and you're probably running those command line scripts once in a blue moon anyway.", "tokens": [50364, 5415, 493, 11, 293, 291, 434, 1391, 2614, 729, 5622, 1622, 23294, 1564, 294, 257, 3344, 7135, 4033, 13, 50718], "temperature": 0.0, "avg_logprob": -0.24575990246188256, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.6790081262588501}, {"id": 174, "seek": 75932, "start": 766.4000000000001, "end": 769.5600000000001, "text": " CGI scripts, we do use some of this, but we lazy load.", "tokens": [50718, 48448, 23294, 11, 321, 360, 764, 512, 295, 341, 11, 457, 321, 14847, 3677, 13, 50876], "temperature": 0.0, "avg_logprob": -0.24575990246188256, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.6790081262588501}, {"id": 175, "seek": 75932, "start": 769.5600000000001, "end": 775.44, "text": " So these are pages that are taking a couple of seconds to run their commands anyway, so", "tokens": [50876, 407, 613, 366, 7183, 300, 366, 1940, 257, 1916, 295, 3949, 281, 1190, 641, 16901, 4033, 11, 370, 51170], "temperature": 0.0, "avg_logprob": -0.24575990246188256, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.6790081262588501}, {"id": 176, "seek": 75932, "start": 775.44, "end": 781.48, "text": " the compile time of loading some of those subjects is a tiny percentage of that anyway.", "tokens": [51170, 264, 31413, 565, 295, 15114, 512, 295, 729, 13066, 307, 257, 5870, 9668, 295, 300, 4033, 13, 51472], "temperature": 0.0, "avg_logprob": -0.24575990246188256, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.6790081262588501}, {"id": 177, "seek": 75932, "start": 781.48, "end": 785.8000000000001, "text": " Yeah, mutable state, that's my technical debt.", "tokens": [51472, 865, 11, 5839, 712, 1785, 11, 300, 311, 452, 6191, 7831, 13, 51688], "temperature": 0.0, "avg_logprob": -0.24575990246188256, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.6790081262588501}, {"id": 178, "seek": 78580, "start": 786.3599999999999, "end": 790.5999999999999, "text": " It's one of the things you learn, you know, mutable state is bad, so all our new code", "tokens": [50392, 467, 311, 472, 295, 264, 721, 291, 1466, 11, 291, 458, 11, 5839, 712, 1785, 307, 1578, 11, 370, 439, 527, 777, 3089, 50604], "temperature": 0.0, "avg_logprob": -0.21804065330355776, "compression_ratio": 1.7236842105263157, "no_speech_prob": 0.04297368600964546}, {"id": 179, "seek": 78580, "start": 790.5999999999999, "end": 797.56, "text": " and your objects are immutable objects.", "tokens": [50604, 293, 428, 6565, 366, 3397, 32148, 6565, 13, 50952], "temperature": 0.0, "avg_logprob": -0.21804065330355776, "compression_ratio": 1.7236842105263157, "no_speech_prob": 0.04297368600964546}, {"id": 180, "seek": 78580, "start": 797.56, "end": 801.3199999999999, "text": " Refactoring and regression testing, and I'm talking about beyond unit and integration", "tokens": [50952, 16957, 578, 3662, 293, 24590, 4997, 11, 293, 286, 478, 1417, 466, 4399, 4985, 293, 10980, 51140], "temperature": 0.0, "avg_logprob": -0.21804065330355776, "compression_ratio": 1.7236842105263157, "no_speech_prob": 0.04297368600964546}, {"id": 181, "seek": 78580, "start": 801.3199999999999, "end": 806.9599999999999, "text": " testing because that's kind of the easy stuff.", "tokens": [51140, 4997, 570, 300, 311, 733, 295, 264, 1858, 1507, 13, 51422], "temperature": 0.0, "avg_logprob": -0.21804065330355776, "compression_ratio": 1.7236842105263157, "no_speech_prob": 0.04297368600964546}, {"id": 182, "seek": 78580, "start": 806.9599999999999, "end": 810.8, "text": " We're adding this for all new code, and mind we do refactoring, we're making sure there's", "tokens": [51422, 492, 434, 5127, 341, 337, 439, 777, 3089, 11, 293, 1575, 321, 360, 1895, 578, 3662, 11, 321, 434, 1455, 988, 456, 311, 51614], "temperature": 0.0, "avg_logprob": -0.21804065330355776, "compression_ratio": 1.7236842105263157, "no_speech_prob": 0.04297368600964546}, {"id": 183, "seek": 78580, "start": 810.8, "end": 815.76, "text": " test coverage there and addressing any gaps.", "tokens": [51614, 1500, 9645, 456, 293, 14329, 604, 15031, 13, 51862], "temperature": 0.0, "avg_logprob": -0.21804065330355776, "compression_ratio": 1.7236842105263157, "no_speech_prob": 0.04297368600964546}, {"id": 184, "seek": 81576, "start": 815.76, "end": 822.16, "text": " But what about those critical business scripts that have existed forever and have no test", "tokens": [50364, 583, 437, 466, 729, 4924, 1606, 23294, 300, 362, 13135, 5680, 293, 362, 572, 1500, 50684], "temperature": 0.0, "avg_logprob": -0.235632359296426, "compression_ratio": 1.6103286384976525, "no_speech_prob": 0.0040609147399663925}, {"id": 185, "seek": 81576, "start": 822.16, "end": 826.0, "text": " coverage and basically run the business?", "tokens": [50684, 9645, 293, 1936, 1190, 264, 1606, 30, 50876], "temperature": 0.0, "avg_logprob": -0.235632359296426, "compression_ratio": 1.6103286384976525, "no_speech_prob": 0.0040609147399663925}, {"id": 186, "seek": 81576, "start": 826.0, "end": 833.68, "text": " I mean, how do you adjust bootstrapping problem of refactoring so you can work easy with them", "tokens": [50876, 286, 914, 11, 577, 360, 291, 4369, 11450, 19639, 3759, 1154, 295, 1895, 578, 3662, 370, 291, 393, 589, 1858, 365, 552, 51260], "temperature": 0.0, "avg_logprob": -0.235632359296426, "compression_ratio": 1.6103286384976525, "no_speech_prob": 0.0040609147399663925}, {"id": 187, "seek": 81576, "start": 833.68, "end": 837.08, "text": " but there's no tests, but you don't want to refactor them because there's no tests, it's", "tokens": [51260, 457, 456, 311, 572, 6921, 11, 457, 291, 500, 380, 528, 281, 1895, 15104, 552, 570, 456, 311, 572, 6921, 11, 309, 311, 51430], "temperature": 0.0, "avg_logprob": -0.235632359296426, "compression_ratio": 1.6103286384976525, "no_speech_prob": 0.0040609147399663925}, {"id": 188, "seek": 81576, "start": 837.08, "end": 841.36, "text": " kind of a catch-22 situation.", "tokens": [51430, 733, 295, 257, 3745, 12, 7490, 2590, 13, 51644], "temperature": 0.0, "avg_logprob": -0.235632359296426, "compression_ratio": 1.6103286384976525, "no_speech_prob": 0.0040609147399663925}, {"id": 189, "seek": 84136, "start": 842.36, "end": 850.6, "text": " Well, this is Pearl, so we've got some useful features we can use to work around that.", "tokens": [50414, 1042, 11, 341, 307, 24639, 11, 370, 321, 600, 658, 512, 4420, 4122, 321, 393, 764, 281, 589, 926, 300, 13, 50826], "temperature": 0.0, "avg_logprob": -0.15794484274727957, "compression_ratio": 1.608695652173913, "no_speech_prob": 0.006494528613984585}, {"id": 190, "seek": 84136, "start": 850.6, "end": 856.6800000000001, "text": " One of the frameworks we've come up with is we are creating override libraries that we", "tokens": [50826, 1485, 295, 264, 29834, 321, 600, 808, 493, 365, 307, 321, 366, 4084, 42321, 15148, 300, 321, 51130], "temperature": 0.0, "avg_logprob": -0.15794484274727957, "compression_ratio": 1.608695652173913, "no_speech_prob": 0.006494528613984585}, {"id": 191, "seek": 84136, "start": 856.6800000000001, "end": 865.88, "text": " pass into scripts that allows us to override various functions at various times in the", "tokens": [51130, 1320, 666, 23294, 300, 4045, 505, 281, 42321, 3683, 6828, 412, 3683, 1413, 294, 264, 51590], "temperature": 0.0, "avg_logprob": -0.15794484274727957, "compression_ratio": 1.608695652173913, "no_speech_prob": 0.006494528613984585}, {"id": 192, "seek": 84136, "start": 865.88, "end": 868.24, "text": " lifecycle of that script that runs.", "tokens": [51590, 45722, 295, 300, 5755, 300, 6676, 13, 51708], "temperature": 0.0, "avg_logprob": -0.15794484274727957, "compression_ratio": 1.608695652173913, "no_speech_prob": 0.006494528613984585}, {"id": 193, "seek": 86824, "start": 868.24, "end": 875.04, "text": " So here we are overriding the call to file slippers read text method by saying run this", "tokens": [50364, 407, 510, 321, 366, 670, 81, 2819, 264, 818, 281, 3991, 45670, 1401, 2487, 3170, 538, 1566, 1190, 341, 50704], "temperature": 0.0, "avg_logprob": -0.1608892305932864, "compression_ratio": 1.6974789915966386, "no_speech_prob": 0.0072766938246786594}, {"id": 194, "seek": 86824, "start": 875.04, "end": 880.6, "text": " script with this override library path and then we have these various blocks that will", "tokens": [50704, 5755, 365, 341, 42321, 6405, 3100, 293, 550, 321, 362, 613, 3683, 8474, 300, 486, 50982], "temperature": 0.0, "avg_logprob": -0.1608892305932864, "compression_ratio": 1.6974789915966386, "no_speech_prob": 0.0072766938246786594}, {"id": 195, "seek": 86824, "start": 880.6, "end": 884.84, "text": " override calls so we can kind of monkey patch things.", "tokens": [50982, 42321, 5498, 370, 321, 393, 733, 295, 17847, 9972, 721, 13, 51194], "temperature": 0.0, "avg_logprob": -0.1608892305932864, "compression_ratio": 1.6974789915966386, "no_speech_prob": 0.0072766938246786594}, {"id": 196, "seek": 86824, "start": 884.84, "end": 892.4, "text": " So we can add as much test coverage as we need and then start changing the script.", "tokens": [51194, 407, 321, 393, 909, 382, 709, 1500, 9645, 382, 321, 643, 293, 550, 722, 4473, 264, 5755, 13, 51572], "temperature": 0.0, "avg_logprob": -0.1608892305932864, "compression_ratio": 1.6974789915966386, "no_speech_prob": 0.0072766938246786594}, {"id": 197, "seek": 86824, "start": 892.4, "end": 897.6, "text": " So that's kind of an example of how we do it, a bit down in the weeds, but I would encourage", "tokens": [51572, 407, 300, 311, 733, 295, 364, 1365, 295, 577, 321, 360, 309, 11, 257, 857, 760, 294, 264, 26370, 11, 457, 286, 576, 5373, 51832], "temperature": 0.0, "avg_logprob": -0.1608892305932864, "compression_ratio": 1.6974789915966386, "no_speech_prob": 0.0072766938246786594}, {"id": 198, "seek": 89760, "start": 897.6, "end": 901.4, "text": " you to watch this talk by Nick.", "tokens": [50364, 291, 281, 1159, 341, 751, 538, 9449, 13, 50554], "temperature": 0.0, "avg_logprob": -0.1543012965809215, "compression_ratio": 1.5898617511520738, "no_speech_prob": 0.0279405377805233}, {"id": 199, "seek": 89760, "start": 901.4, "end": 905.36, "text": " He talked about this at the Pearl and Racket conference last year.", "tokens": [50554, 634, 2825, 466, 341, 412, 264, 24639, 293, 497, 501, 302, 7586, 1036, 1064, 13, 50752], "temperature": 0.0, "avg_logprob": -0.1543012965809215, "compression_ratio": 1.5898617511520738, "no_speech_prob": 0.0279405377805233}, {"id": 200, "seek": 89760, "start": 905.36, "end": 911.84, "text": " It goes into all the details of how you can do this, which blocks you can use to run when,", "tokens": [50752, 467, 1709, 666, 439, 264, 4365, 295, 577, 291, 393, 360, 341, 11, 597, 8474, 291, 393, 764, 281, 1190, 562, 11, 51076], "temperature": 0.0, "avg_logprob": -0.1543012965809215, "compression_ratio": 1.5898617511520738, "no_speech_prob": 0.0279405377805233}, {"id": 201, "seek": 89760, "start": 911.84, "end": 916.96, "text": " how it works and some of the issues around doing that because you're actually adding", "tokens": [51076, 577, 309, 1985, 293, 512, 295, 264, 2663, 926, 884, 300, 570, 291, 434, 767, 5127, 51332], "temperature": 0.0, "avg_logprob": -0.1543012965809215, "compression_ratio": 1.5898617511520738, "no_speech_prob": 0.0279405377805233}, {"id": 202, "seek": 89760, "start": 916.96, "end": 923.1600000000001, "text": " technical debt when you do this, but we need that test coverage there.", "tokens": [51332, 6191, 7831, 562, 291, 360, 341, 11, 457, 321, 643, 300, 1500, 9645, 456, 13, 51642], "temperature": 0.0, "avg_logprob": -0.1543012965809215, "compression_ratio": 1.5898617511520738, "no_speech_prob": 0.0279405377805233}, {"id": 203, "seek": 92316, "start": 923.16, "end": 928.12, "text": " So the aim is get the test coverage in place, the fact of the scripts, the fact of the test", "tokens": [50364, 407, 264, 5939, 307, 483, 264, 1500, 9645, 294, 1081, 11, 264, 1186, 295, 264, 23294, 11, 264, 1186, 295, 264, 1500, 50612], "temperature": 0.0, "avg_logprob": -0.18870925903320312, "compression_ratio": 1.8864628820960698, "no_speech_prob": 0.3242374658584595}, {"id": 204, "seek": 92316, "start": 928.12, "end": 931.68, "text": " coverage, we're in a better place.", "tokens": [50612, 9645, 11, 321, 434, 294, 257, 1101, 1081, 13, 50790], "temperature": 0.0, "avg_logprob": -0.18870925903320312, "compression_ratio": 1.8864628820960698, "no_speech_prob": 0.3242374658584595}, {"id": 205, "seek": 92316, "start": 931.68, "end": 935.64, "text": " This has been critical for some of the scripts we have because I mean they literally run", "tokens": [50790, 639, 575, 668, 4924, 337, 512, 295, 264, 23294, 321, 362, 570, 286, 914, 436, 3736, 1190, 50988], "temperature": 0.0, "avg_logprob": -0.18870925903320312, "compression_ratio": 1.8864628820960698, "no_speech_prob": 0.3242374658584595}, {"id": 206, "seek": 92316, "start": 935.64, "end": 940.8, "text": " the business and they literally have no test coverage while they have test coverage now.", "tokens": [50988, 264, 1606, 293, 436, 3736, 362, 572, 1500, 9645, 1339, 436, 362, 1500, 9645, 586, 13, 51246], "temperature": 0.0, "avg_logprob": -0.18870925903320312, "compression_ratio": 1.8864628820960698, "no_speech_prob": 0.3242374658584595}, {"id": 207, "seek": 92316, "start": 940.8, "end": 947.68, "text": " Like I said, we don't move fast and break things.", "tokens": [51246, 1743, 286, 848, 11, 321, 500, 380, 1286, 2370, 293, 1821, 721, 13, 51590], "temperature": 0.0, "avg_logprob": -0.18870925903320312, "compression_ratio": 1.8864628820960698, "no_speech_prob": 0.3242374658584595}, {"id": 208, "seek": 92316, "start": 947.68, "end": 948.68, "text": " Contributing to C pan.", "tokens": [51590, 4839, 2024, 10861, 281, 383, 2462, 13, 51640], "temperature": 0.0, "avg_logprob": -0.18870925903320312, "compression_ratio": 1.8864628820960698, "no_speech_prob": 0.3242374658584595}, {"id": 209, "seek": 92316, "start": 948.68, "end": 950.9599999999999, "text": " So yeah, we actively encourage contributions to C pan.", "tokens": [51640, 407, 1338, 11, 321, 13022, 5373, 15725, 281, 383, 2462, 13, 51754], "temperature": 0.0, "avg_logprob": -0.18870925903320312, "compression_ratio": 1.8864628820960698, "no_speech_prob": 0.3242374658584595}, {"id": 210, "seek": 95096, "start": 950.96, "end": 955.48, "text": " These are all the distributions that we've either written or taken over maintenance of", "tokens": [50364, 1981, 366, 439, 264, 37870, 300, 321, 600, 2139, 3720, 420, 2726, 670, 11258, 295, 50590], "temperature": 0.0, "avg_logprob": -0.26534825512486643, "compression_ratio": 1.6384615384615384, "no_speech_prob": 0.11405850946903229}, {"id": 211, "seek": 95096, "start": 955.48, "end": 960.88, "text": " in the last decade, which is the time I've been a pay prop.", "tokens": [50590, 294, 264, 1036, 10378, 11, 597, 307, 264, 565, 286, 600, 668, 257, 1689, 2365, 13, 50860], "temperature": 0.0, "avg_logprob": -0.26534825512486643, "compression_ratio": 1.6384615384615384, "no_speech_prob": 0.11405850946903229}, {"id": 212, "seek": 95096, "start": 960.88, "end": 963.9200000000001, "text": " Stuff like some modulus plugins.", "tokens": [50860, 31347, 411, 512, 42287, 33759, 13, 51012], "temperature": 0.0, "avg_logprob": -0.26534825512486643, "compression_ratio": 1.6384615384615384, "no_speech_prob": 0.11405850946903229}, {"id": 213, "seek": 95096, "start": 963.9200000000001, "end": 969.1600000000001, "text": " So there's this plugin for NMIT, modulus that allows you to profile your routes using NMIT", "tokens": [51012, 407, 456, 311, 341, 23407, 337, 426, 44, 3927, 11, 42287, 300, 4045, 291, 281, 7964, 428, 18242, 1228, 426, 44, 3927, 51274], "temperature": 0.0, "avg_logprob": -0.26534825512486643, "compression_ratio": 1.6384615384615384, "no_speech_prob": 0.11405850946903229}, {"id": 214, "seek": 95096, "start": 969.1600000000001, "end": 970.1600000000001, "text": " prof.", "tokens": [51274, 1740, 13, 51324], "temperature": 0.0, "avg_logprob": -0.26534825512486643, "compression_ratio": 1.6384615384615384, "no_speech_prob": 0.11405850946903229}, {"id": 215, "seek": 95096, "start": 970.1600000000001, "end": 971.1600000000001, "text": " It's really useful.", "tokens": [51324, 467, 311, 534, 4420, 13, 51374], "temperature": 0.0, "avg_logprob": -0.26534825512486643, "compression_ratio": 1.6384615384615384, "no_speech_prob": 0.11405850946903229}, {"id": 216, "seek": 95096, "start": 971.1600000000001, "end": 974.6800000000001, "text": " I wrote some of this OAuth 2 server stuff.", "tokens": [51374, 286, 4114, 512, 295, 341, 48424, 2910, 568, 7154, 1507, 13, 51550], "temperature": 0.0, "avg_logprob": -0.26534825512486643, "compression_ratio": 1.6384615384615384, "no_speech_prob": 0.11405850946903229}, {"id": 217, "seek": 95096, "start": 974.6800000000001, "end": 980.6800000000001, "text": " If you've ever used OAuth 2 and tried to implement server side stuff, it's a fun game.", "tokens": [51550, 759, 291, 600, 1562, 1143, 48424, 2910, 568, 293, 3031, 281, 4445, 7154, 1252, 1507, 11, 309, 311, 257, 1019, 1216, 13, 51850], "temperature": 0.0, "avg_logprob": -0.26534825512486643, "compression_ratio": 1.6384615384615384, "no_speech_prob": 0.11405850946903229}, {"id": 218, "seek": 98068, "start": 981.16, "end": 985.0, "text": " That hopefully makes it a bit easier.", "tokens": [50388, 663, 4696, 1669, 309, 257, 857, 3571, 13, 50580], "temperature": 0.0, "avg_logprob": -0.36696279273842863, "compression_ratio": 1.565040650406504, "no_speech_prob": 0.022772397845983505}, {"id": 219, "seek": 98068, "start": 985.0, "end": 987.28, "text": " Third party payment libraries.", "tokens": [50580, 12548, 3595, 10224, 15148, 13, 50694], "temperature": 0.0, "avg_logprob": -0.36696279273842863, "compression_ratio": 1.565040650406504, "no_speech_prob": 0.022772397845983505}, {"id": 220, "seek": 98068, "start": 987.28, "end": 991.56, "text": " We interact with third party payment providers so we've written some stuff.", "tokens": [50694, 492, 4648, 365, 2636, 3595, 10224, 11330, 370, 321, 600, 3720, 512, 1507, 13, 50908], "temperature": 0.0, "avg_logprob": -0.36696279273842863, "compression_ratio": 1.565040650406504, "no_speech_prob": 0.022772397845983505}, {"id": 221, "seek": 98068, "start": 991.56, "end": 994.16, "text": " Go Caldlis do direct debit in the UK.", "tokens": [50908, 1037, 3511, 67, 75, 271, 360, 2047, 39709, 294, 264, 7051, 13, 51038], "temperature": 0.0, "avg_logprob": -0.36696279273842863, "compression_ratio": 1.565040650406504, "no_speech_prob": 0.022772397845983505}, {"id": 222, "seek": 98068, "start": 994.16, "end": 995.68, "text": " TrueLayer is a new opencomer.", "tokens": [51038, 13587, 43, 11167, 307, 257, 777, 1269, 1112, 260, 13, 51114], "temperature": 0.0, "avg_logprob": -0.36696279273842863, "compression_ratio": 1.565040650406504, "no_speech_prob": 0.022772397845983505}, {"id": 223, "seek": 98068, "start": 995.68, "end": 1001.8399999999999, "text": " They're using the open banking spec so I think they're going to get quite big in the coming", "tokens": [51114, 814, 434, 1228, 264, 1269, 18261, 1608, 370, 286, 519, 436, 434, 516, 281, 483, 1596, 955, 294, 264, 1348, 51422], "temperature": 0.0, "avg_logprob": -0.36696279273842863, "compression_ratio": 1.565040650406504, "no_speech_prob": 0.022772397845983505}, {"id": 224, "seek": 98068, "start": 1001.8399999999999, "end": 1002.8399999999999, "text": " years.", "tokens": [51422, 924, 13, 51472], "temperature": 0.0, "avg_logprob": -0.36696279273842863, "compression_ratio": 1.565040650406504, "no_speech_prob": 0.022772397845983505}, {"id": 225, "seek": 98068, "start": 1002.8399999999999, "end": 1010.0799999999999, "text": " And other stuff, so we maintain CGI.pm because we still have CGI scripts.", "tokens": [51472, 400, 661, 1507, 11, 370, 321, 6909, 48448, 13, 14395, 570, 321, 920, 362, 48448, 23294, 13, 51834], "temperature": 0.0, "avg_logprob": -0.36696279273842863, "compression_ratio": 1.565040650406504, "no_speech_prob": 0.022772397845983505}, {"id": 226, "seek": 101008, "start": 1010.2800000000001, "end": 1017.2800000000001, "text": " We can maintain un-maintained libraries, Google Maps stuff and all that kind of stuff.", "tokens": [50374, 492, 393, 6909, 517, 12, 76, 5114, 3563, 15148, 11, 3329, 28978, 1507, 293, 439, 300, 733, 295, 1507, 13, 50724], "temperature": 0.0, "avg_logprob": -0.32169612042315593, "compression_ratio": 1.4766355140186915, "no_speech_prob": 0.0010596346110105515}, {"id": 227, "seek": 101008, "start": 1017.2800000000001, "end": 1024.8, "text": " The issues and challenges around that, well, the pool of contributors to C pan is shrinking.", "tokens": [50724, 440, 2663, 293, 4759, 926, 300, 11, 731, 11, 264, 7005, 295, 45627, 281, 383, 2462, 307, 41684, 13, 51100], "temperature": 0.0, "avg_logprob": -0.32169612042315593, "compression_ratio": 1.4766355140186915, "no_speech_prob": 0.0010596346110105515}, {"id": 228, "seek": 101008, "start": 1024.8, "end": 1028.8400000000001, "text": " Libraries for newer services and APIs don't exist.", "tokens": [51100, 12006, 4889, 337, 17628, 3328, 293, 21445, 500, 380, 2514, 13, 51302], "temperature": 0.0, "avg_logprob": -0.32169612042315593, "compression_ratio": 1.4766355140186915, "no_speech_prob": 0.0010596346110105515}, {"id": 229, "seek": 101008, "start": 1028.8400000000001, "end": 1035.72, "text": " Often you'll find third party libraries for languages except Pearl, which is a shame.", "tokens": [51302, 20043, 291, 603, 915, 2636, 3595, 15148, 337, 8650, 3993, 24639, 11, 597, 307, 257, 10069, 13, 51646], "temperature": 0.0, "avg_logprob": -0.32169612042315593, "compression_ratio": 1.4766355140186915, "no_speech_prob": 0.0010596346110105515}, {"id": 230, "seek": 103572, "start": 1035.84, "end": 1040.84, "text": " Modern APIs are restful and easy to create a third party library for.", "tokens": [50370, 19814, 21445, 366, 1472, 906, 293, 1858, 281, 1884, 257, 2636, 3595, 6405, 337, 13, 50620], "temperature": 0.0, "avg_logprob": -0.2931127374822443, "compression_ratio": 1.5201612903225807, "no_speech_prob": 0.02323472872376442}, {"id": 231, "seek": 103572, "start": 1040.84, "end": 1044.68, "text": " We're happy to throw somebody at it for a week or two, which is what we did with the", "tokens": [50620, 492, 434, 2055, 281, 3507, 2618, 412, 309, 337, 257, 1243, 420, 732, 11, 597, 307, 437, 321, 630, 365, 264, 50812], "temperature": 0.0, "avg_logprob": -0.2931127374822443, "compression_ratio": 1.5201612903225807, "no_speech_prob": 0.02323472872376442}, {"id": 232, "seek": 103572, "start": 1044.68, "end": 1045.68, "text": " TrueLayer one.", "tokens": [50812, 13587, 43, 11167, 472, 13, 50862], "temperature": 0.0, "avg_logprob": -0.2931127374822443, "compression_ratio": 1.5201612903225807, "no_speech_prob": 0.02323472872376442}, {"id": 233, "seek": 103572, "start": 1045.68, "end": 1051.16, "text": " They threw me at it for a week and there's one on C pan.", "tokens": [50862, 814, 11918, 385, 412, 309, 337, 257, 1243, 293, 456, 311, 472, 322, 383, 2462, 13, 51136], "temperature": 0.0, "avg_logprob": -0.2931127374822443, "compression_ratio": 1.5201612903225807, "no_speech_prob": 0.02323472872376442}, {"id": 234, "seek": 103572, "start": 1051.16, "end": 1055.44, "text": " Navigating around IP issues, well, that encourages to decouple our code.", "tokens": [51136, 9219, 328, 990, 926, 8671, 2663, 11, 731, 11, 300, 28071, 281, 979, 263, 781, 527, 3089, 13, 51350], "temperature": 0.0, "avg_logprob": -0.2931127374822443, "compression_ratio": 1.5201612903225807, "no_speech_prob": 0.02323472872376442}, {"id": 235, "seek": 103572, "start": 1055.44, "end": 1060.76, "text": " So that's actually quite a good thing.", "tokens": [51350, 407, 300, 311, 767, 1596, 257, 665, 551, 13, 51616], "temperature": 0.0, "avg_logprob": -0.2931127374822443, "compression_ratio": 1.5201612903225807, "no_speech_prob": 0.02323472872376442}, {"id": 236, "seek": 103572, "start": 1060.76, "end": 1064.3600000000001, "text": " And finally, hiring devs new to Pearl.", "tokens": [51616, 400, 2721, 11, 15335, 1905, 82, 777, 281, 24639, 13, 51796], "temperature": 0.0, "avg_logprob": -0.2931127374822443, "compression_ratio": 1.5201612903225807, "no_speech_prob": 0.02323472872376442}, {"id": 237, "seek": 106436, "start": 1064.3999999999999, "end": 1070.1999999999998, "text": " I say Pearl has been on the plateau of productivity for quite a while.", "tokens": [50366, 286, 584, 24639, 575, 668, 322, 264, 39885, 295, 15604, 337, 1596, 257, 1339, 13, 50656], "temperature": 0.0, "avg_logprob": -0.2691758049858941, "compression_ratio": 1.52, "no_speech_prob": 0.0029912209138274193}, {"id": 238, "seek": 106436, "start": 1070.1999999999998, "end": 1074.8799999999999, "text": " Those that left it a long time ago don't know the current ecosystem.", "tokens": [50656, 3950, 300, 1411, 309, 257, 938, 565, 2057, 500, 380, 458, 264, 2190, 11311, 13, 50890], "temperature": 0.0, "avg_logprob": -0.2691758049858941, "compression_ratio": 1.52, "no_speech_prob": 0.0029912209138274193}, {"id": 239, "seek": 106436, "start": 1074.8799999999999, "end": 1079.32, "text": " But more than a generation removed from even Pearl 5.", "tokens": [50890, 583, 544, 813, 257, 5125, 7261, 490, 754, 24639, 1025, 13, 51112], "temperature": 0.0, "avg_logprob": -0.2691758049858941, "compression_ratio": 1.52, "no_speech_prob": 0.0029912209138274193}, {"id": 240, "seek": 106436, "start": 1079.32, "end": 1087.32, "text": " Pearl 1 was released in 1987 and actually probably Larry was prototyping it a long time before that.", "tokens": [51112, 24639, 502, 390, 4736, 294, 29008, 293, 767, 1391, 18145, 390, 46219, 3381, 309, 257, 938, 565, 949, 300, 13, 51512], "temperature": 0.0, "avg_logprob": -0.2691758049858941, "compression_ratio": 1.52, "no_speech_prob": 0.0029912209138274193}, {"id": 241, "seek": 106436, "start": 1087.32, "end": 1092.4799999999998, "text": " 510, which can be considered modern Pearl, there are people starting a university now", "tokens": [51512, 1025, 3279, 11, 597, 393, 312, 4888, 4363, 24639, 11, 456, 366, 561, 2891, 257, 5454, 586, 51770], "temperature": 0.0, "avg_logprob": -0.2691758049858941, "compression_ratio": 1.52, "no_speech_prob": 0.0029912209138274193}, {"id": 242, "seek": 109248, "start": 1092.6, "end": 1095.6, "text": " that were born after 510 came out.", "tokens": [50370, 300, 645, 4232, 934, 1025, 3279, 1361, 484, 13, 50520], "temperature": 0.0, "avg_logprob": -0.2271452303285952, "compression_ratio": 1.589430894308943, "no_speech_prob": 0.011626268737018108}, {"id": 243, "seek": 109248, "start": 1095.6, "end": 1102.6, "text": " But it's still in a lot of places and I know that because we've interviewed people.", "tokens": [50520, 583, 309, 311, 920, 294, 257, 688, 295, 3190, 293, 286, 458, 300, 570, 321, 600, 19770, 561, 13, 50870], "temperature": 0.0, "avg_logprob": -0.2271452303285952, "compression_ratio": 1.589430894308943, "no_speech_prob": 0.011626268737018108}, {"id": 244, "seek": 109248, "start": 1102.6, "end": 1104.88, "text": " Some of these users can't talk about it.", "tokens": [50870, 2188, 295, 613, 5022, 393, 380, 751, 466, 309, 13, 50984], "temperature": 0.0, "avg_logprob": -0.2271452303285952, "compression_ratio": 1.589430894308943, "no_speech_prob": 0.011626268737018108}, {"id": 245, "seek": 109248, "start": 1104.88, "end": 1109.08, "text": " Banks, the fangs, I won't emphasize which letter in the fangs, but we know there's people", "tokens": [50984, 33081, 11, 264, 283, 28686, 11, 286, 1582, 380, 16078, 597, 5063, 294, 264, 283, 28686, 11, 457, 321, 458, 456, 311, 561, 51194], "temperature": 0.0, "avg_logprob": -0.2271452303285952, "compression_ratio": 1.589430894308943, "no_speech_prob": 0.011626268737018108}, {"id": 246, "seek": 109248, "start": 1109.08, "end": 1112.2, "text": " using Pearl in these places.", "tokens": [51194, 1228, 24639, 294, 613, 3190, 13, 51350], "temperature": 0.0, "avg_logprob": -0.2271452303285952, "compression_ratio": 1.589430894308943, "no_speech_prob": 0.011626268737018108}, {"id": 247, "seek": 109248, "start": 1112.2, "end": 1116.2, "text": " So I think the rumors of Pearl's demise are greatly exaggerated, but it's kind of a known", "tokens": [51350, 407, 286, 519, 264, 21201, 295, 24639, 311, 45982, 366, 14147, 36196, 11, 457, 309, 311, 733, 295, 257, 2570, 51550], "temperature": 0.0, "avg_logprob": -0.2271452303285952, "compression_ratio": 1.589430894308943, "no_speech_prob": 0.011626268737018108}, {"id": 248, "seek": 109248, "start": 1116.2, "end": 1118.56, "text": " unknown at this point.", "tokens": [51550, 9841, 412, 341, 935, 13, 51668], "temperature": 0.0, "avg_logprob": -0.2271452303285952, "compression_ratio": 1.589430894308943, "no_speech_prob": 0.011626268737018108}, {"id": 249, "seek": 111856, "start": 1118.6399999999999, "end": 1122.6399999999999, "text": " And it's still be using Greenfield projects, so the system that Fosdham used to review,", "tokens": [50368, 400, 309, 311, 920, 312, 1228, 6969, 7610, 4455, 11, 370, 264, 1185, 300, 479, 329, 67, 4822, 1143, 281, 3131, 11, 50568], "temperature": 0.0, "avg_logprob": -0.24650489366971529, "compression_ratio": 1.5627376425855513, "no_speech_prob": 0.01521802693605423}, {"id": 250, "seek": 111856, "start": 1122.6399999999999, "end": 1127.6399999999999, "text": " annotate, cut, process, transcode and publish all of their videos runs on modern Pearl.", "tokens": [50568, 25339, 473, 11, 1723, 11, 1399, 11, 1145, 22332, 293, 11374, 439, 295, 641, 2145, 6676, 322, 4363, 24639, 13, 50818], "temperature": 0.0, "avg_logprob": -0.24650489366971529, "compression_ratio": 1.5627376425855513, "no_speech_prob": 0.01521802693605423}, {"id": 251, "seek": 111856, "start": 1127.6399999999999, "end": 1132.6399999999999, "text": " So over a thousand videos this weekend are going through a modern Pearl system.", "tokens": [50818, 407, 670, 257, 4714, 2145, 341, 6711, 366, 516, 807, 257, 4363, 24639, 1185, 13, 51068], "temperature": 0.0, "avg_logprob": -0.24650489366971529, "compression_ratio": 1.5627376425855513, "no_speech_prob": 0.01521802693605423}, {"id": 252, "seek": 111856, "start": 1136.6399999999999, "end": 1141.6399999999999, "text": " And its popularity is kind of normalized over the last two decades, I think.", "tokens": [51268, 400, 1080, 19301, 307, 733, 295, 48704, 670, 264, 1036, 732, 7878, 11, 286, 519, 13, 51518], "temperature": 0.0, "avg_logprob": -0.24650489366971529, "compression_ratio": 1.5627376425855513, "no_speech_prob": 0.01521802693605423}, {"id": 253, "seek": 111856, "start": 1141.6399999999999, "end": 1143.6399999999999, "text": " So it's had to find Pearl developers.", "tokens": [51518, 407, 309, 311, 632, 281, 915, 24639, 8849, 13, 51618], "temperature": 0.0, "avg_logprob": -0.24650489366971529, "compression_ratio": 1.5627376425855513, "no_speech_prob": 0.01521802693605423}, {"id": 254, "seek": 111856, "start": 1143.6399999999999, "end": 1146.6399999999999, "text": " But newcomers don't have preconceptions.", "tokens": [51618, 583, 40014, 433, 500, 380, 362, 47473, 22393, 13, 51768], "temperature": 0.0, "avg_logprob": -0.24650489366971529, "compression_ratio": 1.5627376425855513, "no_speech_prob": 0.01521802693605423}, {"id": 255, "seek": 114856, "start": 1148.6399999999999, "end": 1152.6399999999999, "text": " That's my experience of interviewing anyway.", "tokens": [50368, 663, 311, 452, 1752, 295, 26524, 4033, 13, 50568], "temperature": 0.0, "avg_logprob": -0.10764627830654967, "compression_ratio": 1.632, "no_speech_prob": 0.002002169843763113}, {"id": 256, "seek": 114856, "start": 1152.6399999999999, "end": 1156.6399999999999, "text": " I think those under 30 either haven't heard of the language or haven't used it.", "tokens": [50568, 286, 519, 729, 833, 2217, 2139, 2378, 380, 2198, 295, 264, 2856, 420, 2378, 380, 1143, 309, 13, 50768], "temperature": 0.0, "avg_logprob": -0.10764627830654967, "compression_ratio": 1.632, "no_speech_prob": 0.002002169843763113}, {"id": 257, "seek": 114856, "start": 1156.6399999999999, "end": 1160.6399999999999, "text": " And those who don't want to use it self-select out of the process anyway.", "tokens": [50768, 400, 729, 567, 500, 380, 528, 281, 764, 309, 2698, 12, 405, 1809, 484, 295, 264, 1399, 4033, 13, 50968], "temperature": 0.0, "avg_logprob": -0.10764627830654967, "compression_ratio": 1.632, "no_speech_prob": 0.002002169843763113}, {"id": 258, "seek": 114856, "start": 1160.6399999999999, "end": 1164.6399999999999, "text": " Because we are explicit that we use Pearl in our job specs.", "tokens": [50968, 1436, 321, 366, 13691, 300, 321, 764, 24639, 294, 527, 1691, 27911, 13, 51168], "temperature": 0.0, "avg_logprob": -0.10764627830654967, "compression_ratio": 1.632, "no_speech_prob": 0.002002169843763113}, {"id": 259, "seek": 114856, "start": 1164.6399999999999, "end": 1168.6399999999999, "text": " We just don't require it unless we're hiring a senior Pearl developer.", "tokens": [51168, 492, 445, 500, 380, 3651, 309, 5969, 321, 434, 15335, 257, 7965, 24639, 10754, 13, 51368], "temperature": 0.0, "avg_logprob": -0.10764627830654967, "compression_ratio": 1.632, "no_speech_prob": 0.002002169843763113}, {"id": 260, "seek": 114856, "start": 1172.6399999999999, "end": 1176.6399999999999, "text": " And I find modern Pearl is an interesting and enjoyable language to work with.", "tokens": [51568, 400, 286, 915, 4363, 24639, 307, 364, 1880, 293, 20305, 2856, 281, 589, 365, 13, 51768], "temperature": 0.0, "avg_logprob": -0.10764627830654967, "compression_ratio": 1.632, "no_speech_prob": 0.002002169843763113}, {"id": 261, "seek": 117664, "start": 1176.72, "end": 1180.72, "text": " Working with legacy code is not specifically a Pearl thing.", "tokens": [50368, 18337, 365, 11711, 3089, 307, 406, 4682, 257, 24639, 551, 13, 50568], "temperature": 0.0, "avg_logprob": -0.13523690596870755, "compression_ratio": 1.6681818181818182, "no_speech_prob": 0.003166625974699855}, {"id": 262, "seek": 117664, "start": 1182.72, "end": 1186.72, "text": " And we make sure to do all of this stuff, because you should be doing all of this stuff.", "tokens": [50668, 400, 321, 652, 988, 281, 360, 439, 295, 341, 1507, 11, 570, 291, 820, 312, 884, 439, 295, 341, 1507, 13, 50868], "temperature": 0.0, "avg_logprob": -0.13523690596870755, "compression_ratio": 1.6681818181818182, "no_speech_prob": 0.003166625974699855}, {"id": 263, "seek": 117664, "start": 1187.72, "end": 1191.72, "text": " And we're finding in a distributed work environment you need to do all of this stuff.", "tokens": [50918, 400, 321, 434, 5006, 294, 257, 12631, 589, 2823, 291, 643, 281, 360, 439, 295, 341, 1507, 13, 51118], "temperature": 0.0, "avg_logprob": -0.13523690596870755, "compression_ratio": 1.6681818181818182, "no_speech_prob": 0.003166625974699855}, {"id": 264, "seek": 117664, "start": 1194.72, "end": 1197.72, "text": " I've not really talked about this much in the past, but I have written blog posts.", "tokens": [51268, 286, 600, 406, 534, 2825, 466, 341, 709, 294, 264, 1791, 11, 457, 286, 362, 3720, 6968, 12300, 13, 51418], "temperature": 0.0, "avg_logprob": -0.13523690596870755, "compression_ratio": 1.6681818181818182, "no_speech_prob": 0.003166625974699855}, {"id": 265, "seek": 117664, "start": 1197.72, "end": 1200.72, "text": " So check out the blog posts if you're interested.", "tokens": [51418, 407, 1520, 484, 264, 6968, 12300, 498, 291, 434, 3102, 13, 51568], "temperature": 0.0, "avg_logprob": -0.13523690596870755, "compression_ratio": 1.6681818181818182, "no_speech_prob": 0.003166625974699855}, {"id": 266, "seek": 120072, "start": 1200.8, "end": 1204.8, "text": " And the key is that you can still be very experienced, but still a newcomer.", "tokens": [50368, 400, 264, 2141, 307, 300, 291, 393, 920, 312, 588, 6751, 11, 457, 920, 257, 40014, 260, 13, 50568], "temperature": 0.0, "avg_logprob": -0.14052439844885536, "compression_ratio": 1.5566502463054188, "no_speech_prob": 0.022194193676114082}, {"id": 267, "seek": 120072, "start": 1204.8, "end": 1208.8, "text": " And that's absolutely fine. And I think it's actually beneficial to the ecosystem and the community.", "tokens": [50568, 400, 300, 311, 3122, 2489, 13, 400, 286, 519, 309, 311, 767, 14072, 281, 264, 11311, 293, 264, 1768, 13, 50768], "temperature": 0.0, "avg_logprob": -0.14052439844885536, "compression_ratio": 1.5566502463054188, "no_speech_prob": 0.022194193676114082}, {"id": 268, "seek": 120072, "start": 1208.8, "end": 1212.8, "text": " So if you are, please speak up. You want to hear from you.", "tokens": [50768, 407, 498, 291, 366, 11, 1767, 1710, 493, 13, 509, 528, 281, 1568, 490, 291, 13, 50968], "temperature": 0.0, "avg_logprob": -0.14052439844885536, "compression_ratio": 1.5566502463054188, "no_speech_prob": 0.022194193676114082}, {"id": 269, "seek": 120072, "start": 1215.8, "end": 1219.8, "text": " And that's it. I don't think I have time for questions.", "tokens": [51118, 400, 300, 311, 309, 13, 286, 500, 380, 519, 286, 362, 565, 337, 1651, 13, 51318], "temperature": 0.0, "avg_logprob": -0.14052439844885536, "compression_ratio": 1.5566502463054188, "no_speech_prob": 0.022194193676114082}, {"id": 270, "seek": 120072, "start": 1219.8, "end": 1223.8, "text": " So thank you very much.", "tokens": [51318, 407, 1309, 291, 588, 709, 13, 51518], "temperature": 0.0, "avg_logprob": -0.14052439844885536, "compression_ratio": 1.5566502463054188, "no_speech_prob": 0.022194193676114082}, {"id": 271, "seek": 123072, "start": 1230.72, "end": 1234.8, "text": " Thank you.", "tokens": [50368, 1044, 291, 13, 50568], "temperature": 0.0, "avg_logprob": -0.4617151419321696, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.9752750396728516}], "language": "en"}