{"text": " Good afternoon. Welcome to the DNS Dev Room. Lovely to see a full room once again. And I would like to just give the word to our first presenter, Thijs, who will talk about consistent hashing and related stuff. Thank you. Good afternoon. I was already mentioning like quite a full room for such a niche topic. Anyway, I asked her here because I got too many slides, as always. My name is Thijs Freyja, I work for KONG. We company open source gateway. One of the things we do is load balancing. And this talks about like how we implement consistent hashing in the load balancer, what we run into, or works, what doesn't work. So consistent load balancing, like what, why, and how. And then like what does DNS have to do with it. The what is actually fairly simple. You take an outgoing connection, you take a property, and I'm basing the property, you make sure that every single connection outgoing with that property ends up on the same back ends system. Which is fairly, I think from the hash bucket perspective, fairly straightforward. A typical for our situation gateway, typical setup, incoming traffic, cluster of gateways, and then load balancing towards the back ends, each in one or multiple instances. When we do consistent hashing, what we'd like to do is, for example, pick a user ID, and then make sure that that user ID as a property ends up on one specific back end server. And in this case it would be Harry, John, and Mary would go to instance one, Paul, and Joanne go to instance number two. What did I touch? Fat finger. No. Come on. Yeah, next question. Why? Like I said, it's a bit of a niche topic. It is very specifically geared towards cash optimization. Consistent hashing is something that many people know, but this is very specifically to, if you do a lot of hashing, you don't want to have cash misses, especially when you're scaling systems. And for legacy, we have customers using it for sticky sessions, but it's like a bit of a mediocre solution to that. So in this case, yeah, as I already explained, the same users go to the same back end, which means that the data that a back end application needs to retrieve from a database would only be related to those specific individuals. So the cash hits will be higher considering the amount of cash that the system has available. Then hashing. Hashing in general is the basic concept of hash buckets. You take an input, you throw it into a hashing algorithm. C or C 32 we used before. Now we use XX hash fast. It needs to be, have a nice consistent distribution. Then you do a modulo, in this case modulo 10, you end up in one of 10 buckets. That's basically how it works. So whatever you input, as long as the same input ends up in the same bucket. Now let's take this, the 10 buckets that we have and let's extend that and say like we have continuum with how in the print the Kitama library, which is where this was first implemented, they call it continuum. And we're going to have four nodes, each one serving 25% of the traffic of the entire continuum. So everything that we get in and we hash into some bucket falls into one of those in the end four nodes. Now if we now scale the system, we add a fifth node. Now we see that we have 20% capacity added. So what is that going to do with our hashing algorithm? From node A, traffic previously going to node A will now end up, 5% will end up on node B. From B 10% will go to node C and so on. The overall consistency loss 50%, which means that our backend systems are going to have to fetch a lot of data to catch over this 50% because they moved systems. That's the thing that we're trying to prevent. So we have 20% capacity added, 50% of the continuum changed. Now if you look at what does that mean? At the bottom side we have catch-hate ratio, take an HTTP server, 70, 80, 90% HTTP servers can catch that, get there. Then you can see that with a 20% consistency loss, which will be the minimum in our case because we add a server, 20% capacity, so the minimum is always going to be 20%. So if we do that, we have like 50% extra capacity temporarily. If we don't use consistent hashing, we have 50% loss and we go to more than 120% pretty much on extra capacity, which is quite a big peak that we get on top. Now if you lay this out on a ring, and in this case we'll have simplified depiction, 20 buckets, whereas in reality for each expected backend that you need, you would expect to use like 50 to 100 entries at least. So if I would have a four backends, I would use 400 entries on this ring. Now if we distribute, if we distribute the five targets, the four targets that we had, going to do the same example again, the four targets that we had, then we have two relationships. That's the target, the IP port combination, and it's related to one of the positions on the slot, one of the slot, different concept, and it's going to be based on weight. Now we have four nodes, same weight, so each node gets 25% of the available slots, fairly straightforward. Then there's a slot towards the position on the hash bucket, and that's a one-on-one relationship. Every slot goes into one bucket, but it's randomized. So if we apply that, this is the way I would get. So instead of a continuous ranges of AAAA, BBB, CCC, we get a random layout with those nodes. If we now do hashing, basically we see that every hash ends up nicely in its bucket, and as a side effect, we'll get if hashing is not available, because the property is not available, we can do an easy round robin, good by simply walking the ring, which is a side effect of Yawarun. Now if we move into adding the node again, the same thing that we did before, we're adding 20% capacity, what we're going to do, we're going to relieve every, for the slots that we have assigned, we're going to ask every back end to relieve the amount of slots that are no longer to be assigned to them, in this case they were used from 25 to 20%, one slot, and we assign them to the new one. Now if we do that, we can see that the distribution stays the same, and the hashing principle now works, because we have minimal consistency loss. Now instead of having the 50% consistency loss at the start, we now end up with like the minimal consistency loss of only exactly the 20% that we added in capacity. It also has featured that if we have a simple health checker attached to it, it's quite common with load balancers, is that we can actually move on to the next slot, and our distribution will not really change. Yes, we'll have an impact on the consistent hashing principle, and we'll have catch losses, but due to the way it's random layout, we still maintain that the weights are properly distributed, and the traffic is going to be distributed about across all your remaining nodes. Now, that is like the basic concept of how you do the consistent hashing, and how you minimize this hashing loss. Now when it gets really tricky, is when you have to do this in a cluster. In a con cluster, the nodes are basically independent, so there's no shared state, at least we try to minimize, and we just saw that we had a lot of like random stuff in there, distribution layout, etc., and that's what makes it hard. So if we have to build a deterministic layout of that ring, we have to make sure that we build the exact same ring with the exact same layout on every node in the cluster. And that's where it gets hard. So for the random layout, the way we solve this is by using the distribution, the random distribution, but not the unpredictable, the unpredictability of a random number generator by using a separate random number generator, but with a fixed seed, just a constant, so it generates the same thing over and over again on every node, because we don't care about it being unique, we only care about the distribution, that is randomly distributed on the ring. Tracking changes as nodes are being added and removed, we keep a log history. So whenever we add a new node, if a cluster gets expanded, we just replay all the changes, so we end up with the exact same state of the cluster, of the ring, and make sure that the hashing still functions. And then you think we have it covered, and then comes DNS. Because initially we had it laid out to do just IP and port, but that's static, and in all of our customers' environments, it doesn't work. So we have the Kubernetes OpenShift console, and a common denominator there is DNS. So they do source discovery, and then exposes through a DNS interface, that's where you get your backhands. So the solution we had is that we had to expand our balancer to not just take IP at a result, we had to take hostnames. Now we have to resolve them, and then instead of having a single entry for a hostname, we could have like 2, 3, 4, 5, depending on what's in the record. But that hurts. Because if you look at what some of those discovery tools do, they don't set a truncation flag, which means that every node in the cluster is going to get a different answer in a different random order. A console, for example, does that, and the core of it is that those tools try to do load balancing on an infrastructure level by forcing you to renew the DNS records, and then they're going to give you only the information they want you to have. So a console is typically quite often we've seen deployment with TTL0 and no truncation flag. So you get one record, two records, three records, but not all of them. Once we have a truncation flag, we know we can retry, we can do TCP, we get a whole lot of them, and then we can check that our balancer stays in sync. Quite often we see that it doesn't happen and the balancer goes out of sync, and then we have customers complaining, basically. TTL0 means lots of changes and updates. Every change is an update to the balance of the structure, which is like really not a good combination. And then of course there's bugs. I was just, you were commenting on DNS, it's always DNS. And we actually, we had a discussion yesterday and somebody said actually like, DNS is like the RFC is just like the primer, and then the real implementation is there are 100 million different limitations out there. That's what DNS pretty much is. And you have the cater for all of them. So we have customers that set up DNS to only return a single record ever, and an infrastructure team is refusing to change it despite the fact that application teams have difficulties with their load balancing. Amazon has Route 53, occasionally gives you a TTL0, because my guess is it's a rounding bug when the TTL gets too low to return zero, which it shouldn't be doing. Now if you think all of this is hard, try filing a bug with Amazon. That's really hard. So in essence, we haven't implemented implemented it, but to really properly replay everything, we would need to have some central storage where we have the DNS records over time stored as well. So not only the changes in the host names, but also at that point in time, how does it resolve what are the entries we're getting? Because if I add a new node in my cluster later on, rebuild it, and that node gets four entries in the DNS, where the ones that were started earlier got only three, so we'll get the thing is out of sync again. Now if you look at the overall thing, I don't know where we are in time. Oh, we're in 10 minutes left. 10 minutes left. I've been hurrying too much. So concluding, it is, like I said, it's a niche algorithm and it is good for cache optimizations, but it is still, its primary concern is still load balancing. It's distributing load. The consistency is only secondary. And for caching, it makes sense because like with a cache, I mean, you lose some performance, but you don't lose data. So if you change it, you lose the consistency, it just rebuilds it and then you're good to go. Minimize the cache disruptions. The trick is with, it does require some contacts as the hash input. On the TCP level, you could have like an SNI name maybe or an IP. It's like really rough because it also needs the contacts that you need into the hash, needs to have enough cardinality to actually make sure that you're going to hit everything in your cluster. So if you have, I don't know, you say you do on a header, that either says Android or iOS. That means in your hashing algorithm, you're going to hit only two backhands ever. So if you scale and you have five backhands, you're still going to hit only two. If you have to be aware of that, that there's enough cardinality. And as before, DNS is be careful. Make sure that people set it up correctly. If you have it all in one hand, if you control the whole lot of it, you can set whether the truncation flag is set or not, whether it results everything, it gives you all the nodes, all the entries. That's good. If you're not, make sure you check with your other teams that they actually make sure you get the data to make sure that they're not fighting each other. Then there was the comparing algorithms. Like the first two are actually like the more generic ones. The way to round around like everybody knows. It's a good distribution. It doesn't care about caching. So you hit everything with everything you got. These connections are the same, but at least it takes into kind of like long lift connections, which not depending on what you're running or what service you're running might make a good distinction. Really different. Consistent hashing, cache optimization, and it works wonders under the right circumstances. There's a catch to really catch. Least latency, we have that. It's also niche, I'd say. I even wrote it. If you have high variance CPU loads, so take GraphQL, where you can have simple queries and very big queries, then this makes sense. But one thing to be careful of is that you need to have equal network latencies. So if you have all your nodes in the same network, your back ends, you have the same network latency, then it works. But if you have one close by and another one a couple of hops away that has more latency, then the least latency one will actually push the close by ones into starvation. Because they have lower latency because of the network, so we're going to push more load, and by the time the latency of those systems goes up, you're basically pushing them into resource starvation, either CPU memory or whatever, and then they become slower. And that's not an efficient way to run those servers, probably. So there's a catch to it. And I got it really in time. Questions? Thank you, Dyer. Thank you. Plenty of questions. You said that some DNS servers do not send and truncate bits. Would it be possible to just do TCP? Always? To always do TCP? Yes, that's an option. That's an option. If you can configure your client, not all clients can be configured. In our case, the client doesn't, we work with OpenResty. OpenResty underlying DNS client doesn't, it has a bug that prevents us from using it, actually. It doesn't do retries, which is, but that indeed is a good solution to making sure you get the entire, the entire record, all the entries. Yeah. I have a related question, which is, how often do you actually see enough data in a response to truncation of a content issue? It seems like you get hundreds of address port pairs and transfer before you know it. Depends on, depends on DNS implementation and to use the eyes of, of, yeah. So how many, how many times do you actually see truncation happening in those records? I don't have data. I guess it must have happened or you wouldn't know. Yeah. I don't have the data. I know that console does it. Console by default will only report three and it's UDP packet size. And I think it is UDP packet size. I don't know what it exactly is, but I would assume like four or five maybe and then truncation happens. Depends also depends on like name sizes and everything because it has to fit in a single packet. Oh, maybe console just arbitrarily truncates. Yes. Not to do with packet size. Yes. But that's, that is because it's a service discovery tool and it tries to pull the load balancer rule towards it and force you to only hit the nodes that it wants you to hit. Okay. So it has, I think it has for example things like data center awareness. So depending on where the, where the request comes from, it will give you a different set of answers than in another data center. So you're going to hit different backends. Yeah. Sorry, can you repeat the question? For the log synchronization. What algorithm are we using for the log synchronization? Which one do you mean across the cluster or inside a single balancer? Let's go with the balancer. I'll give you answer both. First one on the cluster, we don't have it because we, in the end, we have no synchronization over this shared state of this entire balancer. We don't share it. The only thing we have is the order in which nodes have been added and that's synchronized through a database basically, a control plane. Then inside the balancer algorithm itself due to the way the open rescue works, you basically don't need a log on this. The one thing is you need to be careful that you do not yield in between operations that actually are modifying the data structures. As long as you do that in an atomic operation, you're good and you don't need a log. So I answer the question. Maybe this, you could share the state of the various nodes in the cluster by just sharing the state instead of assuming you get the same input data and computing a state. So then you would of course introduce interdependencies because it would guarantee that all nodes at least use the same tables. So the question is can you use shared state instead of rebuilding it in every cluster separately? Yes, you can. The conflusters are basically independent. The data planes are on their own and they do not share state. They get their instructions from a control plane. That's it. Yes, there is one, there is the alternative option. We haven't implemented it yet. I don't think we will implement this. In reality, we see too little cases where we actually see the things go out of sync and cause issues. Usually you can tweak it by using a longer TTL so there's going to be less updates and you don't need it. So I don't think we will be implementing it in the end. Have you considered using rendezvous hashing instead of consistent hashing? Have we considered rendezvous hashing instead of consistent hashing? No. No. Frankly, I don't know it. I wrote this stuff actually quite some years ago. It was updated by a colleague later on. But I will be looking into rendezvous hashing. Thank you. Any more questions? Check. Matrix. No questions. Almost, almost, almost on the minute. You", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 14.120000000000001, "text": " Good afternoon. Welcome to the DNS Dev Room. Lovely to see a full room once again. And", "tokens": [50364, 2205, 6499, 13, 4027, 281, 264, 35153, 9096, 19190, 13, 33925, 281, 536, 257, 1577, 1808, 1564, 797, 13, 400, 51070], "temperature": 0.0, "avg_logprob": -0.2583408933697325, "compression_ratio": 1.4010695187165776, "no_speech_prob": 0.3955546021461487}, {"id": 1, "seek": 0, "start": 14.120000000000001, "end": 18.28, "text": " I would like to just give the word to our first presenter, Thijs, who will talk about", "tokens": [51070, 286, 576, 411, 281, 445, 976, 264, 1349, 281, 527, 700, 35594, 11, 334, 1718, 82, 11, 567, 486, 751, 466, 51278], "temperature": 0.0, "avg_logprob": -0.2583408933697325, "compression_ratio": 1.4010695187165776, "no_speech_prob": 0.3955546021461487}, {"id": 2, "seek": 0, "start": 18.28, "end": 25.88, "text": " consistent hashing and related stuff. Thank you. Good afternoon. I was already mentioning", "tokens": [51278, 8398, 575, 571, 293, 4077, 1507, 13, 1044, 291, 13, 2205, 6499, 13, 286, 390, 1217, 18315, 51658], "temperature": 0.0, "avg_logprob": -0.2583408933697325, "compression_ratio": 1.4010695187165776, "no_speech_prob": 0.3955546021461487}, {"id": 3, "seek": 2588, "start": 25.88, "end": 33.36, "text": " like quite a full room for such a niche topic. Anyway, I asked her here because I got too", "tokens": [50364, 411, 1596, 257, 1577, 1808, 337, 1270, 257, 19956, 4829, 13, 5684, 11, 286, 2351, 720, 510, 570, 286, 658, 886, 50738], "temperature": 0.0, "avg_logprob": -0.31045046719637787, "compression_ratio": 1.5104602510460252, "no_speech_prob": 0.354931116104126}, {"id": 4, "seek": 2588, "start": 33.36, "end": 40.28, "text": " many slides, as always. My name is Thijs Freyja, I work for KONG. We company open source gateway.", "tokens": [50738, 867, 9788, 11, 382, 1009, 13, 1222, 1315, 307, 334, 1718, 82, 6142, 88, 2938, 11, 286, 589, 337, 591, 12661, 13, 492, 2237, 1269, 4009, 28532, 13, 51084], "temperature": 0.0, "avg_logprob": -0.31045046719637787, "compression_ratio": 1.5104602510460252, "no_speech_prob": 0.354931116104126}, {"id": 5, "seek": 2588, "start": 40.28, "end": 44.36, "text": " One of the things we do is load balancing. And this talks about like how we implement", "tokens": [51084, 1485, 295, 264, 721, 321, 360, 307, 3677, 22495, 13, 400, 341, 6686, 466, 411, 577, 321, 4445, 51288], "temperature": 0.0, "avg_logprob": -0.31045046719637787, "compression_ratio": 1.5104602510460252, "no_speech_prob": 0.354931116104126}, {"id": 6, "seek": 2588, "start": 44.36, "end": 52.08, "text": " consistent hashing in the load balancer, what we run into, or works, what doesn't work.", "tokens": [51288, 8398, 575, 571, 294, 264, 3677, 3119, 28347, 11, 437, 321, 1190, 666, 11, 420, 1985, 11, 437, 1177, 380, 589, 13, 51674], "temperature": 0.0, "avg_logprob": -0.31045046719637787, "compression_ratio": 1.5104602510460252, "no_speech_prob": 0.354931116104126}, {"id": 7, "seek": 5208, "start": 52.08, "end": 59.8, "text": " So consistent load balancing, like what, why, and how. And then like what does DNS have to do with it.", "tokens": [50364, 407, 8398, 3677, 22495, 11, 411, 437, 11, 983, 11, 293, 577, 13, 400, 550, 411, 437, 775, 35153, 362, 281, 360, 365, 309, 13, 50750], "temperature": 0.0, "avg_logprob": -0.2669572522563319, "compression_ratio": 1.634453781512605, "no_speech_prob": 0.003423220245167613}, {"id": 8, "seek": 5208, "start": 59.8, "end": 66.16, "text": " The what is actually fairly simple. You take an outgoing connection, you take a property,", "tokens": [50750, 440, 437, 307, 767, 6457, 2199, 13, 509, 747, 364, 41565, 4984, 11, 291, 747, 257, 4707, 11, 51068], "temperature": 0.0, "avg_logprob": -0.2669572522563319, "compression_ratio": 1.634453781512605, "no_speech_prob": 0.003423220245167613}, {"id": 9, "seek": 5208, "start": 66.16, "end": 71.32, "text": " and I'm basing the property, you make sure that every single connection outgoing with that property", "tokens": [51068, 293, 286, 478, 987, 278, 264, 4707, 11, 291, 652, 988, 300, 633, 2167, 4984, 41565, 365, 300, 4707, 51326], "temperature": 0.0, "avg_logprob": -0.2669572522563319, "compression_ratio": 1.634453781512605, "no_speech_prob": 0.003423220245167613}, {"id": 10, "seek": 5208, "start": 71.32, "end": 78.03999999999999, "text": " ends up on the same back ends system. Which is fairly, I think from the hash bucket perspective,", "tokens": [51326, 5314, 493, 322, 264, 912, 646, 5314, 1185, 13, 3013, 307, 6457, 11, 286, 519, 490, 264, 22019, 13058, 4585, 11, 51662], "temperature": 0.0, "avg_logprob": -0.2669572522563319, "compression_ratio": 1.634453781512605, "no_speech_prob": 0.003423220245167613}, {"id": 11, "seek": 7804, "start": 78.04, "end": 84.80000000000001, "text": " fairly straightforward. A typical for our situation gateway, typical setup, incoming traffic,", "tokens": [50364, 6457, 15325, 13, 316, 7476, 337, 527, 2590, 28532, 11, 7476, 8657, 11, 22341, 6419, 11, 50702], "temperature": 0.0, "avg_logprob": -0.2452762729519016, "compression_ratio": 1.597457627118644, "no_speech_prob": 0.003270662622526288}, {"id": 12, "seek": 7804, "start": 84.80000000000001, "end": 95.72, "text": " cluster of gateways, and then load balancing towards the back ends, each in one or multiple instances.", "tokens": [50702, 13630, 295, 8539, 942, 11, 293, 550, 3677, 22495, 3030, 264, 646, 5314, 11, 1184, 294, 472, 420, 3866, 14519, 13, 51248], "temperature": 0.0, "avg_logprob": -0.2452762729519016, "compression_ratio": 1.597457627118644, "no_speech_prob": 0.003270662622526288}, {"id": 13, "seek": 7804, "start": 95.72, "end": 101.12, "text": " When we do consistent hashing, what we'd like to do is, for example, pick a user ID, and", "tokens": [51248, 1133, 321, 360, 8398, 575, 571, 11, 437, 321, 1116, 411, 281, 360, 307, 11, 337, 1365, 11, 1888, 257, 4195, 7348, 11, 293, 51518], "temperature": 0.0, "avg_logprob": -0.2452762729519016, "compression_ratio": 1.597457627118644, "no_speech_prob": 0.003270662622526288}, {"id": 14, "seek": 7804, "start": 101.12, "end": 106.76, "text": " then make sure that that user ID as a property ends up on one specific back end server. And", "tokens": [51518, 550, 652, 988, 300, 300, 4195, 7348, 382, 257, 4707, 5314, 493, 322, 472, 2685, 646, 917, 7154, 13, 400, 51800], "temperature": 0.0, "avg_logprob": -0.2452762729519016, "compression_ratio": 1.597457627118644, "no_speech_prob": 0.003270662622526288}, {"id": 15, "seek": 10676, "start": 106.80000000000001, "end": 112.28, "text": " in this case it would be Harry, John, and Mary would go to instance one, Paul, and Joanne go to instance number two.", "tokens": [50366, 294, 341, 1389, 309, 576, 312, 9378, 11, 2619, 11, 293, 6059, 576, 352, 281, 5197, 472, 11, 4552, 11, 293, 3139, 12674, 352, 281, 5197, 1230, 732, 13, 50640], "temperature": 0.0, "avg_logprob": -0.41788339614868164, "compression_ratio": 1.3641304347826086, "no_speech_prob": 0.00815797783434391}, {"id": 16, "seek": 10676, "start": 117.92, "end": 119.24000000000001, "text": " What did I touch?", "tokens": [50922, 708, 630, 286, 2557, 30, 50988], "temperature": 0.0, "avg_logprob": -0.41788339614868164, "compression_ratio": 1.3641304347826086, "no_speech_prob": 0.00815797783434391}, {"id": 17, "seek": 10676, "start": 122.12, "end": 122.68, "text": " Fat finger.", "tokens": [51132, 16948, 5984, 13, 51160], "temperature": 0.0, "avg_logprob": -0.41788339614868164, "compression_ratio": 1.3641304347826086, "no_speech_prob": 0.00815797783434391}, {"id": 18, "seek": 10676, "start": 123.64, "end": 132.76, "text": " No. Come on. Yeah, next question. Why? Like I said, it's a bit of a niche topic. It is very specifically", "tokens": [51208, 883, 13, 2492, 322, 13, 865, 11, 958, 1168, 13, 1545, 30, 1743, 286, 848, 11, 309, 311, 257, 857, 295, 257, 19956, 4829, 13, 467, 307, 588, 4682, 51664], "temperature": 0.0, "avg_logprob": -0.41788339614868164, "compression_ratio": 1.3641304347826086, "no_speech_prob": 0.00815797783434391}, {"id": 19, "seek": 13276, "start": 133.32, "end": 139.72, "text": " geared towards cash optimization. Consistent hashing is something that many people know,", "tokens": [50392, 35924, 3030, 6388, 19618, 13, 6923, 25367, 575, 571, 307, 746, 300, 867, 561, 458, 11, 50712], "temperature": 0.0, "avg_logprob": -0.1427434285481771, "compression_ratio": 1.576036866359447, "no_speech_prob": 0.024991873651742935}, {"id": 20, "seek": 13276, "start": 140.92, "end": 146.2, "text": " but this is very specifically to, if you do a lot of hashing, you don't want to have cash misses,", "tokens": [50772, 457, 341, 307, 588, 4682, 281, 11, 498, 291, 360, 257, 688, 295, 575, 571, 11, 291, 500, 380, 528, 281, 362, 6388, 29394, 11, 51036], "temperature": 0.0, "avg_logprob": -0.1427434285481771, "compression_ratio": 1.576036866359447, "no_speech_prob": 0.024991873651742935}, {"id": 21, "seek": 13276, "start": 146.2, "end": 152.12, "text": " especially when you're scaling systems. And for legacy, we have customers using it for sticky", "tokens": [51036, 2318, 562, 291, 434, 21589, 3652, 13, 400, 337, 11711, 11, 321, 362, 4581, 1228, 309, 337, 14470, 51332], "temperature": 0.0, "avg_logprob": -0.1427434285481771, "compression_ratio": 1.576036866359447, "no_speech_prob": 0.024991873651742935}, {"id": 22, "seek": 13276, "start": 152.12, "end": 156.44, "text": " sessions, but it's like a bit of a mediocre solution to that.", "tokens": [51332, 11081, 11, 457, 309, 311, 411, 257, 857, 295, 257, 45415, 3827, 281, 300, 13, 51548], "temperature": 0.0, "avg_logprob": -0.1427434285481771, "compression_ratio": 1.576036866359447, "no_speech_prob": 0.024991873651742935}, {"id": 23, "seek": 15644, "start": 156.76, "end": 168.04, "text": " So in this case, yeah, as I already explained, the same users go to the same back end, which means that", "tokens": [50380, 407, 294, 341, 1389, 11, 1338, 11, 382, 286, 1217, 8825, 11, 264, 912, 5022, 352, 281, 264, 912, 646, 917, 11, 597, 1355, 300, 50944], "temperature": 0.0, "avg_logprob": -0.21135931856491985, "compression_ratio": 1.5691489361702127, "no_speech_prob": 0.0009973000269383192}, {"id": 24, "seek": 15644, "start": 169.07999999999998, "end": 174.04, "text": " the data that a back end application needs to retrieve from a database would only be related", "tokens": [50996, 264, 1412, 300, 257, 646, 917, 3861, 2203, 281, 30254, 490, 257, 8149, 576, 787, 312, 4077, 51244], "temperature": 0.0, "avg_logprob": -0.21135931856491985, "compression_ratio": 1.5691489361702127, "no_speech_prob": 0.0009973000269383192}, {"id": 25, "seek": 15644, "start": 174.04, "end": 179.24, "text": " to those specific individuals. So the cash hits will be higher considering the amount of cash that", "tokens": [51244, 281, 729, 2685, 5346, 13, 407, 264, 6388, 8664, 486, 312, 2946, 8079, 264, 2372, 295, 6388, 300, 51504], "temperature": 0.0, "avg_logprob": -0.21135931856491985, "compression_ratio": 1.5691489361702127, "no_speech_prob": 0.0009973000269383192}, {"id": 26, "seek": 17924, "start": 179.32000000000002, "end": 189.48000000000002, "text": " the system has available. Then hashing. Hashing in general is the basic concept of hash buckets.", "tokens": [50368, 264, 1185, 575, 2435, 13, 1396, 575, 571, 13, 8646, 571, 294, 2674, 307, 264, 3875, 3410, 295, 22019, 32191, 13, 50876], "temperature": 0.0, "avg_logprob": -0.2155423917268452, "compression_ratio": 1.450777202072539, "no_speech_prob": 0.004002826288342476}, {"id": 27, "seek": 17924, "start": 190.28, "end": 196.44, "text": " You take an input, you throw it into a hashing algorithm. C or C 32 we used before. Now we use", "tokens": [50916, 509, 747, 364, 4846, 11, 291, 3507, 309, 666, 257, 575, 571, 9284, 13, 383, 420, 383, 8858, 321, 1143, 949, 13, 823, 321, 764, 51224], "temperature": 0.0, "avg_logprob": -0.2155423917268452, "compression_ratio": 1.450777202072539, "no_speech_prob": 0.004002826288342476}, {"id": 28, "seek": 17924, "start": 196.44, "end": 203.88, "text": " XX hash fast. It needs to be, have a nice consistent distribution. Then you do a modulo,", "tokens": [51224, 27050, 22019, 2370, 13, 467, 2203, 281, 312, 11, 362, 257, 1481, 8398, 7316, 13, 1396, 291, 360, 257, 1072, 13455, 11, 51596], "temperature": 0.0, "avg_logprob": -0.2155423917268452, "compression_ratio": 1.450777202072539, "no_speech_prob": 0.004002826288342476}, {"id": 29, "seek": 20388, "start": 203.96, "end": 210.04, "text": " in this case modulo 10, you end up in one of 10 buckets. That's basically how it works.", "tokens": [50368, 294, 341, 1389, 1072, 13455, 1266, 11, 291, 917, 493, 294, 472, 295, 1266, 32191, 13, 663, 311, 1936, 577, 309, 1985, 13, 50672], "temperature": 0.0, "avg_logprob": -0.1734296330865824, "compression_ratio": 1.6557377049180328, "no_speech_prob": 0.005057098809629679}, {"id": 30, "seek": 20388, "start": 210.04, "end": 213.64, "text": " So whatever you input, as long as the same input ends up in the same bucket.", "tokens": [50672, 407, 2035, 291, 4846, 11, 382, 938, 382, 264, 912, 4846, 5314, 493, 294, 264, 912, 13058, 13, 50852], "temperature": 0.0, "avg_logprob": -0.1734296330865824, "compression_ratio": 1.6557377049180328, "no_speech_prob": 0.005057098809629679}, {"id": 31, "seek": 20388, "start": 218.76, "end": 221.88, "text": " Now let's take this, the 10 buckets that we have and let's", "tokens": [51108, 823, 718, 311, 747, 341, 11, 264, 1266, 32191, 300, 321, 362, 293, 718, 311, 51264], "temperature": 0.0, "avg_logprob": -0.1734296330865824, "compression_ratio": 1.6557377049180328, "no_speech_prob": 0.005057098809629679}, {"id": 32, "seek": 20388, "start": 223.07999999999998, "end": 228.04, "text": " extend that and say like we have continuum with how in the print the Kitama library,", "tokens": [51324, 10101, 300, 293, 584, 411, 321, 362, 36120, 365, 577, 294, 264, 4482, 264, 23037, 2404, 6405, 11, 51572], "temperature": 0.0, "avg_logprob": -0.1734296330865824, "compression_ratio": 1.6557377049180328, "no_speech_prob": 0.005057098809629679}, {"id": 33, "seek": 20388, "start": 228.04, "end": 233.64, "text": " which is where this was first implemented, they call it continuum. And we're going to have four", "tokens": [51572, 597, 307, 689, 341, 390, 700, 12270, 11, 436, 818, 309, 36120, 13, 400, 321, 434, 516, 281, 362, 1451, 51852], "temperature": 0.0, "avg_logprob": -0.1734296330865824, "compression_ratio": 1.6557377049180328, "no_speech_prob": 0.005057098809629679}, {"id": 34, "seek": 23364, "start": 233.72, "end": 239.72, "text": " nodes, each one serving 25% of the traffic of the entire continuum. So everything that we get in", "tokens": [50368, 13891, 11, 1184, 472, 8148, 3552, 4, 295, 264, 6419, 295, 264, 2302, 36120, 13, 407, 1203, 300, 321, 483, 294, 50668], "temperature": 0.0, "avg_logprob": -0.0988743869881881, "compression_ratio": 1.547872340425532, "no_speech_prob": 0.0007090435246936977}, {"id": 35, "seek": 23364, "start": 239.72, "end": 246.83999999999997, "text": " and we hash into some bucket falls into one of those in the end four nodes. Now if we now scale", "tokens": [50668, 293, 321, 22019, 666, 512, 13058, 8804, 666, 472, 295, 729, 294, 264, 917, 1451, 13891, 13, 823, 498, 321, 586, 4373, 51024], "temperature": 0.0, "avg_logprob": -0.0988743869881881, "compression_ratio": 1.547872340425532, "no_speech_prob": 0.0007090435246936977}, {"id": 36, "seek": 23364, "start": 246.83999999999997, "end": 255.07999999999998, "text": " the system, we add a fifth node. Now we see that we have 20% capacity added. So what is that going", "tokens": [51024, 264, 1185, 11, 321, 909, 257, 9266, 9984, 13, 823, 321, 536, 300, 321, 362, 945, 4, 6042, 3869, 13, 407, 437, 307, 300, 516, 51436], "temperature": 0.0, "avg_logprob": -0.0988743869881881, "compression_ratio": 1.547872340425532, "no_speech_prob": 0.0007090435246936977}, {"id": 37, "seek": 25508, "start": 255.08, "end": 263.48, "text": " to do with our hashing algorithm? From node A, traffic previously going to node A will now end", "tokens": [50364, 281, 360, 365, 527, 575, 571, 9284, 30, 3358, 9984, 316, 11, 6419, 8046, 516, 281, 9984, 316, 486, 586, 917, 50784], "temperature": 0.0, "avg_logprob": -0.12353436358563312, "compression_ratio": 1.5, "no_speech_prob": 0.006487155333161354}, {"id": 38, "seek": 25508, "start": 263.48, "end": 272.76, "text": " up, 5% will end up on node B. From B 10% will go to node C and so on. The overall consistency", "tokens": [50784, 493, 11, 1025, 4, 486, 917, 493, 322, 9984, 363, 13, 3358, 363, 1266, 4, 486, 352, 281, 9984, 383, 293, 370, 322, 13, 440, 4787, 14416, 51248], "temperature": 0.0, "avg_logprob": -0.12353436358563312, "compression_ratio": 1.5, "no_speech_prob": 0.006487155333161354}, {"id": 39, "seek": 25508, "start": 272.76, "end": 278.68, "text": " loss 50%, which means that our backend systems are going to have to fetch a lot of data to catch", "tokens": [51248, 4470, 2625, 8923, 597, 1355, 300, 527, 38087, 3652, 366, 516, 281, 362, 281, 23673, 257, 688, 295, 1412, 281, 3745, 51544], "temperature": 0.0, "avg_logprob": -0.12353436358563312, "compression_ratio": 1.5, "no_speech_prob": 0.006487155333161354}, {"id": 40, "seek": 27868, "start": 278.68, "end": 284.2, "text": " over this 50% because they moved systems. That's the thing that we're trying to prevent.", "tokens": [50364, 670, 341, 2625, 4, 570, 436, 4259, 3652, 13, 663, 311, 264, 551, 300, 321, 434, 1382, 281, 4871, 13, 50640], "temperature": 0.0, "avg_logprob": -0.17478984335194464, "compression_ratio": 1.48868778280543, "no_speech_prob": 0.00831227470189333}, {"id": 41, "seek": 27868, "start": 285.08, "end": 289.56, "text": " So we have 20% capacity added, 50% of the continuum changed.", "tokens": [50684, 407, 321, 362, 945, 4, 6042, 3869, 11, 2625, 4, 295, 264, 36120, 3105, 13, 50908], "temperature": 0.0, "avg_logprob": -0.17478984335194464, "compression_ratio": 1.48868778280543, "no_speech_prob": 0.00831227470189333}, {"id": 42, "seek": 27868, "start": 291.8, "end": 297.64, "text": " Now if you look at what does that mean? At the bottom side we have catch-hate ratio,", "tokens": [51020, 823, 498, 291, 574, 412, 437, 775, 300, 914, 30, 1711, 264, 2767, 1252, 321, 362, 3745, 12, 71, 473, 8509, 11, 51312], "temperature": 0.0, "avg_logprob": -0.17478984335194464, "compression_ratio": 1.48868778280543, "no_speech_prob": 0.00831227470189333}, {"id": 43, "seek": 27868, "start": 298.76, "end": 307.64, "text": " take an HTTP server, 70, 80, 90% HTTP servers can catch that, get there. Then you can see that", "tokens": [51368, 747, 364, 33283, 7154, 11, 5285, 11, 4688, 11, 4289, 4, 33283, 15909, 393, 3745, 300, 11, 483, 456, 13, 1396, 291, 393, 536, 300, 51812], "temperature": 0.0, "avg_logprob": -0.17478984335194464, "compression_ratio": 1.48868778280543, "no_speech_prob": 0.00831227470189333}, {"id": 44, "seek": 30764, "start": 307.64, "end": 314.76, "text": " with a 20% consistency loss, which will be the minimum in our case because we add a server,", "tokens": [50364, 365, 257, 945, 4, 14416, 4470, 11, 597, 486, 312, 264, 7285, 294, 527, 1389, 570, 321, 909, 257, 7154, 11, 50720], "temperature": 0.0, "avg_logprob": -0.13813633918762208, "compression_ratio": 1.6576576576576576, "no_speech_prob": 0.0011687377700582147}, {"id": 45, "seek": 30764, "start": 314.76, "end": 319.8, "text": " 20% capacity, so the minimum is always going to be 20%. So if we do that, we have like 50%", "tokens": [50720, 945, 4, 6042, 11, 370, 264, 7285, 307, 1009, 516, 281, 312, 945, 6856, 407, 498, 321, 360, 300, 11, 321, 362, 411, 2625, 4, 50972], "temperature": 0.0, "avg_logprob": -0.13813633918762208, "compression_ratio": 1.6576576576576576, "no_speech_prob": 0.0011687377700582147}, {"id": 46, "seek": 30764, "start": 319.8, "end": 327.08, "text": " extra capacity temporarily. If we don't use consistent hashing, we have 50% loss and we go to", "tokens": [50972, 2857, 6042, 23750, 13, 759, 321, 500, 380, 764, 8398, 575, 571, 11, 321, 362, 2625, 4, 4470, 293, 321, 352, 281, 51336], "temperature": 0.0, "avg_logprob": -0.13813633918762208, "compression_ratio": 1.6576576576576576, "no_speech_prob": 0.0011687377700582147}, {"id": 47, "seek": 30764, "start": 327.64, "end": 333.88, "text": " more than 120% pretty much on extra capacity, which is quite a big peak that we get on top.", "tokens": [51364, 544, 813, 10411, 4, 1238, 709, 322, 2857, 6042, 11, 597, 307, 1596, 257, 955, 10651, 300, 321, 483, 322, 1192, 13, 51676], "temperature": 0.0, "avg_logprob": -0.13813633918762208, "compression_ratio": 1.6576576576576576, "no_speech_prob": 0.0011687377700582147}, {"id": 48, "seek": 33388, "start": 334.52, "end": 344.68, "text": " Now if you lay this out on a ring, and in this case we'll have simplified depiction,", "tokens": [50396, 823, 498, 291, 2360, 341, 484, 322, 257, 4875, 11, 293, 294, 341, 1389, 321, 603, 362, 26335, 47740, 11, 50904], "temperature": 0.0, "avg_logprob": -0.2288769198135591, "compression_ratio": 1.5081967213114753, "no_speech_prob": 0.0005607607308775187}, {"id": 49, "seek": 33388, "start": 344.68, "end": 350.36, "text": " 20 buckets, whereas in reality for each expected backend that you need, you would expect to use", "tokens": [50904, 945, 32191, 11, 9735, 294, 4103, 337, 1184, 5176, 38087, 300, 291, 643, 11, 291, 576, 2066, 281, 764, 51188], "temperature": 0.0, "avg_logprob": -0.2288769198135591, "compression_ratio": 1.5081967213114753, "no_speech_prob": 0.0005607607308775187}, {"id": 50, "seek": 33388, "start": 350.36, "end": 357.56, "text": " like 50 to 100 entries at least. So if I would have a four backends, I would use 400 entries on", "tokens": [51188, 411, 2625, 281, 2319, 23041, 412, 1935, 13, 407, 498, 286, 576, 362, 257, 1451, 646, 2581, 11, 286, 576, 764, 8423, 23041, 322, 51548], "temperature": 0.0, "avg_logprob": -0.2288769198135591, "compression_ratio": 1.5081967213114753, "no_speech_prob": 0.0005607607308775187}, {"id": 51, "seek": 35756, "start": 357.56, "end": 366.28000000000003, "text": " this ring. Now if we distribute, if we distribute the five targets, the four targets that we had,", "tokens": [50364, 341, 4875, 13, 823, 498, 321, 20594, 11, 498, 321, 20594, 264, 1732, 12911, 11, 264, 1451, 12911, 300, 321, 632, 11, 50800], "temperature": 0.0, "avg_logprob": -0.13775980949401856, "compression_ratio": 1.9073170731707316, "no_speech_prob": 0.019715547561645508}, {"id": 52, "seek": 35756, "start": 366.28000000000003, "end": 372.92, "text": " going to do the same example again, the four targets that we had, then we have two relationships.", "tokens": [50800, 516, 281, 360, 264, 912, 1365, 797, 11, 264, 1451, 12911, 300, 321, 632, 11, 550, 321, 362, 732, 6159, 13, 51132], "temperature": 0.0, "avg_logprob": -0.13775980949401856, "compression_ratio": 1.9073170731707316, "no_speech_prob": 0.019715547561645508}, {"id": 53, "seek": 35756, "start": 373.56, "end": 379.72, "text": " That's the target, the IP port combination, and it's related to one of the positions on the slot,", "tokens": [51164, 663, 311, 264, 3779, 11, 264, 8671, 2436, 6562, 11, 293, 309, 311, 4077, 281, 472, 295, 264, 8432, 322, 264, 14747, 11, 51472], "temperature": 0.0, "avg_logprob": -0.13775980949401856, "compression_ratio": 1.9073170731707316, "no_speech_prob": 0.019715547561645508}, {"id": 54, "seek": 35756, "start": 380.44, "end": 386.6, "text": " one of the slot, different concept, and it's going to be based on weight. Now we have four nodes,", "tokens": [51508, 472, 295, 264, 14747, 11, 819, 3410, 11, 293, 309, 311, 516, 281, 312, 2361, 322, 3364, 13, 823, 321, 362, 1451, 13891, 11, 51816], "temperature": 0.0, "avg_logprob": -0.13775980949401856, "compression_ratio": 1.9073170731707316, "no_speech_prob": 0.019715547561645508}, {"id": 55, "seek": 38660, "start": 387.16, "end": 393.0, "text": " same weight, so each node gets 25% of the available slots, fairly straightforward.", "tokens": [50392, 912, 3364, 11, 370, 1184, 9984, 2170, 3552, 4, 295, 264, 2435, 24266, 11, 6457, 15325, 13, 50684], "temperature": 0.0, "avg_logprob": -0.11076109568277995, "compression_ratio": 1.4540816326530612, "no_speech_prob": 0.000984183163382113}, {"id": 56, "seek": 38660, "start": 394.76000000000005, "end": 400.92, "text": " Then there's a slot towards the position on the hash bucket, and that's a one-on-one relationship.", "tokens": [50772, 1396, 456, 311, 257, 14747, 3030, 264, 2535, 322, 264, 22019, 13058, 11, 293, 300, 311, 257, 472, 12, 266, 12, 546, 2480, 13, 51080], "temperature": 0.0, "avg_logprob": -0.11076109568277995, "compression_ratio": 1.4540816326530612, "no_speech_prob": 0.000984183163382113}, {"id": 57, "seek": 38660, "start": 400.92, "end": 409.56, "text": " Every slot goes into one bucket, but it's randomized. So if we apply that, this is the way I would get.", "tokens": [51080, 2048, 14747, 1709, 666, 472, 13058, 11, 457, 309, 311, 38513, 13, 407, 498, 321, 3079, 300, 11, 341, 307, 264, 636, 286, 576, 483, 13, 51512], "temperature": 0.0, "avg_logprob": -0.11076109568277995, "compression_ratio": 1.4540816326530612, "no_speech_prob": 0.000984183163382113}, {"id": 58, "seek": 40956, "start": 410.44, "end": 418.76, "text": " So instead of a continuous ranges of AAAA, BBB, CCC, we get a random layout with those nodes.", "tokens": [50408, 407, 2602, 295, 257, 10957, 22526, 295, 34347, 32, 11, 19168, 33, 11, 383, 11717, 11, 321, 483, 257, 4974, 13333, 365, 729, 13891, 13, 50824], "temperature": 0.0, "avg_logprob": -0.15506749059639724, "compression_ratio": 1.3185185185185184, "no_speech_prob": 0.002672638976946473}, {"id": 59, "seek": 40956, "start": 426.2, "end": 431.48, "text": " If we now do hashing, basically we see that every hash ends up nicely in its bucket,", "tokens": [51196, 759, 321, 586, 360, 575, 571, 11, 1936, 321, 536, 300, 633, 22019, 5314, 493, 9594, 294, 1080, 13058, 11, 51460], "temperature": 0.0, "avg_logprob": -0.15506749059639724, "compression_ratio": 1.3185185185185184, "no_speech_prob": 0.002672638976946473}, {"id": 60, "seek": 43148, "start": 432.28000000000003, "end": 440.84000000000003, "text": " and as a side effect, we'll get if hashing is not available, because the property is not available,", "tokens": [50404, 293, 382, 257, 1252, 1802, 11, 321, 603, 483, 498, 575, 571, 307, 406, 2435, 11, 570, 264, 4707, 307, 406, 2435, 11, 50832], "temperature": 0.0, "avg_logprob": -0.19909222920735678, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.004067037720233202}, {"id": 61, "seek": 43148, "start": 440.84000000000003, "end": 446.76, "text": " we can do an easy round robin, good by simply walking the ring, which is a side effect of Yawarun.", "tokens": [50832, 321, 393, 360, 364, 1858, 3098, 3870, 259, 11, 665, 538, 2935, 4494, 264, 4875, 11, 597, 307, 257, 1252, 1802, 295, 398, 1607, 289, 409, 13, 51128], "temperature": 0.0, "avg_logprob": -0.19909222920735678, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.004067037720233202}, {"id": 62, "seek": 43148, "start": 449.08000000000004, "end": 452.92, "text": " Now if we move into adding the node again, the same thing that we did before,", "tokens": [51244, 823, 498, 321, 1286, 666, 5127, 264, 9984, 797, 11, 264, 912, 551, 300, 321, 630, 949, 11, 51436], "temperature": 0.0, "avg_logprob": -0.19909222920735678, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.004067037720233202}, {"id": 63, "seek": 43148, "start": 452.92, "end": 457.40000000000003, "text": " we're adding 20% capacity, what we're going to do, we're going to relieve every,", "tokens": [51436, 321, 434, 5127, 945, 4, 6042, 11, 437, 321, 434, 516, 281, 360, 11, 321, 434, 516, 281, 30450, 633, 11, 51660], "temperature": 0.0, "avg_logprob": -0.19909222920735678, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.004067037720233202}, {"id": 64, "seek": 45740, "start": 458.35999999999996, "end": 462.44, "text": " for the slots that we have assigned, we're going to ask every back end to relieve", "tokens": [50412, 337, 264, 24266, 300, 321, 362, 13279, 11, 321, 434, 516, 281, 1029, 633, 646, 917, 281, 30450, 50616], "temperature": 0.0, "avg_logprob": -0.15764675537745157, "compression_ratio": 1.6740088105726871, "no_speech_prob": 0.004894370678812265}, {"id": 65, "seek": 45740, "start": 463.15999999999997, "end": 468.76, "text": " the amount of slots that are no longer to be assigned to them, in this case they were used from 25 to 20%,", "tokens": [50652, 264, 2372, 295, 24266, 300, 366, 572, 2854, 281, 312, 13279, 281, 552, 11, 294, 341, 1389, 436, 645, 1143, 490, 3552, 281, 945, 8923, 50932], "temperature": 0.0, "avg_logprob": -0.15764675537745157, "compression_ratio": 1.6740088105726871, "no_speech_prob": 0.004894370678812265}, {"id": 66, "seek": 45740, "start": 469.32, "end": 476.12, "text": " one slot, and we assign them to the new one. Now if we do that, we can see that the distribution", "tokens": [50960, 472, 14747, 11, 293, 321, 6269, 552, 281, 264, 777, 472, 13, 823, 498, 321, 360, 300, 11, 321, 393, 536, 300, 264, 7316, 51300], "temperature": 0.0, "avg_logprob": -0.15764675537745157, "compression_ratio": 1.6740088105726871, "no_speech_prob": 0.004894370678812265}, {"id": 67, "seek": 45740, "start": 476.67999999999995, "end": 484.12, "text": " stays the same, and the hashing principle now works, because we have minimal consistency loss.", "tokens": [51328, 10834, 264, 912, 11, 293, 264, 575, 571, 8665, 586, 1985, 11, 570, 321, 362, 13206, 14416, 4470, 13, 51700], "temperature": 0.0, "avg_logprob": -0.15764675537745157, "compression_ratio": 1.6740088105726871, "no_speech_prob": 0.004894370678812265}, {"id": 68, "seek": 48412, "start": 484.84000000000003, "end": 489.48, "text": " Now instead of having the 50% consistency loss at the start, we now end up with like", "tokens": [50400, 823, 2602, 295, 1419, 264, 2625, 4, 14416, 4470, 412, 264, 722, 11, 321, 586, 917, 493, 365, 411, 50632], "temperature": 0.0, "avg_logprob": -0.10333377974373954, "compression_ratio": 1.5566037735849056, "no_speech_prob": 0.0008417305652983487}, {"id": 69, "seek": 48412, "start": 489.48, "end": 493.72, "text": " the minimal consistency loss of only exactly the 20% that we added in capacity.", "tokens": [50632, 264, 13206, 14416, 4470, 295, 787, 2293, 264, 945, 4, 300, 321, 3869, 294, 6042, 13, 50844], "temperature": 0.0, "avg_logprob": -0.10333377974373954, "compression_ratio": 1.5566037735849056, "no_speech_prob": 0.0008417305652983487}, {"id": 70, "seek": 48412, "start": 498.92, "end": 504.28000000000003, "text": " It also has featured that if we have a simple health checker attached to it,", "tokens": [51104, 467, 611, 575, 13822, 300, 498, 321, 362, 257, 2199, 1585, 1520, 260, 8570, 281, 309, 11, 51372], "temperature": 0.0, "avg_logprob": -0.10333377974373954, "compression_ratio": 1.5566037735849056, "no_speech_prob": 0.0008417305652983487}, {"id": 71, "seek": 48412, "start": 504.28000000000003, "end": 509.8, "text": " it's quite common with load balancers, is that we can actually move on to the next slot,", "tokens": [51372, 309, 311, 1596, 2689, 365, 3677, 3119, 4463, 433, 11, 307, 300, 321, 393, 767, 1286, 322, 281, 264, 958, 14747, 11, 51648], "temperature": 0.0, "avg_logprob": -0.10333377974373954, "compression_ratio": 1.5566037735849056, "no_speech_prob": 0.0008417305652983487}, {"id": 72, "seek": 50980, "start": 510.76, "end": 515.4, "text": " and our distribution will not really change. Yes, we'll have an impact on the consistent hashing", "tokens": [50412, 293, 527, 7316, 486, 406, 534, 1319, 13, 1079, 11, 321, 603, 362, 364, 2712, 322, 264, 8398, 575, 571, 50644], "temperature": 0.0, "avg_logprob": -0.16383042206635345, "compression_ratio": 1.6224489795918366, "no_speech_prob": 0.002706887200474739}, {"id": 73, "seek": 50980, "start": 515.4, "end": 520.36, "text": " principle, and we'll have catch losses, but due to the way it's random layout,", "tokens": [50644, 8665, 11, 293, 321, 603, 362, 3745, 15352, 11, 457, 3462, 281, 264, 636, 309, 311, 4974, 13333, 11, 50892], "temperature": 0.0, "avg_logprob": -0.16383042206635345, "compression_ratio": 1.6224489795918366, "no_speech_prob": 0.002706887200474739}, {"id": 74, "seek": 50980, "start": 521.48, "end": 526.12, "text": " we still maintain that the weights are properly distributed, and the traffic is going to be", "tokens": [50948, 321, 920, 6909, 300, 264, 17443, 366, 6108, 12631, 11, 293, 264, 6419, 307, 516, 281, 312, 51180], "temperature": 0.0, "avg_logprob": -0.16383042206635345, "compression_ratio": 1.6224489795918366, "no_speech_prob": 0.002706887200474739}, {"id": 75, "seek": 50980, "start": 526.12, "end": 528.6, "text": " distributed about across all your remaining nodes.", "tokens": [51180, 12631, 466, 2108, 439, 428, 8877, 13891, 13, 51304], "temperature": 0.0, "avg_logprob": -0.16383042206635345, "compression_ratio": 1.6224489795918366, "no_speech_prob": 0.002706887200474739}, {"id": 76, "seek": 52860, "start": 528.6, "end": 542.76, "text": " Now, that is like the basic concept of how you do the consistent hashing,", "tokens": [50364, 823, 11, 300, 307, 411, 264, 3875, 3410, 295, 577, 291, 360, 264, 8398, 575, 571, 11, 51072], "temperature": 0.0, "avg_logprob": -0.15214325132824125, "compression_ratio": 1.5414012738853504, "no_speech_prob": 0.0011332329595461488}, {"id": 77, "seek": 52860, "start": 542.76, "end": 547.72, "text": " and how you minimize this hashing loss. Now when it gets really tricky,", "tokens": [51072, 293, 577, 291, 17522, 341, 575, 571, 4470, 13, 823, 562, 309, 2170, 534, 12414, 11, 51320], "temperature": 0.0, "avg_logprob": -0.15214325132824125, "compression_ratio": 1.5414012738853504, "no_speech_prob": 0.0011332329595461488}, {"id": 78, "seek": 52860, "start": 547.72, "end": 552.76, "text": " is when you have to do this in a cluster. In a con cluster, the nodes are basically independent,", "tokens": [51320, 307, 562, 291, 362, 281, 360, 341, 294, 257, 13630, 13, 682, 257, 416, 13630, 11, 264, 13891, 366, 1936, 6695, 11, 51572], "temperature": 0.0, "avg_logprob": -0.15214325132824125, "compression_ratio": 1.5414012738853504, "no_speech_prob": 0.0011332329595461488}, {"id": 79, "seek": 55276, "start": 552.76, "end": 559.0, "text": " so there's no shared state, at least we try to minimize, and we just saw that we had a lot of", "tokens": [50364, 370, 456, 311, 572, 5507, 1785, 11, 412, 1935, 321, 853, 281, 17522, 11, 293, 321, 445, 1866, 300, 321, 632, 257, 688, 295, 50676], "temperature": 0.0, "avg_logprob": -0.1394909240387298, "compression_ratio": 1.729064039408867, "no_speech_prob": 0.00327211432158947}, {"id": 80, "seek": 55276, "start": 559.0, "end": 563.72, "text": " like random stuff in there, distribution layout, etc., and that's what makes it hard.", "tokens": [50676, 411, 4974, 1507, 294, 456, 11, 7316, 13333, 11, 5183, 7933, 293, 300, 311, 437, 1669, 309, 1152, 13, 50912], "temperature": 0.0, "avg_logprob": -0.1394909240387298, "compression_ratio": 1.729064039408867, "no_speech_prob": 0.00327211432158947}, {"id": 81, "seek": 55276, "start": 567.56, "end": 575.64, "text": " So if we have to build a deterministic layout of that ring, we have to make sure that we build", "tokens": [51104, 407, 498, 321, 362, 281, 1322, 257, 15957, 3142, 13333, 295, 300, 4875, 11, 321, 362, 281, 652, 988, 300, 321, 1322, 51508], "temperature": 0.0, "avg_logprob": -0.1394909240387298, "compression_ratio": 1.729064039408867, "no_speech_prob": 0.00327211432158947}, {"id": 82, "seek": 55276, "start": 575.64, "end": 579.56, "text": " the exact same ring with the exact same layout on every node in the cluster.", "tokens": [51508, 264, 1900, 912, 4875, 365, 264, 1900, 912, 13333, 322, 633, 9984, 294, 264, 13630, 13, 51704], "temperature": 0.0, "avg_logprob": -0.1394909240387298, "compression_ratio": 1.729064039408867, "no_speech_prob": 0.00327211432158947}, {"id": 83, "seek": 57956, "start": 580.3599999999999, "end": 588.8399999999999, "text": " And that's where it gets hard. So for the random layout, the way we solve this is by", "tokens": [50404, 400, 300, 311, 689, 309, 2170, 1152, 13, 407, 337, 264, 4974, 13333, 11, 264, 636, 321, 5039, 341, 307, 538, 50828], "temperature": 0.0, "avg_logprob": -0.1919471195765904, "compression_ratio": 1.7871287128712872, "no_speech_prob": 0.0014097087550908327}, {"id": 84, "seek": 57956, "start": 589.56, "end": 596.1999999999999, "text": " using the distribution, the random distribution, but not the unpredictable, the unpredictability", "tokens": [50864, 1228, 264, 7316, 11, 264, 4974, 7316, 11, 457, 406, 264, 31160, 11, 264, 28341, 2310, 51196], "temperature": 0.0, "avg_logprob": -0.1919471195765904, "compression_ratio": 1.7871287128712872, "no_speech_prob": 0.0014097087550908327}, {"id": 85, "seek": 57956, "start": 596.1999999999999, "end": 602.52, "text": " of a random number generator by using a separate random number generator, but with a fixed seed,", "tokens": [51196, 295, 257, 4974, 1230, 19265, 538, 1228, 257, 4994, 4974, 1230, 19265, 11, 457, 365, 257, 6806, 8871, 11, 51512], "temperature": 0.0, "avg_logprob": -0.1919471195765904, "compression_ratio": 1.7871287128712872, "no_speech_prob": 0.0014097087550908327}, {"id": 86, "seek": 57956, "start": 602.52, "end": 605.9599999999999, "text": " just a constant, so it generates the same thing over and over again on every node,", "tokens": [51512, 445, 257, 5754, 11, 370, 309, 23815, 264, 912, 551, 670, 293, 670, 797, 322, 633, 9984, 11, 51684], "temperature": 0.0, "avg_logprob": -0.1919471195765904, "compression_ratio": 1.7871287128712872, "no_speech_prob": 0.0014097087550908327}, {"id": 87, "seek": 60596, "start": 606.44, "end": 610.2800000000001, "text": " because we don't care about it being unique, we only care about the distribution,", "tokens": [50388, 570, 321, 500, 380, 1127, 466, 309, 885, 3845, 11, 321, 787, 1127, 466, 264, 7316, 11, 50580], "temperature": 0.0, "avg_logprob": -0.1413935670758238, "compression_ratio": 1.707112970711297, "no_speech_prob": 0.0010981131345033646}, {"id": 88, "seek": 60596, "start": 610.84, "end": 617.8000000000001, "text": " that is randomly distributed on the ring. Tracking changes as nodes are being added and removed,", "tokens": [50608, 300, 307, 16979, 12631, 322, 264, 4875, 13, 1765, 14134, 2962, 382, 13891, 366, 885, 3869, 293, 7261, 11, 50956], "temperature": 0.0, "avg_logprob": -0.1413935670758238, "compression_ratio": 1.707112970711297, "no_speech_prob": 0.0010981131345033646}, {"id": 89, "seek": 60596, "start": 618.84, "end": 623.8000000000001, "text": " we keep a log history. So whenever we add a new node, if a cluster gets expanded,", "tokens": [51008, 321, 1066, 257, 3565, 2503, 13, 407, 5699, 321, 909, 257, 777, 9984, 11, 498, 257, 13630, 2170, 14342, 11, 51256], "temperature": 0.0, "avg_logprob": -0.1413935670758238, "compression_ratio": 1.707112970711297, "no_speech_prob": 0.0010981131345033646}, {"id": 90, "seek": 60596, "start": 624.52, "end": 630.6800000000001, "text": " we just replay all the changes, so we end up with the exact same state of the cluster,", "tokens": [51292, 321, 445, 23836, 439, 264, 2962, 11, 370, 321, 917, 493, 365, 264, 1900, 912, 1785, 295, 264, 13630, 11, 51600], "temperature": 0.0, "avg_logprob": -0.1413935670758238, "compression_ratio": 1.707112970711297, "no_speech_prob": 0.0010981131345033646}, {"id": 91, "seek": 60596, "start": 630.6800000000001, "end": 633.5600000000001, "text": " of the ring, and make sure that the hashing still functions.", "tokens": [51600, 295, 264, 4875, 11, 293, 652, 988, 300, 264, 575, 571, 920, 6828, 13, 51744], "temperature": 0.0, "avg_logprob": -0.1413935670758238, "compression_ratio": 1.707112970711297, "no_speech_prob": 0.0010981131345033646}, {"id": 92, "seek": 63596, "start": 636.9200000000001, "end": 641.5600000000001, "text": " And then you think we have it covered, and then comes DNS.", "tokens": [50412, 400, 550, 291, 519, 321, 362, 309, 5343, 11, 293, 550, 1487, 35153, 13, 50644], "temperature": 0.0, "avg_logprob": -0.19010324831362124, "compression_ratio": 1.4880382775119618, "no_speech_prob": 0.0012838962720707059}, {"id": 93, "seek": 63596, "start": 643.4000000000001, "end": 650.36, "text": " Because initially we had it laid out to do just IP and port, but that's static,", "tokens": [50736, 1436, 9105, 321, 632, 309, 9897, 484, 281, 360, 445, 8671, 293, 2436, 11, 457, 300, 311, 13437, 11, 51084], "temperature": 0.0, "avg_logprob": -0.19010324831362124, "compression_ratio": 1.4880382775119618, "no_speech_prob": 0.0012838962720707059}, {"id": 94, "seek": 63596, "start": 651.08, "end": 655.5600000000001, "text": " and in all of our customers' environments, it doesn't work. So we have the Kubernetes", "tokens": [51120, 293, 294, 439, 295, 527, 4581, 6, 12388, 11, 309, 1177, 380, 589, 13, 407, 321, 362, 264, 23145, 51344], "temperature": 0.0, "avg_logprob": -0.19010324831362124, "compression_ratio": 1.4880382775119618, "no_speech_prob": 0.0012838962720707059}, {"id": 95, "seek": 63596, "start": 656.12, "end": 662.0400000000001, "text": " OpenShift console, and a common denominator there is DNS. So they do source discovery,", "tokens": [51372, 7238, 7774, 2008, 11076, 11, 293, 257, 2689, 20687, 456, 307, 35153, 13, 407, 436, 360, 4009, 12114, 11, 51668], "temperature": 0.0, "avg_logprob": -0.19010324831362124, "compression_ratio": 1.4880382775119618, "no_speech_prob": 0.0012838962720707059}, {"id": 96, "seek": 66204, "start": 662.04, "end": 665.56, "text": " and then exposes through a DNS interface, that's where you get your backhands.", "tokens": [50364, 293, 550, 1278, 4201, 807, 257, 35153, 9226, 11, 300, 311, 689, 291, 483, 428, 646, 71, 2967, 13, 50540], "temperature": 0.0, "avg_logprob": -0.18253644307454428, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.0013456182787194848}, {"id": 97, "seek": 66204, "start": 671.9599999999999, "end": 678.92, "text": " So the solution we had is that we had to expand our balancer to not just take IP at a result,", "tokens": [50860, 407, 264, 3827, 321, 632, 307, 300, 321, 632, 281, 5268, 527, 3119, 28347, 281, 406, 445, 747, 8671, 412, 257, 1874, 11, 51208], "temperature": 0.0, "avg_logprob": -0.18253644307454428, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.0013456182787194848}, {"id": 98, "seek": 66204, "start": 678.92, "end": 684.4399999999999, "text": " we had to take hostnames. Now we have to resolve them, and then instead of having a single entry", "tokens": [51208, 321, 632, 281, 747, 3975, 77, 1632, 13, 823, 321, 362, 281, 14151, 552, 11, 293, 550, 2602, 295, 1419, 257, 2167, 8729, 51484], "temperature": 0.0, "avg_logprob": -0.18253644307454428, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.0013456182787194848}, {"id": 99, "seek": 66204, "start": 684.4399999999999, "end": 689.0, "text": " for a hostname, we could have like 2, 3, 4, 5, depending on what's in the record.", "tokens": [51484, 337, 257, 3975, 16344, 11, 321, 727, 362, 411, 568, 11, 805, 11, 1017, 11, 1025, 11, 5413, 322, 437, 311, 294, 264, 2136, 13, 51712], "temperature": 0.0, "avg_logprob": -0.18253644307454428, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.0013456182787194848}, {"id": 100, "seek": 69204, "start": 692.12, "end": 705.7199999999999, "text": " But that hurts. Because if you look at what some of those discovery tools do,", "tokens": [50368, 583, 300, 11051, 13, 1436, 498, 291, 574, 412, 437, 512, 295, 729, 12114, 3873, 360, 11, 51048], "temperature": 0.0, "avg_logprob": -0.14040301827823415, "compression_ratio": 1.5465116279069768, "no_speech_prob": 0.0008956918027251959}, {"id": 101, "seek": 69204, "start": 707.0799999999999, "end": 711.88, "text": " they don't set a truncation flag, which means that every node in the cluster is going to get", "tokens": [51116, 436, 500, 380, 992, 257, 504, 409, 46252, 7166, 11, 597, 1355, 300, 633, 9984, 294, 264, 13630, 307, 516, 281, 483, 51356], "temperature": 0.0, "avg_logprob": -0.14040301827823415, "compression_ratio": 1.5465116279069768, "no_speech_prob": 0.0008956918027251959}, {"id": 102, "seek": 69204, "start": 711.88, "end": 718.52, "text": " a different answer in a different random order. A console, for example, does that, and the core", "tokens": [51356, 257, 819, 1867, 294, 257, 819, 4974, 1668, 13, 316, 11076, 11, 337, 1365, 11, 775, 300, 11, 293, 264, 4965, 51688], "temperature": 0.0, "avg_logprob": -0.14040301827823415, "compression_ratio": 1.5465116279069768, "no_speech_prob": 0.0008956918027251959}, {"id": 103, "seek": 71852, "start": 718.52, "end": 725.0, "text": " of it is that those tools try to do load balancing on an infrastructure level by forcing you to renew", "tokens": [50364, 295, 309, 307, 300, 729, 3873, 853, 281, 360, 3677, 22495, 322, 364, 6896, 1496, 538, 19030, 291, 281, 10162, 50688], "temperature": 0.0, "avg_logprob": -0.11792883040413024, "compression_ratio": 1.730909090909091, "no_speech_prob": 0.01909463107585907}, {"id": 104, "seek": 71852, "start": 725.0, "end": 728.92, "text": " the DNS records, and then they're going to give you only the information they want you to have.", "tokens": [50688, 264, 35153, 7724, 11, 293, 550, 436, 434, 516, 281, 976, 291, 787, 264, 1589, 436, 528, 291, 281, 362, 13, 50884], "temperature": 0.0, "avg_logprob": -0.11792883040413024, "compression_ratio": 1.730909090909091, "no_speech_prob": 0.01909463107585907}, {"id": 105, "seek": 71852, "start": 729.48, "end": 737.88, "text": " So a console is typically quite often we've seen deployment with TTL0 and no truncation flag.", "tokens": [50912, 407, 257, 11076, 307, 5850, 1596, 2049, 321, 600, 1612, 19317, 365, 32576, 43, 15, 293, 572, 504, 409, 46252, 7166, 13, 51332], "temperature": 0.0, "avg_logprob": -0.11792883040413024, "compression_ratio": 1.730909090909091, "no_speech_prob": 0.01909463107585907}, {"id": 106, "seek": 71852, "start": 737.88, "end": 742.84, "text": " So you get one record, two records, three records, but not all of them. Once we have a", "tokens": [51332, 407, 291, 483, 472, 2136, 11, 732, 7724, 11, 1045, 7724, 11, 457, 406, 439, 295, 552, 13, 3443, 321, 362, 257, 51580], "temperature": 0.0, "avg_logprob": -0.11792883040413024, "compression_ratio": 1.730909090909091, "no_speech_prob": 0.01909463107585907}, {"id": 107, "seek": 71852, "start": 742.84, "end": 747.8, "text": " truncation flag, we know we can retry, we can do TCP, we get a whole lot of them, and then we can", "tokens": [51580, 504, 409, 46252, 7166, 11, 321, 458, 321, 393, 1533, 627, 11, 321, 393, 360, 48965, 11, 321, 483, 257, 1379, 688, 295, 552, 11, 293, 550, 321, 393, 51828], "temperature": 0.0, "avg_logprob": -0.11792883040413024, "compression_ratio": 1.730909090909091, "no_speech_prob": 0.01909463107585907}, {"id": 108, "seek": 74780, "start": 747.8, "end": 752.04, "text": " check that our balancer stays in sync. Quite often we see that it doesn't happen and the", "tokens": [50364, 1520, 300, 527, 3119, 28347, 10834, 294, 20271, 13, 20464, 2049, 321, 536, 300, 309, 1177, 380, 1051, 293, 264, 50576], "temperature": 0.0, "avg_logprob": -0.1804382024186381, "compression_ratio": 1.5777777777777777, "no_speech_prob": 0.004536343272775412}, {"id": 109, "seek": 74780, "start": 752.04, "end": 759.16, "text": " balancer goes out of sync, and then we have customers complaining, basically. TTL0 means", "tokens": [50576, 3119, 28347, 1709, 484, 295, 20271, 11, 293, 550, 321, 362, 4581, 20740, 11, 1936, 13, 32576, 43, 15, 1355, 50932], "temperature": 0.0, "avg_logprob": -0.1804382024186381, "compression_ratio": 1.5777777777777777, "no_speech_prob": 0.004536343272775412}, {"id": 110, "seek": 74780, "start": 759.8, "end": 764.76, "text": " lots of changes and updates. Every change is an update to the balance of the structure,", "tokens": [50964, 3195, 295, 2962, 293, 9205, 13, 2048, 1319, 307, 364, 5623, 281, 264, 4772, 295, 264, 3877, 11, 51212], "temperature": 0.0, "avg_logprob": -0.1804382024186381, "compression_ratio": 1.5777777777777777, "no_speech_prob": 0.004536343272775412}, {"id": 111, "seek": 74780, "start": 764.76, "end": 772.8399999999999, "text": " which is like really not a good combination. And then of course there's bugs. I was just,", "tokens": [51212, 597, 307, 411, 534, 406, 257, 665, 6562, 13, 400, 550, 295, 1164, 456, 311, 15120, 13, 286, 390, 445, 11, 51616], "temperature": 0.0, "avg_logprob": -0.1804382024186381, "compression_ratio": 1.5777777777777777, "no_speech_prob": 0.004536343272775412}, {"id": 112, "seek": 77284, "start": 773.8000000000001, "end": 779.32, "text": " you were commenting on DNS, it's always DNS. And we actually, we had a discussion yesterday and", "tokens": [50412, 291, 645, 29590, 322, 35153, 11, 309, 311, 1009, 35153, 13, 400, 321, 767, 11, 321, 632, 257, 5017, 5186, 293, 50688], "temperature": 0.0, "avg_logprob": -0.19308500630514963, "compression_ratio": 1.643835616438356, "no_speech_prob": 0.008706520311534405}, {"id": 113, "seek": 77284, "start": 779.32, "end": 784.6800000000001, "text": " somebody said actually like, DNS is like the RFC is just like the primer, and then the real", "tokens": [50688, 2618, 848, 767, 411, 11, 35153, 307, 411, 264, 497, 18671, 307, 445, 411, 264, 12595, 11, 293, 550, 264, 957, 50956], "temperature": 0.0, "avg_logprob": -0.19308500630514963, "compression_ratio": 1.643835616438356, "no_speech_prob": 0.008706520311534405}, {"id": 114, "seek": 77284, "start": 784.6800000000001, "end": 789.24, "text": " implementation is there are 100 million different limitations out there. That's what DNS pretty", "tokens": [50956, 11420, 307, 456, 366, 2319, 2459, 819, 15705, 484, 456, 13, 663, 311, 437, 35153, 1238, 51184], "temperature": 0.0, "avg_logprob": -0.19308500630514963, "compression_ratio": 1.643835616438356, "no_speech_prob": 0.008706520311534405}, {"id": 115, "seek": 77284, "start": 789.24, "end": 797.1600000000001, "text": " much is. And you have the cater for all of them. So we have customers that set up DNS to only return", "tokens": [51184, 709, 307, 13, 400, 291, 362, 264, 21557, 337, 439, 295, 552, 13, 407, 321, 362, 4581, 300, 992, 493, 35153, 281, 787, 2736, 51580], "temperature": 0.0, "avg_logprob": -0.19308500630514963, "compression_ratio": 1.643835616438356, "no_speech_prob": 0.008706520311534405}, {"id": 116, "seek": 77284, "start": 797.1600000000001, "end": 801.72, "text": " a single record ever, and an infrastructure team is refusing to change it despite the fact that", "tokens": [51580, 257, 2167, 2136, 1562, 11, 293, 364, 6896, 1469, 307, 37289, 281, 1319, 309, 7228, 264, 1186, 300, 51808], "temperature": 0.0, "avg_logprob": -0.19308500630514963, "compression_ratio": 1.643835616438356, "no_speech_prob": 0.008706520311534405}, {"id": 117, "seek": 80172, "start": 801.8000000000001, "end": 809.4, "text": " application teams have difficulties with their load balancing. Amazon has Route 53,", "tokens": [50368, 3861, 5491, 362, 14399, 365, 641, 3677, 22495, 13, 6795, 575, 39142, 21860, 11, 50748], "temperature": 0.0, "avg_logprob": -0.1819958036596125, "compression_ratio": 1.4747899159663866, "no_speech_prob": 0.004254186060279608}, {"id": 118, "seek": 80172, "start": 810.0400000000001, "end": 818.9200000000001, "text": " occasionally gives you a TTL0, because my guess is it's a rounding bug when the TTL gets too low", "tokens": [50780, 16895, 2709, 291, 257, 32576, 43, 15, 11, 570, 452, 2041, 307, 309, 311, 257, 48237, 7426, 562, 264, 32576, 43, 2170, 886, 2295, 51224], "temperature": 0.0, "avg_logprob": -0.1819958036596125, "compression_ratio": 1.4747899159663866, "no_speech_prob": 0.004254186060279608}, {"id": 119, "seek": 80172, "start": 818.9200000000001, "end": 823.0, "text": " to return zero, which it shouldn't be doing. Now if you think all of this is hard,", "tokens": [51224, 281, 2736, 4018, 11, 597, 309, 4659, 380, 312, 884, 13, 823, 498, 291, 519, 439, 295, 341, 307, 1152, 11, 51428], "temperature": 0.0, "avg_logprob": -0.1819958036596125, "compression_ratio": 1.4747899159663866, "no_speech_prob": 0.004254186060279608}, {"id": 120, "seek": 80172, "start": 823.72, "end": 831.4, "text": " try filing a bug with Amazon. That's really hard. So in essence, we haven't implemented", "tokens": [51464, 853, 26854, 257, 7426, 365, 6795, 13, 663, 311, 534, 1152, 13, 407, 294, 12801, 11, 321, 2378, 380, 12270, 51848], "temperature": 0.0, "avg_logprob": -0.1819958036596125, "compression_ratio": 1.4747899159663866, "no_speech_prob": 0.004254186060279608}, {"id": 121, "seek": 83172, "start": 832.0400000000001, "end": 839.0, "text": " implemented it, but to really properly replay everything, we would need to have some central", "tokens": [50380, 12270, 309, 11, 457, 281, 534, 6108, 23836, 1203, 11, 321, 576, 643, 281, 362, 512, 5777, 50728], "temperature": 0.0, "avg_logprob": -0.11778813023721019, "compression_ratio": 1.5819672131147542, "no_speech_prob": 0.004329447168856859}, {"id": 122, "seek": 83172, "start": 839.0, "end": 845.08, "text": " storage where we have the DNS records over time stored as well. So not only the changes in the", "tokens": [50728, 6725, 689, 321, 362, 264, 35153, 7724, 670, 565, 12187, 382, 731, 13, 407, 406, 787, 264, 2962, 294, 264, 51032], "temperature": 0.0, "avg_logprob": -0.11778813023721019, "compression_ratio": 1.5819672131147542, "no_speech_prob": 0.004329447168856859}, {"id": 123, "seek": 83172, "start": 845.08, "end": 849.72, "text": " host names, but also at that point in time, how does it resolve what are the entries we're getting?", "tokens": [51032, 3975, 5288, 11, 457, 611, 412, 300, 935, 294, 565, 11, 577, 775, 309, 14151, 437, 366, 264, 23041, 321, 434, 1242, 30, 51264], "temperature": 0.0, "avg_logprob": -0.11778813023721019, "compression_ratio": 1.5819672131147542, "no_speech_prob": 0.004329447168856859}, {"id": 124, "seek": 83172, "start": 850.36, "end": 856.6, "text": " Because if I add a new node in my cluster later on, rebuild it, and that node gets four entries in", "tokens": [51296, 1436, 498, 286, 909, 257, 777, 9984, 294, 452, 13630, 1780, 322, 11, 16877, 309, 11, 293, 300, 9984, 2170, 1451, 23041, 294, 51608], "temperature": 0.0, "avg_logprob": -0.11778813023721019, "compression_ratio": 1.5819672131147542, "no_speech_prob": 0.004329447168856859}, {"id": 125, "seek": 85660, "start": 856.6, "end": 862.2, "text": " the DNS, where the ones that were started earlier got only three, so we'll get the thing is out of sync again.", "tokens": [50364, 264, 35153, 11, 689, 264, 2306, 300, 645, 1409, 3071, 658, 787, 1045, 11, 370, 321, 603, 483, 264, 551, 307, 484, 295, 20271, 797, 13, 50644], "temperature": 0.0, "avg_logprob": -0.2514906180532355, "compression_ratio": 1.4885057471264367, "no_speech_prob": 0.00608485983684659}, {"id": 126, "seek": 85660, "start": 866.9200000000001, "end": 867.72, "text": " Now if you look at the", "tokens": [50880, 823, 498, 291, 574, 412, 264, 50920], "temperature": 0.0, "avg_logprob": -0.2514906180532355, "compression_ratio": 1.4885057471264367, "no_speech_prob": 0.00608485983684659}, {"id": 127, "seek": 85660, "start": 870.52, "end": 875.4, "text": " overall thing, I don't know where we are in time. Oh, we're in 10 minutes left.", "tokens": [51060, 4787, 551, 11, 286, 500, 380, 458, 689, 321, 366, 294, 565, 13, 876, 11, 321, 434, 294, 1266, 2077, 1411, 13, 51304], "temperature": 0.0, "avg_logprob": -0.2514906180532355, "compression_ratio": 1.4885057471264367, "no_speech_prob": 0.00608485983684659}, {"id": 128, "seek": 85660, "start": 875.4, "end": 877.8000000000001, "text": " 10 minutes left. I've been hurrying too much.", "tokens": [51304, 1266, 2077, 1411, 13, 286, 600, 668, 11025, 278, 886, 709, 13, 51424], "temperature": 0.0, "avg_logprob": -0.2514906180532355, "compression_ratio": 1.4885057471264367, "no_speech_prob": 0.00608485983684659}, {"id": 129, "seek": 87780, "start": 877.88, "end": 890.8399999999999, "text": " So concluding, it is, like I said, it's a niche algorithm and it is good for cache optimizations,", "tokens": [50368, 407, 9312, 278, 11, 309, 307, 11, 411, 286, 848, 11, 309, 311, 257, 19956, 9284, 293, 309, 307, 665, 337, 19459, 5028, 14455, 11, 51016], "temperature": 0.0, "avg_logprob": -0.22934898170264992, "compression_ratio": 1.532258064516129, "no_speech_prob": 0.004058941267430782}, {"id": 130, "seek": 87780, "start": 890.8399999999999, "end": 896.4399999999999, "text": " but it is still, its primary concern is still load balancing. It's distributing load. The", "tokens": [51016, 457, 309, 307, 920, 11, 1080, 6194, 3136, 307, 920, 3677, 22495, 13, 467, 311, 41406, 3677, 13, 440, 51296], "temperature": 0.0, "avg_logprob": -0.22934898170264992, "compression_ratio": 1.532258064516129, "no_speech_prob": 0.004058941267430782}, {"id": 131, "seek": 87780, "start": 896.4399999999999, "end": 902.04, "text": " consistency is only secondary. And for caching, it makes sense because like with a cache, I mean,", "tokens": [51296, 14416, 307, 787, 11396, 13, 400, 337, 269, 2834, 11, 309, 1669, 2020, 570, 411, 365, 257, 19459, 11, 286, 914, 11, 51576], "temperature": 0.0, "avg_logprob": -0.22934898170264992, "compression_ratio": 1.532258064516129, "no_speech_prob": 0.004058941267430782}, {"id": 132, "seek": 90204, "start": 902.12, "end": 908.76, "text": " you lose some performance, but you don't lose data. So if you change it, you lose the consistency,", "tokens": [50368, 291, 3624, 512, 3389, 11, 457, 291, 500, 380, 3624, 1412, 13, 407, 498, 291, 1319, 309, 11, 291, 3624, 264, 14416, 11, 50700], "temperature": 0.0, "avg_logprob": -0.1563331430608576, "compression_ratio": 1.559670781893004, "no_speech_prob": 0.003591888817027211}, {"id": 133, "seek": 90204, "start": 908.76, "end": 914.1999999999999, "text": " it just rebuilds it and then you're good to go. Minimize the cache disruptions.", "tokens": [50700, 309, 445, 16877, 82, 309, 293, 550, 291, 434, 665, 281, 352, 13, 2829, 43890, 264, 19459, 14124, 626, 13, 50972], "temperature": 0.0, "avg_logprob": -0.1563331430608576, "compression_ratio": 1.559670781893004, "no_speech_prob": 0.003591888817027211}, {"id": 134, "seek": 90204, "start": 916.1999999999999, "end": 922.76, "text": " The trick is with, it does require some contacts as the hash input. On the TCP level, you could have", "tokens": [51072, 440, 4282, 307, 365, 11, 309, 775, 3651, 512, 15836, 382, 264, 22019, 4846, 13, 1282, 264, 48965, 1496, 11, 291, 727, 362, 51400], "temperature": 0.0, "avg_logprob": -0.1563331430608576, "compression_ratio": 1.559670781893004, "no_speech_prob": 0.003591888817027211}, {"id": 135, "seek": 90204, "start": 922.76, "end": 929.8, "text": " like an SNI name maybe or an IP. It's like really rough because it also needs the contacts that you", "tokens": [51400, 411, 364, 13955, 40, 1315, 1310, 420, 364, 8671, 13, 467, 311, 411, 534, 5903, 570, 309, 611, 2203, 264, 15836, 300, 291, 51752], "temperature": 0.0, "avg_logprob": -0.1563331430608576, "compression_ratio": 1.559670781893004, "no_speech_prob": 0.003591888817027211}, {"id": 136, "seek": 92980, "start": 930.68, "end": 936.28, "text": " need into the hash, needs to have enough cardinality to actually make sure that you're going to hit", "tokens": [50408, 643, 666, 264, 22019, 11, 2203, 281, 362, 1547, 2920, 259, 1860, 281, 767, 652, 988, 300, 291, 434, 516, 281, 2045, 50688], "temperature": 0.0, "avg_logprob": -0.1330150429529088, "compression_ratio": 1.861003861003861, "no_speech_prob": 0.00347878597676754}, {"id": 137, "seek": 92980, "start": 936.28, "end": 941.4, "text": " everything in your cluster. So if you have, I don't know, you say you do on a header,", "tokens": [50688, 1203, 294, 428, 13630, 13, 407, 498, 291, 362, 11, 286, 500, 380, 458, 11, 291, 584, 291, 360, 322, 257, 23117, 11, 50944], "temperature": 0.0, "avg_logprob": -0.1330150429529088, "compression_ratio": 1.861003861003861, "no_speech_prob": 0.00347878597676754}, {"id": 138, "seek": 92980, "start": 941.4, "end": 946.12, "text": " that either says Android or iOS. That means in your hashing algorithm, you're going to hit only", "tokens": [50944, 300, 2139, 1619, 8853, 420, 17430, 13, 663, 1355, 294, 428, 575, 571, 9284, 11, 291, 434, 516, 281, 2045, 787, 51180], "temperature": 0.0, "avg_logprob": -0.1330150429529088, "compression_ratio": 1.861003861003861, "no_speech_prob": 0.00347878597676754}, {"id": 139, "seek": 92980, "start": 946.12, "end": 950.76, "text": " two backhands ever. So if you scale and you have five backhands, you're still going to hit only two.", "tokens": [51180, 732, 646, 71, 2967, 1562, 13, 407, 498, 291, 4373, 293, 291, 362, 1732, 646, 71, 2967, 11, 291, 434, 920, 516, 281, 2045, 787, 732, 13, 51412], "temperature": 0.0, "avg_logprob": -0.1330150429529088, "compression_ratio": 1.861003861003861, "no_speech_prob": 0.00347878597676754}, {"id": 140, "seek": 92980, "start": 950.76, "end": 957.8, "text": " If you have to be aware of that, that there's enough cardinality. And as before, DNS is be careful.", "tokens": [51412, 759, 291, 362, 281, 312, 3650, 295, 300, 11, 300, 456, 311, 1547, 2920, 259, 1860, 13, 400, 382, 949, 11, 35153, 307, 312, 5026, 13, 51764], "temperature": 0.0, "avg_logprob": -0.1330150429529088, "compression_ratio": 1.861003861003861, "no_speech_prob": 0.00347878597676754}, {"id": 141, "seek": 95780, "start": 957.8, "end": 961.9599999999999, "text": " Make sure that people set it up correctly. If you have it all in one hand, if you control the whole", "tokens": [50364, 4387, 988, 300, 561, 992, 309, 493, 8944, 13, 759, 291, 362, 309, 439, 294, 472, 1011, 11, 498, 291, 1969, 264, 1379, 50572], "temperature": 0.0, "avg_logprob": -0.09271827546676786, "compression_ratio": 1.7918552036199096, "no_speech_prob": 0.0034808998461812735}, {"id": 142, "seek": 95780, "start": 961.9599999999999, "end": 967.3199999999999, "text": " lot of it, you can set whether the truncation flag is set or not, whether it results everything,", "tokens": [50572, 688, 295, 309, 11, 291, 393, 992, 1968, 264, 504, 409, 46252, 7166, 307, 992, 420, 406, 11, 1968, 309, 3542, 1203, 11, 50840], "temperature": 0.0, "avg_logprob": -0.09271827546676786, "compression_ratio": 1.7918552036199096, "no_speech_prob": 0.0034808998461812735}, {"id": 143, "seek": 95780, "start": 967.3199999999999, "end": 972.4399999999999, "text": " it gives you all the nodes, all the entries. That's good. If you're not, make sure you check with", "tokens": [50840, 309, 2709, 291, 439, 264, 13891, 11, 439, 264, 23041, 13, 663, 311, 665, 13, 759, 291, 434, 406, 11, 652, 988, 291, 1520, 365, 51096], "temperature": 0.0, "avg_logprob": -0.09271827546676786, "compression_ratio": 1.7918552036199096, "no_speech_prob": 0.0034808998461812735}, {"id": 144, "seek": 95780, "start": 972.4399999999999, "end": 978.04, "text": " your other teams that they actually make sure you get the data to make sure that they're not fighting", "tokens": [51096, 428, 661, 5491, 300, 436, 767, 652, 988, 291, 483, 264, 1412, 281, 652, 988, 300, 436, 434, 406, 5237, 51376], "temperature": 0.0, "avg_logprob": -0.09271827546676786, "compression_ratio": 1.7918552036199096, "no_speech_prob": 0.0034808998461812735}, {"id": 145, "seek": 97804, "start": 978.04, "end": 988.1999999999999, "text": " each other. Then there was the comparing algorithms. Like the first two are actually", "tokens": [50364, 1184, 661, 13, 1396, 456, 390, 264, 15763, 14642, 13, 1743, 264, 700, 732, 366, 767, 50872], "temperature": 0.0, "avg_logprob": -0.20955209846956185, "compression_ratio": 1.6376146788990826, "no_speech_prob": 0.047380924224853516}, {"id": 146, "seek": 97804, "start": 988.1999999999999, "end": 994.5999999999999, "text": " like the more generic ones. The way to round around like everybody knows. It's a good distribution.", "tokens": [50872, 411, 264, 544, 19577, 2306, 13, 440, 636, 281, 3098, 926, 411, 2201, 3255, 13, 467, 311, 257, 665, 7316, 13, 51192], "temperature": 0.0, "avg_logprob": -0.20955209846956185, "compression_ratio": 1.6376146788990826, "no_speech_prob": 0.047380924224853516}, {"id": 147, "seek": 97804, "start": 995.64, "end": 999.48, "text": " It doesn't care about caching. So you hit everything with everything you got.", "tokens": [51244, 467, 1177, 380, 1127, 466, 269, 2834, 13, 407, 291, 2045, 1203, 365, 1203, 291, 658, 13, 51436], "temperature": 0.0, "avg_logprob": -0.20955209846956185, "compression_ratio": 1.6376146788990826, "no_speech_prob": 0.047380924224853516}, {"id": 148, "seek": 97804, "start": 1000.5999999999999, "end": 1005.0799999999999, "text": " These connections are the same, but at least it takes into kind of like long lift connections,", "tokens": [51492, 1981, 9271, 366, 264, 912, 11, 457, 412, 1935, 309, 2516, 666, 733, 295, 411, 938, 5533, 9271, 11, 51716], "temperature": 0.0, "avg_logprob": -0.20955209846956185, "compression_ratio": 1.6376146788990826, "no_speech_prob": 0.047380924224853516}, {"id": 149, "seek": 100508, "start": 1005.8000000000001, "end": 1009.8000000000001, "text": " which not depending on what you're running or what service you're running might make a good", "tokens": [50400, 597, 406, 5413, 322, 437, 291, 434, 2614, 420, 437, 2643, 291, 434, 2614, 1062, 652, 257, 665, 50600], "temperature": 0.0, "avg_logprob": -0.19552867114543915, "compression_ratio": 1.491891891891892, "no_speech_prob": 0.0021814291831105947}, {"id": 150, "seek": 100508, "start": 1009.8000000000001, "end": 1019.4000000000001, "text": " distinction. Really different. Consistent hashing, cache optimization, and it works wonders under", "tokens": [50600, 16844, 13, 4083, 819, 13, 6923, 25367, 575, 571, 11, 19459, 19618, 11, 293, 309, 1985, 27348, 833, 51080], "temperature": 0.0, "avg_logprob": -0.19552867114543915, "compression_ratio": 1.491891891891892, "no_speech_prob": 0.0021814291831105947}, {"id": 151, "seek": 100508, "start": 1019.4000000000001, "end": 1028.28, "text": " the right circumstances. There's a catch to really catch. Least latency, we have that.", "tokens": [51080, 264, 558, 9121, 13, 821, 311, 257, 3745, 281, 534, 3745, 13, 1456, 525, 27043, 11, 321, 362, 300, 13, 51524], "temperature": 0.0, "avg_logprob": -0.19552867114543915, "compression_ratio": 1.491891891891892, "no_speech_prob": 0.0021814291831105947}, {"id": 152, "seek": 102828, "start": 1028.52, "end": 1038.52, "text": " It's also niche, I'd say. I even wrote it. If you have high variance CPU loads,", "tokens": [50376, 467, 311, 611, 19956, 11, 286, 1116, 584, 13, 286, 754, 4114, 309, 13, 759, 291, 362, 1090, 21977, 13199, 12668, 11, 50876], "temperature": 0.0, "avg_logprob": -0.19036657913871433, "compression_ratio": 1.579185520361991, "no_speech_prob": 0.003701998619362712}, {"id": 153, "seek": 102828, "start": 1039.16, "end": 1045.56, "text": " so take GraphQL, where you can have simple queries and very big queries, then this makes sense.", "tokens": [50908, 370, 747, 21884, 13695, 11, 689, 291, 393, 362, 2199, 24109, 293, 588, 955, 24109, 11, 550, 341, 1669, 2020, 13, 51228], "temperature": 0.0, "avg_logprob": -0.19036657913871433, "compression_ratio": 1.579185520361991, "no_speech_prob": 0.003701998619362712}, {"id": 154, "seek": 102828, "start": 1046.28, "end": 1050.28, "text": " But one thing to be careful of is that you need to have equal network latencies.", "tokens": [51264, 583, 472, 551, 281, 312, 5026, 295, 307, 300, 291, 643, 281, 362, 2681, 3209, 4465, 6464, 13, 51464], "temperature": 0.0, "avg_logprob": -0.19036657913871433, "compression_ratio": 1.579185520361991, "no_speech_prob": 0.003701998619362712}, {"id": 155, "seek": 102828, "start": 1050.92, "end": 1056.04, "text": " So if you have all your nodes in the same network, your back ends, you have the same network", "tokens": [51496, 407, 498, 291, 362, 439, 428, 13891, 294, 264, 912, 3209, 11, 428, 646, 5314, 11, 291, 362, 264, 912, 3209, 51752], "temperature": 0.0, "avg_logprob": -0.19036657913871433, "compression_ratio": 1.579185520361991, "no_speech_prob": 0.003701998619362712}, {"id": 156, "seek": 105604, "start": 1056.04, "end": 1061.1599999999999, "text": " latency, then it works. But if you have one close by and another one a couple of hops away", "tokens": [50364, 27043, 11, 550, 309, 1985, 13, 583, 498, 291, 362, 472, 1998, 538, 293, 1071, 472, 257, 1916, 295, 47579, 1314, 50620], "temperature": 0.0, "avg_logprob": -0.1285655072757176, "compression_ratio": 1.7878787878787878, "no_speech_prob": 0.001781882019713521}, {"id": 157, "seek": 105604, "start": 1061.1599999999999, "end": 1067.6399999999999, "text": " that has more latency, then the least latency one will actually push the close by ones into starvation.", "tokens": [50620, 300, 575, 544, 27043, 11, 550, 264, 1935, 27043, 472, 486, 767, 2944, 264, 1998, 538, 2306, 666, 3543, 11116, 13, 50944], "temperature": 0.0, "avg_logprob": -0.1285655072757176, "compression_ratio": 1.7878787878787878, "no_speech_prob": 0.001781882019713521}, {"id": 158, "seek": 105604, "start": 1068.84, "end": 1072.68, "text": " Because they have lower latency because of the network, so we're going to push more load,", "tokens": [51004, 1436, 436, 362, 3126, 27043, 570, 295, 264, 3209, 11, 370, 321, 434, 516, 281, 2944, 544, 3677, 11, 51196], "temperature": 0.0, "avg_logprob": -0.1285655072757176, "compression_ratio": 1.7878787878787878, "no_speech_prob": 0.001781882019713521}, {"id": 159, "seek": 105604, "start": 1072.68, "end": 1077.0, "text": " and by the time the latency of those systems goes up, you're basically pushing them into", "tokens": [51196, 293, 538, 264, 565, 264, 27043, 295, 729, 3652, 1709, 493, 11, 291, 434, 1936, 7380, 552, 666, 51412], "temperature": 0.0, "avg_logprob": -0.1285655072757176, "compression_ratio": 1.7878787878787878, "no_speech_prob": 0.001781882019713521}, {"id": 160, "seek": 105604, "start": 1077.0, "end": 1082.6, "text": " resource starvation, either CPU memory or whatever, and then they become slower. And that's not an", "tokens": [51412, 7684, 3543, 11116, 11, 2139, 13199, 4675, 420, 2035, 11, 293, 550, 436, 1813, 14009, 13, 400, 300, 311, 406, 364, 51692], "temperature": 0.0, "avg_logprob": -0.1285655072757176, "compression_ratio": 1.7878787878787878, "no_speech_prob": 0.001781882019713521}, {"id": 161, "seek": 108260, "start": 1082.6, "end": 1086.6799999999998, "text": " efficient way to run those servers, probably. So there's a catch to it.", "tokens": [50364, 7148, 636, 281, 1190, 729, 15909, 11, 1391, 13, 407, 456, 311, 257, 3745, 281, 309, 13, 50568], "temperature": 0.0, "avg_logprob": -0.3149418219541892, "compression_ratio": 1.1228070175438596, "no_speech_prob": 0.003919835202395916}, {"id": 162, "seek": 108260, "start": 1091.56, "end": 1098.28, "text": " And I got it really in time. Questions? Thank you, Dyer.", "tokens": [50812, 400, 286, 658, 309, 534, 294, 565, 13, 27738, 30, 1044, 291, 11, 413, 7224, 13, 51148], "temperature": 0.0, "avg_logprob": -0.3149418219541892, "compression_ratio": 1.1228070175438596, "no_speech_prob": 0.003919835202395916}, {"id": 163, "seek": 109828, "start": 1098.52, "end": 1103.96, "text": " Thank you.", "tokens": [50376, 1044, 291, 13, 50648], "temperature": 0.0, "avg_logprob": -0.33512301445007325, "compression_ratio": 1.4840425531914894, "no_speech_prob": 0.019711483269929886}, {"id": 164, "seek": 109828, "start": 1105.96, "end": 1113.48, "text": " Plenty of questions. You said that some DNS servers do not send and truncate bits.", "tokens": [50748, 2149, 4179, 295, 1651, 13, 509, 848, 300, 512, 35153, 15909, 360, 406, 2845, 293, 504, 409, 66, 473, 9239, 13, 51124], "temperature": 0.0, "avg_logprob": -0.33512301445007325, "compression_ratio": 1.4840425531914894, "no_speech_prob": 0.019711483269929886}, {"id": 165, "seek": 109828, "start": 1113.48, "end": 1121.32, "text": " Would it be possible to just do TCP? Always? To always do TCP? Yes, that's an option.", "tokens": [51124, 6068, 309, 312, 1944, 281, 445, 360, 48965, 30, 11270, 30, 1407, 1009, 360, 48965, 30, 1079, 11, 300, 311, 364, 3614, 13, 51516], "temperature": 0.0, "avg_logprob": -0.33512301445007325, "compression_ratio": 1.4840425531914894, "no_speech_prob": 0.019711483269929886}, {"id": 166, "seek": 109828, "start": 1121.8799999999999, "end": 1127.08, "text": " That's an option. If you can configure your client, not all clients can be configured. In our case,", "tokens": [51544, 663, 311, 364, 3614, 13, 759, 291, 393, 22162, 428, 6423, 11, 406, 439, 6982, 393, 312, 30538, 13, 682, 527, 1389, 11, 51804], "temperature": 0.0, "avg_logprob": -0.33512301445007325, "compression_ratio": 1.4840425531914894, "no_speech_prob": 0.019711483269929886}, {"id": 167, "seek": 112708, "start": 1127.08, "end": 1131.48, "text": " the client doesn't, we work with OpenResty. OpenResty underlying DNS client doesn't,", "tokens": [50364, 264, 6423, 1177, 380, 11, 321, 589, 365, 7238, 49, 7819, 13, 7238, 49, 7819, 14217, 35153, 6423, 1177, 380, 11, 50584], "temperature": 0.0, "avg_logprob": -0.17141597145482113, "compression_ratio": 1.6651162790697673, "no_speech_prob": 0.002469804137945175}, {"id": 168, "seek": 112708, "start": 1133.72, "end": 1139.32, "text": " it has a bug that prevents us from using it, actually. It doesn't do retries, which is,", "tokens": [50696, 309, 575, 257, 7426, 300, 22367, 505, 490, 1228, 309, 11, 767, 13, 467, 1177, 380, 360, 1533, 2244, 11, 597, 307, 11, 50976], "temperature": 0.0, "avg_logprob": -0.17141597145482113, "compression_ratio": 1.6651162790697673, "no_speech_prob": 0.002469804137945175}, {"id": 169, "seek": 112708, "start": 1139.32, "end": 1144.84, "text": " but that indeed is a good solution to making sure you get the entire, the entire record,", "tokens": [50976, 457, 300, 6451, 307, 257, 665, 3827, 281, 1455, 988, 291, 483, 264, 2302, 11, 264, 2302, 2136, 11, 51252], "temperature": 0.0, "avg_logprob": -0.17141597145482113, "compression_ratio": 1.6651162790697673, "no_speech_prob": 0.002469804137945175}, {"id": 170, "seek": 112708, "start": 1144.84, "end": 1152.04, "text": " all the entries. Yeah. I have a related question, which is, how often do you actually see enough", "tokens": [51252, 439, 264, 23041, 13, 865, 13, 286, 362, 257, 4077, 1168, 11, 597, 307, 11, 577, 2049, 360, 291, 767, 536, 1547, 51612], "temperature": 0.0, "avg_logprob": -0.17141597145482113, "compression_ratio": 1.6651162790697673, "no_speech_prob": 0.002469804137945175}, {"id": 171, "seek": 115204, "start": 1152.04, "end": 1157.56, "text": " data in a response to truncation of a content issue? It seems like you get hundreds of address", "tokens": [50364, 1412, 294, 257, 4134, 281, 504, 409, 46252, 295, 257, 2701, 2734, 30, 467, 2544, 411, 291, 483, 6779, 295, 2985, 50640], "temperature": 0.0, "avg_logprob": -0.26168163617451984, "compression_ratio": 1.617391304347826, "no_speech_prob": 0.00413231085985899}, {"id": 172, "seek": 115204, "start": 1157.56, "end": 1163.96, "text": " port pairs and transfer before you know it. Depends on, depends on DNS implementation and to use", "tokens": [50640, 2436, 15494, 293, 5003, 949, 291, 458, 309, 13, 4056, 2581, 322, 11, 5946, 322, 35153, 11420, 293, 281, 764, 50960], "temperature": 0.0, "avg_logprob": -0.26168163617451984, "compression_ratio": 1.617391304347826, "no_speech_prob": 0.00413231085985899}, {"id": 173, "seek": 115204, "start": 1163.96, "end": 1172.76, "text": " the eyes of, of, yeah. So how many, how many times do you actually see truncation happening", "tokens": [50960, 264, 2575, 295, 11, 295, 11, 1338, 13, 407, 577, 867, 11, 577, 867, 1413, 360, 291, 767, 536, 504, 409, 46252, 2737, 51400], "temperature": 0.0, "avg_logprob": -0.26168163617451984, "compression_ratio": 1.617391304347826, "no_speech_prob": 0.00413231085985899}, {"id": 174, "seek": 115204, "start": 1172.76, "end": 1178.92, "text": " in those records? I don't have data. I guess it must have happened or you wouldn't know.", "tokens": [51400, 294, 729, 7724, 30, 286, 500, 380, 362, 1412, 13, 286, 2041, 309, 1633, 362, 2011, 420, 291, 2759, 380, 458, 13, 51708], "temperature": 0.0, "avg_logprob": -0.26168163617451984, "compression_ratio": 1.617391304347826, "no_speech_prob": 0.00413231085985899}, {"id": 175, "seek": 117892, "start": 1178.92, "end": 1183.88, "text": " Yeah. I don't have the data. I know that console does it. Console by default will only report three", "tokens": [50364, 865, 13, 286, 500, 380, 362, 264, 1412, 13, 286, 458, 300, 11076, 775, 309, 13, 44152, 538, 7576, 486, 787, 2275, 1045, 50612], "temperature": 0.0, "avg_logprob": -0.19314738475915158, "compression_ratio": 1.6804123711340206, "no_speech_prob": 0.0016220173565670848}, {"id": 176, "seek": 117892, "start": 1185.0800000000002, "end": 1190.68, "text": " and it's UDP packet size. And I think it is UDP packet size. I don't know what it exactly is,", "tokens": [50672, 293, 309, 311, 624, 11373, 20300, 2744, 13, 400, 286, 519, 309, 307, 624, 11373, 20300, 2744, 13, 286, 500, 380, 458, 437, 309, 2293, 307, 11, 50952], "temperature": 0.0, "avg_logprob": -0.19314738475915158, "compression_ratio": 1.6804123711340206, "no_speech_prob": 0.0016220173565670848}, {"id": 177, "seek": 117892, "start": 1190.68, "end": 1195.96, "text": " but I would assume like four or five maybe and then truncation happens. Depends also depends on", "tokens": [50952, 457, 286, 576, 6552, 411, 1451, 420, 1732, 1310, 293, 550, 504, 409, 46252, 2314, 13, 4056, 2581, 611, 5946, 322, 51216], "temperature": 0.0, "avg_logprob": -0.19314738475915158, "compression_ratio": 1.6804123711340206, "no_speech_prob": 0.0016220173565670848}, {"id": 178, "seek": 117892, "start": 1195.96, "end": 1201.48, "text": " like name sizes and everything because it has to fit in a single packet. Oh, maybe console just", "tokens": [51216, 411, 1315, 11602, 293, 1203, 570, 309, 575, 281, 3318, 294, 257, 2167, 20300, 13, 876, 11, 1310, 11076, 445, 51492], "temperature": 0.0, "avg_logprob": -0.19314738475915158, "compression_ratio": 1.6804123711340206, "no_speech_prob": 0.0016220173565670848}, {"id": 179, "seek": 117892, "start": 1201.48, "end": 1206.3600000000001, "text": " arbitrarily truncates. Yes. Not to do with packet size. Yes. But that's, that is because it's a service", "tokens": [51492, 19071, 3289, 504, 409, 66, 1024, 13, 1079, 13, 1726, 281, 360, 365, 20300, 2744, 13, 1079, 13, 583, 300, 311, 11, 300, 307, 570, 309, 311, 257, 2643, 51736], "temperature": 0.0, "avg_logprob": -0.19314738475915158, "compression_ratio": 1.6804123711340206, "no_speech_prob": 0.0016220173565670848}, {"id": 180, "seek": 120636, "start": 1206.36, "end": 1212.28, "text": " discovery tool and it tries to pull the load balancer rule towards it and force you to only", "tokens": [50364, 12114, 2290, 293, 309, 9898, 281, 2235, 264, 3677, 3119, 28347, 4978, 3030, 309, 293, 3464, 291, 281, 787, 50660], "temperature": 0.0, "avg_logprob": -0.10233836703830296, "compression_ratio": 1.6425339366515836, "no_speech_prob": 0.010778228752315044}, {"id": 181, "seek": 120636, "start": 1213.0, "end": 1217.9599999999998, "text": " hit the nodes that it wants you to hit. Okay. So it has, I think it has for example things like", "tokens": [50696, 2045, 264, 13891, 300, 309, 2738, 291, 281, 2045, 13, 1033, 13, 407, 309, 575, 11, 286, 519, 309, 575, 337, 1365, 721, 411, 50944], "temperature": 0.0, "avg_logprob": -0.10233836703830296, "compression_ratio": 1.6425339366515836, "no_speech_prob": 0.010778228752315044}, {"id": 182, "seek": 120636, "start": 1218.6, "end": 1222.6799999999998, "text": " data center awareness. So depending on where the, where the request comes from,", "tokens": [50976, 1412, 3056, 8888, 13, 407, 5413, 322, 689, 264, 11, 689, 264, 5308, 1487, 490, 11, 51180], "temperature": 0.0, "avg_logprob": -0.10233836703830296, "compression_ratio": 1.6425339366515836, "no_speech_prob": 0.010778228752315044}, {"id": 183, "seek": 120636, "start": 1222.6799999999998, "end": 1226.36, "text": " it will give you a different set of answers than in another data center. So you're going to hit", "tokens": [51180, 309, 486, 976, 291, 257, 819, 992, 295, 6338, 813, 294, 1071, 1412, 3056, 13, 407, 291, 434, 516, 281, 2045, 51364], "temperature": 0.0, "avg_logprob": -0.10233836703830296, "compression_ratio": 1.6425339366515836, "no_speech_prob": 0.010778228752315044}, {"id": 184, "seek": 122636, "start": 1226.36, "end": 1239.8, "text": " different backends. Yeah. Sorry, can you repeat the question? For the log synchronization.", "tokens": [50364, 819, 646, 2581, 13, 865, 13, 4919, 11, 393, 291, 7149, 264, 1168, 30, 1171, 264, 3565, 19331, 2144, 13, 51036], "temperature": 0.0, "avg_logprob": -0.2581648932562934, "compression_ratio": 1.413533834586466, "no_speech_prob": 0.060842208564281464}, {"id": 185, "seek": 122636, "start": 1241.7199999999998, "end": 1246.28, "text": " What algorithm are we using for the log synchronization? Which one do you mean across the cluster", "tokens": [51132, 708, 9284, 366, 321, 1228, 337, 264, 3565, 19331, 2144, 30, 3013, 472, 360, 291, 914, 2108, 264, 13630, 51360], "temperature": 0.0, "avg_logprob": -0.2581648932562934, "compression_ratio": 1.413533834586466, "no_speech_prob": 0.060842208564281464}, {"id": 186, "seek": 124628, "start": 1247.24, "end": 1250.04, "text": " or inside a single balancer?", "tokens": [50412, 420, 1854, 257, 2167, 3119, 28347, 30, 50552], "temperature": 0.0, "avg_logprob": -0.1396388558780446, "compression_ratio": 1.5707070707070707, "no_speech_prob": 0.043332748115062714}, {"id": 187, "seek": 124628, "start": 1253.32, "end": 1259.24, "text": " Let's go with the balancer. I'll give you answer both. First one on the cluster, we don't have it", "tokens": [50716, 961, 311, 352, 365, 264, 3119, 28347, 13, 286, 603, 976, 291, 1867, 1293, 13, 2386, 472, 322, 264, 13630, 11, 321, 500, 380, 362, 309, 51012], "temperature": 0.0, "avg_logprob": -0.1396388558780446, "compression_ratio": 1.5707070707070707, "no_speech_prob": 0.043332748115062714}, {"id": 188, "seek": 124628, "start": 1259.24, "end": 1265.96, "text": " because we, in the end, we have no synchronization over this shared state of this entire balancer.", "tokens": [51012, 570, 321, 11, 294, 264, 917, 11, 321, 362, 572, 19331, 2144, 670, 341, 5507, 1785, 295, 341, 2302, 3119, 28347, 13, 51348], "temperature": 0.0, "avg_logprob": -0.1396388558780446, "compression_ratio": 1.5707070707070707, "no_speech_prob": 0.043332748115062714}, {"id": 189, "seek": 124628, "start": 1265.96, "end": 1270.28, "text": " We don't share it. The only thing we have is the order in which nodes have been added", "tokens": [51348, 492, 500, 380, 2073, 309, 13, 440, 787, 551, 321, 362, 307, 264, 1668, 294, 597, 13891, 362, 668, 3869, 51564], "temperature": 0.0, "avg_logprob": -0.1396388558780446, "compression_ratio": 1.5707070707070707, "no_speech_prob": 0.043332748115062714}, {"id": 190, "seek": 127028, "start": 1271.24, "end": 1277.32, "text": " and that's synchronized through a database basically, a control plane. Then inside the", "tokens": [50412, 293, 300, 311, 19331, 1602, 807, 257, 8149, 1936, 11, 257, 1969, 5720, 13, 1396, 1854, 264, 50716], "temperature": 0.0, "avg_logprob": -0.12454545220663381, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.004960914608091116}, {"id": 191, "seek": 127028, "start": 1277.32, "end": 1284.68, "text": " balancer algorithm itself due to the way the open rescue works, you basically don't need a log on", "tokens": [50716, 3119, 28347, 9284, 2564, 3462, 281, 264, 636, 264, 1269, 13283, 1985, 11, 291, 1936, 500, 380, 643, 257, 3565, 322, 51084], "temperature": 0.0, "avg_logprob": -0.12454545220663381, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.004960914608091116}, {"id": 192, "seek": 127028, "start": 1284.68, "end": 1292.68, "text": " this. The one thing is you need to be careful that you do not yield in between operations that", "tokens": [51084, 341, 13, 440, 472, 551, 307, 291, 643, 281, 312, 5026, 300, 291, 360, 406, 11257, 294, 1296, 7705, 300, 51484], "temperature": 0.0, "avg_logprob": -0.12454545220663381, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.004960914608091116}, {"id": 193, "seek": 127028, "start": 1292.68, "end": 1297.6399999999999, "text": " actually are modifying the data structures. As long as you do that in an atomic operation,", "tokens": [51484, 767, 366, 42626, 264, 1412, 9227, 13, 1018, 938, 382, 291, 360, 300, 294, 364, 22275, 6916, 11, 51732], "temperature": 0.0, "avg_logprob": -0.12454545220663381, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.004960914608091116}, {"id": 194, "seek": 129764, "start": 1297.72, "end": 1300.8400000000001, "text": " you're good and you don't need a log. So I answer the question.", "tokens": [50368, 291, 434, 665, 293, 291, 500, 380, 643, 257, 3565, 13, 407, 286, 1867, 264, 1168, 13, 50524], "temperature": 0.0, "avg_logprob": -0.23186187420861196, "compression_ratio": 1.5096774193548388, "no_speech_prob": 0.008516957052052021}, {"id": 195, "seek": 129764, "start": 1304.3600000000001, "end": 1311.72, "text": " Maybe this, you could share the state of the various nodes in the cluster by just", "tokens": [50700, 2704, 341, 11, 291, 727, 2073, 264, 1785, 295, 264, 3683, 13891, 294, 264, 13630, 538, 445, 51068], "temperature": 0.0, "avg_logprob": -0.23186187420861196, "compression_ratio": 1.5096774193548388, "no_speech_prob": 0.008516957052052021}, {"id": 196, "seek": 129764, "start": 1312.2800000000002, "end": 1318.2, "text": " sharing the state instead of assuming you get the same input data and computing a state.", "tokens": [51096, 5414, 264, 1785, 2602, 295, 11926, 291, 483, 264, 912, 4846, 1412, 293, 15866, 257, 1785, 13, 51392], "temperature": 0.0, "avg_logprob": -0.23186187420861196, "compression_ratio": 1.5096774193548388, "no_speech_prob": 0.008516957052052021}, {"id": 197, "seek": 131820, "start": 1319.16, "end": 1327.88, "text": " So then you would of course introduce interdependencies because it would guarantee that all nodes", "tokens": [50412, 407, 550, 291, 576, 295, 1164, 5366, 728, 36763, 6464, 570, 309, 576, 10815, 300, 439, 13891, 50848], "temperature": 0.0, "avg_logprob": -0.3109320301120564, "compression_ratio": 1.5, "no_speech_prob": 0.007842903956770897}, {"id": 198, "seek": 131820, "start": 1330.92, "end": 1336.6000000000001, "text": " at least use the same tables. So the question is can you use shared state", "tokens": [51000, 412, 1935, 764, 264, 912, 8020, 13, 407, 264, 1168, 307, 393, 291, 764, 5507, 1785, 51284], "temperature": 0.0, "avg_logprob": -0.3109320301120564, "compression_ratio": 1.5, "no_speech_prob": 0.007842903956770897}, {"id": 199, "seek": 131820, "start": 1337.64, "end": 1345.4, "text": " instead of rebuilding it in every cluster separately? Yes, you can. The conflusters", "tokens": [51336, 2602, 295, 36717, 309, 294, 633, 13630, 14759, 30, 1079, 11, 291, 393, 13, 440, 1497, 75, 17181, 51724], "temperature": 0.0, "avg_logprob": -0.3109320301120564, "compression_ratio": 1.5, "no_speech_prob": 0.007842903956770897}, {"id": 200, "seek": 134540, "start": 1345.4, "end": 1349.64, "text": " are basically independent. The data planes are on their own and they do not share state.", "tokens": [50364, 366, 1936, 6695, 13, 440, 1412, 14952, 366, 322, 641, 1065, 293, 436, 360, 406, 2073, 1785, 13, 50576], "temperature": 0.0, "avg_logprob": -0.10955417156219482, "compression_ratio": 1.6605839416058394, "no_speech_prob": 0.016375256702303886}, {"id": 201, "seek": 134540, "start": 1349.64, "end": 1355.8000000000002, "text": " They get their instructions from a control plane. That's it. Yes, there is one, there is the", "tokens": [50576, 814, 483, 641, 9415, 490, 257, 1969, 5720, 13, 663, 311, 309, 13, 1079, 11, 456, 307, 472, 11, 456, 307, 264, 50884], "temperature": 0.0, "avg_logprob": -0.10955417156219482, "compression_ratio": 1.6605839416058394, "no_speech_prob": 0.016375256702303886}, {"id": 202, "seek": 134540, "start": 1355.8000000000002, "end": 1360.8400000000001, "text": " alternative option. We haven't implemented it yet. I don't think we will implement this.", "tokens": [50884, 8535, 3614, 13, 492, 2378, 380, 12270, 309, 1939, 13, 286, 500, 380, 519, 321, 486, 4445, 341, 13, 51136], "temperature": 0.0, "avg_logprob": -0.10955417156219482, "compression_ratio": 1.6605839416058394, "no_speech_prob": 0.016375256702303886}, {"id": 203, "seek": 134540, "start": 1361.4, "end": 1367.16, "text": " In reality, we see too little cases where we actually see the things go out of sync and cause", "tokens": [51164, 682, 4103, 11, 321, 536, 886, 707, 3331, 689, 321, 767, 536, 264, 721, 352, 484, 295, 20271, 293, 3082, 51452], "temperature": 0.0, "avg_logprob": -0.10955417156219482, "compression_ratio": 1.6605839416058394, "no_speech_prob": 0.016375256702303886}, {"id": 204, "seek": 134540, "start": 1367.16, "end": 1374.3600000000001, "text": " issues. Usually you can tweak it by using a longer TTL so there's going to be less updates", "tokens": [51452, 2663, 13, 11419, 291, 393, 29879, 309, 538, 1228, 257, 2854, 32576, 43, 370, 456, 311, 516, 281, 312, 1570, 9205, 51812], "temperature": 0.0, "avg_logprob": -0.10955417156219482, "compression_ratio": 1.6605839416058394, "no_speech_prob": 0.016375256702303886}, {"id": 205, "seek": 137436, "start": 1374.4399999999998, "end": 1377.8, "text": " and you don't need it. So I don't think we will be implementing it in the end.", "tokens": [50368, 293, 291, 500, 380, 643, 309, 13, 407, 286, 500, 380, 519, 321, 486, 312, 18114, 309, 294, 264, 917, 13, 50536], "temperature": 0.0, "avg_logprob": -0.1359637975692749, "compression_ratio": 1.7443181818181819, "no_speech_prob": 0.0025878543965518475}, {"id": 206, "seek": 137436, "start": 1382.12, "end": 1386.84, "text": " Have you considered using rendezvous hashing instead of consistent hashing?", "tokens": [50752, 3560, 291, 4888, 1228, 40026, 16514, 575, 571, 2602, 295, 8398, 575, 571, 30, 50988], "temperature": 0.0, "avg_logprob": -0.1359637975692749, "compression_ratio": 1.7443181818181819, "no_speech_prob": 0.0025878543965518475}, {"id": 207, "seek": 137436, "start": 1387.9599999999998, "end": 1392.04, "text": " Have we considered rendezvous hashing instead of consistent hashing? No.", "tokens": [51044, 3560, 321, 4888, 40026, 16514, 575, 571, 2602, 295, 8398, 575, 571, 30, 883, 13, 51248], "temperature": 0.0, "avg_logprob": -0.1359637975692749, "compression_ratio": 1.7443181818181819, "no_speech_prob": 0.0025878543965518475}, {"id": 208, "seek": 137436, "start": 1395.6399999999999, "end": 1401.4799999999998, "text": " No. Frankly, I don't know it. I wrote this stuff actually quite some years ago.", "tokens": [51428, 883, 13, 41344, 11, 286, 500, 380, 458, 309, 13, 286, 4114, 341, 1507, 767, 1596, 512, 924, 2057, 13, 51720], "temperature": 0.0, "avg_logprob": -0.1359637975692749, "compression_ratio": 1.7443181818181819, "no_speech_prob": 0.0025878543965518475}, {"id": 209, "seek": 140148, "start": 1402.2, "end": 1408.68, "text": " It was updated by a colleague later on. But I will be looking into rendezvous hashing. Thank you.", "tokens": [50400, 467, 390, 10588, 538, 257, 13532, 1780, 322, 13, 583, 286, 486, 312, 1237, 666, 40026, 16514, 575, 571, 13, 1044, 291, 13, 50724], "temperature": 0.0, "avg_logprob": -0.24001539670504057, "compression_ratio": 1.3142857142857143, "no_speech_prob": 0.009451371617615223}, {"id": 210, "seek": 140148, "start": 1411.72, "end": 1412.52, "text": " Any more questions?", "tokens": [50876, 2639, 544, 1651, 30, 50916], "temperature": 0.0, "avg_logprob": -0.24001539670504057, "compression_ratio": 1.3142857142857143, "no_speech_prob": 0.009451371617615223}, {"id": 211, "seek": 140148, "start": 1416.3600000000001, "end": 1419.0, "text": " Check. Matrix. No questions.", "tokens": [51108, 6881, 13, 36274, 13, 883, 1651, 13, 51240], "temperature": 0.0, "avg_logprob": -0.24001539670504057, "compression_ratio": 1.3142857142857143, "no_speech_prob": 0.009451371617615223}, {"id": 212, "seek": 140148, "start": 1424.52, "end": 1427.32, "text": " Almost, almost, almost on the minute.", "tokens": [51516, 12627, 11, 1920, 11, 1920, 322, 264, 3456, 13, 51656], "temperature": 0.0, "avg_logprob": -0.24001539670504057, "compression_ratio": 1.3142857142857143, "no_speech_prob": 0.009451371617615223}, {"id": 213, "seek": 143148, "start": 1431.48, "end": 1432.94, "text": " You", "tokens": [50412, 509, 50437], "temperature": 0.0, "avg_logprob": -0.9891819953918457, "compression_ratio": 0.2727272727272727, "no_speech_prob": 0.8374747633934021}], "language": "en"}