{"text": " We have now up next Alexi talking about NICS for bioinformatics pipelines. So thank you everyone for coming. For five minutes I will try to make a kind of different presentation and try to say how NICS can help safe patients. It's not a clickbait title I promise. So I have a doctor in training but I also have a background in computer science so it's a kind of a mixed presentation and I'm working in France in Besanson Hospital. So when we are dealing with patients we want basically three things. First we want to give accurate results because for these patients diagnosis can be life changing. Second we need to be reproducible because all the doctors trust us with giving accurate results every time. Finally we want to be as fast as possible because there is a high demand for results. I'm working in a rare disease setup where obviously things are rare so it's hard to find and how do we do it? Well it's a mix of computer science. And expertise and state of the art technology. So here is a very worth scheme of how everything works. We start from a blood sample of a patient and we try to extract the DNA and sequence it on this machine thing. Unfortunately the machine doesn't do everything and we need some bioinformatics in there. And also the bioinformatics doesn't do everything either. We need a human at the end of a pipeline which is why there is a CSV file that a human has to read. And basically what the bioinformatics setup does is that it figures out a list of candidates for diagnosis and try to filter down the results. For example it can go from one million candidates to a thousand. If it filters too much we can miss the diagnosis. If it doesn't filter enough, well the human will have a really hard time trying to pass the CSV. When you say pipeline it's a really fancy word for just a set of common line utility tools but we also have databases in there that are in our setup just text files compressed. And when I say pipeline we just feed data from one CLE tool to another. And now how does Nix can help it with this? Well as a medical lab we have to be reproducible. It's like in the law. So Nix is a perfect fit because we can fix the software dependency and the dependency either like byte by byte dependency. So that's done. So it would be great if you could run on the high performance computing cluster. And in our region the folks in our cluster agreed to install Nix. And now we can run our current production with Nix there. Two things we didn't do with Nix was to manage the whole workflow. There is actually a tool for that Nix but it's more like a niche thing so we prefer to use a more common tool. And the final things what we could do in Nix but we didn't is to manage this large database because in our setup it's a different folder for Nix so we cannot install it. But it's there in Nix. Last last thing. I really enjoyed the community. It was a really nice interaction. I'm sure everyone knows. But it's also kind of a slow process because I tried to package something myself which is not easy at the beginning. And as you know there is like 5,000 pull requests on GitHub so feedback can be sometimes a bit slow and also I'm working on my spate arm either so it can also take some time sometimes. But for example the support for large databases has been added after a few conversations on Matrix. It was really fast. I hope you take some key points there but if you want to know more you can send me an email and I'll be glad to answer. Thank you. Thank you. Thank you. Thank you. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 14.96, "text": " We have now up next Alexi talking about NICS for bioinformatics pipelines.", "tokens": [50364, 492, 362, 586, 493, 958, 5202, 72, 1417, 466, 426, 2532, 50, 337, 12198, 37811, 30292, 40168, 13, 51112], "temperature": 0.0, "avg_logprob": -0.2751711753949727, "compression_ratio": 1.4216216216216215, "no_speech_prob": 0.05554299056529999}, {"id": 1, "seek": 0, "start": 14.96, "end": 17.48, "text": " So thank you everyone for coming.", "tokens": [51112, 407, 1309, 291, 1518, 337, 1348, 13, 51238], "temperature": 0.0, "avg_logprob": -0.2751711753949727, "compression_ratio": 1.4216216216216215, "no_speech_prob": 0.05554299056529999}, {"id": 2, "seek": 0, "start": 17.48, "end": 24.0, "text": " For five minutes I will try to make a kind of different presentation and try to say how", "tokens": [51238, 1171, 1732, 2077, 286, 486, 853, 281, 652, 257, 733, 295, 819, 5860, 293, 853, 281, 584, 577, 51564], "temperature": 0.0, "avg_logprob": -0.2751711753949727, "compression_ratio": 1.4216216216216215, "no_speech_prob": 0.05554299056529999}, {"id": 3, "seek": 0, "start": 24.0, "end": 26.52, "text": " NICS can help safe patients.", "tokens": [51564, 426, 2532, 50, 393, 854, 3273, 4209, 13, 51690], "temperature": 0.0, "avg_logprob": -0.2751711753949727, "compression_ratio": 1.4216216216216215, "no_speech_prob": 0.05554299056529999}, {"id": 4, "seek": 0, "start": 26.52, "end": 28.8, "text": " It's not a clickbait title I promise.", "tokens": [51690, 467, 311, 406, 257, 2052, 41274, 4876, 286, 6228, 13, 51804], "temperature": 0.0, "avg_logprob": -0.2751711753949727, "compression_ratio": 1.4216216216216215, "no_speech_prob": 0.05554299056529999}, {"id": 5, "seek": 2880, "start": 28.8, "end": 35.8, "text": " So I have a doctor in training but I also have a background in computer science so it's", "tokens": [50364, 407, 286, 362, 257, 4631, 294, 3097, 457, 286, 611, 362, 257, 3678, 294, 3820, 3497, 370, 309, 311, 50714], "temperature": 0.0, "avg_logprob": -0.26698069823415654, "compression_ratio": 1.5275229357798166, "no_speech_prob": 0.006211448926478624}, {"id": 6, "seek": 2880, "start": 35.8, "end": 42.6, "text": " a kind of a mixed presentation and I'm working in France in Besanson Hospital.", "tokens": [50714, 257, 733, 295, 257, 7467, 5860, 293, 286, 478, 1364, 294, 6190, 294, 8190, 34195, 15645, 13, 51054], "temperature": 0.0, "avg_logprob": -0.26698069823415654, "compression_ratio": 1.5275229357798166, "no_speech_prob": 0.006211448926478624}, {"id": 7, "seek": 2880, "start": 42.6, "end": 47.08, "text": " So when we are dealing with patients we want basically three things.", "tokens": [51054, 407, 562, 321, 366, 6260, 365, 4209, 321, 528, 1936, 1045, 721, 13, 51278], "temperature": 0.0, "avg_logprob": -0.26698069823415654, "compression_ratio": 1.5275229357798166, "no_speech_prob": 0.006211448926478624}, {"id": 8, "seek": 2880, "start": 47.08, "end": 55.400000000000006, "text": " First we want to give accurate results because for these patients diagnosis can be life changing.", "tokens": [51278, 2386, 321, 528, 281, 976, 8559, 3542, 570, 337, 613, 4209, 15217, 393, 312, 993, 4473, 13, 51694], "temperature": 0.0, "avg_logprob": -0.26698069823415654, "compression_ratio": 1.5275229357798166, "no_speech_prob": 0.006211448926478624}, {"id": 9, "seek": 5540, "start": 55.4, "end": 62.16, "text": " Second we need to be reproducible because all the doctors trust us with giving accurate", "tokens": [50364, 5736, 321, 643, 281, 312, 11408, 32128, 570, 439, 264, 8778, 3361, 505, 365, 2902, 8559, 50702], "temperature": 0.0, "avg_logprob": -0.2936468672478336, "compression_ratio": 1.552511415525114, "no_speech_prob": 0.019144712015986443}, {"id": 10, "seek": 5540, "start": 62.16, "end": 64.4, "text": " results every time.", "tokens": [50702, 3542, 633, 565, 13, 50814], "temperature": 0.0, "avg_logprob": -0.2936468672478336, "compression_ratio": 1.552511415525114, "no_speech_prob": 0.019144712015986443}, {"id": 11, "seek": 5540, "start": 64.4, "end": 72.32, "text": " Finally we want to be as fast as possible because there is a high demand for results.", "tokens": [50814, 6288, 321, 528, 281, 312, 382, 2370, 382, 1944, 570, 456, 307, 257, 1090, 4733, 337, 3542, 13, 51210], "temperature": 0.0, "avg_logprob": -0.2936468672478336, "compression_ratio": 1.552511415525114, "no_speech_prob": 0.019144712015986443}, {"id": 12, "seek": 5540, "start": 72.32, "end": 78.56, "text": " I'm working in a rare disease setup where obviously things are rare so it's hard to find", "tokens": [51210, 286, 478, 1364, 294, 257, 5892, 4752, 8657, 689, 2745, 721, 366, 5892, 370, 309, 311, 1152, 281, 915, 51522], "temperature": 0.0, "avg_logprob": -0.2936468672478336, "compression_ratio": 1.552511415525114, "no_speech_prob": 0.019144712015986443}, {"id": 13, "seek": 5540, "start": 78.56, "end": 80.8, "text": " and how do we do it?", "tokens": [51522, 293, 577, 360, 321, 360, 309, 30, 51634], "temperature": 0.0, "avg_logprob": -0.2936468672478336, "compression_ratio": 1.552511415525114, "no_speech_prob": 0.019144712015986443}, {"id": 14, "seek": 5540, "start": 80.8, "end": 85.32, "text": " Well it's a mix of computer science.", "tokens": [51634, 1042, 309, 311, 257, 2890, 295, 3820, 3497, 13, 51860], "temperature": 0.0, "avg_logprob": -0.2936468672478336, "compression_ratio": 1.552511415525114, "no_speech_prob": 0.019144712015986443}, {"id": 15, "seek": 8532, "start": 85.32, "end": 89.08, "text": " And expertise and state of the art technology.", "tokens": [50364, 400, 11769, 293, 1785, 295, 264, 1523, 2899, 13, 50552], "temperature": 0.0, "avg_logprob": -0.2187293800147804, "compression_ratio": 1.5459183673469388, "no_speech_prob": 0.011328933760523796}, {"id": 16, "seek": 8532, "start": 89.08, "end": 94.44, "text": " So here is a very worth scheme of how everything works.", "tokens": [50552, 407, 510, 307, 257, 588, 3163, 12232, 295, 577, 1203, 1985, 13, 50820], "temperature": 0.0, "avg_logprob": -0.2187293800147804, "compression_ratio": 1.5459183673469388, "no_speech_prob": 0.011328933760523796}, {"id": 17, "seek": 8532, "start": 94.44, "end": 101.0, "text": " We start from a blood sample of a patient and we try to extract the DNA and sequence", "tokens": [50820, 492, 722, 490, 257, 3390, 6889, 295, 257, 4537, 293, 321, 853, 281, 8947, 264, 8272, 293, 8310, 51148], "temperature": 0.0, "avg_logprob": -0.2187293800147804, "compression_ratio": 1.5459183673469388, "no_speech_prob": 0.011328933760523796}, {"id": 18, "seek": 8532, "start": 101.0, "end": 104.67999999999999, "text": " it on this machine thing.", "tokens": [51148, 309, 322, 341, 3479, 551, 13, 51332], "temperature": 0.0, "avg_logprob": -0.2187293800147804, "compression_ratio": 1.5459183673469388, "no_speech_prob": 0.011328933760523796}, {"id": 19, "seek": 8532, "start": 104.67999999999999, "end": 112.75999999999999, "text": " Unfortunately the machine doesn't do everything and we need some bioinformatics in there.", "tokens": [51332, 8590, 264, 3479, 1177, 380, 360, 1203, 293, 321, 643, 512, 12198, 37811, 30292, 294, 456, 13, 51736], "temperature": 0.0, "avg_logprob": -0.2187293800147804, "compression_ratio": 1.5459183673469388, "no_speech_prob": 0.011328933760523796}, {"id": 20, "seek": 11276, "start": 112.76, "end": 116.48, "text": " And also the bioinformatics doesn't do everything either.", "tokens": [50364, 400, 611, 264, 12198, 37811, 30292, 1177, 380, 360, 1203, 2139, 13, 50550], "temperature": 0.0, "avg_logprob": -0.17224497380463974, "compression_ratio": 1.6294642857142858, "no_speech_prob": 0.005129423923790455}, {"id": 21, "seek": 11276, "start": 116.48, "end": 122.84, "text": " We need a human at the end of a pipeline which is why there is a CSV file that a human has", "tokens": [50550, 492, 643, 257, 1952, 412, 264, 917, 295, 257, 15517, 597, 307, 983, 456, 307, 257, 48814, 3991, 300, 257, 1952, 575, 50868], "temperature": 0.0, "avg_logprob": -0.17224497380463974, "compression_ratio": 1.6294642857142858, "no_speech_prob": 0.005129423923790455}, {"id": 22, "seek": 11276, "start": 122.84, "end": 124.72, "text": " to read.", "tokens": [50868, 281, 1401, 13, 50962], "temperature": 0.0, "avg_logprob": -0.17224497380463974, "compression_ratio": 1.6294642857142858, "no_speech_prob": 0.005129423923790455}, {"id": 23, "seek": 11276, "start": 124.72, "end": 132.36, "text": " And basically what the bioinformatics setup does is that it figures out a list of candidates", "tokens": [50962, 400, 1936, 437, 264, 12198, 37811, 30292, 8657, 775, 307, 300, 309, 9624, 484, 257, 1329, 295, 11255, 51344], "temperature": 0.0, "avg_logprob": -0.17224497380463974, "compression_ratio": 1.6294642857142858, "no_speech_prob": 0.005129423923790455}, {"id": 24, "seek": 11276, "start": 132.36, "end": 137.12, "text": " for diagnosis and try to filter down the results.", "tokens": [51344, 337, 15217, 293, 853, 281, 6608, 760, 264, 3542, 13, 51582], "temperature": 0.0, "avg_logprob": -0.17224497380463974, "compression_ratio": 1.6294642857142858, "no_speech_prob": 0.005129423923790455}, {"id": 25, "seek": 11276, "start": 137.12, "end": 142.44, "text": " For example it can go from one million candidates to a thousand.", "tokens": [51582, 1171, 1365, 309, 393, 352, 490, 472, 2459, 11255, 281, 257, 4714, 13, 51848], "temperature": 0.0, "avg_logprob": -0.17224497380463974, "compression_ratio": 1.6294642857142858, "no_speech_prob": 0.005129423923790455}, {"id": 26, "seek": 14244, "start": 142.44, "end": 146.12, "text": " If it filters too much we can miss the diagnosis.", "tokens": [50364, 759, 309, 15995, 886, 709, 321, 393, 1713, 264, 15217, 13, 50548], "temperature": 0.0, "avg_logprob": -0.2017765987066575, "compression_ratio": 1.5380952380952382, "no_speech_prob": 0.010250871069729328}, {"id": 27, "seek": 14244, "start": 146.12, "end": 152.52, "text": " If it doesn't filter enough, well the human will have a really hard time trying to pass", "tokens": [50548, 759, 309, 1177, 380, 6608, 1547, 11, 731, 264, 1952, 486, 362, 257, 534, 1152, 565, 1382, 281, 1320, 50868], "temperature": 0.0, "avg_logprob": -0.2017765987066575, "compression_ratio": 1.5380952380952382, "no_speech_prob": 0.010250871069729328}, {"id": 28, "seek": 14244, "start": 152.52, "end": 155.32, "text": " the CSV.", "tokens": [50868, 264, 48814, 13, 51008], "temperature": 0.0, "avg_logprob": -0.2017765987066575, "compression_ratio": 1.5380952380952382, "no_speech_prob": 0.010250871069729328}, {"id": 29, "seek": 14244, "start": 155.32, "end": 159.52, "text": " When you say pipeline it's a really fancy word for just a set of common line utility", "tokens": [51008, 1133, 291, 584, 15517, 309, 311, 257, 534, 10247, 1349, 337, 445, 257, 992, 295, 2689, 1622, 14877, 51218], "temperature": 0.0, "avg_logprob": -0.2017765987066575, "compression_ratio": 1.5380952380952382, "no_speech_prob": 0.010250871069729328}, {"id": 30, "seek": 14244, "start": 159.52, "end": 168.56, "text": " tools but we also have databases in there that are in our setup just text files compressed.", "tokens": [51218, 3873, 457, 321, 611, 362, 22380, 294, 456, 300, 366, 294, 527, 8657, 445, 2487, 7098, 30353, 13, 51670], "temperature": 0.0, "avg_logprob": -0.2017765987066575, "compression_ratio": 1.5380952380952382, "no_speech_prob": 0.010250871069729328}, {"id": 31, "seek": 16856, "start": 168.56, "end": 174.12, "text": " And when I say pipeline we just feed data from one CLE tool to another.", "tokens": [50364, 400, 562, 286, 584, 15517, 321, 445, 3154, 1412, 490, 472, 383, 2634, 2290, 281, 1071, 13, 50642], "temperature": 0.0, "avg_logprob": -0.20334639600528184, "compression_ratio": 1.5162790697674418, "no_speech_prob": 0.35780397057533264}, {"id": 32, "seek": 16856, "start": 174.12, "end": 178.6, "text": " And now how does Nix can help it with this?", "tokens": [50642, 400, 586, 577, 775, 426, 970, 393, 854, 309, 365, 341, 30, 50866], "temperature": 0.0, "avg_logprob": -0.20334639600528184, "compression_ratio": 1.5162790697674418, "no_speech_prob": 0.35780397057533264}, {"id": 33, "seek": 16856, "start": 178.6, "end": 182.68, "text": " Well as a medical lab we have to be reproducible.", "tokens": [50866, 1042, 382, 257, 4625, 2715, 321, 362, 281, 312, 11408, 32128, 13, 51070], "temperature": 0.0, "avg_logprob": -0.20334639600528184, "compression_ratio": 1.5162790697674418, "no_speech_prob": 0.35780397057533264}, {"id": 34, "seek": 16856, "start": 182.68, "end": 184.28, "text": " It's like in the law.", "tokens": [51070, 467, 311, 411, 294, 264, 2101, 13, 51150], "temperature": 0.0, "avg_logprob": -0.20334639600528184, "compression_ratio": 1.5162790697674418, "no_speech_prob": 0.35780397057533264}, {"id": 35, "seek": 16856, "start": 184.28, "end": 189.36, "text": " So Nix is a perfect fit because we can fix the software dependency and the dependency", "tokens": [51150, 407, 426, 970, 307, 257, 2176, 3318, 570, 321, 393, 3191, 264, 4722, 33621, 293, 264, 33621, 51404], "temperature": 0.0, "avg_logprob": -0.20334639600528184, "compression_ratio": 1.5162790697674418, "no_speech_prob": 0.35780397057533264}, {"id": 36, "seek": 16856, "start": 189.36, "end": 194.72, "text": " either like byte by byte dependency.", "tokens": [51404, 2139, 411, 40846, 538, 40846, 33621, 13, 51672], "temperature": 0.0, "avg_logprob": -0.20334639600528184, "compression_ratio": 1.5162790697674418, "no_speech_prob": 0.35780397057533264}, {"id": 37, "seek": 16856, "start": 194.72, "end": 197.12, "text": " So that's done.", "tokens": [51672, 407, 300, 311, 1096, 13, 51792], "temperature": 0.0, "avg_logprob": -0.20334639600528184, "compression_ratio": 1.5162790697674418, "no_speech_prob": 0.35780397057533264}, {"id": 38, "seek": 19712, "start": 197.12, "end": 201.96, "text": " So it would be great if you could run on the high performance computing cluster.", "tokens": [50364, 407, 309, 576, 312, 869, 498, 291, 727, 1190, 322, 264, 1090, 3389, 15866, 13630, 13, 50606], "temperature": 0.0, "avg_logprob": -0.18659669101828397, "compression_ratio": 1.61864406779661, "no_speech_prob": 0.00645080953836441}, {"id": 39, "seek": 19712, "start": 201.96, "end": 208.20000000000002, "text": " And in our region the folks in our cluster agreed to install Nix.", "tokens": [50606, 400, 294, 527, 4458, 264, 4024, 294, 527, 13630, 9166, 281, 3625, 426, 970, 13, 50918], "temperature": 0.0, "avg_logprob": -0.18659669101828397, "compression_ratio": 1.61864406779661, "no_speech_prob": 0.00645080953836441}, {"id": 40, "seek": 19712, "start": 208.20000000000002, "end": 213.0, "text": " And now we can run our current production with Nix there.", "tokens": [50918, 400, 586, 321, 393, 1190, 527, 2190, 4265, 365, 426, 970, 456, 13, 51158], "temperature": 0.0, "avg_logprob": -0.18659669101828397, "compression_ratio": 1.61864406779661, "no_speech_prob": 0.00645080953836441}, {"id": 41, "seek": 19712, "start": 213.0, "end": 216.84, "text": " Two things we didn't do with Nix was to manage the whole workflow.", "tokens": [51158, 4453, 721, 321, 994, 380, 360, 365, 426, 970, 390, 281, 3067, 264, 1379, 20993, 13, 51350], "temperature": 0.0, "avg_logprob": -0.18659669101828397, "compression_ratio": 1.61864406779661, "no_speech_prob": 0.00645080953836441}, {"id": 42, "seek": 19712, "start": 216.84, "end": 222.84, "text": " There is actually a tool for that Nix but it's more like a niche thing so we prefer", "tokens": [51350, 821, 307, 767, 257, 2290, 337, 300, 426, 970, 457, 309, 311, 544, 411, 257, 19956, 551, 370, 321, 4382, 51650], "temperature": 0.0, "avg_logprob": -0.18659669101828397, "compression_ratio": 1.61864406779661, "no_speech_prob": 0.00645080953836441}, {"id": 43, "seek": 19712, "start": 222.84, "end": 226.04000000000002, "text": " to use a more common tool.", "tokens": [51650, 281, 764, 257, 544, 2689, 2290, 13, 51810], "temperature": 0.0, "avg_logprob": -0.18659669101828397, "compression_ratio": 1.61864406779661, "no_speech_prob": 0.00645080953836441}, {"id": 44, "seek": 22604, "start": 226.04, "end": 231.48, "text": " And the final things what we could do in Nix but we didn't is to manage this large", "tokens": [50364, 400, 264, 2572, 721, 437, 321, 727, 360, 294, 426, 970, 457, 321, 994, 380, 307, 281, 3067, 341, 2416, 50636], "temperature": 0.0, "avg_logprob": -0.23768137977236792, "compression_ratio": 1.5991735537190082, "no_speech_prob": 0.006115321535617113}, {"id": 45, "seek": 22604, "start": 231.48, "end": 237.6, "text": " database because in our setup it's a different folder for Nix so we cannot install it.", "tokens": [50636, 8149, 570, 294, 527, 8657, 309, 311, 257, 819, 10820, 337, 426, 970, 370, 321, 2644, 3625, 309, 13, 50942], "temperature": 0.0, "avg_logprob": -0.23768137977236792, "compression_ratio": 1.5991735537190082, "no_speech_prob": 0.006115321535617113}, {"id": 46, "seek": 22604, "start": 237.6, "end": 241.35999999999999, "text": " But it's there in Nix.", "tokens": [50942, 583, 309, 311, 456, 294, 426, 970, 13, 51130], "temperature": 0.0, "avg_logprob": -0.23768137977236792, "compression_ratio": 1.5991735537190082, "no_speech_prob": 0.006115321535617113}, {"id": 47, "seek": 22604, "start": 241.35999999999999, "end": 243.16, "text": " Last last thing.", "tokens": [51130, 5264, 1036, 551, 13, 51220], "temperature": 0.0, "avg_logprob": -0.23768137977236792, "compression_ratio": 1.5991735537190082, "no_speech_prob": 0.006115321535617113}, {"id": 48, "seek": 22604, "start": 243.16, "end": 245.64, "text": " I really enjoyed the community.", "tokens": [51220, 286, 534, 4626, 264, 1768, 13, 51344], "temperature": 0.0, "avg_logprob": -0.23768137977236792, "compression_ratio": 1.5991735537190082, "no_speech_prob": 0.006115321535617113}, {"id": 49, "seek": 22604, "start": 245.64, "end": 248.04, "text": " It was a really nice interaction.", "tokens": [51344, 467, 390, 257, 534, 1481, 9285, 13, 51464], "temperature": 0.0, "avg_logprob": -0.23768137977236792, "compression_ratio": 1.5991735537190082, "no_speech_prob": 0.006115321535617113}, {"id": 50, "seek": 22604, "start": 248.04, "end": 250.72, "text": " I'm sure everyone knows.", "tokens": [51464, 286, 478, 988, 1518, 3255, 13, 51598], "temperature": 0.0, "avg_logprob": -0.23768137977236792, "compression_ratio": 1.5991735537190082, "no_speech_prob": 0.006115321535617113}, {"id": 51, "seek": 22604, "start": 250.72, "end": 255.2, "text": " But it's also kind of a slow process because I tried to package something myself which", "tokens": [51598, 583, 309, 311, 611, 733, 295, 257, 2964, 1399, 570, 286, 3031, 281, 7372, 746, 2059, 597, 51822], "temperature": 0.0, "avg_logprob": -0.23768137977236792, "compression_ratio": 1.5991735537190082, "no_speech_prob": 0.006115321535617113}, {"id": 52, "seek": 25520, "start": 255.2, "end": 257.64, "text": " is not easy at the beginning.", "tokens": [50364, 307, 406, 1858, 412, 264, 2863, 13, 50486], "temperature": 0.0, "avg_logprob": -0.30544028171273163, "compression_ratio": 1.5045045045045045, "no_speech_prob": 0.004436078481376171}, {"id": 53, "seek": 25520, "start": 257.64, "end": 263.96, "text": " And as you know there is like 5,000 pull requests on GitHub so feedback can be sometimes a bit", "tokens": [50486, 400, 382, 291, 458, 456, 307, 411, 1025, 11, 1360, 2235, 12475, 322, 23331, 370, 5824, 393, 312, 2171, 257, 857, 50802], "temperature": 0.0, "avg_logprob": -0.30544028171273163, "compression_ratio": 1.5045045045045045, "no_speech_prob": 0.004436078481376171}, {"id": 54, "seek": 25520, "start": 263.96, "end": 270.59999999999997, "text": " slow and also I'm working on my spate arm either so it can also take some time sometimes.", "tokens": [50802, 2964, 293, 611, 286, 478, 1364, 322, 452, 637, 473, 3726, 2139, 370, 309, 393, 611, 747, 512, 565, 2171, 13, 51134], "temperature": 0.0, "avg_logprob": -0.30544028171273163, "compression_ratio": 1.5045045045045045, "no_speech_prob": 0.004436078481376171}, {"id": 55, "seek": 25520, "start": 270.59999999999997, "end": 278.48, "text": " But for example the support for large databases has been added after a few conversations on", "tokens": [51134, 583, 337, 1365, 264, 1406, 337, 2416, 22380, 575, 668, 3869, 934, 257, 1326, 7315, 322, 51528], "temperature": 0.0, "avg_logprob": -0.30544028171273163, "compression_ratio": 1.5045045045045045, "no_speech_prob": 0.004436078481376171}, {"id": 56, "seek": 25520, "start": 278.48, "end": 282.2, "text": " Matrix.", "tokens": [51528, 36274, 13, 51714], "temperature": 0.0, "avg_logprob": -0.30544028171273163, "compression_ratio": 1.5045045045045045, "no_speech_prob": 0.004436078481376171}, {"id": 57, "seek": 25520, "start": 282.2, "end": 283.76, "text": " It was really fast.", "tokens": [51714, 467, 390, 534, 2370, 13, 51792], "temperature": 0.0, "avg_logprob": -0.30544028171273163, "compression_ratio": 1.5045045045045045, "no_speech_prob": 0.004436078481376171}, {"id": 58, "seek": 28376, "start": 283.76, "end": 288.44, "text": " I hope you take some key points there but if you want to know more you can send me an", "tokens": [50364, 286, 1454, 291, 747, 512, 2141, 2793, 456, 457, 498, 291, 528, 281, 458, 544, 291, 393, 2845, 385, 364, 50598], "temperature": 0.0, "avg_logprob": -0.33011239261950476, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.10943679511547089}, {"id": 59, "seek": 28376, "start": 288.44, "end": 291.52, "text": " email and I'll be glad to answer.", "tokens": [50598, 3796, 293, 286, 603, 312, 5404, 281, 1867, 13, 50752], "temperature": 0.0, "avg_logprob": -0.33011239261950476, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.10943679511547089}, {"id": 60, "seek": 28376, "start": 291.52, "end": 292.52, "text": " Thank you.", "tokens": [50752, 1044, 291, 13, 50802], "temperature": 0.0, "avg_logprob": -0.33011239261950476, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.10943679511547089}, {"id": 61, "seek": 28376, "start": 292.52, "end": 293.52, "text": " Thank you.", "tokens": [50802, 1044, 291, 13, 50852], "temperature": 0.0, "avg_logprob": -0.33011239261950476, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.10943679511547089}, {"id": 62, "seek": 28376, "start": 293.52, "end": 294.52, "text": " Thank you.", "tokens": [50852, 1044, 291, 13, 50902], "temperature": 0.0, "avg_logprob": -0.33011239261950476, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.10943679511547089}, {"id": 63, "seek": 28376, "start": 294.52, "end": 295.52, "text": " Thank you.", "tokens": [50902, 1044, 291, 13, 50952], "temperature": 0.0, "avg_logprob": -0.33011239261950476, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.10943679511547089}, {"id": 64, "seek": 28376, "start": 295.52, "end": 296.02, "text": " Thank you.", "tokens": [50952, 1044, 291, 13, 50977], "temperature": 0.0, "avg_logprob": -0.33011239261950476, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.10943679511547089}], "language": "en"}