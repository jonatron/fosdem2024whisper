{"text": " So, thank you all for coming to the Rust Dev Room 2024. We have a really, really good lineup of talks and we're going to start off with one of the strongest ones I think is, Bredrak Gurevsky is going to talk about Semvern Rust and how to make sure that your stuff is not breaking other people's stuff. Thanks everyone. Yeah, let's talk about the breakage, tooling and edge cases of semantic versioning in Rust. My name is Bredrak Gurevsky, some of you might recognize me as the maintainer of cargo semper checks. This is a linter for semantic versioning that this talk is about. But before we get to talking about the linter, let's get familiarized with what semantic versioning actually is and does. Ultimately semantic versioning is about communication. It's a way for library maintainers to let their users know what kind of changes to expect in new releases of libraries. If the changes are major and potentially requiring action on the part of the user of the library, we say that's a major change, we bump the major version number and that lets users know to expect that they might need to do a little bit of work to adopt it. Otherwise, if the library remains compatible with the previous version, that's not a major change and users expect to be able to just update to that new version automatically. So in this way, semper is communication not just between individual maintainers and the users of the libraries, but also between maintainers and the tooling that those users use. Let me give you a concrete example. This is a bit of automation that I have set up in many of my projects. Once a week, a job just runs cargo update on my project, opens a pull request and automatically merges it if tests pass. Now this only works so long as every one of these packages correctly adheres to semantic version, right? Cargo update will bump everything to the latest non-major version that it can find and hopefully tests pass and everything gets merged. But if there is an accidental breaking change and one of these pull requests, then everything sucks and we're back to square one, right? In this talk, I'm going to try to convince you of two major things. The first one is that semantic versioning in practice is so dang hard that no mere mortals can uphold it. None of us in this room are good enough to do this on a consistent day-in-day-out basis. I'm going to show you that the rules of semantic versioning are much more complex than what it seems like at first. I'm going to show you that even the rules that seem simple have a ton of non-obvious edge cases that we have to deal with. And I will show you empirical evidence based on real-world data that this is not just a skill issue. It's not something that can be solved with more experience or with harder work or just caring more about your project senior users. And then I'd like to show you that computers are actually really good at semantic versioning. We can use linter's like cargo semper checks to address almost all of the problems we're going to run into as part of this talk. And if you're so inclined, I'll even show you how cargo semper checks works under the hood so that you can contribute to it if you see fit for the benefit of all of us here in this room and in the broader Rust community. Let's dig right in. Let's talk about why semantic versioning is so hard in Rust. It's used within cargo's own publishing process itself and it's used by large teams like Amazon's AWS and Google open source projects to make sure that their own semper, that their own releases adhere to semper correctly. The way it's designed to be used is by running cargo semper checks right before you publish a new version of your crate. When you do this, cargo semper checks will detect the kind of version bump that you're making, whether it's major or minor, and then it will scan for API changes that might be inappropriate for that bump and let you know what it finds. The way to get cargo semper checks is by running a regular cargo install and if you're in a CI environment, we have a pre-built GitHub action that will do everything for you. And since some of us prefer to use release managers instead of just running cargo publish by ourselves, it's also integrated in some of the release managers. I particularly like release please, which will automatically run cargo semper checks as part of the release process. So if you're on the market for a good release manager, you should check this one out. It's awesome. I want to show you a couple of particular examples of how cargo semper checks finds these issues that might not be particularly obvious to the naked eye. The first example is a public function being deleted. Here we have a crate that had this public function called add and this pull request is just coming in and deleting that public function. This is pretty obviously a breaking change, right? And if we run cargo semper checks, it will tell us as much as well. It will say this function is missing, it cannot be imported by its prior path, and it will point out that the problematic function is the add function in this crate at that specific line in that file. This is great, but you might say, okay, we would have caught this by eye, right? This is pretty obvious. I don't need a tool here. Well, as it turns out, deletions of public items are not always a major breaking change, right? One way in which that can be the case is if we have that public function inside a private module. Yes, the function is public, but it's just not reachable. There's no way to import it, and so since nothing outside its own crate can use it, deleting that function is not a breaking change, right? There's no possible way that anyone could be affected by that. Another more interesting example is when we have a public module, but that module is marked doc hidden, or if the function itself is marked doc hidden. If you're not familiar with the doc hidden attribute, it's a way to mark a piece of your public surface area as not being part of your public API. It's explicitly saying these are internal implementation details that are made visible for a reason other than being public API. These most often happen when crates have macros where they need to expose some functionality that is only intended for use by those macros. Remember that macros get expanded in the downstream crates, and so they have to be able to access everything that is public in your own crate. We don't want to maintain the internal implementation details of macros as public API, so we usually mark that functionality as doc hidden. But it's not actually enough to say, oh, this module is doc hidden, therefore that function is not public API. Here's the opposite example. We have a public module that's doc hidden and a public function inside it, and that public function is now public API. Why? Because it's re-exported and the re-export is not doc hidden. So users of this crate could have imported this function without ever relying on any doc hidden functionality. So even though the module where the function is defined is doc hidden, this function is still public API. These roles are pretty complicated, right? It's not at all unreasonable that someone might mess this up, and in fact we found hundreds of issues like this when we scanned the top 1000 rust crates on crates I.O. Cargo-Sanver checks will catch all of these cases correctly, so it's just a lot easier to use the tooling instead of having to rack our brains when facing a PR that we have to review. So clearly deletions of public items are not always a major breaking change. Let's dig into a second example. Here we have a public struct foo that has some fields, and in this pull request we're adding a new field. And the author of this pull request was quite careful. They noticed that the foo struct has a constructor called new, and they made sure to not change the function signature of that constructor. Instead, they initialized the new fields to default value, and this seems entirely reasonable, right? This is a pull request that many of us would probably merge when facing it. The falsehood here is that adding fields to a struct can only be breaking, it can only be a breaking change via changes to methods. This is not true, right? The problem here is very, very non-obvious, especially to someone who came to rust from a different programming language first, like me. The issue is that this struct is not marked non-exhaustive, and all of its prior fields were public. If both of these things are true, this struct could be constructed with a struct literal. So users don't actually have to use this new method, they can just construct it directly by specifying all of the fields individually. So if a user in a downstream crate wrote something like, let value equals foo curly brace and then listed out all of the fields, they are now broken if we add this new field. They never specified a value for third, and so therefore this code no longer compiles. This is something that could very, very easily sneak up on us in a pull request whether we opened it or reviewing it, especially early in the morning when we're undercaffeinated. Right? And again, it's easier to just let cargo semper checks do the heavy lifting here. Running cargo semper checks again points out the problem. It says that a struct that could be made with a literal has a new public field, so existing struct literals must be updated, that's a breaking change, and it even points out that foo third is the field that is problematic in this case. So adding fields to a struct can sometimes be a breaking change even if we took great care to make sure that all of the methods and everything else around the struct has not changed. That's another falsehood we can cross off of our list. Let's jump into a third example, and this one's probably my favorite. Here we have a private struct foo, so not public, but private, and we're just changing some internal implementation details of that struct. Right? It used to take this static string reference, and we now want to support non-static strings. The struct is cloned, so we want to preserve cheap cloning, and we're going to use a ref-counted string to make that happen. Right? This is fine. I would probably accept this, you know, especially in the morning undercaffeinated. The falsehood here is that, you know, if I didn't touch it, I didn't break it. Right? I never touched public API. All of this code that I just showed you was private, and so I couldn't have broken the public API here. Right? Unfortunately, this is not true, and if we run Cargo-Semford-Checks, it will point out the problem. It says a public type has stopped implementing one or more auto traits. Type bar is no longer send and is no longer sync. And you might be thinking, second, what type bar? We were touching struct foo. There is no type bar here. Right? I was code reviewing, I read all of the changes, and there's no problem. So why is Cargo-Semford-Checks complaining about something that I didn't touch? Right? This must be a false positive. Here, our tools are doing us a disservice. The problem here is not the user's change. The problem is that the change affects something that is not shown in the pull request. Right? So I didn't touch it, I didn't break it, happens to be false, because type bar isn't here. Right? You have to click this button if it happens to be in the same file in order to be able to see the problem. The problem is that struct bar is public, and its implemented traits are there for public. And bar internally contains a foo. Now, an auto trait in Rust is a trait that the compiler automatically implements for us whenever possible. The rule is that a type implements an auto trait if all of its constituents also implement that same trait. Constituents being all of the fields, all of the variants, all of the data that that type might contain. Right? So send and sync are these auto traits in Rust that are used to express whether types are safe to be shared across threads. And the problem that we run into here is that the static string that we used to have inside foo was both send and sync at the same time. This reference counted string is neither send nor sync. Now, since the fields value over here is no longer send nor sync, that means that struct foo is no longer send nor sync, that means that struct bar is no longer send nor sync. And that breaks our public API. Because users that might have been using struct bar in some sort of context that relies on parallelism where that bar is shared across threads or passed between threads, their code is now broken. So they will see an error that looks like this. Rust C will say, RC of string cannot be shared between threads safely. Use parallelism requires that that value is sync and RC string is not because within bar, within foo, that field does not implement send and sync. This is something that has been, it's really a question of time until it bites any given project. This is just kind of impossible to catch because the problem is just not on the pull request page. And so cargo Stanford checks is just much better at finding these things than we humans are because it's looking at the data that the compiler emits. It's not just looking at the limited pull request review screen that we see on GitHub. So if I didn't touch it, I didn't break it is another falsehood that we get to cross off of our list. Hopefully by this point I've convinced you that cargo Stanford checks has some value and that it's likely to catch some stuff that we would otherwise miss and that we would find out when someone opens an issue on our project. Now that you've seen some of the issues that it can flag, let's talk about how this works and why you should trust what it can find. And in order to do this I want to come back to this example of deleting a public function. And I want to show you specifically how this works under the hood. We said that deleting a public function is a breaking change, a major breaking change if all of the following is true. In the original version the function was public. Another crate could have imported that function and used it. That import did not rely on any doc hidden items either on containing modules or on the item itself. And if we tried to use that same import in the newly released version that will no longer work for any of these reasons. Either the function is no longer public or it's no longer importable or it's no longer public API. In any case that's a major breaking change. And if we're looking for all of these breaking changes of this kind it's as easy as saying find all functions such that all of these things are true. Now if you're thinking what I'm thinking this might sound an awful lot like a database query, right? Select all functions where you know. And to help us see this I want to show you a diagram. We're looking at a version pair, right? We have the old version on the left and the new version on the right. And we're going to be looking for public functions that are importable and public API. And we're going to try to match them to versions in the new crates that have the same public function and the same importable path as the function that we were just looking at. And we found a breaking change if the count of such matching functions and importable paths is zero. If we don't find any of them, right? So the function could be imported and used in the past and can no longer be imported and used in the current version. This is a breaking change. And lo and behold, that's exactly how this works under the hood. Here's a database query that does the same thing. Now the point of this talk is not the query language, so I'm not going to dig too deep into the syntax or the semantics here, but I just want to show you that this is the exact same thing that we were just talking about. So we're looking at the baseline at the original version of the crate. We're going to be finding all functions that were public that could be imported by another crate and that were public API. And of course we're outputting stuff for later in case we find a breaking change. And we're going to say the same import does not exist. We will count how many matching functions at the same import path we find in the new version and we will say that count is zero. This is pretty nice, right? We get to write a piece of business logic that is completely ignorant of anything else about how we get this information. We just wrote down what the rule is in English and then we wrote down an equivalent database query that implements that rule and we just called it a day. This is pretty nice. I really like this personally. And if you're interested in architecture diagram, this is roughly what it looks like. Carbis and Verchex sits on top. On the bottom are our data sources. We get information from a tool called Rust doc which comes built in part of the Rust tool chain. We can ask Rust doc to generate a machine readable JSON representation of the crates API and we will read that JSON with Carbis and Verchex. Now Rust doc JSON's format is not stable. It changes relatively frequently more or less on every, if not every, than every other Rust release. This obviously can cause some issues and it has been the source of much frustration and consternation with other folks that have been building Rust doc based tooling. Carbis and Verchex has actually managed to solve this problem. Carbis and Verchex is not the first attempt at a Sembrer linter but it's the first one that managed to be isolated from changes in the underlying Rust doc format. Instead of requiring that you use a specific nightly, we're actually able to support multiple stable Rust versions concurrently. It doesn't matter which Rust doc JSON format version we get, they should work fine so long as they're reasonably recent. And the way this works is we rely on a query engine called Trustfall to sit in between. Carbis and Verchex runs queries in this Trustfall language syntax that I showed you a couple of slides ago. And Trustfall figures out which Rust doc JSON format version it's looking at and uses a little shim, little adapter, a little Rust piece of code that is able to translate that JSON format into something that adheres to the Trustfall schema that Carbis and Verchex is used to. That schema is written in a fairly high level. It talks about, you know, Rust functions and modules and importable path and, you know, whether things are public or private and does not say this value is in a field named such and such and it's an object containing the following fields and so on. So it's very unlikely to be broken by format changes in Rust doc because Rust today, tomorrow and next week is still going to have functions, modules, structs, fields and so on, right? All of that stuff doesn't really change very much. So in practice that means that we get to encapsulate all of the format specific logic in these adapters and nothing outside of this big ellipse at the bottom knows anything about how the data is represented and what format it came in. The query engine on top figures out how to most efficiently run these queries that we're running and that just leaves Carbis and Verchex writing business logic in this query language. Carbis and Verchex only cares about this is the semver logic that we're interested in implementing and everything else happens behind the scenes at a lower level in this diagram. I just want to give you a little bit of a taste of what Trustful is in case this seems interesting to you. It's a project that I also started. It allows us to represent data as a graph and query any kind of data sources. So this is not something that's specific to Rust doc at all. It's heavily battle tested. It's been in production for more than seven years. It's written in Rust. It's open source and it allows adapters to be written in a variety of programming languages like Rust, Python, JavaScript, WebAssembly and so on. And when I say it can turn everything into a database, I really mean it. If you have any kind of data source, be it an API, a database, an arbitrary file format, a machine learning model, you can query it with Trustful and you can do so in place and without having to do an ETL step in advance to ingest the data and then represent it in some other format. If you're interested in digging more into Trustful, I've given a couple of talks on that specifically. I gave a talk called How to query almost everything that's a deep dive into Trustful in particular and how it works. And I also gave a performance oriented talk talking about how cargo semper checks became more than 2,000 times faster by using some new optimization opportunities that Trustful exposed at P99 last year. And if you're interested in playing with Trustful yourself, we have a couple of playgrounds that you can check out on your laptop right now. We have a playground that uses Rustdoc JSON that uses the same exact code that powers cargo semper checks that lets you query popular Rust crates APIs and you can find all sorts of interesting things about them. And just to show that you can query any kind of other data set as well, you can query the hack and use rest APIs as well with Trustful queries from your browser. And just for kicks, because Rust is awesome like that, in these playgrounds we compile the entire Rust, we compile the entire Trustful engine to WebAssembly so all of the queries run client side in your browser. So really go crazy with these queries, I don't care, it's your bandwidth and your CPU, right? So if you get rate limited by hacker news, it's your problem, not mine, please go ham. Fundamentally, Trustful is what makes cargo semper checks possible. We need, there are hundreds of ways to break semantic versioning rules in Rust. And if we had to rewrite every one of our lints, whenever the format under the hood changed, this would be completely infeasible. By being able to decouple the format specific logic from the query logic, the business logic of linting semper, we can focus on linting and ergonomics and cargo semper checks and deal with everything else under the hood. We can take an n times m problem of n lints and m formats and turn it into an n plus m problem, which is much, much more maintainable, especially as a free open source project. So cargo semper checks on the back of Trustful has been growing fairly rapidly. We currently have 58 lints and almost every new release comes with a few more. This is twice as many as a year ago and still growing quite fast. We have 32 contributors and in fact, many of the new lints that we keep adding are first time contributions, which is awesome because it means that this query language is not something that is super niche and difficult to learn and is actually friendly to new folks. And most importantly, our users love us. Everybody prefers to find out about accidentally breaking changes before they get pushed to production and get released and then somebody opens an issue saying, sorry, you broke my project. So hopefully by this point, I've convinced you that semantic versioning is valuable, but it's impossible without automated help. And that cargo semper checks is a solution to this problem that has lots of happy users. So if you take nothing else away from this talk, please consider using cargo semper checks if you maintain Rust code because all of us will be better off. And if you'd like to help, you can contribute code and lints to cargo semper checks. Even though we have 58 lints right now, there are still dozens and hundreds more breaking changes that we still need to lint for. We could really use some sponsorships free and open source projects live and die by GitHub sponsors. So if you or your company use cargo semper checks, please consider sponsoring our development. And finally, for the sake of everyone in the Rust community, please try to not push out breaking changes. Nobody will blame you for it, but it's a lot more fun if you find them before you release the crate as opposed to after you release the crate. So please check out cargo semper checks. Please find me in the hallway if you'd like to chat more. And thank you so much for your time. So I think, do we have time for questions? Yeah, how long? Five minutes. So let's open it up. I'm going to give you the mic so that people on the industry can also hear. Awesome, thank you. So one of the things that I know about semantic versioning is that version zero is, it's an interesting one. And you didn't talk about it at all, but it also notes on the page that there was a lot of version zero. So I was wondering about your opinion on it. Yeah, that's a good question. The question was, is version zero special in Rust? The semper specification and the Rust community have diverged on what version zero means, essentially. So the semantic versioning is about communication, right? So it's about the norms that are accepted in the community rather than a fixed and rigid set of rules. And in the Rust community, we've decided that leftmost, you know, any zeros on the left-hand side of the version kind of don't count. So version zero dot five to version zero dot six counts as a major change, right? And zero dot zero dot one to zero dot zero dot two is also a major change, right? This in practice is what keeps all of us sane because otherwise if zero dot x to any zero dot y could ship any breaking change, then all projects would always, you know, stay on zero dot x and then cargo update would still not work and not be able to bump us. So this is from a point of pragmatism for the sake of the community as opposed to some rigid system of rules. Thanks. Like you said, some changes can be intentionally breaking semper. Is there a way to annotate them so the tool knows or do you have to bypass the tool in these cases? Great question. So the question is, since some changes might be intentionally breaking semper, is there a good way to annotate them so that users can notice them in a way that is not going to break their CI? Unfortunately, there's not a lot of great tooling here. Obviously, we have things like change logs. Authors will usually post on, you know, their social media pages and things like that. They will try to get the word out. It's very rare for a maintainer to deem something so critical that it justifies an intentional semper violation and yet just kind of tell nobody about it. But we don't have great tooling that will say, hey, by the way, this is intentionally breaking because of reasons x, y, and z that you should read up on. It would be lovely if we could sort of mark the item so that when it gets used then it causes a breaking change. We got a custom error message printed out by Rust C that says this is why this is happening and this is how you go about fixing it. Unfortunately, we're not there yet. And the answer is more code needs to be written and more financial support needs to go into all of these projects for that to happen. Is there any work going on integrating these tooling into packaging like Debian or which suffer from these problems once in a while? Yeah, great question. The question was whether there's any work ongoing to integrate something like Cargo-Sanverchex into the broader packaging tools that we already use on a daily basis. The answer is yes. So I've been in close contact with the cargo team. They actually reached out and asked if it would be feasible to work toward integrating Cargo-Sanverchex into cargo itself so that instead of running Cargo-Sanverchex, then Cargo publish, you just run Cargo publish and Cargo tells you whether, you know, what it found. This is obviously a little bit tricky. It's not super straightforward for a couple of reasons. One is that when things get merged into cargo, they're stable and they're stable forever. So we want to make sure that the APIs that we expose are really good and that the right API is not just for now and for next year, but for the next 10, 20, 50 years. The second thing is that we want to make sure that users can always override what Cargo-Sanverchex has found, right? Because there are these cases where an intentional Semver violation is justified. We want to have a workflow that's kind of like Cargo publish dash dash allow dirty, where Cargo publish will normally not allow you to do that, but there is a way to override and say, I know what I'm doing, I've thought about it, and this is still the right thing to do. So we really want to make sure that we dial in the exact user experience that is the right thing for everyone in the ecosystem and that we can support in the long run before we go about integrating it. But long story short, yes, the work on this is ongoing and again, it's a function of how quickly we can get this work done in order to make it happen. Okay, so last one. Okay, so let me give you the mic. So I'm interested in trustful. Do you know if there are other applications such as I'm thinking about validating breaking changes in open API definitions, for example? Yes, great question. I would love to chat. The question was if trustful has other applications besides Cargo-Sanverchex, the answer is yes. This is something I'm very interested in chatting about. So if anyone else has this question, please find me in the hallway and I can show you some more demos. A few other linters are looking into trustful for designing custom lints. I'm also working on a Python semantic versioning linter. Python is a very interesting beast because it's much more dynamic, so Semver is pretty tricky there. And my former employer actually uses trustful to enforce code standards that are not just correctness, but they're just about best practices that the company has decided are supposed to happen. In fact, one of the talks that I put on the slide, this how to query almost everything has a specific example of linting Python applications that get deployed and looking for mismatches in the Python version declared in the project manifest in a pyproject.toml file versus the Kubernetes configuration in the Docker file that goes with it, which also says, you know, from Python 3 colon 8 or whatever. It turns out that we can query for what does the Docker think the Python version is, what does the manifest think the Python version is and find cases where they don't match. And spoiler alert, I mean, we found hundreds of these issues when we rolled out those tools. These things just happen. Great. Thank you very much. Thank you so much for having me.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 10.48, "text": " So, thank you all for coming to the Rust Dev Room 2024.", "tokens": [50364, 407, 11, 1309, 291, 439, 337, 1348, 281, 264, 34952, 9096, 19190, 45237, 13, 50888], "temperature": 0.0, "avg_logprob": -0.3215772117056498, "compression_ratio": 1.4827586206896552, "no_speech_prob": 0.5630002021789551}, {"id": 1, "seek": 0, "start": 10.48, "end": 16.36, "text": " We have a really, really good lineup of talks and we're going to start off with one of the", "tokens": [50888, 492, 362, 257, 534, 11, 534, 665, 26461, 295, 6686, 293, 321, 434, 516, 281, 722, 766, 365, 472, 295, 264, 51182], "temperature": 0.0, "avg_logprob": -0.3215772117056498, "compression_ratio": 1.4827586206896552, "no_speech_prob": 0.5630002021789551}, {"id": 2, "seek": 0, "start": 16.36, "end": 22.96, "text": " strongest ones I think is, Bredrak Gurevsky is going to talk about Semvern Rust and how", "tokens": [51182, 16595, 2306, 286, 519, 307, 11, 363, 986, 11272, 460, 540, 85, 25810, 307, 516, 281, 751, 466, 14421, 1659, 34952, 293, 577, 51512], "temperature": 0.0, "avg_logprob": -0.3215772117056498, "compression_ratio": 1.4827586206896552, "no_speech_prob": 0.5630002021789551}, {"id": 3, "seek": 0, "start": 22.96, "end": 26.88, "text": " to make sure that your stuff is not breaking other people's stuff.", "tokens": [51512, 281, 652, 988, 300, 428, 1507, 307, 406, 7697, 661, 561, 311, 1507, 13, 51708], "temperature": 0.0, "avg_logprob": -0.3215772117056498, "compression_ratio": 1.4827586206896552, "no_speech_prob": 0.5630002021789551}, {"id": 4, "seek": 2688, "start": 26.88, "end": 39.36, "text": " Thanks everyone. Yeah, let's talk about the breakage, tooling and edge cases of semantic", "tokens": [50364, 2561, 1518, 13, 865, 11, 718, 311, 751, 466, 264, 1821, 609, 11, 46593, 293, 4691, 3331, 295, 47982, 50988], "temperature": 0.0, "avg_logprob": -0.1932495920281661, "compression_ratio": 1.6079295154185023, "no_speech_prob": 0.005632340908050537}, {"id": 5, "seek": 2688, "start": 39.36, "end": 45.480000000000004, "text": " versioning in Rust. My name is Bredrak Gurevsky, some of you might recognize me as the maintainer", "tokens": [50988, 3037, 278, 294, 34952, 13, 1222, 1315, 307, 363, 986, 11272, 460, 540, 85, 25810, 11, 512, 295, 291, 1062, 5521, 385, 382, 264, 6909, 260, 51294], "temperature": 0.0, "avg_logprob": -0.1932495920281661, "compression_ratio": 1.6079295154185023, "no_speech_prob": 0.005632340908050537}, {"id": 6, "seek": 2688, "start": 45.480000000000004, "end": 50.96, "text": " of cargo semper checks. This is a linter for semantic versioning that this talk is about.", "tokens": [51294, 295, 19449, 4361, 610, 13834, 13, 639, 307, 257, 287, 5106, 337, 47982, 3037, 278, 300, 341, 751, 307, 466, 13, 51568], "temperature": 0.0, "avg_logprob": -0.1932495920281661, "compression_ratio": 1.6079295154185023, "no_speech_prob": 0.005632340908050537}, {"id": 7, "seek": 2688, "start": 50.96, "end": 55.0, "text": " But before we get to talking about the linter, let's get familiarized with what semantic", "tokens": [51568, 583, 949, 321, 483, 281, 1417, 466, 264, 287, 5106, 11, 718, 311, 483, 4963, 1602, 365, 437, 47982, 51770], "temperature": 0.0, "avg_logprob": -0.1932495920281661, "compression_ratio": 1.6079295154185023, "no_speech_prob": 0.005632340908050537}, {"id": 8, "seek": 5500, "start": 55.0, "end": 61.96, "text": " versioning actually is and does. Ultimately semantic versioning is about communication.", "tokens": [50364, 3037, 278, 767, 307, 293, 775, 13, 23921, 47982, 3037, 278, 307, 466, 6101, 13, 50712], "temperature": 0.0, "avg_logprob": -0.10836663246154785, "compression_ratio": 1.777327935222672, "no_speech_prob": 0.05658825859427452}, {"id": 9, "seek": 5500, "start": 61.96, "end": 66.84, "text": " It's a way for library maintainers to let their users know what kind of changes to expect", "tokens": [50712, 467, 311, 257, 636, 337, 6405, 6909, 433, 281, 718, 641, 5022, 458, 437, 733, 295, 2962, 281, 2066, 50956], "temperature": 0.0, "avg_logprob": -0.10836663246154785, "compression_ratio": 1.777327935222672, "no_speech_prob": 0.05658825859427452}, {"id": 10, "seek": 5500, "start": 66.84, "end": 72.2, "text": " in new releases of libraries. If the changes are major and potentially requiring action", "tokens": [50956, 294, 777, 16952, 295, 15148, 13, 759, 264, 2962, 366, 2563, 293, 7263, 24165, 3069, 51224], "temperature": 0.0, "avg_logprob": -0.10836663246154785, "compression_ratio": 1.777327935222672, "no_speech_prob": 0.05658825859427452}, {"id": 11, "seek": 5500, "start": 72.2, "end": 76.32, "text": " on the part of the user of the library, we say that's a major change, we bump the major", "tokens": [51224, 322, 264, 644, 295, 264, 4195, 295, 264, 6405, 11, 321, 584, 300, 311, 257, 2563, 1319, 11, 321, 9961, 264, 2563, 51430], "temperature": 0.0, "avg_logprob": -0.10836663246154785, "compression_ratio": 1.777327935222672, "no_speech_prob": 0.05658825859427452}, {"id": 12, "seek": 5500, "start": 76.32, "end": 80.64, "text": " version number and that lets users know to expect that they might need to do a little", "tokens": [51430, 3037, 1230, 293, 300, 6653, 5022, 458, 281, 2066, 300, 436, 1062, 643, 281, 360, 257, 707, 51646], "temperature": 0.0, "avg_logprob": -0.10836663246154785, "compression_ratio": 1.777327935222672, "no_speech_prob": 0.05658825859427452}, {"id": 13, "seek": 8064, "start": 80.64, "end": 85.24, "text": " bit of work to adopt it. Otherwise, if the library remains compatible with the previous", "tokens": [50364, 857, 295, 589, 281, 6878, 309, 13, 10328, 11, 498, 264, 6405, 7023, 18218, 365, 264, 3894, 50594], "temperature": 0.0, "avg_logprob": -0.10710558845001517, "compression_ratio": 1.7045454545454546, "no_speech_prob": 0.2655188739299774}, {"id": 14, "seek": 8064, "start": 85.24, "end": 90.28, "text": " version, that's not a major change and users expect to be able to just update to that new", "tokens": [50594, 3037, 11, 300, 311, 406, 257, 2563, 1319, 293, 5022, 2066, 281, 312, 1075, 281, 445, 5623, 281, 300, 777, 50846], "temperature": 0.0, "avg_logprob": -0.10710558845001517, "compression_ratio": 1.7045454545454546, "no_speech_prob": 0.2655188739299774}, {"id": 15, "seek": 8064, "start": 90.28, "end": 96.36, "text": " version automatically. So in this way, semper is communication not just between individual", "tokens": [50846, 3037, 6772, 13, 407, 294, 341, 636, 11, 4361, 610, 307, 6101, 406, 445, 1296, 2609, 51150], "temperature": 0.0, "avg_logprob": -0.10710558845001517, "compression_ratio": 1.7045454545454546, "no_speech_prob": 0.2655188739299774}, {"id": 16, "seek": 8064, "start": 96.36, "end": 101.32, "text": " maintainers and the users of the libraries, but also between maintainers and the tooling", "tokens": [51150, 6909, 433, 293, 264, 5022, 295, 264, 15148, 11, 457, 611, 1296, 6909, 433, 293, 264, 46593, 51398], "temperature": 0.0, "avg_logprob": -0.10710558845001517, "compression_ratio": 1.7045454545454546, "no_speech_prob": 0.2655188739299774}, {"id": 17, "seek": 8064, "start": 101.32, "end": 106.48, "text": " that those users use. Let me give you a concrete example. This is a bit of automation that I", "tokens": [51398, 300, 729, 5022, 764, 13, 961, 385, 976, 291, 257, 9859, 1365, 13, 639, 307, 257, 857, 295, 17769, 300, 286, 51656], "temperature": 0.0, "avg_logprob": -0.10710558845001517, "compression_ratio": 1.7045454545454546, "no_speech_prob": 0.2655188739299774}, {"id": 18, "seek": 10648, "start": 106.48, "end": 112.68, "text": " have set up in many of my projects. Once a week, a job just runs cargo update on my", "tokens": [50364, 362, 992, 493, 294, 867, 295, 452, 4455, 13, 3443, 257, 1243, 11, 257, 1691, 445, 6676, 19449, 5623, 322, 452, 50674], "temperature": 0.0, "avg_logprob": -0.1493717284429641, "compression_ratio": 1.6679104477611941, "no_speech_prob": 0.02095663547515869}, {"id": 19, "seek": 10648, "start": 112.68, "end": 119.16, "text": " project, opens a pull request and automatically merges it if tests pass. Now this only works", "tokens": [50674, 1716, 11, 9870, 257, 2235, 5308, 293, 6772, 3551, 2880, 309, 498, 6921, 1320, 13, 823, 341, 787, 1985, 50998], "temperature": 0.0, "avg_logprob": -0.1493717284429641, "compression_ratio": 1.6679104477611941, "no_speech_prob": 0.02095663547515869}, {"id": 20, "seek": 10648, "start": 119.16, "end": 123.76, "text": " so long as every one of these packages correctly adheres to semantic version, right? Cargo", "tokens": [50998, 370, 938, 382, 633, 472, 295, 613, 17401, 8944, 614, 19464, 281, 47982, 3037, 11, 558, 30, 2741, 1571, 51228], "temperature": 0.0, "avg_logprob": -0.1493717284429641, "compression_ratio": 1.6679104477611941, "no_speech_prob": 0.02095663547515869}, {"id": 21, "seek": 10648, "start": 123.76, "end": 129.32, "text": " update will bump everything to the latest non-major version that it can find and hopefully", "tokens": [51228, 5623, 486, 9961, 1203, 281, 264, 6792, 2107, 12, 1696, 2337, 3037, 300, 309, 393, 915, 293, 4696, 51506], "temperature": 0.0, "avg_logprob": -0.1493717284429641, "compression_ratio": 1.6679104477611941, "no_speech_prob": 0.02095663547515869}, {"id": 22, "seek": 10648, "start": 129.32, "end": 134.52, "text": " tests pass and everything gets merged. But if there is an accidental breaking change and", "tokens": [51506, 6921, 1320, 293, 1203, 2170, 36427, 13, 583, 498, 456, 307, 364, 38094, 7697, 1319, 293, 51766], "temperature": 0.0, "avg_logprob": -0.1493717284429641, "compression_ratio": 1.6679104477611941, "no_speech_prob": 0.02095663547515869}, {"id": 23, "seek": 13452, "start": 134.52, "end": 140.88000000000002, "text": " one of these pull requests, then everything sucks and we're back to square one, right?", "tokens": [50364, 472, 295, 613, 2235, 12475, 11, 550, 1203, 15846, 293, 321, 434, 646, 281, 3732, 472, 11, 558, 30, 50682], "temperature": 0.0, "avg_logprob": -0.10153993807340923, "compression_ratio": 1.6704545454545454, "no_speech_prob": 0.0007792862015776336}, {"id": 24, "seek": 13452, "start": 140.88000000000002, "end": 145.12, "text": " In this talk, I'm going to try to convince you of two major things. The first one is", "tokens": [50682, 682, 341, 751, 11, 286, 478, 516, 281, 853, 281, 13447, 291, 295, 732, 2563, 721, 13, 440, 700, 472, 307, 50894], "temperature": 0.0, "avg_logprob": -0.10153993807340923, "compression_ratio": 1.6704545454545454, "no_speech_prob": 0.0007792862015776336}, {"id": 25, "seek": 13452, "start": 145.12, "end": 151.08, "text": " that semantic versioning in practice is so dang hard that no mere mortals can uphold it.", "tokens": [50894, 300, 47982, 3037, 278, 294, 3124, 307, 370, 21892, 1152, 300, 572, 8401, 6599, 1124, 393, 34451, 309, 13, 51192], "temperature": 0.0, "avg_logprob": -0.10153993807340923, "compression_ratio": 1.6704545454545454, "no_speech_prob": 0.0007792862015776336}, {"id": 26, "seek": 13452, "start": 151.08, "end": 156.04000000000002, "text": " None of us in this room are good enough to do this on a consistent day-in-day-out basis.", "tokens": [51192, 14492, 295, 505, 294, 341, 1808, 366, 665, 1547, 281, 360, 341, 322, 257, 8398, 786, 12, 259, 12, 810, 12, 346, 5143, 13, 51440], "temperature": 0.0, "avg_logprob": -0.10153993807340923, "compression_ratio": 1.6704545454545454, "no_speech_prob": 0.0007792862015776336}, {"id": 27, "seek": 13452, "start": 156.04000000000002, "end": 159.8, "text": " I'm going to show you that the rules of semantic versioning are much more complex than what", "tokens": [51440, 286, 478, 516, 281, 855, 291, 300, 264, 4474, 295, 47982, 3037, 278, 366, 709, 544, 3997, 813, 437, 51628], "temperature": 0.0, "avg_logprob": -0.10153993807340923, "compression_ratio": 1.6704545454545454, "no_speech_prob": 0.0007792862015776336}, {"id": 28, "seek": 15980, "start": 159.8, "end": 164.72, "text": " it seems like at first. I'm going to show you that even the rules that seem simple have", "tokens": [50364, 309, 2544, 411, 412, 700, 13, 286, 478, 516, 281, 855, 291, 300, 754, 264, 4474, 300, 1643, 2199, 362, 50610], "temperature": 0.0, "avg_logprob": -0.10301355079368309, "compression_ratio": 1.7076923076923076, "no_speech_prob": 0.012817446142435074}, {"id": 29, "seek": 15980, "start": 164.72, "end": 169.84, "text": " a ton of non-obvious edge cases that we have to deal with. And I will show you empirical", "tokens": [50610, 257, 2952, 295, 2107, 12, 996, 1502, 4691, 3331, 300, 321, 362, 281, 2028, 365, 13, 400, 286, 486, 855, 291, 31886, 50866], "temperature": 0.0, "avg_logprob": -0.10301355079368309, "compression_ratio": 1.7076923076923076, "no_speech_prob": 0.012817446142435074}, {"id": 30, "seek": 15980, "start": 169.84, "end": 174.96, "text": " evidence based on real-world data that this is not just a skill issue. It's not something", "tokens": [50866, 4467, 2361, 322, 957, 12, 13217, 1412, 300, 341, 307, 406, 445, 257, 5389, 2734, 13, 467, 311, 406, 746, 51122], "temperature": 0.0, "avg_logprob": -0.10301355079368309, "compression_ratio": 1.7076923076923076, "no_speech_prob": 0.012817446142435074}, {"id": 31, "seek": 15980, "start": 174.96, "end": 179.72000000000003, "text": " that can be solved with more experience or with harder work or just caring more about", "tokens": [51122, 300, 393, 312, 13041, 365, 544, 1752, 420, 365, 6081, 589, 420, 445, 15365, 544, 466, 51360], "temperature": 0.0, "avg_logprob": -0.10301355079368309, "compression_ratio": 1.7076923076923076, "no_speech_prob": 0.012817446142435074}, {"id": 32, "seek": 15980, "start": 179.72000000000003, "end": 185.36, "text": " your project senior users. And then I'd like to show you that computers are actually really", "tokens": [51360, 428, 1716, 7965, 5022, 13, 400, 550, 286, 1116, 411, 281, 855, 291, 300, 10807, 366, 767, 534, 51642], "temperature": 0.0, "avg_logprob": -0.10301355079368309, "compression_ratio": 1.7076923076923076, "no_speech_prob": 0.012817446142435074}, {"id": 33, "seek": 18536, "start": 185.4, "end": 191.0, "text": " good at semantic versioning. We can use linter's like cargo semper checks to address almost", "tokens": [50366, 665, 412, 47982, 3037, 278, 13, 492, 393, 764, 287, 5106, 311, 411, 19449, 4361, 610, 13834, 281, 2985, 1920, 50646], "temperature": 0.0, "avg_logprob": -0.14470693444003577, "compression_ratio": 1.7452471482889733, "no_speech_prob": 0.09661338478326797}, {"id": 34, "seek": 18536, "start": 191.0, "end": 196.12, "text": " all of the problems we're going to run into as part of this talk. And if you're so inclined,", "tokens": [50646, 439, 295, 264, 2740, 321, 434, 516, 281, 1190, 666, 382, 644, 295, 341, 751, 13, 400, 498, 291, 434, 370, 28173, 11, 50902], "temperature": 0.0, "avg_logprob": -0.14470693444003577, "compression_ratio": 1.7452471482889733, "no_speech_prob": 0.09661338478326797}, {"id": 35, "seek": 18536, "start": 196.12, "end": 200.76000000000002, "text": " I'll even show you how cargo semper checks works under the hood so that you can contribute", "tokens": [50902, 286, 603, 754, 855, 291, 577, 19449, 4361, 610, 13834, 1985, 833, 264, 13376, 370, 300, 291, 393, 10586, 51134], "temperature": 0.0, "avg_logprob": -0.14470693444003577, "compression_ratio": 1.7452471482889733, "no_speech_prob": 0.09661338478326797}, {"id": 36, "seek": 18536, "start": 200.76000000000002, "end": 204.38000000000002, "text": " to it if you see fit for the benefit of all of us here in this room and in the broader", "tokens": [51134, 281, 309, 498, 291, 536, 3318, 337, 264, 5121, 295, 439, 295, 505, 510, 294, 341, 1808, 293, 294, 264, 13227, 51315], "temperature": 0.0, "avg_logprob": -0.14470693444003577, "compression_ratio": 1.7452471482889733, "no_speech_prob": 0.09661338478326797}, {"id": 37, "seek": 18536, "start": 204.38000000000002, "end": 210.8, "text": " Rust community. Let's dig right in. Let's talk about why semantic versioning is so hard", "tokens": [51315, 34952, 1768, 13, 961, 311, 2528, 558, 294, 13, 961, 311, 751, 466, 983, 47982, 3037, 278, 307, 370, 1152, 51636], "temperature": 0.0, "avg_logprob": -0.14470693444003577, "compression_ratio": 1.7452471482889733, "no_speech_prob": 0.09661338478326797}, {"id": 38, "seek": 18536, "start": 210.8, "end": 211.4, "text": " in Rust.", "tokens": [51636, 294, 34952, 13, 51666], "temperature": 0.0, "avg_logprob": -0.14470693444003577, "compression_ratio": 1.7452471482889733, "no_speech_prob": 0.09661338478326797}, {"id": 39, "seek": 78536, "start": 785.36, "end": 799.72, "text": " It's used within cargo's own publishing process itself and it's used by large teams like", "tokens": [50364, 467, 311, 1143, 1951, 19449, 311, 1065, 17832, 1399, 2564, 293, 309, 311, 1143, 538, 2416, 5491, 411, 51082], "temperature": 0.0, "avg_logprob": -0.2043108493089676, "compression_ratio": 1.488888888888889, "no_speech_prob": 0.05006455257534981}, {"id": 40, "seek": 78536, "start": 799.72, "end": 805.44, "text": " Amazon's AWS and Google open source projects to make sure that their own semper, that their", "tokens": [51082, 6795, 311, 17650, 293, 3329, 1269, 4009, 4455, 281, 652, 988, 300, 641, 1065, 4361, 610, 11, 300, 641, 51368], "temperature": 0.0, "avg_logprob": -0.2043108493089676, "compression_ratio": 1.488888888888889, "no_speech_prob": 0.05006455257534981}, {"id": 41, "seek": 78536, "start": 805.44, "end": 811.52, "text": " own releases adhere to semper correctly. The way it's designed to be used is by running", "tokens": [51368, 1065, 16952, 33584, 281, 4361, 610, 8944, 13, 440, 636, 309, 311, 4761, 281, 312, 1143, 307, 538, 2614, 51672], "temperature": 0.0, "avg_logprob": -0.2043108493089676, "compression_ratio": 1.488888888888889, "no_speech_prob": 0.05006455257534981}, {"id": 42, "seek": 81152, "start": 811.52, "end": 817.1999999999999, "text": " cargo semper checks right before you publish a new version of your crate. When you do this,", "tokens": [50364, 19449, 4361, 610, 13834, 558, 949, 291, 11374, 257, 777, 3037, 295, 428, 42426, 13, 1133, 291, 360, 341, 11, 50648], "temperature": 0.0, "avg_logprob": -0.11738461487052977, "compression_ratio": 1.7179487179487178, "no_speech_prob": 0.2775556147098541}, {"id": 43, "seek": 81152, "start": 817.1999999999999, "end": 821.1999999999999, "text": " cargo semper checks will detect the kind of version bump that you're making, whether it's", "tokens": [50648, 19449, 4361, 610, 13834, 486, 5531, 264, 733, 295, 3037, 9961, 300, 291, 434, 1455, 11, 1968, 309, 311, 50848], "temperature": 0.0, "avg_logprob": -0.11738461487052977, "compression_ratio": 1.7179487179487178, "no_speech_prob": 0.2775556147098541}, {"id": 44, "seek": 81152, "start": 821.1999999999999, "end": 825.64, "text": " major or minor, and then it will scan for API changes that might be inappropriate for", "tokens": [50848, 2563, 420, 6696, 11, 293, 550, 309, 486, 11049, 337, 9362, 2962, 300, 1062, 312, 26723, 337, 51070], "temperature": 0.0, "avg_logprob": -0.11738461487052977, "compression_ratio": 1.7179487179487178, "no_speech_prob": 0.2775556147098541}, {"id": 45, "seek": 81152, "start": 825.64, "end": 830.88, "text": " that bump and let you know what it finds. The way to get cargo semper checks is by running", "tokens": [51070, 300, 9961, 293, 718, 291, 458, 437, 309, 10704, 13, 440, 636, 281, 483, 19449, 4361, 610, 13834, 307, 538, 2614, 51332], "temperature": 0.0, "avg_logprob": -0.11738461487052977, "compression_ratio": 1.7179487179487178, "no_speech_prob": 0.2775556147098541}, {"id": 46, "seek": 81152, "start": 830.88, "end": 835.0, "text": " a regular cargo install and if you're in a CI environment, we have a pre-built GitHub", "tokens": [51332, 257, 3890, 19449, 3625, 293, 498, 291, 434, 294, 257, 37777, 2823, 11, 321, 362, 257, 659, 12, 23018, 23331, 51538], "temperature": 0.0, "avg_logprob": -0.11738461487052977, "compression_ratio": 1.7179487179487178, "no_speech_prob": 0.2775556147098541}, {"id": 47, "seek": 81152, "start": 835.0, "end": 840.56, "text": " action that will do everything for you. And since some of us prefer to use release managers", "tokens": [51538, 3069, 300, 486, 360, 1203, 337, 291, 13, 400, 1670, 512, 295, 505, 4382, 281, 764, 4374, 14084, 51816], "temperature": 0.0, "avg_logprob": -0.11738461487052977, "compression_ratio": 1.7179487179487178, "no_speech_prob": 0.2775556147098541}, {"id": 48, "seek": 84056, "start": 840.5999999999999, "end": 845.4, "text": " instead of just running cargo publish by ourselves, it's also integrated in some of the release", "tokens": [50366, 2602, 295, 445, 2614, 19449, 11374, 538, 4175, 11, 309, 311, 611, 10919, 294, 512, 295, 264, 4374, 50606], "temperature": 0.0, "avg_logprob": -0.11729668154574857, "compression_ratio": 1.792828685258964, "no_speech_prob": 0.0008828260470181704}, {"id": 49, "seek": 84056, "start": 845.4, "end": 850.4399999999999, "text": " managers. I particularly like release please, which will automatically run cargo semper", "tokens": [50606, 14084, 13, 286, 4098, 411, 4374, 1767, 11, 597, 486, 6772, 1190, 19449, 4361, 610, 50858], "temperature": 0.0, "avg_logprob": -0.11729668154574857, "compression_ratio": 1.792828685258964, "no_speech_prob": 0.0008828260470181704}, {"id": 50, "seek": 84056, "start": 850.4399999999999, "end": 854.64, "text": " checks as part of the release process. So if you're on the market for a good release", "tokens": [50858, 13834, 382, 644, 295, 264, 4374, 1399, 13, 407, 498, 291, 434, 322, 264, 2142, 337, 257, 665, 4374, 51068], "temperature": 0.0, "avg_logprob": -0.11729668154574857, "compression_ratio": 1.792828685258964, "no_speech_prob": 0.0008828260470181704}, {"id": 51, "seek": 84056, "start": 854.64, "end": 861.8399999999999, "text": " manager, you should check this one out. It's awesome. I want to show you a couple of particular", "tokens": [51068, 6598, 11, 291, 820, 1520, 341, 472, 484, 13, 467, 311, 3476, 13, 286, 528, 281, 855, 291, 257, 1916, 295, 1729, 51428], "temperature": 0.0, "avg_logprob": -0.11729668154574857, "compression_ratio": 1.792828685258964, "no_speech_prob": 0.0008828260470181704}, {"id": 52, "seek": 84056, "start": 861.8399999999999, "end": 866.76, "text": " examples of how cargo semper checks finds these issues that might not be particularly", "tokens": [51428, 5110, 295, 577, 19449, 4361, 610, 13834, 10704, 613, 2663, 300, 1062, 406, 312, 4098, 51674], "temperature": 0.0, "avg_logprob": -0.11729668154574857, "compression_ratio": 1.792828685258964, "no_speech_prob": 0.0008828260470181704}, {"id": 53, "seek": 86676, "start": 866.8, "end": 873.56, "text": " obvious to the naked eye. The first example is a public function being deleted. Here we", "tokens": [50366, 6322, 281, 264, 15791, 3313, 13, 440, 700, 1365, 307, 257, 1908, 2445, 885, 22981, 13, 1692, 321, 50704], "temperature": 0.0, "avg_logprob": -0.10900149572463262, "compression_ratio": 1.715953307392996, "no_speech_prob": 0.0025502617936581373}, {"id": 54, "seek": 86676, "start": 873.56, "end": 878.04, "text": " have a crate that had this public function called add and this pull request is just coming", "tokens": [50704, 362, 257, 42426, 300, 632, 341, 1908, 2445, 1219, 909, 293, 341, 2235, 5308, 307, 445, 1348, 50928], "temperature": 0.0, "avg_logprob": -0.10900149572463262, "compression_ratio": 1.715953307392996, "no_speech_prob": 0.0025502617936581373}, {"id": 55, "seek": 86676, "start": 878.04, "end": 883.04, "text": " in and deleting that public function. This is pretty obviously a breaking change, right?", "tokens": [50928, 294, 293, 48946, 300, 1908, 2445, 13, 639, 307, 1238, 2745, 257, 7697, 1319, 11, 558, 30, 51178], "temperature": 0.0, "avg_logprob": -0.10900149572463262, "compression_ratio": 1.715953307392996, "no_speech_prob": 0.0025502617936581373}, {"id": 56, "seek": 86676, "start": 883.04, "end": 887.28, "text": " And if we run cargo semper checks, it will tell us as much as well. It will say this", "tokens": [51178, 400, 498, 321, 1190, 19449, 4361, 610, 13834, 11, 309, 486, 980, 505, 382, 709, 382, 731, 13, 467, 486, 584, 341, 51390], "temperature": 0.0, "avg_logprob": -0.10900149572463262, "compression_ratio": 1.715953307392996, "no_speech_prob": 0.0025502617936581373}, {"id": 57, "seek": 86676, "start": 887.28, "end": 891.8, "text": " function is missing, it cannot be imported by its prior path, and it will point out that", "tokens": [51390, 2445, 307, 5361, 11, 309, 2644, 312, 25524, 538, 1080, 4059, 3100, 11, 293, 309, 486, 935, 484, 300, 51616], "temperature": 0.0, "avg_logprob": -0.10900149572463262, "compression_ratio": 1.715953307392996, "no_speech_prob": 0.0025502617936581373}, {"id": 58, "seek": 89180, "start": 891.8399999999999, "end": 897.0799999999999, "text": " the problematic function is the add function in this crate at that specific line in that", "tokens": [50366, 264, 19011, 2445, 307, 264, 909, 2445, 294, 341, 42426, 412, 300, 2685, 1622, 294, 300, 50628], "temperature": 0.0, "avg_logprob": -0.09960826914361183, "compression_ratio": 1.5608695652173914, "no_speech_prob": 0.0023964911233633757}, {"id": 59, "seek": 89180, "start": 897.0799999999999, "end": 902.8399999999999, "text": " file. This is great, but you might say, okay, we would have caught this by eye, right? This", "tokens": [50628, 3991, 13, 639, 307, 869, 11, 457, 291, 1062, 584, 11, 1392, 11, 321, 576, 362, 5415, 341, 538, 3313, 11, 558, 30, 639, 50916], "temperature": 0.0, "avg_logprob": -0.09960826914361183, "compression_ratio": 1.5608695652173914, "no_speech_prob": 0.0023964911233633757}, {"id": 60, "seek": 89180, "start": 902.8399999999999, "end": 908.88, "text": " is pretty obvious. I don't need a tool here. Well, as it turns out, deletions of public", "tokens": [50916, 307, 1238, 6322, 13, 286, 500, 380, 643, 257, 2290, 510, 13, 1042, 11, 382, 309, 4523, 484, 11, 1103, 302, 626, 295, 1908, 51218], "temperature": 0.0, "avg_logprob": -0.09960826914361183, "compression_ratio": 1.5608695652173914, "no_speech_prob": 0.0023964911233633757}, {"id": 61, "seek": 89180, "start": 908.88, "end": 917.88, "text": " items are not always a major breaking change, right? One way in which that can be the case", "tokens": [51218, 4754, 366, 406, 1009, 257, 2563, 7697, 1319, 11, 558, 30, 1485, 636, 294, 597, 300, 393, 312, 264, 1389, 51668], "temperature": 0.0, "avg_logprob": -0.09960826914361183, "compression_ratio": 1.5608695652173914, "no_speech_prob": 0.0023964911233633757}, {"id": 62, "seek": 91788, "start": 917.96, "end": 922.96, "text": " is if we have that public function inside a private module. Yes, the function is public,", "tokens": [50368, 307, 498, 321, 362, 300, 1908, 2445, 1854, 257, 4551, 10088, 13, 1079, 11, 264, 2445, 307, 1908, 11, 50618], "temperature": 0.0, "avg_logprob": -0.10729357646061824, "compression_ratio": 1.8327645051194539, "no_speech_prob": 0.004069173708558083}, {"id": 63, "seek": 91788, "start": 922.96, "end": 926.88, "text": " but it's just not reachable. There's no way to import it, and so since nothing outside", "tokens": [50618, 457, 309, 311, 445, 406, 2524, 712, 13, 821, 311, 572, 636, 281, 974, 309, 11, 293, 370, 1670, 1825, 2380, 50814], "temperature": 0.0, "avg_logprob": -0.10729357646061824, "compression_ratio": 1.8327645051194539, "no_speech_prob": 0.004069173708558083}, {"id": 64, "seek": 91788, "start": 926.88, "end": 931.0, "text": " its own crate can use it, deleting that function is not a breaking change, right? There's no", "tokens": [50814, 1080, 1065, 42426, 393, 764, 309, 11, 48946, 300, 2445, 307, 406, 257, 7697, 1319, 11, 558, 30, 821, 311, 572, 51020], "temperature": 0.0, "avg_logprob": -0.10729357646061824, "compression_ratio": 1.8327645051194539, "no_speech_prob": 0.004069173708558083}, {"id": 65, "seek": 91788, "start": 931.0, "end": 936.72, "text": " possible way that anyone could be affected by that. Another more interesting example is", "tokens": [51020, 1944, 636, 300, 2878, 727, 312, 8028, 538, 300, 13, 3996, 544, 1880, 1365, 307, 51306], "temperature": 0.0, "avg_logprob": -0.10729357646061824, "compression_ratio": 1.8327645051194539, "no_speech_prob": 0.004069173708558083}, {"id": 66, "seek": 91788, "start": 936.72, "end": 940.96, "text": " when we have a public module, but that module is marked doc hidden, or if the function itself", "tokens": [51306, 562, 321, 362, 257, 1908, 10088, 11, 457, 300, 10088, 307, 12658, 3211, 7633, 11, 420, 498, 264, 2445, 2564, 51518], "temperature": 0.0, "avg_logprob": -0.10729357646061824, "compression_ratio": 1.8327645051194539, "no_speech_prob": 0.004069173708558083}, {"id": 67, "seek": 91788, "start": 940.96, "end": 944.96, "text": " is marked doc hidden. If you're not familiar with the doc hidden attribute, it's a way", "tokens": [51518, 307, 12658, 3211, 7633, 13, 759, 291, 434, 406, 4963, 365, 264, 3211, 7633, 19667, 11, 309, 311, 257, 636, 51718], "temperature": 0.0, "avg_logprob": -0.10729357646061824, "compression_ratio": 1.8327645051194539, "no_speech_prob": 0.004069173708558083}, {"id": 68, "seek": 94496, "start": 945.0400000000001, "end": 952.0400000000001, "text": " to mark a piece of your public surface area as not being part of your public API. It's", "tokens": [50368, 281, 1491, 257, 2522, 295, 428, 1908, 3753, 1859, 382, 406, 885, 644, 295, 428, 1908, 9362, 13, 467, 311, 50718], "temperature": 0.0, "avg_logprob": -0.12565074580730778, "compression_ratio": 1.7164750957854407, "no_speech_prob": 0.01825271174311638}, {"id": 69, "seek": 94496, "start": 953.08, "end": 957.72, "text": " explicitly saying these are internal implementation details that are made visible for a reason", "tokens": [50770, 20803, 1566, 613, 366, 6920, 11420, 4365, 300, 366, 1027, 8974, 337, 257, 1778, 51002], "temperature": 0.0, "avg_logprob": -0.12565074580730778, "compression_ratio": 1.7164750957854407, "no_speech_prob": 0.01825271174311638}, {"id": 70, "seek": 94496, "start": 957.72, "end": 964.22, "text": " other than being public API. These most often happen when crates have macros where they", "tokens": [51002, 661, 813, 885, 1908, 9362, 13, 1981, 881, 2049, 1051, 562, 941, 1024, 362, 7912, 2635, 689, 436, 51327], "temperature": 0.0, "avg_logprob": -0.12565074580730778, "compression_ratio": 1.7164750957854407, "no_speech_prob": 0.01825271174311638}, {"id": 71, "seek": 94496, "start": 964.22, "end": 968.76, "text": " need to expose some functionality that is only intended for use by those macros. Remember", "tokens": [51327, 643, 281, 19219, 512, 14980, 300, 307, 787, 10226, 337, 764, 538, 729, 7912, 2635, 13, 5459, 51554], "temperature": 0.0, "avg_logprob": -0.12565074580730778, "compression_ratio": 1.7164750957854407, "no_speech_prob": 0.01825271174311638}, {"id": 72, "seek": 94496, "start": 968.76, "end": 972.76, "text": " that macros get expanded in the downstream crates, and so they have to be able to access", "tokens": [51554, 300, 7912, 2635, 483, 14342, 294, 264, 30621, 941, 1024, 11, 293, 370, 436, 362, 281, 312, 1075, 281, 2105, 51754], "temperature": 0.0, "avg_logprob": -0.12565074580730778, "compression_ratio": 1.7164750957854407, "no_speech_prob": 0.01825271174311638}, {"id": 73, "seek": 97276, "start": 972.8, "end": 977.88, "text": " everything that is public in your own crate. We don't want to maintain the internal implementation", "tokens": [50366, 1203, 300, 307, 1908, 294, 428, 1065, 42426, 13, 492, 500, 380, 528, 281, 6909, 264, 6920, 11420, 50620], "temperature": 0.0, "avg_logprob": -0.10959861434508707, "compression_ratio": 1.8313253012048192, "no_speech_prob": 0.002050320850685239}, {"id": 74, "seek": 97276, "start": 977.88, "end": 984.88, "text": " details of macros as public API, so we usually mark that functionality as doc hidden. But", "tokens": [50620, 4365, 295, 7912, 2635, 382, 1908, 9362, 11, 370, 321, 2673, 1491, 300, 14980, 382, 3211, 7633, 13, 583, 50970], "temperature": 0.0, "avg_logprob": -0.10959861434508707, "compression_ratio": 1.8313253012048192, "no_speech_prob": 0.002050320850685239}, {"id": 75, "seek": 97276, "start": 984.88, "end": 988.72, "text": " it's not actually enough to say, oh, this module is doc hidden, therefore that function", "tokens": [50970, 309, 311, 406, 767, 1547, 281, 584, 11, 1954, 11, 341, 10088, 307, 3211, 7633, 11, 4412, 300, 2445, 51162], "temperature": 0.0, "avg_logprob": -0.10959861434508707, "compression_ratio": 1.8313253012048192, "no_speech_prob": 0.002050320850685239}, {"id": 76, "seek": 97276, "start": 988.72, "end": 994.36, "text": " is not public API. Here's the opposite example. We have a public module that's doc hidden", "tokens": [51162, 307, 406, 1908, 9362, 13, 1692, 311, 264, 6182, 1365, 13, 492, 362, 257, 1908, 10088, 300, 311, 3211, 7633, 51444], "temperature": 0.0, "avg_logprob": -0.10959861434508707, "compression_ratio": 1.8313253012048192, "no_speech_prob": 0.002050320850685239}, {"id": 77, "seek": 97276, "start": 994.36, "end": 999.08, "text": " and a public function inside it, and that public function is now public API. Why? Because", "tokens": [51444, 293, 257, 1908, 2445, 1854, 309, 11, 293, 300, 1908, 2445, 307, 586, 1908, 9362, 13, 1545, 30, 1436, 51680], "temperature": 0.0, "avg_logprob": -0.10959861434508707, "compression_ratio": 1.8313253012048192, "no_speech_prob": 0.002050320850685239}, {"id": 78, "seek": 99908, "start": 999.12, "end": 1005.12, "text": " it's re-exported and the re-export is not doc hidden. So users of this crate could have", "tokens": [50366, 309, 311, 319, 12, 3121, 2707, 292, 293, 264, 319, 12, 3121, 2707, 307, 406, 3211, 7633, 13, 407, 5022, 295, 341, 42426, 727, 362, 50666], "temperature": 0.0, "avg_logprob": -0.14645760014372053, "compression_ratio": 1.6943396226415095, "no_speech_prob": 0.0005526505410671234}, {"id": 79, "seek": 99908, "start": 1005.12, "end": 1010.5200000000001, "text": " imported this function without ever relying on any doc hidden functionality. So even though", "tokens": [50666, 25524, 341, 2445, 1553, 1562, 24140, 322, 604, 3211, 7633, 14980, 13, 407, 754, 1673, 50936], "temperature": 0.0, "avg_logprob": -0.14645760014372053, "compression_ratio": 1.6943396226415095, "no_speech_prob": 0.0005526505410671234}, {"id": 80, "seek": 99908, "start": 1010.5200000000001, "end": 1014.88, "text": " the module where the function is defined is doc hidden, this function is still public", "tokens": [50936, 264, 10088, 689, 264, 2445, 307, 7642, 307, 3211, 7633, 11, 341, 2445, 307, 920, 1908, 51154], "temperature": 0.0, "avg_logprob": -0.14645760014372053, "compression_ratio": 1.6943396226415095, "no_speech_prob": 0.0005526505410671234}, {"id": 81, "seek": 99908, "start": 1014.88, "end": 1020.88, "text": " API. These roles are pretty complicated, right? It's not at all unreasonable that someone", "tokens": [51154, 9362, 13, 1981, 9604, 366, 1238, 6179, 11, 558, 30, 467, 311, 406, 412, 439, 41730, 300, 1580, 51454], "temperature": 0.0, "avg_logprob": -0.14645760014372053, "compression_ratio": 1.6943396226415095, "no_speech_prob": 0.0005526505410671234}, {"id": 82, "seek": 99908, "start": 1020.88, "end": 1024.88, "text": " might mess this up, and in fact we found hundreds of issues like this when we scanned the top", "tokens": [51454, 1062, 2082, 341, 493, 11, 293, 294, 1186, 321, 1352, 6779, 295, 2663, 411, 341, 562, 321, 45089, 264, 1192, 51654], "temperature": 0.0, "avg_logprob": -0.14645760014372053, "compression_ratio": 1.6943396226415095, "no_speech_prob": 0.0005526505410671234}, {"id": 83, "seek": 102488, "start": 1024.96, "end": 1031.96, "text": " 1000 rust crates on crates I.O. Cargo-Sanver checks will catch all of these cases correctly,", "tokens": [50368, 9714, 15259, 941, 1024, 322, 941, 1024, 286, 13, 46, 13, 2741, 1571, 12, 50, 282, 331, 13834, 486, 3745, 439, 295, 613, 3331, 8944, 11, 50718], "temperature": 0.0, "avg_logprob": -0.1931386192639669, "compression_ratio": 1.5169491525423728, "no_speech_prob": 0.000709596904926002}, {"id": 84, "seek": 102488, "start": 1032.6000000000001, "end": 1036.92, "text": " so it's just a lot easier to use the tooling instead of having to rack our brains when", "tokens": [50750, 370, 309, 311, 445, 257, 688, 3571, 281, 764, 264, 46593, 2602, 295, 1419, 281, 14788, 527, 15442, 562, 50966], "temperature": 0.0, "avg_logprob": -0.1931386192639669, "compression_ratio": 1.5169491525423728, "no_speech_prob": 0.000709596904926002}, {"id": 85, "seek": 102488, "start": 1036.92, "end": 1043.5200000000002, "text": " facing a PR that we have to review. So clearly deletions of public items are not always a", "tokens": [50966, 7170, 257, 11568, 300, 321, 362, 281, 3131, 13, 407, 4448, 1103, 302, 626, 295, 1908, 4754, 366, 406, 1009, 257, 51296], "temperature": 0.0, "avg_logprob": -0.1931386192639669, "compression_ratio": 1.5169491525423728, "no_speech_prob": 0.000709596904926002}, {"id": 86, "seek": 102488, "start": 1043.5200000000002, "end": 1050.5200000000002, "text": " major breaking change. Let's dig into a second example. Here we have a public struct foo", "tokens": [51296, 2563, 7697, 1319, 13, 961, 311, 2528, 666, 257, 1150, 1365, 13, 1692, 321, 362, 257, 1908, 6594, 726, 78, 51646], "temperature": 0.0, "avg_logprob": -0.1931386192639669, "compression_ratio": 1.5169491525423728, "no_speech_prob": 0.000709596904926002}, {"id": 87, "seek": 105052, "start": 1051.52, "end": 1057.52, "text": " that has some fields, and in this pull request we're adding a new field. And the author of", "tokens": [50414, 300, 575, 512, 7909, 11, 293, 294, 341, 2235, 5308, 321, 434, 5127, 257, 777, 2519, 13, 400, 264, 3793, 295, 50714], "temperature": 0.0, "avg_logprob": -0.1725440164214199, "compression_ratio": 1.7315175097276265, "no_speech_prob": 0.0012444044696167111}, {"id": 88, "seek": 105052, "start": 1058.36, "end": 1063.28, "text": " this pull request was quite careful. They noticed that the foo struct has a constructor", "tokens": [50756, 341, 2235, 5308, 390, 1596, 5026, 13, 814, 5694, 300, 264, 726, 78, 6594, 575, 257, 47479, 51002], "temperature": 0.0, "avg_logprob": -0.1725440164214199, "compression_ratio": 1.7315175097276265, "no_speech_prob": 0.0012444044696167111}, {"id": 89, "seek": 105052, "start": 1063.28, "end": 1068.28, "text": " called new, and they made sure to not change the function signature of that constructor.", "tokens": [51002, 1219, 777, 11, 293, 436, 1027, 988, 281, 406, 1319, 264, 2445, 13397, 295, 300, 47479, 13, 51252], "temperature": 0.0, "avg_logprob": -0.1725440164214199, "compression_ratio": 1.7315175097276265, "no_speech_prob": 0.0012444044696167111}, {"id": 90, "seek": 105052, "start": 1068.28, "end": 1074.28, "text": " Instead, they initialized the new fields to default value, and this seems entirely reasonable,", "tokens": [51252, 7156, 11, 436, 5883, 1602, 264, 777, 7909, 281, 7576, 2158, 11, 293, 341, 2544, 7696, 10585, 11, 51552], "temperature": 0.0, "avg_logprob": -0.1725440164214199, "compression_ratio": 1.7315175097276265, "no_speech_prob": 0.0012444044696167111}, {"id": 91, "seek": 105052, "start": 1074.28, "end": 1079.28, "text": " right? This is a pull request that many of us would probably merge when facing it.", "tokens": [51552, 558, 30, 639, 307, 257, 2235, 5308, 300, 867, 295, 505, 576, 1391, 22183, 562, 7170, 309, 13, 51802], "temperature": 0.0, "avg_logprob": -0.1725440164214199, "compression_ratio": 1.7315175097276265, "no_speech_prob": 0.0012444044696167111}, {"id": 92, "seek": 107928, "start": 1080.28, "end": 1084.8799999999999, "text": " The falsehood here is that adding fields to a struct can only be breaking, it can only", "tokens": [50414, 440, 7908, 3809, 510, 307, 300, 5127, 7909, 281, 257, 6594, 393, 787, 312, 7697, 11, 309, 393, 787, 50644], "temperature": 0.0, "avg_logprob": -0.13435844902519709, "compression_ratio": 1.6988416988416988, "no_speech_prob": 0.0002780083450488746}, {"id": 93, "seek": 107928, "start": 1084.8799999999999, "end": 1090.8799999999999, "text": " be a breaking change via changes to methods. This is not true, right? The problem here", "tokens": [50644, 312, 257, 7697, 1319, 5766, 2962, 281, 7150, 13, 639, 307, 406, 2074, 11, 558, 30, 440, 1154, 510, 50944], "temperature": 0.0, "avg_logprob": -0.13435844902519709, "compression_ratio": 1.6988416988416988, "no_speech_prob": 0.0002780083450488746}, {"id": 94, "seek": 107928, "start": 1090.8799999999999, "end": 1095.24, "text": " is very, very non-obvious, especially to someone who came to rust from a different programming", "tokens": [50944, 307, 588, 11, 588, 2107, 12, 996, 1502, 11, 2318, 281, 1580, 567, 1361, 281, 15259, 490, 257, 819, 9410, 51162], "temperature": 0.0, "avg_logprob": -0.13435844902519709, "compression_ratio": 1.6988416988416988, "no_speech_prob": 0.0002780083450488746}, {"id": 95, "seek": 107928, "start": 1095.24, "end": 1102.24, "text": " language first, like me. The issue is that this struct is not marked non-exhaustive,", "tokens": [51162, 2856, 700, 11, 411, 385, 13, 440, 2734, 307, 300, 341, 6594, 307, 406, 12658, 2107, 12, 3121, 1641, 381, 488, 11, 51512], "temperature": 0.0, "avg_logprob": -0.13435844902519709, "compression_ratio": 1.6988416988416988, "no_speech_prob": 0.0002780083450488746}, {"id": 96, "seek": 107928, "start": 1103.16, "end": 1109.24, "text": " and all of its prior fields were public. If both of these things are true, this struct", "tokens": [51558, 293, 439, 295, 1080, 4059, 7909, 645, 1908, 13, 759, 1293, 295, 613, 721, 366, 2074, 11, 341, 6594, 51862], "temperature": 0.0, "avg_logprob": -0.13435844902519709, "compression_ratio": 1.6988416988416988, "no_speech_prob": 0.0002780083450488746}, {"id": 97, "seek": 110924, "start": 1109.24, "end": 1114.52, "text": " could be constructed with a struct literal. So users don't actually have to use this", "tokens": [50364, 727, 312, 17083, 365, 257, 6594, 20411, 13, 407, 5022, 500, 380, 767, 362, 281, 764, 341, 50628], "temperature": 0.0, "avg_logprob": -0.10955437098708108, "compression_ratio": 1.748091603053435, "no_speech_prob": 0.0006876603583805263}, {"id": 98, "seek": 110924, "start": 1114.52, "end": 1119.08, "text": " new method, they can just construct it directly by specifying all of the fields individually.", "tokens": [50628, 777, 3170, 11, 436, 393, 445, 7690, 309, 3838, 538, 1608, 5489, 439, 295, 264, 7909, 16652, 13, 50856], "temperature": 0.0, "avg_logprob": -0.10955437098708108, "compression_ratio": 1.748091603053435, "no_speech_prob": 0.0006876603583805263}, {"id": 99, "seek": 110924, "start": 1119.08, "end": 1125.36, "text": " So if a user in a downstream crate wrote something like, let value equals foo curly brace and", "tokens": [50856, 407, 498, 257, 4195, 294, 257, 30621, 42426, 4114, 746, 411, 11, 718, 2158, 6915, 726, 78, 32066, 38458, 293, 51170], "temperature": 0.0, "avg_logprob": -0.10955437098708108, "compression_ratio": 1.748091603053435, "no_speech_prob": 0.0006876603583805263}, {"id": 100, "seek": 110924, "start": 1125.36, "end": 1130.88, "text": " then listed out all of the fields, they are now broken if we add this new field. They never", "tokens": [51170, 550, 10052, 484, 439, 295, 264, 7909, 11, 436, 366, 586, 5463, 498, 321, 909, 341, 777, 2519, 13, 814, 1128, 51446], "temperature": 0.0, "avg_logprob": -0.10955437098708108, "compression_ratio": 1.748091603053435, "no_speech_prob": 0.0006876603583805263}, {"id": 101, "seek": 110924, "start": 1130.88, "end": 1136.2, "text": " specified a value for third, and so therefore this code no longer compiles. This is something", "tokens": [51446, 22206, 257, 2158, 337, 2636, 11, 293, 370, 4412, 341, 3089, 572, 2854, 715, 4680, 13, 639, 307, 746, 51712], "temperature": 0.0, "avg_logprob": -0.10955437098708108, "compression_ratio": 1.748091603053435, "no_speech_prob": 0.0006876603583805263}, {"id": 102, "seek": 113620, "start": 1136.2, "end": 1141.1200000000001, "text": " that could very, very easily sneak up on us in a pull request whether we opened it or", "tokens": [50364, 300, 727, 588, 11, 588, 3612, 13164, 493, 322, 505, 294, 257, 2235, 5308, 1968, 321, 5625, 309, 420, 50610], "temperature": 0.0, "avg_logprob": -0.1526591734452681, "compression_ratio": 1.6423357664233578, "no_speech_prob": 0.0015483502065762877}, {"id": 103, "seek": 113620, "start": 1141.1200000000001, "end": 1148.1200000000001, "text": " reviewing it, especially early in the morning when we're undercaffeinated. Right? And again,", "tokens": [50610, 19576, 309, 11, 2318, 2440, 294, 264, 2446, 562, 321, 434, 833, 496, 16349, 5410, 13, 1779, 30, 400, 797, 11, 50960], "temperature": 0.0, "avg_logprob": -0.1526591734452681, "compression_ratio": 1.6423357664233578, "no_speech_prob": 0.0015483502065762877}, {"id": 104, "seek": 113620, "start": 1149.1200000000001, "end": 1153.0, "text": " it's easier to just let cargo semper checks do the heavy lifting here. Running cargo semper", "tokens": [51010, 309, 311, 3571, 281, 445, 718, 19449, 4361, 610, 13834, 360, 264, 4676, 15798, 510, 13, 28136, 19449, 4361, 610, 51204], "temperature": 0.0, "avg_logprob": -0.1526591734452681, "compression_ratio": 1.6423357664233578, "no_speech_prob": 0.0015483502065762877}, {"id": 105, "seek": 113620, "start": 1153.0, "end": 1158.8400000000001, "text": " checks again points out the problem. It says that a struct that could be made with a literal", "tokens": [51204, 13834, 797, 2793, 484, 264, 1154, 13, 467, 1619, 300, 257, 6594, 300, 727, 312, 1027, 365, 257, 20411, 51496], "temperature": 0.0, "avg_logprob": -0.1526591734452681, "compression_ratio": 1.6423357664233578, "no_speech_prob": 0.0015483502065762877}, {"id": 106, "seek": 113620, "start": 1158.8400000000001, "end": 1163.44, "text": " has a new public field, so existing struct literals must be updated, that's a breaking", "tokens": [51496, 575, 257, 777, 1908, 2519, 11, 370, 6741, 6594, 2733, 1124, 1633, 312, 10588, 11, 300, 311, 257, 7697, 51726], "temperature": 0.0, "avg_logprob": -0.1526591734452681, "compression_ratio": 1.6423357664233578, "no_speech_prob": 0.0015483502065762877}, {"id": 107, "seek": 116344, "start": 1163.48, "end": 1170.48, "text": " change, and it even points out that foo third is the field that is problematic in this case.", "tokens": [50366, 1319, 11, 293, 309, 754, 2793, 484, 300, 726, 78, 2636, 307, 264, 2519, 300, 307, 19011, 294, 341, 1389, 13, 50716], "temperature": 0.0, "avg_logprob": -0.14947296282567016, "compression_ratio": 1.6679245283018869, "no_speech_prob": 0.0010002818889915943}, {"id": 108, "seek": 116344, "start": 1171.96, "end": 1176.04, "text": " So adding fields to a struct can sometimes be a breaking change even if we took great", "tokens": [50790, 407, 5127, 7909, 281, 257, 6594, 393, 2171, 312, 257, 7697, 1319, 754, 498, 321, 1890, 869, 50994], "temperature": 0.0, "avg_logprob": -0.14947296282567016, "compression_ratio": 1.6679245283018869, "no_speech_prob": 0.0010002818889915943}, {"id": 109, "seek": 116344, "start": 1176.04, "end": 1180.16, "text": " care to make sure that all of the methods and everything else around the struct has", "tokens": [50994, 1127, 281, 652, 988, 300, 439, 295, 264, 7150, 293, 1203, 1646, 926, 264, 6594, 575, 51200], "temperature": 0.0, "avg_logprob": -0.14947296282567016, "compression_ratio": 1.6679245283018869, "no_speech_prob": 0.0010002818889915943}, {"id": 110, "seek": 116344, "start": 1180.16, "end": 1187.16, "text": " not changed. That's another falsehood we can cross off of our list. Let's jump into a third", "tokens": [51200, 406, 3105, 13, 663, 311, 1071, 7908, 3809, 321, 393, 3278, 766, 295, 527, 1329, 13, 961, 311, 3012, 666, 257, 2636, 51550], "temperature": 0.0, "avg_logprob": -0.14947296282567016, "compression_ratio": 1.6679245283018869, "no_speech_prob": 0.0010002818889915943}, {"id": 111, "seek": 116344, "start": 1187.16, "end": 1192.6000000000001, "text": " example, and this one's probably my favorite. Here we have a private struct foo, so not", "tokens": [51550, 1365, 11, 293, 341, 472, 311, 1391, 452, 2954, 13, 1692, 321, 362, 257, 4551, 6594, 726, 78, 11, 370, 406, 51822], "temperature": 0.0, "avg_logprob": -0.14947296282567016, "compression_ratio": 1.6679245283018869, "no_speech_prob": 0.0010002818889915943}, {"id": 112, "seek": 119260, "start": 1192.6, "end": 1197.36, "text": " public, but private, and we're just changing some internal implementation details of that", "tokens": [50364, 1908, 11, 457, 4551, 11, 293, 321, 434, 445, 4473, 512, 6920, 11420, 4365, 295, 300, 50602], "temperature": 0.0, "avg_logprob": -0.14547781042150548, "compression_ratio": 1.6641509433962265, "no_speech_prob": 0.0014546929160133004}, {"id": 113, "seek": 119260, "start": 1197.36, "end": 1203.4399999999998, "text": " struct. Right? It used to take this static string reference, and we now want to support", "tokens": [50602, 6594, 13, 1779, 30, 467, 1143, 281, 747, 341, 13437, 6798, 6408, 11, 293, 321, 586, 528, 281, 1406, 50906], "temperature": 0.0, "avg_logprob": -0.14547781042150548, "compression_ratio": 1.6641509433962265, "no_speech_prob": 0.0014546929160133004}, {"id": 114, "seek": 119260, "start": 1203.4399999999998, "end": 1209.04, "text": " non-static strings. The struct is cloned, so we want to preserve cheap cloning, and", "tokens": [50906, 2107, 12, 34632, 13985, 13, 440, 6594, 307, 596, 19009, 11, 370, 321, 528, 281, 15665, 7084, 596, 16638, 11, 293, 51186], "temperature": 0.0, "avg_logprob": -0.14547781042150548, "compression_ratio": 1.6641509433962265, "no_speech_prob": 0.0014546929160133004}, {"id": 115, "seek": 119260, "start": 1209.04, "end": 1214.24, "text": " we're going to use a ref-counted string to make that happen. Right? This is fine. I would", "tokens": [51186, 321, 434, 516, 281, 764, 257, 1895, 12, 26050, 292, 6798, 281, 652, 300, 1051, 13, 1779, 30, 639, 307, 2489, 13, 286, 576, 51446], "temperature": 0.0, "avg_logprob": -0.14547781042150548, "compression_ratio": 1.6641509433962265, "no_speech_prob": 0.0014546929160133004}, {"id": 116, "seek": 119260, "start": 1214.24, "end": 1220.52, "text": " probably accept this, you know, especially in the morning undercaffeinated. The falsehood", "tokens": [51446, 1391, 3241, 341, 11, 291, 458, 11, 2318, 294, 264, 2446, 833, 496, 16349, 5410, 13, 440, 7908, 3809, 51760], "temperature": 0.0, "avg_logprob": -0.14547781042150548, "compression_ratio": 1.6641509433962265, "no_speech_prob": 0.0014546929160133004}, {"id": 117, "seek": 122052, "start": 1220.52, "end": 1224.2, "text": " here is that, you know, if I didn't touch it, I didn't break it. Right? I never touched", "tokens": [50364, 510, 307, 300, 11, 291, 458, 11, 498, 286, 994, 380, 2557, 309, 11, 286, 994, 380, 1821, 309, 13, 1779, 30, 286, 1128, 9828, 50548], "temperature": 0.0, "avg_logprob": -0.2351867130824498, "compression_ratio": 1.6219081272084805, "no_speech_prob": 0.0069028399884700775}, {"id": 118, "seek": 122052, "start": 1224.2, "end": 1228.92, "text": " public API. All of this code that I just showed you was private, and so I couldn't have broken", "tokens": [50548, 1908, 9362, 13, 1057, 295, 341, 3089, 300, 286, 445, 4712, 291, 390, 4551, 11, 293, 370, 286, 2809, 380, 362, 5463, 50784], "temperature": 0.0, "avg_logprob": -0.2351867130824498, "compression_ratio": 1.6219081272084805, "no_speech_prob": 0.0069028399884700775}, {"id": 119, "seek": 122052, "start": 1228.92, "end": 1235.92, "text": " the public API here. Right? Unfortunately, this is not true, and if we run Cargo-Semford-Checks,", "tokens": [50784, 264, 1908, 9362, 510, 13, 1779, 30, 8590, 11, 341, 307, 406, 2074, 11, 293, 498, 321, 1190, 2741, 1571, 12, 50, 443, 7404, 12, 15683, 2761, 11, 51134], "temperature": 0.0, "avg_logprob": -0.2351867130824498, "compression_ratio": 1.6219081272084805, "no_speech_prob": 0.0069028399884700775}, {"id": 120, "seek": 122052, "start": 1236.4, "end": 1240.84, "text": " it will point out the problem. It says a public type has stopped implementing one or more", "tokens": [51158, 309, 486, 935, 484, 264, 1154, 13, 467, 1619, 257, 1908, 2010, 575, 5936, 18114, 472, 420, 544, 51380], "temperature": 0.0, "avg_logprob": -0.2351867130824498, "compression_ratio": 1.6219081272084805, "no_speech_prob": 0.0069028399884700775}, {"id": 121, "seek": 122052, "start": 1240.84, "end": 1247.84, "text": " auto traits. Type bar is no longer send and is no longer sync. And you might be thinking,", "tokens": [51380, 8399, 19526, 13, 15576, 2159, 307, 572, 2854, 2845, 293, 307, 572, 2854, 20271, 13, 400, 291, 1062, 312, 1953, 11, 51730], "temperature": 0.0, "avg_logprob": -0.2351867130824498, "compression_ratio": 1.6219081272084805, "no_speech_prob": 0.0069028399884700775}, {"id": 122, "seek": 124784, "start": 1248.08, "end": 1255.08, "text": " second, what type bar? We were touching struct foo. There is no type bar here. Right? I was", "tokens": [50376, 1150, 11, 437, 2010, 2159, 30, 492, 645, 11175, 6594, 726, 78, 13, 821, 307, 572, 2010, 2159, 510, 13, 1779, 30, 286, 390, 50726], "temperature": 0.0, "avg_logprob": -0.16052913665771484, "compression_ratio": 1.6988847583643123, "no_speech_prob": 0.007344130892306566}, {"id": 123, "seek": 124784, "start": 1255.36, "end": 1260.36, "text": " code reviewing, I read all of the changes, and there's no problem. So why is Cargo-Semford-Checks", "tokens": [50740, 3089, 19576, 11, 286, 1401, 439, 295, 264, 2962, 11, 293, 456, 311, 572, 1154, 13, 407, 983, 307, 2741, 1571, 12, 50, 443, 7404, 12, 15683, 2761, 50990], "temperature": 0.0, "avg_logprob": -0.16052913665771484, "compression_ratio": 1.6988847583643123, "no_speech_prob": 0.007344130892306566}, {"id": 124, "seek": 124784, "start": 1260.36, "end": 1265.32, "text": " complaining about something that I didn't touch? Right? This must be a false positive.", "tokens": [50990, 20740, 466, 746, 300, 286, 994, 380, 2557, 30, 1779, 30, 639, 1633, 312, 257, 7908, 3353, 13, 51238], "temperature": 0.0, "avg_logprob": -0.16052913665771484, "compression_ratio": 1.6988847583643123, "no_speech_prob": 0.007344130892306566}, {"id": 125, "seek": 124784, "start": 1265.32, "end": 1269.28, "text": " Here, our tools are doing us a disservice. The problem here is not the user's change.", "tokens": [51238, 1692, 11, 527, 3873, 366, 884, 505, 257, 7802, 25006, 13, 440, 1154, 510, 307, 406, 264, 4195, 311, 1319, 13, 51436], "temperature": 0.0, "avg_logprob": -0.16052913665771484, "compression_ratio": 1.6988847583643123, "no_speech_prob": 0.007344130892306566}, {"id": 126, "seek": 124784, "start": 1269.28, "end": 1275.48, "text": " The problem is that the change affects something that is not shown in the pull request. Right?", "tokens": [51436, 440, 1154, 307, 300, 264, 1319, 11807, 746, 300, 307, 406, 4898, 294, 264, 2235, 5308, 13, 1779, 30, 51746], "temperature": 0.0, "avg_logprob": -0.16052913665771484, "compression_ratio": 1.6988847583643123, "no_speech_prob": 0.007344130892306566}, {"id": 127, "seek": 127548, "start": 1275.52, "end": 1281.16, "text": " So I didn't touch it, I didn't break it, happens to be false, because type bar isn't here.", "tokens": [50366, 407, 286, 994, 380, 2557, 309, 11, 286, 994, 380, 1821, 309, 11, 2314, 281, 312, 7908, 11, 570, 2010, 2159, 1943, 380, 510, 13, 50648], "temperature": 0.0, "avg_logprob": -0.13383133643496353, "compression_ratio": 1.7286821705426356, "no_speech_prob": 0.00037993566365912557}, {"id": 128, "seek": 127548, "start": 1281.16, "end": 1286.04, "text": " Right? You have to click this button if it happens to be in the same file in order to", "tokens": [50648, 1779, 30, 509, 362, 281, 2052, 341, 2960, 498, 309, 2314, 281, 312, 294, 264, 912, 3991, 294, 1668, 281, 50892], "temperature": 0.0, "avg_logprob": -0.13383133643496353, "compression_ratio": 1.7286821705426356, "no_speech_prob": 0.00037993566365912557}, {"id": 129, "seek": 127548, "start": 1286.04, "end": 1291.92, "text": " be able to see the problem. The problem is that struct bar is public, and its implemented", "tokens": [50892, 312, 1075, 281, 536, 264, 1154, 13, 440, 1154, 307, 300, 6594, 2159, 307, 1908, 11, 293, 1080, 12270, 51186], "temperature": 0.0, "avg_logprob": -0.13383133643496353, "compression_ratio": 1.7286821705426356, "no_speech_prob": 0.00037993566365912557}, {"id": 130, "seek": 127548, "start": 1291.92, "end": 1298.92, "text": " traits are there for public. And bar internally contains a foo. Now, an auto trait in Rust", "tokens": [51186, 19526, 366, 456, 337, 1908, 13, 400, 2159, 19501, 8306, 257, 726, 78, 13, 823, 11, 364, 8399, 22538, 294, 34952, 51536], "temperature": 0.0, "avg_logprob": -0.13383133643496353, "compression_ratio": 1.7286821705426356, "no_speech_prob": 0.00037993566365912557}, {"id": 131, "seek": 127548, "start": 1299.96, "end": 1304.88, "text": " is a trait that the compiler automatically implements for us whenever possible. The rule", "tokens": [51588, 307, 257, 22538, 300, 264, 31958, 6772, 704, 17988, 337, 505, 5699, 1944, 13, 440, 4978, 51834], "temperature": 0.0, "avg_logprob": -0.13383133643496353, "compression_ratio": 1.7286821705426356, "no_speech_prob": 0.00037993566365912557}, {"id": 132, "seek": 130488, "start": 1304.92, "end": 1310.24, "text": " is that a type implements an auto trait if all of its constituents also implement that", "tokens": [50366, 307, 300, 257, 2010, 704, 17988, 364, 8399, 22538, 498, 439, 295, 1080, 30847, 611, 4445, 300, 50632], "temperature": 0.0, "avg_logprob": -0.12119259344083126, "compression_ratio": 1.842323651452282, "no_speech_prob": 0.0006460559088736773}, {"id": 133, "seek": 130488, "start": 1310.24, "end": 1315.88, "text": " same trait. Constituents being all of the fields, all of the variants, all of the data", "tokens": [50632, 912, 22538, 13, 8574, 6380, 791, 885, 439, 295, 264, 7909, 11, 439, 295, 264, 21669, 11, 439, 295, 264, 1412, 50914], "temperature": 0.0, "avg_logprob": -0.12119259344083126, "compression_ratio": 1.842323651452282, "no_speech_prob": 0.0006460559088736773}, {"id": 134, "seek": 130488, "start": 1315.88, "end": 1322.16, "text": " that that type might contain. Right? So send and sync are these auto traits in Rust that", "tokens": [50914, 300, 300, 2010, 1062, 5304, 13, 1779, 30, 407, 2845, 293, 20271, 366, 613, 8399, 19526, 294, 34952, 300, 51228], "temperature": 0.0, "avg_logprob": -0.12119259344083126, "compression_ratio": 1.842323651452282, "no_speech_prob": 0.0006460559088736773}, {"id": 135, "seek": 130488, "start": 1322.16, "end": 1327.96, "text": " are used to express whether types are safe to be shared across threads. And the problem", "tokens": [51228, 366, 1143, 281, 5109, 1968, 3467, 366, 3273, 281, 312, 5507, 2108, 19314, 13, 400, 264, 1154, 51518], "temperature": 0.0, "avg_logprob": -0.12119259344083126, "compression_ratio": 1.842323651452282, "no_speech_prob": 0.0006460559088736773}, {"id": 136, "seek": 130488, "start": 1327.96, "end": 1334.8000000000002, "text": " that we run into here is that the static string that we used to have inside foo was both send", "tokens": [51518, 300, 321, 1190, 666, 510, 307, 300, 264, 13437, 6798, 300, 321, 1143, 281, 362, 1854, 726, 78, 390, 1293, 2845, 51860], "temperature": 0.0, "avg_logprob": -0.12119259344083126, "compression_ratio": 1.842323651452282, "no_speech_prob": 0.0006460559088736773}, {"id": 137, "seek": 133480, "start": 1334.8, "end": 1341.8, "text": " and sync at the same time. This reference counted string is neither send nor sync. Now,", "tokens": [50364, 293, 20271, 412, 264, 912, 565, 13, 639, 6408, 20150, 6798, 307, 9662, 2845, 6051, 20271, 13, 823, 11, 50714], "temperature": 0.0, "avg_logprob": -0.14194699629996588, "compression_ratio": 1.912280701754386, "no_speech_prob": 0.005299170035868883}, {"id": 138, "seek": 133480, "start": 1342.36, "end": 1349.04, "text": " since the fields value over here is no longer send nor sync, that means that struct foo", "tokens": [50742, 1670, 264, 7909, 2158, 670, 510, 307, 572, 2854, 2845, 6051, 20271, 11, 300, 1355, 300, 6594, 726, 78, 51076], "temperature": 0.0, "avg_logprob": -0.14194699629996588, "compression_ratio": 1.912280701754386, "no_speech_prob": 0.005299170035868883}, {"id": 139, "seek": 133480, "start": 1349.04, "end": 1354.84, "text": " is no longer send nor sync, that means that struct bar is no longer send nor sync. And", "tokens": [51076, 307, 572, 2854, 2845, 6051, 20271, 11, 300, 1355, 300, 6594, 2159, 307, 572, 2854, 2845, 6051, 20271, 13, 400, 51366], "temperature": 0.0, "avg_logprob": -0.14194699629996588, "compression_ratio": 1.912280701754386, "no_speech_prob": 0.005299170035868883}, {"id": 140, "seek": 133480, "start": 1354.84, "end": 1360.08, "text": " that breaks our public API. Because users that might have been using struct bar in some", "tokens": [51366, 300, 9857, 527, 1908, 9362, 13, 1436, 5022, 300, 1062, 362, 668, 1228, 6594, 2159, 294, 512, 51628], "temperature": 0.0, "avg_logprob": -0.14194699629996588, "compression_ratio": 1.912280701754386, "no_speech_prob": 0.005299170035868883}, {"id": 141, "seek": 133480, "start": 1360.08, "end": 1364.04, "text": " sort of context that relies on parallelism where that bar is shared across threads or", "tokens": [51628, 1333, 295, 4319, 300, 30910, 322, 8952, 1434, 689, 300, 2159, 307, 5507, 2108, 19314, 420, 51826], "temperature": 0.0, "avg_logprob": -0.14194699629996588, "compression_ratio": 1.912280701754386, "no_speech_prob": 0.005299170035868883}, {"id": 142, "seek": 136404, "start": 1364.08, "end": 1369.52, "text": " passed between threads, their code is now broken. So they will see an error that looks", "tokens": [50366, 4678, 1296, 19314, 11, 641, 3089, 307, 586, 5463, 13, 407, 436, 486, 536, 364, 6713, 300, 1542, 50638], "temperature": 0.0, "avg_logprob": -0.1503892486745661, "compression_ratio": 1.6306306306306306, "no_speech_prob": 0.0025500967167317867}, {"id": 143, "seek": 136404, "start": 1369.52, "end": 1376.56, "text": " like this. Rust C will say, RC of string cannot be shared between threads safely. Use parallelism", "tokens": [50638, 411, 341, 13, 34952, 383, 486, 584, 11, 28987, 295, 6798, 2644, 312, 5507, 1296, 19314, 11750, 13, 8278, 8952, 1434, 50990], "temperature": 0.0, "avg_logprob": -0.1503892486745661, "compression_ratio": 1.6306306306306306, "no_speech_prob": 0.0025500967167317867}, {"id": 144, "seek": 136404, "start": 1376.56, "end": 1383.56, "text": " requires that that value is sync and RC string is not because within bar, within foo, that", "tokens": [50990, 7029, 300, 300, 2158, 307, 20271, 293, 28987, 6798, 307, 406, 570, 1951, 2159, 11, 1951, 726, 78, 11, 300, 51340], "temperature": 0.0, "avg_logprob": -0.1503892486745661, "compression_ratio": 1.6306306306306306, "no_speech_prob": 0.0025500967167317867}, {"id": 145, "seek": 136404, "start": 1385.36, "end": 1391.0, "text": " field does not implement send and sync. This is something that has been, it's really a", "tokens": [51430, 2519, 775, 406, 4445, 2845, 293, 20271, 13, 639, 307, 746, 300, 575, 668, 11, 309, 311, 534, 257, 51712], "temperature": 0.0, "avg_logprob": -0.1503892486745661, "compression_ratio": 1.6306306306306306, "no_speech_prob": 0.0025500967167317867}, {"id": 146, "seek": 139100, "start": 1391.04, "end": 1395.48, "text": " question of time until it bites any given project. This is just kind of impossible to", "tokens": [50366, 1168, 295, 565, 1826, 309, 26030, 604, 2212, 1716, 13, 639, 307, 445, 733, 295, 6243, 281, 50588], "temperature": 0.0, "avg_logprob": -0.14034347534179686, "compression_ratio": 1.7054263565891472, "no_speech_prob": 0.011146193370223045}, {"id": 147, "seek": 139100, "start": 1395.48, "end": 1400.88, "text": " catch because the problem is just not on the pull request page. And so cargo Stanford", "tokens": [50588, 3745, 570, 264, 1154, 307, 445, 406, 322, 264, 2235, 5308, 3028, 13, 400, 370, 19449, 20374, 50858], "temperature": 0.0, "avg_logprob": -0.14034347534179686, "compression_ratio": 1.7054263565891472, "no_speech_prob": 0.011146193370223045}, {"id": 148, "seek": 139100, "start": 1400.88, "end": 1405.72, "text": " checks is just much better at finding these things than we humans are because it's looking", "tokens": [50858, 13834, 307, 445, 709, 1101, 412, 5006, 613, 721, 813, 321, 6255, 366, 570, 309, 311, 1237, 51100], "temperature": 0.0, "avg_logprob": -0.14034347534179686, "compression_ratio": 1.7054263565891472, "no_speech_prob": 0.011146193370223045}, {"id": 149, "seek": 139100, "start": 1405.72, "end": 1410.64, "text": " at the data that the compiler emits. It's not just looking at the limited pull request", "tokens": [51100, 412, 264, 1412, 300, 264, 31958, 846, 1208, 13, 467, 311, 406, 445, 1237, 412, 264, 5567, 2235, 5308, 51346], "temperature": 0.0, "avg_logprob": -0.14034347534179686, "compression_ratio": 1.7054263565891472, "no_speech_prob": 0.011146193370223045}, {"id": 150, "seek": 139100, "start": 1410.64, "end": 1416.22, "text": " review screen that we see on GitHub. So if I didn't touch it, I didn't break it is another", "tokens": [51346, 3131, 2568, 300, 321, 536, 322, 23331, 13, 407, 498, 286, 994, 380, 2557, 309, 11, 286, 994, 380, 1821, 309, 307, 1071, 51625], "temperature": 0.0, "avg_logprob": -0.14034347534179686, "compression_ratio": 1.7054263565891472, "no_speech_prob": 0.011146193370223045}, {"id": 151, "seek": 141622, "start": 1416.24, "end": 1422.24, "text": " falsehood that we get to cross off of our list. Hopefully by this point I've convinced", "tokens": [50365, 7908, 3809, 300, 321, 483, 281, 3278, 766, 295, 527, 1329, 13, 10429, 538, 341, 935, 286, 600, 12561, 50665], "temperature": 0.0, "avg_logprob": -0.16609646449579257, "compression_ratio": 1.7003891050583657, "no_speech_prob": 0.006485829595476389}, {"id": 152, "seek": 141622, "start": 1422.98, "end": 1426.46, "text": " you that cargo Stanford checks has some value and that it's likely to catch some stuff that", "tokens": [50702, 291, 300, 19449, 20374, 13834, 575, 512, 2158, 293, 300, 309, 311, 3700, 281, 3745, 512, 1507, 300, 50876], "temperature": 0.0, "avg_logprob": -0.16609646449579257, "compression_ratio": 1.7003891050583657, "no_speech_prob": 0.006485829595476389}, {"id": 153, "seek": 141622, "start": 1426.46, "end": 1431.74, "text": " we would otherwise miss and that we would find out when someone opens an issue on our", "tokens": [50876, 321, 576, 5911, 1713, 293, 300, 321, 576, 915, 484, 562, 1580, 9870, 364, 2734, 322, 527, 51140], "temperature": 0.0, "avg_logprob": -0.16609646449579257, "compression_ratio": 1.7003891050583657, "no_speech_prob": 0.006485829595476389}, {"id": 154, "seek": 141622, "start": 1431.74, "end": 1438.74, "text": " project. Now that you've seen some of the issues that it can flag, let's talk about", "tokens": [51140, 1716, 13, 823, 300, 291, 600, 1612, 512, 295, 264, 2663, 300, 309, 393, 7166, 11, 718, 311, 751, 466, 51490], "temperature": 0.0, "avg_logprob": -0.16609646449579257, "compression_ratio": 1.7003891050583657, "no_speech_prob": 0.006485829595476389}, {"id": 155, "seek": 141622, "start": 1438.78, "end": 1444.06, "text": " how this works and why you should trust what it can find. And in order to do this I want", "tokens": [51492, 577, 341, 1985, 293, 983, 291, 820, 3361, 437, 309, 393, 915, 13, 400, 294, 1668, 281, 360, 341, 286, 528, 51756], "temperature": 0.0, "avg_logprob": -0.16609646449579257, "compression_ratio": 1.7003891050583657, "no_speech_prob": 0.006485829595476389}, {"id": 156, "seek": 144406, "start": 1444.1, "end": 1448.94, "text": " to come back to this example of deleting a public function. And I want to show you specifically", "tokens": [50366, 281, 808, 646, 281, 341, 1365, 295, 48946, 257, 1908, 2445, 13, 400, 286, 528, 281, 855, 291, 4682, 50608], "temperature": 0.0, "avg_logprob": -0.15235037976000682, "compression_ratio": 1.7255813953488373, "no_speech_prob": 0.003482415108010173}, {"id": 157, "seek": 144406, "start": 1448.94, "end": 1455.06, "text": " how this works under the hood. We said that deleting a public function is a breaking change,", "tokens": [50608, 577, 341, 1985, 833, 264, 13376, 13, 492, 848, 300, 48946, 257, 1908, 2445, 307, 257, 7697, 1319, 11, 50914], "temperature": 0.0, "avg_logprob": -0.15235037976000682, "compression_ratio": 1.7255813953488373, "no_speech_prob": 0.003482415108010173}, {"id": 158, "seek": 144406, "start": 1455.06, "end": 1462.06, "text": " a major breaking change if all of the following is true. In the original version the function", "tokens": [50914, 257, 2563, 7697, 1319, 498, 439, 295, 264, 3480, 307, 2074, 13, 682, 264, 3380, 3037, 264, 2445, 51264], "temperature": 0.0, "avg_logprob": -0.15235037976000682, "compression_ratio": 1.7255813953488373, "no_speech_prob": 0.003482415108010173}, {"id": 159, "seek": 144406, "start": 1462.1399999999999, "end": 1469.1399999999999, "text": " was public. Another crate could have imported that function and used it. That import did", "tokens": [51268, 390, 1908, 13, 3996, 42426, 727, 362, 25524, 300, 2445, 293, 1143, 309, 13, 663, 974, 630, 51618], "temperature": 0.0, "avg_logprob": -0.15235037976000682, "compression_ratio": 1.7255813953488373, "no_speech_prob": 0.003482415108010173}, {"id": 160, "seek": 146914, "start": 1469.26, "end": 1476.26, "text": " not rely on any doc hidden items either on containing modules or on the item itself. And", "tokens": [50370, 406, 10687, 322, 604, 3211, 7633, 4754, 2139, 322, 19273, 16679, 420, 322, 264, 3174, 2564, 13, 400, 50720], "temperature": 0.0, "avg_logprob": -0.15722274780273438, "compression_ratio": 1.8291666666666666, "no_speech_prob": 0.004903196357190609}, {"id": 161, "seek": 146914, "start": 1476.8600000000001, "end": 1482.8600000000001, "text": " if we tried to use that same import in the newly released version that will no longer", "tokens": [50750, 498, 321, 3031, 281, 764, 300, 912, 974, 294, 264, 15109, 4736, 3037, 300, 486, 572, 2854, 51050], "temperature": 0.0, "avg_logprob": -0.15722274780273438, "compression_ratio": 1.8291666666666666, "no_speech_prob": 0.004903196357190609}, {"id": 162, "seek": 146914, "start": 1482.8600000000001, "end": 1486.6200000000001, "text": " work for any of these reasons. Either the function is no longer public or it's no longer", "tokens": [51050, 589, 337, 604, 295, 613, 4112, 13, 13746, 264, 2445, 307, 572, 2854, 1908, 420, 309, 311, 572, 2854, 51238], "temperature": 0.0, "avg_logprob": -0.15722274780273438, "compression_ratio": 1.8291666666666666, "no_speech_prob": 0.004903196357190609}, {"id": 163, "seek": 146914, "start": 1486.6200000000001, "end": 1492.1000000000001, "text": " importable or it's no longer public API. In any case that's a major breaking change.", "tokens": [51238, 974, 712, 420, 309, 311, 572, 2854, 1908, 9362, 13, 682, 604, 1389, 300, 311, 257, 2563, 7697, 1319, 13, 51512], "temperature": 0.0, "avg_logprob": -0.15722274780273438, "compression_ratio": 1.8291666666666666, "no_speech_prob": 0.004903196357190609}, {"id": 164, "seek": 146914, "start": 1492.1000000000001, "end": 1496.5400000000002, "text": " And if we're looking for all of these breaking changes of this kind it's as easy as saying", "tokens": [51512, 400, 498, 321, 434, 1237, 337, 439, 295, 613, 7697, 2962, 295, 341, 733, 309, 311, 382, 1858, 382, 1566, 51734], "temperature": 0.0, "avg_logprob": -0.15722274780273438, "compression_ratio": 1.8291666666666666, "no_speech_prob": 0.004903196357190609}, {"id": 165, "seek": 149654, "start": 1496.54, "end": 1502.82, "text": " find all functions such that all of these things are true. Now if you're thinking what", "tokens": [50364, 915, 439, 6828, 1270, 300, 439, 295, 613, 721, 366, 2074, 13, 823, 498, 291, 434, 1953, 437, 50678], "temperature": 0.0, "avg_logprob": -0.153661426744963, "compression_ratio": 1.78515625, "no_speech_prob": 0.0015009354101493955}, {"id": 166, "seek": 149654, "start": 1502.82, "end": 1509.06, "text": " I'm thinking this might sound an awful lot like a database query, right? Select all functions", "tokens": [50678, 286, 478, 1953, 341, 1062, 1626, 364, 11232, 688, 411, 257, 8149, 14581, 11, 558, 30, 13638, 439, 6828, 50990], "temperature": 0.0, "avg_logprob": -0.153661426744963, "compression_ratio": 1.78515625, "no_speech_prob": 0.0015009354101493955}, {"id": 167, "seek": 149654, "start": 1509.06, "end": 1516.06, "text": " where you know. And to help us see this I want to show you a diagram. We're looking at a", "tokens": [50990, 689, 291, 458, 13, 400, 281, 854, 505, 536, 341, 286, 528, 281, 855, 291, 257, 10686, 13, 492, 434, 1237, 412, 257, 51340], "temperature": 0.0, "avg_logprob": -0.153661426744963, "compression_ratio": 1.78515625, "no_speech_prob": 0.0015009354101493955}, {"id": 168, "seek": 149654, "start": 1516.1, "end": 1521.06, "text": " version pair, right? We have the old version on the left and the new version on the right.", "tokens": [51342, 3037, 6119, 11, 558, 30, 492, 362, 264, 1331, 3037, 322, 264, 1411, 293, 264, 777, 3037, 322, 264, 558, 13, 51590], "temperature": 0.0, "avg_logprob": -0.153661426744963, "compression_ratio": 1.78515625, "no_speech_prob": 0.0015009354101493955}, {"id": 169, "seek": 149654, "start": 1521.06, "end": 1526.5, "text": " And we're going to be looking for public functions that are importable and public API. And we're", "tokens": [51590, 400, 321, 434, 516, 281, 312, 1237, 337, 1908, 6828, 300, 366, 974, 712, 293, 1908, 9362, 13, 400, 321, 434, 51862], "temperature": 0.0, "avg_logprob": -0.153661426744963, "compression_ratio": 1.78515625, "no_speech_prob": 0.0015009354101493955}, {"id": 170, "seek": 152650, "start": 1526.5, "end": 1531.9, "text": " going to try to match them to versions in the new crates that have the same public function", "tokens": [50364, 516, 281, 853, 281, 2995, 552, 281, 9606, 294, 264, 777, 941, 1024, 300, 362, 264, 912, 1908, 2445, 50634], "temperature": 0.0, "avg_logprob": -0.10880669841059933, "compression_ratio": 1.8865546218487395, "no_speech_prob": 0.0008828552672639489}, {"id": 171, "seek": 152650, "start": 1531.9, "end": 1536.5, "text": " and the same importable path as the function that we were just looking at. And we found", "tokens": [50634, 293, 264, 912, 974, 712, 3100, 382, 264, 2445, 300, 321, 645, 445, 1237, 412, 13, 400, 321, 1352, 50864], "temperature": 0.0, "avg_logprob": -0.10880669841059933, "compression_ratio": 1.8865546218487395, "no_speech_prob": 0.0008828552672639489}, {"id": 172, "seek": 152650, "start": 1536.5, "end": 1542.18, "text": " a breaking change if the count of such matching functions and importable paths is zero. If", "tokens": [50864, 257, 7697, 1319, 498, 264, 1207, 295, 1270, 14324, 6828, 293, 974, 712, 14518, 307, 4018, 13, 759, 51148], "temperature": 0.0, "avg_logprob": -0.10880669841059933, "compression_ratio": 1.8865546218487395, "no_speech_prob": 0.0008828552672639489}, {"id": 173, "seek": 152650, "start": 1542.18, "end": 1547.42, "text": " we don't find any of them, right? So the function could be imported and used in the past and", "tokens": [51148, 321, 500, 380, 915, 604, 295, 552, 11, 558, 30, 407, 264, 2445, 727, 312, 25524, 293, 1143, 294, 264, 1791, 293, 51410], "temperature": 0.0, "avg_logprob": -0.10880669841059933, "compression_ratio": 1.8865546218487395, "no_speech_prob": 0.0008828552672639489}, {"id": 174, "seek": 152650, "start": 1547.42, "end": 1553.3, "text": " can no longer be imported and used in the current version. This is a breaking change.", "tokens": [51410, 393, 572, 2854, 312, 25524, 293, 1143, 294, 264, 2190, 3037, 13, 639, 307, 257, 7697, 1319, 13, 51704], "temperature": 0.0, "avg_logprob": -0.10880669841059933, "compression_ratio": 1.8865546218487395, "no_speech_prob": 0.0008828552672639489}, {"id": 175, "seek": 155330, "start": 1553.3, "end": 1557.94, "text": " And lo and behold, that's exactly how this works under the hood. Here's a database query", "tokens": [50364, 400, 450, 293, 27234, 11, 300, 311, 2293, 577, 341, 1985, 833, 264, 13376, 13, 1692, 311, 257, 8149, 14581, 50596], "temperature": 0.0, "avg_logprob": -0.11746734380722046, "compression_ratio": 1.722007722007722, "no_speech_prob": 0.01064841728657484}, {"id": 176, "seek": 155330, "start": 1557.94, "end": 1562.1399999999999, "text": " that does the same thing. Now the point of this talk is not the query language, so I'm", "tokens": [50596, 300, 775, 264, 912, 551, 13, 823, 264, 935, 295, 341, 751, 307, 406, 264, 14581, 2856, 11, 370, 286, 478, 50806], "temperature": 0.0, "avg_logprob": -0.11746734380722046, "compression_ratio": 1.722007722007722, "no_speech_prob": 0.01064841728657484}, {"id": 177, "seek": 155330, "start": 1562.1399999999999, "end": 1566.74, "text": " not going to dig too deep into the syntax or the semantics here, but I just want to show", "tokens": [50806, 406, 516, 281, 2528, 886, 2452, 666, 264, 28431, 420, 264, 4361, 45298, 510, 11, 457, 286, 445, 528, 281, 855, 51036], "temperature": 0.0, "avg_logprob": -0.11746734380722046, "compression_ratio": 1.722007722007722, "no_speech_prob": 0.01064841728657484}, {"id": 178, "seek": 155330, "start": 1566.74, "end": 1570.5, "text": " you that this is the exact same thing that we were just talking about. So we're looking", "tokens": [51036, 291, 300, 341, 307, 264, 1900, 912, 551, 300, 321, 645, 445, 1417, 466, 13, 407, 321, 434, 1237, 51224], "temperature": 0.0, "avg_logprob": -0.11746734380722046, "compression_ratio": 1.722007722007722, "no_speech_prob": 0.01064841728657484}, {"id": 179, "seek": 155330, "start": 1570.5, "end": 1577.5, "text": " at the baseline at the original version of the crate. We're going to be finding all functions", "tokens": [51224, 412, 264, 20518, 412, 264, 3380, 3037, 295, 264, 42426, 13, 492, 434, 516, 281, 312, 5006, 439, 6828, 51574], "temperature": 0.0, "avg_logprob": -0.11746734380722046, "compression_ratio": 1.722007722007722, "no_speech_prob": 0.01064841728657484}, {"id": 180, "seek": 157750, "start": 1577.5, "end": 1585.86, "text": " that were public that could be imported by another crate and that were public API. And", "tokens": [50364, 300, 645, 1908, 300, 727, 312, 25524, 538, 1071, 42426, 293, 300, 645, 1908, 9362, 13, 400, 50782], "temperature": 0.0, "avg_logprob": -0.1448347114381336, "compression_ratio": 1.6650717703349283, "no_speech_prob": 0.004608563147485256}, {"id": 181, "seek": 157750, "start": 1585.86, "end": 1591.58, "text": " of course we're outputting stuff for later in case we find a breaking change. And we're", "tokens": [50782, 295, 1164, 321, 434, 5598, 783, 1507, 337, 1780, 294, 1389, 321, 915, 257, 7697, 1319, 13, 400, 321, 434, 51068], "temperature": 0.0, "avg_logprob": -0.1448347114381336, "compression_ratio": 1.6650717703349283, "no_speech_prob": 0.004608563147485256}, {"id": 182, "seek": 157750, "start": 1591.58, "end": 1597.62, "text": " going to say the same import does not exist. We will count how many matching functions", "tokens": [51068, 516, 281, 584, 264, 912, 974, 775, 406, 2514, 13, 492, 486, 1207, 577, 867, 14324, 6828, 51370], "temperature": 0.0, "avg_logprob": -0.1448347114381336, "compression_ratio": 1.6650717703349283, "no_speech_prob": 0.004608563147485256}, {"id": 183, "seek": 157750, "start": 1597.62, "end": 1603.98, "text": " at the same import path we find in the new version and we will say that count is zero.", "tokens": [51370, 412, 264, 912, 974, 3100, 321, 915, 294, 264, 777, 3037, 293, 321, 486, 584, 300, 1207, 307, 4018, 13, 51688], "temperature": 0.0, "avg_logprob": -0.1448347114381336, "compression_ratio": 1.6650717703349283, "no_speech_prob": 0.004608563147485256}, {"id": 184, "seek": 160398, "start": 1603.98, "end": 1608.38, "text": " This is pretty nice, right? We get to write a piece of business logic that is completely", "tokens": [50364, 639, 307, 1238, 1481, 11, 558, 30, 492, 483, 281, 2464, 257, 2522, 295, 1606, 9952, 300, 307, 2584, 50584], "temperature": 0.0, "avg_logprob": -0.14955016544886998, "compression_ratio": 1.641025641025641, "no_speech_prob": 0.3480694890022278}, {"id": 185, "seek": 160398, "start": 1608.38, "end": 1613.14, "text": " ignorant of anything else about how we get this information. We just wrote down what", "tokens": [50584, 29374, 295, 1340, 1646, 466, 577, 321, 483, 341, 1589, 13, 492, 445, 4114, 760, 437, 50822], "temperature": 0.0, "avg_logprob": -0.14955016544886998, "compression_ratio": 1.641025641025641, "no_speech_prob": 0.3480694890022278}, {"id": 186, "seek": 160398, "start": 1613.14, "end": 1617.34, "text": " the rule is in English and then we wrote down an equivalent database query that implements", "tokens": [50822, 264, 4978, 307, 294, 3669, 293, 550, 321, 4114, 760, 364, 10344, 8149, 14581, 300, 704, 17988, 51032], "temperature": 0.0, "avg_logprob": -0.14955016544886998, "compression_ratio": 1.641025641025641, "no_speech_prob": 0.3480694890022278}, {"id": 187, "seek": 160398, "start": 1617.34, "end": 1624.6200000000001, "text": " that rule and we just called it a day. This is pretty nice. I really like this personally.", "tokens": [51032, 300, 4978, 293, 321, 445, 1219, 309, 257, 786, 13, 639, 307, 1238, 1481, 13, 286, 534, 411, 341, 5665, 13, 51396], "temperature": 0.0, "avg_logprob": -0.14955016544886998, "compression_ratio": 1.641025641025641, "no_speech_prob": 0.3480694890022278}, {"id": 188, "seek": 160398, "start": 1624.6200000000001, "end": 1629.18, "text": " And if you're interested in architecture diagram, this is roughly what it looks like. Carbis", "tokens": [51396, 400, 498, 291, 434, 3102, 294, 9482, 10686, 11, 341, 307, 9810, 437, 309, 1542, 411, 13, 2741, 65, 271, 51624], "temperature": 0.0, "avg_logprob": -0.14955016544886998, "compression_ratio": 1.641025641025641, "no_speech_prob": 0.3480694890022278}, {"id": 189, "seek": 162918, "start": 1629.26, "end": 1634.1000000000001, "text": " and Verchex sits on top. On the bottom are our data sources. We get information from", "tokens": [50368, 293, 4281, 1876, 87, 12696, 322, 1192, 13, 1282, 264, 2767, 366, 527, 1412, 7139, 13, 492, 483, 1589, 490, 50610], "temperature": 0.0, "avg_logprob": -0.2173633575439453, "compression_ratio": 1.587719298245614, "no_speech_prob": 0.4762275516986847}, {"id": 190, "seek": 162918, "start": 1634.1000000000001, "end": 1639.8600000000001, "text": " a tool called Rust doc which comes built in part of the Rust tool chain. We can ask Rust", "tokens": [50610, 257, 2290, 1219, 34952, 3211, 597, 1487, 3094, 294, 644, 295, 264, 34952, 2290, 5021, 13, 492, 393, 1029, 34952, 50898], "temperature": 0.0, "avg_logprob": -0.2173633575439453, "compression_ratio": 1.587719298245614, "no_speech_prob": 0.4762275516986847}, {"id": 191, "seek": 162918, "start": 1639.8600000000001, "end": 1647.74, "text": " doc to generate a machine readable JSON representation of the crates API and we will read that JSON", "tokens": [50898, 3211, 281, 8460, 257, 3479, 49857, 31828, 10290, 295, 264, 941, 1024, 9362, 293, 321, 486, 1401, 300, 31828, 51292], "temperature": 0.0, "avg_logprob": -0.2173633575439453, "compression_ratio": 1.587719298245614, "no_speech_prob": 0.4762275516986847}, {"id": 192, "seek": 162918, "start": 1647.74, "end": 1654.1000000000001, "text": " with Carbis and Verchex. Now Rust doc JSON's format is not stable. It changes relatively", "tokens": [51292, 365, 2741, 65, 271, 293, 4281, 1876, 87, 13, 823, 34952, 3211, 31828, 311, 7877, 307, 406, 8351, 13, 467, 2962, 7226, 51610], "temperature": 0.0, "avg_logprob": -0.2173633575439453, "compression_ratio": 1.587719298245614, "no_speech_prob": 0.4762275516986847}, {"id": 193, "seek": 165410, "start": 1654.1399999999999, "end": 1660.3, "text": " frequently more or less on every, if not every, than every other Rust release. This obviously", "tokens": [50366, 10374, 544, 420, 1570, 322, 633, 11, 498, 406, 633, 11, 813, 633, 661, 34952, 4374, 13, 639, 2745, 50674], "temperature": 0.0, "avg_logprob": -0.15516536607654816, "compression_ratio": 1.7237354085603114, "no_speech_prob": 0.008059506304562092}, {"id": 194, "seek": 165410, "start": 1660.3, "end": 1666.1799999999998, "text": " can cause some issues and it has been the source of much frustration and consternation", "tokens": [50674, 393, 3082, 512, 2663, 293, 309, 575, 668, 264, 4009, 295, 709, 20491, 293, 1817, 1248, 399, 50968], "temperature": 0.0, "avg_logprob": -0.15516536607654816, "compression_ratio": 1.7237354085603114, "no_speech_prob": 0.008059506304562092}, {"id": 195, "seek": 165410, "start": 1666.1799999999998, "end": 1672.02, "text": " with other folks that have been building Rust doc based tooling. Carbis and Verchex has", "tokens": [50968, 365, 661, 4024, 300, 362, 668, 2390, 34952, 3211, 2361, 46593, 13, 2741, 65, 271, 293, 4281, 1876, 87, 575, 51260], "temperature": 0.0, "avg_logprob": -0.15516536607654816, "compression_ratio": 1.7237354085603114, "no_speech_prob": 0.008059506304562092}, {"id": 196, "seek": 165410, "start": 1672.02, "end": 1675.82, "text": " actually managed to solve this problem. Carbis and Verchex is not the first attempt at a", "tokens": [51260, 767, 6453, 281, 5039, 341, 1154, 13, 2741, 65, 271, 293, 4281, 1876, 87, 307, 406, 264, 700, 5217, 412, 257, 51450], "temperature": 0.0, "avg_logprob": -0.15516536607654816, "compression_ratio": 1.7237354085603114, "no_speech_prob": 0.008059506304562092}, {"id": 197, "seek": 165410, "start": 1675.82, "end": 1681.4199999999998, "text": " Sembrer linter but it's the first one that managed to be isolated from changes in the", "tokens": [51450, 14421, 1443, 260, 287, 5106, 457, 309, 311, 264, 700, 472, 300, 6453, 281, 312, 14621, 490, 2962, 294, 264, 51730], "temperature": 0.0, "avg_logprob": -0.15516536607654816, "compression_ratio": 1.7237354085603114, "no_speech_prob": 0.008059506304562092}, {"id": 198, "seek": 168142, "start": 1681.42, "end": 1686.02, "text": " underlying Rust doc format. Instead of requiring that you use a specific nightly, we're actually", "tokens": [50364, 14217, 34952, 3211, 7877, 13, 7156, 295, 24165, 300, 291, 764, 257, 2685, 1818, 356, 11, 321, 434, 767, 50594], "temperature": 0.0, "avg_logprob": -0.1366869935365481, "compression_ratio": 1.6013986013986015, "no_speech_prob": 0.008184214122593403}, {"id": 199, "seek": 168142, "start": 1686.02, "end": 1691.26, "text": " able to support multiple stable Rust versions concurrently. It doesn't matter which Rust", "tokens": [50594, 1075, 281, 1406, 3866, 8351, 34952, 9606, 37702, 356, 13, 467, 1177, 380, 1871, 597, 34952, 50856], "temperature": 0.0, "avg_logprob": -0.1366869935365481, "compression_ratio": 1.6013986013986015, "no_speech_prob": 0.008184214122593403}, {"id": 200, "seek": 168142, "start": 1691.26, "end": 1696.8200000000002, "text": " doc JSON format version we get, they should work fine so long as they're reasonably recent.", "tokens": [50856, 3211, 31828, 7877, 3037, 321, 483, 11, 436, 820, 589, 2489, 370, 938, 382, 436, 434, 23551, 5162, 13, 51134], "temperature": 0.0, "avg_logprob": -0.1366869935365481, "compression_ratio": 1.6013986013986015, "no_speech_prob": 0.008184214122593403}, {"id": 201, "seek": 168142, "start": 1696.8200000000002, "end": 1701.8600000000001, "text": " And the way this works is we rely on a query engine called Trustfall to sit in between.", "tokens": [51134, 400, 264, 636, 341, 1985, 307, 321, 10687, 322, 257, 14581, 2848, 1219, 11580, 6691, 281, 1394, 294, 1296, 13, 51386], "temperature": 0.0, "avg_logprob": -0.1366869935365481, "compression_ratio": 1.6013986013986015, "no_speech_prob": 0.008184214122593403}, {"id": 202, "seek": 168142, "start": 1701.8600000000001, "end": 1706.74, "text": " Carbis and Verchex runs queries in this Trustfall language syntax that I showed you a couple", "tokens": [51386, 2741, 65, 271, 293, 4281, 1876, 87, 6676, 24109, 294, 341, 11580, 6691, 2856, 28431, 300, 286, 4712, 291, 257, 1916, 51630], "temperature": 0.0, "avg_logprob": -0.1366869935365481, "compression_ratio": 1.6013986013986015, "no_speech_prob": 0.008184214122593403}, {"id": 203, "seek": 170674, "start": 1706.78, "end": 1712.9, "text": " of slides ago. And Trustfall figures out which Rust doc JSON format version it's looking at", "tokens": [50366, 295, 9788, 2057, 13, 400, 11580, 6691, 9624, 484, 597, 34952, 3211, 31828, 7877, 3037, 309, 311, 1237, 412, 50672], "temperature": 0.0, "avg_logprob": -0.1389998197555542, "compression_ratio": 1.6814814814814816, "no_speech_prob": 0.02331581339240074}, {"id": 204, "seek": 170674, "start": 1712.9, "end": 1719.02, "text": " and uses a little shim, little adapter, a little Rust piece of code that is able to translate", "tokens": [50672, 293, 4960, 257, 707, 402, 332, 11, 707, 22860, 11, 257, 707, 34952, 2522, 295, 3089, 300, 307, 1075, 281, 13799, 50978], "temperature": 0.0, "avg_logprob": -0.1389998197555542, "compression_ratio": 1.6814814814814816, "no_speech_prob": 0.02331581339240074}, {"id": 205, "seek": 170674, "start": 1719.02, "end": 1724.34, "text": " that JSON format into something that adheres to the Trustfall schema that Carbis and Verchex", "tokens": [50978, 300, 31828, 7877, 666, 746, 300, 614, 19464, 281, 264, 11580, 6691, 34078, 300, 2741, 65, 271, 293, 4281, 1876, 87, 51244], "temperature": 0.0, "avg_logprob": -0.1389998197555542, "compression_ratio": 1.6814814814814816, "no_speech_prob": 0.02331581339240074}, {"id": 206, "seek": 170674, "start": 1724.34, "end": 1729.86, "text": " is used to. That schema is written in a fairly high level. It talks about, you know, Rust", "tokens": [51244, 307, 1143, 281, 13, 663, 34078, 307, 3720, 294, 257, 6457, 1090, 1496, 13, 467, 6686, 466, 11, 291, 458, 11, 34952, 51520], "temperature": 0.0, "avg_logprob": -0.1389998197555542, "compression_ratio": 1.6814814814814816, "no_speech_prob": 0.02331581339240074}, {"id": 207, "seek": 170674, "start": 1729.86, "end": 1734.58, "text": " functions and modules and importable path and, you know, whether things are public or", "tokens": [51520, 6828, 293, 16679, 293, 974, 712, 3100, 293, 11, 291, 458, 11, 1968, 721, 366, 1908, 420, 51756], "temperature": 0.0, "avg_logprob": -0.1389998197555542, "compression_ratio": 1.6814814814814816, "no_speech_prob": 0.02331581339240074}, {"id": 208, "seek": 173458, "start": 1734.62, "end": 1740.46, "text": " private and does not say this value is in a field named such and such and it's an object", "tokens": [50366, 4551, 293, 775, 406, 584, 341, 2158, 307, 294, 257, 2519, 4926, 1270, 293, 1270, 293, 309, 311, 364, 2657, 50658], "temperature": 0.0, "avg_logprob": -0.13198108143276638, "compression_ratio": 1.6931818181818181, "no_speech_prob": 0.0008039480890147388}, {"id": 209, "seek": 173458, "start": 1740.46, "end": 1746.3, "text": " containing the following fields and so on. So it's very unlikely to be broken by format", "tokens": [50658, 19273, 264, 3480, 7909, 293, 370, 322, 13, 407, 309, 311, 588, 17518, 281, 312, 5463, 538, 7877, 50950], "temperature": 0.0, "avg_logprob": -0.13198108143276638, "compression_ratio": 1.6931818181818181, "no_speech_prob": 0.0008039480890147388}, {"id": 210, "seek": 173458, "start": 1746.3, "end": 1752.5, "text": " changes in Rust doc because Rust today, tomorrow and next week is still going to have functions,", "tokens": [50950, 2962, 294, 34952, 3211, 570, 34952, 965, 11, 4153, 293, 958, 1243, 307, 920, 516, 281, 362, 6828, 11, 51260], "temperature": 0.0, "avg_logprob": -0.13198108143276638, "compression_ratio": 1.6931818181818181, "no_speech_prob": 0.0008039480890147388}, {"id": 211, "seek": 173458, "start": 1752.5, "end": 1756.6999999999998, "text": " modules, structs, fields and so on, right? All of that stuff doesn't really change very", "tokens": [51260, 16679, 11, 6594, 82, 11, 7909, 293, 370, 322, 11, 558, 30, 1057, 295, 300, 1507, 1177, 380, 534, 1319, 588, 51470], "temperature": 0.0, "avg_logprob": -0.13198108143276638, "compression_ratio": 1.6931818181818181, "no_speech_prob": 0.0008039480890147388}, {"id": 212, "seek": 173458, "start": 1756.6999999999998, "end": 1762.6999999999998, "text": " much. So in practice that means that we get to encapsulate all of the format specific", "tokens": [51470, 709, 13, 407, 294, 3124, 300, 1355, 300, 321, 483, 281, 38745, 5256, 439, 295, 264, 7877, 2685, 51770], "temperature": 0.0, "avg_logprob": -0.13198108143276638, "compression_ratio": 1.6931818181818181, "no_speech_prob": 0.0008039480890147388}, {"id": 213, "seek": 176270, "start": 1762.74, "end": 1768.42, "text": " logic in these adapters and nothing outside of this big ellipse at the bottom knows anything", "tokens": [50366, 9952, 294, 613, 23169, 1559, 293, 1825, 2380, 295, 341, 955, 8284, 48041, 412, 264, 2767, 3255, 1340, 50650], "temperature": 0.0, "avg_logprob": -0.12662068154047995, "compression_ratio": 1.7569721115537849, "no_speech_prob": 0.0037052263505756855}, {"id": 214, "seek": 176270, "start": 1768.42, "end": 1773.98, "text": " about how the data is represented and what format it came in. The query engine on top", "tokens": [50650, 466, 577, 264, 1412, 307, 10379, 293, 437, 7877, 309, 1361, 294, 13, 440, 14581, 2848, 322, 1192, 50928], "temperature": 0.0, "avg_logprob": -0.12662068154047995, "compression_ratio": 1.7569721115537849, "no_speech_prob": 0.0037052263505756855}, {"id": 215, "seek": 176270, "start": 1773.98, "end": 1778.8600000000001, "text": " figures out how to most efficiently run these queries that we're running and that just leaves", "tokens": [50928, 9624, 484, 577, 281, 881, 19621, 1190, 613, 24109, 300, 321, 434, 2614, 293, 300, 445, 5510, 51172], "temperature": 0.0, "avg_logprob": -0.12662068154047995, "compression_ratio": 1.7569721115537849, "no_speech_prob": 0.0037052263505756855}, {"id": 216, "seek": 176270, "start": 1778.8600000000001, "end": 1783.78, "text": " Carbis and Verchex writing business logic in this query language. Carbis and Verchex", "tokens": [51172, 2741, 65, 271, 293, 4281, 1876, 87, 3579, 1606, 9952, 294, 341, 14581, 2856, 13, 2741, 65, 271, 293, 4281, 1876, 87, 51418], "temperature": 0.0, "avg_logprob": -0.12662068154047995, "compression_ratio": 1.7569721115537849, "no_speech_prob": 0.0037052263505756855}, {"id": 217, "seek": 176270, "start": 1783.78, "end": 1788.18, "text": " only cares about this is the semver logic that we're interested in implementing and", "tokens": [51418, 787, 12310, 466, 341, 307, 264, 4361, 331, 9952, 300, 321, 434, 3102, 294, 18114, 293, 51638], "temperature": 0.0, "avg_logprob": -0.12662068154047995, "compression_ratio": 1.7569721115537849, "no_speech_prob": 0.0037052263505756855}, {"id": 218, "seek": 178818, "start": 1788.22, "end": 1795.22, "text": " everything else happens behind the scenes at a lower level in this diagram. I just want", "tokens": [50366, 1203, 1646, 2314, 2261, 264, 8026, 412, 257, 3126, 1496, 294, 341, 10686, 13, 286, 445, 528, 50716], "temperature": 0.0, "avg_logprob": -0.12526496130091544, "compression_ratio": 1.7326732673267327, "no_speech_prob": 0.0008294009603559971}, {"id": 219, "seek": 178818, "start": 1795.7, "end": 1799.1000000000001, "text": " to give you a little bit of a taste of what Trustful is in case this seems interesting", "tokens": [50740, 281, 976, 291, 257, 707, 857, 295, 257, 3939, 295, 437, 11580, 906, 307, 294, 1389, 341, 2544, 1880, 50910], "temperature": 0.0, "avg_logprob": -0.12526496130091544, "compression_ratio": 1.7326732673267327, "no_speech_prob": 0.0008294009603559971}, {"id": 220, "seek": 178818, "start": 1799.1000000000001, "end": 1804.6200000000001, "text": " to you. It's a project that I also started. It allows us to represent data as a graph and", "tokens": [50910, 281, 291, 13, 467, 311, 257, 1716, 300, 286, 611, 1409, 13, 467, 4045, 505, 281, 2906, 1412, 382, 257, 4295, 293, 51186], "temperature": 0.0, "avg_logprob": -0.12526496130091544, "compression_ratio": 1.7326732673267327, "no_speech_prob": 0.0008294009603559971}, {"id": 221, "seek": 178818, "start": 1804.6200000000001, "end": 1808.1000000000001, "text": " query any kind of data sources. So this is not something that's specific to Rust doc", "tokens": [51186, 14581, 604, 733, 295, 1412, 7139, 13, 407, 341, 307, 406, 746, 300, 311, 2685, 281, 34952, 3211, 51360], "temperature": 0.0, "avg_logprob": -0.12526496130091544, "compression_ratio": 1.7326732673267327, "no_speech_prob": 0.0008294009603559971}, {"id": 222, "seek": 178818, "start": 1808.1000000000001, "end": 1813.3400000000001, "text": " at all. It's heavily battle tested. It's been in production for more than seven years.", "tokens": [51360, 412, 439, 13, 467, 311, 10950, 4635, 8246, 13, 467, 311, 668, 294, 4265, 337, 544, 813, 3407, 924, 13, 51622], "temperature": 0.0, "avg_logprob": -0.12526496130091544, "compression_ratio": 1.7326732673267327, "no_speech_prob": 0.0008294009603559971}, {"id": 223, "seek": 178818, "start": 1813.3400000000001, "end": 1817.5800000000002, "text": " It's written in Rust. It's open source and it allows adapters to be written in a variety", "tokens": [51622, 467, 311, 3720, 294, 34952, 13, 467, 311, 1269, 4009, 293, 309, 4045, 23169, 1559, 281, 312, 3720, 294, 257, 5673, 51834], "temperature": 0.0, "avg_logprob": -0.12526496130091544, "compression_ratio": 1.7326732673267327, "no_speech_prob": 0.0008294009603559971}, {"id": 224, "seek": 181758, "start": 1817.62, "end": 1823.46, "text": " of programming languages like Rust, Python, JavaScript, WebAssembly and so on. And when", "tokens": [50366, 295, 9410, 8650, 411, 34952, 11, 15329, 11, 15778, 11, 9573, 10884, 19160, 293, 370, 322, 13, 400, 562, 50658], "temperature": 0.0, "avg_logprob": -0.12732677748709015, "compression_ratio": 1.638095238095238, "no_speech_prob": 0.002286287024617195}, {"id": 225, "seek": 181758, "start": 1823.46, "end": 1827.4199999999998, "text": " I say it can turn everything into a database, I really mean it. If you have any kind of", "tokens": [50658, 286, 584, 309, 393, 1261, 1203, 666, 257, 8149, 11, 286, 534, 914, 309, 13, 759, 291, 362, 604, 733, 295, 50856], "temperature": 0.0, "avg_logprob": -0.12732677748709015, "compression_ratio": 1.638095238095238, "no_speech_prob": 0.002286287024617195}, {"id": 226, "seek": 181758, "start": 1827.4199999999998, "end": 1831.98, "text": " data source, be it an API, a database, an arbitrary file format, a machine learning", "tokens": [50856, 1412, 4009, 11, 312, 309, 364, 9362, 11, 257, 8149, 11, 364, 23211, 3991, 7877, 11, 257, 3479, 2539, 51084], "temperature": 0.0, "avg_logprob": -0.12732677748709015, "compression_ratio": 1.638095238095238, "no_speech_prob": 0.002286287024617195}, {"id": 227, "seek": 181758, "start": 1831.98, "end": 1836.58, "text": " model, you can query it with Trustful and you can do so in place and without having", "tokens": [51084, 2316, 11, 291, 393, 14581, 309, 365, 11580, 906, 293, 291, 393, 360, 370, 294, 1081, 293, 1553, 1419, 51314], "temperature": 0.0, "avg_logprob": -0.12732677748709015, "compression_ratio": 1.638095238095238, "no_speech_prob": 0.002286287024617195}, {"id": 228, "seek": 181758, "start": 1836.58, "end": 1841.34, "text": " to do an ETL step in advance to ingest the data and then represent it in some other", "tokens": [51314, 281, 360, 364, 36953, 43, 1823, 294, 7295, 281, 3957, 377, 264, 1412, 293, 550, 2906, 309, 294, 512, 661, 51552], "temperature": 0.0, "avg_logprob": -0.12732677748709015, "compression_ratio": 1.638095238095238, "no_speech_prob": 0.002286287024617195}, {"id": 229, "seek": 181758, "start": 1841.34, "end": 1847.34, "text": " format. If you're interested in digging more into Trustful, I've given a couple of talks", "tokens": [51552, 7877, 13, 759, 291, 434, 3102, 294, 17343, 544, 666, 11580, 906, 11, 286, 600, 2212, 257, 1916, 295, 6686, 51852], "temperature": 0.0, "avg_logprob": -0.12732677748709015, "compression_ratio": 1.638095238095238, "no_speech_prob": 0.002286287024617195}, {"id": 230, "seek": 184734, "start": 1847.3799999999999, "end": 1852.62, "text": " on that specifically. I gave a talk called How to query almost everything that's a deep", "tokens": [50366, 322, 300, 4682, 13, 286, 2729, 257, 751, 1219, 1012, 281, 14581, 1920, 1203, 300, 311, 257, 2452, 50628], "temperature": 0.0, "avg_logprob": -0.14586769365796856, "compression_ratio": 1.5871886120996441, "no_speech_prob": 0.0007669592741876841}, {"id": 231, "seek": 184734, "start": 1852.62, "end": 1857.1399999999999, "text": " dive into Trustful in particular and how it works. And I also gave a performance oriented", "tokens": [50628, 9192, 666, 11580, 906, 294, 1729, 293, 577, 309, 1985, 13, 400, 286, 611, 2729, 257, 3389, 21841, 50854], "temperature": 0.0, "avg_logprob": -0.14586769365796856, "compression_ratio": 1.5871886120996441, "no_speech_prob": 0.0007669592741876841}, {"id": 232, "seek": 184734, "start": 1857.1399999999999, "end": 1862.98, "text": " talk talking about how cargo semper checks became more than 2,000 times faster by using", "tokens": [50854, 751, 1417, 466, 577, 19449, 4361, 610, 13834, 3062, 544, 813, 568, 11, 1360, 1413, 4663, 538, 1228, 51146], "temperature": 0.0, "avg_logprob": -0.14586769365796856, "compression_ratio": 1.5871886120996441, "no_speech_prob": 0.0007669592741876841}, {"id": 233, "seek": 184734, "start": 1862.98, "end": 1868.78, "text": " some new optimization opportunities that Trustful exposed at P99 last year. And if you're", "tokens": [51146, 512, 777, 19618, 4786, 300, 11580, 906, 9495, 412, 430, 8494, 1036, 1064, 13, 400, 498, 291, 434, 51436], "temperature": 0.0, "avg_logprob": -0.14586769365796856, "compression_ratio": 1.5871886120996441, "no_speech_prob": 0.0007669592741876841}, {"id": 234, "seek": 184734, "start": 1868.78, "end": 1873.3799999999999, "text": " interested in playing with Trustful yourself, we have a couple of playgrounds that you can", "tokens": [51436, 3102, 294, 2433, 365, 11580, 906, 1803, 11, 321, 362, 257, 1916, 295, 24646, 82, 300, 291, 393, 51666], "temperature": 0.0, "avg_logprob": -0.14586769365796856, "compression_ratio": 1.5871886120996441, "no_speech_prob": 0.0007669592741876841}, {"id": 235, "seek": 187338, "start": 1873.42, "end": 1879.3000000000002, "text": " check out on your laptop right now. We have a playground that uses Rustdoc JSON that uses", "tokens": [50366, 1520, 484, 322, 428, 10732, 558, 586, 13, 492, 362, 257, 24646, 300, 4960, 34952, 39966, 31828, 300, 4960, 50660], "temperature": 0.0, "avg_logprob": -0.16753490840163188, "compression_ratio": 1.6715867158671587, "no_speech_prob": 0.05104167386889458}, {"id": 236, "seek": 187338, "start": 1879.3000000000002, "end": 1884.8600000000001, "text": " the same exact code that powers cargo semper checks that lets you query popular Rust crates", "tokens": [50660, 264, 912, 1900, 3089, 300, 8674, 19449, 4361, 610, 13834, 300, 6653, 291, 14581, 3743, 34952, 941, 1024, 50938], "temperature": 0.0, "avg_logprob": -0.16753490840163188, "compression_ratio": 1.6715867158671587, "no_speech_prob": 0.05104167386889458}, {"id": 237, "seek": 187338, "start": 1884.8600000000001, "end": 1889.22, "text": " APIs and you can find all sorts of interesting things about them. And just to show that you", "tokens": [50938, 21445, 293, 291, 393, 915, 439, 7527, 295, 1880, 721, 466, 552, 13, 400, 445, 281, 855, 300, 291, 51156], "temperature": 0.0, "avg_logprob": -0.16753490840163188, "compression_ratio": 1.6715867158671587, "no_speech_prob": 0.05104167386889458}, {"id": 238, "seek": 187338, "start": 1889.22, "end": 1893.5800000000002, "text": " can query any kind of other data set as well, you can query the hack and use rest APIs as", "tokens": [51156, 393, 14581, 604, 733, 295, 661, 1412, 992, 382, 731, 11, 291, 393, 14581, 264, 10339, 293, 764, 1472, 21445, 382, 51374], "temperature": 0.0, "avg_logprob": -0.16753490840163188, "compression_ratio": 1.6715867158671587, "no_speech_prob": 0.05104167386889458}, {"id": 239, "seek": 187338, "start": 1893.5800000000002, "end": 1898.18, "text": " well with Trustful queries from your browser. And just for kicks, because Rust is awesome", "tokens": [51374, 731, 365, 11580, 906, 24109, 490, 428, 11185, 13, 400, 445, 337, 21293, 11, 570, 34952, 307, 3476, 51604], "temperature": 0.0, "avg_logprob": -0.16753490840163188, "compression_ratio": 1.6715867158671587, "no_speech_prob": 0.05104167386889458}, {"id": 240, "seek": 189818, "start": 1898.22, "end": 1903.26, "text": " like that, in these playgrounds we compile the entire Rust, we compile the entire Trustful", "tokens": [50366, 411, 300, 11, 294, 613, 24646, 82, 321, 31413, 264, 2302, 34952, 11, 321, 31413, 264, 2302, 11580, 906, 50618], "temperature": 0.0, "avg_logprob": -0.20657966411219233, "compression_ratio": 1.599264705882353, "no_speech_prob": 0.028858723118901253}, {"id": 241, "seek": 189818, "start": 1903.26, "end": 1908.0600000000002, "text": " engine to WebAssembly so all of the queries run client side in your browser. So really", "tokens": [50618, 2848, 281, 9573, 10884, 19160, 370, 439, 295, 264, 24109, 1190, 6423, 1252, 294, 428, 11185, 13, 407, 534, 50858], "temperature": 0.0, "avg_logprob": -0.20657966411219233, "compression_ratio": 1.599264705882353, "no_speech_prob": 0.028858723118901253}, {"id": 242, "seek": 189818, "start": 1908.0600000000002, "end": 1912.54, "text": " go crazy with these queries, I don't care, it's your bandwidth and your CPU, right? So", "tokens": [50858, 352, 3219, 365, 613, 24109, 11, 286, 500, 380, 1127, 11, 309, 311, 428, 23647, 293, 428, 13199, 11, 558, 30, 407, 51082], "temperature": 0.0, "avg_logprob": -0.20657966411219233, "compression_ratio": 1.599264705882353, "no_speech_prob": 0.028858723118901253}, {"id": 243, "seek": 189818, "start": 1912.54, "end": 1917.22, "text": " if you get rate limited by hacker news, it's your problem, not mine, please go ham.", "tokens": [51082, 498, 291, 483, 3314, 5567, 538, 38155, 2583, 11, 309, 311, 428, 1154, 11, 406, 3892, 11, 1767, 352, 7852, 13, 51316], "temperature": 0.0, "avg_logprob": -0.20657966411219233, "compression_ratio": 1.599264705882353, "no_speech_prob": 0.028858723118901253}, {"id": 244, "seek": 189818, "start": 1919.98, "end": 1925.6200000000001, "text": " Fundamentally, Trustful is what makes cargo semper checks possible. We need, there are", "tokens": [51454, 13493, 2466, 379, 11, 11580, 906, 307, 437, 1669, 19449, 4361, 610, 13834, 1944, 13, 492, 643, 11, 456, 366, 51736], "temperature": 0.0, "avg_logprob": -0.20657966411219233, "compression_ratio": 1.599264705882353, "no_speech_prob": 0.028858723118901253}, {"id": 245, "seek": 192562, "start": 1925.6599999999999, "end": 1932.4199999999998, "text": " hundreds of ways to break semantic versioning rules in Rust. And if we had to rewrite every", "tokens": [50366, 6779, 295, 2098, 281, 1821, 47982, 3037, 278, 4474, 294, 34952, 13, 400, 498, 321, 632, 281, 28132, 633, 50704], "temperature": 0.0, "avg_logprob": -0.14340892045394235, "compression_ratio": 1.6199095022624435, "no_speech_prob": 0.0011690356768667698}, {"id": 246, "seek": 192562, "start": 1932.4199999999998, "end": 1937.5, "text": " one of our lints, whenever the format under the hood changed, this would be completely", "tokens": [50704, 472, 295, 527, 287, 8654, 11, 5699, 264, 7877, 833, 264, 13376, 3105, 11, 341, 576, 312, 2584, 50958], "temperature": 0.0, "avg_logprob": -0.14340892045394235, "compression_ratio": 1.6199095022624435, "no_speech_prob": 0.0011690356768667698}, {"id": 247, "seek": 192562, "start": 1937.5, "end": 1944.02, "text": " infeasible. By being able to decouple the format specific logic from the query logic,", "tokens": [50958, 1536, 68, 296, 964, 13, 3146, 885, 1075, 281, 979, 263, 781, 264, 7877, 2685, 9952, 490, 264, 14581, 9952, 11, 51284], "temperature": 0.0, "avg_logprob": -0.14340892045394235, "compression_ratio": 1.6199095022624435, "no_speech_prob": 0.0011690356768667698}, {"id": 248, "seek": 192562, "start": 1944.02, "end": 1949.1799999999998, "text": " the business logic of linting semper, we can focus on linting and ergonomics and cargo semper", "tokens": [51284, 264, 1606, 9952, 295, 287, 686, 278, 4361, 610, 11, 321, 393, 1879, 322, 287, 686, 278, 293, 42735, 29884, 293, 19449, 4361, 610, 51542], "temperature": 0.0, "avg_logprob": -0.14340892045394235, "compression_ratio": 1.6199095022624435, "no_speech_prob": 0.0011690356768667698}, {"id": 249, "seek": 194918, "start": 1949.22, "end": 1955.9, "text": " checks and deal with everything else under the hood. We can take an n times m problem of n", "tokens": [50366, 13834, 293, 2028, 365, 1203, 1646, 833, 264, 13376, 13, 492, 393, 747, 364, 297, 1413, 275, 1154, 295, 297, 50700], "temperature": 0.0, "avg_logprob": -0.11860744302923029, "compression_ratio": 1.6616541353383458, "no_speech_prob": 0.08746398985385895}, {"id": 250, "seek": 194918, "start": 1955.9, "end": 1960.66, "text": " lints and m formats and turn it into an n plus m problem, which is much, much more", "tokens": [50700, 287, 8654, 293, 275, 25879, 293, 1261, 309, 666, 364, 297, 1804, 275, 1154, 11, 597, 307, 709, 11, 709, 544, 50938], "temperature": 0.0, "avg_logprob": -0.11860744302923029, "compression_ratio": 1.6616541353383458, "no_speech_prob": 0.08746398985385895}, {"id": 251, "seek": 194918, "start": 1960.66, "end": 1966.7, "text": " maintainable, especially as a free open source project. So cargo semper checks on the back", "tokens": [50938, 6909, 712, 11, 2318, 382, 257, 1737, 1269, 4009, 1716, 13, 407, 19449, 4361, 610, 13834, 322, 264, 646, 51240], "temperature": 0.0, "avg_logprob": -0.11860744302923029, "compression_ratio": 1.6616541353383458, "no_speech_prob": 0.08746398985385895}, {"id": 252, "seek": 194918, "start": 1966.7, "end": 1971.42, "text": " of Trustful has been growing fairly rapidly. We currently have 58 lints and almost every", "tokens": [51240, 295, 11580, 906, 575, 668, 4194, 6457, 12910, 13, 492, 4362, 362, 21786, 287, 8654, 293, 1920, 633, 51476], "temperature": 0.0, "avg_logprob": -0.11860744302923029, "compression_ratio": 1.6616541353383458, "no_speech_prob": 0.08746398985385895}, {"id": 253, "seek": 194918, "start": 1971.42, "end": 1976.5, "text": " new release comes with a few more. This is twice as many as a year ago and still growing", "tokens": [51476, 777, 4374, 1487, 365, 257, 1326, 544, 13, 639, 307, 6091, 382, 867, 382, 257, 1064, 2057, 293, 920, 4194, 51730], "temperature": 0.0, "avg_logprob": -0.11860744302923029, "compression_ratio": 1.6616541353383458, "no_speech_prob": 0.08746398985385895}, {"id": 254, "seek": 197650, "start": 1976.54, "end": 1982.46, "text": " quite fast. We have 32 contributors and in fact, many of the new lints that we keep adding", "tokens": [50366, 1596, 2370, 13, 492, 362, 8858, 45627, 293, 294, 1186, 11, 867, 295, 264, 777, 287, 8654, 300, 321, 1066, 5127, 50662], "temperature": 0.0, "avg_logprob": -0.12502329128304707, "compression_ratio": 1.6091549295774648, "no_speech_prob": 0.005551040172576904}, {"id": 255, "seek": 197650, "start": 1982.46, "end": 1987.02, "text": " are first time contributions, which is awesome because it means that this query language", "tokens": [50662, 366, 700, 565, 15725, 11, 597, 307, 3476, 570, 309, 1355, 300, 341, 14581, 2856, 50890], "temperature": 0.0, "avg_logprob": -0.12502329128304707, "compression_ratio": 1.6091549295774648, "no_speech_prob": 0.005551040172576904}, {"id": 256, "seek": 197650, "start": 1987.02, "end": 1993.1, "text": " is not something that is super niche and difficult to learn and is actually friendly to new folks.", "tokens": [50890, 307, 406, 746, 300, 307, 1687, 19956, 293, 2252, 281, 1466, 293, 307, 767, 9208, 281, 777, 4024, 13, 51194], "temperature": 0.0, "avg_logprob": -0.12502329128304707, "compression_ratio": 1.6091549295774648, "no_speech_prob": 0.005551040172576904}, {"id": 257, "seek": 197650, "start": 1993.1, "end": 1997.82, "text": " And most importantly, our users love us. Everybody prefers to find out about accidentally", "tokens": [51194, 400, 881, 8906, 11, 527, 5022, 959, 505, 13, 7646, 44334, 281, 915, 484, 466, 15715, 51430], "temperature": 0.0, "avg_logprob": -0.12502329128304707, "compression_ratio": 1.6091549295774648, "no_speech_prob": 0.005551040172576904}, {"id": 258, "seek": 197650, "start": 1997.82, "end": 2003.1, "text": " breaking changes before they get pushed to production and get released and then somebody", "tokens": [51430, 7697, 2962, 949, 436, 483, 9152, 281, 4265, 293, 483, 4736, 293, 550, 2618, 51694], "temperature": 0.0, "avg_logprob": -0.12502329128304707, "compression_ratio": 1.6091549295774648, "no_speech_prob": 0.005551040172576904}, {"id": 259, "seek": 200310, "start": 2003.1399999999999, "end": 2009.4199999999998, "text": " opens an issue saying, sorry, you broke my project. So hopefully by this point, I've", "tokens": [50366, 9870, 364, 2734, 1566, 11, 2597, 11, 291, 6902, 452, 1716, 13, 407, 4696, 538, 341, 935, 11, 286, 600, 50680], "temperature": 0.0, "avg_logprob": -0.14128694710908113, "compression_ratio": 1.6580882352941178, "no_speech_prob": 0.004068758338689804}, {"id": 260, "seek": 200310, "start": 2009.4199999999998, "end": 2013.8999999999999, "text": " convinced you that semantic versioning is valuable, but it's impossible without automated", "tokens": [50680, 12561, 291, 300, 47982, 3037, 278, 307, 8263, 11, 457, 309, 311, 6243, 1553, 18473, 50904], "temperature": 0.0, "avg_logprob": -0.14128694710908113, "compression_ratio": 1.6580882352941178, "no_speech_prob": 0.004068758338689804}, {"id": 261, "seek": 200310, "start": 2013.8999999999999, "end": 2019.4199999999998, "text": " help. And that cargo semper checks is a solution to this problem that has lots of happy users.", "tokens": [50904, 854, 13, 400, 300, 19449, 4361, 610, 13834, 307, 257, 3827, 281, 341, 1154, 300, 575, 3195, 295, 2055, 5022, 13, 51180], "temperature": 0.0, "avg_logprob": -0.14128694710908113, "compression_ratio": 1.6580882352941178, "no_speech_prob": 0.004068758338689804}, {"id": 262, "seek": 200310, "start": 2019.4199999999998, "end": 2023.4599999999998, "text": " So if you take nothing else away from this talk, please consider using cargo semper checks", "tokens": [51180, 407, 498, 291, 747, 1825, 1646, 1314, 490, 341, 751, 11, 1767, 1949, 1228, 19449, 4361, 610, 13834, 51382], "temperature": 0.0, "avg_logprob": -0.14128694710908113, "compression_ratio": 1.6580882352941178, "no_speech_prob": 0.004068758338689804}, {"id": 263, "seek": 200310, "start": 2023.4599999999998, "end": 2029.54, "text": " if you maintain Rust code because all of us will be better off. And if you'd like to help,", "tokens": [51382, 498, 291, 6909, 34952, 3089, 570, 439, 295, 505, 486, 312, 1101, 766, 13, 400, 498, 291, 1116, 411, 281, 854, 11, 51686], "temperature": 0.0, "avg_logprob": -0.14128694710908113, "compression_ratio": 1.6580882352941178, "no_speech_prob": 0.004068758338689804}, {"id": 264, "seek": 202954, "start": 2029.58, "end": 2033.74, "text": " you can contribute code and lints to cargo semper checks. Even though we have 58 lints", "tokens": [50366, 291, 393, 10586, 3089, 293, 287, 8654, 281, 19449, 4361, 610, 13834, 13, 2754, 1673, 321, 362, 21786, 287, 8654, 50574], "temperature": 0.0, "avg_logprob": -0.12088699638843536, "compression_ratio": 1.686335403726708, "no_speech_prob": 0.056587133556604385}, {"id": 265, "seek": 202954, "start": 2033.74, "end": 2037.78, "text": " right now, there are still dozens and hundreds more breaking changes that we still need to", "tokens": [50574, 558, 586, 11, 456, 366, 920, 18431, 293, 6779, 544, 7697, 2962, 300, 321, 920, 643, 281, 50776], "temperature": 0.0, "avg_logprob": -0.12088699638843536, "compression_ratio": 1.686335403726708, "no_speech_prob": 0.056587133556604385}, {"id": 266, "seek": 202954, "start": 2037.78, "end": 2042.7, "text": " lint for. We could really use some sponsorships free and open source projects live and die", "tokens": [50776, 287, 686, 337, 13, 492, 727, 534, 764, 512, 22593, 7640, 1737, 293, 1269, 4009, 4455, 1621, 293, 978, 51022], "temperature": 0.0, "avg_logprob": -0.12088699638843536, "compression_ratio": 1.686335403726708, "no_speech_prob": 0.056587133556604385}, {"id": 267, "seek": 202954, "start": 2042.7, "end": 2048.38, "text": " by GitHub sponsors. So if you or your company use cargo semper checks, please consider sponsoring", "tokens": [51022, 538, 23331, 22593, 13, 407, 498, 291, 420, 428, 2237, 764, 19449, 4361, 610, 13834, 11, 1767, 1949, 30311, 51306], "temperature": 0.0, "avg_logprob": -0.12088699638843536, "compression_ratio": 1.686335403726708, "no_speech_prob": 0.056587133556604385}, {"id": 268, "seek": 202954, "start": 2048.38, "end": 2054.22, "text": " our development. And finally, for the sake of everyone in the Rust community, please try", "tokens": [51306, 527, 3250, 13, 400, 2721, 11, 337, 264, 9717, 295, 1518, 294, 264, 34952, 1768, 11, 1767, 853, 51598], "temperature": 0.0, "avg_logprob": -0.12088699638843536, "compression_ratio": 1.686335403726708, "no_speech_prob": 0.056587133556604385}, {"id": 269, "seek": 202954, "start": 2054.22, "end": 2058.54, "text": " to not push out breaking changes. Nobody will blame you for it, but it's a lot more fun", "tokens": [51598, 281, 406, 2944, 484, 7697, 2962, 13, 9297, 486, 10127, 291, 337, 309, 11, 457, 309, 311, 257, 688, 544, 1019, 51814], "temperature": 0.0, "avg_logprob": -0.12088699638843536, "compression_ratio": 1.686335403726708, "no_speech_prob": 0.056587133556604385}, {"id": 270, "seek": 205854, "start": 2058.54, "end": 2064.58, "text": " if you find them before you release the crate as opposed to after you release the crate.", "tokens": [50364, 498, 291, 915, 552, 949, 291, 4374, 264, 42426, 382, 8851, 281, 934, 291, 4374, 264, 42426, 13, 50666], "temperature": 0.0, "avg_logprob": -0.27336334652370875, "compression_ratio": 1.5979899497487438, "no_speech_prob": 0.011495291255414486}, {"id": 271, "seek": 205854, "start": 2064.58, "end": 2068.46, "text": " So please check out cargo semper checks. Please find me in the hallway if you'd like to chat", "tokens": [50666, 407, 1767, 1520, 484, 19449, 4361, 610, 13834, 13, 2555, 915, 385, 294, 264, 23903, 498, 291, 1116, 411, 281, 5081, 50860], "temperature": 0.0, "avg_logprob": -0.27336334652370875, "compression_ratio": 1.5979899497487438, "no_speech_prob": 0.011495291255414486}, {"id": 272, "seek": 205854, "start": 2068.46, "end": 2070.66, "text": " more. And thank you so much for your time.", "tokens": [50860, 544, 13, 400, 1309, 291, 370, 709, 337, 428, 565, 13, 50970], "temperature": 0.0, "avg_logprob": -0.27336334652370875, "compression_ratio": 1.5979899497487438, "no_speech_prob": 0.011495291255414486}, {"id": 273, "seek": 205854, "start": 2070.66, "end": 2083.82, "text": " So I think, do we have time for questions? Yeah, how long?", "tokens": [50970, 407, 286, 519, 11, 360, 321, 362, 565, 337, 1651, 30, 865, 11, 577, 938, 30, 51628], "temperature": 0.0, "avg_logprob": -0.27336334652370875, "compression_ratio": 1.5979899497487438, "no_speech_prob": 0.011495291255414486}, {"id": 274, "seek": 205854, "start": 2083.82, "end": 2085.54, "text": " Five minutes.", "tokens": [51628, 9436, 2077, 13, 51714], "temperature": 0.0, "avg_logprob": -0.27336334652370875, "compression_ratio": 1.5979899497487438, "no_speech_prob": 0.011495291255414486}, {"id": 275, "seek": 205854, "start": 2085.54, "end": 2086.54, "text": " So let's open it up.", "tokens": [51714, 407, 718, 311, 1269, 309, 493, 13, 51764], "temperature": 0.0, "avg_logprob": -0.27336334652370875, "compression_ratio": 1.5979899497487438, "no_speech_prob": 0.011495291255414486}, {"id": 276, "seek": 208654, "start": 2087.54, "end": 2091.54, "text": " I'm going to give you the mic so that people on the industry can also hear.", "tokens": [50414, 286, 478, 516, 281, 976, 291, 264, 3123, 370, 300, 561, 322, 264, 3518, 393, 611, 1568, 13, 50614], "temperature": 0.0, "avg_logprob": -0.27106293126156455, "compression_ratio": 1.6619718309859155, "no_speech_prob": 0.1237550750374794}, {"id": 277, "seek": 208654, "start": 2091.54, "end": 2098.14, "text": " Awesome, thank you. So one of the things that I know about semantic versioning is that", "tokens": [50614, 10391, 11, 1309, 291, 13, 407, 472, 295, 264, 721, 300, 286, 458, 466, 47982, 3037, 278, 307, 300, 50944], "temperature": 0.0, "avg_logprob": -0.27106293126156455, "compression_ratio": 1.6619718309859155, "no_speech_prob": 0.1237550750374794}, {"id": 278, "seek": 208654, "start": 2098.14, "end": 2103.3, "text": " version zero is, it's an interesting one. And you didn't talk about it at all, but", "tokens": [50944, 3037, 4018, 307, 11, 309, 311, 364, 1880, 472, 13, 400, 291, 994, 380, 751, 466, 309, 412, 439, 11, 457, 51202], "temperature": 0.0, "avg_logprob": -0.27106293126156455, "compression_ratio": 1.6619718309859155, "no_speech_prob": 0.1237550750374794}, {"id": 279, "seek": 208654, "start": 2103.3, "end": 2108.54, "text": " it also notes on the page that there was a lot of version zero. So I was wondering about", "tokens": [51202, 309, 611, 5570, 322, 264, 3028, 300, 456, 390, 257, 688, 295, 3037, 4018, 13, 407, 286, 390, 6359, 466, 51464], "temperature": 0.0, "avg_logprob": -0.27106293126156455, "compression_ratio": 1.6619718309859155, "no_speech_prob": 0.1237550750374794}, {"id": 280, "seek": 208654, "start": 2108.54, "end": 2109.54, "text": " your opinion on it.", "tokens": [51464, 428, 4800, 322, 309, 13, 51514], "temperature": 0.0, "avg_logprob": -0.27106293126156455, "compression_ratio": 1.6619718309859155, "no_speech_prob": 0.1237550750374794}, {"id": 281, "seek": 210954, "start": 2109.54, "end": 2116.74, "text": " Yeah, that's a good question. The question was, is version zero special in Rust? The", "tokens": [50364, 865, 11, 300, 311, 257, 665, 1168, 13, 440, 1168, 390, 11, 307, 3037, 4018, 2121, 294, 34952, 30, 440, 50724], "temperature": 0.0, "avg_logprob": -0.12816695447237986, "compression_ratio": 1.748, "no_speech_prob": 0.006092292256653309}, {"id": 282, "seek": 210954, "start": 2116.74, "end": 2122.3, "text": " semper specification and the Rust community have diverged on what version zero means,", "tokens": [50724, 4361, 610, 31256, 293, 264, 34952, 1768, 362, 18558, 3004, 322, 437, 3037, 4018, 1355, 11, 51002], "temperature": 0.0, "avg_logprob": -0.12816695447237986, "compression_ratio": 1.748, "no_speech_prob": 0.006092292256653309}, {"id": 283, "seek": 210954, "start": 2122.3, "end": 2127.46, "text": " essentially. So the semantic versioning is about communication, right? So it's about", "tokens": [51002, 4476, 13, 407, 264, 47982, 3037, 278, 307, 466, 6101, 11, 558, 30, 407, 309, 311, 466, 51260], "temperature": 0.0, "avg_logprob": -0.12816695447237986, "compression_ratio": 1.748, "no_speech_prob": 0.006092292256653309}, {"id": 284, "seek": 210954, "start": 2127.46, "end": 2132.3, "text": " the norms that are accepted in the community rather than a fixed and rigid set of rules.", "tokens": [51260, 264, 24357, 300, 366, 9035, 294, 264, 1768, 2831, 813, 257, 6806, 293, 22195, 992, 295, 4474, 13, 51502], "temperature": 0.0, "avg_logprob": -0.12816695447237986, "compression_ratio": 1.748, "no_speech_prob": 0.006092292256653309}, {"id": 285, "seek": 210954, "start": 2132.3, "end": 2138.1, "text": " And in the Rust community, we've decided that leftmost, you know, any zeros on the left-hand", "tokens": [51502, 400, 294, 264, 34952, 1768, 11, 321, 600, 3047, 300, 1411, 1761, 11, 291, 458, 11, 604, 35193, 322, 264, 1411, 12, 5543, 51792], "temperature": 0.0, "avg_logprob": -0.12816695447237986, "compression_ratio": 1.748, "no_speech_prob": 0.006092292256653309}, {"id": 286, "seek": 213810, "start": 2138.1, "end": 2142.9, "text": " side of the version kind of don't count. So version zero dot five to version zero dot", "tokens": [50364, 1252, 295, 264, 3037, 733, 295, 500, 380, 1207, 13, 407, 3037, 4018, 5893, 1732, 281, 3037, 4018, 5893, 50604], "temperature": 0.0, "avg_logprob": -0.13117415625769813, "compression_ratio": 1.8893617021276596, "no_speech_prob": 0.04205571860074997}, {"id": 287, "seek": 213810, "start": 2142.9, "end": 2148.62, "text": " six counts as a major change, right? And zero dot zero dot one to zero dot zero dot two", "tokens": [50604, 2309, 14893, 382, 257, 2563, 1319, 11, 558, 30, 400, 4018, 5893, 4018, 5893, 472, 281, 4018, 5893, 4018, 5893, 732, 50890], "temperature": 0.0, "avg_logprob": -0.13117415625769813, "compression_ratio": 1.8893617021276596, "no_speech_prob": 0.04205571860074997}, {"id": 288, "seek": 213810, "start": 2148.62, "end": 2156.66, "text": " is also a major change, right? This in practice is what keeps all of us sane because otherwise", "tokens": [50890, 307, 611, 257, 2563, 1319, 11, 558, 30, 639, 294, 3124, 307, 437, 5965, 439, 295, 505, 45610, 570, 5911, 51292], "temperature": 0.0, "avg_logprob": -0.13117415625769813, "compression_ratio": 1.8893617021276596, "no_speech_prob": 0.04205571860074997}, {"id": 289, "seek": 213810, "start": 2156.66, "end": 2161.3399999999997, "text": " if zero dot x to any zero dot y could ship any breaking change, then all projects would", "tokens": [51292, 498, 4018, 5893, 2031, 281, 604, 4018, 5893, 288, 727, 5374, 604, 7697, 1319, 11, 550, 439, 4455, 576, 51526], "temperature": 0.0, "avg_logprob": -0.13117415625769813, "compression_ratio": 1.8893617021276596, "no_speech_prob": 0.04205571860074997}, {"id": 290, "seek": 213810, "start": 2161.3399999999997, "end": 2165.66, "text": " always, you know, stay on zero dot x and then cargo update would still not work and not", "tokens": [51526, 1009, 11, 291, 458, 11, 1754, 322, 4018, 5893, 2031, 293, 550, 19449, 5623, 576, 920, 406, 589, 293, 406, 51742], "temperature": 0.0, "avg_logprob": -0.13117415625769813, "compression_ratio": 1.8893617021276596, "no_speech_prob": 0.04205571860074997}, {"id": 291, "seek": 216566, "start": 2165.66, "end": 2170.2999999999997, "text": " be able to bump us. So this is from a point of pragmatism for the sake of the community", "tokens": [50364, 312, 1075, 281, 9961, 505, 13, 407, 341, 307, 490, 257, 935, 295, 33394, 15677, 1434, 337, 264, 9717, 295, 264, 1768, 50596], "temperature": 0.0, "avg_logprob": -0.17921594176629577, "compression_ratio": 1.6738197424892705, "no_speech_prob": 0.026313774287700653}, {"id": 292, "seek": 216566, "start": 2170.2999999999997, "end": 2172.66, "text": " as opposed to some rigid system of rules.", "tokens": [50596, 382, 8851, 281, 512, 22195, 1185, 295, 4474, 13, 50714], "temperature": 0.0, "avg_logprob": -0.17921594176629577, "compression_ratio": 1.6738197424892705, "no_speech_prob": 0.026313774287700653}, {"id": 293, "seek": 216566, "start": 2172.66, "end": 2174.66, "text": " Thanks.", "tokens": [50714, 2561, 13, 50814], "temperature": 0.0, "avg_logprob": -0.17921594176629577, "compression_ratio": 1.6738197424892705, "no_speech_prob": 0.026313774287700653}, {"id": 294, "seek": 216566, "start": 2174.66, "end": 2184.66, "text": " Like you said, some changes can be intentionally breaking semper. Is there a way to annotate", "tokens": [50814, 1743, 291, 848, 11, 512, 2962, 393, 312, 22062, 7697, 4361, 610, 13, 1119, 456, 257, 636, 281, 25339, 473, 51314], "temperature": 0.0, "avg_logprob": -0.17921594176629577, "compression_ratio": 1.6738197424892705, "no_speech_prob": 0.026313774287700653}, {"id": 295, "seek": 216566, "start": 2184.66, "end": 2188.98, "text": " them so the tool knows or do you have to bypass the tool in these cases?", "tokens": [51314, 552, 370, 264, 2290, 3255, 420, 360, 291, 362, 281, 24996, 264, 2290, 294, 613, 3331, 30, 51530], "temperature": 0.0, "avg_logprob": -0.17921594176629577, "compression_ratio": 1.6738197424892705, "no_speech_prob": 0.026313774287700653}, {"id": 296, "seek": 216566, "start": 2188.98, "end": 2193.58, "text": " Great question. So the question is, since some changes might be intentionally breaking", "tokens": [51530, 3769, 1168, 13, 407, 264, 1168, 307, 11, 1670, 512, 2962, 1062, 312, 22062, 7697, 51760], "temperature": 0.0, "avg_logprob": -0.17921594176629577, "compression_ratio": 1.6738197424892705, "no_speech_prob": 0.026313774287700653}, {"id": 297, "seek": 219358, "start": 2193.58, "end": 2197.66, "text": " semper, is there a good way to annotate them so that users can notice them in a way that", "tokens": [50364, 4361, 610, 11, 307, 456, 257, 665, 636, 281, 25339, 473, 552, 370, 300, 5022, 393, 3449, 552, 294, 257, 636, 300, 50568], "temperature": 0.0, "avg_logprob": -0.11937424174526282, "compression_ratio": 1.6389891696750902, "no_speech_prob": 0.14403310418128967}, {"id": 298, "seek": 219358, "start": 2197.66, "end": 2204.5, "text": " is not going to break their CI? Unfortunately, there's not a lot of great tooling here. Obviously,", "tokens": [50568, 307, 406, 516, 281, 1821, 641, 37777, 30, 8590, 11, 456, 311, 406, 257, 688, 295, 869, 46593, 510, 13, 7580, 11, 50910], "temperature": 0.0, "avg_logprob": -0.11937424174526282, "compression_ratio": 1.6389891696750902, "no_speech_prob": 0.14403310418128967}, {"id": 299, "seek": 219358, "start": 2204.5, "end": 2209.02, "text": " we have things like change logs. Authors will usually post on, you know, their social media", "tokens": [50910, 321, 362, 721, 411, 1319, 20820, 13, 40231, 830, 486, 2673, 2183, 322, 11, 291, 458, 11, 641, 2093, 3021, 51136], "temperature": 0.0, "avg_logprob": -0.11937424174526282, "compression_ratio": 1.6389891696750902, "no_speech_prob": 0.14403310418128967}, {"id": 300, "seek": 219358, "start": 2209.02, "end": 2213.42, "text": " pages and things like that. They will try to get the word out. It's very rare for a", "tokens": [51136, 7183, 293, 721, 411, 300, 13, 814, 486, 853, 281, 483, 264, 1349, 484, 13, 467, 311, 588, 5892, 337, 257, 51356], "temperature": 0.0, "avg_logprob": -0.11937424174526282, "compression_ratio": 1.6389891696750902, "no_speech_prob": 0.14403310418128967}, {"id": 301, "seek": 219358, "start": 2213.42, "end": 2219.1, "text": " maintainer to deem something so critical that it justifies an intentional semper violation", "tokens": [51356, 6909, 260, 281, 368, 443, 746, 370, 4924, 300, 309, 445, 11221, 364, 21935, 4361, 610, 22840, 51640], "temperature": 0.0, "avg_logprob": -0.11937424174526282, "compression_ratio": 1.6389891696750902, "no_speech_prob": 0.14403310418128967}, {"id": 302, "seek": 221910, "start": 2219.3399999999997, "end": 2225.06, "text": " and yet just kind of tell nobody about it. But we don't have great tooling that will say,", "tokens": [50376, 293, 1939, 445, 733, 295, 980, 5079, 466, 309, 13, 583, 321, 500, 380, 362, 869, 46593, 300, 486, 584, 11, 50662], "temperature": 0.0, "avg_logprob": -0.16326942443847656, "compression_ratio": 1.6581818181818182, "no_speech_prob": 0.33417683839797974}, {"id": 303, "seek": 221910, "start": 2225.06, "end": 2229.18, "text": " hey, by the way, this is intentionally breaking because of reasons x, y, and z that you should", "tokens": [50662, 4177, 11, 538, 264, 636, 11, 341, 307, 22062, 7697, 570, 295, 4112, 2031, 11, 288, 11, 293, 710, 300, 291, 820, 50868], "temperature": 0.0, "avg_logprob": -0.16326942443847656, "compression_ratio": 1.6581818181818182, "no_speech_prob": 0.33417683839797974}, {"id": 304, "seek": 221910, "start": 2229.18, "end": 2234.7799999999997, "text": " read up on. It would be lovely if we could sort of mark the item so that when it gets", "tokens": [50868, 1401, 493, 322, 13, 467, 576, 312, 7496, 498, 321, 727, 1333, 295, 1491, 264, 3174, 370, 300, 562, 309, 2170, 51148], "temperature": 0.0, "avg_logprob": -0.16326942443847656, "compression_ratio": 1.6581818181818182, "no_speech_prob": 0.33417683839797974}, {"id": 305, "seek": 221910, "start": 2234.7799999999997, "end": 2239.46, "text": " used then it causes a breaking change. We got a custom error message printed out by Rust", "tokens": [51148, 1143, 550, 309, 7700, 257, 7697, 1319, 13, 492, 658, 257, 2375, 6713, 3636, 13567, 484, 538, 34952, 51382], "temperature": 0.0, "avg_logprob": -0.16326942443847656, "compression_ratio": 1.6581818181818182, "no_speech_prob": 0.33417683839797974}, {"id": 306, "seek": 221910, "start": 2239.46, "end": 2245.22, "text": " C that says this is why this is happening and this is how you go about fixing it. Unfortunately,", "tokens": [51382, 383, 300, 1619, 341, 307, 983, 341, 307, 2737, 293, 341, 307, 577, 291, 352, 466, 19442, 309, 13, 8590, 11, 51670], "temperature": 0.0, "avg_logprob": -0.16326942443847656, "compression_ratio": 1.6581818181818182, "no_speech_prob": 0.33417683839797974}, {"id": 307, "seek": 224522, "start": 2245.2599999999998, "end": 2249.74, "text": " we're not there yet. And the answer is more code needs to be written and more financial", "tokens": [50366, 321, 434, 406, 456, 1939, 13, 400, 264, 1867, 307, 544, 3089, 2203, 281, 312, 3720, 293, 544, 4669, 50590], "temperature": 0.0, "avg_logprob": -0.21786892204953914, "compression_ratio": 1.5093167701863355, "no_speech_prob": 0.015952665358781815}, {"id": 308, "seek": 224522, "start": 2249.74, "end": 2252.3799999999997, "text": " support needs to go into all of these projects for that to happen.", "tokens": [50590, 1406, 2203, 281, 352, 666, 439, 295, 613, 4455, 337, 300, 281, 1051, 13, 50722], "temperature": 0.0, "avg_logprob": -0.21786892204953914, "compression_ratio": 1.5093167701863355, "no_speech_prob": 0.015952665358781815}, {"id": 309, "seek": 224522, "start": 2252.3799999999997, "end": 2269.7, "text": " Is there any work going on integrating these tooling into packaging like Debian or which", "tokens": [50722, 1119, 456, 604, 589, 516, 322, 26889, 613, 46593, 666, 16836, 411, 1346, 20196, 420, 597, 51588], "temperature": 0.0, "avg_logprob": -0.21786892204953914, "compression_ratio": 1.5093167701863355, "no_speech_prob": 0.015952665358781815}, {"id": 310, "seek": 226970, "start": 2269.8599999999997, "end": 2272.06, "text": " suffer from these problems once in a while?", "tokens": [50372, 9753, 490, 613, 2740, 1564, 294, 257, 1339, 30, 50482], "temperature": 0.0, "avg_logprob": -0.18887898416230173, "compression_ratio": 1.7533783783783783, "no_speech_prob": 0.16313162446022034}, {"id": 311, "seek": 226970, "start": 2272.06, "end": 2277.8599999999997, "text": " Yeah, great question. The question was whether there's any work ongoing to integrate something", "tokens": [50482, 865, 11, 869, 1168, 13, 440, 1168, 390, 1968, 456, 311, 604, 589, 10452, 281, 13365, 746, 50772], "temperature": 0.0, "avg_logprob": -0.18887898416230173, "compression_ratio": 1.7533783783783783, "no_speech_prob": 0.16313162446022034}, {"id": 312, "seek": 226970, "start": 2277.8599999999997, "end": 2282.3799999999997, "text": " like Cargo-Sanverchex into the broader packaging tools that we already use on a daily basis.", "tokens": [50772, 411, 2741, 1571, 12, 50, 282, 331, 1876, 87, 666, 264, 13227, 16836, 3873, 300, 321, 1217, 764, 322, 257, 5212, 5143, 13, 50998], "temperature": 0.0, "avg_logprob": -0.18887898416230173, "compression_ratio": 1.7533783783783783, "no_speech_prob": 0.16313162446022034}, {"id": 313, "seek": 226970, "start": 2282.3799999999997, "end": 2287.7, "text": " The answer is yes. So I've been in close contact with the cargo team. They actually reached out", "tokens": [50998, 440, 1867, 307, 2086, 13, 407, 286, 600, 668, 294, 1998, 3385, 365, 264, 19449, 1469, 13, 814, 767, 6488, 484, 51264], "temperature": 0.0, "avg_logprob": -0.18887898416230173, "compression_ratio": 1.7533783783783783, "no_speech_prob": 0.16313162446022034}, {"id": 314, "seek": 226970, "start": 2287.7, "end": 2292.9399999999996, "text": " and asked if it would be feasible to work toward integrating Cargo-Sanverchex into cargo itself", "tokens": [51264, 293, 2351, 498, 309, 576, 312, 26648, 281, 589, 7361, 26889, 2741, 1571, 12, 50, 282, 331, 1876, 87, 666, 19449, 2564, 51526], "temperature": 0.0, "avg_logprob": -0.18887898416230173, "compression_ratio": 1.7533783783783783, "no_speech_prob": 0.16313162446022034}, {"id": 315, "seek": 226970, "start": 2292.9399999999996, "end": 2298.62, "text": " so that instead of running Cargo-Sanverchex, then Cargo publish, you just run Cargo publish and", "tokens": [51526, 370, 300, 2602, 295, 2614, 2741, 1571, 12, 50, 282, 331, 1876, 87, 11, 550, 2741, 1571, 11374, 11, 291, 445, 1190, 2741, 1571, 11374, 293, 51810], "temperature": 0.0, "avg_logprob": -0.18887898416230173, "compression_ratio": 1.7533783783783783, "no_speech_prob": 0.16313162446022034}, {"id": 316, "seek": 229862, "start": 2298.66, "end": 2304.14, "text": " Cargo tells you whether, you know, what it found. This is obviously a little bit tricky.", "tokens": [50366, 2741, 1571, 5112, 291, 1968, 11, 291, 458, 11, 437, 309, 1352, 13, 639, 307, 2745, 257, 707, 857, 12414, 13, 50640], "temperature": 0.0, "avg_logprob": -0.12241028917246852, "compression_ratio": 1.6925925925925926, "no_speech_prob": 0.0031707282178103924}, {"id": 317, "seek": 229862, "start": 2304.14, "end": 2310.3399999999997, "text": " It's not super straightforward for a couple of reasons. One is that when things get merged into", "tokens": [50640, 467, 311, 406, 1687, 15325, 337, 257, 1916, 295, 4112, 13, 1485, 307, 300, 562, 721, 483, 36427, 666, 50950], "temperature": 0.0, "avg_logprob": -0.12241028917246852, "compression_ratio": 1.6925925925925926, "no_speech_prob": 0.0031707282178103924}, {"id": 318, "seek": 229862, "start": 2310.3399999999997, "end": 2314.02, "text": " cargo, they're stable and they're stable forever. So we want to make sure that the APIs that we", "tokens": [50950, 19449, 11, 436, 434, 8351, 293, 436, 434, 8351, 5680, 13, 407, 321, 528, 281, 652, 988, 300, 264, 21445, 300, 321, 51134], "temperature": 0.0, "avg_logprob": -0.12241028917246852, "compression_ratio": 1.6925925925925926, "no_speech_prob": 0.0031707282178103924}, {"id": 319, "seek": 229862, "start": 2314.02, "end": 2318.62, "text": " expose are really good and that the right API is not just for now and for next year,", "tokens": [51134, 19219, 366, 534, 665, 293, 300, 264, 558, 9362, 307, 406, 445, 337, 586, 293, 337, 958, 1064, 11, 51364], "temperature": 0.0, "avg_logprob": -0.12241028917246852, "compression_ratio": 1.6925925925925926, "no_speech_prob": 0.0031707282178103924}, {"id": 320, "seek": 229862, "start": 2318.62, "end": 2324.7799999999997, "text": " but for the next 10, 20, 50 years. The second thing is that we want to make sure that users", "tokens": [51364, 457, 337, 264, 958, 1266, 11, 945, 11, 2625, 924, 13, 440, 1150, 551, 307, 300, 321, 528, 281, 652, 988, 300, 5022, 51672], "temperature": 0.0, "avg_logprob": -0.12241028917246852, "compression_ratio": 1.6925925925925926, "no_speech_prob": 0.0031707282178103924}, {"id": 321, "seek": 232478, "start": 2324.82, "end": 2331.1400000000003, "text": " can always override what Cargo-Sanverchex has found, right? Because there are these cases where", "tokens": [50366, 393, 1009, 42321, 437, 2741, 1571, 12, 50, 282, 331, 1876, 87, 575, 1352, 11, 558, 30, 1436, 456, 366, 613, 3331, 689, 50682], "temperature": 0.0, "avg_logprob": -0.15544522603352864, "compression_ratio": 1.6714801444043321, "no_speech_prob": 0.013217371888458729}, {"id": 322, "seek": 232478, "start": 2331.1400000000003, "end": 2336.38, "text": " an intentional Semver violation is justified. We want to have a workflow that's kind of like", "tokens": [50682, 364, 21935, 14421, 331, 22840, 307, 27808, 13, 492, 528, 281, 362, 257, 20993, 300, 311, 733, 295, 411, 50944], "temperature": 0.0, "avg_logprob": -0.15544522603352864, "compression_ratio": 1.6714801444043321, "no_speech_prob": 0.013217371888458729}, {"id": 323, "seek": 232478, "start": 2336.38, "end": 2343.0600000000004, "text": " Cargo publish dash dash allow dirty, where Cargo publish will normally not allow you to do that,", "tokens": [50944, 2741, 1571, 11374, 8240, 8240, 2089, 9360, 11, 689, 2741, 1571, 11374, 486, 5646, 406, 2089, 291, 281, 360, 300, 11, 51278], "temperature": 0.0, "avg_logprob": -0.15544522603352864, "compression_ratio": 1.6714801444043321, "no_speech_prob": 0.013217371888458729}, {"id": 324, "seek": 232478, "start": 2343.0600000000004, "end": 2347.34, "text": " but there is a way to override and say, I know what I'm doing, I've thought about it,", "tokens": [51278, 457, 456, 307, 257, 636, 281, 42321, 293, 584, 11, 286, 458, 437, 286, 478, 884, 11, 286, 600, 1194, 466, 309, 11, 51492], "temperature": 0.0, "avg_logprob": -0.15544522603352864, "compression_ratio": 1.6714801444043321, "no_speech_prob": 0.013217371888458729}, {"id": 325, "seek": 232478, "start": 2347.34, "end": 2352.34, "text": " and this is still the right thing to do. So we really want to make sure that we dial in the", "tokens": [51492, 293, 341, 307, 920, 264, 558, 551, 281, 360, 13, 407, 321, 534, 528, 281, 652, 988, 300, 321, 5502, 294, 264, 51742], "temperature": 0.0, "avg_logprob": -0.15544522603352864, "compression_ratio": 1.6714801444043321, "no_speech_prob": 0.013217371888458729}, {"id": 326, "seek": 235234, "start": 2352.38, "end": 2356.82, "text": " exact user experience that is the right thing for everyone in the ecosystem and that we can", "tokens": [50366, 1900, 4195, 1752, 300, 307, 264, 558, 551, 337, 1518, 294, 264, 11311, 293, 300, 321, 393, 50588], "temperature": 0.0, "avg_logprob": -0.22175966776334322, "compression_ratio": 1.6072874493927125, "no_speech_prob": 0.008538958616554737}, {"id": 327, "seek": 235234, "start": 2356.82, "end": 2362.1800000000003, "text": " support in the long run before we go about integrating it. But long story short, yes,", "tokens": [50588, 1406, 294, 264, 938, 1190, 949, 321, 352, 466, 26889, 309, 13, 583, 938, 1657, 2099, 11, 2086, 11, 50856], "temperature": 0.0, "avg_logprob": -0.22175966776334322, "compression_ratio": 1.6072874493927125, "no_speech_prob": 0.008538958616554737}, {"id": 328, "seek": 235234, "start": 2362.1800000000003, "end": 2366.86, "text": " the work on this is ongoing and again, it's a function of how quickly we can get this work done", "tokens": [50856, 264, 589, 322, 341, 307, 10452, 293, 797, 11, 309, 311, 257, 2445, 295, 577, 2661, 321, 393, 483, 341, 589, 1096, 51090], "temperature": 0.0, "avg_logprob": -0.22175966776334322, "compression_ratio": 1.6072874493927125, "no_speech_prob": 0.008538958616554737}, {"id": 329, "seek": 235234, "start": 2366.86, "end": 2369.46, "text": " in order to make it happen.", "tokens": [51090, 294, 1668, 281, 652, 309, 1051, 13, 51220], "temperature": 0.0, "avg_logprob": -0.22175966776334322, "compression_ratio": 1.6072874493927125, "no_speech_prob": 0.008538958616554737}, {"id": 330, "seek": 235234, "start": 2369.46, "end": 2380.6600000000003, "text": " Okay, so last one. Okay, so let me give you the mic. So I'm interested in trustful. Do you know", "tokens": [51220, 1033, 11, 370, 1036, 472, 13, 1033, 11, 370, 718, 385, 976, 291, 264, 3123, 13, 407, 286, 478, 3102, 294, 3361, 906, 13, 1144, 291, 458, 51780], "temperature": 0.0, "avg_logprob": -0.22175966776334322, "compression_ratio": 1.6072874493927125, "no_speech_prob": 0.008538958616554737}, {"id": 331, "seek": 238066, "start": 2380.7, "end": 2385.8199999999997, "text": " if there are other applications such as I'm thinking about validating breaking changes in", "tokens": [50366, 498, 456, 366, 661, 5821, 1270, 382, 286, 478, 1953, 466, 7363, 990, 7697, 2962, 294, 50622], "temperature": 0.0, "avg_logprob": -0.14997667879671664, "compression_ratio": 1.6285714285714286, "no_speech_prob": 0.004513621795922518}, {"id": 332, "seek": 238066, "start": 2385.8199999999997, "end": 2393.22, "text": " open API definitions, for example? Yes, great question. I would love to chat. The question was", "tokens": [50622, 1269, 9362, 21988, 11, 337, 1365, 30, 1079, 11, 869, 1168, 13, 286, 576, 959, 281, 5081, 13, 440, 1168, 390, 50992], "temperature": 0.0, "avg_logprob": -0.14997667879671664, "compression_ratio": 1.6285714285714286, "no_speech_prob": 0.004513621795922518}, {"id": 333, "seek": 238066, "start": 2393.22, "end": 2399.8199999999997, "text": " if trustful has other applications besides Cargo-Sanverchex, the answer is yes. This is", "tokens": [50992, 498, 3361, 906, 575, 661, 5821, 11868, 2741, 1571, 12, 50, 282, 331, 1876, 87, 11, 264, 1867, 307, 2086, 13, 639, 307, 51322], "temperature": 0.0, "avg_logprob": -0.14997667879671664, "compression_ratio": 1.6285714285714286, "no_speech_prob": 0.004513621795922518}, {"id": 334, "seek": 238066, "start": 2399.8199999999997, "end": 2404.02, "text": " something I'm very interested in chatting about. So if anyone else has this question,", "tokens": [51322, 746, 286, 478, 588, 3102, 294, 24654, 466, 13, 407, 498, 2878, 1646, 575, 341, 1168, 11, 51532], "temperature": 0.0, "avg_logprob": -0.14997667879671664, "compression_ratio": 1.6285714285714286, "no_speech_prob": 0.004513621795922518}, {"id": 335, "seek": 238066, "start": 2404.02, "end": 2409.94, "text": " please find me in the hallway and I can show you some more demos. A few other linters are looking", "tokens": [51532, 1767, 915, 385, 294, 264, 23903, 293, 286, 393, 855, 291, 512, 544, 33788, 13, 316, 1326, 661, 287, 35388, 366, 1237, 51828], "temperature": 0.0, "avg_logprob": -0.14997667879671664, "compression_ratio": 1.6285714285714286, "no_speech_prob": 0.004513621795922518}, {"id": 336, "seek": 240994, "start": 2409.94, "end": 2416.26, "text": " into trustful for designing custom lints. I'm also working on a Python semantic versioning", "tokens": [50364, 666, 3361, 906, 337, 14685, 2375, 287, 8654, 13, 286, 478, 611, 1364, 322, 257, 15329, 47982, 3037, 278, 50680], "temperature": 0.0, "avg_logprob": -0.18096616656281228, "compression_ratio": 1.578512396694215, "no_speech_prob": 0.011140020564198494}, {"id": 337, "seek": 240994, "start": 2416.26, "end": 2422.14, "text": " linter. Python is a very interesting beast because it's much more dynamic, so Semver is pretty", "tokens": [50680, 287, 5106, 13, 15329, 307, 257, 588, 1880, 13464, 570, 309, 311, 709, 544, 8546, 11, 370, 14421, 331, 307, 1238, 50974], "temperature": 0.0, "avg_logprob": -0.18096616656281228, "compression_ratio": 1.578512396694215, "no_speech_prob": 0.011140020564198494}, {"id": 338, "seek": 240994, "start": 2422.14, "end": 2429.26, "text": " tricky there. And my former employer actually uses trustful to enforce code standards that are not", "tokens": [50974, 12414, 456, 13, 400, 452, 5819, 16205, 767, 4960, 3361, 906, 281, 24825, 3089, 7787, 300, 366, 406, 51330], "temperature": 0.0, "avg_logprob": -0.18096616656281228, "compression_ratio": 1.578512396694215, "no_speech_prob": 0.011140020564198494}, {"id": 339, "seek": 240994, "start": 2429.26, "end": 2434.3, "text": " just correctness, but they're just about best practices that the company has decided are supposed", "tokens": [51330, 445, 3006, 1287, 11, 457, 436, 434, 445, 466, 1151, 7525, 300, 264, 2237, 575, 3047, 366, 3442, 51582], "temperature": 0.0, "avg_logprob": -0.18096616656281228, "compression_ratio": 1.578512396694215, "no_speech_prob": 0.011140020564198494}, {"id": 340, "seek": 243430, "start": 2434.34, "end": 2440.7000000000003, "text": " to happen. In fact, one of the talks that I put on the slide, this how to query almost everything", "tokens": [50366, 281, 1051, 13, 682, 1186, 11, 472, 295, 264, 6686, 300, 286, 829, 322, 264, 4137, 11, 341, 577, 281, 14581, 1920, 1203, 50684], "temperature": 0.0, "avg_logprob": -0.15549699250642243, "compression_ratio": 1.6618181818181819, "no_speech_prob": 0.333848774433136}, {"id": 341, "seek": 243430, "start": 2440.7000000000003, "end": 2446.54, "text": " has a specific example of linting Python applications that get deployed and looking for", "tokens": [50684, 575, 257, 2685, 1365, 295, 287, 686, 278, 15329, 5821, 300, 483, 17826, 293, 1237, 337, 50976], "temperature": 0.0, "avg_logprob": -0.15549699250642243, "compression_ratio": 1.6618181818181819, "no_speech_prob": 0.333848774433136}, {"id": 342, "seek": 243430, "start": 2446.54, "end": 2451.54, "text": " mismatches in the Python version declared in the project manifest in a pyproject.toml file", "tokens": [50976, 23220, 852, 279, 294, 264, 15329, 3037, 15489, 294, 264, 1716, 10067, 294, 257, 10664, 4318, 1020, 13, 83, 298, 75, 3991, 51226], "temperature": 0.0, "avg_logprob": -0.15549699250642243, "compression_ratio": 1.6618181818181819, "no_speech_prob": 0.333848774433136}, {"id": 343, "seek": 243430, "start": 2451.54, "end": 2456.38, "text": " versus the Kubernetes configuration in the Docker file that goes with it, which also says,", "tokens": [51226, 5717, 264, 23145, 11694, 294, 264, 33772, 3991, 300, 1709, 365, 309, 11, 597, 611, 1619, 11, 51468], "temperature": 0.0, "avg_logprob": -0.15549699250642243, "compression_ratio": 1.6618181818181819, "no_speech_prob": 0.333848774433136}, {"id": 344, "seek": 243430, "start": 2456.38, "end": 2462.3, "text": " you know, from Python 3 colon 8 or whatever. It turns out that we can query for what does", "tokens": [51468, 291, 458, 11, 490, 15329, 805, 8255, 1649, 420, 2035, 13, 467, 4523, 484, 300, 321, 393, 14581, 337, 437, 775, 51764], "temperature": 0.0, "avg_logprob": -0.15549699250642243, "compression_ratio": 1.6618181818181819, "no_speech_prob": 0.333848774433136}, {"id": 345, "seek": 246230, "start": 2462.3, "end": 2466.0600000000004, "text": " the Docker think the Python version is, what does the manifest think the Python version is and", "tokens": [50364, 264, 33772, 519, 264, 15329, 3037, 307, 11, 437, 775, 264, 10067, 519, 264, 15329, 3037, 307, 293, 50552], "temperature": 0.0, "avg_logprob": -0.21911804397384843, "compression_ratio": 1.592783505154639, "no_speech_prob": 0.0018022229196503758}, {"id": 346, "seek": 246230, "start": 2466.0600000000004, "end": 2471.02, "text": " find cases where they don't match. And spoiler alert, I mean, we found hundreds of these issues", "tokens": [50552, 915, 3331, 689, 436, 500, 380, 2995, 13, 400, 26927, 9615, 11, 286, 914, 11, 321, 1352, 6779, 295, 613, 2663, 50800], "temperature": 0.0, "avg_logprob": -0.21911804397384843, "compression_ratio": 1.592783505154639, "no_speech_prob": 0.0018022229196503758}, {"id": 347, "seek": 246230, "start": 2471.02, "end": 2474.38, "text": " when we rolled out those tools. These things just happen.", "tokens": [50800, 562, 321, 14306, 484, 729, 3873, 13, 1981, 721, 445, 1051, 13, 50968], "temperature": 0.0, "avg_logprob": -0.21911804397384843, "compression_ratio": 1.592783505154639, "no_speech_prob": 0.0018022229196503758}, {"id": 348, "seek": 246230, "start": 2474.38, "end": 2477.7000000000003, "text": " Great. Thank you very much.", "tokens": [50968, 3769, 13, 1044, 291, 588, 709, 13, 51134], "temperature": 0.0, "avg_logprob": -0.21911804397384843, "compression_ratio": 1.592783505154639, "no_speech_prob": 0.0018022229196503758}, {"id": 349, "seek": 246230, "start": 2477.7000000000003, "end": 2479.26, "text": " Thank you so much for having me.", "tokens": [51134, 1044, 291, 370, 709, 337, 1419, 385, 13, 51212], "temperature": 0.0, "avg_logprob": -0.21911804397384843, "compression_ratio": 1.592783505154639, "no_speech_prob": 0.0018022229196503758}], "language": "en"}