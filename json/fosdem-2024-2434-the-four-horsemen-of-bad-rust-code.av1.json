{"text": " Let me do a quick survey. Who has a JavaScript background? Okay, maybe like 10%. Who has a C background? C++? Holy hell. It's like 80% for the people on stream. Who has a Python background? What are you, Paulie Glotz? What's going on? 70% or so. Any other languages? Just scream out. I heard something like, it was something like, oh, but I can't really remember. Does anyone own this book? I found this book on my attic and it was kind of peculiar because it had some arcane cantations in it and it looked like magic, but it certainly had something to do with Rust. And I was really excited. I was really enticed by this book. This is why I want to talk about that book. It was pretty old. There was one section in there which I really liked and it was called the Four Horsemen of Bad Rust Code. This is what this talk is about. Before we get into what the Four Horsemen are, I would like to introduce myself. I'm Matthias. I live in D\u00fcsseldorf in Germany. I've been doing Rust since around 2015. I do Rust for a living as a consultant. I did a Rust YouTube channel a long, long time ago called Hello Rust. Only 10 episodes, but well, what can you do? And lately I started a podcast called Rust in Production. If you like what I say in this talk, maybe you also want to subscribe to the podcast later on. That's it for the advertisement, going back to the Four Horsemen. I thought about this title a lot. Why would you talk about Bad Rust Code? I think from my experience as a Rust consultant, I see patterns evolving over time. I see people doing the same things in Rust that they do in other languages. They repeat the same mistakes and I saw that no one really talked about those problems. That is an issue when you come from a different language and you try to learn the rustic way, the idiomatic way to write Rust code. This is what this talk is about. Let me present to you the antagonists. While I do that, try to picture yourself. Imagine who you are and what you think your role would be in this talk. The first horseman is this. Actually, let me show all of them. And the first one is ignorance. What is ignorance? Magical little term. We will get to that in the next slide. And we have excessive abstraction, premature optimization, and omission. Of course, you could add your own personal Rust horseman. And these are just very subjective, but these are the things that I see in the real world. Now that we introduced the antagonists, let's go through their anti-patterns and what they are famous for one by one, starting with ignorance or ignorance. The horseman that is behind this pattern is someone that uses stringy type APIs. You have seen it before. Someone uses a string where they could have used an enum or they don't really embrace pattern matching. And that makes APIs brittle. You are in a situation where if you refactor something, you might run risk of forgetting that you changed something or maybe you make a typo and then your string is incorrect. And so it doesn't represent what you want to represent. They also freely mutate variables. They go and say, yeah, this is state and I can change it. Rust has the mud keyword for this, but they do that liberally across the entire code base, which makes reasoning on a local scope very, very hard. They also use bad or no error handling. We will get to that in a second. They use unwraps a lot and they don't really think about the error conditions of your application. They also have a lack of architecture in their applications. And they use a general prototype style language of writing Rust code. And where do they come from? Usually those are people that were administrators before or they write shell scripts or they come from other languages like scripting languages. And this is what they know. Nothing wrong with that, but they haven't fully embraced what Rust is capable to offer. How do you discover that you belong to this group in the code? Well, if you do things like this, you have highly imperative code. You go through the code and then you tell the program, hey, do this, do that, do this, do that, instead of using, for example, a declarative way of describing what the stage should be. They also use magic return values like minus one or an empty string to represent a certain special value instead of using errors. Everything is a string. Unwrap is used freely. You clone all the things and you use the mod keyword. Why is cloning a bad thing? I don't think it is. But the problem with clone is that you maybe don't buy into the Rust model of ownership and borrowing. And that means that you bring what you learned from the past from other languages to Rust and at some point you run into issues with your architecture which you cannot easily resolve anymore. And this is why clone is kind of a stop sign. It's not a warning sign, but it should make you think for a moment. It's an indicator of structural problems in your code, if you like. Okay. With that out of the way, let's make it a little more practical. How could we maybe put this into practice and improve our code step by step? Imagine you wanted to calculate prices for different cities for a bunch of hotels that you have in these cities. For example, imagine this was a map. This is an actual map, by the way. Africa does not look like this. And also, Jerusalem is not the center of the world. I mean, we can debate about that, but certainly geographically there are some issues with this map. Imagine your input looked something like this. It's a CSV file. You get a hotel name, a city, a date, a room type, and a price. And you go through this file line by line and you try to parse it into something that looks like that. For Brussels, you have a minimum hotel price of 40 bucks, a mean price of 80, and a maximum price of 150. Fun fact, I arrived yesterday not having a hotel room because I thought I booked a hotel, but it was last year. So I was in the upper range here. Thanks, Walshbeng, by the way, for sharing your room with me. Otherwise, they would have been a nightmare. If you wanted to parse the input file and create a result like this, all you have to do is write this code. That's the entire code. Nothing really big going on here. There are some peculiarities, but this is usually what someone would write who would say Rust is not their first language. Maybe they just try to port whatever they had in another language to Rust. This is code that I see them doing. What you do is you read the CSV file, then you create a hash map of cities, then you iterate over each hotel, you try to parse the data by splitting each line, you extract fields from it, you parse the price, and then you update the city. Updating the city happens somewhere in the lower end. At the end of it, you print the mean, the max, and the minimum. That's it. That's the entire code. You know, it's working. Technically, you could run this code and it will produce the result that you expect. Prices for different cities, we're done, right? Unless we think about the bigger picture and the demons and the monsters that are out there out in the ocean, and they can haunt us and bite us. There's dangerous beasts out there, killer animals. I think what you want to do is improve that code a little bit. How can we make this code a little more idiomatic? This is the same code. Now, let's look at some parts that I personally wouldn't want to have. Consider this block. There's some things going on, but overall, it's a very manual way, a very imperative way of going through the list of hotels. We literally have a couple if conditions here. If price is smaller than city data zero and so on, we update the price, yada, yada, yada. There are patterns that make that a little nicer to read in Rust. This is the same code. It's just something very similar, but we kind of manage to shrink it down a little bit. In comparison to what we had before, we get city data and then we use some sort of tuple extraction to get the mean at a minimum and the max. That makes things a little easier. We can suddenly talk about mean instead of city data zero, for example. That's not the major problem with this code. There's unwraps too in here. Well, for a first prototype, that might work fine, but later on, maybe you don't want to have that. What if you cannot open the hotel's CSV file? What if you cannot parse a price? In this case, the entire program just stops. A question of design, but I would say if there's a single line that is invalid, you probably don't want to stop the execution right away. Another problem is that we index into the memory right away. Who tells us that a line has that many entries, five entries? It might have three. It might have zero. Who knows? But if we index into something that doesn't exist, the program will panic and that is kind of a bad thing. The underscores mean that the variables are not used, so we can remove them. We have a little bit of a cleaner structure and a simple way to check that a line is valid would be to just have this manual check in there. I know it's not very sophisticated, but it helps us along the way. Now we check if the hotel data length is five and if it is not, we just skip the entry. Let's look at parsing for a second. How do we want to handle parsing? I said that maybe we don't want to stop the execution when we run into an issue and we can do that in Rust by matching on the parse result. A very simple way to do that would be to say match price dot parse and if we have an okay value, we take it and if we have an error, we don't really care about the error. We just print an error on standard error and then we continue with the rest of the parsing. Looking at the input, one thing we can do as well is apply a similar pattern and introduce a result type. Now we use a box for representing a result type. This is because you don't need anything, any external library to have a result type that has an error type which can be literally anything. So it can be a string, anything that implements error, the error trade. In this case, it's a very simple way to improve your Rust code. It's a good first step. What we do instead now is we say read to string and then we map the error in case we have an error to something that a user could understand and act on. Then yeah, the code is already a little cleaner. We handled a few error cases already and this is something that might pass a first iteration of a review cycle. Now of course there are certain other issues with this code. For example, CSV handling. CSV is tricky. Proper handling of delimiters is very hard. For example, you might have an entry which has semicolons like on the left side here or you have something that has quotes around a semicolon and you probably want to handle that. So a simple string split does not suffice. Same with encodings. On what platform are we operating on? Do we know the encoding right away? Does the CSV file contain headlines or no headlines? And there's many, many caveats like that. If you're interested, there's a talk called stop using CSV. I don't say you should stop using CSV, but I say you should start watching this talk because it's really good. Right. How can we introduce types? I talked about types a lot and Rust is great with types. We should use more of them. Here's a simple way. I already talked about the result type and in the first line we just create an alias for our result and we say it's anything that has a T where T is generic and the error type is of type box d\u00fcn stet error. And then we can use the result in our code to make it a little easier to read. As well, we introduce a hotel struct and we have a couple fields, just strings and floating points at this point. But this helps us make the code a little more idiomatic already. We will combine those things on the next slides. But first let's look at the CSV parsing. There's a CSV create. I advise you to use it. It's pretty solid. And what you can do is you create a builder and a builder pattern allows you to modify a struct and add members or modify members dynamically. And in this case we decide that our CSV file has no headers and the delimiter is a semi colon. And the way you can use it is like this. You now say for hotel in hotels deserialize. No more strings splitting. And now we match on the hotel because this returns a result. And now we need to make sure that the hotel that we parse is in fact correct. And after the step we don't have to deal with edge cases anymore because we know that the struct is valid. That means it has the required amount of fields and prices are also floats. Which is great makes the code much more readable already. And it was very simple to do so. Now I want to quickly talk about this part. There's a cities hash map. It has a string which is the city name. And then it has three floats which are the mean, the min and the max price. I don't think this is particularly idiomatic. The way it was used before was something like this. And we kind of managed to work our way around it. But a better way I would say would be to introduce a type for this as well. Because if we're talking about prices and pricing seems to be something that is very central to what we do in this application maybe we should have a notion of a price. It's very simple to do that. You just introduce a price type. Now you might be confused why we suddenly don't have a mean anymore. But instead we have a sum in account. And the reason being that when we parse the files we update the sum and later on at the end we can calculate the mean. Which has some mathematical properties which are favorable because now we don't really have, we don't run into rounding issues anymore. This is an aggregation that we can do whenever we want to get kind of a mean on the fly. And at the same time we have a default. Now the default is not really idiomatic too I would say. But the great part about it is that we can later reuse it and make our code a little more readable. In this case we set the min price to the maximum float. But then whenever we introduce a new price it will overwrite the maximum because I guess by definition it's smaller than the maximum or smaller or equal. And same for the max and some in account are kind of set to zero to begin with. And just before we bring it all together here's one more thing that we should do which is have a notion of a display for price. In this case we implement the display trade and we say yeah if ever you want to print a price this is the structure that you should use. The min, the mean and the max. And then this way we can make our code way more readable. Now you can see that instead of using a tuple or floats here we use a price. And when we update the prices we can talk about this object. We can tell the object hey update your min for example. Here we say price.min.min holds a price and we automatically get the min price as well. We update those price fields and yeah we can even introduce a price.add method. I don't show it here but technically why not. We can add a new hold up price. Prices could be added over time. Now that depends on I guess your taste, your flavor of rust. This is the entire code. It's a little longer but you saw all the parts. And now you have something that I would say isn't a workable state. It's not great but we did one thing. We considered rust. We thought the ignorance. We started to embrace the rust type system. We started to lean into ownership and borrowing which are fundamental concepts in rust. We lean into design patterns and we learn how to improve our architecture. And I would also say if you want to improve this part try to learn a different programming paradigm. Rust is not the only language. Try rock or try a functional language like Haskell. It might make you a better rust programmer too. This is how you fight ignorance. Now if you see that none of these horsemen fit to you by the way just think of your colleagues how you would want to introduce them to rust because this is the code you have to review and also probably maintain in the future. So it's time well invested. If you want to learn more about idiomatic rust specifically there is a website. I just put it there. It's an open source repository. It has some resources. This is a rendered version of it. You can sort by difficulty so that's your experience and then you can sort by interactivity if you want to have a workshop or not. For example there are free resources on there and paid resources too. Right let's go on and look at the next horsemen. Excessive abstraction. Everyone in this audience knows someone like that. They try to over engineer solutions because rust leans into that. It allows you to do that. It's a nice language to write abstractions. Everyone likes to do that. But then you add layers of indirection that maybe people don't necessarily understand if they come from a different background. They use trade successively and generics and lifetimes and all of these concepts are great in isolation. The combination of which makes the programs hard to read and understand for newcomers. Now if you find yourself in this camp try to fight this as well. Common symptoms of this are things like this where you have a file builder which takes a t as ref of str and a lifetime of a and this makes sure that you can pass any type and that it has no allocations that are not visible because of the lifetimes. So this might be fast and it might also to some extent be idiomatic but it is something that your colleagues also have to understand. Another thing is I might use this again. Let's make it generic or trades everywhere. And how do you get to that mindset? It's very simple. After you wrote your CSV parser it's natural that you want other parsers too. Of course you want to chase on. Of course you want to read and write into a database. You start thinking that you'll need all of those formats at some point and this is the part that is important at some point. And then you end up with something like this. It's a trade definition for a hotel reader and it has a single method called read and it takes a self that's why it's a method but it also takes a read which implements the read. That means you can pass anything that implements the read trade and it returns a box of iterator of item equals result hotel with a lifetime of A. No allocations except for the box but the iterator itself is a very idiomatic way to say a result of hotel so parsing errors are considered and it's very applicable for all of the reader types that you could possibly want. Let's say you wanted to use that trade and implement it for our hotel reader. Now suddenly we blow up the code to something that is harder to understand or if it is easy for you to understand please reconsider if your abstractions are too much. Maybe you ain't going to need it. Right. So we have a hotel reader and it owns a reader builder and inside of our new method we initialize the CSV hotel reader and we implement hotel reader down here. The single method called read and we say self.reader builder this is the code that we saw before we just put it here this is our CSV parser the initialization of it and then we return a reader.into the serialized hotel map and this is where we map the errors. Right. Does it look great? I don't know depends on someone's nodding. We need to talk but it's certainly nice to use I guess. Now we can say for hotel in hotels.read file. Should hotels know about files? Maybe not. But it's great if you go one step further and you implement iterator on it and now you can say for hotel in hotels. Alright we're getting somewhere from a user's perspective that is really great. But remember we're talking about application code. There's probably code that you earn money with. It's not a library function that is used by thousands of people. It's your simple CSV parser and now we just blew it up into something that is harder to understand. Do you really need this? Well I don't think so. I don't know what this person on the bull does but it certainly looks confusing to me and this is what people think when they see the top signature. I know kind of you wanted to optimize it a bit but at what cost? Right whenever you sit here and you think oh I should implement JSON support and you don't do it for fun. Start thinking if you really need those subscriptions because they can haunt you. Most of the time they don't have no need of it. I don't know what sort of animal this is. Is it a lion cat or something but it's kind of strapped to a cannon and it doesn't look too happy to me. I don't want this. Probably you're not going to need it. As a side note another thing probably you shouldn't do too often are macros. There are traits out there that excessively use macros. What do I mean by macros? Macro rules but also macro derives and these are great but they come at a cost and the cost could be compile times. Just yesterday I talked to Daniel Kerkman who I don't know is he here? He's not here. But thanks for the tip. He has a situation at work where compile times just blow up because of macros and for you it might be easy to write but for other people it might be hard to use. Maybe you want to prefer traits over macros if you can. That was the second horseman fighting excessive abstraction. How can it be done? If you find yourself in this situation keep it simple. Avoid unnecessary complexity. Just think that the person that will maintain the code is not a mass murderer but your best friend. Do you treat friends like this? Watch newcomers use your code. That can be humbling. Ensure that abstractions add value. Yes you can add a layer of abstraction. Does it add value? That's up to you. Decide and don't add introductions that you might need in the future. Add them when you need them. Right. Two off the list we have two more to go. Next one is premature optimization. This is for a lot of people in here because you are C and C++ programmers. I'm looking at you right now because 90% of you raised your hand. I see a lot of people from C and C++ come to Rust with this mindset with these patterns. What are the patterns? They optimize before it's necessary. This is important different from adding too many layers of abstraction. Optimization in this case means profiling is not done but instead you kind of try to outsmart the compiler and you think about performance optimizations way too early before you even need it. Did I even tell you how big that CSV file was in the beginning? How many entries does it have? You don't know. Maybe you should not optimize for it right away. They use complex data structures where simple ones would suffice. For example we saw the hash map with the three tuple elements. These are things that are kind of unravel and then it ends up being a mess not very idiomatic and arguably not even faster. And they also have a tendency to neglect benchmarks. Some red flags. Quotes you might have heard. Without a lifetime this needs to be cloned. Ignore that. If you know that you have a performance problem then you can think about lifetimes. It's fine to clone. Let me help the compiler here. The box is so much overhead. I use B3Map because it's faster than hash map. No need to measure I've got years of experience. They love the term zero cost abstraction or zero copy. Actually it should be zero cost in here. And they hate allocations. Whenever they look at an allocation they feel terrified and they bend over backwards to make that program faster. So whether this is the developer or the compiler and vice versa is up to you. I've been in both situations. They turn a completely simple hotel struct with a couple string fields which are owned yes they live on the heap. Do something that lives on the stack and has a lifetime. And every time you use a hotel you have to carry on the weight of the lifetime. Well does it matter for this one particular case? Probably not. But then you look at other places of the code base and you see that they kind of reverted your changes. They made what you introduced your hard won knowledge about the abstractions and they took them away. Now we start to index into our data structure again. We use string split again. We go backwards. We've been there before. It is super fragile. Again we are going backwards. Now let me play a little game here. Since there are so many C and C++ programs in here I expect you to answer this. What is the bottleneck? This is a very famous medieval game who wanted to be a millionaire. What is the bottleneck? Is it CSV parsing? The DC realization of our entries. Is it string object creation after we DC realized it? We put it into a hotel struct. Is that the bottleneck? Is it floating point operations when you parse the price? Or is it hash map access? Who's for A? Some shy hands? Don't be shy. Who's for B? Okay. Nice. Who's for C? No one. And who's for D? The hash map. Nice. The correct answer is you forgot to run with release. How do you find the actual performance improvements? There's just one correct answer and it is measure. Profile. Use the tools. Cargo flame graph. Cool thing. You will see that in a second. Use benchmarks. There's criteria on Nick still in the room? Nicolet? No. His benchmarking tool. Divan. Pretty great. Use it. Okay. I will give you one example. Let's look at a flame graph of our initial program. The one that a junior developer could write in two hours. What is the bottleneck? There is no bottleneck. This is the setup of our flame graph itself. This is the profiler setup. The code itself is negligible. Negligible, I guess. And why is that? Again, because I didn't tell you how big the fire was, do you think I can come up with thousands of alliterations for hotels? No. So I added 100 entries. There is no bottleneck here. Okay. You might say, but okay. What if the fire grows? Let's add a million entries. Okay. Oh, this is still 120 records. So let's add more. This is a million. You probably ain't going to read it. Let's increase it to 10 million. And indeed, deserialization of the struct takes most of our time. Okay. If we look a little closer, it says, serde deserialize deserialize struct. Okay. We have some memory movement going on. Let's take a baseline. That is our baseline. This is what it takes. 34 seconds. Okay. Now, let's say we kind of want to prove our C and C++ developer wrong. Does this other abstraction that we added for the hotel struct really add that much overhead? No. It's the same. It's like 34 seconds still. Oh, actually, this is the part where we remove the unnecessary fields. But we can go further. We can say, yeah. Here we have a little safer version. We don't index, but we say nth.1. And we have 32 seconds. Now, our bottleneck is append string. String appending. Okay. I think there's something that we can fix. Well, okay. Maybe this is not really that readable. But what we do is we split now by a string. And instead of doing an allocation where we append to our string over and over again, we use this pattern matching here. And this reduces the runtime by 30% already because we save on allocations. Now, if we try to profile this code again, where's the bottleneck now? Read until. Okay. What is that about? We have a lot of memory movement going on. And now we reach a point where the disk becomes the bottleneck. We can use an M-map for this. Now, remember, we are talking about performance and maybe you should not do those optimizations, but prove a C and C++ program were wrong and they are in tuition. And then you see that the bottleneck might be solved elsewhere. Now we are at 30 seconds by changing like four or five lines from the entire program, not the entire thing. We can keep using our abstractions. That's the main point. Here we use an M-map. That's a memory map in the kernel. We save on allocations. 30 seconds. Okay. What if we wanted to do more? It's hard to read, but now we reach the point where in fact the hash map is the bottleneck. And one more step to improve the code would be to split it up into multiple chunks. You can use rayon. You can now finally use a better hash map like a hash map. And we are down to 3.5 seconds. And we did that not by guessing, but by profiling. Now if we want to run a profile, it looks different again. Very different. These are the individual chunks that we managed to split up. We went from 40 seconds to three or four seconds in a couple slides and with few changes. And the point is don't guess, measure. This is the worst part that C developers bring into Rust. They think everything is a performance overhead. And if this challenge, by the way, looked very similar to the one billion row challenge, this is why it was inspired by it. And it is very similar. Read it up. It's kind of fun. We did something similar for hotel data. But the more important point here is how can we fight premature optimization? Measure, don't guess. Focus on algorithms and data structures, not micro-optimizations. More often than not, if you change from a vector to a hash map, this will be way, way more efficient than if you remove your little struct. And if you add lifetimes everywhere. You can get carried away pretty quickly and Rust encourages you to do so, but it also has the tooling to fight it. Be more pragmatic. Focus on readability and maintainability first and foremost. Use profiling tools to make informed decisions. You covered all of that. Your code is idiomatic. It is fast. You didn't overdo it. What is missing? Well, the entire rest. Do you have tests? Do you have documentation? Is your API too large? Does your code lack modularity and encapsulation? These are things that I see from people that are like the lone wolf coders. They know all about Rust, but what they are not really good at is the rest. Explaining the differences to their code maintainers. And writing documentation. Not about the what, but not about the how, but the what. What does your program do? Some things they say. It compiles. My work is done here. The code is documentation. Let's just make it all pop. I'll refactor that later, which never happens. Let's look at that code again. This is our first version junior programmer. Three hours. Okay. How do we test that? It's kind of impossible because this is one big binary, one main. How would we test that? Well, I guess the question is what do we want to test? Well, first off, I would say let's add a test for parsing the entire thing can be a very simple, true test. But if we refactor it such that we have a function that parses cities, now we can start to introduce a path here and do the parsing. And this is where the parsing logic is, by the way. We split it up into a main and the parsed cities. Great. This is our first test. Very crude, but we get to a point where suddenly we can test our changes. We create a temporary directory. We have a path and then we write into a file and that's it. The parsing is done. Great. If we wanted to make it a little better, instead of passing in a path, we pass in something that impels read. Now we don't need to create files like here. Instead, we can have our input as a binary blob. And these are simple things. Add some documentation, add some tests. It's not that hard. And in order to fight a mission, what you need to do is write more documentation, write unit tests, use tools like Clippy and cargo UDAPs, set up CI CD so that you can handle your changes, create releases, use release please, Marco, greetings go out to you, and keep a change lock of what you changed. Right. We're getting towards the end. We have seen the anti patterns. You know them now. I hope that you will be able to, you know, see them in your code. If you want to learn more, there are some other talks that were given here at FOSSTEM and other places. You might want to check them out. Maybe I can put the slides somewhere. And that is all I have to say. Thank you. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 13.88, "text": " Let me do a quick survey. Who has a JavaScript background? Okay, maybe like 10%. Who has", "tokens": [50364, 961, 385, 360, 257, 1702, 8984, 13, 2102, 575, 257, 15778, 3678, 30, 1033, 11, 1310, 411, 1266, 6856, 2102, 575, 51058], "temperature": 0.0, "avg_logprob": -0.2557107949558693, "compression_ratio": 1.453551912568306, "no_speech_prob": 0.37976810336112976}, {"id": 1, "seek": 0, "start": 13.88, "end": 22.0, "text": " a C background? C++? Holy hell. It's like 80% for the people on stream. Who has a Python", "tokens": [51058, 257, 383, 3678, 30, 383, 25472, 30, 6295, 4921, 13, 467, 311, 411, 4688, 4, 337, 264, 561, 322, 4309, 13, 2102, 575, 257, 15329, 51464], "temperature": 0.0, "avg_logprob": -0.2557107949558693, "compression_ratio": 1.453551912568306, "no_speech_prob": 0.37976810336112976}, {"id": 2, "seek": 0, "start": 22.0, "end": 29.080000000000002, "text": " background? What are you, Paulie Glotz? What's going on? 70% or so. Any other languages?", "tokens": [51464, 3678, 30, 708, 366, 291, 11, 4552, 414, 5209, 18530, 30, 708, 311, 516, 322, 30, 5285, 4, 420, 370, 13, 2639, 661, 8650, 30, 51818], "temperature": 0.0, "avg_logprob": -0.2557107949558693, "compression_ratio": 1.453551912568306, "no_speech_prob": 0.37976810336112976}, {"id": 3, "seek": 2908, "start": 29.08, "end": 36.36, "text": " Just scream out. I heard something like, it was something like, oh, but I can't really", "tokens": [50364, 1449, 7291, 484, 13, 286, 2198, 746, 411, 11, 309, 390, 746, 411, 11, 1954, 11, 457, 286, 393, 380, 534, 50728], "temperature": 0.0, "avg_logprob": -0.2724156863447549, "compression_ratio": 1.5491329479768785, "no_speech_prob": 0.13182274997234344}, {"id": 4, "seek": 2908, "start": 36.36, "end": 47.2, "text": " remember. Does anyone own this book? I found this book on my attic and it was kind of peculiar", "tokens": [50728, 1604, 13, 4402, 2878, 1065, 341, 1446, 30, 286, 1352, 341, 1446, 322, 452, 40766, 293, 309, 390, 733, 295, 27149, 51270], "temperature": 0.0, "avg_logprob": -0.2724156863447549, "compression_ratio": 1.5491329479768785, "no_speech_prob": 0.13182274997234344}, {"id": 5, "seek": 2908, "start": 47.2, "end": 55.879999999999995, "text": " because it had some arcane cantations in it and it looked like magic, but it certainly", "tokens": [51270, 570, 309, 632, 512, 10346, 1929, 11223, 763, 294, 309, 293, 309, 2956, 411, 5585, 11, 457, 309, 3297, 51704], "temperature": 0.0, "avg_logprob": -0.2724156863447549, "compression_ratio": 1.5491329479768785, "no_speech_prob": 0.13182274997234344}, {"id": 6, "seek": 5588, "start": 55.88, "end": 62.080000000000005, "text": " had something to do with Rust. And I was really excited. I was really enticed by this book.", "tokens": [50364, 632, 746, 281, 360, 365, 34952, 13, 400, 286, 390, 534, 2919, 13, 286, 390, 534, 948, 4233, 538, 341, 1446, 13, 50674], "temperature": 0.0, "avg_logprob": -0.15595637991073283, "compression_ratio": 1.6952380952380952, "no_speech_prob": 0.12205880135297775}, {"id": 7, "seek": 5588, "start": 62.080000000000005, "end": 67.04, "text": " This is why I want to talk about that book. It was pretty old. There was one section in", "tokens": [50674, 639, 307, 983, 286, 528, 281, 751, 466, 300, 1446, 13, 467, 390, 1238, 1331, 13, 821, 390, 472, 3541, 294, 50922], "temperature": 0.0, "avg_logprob": -0.15595637991073283, "compression_ratio": 1.6952380952380952, "no_speech_prob": 0.12205880135297775}, {"id": 8, "seek": 5588, "start": 67.04, "end": 72.0, "text": " there which I really liked and it was called the Four Horsemen of Bad Rust Code. This is", "tokens": [50922, 456, 597, 286, 534, 4501, 293, 309, 390, 1219, 264, 7451, 33208, 2558, 295, 11523, 34952, 15549, 13, 639, 307, 51170], "temperature": 0.0, "avg_logprob": -0.15595637991073283, "compression_ratio": 1.6952380952380952, "no_speech_prob": 0.12205880135297775}, {"id": 9, "seek": 5588, "start": 72.0, "end": 78.24000000000001, "text": " what this talk is about. Before we get into what the Four Horsemen are, I would like to", "tokens": [51170, 437, 341, 751, 307, 466, 13, 4546, 321, 483, 666, 437, 264, 7451, 33208, 2558, 366, 11, 286, 576, 411, 281, 51482], "temperature": 0.0, "avg_logprob": -0.15595637991073283, "compression_ratio": 1.6952380952380952, "no_speech_prob": 0.12205880135297775}, {"id": 10, "seek": 7824, "start": 78.32, "end": 86.03999999999999, "text": " introduce myself. I'm Matthias. I live in D\u00fcsseldorf in Germany. I've been doing Rust", "tokens": [50368, 5366, 2059, 13, 286, 478, 11327, 4609, 13, 286, 1621, 294, 413, 37838, 67, 28030, 294, 7244, 13, 286, 600, 668, 884, 34952, 50754], "temperature": 0.0, "avg_logprob": -0.14398325250503866, "compression_ratio": 1.4481327800829875, "no_speech_prob": 0.82686847448349}, {"id": 11, "seek": 7824, "start": 86.03999999999999, "end": 95.52, "text": " since around 2015. I do Rust for a living as a consultant. I did a Rust YouTube channel", "tokens": [50754, 1670, 926, 7546, 13, 286, 360, 34952, 337, 257, 2647, 382, 257, 24676, 13, 286, 630, 257, 34952, 3088, 2269, 51228], "temperature": 0.0, "avg_logprob": -0.14398325250503866, "compression_ratio": 1.4481327800829875, "no_speech_prob": 0.82686847448349}, {"id": 12, "seek": 7824, "start": 95.52, "end": 101.11999999999999, "text": " a long, long time ago called Hello Rust. Only 10 episodes, but well, what can you do? And", "tokens": [51228, 257, 938, 11, 938, 565, 2057, 1219, 2425, 34952, 13, 5686, 1266, 9313, 11, 457, 731, 11, 437, 393, 291, 360, 30, 400, 51508], "temperature": 0.0, "avg_logprob": -0.14398325250503866, "compression_ratio": 1.4481327800829875, "no_speech_prob": 0.82686847448349}, {"id": 13, "seek": 7824, "start": 101.11999999999999, "end": 106.28, "text": " lately I started a podcast called Rust in Production. If you like what I say in this", "tokens": [51508, 12881, 286, 1409, 257, 7367, 1219, 34952, 294, 30088, 13, 759, 291, 411, 437, 286, 584, 294, 341, 51766], "temperature": 0.0, "avg_logprob": -0.14398325250503866, "compression_ratio": 1.4481327800829875, "no_speech_prob": 0.82686847448349}, {"id": 14, "seek": 10628, "start": 106.32000000000001, "end": 113.0, "text": " talk, maybe you also want to subscribe to the podcast later on. That's it for the advertisement,", "tokens": [50366, 751, 11, 1310, 291, 611, 528, 281, 3022, 281, 264, 7367, 1780, 322, 13, 663, 311, 309, 337, 264, 31370, 11, 50700], "temperature": 0.0, "avg_logprob": -0.109012328253852, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.0692920833826065}, {"id": 15, "seek": 10628, "start": 113.0, "end": 120.24000000000001, "text": " going back to the Four Horsemen. I thought about this title a lot. Why would you talk", "tokens": [50700, 516, 646, 281, 264, 7451, 33208, 2558, 13, 286, 1194, 466, 341, 4876, 257, 688, 13, 1545, 576, 291, 751, 51062], "temperature": 0.0, "avg_logprob": -0.109012328253852, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.0692920833826065}, {"id": 16, "seek": 10628, "start": 120.24000000000001, "end": 128.8, "text": " about Bad Rust Code? I think from my experience as a Rust consultant, I see patterns evolving", "tokens": [51062, 466, 11523, 34952, 15549, 30, 286, 519, 490, 452, 1752, 382, 257, 34952, 24676, 11, 286, 536, 8294, 21085, 51490], "temperature": 0.0, "avg_logprob": -0.109012328253852, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.0692920833826065}, {"id": 17, "seek": 10628, "start": 128.8, "end": 133.96, "text": " over time. I see people doing the same things in Rust that they do in other languages. They", "tokens": [51490, 670, 565, 13, 286, 536, 561, 884, 264, 912, 721, 294, 34952, 300, 436, 360, 294, 661, 8650, 13, 814, 51748], "temperature": 0.0, "avg_logprob": -0.109012328253852, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.0692920833826065}, {"id": 18, "seek": 13396, "start": 134.0, "end": 138.96, "text": " repeat the same mistakes and I saw that no one really talked about those problems. That", "tokens": [50366, 7149, 264, 912, 8038, 293, 286, 1866, 300, 572, 472, 534, 2825, 466, 729, 2740, 13, 663, 50614], "temperature": 0.0, "avg_logprob": -0.13449321998344674, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.021571900695562363}, {"id": 19, "seek": 13396, "start": 138.96, "end": 144.32, "text": " is an issue when you come from a different language and you try to learn the rustic way,", "tokens": [50614, 307, 364, 2734, 562, 291, 808, 490, 257, 819, 2856, 293, 291, 853, 281, 1466, 264, 15259, 299, 636, 11, 50882], "temperature": 0.0, "avg_logprob": -0.13449321998344674, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.021571900695562363}, {"id": 20, "seek": 13396, "start": 144.32, "end": 149.84, "text": " the idiomatic way to write Rust code. This is what this talk is about. Let me present to you", "tokens": [50882, 264, 18014, 13143, 636, 281, 2464, 34952, 3089, 13, 639, 307, 437, 341, 751, 307, 466, 13, 961, 385, 1974, 281, 291, 51158], "temperature": 0.0, "avg_logprob": -0.13449321998344674, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.021571900695562363}, {"id": 21, "seek": 13396, "start": 149.84, "end": 158.04000000000002, "text": " the antagonists. While I do that, try to picture yourself. Imagine who you are and what you think", "tokens": [51158, 264, 32590, 1751, 13, 3987, 286, 360, 300, 11, 853, 281, 3036, 1803, 13, 11739, 567, 291, 366, 293, 437, 291, 519, 51568], "temperature": 0.0, "avg_logprob": -0.13449321998344674, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.021571900695562363}, {"id": 22, "seek": 15804, "start": 158.07999999999998, "end": 165.32, "text": " your role would be in this talk. The first horseman is this. Actually, let me show all", "tokens": [50366, 428, 3090, 576, 312, 294, 341, 751, 13, 440, 700, 6832, 1601, 307, 341, 13, 5135, 11, 718, 385, 855, 439, 50728], "temperature": 0.0, "avg_logprob": -0.176460778535302, "compression_ratio": 1.4640883977900552, "no_speech_prob": 0.048071619123220444}, {"id": 23, "seek": 15804, "start": 165.32, "end": 176.32, "text": " of them. And the first one is ignorance. What is ignorance? Magical little term. We will", "tokens": [50728, 295, 552, 13, 400, 264, 700, 472, 307, 25390, 13, 708, 307, 25390, 30, 6395, 804, 707, 1433, 13, 492, 486, 51278], "temperature": 0.0, "avg_logprob": -0.176460778535302, "compression_ratio": 1.4640883977900552, "no_speech_prob": 0.048071619123220444}, {"id": 24, "seek": 15804, "start": 176.32, "end": 182.35999999999999, "text": " get to that in the next slide. And we have excessive abstraction, premature optimization,", "tokens": [51278, 483, 281, 300, 294, 264, 958, 4137, 13, 400, 321, 362, 22704, 37765, 11, 34877, 19618, 11, 51580], "temperature": 0.0, "avg_logprob": -0.176460778535302, "compression_ratio": 1.4640883977900552, "no_speech_prob": 0.048071619123220444}, {"id": 25, "seek": 18236, "start": 182.36, "end": 189.48000000000002, "text": " and omission. Of course, you could add your own personal Rust horseman. And these are just", "tokens": [50364, 293, 3406, 3106, 13, 2720, 1164, 11, 291, 727, 909, 428, 1065, 2973, 34952, 6832, 1601, 13, 400, 613, 366, 445, 50720], "temperature": 0.0, "avg_logprob": -0.1868685158816251, "compression_ratio": 1.5739910313901346, "no_speech_prob": 0.024019872769713402}, {"id": 26, "seek": 18236, "start": 189.48000000000002, "end": 195.96, "text": " very subjective, but these are the things that I see in the real world. Now that we", "tokens": [50720, 588, 25972, 11, 457, 613, 366, 264, 721, 300, 286, 536, 294, 264, 957, 1002, 13, 823, 300, 321, 51044], "temperature": 0.0, "avg_logprob": -0.1868685158816251, "compression_ratio": 1.5739910313901346, "no_speech_prob": 0.024019872769713402}, {"id": 27, "seek": 18236, "start": 195.96, "end": 202.76000000000002, "text": " introduced the antagonists, let's go through their anti-patterns and what they are famous", "tokens": [51044, 7268, 264, 32590, 1751, 11, 718, 311, 352, 807, 641, 6061, 12, 79, 1161, 3695, 293, 437, 436, 366, 4618, 51384], "temperature": 0.0, "avg_logprob": -0.1868685158816251, "compression_ratio": 1.5739910313901346, "no_speech_prob": 0.024019872769713402}, {"id": 28, "seek": 18236, "start": 202.76000000000002, "end": 211.28000000000003, "text": " for one by one, starting with ignorance or ignorance. The horseman that is behind this", "tokens": [51384, 337, 472, 538, 472, 11, 2891, 365, 25390, 420, 25390, 13, 440, 6832, 1601, 300, 307, 2261, 341, 51810], "temperature": 0.0, "avg_logprob": -0.1868685158816251, "compression_ratio": 1.5739910313901346, "no_speech_prob": 0.024019872769713402}, {"id": 29, "seek": 21128, "start": 211.32, "end": 219.12, "text": " pattern is someone that uses stringy type APIs. You have seen it before. Someone uses a string", "tokens": [50366, 5102, 307, 1580, 300, 4960, 6798, 88, 2010, 21445, 13, 509, 362, 1612, 309, 949, 13, 8734, 4960, 257, 6798, 50756], "temperature": 0.0, "avg_logprob": -0.18558047538579897, "compression_ratio": 1.6531531531531531, "no_speech_prob": 0.06542094796895981}, {"id": 30, "seek": 21128, "start": 219.12, "end": 225.24, "text": " where they could have used an enum or they don't really embrace pattern matching. And", "tokens": [50756, 689, 436, 727, 362, 1143, 364, 465, 449, 420, 436, 500, 380, 534, 14038, 5102, 14324, 13, 400, 51062], "temperature": 0.0, "avg_logprob": -0.18558047538579897, "compression_ratio": 1.6531531531531531, "no_speech_prob": 0.06542094796895981}, {"id": 31, "seek": 21128, "start": 225.24, "end": 230.72, "text": " that makes APIs brittle. You are in a situation where if you refactor something, you might", "tokens": [51062, 300, 1669, 21445, 49325, 13, 509, 366, 294, 257, 2590, 689, 498, 291, 1895, 15104, 746, 11, 291, 1062, 51336], "temperature": 0.0, "avg_logprob": -0.18558047538579897, "compression_ratio": 1.6531531531531531, "no_speech_prob": 0.06542094796895981}, {"id": 32, "seek": 21128, "start": 230.72, "end": 236.72, "text": " run risk of forgetting that you changed something or maybe you make a typo and then your string", "tokens": [51336, 1190, 3148, 295, 25428, 300, 291, 3105, 746, 420, 1310, 291, 652, 257, 2125, 78, 293, 550, 428, 6798, 51636], "temperature": 0.0, "avg_logprob": -0.18558047538579897, "compression_ratio": 1.6531531531531531, "no_speech_prob": 0.06542094796895981}, {"id": 33, "seek": 23672, "start": 236.76, "end": 243.76, "text": " is incorrect. And so it doesn't represent what you want to represent. They also freely", "tokens": [50366, 307, 18424, 13, 400, 370, 309, 1177, 380, 2906, 437, 291, 528, 281, 2906, 13, 814, 611, 16433, 50716], "temperature": 0.0, "avg_logprob": -0.19226478493731955, "compression_ratio": 1.5695652173913044, "no_speech_prob": 0.02838754467666149}, {"id": 34, "seek": 23672, "start": 243.76, "end": 249.48, "text": " mutate variables. They go and say, yeah, this is state and I can change it. Rust has the", "tokens": [50716, 5839, 473, 9102, 13, 814, 352, 293, 584, 11, 1338, 11, 341, 307, 1785, 293, 286, 393, 1319, 309, 13, 34952, 575, 264, 51002], "temperature": 0.0, "avg_logprob": -0.19226478493731955, "compression_ratio": 1.5695652173913044, "no_speech_prob": 0.02838754467666149}, {"id": 35, "seek": 23672, "start": 249.48, "end": 254.64, "text": " mud keyword for this, but they do that liberally across the entire code base, which makes reasoning", "tokens": [51002, 8933, 20428, 337, 341, 11, 457, 436, 360, 300, 6774, 379, 2108, 264, 2302, 3089, 3096, 11, 597, 1669, 21577, 51260], "temperature": 0.0, "avg_logprob": -0.19226478493731955, "compression_ratio": 1.5695652173913044, "no_speech_prob": 0.02838754467666149}, {"id": 36, "seek": 23672, "start": 254.64, "end": 261.64, "text": " on a local scope very, very hard. They also use bad or no error handling. We will get", "tokens": [51260, 322, 257, 2654, 11923, 588, 11, 588, 1152, 13, 814, 611, 764, 1578, 420, 572, 6713, 13175, 13, 492, 486, 483, 51610], "temperature": 0.0, "avg_logprob": -0.19226478493731955, "compression_ratio": 1.5695652173913044, "no_speech_prob": 0.02838754467666149}, {"id": 37, "seek": 26164, "start": 262.28, "end": 266.44, "text": " to that in a second. They use unwraps a lot and they don't really think about the error", "tokens": [50396, 281, 300, 294, 257, 1150, 13, 814, 764, 14853, 424, 1878, 257, 688, 293, 436, 500, 380, 534, 519, 466, 264, 6713, 50604], "temperature": 0.0, "avg_logprob": -0.1594637713386017, "compression_ratio": 1.7388059701492538, "no_speech_prob": 0.0283915176987648}, {"id": 38, "seek": 26164, "start": 266.44, "end": 273.2, "text": " conditions of your application. They also have a lack of architecture in their applications.", "tokens": [50604, 4487, 295, 428, 3861, 13, 814, 611, 362, 257, 5011, 295, 9482, 294, 641, 5821, 13, 50942], "temperature": 0.0, "avg_logprob": -0.1594637713386017, "compression_ratio": 1.7388059701492538, "no_speech_prob": 0.0283915176987648}, {"id": 39, "seek": 26164, "start": 273.2, "end": 279.8, "text": " And they use a general prototype style language of writing Rust code. And where do they come", "tokens": [50942, 400, 436, 764, 257, 2674, 19475, 3758, 2856, 295, 3579, 34952, 3089, 13, 400, 689, 360, 436, 808, 51272], "temperature": 0.0, "avg_logprob": -0.1594637713386017, "compression_ratio": 1.7388059701492538, "no_speech_prob": 0.0283915176987648}, {"id": 40, "seek": 26164, "start": 279.8, "end": 286.4, "text": " from? Usually those are people that were administrators before or they write shell scripts or they", "tokens": [51272, 490, 30, 11419, 729, 366, 561, 300, 645, 27754, 949, 420, 436, 2464, 8720, 23294, 420, 436, 51602], "temperature": 0.0, "avg_logprob": -0.1594637713386017, "compression_ratio": 1.7388059701492538, "no_speech_prob": 0.0283915176987648}, {"id": 41, "seek": 26164, "start": 286.4, "end": 290.68, "text": " come from other languages like scripting languages. And this is what they know. Nothing wrong", "tokens": [51602, 808, 490, 661, 8650, 411, 5755, 278, 8650, 13, 400, 341, 307, 437, 436, 458, 13, 6693, 2085, 51816], "temperature": 0.0, "avg_logprob": -0.1594637713386017, "compression_ratio": 1.7388059701492538, "no_speech_prob": 0.0283915176987648}, {"id": 42, "seek": 29068, "start": 290.72, "end": 297.72, "text": " with that, but they haven't fully embraced what Rust is capable to offer. How do you discover", "tokens": [50366, 365, 300, 11, 457, 436, 2378, 380, 4498, 28673, 437, 34952, 307, 8189, 281, 2626, 13, 1012, 360, 291, 4411, 50716], "temperature": 0.0, "avg_logprob": -0.12456028512183656, "compression_ratio": 1.6306306306306306, "no_speech_prob": 0.002671344205737114}, {"id": 43, "seek": 29068, "start": 299.04, "end": 304.96000000000004, "text": " that you belong to this group in the code? Well, if you do things like this, you have", "tokens": [50782, 300, 291, 5784, 281, 341, 1594, 294, 264, 3089, 30, 1042, 11, 498, 291, 360, 721, 411, 341, 11, 291, 362, 51078], "temperature": 0.0, "avg_logprob": -0.12456028512183656, "compression_ratio": 1.6306306306306306, "no_speech_prob": 0.002671344205737114}, {"id": 44, "seek": 29068, "start": 304.96000000000004, "end": 309.6, "text": " highly imperative code. You go through the code and then you tell the program, hey, do", "tokens": [51078, 5405, 32490, 3089, 13, 509, 352, 807, 264, 3089, 293, 550, 291, 980, 264, 1461, 11, 4177, 11, 360, 51310], "temperature": 0.0, "avg_logprob": -0.12456028512183656, "compression_ratio": 1.6306306306306306, "no_speech_prob": 0.002671344205737114}, {"id": 45, "seek": 29068, "start": 309.6, "end": 315.4, "text": " this, do that, do this, do that, instead of using, for example, a declarative way of describing", "tokens": [51310, 341, 11, 360, 300, 11, 360, 341, 11, 360, 300, 11, 2602, 295, 1228, 11, 337, 1365, 11, 257, 16694, 1166, 636, 295, 16141, 51600], "temperature": 0.0, "avg_logprob": -0.12456028512183656, "compression_ratio": 1.6306306306306306, "no_speech_prob": 0.002671344205737114}, {"id": 46, "seek": 31540, "start": 315.4, "end": 321.35999999999996, "text": " what the stage should be. They also use magic return values like minus one or an empty string", "tokens": [50364, 437, 264, 3233, 820, 312, 13, 814, 611, 764, 5585, 2736, 4190, 411, 3175, 472, 420, 364, 6707, 6798, 50662], "temperature": 0.0, "avg_logprob": -0.11320812805839207, "compression_ratio": 1.5598290598290598, "no_speech_prob": 0.04599820822477341}, {"id": 47, "seek": 31540, "start": 321.35999999999996, "end": 327.47999999999996, "text": " to represent a certain special value instead of using errors. Everything is a string. Unwrap", "tokens": [50662, 281, 2906, 257, 1629, 2121, 2158, 2602, 295, 1228, 13603, 13, 5471, 307, 257, 6798, 13, 1156, 86, 4007, 50968], "temperature": 0.0, "avg_logprob": -0.11320812805839207, "compression_ratio": 1.5598290598290598, "no_speech_prob": 0.04599820822477341}, {"id": 48, "seek": 31540, "start": 327.47999999999996, "end": 334.47999999999996, "text": " is used freely. You clone all the things and you use the mod keyword. Why is cloning a bad", "tokens": [50968, 307, 1143, 16433, 13, 509, 26506, 439, 264, 721, 293, 291, 764, 264, 1072, 20428, 13, 1545, 307, 596, 16638, 257, 1578, 51318], "temperature": 0.0, "avg_logprob": -0.11320812805839207, "compression_ratio": 1.5598290598290598, "no_speech_prob": 0.04599820822477341}, {"id": 49, "seek": 31540, "start": 334.52, "end": 340.88, "text": " thing? I don't think it is. But the problem with clone is that you maybe don't buy into", "tokens": [51320, 551, 30, 286, 500, 380, 519, 309, 307, 13, 583, 264, 1154, 365, 26506, 307, 300, 291, 1310, 500, 380, 2256, 666, 51638], "temperature": 0.0, "avg_logprob": -0.11320812805839207, "compression_ratio": 1.5598290598290598, "no_speech_prob": 0.04599820822477341}, {"id": 50, "seek": 34088, "start": 340.88, "end": 346.56, "text": " the Rust model of ownership and borrowing. And that means that you bring what you learned", "tokens": [50364, 264, 34952, 2316, 295, 15279, 293, 35024, 13, 400, 300, 1355, 300, 291, 1565, 437, 291, 3264, 50648], "temperature": 0.0, "avg_logprob": -0.16032055170849116, "compression_ratio": 1.6507936507936507, "no_speech_prob": 0.008310798555612564}, {"id": 51, "seek": 34088, "start": 346.56, "end": 352.08, "text": " from the past from other languages to Rust and at some point you run into issues with", "tokens": [50648, 490, 264, 1791, 490, 661, 8650, 281, 34952, 293, 412, 512, 935, 291, 1190, 666, 2663, 365, 50924], "temperature": 0.0, "avg_logprob": -0.16032055170849116, "compression_ratio": 1.6507936507936507, "no_speech_prob": 0.008310798555612564}, {"id": 52, "seek": 34088, "start": 352.08, "end": 357.08, "text": " your architecture which you cannot easily resolve anymore. And this is why clone is kind", "tokens": [50924, 428, 9482, 597, 291, 2644, 3612, 14151, 3602, 13, 400, 341, 307, 983, 26506, 307, 733, 51174], "temperature": 0.0, "avg_logprob": -0.16032055170849116, "compression_ratio": 1.6507936507936507, "no_speech_prob": 0.008310798555612564}, {"id": 53, "seek": 34088, "start": 357.08, "end": 363.48, "text": " of a stop sign. It's not a warning sign, but it should make you think for a moment.", "tokens": [51174, 295, 257, 1590, 1465, 13, 467, 311, 406, 257, 9164, 1465, 11, 457, 309, 820, 652, 291, 519, 337, 257, 1623, 13, 51494], "temperature": 0.0, "avg_logprob": -0.16032055170849116, "compression_ratio": 1.6507936507936507, "no_speech_prob": 0.008310798555612564}, {"id": 54, "seek": 34088, "start": 363.48, "end": 368.56, "text": " It's an indicator of structural problems in your code, if you like.", "tokens": [51494, 467, 311, 364, 16961, 295, 15067, 2740, 294, 428, 3089, 11, 498, 291, 411, 13, 51748], "temperature": 0.0, "avg_logprob": -0.16032055170849116, "compression_ratio": 1.6507936507936507, "no_speech_prob": 0.008310798555612564}, {"id": 55, "seek": 36856, "start": 368.64, "end": 376.36, "text": " Okay. With that out of the way, let's make it a little more practical. How could we maybe", "tokens": [50368, 1033, 13, 2022, 300, 484, 295, 264, 636, 11, 718, 311, 652, 309, 257, 707, 544, 8496, 13, 1012, 727, 321, 1310, 50754], "temperature": 0.0, "avg_logprob": -0.15163751081986862, "compression_ratio": 1.5347826086956522, "no_speech_prob": 0.000868622912093997}, {"id": 56, "seek": 36856, "start": 376.36, "end": 385.04, "text": " put this into practice and improve our code step by step? Imagine you wanted to calculate", "tokens": [50754, 829, 341, 666, 3124, 293, 3470, 527, 3089, 1823, 538, 1823, 30, 11739, 291, 1415, 281, 8873, 51188], "temperature": 0.0, "avg_logprob": -0.15163751081986862, "compression_ratio": 1.5347826086956522, "no_speech_prob": 0.000868622912093997}, {"id": 57, "seek": 36856, "start": 385.04, "end": 391.32, "text": " prices for different cities for a bunch of hotels that you have in these cities. For", "tokens": [51188, 7901, 337, 819, 6486, 337, 257, 3840, 295, 22718, 300, 291, 362, 294, 613, 6486, 13, 1171, 51502], "temperature": 0.0, "avg_logprob": -0.15163751081986862, "compression_ratio": 1.5347826086956522, "no_speech_prob": 0.000868622912093997}, {"id": 58, "seek": 36856, "start": 391.32, "end": 397.88, "text": " example, imagine this was a map. This is an actual map, by the way. Africa does not look", "tokens": [51502, 1365, 11, 3811, 341, 390, 257, 4471, 13, 639, 307, 364, 3539, 4471, 11, 538, 264, 636, 13, 7349, 775, 406, 574, 51830], "temperature": 0.0, "avg_logprob": -0.15163751081986862, "compression_ratio": 1.5347826086956522, "no_speech_prob": 0.000868622912093997}, {"id": 59, "seek": 39788, "start": 397.88, "end": 405.04, "text": " like this. And also, Jerusalem is not the center of the world. I mean, we can debate", "tokens": [50364, 411, 341, 13, 400, 611, 11, 15393, 307, 406, 264, 3056, 295, 264, 1002, 13, 286, 914, 11, 321, 393, 7958, 50722], "temperature": 0.0, "avg_logprob": -0.14331215449741908, "compression_ratio": 1.4193548387096775, "no_speech_prob": 0.005809199530631304}, {"id": 60, "seek": 39788, "start": 405.04, "end": 411.0, "text": " about that, but certainly geographically there are some issues with this map. Imagine your", "tokens": [50722, 466, 300, 11, 457, 3297, 25435, 984, 456, 366, 512, 2663, 365, 341, 4471, 13, 11739, 428, 51020], "temperature": 0.0, "avg_logprob": -0.14331215449741908, "compression_ratio": 1.4193548387096775, "no_speech_prob": 0.005809199530631304}, {"id": 61, "seek": 39788, "start": 411.0, "end": 420.92, "text": " input looked something like this. It's a CSV file. You get a hotel name, a city, a date,", "tokens": [51020, 4846, 2956, 746, 411, 341, 13, 467, 311, 257, 48814, 3991, 13, 509, 483, 257, 7622, 1315, 11, 257, 2307, 11, 257, 4002, 11, 51516], "temperature": 0.0, "avg_logprob": -0.14331215449741908, "compression_ratio": 1.4193548387096775, "no_speech_prob": 0.005809199530631304}, {"id": 62, "seek": 42092, "start": 420.92, "end": 428.08000000000004, "text": " a room type, and a price. And you go through this file line by line and you try to parse", "tokens": [50364, 257, 1808, 2010, 11, 293, 257, 3218, 13, 400, 291, 352, 807, 341, 3991, 1622, 538, 1622, 293, 291, 853, 281, 48377, 50722], "temperature": 0.0, "avg_logprob": -0.13673301365064539, "compression_ratio": 1.572072072072072, "no_speech_prob": 0.1727612316608429}, {"id": 63, "seek": 42092, "start": 428.08000000000004, "end": 435.04, "text": " it into something that looks like that. For Brussels, you have a minimum hotel price of", "tokens": [50722, 309, 666, 746, 300, 1542, 411, 300, 13, 1171, 38717, 11, 291, 362, 257, 7285, 7622, 3218, 295, 51070], "temperature": 0.0, "avg_logprob": -0.13673301365064539, "compression_ratio": 1.572072072072072, "no_speech_prob": 0.1727612316608429}, {"id": 64, "seek": 42092, "start": 435.04, "end": 443.0, "text": " 40 bucks, a mean price of 80, and a maximum price of 150. Fun fact, I arrived yesterday", "tokens": [51070, 3356, 11829, 11, 257, 914, 3218, 295, 4688, 11, 293, 257, 6674, 3218, 295, 8451, 13, 11166, 1186, 11, 286, 6678, 5186, 51468], "temperature": 0.0, "avg_logprob": -0.13673301365064539, "compression_ratio": 1.572072072072072, "no_speech_prob": 0.1727612316608429}, {"id": 65, "seek": 42092, "start": 443.0, "end": 450.04, "text": " not having a hotel room because I thought I booked a hotel, but it was last year. So", "tokens": [51468, 406, 1419, 257, 7622, 1808, 570, 286, 1194, 286, 26735, 257, 7622, 11, 457, 309, 390, 1036, 1064, 13, 407, 51820], "temperature": 0.0, "avg_logprob": -0.13673301365064539, "compression_ratio": 1.572072072072072, "no_speech_prob": 0.1727612316608429}, {"id": 66, "seek": 45004, "start": 450.04, "end": 456.64000000000004, "text": " I was in the upper range here. Thanks, Walshbeng, by the way, for sharing your room with me.", "tokens": [50364, 286, 390, 294, 264, 6597, 3613, 510, 13, 2561, 11, 343, 1124, 71, 65, 1501, 11, 538, 264, 636, 11, 337, 5414, 428, 1808, 365, 385, 13, 50694], "temperature": 0.0, "avg_logprob": -0.18656294973273027, "compression_ratio": 1.5633187772925765, "no_speech_prob": 0.015405265614390373}, {"id": 67, "seek": 45004, "start": 456.64000000000004, "end": 462.40000000000003, "text": " Otherwise, they would have been a nightmare. If you wanted to parse the input file and", "tokens": [50694, 10328, 11, 436, 576, 362, 668, 257, 18724, 13, 759, 291, 1415, 281, 48377, 264, 4846, 3991, 293, 50982], "temperature": 0.0, "avg_logprob": -0.18656294973273027, "compression_ratio": 1.5633187772925765, "no_speech_prob": 0.015405265614390373}, {"id": 68, "seek": 45004, "start": 462.40000000000003, "end": 469.32000000000005, "text": " create a result like this, all you have to do is write this code. That's the entire code.", "tokens": [50982, 1884, 257, 1874, 411, 341, 11, 439, 291, 362, 281, 360, 307, 2464, 341, 3089, 13, 663, 311, 264, 2302, 3089, 13, 51328], "temperature": 0.0, "avg_logprob": -0.18656294973273027, "compression_ratio": 1.5633187772925765, "no_speech_prob": 0.015405265614390373}, {"id": 69, "seek": 45004, "start": 469.32000000000005, "end": 475.76, "text": " Nothing really big going on here. There are some peculiarities, but this is usually what", "tokens": [51328, 6693, 534, 955, 516, 322, 510, 13, 821, 366, 512, 27149, 1088, 11, 457, 341, 307, 2673, 437, 51650], "temperature": 0.0, "avg_logprob": -0.18656294973273027, "compression_ratio": 1.5633187772925765, "no_speech_prob": 0.015405265614390373}, {"id": 70, "seek": 47576, "start": 475.76, "end": 482.24, "text": " someone would write who would say Rust is not their first language. Maybe they just", "tokens": [50364, 1580, 576, 2464, 567, 576, 584, 34952, 307, 406, 641, 700, 2856, 13, 2704, 436, 445, 50688], "temperature": 0.0, "avg_logprob": -0.1191604329251695, "compression_ratio": 1.63013698630137, "no_speech_prob": 0.10350872576236725}, {"id": 71, "seek": 47576, "start": 482.24, "end": 490.03999999999996, "text": " try to port whatever they had in another language to Rust. This is code that I see them doing.", "tokens": [50688, 853, 281, 2436, 2035, 436, 632, 294, 1071, 2856, 281, 34952, 13, 639, 307, 3089, 300, 286, 536, 552, 884, 13, 51078], "temperature": 0.0, "avg_logprob": -0.1191604329251695, "compression_ratio": 1.63013698630137, "no_speech_prob": 0.10350872576236725}, {"id": 72, "seek": 47576, "start": 490.03999999999996, "end": 496.44, "text": " What you do is you read the CSV file, then you create a hash map of cities, then you iterate", "tokens": [51078, 708, 291, 360, 307, 291, 1401, 264, 48814, 3991, 11, 550, 291, 1884, 257, 22019, 4471, 295, 6486, 11, 550, 291, 44497, 51398], "temperature": 0.0, "avg_logprob": -0.1191604329251695, "compression_ratio": 1.63013698630137, "no_speech_prob": 0.10350872576236725}, {"id": 73, "seek": 47576, "start": 496.44, "end": 502.56, "text": " over each hotel, you try to parse the data by splitting each line, you extract fields", "tokens": [51398, 670, 1184, 7622, 11, 291, 853, 281, 48377, 264, 1412, 538, 30348, 1184, 1622, 11, 291, 8947, 7909, 51704], "temperature": 0.0, "avg_logprob": -0.1191604329251695, "compression_ratio": 1.63013698630137, "no_speech_prob": 0.10350872576236725}, {"id": 74, "seek": 50256, "start": 502.56, "end": 508.16, "text": " from it, you parse the price, and then you update the city. Updating the city happens", "tokens": [50364, 490, 309, 11, 291, 48377, 264, 3218, 11, 293, 550, 291, 5623, 264, 2307, 13, 5858, 67, 990, 264, 2307, 2314, 50644], "temperature": 0.0, "avg_logprob": -0.1341453434265766, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.004068075213581324}, {"id": 75, "seek": 50256, "start": 508.16, "end": 519.36, "text": " somewhere in the lower end. At the end of it, you print the mean, the max, and the minimum.", "tokens": [50644, 4079, 294, 264, 3126, 917, 13, 1711, 264, 917, 295, 309, 11, 291, 4482, 264, 914, 11, 264, 11469, 11, 293, 264, 7285, 13, 51204], "temperature": 0.0, "avg_logprob": -0.1341453434265766, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.004068075213581324}, {"id": 76, "seek": 50256, "start": 519.36, "end": 525.4, "text": " That's it. That's the entire code. You know, it's working. Technically, you could run this", "tokens": [51204, 663, 311, 309, 13, 663, 311, 264, 2302, 3089, 13, 509, 458, 11, 309, 311, 1364, 13, 42494, 11, 291, 727, 1190, 341, 51506], "temperature": 0.0, "avg_logprob": -0.1341453434265766, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.004068075213581324}, {"id": 77, "seek": 50256, "start": 525.4, "end": 531.2, "text": " code and it will produce the result that you expect. Prices for different cities, we're", "tokens": [51506, 3089, 293, 309, 486, 5258, 264, 1874, 300, 291, 2066, 13, 430, 24373, 337, 819, 6486, 11, 321, 434, 51796], "temperature": 0.0, "avg_logprob": -0.1341453434265766, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.004068075213581324}, {"id": 78, "seek": 53120, "start": 531.2, "end": 539.96, "text": " done, right? Unless we think about the bigger picture and the demons and the monsters that", "tokens": [50364, 1096, 11, 558, 30, 16581, 321, 519, 466, 264, 3801, 3036, 293, 264, 19733, 293, 264, 15785, 300, 50802], "temperature": 0.0, "avg_logprob": -0.1419626938669305, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.07910978049039841}, {"id": 79, "seek": 53120, "start": 539.96, "end": 545.4000000000001, "text": " are out there out in the ocean, and they can haunt us and bite us. There's dangerous beasts", "tokens": [50802, 366, 484, 456, 484, 294, 264, 7810, 11, 293, 436, 393, 324, 2760, 505, 293, 7988, 505, 13, 821, 311, 5795, 37386, 51074], "temperature": 0.0, "avg_logprob": -0.1419626938669305, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.07910978049039841}, {"id": 80, "seek": 53120, "start": 545.4000000000001, "end": 552.0, "text": " out there, killer animals. I think what you want to do is improve that code a little bit.", "tokens": [51074, 484, 456, 11, 13364, 4882, 13, 286, 519, 437, 291, 528, 281, 360, 307, 3470, 300, 3089, 257, 707, 857, 13, 51404], "temperature": 0.0, "avg_logprob": -0.1419626938669305, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.07910978049039841}, {"id": 81, "seek": 53120, "start": 552.0, "end": 557.0, "text": " How can we make this code a little more idiomatic? This is the same code. Now, let's look at", "tokens": [51404, 1012, 393, 321, 652, 341, 3089, 257, 707, 544, 18014, 13143, 30, 639, 307, 264, 912, 3089, 13, 823, 11, 718, 311, 574, 412, 51654], "temperature": 0.0, "avg_logprob": -0.1419626938669305, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.07910978049039841}, {"id": 82, "seek": 55700, "start": 557.0, "end": 565.4, "text": " some parts that I personally wouldn't want to have. Consider this block. There's some", "tokens": [50364, 512, 3166, 300, 286, 5665, 2759, 380, 528, 281, 362, 13, 17416, 341, 3461, 13, 821, 311, 512, 50784], "temperature": 0.0, "avg_logprob": -0.11624655516251274, "compression_ratio": 1.5874439461883407, "no_speech_prob": 0.13800105452537537}, {"id": 83, "seek": 55700, "start": 565.4, "end": 572.0, "text": " things going on, but overall, it's a very manual way, a very imperative way of going", "tokens": [50784, 721, 516, 322, 11, 457, 4787, 11, 309, 311, 257, 588, 9688, 636, 11, 257, 588, 32490, 636, 295, 516, 51114], "temperature": 0.0, "avg_logprob": -0.11624655516251274, "compression_ratio": 1.5874439461883407, "no_speech_prob": 0.13800105452537537}, {"id": 84, "seek": 55700, "start": 572.0, "end": 579.52, "text": " through the list of hotels. We literally have a couple if conditions here. If price is smaller", "tokens": [51114, 807, 264, 1329, 295, 22718, 13, 492, 3736, 362, 257, 1916, 498, 4487, 510, 13, 759, 3218, 307, 4356, 51490], "temperature": 0.0, "avg_logprob": -0.11624655516251274, "compression_ratio": 1.5874439461883407, "no_speech_prob": 0.13800105452537537}, {"id": 85, "seek": 55700, "start": 579.52, "end": 585.08, "text": " than city data zero and so on, we update the price, yada, yada, yada. There are patterns", "tokens": [51490, 813, 2307, 1412, 4018, 293, 370, 322, 11, 321, 5623, 264, 3218, 11, 288, 1538, 11, 288, 1538, 11, 288, 1538, 13, 821, 366, 8294, 51768], "temperature": 0.0, "avg_logprob": -0.11624655516251274, "compression_ratio": 1.5874439461883407, "no_speech_prob": 0.13800105452537537}, {"id": 86, "seek": 58508, "start": 585.1600000000001, "end": 591.0400000000001, "text": " that make that a little nicer to read in Rust. This is the same code. It's just something", "tokens": [50368, 300, 652, 300, 257, 707, 22842, 281, 1401, 294, 34952, 13, 639, 307, 264, 912, 3089, 13, 467, 311, 445, 746, 50662], "temperature": 0.0, "avg_logprob": -0.1501012215247521, "compression_ratio": 1.5777777777777777, "no_speech_prob": 0.035594094544649124}, {"id": 87, "seek": 58508, "start": 591.0400000000001, "end": 598.5600000000001, "text": " very similar, but we kind of manage to shrink it down a little bit. In comparison to what", "tokens": [50662, 588, 2531, 11, 457, 321, 733, 295, 3067, 281, 23060, 309, 760, 257, 707, 857, 13, 682, 9660, 281, 437, 51038], "temperature": 0.0, "avg_logprob": -0.1501012215247521, "compression_ratio": 1.5777777777777777, "no_speech_prob": 0.035594094544649124}, {"id": 88, "seek": 58508, "start": 598.5600000000001, "end": 606.44, "text": " we had before, we get city data and then we use some sort of tuple extraction to get the", "tokens": [51038, 321, 632, 949, 11, 321, 483, 2307, 1412, 293, 550, 321, 764, 512, 1333, 295, 2604, 781, 30197, 281, 483, 264, 51432], "temperature": 0.0, "avg_logprob": -0.1501012215247521, "compression_ratio": 1.5777777777777777, "no_speech_prob": 0.035594094544649124}, {"id": 89, "seek": 58508, "start": 606.44, "end": 611.24, "text": " mean at a minimum and the max. That makes things a little easier. We can suddenly talk", "tokens": [51432, 914, 412, 257, 7285, 293, 264, 11469, 13, 663, 1669, 721, 257, 707, 3571, 13, 492, 393, 5800, 751, 51672], "temperature": 0.0, "avg_logprob": -0.1501012215247521, "compression_ratio": 1.5777777777777777, "no_speech_prob": 0.035594094544649124}, {"id": 90, "seek": 61124, "start": 611.24, "end": 618.08, "text": " about mean instead of city data zero, for example. That's not the major problem with", "tokens": [50364, 466, 914, 2602, 295, 2307, 1412, 4018, 11, 337, 1365, 13, 663, 311, 406, 264, 2563, 1154, 365, 50706], "temperature": 0.0, "avg_logprob": -0.1760963480523292, "compression_ratio": 1.5650224215246638, "no_speech_prob": 0.002081638667732477}, {"id": 91, "seek": 61124, "start": 618.08, "end": 626.16, "text": " this code. There's unwraps too in here. Well, for a first prototype, that might work fine,", "tokens": [50706, 341, 3089, 13, 821, 311, 14853, 424, 1878, 886, 294, 510, 13, 1042, 11, 337, 257, 700, 19475, 11, 300, 1062, 589, 2489, 11, 51110], "temperature": 0.0, "avg_logprob": -0.1760963480523292, "compression_ratio": 1.5650224215246638, "no_speech_prob": 0.002081638667732477}, {"id": 92, "seek": 61124, "start": 626.16, "end": 631.04, "text": " but later on, maybe you don't want to have that. What if you cannot open the hotel's", "tokens": [51110, 457, 1780, 322, 11, 1310, 291, 500, 380, 528, 281, 362, 300, 13, 708, 498, 291, 2644, 1269, 264, 7622, 311, 51354], "temperature": 0.0, "avg_logprob": -0.1760963480523292, "compression_ratio": 1.5650224215246638, "no_speech_prob": 0.002081638667732477}, {"id": 93, "seek": 61124, "start": 631.04, "end": 636.84, "text": " CSV file? What if you cannot parse a price? In this case, the entire program just stops.", "tokens": [51354, 48814, 3991, 30, 708, 498, 291, 2644, 48377, 257, 3218, 30, 682, 341, 1389, 11, 264, 2302, 1461, 445, 10094, 13, 51644], "temperature": 0.0, "avg_logprob": -0.1760963480523292, "compression_ratio": 1.5650224215246638, "no_speech_prob": 0.002081638667732477}, {"id": 94, "seek": 63684, "start": 637.08, "end": 642.48, "text": " A question of design, but I would say if there's a single line that is invalid, you probably", "tokens": [50376, 316, 1168, 295, 1715, 11, 457, 286, 576, 584, 498, 456, 311, 257, 2167, 1622, 300, 307, 34702, 11, 291, 1391, 50646], "temperature": 0.0, "avg_logprob": -0.15680900316559868, "compression_ratio": 1.640552995391705, "no_speech_prob": 0.04598085954785347}, {"id": 95, "seek": 63684, "start": 642.48, "end": 648.52, "text": " don't want to stop the execution right away. Another problem is that we index into the", "tokens": [50646, 500, 380, 528, 281, 1590, 264, 15058, 558, 1314, 13, 3996, 1154, 307, 300, 321, 8186, 666, 264, 50948], "temperature": 0.0, "avg_logprob": -0.15680900316559868, "compression_ratio": 1.640552995391705, "no_speech_prob": 0.04598085954785347}, {"id": 96, "seek": 63684, "start": 648.52, "end": 656.36, "text": " memory right away. Who tells us that a line has that many entries, five entries? It might", "tokens": [50948, 4675, 558, 1314, 13, 2102, 5112, 505, 300, 257, 1622, 575, 300, 867, 23041, 11, 1732, 23041, 30, 467, 1062, 51340], "temperature": 0.0, "avg_logprob": -0.15680900316559868, "compression_ratio": 1.640552995391705, "no_speech_prob": 0.04598085954785347}, {"id": 97, "seek": 63684, "start": 656.36, "end": 661.72, "text": " have three. It might have zero. Who knows? But if we index into something that doesn't", "tokens": [51340, 362, 1045, 13, 467, 1062, 362, 4018, 13, 2102, 3255, 30, 583, 498, 321, 8186, 666, 746, 300, 1177, 380, 51608], "temperature": 0.0, "avg_logprob": -0.15680900316559868, "compression_ratio": 1.640552995391705, "no_speech_prob": 0.04598085954785347}, {"id": 98, "seek": 66172, "start": 661.76, "end": 666.96, "text": " exist, the program will panic and that is kind of a bad thing. The underscores mean", "tokens": [50366, 2514, 11, 264, 1461, 486, 14783, 293, 300, 307, 733, 295, 257, 1578, 551, 13, 440, 16692, 66, 2706, 914, 50626], "temperature": 0.0, "avg_logprob": -0.10434247693444929, "compression_ratio": 1.6397058823529411, "no_speech_prob": 0.04021090269088745}, {"id": 99, "seek": 66172, "start": 666.96, "end": 671.0, "text": " that the variables are not used, so we can remove them. We have a little bit of a cleaner", "tokens": [50626, 300, 264, 9102, 366, 406, 1143, 11, 370, 321, 393, 4159, 552, 13, 492, 362, 257, 707, 857, 295, 257, 16532, 50828], "temperature": 0.0, "avg_logprob": -0.10434247693444929, "compression_ratio": 1.6397058823529411, "no_speech_prob": 0.04021090269088745}, {"id": 100, "seek": 66172, "start": 671.0, "end": 676.52, "text": " structure and a simple way to check that a line is valid would be to just have this manual", "tokens": [50828, 3877, 293, 257, 2199, 636, 281, 1520, 300, 257, 1622, 307, 7363, 576, 312, 281, 445, 362, 341, 9688, 51104], "temperature": 0.0, "avg_logprob": -0.10434247693444929, "compression_ratio": 1.6397058823529411, "no_speech_prob": 0.04021090269088745}, {"id": 101, "seek": 66172, "start": 676.52, "end": 682.0, "text": " check in there. I know it's not very sophisticated, but it helps us along the way. Now we check", "tokens": [51104, 1520, 294, 456, 13, 286, 458, 309, 311, 406, 588, 16950, 11, 457, 309, 3665, 505, 2051, 264, 636, 13, 823, 321, 1520, 51378], "temperature": 0.0, "avg_logprob": -0.10434247693444929, "compression_ratio": 1.6397058823529411, "no_speech_prob": 0.04021090269088745}, {"id": 102, "seek": 66172, "start": 682.0, "end": 688.36, "text": " if the hotel data length is five and if it is not, we just skip the entry. Let's look", "tokens": [51378, 498, 264, 7622, 1412, 4641, 307, 1732, 293, 498, 309, 307, 406, 11, 321, 445, 10023, 264, 8729, 13, 961, 311, 574, 51696], "temperature": 0.0, "avg_logprob": -0.10434247693444929, "compression_ratio": 1.6397058823529411, "no_speech_prob": 0.04021090269088745}, {"id": 103, "seek": 68836, "start": 688.4, "end": 694.36, "text": " at parsing for a second. How do we want to handle parsing? I said that maybe we don't", "tokens": [50366, 412, 21156, 278, 337, 257, 1150, 13, 1012, 360, 321, 528, 281, 4813, 21156, 278, 30, 286, 848, 300, 1310, 321, 500, 380, 50664], "temperature": 0.0, "avg_logprob": -0.1161386802278716, "compression_ratio": 1.752988047808765, "no_speech_prob": 0.02593180350959301}, {"id": 104, "seek": 68836, "start": 694.36, "end": 699.72, "text": " want to stop the execution when we run into an issue and we can do that in Rust by matching", "tokens": [50664, 528, 281, 1590, 264, 15058, 562, 321, 1190, 666, 364, 2734, 293, 321, 393, 360, 300, 294, 34952, 538, 14324, 50932], "temperature": 0.0, "avg_logprob": -0.1161386802278716, "compression_ratio": 1.752988047808765, "no_speech_prob": 0.02593180350959301}, {"id": 105, "seek": 68836, "start": 699.72, "end": 706.16, "text": " on the parse result. A very simple way to do that would be to say match price dot parse", "tokens": [50932, 322, 264, 48377, 1874, 13, 316, 588, 2199, 636, 281, 360, 300, 576, 312, 281, 584, 2995, 3218, 5893, 48377, 51254], "temperature": 0.0, "avg_logprob": -0.1161386802278716, "compression_ratio": 1.752988047808765, "no_speech_prob": 0.02593180350959301}, {"id": 106, "seek": 68836, "start": 706.16, "end": 709.96, "text": " and if we have an okay value, we take it and if we have an error, we don't really care", "tokens": [51254, 293, 498, 321, 362, 364, 1392, 2158, 11, 321, 747, 309, 293, 498, 321, 362, 364, 6713, 11, 321, 500, 380, 534, 1127, 51444], "temperature": 0.0, "avg_logprob": -0.1161386802278716, "compression_ratio": 1.752988047808765, "no_speech_prob": 0.02593180350959301}, {"id": 107, "seek": 68836, "start": 709.96, "end": 715.2, "text": " about the error. We just print an error on standard error and then we continue with the", "tokens": [51444, 466, 264, 6713, 13, 492, 445, 4482, 364, 6713, 322, 3832, 6713, 293, 550, 321, 2354, 365, 264, 51706], "temperature": 0.0, "avg_logprob": -0.1161386802278716, "compression_ratio": 1.752988047808765, "no_speech_prob": 0.02593180350959301}, {"id": 108, "seek": 71520, "start": 715.24, "end": 722.24, "text": " rest of the parsing. Looking at the input, one thing we can do as well is apply a similar", "tokens": [50366, 1472, 295, 264, 21156, 278, 13, 11053, 412, 264, 4846, 11, 472, 551, 321, 393, 360, 382, 731, 307, 3079, 257, 2531, 50716], "temperature": 0.0, "avg_logprob": -0.12790697076347438, "compression_ratio": 1.6575342465753424, "no_speech_prob": 0.0013880494516342878}, {"id": 109, "seek": 71520, "start": 723.2, "end": 730.2, "text": " pattern and introduce a result type. Now we use a box for representing a result type.", "tokens": [50764, 5102, 293, 5366, 257, 1874, 2010, 13, 823, 321, 764, 257, 2424, 337, 13460, 257, 1874, 2010, 13, 51114], "temperature": 0.0, "avg_logprob": -0.12790697076347438, "compression_ratio": 1.6575342465753424, "no_speech_prob": 0.0013880494516342878}, {"id": 110, "seek": 71520, "start": 732.6800000000001, "end": 738.6400000000001, "text": " This is because you don't need anything, any external library to have a result type that", "tokens": [51238, 639, 307, 570, 291, 500, 380, 643, 1340, 11, 604, 8320, 6405, 281, 362, 257, 1874, 2010, 300, 51536], "temperature": 0.0, "avg_logprob": -0.12790697076347438, "compression_ratio": 1.6575342465753424, "no_speech_prob": 0.0013880494516342878}, {"id": 111, "seek": 71520, "start": 738.6400000000001, "end": 743.36, "text": " has an error type which can be literally anything. So it can be a string, anything that implements", "tokens": [51536, 575, 364, 6713, 2010, 597, 393, 312, 3736, 1340, 13, 407, 309, 393, 312, 257, 6798, 11, 1340, 300, 704, 17988, 51772], "temperature": 0.0, "avg_logprob": -0.12790697076347438, "compression_ratio": 1.6575342465753424, "no_speech_prob": 0.0013880494516342878}, {"id": 112, "seek": 74336, "start": 743.36, "end": 748.32, "text": " error, the error trade. In this case, it's a very simple way to improve your Rust code.", "tokens": [50364, 6713, 11, 264, 6713, 4923, 13, 682, 341, 1389, 11, 309, 311, 257, 588, 2199, 636, 281, 3470, 428, 34952, 3089, 13, 50612], "temperature": 0.0, "avg_logprob": -0.15065897664716166, "compression_ratio": 1.662037037037037, "no_speech_prob": 0.0026297937147319317}, {"id": 113, "seek": 74336, "start": 748.32, "end": 754.82, "text": " It's a good first step. What we do instead now is we say read to string and then we map", "tokens": [50612, 467, 311, 257, 665, 700, 1823, 13, 708, 321, 360, 2602, 586, 307, 321, 584, 1401, 281, 6798, 293, 550, 321, 4471, 50937], "temperature": 0.0, "avg_logprob": -0.15065897664716166, "compression_ratio": 1.662037037037037, "no_speech_prob": 0.0026297937147319317}, {"id": 114, "seek": 74336, "start": 754.82, "end": 761.32, "text": " the error in case we have an error to something that a user could understand and act on. Then", "tokens": [50937, 264, 6713, 294, 1389, 321, 362, 364, 6713, 281, 746, 300, 257, 4195, 727, 1223, 293, 605, 322, 13, 1396, 51262], "temperature": 0.0, "avg_logprob": -0.15065897664716166, "compression_ratio": 1.662037037037037, "no_speech_prob": 0.0026297937147319317}, {"id": 115, "seek": 74336, "start": 761.32, "end": 768.32, "text": " yeah, the code is already a little cleaner. We handled a few error cases already and this", "tokens": [51262, 1338, 11, 264, 3089, 307, 1217, 257, 707, 16532, 13, 492, 18033, 257, 1326, 6713, 3331, 1217, 293, 341, 51612], "temperature": 0.0, "avg_logprob": -0.15065897664716166, "compression_ratio": 1.662037037037037, "no_speech_prob": 0.0026297937147319317}, {"id": 116, "seek": 76832, "start": 769.32, "end": 776.32, "text": " is something that might pass a first iteration of a review cycle. Now of course there are", "tokens": [50414, 307, 746, 300, 1062, 1320, 257, 700, 24784, 295, 257, 3131, 6586, 13, 823, 295, 1164, 456, 366, 50764], "temperature": 0.0, "avg_logprob": -0.15111471306193958, "compression_ratio": 1.6233183856502242, "no_speech_prob": 0.001263825804926455}, {"id": 117, "seek": 76832, "start": 776.9200000000001, "end": 783.12, "text": " certain other issues with this code. For example, CSV handling. CSV is tricky. Proper handling", "tokens": [50794, 1629, 661, 2663, 365, 341, 3089, 13, 1171, 1365, 11, 48814, 13175, 13, 48814, 307, 12414, 13, 27627, 13175, 51104], "temperature": 0.0, "avg_logprob": -0.15111471306193958, "compression_ratio": 1.6233183856502242, "no_speech_prob": 0.001263825804926455}, {"id": 118, "seek": 76832, "start": 783.12, "end": 789.0400000000001, "text": " of delimiters is very hard. For example, you might have an entry which has semicolons like", "tokens": [51104, 295, 1103, 332, 270, 433, 307, 588, 1152, 13, 1171, 1365, 11, 291, 1062, 362, 364, 8729, 597, 575, 27515, 401, 892, 411, 51400], "temperature": 0.0, "avg_logprob": -0.15111471306193958, "compression_ratio": 1.6233183856502242, "no_speech_prob": 0.001263825804926455}, {"id": 119, "seek": 76832, "start": 789.0400000000001, "end": 794.7600000000001, "text": " on the left side here or you have something that has quotes around a semicolon and you", "tokens": [51400, 322, 264, 1411, 1252, 510, 420, 291, 362, 746, 300, 575, 19963, 926, 257, 27515, 38780, 293, 291, 51686], "temperature": 0.0, "avg_logprob": -0.15111471306193958, "compression_ratio": 1.6233183856502242, "no_speech_prob": 0.001263825804926455}, {"id": 120, "seek": 79476, "start": 794.8, "end": 801.8, "text": " probably want to handle that. So a simple string split does not suffice. Same with encodings.", "tokens": [50366, 1391, 528, 281, 4813, 300, 13, 407, 257, 2199, 6798, 7472, 775, 406, 3889, 573, 13, 10635, 365, 2058, 378, 1109, 13, 50716], "temperature": 0.0, "avg_logprob": -0.15936704861220494, "compression_ratio": 1.5627705627705628, "no_speech_prob": 0.00425919983536005}, {"id": 121, "seek": 79476, "start": 802.16, "end": 808.16, "text": " On what platform are we operating on? Do we know the encoding right away? Does the CSV", "tokens": [50734, 1282, 437, 3663, 366, 321, 7447, 322, 30, 1144, 321, 458, 264, 43430, 558, 1314, 30, 4402, 264, 48814, 51034], "temperature": 0.0, "avg_logprob": -0.15936704861220494, "compression_ratio": 1.5627705627705628, "no_speech_prob": 0.00425919983536005}, {"id": 122, "seek": 79476, "start": 808.16, "end": 813.2, "text": " file contain headlines or no headlines? And there's many, many caveats like that. If you're", "tokens": [51034, 3991, 5304, 23867, 420, 572, 23867, 30, 400, 456, 311, 867, 11, 867, 11730, 1720, 411, 300, 13, 759, 291, 434, 51286], "temperature": 0.0, "avg_logprob": -0.15936704861220494, "compression_ratio": 1.5627705627705628, "no_speech_prob": 0.00425919983536005}, {"id": 123, "seek": 79476, "start": 813.2, "end": 818.4, "text": " interested, there's a talk called stop using CSV. I don't say you should stop using CSV,", "tokens": [51286, 3102, 11, 456, 311, 257, 751, 1219, 1590, 1228, 48814, 13, 286, 500, 380, 584, 291, 820, 1590, 1228, 48814, 11, 51546], "temperature": 0.0, "avg_logprob": -0.15936704861220494, "compression_ratio": 1.5627705627705628, "no_speech_prob": 0.00425919983536005}, {"id": 124, "seek": 81840, "start": 818.4, "end": 824.9599999999999, "text": " but I say you should start watching this talk because it's really good. Right. How can", "tokens": [50364, 457, 286, 584, 291, 820, 722, 1976, 341, 751, 570, 309, 311, 534, 665, 13, 1779, 13, 1012, 393, 50692], "temperature": 0.0, "avg_logprob": -0.15608354651409648, "compression_ratio": 1.6629213483146068, "no_speech_prob": 0.02366490289568901}, {"id": 125, "seek": 81840, "start": 824.9599999999999, "end": 830.48, "text": " we introduce types? I talked about types a lot and Rust is great with types. We should", "tokens": [50692, 321, 5366, 3467, 30, 286, 2825, 466, 3467, 257, 688, 293, 34952, 307, 869, 365, 3467, 13, 492, 820, 50968], "temperature": 0.0, "avg_logprob": -0.15608354651409648, "compression_ratio": 1.6629213483146068, "no_speech_prob": 0.02366490289568901}, {"id": 126, "seek": 81840, "start": 830.48, "end": 835.8, "text": " use more of them. Here's a simple way. I already talked about the result type and in the first", "tokens": [50968, 764, 544, 295, 552, 13, 1692, 311, 257, 2199, 636, 13, 286, 1217, 2825, 466, 264, 1874, 2010, 293, 294, 264, 700, 51234], "temperature": 0.0, "avg_logprob": -0.15608354651409648, "compression_ratio": 1.6629213483146068, "no_speech_prob": 0.02366490289568901}, {"id": 127, "seek": 81840, "start": 835.8, "end": 840.9599999999999, "text": " line we just create an alias for our result and we say it's anything that has a T where", "tokens": [51234, 1622, 321, 445, 1884, 364, 419, 4609, 337, 527, 1874, 293, 321, 584, 309, 311, 1340, 300, 575, 257, 314, 689, 51492], "temperature": 0.0, "avg_logprob": -0.15608354651409648, "compression_ratio": 1.6629213483146068, "no_speech_prob": 0.02366490289568901}, {"id": 128, "seek": 81840, "start": 840.9599999999999, "end": 847.96, "text": " T is generic and the error type is of type box d\u00fcn stet error. And then we can use the", "tokens": [51492, 314, 307, 19577, 293, 264, 6713, 2010, 307, 295, 2010, 2424, 274, 3412, 342, 302, 6713, 13, 400, 550, 321, 393, 764, 264, 51842], "temperature": 0.0, "avg_logprob": -0.15608354651409648, "compression_ratio": 1.6629213483146068, "no_speech_prob": 0.02366490289568901}, {"id": 129, "seek": 84840, "start": 848.48, "end": 855.48, "text": " result in our code to make it a little easier to read. As well, we introduce a hotel struct", "tokens": [50368, 1874, 294, 527, 3089, 281, 652, 309, 257, 707, 3571, 281, 1401, 13, 1018, 731, 11, 321, 5366, 257, 7622, 6594, 50718], "temperature": 0.0, "avg_logprob": -0.14296255006894962, "compression_ratio": 1.5982142857142858, "no_speech_prob": 0.0023205659817904234}, {"id": 130, "seek": 84840, "start": 855.84, "end": 860.3199999999999, "text": " and we have a couple fields, just strings and floating points at this point. But this", "tokens": [50736, 293, 321, 362, 257, 1916, 7909, 11, 445, 13985, 293, 12607, 2793, 412, 341, 935, 13, 583, 341, 50960], "temperature": 0.0, "avg_logprob": -0.14296255006894962, "compression_ratio": 1.5982142857142858, "no_speech_prob": 0.0023205659817904234}, {"id": 131, "seek": 84840, "start": 860.3199999999999, "end": 865.52, "text": " helps us make the code a little more idiomatic already. We will combine those things on the", "tokens": [50960, 3665, 505, 652, 264, 3089, 257, 707, 544, 18014, 13143, 1217, 13, 492, 486, 10432, 729, 721, 322, 264, 51220], "temperature": 0.0, "avg_logprob": -0.14296255006894962, "compression_ratio": 1.5982142857142858, "no_speech_prob": 0.0023205659817904234}, {"id": 132, "seek": 84840, "start": 865.52, "end": 872.52, "text": " next slides. But first let's look at the CSV parsing. There's a CSV create. I advise you", "tokens": [51220, 958, 9788, 13, 583, 700, 718, 311, 574, 412, 264, 48814, 21156, 278, 13, 821, 311, 257, 48814, 1884, 13, 286, 18312, 291, 51570], "temperature": 0.0, "avg_logprob": -0.14296255006894962, "compression_ratio": 1.5982142857142858, "no_speech_prob": 0.0023205659817904234}, {"id": 133, "seek": 87252, "start": 872.96, "end": 878.52, "text": " to use it. It's pretty solid. And what you can do is you create a builder and a builder", "tokens": [50386, 281, 764, 309, 13, 467, 311, 1238, 5100, 13, 400, 437, 291, 393, 360, 307, 291, 1884, 257, 27377, 293, 257, 27377, 50664], "temperature": 0.0, "avg_logprob": -0.1652559362432008, "compression_ratio": 1.6418604651162791, "no_speech_prob": 0.05099029466509819}, {"id": 134, "seek": 87252, "start": 878.52, "end": 885.52, "text": " pattern allows you to modify a struct and add members or modify members dynamically.", "tokens": [50664, 5102, 4045, 291, 281, 16927, 257, 6594, 293, 909, 2679, 420, 16927, 2679, 43492, 13, 51014], "temperature": 0.0, "avg_logprob": -0.1652559362432008, "compression_ratio": 1.6418604651162791, "no_speech_prob": 0.05099029466509819}, {"id": 135, "seek": 87252, "start": 885.96, "end": 891.96, "text": " And in this case we decide that our CSV file has no headers and the delimiter is a semi", "tokens": [51036, 400, 294, 341, 1389, 321, 4536, 300, 527, 48814, 3991, 575, 572, 45101, 293, 264, 1103, 332, 1681, 307, 257, 12909, 51336], "temperature": 0.0, "avg_logprob": -0.1652559362432008, "compression_ratio": 1.6418604651162791, "no_speech_prob": 0.05099029466509819}, {"id": 136, "seek": 87252, "start": 891.96, "end": 898.96, "text": " colon. And the way you can use it is like this. You now say for hotel in hotels deserialize.", "tokens": [51336, 8255, 13, 400, 264, 636, 291, 393, 764, 309, 307, 411, 341, 13, 509, 586, 584, 337, 7622, 294, 22718, 730, 260, 831, 1125, 13, 51686], "temperature": 0.0, "avg_logprob": -0.1652559362432008, "compression_ratio": 1.6418604651162791, "no_speech_prob": 0.05099029466509819}, {"id": 137, "seek": 89896, "start": 899.96, "end": 906.96, "text": " No more strings splitting. And now we match on the hotel because this returns a result.", "tokens": [50414, 883, 544, 13985, 30348, 13, 400, 586, 321, 2995, 322, 264, 7622, 570, 341, 11247, 257, 1874, 13, 50764], "temperature": 0.0, "avg_logprob": -0.17816610897288604, "compression_ratio": 1.631336405529954, "no_speech_prob": 0.01047847792506218}, {"id": 138, "seek": 89896, "start": 907.48, "end": 911.84, "text": " And now we need to make sure that the hotel that we parse is in fact correct. And after", "tokens": [50790, 400, 586, 321, 643, 281, 652, 988, 300, 264, 7622, 300, 321, 48377, 307, 294, 1186, 3006, 13, 400, 934, 51008], "temperature": 0.0, "avg_logprob": -0.17816610897288604, "compression_ratio": 1.631336405529954, "no_speech_prob": 0.01047847792506218}, {"id": 139, "seek": 89896, "start": 911.84, "end": 917.0, "text": " the step we don't have to deal with edge cases anymore because we know that the struct is", "tokens": [51008, 264, 1823, 321, 500, 380, 362, 281, 2028, 365, 4691, 3331, 3602, 570, 321, 458, 300, 264, 6594, 307, 51266], "temperature": 0.0, "avg_logprob": -0.17816610897288604, "compression_ratio": 1.631336405529954, "no_speech_prob": 0.01047847792506218}, {"id": 140, "seek": 89896, "start": 917.0, "end": 923.44, "text": " valid. That means it has the required amount of fields and prices are also floats. Which", "tokens": [51266, 7363, 13, 663, 1355, 309, 575, 264, 4739, 2372, 295, 7909, 293, 7901, 366, 611, 37878, 13, 3013, 51588], "temperature": 0.0, "avg_logprob": -0.17816610897288604, "compression_ratio": 1.631336405529954, "no_speech_prob": 0.01047847792506218}, {"id": 141, "seek": 92344, "start": 923.44, "end": 930.0400000000001, "text": " is great makes the code much more readable already. And it was very simple to do so.", "tokens": [50364, 307, 869, 1669, 264, 3089, 709, 544, 49857, 1217, 13, 400, 309, 390, 588, 2199, 281, 360, 370, 13, 50694], "temperature": 0.0, "avg_logprob": -0.12172123626038268, "compression_ratio": 1.5818181818181818, "no_speech_prob": 0.027561074122786522}, {"id": 142, "seek": 92344, "start": 930.0400000000001, "end": 936.96, "text": " Now I want to quickly talk about this part. There's a cities hash map. It has a string", "tokens": [50694, 823, 286, 528, 281, 2661, 751, 466, 341, 644, 13, 821, 311, 257, 6486, 22019, 4471, 13, 467, 575, 257, 6798, 51040], "temperature": 0.0, "avg_logprob": -0.12172123626038268, "compression_ratio": 1.5818181818181818, "no_speech_prob": 0.027561074122786522}, {"id": 143, "seek": 92344, "start": 936.96, "end": 942.12, "text": " which is the city name. And then it has three floats which are the mean, the min and the", "tokens": [51040, 597, 307, 264, 2307, 1315, 13, 400, 550, 309, 575, 1045, 37878, 597, 366, 264, 914, 11, 264, 923, 293, 264, 51298], "temperature": 0.0, "avg_logprob": -0.12172123626038268, "compression_ratio": 1.5818181818181818, "no_speech_prob": 0.027561074122786522}, {"id": 144, "seek": 92344, "start": 942.12, "end": 948.24, "text": " max price. I don't think this is particularly idiomatic. The way it was used before was", "tokens": [51298, 11469, 3218, 13, 286, 500, 380, 519, 341, 307, 4098, 18014, 13143, 13, 440, 636, 309, 390, 1143, 949, 390, 51604], "temperature": 0.0, "avg_logprob": -0.12172123626038268, "compression_ratio": 1.5818181818181818, "no_speech_prob": 0.027561074122786522}, {"id": 145, "seek": 94824, "start": 948.24, "end": 955.24, "text": " something like this. And we kind of managed to work our way around it. But a better way", "tokens": [50364, 746, 411, 341, 13, 400, 321, 733, 295, 6453, 281, 589, 527, 636, 926, 309, 13, 583, 257, 1101, 636, 50714], "temperature": 0.0, "avg_logprob": -0.11713990220078477, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.06003940850496292}, {"id": 146, "seek": 94824, "start": 955.28, "end": 960.4, "text": " I would say would be to introduce a type for this as well. Because if we're talking about", "tokens": [50716, 286, 576, 584, 576, 312, 281, 5366, 257, 2010, 337, 341, 382, 731, 13, 1436, 498, 321, 434, 1417, 466, 50972], "temperature": 0.0, "avg_logprob": -0.11713990220078477, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.06003940850496292}, {"id": 147, "seek": 94824, "start": 960.4, "end": 965.4, "text": " prices and pricing seems to be something that is very central to what we do in this application", "tokens": [50972, 7901, 293, 17621, 2544, 281, 312, 746, 300, 307, 588, 5777, 281, 437, 321, 360, 294, 341, 3861, 51222], "temperature": 0.0, "avg_logprob": -0.11713990220078477, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.06003940850496292}, {"id": 148, "seek": 94824, "start": 965.4, "end": 970.96, "text": " maybe we should have a notion of a price. It's very simple to do that. You just introduce", "tokens": [51222, 1310, 321, 820, 362, 257, 10710, 295, 257, 3218, 13, 467, 311, 588, 2199, 281, 360, 300, 13, 509, 445, 5366, 51500], "temperature": 0.0, "avg_logprob": -0.11713990220078477, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.06003940850496292}, {"id": 149, "seek": 94824, "start": 970.96, "end": 975.36, "text": " a price type. Now you might be confused why we suddenly don't have a mean anymore. But", "tokens": [51500, 257, 3218, 2010, 13, 823, 291, 1062, 312, 9019, 983, 321, 5800, 500, 380, 362, 257, 914, 3602, 13, 583, 51720], "temperature": 0.0, "avg_logprob": -0.11713990220078477, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.06003940850496292}, {"id": 150, "seek": 97536, "start": 975.36, "end": 980.4, "text": " instead we have a sum in account. And the reason being that when we parse the files", "tokens": [50364, 2602, 321, 362, 257, 2408, 294, 2696, 13, 400, 264, 1778, 885, 300, 562, 321, 48377, 264, 7098, 50616], "temperature": 0.0, "avg_logprob": -0.184006545122932, "compression_ratio": 1.6126126126126126, "no_speech_prob": 0.015179711394011974}, {"id": 151, "seek": 97536, "start": 980.4, "end": 987.4, "text": " we update the sum and later on at the end we can calculate the mean. Which has some mathematical", "tokens": [50616, 321, 5623, 264, 2408, 293, 1780, 322, 412, 264, 917, 321, 393, 8873, 264, 914, 13, 3013, 575, 512, 18894, 50966], "temperature": 0.0, "avg_logprob": -0.184006545122932, "compression_ratio": 1.6126126126126126, "no_speech_prob": 0.015179711394011974}, {"id": 152, "seek": 97536, "start": 987.44, "end": 993.6800000000001, "text": " properties which are favorable because now we don't really have, we don't run into rounding", "tokens": [50968, 7221, 597, 366, 29557, 570, 586, 321, 500, 380, 534, 362, 11, 321, 500, 380, 1190, 666, 48237, 51280], "temperature": 0.0, "avg_logprob": -0.184006545122932, "compression_ratio": 1.6126126126126126, "no_speech_prob": 0.015179711394011974}, {"id": 153, "seek": 97536, "start": 993.6800000000001, "end": 999.32, "text": " issues anymore. This is an aggregation that we can do whenever we want to get kind of", "tokens": [51280, 2663, 3602, 13, 639, 307, 364, 16743, 399, 300, 321, 393, 360, 5699, 321, 528, 281, 483, 733, 295, 51562], "temperature": 0.0, "avg_logprob": -0.184006545122932, "compression_ratio": 1.6126126126126126, "no_speech_prob": 0.015179711394011974}, {"id": 154, "seek": 99932, "start": 999.32, "end": 1005.7600000000001, "text": " a mean on the fly. And at the same time we have a default. Now the default is not really", "tokens": [50364, 257, 914, 322, 264, 3603, 13, 400, 412, 264, 912, 565, 321, 362, 257, 7576, 13, 823, 264, 7576, 307, 406, 534, 50686], "temperature": 0.0, "avg_logprob": -0.1258276635473901, "compression_ratio": 1.643835616438356, "no_speech_prob": 0.0038230170030146837}, {"id": 155, "seek": 99932, "start": 1005.7600000000001, "end": 1012.36, "text": " idiomatic too I would say. But the great part about it is that we can later reuse it and", "tokens": [50686, 18014, 13143, 886, 286, 576, 584, 13, 583, 264, 869, 644, 466, 309, 307, 300, 321, 393, 1780, 26225, 309, 293, 51016], "temperature": 0.0, "avg_logprob": -0.1258276635473901, "compression_ratio": 1.643835616438356, "no_speech_prob": 0.0038230170030146837}, {"id": 156, "seek": 99932, "start": 1012.36, "end": 1018.36, "text": " make our code a little more readable. In this case we set the min price to the maximum float.", "tokens": [51016, 652, 527, 3089, 257, 707, 544, 49857, 13, 682, 341, 1389, 321, 992, 264, 923, 3218, 281, 264, 6674, 15706, 13, 51316], "temperature": 0.0, "avg_logprob": -0.1258276635473901, "compression_ratio": 1.643835616438356, "no_speech_prob": 0.0038230170030146837}, {"id": 157, "seek": 99932, "start": 1018.36, "end": 1023.48, "text": " But then whenever we introduce a new price it will overwrite the maximum because I guess", "tokens": [51316, 583, 550, 5699, 321, 5366, 257, 777, 3218, 309, 486, 670, 21561, 264, 6674, 570, 286, 2041, 51572], "temperature": 0.0, "avg_logprob": -0.1258276635473901, "compression_ratio": 1.643835616438356, "no_speech_prob": 0.0038230170030146837}, {"id": 158, "seek": 102348, "start": 1023.48, "end": 1029.6, "text": " by definition it's smaller than the maximum or smaller or equal. And same for the max", "tokens": [50364, 538, 7123, 309, 311, 4356, 813, 264, 6674, 420, 4356, 420, 2681, 13, 400, 912, 337, 264, 11469, 50670], "temperature": 0.0, "avg_logprob": -0.14982736760919743, "compression_ratio": 1.685823754789272, "no_speech_prob": 0.0015974882990121841}, {"id": 159, "seek": 102348, "start": 1029.6, "end": 1036.32, "text": " and some in account are kind of set to zero to begin with. And just before we bring it", "tokens": [50670, 293, 512, 294, 2696, 366, 733, 295, 992, 281, 4018, 281, 1841, 365, 13, 400, 445, 949, 321, 1565, 309, 51006], "temperature": 0.0, "avg_logprob": -0.14982736760919743, "compression_ratio": 1.685823754789272, "no_speech_prob": 0.0015974882990121841}, {"id": 160, "seek": 102348, "start": 1036.32, "end": 1042.16, "text": " all together here's one more thing that we should do which is have a notion of a display", "tokens": [51006, 439, 1214, 510, 311, 472, 544, 551, 300, 321, 820, 360, 597, 307, 362, 257, 10710, 295, 257, 4674, 51298], "temperature": 0.0, "avg_logprob": -0.14982736760919743, "compression_ratio": 1.685823754789272, "no_speech_prob": 0.0015974882990121841}, {"id": 161, "seek": 102348, "start": 1042.16, "end": 1047.96, "text": " for price. In this case we implement the display trade and we say yeah if ever you want to", "tokens": [51298, 337, 3218, 13, 682, 341, 1389, 321, 4445, 264, 4674, 4923, 293, 321, 584, 1338, 498, 1562, 291, 528, 281, 51588], "temperature": 0.0, "avg_logprob": -0.14982736760919743, "compression_ratio": 1.685823754789272, "no_speech_prob": 0.0015974882990121841}, {"id": 162, "seek": 102348, "start": 1047.96, "end": 1052.64, "text": " print a price this is the structure that you should use. The min, the mean and the max.", "tokens": [51588, 4482, 257, 3218, 341, 307, 264, 3877, 300, 291, 820, 764, 13, 440, 923, 11, 264, 914, 293, 264, 11469, 13, 51822], "temperature": 0.0, "avg_logprob": -0.14982736760919743, "compression_ratio": 1.685823754789272, "no_speech_prob": 0.0015974882990121841}, {"id": 163, "seek": 105264, "start": 1052.64, "end": 1058.2, "text": " And then this way we can make our code way more readable. Now you can see that instead", "tokens": [50364, 400, 550, 341, 636, 321, 393, 652, 527, 3089, 636, 544, 49857, 13, 823, 291, 393, 536, 300, 2602, 50642], "temperature": 0.0, "avg_logprob": -0.1676670430780767, "compression_ratio": 1.7067307692307692, "no_speech_prob": 0.02753393165767193}, {"id": 164, "seek": 105264, "start": 1058.2, "end": 1065.4, "text": " of using a tuple or floats here we use a price. And when we update the prices we can talk", "tokens": [50642, 295, 1228, 257, 2604, 781, 420, 37878, 510, 321, 764, 257, 3218, 13, 400, 562, 321, 5623, 264, 7901, 321, 393, 751, 51002], "temperature": 0.0, "avg_logprob": -0.1676670430780767, "compression_ratio": 1.7067307692307692, "no_speech_prob": 0.02753393165767193}, {"id": 165, "seek": 105264, "start": 1065.4, "end": 1070.4, "text": " about this object. We can tell the object hey update your min for example. Here we say", "tokens": [51002, 466, 341, 2657, 13, 492, 393, 980, 264, 2657, 4177, 5623, 428, 923, 337, 1365, 13, 1692, 321, 584, 51252], "temperature": 0.0, "avg_logprob": -0.1676670430780767, "compression_ratio": 1.7067307692307692, "no_speech_prob": 0.02753393165767193}, {"id": 166, "seek": 105264, "start": 1070.4, "end": 1077.0800000000002, "text": " price.min.min holds a price and we automatically get the min price as well. We update those", "tokens": [51252, 3218, 13, 2367, 13, 2367, 9190, 257, 3218, 293, 321, 6772, 483, 264, 923, 3218, 382, 731, 13, 492, 5623, 729, 51586], "temperature": 0.0, "avg_logprob": -0.1676670430780767, "compression_ratio": 1.7067307692307692, "no_speech_prob": 0.02753393165767193}, {"id": 167, "seek": 107708, "start": 1077.08, "end": 1087.3999999999999, "text": " price fields and yeah we can even introduce a price.add method. I don't show it here but", "tokens": [50364, 3218, 7909, 293, 1338, 321, 393, 754, 5366, 257, 3218, 13, 25224, 3170, 13, 286, 500, 380, 855, 309, 510, 457, 50880], "temperature": 0.0, "avg_logprob": -0.19332465305123278, "compression_ratio": 1.5172413793103448, "no_speech_prob": 0.014492694288492203}, {"id": 168, "seek": 107708, "start": 1087.3999999999999, "end": 1092.9199999999998, "text": " technically why not. We can add a new hold up price. Prices could be added over time.", "tokens": [50880, 12120, 983, 406, 13, 492, 393, 909, 257, 777, 1797, 493, 3218, 13, 430, 24373, 727, 312, 3869, 670, 565, 13, 51156], "temperature": 0.0, "avg_logprob": -0.19332465305123278, "compression_ratio": 1.5172413793103448, "no_speech_prob": 0.014492694288492203}, {"id": 169, "seek": 107708, "start": 1092.9199999999998, "end": 1100.48, "text": " Now that depends on I guess your taste, your flavor of rust. This is the entire code. It's", "tokens": [51156, 823, 300, 5946, 322, 286, 2041, 428, 3939, 11, 428, 6813, 295, 15259, 13, 639, 307, 264, 2302, 3089, 13, 467, 311, 51534], "temperature": 0.0, "avg_logprob": -0.19332465305123278, "compression_ratio": 1.5172413793103448, "no_speech_prob": 0.014492694288492203}, {"id": 170, "seek": 107708, "start": 1100.48, "end": 1104.72, "text": " a little longer but you saw all the parts. And now you have something that I would say", "tokens": [51534, 257, 707, 2854, 457, 291, 1866, 439, 264, 3166, 13, 400, 586, 291, 362, 746, 300, 286, 576, 584, 51746], "temperature": 0.0, "avg_logprob": -0.19332465305123278, "compression_ratio": 1.5172413793103448, "no_speech_prob": 0.014492694288492203}, {"id": 171, "seek": 110472, "start": 1104.72, "end": 1114.68, "text": " isn't a workable state. It's not great but we did one thing. We considered rust. We thought", "tokens": [50364, 1943, 380, 257, 589, 712, 1785, 13, 467, 311, 406, 869, 457, 321, 630, 472, 551, 13, 492, 4888, 15259, 13, 492, 1194, 50862], "temperature": 0.0, "avg_logprob": -0.14665709275465746, "compression_ratio": 1.5930232558139534, "no_speech_prob": 0.093868687748909}, {"id": 172, "seek": 110472, "start": 1114.68, "end": 1121.88, "text": " the ignorance. We started to embrace the rust type system. We started to lean into ownership", "tokens": [50862, 264, 25390, 13, 492, 1409, 281, 14038, 264, 15259, 2010, 1185, 13, 492, 1409, 281, 11659, 666, 15279, 51222], "temperature": 0.0, "avg_logprob": -0.14665709275465746, "compression_ratio": 1.5930232558139534, "no_speech_prob": 0.093868687748909}, {"id": 173, "seek": 110472, "start": 1121.88, "end": 1128.08, "text": " and borrowing which are fundamental concepts in rust. We lean into design patterns and we", "tokens": [51222, 293, 35024, 597, 366, 8088, 10392, 294, 15259, 13, 492, 11659, 666, 1715, 8294, 293, 321, 51532], "temperature": 0.0, "avg_logprob": -0.14665709275465746, "compression_ratio": 1.5930232558139534, "no_speech_prob": 0.093868687748909}, {"id": 174, "seek": 112808, "start": 1128.08, "end": 1134.6, "text": " learn how to improve our architecture. And I would also say if you want to improve this", "tokens": [50364, 1466, 577, 281, 3470, 527, 9482, 13, 400, 286, 576, 611, 584, 498, 291, 528, 281, 3470, 341, 50690], "temperature": 0.0, "avg_logprob": -0.12900484525240385, "compression_ratio": 1.6844106463878328, "no_speech_prob": 0.1966753900051117}, {"id": 175, "seek": 112808, "start": 1134.6, "end": 1139.36, "text": " part try to learn a different programming paradigm. Rust is not the only language. Try", "tokens": [50690, 644, 853, 281, 1466, 257, 819, 9410, 24709, 13, 34952, 307, 406, 264, 787, 2856, 13, 6526, 50928], "temperature": 0.0, "avg_logprob": -0.12900484525240385, "compression_ratio": 1.6844106463878328, "no_speech_prob": 0.1966753900051117}, {"id": 176, "seek": 112808, "start": 1139.36, "end": 1144.24, "text": " rock or try a functional language like Haskell. It might make you a better rust programmer", "tokens": [50928, 3727, 420, 853, 257, 11745, 2856, 411, 8646, 43723, 13, 467, 1062, 652, 291, 257, 1101, 15259, 32116, 51172], "temperature": 0.0, "avg_logprob": -0.12900484525240385, "compression_ratio": 1.6844106463878328, "no_speech_prob": 0.1966753900051117}, {"id": 177, "seek": 112808, "start": 1144.24, "end": 1150.8799999999999, "text": " too. This is how you fight ignorance. Now if you see that none of these horsemen fit", "tokens": [51172, 886, 13, 639, 307, 577, 291, 2092, 25390, 13, 823, 498, 291, 536, 300, 6022, 295, 613, 6832, 2558, 3318, 51504], "temperature": 0.0, "avg_logprob": -0.12900484525240385, "compression_ratio": 1.6844106463878328, "no_speech_prob": 0.1966753900051117}, {"id": 178, "seek": 112808, "start": 1150.8799999999999, "end": 1155.12, "text": " to you by the way just think of your colleagues how you would want to introduce them to rust", "tokens": [51504, 281, 291, 538, 264, 636, 445, 519, 295, 428, 7734, 577, 291, 576, 528, 281, 5366, 552, 281, 15259, 51716], "temperature": 0.0, "avg_logprob": -0.12900484525240385, "compression_ratio": 1.6844106463878328, "no_speech_prob": 0.1966753900051117}, {"id": 179, "seek": 115512, "start": 1155.12, "end": 1158.9199999999998, "text": " because this is the code you have to review and also probably maintain in the future. So", "tokens": [50364, 570, 341, 307, 264, 3089, 291, 362, 281, 3131, 293, 611, 1391, 6909, 294, 264, 2027, 13, 407, 50554], "temperature": 0.0, "avg_logprob": -0.130770241772687, "compression_ratio": 1.6704119850187267, "no_speech_prob": 0.031101083382964134}, {"id": 180, "seek": 115512, "start": 1158.9199999999998, "end": 1164.32, "text": " it's time well invested. If you want to learn more about idiomatic rust specifically there", "tokens": [50554, 309, 311, 565, 731, 13104, 13, 759, 291, 528, 281, 1466, 544, 466, 18014, 13143, 15259, 4682, 456, 50824], "temperature": 0.0, "avg_logprob": -0.130770241772687, "compression_ratio": 1.6704119850187267, "no_speech_prob": 0.031101083382964134}, {"id": 181, "seek": 115512, "start": 1164.32, "end": 1171.56, "text": " is a website. I just put it there. It's an open source repository. It has some resources.", "tokens": [50824, 307, 257, 3144, 13, 286, 445, 829, 309, 456, 13, 467, 311, 364, 1269, 4009, 25841, 13, 467, 575, 512, 3593, 13, 51186], "temperature": 0.0, "avg_logprob": -0.130770241772687, "compression_ratio": 1.6704119850187267, "no_speech_prob": 0.031101083382964134}, {"id": 182, "seek": 115512, "start": 1171.56, "end": 1177.36, "text": " This is a rendered version of it. You can sort by difficulty so that's your experience", "tokens": [51186, 639, 307, 257, 28748, 3037, 295, 309, 13, 509, 393, 1333, 538, 10360, 370, 300, 311, 428, 1752, 51476], "temperature": 0.0, "avg_logprob": -0.130770241772687, "compression_ratio": 1.6704119850187267, "no_speech_prob": 0.031101083382964134}, {"id": 183, "seek": 115512, "start": 1177.36, "end": 1182.1599999999999, "text": " and then you can sort by interactivity if you want to have a workshop or not. For example", "tokens": [51476, 293, 550, 291, 393, 1333, 538, 4648, 4253, 498, 291, 528, 281, 362, 257, 13541, 420, 406, 13, 1171, 1365, 51716], "temperature": 0.0, "avg_logprob": -0.130770241772687, "compression_ratio": 1.6704119850187267, "no_speech_prob": 0.031101083382964134}, {"id": 184, "seek": 118216, "start": 1182.2, "end": 1187.76, "text": " there are free resources on there and paid resources too. Right let's go on and look", "tokens": [50366, 456, 366, 1737, 3593, 322, 456, 293, 4835, 3593, 886, 13, 1779, 718, 311, 352, 322, 293, 574, 50644], "temperature": 0.0, "avg_logprob": -0.14448338288527268, "compression_ratio": 1.720472440944882, "no_speech_prob": 0.005292442627251148}, {"id": 185, "seek": 118216, "start": 1187.76, "end": 1194.48, "text": " at the next horsemen. Excessive abstraction. Everyone in this audience knows someone like", "tokens": [50644, 412, 264, 958, 6832, 2558, 13, 2111, 780, 488, 37765, 13, 5198, 294, 341, 4034, 3255, 1580, 411, 50980], "temperature": 0.0, "avg_logprob": -0.14448338288527268, "compression_ratio": 1.720472440944882, "no_speech_prob": 0.005292442627251148}, {"id": 186, "seek": 118216, "start": 1194.48, "end": 1200.76, "text": " that. They try to over engineer solutions because rust leans into that. It allows you", "tokens": [50980, 300, 13, 814, 853, 281, 670, 11403, 6547, 570, 15259, 476, 599, 666, 300, 13, 467, 4045, 291, 51294], "temperature": 0.0, "avg_logprob": -0.14448338288527268, "compression_ratio": 1.720472440944882, "no_speech_prob": 0.005292442627251148}, {"id": 187, "seek": 118216, "start": 1200.76, "end": 1205.6000000000001, "text": " to do that. It's a nice language to write abstractions. Everyone likes to do that. But", "tokens": [51294, 281, 360, 300, 13, 467, 311, 257, 1481, 2856, 281, 2464, 12649, 626, 13, 5198, 5902, 281, 360, 300, 13, 583, 51536], "temperature": 0.0, "avg_logprob": -0.14448338288527268, "compression_ratio": 1.720472440944882, "no_speech_prob": 0.005292442627251148}, {"id": 188, "seek": 118216, "start": 1205.6000000000001, "end": 1210.0, "text": " then you add layers of indirection that maybe people don't necessarily understand if they", "tokens": [51536, 550, 291, 909, 7914, 295, 1016, 621, 882, 300, 1310, 561, 500, 380, 4725, 1223, 498, 436, 51756], "temperature": 0.0, "avg_logprob": -0.14448338288527268, "compression_ratio": 1.720472440944882, "no_speech_prob": 0.005292442627251148}, {"id": 189, "seek": 121000, "start": 1210.04, "end": 1215.2, "text": " come from a different background. They use trade successively and generics and lifetimes", "tokens": [50366, 808, 490, 257, 819, 3678, 13, 814, 764, 4923, 2245, 3413, 293, 1337, 1167, 293, 4545, 302, 1532, 50624], "temperature": 0.0, "avg_logprob": -0.1592633635909469, "compression_ratio": 1.592760180995475, "no_speech_prob": 0.014935391955077648}, {"id": 190, "seek": 121000, "start": 1215.2, "end": 1221.72, "text": " and all of these concepts are great in isolation. The combination of which makes the programs", "tokens": [50624, 293, 439, 295, 613, 10392, 366, 869, 294, 16001, 13, 440, 6562, 295, 597, 1669, 264, 4268, 50950], "temperature": 0.0, "avg_logprob": -0.1592633635909469, "compression_ratio": 1.592760180995475, "no_speech_prob": 0.014935391955077648}, {"id": 191, "seek": 121000, "start": 1221.72, "end": 1226.84, "text": " hard to read and understand for newcomers. Now if you find yourself in this camp try", "tokens": [50950, 1152, 281, 1401, 293, 1223, 337, 40014, 433, 13, 823, 498, 291, 915, 1803, 294, 341, 2255, 853, 51206], "temperature": 0.0, "avg_logprob": -0.1592633635909469, "compression_ratio": 1.592760180995475, "no_speech_prob": 0.014935391955077648}, {"id": 192, "seek": 121000, "start": 1226.84, "end": 1234.72, "text": " to fight this as well. Common symptoms of this are things like this where you have a", "tokens": [51206, 281, 2092, 341, 382, 731, 13, 18235, 8332, 295, 341, 366, 721, 411, 341, 689, 291, 362, 257, 51600], "temperature": 0.0, "avg_logprob": -0.1592633635909469, "compression_ratio": 1.592760180995475, "no_speech_prob": 0.014935391955077648}, {"id": 193, "seek": 123472, "start": 1234.72, "end": 1240.72, "text": " file builder which takes a t as ref of str and a lifetime of a and this makes sure that", "tokens": [50364, 3991, 27377, 597, 2516, 257, 256, 382, 1895, 295, 1056, 293, 257, 11364, 295, 257, 293, 341, 1669, 988, 300, 50664], "temperature": 0.0, "avg_logprob": -0.1455882041008918, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.1643102467060089}, {"id": 194, "seek": 123472, "start": 1240.72, "end": 1247.16, "text": " you can pass any type and that it has no allocations that are not visible because of the lifetimes.", "tokens": [50664, 291, 393, 1320, 604, 2010, 293, 300, 309, 575, 572, 12660, 763, 300, 366, 406, 8974, 570, 295, 264, 4545, 302, 1532, 13, 50986], "temperature": 0.0, "avg_logprob": -0.1455882041008918, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.1643102467060089}, {"id": 195, "seek": 123472, "start": 1247.16, "end": 1253.3600000000001, "text": " So this might be fast and it might also to some extent be idiomatic but it is something", "tokens": [50986, 407, 341, 1062, 312, 2370, 293, 309, 1062, 611, 281, 512, 8396, 312, 18014, 13143, 457, 309, 307, 746, 51296], "temperature": 0.0, "avg_logprob": -0.1455882041008918, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.1643102467060089}, {"id": 196, "seek": 123472, "start": 1253.3600000000001, "end": 1258.16, "text": " that your colleagues also have to understand. Another thing is I might use this again. Let's", "tokens": [51296, 300, 428, 7734, 611, 362, 281, 1223, 13, 3996, 551, 307, 286, 1062, 764, 341, 797, 13, 961, 311, 51536], "temperature": 0.0, "avg_logprob": -0.1455882041008918, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.1643102467060089}, {"id": 197, "seek": 125816, "start": 1258.16, "end": 1266.16, "text": " make it generic or trades everywhere. And how do you get to that mindset? It's very", "tokens": [50364, 652, 309, 19577, 420, 21287, 5315, 13, 400, 577, 360, 291, 483, 281, 300, 12543, 30, 467, 311, 588, 50764], "temperature": 0.0, "avg_logprob": -0.192911451513117, "compression_ratio": 1.6367924528301887, "no_speech_prob": 0.16198678314685822}, {"id": 198, "seek": 125816, "start": 1266.16, "end": 1272.6000000000001, "text": " simple. After you wrote your CSV parser it's natural that you want other parsers too. Of", "tokens": [50764, 2199, 13, 2381, 291, 4114, 428, 48814, 21156, 260, 309, 311, 3303, 300, 291, 528, 661, 21156, 433, 886, 13, 2720, 51086], "temperature": 0.0, "avg_logprob": -0.192911451513117, "compression_ratio": 1.6367924528301887, "no_speech_prob": 0.16198678314685822}, {"id": 199, "seek": 125816, "start": 1272.6000000000001, "end": 1277.8000000000002, "text": " course you want to chase on. Of course you want to read and write into a database. You", "tokens": [51086, 1164, 291, 528, 281, 15359, 322, 13, 2720, 1164, 291, 528, 281, 1401, 293, 2464, 666, 257, 8149, 13, 509, 51346], "temperature": 0.0, "avg_logprob": -0.192911451513117, "compression_ratio": 1.6367924528301887, "no_speech_prob": 0.16198678314685822}, {"id": 200, "seek": 125816, "start": 1277.8000000000002, "end": 1284.1200000000001, "text": " start thinking that you'll need all of those formats at some point and this is the part", "tokens": [51346, 722, 1953, 300, 291, 603, 643, 439, 295, 729, 25879, 412, 512, 935, 293, 341, 307, 264, 644, 51662], "temperature": 0.0, "avg_logprob": -0.192911451513117, "compression_ratio": 1.6367924528301887, "no_speech_prob": 0.16198678314685822}, {"id": 201, "seek": 128412, "start": 1284.12, "end": 1290.9599999999998, "text": " that is important at some point. And then you end up with something like this. It's", "tokens": [50364, 300, 307, 1021, 412, 512, 935, 13, 400, 550, 291, 917, 493, 365, 746, 411, 341, 13, 467, 311, 50706], "temperature": 0.0, "avg_logprob": -0.17250212033589682, "compression_ratio": 1.7244897959183674, "no_speech_prob": 0.09516730904579163}, {"id": 202, "seek": 128412, "start": 1290.9599999999998, "end": 1296.9599999999998, "text": " a trade definition for a hotel reader and it has a single method called read and it", "tokens": [50706, 257, 4923, 7123, 337, 257, 7622, 15149, 293, 309, 575, 257, 2167, 3170, 1219, 1401, 293, 309, 51006], "temperature": 0.0, "avg_logprob": -0.17250212033589682, "compression_ratio": 1.7244897959183674, "no_speech_prob": 0.09516730904579163}, {"id": 203, "seek": 128412, "start": 1296.9599999999998, "end": 1303.04, "text": " takes a self that's why it's a method but it also takes a read which implements the", "tokens": [51006, 2516, 257, 2698, 300, 311, 983, 309, 311, 257, 3170, 457, 309, 611, 2516, 257, 1401, 597, 704, 17988, 264, 51310], "temperature": 0.0, "avg_logprob": -0.17250212033589682, "compression_ratio": 1.7244897959183674, "no_speech_prob": 0.09516730904579163}, {"id": 204, "seek": 128412, "start": 1303.04, "end": 1308.8, "text": " read. That means you can pass anything that implements the read trade and it returns a", "tokens": [51310, 1401, 13, 663, 1355, 291, 393, 1320, 1340, 300, 704, 17988, 264, 1401, 4923, 293, 309, 11247, 257, 51598], "temperature": 0.0, "avg_logprob": -0.17250212033589682, "compression_ratio": 1.7244897959183674, "no_speech_prob": 0.09516730904579163}, {"id": 205, "seek": 130880, "start": 1308.8, "end": 1317.04, "text": " box of iterator of item equals result hotel with a lifetime of A. No allocations except", "tokens": [50364, 2424, 295, 17138, 1639, 295, 3174, 6915, 1874, 7622, 365, 257, 11364, 295, 316, 13, 883, 12660, 763, 3993, 50776], "temperature": 0.0, "avg_logprob": -0.1470811976942905, "compression_ratio": 1.644859813084112, "no_speech_prob": 0.08026569336652756}, {"id": 206, "seek": 130880, "start": 1317.04, "end": 1324.24, "text": " for the box but the iterator itself is a very idiomatic way to say a result of hotel so", "tokens": [50776, 337, 264, 2424, 457, 264, 17138, 1639, 2564, 307, 257, 588, 18014, 13143, 636, 281, 584, 257, 1874, 295, 7622, 370, 51136], "temperature": 0.0, "avg_logprob": -0.1470811976942905, "compression_ratio": 1.644859813084112, "no_speech_prob": 0.08026569336652756}, {"id": 207, "seek": 130880, "start": 1324.24, "end": 1329.08, "text": " parsing errors are considered and it's very applicable for all of the reader types that", "tokens": [51136, 21156, 278, 13603, 366, 4888, 293, 309, 311, 588, 21142, 337, 439, 295, 264, 15149, 3467, 300, 51378], "temperature": 0.0, "avg_logprob": -0.1470811976942905, "compression_ratio": 1.644859813084112, "no_speech_prob": 0.08026569336652756}, {"id": 208, "seek": 130880, "start": 1329.08, "end": 1333.68, "text": " you could possibly want. Let's say you wanted to use that trade and implement it for our", "tokens": [51378, 291, 727, 6264, 528, 13, 961, 311, 584, 291, 1415, 281, 764, 300, 4923, 293, 4445, 309, 337, 527, 51608], "temperature": 0.0, "avg_logprob": -0.1470811976942905, "compression_ratio": 1.644859813084112, "no_speech_prob": 0.08026569336652756}, {"id": 209, "seek": 133368, "start": 1333.68, "end": 1340.1200000000001, "text": " hotel reader. Now suddenly we blow up the code to something that is harder to understand", "tokens": [50364, 7622, 15149, 13, 823, 5800, 321, 6327, 493, 264, 3089, 281, 746, 300, 307, 6081, 281, 1223, 50686], "temperature": 0.0, "avg_logprob": -0.15147540735643963, "compression_ratio": 1.704225352112676, "no_speech_prob": 0.1823105812072754}, {"id": 210, "seek": 133368, "start": 1340.1200000000001, "end": 1346.68, "text": " or if it is easy for you to understand please reconsider if your abstractions are too much.", "tokens": [50686, 420, 498, 309, 307, 1858, 337, 291, 281, 1223, 1767, 40497, 498, 428, 12649, 626, 366, 886, 709, 13, 51014], "temperature": 0.0, "avg_logprob": -0.15147540735643963, "compression_ratio": 1.704225352112676, "no_speech_prob": 0.1823105812072754}, {"id": 211, "seek": 133368, "start": 1346.68, "end": 1353.0, "text": " Maybe you ain't going to need it. Right. So we have a hotel reader and it owns a reader", "tokens": [51014, 2704, 291, 7862, 380, 516, 281, 643, 309, 13, 1779, 13, 407, 321, 362, 257, 7622, 15149, 293, 309, 19143, 257, 15149, 51330], "temperature": 0.0, "avg_logprob": -0.15147540735643963, "compression_ratio": 1.704225352112676, "no_speech_prob": 0.1823105812072754}, {"id": 212, "seek": 133368, "start": 1353.0, "end": 1361.3200000000002, "text": " builder and inside of our new method we initialize the CSV hotel reader and we implement hotel", "tokens": [51330, 27377, 293, 1854, 295, 527, 777, 3170, 321, 5883, 1125, 264, 48814, 7622, 15149, 293, 321, 4445, 7622, 51746], "temperature": 0.0, "avg_logprob": -0.15147540735643963, "compression_ratio": 1.704225352112676, "no_speech_prob": 0.1823105812072754}, {"id": 213, "seek": 136132, "start": 1361.32, "end": 1368.32, "text": " reader down here. The single method called read and we say self.reader builder this is", "tokens": [50364, 15149, 760, 510, 13, 440, 2167, 3170, 1219, 1401, 293, 321, 584, 2698, 13, 2538, 260, 27377, 341, 307, 50714], "temperature": 0.0, "avg_logprob": -0.22070174164824433, "compression_ratio": 1.5701357466063348, "no_speech_prob": 0.016387490555644035}, {"id": 214, "seek": 136132, "start": 1368.32, "end": 1373.8, "text": " the code that we saw before we just put it here this is our CSV parser the initialization", "tokens": [50714, 264, 3089, 300, 321, 1866, 949, 321, 445, 829, 309, 510, 341, 307, 527, 48814, 21156, 260, 264, 5883, 2144, 50988], "temperature": 0.0, "avg_logprob": -0.22070174164824433, "compression_ratio": 1.5701357466063348, "no_speech_prob": 0.016387490555644035}, {"id": 215, "seek": 136132, "start": 1373.8, "end": 1380.76, "text": " of it and then we return a reader.into the serialized hotel map and this is where we", "tokens": [50988, 295, 309, 293, 550, 321, 2736, 257, 15149, 13, 17246, 264, 17436, 1602, 7622, 4471, 293, 341, 307, 689, 321, 51336], "temperature": 0.0, "avg_logprob": -0.22070174164824433, "compression_ratio": 1.5701357466063348, "no_speech_prob": 0.016387490555644035}, {"id": 216, "seek": 136132, "start": 1380.76, "end": 1390.4399999999998, "text": " map the errors. Right. Does it look great? I don't know depends on someone's nodding.", "tokens": [51336, 4471, 264, 13603, 13, 1779, 13, 4402, 309, 574, 869, 30, 286, 500, 380, 458, 5946, 322, 1580, 311, 15224, 3584, 13, 51820], "temperature": 0.0, "avg_logprob": -0.22070174164824433, "compression_ratio": 1.5701357466063348, "no_speech_prob": 0.016387490555644035}, {"id": 217, "seek": 139044, "start": 1390.44, "end": 1399.0, "text": " We need to talk but it's certainly nice to use I guess. Now we can say for hotel in hotels.read", "tokens": [50364, 492, 643, 281, 751, 457, 309, 311, 3297, 1481, 281, 764, 286, 2041, 13, 823, 321, 393, 584, 337, 7622, 294, 22718, 13, 2538, 50792], "temperature": 0.0, "avg_logprob": -0.19017847724582837, "compression_ratio": 1.6311111111111112, "no_speech_prob": 0.1049485132098198}, {"id": 218, "seek": 139044, "start": 1399.0, "end": 1408.2, "text": " file. Should hotels know about files? Maybe not. But it's great if you go one step further", "tokens": [50792, 3991, 13, 6454, 22718, 458, 466, 7098, 30, 2704, 406, 13, 583, 309, 311, 869, 498, 291, 352, 472, 1823, 3052, 51252], "temperature": 0.0, "avg_logprob": -0.19017847724582837, "compression_ratio": 1.6311111111111112, "no_speech_prob": 0.1049485132098198}, {"id": 219, "seek": 139044, "start": 1408.2, "end": 1413.64, "text": " and you implement iterator on it and now you can say for hotel in hotels. Alright we're", "tokens": [51252, 293, 291, 4445, 17138, 1639, 322, 309, 293, 586, 291, 393, 584, 337, 7622, 294, 22718, 13, 2798, 321, 434, 51524], "temperature": 0.0, "avg_logprob": -0.19017847724582837, "compression_ratio": 1.6311111111111112, "no_speech_prob": 0.1049485132098198}, {"id": 220, "seek": 139044, "start": 1413.64, "end": 1418.8400000000001, "text": " getting somewhere from a user's perspective that is really great. But remember we're talking", "tokens": [51524, 1242, 4079, 490, 257, 4195, 311, 4585, 300, 307, 534, 869, 13, 583, 1604, 321, 434, 1417, 51784], "temperature": 0.0, "avg_logprob": -0.19017847724582837, "compression_ratio": 1.6311111111111112, "no_speech_prob": 0.1049485132098198}, {"id": 221, "seek": 141884, "start": 1418.84, "end": 1423.1999999999998, "text": " about application code. There's probably code that you earn money with. It's not a", "tokens": [50364, 466, 3861, 3089, 13, 821, 311, 1391, 3089, 300, 291, 6012, 1460, 365, 13, 467, 311, 406, 257, 50582], "temperature": 0.0, "avg_logprob": -0.15756363704286772, "compression_ratio": 1.5535714285714286, "no_speech_prob": 0.03406398743391037}, {"id": 222, "seek": 141884, "start": 1423.1999999999998, "end": 1429.24, "text": " library function that is used by thousands of people. It's your simple CSV parser and", "tokens": [50582, 6405, 2445, 300, 307, 1143, 538, 5383, 295, 561, 13, 467, 311, 428, 2199, 48814, 21156, 260, 293, 50884], "temperature": 0.0, "avg_logprob": -0.15756363704286772, "compression_ratio": 1.5535714285714286, "no_speech_prob": 0.03406398743391037}, {"id": 223, "seek": 141884, "start": 1429.24, "end": 1434.36, "text": " now we just blew it up into something that is harder to understand. Do you really need", "tokens": [50884, 586, 321, 445, 19075, 309, 493, 666, 746, 300, 307, 6081, 281, 1223, 13, 1144, 291, 534, 643, 51140], "temperature": 0.0, "avg_logprob": -0.15756363704286772, "compression_ratio": 1.5535714285714286, "no_speech_prob": 0.03406398743391037}, {"id": 224, "seek": 141884, "start": 1434.36, "end": 1445.6399999999999, "text": " this? Well I don't think so. I don't know what this person on the bull does but it certainly", "tokens": [51140, 341, 30, 1042, 286, 500, 380, 519, 370, 13, 286, 500, 380, 458, 437, 341, 954, 322, 264, 4693, 775, 457, 309, 3297, 51704], "temperature": 0.0, "avg_logprob": -0.15756363704286772, "compression_ratio": 1.5535714285714286, "no_speech_prob": 0.03406398743391037}, {"id": 225, "seek": 144564, "start": 1445.64, "end": 1452.76, "text": " looks confusing to me and this is what people think when they see the top signature. I know", "tokens": [50364, 1542, 13181, 281, 385, 293, 341, 307, 437, 561, 519, 562, 436, 536, 264, 1192, 13397, 13, 286, 458, 50720], "temperature": 0.0, "avg_logprob": -0.19554275690123094, "compression_ratio": 1.5745614035087718, "no_speech_prob": 0.4210730791091919}, {"id": 226, "seek": 144564, "start": 1452.76, "end": 1459.5200000000002, "text": " kind of you wanted to optimize it a bit but at what cost? Right whenever you sit here", "tokens": [50720, 733, 295, 291, 1415, 281, 19719, 309, 257, 857, 457, 412, 437, 2063, 30, 1779, 5699, 291, 1394, 510, 51058], "temperature": 0.0, "avg_logprob": -0.19554275690123094, "compression_ratio": 1.5745614035087718, "no_speech_prob": 0.4210730791091919}, {"id": 227, "seek": 144564, "start": 1459.5200000000002, "end": 1465.76, "text": " and you think oh I should implement JSON support and you don't do it for fun. Start thinking", "tokens": [51058, 293, 291, 519, 1954, 286, 820, 4445, 31828, 1406, 293, 291, 500, 380, 360, 309, 337, 1019, 13, 6481, 1953, 51370], "temperature": 0.0, "avg_logprob": -0.19554275690123094, "compression_ratio": 1.5745614035087718, "no_speech_prob": 0.4210730791091919}, {"id": 228, "seek": 144564, "start": 1465.76, "end": 1474.3600000000001, "text": " if you really need those subscriptions because they can haunt you. Most of the time they", "tokens": [51370, 498, 291, 534, 643, 729, 44951, 570, 436, 393, 324, 2760, 291, 13, 4534, 295, 264, 565, 436, 51800], "temperature": 0.0, "avg_logprob": -0.19554275690123094, "compression_ratio": 1.5745614035087718, "no_speech_prob": 0.4210730791091919}, {"id": 229, "seek": 147436, "start": 1474.3999999999999, "end": 1481.28, "text": " don't have no need of it. I don't know what sort of animal this is. Is it a lion cat or", "tokens": [50366, 500, 380, 362, 572, 643, 295, 309, 13, 286, 500, 380, 458, 437, 1333, 295, 5496, 341, 307, 13, 1119, 309, 257, 17226, 3857, 420, 50710], "temperature": 0.0, "avg_logprob": -0.20448722337421618, "compression_ratio": 1.552325581395349, "no_speech_prob": 0.05022692680358887}, {"id": 230, "seek": 147436, "start": 1481.28, "end": 1487.52, "text": " something but it's kind of strapped to a cannon and it doesn't look too happy to me.", "tokens": [50710, 746, 457, 309, 311, 733, 295, 2148, 3320, 281, 257, 25938, 293, 309, 1177, 380, 574, 886, 2055, 281, 385, 13, 51022], "temperature": 0.0, "avg_logprob": -0.20448722337421618, "compression_ratio": 1.552325581395349, "no_speech_prob": 0.05022692680358887}, {"id": 231, "seek": 147436, "start": 1487.52, "end": 1502.6399999999999, "text": " I don't want this. Probably you're not going to need it. As a side note another thing probably", "tokens": [51022, 286, 500, 380, 528, 341, 13, 9210, 291, 434, 406, 516, 281, 643, 309, 13, 1018, 257, 1252, 3637, 1071, 551, 1391, 51778], "temperature": 0.0, "avg_logprob": -0.20448722337421618, "compression_ratio": 1.552325581395349, "no_speech_prob": 0.05022692680358887}, {"id": 232, "seek": 150264, "start": 1502.72, "end": 1507.6000000000001, "text": " you shouldn't do too often are macros. There are traits out there that excessively use", "tokens": [50368, 291, 4659, 380, 360, 886, 2049, 366, 7912, 2635, 13, 821, 366, 19526, 484, 456, 300, 9310, 3413, 764, 50612], "temperature": 0.0, "avg_logprob": -0.1431390170393319, "compression_ratio": 1.6577946768060836, "no_speech_prob": 0.28374943137168884}, {"id": 233, "seek": 150264, "start": 1507.6000000000001, "end": 1514.6000000000001, "text": " macros. What do I mean by macros? Macro rules but also macro derives and these are great", "tokens": [50612, 7912, 2635, 13, 708, 360, 286, 914, 538, 7912, 2635, 30, 5707, 340, 4474, 457, 611, 18887, 1163, 1539, 293, 613, 366, 869, 50962], "temperature": 0.0, "avg_logprob": -0.1431390170393319, "compression_ratio": 1.6577946768060836, "no_speech_prob": 0.28374943137168884}, {"id": 234, "seek": 150264, "start": 1514.6000000000001, "end": 1521.0400000000002, "text": " but they come at a cost and the cost could be compile times. Just yesterday I talked", "tokens": [50962, 457, 436, 808, 412, 257, 2063, 293, 264, 2063, 727, 312, 31413, 1413, 13, 1449, 5186, 286, 2825, 51284], "temperature": 0.0, "avg_logprob": -0.1431390170393319, "compression_ratio": 1.6577946768060836, "no_speech_prob": 0.28374943137168884}, {"id": 235, "seek": 150264, "start": 1521.0400000000002, "end": 1526.68, "text": " to Daniel Kerkman who I don't know is he here? He's not here. But thanks for the tip.", "tokens": [51284, 281, 8033, 591, 10608, 1601, 567, 286, 500, 380, 458, 307, 415, 510, 30, 634, 311, 406, 510, 13, 583, 3231, 337, 264, 4125, 13, 51566], "temperature": 0.0, "avg_logprob": -0.1431390170393319, "compression_ratio": 1.6577946768060836, "no_speech_prob": 0.28374943137168884}, {"id": 236, "seek": 150264, "start": 1526.68, "end": 1532.2800000000002, "text": " He has a situation at work where compile times just blow up because of macros and for you", "tokens": [51566, 634, 575, 257, 2590, 412, 589, 689, 31413, 1413, 445, 6327, 493, 570, 295, 7912, 2635, 293, 337, 291, 51846], "temperature": 0.0, "avg_logprob": -0.1431390170393319, "compression_ratio": 1.6577946768060836, "no_speech_prob": 0.28374943137168884}, {"id": 237, "seek": 153228, "start": 1532.3999999999999, "end": 1537.32, "text": " it might be easy to write but for other people it might be hard to use. Maybe you want to", "tokens": [50370, 309, 1062, 312, 1858, 281, 2464, 457, 337, 661, 561, 309, 1062, 312, 1152, 281, 764, 13, 2704, 291, 528, 281, 50616], "temperature": 0.0, "avg_logprob": -0.15324321607264077, "compression_ratio": 1.5462555066079295, "no_speech_prob": 0.0078009022399783134}, {"id": 238, "seek": 153228, "start": 1537.32, "end": 1544.16, "text": " prefer traits over macros if you can. That was the second horseman fighting excessive", "tokens": [50616, 4382, 19526, 670, 7912, 2635, 498, 291, 393, 13, 663, 390, 264, 1150, 6832, 1601, 5237, 22704, 50958], "temperature": 0.0, "avg_logprob": -0.15324321607264077, "compression_ratio": 1.5462555066079295, "no_speech_prob": 0.0078009022399783134}, {"id": 239, "seek": 153228, "start": 1544.16, "end": 1550.84, "text": " abstraction. How can it be done? If you find yourself in this situation keep it simple.", "tokens": [50958, 37765, 13, 1012, 393, 309, 312, 1096, 30, 759, 291, 915, 1803, 294, 341, 2590, 1066, 309, 2199, 13, 51292], "temperature": 0.0, "avg_logprob": -0.15324321607264077, "compression_ratio": 1.5462555066079295, "no_speech_prob": 0.0078009022399783134}, {"id": 240, "seek": 153228, "start": 1550.84, "end": 1556.8, "text": " Avoid unnecessary complexity. Just think that the person that will maintain the code is", "tokens": [51292, 41061, 19350, 14024, 13, 1449, 519, 300, 264, 954, 300, 486, 6909, 264, 3089, 307, 51590], "temperature": 0.0, "avg_logprob": -0.15324321607264077, "compression_ratio": 1.5462555066079295, "no_speech_prob": 0.0078009022399783134}, {"id": 241, "seek": 155680, "start": 1556.84, "end": 1563.44, "text": " not a mass murderer but your best friend. Do you treat friends like this? Watch newcomers", "tokens": [50366, 406, 257, 2758, 28703, 457, 428, 1151, 1277, 13, 1144, 291, 2387, 1855, 411, 341, 30, 7277, 40014, 433, 50696], "temperature": 0.0, "avg_logprob": -0.1389375084324887, "compression_ratio": 1.6306306306306306, "no_speech_prob": 0.054129526019096375}, {"id": 242, "seek": 155680, "start": 1563.44, "end": 1570.0, "text": " use your code. That can be humbling. Ensure that abstractions add value. Yes you can add", "tokens": [50696, 764, 428, 3089, 13, 663, 393, 312, 1484, 18262, 13, 25979, 540, 300, 12649, 626, 909, 2158, 13, 1079, 291, 393, 909, 51024], "temperature": 0.0, "avg_logprob": -0.1389375084324887, "compression_ratio": 1.6306306306306306, "no_speech_prob": 0.054129526019096375}, {"id": 243, "seek": 155680, "start": 1570.0, "end": 1577.0, "text": " a layer of abstraction. Does it add value? That's up to you. Decide and don't add introductions", "tokens": [51024, 257, 4583, 295, 37765, 13, 4402, 309, 909, 2158, 30, 663, 311, 493, 281, 291, 13, 12427, 482, 293, 500, 380, 909, 48032, 51374], "temperature": 0.0, "avg_logprob": -0.1389375084324887, "compression_ratio": 1.6306306306306306, "no_speech_prob": 0.054129526019096375}, {"id": 244, "seek": 155680, "start": 1577.52, "end": 1583.0, "text": " that you might need in the future. Add them when you need them. Right. Two off the list", "tokens": [51400, 300, 291, 1062, 643, 294, 264, 2027, 13, 5349, 552, 562, 291, 643, 552, 13, 1779, 13, 4453, 766, 264, 1329, 51674], "temperature": 0.0, "avg_logprob": -0.1389375084324887, "compression_ratio": 1.6306306306306306, "no_speech_prob": 0.054129526019096375}, {"id": 245, "seek": 158300, "start": 1583.04, "end": 1588.48, "text": " we have two more to go. Next one is premature optimization. This is for a lot of people", "tokens": [50366, 321, 362, 732, 544, 281, 352, 13, 3087, 472, 307, 34877, 19618, 13, 639, 307, 337, 257, 688, 295, 561, 50638], "temperature": 0.0, "avg_logprob": -0.1332100564306909, "compression_ratio": 1.5803571428571428, "no_speech_prob": 0.04593139514327049}, {"id": 246, "seek": 158300, "start": 1588.48, "end": 1594.6, "text": " in here because you are C and C++ programmers. I'm looking at you right now because 90%", "tokens": [50638, 294, 510, 570, 291, 366, 383, 293, 383, 25472, 41504, 13, 286, 478, 1237, 412, 291, 558, 586, 570, 4289, 4, 50944], "temperature": 0.0, "avg_logprob": -0.1332100564306909, "compression_ratio": 1.5803571428571428, "no_speech_prob": 0.04593139514327049}, {"id": 247, "seek": 158300, "start": 1594.6, "end": 1601.6, "text": " of you raised your hand. I see a lot of people from C and C++ come to Rust with this mindset", "tokens": [50944, 295, 291, 6005, 428, 1011, 13, 286, 536, 257, 688, 295, 561, 490, 383, 293, 383, 25472, 808, 281, 34952, 365, 341, 12543, 51294], "temperature": 0.0, "avg_logprob": -0.1332100564306909, "compression_ratio": 1.5803571428571428, "no_speech_prob": 0.04593139514327049}, {"id": 248, "seek": 158300, "start": 1601.96, "end": 1608.96, "text": " with these patterns. What are the patterns? They optimize before it's necessary. This", "tokens": [51312, 365, 613, 8294, 13, 708, 366, 264, 8294, 30, 814, 19719, 949, 309, 311, 4818, 13, 639, 51662], "temperature": 0.0, "avg_logprob": -0.1332100564306909, "compression_ratio": 1.5803571428571428, "no_speech_prob": 0.04593139514327049}, {"id": 249, "seek": 160896, "start": 1609.52, "end": 1616.52, "text": " is important different from adding too many layers of abstraction. Optimization in this", "tokens": [50392, 307, 1021, 819, 490, 5127, 886, 867, 7914, 295, 37765, 13, 35013, 2144, 294, 341, 50742], "temperature": 0.0, "avg_logprob": -0.1821250557899475, "compression_ratio": 1.5353982300884956, "no_speech_prob": 0.00208077160641551}, {"id": 250, "seek": 160896, "start": 1616.8, "end": 1623.8, "text": " case means profiling is not done but instead you kind of try to outsmart the compiler and", "tokens": [50756, 1389, 1355, 1740, 4883, 307, 406, 1096, 457, 2602, 291, 733, 295, 853, 281, 484, 10817, 446, 264, 31958, 293, 51106], "temperature": 0.0, "avg_logprob": -0.1821250557899475, "compression_ratio": 1.5353982300884956, "no_speech_prob": 0.00208077160641551}, {"id": 251, "seek": 160896, "start": 1624.4, "end": 1629.48, "text": " you think about performance optimizations way too early before you even need it. Did", "tokens": [51136, 291, 519, 466, 3389, 5028, 14455, 636, 886, 2440, 949, 291, 754, 643, 309, 13, 2589, 51390], "temperature": 0.0, "avg_logprob": -0.1821250557899475, "compression_ratio": 1.5353982300884956, "no_speech_prob": 0.00208077160641551}, {"id": 252, "seek": 160896, "start": 1629.48, "end": 1633.56, "text": " I even tell you how big that CSV file was in the beginning? How many entries does it", "tokens": [51390, 286, 754, 980, 291, 577, 955, 300, 48814, 3991, 390, 294, 264, 2863, 30, 1012, 867, 23041, 775, 309, 51594], "temperature": 0.0, "avg_logprob": -0.1821250557899475, "compression_ratio": 1.5353982300884956, "no_speech_prob": 0.00208077160641551}, {"id": 253, "seek": 163356, "start": 1633.6, "end": 1640.36, "text": " have? You don't know. Maybe you should not optimize for it right away. They use complex", "tokens": [50366, 362, 30, 509, 500, 380, 458, 13, 2704, 291, 820, 406, 19719, 337, 309, 558, 1314, 13, 814, 764, 3997, 50704], "temperature": 0.0, "avg_logprob": -0.15087741403018726, "compression_ratio": 1.5281385281385282, "no_speech_prob": 0.03065059892833233}, {"id": 254, "seek": 163356, "start": 1640.36, "end": 1647.36, "text": " data structures where simple ones would suffice. For example we saw the hash map with the three", "tokens": [50704, 1412, 9227, 689, 2199, 2306, 576, 3889, 573, 13, 1171, 1365, 321, 1866, 264, 22019, 4471, 365, 264, 1045, 51054], "temperature": 0.0, "avg_logprob": -0.15087741403018726, "compression_ratio": 1.5281385281385282, "no_speech_prob": 0.03065059892833233}, {"id": 255, "seek": 163356, "start": 1647.84, "end": 1652.96, "text": " tuple elements. These are things that are kind of unravel and then it ends up being", "tokens": [51078, 2604, 781, 4959, 13, 1981, 366, 721, 300, 366, 733, 295, 40507, 293, 550, 309, 5314, 493, 885, 51334], "temperature": 0.0, "avg_logprob": -0.15087741403018726, "compression_ratio": 1.5281385281385282, "no_speech_prob": 0.03065059892833233}, {"id": 256, "seek": 163356, "start": 1652.96, "end": 1659.96, "text": " a mess not very idiomatic and arguably not even faster. And they also have a tendency", "tokens": [51334, 257, 2082, 406, 588, 18014, 13143, 293, 26771, 406, 754, 4663, 13, 400, 436, 611, 362, 257, 18187, 51684], "temperature": 0.0, "avg_logprob": -0.15087741403018726, "compression_ratio": 1.5281385281385282, "no_speech_prob": 0.03065059892833233}, {"id": 257, "seek": 165996, "start": 1659.96, "end": 1666.96, "text": " to neglect benchmarks. Some red flags. Quotes you might have heard. Without a lifetime this", "tokens": [50364, 281, 17745, 43751, 13, 2188, 2182, 23265, 13, 2326, 17251, 291, 1062, 362, 2198, 13, 9129, 257, 11364, 341, 50714], "temperature": 0.0, "avg_logprob": -0.14255763073356784, "compression_ratio": 1.5316455696202531, "no_speech_prob": 0.004677043296396732}, {"id": 258, "seek": 165996, "start": 1667.8, "end": 1674.32, "text": " needs to be cloned. Ignore that. If you know that you have a performance problem then you", "tokens": [50756, 2203, 281, 312, 596, 19009, 13, 24754, 418, 300, 13, 759, 291, 458, 300, 291, 362, 257, 3389, 1154, 550, 291, 51082], "temperature": 0.0, "avg_logprob": -0.14255763073356784, "compression_ratio": 1.5316455696202531, "no_speech_prob": 0.004677043296396732}, {"id": 259, "seek": 165996, "start": 1674.32, "end": 1681.16, "text": " can think about lifetimes. It's fine to clone. Let me help the compiler here. The box is so", "tokens": [51082, 393, 519, 466, 4545, 302, 1532, 13, 467, 311, 2489, 281, 26506, 13, 961, 385, 854, 264, 31958, 510, 13, 440, 2424, 307, 370, 51424], "temperature": 0.0, "avg_logprob": -0.14255763073356784, "compression_ratio": 1.5316455696202531, "no_speech_prob": 0.004677043296396732}, {"id": 260, "seek": 165996, "start": 1681.16, "end": 1687.8400000000001, "text": " much overhead. I use B3Map because it's faster than hash map. No need to measure I've got", "tokens": [51424, 709, 19922, 13, 286, 764, 363, 18, 44, 569, 570, 309, 311, 4663, 813, 22019, 4471, 13, 883, 643, 281, 3481, 286, 600, 658, 51758], "temperature": 0.0, "avg_logprob": -0.14255763073356784, "compression_ratio": 1.5316455696202531, "no_speech_prob": 0.004677043296396732}, {"id": 261, "seek": 168784, "start": 1687.8799999999999, "end": 1694.8799999999999, "text": " years of experience. They love the term zero cost abstraction or zero copy. Actually it", "tokens": [50366, 924, 295, 1752, 13, 814, 959, 264, 1433, 4018, 2063, 37765, 420, 4018, 5055, 13, 5135, 309, 50716], "temperature": 0.0, "avg_logprob": -0.21869526534784037, "compression_ratio": 1.5423728813559323, "no_speech_prob": 0.0071100229397416115}, {"id": 262, "seek": 168784, "start": 1695.6, "end": 1701.6, "text": " should be zero cost in here. And they hate allocations. Whenever they look at an allocation", "tokens": [50752, 820, 312, 4018, 2063, 294, 510, 13, 400, 436, 4700, 12660, 763, 13, 14159, 436, 574, 412, 364, 27599, 51052], "temperature": 0.0, "avg_logprob": -0.21869526534784037, "compression_ratio": 1.5423728813559323, "no_speech_prob": 0.0071100229397416115}, {"id": 263, "seek": 168784, "start": 1705.6, "end": 1712.6, "text": " they feel terrified and they bend over backwards to make that program faster. So whether this", "tokens": [51252, 436, 841, 23051, 293, 436, 11229, 670, 12204, 281, 652, 300, 1461, 4663, 13, 407, 1968, 341, 51602], "temperature": 0.0, "avg_logprob": -0.21869526534784037, "compression_ratio": 1.5423728813559323, "no_speech_prob": 0.0071100229397416115}, {"id": 264, "seek": 171260, "start": 1713.1599999999999, "end": 1720.1599999999999, "text": " is the developer or the compiler and vice versa is up to you. I've been in both situations.", "tokens": [50392, 307, 264, 10754, 420, 264, 31958, 293, 11964, 25650, 307, 493, 281, 291, 13, 286, 600, 668, 294, 1293, 6851, 13, 50742], "temperature": 0.0, "avg_logprob": -0.24208272993564606, "compression_ratio": 1.4943820224719102, "no_speech_prob": 0.003528202883899212}, {"id": 265, "seek": 171260, "start": 1724.04, "end": 1731.04, "text": " They turn a completely simple hotel struct with a couple string fields which are owned", "tokens": [50936, 814, 1261, 257, 2584, 2199, 7622, 6594, 365, 257, 1916, 6798, 7909, 597, 366, 11684, 51286], "temperature": 0.0, "avg_logprob": -0.24208272993564606, "compression_ratio": 1.4943820224719102, "no_speech_prob": 0.003528202883899212}, {"id": 266, "seek": 171260, "start": 1733.32, "end": 1737.84, "text": " yes they live on the heap. Do something that lives on the stack and has a lifetime. And", "tokens": [51400, 2086, 436, 1621, 322, 264, 33591, 13, 1144, 746, 300, 2909, 322, 264, 8630, 293, 575, 257, 11364, 13, 400, 51626], "temperature": 0.0, "avg_logprob": -0.24208272993564606, "compression_ratio": 1.4943820224719102, "no_speech_prob": 0.003528202883899212}, {"id": 267, "seek": 173784, "start": 1737.9199999999998, "end": 1744.04, "text": " every time you use a hotel you have to carry on the weight of the lifetime. Well does it", "tokens": [50368, 633, 565, 291, 764, 257, 7622, 291, 362, 281, 3985, 322, 264, 3364, 295, 264, 11364, 13, 1042, 775, 309, 50674], "temperature": 0.0, "avg_logprob": -0.14027511051722935, "compression_ratio": 1.6492537313432836, "no_speech_prob": 0.007006390485912561}, {"id": 268, "seek": 173784, "start": 1744.04, "end": 1748.8, "text": " matter for this one particular case? Probably not. But then you look at other places of", "tokens": [50674, 1871, 337, 341, 472, 1729, 1389, 30, 9210, 406, 13, 583, 550, 291, 574, 412, 661, 3190, 295, 50912], "temperature": 0.0, "avg_logprob": -0.14027511051722935, "compression_ratio": 1.6492537313432836, "no_speech_prob": 0.007006390485912561}, {"id": 269, "seek": 173784, "start": 1748.8, "end": 1755.08, "text": " the code base and you see that they kind of reverted your changes. They made what you", "tokens": [50912, 264, 3089, 3096, 293, 291, 536, 300, 436, 733, 295, 319, 18537, 428, 2962, 13, 814, 1027, 437, 291, 51226], "temperature": 0.0, "avg_logprob": -0.14027511051722935, "compression_ratio": 1.6492537313432836, "no_speech_prob": 0.007006390485912561}, {"id": 270, "seek": 173784, "start": 1755.08, "end": 1761.1599999999999, "text": " introduced your hard won knowledge about the abstractions and they took them away. Now we", "tokens": [51226, 7268, 428, 1152, 1582, 3601, 466, 264, 12649, 626, 293, 436, 1890, 552, 1314, 13, 823, 321, 51530], "temperature": 0.0, "avg_logprob": -0.14027511051722935, "compression_ratio": 1.6492537313432836, "no_speech_prob": 0.007006390485912561}, {"id": 271, "seek": 173784, "start": 1761.1599999999999, "end": 1767.04, "text": " start to index into our data structure again. We use string split again. We go backwards.", "tokens": [51530, 722, 281, 8186, 666, 527, 1412, 3877, 797, 13, 492, 764, 6798, 7472, 797, 13, 492, 352, 12204, 13, 51824], "temperature": 0.0, "avg_logprob": -0.14027511051722935, "compression_ratio": 1.6492537313432836, "no_speech_prob": 0.007006390485912561}, {"id": 272, "seek": 176704, "start": 1767.08, "end": 1774.08, "text": " We've been there before. It is super fragile. Again we are going backwards. Now let me play", "tokens": [50366, 492, 600, 668, 456, 949, 13, 467, 307, 1687, 23847, 13, 3764, 321, 366, 516, 12204, 13, 823, 718, 385, 862, 50716], "temperature": 0.0, "avg_logprob": -0.15582121973452362, "compression_ratio": 1.5304347826086957, "no_speech_prob": 0.007676315028220415}, {"id": 273, "seek": 176704, "start": 1775.56, "end": 1781.44, "text": " a little game here. Since there are so many C and C++ programs in here I expect you to", "tokens": [50790, 257, 707, 1216, 510, 13, 4162, 456, 366, 370, 867, 383, 293, 383, 25472, 4268, 294, 510, 286, 2066, 291, 281, 51084], "temperature": 0.0, "avg_logprob": -0.15582121973452362, "compression_ratio": 1.5304347826086957, "no_speech_prob": 0.007676315028220415}, {"id": 274, "seek": 176704, "start": 1781.44, "end": 1788.44, "text": " answer this. What is the bottleneck? This is a very famous medieval game who wanted to", "tokens": [51084, 1867, 341, 13, 708, 307, 264, 44641, 547, 30, 639, 307, 257, 588, 4618, 24078, 1216, 567, 1415, 281, 51434], "temperature": 0.0, "avg_logprob": -0.15582121973452362, "compression_ratio": 1.5304347826086957, "no_speech_prob": 0.007676315028220415}, {"id": 275, "seek": 176704, "start": 1789.44, "end": 1796.44, "text": " be a millionaire. What is the bottleneck? Is it CSV parsing? The DC realization of our", "tokens": [51484, 312, 257, 41114, 13, 708, 307, 264, 44641, 547, 30, 1119, 309, 9460, 53, 21156, 278, 30, 440, 9114, 25138, 295, 527, 51834], "temperature": 0.0, "avg_logprob": -0.15582121973452362, "compression_ratio": 1.5304347826086957, "no_speech_prob": 0.007676315028220415}, {"id": 276, "seek": 179704, "start": 1797.44, "end": 1804.44, "text": " entries. Is it string object creation after we DC realized it? We put it into a hotel", "tokens": [50384, 23041, 13, 1119, 309, 6798, 2657, 8016, 934, 321, 9114, 5334, 309, 30, 492, 829, 309, 666, 257, 7622, 50734], "temperature": 0.0, "avg_logprob": -0.2668270162633947, "compression_ratio": 1.4293478260869565, "no_speech_prob": 0.005454556550830603}, {"id": 277, "seek": 179704, "start": 1804.8799999999999, "end": 1811.0, "text": " struct. Is that the bottleneck? Is it floating point operations when you parse the price?", "tokens": [50756, 6594, 13, 1119, 300, 264, 44641, 547, 30, 1119, 309, 12607, 935, 7705, 562, 291, 48377, 264, 3218, 30, 51062], "temperature": 0.0, "avg_logprob": -0.2668270162633947, "compression_ratio": 1.4293478260869565, "no_speech_prob": 0.005454556550830603}, {"id": 278, "seek": 179704, "start": 1811.0, "end": 1818.0, "text": " Or is it hash map access? Who's for A? Some shy hands? Don't be shy. Who's for B? Okay.", "tokens": [51062, 1610, 307, 309, 22019, 4471, 2105, 30, 2102, 311, 337, 316, 30, 2188, 12685, 2377, 30, 1468, 380, 312, 12685, 13, 2102, 311, 337, 363, 30, 1033, 13, 51412], "temperature": 0.0, "avg_logprob": -0.2668270162633947, "compression_ratio": 1.4293478260869565, "no_speech_prob": 0.005454556550830603}, {"id": 279, "seek": 181800, "start": 1818.0, "end": 1825.0, "text": " Nice. Who's for C? No one. And who's for D? The hash map. Nice. The correct answer is", "tokens": [50364, 5490, 13, 2102, 311, 337, 383, 30, 883, 472, 13, 400, 567, 311, 337, 413, 30, 440, 22019, 4471, 13, 5490, 13, 440, 3006, 1867, 307, 50714], "temperature": 0.0, "avg_logprob": -0.23149367173512778, "compression_ratio": 1.2878787878787878, "no_speech_prob": 0.004060131963342428}, {"id": 280, "seek": 181800, "start": 1837.56, "end": 1844.56, "text": " you forgot to run with release. How do you find the actual performance improvements?", "tokens": [51342, 291, 5298, 281, 1190, 365, 4374, 13, 1012, 360, 291, 915, 264, 3539, 3389, 13797, 30, 51692], "temperature": 0.0, "avg_logprob": -0.23149367173512778, "compression_ratio": 1.2878787878787878, "no_speech_prob": 0.004060131963342428}, {"id": 281, "seek": 184456, "start": 1844.56, "end": 1851.56, "text": " There's just one correct answer and it is measure. Profile. Use the tools. Cargo flame", "tokens": [50364, 821, 311, 445, 472, 3006, 1867, 293, 309, 307, 3481, 13, 6039, 794, 13, 8278, 264, 3873, 13, 2741, 1571, 13287, 50714], "temperature": 0.0, "avg_logprob": -0.3765098865215595, "compression_ratio": 1.4308510638297873, "no_speech_prob": 0.002932519419118762}, {"id": 282, "seek": 184456, "start": 1852.56, "end": 1859.56, "text": " graph. Cool thing. You will see that in a second. Use benchmarks. There's criteria on", "tokens": [50764, 4295, 13, 8561, 551, 13, 509, 486, 536, 300, 294, 257, 1150, 13, 8278, 43751, 13, 821, 311, 11101, 322, 51114], "temperature": 0.0, "avg_logprob": -0.3765098865215595, "compression_ratio": 1.4308510638297873, "no_speech_prob": 0.002932519419118762}, {"id": 283, "seek": 184456, "start": 1860.56, "end": 1867.56, "text": " Nick still in the room? Nicolet? No. His benchmarking tool. Divan. Pretty great. Use it. Okay. I", "tokens": [51164, 9449, 920, 294, 264, 1808, 30, 14776, 401, 302, 30, 883, 13, 2812, 18927, 278, 2290, 13, 413, 24193, 13, 10693, 869, 13, 8278, 309, 13, 1033, 13, 286, 51514], "temperature": 0.0, "avg_logprob": -0.3765098865215595, "compression_ratio": 1.4308510638297873, "no_speech_prob": 0.002932519419118762}, {"id": 284, "seek": 186756, "start": 1868.56, "end": 1875.56, "text": " will give you one example. Let's look at a flame graph of our initial program. The one that a", "tokens": [50414, 486, 976, 291, 472, 1365, 13, 961, 311, 574, 412, 257, 13287, 4295, 295, 527, 5883, 1461, 13, 440, 472, 300, 257, 50764], "temperature": 0.0, "avg_logprob": -0.15181536070058044, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.007225724868476391}, {"id": 285, "seek": 186756, "start": 1876.56, "end": 1883.56, "text": " junior developer could write in two hours. What is the bottleneck? There is no bottleneck. This", "tokens": [50814, 16195, 10754, 727, 2464, 294, 732, 2496, 13, 708, 307, 264, 44641, 547, 30, 821, 307, 572, 44641, 547, 13, 639, 51164], "temperature": 0.0, "avg_logprob": -0.15181536070058044, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.007225724868476391}, {"id": 286, "seek": 186756, "start": 1884.56, "end": 1890.56, "text": " is the setup of our flame graph itself. This is the profiler setup. The code itself is", "tokens": [51214, 307, 264, 8657, 295, 527, 13287, 4295, 2564, 13, 639, 307, 264, 1740, 5441, 8657, 13, 440, 3089, 2564, 307, 51514], "temperature": 0.0, "avg_logprob": -0.15181536070058044, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.007225724868476391}, {"id": 287, "seek": 189056, "start": 1890.56, "end": 1896.56, "text": " negligible. Negligible, I guess. And why is that? Again, because I didn't tell you how big the", "tokens": [50364, 32570, 964, 13, 19103, 5073, 964, 11, 286, 2041, 13, 400, 983, 307, 300, 30, 3764, 11, 570, 286, 994, 380, 980, 291, 577, 955, 264, 50664], "temperature": 0.0, "avg_logprob": -0.1705812677606806, "compression_ratio": 1.534136546184739, "no_speech_prob": 0.005297393072396517}, {"id": 288, "seek": 189056, "start": 1897.56, "end": 1901.56, "text": " fire was, do you think I can come up with thousands of alliterations for hotels? No. So I added", "tokens": [50714, 2610, 390, 11, 360, 291, 519, 286, 393, 808, 493, 365, 5383, 295, 439, 1681, 763, 337, 22718, 30, 883, 13, 407, 286, 3869, 50914], "temperature": 0.0, "avg_logprob": -0.1705812677606806, "compression_ratio": 1.534136546184739, "no_speech_prob": 0.005297393072396517}, {"id": 289, "seek": 189056, "start": 1902.56, "end": 1908.56, "text": " 100 entries. There is no bottleneck here. Okay. You might say, but okay. What if the fire grows?", "tokens": [50964, 2319, 23041, 13, 821, 307, 572, 44641, 547, 510, 13, 1033, 13, 509, 1062, 584, 11, 457, 1392, 13, 708, 498, 264, 2610, 13156, 30, 51264], "temperature": 0.0, "avg_logprob": -0.1705812677606806, "compression_ratio": 1.534136546184739, "no_speech_prob": 0.005297393072396517}, {"id": 290, "seek": 189056, "start": 1909.56, "end": 1917.56, "text": " Let's add a million entries. Okay. Oh, this is still 120 records. So let's add more. This is a", "tokens": [51314, 961, 311, 909, 257, 2459, 23041, 13, 1033, 13, 876, 11, 341, 307, 920, 10411, 7724, 13, 407, 718, 311, 909, 544, 13, 639, 307, 257, 51714], "temperature": 0.0, "avg_logprob": -0.1705812677606806, "compression_ratio": 1.534136546184739, "no_speech_prob": 0.005297393072396517}, {"id": 291, "seek": 191756, "start": 1917.56, "end": 1926.56, "text": " million. You probably ain't going to read it. Let's increase it to 10 million. And indeed, deserialization", "tokens": [50364, 2459, 13, 509, 1391, 7862, 380, 516, 281, 1401, 309, 13, 961, 311, 3488, 309, 281, 1266, 2459, 13, 400, 6451, 11, 730, 260, 831, 2144, 50814], "temperature": 0.0, "avg_logprob": -0.16770890247390932, "compression_ratio": 1.5340314136125655, "no_speech_prob": 0.0006876315455883741}, {"id": 292, "seek": 191756, "start": 1927.56, "end": 1934.56, "text": " of the struct takes most of our time. Okay. If we look a little closer, it says,", "tokens": [50864, 295, 264, 6594, 2516, 881, 295, 527, 565, 13, 1033, 13, 759, 321, 574, 257, 707, 4966, 11, 309, 1619, 11, 51214], "temperature": 0.0, "avg_logprob": -0.16770890247390932, "compression_ratio": 1.5340314136125655, "no_speech_prob": 0.0006876315455883741}, {"id": 293, "seek": 191756, "start": 1935.56, "end": 1941.56, "text": " serde deserialize deserialize struct. Okay. We have some memory movement going on. Let's take a baseline.", "tokens": [51264, 816, 1479, 730, 260, 831, 1125, 730, 260, 831, 1125, 6594, 13, 1033, 13, 492, 362, 512, 4675, 3963, 516, 322, 13, 961, 311, 747, 257, 20518, 13, 51564], "temperature": 0.0, "avg_logprob": -0.16770890247390932, "compression_ratio": 1.5340314136125655, "no_speech_prob": 0.0006876315455883741}, {"id": 294, "seek": 194156, "start": 1942.56, "end": 1951.56, "text": " That is our baseline. This is what it takes. 34 seconds. Okay. Now, let's say we kind of want to prove our", "tokens": [50414, 663, 307, 527, 20518, 13, 639, 307, 437, 309, 2516, 13, 12790, 3949, 13, 1033, 13, 823, 11, 718, 311, 584, 321, 733, 295, 528, 281, 7081, 527, 50864], "temperature": 0.0, "avg_logprob": -0.1310768681903218, "compression_ratio": 1.4908256880733946, "no_speech_prob": 0.002285972237586975}, {"id": 295, "seek": 194156, "start": 1952.56, "end": 1956.56, "text": " C and C++ developer wrong. Does this other abstraction that we added for the hotel struct really add that much", "tokens": [50914, 383, 293, 383, 25472, 10754, 2085, 13, 4402, 341, 661, 37765, 300, 321, 3869, 337, 264, 7622, 6594, 534, 909, 300, 709, 51114], "temperature": 0.0, "avg_logprob": -0.1310768681903218, "compression_ratio": 1.4908256880733946, "no_speech_prob": 0.002285972237586975}, {"id": 296, "seek": 194156, "start": 1957.56, "end": 1963.56, "text": " overhead? No. It's the same. It's like 34 seconds still. Oh, actually, this is the part where we remove the", "tokens": [51164, 19922, 30, 883, 13, 467, 311, 264, 912, 13, 467, 311, 411, 12790, 3949, 920, 13, 876, 11, 767, 11, 341, 307, 264, 644, 689, 321, 4159, 264, 51464], "temperature": 0.0, "avg_logprob": -0.1310768681903218, "compression_ratio": 1.4908256880733946, "no_speech_prob": 0.002285972237586975}, {"id": 297, "seek": 196356, "start": 1963.56, "end": 1973.56, "text": " unnecessary fields. But we can go further. We can say, yeah. Here we have a little safer version. We don't index,", "tokens": [50364, 19350, 7909, 13, 583, 321, 393, 352, 3052, 13, 492, 393, 584, 11, 1338, 13, 1692, 321, 362, 257, 707, 15856, 3037, 13, 492, 500, 380, 8186, 11, 50864], "temperature": 0.0, "avg_logprob": -0.1802551045137293, "compression_ratio": 1.3869047619047619, "no_speech_prob": 0.009853511117398739}, {"id": 298, "seek": 196356, "start": 1974.56, "end": 1985.56, "text": " but we say nth.1. And we have 32 seconds. Now, our bottleneck is append string. String appending. Okay. I think there's", "tokens": [50914, 457, 321, 584, 297, 392, 13, 16, 13, 400, 321, 362, 8858, 3949, 13, 823, 11, 527, 44641, 547, 307, 34116, 6798, 13, 745, 2937, 724, 2029, 13, 1033, 13, 286, 519, 456, 311, 51464], "temperature": 0.0, "avg_logprob": -0.1802551045137293, "compression_ratio": 1.3869047619047619, "no_speech_prob": 0.009853511117398739}, {"id": 299, "seek": 198556, "start": 1985.56, "end": 1998.56, "text": " something that we can fix. Well, okay. Maybe this is not really that readable. But what we do is we split now by a", "tokens": [50364, 746, 300, 321, 393, 3191, 13, 1042, 11, 1392, 13, 2704, 341, 307, 406, 534, 300, 49857, 13, 583, 437, 321, 360, 307, 321, 7472, 586, 538, 257, 51014], "temperature": 0.0, "avg_logprob": -0.07836596171061198, "compression_ratio": 1.4805194805194806, "no_speech_prob": 0.002018547849729657}, {"id": 300, "seek": 198556, "start": 1999.56, "end": 2006.56, "text": " string. And instead of doing an allocation where we append to our string over and over again, we use this pattern", "tokens": [51064, 6798, 13, 400, 2602, 295, 884, 364, 27599, 689, 321, 34116, 281, 527, 6798, 670, 293, 670, 797, 11, 321, 764, 341, 5102, 51414], "temperature": 0.0, "avg_logprob": -0.07836596171061198, "compression_ratio": 1.4805194805194806, "no_speech_prob": 0.002018547849729657}, {"id": 301, "seek": 200656, "start": 2006.56, "end": 2017.56, "text": " matching here. And this reduces the runtime by 30% already because we save on allocations. Now, if we try to profile this", "tokens": [50364, 14324, 510, 13, 400, 341, 18081, 264, 34474, 538, 2217, 4, 1217, 570, 321, 3155, 322, 12660, 763, 13, 823, 11, 498, 321, 853, 281, 7964, 341, 50914], "temperature": 0.0, "avg_logprob": -0.10243339387197344, "compression_ratio": 1.3444444444444446, "no_speech_prob": 0.11751683801412582}, {"id": 302, "seek": 200656, "start": 2018.56, "end": 2027.56, "text": " code again, where's the bottleneck now? Read until. Okay. What is that about? We have a lot of memory movement going on.", "tokens": [50964, 3089, 797, 11, 689, 311, 264, 44641, 547, 586, 30, 17604, 1826, 13, 1033, 13, 708, 307, 300, 466, 30, 492, 362, 257, 688, 295, 4675, 3963, 516, 322, 13, 51414], "temperature": 0.0, "avg_logprob": -0.10243339387197344, "compression_ratio": 1.3444444444444446, "no_speech_prob": 0.11751683801412582}, {"id": 303, "seek": 202756, "start": 2028.56, "end": 2037.56, "text": " And now we reach a point where the disk becomes the bottleneck. We can use an M-map for this. Now, remember, we are talking about", "tokens": [50414, 400, 586, 321, 2524, 257, 935, 689, 264, 12355, 3643, 264, 44641, 547, 13, 492, 393, 764, 364, 376, 12, 24223, 337, 341, 13, 823, 11, 1604, 11, 321, 366, 1417, 466, 50864], "temperature": 0.0, "avg_logprob": -0.1900400161743164, "compression_ratio": 1.5923076923076922, "no_speech_prob": 0.19422388076782227}, {"id": 304, "seek": 202756, "start": 2038.56, "end": 2045.56, "text": " performance and maybe you should not do those optimizations, but prove a C and C++ program were wrong and they are in tuition. And then you see that", "tokens": [50914, 3389, 293, 1310, 291, 820, 406, 360, 729, 5028, 14455, 11, 457, 7081, 257, 383, 293, 383, 25472, 1461, 645, 2085, 293, 436, 366, 294, 23925, 13, 400, 550, 291, 536, 300, 51264], "temperature": 0.0, "avg_logprob": -0.1900400161743164, "compression_ratio": 1.5923076923076922, "no_speech_prob": 0.19422388076782227}, {"id": 305, "seek": 202756, "start": 2046.56, "end": 2052.56, "text": " the bottleneck might be solved elsewhere. Now we are at 30 seconds by changing like four or five lines from the entire program, not the", "tokens": [51314, 264, 44641, 547, 1062, 312, 13041, 14517, 13, 823, 321, 366, 412, 2217, 3949, 538, 4473, 411, 1451, 420, 1732, 3876, 490, 264, 2302, 1461, 11, 406, 264, 51614], "temperature": 0.0, "avg_logprob": -0.1900400161743164, "compression_ratio": 1.5923076923076922, "no_speech_prob": 0.19422388076782227}, {"id": 306, "seek": 205256, "start": 2052.56, "end": 2062.56, "text": " entire thing. We can keep using our abstractions. That's the main point. Here we use an M-map. That's a memory map in the kernel. We save on allocations.", "tokens": [50364, 2302, 551, 13, 492, 393, 1066, 1228, 527, 12649, 626, 13, 663, 311, 264, 2135, 935, 13, 1692, 321, 764, 364, 376, 12, 24223, 13, 663, 311, 257, 4675, 4471, 294, 264, 28256, 13, 492, 3155, 322, 12660, 763, 13, 50864], "temperature": 0.0, "avg_logprob": -0.11905658379029692, "compression_ratio": 1.5023041474654377, "no_speech_prob": 0.017979295924305916}, {"id": 307, "seek": 205256, "start": 2063.56, "end": 2075.56, "text": " 30 seconds. Okay. What if we wanted to do more? It's hard to read, but now we reach the point where in fact the hash map is the bottleneck. And one more step to improve the", "tokens": [50914, 2217, 3949, 13, 1033, 13, 708, 498, 321, 1415, 281, 360, 544, 30, 467, 311, 1152, 281, 1401, 11, 457, 586, 321, 2524, 264, 935, 689, 294, 1186, 264, 22019, 4471, 307, 264, 44641, 547, 13, 400, 472, 544, 1823, 281, 3470, 264, 51514], "temperature": 0.0, "avg_logprob": -0.11905658379029692, "compression_ratio": 1.5023041474654377, "no_speech_prob": 0.017979295924305916}, {"id": 308, "seek": 207556, "start": 2075.56, "end": 2085.56, "text": " code would be to split it up into multiple chunks. You can use rayon. You can now finally use a better hash map like a hash map. And we are down to 3.5 seconds.", "tokens": [50364, 3089, 576, 312, 281, 7472, 309, 493, 666, 3866, 24004, 13, 509, 393, 764, 18592, 266, 13, 509, 393, 586, 2721, 764, 257, 1101, 22019, 4471, 411, 257, 22019, 4471, 13, 400, 321, 366, 760, 281, 805, 13, 20, 3949, 13, 50864], "temperature": 0.0, "avg_logprob": -0.10559529936715459, "compression_ratio": 1.5844748858447488, "no_speech_prob": 0.32368043065071106}, {"id": 309, "seek": 207556, "start": 2086.56, "end": 2096.56, "text": " And we did that not by guessing, but by profiling. Now if we want to run a profile, it looks different again. Very different. These are the individual chunks that we managed to split up.", "tokens": [50914, 400, 321, 630, 300, 406, 538, 17939, 11, 457, 538, 1740, 4883, 13, 823, 498, 321, 528, 281, 1190, 257, 7964, 11, 309, 1542, 819, 797, 13, 4372, 819, 13, 1981, 366, 264, 2609, 24004, 300, 321, 6453, 281, 7472, 493, 13, 51414], "temperature": 0.0, "avg_logprob": -0.10559529936715459, "compression_ratio": 1.5844748858447488, "no_speech_prob": 0.32368043065071106}, {"id": 310, "seek": 209656, "start": 2096.56, "end": 2109.56, "text": " We went from 40 seconds to three or four seconds in a couple slides and with few changes. And the point is don't guess, measure. This is the worst part that C developers bring into Rust.", "tokens": [50364, 492, 1437, 490, 3356, 3949, 281, 1045, 420, 1451, 3949, 294, 257, 1916, 9788, 293, 365, 1326, 2962, 13, 400, 264, 935, 307, 500, 380, 2041, 11, 3481, 13, 639, 307, 264, 5855, 644, 300, 383, 8849, 1565, 666, 34952, 13, 51014], "temperature": 0.0, "avg_logprob": -0.11674920477048316, "compression_ratio": 1.6007751937984496, "no_speech_prob": 0.30676862597465515}, {"id": 311, "seek": 209656, "start": 2110.56, "end": 2122.56, "text": " They think everything is a performance overhead. And if this challenge, by the way, looked very similar to the one billion row challenge, this is why it was inspired by it. And it is very similar. Read it up. It's kind of fun.", "tokens": [51064, 814, 519, 1203, 307, 257, 3389, 19922, 13, 400, 498, 341, 3430, 11, 538, 264, 636, 11, 2956, 588, 2531, 281, 264, 472, 5218, 5386, 3430, 11, 341, 307, 983, 309, 390, 7547, 538, 309, 13, 400, 309, 307, 588, 2531, 13, 17604, 309, 493, 13, 467, 311, 733, 295, 1019, 13, 51664], "temperature": 0.0, "avg_logprob": -0.11674920477048316, "compression_ratio": 1.6007751937984496, "no_speech_prob": 0.30676862597465515}, {"id": 312, "seek": 212256, "start": 2123.56, "end": 2137.56, "text": " We did something similar for hotel data. But the more important point here is how can we fight premature optimization? Measure, don't guess. Focus on algorithms and data structures, not micro-optimizations.", "tokens": [50414, 492, 630, 746, 2531, 337, 7622, 1412, 13, 583, 264, 544, 1021, 935, 510, 307, 577, 393, 321, 2092, 34877, 19618, 30, 41436, 11, 500, 380, 2041, 13, 21862, 322, 14642, 293, 1412, 9227, 11, 406, 4532, 12, 5747, 332, 14455, 13, 51114], "temperature": 0.0, "avg_logprob": -0.10559313484791959, "compression_ratio": 1.569672131147541, "no_speech_prob": 0.007933707907795906}, {"id": 313, "seek": 212256, "start": 2138.56, "end": 2149.56, "text": " More often than not, if you change from a vector to a hash map, this will be way, way more efficient than if you remove your little struct. And if you add lifetimes everywhere.", "tokens": [51164, 5048, 2049, 813, 406, 11, 498, 291, 1319, 490, 257, 8062, 281, 257, 22019, 4471, 11, 341, 486, 312, 636, 11, 636, 544, 7148, 813, 498, 291, 4159, 428, 707, 6594, 13, 400, 498, 291, 909, 4545, 302, 1532, 5315, 13, 51714], "temperature": 0.0, "avg_logprob": -0.10559313484791959, "compression_ratio": 1.569672131147541, "no_speech_prob": 0.007933707907795906}, {"id": 314, "seek": 214956, "start": 2150.56, "end": 2166.56, "text": " You can get carried away pretty quickly and Rust encourages you to do so, but it also has the tooling to fight it. Be more pragmatic. Focus on readability and maintainability first and foremost. Use profiling tools to make informed decisions.", "tokens": [50414, 509, 393, 483, 9094, 1314, 1238, 2661, 293, 34952, 28071, 291, 281, 360, 370, 11, 457, 309, 611, 575, 264, 46593, 281, 2092, 309, 13, 879, 544, 46904, 13, 21862, 322, 1401, 2310, 293, 6909, 2310, 700, 293, 18864, 13, 8278, 1740, 4883, 3873, 281, 652, 11740, 5327, 13, 51214], "temperature": 0.0, "avg_logprob": -0.10533719692590102, "compression_ratio": 1.4069767441860466, "no_speech_prob": 0.03202001750469208}, {"id": 315, "seek": 216656, "start": 2167.56, "end": 2193.56, "text": " You covered all of that. Your code is idiomatic. It is fast. You didn't overdo it. What is missing? Well, the entire rest. Do you have tests? Do you have documentation? Is your API too large? Does your code lack modularity and encapsulation?", "tokens": [50414, 509, 5343, 439, 295, 300, 13, 2260, 3089, 307, 18014, 13143, 13, 467, 307, 2370, 13, 509, 994, 380, 670, 2595, 309, 13, 708, 307, 5361, 30, 1042, 11, 264, 2302, 1472, 13, 1144, 291, 362, 6921, 30, 1144, 291, 362, 14333, 30, 1119, 428, 9362, 886, 2416, 30, 4402, 428, 3089, 5011, 31111, 507, 293, 38745, 2776, 30, 51714], "temperature": 0.0, "avg_logprob": -0.06732071013677687, "compression_ratio": 1.4695121951219512, "no_speech_prob": 0.3235965073108673}, {"id": 316, "seek": 219356, "start": 2194.56, "end": 2207.56, "text": " These are things that I see from people that are like the lone wolf coders. They know all about Rust, but what they are not really good at is the rest. Explaining the differences to their code maintainers.", "tokens": [50414, 1981, 366, 721, 300, 286, 536, 490, 561, 300, 366, 411, 264, 35314, 19216, 17656, 433, 13, 814, 458, 439, 466, 34952, 11, 457, 437, 436, 366, 406, 534, 665, 412, 307, 264, 1472, 13, 12514, 3686, 264, 7300, 281, 641, 3089, 6909, 433, 13, 51064], "temperature": 0.0, "avg_logprob": -0.11241284169648823, "compression_ratio": 1.5643564356435644, "no_speech_prob": 0.06545024365186691}, {"id": 317, "seek": 219356, "start": 2208.56, "end": 2215.56, "text": " And writing documentation. Not about the what, but not about the how, but the what. What does your program do?", "tokens": [51114, 400, 3579, 14333, 13, 1726, 466, 264, 437, 11, 457, 406, 466, 264, 577, 11, 457, 264, 437, 13, 708, 775, 428, 1461, 360, 30, 51464], "temperature": 0.0, "avg_logprob": -0.11241284169648823, "compression_ratio": 1.5643564356435644, "no_speech_prob": 0.06545024365186691}, {"id": 318, "seek": 221556, "start": 2216.56, "end": 2231.56, "text": " Some things they say. It compiles. My work is done here. The code is documentation. Let's just make it all pop. I'll refactor that later, which never happens. Let's look at that code again. This is our first version junior programmer. Three hours.", "tokens": [50414, 2188, 721, 436, 584, 13, 467, 715, 4680, 13, 1222, 589, 307, 1096, 510, 13, 440, 3089, 307, 14333, 13, 961, 311, 445, 652, 309, 439, 1665, 13, 286, 603, 1895, 15104, 300, 1780, 11, 597, 1128, 2314, 13, 961, 311, 574, 412, 300, 3089, 797, 13, 639, 307, 527, 700, 3037, 16195, 32116, 13, 6244, 2496, 13, 51164], "temperature": 0.0, "avg_logprob": -0.14920510527908162, "compression_ratio": 1.5358649789029535, "no_speech_prob": 0.31041982769966125}, {"id": 319, "seek": 221556, "start": 2232.56, "end": 2239.56, "text": " Okay. How do we test that? It's kind of impossible because this is one big binary, one main. How would we test that?", "tokens": [51214, 1033, 13, 1012, 360, 321, 1500, 300, 30, 467, 311, 733, 295, 6243, 570, 341, 307, 472, 955, 17434, 11, 472, 2135, 13, 1012, 576, 321, 1500, 300, 30, 51564], "temperature": 0.0, "avg_logprob": -0.14920510527908162, "compression_ratio": 1.5358649789029535, "no_speech_prob": 0.31041982769966125}, {"id": 320, "seek": 223956, "start": 2240.56, "end": 2250.56, "text": " Well, I guess the question is what do we want to test? Well, first off, I would say let's add a test for parsing the entire thing can be a very simple, true test.", "tokens": [50414, 1042, 11, 286, 2041, 264, 1168, 307, 437, 360, 321, 528, 281, 1500, 30, 1042, 11, 700, 766, 11, 286, 576, 584, 718, 311, 909, 257, 1500, 337, 21156, 278, 264, 2302, 551, 393, 312, 257, 588, 2199, 11, 2074, 1500, 13, 50914], "temperature": 0.0, "avg_logprob": -0.11346476128760805, "compression_ratio": 1.591743119266055, "no_speech_prob": 0.011866559274494648}, {"id": 321, "seek": 223956, "start": 2251.56, "end": 2263.56, "text": " But if we refactor it such that we have a function that parses cities, now we can start to introduce a path here and do the parsing. And this is where the parsing logic is, by the way.", "tokens": [50964, 583, 498, 321, 1895, 15104, 309, 1270, 300, 321, 362, 257, 2445, 300, 21156, 279, 6486, 11, 586, 321, 393, 722, 281, 5366, 257, 3100, 510, 293, 360, 264, 21156, 278, 13, 400, 341, 307, 689, 264, 21156, 278, 9952, 307, 11, 538, 264, 636, 13, 51564], "temperature": 0.0, "avg_logprob": -0.11346476128760805, "compression_ratio": 1.591743119266055, "no_speech_prob": 0.011866559274494648}, {"id": 322, "seek": 226356, "start": 2263.56, "end": 2272.56, "text": " We split it up into a main and the parsed cities. Great. This is our first test. Very crude, but we get to a point where suddenly we can test our changes.", "tokens": [50364, 492, 7472, 309, 493, 666, 257, 2135, 293, 264, 21156, 292, 6486, 13, 3769, 13, 639, 307, 527, 700, 1500, 13, 4372, 30796, 11, 457, 321, 483, 281, 257, 935, 689, 5800, 321, 393, 1500, 527, 2962, 13, 50814], "temperature": 0.0, "avg_logprob": -0.11767923304464965, "compression_ratio": 1.6862745098039216, "no_speech_prob": 0.05830831080675125}, {"id": 323, "seek": 226356, "start": 2273.56, "end": 2280.56, "text": " We create a temporary directory. We have a path and then we write into a file and that's it. The parsing is done. Great.", "tokens": [50864, 492, 1884, 257, 13413, 21120, 13, 492, 362, 257, 3100, 293, 550, 321, 2464, 666, 257, 3991, 293, 300, 311, 309, 13, 440, 21156, 278, 307, 1096, 13, 3769, 13, 51214], "temperature": 0.0, "avg_logprob": -0.11767923304464965, "compression_ratio": 1.6862745098039216, "no_speech_prob": 0.05830831080675125}, {"id": 324, "seek": 226356, "start": 2281.56, "end": 2289.56, "text": " If we wanted to make it a little better, instead of passing in a path, we pass in something that impels read. Now we don't need to create files like here.", "tokens": [51264, 759, 321, 1415, 281, 652, 309, 257, 707, 1101, 11, 2602, 295, 8437, 294, 257, 3100, 11, 321, 1320, 294, 746, 300, 704, 1625, 1401, 13, 823, 321, 500, 380, 643, 281, 1884, 7098, 411, 510, 13, 51664], "temperature": 0.0, "avg_logprob": -0.11767923304464965, "compression_ratio": 1.6862745098039216, "no_speech_prob": 0.05830831080675125}, {"id": 325, "seek": 228956, "start": 2289.56, "end": 2299.56, "text": " Instead, we can have our input as a binary blob. And these are simple things. Add some documentation, add some tests. It's not that hard.", "tokens": [50364, 7156, 11, 321, 393, 362, 527, 4846, 382, 257, 17434, 46115, 13, 400, 613, 366, 2199, 721, 13, 5349, 512, 14333, 11, 909, 512, 6921, 13, 467, 311, 406, 300, 1152, 13, 50864], "temperature": 0.0, "avg_logprob": -0.18633784188164604, "compression_ratio": 1.6692015209125475, "no_speech_prob": 0.056536052376031876}, {"id": 326, "seek": 228956, "start": 2300.56, "end": 2318.56, "text": " And in order to fight a mission, what you need to do is write more documentation, write unit tests, use tools like Clippy and cargo UDAPs, set up CI CD so that you can handle your changes, create releases, use release please, Marco, greetings go out to you, and keep a change lock of what you changed.", "tokens": [50914, 400, 294, 1668, 281, 2092, 257, 4447, 11, 437, 291, 643, 281, 360, 307, 2464, 544, 14333, 11, 2464, 4985, 6921, 11, 764, 3873, 411, 2033, 48363, 293, 19449, 624, 35, 4715, 82, 11, 992, 493, 37777, 6743, 370, 300, 291, 393, 4813, 428, 2962, 11, 1884, 16952, 11, 764, 4374, 1767, 11, 26535, 11, 33667, 352, 484, 281, 291, 11, 293, 1066, 257, 1319, 4017, 295, 437, 291, 3105, 13, 51814], "temperature": 0.0, "avg_logprob": -0.18633784188164604, "compression_ratio": 1.6692015209125475, "no_speech_prob": 0.056536052376031876}, {"id": 327, "seek": 231956, "start": 2320.56, "end": 2330.56, "text": " Right. We're getting towards the end. We have seen the anti patterns. You know them now. I hope that you will be able to, you know, see them in your code.", "tokens": [50414, 1779, 13, 492, 434, 1242, 3030, 264, 917, 13, 492, 362, 1612, 264, 6061, 8294, 13, 509, 458, 552, 586, 13, 286, 1454, 300, 291, 486, 312, 1075, 281, 11, 291, 458, 11, 536, 552, 294, 428, 3089, 13, 50914], "temperature": 0.0, "avg_logprob": -0.12589222622900895, "compression_ratio": 1.576271186440678, "no_speech_prob": 0.006479887291789055}, {"id": 328, "seek": 231956, "start": 2331.56, "end": 2345.56, "text": " If you want to learn more, there are some other talks that were given here at FOSSTEM and other places. You might want to check them out. Maybe I can put the slides somewhere. And that is all I have to say. Thank you.", "tokens": [50964, 759, 291, 528, 281, 1466, 544, 11, 456, 366, 512, 661, 6686, 300, 645, 2212, 510, 412, 479, 4367, 6840, 6683, 293, 661, 3190, 13, 509, 1062, 528, 281, 1520, 552, 484, 13, 2704, 286, 393, 829, 264, 9788, 4079, 13, 400, 300, 307, 439, 286, 362, 281, 584, 13, 1044, 291, 13, 51664], "temperature": 0.0, "avg_logprob": -0.12589222622900895, "compression_ratio": 1.576271186440678, "no_speech_prob": 0.006479887291789055}, {"id": 329, "seek": 234956, "start": 2349.56, "end": 2350.56, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 50414], "temperature": 0.0, "avg_logprob": -0.4571605920791626, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.9253492951393127}], "language": "en"}