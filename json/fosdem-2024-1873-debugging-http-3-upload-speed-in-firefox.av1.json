{"text": " Okay, I think we can roll it. And we are moving now to debugging HTTP 3 upload speed in Firefox and I'm more than happy to welcome Manuel Buschard for it. Hello. I'm Manuel Buschard. I'm Manuel. I'm working at Mozilla in the networking team called Necro and we work on Firefox networking. And in this talk I'm going about our debugging of HTTP 3 and HTTP 2 upload speed. And for this I'm going to give you some background information first. Then I'll cover the HTTP 2 upload speed problem that we investigated last year. And afterwards I'll go over to the HTTP 3 upload speed problem that we investigated afterwards. So yeah, first to the Necro team. We in general focus on security, privacy, but always also on performance. And our protocols that we work on is mostly HTTP but also DNS, web socket, web transport. And we also own the caching and the proxy feature. So this is what we generally work on. And when we think about networking performance, we usually think about it in terms of how long does it take from clicking a link to seeing the result. And for this we usually just need download speed. For other use cases like uploading large files like videos, we generally also need the upload speed. And in this talk I'm going about the HTTP 2 and HTTP 3 upload speed. Those protocols are more in focus. They are relatively newer than the HTTP 1. They got introduced in the past decade. And yeah, so for HTTP 2 upload, first what's the difference in HTTP 2 to HTTP 1. In HTTP 2 we allow to make multiple HTTP requests via one TCP socket. And this TCP socket is handled by the operating system. And real quick, the bug in our HTTP code that caused the slow upload was that we configured the socket to have a fixed size buffer of 110 to 80 kilobytes. And this fixed size buffer became a bottleneck in high bandwidth situations. And yeah, for the fix we just needed to adjust this TCP socket to not set the fixed size buffer and let the operating system handle the buffer size. And this shows that the operating system is responsible for the upload speed or the performance of upload. And this is a stark difference to HTTP 3 upload. And with this fix of just not setting the fixed size buffer, we can take a look at Chrome upload speed, Firefox before the fix, in red and in yellow Firefox after the fix. And we see that in certain configurations like high bandwidth and also from low to higher round trip times we have upload speed improvements up to like four times the speed. So we only have to wait a fourth of the time. And we are on par here with Chrome, which is using all the bandwidth you can use for the upload. So with this fixed last year, we took a more in depth look at upload speed in general. And we also had bug reports about slow HTTP 3 upload and with HTTP 2 seeing very good results, we made it a high priority for us as well and took a look there. So for the fix or seeing how much it changed, we introduced some high level telemetry. And these are person tiles of user reported upload speed. We have different versions, 114 on the left side is around one year ago. And in 115 to 16, we rolled out the HTTP 2 upload speed fix and we can see the improvements in the high level telemetry about upload speed. It's an improvement like in the higher parts, it's roughly doubled and not quite, but it's very visible. So now two difference to HTTP 3 upload. HTTP 3 upload is widely different. HTTP 3 uses a different transport layer. We don't use TCP anymore, but Qwik was standardised alongside with HTTP 3 and just relatively recently. So the standardisation was finalised in 2021, which is two to three years from now, right now. And Firefox also included HTTP 3 upload around the time in 2021. The work started in 2019, which is all relatively recent in comparison to TCP and HTTP 2. HTTP 2 is around a decade now, all. And the problem is different here because the operating system is responsible for the TCP stack. It is responsible for sending all the data performant and in Qwik we have to implement the same congestion control in Firefox and the Firefox application, so it's not the responsibility shifted to Firefox or the application. TCP is already decades old, it was done about 50 years ago and it's operating since 30 years and got a lot of eyes on it. And our Firefox implementation is really new and we were kind of the first ones to look into upload speed performance here, so we had a lot of low hanging fruits here to work on. And I wanted to visualise this a bit, like we have HV 2 and HV 3, which are very similar. In HV 3 we rely on Qwik and Qwik is also implemented by us. In HV 2 we have TCP and TCP is provided by the operating system. So I want to go into a few findings that we had in our presentation, in our IO graphs and other tooling that we took. The most useful tool for us was IO graphs where we just printed within the application, like with logging, when we send packets, when we receive packets, how big our congestion is and everything. So the first problem we have, what does this graph show? So this graph is our congestion window over time. What is the congestion window? So the congestion, well, I would like to go over this. We don't want to overload the network. And overloading the network is called like congestion control, well, not overloading the network. And this is the responsible of the transport layer, which is TCP or Qwik. And all the bugs that we had were in this congestion control, or most of the bugs. And the congestion window that we have is the estimate of how fast we can upload right now. And this changes over time. With every packet that we receive, we think we can upload more. So we have a graph like here where we steadily increase the congestion window over time with all the packets that we receive. And when we detect that packets got lost, we are assuming that the network is overloaded and we reduce the congestion window by half. And this is like one of the early graphs that we had. And orange are like the bytes in flight that we have. They circulate from top to bottom. Increasing again, blue is the congestion window. And what we see at the drop points is that the congestion window doesn't half. We would expect it to half during a congestion event. Instead it drops almost to zero. And this was one of the bugs that we had. We just dropped to zero. Each packet that we detected was lost, half the congestion window. And normally you would only do this once, but we did it multiple times for each packet. So essentially we dropped to almost zero on all congestion events here. This was one of the first fix. Later... Yeah. Later. This is the same graph. With the congestion window problem fixed, we had to investigate further. There were more problems. Here, like all these drops of packets going down, we want to stay with our bytes in flight as high as possible, with our upload speed as high as possible. But we dropped down quite some times. And if we... Yeah. For this problem, we need a bit of background information. And this background information was this slide, which I apparently put a bit later. And I'll go back to the background about Cric first before going over the next problem. So Cric got introduced. Sorry about the mix up here. Cric, the new transport layer protocol. What is Cric? Cric is on the same layer as TCP, but conceptually you can have multiple TCP connections at once over one quick connection. And we have other benefits, like TLS being integrated, so that the connection setup phase takes less time, only one round trip time instead of two round trip times. Yeah. And now we get back to the introduction of the concept of congestion control. Traction control is for us handles like not overloading the network from all participants in the internet. So everyone makes sure that we don't overload the network and keep it usable for everyone. And the congestion window is one of the concepts that we looked at the first graph and also in the second graph. This is our estimation at how much can we upload at a time. What is our upload speed to the destination server? And so our estimation depends on us receiving packets. And we want to increase the congestion window only if we are sure that we are using the congestion window. Like we are sending as much data as we have in the congestion window because otherwise we are not sure if our estimate is correct if we are sending less data than what is that we estimate we could. And this detection on whether a packet was sent during the utilization of the congestion window like sending as much data as we could. This had a bug as well and made us mark packets as not utilizing the congestion window for 50 to 75 percent of the packets which meant that we didn't increase the congestion window as fast as we could. This is another simple incremental fix for our HPE 3 upload speed problem. And after fixing this the graph looks like this. It has a steeper curve, steeper line. Here we also see that the first problem that we had got fixed. We don't drop to zero with the congestion window but have it halfway here. With these steady increases we can also see them in our high level telemetry that we introduced for our HPE 2 upload speed problem. In HPE 3 in the higher network bandwidth we have already an increase of three times. We are three times as fast as before tackling the problem from around 31 megabits per second to 93 megabits per sentence. This is the 95 percentiles. This is a network speed of better than 95 of all clients. Also visible from the high level telemetry. For the current state we are still working on this. We have more bugs that we are aware of and are also in contact with or in collaboration with contributors who can upload or request logs from them to have a look at their network condition. This is the diagram from before but from the contributors log where we can identify which problems are present from our machines in comparison to their network location. With the logging mechanism which we also included in Firefox this became a bit easier about logging. A few of the further works that we are currently still aware of is that the upload has a few CPU bottlenecks. Mostly profiling. The QuickStack made us aware that not the cryptography part of Quick is taking most of the time but some other parts which is unexpected. We have already identified a few code tests that can be improved and are improving these. We will also continue with profiling this. We also have similar to the HDP case we have a fixed size buffer. This will get to be a problem at some point at much higher bandwidth than with HP2 upload speed problem because we have a buffer that is 8 times as high, 1 megabyte instead of 128 kilobyte. We are also aware of the problem that when we are in package reordering networks we detect these package reordering as losses too frequently. There are ways around this in TCP specifications like REC or Forward Egg that we are taking a look at and investigating which one we want to implement and which proves to be the best of the options. We are also setting up CIS to catch regressions in the future and also have a detailed view from different networking conditions, how they look. We have seen where we got improvements in HDP3 already, it is now at a similar level to the HDP2 upload. It is looking already a lot better but we are still on it and we are aware of a few bugs and we will investigate further. We want to make it as good as we can to see all the benefits that HDP3 can provide for us. A lot of this was in cooperation with contributors reporting bugs. One specific bug is the HDP3 upload speed bug. If you want to take a look at our work there you can follow the investigations there. You can reach us at the Metrics channel if you want to get in contact with the NECO team. We have a NECO specific documentation also about creating logs. If you are interested in the NECO team we are making ourselves a bit more transparent by providing our meeting nodes and having a blog. If you need help with fixing bugs or want to get in contact like contributing, we also are going to provide office hours where you can talk to us directly and get in touch. Thanks for listening. Thank you. We might have time for one or two questions. Hi, thanks for talking. I just wanted to ask if there is any chance of Quick being brought into the Linux kernel or Windows kernel or wherever else Firefox runs. The question is whether Quick is going to be implemented in the operating system with the Shokut APIs. I am expecting that it will be implemented at some point. We do have, I have seen some TLS integration. This is one of the stoppers probably that TLS has to be integrated into the kernel as well. Quick is so new that it didn't have time to be integrated into the operating system. I think as soon as operating systems provide APIs we will start using them. They are not here right now but in the future I would assume yes. Two years of being standardized is like nothing. TCP is like for 30 years already. Last question, I see a lot of people coming in and for sure Manu will be available outside, no? Yes. Making promises is your name. My question is just which congestion control did you implement in Firefox? Yes. We are using Qubic by default. We have also implemented new Reno and we are looking also at BBR because this is also exciting for our lack. It's better for lower latencies. We didn't have a plan to implement it right now but it's like in the future we probably will tackle that too. Thank you so much Manu. I didn't count some of them but I took photos and we can count at different rates. I saw the sticker you have on your water bottle. Yalazila. Yalazila. Yalazila. Yalazila. Yalazila. Yalazila. Yalazila. And I think also this is a no? Yes. No. Yes. Yes. Yes. Yes. Yes. Yes. Yes. Yes. Yes. Yes. Yes. Yes. Yes. Yes. Yes. Yes. Yes. Yes. Yes. Yes. Yes. Yes, yes. Yes. This is all about the politics. I'd say about the politics. Call me to be disturbed. I'd like to work with you. Yeah, except... I used to... my mother told me how to... You know, like when they had to mess up with this. Yeah, I mean, it's funny when we're not having a discussion. Do you think there's a few... ...sci-fi sites? No. Yeah. I don't know about that. Sorry, it was on. Yeah. Yeah. Yes. You're stuck with me for two minutes or so. Carmen needs another adapter and we are looking over it. It's coming. We're fixing everything. Is anyone that already got the t-shirt from the booth or the collapsible mug? Oh, good. You're saving the world. I'm there for it. I also like it. Someone else is doing steps today. This is how you stay in shape. You moderate the dev room, you run. All good. We are first. Also a big thank you to Konstantina. She organized the booth, by the way. Konstantina and Mozilla, if you want to... Yes. Yes. Do you want to? She brought more stickers here, especially this stock is related to MDN. We have the sticker here, if you want. And we have the cute llama. I heard it. Gold. It's here, waiting. One is mine. And if you want to learn more about llama, the project, not the animal, we have a guide here with all things related to Mozilla and AI. Grab the... And the first one is from the first talk about support. Grab these papers and you can have more information. Are we ready? Let me go then. Without further ado, ladies and gentlemen, Chris will introduce us to the MDN curriculum. Yay! Hi. APPLAUSE So, hello everyone. Nice to see you all. Thanks for coming. My name is Chris Mills and I'm going to take you through a new MDN project soon to be released called the MDN Curriculum. Take you through a little bit about who I am to begin with. I describe myself as a death metal hippie. I love documentation and I love the open web and I love tinkering with open standards. I used to work for Mozilla. For quite a while I was the content lead and team manager for MDN. But I left and did some other stuff and now I've come back as a contractor and this is the current thing that I've been working on with the MDN team. Another thing to add is that I'm a heavy metal drummer so if you want to ask me a question later on please speak slowly. A little bit about this talk. We are going to talk about, first of all, some of the problems that myself and I was perceived with Frontend Development in 2024, particularly in terms of education and the skills that new web developers are bringing to the table when they come and get jobs. I'm going to take you through the thoughts of how a curriculum, a new curriculum could solve some of these problems and some of the research that we did to try and prove out some of our theories about this. I'll then talk to you a little bit about the actual curriculum that we came up with and kind of its structure, its approach, some of its goals and then I'll talk to you about possible next steps, some of the things that we can then go on to do with this curriculum as a basis. Now, first of all, I'm going to talk to us about, talk to you about something that we're very good at in open source communities, problems and complaining. Yay, Mr. Brexits, back in the UK government, I'm so pleased. No, not those kind of problems. Really, we're talking about problems with Frontend Development, kind of what skills are new web developers missing when they come into the industry? What's the effect of web, what's the state of web education, what kind of effects are these problems having on, you know, the web in general and the quality of sites that we build? One thing that I've talked to quite a lot of hiring managers about, and this will also be mentioned in the research that I'll talk about later, is just lack of general core principles of new developers coming into the industry. I mean, a short anecdote that I'll share with you is a couple of years ago, a friend of mine called me into his company, he worked for a large agency at the time and he wanted me to talk to all of his Frontend teams and he wanted me to talk to all of his Frontend teams about accessibility. Really basic accessibility, you know, just kind of use headings and paragraphs and use alt text, that kind of stuff. And I went in there and did a 20 minute talk and I was thinking, do I really need to talk to these folks about this? And it was like a revelation to them. They were all like, whoa, so that's why you have to do this stuff? I was just blown away. I was like, I thought we'd kind of largely won this battle and moved on. It kind of blew my mind about how little they knew about this stuff. And I kind of feel that with a lot of the new developers community industry, you know, they're not really learning core languages and old school standards as much as just kind of, well, I want to get a job so I'm going to learn React and I'm not going to turn this into a massive winch, but you know, that kind of results in not knowing these core principles and best practices quite as well as perhaps they could. The next thing to talk about is lack of core language skills. This is another thing that hiring managers have talked to me about a lot. So people learn React and other frameworks, but they don't maybe take the time to learn the core JavaScript language as much as they could. So, you know, they can build websites that work great and have a good look in UIs, but maybe their problem-solving skills aren't quite as good as they could be when they suddenly need to get brought onto a problem that requires not writing some code inside a framework. And also, we kind of worry that maybe this is not so good for people's long-term employability, because, you know, if they just learn React, what then happens if all of a sudden the company goes, well, now we're going to do all of this stuff in a different framework, or, you know, another framework suddenly becomes really popular and every employer wants to use it on their projects. This is probably the biggest one that I've heard from employers is just general lack of soft skills from UIs. So, and I know, you know, you could make the argument that this kind of stuff comes of experience, but it really would be great to try and promote that learners spend more time thinking about skills such as research and kind of basic critical thinking and problem-solving and also working on having this constant learning mindset that you kind of need to have to succeed in this industry, because things are just always changing all the time. So, who's to blame for any of these problems? Well, not really anybody, I would say. I'm not going to point the finger at anyone in particular, because, you know, you've got all of this ideological thinking that says everything should be accessible all the time, and this should happen, and then this should happen. But actually, people just want to get a job, so it's no wonder that people go, well, all of these job adverts are saying, I need to know this framework, so I'm just going to take the quickest path I can to get employment and be able to pay my mortgage and buy food. Coding boot camps that I've reviewed largely tend to focus on this kind of stuff, you know, and again, I'm not blaming them, I'm not saying it's a terrible thing, but they tend to be, the attitude tends to be, you know, we will take you from nothing to getting your first job in three months or six months or whatever, and that's a perfectly reasonable way to frame what you're offering to people, but there is the problem that maybe the best practices and the background skills aren't maybe being as taught as well as they could be, and of course, courses become out of date very quickly. Particularly, this tends to be a problem with university courses that I've come across. I know a lot of lecturers that really struggle to kind of keep up with all of the stuff that they've got to do, which isn't just learning about technology, they struggle to put the time in to keep their skill set current with all of the stuff that's going on in the industry. So, I think that's a good point. I think that's a good point with all of the stuff that's going on in the industry. And then, I'm also going to just say a few things about interview processes, and again, this definitely isn't the fault of the actual learners trying to come into the industry. But because people don't tend to have a consistent set of skills, a lot of interview processes tend to kind of be, well, we're looking for this kind of unicorn that knows these ten things really well, that are all really complicated. And all of the people that we're talking to have kind of got about four of these things definitely shown up on their CV. So, we've got to do a whole bunch of whiteboard interviews and coding interviews and huge, long, convoluted interview processes to check whether this person can do this job that we're trying to hire for. Another interesting thing to make mention of AI, which has already been talked about today, is it fascinated me that in the last maybe six months to a year or so, I've started to hear multiple hiring managers talk about the fact that oh, we had to put a load of extra processes in and the interviews have become even more complicated now because a lot of our candidates are trying to cheat using AI. I've literally heard about people having chat GPT open in another window whilst they're doing an interview and just typing all of the interview questions into it and then parroting back the answers to the interviewers. And it's like, that's a bit nightmarish and it's difficult to really think about what to do about that. But I kind of think, well, if these people were maybe more confident in their skill sets in the first place, maybe they wouldn't have to think to rely on that quite as much. Another interesting thing is that something that we're sort of looking to do with some kind of curriculum would maybe to have some kind of industry standard benchmark certification, eventually. This is kind of pie in the sky, often the future. But maybe this certification could kind of say, you know, anybody that's got this certification, it's a trusted certification, you know, in the same way that industries such as law or architecture have trusted bodies who have these certifications that everybody gets to prove that they know what they're talking about. But we don't really have that for our industry. And employers don't really trust some random certificate from some, you know, whatever boot camp, you know, I'm not saying those boot camps are bad or not trustworthy, but employers just have a hard time trusting them. And as makes perfect sense, they value demonstrable experience and portfolios a lot more.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 10.6, "text": " Okay, I think we can roll it.", "tokens": [50364, 1033, 11, 286, 519, 321, 393, 3373, 309, 13, 50894], "temperature": 0.0, "avg_logprob": -0.5494162132000101, "compression_ratio": 1.2816901408450705, "no_speech_prob": 0.22630620002746582}, {"id": 1, "seek": 0, "start": 10.6, "end": 15.540000000000001, "text": " And we are moving now to debugging HTTP 3 upload speed in Firefox and I'm more than", "tokens": [50894, 400, 321, 366, 2684, 586, 281, 45592, 33283, 805, 6580, 3073, 294, 46613, 293, 286, 478, 544, 813, 51141], "temperature": 0.0, "avg_logprob": -0.5494162132000101, "compression_ratio": 1.2816901408450705, "no_speech_prob": 0.22630620002746582}, {"id": 2, "seek": 0, "start": 15.540000000000001, "end": 20.2, "text": " happy to welcome Manuel Buschard for it.", "tokens": [51141, 2055, 281, 2928, 34362, 8006, 339, 515, 337, 309, 13, 51374], "temperature": 0.0, "avg_logprob": -0.5494162132000101, "compression_ratio": 1.2816901408450705, "no_speech_prob": 0.22630620002746582}, {"id": 3, "seek": 0, "start": 20.2, "end": 22.2, "text": " Hello.", "tokens": [51374, 2425, 13, 51474], "temperature": 0.0, "avg_logprob": -0.5494162132000101, "compression_ratio": 1.2816901408450705, "no_speech_prob": 0.22630620002746582}, {"id": 4, "seek": 0, "start": 22.2, "end": 28.080000000000002, "text": " I'm Manuel Buschard.", "tokens": [51474, 286, 478, 34362, 8006, 339, 515, 13, 51768], "temperature": 0.0, "avg_logprob": -0.5494162132000101, "compression_ratio": 1.2816901408450705, "no_speech_prob": 0.22630620002746582}, {"id": 5, "seek": 2808, "start": 28.08, "end": 30.08, "text": " I'm Manuel.", "tokens": [50364, 286, 478, 34362, 13, 50464], "temperature": 0.0, "avg_logprob": -0.23032908653145406, "compression_ratio": 1.4770114942528736, "no_speech_prob": 0.008492930792272091}, {"id": 6, "seek": 2808, "start": 30.08, "end": 41.4, "text": " I'm working at Mozilla in the networking team called Necro and we work on Firefox networking.", "tokens": [50464, 286, 478, 1364, 412, 3335, 26403, 294, 264, 17985, 1469, 1219, 1734, 23401, 293, 321, 589, 322, 46613, 17985, 13, 51030], "temperature": 0.0, "avg_logprob": -0.23032908653145406, "compression_ratio": 1.4770114942528736, "no_speech_prob": 0.008492930792272091}, {"id": 7, "seek": 2808, "start": 41.4, "end": 49.08, "text": " And in this talk I'm going about our debugging of HTTP 3 and HTTP 2 upload speed.", "tokens": [51030, 400, 294, 341, 751, 286, 478, 516, 466, 527, 45592, 295, 33283, 805, 293, 33283, 568, 6580, 3073, 13, 51414], "temperature": 0.0, "avg_logprob": -0.23032908653145406, "compression_ratio": 1.4770114942528736, "no_speech_prob": 0.008492930792272091}, {"id": 8, "seek": 2808, "start": 49.08, "end": 54.12, "text": " And for this I'm going to give you some background information first.", "tokens": [51414, 400, 337, 341, 286, 478, 516, 281, 976, 291, 512, 3678, 1589, 700, 13, 51666], "temperature": 0.0, "avg_logprob": -0.23032908653145406, "compression_ratio": 1.4770114942528736, "no_speech_prob": 0.008492930792272091}, {"id": 9, "seek": 5412, "start": 54.12, "end": 61.08, "text": " Then I'll cover the HTTP 2 upload speed problem that we investigated last year.", "tokens": [50364, 1396, 286, 603, 2060, 264, 33283, 568, 6580, 3073, 1154, 300, 321, 30070, 1036, 1064, 13, 50712], "temperature": 0.0, "avg_logprob": -0.18627484639485678, "compression_ratio": 1.6358381502890174, "no_speech_prob": 0.005994557403028011}, {"id": 10, "seek": 5412, "start": 61.08, "end": 68.28, "text": " And afterwards I'll go over to the HTTP 3 upload speed problem that we investigated afterwards.", "tokens": [50712, 400, 10543, 286, 603, 352, 670, 281, 264, 33283, 805, 6580, 3073, 1154, 300, 321, 30070, 10543, 13, 51072], "temperature": 0.0, "avg_logprob": -0.18627484639485678, "compression_ratio": 1.6358381502890174, "no_speech_prob": 0.005994557403028011}, {"id": 11, "seek": 5412, "start": 68.28, "end": 74.03999999999999, "text": " So yeah, first to the Necro team.", "tokens": [51072, 407, 1338, 11, 700, 281, 264, 1734, 23401, 1469, 13, 51360], "temperature": 0.0, "avg_logprob": -0.18627484639485678, "compression_ratio": 1.6358381502890174, "no_speech_prob": 0.005994557403028011}, {"id": 12, "seek": 5412, "start": 74.03999999999999, "end": 82.8, "text": " We in general focus on security, privacy, but always also on performance.", "tokens": [51360, 492, 294, 2674, 1879, 322, 3825, 11, 11427, 11, 457, 1009, 611, 322, 3389, 13, 51798], "temperature": 0.0, "avg_logprob": -0.18627484639485678, "compression_ratio": 1.6358381502890174, "no_speech_prob": 0.005994557403028011}, {"id": 13, "seek": 8280, "start": 82.8, "end": 93.8, "text": " And our protocols that we work on is mostly HTTP but also DNS, web socket, web transport.", "tokens": [50364, 400, 527, 20618, 300, 321, 589, 322, 307, 5240, 33283, 457, 611, 35153, 11, 3670, 19741, 11, 3670, 5495, 13, 50914], "temperature": 0.0, "avg_logprob": -0.15997886657714844, "compression_ratio": 1.5056179775280898, "no_speech_prob": 0.009236338548362255}, {"id": 14, "seek": 8280, "start": 93.8, "end": 98.0, "text": " And we also own the caching and the proxy feature.", "tokens": [50914, 400, 321, 611, 1065, 264, 269, 2834, 293, 264, 29690, 4111, 13, 51124], "temperature": 0.0, "avg_logprob": -0.15997886657714844, "compression_ratio": 1.5056179775280898, "no_speech_prob": 0.009236338548362255}, {"id": 15, "seek": 8280, "start": 98.0, "end": 104.0, "text": " So this is what we generally work on.", "tokens": [51124, 407, 341, 307, 437, 321, 5101, 589, 322, 13, 51424], "temperature": 0.0, "avg_logprob": -0.15997886657714844, "compression_ratio": 1.5056179775280898, "no_speech_prob": 0.009236338548362255}, {"id": 16, "seek": 8280, "start": 104.0, "end": 112.75999999999999, "text": " And when we think about networking performance, we usually think about it in terms of how", "tokens": [51424, 400, 562, 321, 519, 466, 17985, 3389, 11, 321, 2673, 519, 466, 309, 294, 2115, 295, 577, 51862], "temperature": 0.0, "avg_logprob": -0.15997886657714844, "compression_ratio": 1.5056179775280898, "no_speech_prob": 0.009236338548362255}, {"id": 17, "seek": 11276, "start": 112.76, "end": 120.32000000000001, "text": " long does it take from clicking a link to seeing the result.", "tokens": [50364, 938, 775, 309, 747, 490, 9697, 257, 2113, 281, 2577, 264, 1874, 13, 50742], "temperature": 0.0, "avg_logprob": -0.23119952281316122, "compression_ratio": 1.446808510638298, "no_speech_prob": 0.005134453997015953}, {"id": 18, "seek": 11276, "start": 120.32000000000001, "end": 130.28, "text": " And for this we usually just need download speed.", "tokens": [50742, 400, 337, 341, 321, 2673, 445, 643, 5484, 3073, 13, 51240], "temperature": 0.0, "avg_logprob": -0.23119952281316122, "compression_ratio": 1.446808510638298, "no_speech_prob": 0.005134453997015953}, {"id": 19, "seek": 11276, "start": 130.28, "end": 140.08, "text": " For other use cases like uploading large files like videos, we generally also need the upload", "tokens": [51240, 1171, 661, 764, 3331, 411, 27301, 2416, 7098, 411, 2145, 11, 321, 5101, 611, 643, 264, 6580, 51730], "temperature": 0.0, "avg_logprob": -0.23119952281316122, "compression_ratio": 1.446808510638298, "no_speech_prob": 0.005134453997015953}, {"id": 20, "seek": 14008, "start": 140.08, "end": 142.28, "text": " speed.", "tokens": [50364, 3073, 13, 50474], "temperature": 0.0, "avg_logprob": -0.24346437209691757, "compression_ratio": 1.5480225988700564, "no_speech_prob": 0.06526171416044235}, {"id": 21, "seek": 14008, "start": 142.28, "end": 148.48000000000002, "text": " And in this talk I'm going about the HTTP 2 and HTTP 3 upload speed.", "tokens": [50474, 400, 294, 341, 751, 286, 478, 516, 466, 264, 33283, 568, 293, 33283, 805, 6580, 3073, 13, 50784], "temperature": 0.0, "avg_logprob": -0.24346437209691757, "compression_ratio": 1.5480225988700564, "no_speech_prob": 0.06526171416044235}, {"id": 22, "seek": 14008, "start": 148.48000000000002, "end": 152.12, "text": " Those protocols are more in focus.", "tokens": [50784, 3950, 20618, 366, 544, 294, 1879, 13, 50966], "temperature": 0.0, "avg_logprob": -0.24346437209691757, "compression_ratio": 1.5480225988700564, "no_speech_prob": 0.06526171416044235}, {"id": 23, "seek": 14008, "start": 152.12, "end": 156.4, "text": " They are relatively newer than the HTTP 1.", "tokens": [50966, 814, 366, 7226, 17628, 813, 264, 33283, 502, 13, 51180], "temperature": 0.0, "avg_logprob": -0.24346437209691757, "compression_ratio": 1.5480225988700564, "no_speech_prob": 0.06526171416044235}, {"id": 24, "seek": 14008, "start": 156.4, "end": 159.36, "text": " They got introduced in the past decade.", "tokens": [51180, 814, 658, 7268, 294, 264, 1791, 10378, 13, 51328], "temperature": 0.0, "avg_logprob": -0.24346437209691757, "compression_ratio": 1.5480225988700564, "no_speech_prob": 0.06526171416044235}, {"id": 25, "seek": 14008, "start": 159.36, "end": 169.68, "text": " And yeah, so for HTTP 2 upload, first what's the difference in HTTP 2 to HTTP 1.", "tokens": [51328, 400, 1338, 11, 370, 337, 33283, 568, 6580, 11, 700, 437, 311, 264, 2649, 294, 33283, 568, 281, 33283, 502, 13, 51844], "temperature": 0.0, "avg_logprob": -0.24346437209691757, "compression_ratio": 1.5480225988700564, "no_speech_prob": 0.06526171416044235}, {"id": 26, "seek": 16968, "start": 169.68, "end": 180.20000000000002, "text": " In HTTP 2 we allow to make multiple HTTP requests via one TCP socket.", "tokens": [50364, 682, 33283, 568, 321, 2089, 281, 652, 3866, 33283, 12475, 5766, 472, 48965, 19741, 13, 50890], "temperature": 0.0, "avg_logprob": -0.18611801795239719, "compression_ratio": 1.391025641025641, "no_speech_prob": 0.010624619200825691}, {"id": 27, "seek": 16968, "start": 180.20000000000002, "end": 186.28, "text": " And this TCP socket is handled by the operating system.", "tokens": [50890, 400, 341, 48965, 19741, 307, 18033, 538, 264, 7447, 1185, 13, 51194], "temperature": 0.0, "avg_logprob": -0.18611801795239719, "compression_ratio": 1.391025641025641, "no_speech_prob": 0.010624619200825691}, {"id": 28, "seek": 16968, "start": 186.28, "end": 195.76000000000002, "text": " And real quick, the bug in our HTTP code that caused the slow upload was that we configured", "tokens": [51194, 400, 957, 1702, 11, 264, 7426, 294, 527, 33283, 3089, 300, 7008, 264, 2964, 6580, 390, 300, 321, 30538, 51668], "temperature": 0.0, "avg_logprob": -0.18611801795239719, "compression_ratio": 1.391025641025641, "no_speech_prob": 0.010624619200825691}, {"id": 29, "seek": 19576, "start": 195.76, "end": 201.35999999999999, "text": " the socket to have a fixed size buffer of 110 to 80 kilobytes.", "tokens": [50364, 264, 19741, 281, 362, 257, 6806, 2744, 21762, 295, 20154, 281, 4688, 5128, 996, 43673, 13, 50644], "temperature": 0.0, "avg_logprob": -0.22125308267001448, "compression_ratio": 1.4805194805194806, "no_speech_prob": 0.009550780057907104}, {"id": 30, "seek": 19576, "start": 201.35999999999999, "end": 208.67999999999998, "text": " And this fixed size buffer became a bottleneck in high bandwidth situations.", "tokens": [50644, 400, 341, 6806, 2744, 21762, 3062, 257, 44641, 547, 294, 1090, 23647, 6851, 13, 51010], "temperature": 0.0, "avg_logprob": -0.22125308267001448, "compression_ratio": 1.4805194805194806, "no_speech_prob": 0.009550780057907104}, {"id": 31, "seek": 19576, "start": 208.67999999999998, "end": 220.95999999999998, "text": " And yeah, for the fix we just needed to adjust this TCP socket to not set the fixed size", "tokens": [51010, 400, 1338, 11, 337, 264, 3191, 321, 445, 2978, 281, 4369, 341, 48965, 19741, 281, 406, 992, 264, 6806, 2744, 51624], "temperature": 0.0, "avg_logprob": -0.22125308267001448, "compression_ratio": 1.4805194805194806, "no_speech_prob": 0.009550780057907104}, {"id": 32, "seek": 22096, "start": 220.96, "end": 226.28, "text": " buffer and let the operating system handle the buffer size.", "tokens": [50364, 21762, 293, 718, 264, 7447, 1185, 4813, 264, 21762, 2744, 13, 50630], "temperature": 0.0, "avg_logprob": -0.19971907372568168, "compression_ratio": 1.5467625899280575, "no_speech_prob": 0.19136033952236176}, {"id": 33, "seek": 22096, "start": 226.28, "end": 235.4, "text": " And this shows that the operating system is responsible for the upload speed or the performance", "tokens": [50630, 400, 341, 3110, 300, 264, 7447, 1185, 307, 6250, 337, 264, 6580, 3073, 420, 264, 3389, 51086], "temperature": 0.0, "avg_logprob": -0.19971907372568168, "compression_ratio": 1.5467625899280575, "no_speech_prob": 0.19136033952236176}, {"id": 34, "seek": 22096, "start": 235.4, "end": 237.68, "text": " of upload.", "tokens": [51086, 295, 6580, 13, 51200], "temperature": 0.0, "avg_logprob": -0.19971907372568168, "compression_ratio": 1.5467625899280575, "no_speech_prob": 0.19136033952236176}, {"id": 35, "seek": 22096, "start": 237.68, "end": 246.84, "text": " And this is a stark difference to HTTP 3 upload.", "tokens": [51200, 400, 341, 307, 257, 17417, 2649, 281, 33283, 805, 6580, 13, 51658], "temperature": 0.0, "avg_logprob": -0.19971907372568168, "compression_ratio": 1.5467625899280575, "no_speech_prob": 0.19136033952236176}, {"id": 36, "seek": 24684, "start": 246.92000000000002, "end": 260.2, "text": " And with this fix of just not setting the fixed size buffer, we can take a look at Chrome", "tokens": [50368, 400, 365, 341, 3191, 295, 445, 406, 3287, 264, 6806, 2744, 21762, 11, 321, 393, 747, 257, 574, 412, 15327, 51032], "temperature": 0.0, "avg_logprob": -0.15613031387329102, "compression_ratio": 1.3464566929133859, "no_speech_prob": 0.05647678300738335}, {"id": 37, "seek": 24684, "start": 260.2, "end": 266.92, "text": " upload speed, Firefox before the fix, in red and in yellow Firefox after the fix.", "tokens": [51032, 6580, 3073, 11, 46613, 949, 264, 3191, 11, 294, 2182, 293, 294, 5566, 46613, 934, 264, 3191, 13, 51368], "temperature": 0.0, "avg_logprob": -0.15613031387329102, "compression_ratio": 1.3464566929133859, "no_speech_prob": 0.05647678300738335}, {"id": 38, "seek": 26692, "start": 266.92, "end": 280.0, "text": " And we see that in certain configurations like high bandwidth and also from low to higher", "tokens": [50364, 400, 321, 536, 300, 294, 1629, 31493, 411, 1090, 23647, 293, 611, 490, 2295, 281, 2946, 51018], "temperature": 0.0, "avg_logprob": -0.18938180116506723, "compression_ratio": 1.5, "no_speech_prob": 0.1458548754453659}, {"id": 39, "seek": 26692, "start": 280.0, "end": 286.64, "text": " round trip times we have upload speed improvements up to like four times the speed.", "tokens": [51018, 3098, 4931, 1413, 321, 362, 6580, 3073, 13797, 493, 281, 411, 1451, 1413, 264, 3073, 13, 51350], "temperature": 0.0, "avg_logprob": -0.18938180116506723, "compression_ratio": 1.5, "no_speech_prob": 0.1458548754453659}, {"id": 40, "seek": 26692, "start": 286.64, "end": 289.8, "text": " So we only have to wait a fourth of the time.", "tokens": [51350, 407, 321, 787, 362, 281, 1699, 257, 6409, 295, 264, 565, 13, 51508], "temperature": 0.0, "avg_logprob": -0.18938180116506723, "compression_ratio": 1.5, "no_speech_prob": 0.1458548754453659}, {"id": 41, "seek": 28980, "start": 289.8, "end": 299.96000000000004, "text": " And we are on par here with Chrome, which is using all the bandwidth you can use for", "tokens": [50364, 400, 321, 366, 322, 971, 510, 365, 15327, 11, 597, 307, 1228, 439, 264, 23647, 291, 393, 764, 337, 50872], "temperature": 0.0, "avg_logprob": -0.15636333465576172, "compression_ratio": 1.3555555555555556, "no_speech_prob": 0.0035354415886104107}, {"id": 42, "seek": 28980, "start": 299.96000000000004, "end": 301.6, "text": " the upload.", "tokens": [50872, 264, 6580, 13, 50954], "temperature": 0.0, "avg_logprob": -0.15636333465576172, "compression_ratio": 1.3555555555555556, "no_speech_prob": 0.0035354415886104107}, {"id": 43, "seek": 28980, "start": 301.6, "end": 314.16, "text": " So with this fixed last year, we took a more in depth look at upload speed in general.", "tokens": [50954, 407, 365, 341, 6806, 1036, 1064, 11, 321, 1890, 257, 544, 294, 7161, 574, 412, 6580, 3073, 294, 2674, 13, 51582], "temperature": 0.0, "avg_logprob": -0.15636333465576172, "compression_ratio": 1.3555555555555556, "no_speech_prob": 0.0035354415886104107}, {"id": 44, "seek": 31416, "start": 314.16, "end": 323.56, "text": " And we also had bug reports about slow HTTP 3 upload and with HTTP 2 seeing very good", "tokens": [50364, 400, 321, 611, 632, 7426, 7122, 466, 2964, 33283, 805, 6580, 293, 365, 33283, 568, 2577, 588, 665, 50834], "temperature": 0.0, "avg_logprob": -0.1895007292429606, "compression_ratio": 1.2519685039370079, "no_speech_prob": 0.003590470179915428}, {"id": 45, "seek": 31416, "start": 323.56, "end": 333.0, "text": " results, we made it a high priority for us as well and took a look there.", "tokens": [50834, 3542, 11, 321, 1027, 309, 257, 1090, 9365, 337, 505, 382, 731, 293, 1890, 257, 574, 456, 13, 51306], "temperature": 0.0, "avg_logprob": -0.1895007292429606, "compression_ratio": 1.2519685039370079, "no_speech_prob": 0.003590470179915428}, {"id": 46, "seek": 33300, "start": 333.0, "end": 345.2, "text": " So for the fix or seeing how much it changed, we introduced some high level telemetry.", "tokens": [50364, 407, 337, 264, 3191, 420, 2577, 577, 709, 309, 3105, 11, 321, 7268, 512, 1090, 1496, 4304, 5537, 627, 13, 50974], "temperature": 0.0, "avg_logprob": -0.2604907010052655, "compression_ratio": 1.2743362831858407, "no_speech_prob": 0.005052296910434961}, {"id": 47, "seek": 33300, "start": 345.2, "end": 355.76, "text": " And these are person tiles of user reported upload speed.", "tokens": [50974, 400, 613, 366, 954, 21982, 295, 4195, 7055, 6580, 3073, 13, 51502], "temperature": 0.0, "avg_logprob": -0.2604907010052655, "compression_ratio": 1.2743362831858407, "no_speech_prob": 0.005052296910434961}, {"id": 48, "seek": 35576, "start": 356.76, "end": 363.92, "text": " We have different versions, 114 on the left side is around one year ago.", "tokens": [50414, 492, 362, 819, 9606, 11, 2975, 19, 322, 264, 1411, 1252, 307, 926, 472, 1064, 2057, 13, 50772], "temperature": 0.0, "avg_logprob": -0.24979097801342345, "compression_ratio": 1.367741935483871, "no_speech_prob": 0.23827983438968658}, {"id": 49, "seek": 35576, "start": 363.92, "end": 376.15999999999997, "text": " And in 115 to 16, we rolled out the HTTP 2 upload speed fix and we can see the improvements", "tokens": [50772, 400, 294, 39436, 281, 3165, 11, 321, 14306, 484, 264, 33283, 568, 6580, 3073, 3191, 293, 321, 393, 536, 264, 13797, 51384], "temperature": 0.0, "avg_logprob": -0.24979097801342345, "compression_ratio": 1.367741935483871, "no_speech_prob": 0.23827983438968658}, {"id": 50, "seek": 35576, "start": 376.15999999999997, "end": 381.36, "text": " in the high level telemetry about upload speed.", "tokens": [51384, 294, 264, 1090, 1496, 4304, 5537, 627, 466, 6580, 3073, 13, 51644], "temperature": 0.0, "avg_logprob": -0.24979097801342345, "compression_ratio": 1.367741935483871, "no_speech_prob": 0.23827983438968658}, {"id": 51, "seek": 38136, "start": 381.36, "end": 392.76, "text": " It's an improvement like in the higher parts, it's roughly doubled and not quite, but it's", "tokens": [50364, 467, 311, 364, 10444, 411, 294, 264, 2946, 3166, 11, 309, 311, 9810, 24405, 293, 406, 1596, 11, 457, 309, 311, 50934], "temperature": 0.0, "avg_logprob": -0.3121330912520246, "compression_ratio": 1.2, "no_speech_prob": 0.01539014745503664}, {"id": 52, "seek": 38136, "start": 392.76, "end": 396.68, "text": " very visible.", "tokens": [50934, 588, 8974, 13, 51130], "temperature": 0.0, "avg_logprob": -0.3121330912520246, "compression_ratio": 1.2, "no_speech_prob": 0.01539014745503664}, {"id": 53, "seek": 38136, "start": 396.68, "end": 400.92, "text": " So now two difference to HTTP 3 upload.", "tokens": [51130, 407, 586, 732, 2649, 281, 33283, 805, 6580, 13, 51342], "temperature": 0.0, "avg_logprob": -0.3121330912520246, "compression_ratio": 1.2, "no_speech_prob": 0.01539014745503664}, {"id": 54, "seek": 40092, "start": 400.92, "end": 405.52000000000004, "text": " HTTP 3 upload is widely different.", "tokens": [50364, 33283, 805, 6580, 307, 13371, 819, 13, 50594], "temperature": 0.0, "avg_logprob": -0.37512545152144, "compression_ratio": 1.2900763358778626, "no_speech_prob": 0.11247918754816055}, {"id": 55, "seek": 40092, "start": 405.52000000000004, "end": 413.40000000000003, "text": " HTTP 3 uses a different transport layer.", "tokens": [50594, 33283, 805, 4960, 257, 819, 5495, 4583, 13, 50988], "temperature": 0.0, "avg_logprob": -0.37512545152144, "compression_ratio": 1.2900763358778626, "no_speech_prob": 0.11247918754816055}, {"id": 56, "seek": 40092, "start": 413.40000000000003, "end": 425.20000000000005, "text": " We don't use TCP anymore, but Qwik was standardised alongside with HTTP 3 and just relatively", "tokens": [50988, 492, 500, 380, 764, 48965, 3602, 11, 457, 1249, 86, 1035, 390, 3832, 2640, 12385, 365, 33283, 805, 293, 445, 7226, 51578], "temperature": 0.0, "avg_logprob": -0.37512545152144, "compression_ratio": 1.2900763358778626, "no_speech_prob": 0.11247918754816055}, {"id": 57, "seek": 42520, "start": 425.2, "end": 426.2, "text": " recently.", "tokens": [50364, 3938, 13, 50414], "temperature": 0.0, "avg_logprob": -0.22527595276528217, "compression_ratio": 1.2335766423357664, "no_speech_prob": 0.03382345288991928}, {"id": 58, "seek": 42520, "start": 426.2, "end": 435.24, "text": " So the standardisation was finalised in 2021, which is two to three years from now, right", "tokens": [50414, 407, 264, 3832, 7623, 390, 2572, 2640, 294, 7201, 11, 597, 307, 732, 281, 1045, 924, 490, 586, 11, 558, 50866], "temperature": 0.0, "avg_logprob": -0.22527595276528217, "compression_ratio": 1.2335766423357664, "no_speech_prob": 0.03382345288991928}, {"id": 59, "seek": 42520, "start": 435.24, "end": 437.64, "text": " now.", "tokens": [50866, 586, 13, 50986], "temperature": 0.0, "avg_logprob": -0.22527595276528217, "compression_ratio": 1.2335766423357664, "no_speech_prob": 0.03382345288991928}, {"id": 60, "seek": 42520, "start": 437.64, "end": 445.96, "text": " And Firefox also included HTTP 3 upload around the time in 2021.", "tokens": [50986, 400, 46613, 611, 5556, 33283, 805, 6580, 926, 264, 565, 294, 7201, 13, 51402], "temperature": 0.0, "avg_logprob": -0.22527595276528217, "compression_ratio": 1.2335766423357664, "no_speech_prob": 0.03382345288991928}, {"id": 61, "seek": 44596, "start": 445.96, "end": 458.2, "text": " The work started in 2019, which is all relatively recent in comparison to TCP and HTTP 2.", "tokens": [50364, 440, 589, 1409, 294, 6071, 11, 597, 307, 439, 7226, 5162, 294, 9660, 281, 48965, 293, 33283, 568, 13, 50976], "temperature": 0.0, "avg_logprob": -0.23070025444030762, "compression_ratio": 1.353658536585366, "no_speech_prob": 0.005803158972412348}, {"id": 62, "seek": 44596, "start": 458.2, "end": 464.24, "text": " HTTP 2 is around a decade now, all.", "tokens": [50976, 33283, 568, 307, 926, 257, 10378, 586, 11, 439, 13, 51278], "temperature": 0.0, "avg_logprob": -0.23070025444030762, "compression_ratio": 1.353658536585366, "no_speech_prob": 0.005803158972412348}, {"id": 63, "seek": 44596, "start": 464.24, "end": 471.67999999999995, "text": " And the problem is different here because the operating system is responsible for the", "tokens": [51278, 400, 264, 1154, 307, 819, 510, 570, 264, 7447, 1185, 307, 6250, 337, 264, 51650], "temperature": 0.0, "avg_logprob": -0.23070025444030762, "compression_ratio": 1.353658536585366, "no_speech_prob": 0.005803158972412348}, {"id": 64, "seek": 44596, "start": 471.67999999999995, "end": 473.96, "text": " TCP stack.", "tokens": [51650, 48965, 8630, 13, 51764], "temperature": 0.0, "avg_logprob": -0.23070025444030762, "compression_ratio": 1.353658536585366, "no_speech_prob": 0.005803158972412348}, {"id": 65, "seek": 47396, "start": 473.96, "end": 486.76, "text": " It is responsible for sending all the data performant and in Qwik we have to implement", "tokens": [50364, 467, 307, 6250, 337, 7750, 439, 264, 1412, 2042, 394, 293, 294, 1249, 86, 1035, 321, 362, 281, 4445, 51004], "temperature": 0.0, "avg_logprob": -0.28964702755797145, "compression_ratio": 1.5342465753424657, "no_speech_prob": 0.006458744872361422}, {"id": 66, "seek": 47396, "start": 486.76, "end": 497.0, "text": " the same congestion control in Firefox and the Firefox application, so it's not the", "tokens": [51004, 264, 912, 40816, 1969, 294, 46613, 293, 264, 46613, 3861, 11, 370, 309, 311, 406, 264, 51516], "temperature": 0.0, "avg_logprob": -0.28964702755797145, "compression_ratio": 1.5342465753424657, "no_speech_prob": 0.006458744872361422}, {"id": 67, "seek": 47396, "start": 497.0, "end": 501.12, "text": " responsibility shifted to Firefox or the application.", "tokens": [51516, 6357, 18892, 281, 46613, 420, 264, 3861, 13, 51722], "temperature": 0.0, "avg_logprob": -0.28964702755797145, "compression_ratio": 1.5342465753424657, "no_speech_prob": 0.006458744872361422}, {"id": 68, "seek": 50112, "start": 501.44, "end": 510.32, "text": " TCP is already decades old, it was done about 50 years ago and it's operating since 30", "tokens": [50380, 48965, 307, 1217, 7878, 1331, 11, 309, 390, 1096, 466, 2625, 924, 2057, 293, 309, 311, 7447, 1670, 2217, 50824], "temperature": 0.0, "avg_logprob": -0.367915887099046, "compression_ratio": 1.477832512315271, "no_speech_prob": 0.02864857017993927}, {"id": 69, "seek": 50112, "start": 510.32, "end": 515.04, "text": " years and got a lot of eyes on it.", "tokens": [50824, 924, 293, 658, 257, 688, 295, 2575, 322, 309, 13, 51060], "temperature": 0.0, "avg_logprob": -0.367915887099046, "compression_ratio": 1.477832512315271, "no_speech_prob": 0.02864857017993927}, {"id": 70, "seek": 50112, "start": 515.04, "end": 520.72, "text": " And our Firefox implementation is really new and we were kind of the first ones to look", "tokens": [51060, 400, 527, 46613, 11420, 307, 534, 777, 293, 321, 645, 733, 295, 264, 700, 2306, 281, 574, 51344], "temperature": 0.0, "avg_logprob": -0.367915887099046, "compression_ratio": 1.477832512315271, "no_speech_prob": 0.02864857017993927}, {"id": 71, "seek": 50112, "start": 520.72, "end": 527.92, "text": " into upload speed performance here, so we had a lot of low hanging fruits here to work", "tokens": [51344, 666, 6580, 3073, 3389, 510, 11, 370, 321, 632, 257, 688, 295, 2295, 8345, 12148, 510, 281, 589, 51704], "temperature": 0.0, "avg_logprob": -0.367915887099046, "compression_ratio": 1.477832512315271, "no_speech_prob": 0.02864857017993927}, {"id": 72, "seek": 50112, "start": 527.92, "end": 529.4, "text": " on.", "tokens": [51704, 322, 13, 51778], "temperature": 0.0, "avg_logprob": -0.367915887099046, "compression_ratio": 1.477832512315271, "no_speech_prob": 0.02864857017993927}, {"id": 73, "seek": 52940, "start": 529.4, "end": 538.0799999999999, "text": " And I wanted to visualise this a bit, like we have HV 2 and HV 3, which are very similar.", "tokens": [50364, 400, 286, 1415, 281, 5056, 908, 341, 257, 857, 11, 411, 321, 362, 389, 53, 568, 293, 389, 53, 805, 11, 597, 366, 588, 2531, 13, 50798], "temperature": 0.0, "avg_logprob": -0.21076200558589056, "compression_ratio": 1.2521008403361344, "no_speech_prob": 0.0029191195499151945}, {"id": 74, "seek": 52940, "start": 538.0799999999999, "end": 546.04, "text": " In HV 3 we rely on Qwik and Qwik is also implemented by us.", "tokens": [50798, 682, 389, 53, 805, 321, 10687, 322, 1249, 86, 1035, 293, 1249, 86, 1035, 307, 611, 12270, 538, 505, 13, 51196], "temperature": 0.0, "avg_logprob": -0.21076200558589056, "compression_ratio": 1.2521008403361344, "no_speech_prob": 0.0029191195499151945}, {"id": 75, "seek": 54604, "start": 546.04, "end": 561.24, "text": " In HV 2 we have TCP and TCP is provided by the operating system.", "tokens": [50364, 682, 389, 53, 568, 321, 362, 48965, 293, 48965, 307, 5649, 538, 264, 7447, 1185, 13, 51124], "temperature": 0.0, "avg_logprob": -0.18535658291407994, "compression_ratio": 1.2396694214876034, "no_speech_prob": 0.0043846373446285725}, {"id": 76, "seek": 54604, "start": 561.24, "end": 575.1999999999999, "text": " So I want to go into a few findings that we had in our presentation, in our IO graphs", "tokens": [51124, 407, 286, 528, 281, 352, 666, 257, 1326, 16483, 300, 321, 632, 294, 527, 5860, 11, 294, 527, 39839, 24877, 51822], "temperature": 0.0, "avg_logprob": -0.18535658291407994, "compression_ratio": 1.2396694214876034, "no_speech_prob": 0.0043846373446285725}, {"id": 77, "seek": 57520, "start": 575.2, "end": 577.5600000000001, "text": " and other tooling that we took.", "tokens": [50364, 293, 661, 46593, 300, 321, 1890, 13, 50482], "temperature": 0.0, "avg_logprob": -0.2329355137688773, "compression_ratio": 1.474025974025974, "no_speech_prob": 0.18810878694057465}, {"id": 78, "seek": 57520, "start": 577.5600000000001, "end": 585.6, "text": " The most useful tool for us was IO graphs where we just printed within the application,", "tokens": [50482, 440, 881, 4420, 2290, 337, 505, 390, 39839, 24877, 689, 321, 445, 13567, 1951, 264, 3861, 11, 50884], "temperature": 0.0, "avg_logprob": -0.2329355137688773, "compression_ratio": 1.474025974025974, "no_speech_prob": 0.18810878694057465}, {"id": 79, "seek": 57520, "start": 585.6, "end": 595.2, "text": " like with logging, when we send packets, when we receive packets, how big our congestion", "tokens": [50884, 411, 365, 27991, 11, 562, 321, 2845, 30364, 11, 562, 321, 4774, 30364, 11, 577, 955, 527, 40816, 51364], "temperature": 0.0, "avg_logprob": -0.2329355137688773, "compression_ratio": 1.474025974025974, "no_speech_prob": 0.18810878694057465}, {"id": 80, "seek": 57520, "start": 595.2, "end": 601.08, "text": " is and everything.", "tokens": [51364, 307, 293, 1203, 13, 51658], "temperature": 0.0, "avg_logprob": -0.2329355137688773, "compression_ratio": 1.474025974025974, "no_speech_prob": 0.18810878694057465}, {"id": 81, "seek": 60108, "start": 601.08, "end": 605.2800000000001, "text": " So the first problem we have, what does this graph show?", "tokens": [50364, 407, 264, 700, 1154, 321, 362, 11, 437, 775, 341, 4295, 855, 30, 50574], "temperature": 0.0, "avg_logprob": -0.20813717032378576, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.03341853618621826}, {"id": 82, "seek": 60108, "start": 605.2800000000001, "end": 614.44, "text": " So this graph is our congestion window over time.", "tokens": [50574, 407, 341, 4295, 307, 527, 40816, 4910, 670, 565, 13, 51032], "temperature": 0.0, "avg_logprob": -0.20813717032378576, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.03341853618621826}, {"id": 83, "seek": 60108, "start": 614.44, "end": 615.6800000000001, "text": " What is the congestion window?", "tokens": [51032, 708, 307, 264, 40816, 4910, 30, 51094], "temperature": 0.0, "avg_logprob": -0.20813717032378576, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.03341853618621826}, {"id": 84, "seek": 60108, "start": 615.6800000000001, "end": 627.0, "text": " So the congestion, well, I would like to go over this.", "tokens": [51094, 407, 264, 40816, 11, 731, 11, 286, 576, 411, 281, 352, 670, 341, 13, 51660], "temperature": 0.0, "avg_logprob": -0.20813717032378576, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.03341853618621826}, {"id": 85, "seek": 62700, "start": 627.0, "end": 630.04, "text": " We don't want to overload the network.", "tokens": [50364, 492, 500, 380, 528, 281, 28777, 264, 3209, 13, 50516], "temperature": 0.0, "avg_logprob": -0.22096175652045708, "compression_ratio": 1.723529411764706, "no_speech_prob": 0.0702064037322998}, {"id": 86, "seek": 62700, "start": 630.04, "end": 637.56, "text": " And overloading the network is called like congestion control, well, not overloading", "tokens": [50516, 400, 28777, 278, 264, 3209, 307, 1219, 411, 40816, 1969, 11, 731, 11, 406, 28777, 278, 50892], "temperature": 0.0, "avg_logprob": -0.22096175652045708, "compression_ratio": 1.723529411764706, "no_speech_prob": 0.0702064037322998}, {"id": 87, "seek": 62700, "start": 637.56, "end": 639.12, "text": " the network.", "tokens": [50892, 264, 3209, 13, 50970], "temperature": 0.0, "avg_logprob": -0.22096175652045708, "compression_ratio": 1.723529411764706, "no_speech_prob": 0.0702064037322998}, {"id": 88, "seek": 62700, "start": 639.12, "end": 646.68, "text": " And this is the responsible of the transport layer, which is TCP or Qwik.", "tokens": [50970, 400, 341, 307, 264, 6250, 295, 264, 5495, 4583, 11, 597, 307, 48965, 420, 1249, 86, 1035, 13, 51348], "temperature": 0.0, "avg_logprob": -0.22096175652045708, "compression_ratio": 1.723529411764706, "no_speech_prob": 0.0702064037322998}, {"id": 89, "seek": 62700, "start": 646.68, "end": 654.12, "text": " And all the bugs that we had were in this congestion control, or most of the bugs.", "tokens": [51348, 400, 439, 264, 15120, 300, 321, 632, 645, 294, 341, 40816, 1969, 11, 420, 881, 295, 264, 15120, 13, 51720], "temperature": 0.0, "avg_logprob": -0.22096175652045708, "compression_ratio": 1.723529411764706, "no_speech_prob": 0.0702064037322998}, {"id": 90, "seek": 65412, "start": 654.12, "end": 663.64, "text": " And the congestion window that we have is the estimate of how fast we can upload right", "tokens": [50364, 400, 264, 40816, 4910, 300, 321, 362, 307, 264, 12539, 295, 577, 2370, 321, 393, 6580, 558, 50840], "temperature": 0.0, "avg_logprob": -0.20098637561408841, "compression_ratio": 1.4409448818897639, "no_speech_prob": 0.009846298955380917}, {"id": 91, "seek": 65412, "start": 663.64, "end": 665.48, "text": " now.", "tokens": [50840, 586, 13, 50932], "temperature": 0.0, "avg_logprob": -0.20098637561408841, "compression_ratio": 1.4409448818897639, "no_speech_prob": 0.009846298955380917}, {"id": 92, "seek": 65412, "start": 665.48, "end": 670.24, "text": " And this changes over time.", "tokens": [50932, 400, 341, 2962, 670, 565, 13, 51170], "temperature": 0.0, "avg_logprob": -0.20098637561408841, "compression_ratio": 1.4409448818897639, "no_speech_prob": 0.009846298955380917}, {"id": 93, "seek": 65412, "start": 670.24, "end": 677.6, "text": " With every packet that we receive, we think we can upload more.", "tokens": [51170, 2022, 633, 20300, 300, 321, 4774, 11, 321, 519, 321, 393, 6580, 544, 13, 51538], "temperature": 0.0, "avg_logprob": -0.20098637561408841, "compression_ratio": 1.4409448818897639, "no_speech_prob": 0.009846298955380917}, {"id": 94, "seek": 67760, "start": 677.6, "end": 686.72, "text": " So we have a graph like here where we steadily increase the congestion window over time with", "tokens": [50364, 407, 321, 362, 257, 4295, 411, 510, 689, 321, 36129, 3488, 264, 40816, 4910, 670, 565, 365, 50820], "temperature": 0.0, "avg_logprob": -0.1252948260698162, "compression_ratio": 1.608695652173913, "no_speech_prob": 0.03508031368255615}, {"id": 95, "seek": 67760, "start": 686.72, "end": 689.24, "text": " all the packets that we receive.", "tokens": [50820, 439, 264, 30364, 300, 321, 4774, 13, 50946], "temperature": 0.0, "avg_logprob": -0.1252948260698162, "compression_ratio": 1.608695652173913, "no_speech_prob": 0.03508031368255615}, {"id": 96, "seek": 67760, "start": 689.24, "end": 695.08, "text": " And when we detect that packets got lost, we are assuming that the network is overloaded", "tokens": [50946, 400, 562, 321, 5531, 300, 30364, 658, 2731, 11, 321, 366, 11926, 300, 264, 3209, 307, 28777, 292, 51238], "temperature": 0.0, "avg_logprob": -0.1252948260698162, "compression_ratio": 1.608695652173913, "no_speech_prob": 0.03508031368255615}, {"id": 97, "seek": 67760, "start": 695.08, "end": 699.36, "text": " and we reduce the congestion window by half.", "tokens": [51238, 293, 321, 5407, 264, 40816, 4910, 538, 1922, 13, 51452], "temperature": 0.0, "avg_logprob": -0.1252948260698162, "compression_ratio": 1.608695652173913, "no_speech_prob": 0.03508031368255615}, {"id": 98, "seek": 69936, "start": 699.36, "end": 703.88, "text": " And this is like one of the early graphs that we had.", "tokens": [50364, 400, 341, 307, 411, 472, 295, 264, 2440, 24877, 300, 321, 632, 13, 50590], "temperature": 0.0, "avg_logprob": -0.22607694731818306, "compression_ratio": 1.569767441860465, "no_speech_prob": 0.08736809343099594}, {"id": 99, "seek": 69936, "start": 703.88, "end": 708.32, "text": " And orange are like the bytes in flight that we have.", "tokens": [50590, 400, 7671, 366, 411, 264, 36088, 294, 7018, 300, 321, 362, 13, 50812], "temperature": 0.0, "avg_logprob": -0.22607694731818306, "compression_ratio": 1.569767441860465, "no_speech_prob": 0.08736809343099594}, {"id": 100, "seek": 69936, "start": 708.32, "end": 712.08, "text": " They circulate from top to bottom.", "tokens": [50812, 814, 12515, 473, 490, 1192, 281, 2767, 13, 51000], "temperature": 0.0, "avg_logprob": -0.22607694731818306, "compression_ratio": 1.569767441860465, "no_speech_prob": 0.08736809343099594}, {"id": 101, "seek": 69936, "start": 712.08, "end": 717.16, "text": " Increasing again, blue is the congestion window.", "tokens": [51000, 30367, 3349, 797, 11, 3344, 307, 264, 40816, 4910, 13, 51254], "temperature": 0.0, "avg_logprob": -0.22607694731818306, "compression_ratio": 1.569767441860465, "no_speech_prob": 0.08736809343099594}, {"id": 102, "seek": 69936, "start": 717.16, "end": 729.16, "text": " And what we see at the drop points is that the congestion window doesn't half.", "tokens": [51254, 400, 437, 321, 536, 412, 264, 3270, 2793, 307, 300, 264, 40816, 4910, 1177, 380, 1922, 13, 51854], "temperature": 0.0, "avg_logprob": -0.22607694731818306, "compression_ratio": 1.569767441860465, "no_speech_prob": 0.08736809343099594}, {"id": 103, "seek": 72916, "start": 729.16, "end": 734.6, "text": " We would expect it to half during a congestion event.", "tokens": [50364, 492, 576, 2066, 309, 281, 1922, 1830, 257, 40816, 2280, 13, 50636], "temperature": 0.0, "avg_logprob": -0.18978246053059897, "compression_ratio": 1.6041666666666667, "no_speech_prob": 0.0006069277296774089}, {"id": 104, "seek": 72916, "start": 734.6, "end": 738.0799999999999, "text": " Instead it drops almost to zero.", "tokens": [50636, 7156, 309, 11438, 1920, 281, 4018, 13, 50810], "temperature": 0.0, "avg_logprob": -0.18978246053059897, "compression_ratio": 1.6041666666666667, "no_speech_prob": 0.0006069277296774089}, {"id": 105, "seek": 72916, "start": 738.0799999999999, "end": 741.4399999999999, "text": " And this was one of the bugs that we had.", "tokens": [50810, 400, 341, 390, 472, 295, 264, 15120, 300, 321, 632, 13, 50978], "temperature": 0.0, "avg_logprob": -0.18978246053059897, "compression_ratio": 1.6041666666666667, "no_speech_prob": 0.0006069277296774089}, {"id": 106, "seek": 72916, "start": 741.4399999999999, "end": 744.24, "text": " We just dropped to zero.", "tokens": [50978, 492, 445, 8119, 281, 4018, 13, 51118], "temperature": 0.0, "avg_logprob": -0.18978246053059897, "compression_ratio": 1.6041666666666667, "no_speech_prob": 0.0006069277296774089}, {"id": 107, "seek": 72916, "start": 744.24, "end": 749.9599999999999, "text": " Each packet that we detected was lost, half the congestion window.", "tokens": [51118, 6947, 20300, 300, 321, 21896, 390, 2731, 11, 1922, 264, 40816, 4910, 13, 51404], "temperature": 0.0, "avg_logprob": -0.18978246053059897, "compression_ratio": 1.6041666666666667, "no_speech_prob": 0.0006069277296774089}, {"id": 108, "seek": 72916, "start": 749.9599999999999, "end": 755.28, "text": " And normally you would only do this once, but we did it multiple times for each packet.", "tokens": [51404, 400, 5646, 291, 576, 787, 360, 341, 1564, 11, 457, 321, 630, 309, 3866, 1413, 337, 1184, 20300, 13, 51670], "temperature": 0.0, "avg_logprob": -0.18978246053059897, "compression_ratio": 1.6041666666666667, "no_speech_prob": 0.0006069277296774089}, {"id": 109, "seek": 75528, "start": 755.28, "end": 762.1999999999999, "text": " So essentially we dropped to almost zero on all congestion events here.", "tokens": [50364, 407, 4476, 321, 8119, 281, 1920, 4018, 322, 439, 40816, 3931, 510, 13, 50710], "temperature": 0.0, "avg_logprob": -0.4231264163286258, "compression_ratio": 1.2156862745098038, "no_speech_prob": 0.017926258966326714}, {"id": 110, "seek": 75528, "start": 762.1999999999999, "end": 764.72, "text": " This was one of the first fix.", "tokens": [50710, 639, 390, 472, 295, 264, 700, 3191, 13, 50836], "temperature": 0.0, "avg_logprob": -0.4231264163286258, "compression_ratio": 1.2156862745098038, "no_speech_prob": 0.017926258966326714}, {"id": 111, "seek": 75528, "start": 764.72, "end": 765.72, "text": " Later...", "tokens": [50836, 11965, 485, 50886], "temperature": 0.0, "avg_logprob": -0.4231264163286258, "compression_ratio": 1.2156862745098038, "no_speech_prob": 0.017926258966326714}, {"id": 112, "seek": 75528, "start": 765.72, "end": 766.72, "text": " Yeah.", "tokens": [50886, 865, 13, 50936], "temperature": 0.0, "avg_logprob": -0.4231264163286258, "compression_ratio": 1.2156862745098038, "no_speech_prob": 0.017926258966326714}, {"id": 113, "seek": 75528, "start": 766.72, "end": 767.72, "text": " Later.", "tokens": [50936, 11965, 13, 50986], "temperature": 0.0, "avg_logprob": -0.4231264163286258, "compression_ratio": 1.2156862745098038, "no_speech_prob": 0.017926258966326714}, {"id": 114, "seek": 76772, "start": 767.72, "end": 789.88, "text": " This is the same graph.", "tokens": [50364, 639, 307, 264, 912, 4295, 13, 51472], "temperature": 0.0, "avg_logprob": -0.29198877334594725, "compression_ratio": 1.103448275862069, "no_speech_prob": 0.009993892163038254}, {"id": 115, "seek": 76772, "start": 789.88, "end": 797.08, "text": " With the congestion window problem fixed, we had to investigate further.", "tokens": [51472, 2022, 264, 40816, 4910, 1154, 6806, 11, 321, 632, 281, 15013, 3052, 13, 51832], "temperature": 0.0, "avg_logprob": -0.29198877334594725, "compression_ratio": 1.103448275862069, "no_speech_prob": 0.009993892163038254}, {"id": 116, "seek": 79708, "start": 798.08, "end": 800.84, "text": " There were more problems.", "tokens": [50414, 821, 645, 544, 2740, 13, 50552], "temperature": 0.0, "avg_logprob": -0.2687616013644034, "compression_ratio": 1.4829931972789117, "no_speech_prob": 0.14904603362083435}, {"id": 117, "seek": 79708, "start": 800.84, "end": 808.76, "text": " Here, like all these drops of packets going down, we want to stay with our bytes in flight", "tokens": [50552, 1692, 11, 411, 439, 613, 11438, 295, 30364, 516, 760, 11, 321, 528, 281, 1754, 365, 527, 36088, 294, 7018, 50948], "temperature": 0.0, "avg_logprob": -0.2687616013644034, "compression_ratio": 1.4829931972789117, "no_speech_prob": 0.14904603362083435}, {"id": 118, "seek": 79708, "start": 808.76, "end": 812.44, "text": " as high as possible, with our upload speed as high as possible.", "tokens": [50948, 382, 1090, 382, 1944, 11, 365, 527, 6580, 3073, 382, 1090, 382, 1944, 13, 51132], "temperature": 0.0, "avg_logprob": -0.2687616013644034, "compression_ratio": 1.4829931972789117, "no_speech_prob": 0.14904603362083435}, {"id": 119, "seek": 79708, "start": 812.44, "end": 816.36, "text": " But we dropped down quite some times.", "tokens": [51132, 583, 321, 8119, 760, 1596, 512, 1413, 13, 51328], "temperature": 0.0, "avg_logprob": -0.2687616013644034, "compression_ratio": 1.4829931972789117, "no_speech_prob": 0.14904603362083435}, {"id": 120, "seek": 81636, "start": 816.36, "end": 823.36, "text": " And if we...", "tokens": [50364, 400, 498, 321, 485, 50714], "temperature": 0.0, "avg_logprob": -0.29950566725297406, "compression_ratio": 1.376068376068376, "no_speech_prob": 0.01062424574047327}, {"id": 121, "seek": 81636, "start": 823.36, "end": 828.72, "text": " Yeah.", "tokens": [50714, 865, 13, 50982], "temperature": 0.0, "avg_logprob": -0.29950566725297406, "compression_ratio": 1.376068376068376, "no_speech_prob": 0.01062424574047327}, {"id": 122, "seek": 81636, "start": 828.72, "end": 833.8000000000001, "text": " For this problem, we need a bit of background information.", "tokens": [50982, 1171, 341, 1154, 11, 321, 643, 257, 857, 295, 3678, 1589, 13, 51236], "temperature": 0.0, "avg_logprob": -0.29950566725297406, "compression_ratio": 1.376068376068376, "no_speech_prob": 0.01062424574047327}, {"id": 123, "seek": 81636, "start": 833.8000000000001, "end": 842.96, "text": " And this background information was this slide, which I apparently put a bit later.", "tokens": [51236, 400, 341, 3678, 1589, 390, 341, 4137, 11, 597, 286, 7970, 829, 257, 857, 1780, 13, 51694], "temperature": 0.0, "avg_logprob": -0.29950566725297406, "compression_ratio": 1.376068376068376, "no_speech_prob": 0.01062424574047327}, {"id": 124, "seek": 84296, "start": 842.96, "end": 849.1600000000001, "text": " And I'll go back to the background about Cric first before going over the next problem.", "tokens": [50364, 400, 286, 603, 352, 646, 281, 264, 3678, 466, 383, 1341, 700, 949, 516, 670, 264, 958, 1154, 13, 50674], "temperature": 0.0, "avg_logprob": -0.19154699349109036, "compression_ratio": 1.4923076923076923, "no_speech_prob": 0.01586298830807209}, {"id": 125, "seek": 84296, "start": 849.1600000000001, "end": 851.1600000000001, "text": " So Cric got introduced.", "tokens": [50674, 407, 383, 1341, 658, 7268, 13, 50774], "temperature": 0.0, "avg_logprob": -0.19154699349109036, "compression_ratio": 1.4923076923076923, "no_speech_prob": 0.01586298830807209}, {"id": 126, "seek": 84296, "start": 851.1600000000001, "end": 855.76, "text": " Sorry about the mix up here.", "tokens": [50774, 4919, 466, 264, 2890, 493, 510, 13, 51004], "temperature": 0.0, "avg_logprob": -0.19154699349109036, "compression_ratio": 1.4923076923076923, "no_speech_prob": 0.01586298830807209}, {"id": 127, "seek": 84296, "start": 855.76, "end": 859.48, "text": " Cric, the new transport layer protocol.", "tokens": [51004, 383, 1341, 11, 264, 777, 5495, 4583, 10336, 13, 51190], "temperature": 0.0, "avg_logprob": -0.19154699349109036, "compression_ratio": 1.4923076923076923, "no_speech_prob": 0.01586298830807209}, {"id": 128, "seek": 84296, "start": 859.48, "end": 861.48, "text": " What is Cric?", "tokens": [51190, 708, 307, 383, 1341, 30, 51290], "temperature": 0.0, "avg_logprob": -0.19154699349109036, "compression_ratio": 1.4923076923076923, "no_speech_prob": 0.01586298830807209}, {"id": 129, "seek": 84296, "start": 861.48, "end": 871.6, "text": " Cric is on the same layer as TCP, but conceptually you can have multiple TCP connections at once", "tokens": [51290, 383, 1341, 307, 322, 264, 912, 4583, 382, 48965, 11, 457, 3410, 671, 291, 393, 362, 3866, 48965, 9271, 412, 1564, 51796], "temperature": 0.0, "avg_logprob": -0.19154699349109036, "compression_ratio": 1.4923076923076923, "no_speech_prob": 0.01586298830807209}, {"id": 130, "seek": 87160, "start": 871.64, "end": 874.76, "text": " over one quick connection.", "tokens": [50366, 670, 472, 1702, 4984, 13, 50522], "temperature": 0.0, "avg_logprob": -0.27753790687112245, "compression_ratio": 1.5625, "no_speech_prob": 0.015087436884641647}, {"id": 131, "seek": 87160, "start": 874.76, "end": 881.48, "text": " And we have other benefits, like TLS being integrated, so that the connection setup phase", "tokens": [50522, 400, 321, 362, 661, 5311, 11, 411, 314, 19198, 885, 10919, 11, 370, 300, 264, 4984, 8657, 5574, 50858], "temperature": 0.0, "avg_logprob": -0.27753790687112245, "compression_ratio": 1.5625, "no_speech_prob": 0.015087436884641647}, {"id": 132, "seek": 87160, "start": 881.48, "end": 888.96, "text": " takes less time, only one round trip time instead of two round trip times.", "tokens": [50858, 2516, 1570, 565, 11, 787, 472, 3098, 4931, 565, 2602, 295, 732, 3098, 4931, 1413, 13, 51232], "temperature": 0.0, "avg_logprob": -0.27753790687112245, "compression_ratio": 1.5625, "no_speech_prob": 0.015087436884641647}, {"id": 133, "seek": 87160, "start": 888.96, "end": 889.96, "text": " Yeah.", "tokens": [51232, 865, 13, 51282], "temperature": 0.0, "avg_logprob": -0.27753790687112245, "compression_ratio": 1.5625, "no_speech_prob": 0.015087436884641647}, {"id": 134, "seek": 87160, "start": 889.96, "end": 898.64, "text": " And now we get back to the introduction of the concept of congestion control.", "tokens": [51282, 400, 586, 321, 483, 646, 281, 264, 9339, 295, 264, 3410, 295, 40816, 1969, 13, 51716], "temperature": 0.0, "avg_logprob": -0.27753790687112245, "compression_ratio": 1.5625, "no_speech_prob": 0.015087436884641647}, {"id": 135, "seek": 89864, "start": 898.64, "end": 907.64, "text": " Traction control is for us handles like not overloading the network from all participants", "tokens": [50364, 1765, 2894, 1969, 307, 337, 505, 18722, 411, 406, 28777, 278, 264, 3209, 490, 439, 10503, 50814], "temperature": 0.0, "avg_logprob": -0.23498759857595783, "compression_ratio": 1.648936170212766, "no_speech_prob": 0.004387624096125364}, {"id": 136, "seek": 89864, "start": 907.64, "end": 908.64, "text": " in the internet.", "tokens": [50814, 294, 264, 4705, 13, 50864], "temperature": 0.0, "avg_logprob": -0.23498759857595783, "compression_ratio": 1.648936170212766, "no_speech_prob": 0.004387624096125364}, {"id": 137, "seek": 89864, "start": 908.64, "end": 916.4399999999999, "text": " So everyone makes sure that we don't overload the network and keep it usable for everyone.", "tokens": [50864, 407, 1518, 1669, 988, 300, 321, 500, 380, 28777, 264, 3209, 293, 1066, 309, 29975, 337, 1518, 13, 51254], "temperature": 0.0, "avg_logprob": -0.23498759857595783, "compression_ratio": 1.648936170212766, "no_speech_prob": 0.004387624096125364}, {"id": 138, "seek": 89864, "start": 916.4399999999999, "end": 922.68, "text": " And the congestion window is one of the concepts that we looked at the first graph and also", "tokens": [51254, 400, 264, 40816, 4910, 307, 472, 295, 264, 10392, 300, 321, 2956, 412, 264, 700, 4295, 293, 611, 51566], "temperature": 0.0, "avg_logprob": -0.23498759857595783, "compression_ratio": 1.648936170212766, "no_speech_prob": 0.004387624096125364}, {"id": 139, "seek": 89864, "start": 922.68, "end": 924.48, "text": " in the second graph.", "tokens": [51566, 294, 264, 1150, 4295, 13, 51656], "temperature": 0.0, "avg_logprob": -0.23498759857595783, "compression_ratio": 1.648936170212766, "no_speech_prob": 0.004387624096125364}, {"id": 140, "seek": 92448, "start": 924.48, "end": 929.36, "text": " This is our estimation at how much can we upload at a time.", "tokens": [50364, 639, 307, 527, 35701, 412, 577, 709, 393, 321, 6580, 412, 257, 565, 13, 50608], "temperature": 0.0, "avg_logprob": -0.1921733425509545, "compression_ratio": 1.5776397515527951, "no_speech_prob": 0.0015459717251360416}, {"id": 141, "seek": 92448, "start": 929.36, "end": 936.64, "text": " What is our upload speed to the destination server?", "tokens": [50608, 708, 307, 527, 6580, 3073, 281, 264, 12236, 7154, 30, 50972], "temperature": 0.0, "avg_logprob": -0.1921733425509545, "compression_ratio": 1.5776397515527951, "no_speech_prob": 0.0015459717251360416}, {"id": 142, "seek": 92448, "start": 936.64, "end": 942.24, "text": " And so our estimation depends on us receiving packets.", "tokens": [50972, 400, 370, 527, 35701, 5946, 322, 505, 10040, 30364, 13, 51252], "temperature": 0.0, "avg_logprob": -0.1921733425509545, "compression_ratio": 1.5776397515527951, "no_speech_prob": 0.0015459717251360416}, {"id": 143, "seek": 92448, "start": 942.24, "end": 950.0, "text": " And we want to increase the congestion window only if we are sure that we are using the", "tokens": [51252, 400, 321, 528, 281, 3488, 264, 40816, 4910, 787, 498, 321, 366, 988, 300, 321, 366, 1228, 264, 51640], "temperature": 0.0, "avg_logprob": -0.1921733425509545, "compression_ratio": 1.5776397515527951, "no_speech_prob": 0.0015459717251360416}, {"id": 144, "seek": 95000, "start": 950.0, "end": 951.0, "text": " congestion window.", "tokens": [50364, 40816, 4910, 13, 50414], "temperature": 0.0, "avg_logprob": -0.2265475111187629, "compression_ratio": 1.6615384615384616, "no_speech_prob": 0.010464245453476906}, {"id": 145, "seek": 95000, "start": 951.0, "end": 958.52, "text": " Like we are sending as much data as we have in the congestion window because otherwise", "tokens": [50414, 1743, 321, 366, 7750, 382, 709, 1412, 382, 321, 362, 294, 264, 40816, 4910, 570, 5911, 50790], "temperature": 0.0, "avg_logprob": -0.2265475111187629, "compression_ratio": 1.6615384615384616, "no_speech_prob": 0.010464245453476906}, {"id": 146, "seek": 95000, "start": 958.52, "end": 968.68, "text": " we are not sure if our estimate is correct if we are sending less data than what is that", "tokens": [50790, 321, 366, 406, 988, 498, 527, 12539, 307, 3006, 498, 321, 366, 7750, 1570, 1412, 813, 437, 307, 300, 51298], "temperature": 0.0, "avg_logprob": -0.2265475111187629, "compression_ratio": 1.6615384615384616, "no_speech_prob": 0.010464245453476906}, {"id": 147, "seek": 95000, "start": 968.68, "end": 970.84, "text": " we estimate we could.", "tokens": [51298, 321, 12539, 321, 727, 13, 51406], "temperature": 0.0, "avg_logprob": -0.2265475111187629, "compression_ratio": 1.6615384615384616, "no_speech_prob": 0.010464245453476906}, {"id": 148, "seek": 97084, "start": 971.1600000000001, "end": 982.12, "text": " And this detection on whether a packet was sent during the utilization of the congestion", "tokens": [50380, 400, 341, 17784, 322, 1968, 257, 20300, 390, 2279, 1830, 264, 37074, 295, 264, 40816, 50928], "temperature": 0.0, "avg_logprob": -0.23456975525500728, "compression_ratio": 1.5845070422535212, "no_speech_prob": 0.02880234457552433}, {"id": 149, "seek": 97084, "start": 982.12, "end": 986.0, "text": " window like sending as much data as we could.", "tokens": [50928, 4910, 411, 7750, 382, 709, 1412, 382, 321, 727, 13, 51122], "temperature": 0.0, "avg_logprob": -0.23456975525500728, "compression_ratio": 1.5845070422535212, "no_speech_prob": 0.02880234457552433}, {"id": 150, "seek": 97084, "start": 986.0, "end": 1000.12, "text": " This had a bug as well and made us mark packets as not utilizing the congestion window for", "tokens": [51122, 639, 632, 257, 7426, 382, 731, 293, 1027, 505, 1491, 30364, 382, 406, 26775, 264, 40816, 4910, 337, 51828], "temperature": 0.0, "avg_logprob": -0.23456975525500728, "compression_ratio": 1.5845070422535212, "no_speech_prob": 0.02880234457552433}, {"id": 151, "seek": 100012, "start": 1001.0, "end": 1007.36, "text": " 50 to 75 percent of the packets which meant that we didn't increase the congestion window", "tokens": [50408, 2625, 281, 9562, 3043, 295, 264, 30364, 597, 4140, 300, 321, 994, 380, 3488, 264, 40816, 4910, 50726], "temperature": 0.0, "avg_logprob": -0.26913524681413675, "compression_ratio": 1.3877551020408163, "no_speech_prob": 0.0015716117341071367}, {"id": 152, "seek": 100012, "start": 1007.36, "end": 1009.36, "text": " as fast as we could.", "tokens": [50726, 382, 2370, 382, 321, 727, 13, 50826], "temperature": 0.0, "avg_logprob": -0.26913524681413675, "compression_ratio": 1.3877551020408163, "no_speech_prob": 0.0015716117341071367}, {"id": 153, "seek": 100012, "start": 1009.36, "end": 1017.8, "text": " This is another simple incremental fix for our HPE 3 upload speed problem.", "tokens": [50826, 639, 307, 1071, 2199, 35759, 3191, 337, 527, 389, 5208, 805, 6580, 3073, 1154, 13, 51248], "temperature": 0.0, "avg_logprob": -0.26913524681413675, "compression_ratio": 1.3877551020408163, "no_speech_prob": 0.0015716117341071367}, {"id": 154, "seek": 100012, "start": 1017.8, "end": 1021.36, "text": " And after fixing this the graph looks like this.", "tokens": [51248, 400, 934, 19442, 341, 264, 4295, 1542, 411, 341, 13, 51426], "temperature": 0.0, "avg_logprob": -0.26913524681413675, "compression_ratio": 1.3877551020408163, "no_speech_prob": 0.0015716117341071367}, {"id": 155, "seek": 100012, "start": 1021.36, "end": 1027.4, "text": " It has a steeper curve, steeper line.", "tokens": [51426, 467, 575, 257, 16841, 260, 7605, 11, 16841, 260, 1622, 13, 51728], "temperature": 0.0, "avg_logprob": -0.26913524681413675, "compression_ratio": 1.3877551020408163, "no_speech_prob": 0.0015716117341071367}, {"id": 156, "seek": 102740, "start": 1027.4, "end": 1032.92, "text": " Here we also see that the first problem that we had got fixed.", "tokens": [50364, 1692, 321, 611, 536, 300, 264, 700, 1154, 300, 321, 632, 658, 6806, 13, 50640], "temperature": 0.0, "avg_logprob": -0.24546360551265248, "compression_ratio": 1.484076433121019, "no_speech_prob": 0.0014096988597884774}, {"id": 157, "seek": 102740, "start": 1032.92, "end": 1040.92, "text": " We don't drop to zero with the congestion window but have it halfway here.", "tokens": [50640, 492, 500, 380, 3270, 281, 4018, 365, 264, 40816, 4910, 457, 362, 309, 15461, 510, 13, 51040], "temperature": 0.0, "avg_logprob": -0.24546360551265248, "compression_ratio": 1.484076433121019, "no_speech_prob": 0.0014096988597884774}, {"id": 158, "seek": 102740, "start": 1046.68, "end": 1053.4, "text": " With these steady increases we can also see them in our high level telemetry that we introduced", "tokens": [51328, 2022, 613, 13211, 8637, 321, 393, 611, 536, 552, 294, 527, 1090, 1496, 4304, 5537, 627, 300, 321, 7268, 51664], "temperature": 0.0, "avg_logprob": -0.24546360551265248, "compression_ratio": 1.484076433121019, "no_speech_prob": 0.0014096988597884774}, {"id": 159, "seek": 105340, "start": 1053.4, "end": 1058.6000000000001, "text": " for our HPE 2 upload speed problem.", "tokens": [50364, 337, 527, 389, 5208, 568, 6580, 3073, 1154, 13, 50624], "temperature": 0.0, "avg_logprob": -0.2095424383878708, "compression_ratio": 1.4578313253012047, "no_speech_prob": 0.0032611193601042032}, {"id": 160, "seek": 105340, "start": 1058.6000000000001, "end": 1069.6000000000001, "text": " In HPE 3 in the higher network bandwidth we have already an increase of three times.", "tokens": [50624, 682, 389, 5208, 805, 294, 264, 2946, 3209, 23647, 321, 362, 1217, 364, 3488, 295, 1045, 1413, 13, 51174], "temperature": 0.0, "avg_logprob": -0.2095424383878708, "compression_ratio": 1.4578313253012047, "no_speech_prob": 0.0032611193601042032}, {"id": 161, "seek": 105340, "start": 1069.6000000000001, "end": 1078.8400000000001, "text": " We are three times as fast as before tackling the problem from around 31 megabits per second", "tokens": [51174, 492, 366, 1045, 1413, 382, 2370, 382, 949, 34415, 264, 1154, 490, 926, 10353, 10816, 455, 1208, 680, 1150, 51636], "temperature": 0.0, "avg_logprob": -0.2095424383878708, "compression_ratio": 1.4578313253012047, "no_speech_prob": 0.0032611193601042032}, {"id": 162, "seek": 105340, "start": 1078.8400000000001, "end": 1080.92, "text": " to 93 megabits per sentence.", "tokens": [51636, 281, 28876, 10816, 455, 1208, 680, 8174, 13, 51740], "temperature": 0.0, "avg_logprob": -0.2095424383878708, "compression_ratio": 1.4578313253012047, "no_speech_prob": 0.0032611193601042032}, {"id": 163, "seek": 108092, "start": 1080.96, "end": 1085.16, "text": " This is the 95 percentiles.", "tokens": [50366, 639, 307, 264, 13420, 3043, 4680, 13, 50576], "temperature": 0.0, "avg_logprob": -0.40150772897820725, "compression_ratio": 1.205607476635514, "no_speech_prob": 0.0011494754580780864}, {"id": 164, "seek": 108092, "start": 1085.16, "end": 1093.16, "text": " This is a network speed of better than 95 of all clients.", "tokens": [50576, 639, 307, 257, 3209, 3073, 295, 1101, 813, 13420, 295, 439, 6982, 13, 50976], "temperature": 0.0, "avg_logprob": -0.40150772897820725, "compression_ratio": 1.205607476635514, "no_speech_prob": 0.0011494754580780864}, {"id": 165, "seek": 108092, "start": 1097.48, "end": 1103.04, "text": " Also visible from the high level telemetry.", "tokens": [51192, 2743, 8974, 490, 264, 1090, 1496, 4304, 5537, 627, 13, 51470], "temperature": 0.0, "avg_logprob": -0.40150772897820725, "compression_ratio": 1.205607476635514, "no_speech_prob": 0.0011494754580780864}, {"id": 166, "seek": 110304, "start": 1103.04, "end": 1110.04, "text": " For the current state we are still working on this.", "tokens": [50364, 1171, 264, 2190, 1785, 321, 366, 920, 1364, 322, 341, 13, 50714], "temperature": 0.0, "avg_logprob": -0.28374681801631535, "compression_ratio": 1.544871794871795, "no_speech_prob": 0.010286631993949413}, {"id": 167, "seek": 110304, "start": 1110.04, "end": 1122.56, "text": " We have more bugs that we are aware of and are also in contact with or in collaboration", "tokens": [50714, 492, 362, 544, 15120, 300, 321, 366, 3650, 295, 293, 366, 611, 294, 3385, 365, 420, 294, 9363, 51340], "temperature": 0.0, "avg_logprob": -0.28374681801631535, "compression_ratio": 1.544871794871795, "no_speech_prob": 0.010286631993949413}, {"id": 168, "seek": 110304, "start": 1122.56, "end": 1131.2, "text": " with contributors who can upload or request logs from them to have a look at their network", "tokens": [51340, 365, 45627, 567, 393, 6580, 420, 5308, 20820, 490, 552, 281, 362, 257, 574, 412, 641, 3209, 51772], "temperature": 0.0, "avg_logprob": -0.28374681801631535, "compression_ratio": 1.544871794871795, "no_speech_prob": 0.010286631993949413}, {"id": 169, "seek": 110304, "start": 1131.2, "end": 1132.8, "text": " condition.", "tokens": [51772, 4188, 13, 51852], "temperature": 0.0, "avg_logprob": -0.28374681801631535, "compression_ratio": 1.544871794871795, "no_speech_prob": 0.010286631993949413}, {"id": 170, "seek": 113280, "start": 1133.04, "end": 1143.12, "text": " This is the diagram from before but from the contributors log where we can identify which", "tokens": [50376, 639, 307, 264, 10686, 490, 949, 457, 490, 264, 45627, 3565, 689, 321, 393, 5876, 597, 50880], "temperature": 0.0, "avg_logprob": -0.4174830027988979, "compression_ratio": 1.3739837398373984, "no_speech_prob": 0.0017750575207173824}, {"id": 171, "seek": 113280, "start": 1143.12, "end": 1153.12, "text": " problems are present from our machines in comparison to their network location.", "tokens": [50880, 2740, 366, 1974, 490, 527, 8379, 294, 9660, 281, 641, 3209, 4914, 13, 51380], "temperature": 0.0, "avg_logprob": -0.4174830027988979, "compression_ratio": 1.3739837398373984, "no_speech_prob": 0.0017750575207173824}, {"id": 172, "seek": 115312, "start": 1153.1999999999998, "end": 1165.1999999999998, "text": " With the logging mechanism which we also included in Firefox this became a bit easier", "tokens": [50368, 2022, 264, 27991, 7513, 597, 321, 611, 5556, 294, 46613, 341, 3062, 257, 857, 3571, 50968], "temperature": 0.0, "avg_logprob": -0.4884857904343378, "compression_ratio": 1.3643410852713178, "no_speech_prob": 0.00869751162827015}, {"id": 173, "seek": 115312, "start": 1167.1999999999998, "end": 1169.1999999999998, "text": " about logging.", "tokens": [51068, 466, 27991, 13, 51168], "temperature": 0.0, "avg_logprob": -0.4884857904343378, "compression_ratio": 1.3643410852713178, "no_speech_prob": 0.00869751162827015}, {"id": 174, "seek": 115312, "start": 1169.76, "end": 1177.4399999999998, "text": " A few of the further works that we are currently still aware of is that the", "tokens": [51196, 316, 1326, 295, 264, 3052, 1985, 300, 321, 366, 4362, 920, 3650, 295, 307, 300, 264, 51580], "temperature": 0.0, "avg_logprob": -0.4884857904343378, "compression_ratio": 1.3643410852713178, "no_speech_prob": 0.00869751162827015}, {"id": 175, "seek": 117744, "start": 1178.24, "end": 1184.24, "text": " upload has a few CPU bottlenecks.", "tokens": [50404, 6580, 575, 257, 1326, 13199, 44641, 2761, 13, 50704], "temperature": 0.0, "avg_logprob": -0.5171665098608994, "compression_ratio": 1.2148760330578512, "no_speech_prob": 0.00228121317923069}, {"id": 176, "seek": 117744, "start": 1184.24, "end": 1189.24, "text": " Mostly profiling.", "tokens": [50704, 29035, 1740, 4883, 13, 50954], "temperature": 0.0, "avg_logprob": -0.5171665098608994, "compression_ratio": 1.2148760330578512, "no_speech_prob": 0.00228121317923069}, {"id": 177, "seek": 117744, "start": 1189.24, "end": 1200.24, "text": " The QuickStack made us aware that not the cryptography part of Quick is taking most of the time", "tokens": [50954, 440, 12101, 4520, 501, 1027, 505, 3650, 300, 406, 264, 9844, 5820, 644, 295, 12101, 307, 1940, 881, 295, 264, 565, 51504], "temperature": 0.0, "avg_logprob": -0.5171665098608994, "compression_ratio": 1.2148760330578512, "no_speech_prob": 0.00228121317923069}, {"id": 178, "seek": 120024, "start": 1200.8, "end": 1206.8, "text": " but some other parts which is unexpected.", "tokens": [50392, 457, 512, 661, 3166, 597, 307, 13106, 13, 50692], "temperature": 0.0, "avg_logprob": -0.31343313852945964, "compression_ratio": 1.4906832298136645, "no_speech_prob": 0.008818534202873707}, {"id": 179, "seek": 120024, "start": 1206.8, "end": 1214.8, "text": " We have already identified a few code tests that can be improved and are improving these.", "tokens": [50692, 492, 362, 1217, 9234, 257, 1326, 3089, 6921, 300, 393, 312, 9689, 293, 366, 11470, 613, 13, 51092], "temperature": 0.0, "avg_logprob": -0.31343313852945964, "compression_ratio": 1.4906832298136645, "no_speech_prob": 0.008818534202873707}, {"id": 180, "seek": 120024, "start": 1215.6, "end": 1218.6, "text": " We will also continue with profiling this.", "tokens": [51132, 492, 486, 611, 2354, 365, 1740, 4883, 341, 13, 51282], "temperature": 0.0, "avg_logprob": -0.31343313852945964, "compression_ratio": 1.4906832298136645, "no_speech_prob": 0.008818534202873707}, {"id": 181, "seek": 120024, "start": 1218.6, "end": 1223.6, "text": " We also have similar to the HDP case we have a fixed size buffer.", "tokens": [51282, 492, 611, 362, 2531, 281, 264, 389, 11373, 1389, 321, 362, 257, 6806, 2744, 21762, 13, 51532], "temperature": 0.0, "avg_logprob": -0.31343313852945964, "compression_ratio": 1.4906832298136645, "no_speech_prob": 0.008818534202873707}, {"id": 182, "seek": 122360, "start": 1223.9199999999998, "end": 1233.9199999999998, "text": " This will get to be a problem at some point at much higher bandwidth than with HP2 upload", "tokens": [50380, 639, 486, 483, 281, 312, 257, 1154, 412, 512, 935, 412, 709, 2946, 23647, 813, 365, 12557, 17, 6580, 50880], "temperature": 0.0, "avg_logprob": -0.3530730924744537, "compression_ratio": 1.4583333333333333, "no_speech_prob": 0.012572137638926506}, {"id": 183, "seek": 122360, "start": 1233.9199999999998, "end": 1243.9199999999998, "text": " speed problem because we have a buffer that is 8 times as high, 1 megabyte instead of 128 kilobyte.", "tokens": [50880, 3073, 1154, 570, 321, 362, 257, 21762, 300, 307, 1649, 1413, 382, 1090, 11, 502, 10816, 34529, 2602, 295, 29810, 5128, 13944, 975, 13, 51380], "temperature": 0.0, "avg_logprob": -0.3530730924744537, "compression_ratio": 1.4583333333333333, "no_speech_prob": 0.012572137638926506}, {"id": 184, "seek": 122360, "start": 1245.9199999999998, "end": 1252.9199999999998, "text": " We are also aware of the problem that when we are in package reordering networks we detect", "tokens": [51480, 492, 366, 611, 3650, 295, 264, 1154, 300, 562, 321, 366, 294, 7372, 319, 765, 1794, 9590, 321, 5531, 51830], "temperature": 0.0, "avg_logprob": -0.3530730924744537, "compression_ratio": 1.4583333333333333, "no_speech_prob": 0.012572137638926506}, {"id": 185, "seek": 125360, "start": 1253.9199999999998, "end": 1257.9199999999998, "text": " these package reordering as losses too frequently.", "tokens": [50380, 613, 7372, 319, 765, 1794, 382, 15352, 886, 10374, 13, 50580], "temperature": 0.0, "avg_logprob": -0.3873916165582065, "compression_ratio": 1.439306358381503, "no_speech_prob": 0.004037703853100538}, {"id": 186, "seek": 125360, "start": 1257.9199999999998, "end": 1267.9199999999998, "text": " There are ways around this in TCP specifications like REC or Forward Egg that we are taking a look at", "tokens": [50580, 821, 366, 2098, 926, 341, 294, 48965, 29448, 411, 497, 8140, 420, 35524, 16960, 300, 321, 366, 1940, 257, 574, 412, 51080], "temperature": 0.0, "avg_logprob": -0.3873916165582065, "compression_ratio": 1.439306358381503, "no_speech_prob": 0.004037703853100538}, {"id": 187, "seek": 125360, "start": 1267.9199999999998, "end": 1279.9199999999998, "text": " and investigating which one we want to implement and which proves to be the best of the options.", "tokens": [51080, 293, 22858, 597, 472, 321, 528, 281, 4445, 293, 597, 25019, 281, 312, 264, 1151, 295, 264, 3956, 13, 51680], "temperature": 0.0, "avg_logprob": -0.3873916165582065, "compression_ratio": 1.439306358381503, "no_speech_prob": 0.004037703853100538}, {"id": 188, "seek": 127992, "start": 1280.48, "end": 1287.48, "text": " We are also setting up CIS to catch regressions in the future and also have a detailed view", "tokens": [50392, 492, 366, 611, 3287, 493, 383, 2343, 281, 3745, 1121, 735, 626, 294, 264, 2027, 293, 611, 362, 257, 9942, 1910, 50742], "temperature": 0.0, "avg_logprob": -0.2944279909133911, "compression_ratio": 1.3756906077348066, "no_speech_prob": 0.00562104769051075}, {"id": 189, "seek": 127992, "start": 1291.64, "end": 1298.64, "text": " from different networking conditions, how they look.", "tokens": [50950, 490, 819, 17985, 4487, 11, 577, 436, 574, 13, 51300], "temperature": 0.0, "avg_logprob": -0.2944279909133911, "compression_ratio": 1.3756906077348066, "no_speech_prob": 0.00562104769051075}, {"id": 190, "seek": 127992, "start": 1300.8000000000002, "end": 1307.8000000000002, "text": " We have seen where we got improvements in HDP3 already, it is now at a similar level to the HDP2 upload.", "tokens": [51408, 492, 362, 1612, 689, 321, 658, 13797, 294, 389, 11373, 18, 1217, 11, 309, 307, 586, 412, 257, 2531, 1496, 281, 264, 389, 11373, 17, 6580, 13, 51758], "temperature": 0.0, "avg_logprob": -0.2944279909133911, "compression_ratio": 1.3756906077348066, "no_speech_prob": 0.00562104769051075}, {"id": 191, "seek": 130992, "start": 1310.92, "end": 1323.92, "text": " It is looking already a lot better but we are still on it and we are aware of a few bugs and we will investigate further.", "tokens": [50414, 467, 307, 1237, 1217, 257, 688, 1101, 457, 321, 366, 920, 322, 309, 293, 321, 366, 3650, 295, 257, 1326, 15120, 293, 321, 486, 15013, 3052, 13, 51064], "temperature": 0.0, "avg_logprob": -0.25047909586053146, "compression_ratio": 1.4228187919463087, "no_speech_prob": 0.002141952281817794}, {"id": 192, "seek": 130992, "start": 1324.92, "end": 1333.92, "text": " We want to make it as good as we can to see all the benefits that HDP3 can provide for us.", "tokens": [51114, 492, 528, 281, 652, 309, 382, 665, 382, 321, 393, 281, 536, 439, 264, 5311, 300, 389, 11373, 18, 393, 2893, 337, 505, 13, 51564], "temperature": 0.0, "avg_logprob": -0.25047909586053146, "compression_ratio": 1.4228187919463087, "no_speech_prob": 0.002141952281817794}, {"id": 193, "seek": 133392, "start": 1334.92, "end": 1343.92, "text": " A lot of this was in cooperation with contributors reporting bugs.", "tokens": [50414, 316, 688, 295, 341, 390, 294, 14968, 365, 45627, 10031, 15120, 13, 50864], "temperature": 0.0, "avg_logprob": -0.15817171096801758, "compression_ratio": 1.3537414965986394, "no_speech_prob": 0.007425057701766491}, {"id": 194, "seek": 133392, "start": 1348.92, "end": 1351.92, "text": " One specific bug is the HDP3 upload speed bug.", "tokens": [51114, 1485, 2685, 7426, 307, 264, 389, 11373, 18, 6580, 3073, 7426, 13, 51264], "temperature": 0.0, "avg_logprob": -0.15817171096801758, "compression_ratio": 1.3537414965986394, "no_speech_prob": 0.007425057701766491}, {"id": 195, "seek": 133392, "start": 1351.92, "end": 1357.92, "text": " If you want to take a look at our work there you can follow the investigations there.", "tokens": [51264, 759, 291, 528, 281, 747, 257, 574, 412, 527, 589, 456, 291, 393, 1524, 264, 25582, 456, 13, 51564], "temperature": 0.0, "avg_logprob": -0.15817171096801758, "compression_ratio": 1.3537414965986394, "no_speech_prob": 0.007425057701766491}, {"id": 196, "seek": 135792, "start": 1357.92, "end": 1364.92, "text": " You can reach us at the Metrics channel if you want to get in contact with the NECO team.", "tokens": [50364, 509, 393, 2524, 505, 412, 264, 6377, 10716, 2269, 498, 291, 528, 281, 483, 294, 3385, 365, 264, 426, 8140, 46, 1469, 13, 50714], "temperature": 0.0, "avg_logprob": -0.19977943932832176, "compression_ratio": 1.4917127071823204, "no_speech_prob": 0.005975184962153435}, {"id": 197, "seek": 135792, "start": 1364.92, "end": 1371.92, "text": " We have a NECO specific documentation also about creating logs.", "tokens": [50714, 492, 362, 257, 426, 8140, 46, 2685, 14333, 611, 466, 4084, 20820, 13, 51064], "temperature": 0.0, "avg_logprob": -0.19977943932832176, "compression_ratio": 1.4917127071823204, "no_speech_prob": 0.005975184962153435}, {"id": 198, "seek": 135792, "start": 1374.92, "end": 1383.92, "text": " If you are interested in the NECO team we are making ourselves a bit more transparent by providing our meeting nodes", "tokens": [51214, 759, 291, 366, 3102, 294, 264, 426, 8140, 46, 1469, 321, 366, 1455, 4175, 257, 857, 544, 12737, 538, 6530, 527, 3440, 13891, 51664], "temperature": 0.0, "avg_logprob": -0.19977943932832176, "compression_ratio": 1.4917127071823204, "no_speech_prob": 0.005975184962153435}, {"id": 199, "seek": 138392, "start": 1384.92, "end": 1387.92, "text": " and having a blog.", "tokens": [50414, 293, 1419, 257, 6968, 13, 50564], "temperature": 0.0, "avg_logprob": -0.2094382719560103, "compression_ratio": 1.4013157894736843, "no_speech_prob": 0.012422572821378708}, {"id": 200, "seek": 138392, "start": 1389.92, "end": 1397.92, "text": " If you need help with fixing bugs or want to get in contact like contributing,", "tokens": [50664, 759, 291, 643, 854, 365, 19442, 15120, 420, 528, 281, 483, 294, 3385, 411, 19270, 11, 51064], "temperature": 0.0, "avg_logprob": -0.2094382719560103, "compression_ratio": 1.4013157894736843, "no_speech_prob": 0.012422572821378708}, {"id": 201, "seek": 138392, "start": 1398.92, "end": 1406.92, "text": " we also are going to provide office hours where you can talk to us directly and get in touch.", "tokens": [51114, 321, 611, 366, 516, 281, 2893, 3398, 2496, 689, 291, 393, 751, 281, 505, 3838, 293, 483, 294, 2557, 13, 51514], "temperature": 0.0, "avg_logprob": -0.2094382719560103, "compression_ratio": 1.4013157894736843, "no_speech_prob": 0.012422572821378708}, {"id": 202, "seek": 138392, "start": 1409.92, "end": 1411.92, "text": " Thanks for listening.", "tokens": [51664, 2561, 337, 4764, 13, 51764], "temperature": 0.0, "avg_logprob": -0.2094382719560103, "compression_ratio": 1.4013157894736843, "no_speech_prob": 0.012422572821378708}, {"id": 203, "seek": 141192, "start": 1411.92, "end": 1413.92, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 50464], "temperature": 0.0, "avg_logprob": -0.24956011772155762, "compression_ratio": 1.3647798742138364, "no_speech_prob": 0.07155022025108337}, {"id": 204, "seek": 141192, "start": 1417.92, "end": 1420.92, "text": " We might have time for one or two questions.", "tokens": [50664, 492, 1062, 362, 565, 337, 472, 420, 732, 1651, 13, 50814], "temperature": 0.0, "avg_logprob": -0.24956011772155762, "compression_ratio": 1.3647798742138364, "no_speech_prob": 0.07155022025108337}, {"id": 205, "seek": 141192, "start": 1425.92, "end": 1427.92, "text": " Hi, thanks for talking.", "tokens": [51064, 2421, 11, 3231, 337, 1417, 13, 51164], "temperature": 0.0, "avg_logprob": -0.24956011772155762, "compression_ratio": 1.3647798742138364, "no_speech_prob": 0.07155022025108337}, {"id": 206, "seek": 141192, "start": 1427.92, "end": 1434.92, "text": " I just wanted to ask if there is any chance of Quick being brought into the Linux kernel or Windows kernel or wherever else Firefox runs.", "tokens": [51164, 286, 445, 1415, 281, 1029, 498, 456, 307, 604, 2931, 295, 12101, 885, 3038, 666, 264, 18734, 28256, 420, 8591, 28256, 420, 8660, 1646, 46613, 6676, 13, 51514], "temperature": 0.0, "avg_logprob": -0.24956011772155762, "compression_ratio": 1.3647798742138364, "no_speech_prob": 0.07155022025108337}, {"id": 207, "seek": 143492, "start": 1435.92, "end": 1442.92, "text": " The question is whether Quick is going to be implemented in the operating system with the Shokut APIs.", "tokens": [50414, 440, 1168, 307, 1968, 12101, 307, 516, 281, 312, 12270, 294, 264, 7447, 1185, 365, 264, 1160, 453, 325, 21445, 13, 50764], "temperature": 0.0, "avg_logprob": -0.26848228354203074, "compression_ratio": 1.5204081632653061, "no_speech_prob": 0.0508059561252594}, {"id": 208, "seek": 143492, "start": 1443.92, "end": 1447.92, "text": " I am expecting that it will be implemented at some point.", "tokens": [50814, 286, 669, 9650, 300, 309, 486, 312, 12270, 412, 512, 935, 13, 51014], "temperature": 0.0, "avg_logprob": -0.26848228354203074, "compression_ratio": 1.5204081632653061, "no_speech_prob": 0.0508059561252594}, {"id": 209, "seek": 143492, "start": 1447.92, "end": 1452.92, "text": " We do have, I have seen some TLS integration.", "tokens": [51014, 492, 360, 362, 11, 286, 362, 1612, 512, 314, 19198, 10980, 13, 51264], "temperature": 0.0, "avg_logprob": -0.26848228354203074, "compression_ratio": 1.5204081632653061, "no_speech_prob": 0.0508059561252594}, {"id": 210, "seek": 143492, "start": 1452.92, "end": 1457.92, "text": " This is one of the stoppers probably that TLS has to be integrated into the kernel as well.", "tokens": [51264, 639, 307, 472, 295, 264, 1590, 21819, 1391, 300, 314, 19198, 575, 281, 312, 10919, 666, 264, 28256, 382, 731, 13, 51514], "temperature": 0.0, "avg_logprob": -0.26848228354203074, "compression_ratio": 1.5204081632653061, "no_speech_prob": 0.0508059561252594}, {"id": 211, "seek": 145792, "start": 1458.92, "end": 1463.92, "text": " Quick is so new that it didn't have time to be integrated into the operating system.", "tokens": [50414, 12101, 307, 370, 777, 300, 309, 994, 380, 362, 565, 281, 312, 10919, 666, 264, 7447, 1185, 13, 50664], "temperature": 0.0, "avg_logprob": -0.1927121537072318, "compression_ratio": 1.4394904458598725, "no_speech_prob": 0.038303449749946594}, {"id": 212, "seek": 145792, "start": 1463.92, "end": 1470.92, "text": " I think as soon as operating systems provide APIs we will start using them.", "tokens": [50664, 286, 519, 382, 2321, 382, 7447, 3652, 2893, 21445, 321, 486, 722, 1228, 552, 13, 51014], "temperature": 0.0, "avg_logprob": -0.1927121537072318, "compression_ratio": 1.4394904458598725, "no_speech_prob": 0.038303449749946594}, {"id": 213, "seek": 145792, "start": 1474.92, "end": 1479.92, "text": " They are not here right now but in the future I would assume yes.", "tokens": [51214, 814, 366, 406, 510, 558, 586, 457, 294, 264, 2027, 286, 576, 6552, 2086, 13, 51464], "temperature": 0.0, "avg_logprob": -0.1927121537072318, "compression_ratio": 1.4394904458598725, "no_speech_prob": 0.038303449749946594}, {"id": 214, "seek": 147992, "start": 1480.92, "end": 1485.92, "text": " Two years of being standardized is like nothing.", "tokens": [50414, 4453, 924, 295, 885, 31677, 307, 411, 1825, 13, 50664], "temperature": 0.0, "avg_logprob": -0.26260682600962965, "compression_ratio": 1.4504950495049505, "no_speech_prob": 0.023078208789229393}, {"id": 215, "seek": 147992, "start": 1485.92, "end": 1490.92, "text": " TCP is like for 30 years already.", "tokens": [50664, 48965, 307, 411, 337, 2217, 924, 1217, 13, 50914], "temperature": 0.0, "avg_logprob": -0.26260682600962965, "compression_ratio": 1.4504950495049505, "no_speech_prob": 0.023078208789229393}, {"id": 216, "seek": 147992, "start": 1490.92, "end": 1495.92, "text": " Last question, I see a lot of people coming in and for sure Manu will be available outside, no?", "tokens": [50914, 5264, 1168, 11, 286, 536, 257, 688, 295, 561, 1348, 294, 293, 337, 988, 2458, 84, 486, 312, 2435, 2380, 11, 572, 30, 51164], "temperature": 0.0, "avg_logprob": -0.26260682600962965, "compression_ratio": 1.4504950495049505, "no_speech_prob": 0.023078208789229393}, {"id": 217, "seek": 147992, "start": 1495.92, "end": 1496.92, "text": " Yes.", "tokens": [51164, 1079, 13, 51214], "temperature": 0.0, "avg_logprob": -0.26260682600962965, "compression_ratio": 1.4504950495049505, "no_speech_prob": 0.023078208789229393}, {"id": 218, "seek": 147992, "start": 1496.92, "end": 1498.92, "text": " Making promises is your name.", "tokens": [51214, 14595, 16403, 307, 428, 1315, 13, 51314], "temperature": 0.0, "avg_logprob": -0.26260682600962965, "compression_ratio": 1.4504950495049505, "no_speech_prob": 0.023078208789229393}, {"id": 219, "seek": 147992, "start": 1498.92, "end": 1504.92, "text": " My question is just which congestion control did you implement in Firefox?", "tokens": [51314, 1222, 1168, 307, 445, 597, 40816, 1969, 630, 291, 4445, 294, 46613, 30, 51614], "temperature": 0.0, "avg_logprob": -0.26260682600962965, "compression_ratio": 1.4504950495049505, "no_speech_prob": 0.023078208789229393}, {"id": 220, "seek": 147992, "start": 1504.92, "end": 1505.92, "text": " Yes.", "tokens": [51614, 1079, 13, 51664], "temperature": 0.0, "avg_logprob": -0.26260682600962965, "compression_ratio": 1.4504950495049505, "no_speech_prob": 0.023078208789229393}, {"id": 221, "seek": 150592, "start": 1506.92, "end": 1509.92, "text": " We are using Qubic by default.", "tokens": [50414, 492, 366, 1228, 1249, 836, 299, 538, 7576, 13, 50564], "temperature": 0.0, "avg_logprob": -0.275238831837972, "compression_ratio": 1.323076923076923, "no_speech_prob": 0.006581722293049097}, {"id": 222, "seek": 150592, "start": 1509.92, "end": 1525.92, "text": " We have also implemented new Reno and we are looking also at BBR because this is also exciting for our lack.", "tokens": [50564, 492, 362, 611, 12270, 777, 44404, 293, 321, 366, 1237, 611, 412, 363, 11609, 570, 341, 307, 611, 4670, 337, 527, 5011, 13, 51364], "temperature": 0.0, "avg_logprob": -0.275238831837972, "compression_ratio": 1.323076923076923, "no_speech_prob": 0.006581722293049097}, {"id": 223, "seek": 150592, "start": 1525.92, "end": 1528.92, "text": " It's better for lower latencies.", "tokens": [51364, 467, 311, 1101, 337, 3126, 4465, 6464, 13, 51514], "temperature": 0.0, "avg_logprob": -0.275238831837972, "compression_ratio": 1.323076923076923, "no_speech_prob": 0.006581722293049097}, {"id": 224, "seek": 152892, "start": 1529.92, "end": 1538.92, "text": " We didn't have a plan to implement it right now but it's like in the future we probably will tackle that too.", "tokens": [50414, 492, 994, 380, 362, 257, 1393, 281, 4445, 309, 558, 586, 457, 309, 311, 411, 294, 264, 2027, 321, 1391, 486, 14896, 300, 886, 13, 50864], "temperature": 0.0, "avg_logprob": -0.17271342770806675, "compression_ratio": 1.3935483870967742, "no_speech_prob": 0.045396171510219574}, {"id": 225, "seek": 152892, "start": 1538.92, "end": 1540.92, "text": " Thank you so much Manu.", "tokens": [50864, 1044, 291, 370, 709, 2458, 84, 13, 50964], "temperature": 0.0, "avg_logprob": -0.17271342770806675, "compression_ratio": 1.3935483870967742, "no_speech_prob": 0.045396171510219574}, {"id": 226, "seek": 152892, "start": 1548.92, "end": 1553.92, "text": " I didn't count some of them but I took photos and we can count at different rates.", "tokens": [51364, 286, 994, 380, 1207, 512, 295, 552, 457, 286, 1890, 5787, 293, 321, 393, 1207, 412, 819, 6846, 13, 51614], "temperature": 0.0, "avg_logprob": -0.17271342770806675, "compression_ratio": 1.3935483870967742, "no_speech_prob": 0.045396171510219574}, {"id": 227, "seek": 155892, "start": 1559.92, "end": 1565.92, "text": " I saw the sticker you have on your water bottle.", "tokens": [50414, 286, 1866, 264, 20400, 291, 362, 322, 428, 1281, 7817, 13, 50714], "temperature": 0.0, "avg_logprob": -0.25271113838736464, "compression_ratio": 2.173469387755102, "no_speech_prob": 0.38069596886634827}, {"id": 228, "seek": 155892, "start": 1565.92, "end": 1566.92, "text": " Yalazila.", "tokens": [50714, 398, 304, 921, 7371, 13, 50764], "temperature": 0.0, "avg_logprob": -0.25271113838736464, "compression_ratio": 2.173469387755102, "no_speech_prob": 0.38069596886634827}, {"id": 229, "seek": 155892, "start": 1566.92, "end": 1567.92, "text": " Yalazila.", "tokens": [50764, 398, 304, 921, 7371, 13, 50814], "temperature": 0.0, "avg_logprob": -0.25271113838736464, "compression_ratio": 2.173469387755102, "no_speech_prob": 0.38069596886634827}, {"id": 230, "seek": 155892, "start": 1567.92, "end": 1568.92, "text": " Yalazila.", "tokens": [50814, 398, 304, 921, 7371, 13, 50864], "temperature": 0.0, "avg_logprob": -0.25271113838736464, "compression_ratio": 2.173469387755102, "no_speech_prob": 0.38069596886634827}, {"id": 231, "seek": 155892, "start": 1568.92, "end": 1569.92, "text": " Yalazila.", "tokens": [50864, 398, 304, 921, 7371, 13, 50914], "temperature": 0.0, "avg_logprob": -0.25271113838736464, "compression_ratio": 2.173469387755102, "no_speech_prob": 0.38069596886634827}, {"id": 232, "seek": 155892, "start": 1569.92, "end": 1570.92, "text": " Yalazila.", "tokens": [50914, 398, 304, 921, 7371, 13, 50964], "temperature": 0.0, "avg_logprob": -0.25271113838736464, "compression_ratio": 2.173469387755102, "no_speech_prob": 0.38069596886634827}, {"id": 233, "seek": 155892, "start": 1570.92, "end": 1571.92, "text": " Yalazila.", "tokens": [50964, 398, 304, 921, 7371, 13, 51014], "temperature": 0.0, "avg_logprob": -0.25271113838736464, "compression_ratio": 2.173469387755102, "no_speech_prob": 0.38069596886634827}, {"id": 234, "seek": 155892, "start": 1571.92, "end": 1572.92, "text": " Yalazila.", "tokens": [51014, 398, 304, 921, 7371, 13, 51064], "temperature": 0.0, "avg_logprob": -0.25271113838736464, "compression_ratio": 2.173469387755102, "no_speech_prob": 0.38069596886634827}, {"id": 235, "seek": 155892, "start": 1572.92, "end": 1574.92, "text": " And I think also this is a no?", "tokens": [51064, 400, 286, 519, 611, 341, 307, 257, 572, 30, 51164], "temperature": 0.0, "avg_logprob": -0.25271113838736464, "compression_ratio": 2.173469387755102, "no_speech_prob": 0.38069596886634827}, {"id": 236, "seek": 155892, "start": 1574.92, "end": 1575.92, "text": " Yes.", "tokens": [51164, 1079, 13, 51214], "temperature": 0.0, "avg_logprob": -0.25271113838736464, "compression_ratio": 2.173469387755102, "no_speech_prob": 0.38069596886634827}, {"id": 237, "seek": 155892, "start": 1575.92, "end": 1576.92, "text": " No.", "tokens": [51214, 883, 13, 51264], "temperature": 0.0, "avg_logprob": -0.25271113838736464, "compression_ratio": 2.173469387755102, "no_speech_prob": 0.38069596886634827}, {"id": 238, "seek": 155892, "start": 1576.92, "end": 1577.92, "text": " Yes.", "tokens": [51264, 1079, 13, 51314], "temperature": 0.0, "avg_logprob": -0.25271113838736464, "compression_ratio": 2.173469387755102, "no_speech_prob": 0.38069596886634827}, {"id": 239, "seek": 155892, "start": 1577.92, "end": 1578.92, "text": " Yes.", "tokens": [51314, 1079, 13, 51364], "temperature": 0.0, "avg_logprob": -0.25271113838736464, "compression_ratio": 2.173469387755102, "no_speech_prob": 0.38069596886634827}, {"id": 240, "seek": 155892, "start": 1578.92, "end": 1579.92, "text": " Yes.", "tokens": [51364, 1079, 13, 51414], "temperature": 0.0, "avg_logprob": -0.25271113838736464, "compression_ratio": 2.173469387755102, "no_speech_prob": 0.38069596886634827}, {"id": 241, "seek": 155892, "start": 1579.92, "end": 1580.92, "text": " Yes.", "tokens": [51414, 1079, 13, 51464], "temperature": 0.0, "avg_logprob": -0.25271113838736464, "compression_ratio": 2.173469387755102, "no_speech_prob": 0.38069596886634827}, {"id": 242, "seek": 155892, "start": 1580.92, "end": 1581.92, "text": " Yes.", "tokens": [51464, 1079, 13, 51514], "temperature": 0.0, "avg_logprob": -0.25271113838736464, "compression_ratio": 2.173469387755102, "no_speech_prob": 0.38069596886634827}, {"id": 243, "seek": 155892, "start": 1581.92, "end": 1582.92, "text": " Yes.", "tokens": [51514, 1079, 13, 51564], "temperature": 0.0, "avg_logprob": -0.25271113838736464, "compression_ratio": 2.173469387755102, "no_speech_prob": 0.38069596886634827}, {"id": 244, "seek": 155892, "start": 1582.92, "end": 1583.92, "text": " Yes.", "tokens": [51564, 1079, 13, 51614], "temperature": 0.0, "avg_logprob": -0.25271113838736464, "compression_ratio": 2.173469387755102, "no_speech_prob": 0.38069596886634827}, {"id": 245, "seek": 155892, "start": 1583.92, "end": 1584.92, "text": " Yes.", "tokens": [51614, 1079, 13, 51664], "temperature": 0.0, "avg_logprob": -0.25271113838736464, "compression_ratio": 2.173469387755102, "no_speech_prob": 0.38069596886634827}, {"id": 246, "seek": 155892, "start": 1584.92, "end": 1585.92, "text": " Yes.", "tokens": [51664, 1079, 13, 51714], "temperature": 0.0, "avg_logprob": -0.25271113838736464, "compression_ratio": 2.173469387755102, "no_speech_prob": 0.38069596886634827}, {"id": 247, "seek": 155892, "start": 1585.92, "end": 1586.92, "text": " Yes.", "tokens": [51714, 1079, 13, 51764], "temperature": 0.0, "avg_logprob": -0.25271113838736464, "compression_ratio": 2.173469387755102, "no_speech_prob": 0.38069596886634827}, {"id": 248, "seek": 155892, "start": 1586.92, "end": 1587.92, "text": " Yes.", "tokens": [51764, 1079, 13, 51814], "temperature": 0.0, "avg_logprob": -0.25271113838736464, "compression_ratio": 2.173469387755102, "no_speech_prob": 0.38069596886634827}, {"id": 249, "seek": 158792, "start": 1587.92, "end": 1588.92, "text": " Yes.", "tokens": [50364, 1079, 13, 50414], "temperature": 1.0, "avg_logprob": -0.3717215611384465, "compression_ratio": 3.2, "no_speech_prob": 0.5881730914115906}, {"id": 250, "seek": 158792, "start": 1588.92, "end": 1589.92, "text": " Yes.", "tokens": [50414, 1079, 13, 50464], "temperature": 1.0, "avg_logprob": -0.3717215611384465, "compression_ratio": 3.2, "no_speech_prob": 0.5881730914115906}, {"id": 251, "seek": 158792, "start": 1589.92, "end": 1590.92, "text": " Yes.", "tokens": [50464, 1079, 13, 50514], "temperature": 1.0, "avg_logprob": -0.3717215611384465, "compression_ratio": 3.2, "no_speech_prob": 0.5881730914115906}, {"id": 252, "seek": 158792, "start": 1590.92, "end": 1591.92, "text": " Yes.", "tokens": [50514, 1079, 13, 50564], "temperature": 1.0, "avg_logprob": -0.3717215611384465, "compression_ratio": 3.2, "no_speech_prob": 0.5881730914115906}, {"id": 253, "seek": 158792, "start": 1591.92, "end": 1592.92, "text": " Yes.", "tokens": [50564, 1079, 13, 50614], "temperature": 1.0, "avg_logprob": -0.3717215611384465, "compression_ratio": 3.2, "no_speech_prob": 0.5881730914115906}, {"id": 254, "seek": 158792, "start": 1600.92, "end": 1601.92, "text": " Yes.", "tokens": [51014, 1079, 13, 51064], "temperature": 1.0, "avg_logprob": -0.3717215611384465, "compression_ratio": 3.2, "no_speech_prob": 0.5881730914115906}, {"id": 255, "seek": 158792, "start": 1601.92, "end": 1602.92, "text": " Yes.", "tokens": [51064, 1079, 13, 51114], "temperature": 1.0, "avg_logprob": -0.3717215611384465, "compression_ratio": 3.2, "no_speech_prob": 0.5881730914115906}, {"id": 256, "seek": 158792, "start": 1602.92, "end": 1603.92, "text": " Yes.", "tokens": [51114, 1079, 13, 51164], "temperature": 1.0, "avg_logprob": -0.3717215611384465, "compression_ratio": 3.2, "no_speech_prob": 0.5881730914115906}, {"id": 257, "seek": 158792, "start": 1603.92, "end": 1604.92, "text": " Yes.", "tokens": [51164, 1079, 13, 51214], "temperature": 1.0, "avg_logprob": -0.3717215611384465, "compression_ratio": 3.2, "no_speech_prob": 0.5881730914115906}, {"id": 258, "seek": 158792, "start": 1604.92, "end": 1605.92, "text": " Yes.", "tokens": [51214, 1079, 13, 51264], "temperature": 1.0, "avg_logprob": -0.3717215611384465, "compression_ratio": 3.2, "no_speech_prob": 0.5881730914115906}, {"id": 259, "seek": 158792, "start": 1605.92, "end": 1606.92, "text": " Yes, yes.", "tokens": [51264, 1079, 11, 2086, 13, 51314], "temperature": 1.0, "avg_logprob": -0.3717215611384465, "compression_ratio": 3.2, "no_speech_prob": 0.5881730914115906}, {"id": 260, "seek": 158792, "start": 1606.92, "end": 1607.92, "text": " Yes.", "tokens": [51314, 1079, 13, 51364], "temperature": 1.0, "avg_logprob": -0.3717215611384465, "compression_ratio": 3.2, "no_speech_prob": 0.5881730914115906}, {"id": 261, "seek": 160792, "start": 1607.92, "end": 1610.92, "text": " This is all about the politics.", "tokens": [50364, 639, 307, 439, 466, 264, 7341, 13, 50514], "temperature": 0.0, "avg_logprob": -0.8167412912743723, "compression_ratio": 1.6047619047619048, "no_speech_prob": 0.7810250520706177}, {"id": 262, "seek": 160792, "start": 1610.92, "end": 1612.92, "text": " I'd say about the politics.", "tokens": [50514, 286, 1116, 584, 466, 264, 7341, 13, 50614], "temperature": 0.0, "avg_logprob": -0.8167412912743723, "compression_ratio": 1.6047619047619048, "no_speech_prob": 0.7810250520706177}, {"id": 263, "seek": 160792, "start": 1612.92, "end": 1614.92, "text": " Call me to be disturbed.", "tokens": [50614, 7807, 385, 281, 312, 30558, 13, 50714], "temperature": 0.0, "avg_logprob": -0.8167412912743723, "compression_ratio": 1.6047619047619048, "no_speech_prob": 0.7810250520706177}, {"id": 264, "seek": 160792, "start": 1614.92, "end": 1616.92, "text": " I'd like to work with you.", "tokens": [50714, 286, 1116, 411, 281, 589, 365, 291, 13, 50814], "temperature": 0.0, "avg_logprob": -0.8167412912743723, "compression_ratio": 1.6047619047619048, "no_speech_prob": 0.7810250520706177}, {"id": 265, "seek": 160792, "start": 1616.92, "end": 1618.92, "text": " Yeah, except...", "tokens": [50814, 865, 11, 3993, 485, 50914], "temperature": 0.0, "avg_logprob": -0.8167412912743723, "compression_ratio": 1.6047619047619048, "no_speech_prob": 0.7810250520706177}, {"id": 266, "seek": 160792, "start": 1618.92, "end": 1621.92, "text": " I used to... my mother told me how to...", "tokens": [50914, 286, 1143, 281, 485, 452, 2895, 1907, 385, 577, 281, 485, 51064], "temperature": 0.0, "avg_logprob": -0.8167412912743723, "compression_ratio": 1.6047619047619048, "no_speech_prob": 0.7810250520706177}, {"id": 267, "seek": 160792, "start": 1621.92, "end": 1624.92, "text": " You know, like when they had to mess up with this.", "tokens": [51064, 509, 458, 11, 411, 562, 436, 632, 281, 2082, 493, 365, 341, 13, 51214], "temperature": 0.0, "avg_logprob": -0.8167412912743723, "compression_ratio": 1.6047619047619048, "no_speech_prob": 0.7810250520706177}, {"id": 268, "seek": 160792, "start": 1624.92, "end": 1627.92, "text": " Yeah, I mean, it's funny when we're not having a discussion.", "tokens": [51214, 865, 11, 286, 914, 11, 309, 311, 4074, 562, 321, 434, 406, 1419, 257, 5017, 13, 51364], "temperature": 0.0, "avg_logprob": -0.8167412912743723, "compression_ratio": 1.6047619047619048, "no_speech_prob": 0.7810250520706177}, {"id": 269, "seek": 160792, "start": 1627.92, "end": 1629.92, "text": " Do you think there's a few...", "tokens": [51364, 1144, 291, 519, 456, 311, 257, 1326, 485, 51464], "temperature": 0.0, "avg_logprob": -0.8167412912743723, "compression_ratio": 1.6047619047619048, "no_speech_prob": 0.7810250520706177}, {"id": 270, "seek": 160792, "start": 1629.92, "end": 1631.92, "text": " ...sci-fi sites?", "tokens": [51464, 1097, 82, 537, 12, 13325, 7533, 30, 51564], "temperature": 0.0, "avg_logprob": -0.8167412912743723, "compression_ratio": 1.6047619047619048, "no_speech_prob": 0.7810250520706177}, {"id": 271, "seek": 160792, "start": 1631.92, "end": 1633.92, "text": " No.", "tokens": [51564, 883, 13, 51664], "temperature": 0.0, "avg_logprob": -0.8167412912743723, "compression_ratio": 1.6047619047619048, "no_speech_prob": 0.7810250520706177}, {"id": 272, "seek": 160792, "start": 1633.92, "end": 1635.92, "text": " Yeah.", "tokens": [51664, 865, 13, 51764], "temperature": 0.0, "avg_logprob": -0.8167412912743723, "compression_ratio": 1.6047619047619048, "no_speech_prob": 0.7810250520706177}, {"id": 273, "seek": 163592, "start": 1635.92, "end": 1637.92, "text": " I don't know about that.", "tokens": [50364, 286, 500, 380, 458, 466, 300, 13, 50464], "temperature": 0.0, "avg_logprob": -0.5464395609768954, "compression_ratio": 1.1704545454545454, "no_speech_prob": 0.06400918960571289}, {"id": 274, "seek": 163592, "start": 1637.92, "end": 1639.92, "text": " Sorry, it was on.", "tokens": [50464, 4919, 11, 309, 390, 322, 13, 50564], "temperature": 0.0, "avg_logprob": -0.5464395609768954, "compression_ratio": 1.1704545454545454, "no_speech_prob": 0.06400918960571289}, {"id": 275, "seek": 163592, "start": 1639.92, "end": 1641.92, "text": " Yeah.", "tokens": [50564, 865, 13, 50664], "temperature": 0.0, "avg_logprob": -0.5464395609768954, "compression_ratio": 1.1704545454545454, "no_speech_prob": 0.06400918960571289}, {"id": 276, "seek": 163592, "start": 1641.92, "end": 1643.92, "text": " Yeah.", "tokens": [50664, 865, 13, 50764], "temperature": 0.0, "avg_logprob": -0.5464395609768954, "compression_ratio": 1.1704545454545454, "no_speech_prob": 0.06400918960571289}, {"id": 277, "seek": 163592, "start": 1643.92, "end": 1645.92, "text": " Yes.", "tokens": [50764, 1079, 13, 50864], "temperature": 0.0, "avg_logprob": -0.5464395609768954, "compression_ratio": 1.1704545454545454, "no_speech_prob": 0.06400918960571289}, {"id": 278, "seek": 163592, "start": 1659.92, "end": 1662.92, "text": " You're stuck with me for two minutes or so.", "tokens": [51564, 509, 434, 5541, 365, 385, 337, 732, 2077, 420, 370, 13, 51714], "temperature": 0.0, "avg_logprob": -0.5464395609768954, "compression_ratio": 1.1704545454545454, "no_speech_prob": 0.06400918960571289}, {"id": 279, "seek": 166292, "start": 1662.92, "end": 1666.92, "text": " Carmen needs another adapter and we are looking over it.", "tokens": [50364, 35778, 2203, 1071, 22860, 293, 321, 366, 1237, 670, 309, 13, 50564], "temperature": 0.0, "avg_logprob": -0.1318244437376658, "compression_ratio": 1.4688995215311005, "no_speech_prob": 0.29099932312965393}, {"id": 280, "seek": 166292, "start": 1666.92, "end": 1668.92, "text": " It's coming.", "tokens": [50564, 467, 311, 1348, 13, 50664], "temperature": 0.0, "avg_logprob": -0.1318244437376658, "compression_ratio": 1.4688995215311005, "no_speech_prob": 0.29099932312965393}, {"id": 281, "seek": 166292, "start": 1668.92, "end": 1670.92, "text": " We're fixing everything.", "tokens": [50664, 492, 434, 19442, 1203, 13, 50764], "temperature": 0.0, "avg_logprob": -0.1318244437376658, "compression_ratio": 1.4688995215311005, "no_speech_prob": 0.29099932312965393}, {"id": 282, "seek": 166292, "start": 1674.92, "end": 1679.92, "text": " Is anyone that already got the t-shirt from the booth or the collapsible mug?", "tokens": [50964, 1119, 2878, 300, 1217, 658, 264, 256, 12, 15313, 490, 264, 20912, 420, 264, 16567, 964, 23610, 30, 51214], "temperature": 0.0, "avg_logprob": -0.1318244437376658, "compression_ratio": 1.4688995215311005, "no_speech_prob": 0.29099932312965393}, {"id": 283, "seek": 166292, "start": 1679.92, "end": 1681.92, "text": " Oh, good.", "tokens": [51214, 876, 11, 665, 13, 51314], "temperature": 0.0, "avg_logprob": -0.1318244437376658, "compression_ratio": 1.4688995215311005, "no_speech_prob": 0.29099932312965393}, {"id": 284, "seek": 166292, "start": 1681.92, "end": 1683.92, "text": " You're saving the world.", "tokens": [51314, 509, 434, 6816, 264, 1002, 13, 51414], "temperature": 0.0, "avg_logprob": -0.1318244437376658, "compression_ratio": 1.4688995215311005, "no_speech_prob": 0.29099932312965393}, {"id": 285, "seek": 166292, "start": 1683.92, "end": 1685.92, "text": " I'm there for it.", "tokens": [51414, 286, 478, 456, 337, 309, 13, 51514], "temperature": 0.0, "avg_logprob": -0.1318244437376658, "compression_ratio": 1.4688995215311005, "no_speech_prob": 0.29099932312965393}, {"id": 286, "seek": 166292, "start": 1685.92, "end": 1687.92, "text": " I also like it.", "tokens": [51514, 286, 611, 411, 309, 13, 51614], "temperature": 0.0, "avg_logprob": -0.1318244437376658, "compression_ratio": 1.4688995215311005, "no_speech_prob": 0.29099932312965393}, {"id": 287, "seek": 166292, "start": 1687.92, "end": 1689.92, "text": " Someone else is doing steps today.", "tokens": [51614, 8734, 1646, 307, 884, 4439, 965, 13, 51714], "temperature": 0.0, "avg_logprob": -0.1318244437376658, "compression_ratio": 1.4688995215311005, "no_speech_prob": 0.29099932312965393}, {"id": 288, "seek": 166292, "start": 1689.92, "end": 1691.92, "text": " This is how you stay in shape.", "tokens": [51714, 639, 307, 577, 291, 1754, 294, 3909, 13, 51814], "temperature": 0.0, "avg_logprob": -0.1318244437376658, "compression_ratio": 1.4688995215311005, "no_speech_prob": 0.29099932312965393}, {"id": 289, "seek": 169192, "start": 1691.92, "end": 1693.92, "text": " You moderate the dev room, you run.", "tokens": [50364, 509, 18174, 264, 1905, 1808, 11, 291, 1190, 13, 50464], "temperature": 0.0, "avg_logprob": -0.15258014613184437, "compression_ratio": 1.6132075471698113, "no_speech_prob": 0.06496453285217285}, {"id": 290, "seek": 169192, "start": 1693.92, "end": 1695.92, "text": " All good.", "tokens": [50464, 1057, 665, 13, 50564], "temperature": 0.0, "avg_logprob": -0.15258014613184437, "compression_ratio": 1.6132075471698113, "no_speech_prob": 0.06496453285217285}, {"id": 291, "seek": 169192, "start": 1695.92, "end": 1697.92, "text": " We are first.", "tokens": [50564, 492, 366, 700, 13, 50664], "temperature": 0.0, "avg_logprob": -0.15258014613184437, "compression_ratio": 1.6132075471698113, "no_speech_prob": 0.06496453285217285}, {"id": 292, "seek": 169192, "start": 1697.92, "end": 1699.92, "text": " Also a big thank you to Konstantina.", "tokens": [50664, 2743, 257, 955, 1309, 291, 281, 44200, 394, 1426, 13, 50764], "temperature": 0.0, "avg_logprob": -0.15258014613184437, "compression_ratio": 1.6132075471698113, "no_speech_prob": 0.06496453285217285}, {"id": 293, "seek": 169192, "start": 1699.92, "end": 1701.92, "text": " She organized the booth, by the way.", "tokens": [50764, 1240, 9983, 264, 20912, 11, 538, 264, 636, 13, 50864], "temperature": 0.0, "avg_logprob": -0.15258014613184437, "compression_ratio": 1.6132075471698113, "no_speech_prob": 0.06496453285217285}, {"id": 294, "seek": 169192, "start": 1701.92, "end": 1703.92, "text": " Konstantina and Mozilla, if you want to...", "tokens": [50864, 44200, 394, 1426, 293, 3335, 26403, 11, 498, 291, 528, 281, 485, 50964], "temperature": 0.0, "avg_logprob": -0.15258014613184437, "compression_ratio": 1.6132075471698113, "no_speech_prob": 0.06496453285217285}, {"id": 295, "seek": 169192, "start": 1703.92, "end": 1705.92, "text": " Yes.", "tokens": [50964, 1079, 13, 51064], "temperature": 0.0, "avg_logprob": -0.15258014613184437, "compression_ratio": 1.6132075471698113, "no_speech_prob": 0.06496453285217285}, {"id": 296, "seek": 169192, "start": 1705.92, "end": 1707.92, "text": " Yes.", "tokens": [51064, 1079, 13, 51164], "temperature": 0.0, "avg_logprob": -0.15258014613184437, "compression_ratio": 1.6132075471698113, "no_speech_prob": 0.06496453285217285}, {"id": 297, "seek": 169192, "start": 1707.92, "end": 1709.92, "text": " Do you want to?", "tokens": [51164, 1144, 291, 528, 281, 30, 51264], "temperature": 0.0, "avg_logprob": -0.15258014613184437, "compression_ratio": 1.6132075471698113, "no_speech_prob": 0.06496453285217285}, {"id": 298, "seek": 169192, "start": 1709.92, "end": 1711.92, "text": " She brought more stickers here,", "tokens": [51264, 1240, 3038, 544, 21019, 510, 11, 51364], "temperature": 0.0, "avg_logprob": -0.15258014613184437, "compression_ratio": 1.6132075471698113, "no_speech_prob": 0.06496453285217285}, {"id": 299, "seek": 169192, "start": 1711.92, "end": 1713.92, "text": " especially this stock is related to MDN.", "tokens": [51364, 2318, 341, 4127, 307, 4077, 281, 22521, 45, 13, 51464], "temperature": 0.0, "avg_logprob": -0.15258014613184437, "compression_ratio": 1.6132075471698113, "no_speech_prob": 0.06496453285217285}, {"id": 300, "seek": 169192, "start": 1713.92, "end": 1715.92, "text": " We have the sticker here, if you want.", "tokens": [51464, 492, 362, 264, 20400, 510, 11, 498, 291, 528, 13, 51564], "temperature": 0.0, "avg_logprob": -0.15258014613184437, "compression_ratio": 1.6132075471698113, "no_speech_prob": 0.06496453285217285}, {"id": 301, "seek": 169192, "start": 1715.92, "end": 1717.92, "text": " And we have the cute llama.", "tokens": [51564, 400, 321, 362, 264, 4052, 23272, 13, 51664], "temperature": 0.0, "avg_logprob": -0.15258014613184437, "compression_ratio": 1.6132075471698113, "no_speech_prob": 0.06496453285217285}, {"id": 302, "seek": 171792, "start": 1717.92, "end": 1719.92, "text": " I heard it.", "tokens": [50364, 286, 2198, 309, 13, 50464], "temperature": 0.0, "avg_logprob": -0.1339714638540678, "compression_ratio": 1.5432692307692308, "no_speech_prob": 0.03990233317017555}, {"id": 303, "seek": 171792, "start": 1719.92, "end": 1721.92, "text": " Gold.", "tokens": [50464, 6731, 13, 50564], "temperature": 0.0, "avg_logprob": -0.1339714638540678, "compression_ratio": 1.5432692307692308, "no_speech_prob": 0.03990233317017555}, {"id": 304, "seek": 171792, "start": 1721.92, "end": 1723.92, "text": " It's here, waiting.", "tokens": [50564, 467, 311, 510, 11, 3806, 13, 50664], "temperature": 0.0, "avg_logprob": -0.1339714638540678, "compression_ratio": 1.5432692307692308, "no_speech_prob": 0.03990233317017555}, {"id": 305, "seek": 171792, "start": 1723.92, "end": 1725.92, "text": " One is mine.", "tokens": [50664, 1485, 307, 3892, 13, 50764], "temperature": 0.0, "avg_logprob": -0.1339714638540678, "compression_ratio": 1.5432692307692308, "no_speech_prob": 0.03990233317017555}, {"id": 306, "seek": 171792, "start": 1725.92, "end": 1727.92, "text": " And if you want to learn more about", "tokens": [50764, 400, 498, 291, 528, 281, 1466, 544, 466, 50864], "temperature": 0.0, "avg_logprob": -0.1339714638540678, "compression_ratio": 1.5432692307692308, "no_speech_prob": 0.03990233317017555}, {"id": 307, "seek": 171792, "start": 1727.92, "end": 1729.92, "text": " llama, the project, not the animal,", "tokens": [50864, 23272, 11, 264, 1716, 11, 406, 264, 5496, 11, 50964], "temperature": 0.0, "avg_logprob": -0.1339714638540678, "compression_ratio": 1.5432692307692308, "no_speech_prob": 0.03990233317017555}, {"id": 308, "seek": 171792, "start": 1729.92, "end": 1731.92, "text": " we have a guide here", "tokens": [50964, 321, 362, 257, 5934, 510, 51064], "temperature": 0.0, "avg_logprob": -0.1339714638540678, "compression_ratio": 1.5432692307692308, "no_speech_prob": 0.03990233317017555}, {"id": 309, "seek": 171792, "start": 1731.92, "end": 1733.92, "text": " with all things related to Mozilla and AI.", "tokens": [51064, 365, 439, 721, 4077, 281, 3335, 26403, 293, 7318, 13, 51164], "temperature": 0.0, "avg_logprob": -0.1339714638540678, "compression_ratio": 1.5432692307692308, "no_speech_prob": 0.03990233317017555}, {"id": 310, "seek": 171792, "start": 1733.92, "end": 1735.92, "text": " Grab the...", "tokens": [51164, 20357, 264, 485, 51264], "temperature": 0.0, "avg_logprob": -0.1339714638540678, "compression_ratio": 1.5432692307692308, "no_speech_prob": 0.03990233317017555}, {"id": 311, "seek": 171792, "start": 1735.92, "end": 1737.92, "text": " And the first one is from the first talk", "tokens": [51264, 400, 264, 700, 472, 307, 490, 264, 700, 751, 51364], "temperature": 0.0, "avg_logprob": -0.1339714638540678, "compression_ratio": 1.5432692307692308, "no_speech_prob": 0.03990233317017555}, {"id": 312, "seek": 171792, "start": 1737.92, "end": 1739.92, "text": " about support.", "tokens": [51364, 466, 1406, 13, 51464], "temperature": 0.0, "avg_logprob": -0.1339714638540678, "compression_ratio": 1.5432692307692308, "no_speech_prob": 0.03990233317017555}, {"id": 313, "seek": 171792, "start": 1739.92, "end": 1741.92, "text": " Grab these papers", "tokens": [51464, 20357, 613, 10577, 51564], "temperature": 0.0, "avg_logprob": -0.1339714638540678, "compression_ratio": 1.5432692307692308, "no_speech_prob": 0.03990233317017555}, {"id": 314, "seek": 171792, "start": 1741.92, "end": 1743.92, "text": " and you can have more information.", "tokens": [51564, 293, 291, 393, 362, 544, 1589, 13, 51664], "temperature": 0.0, "avg_logprob": -0.1339714638540678, "compression_ratio": 1.5432692307692308, "no_speech_prob": 0.03990233317017555}, {"id": 315, "seek": 171792, "start": 1743.92, "end": 1745.92, "text": " Are we ready?", "tokens": [51664, 2014, 321, 1919, 30, 51764], "temperature": 0.0, "avg_logprob": -0.1339714638540678, "compression_ratio": 1.5432692307692308, "no_speech_prob": 0.03990233317017555}, {"id": 316, "seek": 174592, "start": 1745.92, "end": 1747.92, "text": " Let me go then.", "tokens": [50364, 961, 385, 352, 550, 13, 50464], "temperature": 0.0, "avg_logprob": -0.14040251645174892, "compression_ratio": 1.482608695652174, "no_speech_prob": 0.17665065824985504}, {"id": 317, "seek": 174592, "start": 1747.92, "end": 1749.92, "text": " Without further ado, ladies and gentlemen,", "tokens": [50464, 9129, 3052, 22450, 11, 9974, 293, 11669, 11, 50564], "temperature": 0.0, "avg_logprob": -0.14040251645174892, "compression_ratio": 1.482608695652174, "no_speech_prob": 0.17665065824985504}, {"id": 318, "seek": 174592, "start": 1749.92, "end": 1751.92, "text": " Chris will", "tokens": [50564, 6688, 486, 50664], "temperature": 0.0, "avg_logprob": -0.14040251645174892, "compression_ratio": 1.482608695652174, "no_speech_prob": 0.17665065824985504}, {"id": 319, "seek": 174592, "start": 1751.92, "end": 1753.92, "text": " introduce us to the MDN curriculum.", "tokens": [50664, 5366, 505, 281, 264, 22521, 45, 14302, 13, 50764], "temperature": 0.0, "avg_logprob": -0.14040251645174892, "compression_ratio": 1.482608695652174, "no_speech_prob": 0.17665065824985504}, {"id": 320, "seek": 174592, "start": 1753.92, "end": 1755.92, "text": " Yay!", "tokens": [50764, 13268, 0, 50864], "temperature": 0.0, "avg_logprob": -0.14040251645174892, "compression_ratio": 1.482608695652174, "no_speech_prob": 0.17665065824985504}, {"id": 321, "seek": 174592, "start": 1755.92, "end": 1757.92, "text": " Hi.", "tokens": [50864, 2421, 13, 50964], "temperature": 0.0, "avg_logprob": -0.14040251645174892, "compression_ratio": 1.482608695652174, "no_speech_prob": 0.17665065824985504}, {"id": 322, "seek": 174592, "start": 1757.92, "end": 1759.92, "text": " APPLAUSE", "tokens": [50964, 35298, 51064], "temperature": 0.0, "avg_logprob": -0.14040251645174892, "compression_ratio": 1.482608695652174, "no_speech_prob": 0.17665065824985504}, {"id": 323, "seek": 174592, "start": 1759.92, "end": 1761.92, "text": " So, hello everyone.", "tokens": [51064, 407, 11, 7751, 1518, 13, 51164], "temperature": 0.0, "avg_logprob": -0.14040251645174892, "compression_ratio": 1.482608695652174, "no_speech_prob": 0.17665065824985504}, {"id": 324, "seek": 174592, "start": 1761.92, "end": 1763.92, "text": " Nice to see you all.", "tokens": [51164, 5490, 281, 536, 291, 439, 13, 51264], "temperature": 0.0, "avg_logprob": -0.14040251645174892, "compression_ratio": 1.482608695652174, "no_speech_prob": 0.17665065824985504}, {"id": 325, "seek": 174592, "start": 1763.92, "end": 1765.92, "text": " Thanks for coming.", "tokens": [51264, 2561, 337, 1348, 13, 51364], "temperature": 0.0, "avg_logprob": -0.14040251645174892, "compression_ratio": 1.482608695652174, "no_speech_prob": 0.17665065824985504}, {"id": 326, "seek": 174592, "start": 1765.92, "end": 1767.92, "text": " My name is Chris Mills and I'm going to take you through", "tokens": [51364, 1222, 1315, 307, 6688, 44277, 293, 286, 478, 516, 281, 747, 291, 807, 51464], "temperature": 0.0, "avg_logprob": -0.14040251645174892, "compression_ratio": 1.482608695652174, "no_speech_prob": 0.17665065824985504}, {"id": 327, "seek": 174592, "start": 1767.92, "end": 1769.92, "text": " a new MDN project", "tokens": [51464, 257, 777, 22521, 45, 1716, 51564], "temperature": 0.0, "avg_logprob": -0.14040251645174892, "compression_ratio": 1.482608695652174, "no_speech_prob": 0.17665065824985504}, {"id": 328, "seek": 174592, "start": 1769.92, "end": 1771.92, "text": " soon to be released called the MDN Curriculum.", "tokens": [51564, 2321, 281, 312, 4736, 1219, 264, 22521, 45, 7907, 1341, 11560, 13, 51664], "temperature": 0.0, "avg_logprob": -0.14040251645174892, "compression_ratio": 1.482608695652174, "no_speech_prob": 0.17665065824985504}, {"id": 329, "seek": 174592, "start": 1771.92, "end": 1773.92, "text": " Take you through a little bit about", "tokens": [51664, 3664, 291, 807, 257, 707, 857, 466, 51764], "temperature": 0.0, "avg_logprob": -0.14040251645174892, "compression_ratio": 1.482608695652174, "no_speech_prob": 0.17665065824985504}, {"id": 330, "seek": 177392, "start": 1773.92, "end": 1775.92, "text": " who I am to begin with.", "tokens": [50364, 567, 286, 669, 281, 1841, 365, 13, 50464], "temperature": 0.0, "avg_logprob": -0.06830304997567913, "compression_ratio": 1.6811023622047243, "no_speech_prob": 0.012838035821914673}, {"id": 331, "seek": 177392, "start": 1775.92, "end": 1777.92, "text": " I describe myself", "tokens": [50464, 286, 6786, 2059, 50564], "temperature": 0.0, "avg_logprob": -0.06830304997567913, "compression_ratio": 1.6811023622047243, "no_speech_prob": 0.012838035821914673}, {"id": 332, "seek": 177392, "start": 1777.92, "end": 1779.92, "text": " as a death metal hippie.", "tokens": [50564, 382, 257, 2966, 5760, 27745, 414, 13, 50664], "temperature": 0.0, "avg_logprob": -0.06830304997567913, "compression_ratio": 1.6811023622047243, "no_speech_prob": 0.012838035821914673}, {"id": 333, "seek": 177392, "start": 1779.92, "end": 1781.92, "text": " I love documentation", "tokens": [50664, 286, 959, 14333, 50764], "temperature": 0.0, "avg_logprob": -0.06830304997567913, "compression_ratio": 1.6811023622047243, "no_speech_prob": 0.012838035821914673}, {"id": 334, "seek": 177392, "start": 1781.92, "end": 1783.92, "text": " and I love the open web", "tokens": [50764, 293, 286, 959, 264, 1269, 3670, 50864], "temperature": 0.0, "avg_logprob": -0.06830304997567913, "compression_ratio": 1.6811023622047243, "no_speech_prob": 0.012838035821914673}, {"id": 335, "seek": 177392, "start": 1783.92, "end": 1785.92, "text": " and I love tinkering with open standards.", "tokens": [50864, 293, 286, 959, 256, 475, 1794, 365, 1269, 7787, 13, 50964], "temperature": 0.0, "avg_logprob": -0.06830304997567913, "compression_ratio": 1.6811023622047243, "no_speech_prob": 0.012838035821914673}, {"id": 336, "seek": 177392, "start": 1785.92, "end": 1787.92, "text": " I used to work for Mozilla.", "tokens": [50964, 286, 1143, 281, 589, 337, 3335, 26403, 13, 51064], "temperature": 0.0, "avg_logprob": -0.06830304997567913, "compression_ratio": 1.6811023622047243, "no_speech_prob": 0.012838035821914673}, {"id": 337, "seek": 177392, "start": 1787.92, "end": 1789.92, "text": " For quite a while I was the content lead", "tokens": [51064, 1171, 1596, 257, 1339, 286, 390, 264, 2701, 1477, 51164], "temperature": 0.0, "avg_logprob": -0.06830304997567913, "compression_ratio": 1.6811023622047243, "no_speech_prob": 0.012838035821914673}, {"id": 338, "seek": 177392, "start": 1789.92, "end": 1791.92, "text": " and team manager for MDN.", "tokens": [51164, 293, 1469, 6598, 337, 22521, 45, 13, 51264], "temperature": 0.0, "avg_logprob": -0.06830304997567913, "compression_ratio": 1.6811023622047243, "no_speech_prob": 0.012838035821914673}, {"id": 339, "seek": 177392, "start": 1791.92, "end": 1793.92, "text": " But I left", "tokens": [51264, 583, 286, 1411, 51364], "temperature": 0.0, "avg_logprob": -0.06830304997567913, "compression_ratio": 1.6811023622047243, "no_speech_prob": 0.012838035821914673}, {"id": 340, "seek": 177392, "start": 1793.92, "end": 1795.92, "text": " and did some other stuff and now I've come back", "tokens": [51364, 293, 630, 512, 661, 1507, 293, 586, 286, 600, 808, 646, 51464], "temperature": 0.0, "avg_logprob": -0.06830304997567913, "compression_ratio": 1.6811023622047243, "no_speech_prob": 0.012838035821914673}, {"id": 341, "seek": 177392, "start": 1795.92, "end": 1797.92, "text": " as a contractor and this is the current thing", "tokens": [51464, 382, 257, 26463, 293, 341, 307, 264, 2190, 551, 51564], "temperature": 0.0, "avg_logprob": -0.06830304997567913, "compression_ratio": 1.6811023622047243, "no_speech_prob": 0.012838035821914673}, {"id": 342, "seek": 177392, "start": 1797.92, "end": 1799.92, "text": " that I've been working on with the MDN team.", "tokens": [51564, 300, 286, 600, 668, 1364, 322, 365, 264, 22521, 45, 1469, 13, 51664], "temperature": 0.0, "avg_logprob": -0.06830304997567913, "compression_ratio": 1.6811023622047243, "no_speech_prob": 0.012838035821914673}, {"id": 343, "seek": 177392, "start": 1799.92, "end": 1801.92, "text": " Another thing to add is that", "tokens": [51664, 3996, 551, 281, 909, 307, 300, 51764], "temperature": 0.0, "avg_logprob": -0.06830304997567913, "compression_ratio": 1.6811023622047243, "no_speech_prob": 0.012838035821914673}, {"id": 344, "seek": 180192, "start": 1801.92, "end": 1803.92, "text": " I'm a heavy metal drummer", "tokens": [50364, 286, 478, 257, 4676, 5760, 38535, 50464], "temperature": 0.0, "avg_logprob": -0.09504599841135852, "compression_ratio": 1.52, "no_speech_prob": 0.0014158000703901052}, {"id": 345, "seek": 180192, "start": 1803.92, "end": 1805.92, "text": " so if you want to ask me a question later on", "tokens": [50464, 370, 498, 291, 528, 281, 1029, 385, 257, 1168, 1780, 322, 50564], "temperature": 0.0, "avg_logprob": -0.09504599841135852, "compression_ratio": 1.52, "no_speech_prob": 0.0014158000703901052}, {"id": 346, "seek": 180192, "start": 1805.92, "end": 1807.92, "text": " please speak slowly.", "tokens": [50564, 1767, 1710, 5692, 13, 50664], "temperature": 0.0, "avg_logprob": -0.09504599841135852, "compression_ratio": 1.52, "no_speech_prob": 0.0014158000703901052}, {"id": 347, "seek": 180192, "start": 1811.92, "end": 1813.92, "text": " A little bit about this talk.", "tokens": [50864, 316, 707, 857, 466, 341, 751, 13, 50964], "temperature": 0.0, "avg_logprob": -0.09504599841135852, "compression_ratio": 1.52, "no_speech_prob": 0.0014158000703901052}, {"id": 348, "seek": 180192, "start": 1813.92, "end": 1815.92, "text": " We are going to talk about, first of all,", "tokens": [50964, 492, 366, 516, 281, 751, 466, 11, 700, 295, 439, 11, 51064], "temperature": 0.0, "avg_logprob": -0.09504599841135852, "compression_ratio": 1.52, "no_speech_prob": 0.0014158000703901052}, {"id": 349, "seek": 180192, "start": 1815.92, "end": 1817.92, "text": " some of the problems that myself and I", "tokens": [51064, 512, 295, 264, 2740, 300, 2059, 293, 286, 51164], "temperature": 0.0, "avg_logprob": -0.09504599841135852, "compression_ratio": 1.52, "no_speech_prob": 0.0014158000703901052}, {"id": 350, "seek": 180192, "start": 1817.92, "end": 1819.92, "text": " was perceived with Frontend Development", "tokens": [51164, 390, 19049, 365, 17348, 521, 15041, 51264], "temperature": 0.0, "avg_logprob": -0.09504599841135852, "compression_ratio": 1.52, "no_speech_prob": 0.0014158000703901052}, {"id": 351, "seek": 180192, "start": 1819.92, "end": 1821.92, "text": " in 2024, particularly", "tokens": [51264, 294, 45237, 11, 4098, 51364], "temperature": 0.0, "avg_logprob": -0.09504599841135852, "compression_ratio": 1.52, "no_speech_prob": 0.0014158000703901052}, {"id": 352, "seek": 180192, "start": 1821.92, "end": 1823.92, "text": " in terms of education", "tokens": [51364, 294, 2115, 295, 3309, 51464], "temperature": 0.0, "avg_logprob": -0.09504599841135852, "compression_ratio": 1.52, "no_speech_prob": 0.0014158000703901052}, {"id": 353, "seek": 180192, "start": 1823.92, "end": 1825.92, "text": " and the skills that new web developers", "tokens": [51464, 293, 264, 3942, 300, 777, 3670, 8849, 51564], "temperature": 0.0, "avg_logprob": -0.09504599841135852, "compression_ratio": 1.52, "no_speech_prob": 0.0014158000703901052}, {"id": 354, "seek": 180192, "start": 1825.92, "end": 1827.92, "text": " are bringing to the table when they come", "tokens": [51564, 366, 5062, 281, 264, 3199, 562, 436, 808, 51664], "temperature": 0.0, "avg_logprob": -0.09504599841135852, "compression_ratio": 1.52, "no_speech_prob": 0.0014158000703901052}, {"id": 355, "seek": 180192, "start": 1827.92, "end": 1829.92, "text": " and get jobs.", "tokens": [51664, 293, 483, 4782, 13, 51764], "temperature": 0.0, "avg_logprob": -0.09504599841135852, "compression_ratio": 1.52, "no_speech_prob": 0.0014158000703901052}, {"id": 356, "seek": 182992, "start": 1829.92, "end": 1831.92, "text": " I'm going to take you through the thoughts", "tokens": [50364, 286, 478, 516, 281, 747, 291, 807, 264, 4598, 50464], "temperature": 0.0, "avg_logprob": -0.11472283977351777, "compression_ratio": 1.9381818181818182, "no_speech_prob": 0.013828347437083721}, {"id": 357, "seek": 182992, "start": 1831.92, "end": 1833.92, "text": " of how a curriculum,", "tokens": [50464, 295, 577, 257, 14302, 11, 50564], "temperature": 0.0, "avg_logprob": -0.11472283977351777, "compression_ratio": 1.9381818181818182, "no_speech_prob": 0.013828347437083721}, {"id": 358, "seek": 182992, "start": 1833.92, "end": 1835.92, "text": " a new curriculum could solve some of these problems", "tokens": [50564, 257, 777, 14302, 727, 5039, 512, 295, 613, 2740, 50664], "temperature": 0.0, "avg_logprob": -0.11472283977351777, "compression_ratio": 1.9381818181818182, "no_speech_prob": 0.013828347437083721}, {"id": 359, "seek": 182992, "start": 1835.92, "end": 1837.92, "text": " and some of the research that we did", "tokens": [50664, 293, 512, 295, 264, 2132, 300, 321, 630, 50764], "temperature": 0.0, "avg_logprob": -0.11472283977351777, "compression_ratio": 1.9381818181818182, "no_speech_prob": 0.013828347437083721}, {"id": 360, "seek": 182992, "start": 1837.92, "end": 1839.92, "text": " to try and prove out some of our theories about this.", "tokens": [50764, 281, 853, 293, 7081, 484, 512, 295, 527, 13667, 466, 341, 13, 50864], "temperature": 0.0, "avg_logprob": -0.11472283977351777, "compression_ratio": 1.9381818181818182, "no_speech_prob": 0.013828347437083721}, {"id": 361, "seek": 182992, "start": 1841.92, "end": 1843.92, "text": " I'll then talk to you a little bit about the actual curriculum", "tokens": [50964, 286, 603, 550, 751, 281, 291, 257, 707, 857, 466, 264, 3539, 14302, 51064], "temperature": 0.0, "avg_logprob": -0.11472283977351777, "compression_ratio": 1.9381818181818182, "no_speech_prob": 0.013828347437083721}, {"id": 362, "seek": 182992, "start": 1843.92, "end": 1845.92, "text": " that we came up with and kind of its structure,", "tokens": [51064, 300, 321, 1361, 493, 365, 293, 733, 295, 1080, 3877, 11, 51164], "temperature": 0.0, "avg_logprob": -0.11472283977351777, "compression_ratio": 1.9381818181818182, "no_speech_prob": 0.013828347437083721}, {"id": 363, "seek": 182992, "start": 1845.92, "end": 1847.92, "text": " its approach, some of its goals", "tokens": [51164, 1080, 3109, 11, 512, 295, 1080, 5493, 51264], "temperature": 0.0, "avg_logprob": -0.11472283977351777, "compression_ratio": 1.9381818181818182, "no_speech_prob": 0.013828347437083721}, {"id": 364, "seek": 182992, "start": 1847.92, "end": 1849.92, "text": " and then I'll talk to you about possible next steps,", "tokens": [51264, 293, 550, 286, 603, 751, 281, 291, 466, 1944, 958, 4439, 11, 51364], "temperature": 0.0, "avg_logprob": -0.11472283977351777, "compression_ratio": 1.9381818181818182, "no_speech_prob": 0.013828347437083721}, {"id": 365, "seek": 182992, "start": 1849.92, "end": 1851.92, "text": " some of the things that we can then go on to do", "tokens": [51364, 512, 295, 264, 721, 300, 321, 393, 550, 352, 322, 281, 360, 51464], "temperature": 0.0, "avg_logprob": -0.11472283977351777, "compression_ratio": 1.9381818181818182, "no_speech_prob": 0.013828347437083721}, {"id": 366, "seek": 182992, "start": 1851.92, "end": 1853.92, "text": " with this curriculum as a basis.", "tokens": [51464, 365, 341, 14302, 382, 257, 5143, 13, 51564], "temperature": 0.0, "avg_logprob": -0.11472283977351777, "compression_ratio": 1.9381818181818182, "no_speech_prob": 0.013828347437083721}, {"id": 367, "seek": 182992, "start": 1855.92, "end": 1857.92, "text": " Now, first of all, I'm going to talk to us about,", "tokens": [51664, 823, 11, 700, 295, 439, 11, 286, 478, 516, 281, 751, 281, 505, 466, 11, 51764], "temperature": 0.0, "avg_logprob": -0.11472283977351777, "compression_ratio": 1.9381818181818182, "no_speech_prob": 0.013828347437083721}, {"id": 368, "seek": 185792, "start": 1857.92, "end": 1859.92, "text": " talk to you about something that we're very good at", "tokens": [50364, 751, 281, 291, 466, 746, 300, 321, 434, 588, 665, 412, 50464], "temperature": 0.0, "avg_logprob": -0.13267367943785244, "compression_ratio": 1.6736842105263159, "no_speech_prob": 0.006969486828893423}, {"id": 369, "seek": 185792, "start": 1859.92, "end": 1861.92, "text": " in open source communities,", "tokens": [50464, 294, 1269, 4009, 4456, 11, 50564], "temperature": 0.0, "avg_logprob": -0.13267367943785244, "compression_ratio": 1.6736842105263159, "no_speech_prob": 0.006969486828893423}, {"id": 370, "seek": 185792, "start": 1861.92, "end": 1863.92, "text": " problems and complaining.", "tokens": [50564, 2740, 293, 20740, 13, 50664], "temperature": 0.0, "avg_logprob": -0.13267367943785244, "compression_ratio": 1.6736842105263159, "no_speech_prob": 0.006969486828893423}, {"id": 371, "seek": 185792, "start": 1863.92, "end": 1865.92, "text": " Yay, Mr. Brexits, back in the UK government,", "tokens": [50664, 13268, 11, 2221, 13, 7090, 87, 1208, 11, 646, 294, 264, 7051, 2463, 11, 50764], "temperature": 0.0, "avg_logprob": -0.13267367943785244, "compression_ratio": 1.6736842105263159, "no_speech_prob": 0.006969486828893423}, {"id": 372, "seek": 185792, "start": 1865.92, "end": 1867.92, "text": " I'm so pleased.", "tokens": [50764, 286, 478, 370, 10587, 13, 50864], "temperature": 0.0, "avg_logprob": -0.13267367943785244, "compression_ratio": 1.6736842105263159, "no_speech_prob": 0.006969486828893423}, {"id": 373, "seek": 185792, "start": 1867.92, "end": 1869.92, "text": " No, not those kind of problems.", "tokens": [50864, 883, 11, 406, 729, 733, 295, 2740, 13, 50964], "temperature": 0.0, "avg_logprob": -0.13267367943785244, "compression_ratio": 1.6736842105263159, "no_speech_prob": 0.006969486828893423}, {"id": 374, "seek": 185792, "start": 1871.92, "end": 1873.92, "text": " Really, we're talking about problems with Frontend Development,", "tokens": [51064, 4083, 11, 321, 434, 1417, 466, 2740, 365, 17348, 521, 15041, 11, 51164], "temperature": 0.0, "avg_logprob": -0.13267367943785244, "compression_ratio": 1.6736842105263159, "no_speech_prob": 0.006969486828893423}, {"id": 375, "seek": 185792, "start": 1873.92, "end": 1875.92, "text": " kind of what skills are", "tokens": [51164, 733, 295, 437, 3942, 366, 51264], "temperature": 0.0, "avg_logprob": -0.13267367943785244, "compression_ratio": 1.6736842105263159, "no_speech_prob": 0.006969486828893423}, {"id": 376, "seek": 185792, "start": 1875.92, "end": 1877.92, "text": " new web developers missing when they come", "tokens": [51264, 777, 3670, 8849, 5361, 562, 436, 808, 51364], "temperature": 0.0, "avg_logprob": -0.13267367943785244, "compression_ratio": 1.6736842105263159, "no_speech_prob": 0.006969486828893423}, {"id": 377, "seek": 185792, "start": 1877.92, "end": 1879.92, "text": " into the industry? What's the effect of web,", "tokens": [51364, 666, 264, 3518, 30, 708, 311, 264, 1802, 295, 3670, 11, 51464], "temperature": 0.0, "avg_logprob": -0.13267367943785244, "compression_ratio": 1.6736842105263159, "no_speech_prob": 0.006969486828893423}, {"id": 378, "seek": 185792, "start": 1879.92, "end": 1881.92, "text": " what's the state of web education,", "tokens": [51464, 437, 311, 264, 1785, 295, 3670, 3309, 11, 51564], "temperature": 0.0, "avg_logprob": -0.13267367943785244, "compression_ratio": 1.6736842105263159, "no_speech_prob": 0.006969486828893423}, {"id": 379, "seek": 185792, "start": 1881.92, "end": 1883.92, "text": " what kind of effects are these problems", "tokens": [51564, 437, 733, 295, 5065, 366, 613, 2740, 51664], "temperature": 0.0, "avg_logprob": -0.13267367943785244, "compression_ratio": 1.6736842105263159, "no_speech_prob": 0.006969486828893423}, {"id": 380, "seek": 185792, "start": 1883.92, "end": 1885.92, "text": " having on, you know, the web", "tokens": [51664, 1419, 322, 11, 291, 458, 11, 264, 3670, 51764], "temperature": 0.0, "avg_logprob": -0.13267367943785244, "compression_ratio": 1.6736842105263159, "no_speech_prob": 0.006969486828893423}, {"id": 381, "seek": 188592, "start": 1885.92, "end": 1887.92, "text": " in general and the quality of sites that we build?", "tokens": [50364, 294, 2674, 293, 264, 3125, 295, 7533, 300, 321, 1322, 30, 50464], "temperature": 0.0, "avg_logprob": -0.12293660720722788, "compression_ratio": 1.8576271186440678, "no_speech_prob": 0.0011197502026334405}, {"id": 382, "seek": 188592, "start": 1889.92, "end": 1891.92, "text": " One thing that", "tokens": [50564, 1485, 551, 300, 50664], "temperature": 0.0, "avg_logprob": -0.12293660720722788, "compression_ratio": 1.8576271186440678, "no_speech_prob": 0.0011197502026334405}, {"id": 383, "seek": 188592, "start": 1891.92, "end": 1893.92, "text": " I've talked to quite a lot of hiring managers", "tokens": [50664, 286, 600, 2825, 281, 1596, 257, 688, 295, 15335, 14084, 50764], "temperature": 0.0, "avg_logprob": -0.12293660720722788, "compression_ratio": 1.8576271186440678, "no_speech_prob": 0.0011197502026334405}, {"id": 384, "seek": 188592, "start": 1893.92, "end": 1895.92, "text": " about, and this will also", "tokens": [50764, 466, 11, 293, 341, 486, 611, 50864], "temperature": 0.0, "avg_logprob": -0.12293660720722788, "compression_ratio": 1.8576271186440678, "no_speech_prob": 0.0011197502026334405}, {"id": 385, "seek": 188592, "start": 1895.92, "end": 1897.92, "text": " be mentioned in the research that I'll talk about later,", "tokens": [50864, 312, 2835, 294, 264, 2132, 300, 286, 603, 751, 466, 1780, 11, 50964], "temperature": 0.0, "avg_logprob": -0.12293660720722788, "compression_ratio": 1.8576271186440678, "no_speech_prob": 0.0011197502026334405}, {"id": 386, "seek": 188592, "start": 1897.92, "end": 1899.92, "text": " is just lack of general core", "tokens": [50964, 307, 445, 5011, 295, 2674, 4965, 51064], "temperature": 0.0, "avg_logprob": -0.12293660720722788, "compression_ratio": 1.8576271186440678, "no_speech_prob": 0.0011197502026334405}, {"id": 387, "seek": 188592, "start": 1899.92, "end": 1901.92, "text": " principles of new developers coming into the industry.", "tokens": [51064, 9156, 295, 777, 8849, 1348, 666, 264, 3518, 13, 51164], "temperature": 0.0, "avg_logprob": -0.12293660720722788, "compression_ratio": 1.8576271186440678, "no_speech_prob": 0.0011197502026334405}, {"id": 388, "seek": 188592, "start": 1901.92, "end": 1903.92, "text": " I mean, a short anecdote that I'll share with you", "tokens": [51164, 286, 914, 11, 257, 2099, 49845, 300, 286, 603, 2073, 365, 291, 51264], "temperature": 0.0, "avg_logprob": -0.12293660720722788, "compression_ratio": 1.8576271186440678, "no_speech_prob": 0.0011197502026334405}, {"id": 389, "seek": 188592, "start": 1903.92, "end": 1905.92, "text": " is a couple of years ago,", "tokens": [51264, 307, 257, 1916, 295, 924, 2057, 11, 51364], "temperature": 0.0, "avg_logprob": -0.12293660720722788, "compression_ratio": 1.8576271186440678, "no_speech_prob": 0.0011197502026334405}, {"id": 390, "seek": 188592, "start": 1905.92, "end": 1907.92, "text": " a friend of mine called me into his company,", "tokens": [51364, 257, 1277, 295, 3892, 1219, 385, 666, 702, 2237, 11, 51464], "temperature": 0.0, "avg_logprob": -0.12293660720722788, "compression_ratio": 1.8576271186440678, "no_speech_prob": 0.0011197502026334405}, {"id": 391, "seek": 188592, "start": 1907.92, "end": 1909.92, "text": " he worked for a large agency at the time", "tokens": [51464, 415, 2732, 337, 257, 2416, 7934, 412, 264, 565, 51564], "temperature": 0.0, "avg_logprob": -0.12293660720722788, "compression_ratio": 1.8576271186440678, "no_speech_prob": 0.0011197502026334405}, {"id": 392, "seek": 188592, "start": 1909.92, "end": 1911.92, "text": " and he wanted me to talk to all of his Frontend teams", "tokens": [51564, 293, 415, 1415, 385, 281, 751, 281, 439, 295, 702, 17348, 521, 5491, 51664], "temperature": 0.0, "avg_logprob": -0.12293660720722788, "compression_ratio": 1.8576271186440678, "no_speech_prob": 0.0011197502026334405}, {"id": 393, "seek": 188592, "start": 1911.92, "end": 1913.92, "text": " and he wanted me to talk to all of his Frontend teams", "tokens": [51664, 293, 415, 1415, 385, 281, 751, 281, 439, 295, 702, 17348, 521, 5491, 51764], "temperature": 0.0, "avg_logprob": -0.12293660720722788, "compression_ratio": 1.8576271186440678, "no_speech_prob": 0.0011197502026334405}, {"id": 394, "seek": 191392, "start": 1913.92, "end": 1915.92, "text": " about accessibility.", "tokens": [50364, 466, 15002, 13, 50464], "temperature": 0.0, "avg_logprob": -0.08225299595119236, "compression_ratio": 1.7107142857142856, "no_speech_prob": 0.01080081332474947}, {"id": 395, "seek": 191392, "start": 1915.92, "end": 1917.92, "text": " Really basic accessibility, you know,", "tokens": [50464, 4083, 3875, 15002, 11, 291, 458, 11, 50564], "temperature": 0.0, "avg_logprob": -0.08225299595119236, "compression_ratio": 1.7107142857142856, "no_speech_prob": 0.01080081332474947}, {"id": 396, "seek": 191392, "start": 1917.92, "end": 1919.92, "text": " just kind of use headings and paragraphs", "tokens": [50564, 445, 733, 295, 764, 1378, 1109, 293, 48910, 50664], "temperature": 0.0, "avg_logprob": -0.08225299595119236, "compression_ratio": 1.7107142857142856, "no_speech_prob": 0.01080081332474947}, {"id": 397, "seek": 191392, "start": 1919.92, "end": 1921.92, "text": " and use alt text, that kind of stuff.", "tokens": [50664, 293, 764, 4955, 2487, 11, 300, 733, 295, 1507, 13, 50764], "temperature": 0.0, "avg_logprob": -0.08225299595119236, "compression_ratio": 1.7107142857142856, "no_speech_prob": 0.01080081332474947}, {"id": 398, "seek": 191392, "start": 1921.92, "end": 1923.92, "text": " And I went in there", "tokens": [50764, 400, 286, 1437, 294, 456, 50864], "temperature": 0.0, "avg_logprob": -0.08225299595119236, "compression_ratio": 1.7107142857142856, "no_speech_prob": 0.01080081332474947}, {"id": 399, "seek": 191392, "start": 1923.92, "end": 1925.92, "text": " and did a 20 minute talk", "tokens": [50864, 293, 630, 257, 945, 3456, 751, 50964], "temperature": 0.0, "avg_logprob": -0.08225299595119236, "compression_ratio": 1.7107142857142856, "no_speech_prob": 0.01080081332474947}, {"id": 400, "seek": 191392, "start": 1925.92, "end": 1927.92, "text": " and I was thinking, do I really need to talk", "tokens": [50964, 293, 286, 390, 1953, 11, 360, 286, 534, 643, 281, 751, 51064], "temperature": 0.0, "avg_logprob": -0.08225299595119236, "compression_ratio": 1.7107142857142856, "no_speech_prob": 0.01080081332474947}, {"id": 401, "seek": 191392, "start": 1927.92, "end": 1929.92, "text": " to these folks about this?", "tokens": [51064, 281, 613, 4024, 466, 341, 30, 51164], "temperature": 0.0, "avg_logprob": -0.08225299595119236, "compression_ratio": 1.7107142857142856, "no_speech_prob": 0.01080081332474947}, {"id": 402, "seek": 191392, "start": 1929.92, "end": 1931.92, "text": " And it was like a revelation to them.", "tokens": [51164, 400, 309, 390, 411, 257, 23456, 281, 552, 13, 51264], "temperature": 0.0, "avg_logprob": -0.08225299595119236, "compression_ratio": 1.7107142857142856, "no_speech_prob": 0.01080081332474947}, {"id": 403, "seek": 191392, "start": 1931.92, "end": 1933.92, "text": " They were all like, whoa,", "tokens": [51264, 814, 645, 439, 411, 11, 13310, 11, 51364], "temperature": 0.0, "avg_logprob": -0.08225299595119236, "compression_ratio": 1.7107142857142856, "no_speech_prob": 0.01080081332474947}, {"id": 404, "seek": 191392, "start": 1933.92, "end": 1935.92, "text": " so that's why you have to do this stuff?", "tokens": [51364, 370, 300, 311, 983, 291, 362, 281, 360, 341, 1507, 30, 51464], "temperature": 0.0, "avg_logprob": -0.08225299595119236, "compression_ratio": 1.7107142857142856, "no_speech_prob": 0.01080081332474947}, {"id": 405, "seek": 191392, "start": 1935.92, "end": 1937.92, "text": " I was just blown away. I was like,", "tokens": [51464, 286, 390, 445, 16479, 1314, 13, 286, 390, 411, 11, 51564], "temperature": 0.0, "avg_logprob": -0.08225299595119236, "compression_ratio": 1.7107142857142856, "no_speech_prob": 0.01080081332474947}, {"id": 406, "seek": 191392, "start": 1937.92, "end": 1939.92, "text": " I thought we'd kind of largely won this battle", "tokens": [51564, 286, 1194, 321, 1116, 733, 295, 11611, 1582, 341, 4635, 51664], "temperature": 0.0, "avg_logprob": -0.08225299595119236, "compression_ratio": 1.7107142857142856, "no_speech_prob": 0.01080081332474947}, {"id": 407, "seek": 191392, "start": 1939.92, "end": 1941.92, "text": " and moved on. It kind of blew my mind", "tokens": [51664, 293, 4259, 322, 13, 467, 733, 295, 19075, 452, 1575, 51764], "temperature": 0.0, "avg_logprob": -0.08225299595119236, "compression_ratio": 1.7107142857142856, "no_speech_prob": 0.01080081332474947}, {"id": 408, "seek": 194192, "start": 1941.92, "end": 1943.92, "text": " about how little they knew about this stuff.", "tokens": [50364, 466, 577, 707, 436, 2586, 466, 341, 1507, 13, 50464], "temperature": 0.0, "avg_logprob": -0.08487955052801903, "compression_ratio": 1.7366666666666666, "no_speech_prob": 0.0015450610080733895}, {"id": 409, "seek": 194192, "start": 1943.92, "end": 1945.92, "text": " And I kind of feel that", "tokens": [50464, 400, 286, 733, 295, 841, 300, 50564], "temperature": 0.0, "avg_logprob": -0.08487955052801903, "compression_ratio": 1.7366666666666666, "no_speech_prob": 0.0015450610080733895}, {"id": 410, "seek": 194192, "start": 1945.92, "end": 1947.92, "text": " with a lot of the new developers community industry,", "tokens": [50564, 365, 257, 688, 295, 264, 777, 8849, 1768, 3518, 11, 50664], "temperature": 0.0, "avg_logprob": -0.08487955052801903, "compression_ratio": 1.7366666666666666, "no_speech_prob": 0.0015450610080733895}, {"id": 411, "seek": 194192, "start": 1947.92, "end": 1949.92, "text": " you know, they're not really learning", "tokens": [50664, 291, 458, 11, 436, 434, 406, 534, 2539, 50764], "temperature": 0.0, "avg_logprob": -0.08487955052801903, "compression_ratio": 1.7366666666666666, "no_speech_prob": 0.0015450610080733895}, {"id": 412, "seek": 194192, "start": 1949.92, "end": 1951.92, "text": " core languages and old school standards", "tokens": [50764, 4965, 8650, 293, 1331, 1395, 7787, 50864], "temperature": 0.0, "avg_logprob": -0.08487955052801903, "compression_ratio": 1.7366666666666666, "no_speech_prob": 0.0015450610080733895}, {"id": 413, "seek": 194192, "start": 1951.92, "end": 1953.92, "text": " as much as just kind of, well,", "tokens": [50864, 382, 709, 382, 445, 733, 295, 11, 731, 11, 50964], "temperature": 0.0, "avg_logprob": -0.08487955052801903, "compression_ratio": 1.7366666666666666, "no_speech_prob": 0.0015450610080733895}, {"id": 414, "seek": 194192, "start": 1953.92, "end": 1955.92, "text": " I want to get a job so I'm going to learn React", "tokens": [50964, 286, 528, 281, 483, 257, 1691, 370, 286, 478, 516, 281, 1466, 30644, 51064], "temperature": 0.0, "avg_logprob": -0.08487955052801903, "compression_ratio": 1.7366666666666666, "no_speech_prob": 0.0015450610080733895}, {"id": 415, "seek": 194192, "start": 1955.92, "end": 1957.92, "text": " and I'm not going to turn this into a massive winch,", "tokens": [51064, 293, 286, 478, 406, 516, 281, 1261, 341, 666, 257, 5994, 1942, 339, 11, 51164], "temperature": 0.0, "avg_logprob": -0.08487955052801903, "compression_ratio": 1.7366666666666666, "no_speech_prob": 0.0015450610080733895}, {"id": 416, "seek": 194192, "start": 1957.92, "end": 1959.92, "text": " but you know, that kind of results", "tokens": [51164, 457, 291, 458, 11, 300, 733, 295, 3542, 51264], "temperature": 0.0, "avg_logprob": -0.08487955052801903, "compression_ratio": 1.7366666666666666, "no_speech_prob": 0.0015450610080733895}, {"id": 417, "seek": 194192, "start": 1959.92, "end": 1961.92, "text": " in not knowing these core principles", "tokens": [51264, 294, 406, 5276, 613, 4965, 9156, 51364], "temperature": 0.0, "avg_logprob": -0.08487955052801903, "compression_ratio": 1.7366666666666666, "no_speech_prob": 0.0015450610080733895}, {"id": 418, "seek": 194192, "start": 1961.92, "end": 1963.92, "text": " and best practices quite as well as", "tokens": [51364, 293, 1151, 7525, 1596, 382, 731, 382, 51464], "temperature": 0.0, "avg_logprob": -0.08487955052801903, "compression_ratio": 1.7366666666666666, "no_speech_prob": 0.0015450610080733895}, {"id": 419, "seek": 194192, "start": 1963.92, "end": 1965.92, "text": " perhaps they could.", "tokens": [51464, 4317, 436, 727, 13, 51564], "temperature": 0.0, "avg_logprob": -0.08487955052801903, "compression_ratio": 1.7366666666666666, "no_speech_prob": 0.0015450610080733895}, {"id": 420, "seek": 194192, "start": 1967.92, "end": 1969.92, "text": " The next thing to talk about is lack of core language skills.", "tokens": [51664, 440, 958, 551, 281, 751, 466, 307, 5011, 295, 4965, 2856, 3942, 13, 51764], "temperature": 0.0, "avg_logprob": -0.08487955052801903, "compression_ratio": 1.7366666666666666, "no_speech_prob": 0.0015450610080733895}, {"id": 421, "seek": 196992, "start": 1969.92, "end": 1971.92, "text": " This is another thing that hiring managers", "tokens": [50364, 639, 307, 1071, 551, 300, 15335, 14084, 50464], "temperature": 0.0, "avg_logprob": -0.06816235984243997, "compression_ratio": 1.6704545454545454, "no_speech_prob": 0.013217167928814888}, {"id": 422, "seek": 196992, "start": 1971.92, "end": 1973.92, "text": " have talked to me about a lot.", "tokens": [50464, 362, 2825, 281, 385, 466, 257, 688, 13, 50564], "temperature": 0.0, "avg_logprob": -0.06816235984243997, "compression_ratio": 1.6704545454545454, "no_speech_prob": 0.013217167928814888}, {"id": 423, "seek": 196992, "start": 1973.92, "end": 1975.92, "text": " So people learn React", "tokens": [50564, 407, 561, 1466, 30644, 50664], "temperature": 0.0, "avg_logprob": -0.06816235984243997, "compression_ratio": 1.6704545454545454, "no_speech_prob": 0.013217167928814888}, {"id": 424, "seek": 196992, "start": 1975.92, "end": 1977.92, "text": " and other frameworks,", "tokens": [50664, 293, 661, 29834, 11, 50764], "temperature": 0.0, "avg_logprob": -0.06816235984243997, "compression_ratio": 1.6704545454545454, "no_speech_prob": 0.013217167928814888}, {"id": 425, "seek": 196992, "start": 1977.92, "end": 1979.92, "text": " but they don't maybe take the time", "tokens": [50764, 457, 436, 500, 380, 1310, 747, 264, 565, 50864], "temperature": 0.0, "avg_logprob": -0.06816235984243997, "compression_ratio": 1.6704545454545454, "no_speech_prob": 0.013217167928814888}, {"id": 426, "seek": 196992, "start": 1979.92, "end": 1981.92, "text": " to learn the core JavaScript language", "tokens": [50864, 281, 1466, 264, 4965, 15778, 2856, 50964], "temperature": 0.0, "avg_logprob": -0.06816235984243997, "compression_ratio": 1.6704545454545454, "no_speech_prob": 0.013217167928814888}, {"id": 427, "seek": 196992, "start": 1981.92, "end": 1983.92, "text": " as much as they could. So, you know,", "tokens": [50964, 382, 709, 382, 436, 727, 13, 407, 11, 291, 458, 11, 51064], "temperature": 0.0, "avg_logprob": -0.06816235984243997, "compression_ratio": 1.6704545454545454, "no_speech_prob": 0.013217167928814888}, {"id": 428, "seek": 196992, "start": 1983.92, "end": 1985.92, "text": " they can build", "tokens": [51064, 436, 393, 1322, 51164], "temperature": 0.0, "avg_logprob": -0.06816235984243997, "compression_ratio": 1.6704545454545454, "no_speech_prob": 0.013217167928814888}, {"id": 429, "seek": 196992, "start": 1985.92, "end": 1987.92, "text": " websites that work great and have a good", "tokens": [51164, 12891, 300, 589, 869, 293, 362, 257, 665, 51264], "temperature": 0.0, "avg_logprob": -0.06816235984243997, "compression_ratio": 1.6704545454545454, "no_speech_prob": 0.013217167928814888}, {"id": 430, "seek": 196992, "start": 1987.92, "end": 1989.92, "text": " look in UIs, but maybe", "tokens": [51264, 574, 294, 624, 6802, 11, 457, 1310, 51364], "temperature": 0.0, "avg_logprob": -0.06816235984243997, "compression_ratio": 1.6704545454545454, "no_speech_prob": 0.013217167928814888}, {"id": 431, "seek": 196992, "start": 1989.92, "end": 1991.92, "text": " their problem-solving skills", "tokens": [51364, 641, 1154, 12, 30926, 798, 3942, 51464], "temperature": 0.0, "avg_logprob": -0.06816235984243997, "compression_ratio": 1.6704545454545454, "no_speech_prob": 0.013217167928814888}, {"id": 432, "seek": 196992, "start": 1991.92, "end": 1993.92, "text": " aren't quite as good as", "tokens": [51464, 3212, 380, 1596, 382, 665, 382, 51564], "temperature": 0.0, "avg_logprob": -0.06816235984243997, "compression_ratio": 1.6704545454545454, "no_speech_prob": 0.013217167928814888}, {"id": 433, "seek": 196992, "start": 1993.92, "end": 1995.92, "text": " they could be when they suddenly need to get", "tokens": [51564, 436, 727, 312, 562, 436, 5800, 643, 281, 483, 51664], "temperature": 0.0, "avg_logprob": -0.06816235984243997, "compression_ratio": 1.6704545454545454, "no_speech_prob": 0.013217167928814888}, {"id": 434, "seek": 196992, "start": 1995.92, "end": 1997.92, "text": " brought onto a problem that requires", "tokens": [51664, 3038, 3911, 257, 1154, 300, 7029, 51764], "temperature": 0.0, "avg_logprob": -0.06816235984243997, "compression_ratio": 1.6704545454545454, "no_speech_prob": 0.013217167928814888}, {"id": 435, "seek": 199792, "start": 1997.92, "end": 1999.92, "text": " not writing some code inside a framework.", "tokens": [50364, 406, 3579, 512, 3089, 1854, 257, 8388, 13, 50464], "temperature": 0.0, "avg_logprob": -0.09048266564646075, "compression_ratio": 1.648936170212766, "no_speech_prob": 0.002324021188542247}, {"id": 436, "seek": 199792, "start": 2001.92, "end": 2003.92, "text": " And also, we kind of", "tokens": [50564, 400, 611, 11, 321, 733, 295, 50664], "temperature": 0.0, "avg_logprob": -0.09048266564646075, "compression_ratio": 1.648936170212766, "no_speech_prob": 0.002324021188542247}, {"id": 437, "seek": 199792, "start": 2003.92, "end": 2005.92, "text": " worry that maybe this is not so good", "tokens": [50664, 3292, 300, 1310, 341, 307, 406, 370, 665, 50764], "temperature": 0.0, "avg_logprob": -0.09048266564646075, "compression_ratio": 1.648936170212766, "no_speech_prob": 0.002324021188542247}, {"id": 438, "seek": 199792, "start": 2005.92, "end": 2007.92, "text": " for people's long-term employability,", "tokens": [50764, 337, 561, 311, 938, 12, 7039, 3188, 2310, 11, 50864], "temperature": 0.0, "avg_logprob": -0.09048266564646075, "compression_ratio": 1.648936170212766, "no_speech_prob": 0.002324021188542247}, {"id": 439, "seek": 199792, "start": 2007.92, "end": 2009.92, "text": " because, you know, if they just learn React,", "tokens": [50864, 570, 11, 291, 458, 11, 498, 436, 445, 1466, 30644, 11, 50964], "temperature": 0.0, "avg_logprob": -0.09048266564646075, "compression_ratio": 1.648936170212766, "no_speech_prob": 0.002324021188542247}, {"id": 440, "seek": 199792, "start": 2009.92, "end": 2011.92, "text": " what then happens if all of a sudden", "tokens": [50964, 437, 550, 2314, 498, 439, 295, 257, 3990, 51064], "temperature": 0.0, "avg_logprob": -0.09048266564646075, "compression_ratio": 1.648936170212766, "no_speech_prob": 0.002324021188542247}, {"id": 441, "seek": 199792, "start": 2011.92, "end": 2013.92, "text": " the company goes, well, now we're going to do all of this stuff", "tokens": [51064, 264, 2237, 1709, 11, 731, 11, 586, 321, 434, 516, 281, 360, 439, 295, 341, 1507, 51164], "temperature": 0.0, "avg_logprob": -0.09048266564646075, "compression_ratio": 1.648936170212766, "no_speech_prob": 0.002324021188542247}, {"id": 442, "seek": 199792, "start": 2013.92, "end": 2015.92, "text": " in a different framework, or, you know,", "tokens": [51164, 294, 257, 819, 8388, 11, 420, 11, 291, 458, 11, 51264], "temperature": 0.0, "avg_logprob": -0.09048266564646075, "compression_ratio": 1.648936170212766, "no_speech_prob": 0.002324021188542247}, {"id": 443, "seek": 199792, "start": 2015.92, "end": 2017.92, "text": " another framework suddenly becomes really popular", "tokens": [51264, 1071, 8388, 5800, 3643, 534, 3743, 51364], "temperature": 0.0, "avg_logprob": -0.09048266564646075, "compression_ratio": 1.648936170212766, "no_speech_prob": 0.002324021188542247}, {"id": 444, "seek": 199792, "start": 2017.92, "end": 2019.92, "text": " and every employer wants to use it on their projects.", "tokens": [51364, 293, 633, 16205, 2738, 281, 764, 309, 322, 641, 4455, 13, 51464], "temperature": 0.0, "avg_logprob": -0.09048266564646075, "compression_ratio": 1.648936170212766, "no_speech_prob": 0.002324021188542247}, {"id": 445, "seek": 199792, "start": 2023.92, "end": 2025.92, "text": " This is probably the biggest one that", "tokens": [51664, 639, 307, 1391, 264, 3880, 472, 300, 51764], "temperature": 0.0, "avg_logprob": -0.09048266564646075, "compression_ratio": 1.648936170212766, "no_speech_prob": 0.002324021188542247}, {"id": 446, "seek": 202592, "start": 2025.92, "end": 2027.92, "text": " I've heard from employers is just", "tokens": [50364, 286, 600, 2198, 490, 16744, 307, 445, 50464], "temperature": 0.0, "avg_logprob": -0.06916155777578278, "compression_ratio": 1.7536231884057971, "no_speech_prob": 0.004612245596945286}, {"id": 447, "seek": 202592, "start": 2027.92, "end": 2029.92, "text": " general lack of soft skills from UIs.", "tokens": [50464, 2674, 5011, 295, 2787, 3942, 490, 624, 6802, 13, 50564], "temperature": 0.0, "avg_logprob": -0.06916155777578278, "compression_ratio": 1.7536231884057971, "no_speech_prob": 0.004612245596945286}, {"id": 448, "seek": 202592, "start": 2029.92, "end": 2031.92, "text": " So, and I know,", "tokens": [50564, 407, 11, 293, 286, 458, 11, 50664], "temperature": 0.0, "avg_logprob": -0.06916155777578278, "compression_ratio": 1.7536231884057971, "no_speech_prob": 0.004612245596945286}, {"id": 449, "seek": 202592, "start": 2031.92, "end": 2033.92, "text": " you know, you could make the argument that", "tokens": [50664, 291, 458, 11, 291, 727, 652, 264, 6770, 300, 50764], "temperature": 0.0, "avg_logprob": -0.06916155777578278, "compression_ratio": 1.7536231884057971, "no_speech_prob": 0.004612245596945286}, {"id": 450, "seek": 202592, "start": 2033.92, "end": 2035.92, "text": " this kind of stuff comes of experience,", "tokens": [50764, 341, 733, 295, 1507, 1487, 295, 1752, 11, 50864], "temperature": 0.0, "avg_logprob": -0.06916155777578278, "compression_ratio": 1.7536231884057971, "no_speech_prob": 0.004612245596945286}, {"id": 451, "seek": 202592, "start": 2035.92, "end": 2037.92, "text": " but it really would be great to try and promote", "tokens": [50864, 457, 309, 534, 576, 312, 869, 281, 853, 293, 9773, 50964], "temperature": 0.0, "avg_logprob": -0.06916155777578278, "compression_ratio": 1.7536231884057971, "no_speech_prob": 0.004612245596945286}, {"id": 452, "seek": 202592, "start": 2037.92, "end": 2039.92, "text": " that learners spend more time", "tokens": [50964, 300, 23655, 3496, 544, 565, 51064], "temperature": 0.0, "avg_logprob": -0.06916155777578278, "compression_ratio": 1.7536231884057971, "no_speech_prob": 0.004612245596945286}, {"id": 453, "seek": 202592, "start": 2039.92, "end": 2041.92, "text": " thinking about skills such as research", "tokens": [51064, 1953, 466, 3942, 1270, 382, 2132, 51164], "temperature": 0.0, "avg_logprob": -0.06916155777578278, "compression_ratio": 1.7536231884057971, "no_speech_prob": 0.004612245596945286}, {"id": 454, "seek": 202592, "start": 2041.92, "end": 2043.92, "text": " and kind of", "tokens": [51164, 293, 733, 295, 51264], "temperature": 0.0, "avg_logprob": -0.06916155777578278, "compression_ratio": 1.7536231884057971, "no_speech_prob": 0.004612245596945286}, {"id": 455, "seek": 202592, "start": 2043.92, "end": 2045.92, "text": " basic critical thinking and problem-solving", "tokens": [51264, 3875, 4924, 1953, 293, 1154, 12, 30926, 798, 51364], "temperature": 0.0, "avg_logprob": -0.06916155777578278, "compression_ratio": 1.7536231884057971, "no_speech_prob": 0.004612245596945286}, {"id": 456, "seek": 202592, "start": 2045.92, "end": 2047.92, "text": " and also", "tokens": [51364, 293, 611, 51464], "temperature": 0.0, "avg_logprob": -0.06916155777578278, "compression_ratio": 1.7536231884057971, "no_speech_prob": 0.004612245596945286}, {"id": 457, "seek": 202592, "start": 2047.92, "end": 2049.92, "text": " working on having this constant learning", "tokens": [51464, 1364, 322, 1419, 341, 5754, 2539, 51564], "temperature": 0.0, "avg_logprob": -0.06916155777578278, "compression_ratio": 1.7536231884057971, "no_speech_prob": 0.004612245596945286}, {"id": 458, "seek": 202592, "start": 2049.92, "end": 2051.92, "text": " mindset that you kind of need to have", "tokens": [51564, 12543, 300, 291, 733, 295, 643, 281, 362, 51664], "temperature": 0.0, "avg_logprob": -0.06916155777578278, "compression_ratio": 1.7536231884057971, "no_speech_prob": 0.004612245596945286}, {"id": 459, "seek": 202592, "start": 2051.92, "end": 2053.92, "text": " to succeed in this industry, because things are just", "tokens": [51664, 281, 7754, 294, 341, 3518, 11, 570, 721, 366, 445, 51764], "temperature": 0.0, "avg_logprob": -0.06916155777578278, "compression_ratio": 1.7536231884057971, "no_speech_prob": 0.004612245596945286}, {"id": 460, "seek": 205392, "start": 2053.92, "end": 2055.92, "text": " always changing all the time.", "tokens": [50364, 1009, 4473, 439, 264, 565, 13, 50464], "temperature": 0.0, "avg_logprob": -0.07977778291049069, "compression_ratio": 1.7466666666666666, "no_speech_prob": 0.00358001422137022}, {"id": 461, "seek": 205392, "start": 2059.92, "end": 2061.92, "text": " So, who's to blame for any of these problems?", "tokens": [50664, 407, 11, 567, 311, 281, 10127, 337, 604, 295, 613, 2740, 30, 50764], "temperature": 0.0, "avg_logprob": -0.07977778291049069, "compression_ratio": 1.7466666666666666, "no_speech_prob": 0.00358001422137022}, {"id": 462, "seek": 205392, "start": 2061.92, "end": 2063.92, "text": " Well, not really anybody, I would say.", "tokens": [50764, 1042, 11, 406, 534, 4472, 11, 286, 576, 584, 13, 50864], "temperature": 0.0, "avg_logprob": -0.07977778291049069, "compression_ratio": 1.7466666666666666, "no_speech_prob": 0.00358001422137022}, {"id": 463, "seek": 205392, "start": 2063.92, "end": 2065.92, "text": " I'm not going to point the finger at anyone in particular,", "tokens": [50864, 286, 478, 406, 516, 281, 935, 264, 5984, 412, 2878, 294, 1729, 11, 50964], "temperature": 0.0, "avg_logprob": -0.07977778291049069, "compression_ratio": 1.7466666666666666, "no_speech_prob": 0.00358001422137022}, {"id": 464, "seek": 205392, "start": 2065.92, "end": 2067.92, "text": " because, you know, you've got all of this", "tokens": [50964, 570, 11, 291, 458, 11, 291, 600, 658, 439, 295, 341, 51064], "temperature": 0.0, "avg_logprob": -0.07977778291049069, "compression_ratio": 1.7466666666666666, "no_speech_prob": 0.00358001422137022}, {"id": 465, "seek": 205392, "start": 2067.92, "end": 2069.92, "text": " ideological thinking that says everything", "tokens": [51064, 35341, 1953, 300, 1619, 1203, 51164], "temperature": 0.0, "avg_logprob": -0.07977778291049069, "compression_ratio": 1.7466666666666666, "no_speech_prob": 0.00358001422137022}, {"id": 466, "seek": 205392, "start": 2069.92, "end": 2071.92, "text": " should be accessible all the time, and this should happen,", "tokens": [51164, 820, 312, 9515, 439, 264, 565, 11, 293, 341, 820, 1051, 11, 51264], "temperature": 0.0, "avg_logprob": -0.07977778291049069, "compression_ratio": 1.7466666666666666, "no_speech_prob": 0.00358001422137022}, {"id": 467, "seek": 205392, "start": 2071.92, "end": 2073.92, "text": " and then this should happen. But actually,", "tokens": [51264, 293, 550, 341, 820, 1051, 13, 583, 767, 11, 51364], "temperature": 0.0, "avg_logprob": -0.07977778291049069, "compression_ratio": 1.7466666666666666, "no_speech_prob": 0.00358001422137022}, {"id": 468, "seek": 205392, "start": 2073.92, "end": 2075.92, "text": " people just want to get a job,", "tokens": [51364, 561, 445, 528, 281, 483, 257, 1691, 11, 51464], "temperature": 0.0, "avg_logprob": -0.07977778291049069, "compression_ratio": 1.7466666666666666, "no_speech_prob": 0.00358001422137022}, {"id": 469, "seek": 205392, "start": 2075.92, "end": 2077.92, "text": " so it's no wonder that people go, well,", "tokens": [51464, 370, 309, 311, 572, 2441, 300, 561, 352, 11, 731, 11, 51564], "temperature": 0.0, "avg_logprob": -0.07977778291049069, "compression_ratio": 1.7466666666666666, "no_speech_prob": 0.00358001422137022}, {"id": 470, "seek": 205392, "start": 2077.92, "end": 2079.92, "text": " all of these job adverts are saying,", "tokens": [51564, 439, 295, 613, 1691, 614, 36999, 366, 1566, 11, 51664], "temperature": 0.0, "avg_logprob": -0.07977778291049069, "compression_ratio": 1.7466666666666666, "no_speech_prob": 0.00358001422137022}, {"id": 471, "seek": 205392, "start": 2079.92, "end": 2081.92, "text": " I need to know this framework, so I'm just going to take", "tokens": [51664, 286, 643, 281, 458, 341, 8388, 11, 370, 286, 478, 445, 516, 281, 747, 51764], "temperature": 0.0, "avg_logprob": -0.07977778291049069, "compression_ratio": 1.7466666666666666, "no_speech_prob": 0.00358001422137022}, {"id": 472, "seek": 208192, "start": 2081.92, "end": 2083.92, "text": " the quickest path I can to get employment", "tokens": [50364, 264, 49403, 3100, 286, 393, 281, 483, 11949, 50464], "temperature": 0.0, "avg_logprob": -0.09912340508566962, "compression_ratio": 1.748299319727891, "no_speech_prob": 0.007673177868127823}, {"id": 473, "seek": 208192, "start": 2083.92, "end": 2085.92, "text": " and be able to pay my mortgage and buy food.", "tokens": [50464, 293, 312, 1075, 281, 1689, 452, 20236, 293, 2256, 1755, 13, 50564], "temperature": 0.0, "avg_logprob": -0.09912340508566962, "compression_ratio": 1.748299319727891, "no_speech_prob": 0.007673177868127823}, {"id": 474, "seek": 208192, "start": 2087.92, "end": 2089.92, "text": " Coding boot camps", "tokens": [50664, 383, 8616, 11450, 16573, 50764], "temperature": 0.0, "avg_logprob": -0.09912340508566962, "compression_ratio": 1.748299319727891, "no_speech_prob": 0.007673177868127823}, {"id": 475, "seek": 208192, "start": 2089.92, "end": 2091.92, "text": " that I've reviewed largely tend to focus", "tokens": [50764, 300, 286, 600, 18429, 11611, 3928, 281, 1879, 50864], "temperature": 0.0, "avg_logprob": -0.09912340508566962, "compression_ratio": 1.748299319727891, "no_speech_prob": 0.007673177868127823}, {"id": 476, "seek": 208192, "start": 2091.92, "end": 2093.92, "text": " on this kind of stuff, you know, and again,", "tokens": [50864, 322, 341, 733, 295, 1507, 11, 291, 458, 11, 293, 797, 11, 50964], "temperature": 0.0, "avg_logprob": -0.09912340508566962, "compression_ratio": 1.748299319727891, "no_speech_prob": 0.007673177868127823}, {"id": 477, "seek": 208192, "start": 2093.92, "end": 2095.92, "text": " I'm not blaming them, I'm not saying it's a terrible thing,", "tokens": [50964, 286, 478, 406, 32364, 552, 11, 286, 478, 406, 1566, 309, 311, 257, 6237, 551, 11, 51064], "temperature": 0.0, "avg_logprob": -0.09912340508566962, "compression_ratio": 1.748299319727891, "no_speech_prob": 0.007673177868127823}, {"id": 478, "seek": 208192, "start": 2095.92, "end": 2097.92, "text": " but they tend to be, the", "tokens": [51064, 457, 436, 3928, 281, 312, 11, 264, 51164], "temperature": 0.0, "avg_logprob": -0.09912340508566962, "compression_ratio": 1.748299319727891, "no_speech_prob": 0.007673177868127823}, {"id": 479, "seek": 208192, "start": 2097.92, "end": 2099.92, "text": " attitude tends to be, you know, we will take you", "tokens": [51164, 10157, 12258, 281, 312, 11, 291, 458, 11, 321, 486, 747, 291, 51264], "temperature": 0.0, "avg_logprob": -0.09912340508566962, "compression_ratio": 1.748299319727891, "no_speech_prob": 0.007673177868127823}, {"id": 480, "seek": 208192, "start": 2099.92, "end": 2101.92, "text": " from nothing to getting your first job in three months", "tokens": [51264, 490, 1825, 281, 1242, 428, 700, 1691, 294, 1045, 2493, 51364], "temperature": 0.0, "avg_logprob": -0.09912340508566962, "compression_ratio": 1.748299319727891, "no_speech_prob": 0.007673177868127823}, {"id": 481, "seek": 208192, "start": 2101.92, "end": 2103.92, "text": " or six months or whatever, and that's", "tokens": [51364, 420, 2309, 2493, 420, 2035, 11, 293, 300, 311, 51464], "temperature": 0.0, "avg_logprob": -0.09912340508566962, "compression_ratio": 1.748299319727891, "no_speech_prob": 0.007673177868127823}, {"id": 482, "seek": 208192, "start": 2103.92, "end": 2105.92, "text": " a perfectly reasonable way", "tokens": [51464, 257, 6239, 10585, 636, 51564], "temperature": 0.0, "avg_logprob": -0.09912340508566962, "compression_ratio": 1.748299319727891, "no_speech_prob": 0.007673177868127823}, {"id": 483, "seek": 208192, "start": 2105.92, "end": 2107.92, "text": " to frame what you're offering to people,", "tokens": [51564, 281, 3920, 437, 291, 434, 8745, 281, 561, 11, 51664], "temperature": 0.0, "avg_logprob": -0.09912340508566962, "compression_ratio": 1.748299319727891, "no_speech_prob": 0.007673177868127823}, {"id": 484, "seek": 208192, "start": 2107.92, "end": 2109.92, "text": " but there is the problem that", "tokens": [51664, 457, 456, 307, 264, 1154, 300, 51764], "temperature": 0.0, "avg_logprob": -0.09912340508566962, "compression_ratio": 1.748299319727891, "no_speech_prob": 0.007673177868127823}, {"id": 485, "seek": 210992, "start": 2109.92, "end": 2111.92, "text": " maybe the best practices and the background skills", "tokens": [50364, 1310, 264, 1151, 7525, 293, 264, 3678, 3942, 50464], "temperature": 0.0, "avg_logprob": -0.21255230429946192, "compression_ratio": 1.7884615384615385, "no_speech_prob": 0.0026019441429525614}, {"id": 486, "seek": 210992, "start": 2111.92, "end": 2113.92, "text": " aren't maybe being as taught as well as they could be,", "tokens": [50464, 3212, 380, 1310, 885, 382, 5928, 382, 731, 382, 436, 727, 312, 11, 50564], "temperature": 0.0, "avg_logprob": -0.21255230429946192, "compression_ratio": 1.7884615384615385, "no_speech_prob": 0.0026019441429525614}, {"id": 487, "seek": 210992, "start": 2113.92, "end": 2115.92, "text": " and of course, courses become out of date", "tokens": [50564, 293, 295, 1164, 11, 7712, 1813, 484, 295, 4002, 50664], "temperature": 0.0, "avg_logprob": -0.21255230429946192, "compression_ratio": 1.7884615384615385, "no_speech_prob": 0.0026019441429525614}, {"id": 488, "seek": 210992, "start": 2115.92, "end": 2117.92, "text": " very quickly.", "tokens": [50664, 588, 2661, 13, 50764], "temperature": 0.0, "avg_logprob": -0.21255230429946192, "compression_ratio": 1.7884615384615385, "no_speech_prob": 0.0026019441429525614}, {"id": 489, "seek": 210992, "start": 2117.92, "end": 2119.92, "text": " Particularly, this tends to be a problem", "tokens": [50764, 32281, 11, 341, 12258, 281, 312, 257, 1154, 50864], "temperature": 0.0, "avg_logprob": -0.21255230429946192, "compression_ratio": 1.7884615384615385, "no_speech_prob": 0.0026019441429525614}, {"id": 490, "seek": 210992, "start": 2119.92, "end": 2121.92, "text": " with", "tokens": [50864, 365, 50964], "temperature": 0.0, "avg_logprob": -0.21255230429946192, "compression_ratio": 1.7884615384615385, "no_speech_prob": 0.0026019441429525614}, {"id": 491, "seek": 210992, "start": 2121.92, "end": 2123.92, "text": " university courses that I've come across.", "tokens": [50964, 5454, 7712, 300, 286, 600, 808, 2108, 13, 51064], "temperature": 0.0, "avg_logprob": -0.21255230429946192, "compression_ratio": 1.7884615384615385, "no_speech_prob": 0.0026019441429525614}, {"id": 492, "seek": 210992, "start": 2123.92, "end": 2125.92, "text": " I know a lot of lecturers that really struggle", "tokens": [51064, 286, 458, 257, 688, 295, 5899, 14198, 300, 534, 7799, 51164], "temperature": 0.0, "avg_logprob": -0.21255230429946192, "compression_ratio": 1.7884615384615385, "no_speech_prob": 0.0026019441429525614}, {"id": 493, "seek": 210992, "start": 2125.92, "end": 2127.92, "text": " to kind of keep up with all of the stuff that they've got to do,", "tokens": [51164, 281, 733, 295, 1066, 493, 365, 439, 295, 264, 1507, 300, 436, 600, 658, 281, 360, 11, 51264], "temperature": 0.0, "avg_logprob": -0.21255230429946192, "compression_ratio": 1.7884615384615385, "no_speech_prob": 0.0026019441429525614}, {"id": 494, "seek": 210992, "start": 2127.92, "end": 2129.92, "text": " which isn't just learning about technology,", "tokens": [51264, 597, 1943, 380, 445, 2539, 466, 2899, 11, 51364], "temperature": 0.0, "avg_logprob": -0.21255230429946192, "compression_ratio": 1.7884615384615385, "no_speech_prob": 0.0026019441429525614}, {"id": 495, "seek": 210992, "start": 2129.92, "end": 2131.92, "text": " they struggle to put the time in", "tokens": [51364, 436, 7799, 281, 829, 264, 565, 294, 51464], "temperature": 0.0, "avg_logprob": -0.21255230429946192, "compression_ratio": 1.7884615384615385, "no_speech_prob": 0.0026019441429525614}, {"id": 496, "seek": 210992, "start": 2131.92, "end": 2133.92, "text": " to keep their skill set current", "tokens": [51464, 281, 1066, 641, 5389, 992, 2190, 51564], "temperature": 0.0, "avg_logprob": -0.21255230429946192, "compression_ratio": 1.7884615384615385, "no_speech_prob": 0.0026019441429525614}, {"id": 497, "seek": 210992, "start": 2133.92, "end": 2135.92, "text": " with all of the stuff that's going on in the industry.", "tokens": [51564, 365, 439, 295, 264, 1507, 300, 311, 516, 322, 294, 264, 3518, 13, 51664], "temperature": 0.0, "avg_logprob": -0.21255230429946192, "compression_ratio": 1.7884615384615385, "no_speech_prob": 0.0026019441429525614}, {"id": 498, "seek": 210992, "start": 2135.92, "end": 2137.92, "text": " So, I think that's a good point.", "tokens": [51664, 407, 11, 286, 519, 300, 311, 257, 665, 935, 13, 51764], "temperature": 0.0, "avg_logprob": -0.21255230429946192, "compression_ratio": 1.7884615384615385, "no_speech_prob": 0.0026019441429525614}, {"id": 499, "seek": 213792, "start": 2137.92, "end": 2139.92, "text": " I think that's a good point with all of the stuff that's going on in the industry.", "tokens": [50364, 286, 519, 300, 311, 257, 665, 935, 365, 439, 295, 264, 1507, 300, 311, 516, 322, 294, 264, 3518, 13, 50464], "temperature": 0.0, "avg_logprob": -0.1731102615594864, "compression_ratio": 1.7829457364341086, "no_speech_prob": 0.004452400375157595}, {"id": 500, "seek": 213792, "start": 2141.92, "end": 2143.92, "text": " And then, I'm also going to", "tokens": [50564, 400, 550, 11, 286, 478, 611, 516, 281, 50664], "temperature": 0.0, "avg_logprob": -0.1731102615594864, "compression_ratio": 1.7829457364341086, "no_speech_prob": 0.004452400375157595}, {"id": 501, "seek": 213792, "start": 2143.92, "end": 2145.92, "text": " just say a few things about", "tokens": [50664, 445, 584, 257, 1326, 721, 466, 50764], "temperature": 0.0, "avg_logprob": -0.1731102615594864, "compression_ratio": 1.7829457364341086, "no_speech_prob": 0.004452400375157595}, {"id": 502, "seek": 213792, "start": 2145.92, "end": 2147.92, "text": " interview processes, and again, this definitely isn't", "tokens": [50764, 4049, 7555, 11, 293, 797, 11, 341, 2138, 1943, 380, 50864], "temperature": 0.0, "avg_logprob": -0.1731102615594864, "compression_ratio": 1.7829457364341086, "no_speech_prob": 0.004452400375157595}, {"id": 503, "seek": 213792, "start": 2147.92, "end": 2149.92, "text": " the fault of", "tokens": [50864, 264, 7441, 295, 50964], "temperature": 0.0, "avg_logprob": -0.1731102615594864, "compression_ratio": 1.7829457364341086, "no_speech_prob": 0.004452400375157595}, {"id": 504, "seek": 213792, "start": 2149.92, "end": 2151.92, "text": " the actual learners trying to come into the industry.", "tokens": [50964, 264, 3539, 23655, 1382, 281, 808, 666, 264, 3518, 13, 51064], "temperature": 0.0, "avg_logprob": -0.1731102615594864, "compression_ratio": 1.7829457364341086, "no_speech_prob": 0.004452400375157595}, {"id": 505, "seek": 213792, "start": 2151.92, "end": 2153.92, "text": " But because", "tokens": [51064, 583, 570, 51164], "temperature": 0.0, "avg_logprob": -0.1731102615594864, "compression_ratio": 1.7829457364341086, "no_speech_prob": 0.004452400375157595}, {"id": 506, "seek": 213792, "start": 2153.92, "end": 2155.92, "text": " people don't tend to have a", "tokens": [51164, 561, 500, 380, 3928, 281, 362, 257, 51264], "temperature": 0.0, "avg_logprob": -0.1731102615594864, "compression_ratio": 1.7829457364341086, "no_speech_prob": 0.004452400375157595}, {"id": 507, "seek": 213792, "start": 2155.92, "end": 2157.92, "text": " consistent set of skills,", "tokens": [51264, 8398, 992, 295, 3942, 11, 51364], "temperature": 0.0, "avg_logprob": -0.1731102615594864, "compression_ratio": 1.7829457364341086, "no_speech_prob": 0.004452400375157595}, {"id": 508, "seek": 213792, "start": 2157.92, "end": 2159.92, "text": " a lot of interview processes", "tokens": [51364, 257, 688, 295, 4049, 7555, 51464], "temperature": 0.0, "avg_logprob": -0.1731102615594864, "compression_ratio": 1.7829457364341086, "no_speech_prob": 0.004452400375157595}, {"id": 509, "seek": 213792, "start": 2159.92, "end": 2161.92, "text": " tend to kind of be, well,", "tokens": [51464, 3928, 281, 733, 295, 312, 11, 731, 11, 51564], "temperature": 0.0, "avg_logprob": -0.1731102615594864, "compression_ratio": 1.7829457364341086, "no_speech_prob": 0.004452400375157595}, {"id": 510, "seek": 213792, "start": 2161.92, "end": 2163.92, "text": " we're looking for this kind of unicorn", "tokens": [51564, 321, 434, 1237, 337, 341, 733, 295, 28122, 51664], "temperature": 0.0, "avg_logprob": -0.1731102615594864, "compression_ratio": 1.7829457364341086, "no_speech_prob": 0.004452400375157595}, {"id": 511, "seek": 213792, "start": 2163.92, "end": 2165.92, "text": " that knows these ten things really well,", "tokens": [51664, 300, 3255, 613, 2064, 721, 534, 731, 11, 51764], "temperature": 0.0, "avg_logprob": -0.1731102615594864, "compression_ratio": 1.7829457364341086, "no_speech_prob": 0.004452400375157595}, {"id": 512, "seek": 216592, "start": 2165.92, "end": 2167.92, "text": " that are all really complicated.", "tokens": [50364, 300, 366, 439, 534, 6179, 13, 50464], "temperature": 0.0, "avg_logprob": -0.0858415687171212, "compression_ratio": 1.71, "no_speech_prob": 0.001750319730490446}, {"id": 513, "seek": 216592, "start": 2167.92, "end": 2169.92, "text": " And all of the people that we're talking to have kind of got", "tokens": [50464, 400, 439, 295, 264, 561, 300, 321, 434, 1417, 281, 362, 733, 295, 658, 50564], "temperature": 0.0, "avg_logprob": -0.0858415687171212, "compression_ratio": 1.71, "no_speech_prob": 0.001750319730490446}, {"id": 514, "seek": 216592, "start": 2169.92, "end": 2171.92, "text": " about four of these things definitely", "tokens": [50564, 466, 1451, 295, 613, 721, 2138, 50664], "temperature": 0.0, "avg_logprob": -0.0858415687171212, "compression_ratio": 1.71, "no_speech_prob": 0.001750319730490446}, {"id": 515, "seek": 216592, "start": 2171.92, "end": 2173.92, "text": " shown up on their CV.", "tokens": [50664, 4898, 493, 322, 641, 22995, 13, 50764], "temperature": 0.0, "avg_logprob": -0.0858415687171212, "compression_ratio": 1.71, "no_speech_prob": 0.001750319730490446}, {"id": 516, "seek": 216592, "start": 2173.92, "end": 2175.92, "text": " So, we've got to do a whole bunch of whiteboard interviews", "tokens": [50764, 407, 11, 321, 600, 658, 281, 360, 257, 1379, 3840, 295, 2418, 3787, 12318, 50864], "temperature": 0.0, "avg_logprob": -0.0858415687171212, "compression_ratio": 1.71, "no_speech_prob": 0.001750319730490446}, {"id": 517, "seek": 216592, "start": 2175.92, "end": 2177.92, "text": " and coding interviews and huge, long,", "tokens": [50864, 293, 17720, 12318, 293, 2603, 11, 938, 11, 50964], "temperature": 0.0, "avg_logprob": -0.0858415687171212, "compression_ratio": 1.71, "no_speech_prob": 0.001750319730490446}, {"id": 518, "seek": 216592, "start": 2177.92, "end": 2179.92, "text": " convoluted interview processes to check", "tokens": [50964, 3754, 2308, 292, 4049, 7555, 281, 1520, 51064], "temperature": 0.0, "avg_logprob": -0.0858415687171212, "compression_ratio": 1.71, "no_speech_prob": 0.001750319730490446}, {"id": 519, "seek": 216592, "start": 2179.92, "end": 2181.92, "text": " whether this person", "tokens": [51064, 1968, 341, 954, 51164], "temperature": 0.0, "avg_logprob": -0.0858415687171212, "compression_ratio": 1.71, "no_speech_prob": 0.001750319730490446}, {"id": 520, "seek": 216592, "start": 2181.92, "end": 2183.92, "text": " can do this job that we're trying to hire for.", "tokens": [51164, 393, 360, 341, 1691, 300, 321, 434, 1382, 281, 11158, 337, 13, 51264], "temperature": 0.0, "avg_logprob": -0.0858415687171212, "compression_ratio": 1.71, "no_speech_prob": 0.001750319730490446}, {"id": 521, "seek": 216592, "start": 2183.92, "end": 2185.92, "text": " Another interesting", "tokens": [51264, 3996, 1880, 51364], "temperature": 0.0, "avg_logprob": -0.0858415687171212, "compression_ratio": 1.71, "no_speech_prob": 0.001750319730490446}, {"id": 522, "seek": 216592, "start": 2185.92, "end": 2187.92, "text": " thing to make mention of AI,", "tokens": [51364, 551, 281, 652, 2152, 295, 7318, 11, 51464], "temperature": 0.0, "avg_logprob": -0.0858415687171212, "compression_ratio": 1.71, "no_speech_prob": 0.001750319730490446}, {"id": 523, "seek": 216592, "start": 2187.92, "end": 2189.92, "text": " which has already been talked about today,", "tokens": [51464, 597, 575, 1217, 668, 2825, 466, 965, 11, 51564], "temperature": 0.0, "avg_logprob": -0.0858415687171212, "compression_ratio": 1.71, "no_speech_prob": 0.001750319730490446}, {"id": 524, "seek": 216592, "start": 2189.92, "end": 2191.92, "text": " is it fascinated me that in the last", "tokens": [51564, 307, 309, 24597, 385, 300, 294, 264, 1036, 51664], "temperature": 0.0, "avg_logprob": -0.0858415687171212, "compression_ratio": 1.71, "no_speech_prob": 0.001750319730490446}, {"id": 525, "seek": 216592, "start": 2191.92, "end": 2193.92, "text": " maybe six months to a year", "tokens": [51664, 1310, 2309, 2493, 281, 257, 1064, 51764], "temperature": 0.0, "avg_logprob": -0.0858415687171212, "compression_ratio": 1.71, "no_speech_prob": 0.001750319730490446}, {"id": 526, "seek": 219392, "start": 2193.92, "end": 2195.92, "text": " or so, I've started to hear", "tokens": [50364, 420, 370, 11, 286, 600, 1409, 281, 1568, 50464], "temperature": 0.0, "avg_logprob": -0.08098424624090325, "compression_ratio": 1.755485893416928, "no_speech_prob": 0.007773130666464567}, {"id": 527, "seek": 219392, "start": 2195.92, "end": 2197.92, "text": " multiple hiring managers talk about the fact that", "tokens": [50464, 3866, 15335, 14084, 751, 466, 264, 1186, 300, 50564], "temperature": 0.0, "avg_logprob": -0.08098424624090325, "compression_ratio": 1.755485893416928, "no_speech_prob": 0.007773130666464567}, {"id": 528, "seek": 219392, "start": 2197.92, "end": 2199.92, "text": " oh, we had to put a load of", "tokens": [50564, 1954, 11, 321, 632, 281, 829, 257, 3677, 295, 50664], "temperature": 0.0, "avg_logprob": -0.08098424624090325, "compression_ratio": 1.755485893416928, "no_speech_prob": 0.007773130666464567}, {"id": 529, "seek": 219392, "start": 2199.92, "end": 2201.92, "text": " extra processes in and the interviews have become", "tokens": [50664, 2857, 7555, 294, 293, 264, 12318, 362, 1813, 50764], "temperature": 0.0, "avg_logprob": -0.08098424624090325, "compression_ratio": 1.755485893416928, "no_speech_prob": 0.007773130666464567}, {"id": 530, "seek": 219392, "start": 2201.92, "end": 2203.92, "text": " even more complicated now because", "tokens": [50764, 754, 544, 6179, 586, 570, 50864], "temperature": 0.0, "avg_logprob": -0.08098424624090325, "compression_ratio": 1.755485893416928, "no_speech_prob": 0.007773130666464567}, {"id": 531, "seek": 219392, "start": 2203.92, "end": 2205.92, "text": " a lot of our candidates are trying to cheat", "tokens": [50864, 257, 688, 295, 527, 11255, 366, 1382, 281, 17470, 50964], "temperature": 0.0, "avg_logprob": -0.08098424624090325, "compression_ratio": 1.755485893416928, "no_speech_prob": 0.007773130666464567}, {"id": 532, "seek": 219392, "start": 2205.92, "end": 2207.92, "text": " using AI. I've literally heard about people", "tokens": [50964, 1228, 7318, 13, 286, 600, 3736, 2198, 466, 561, 51064], "temperature": 0.0, "avg_logprob": -0.08098424624090325, "compression_ratio": 1.755485893416928, "no_speech_prob": 0.007773130666464567}, {"id": 533, "seek": 219392, "start": 2207.92, "end": 2209.92, "text": " having chat GPT open in another window", "tokens": [51064, 1419, 5081, 26039, 51, 1269, 294, 1071, 4910, 51164], "temperature": 0.0, "avg_logprob": -0.08098424624090325, "compression_ratio": 1.755485893416928, "no_speech_prob": 0.007773130666464567}, {"id": 534, "seek": 219392, "start": 2209.92, "end": 2211.92, "text": " whilst they're doing an interview and just typing", "tokens": [51164, 18534, 436, 434, 884, 364, 4049, 293, 445, 18444, 51264], "temperature": 0.0, "avg_logprob": -0.08098424624090325, "compression_ratio": 1.755485893416928, "no_speech_prob": 0.007773130666464567}, {"id": 535, "seek": 219392, "start": 2211.92, "end": 2213.92, "text": " all of the interview questions into it and then", "tokens": [51264, 439, 295, 264, 4049, 1651, 666, 309, 293, 550, 51364], "temperature": 0.0, "avg_logprob": -0.08098424624090325, "compression_ratio": 1.755485893416928, "no_speech_prob": 0.007773130666464567}, {"id": 536, "seek": 219392, "start": 2213.92, "end": 2215.92, "text": " parroting back the answers to the interviewers.", "tokens": [51364, 42462, 278, 646, 264, 6338, 281, 264, 4049, 433, 13, 51464], "temperature": 0.0, "avg_logprob": -0.08098424624090325, "compression_ratio": 1.755485893416928, "no_speech_prob": 0.007773130666464567}, {"id": 537, "seek": 219392, "start": 2215.92, "end": 2217.92, "text": " And it's like, that's a bit", "tokens": [51464, 400, 309, 311, 411, 11, 300, 311, 257, 857, 51564], "temperature": 0.0, "avg_logprob": -0.08098424624090325, "compression_ratio": 1.755485893416928, "no_speech_prob": 0.007773130666464567}, {"id": 538, "seek": 219392, "start": 2217.92, "end": 2219.92, "text": " nightmarish and", "tokens": [51564, 1818, 6209, 742, 293, 51664], "temperature": 0.0, "avg_logprob": -0.08098424624090325, "compression_ratio": 1.755485893416928, "no_speech_prob": 0.007773130666464567}, {"id": 539, "seek": 219392, "start": 2219.92, "end": 2221.92, "text": " it's difficult to really think about what to do about", "tokens": [51664, 309, 311, 2252, 281, 534, 519, 466, 437, 281, 360, 466, 51764], "temperature": 0.0, "avg_logprob": -0.08098424624090325, "compression_ratio": 1.755485893416928, "no_speech_prob": 0.007773130666464567}, {"id": 540, "seek": 222192, "start": 2221.92, "end": 2223.92, "text": " that. But I kind of think, well, if these people", "tokens": [50364, 300, 13, 583, 286, 733, 295, 519, 11, 731, 11, 498, 613, 561, 50464], "temperature": 0.0, "avg_logprob": -0.09875335978038276, "compression_ratio": 1.784452296819788, "no_speech_prob": 0.003984771203249693}, {"id": 541, "seek": 222192, "start": 2223.92, "end": 2225.92, "text": " were maybe more confident", "tokens": [50464, 645, 1310, 544, 6679, 50564], "temperature": 0.0, "avg_logprob": -0.09875335978038276, "compression_ratio": 1.784452296819788, "no_speech_prob": 0.003984771203249693}, {"id": 542, "seek": 222192, "start": 2225.92, "end": 2227.92, "text": " in their skill sets in the first place, maybe", "tokens": [50564, 294, 641, 5389, 6352, 294, 264, 700, 1081, 11, 1310, 50664], "temperature": 0.0, "avg_logprob": -0.09875335978038276, "compression_ratio": 1.784452296819788, "no_speech_prob": 0.003984771203249693}, {"id": 543, "seek": 222192, "start": 2227.92, "end": 2229.92, "text": " they wouldn't have to think to rely on that quite as much.", "tokens": [50664, 436, 2759, 380, 362, 281, 519, 281, 10687, 322, 300, 1596, 382, 709, 13, 50764], "temperature": 0.0, "avg_logprob": -0.09875335978038276, "compression_ratio": 1.784452296819788, "no_speech_prob": 0.003984771203249693}, {"id": 544, "seek": 222192, "start": 2229.92, "end": 2231.92, "text": " Another", "tokens": [50764, 3996, 50864], "temperature": 0.0, "avg_logprob": -0.09875335978038276, "compression_ratio": 1.784452296819788, "no_speech_prob": 0.003984771203249693}, {"id": 545, "seek": 222192, "start": 2231.92, "end": 2233.92, "text": " interesting thing is that", "tokens": [50864, 1880, 551, 307, 300, 50964], "temperature": 0.0, "avg_logprob": -0.09875335978038276, "compression_ratio": 1.784452296819788, "no_speech_prob": 0.003984771203249693}, {"id": 546, "seek": 222192, "start": 2233.92, "end": 2235.92, "text": " something that we're sort of looking", "tokens": [50964, 746, 300, 321, 434, 1333, 295, 1237, 51064], "temperature": 0.0, "avg_logprob": -0.09875335978038276, "compression_ratio": 1.784452296819788, "no_speech_prob": 0.003984771203249693}, {"id": 547, "seek": 222192, "start": 2235.92, "end": 2237.92, "text": " to do with some kind of curriculum", "tokens": [51064, 281, 360, 365, 512, 733, 295, 14302, 51164], "temperature": 0.0, "avg_logprob": -0.09875335978038276, "compression_ratio": 1.784452296819788, "no_speech_prob": 0.003984771203249693}, {"id": 548, "seek": 222192, "start": 2237.92, "end": 2239.92, "text": " would maybe to have", "tokens": [51164, 576, 1310, 281, 362, 51264], "temperature": 0.0, "avg_logprob": -0.09875335978038276, "compression_ratio": 1.784452296819788, "no_speech_prob": 0.003984771203249693}, {"id": 549, "seek": 222192, "start": 2239.92, "end": 2241.92, "text": " some kind of industry standard benchmark", "tokens": [51264, 512, 733, 295, 3518, 3832, 18927, 51364], "temperature": 0.0, "avg_logprob": -0.09875335978038276, "compression_ratio": 1.784452296819788, "no_speech_prob": 0.003984771203249693}, {"id": 550, "seek": 222192, "start": 2241.92, "end": 2243.92, "text": " certification, eventually. This is kind of", "tokens": [51364, 21775, 11, 4728, 13, 639, 307, 733, 295, 51464], "temperature": 0.0, "avg_logprob": -0.09875335978038276, "compression_ratio": 1.784452296819788, "no_speech_prob": 0.003984771203249693}, {"id": 551, "seek": 222192, "start": 2243.92, "end": 2245.92, "text": " pie in the sky, often the future.", "tokens": [51464, 1730, 294, 264, 5443, 11, 2049, 264, 2027, 13, 51564], "temperature": 0.0, "avg_logprob": -0.09875335978038276, "compression_ratio": 1.784452296819788, "no_speech_prob": 0.003984771203249693}, {"id": 552, "seek": 222192, "start": 2245.92, "end": 2247.92, "text": " But maybe this certification could kind of say,", "tokens": [51564, 583, 1310, 341, 21775, 727, 733, 295, 584, 11, 51664], "temperature": 0.0, "avg_logprob": -0.09875335978038276, "compression_ratio": 1.784452296819788, "no_speech_prob": 0.003984771203249693}, {"id": 553, "seek": 222192, "start": 2247.92, "end": 2249.92, "text": " you know, anybody that's got this", "tokens": [51664, 291, 458, 11, 4472, 300, 311, 658, 341, 51764], "temperature": 0.0, "avg_logprob": -0.09875335978038276, "compression_ratio": 1.784452296819788, "no_speech_prob": 0.003984771203249693}, {"id": 554, "seek": 224992, "start": 2249.92, "end": 2251.92, "text": " certification,", "tokens": [50364, 21775, 11, 50464], "temperature": 0.0, "avg_logprob": -0.06945392579743356, "compression_ratio": 1.8981132075471698, "no_speech_prob": 0.0017656659474596381}, {"id": 555, "seek": 224992, "start": 2251.92, "end": 2253.92, "text": " it's a trusted certification, you know,", "tokens": [50464, 309, 311, 257, 16034, 21775, 11, 291, 458, 11, 50564], "temperature": 0.0, "avg_logprob": -0.06945392579743356, "compression_ratio": 1.8981132075471698, "no_speech_prob": 0.0017656659474596381}, {"id": 556, "seek": 224992, "start": 2253.92, "end": 2255.92, "text": " in the same way that", "tokens": [50564, 294, 264, 912, 636, 300, 50664], "temperature": 0.0, "avg_logprob": -0.06945392579743356, "compression_ratio": 1.8981132075471698, "no_speech_prob": 0.0017656659474596381}, {"id": 557, "seek": 224992, "start": 2255.92, "end": 2257.92, "text": " industries such as law or architecture", "tokens": [50664, 13284, 1270, 382, 2101, 420, 9482, 50764], "temperature": 0.0, "avg_logprob": -0.06945392579743356, "compression_ratio": 1.8981132075471698, "no_speech_prob": 0.0017656659474596381}, {"id": 558, "seek": 224992, "start": 2257.92, "end": 2259.92, "text": " have trusted bodies who have", "tokens": [50764, 362, 16034, 7510, 567, 362, 50864], "temperature": 0.0, "avg_logprob": -0.06945392579743356, "compression_ratio": 1.8981132075471698, "no_speech_prob": 0.0017656659474596381}, {"id": 559, "seek": 224992, "start": 2259.92, "end": 2261.92, "text": " these certifications that everybody gets to prove", "tokens": [50864, 613, 5351, 7833, 300, 2201, 2170, 281, 7081, 50964], "temperature": 0.0, "avg_logprob": -0.06945392579743356, "compression_ratio": 1.8981132075471698, "no_speech_prob": 0.0017656659474596381}, {"id": 560, "seek": 224992, "start": 2261.92, "end": 2263.92, "text": " that they know what they're talking about.", "tokens": [50964, 300, 436, 458, 437, 436, 434, 1417, 466, 13, 51064], "temperature": 0.0, "avg_logprob": -0.06945392579743356, "compression_ratio": 1.8981132075471698, "no_speech_prob": 0.0017656659474596381}, {"id": 561, "seek": 224992, "start": 2263.92, "end": 2265.92, "text": " But we don't really have that for our industry.", "tokens": [51064, 583, 321, 500, 380, 534, 362, 300, 337, 527, 3518, 13, 51164], "temperature": 0.0, "avg_logprob": -0.06945392579743356, "compression_ratio": 1.8981132075471698, "no_speech_prob": 0.0017656659474596381}, {"id": 562, "seek": 224992, "start": 2265.92, "end": 2266.92, "text": " And", "tokens": [51164, 400, 51214], "temperature": 0.0, "avg_logprob": -0.06945392579743356, "compression_ratio": 1.8981132075471698, "no_speech_prob": 0.0017656659474596381}, {"id": 563, "seek": 224992, "start": 2266.92, "end": 2268.92, "text": " employers don't really trust some random", "tokens": [51214, 16744, 500, 380, 534, 3361, 512, 4974, 51314], "temperature": 0.0, "avg_logprob": -0.06945392579743356, "compression_ratio": 1.8981132075471698, "no_speech_prob": 0.0017656659474596381}, {"id": 564, "seek": 224992, "start": 2268.92, "end": 2270.92, "text": " certificate from some, you know,", "tokens": [51314, 15953, 490, 512, 11, 291, 458, 11, 51414], "temperature": 0.0, "avg_logprob": -0.06945392579743356, "compression_ratio": 1.8981132075471698, "no_speech_prob": 0.0017656659474596381}, {"id": 565, "seek": 224992, "start": 2270.92, "end": 2272.92, "text": " whatever boot camp, you know, I'm not", "tokens": [51414, 2035, 11450, 2255, 11, 291, 458, 11, 286, 478, 406, 51514], "temperature": 0.0, "avg_logprob": -0.06945392579743356, "compression_ratio": 1.8981132075471698, "no_speech_prob": 0.0017656659474596381}, {"id": 566, "seek": 224992, "start": 2272.92, "end": 2274.92, "text": " saying those boot camps are bad or not trustworthy,", "tokens": [51514, 1566, 729, 11450, 16573, 366, 1578, 420, 406, 39714, 11, 51614], "temperature": 0.0, "avg_logprob": -0.06945392579743356, "compression_ratio": 1.8981132075471698, "no_speech_prob": 0.0017656659474596381}, {"id": 567, "seek": 224992, "start": 2274.92, "end": 2276.92, "text": " but employers just have a hard time", "tokens": [51614, 457, 16744, 445, 362, 257, 1152, 565, 51714], "temperature": 0.0, "avg_logprob": -0.06945392579743356, "compression_ratio": 1.8981132075471698, "no_speech_prob": 0.0017656659474596381}, {"id": 568, "seek": 224992, "start": 2276.92, "end": 2278.92, "text": " trusting them.", "tokens": [51714, 28235, 552, 13, 51814], "temperature": 0.0, "avg_logprob": -0.06945392579743356, "compression_ratio": 1.8981132075471698, "no_speech_prob": 0.0017656659474596381}, {"id": 569, "seek": 227892, "start": 2278.92, "end": 2280.92, "text": " And as makes perfect sense,", "tokens": [50364, 400, 382, 1669, 2176, 2020, 11, 50464], "temperature": 0.0, "avg_logprob": -0.09815499415764442, "compression_ratio": 1.0987654320987654, "no_speech_prob": 0.004002086818218231}, {"id": 570, "seek": 227892, "start": 2280.92, "end": 2282.92, "text": " they value demonstrable", "tokens": [50464, 436, 2158, 5516, 424, 638, 50564], "temperature": 0.0, "avg_logprob": -0.09815499415764442, "compression_ratio": 1.0987654320987654, "no_speech_prob": 0.004002086818218231}, {"id": 571, "seek": 227892, "start": 2282.92, "end": 2284.92, "text": " experience and portfolios a lot more.", "tokens": [50564, 1752, 293, 11688, 2717, 257, 688, 544, 13, 50664], "temperature": 0.0, "avg_logprob": -0.09815499415764442, "compression_ratio": 1.0987654320987654, "no_speech_prob": 0.004002086818218231}], "language": "en"}