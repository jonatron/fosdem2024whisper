{"text": " Welcome. Thanks for having me. My talk was actually about one o'clock this afternoon, but I'll jump in now. This is the right \u2013 am I too loud? It's fine. Okay. Well, I am Nicholas from Germany living in Amsterdam. I'm co-founder of CITA, Energy Flexibility, and we co-founded the FlexMeasures project. I will briefly talk about the FlexMeasures project. Last time at Boston, we also had to talk about some specifics. I like to introduce a project with some specific applications. So last year, we talked about our Vehicle to Grid implementation, where we use flex measures and home assistant. And today also, I'll go more on the developer perspective as a developer, you would actually work with flex measures. I only have 15 minutes, so I will fly over it a bit. Don't worry. I mean, let's not read every line of code. It's just to give you an impression. How would it be like? With flex measures as an introduction, we have been focusing on behind-the-meter optimization. So that's these other things you find behind-the-meter. So there's enough complexity to run an optimization and find the best running times for the things that are flexible here, which are usually EV charging, batteries. And today, we talk about hot water storage. These things are not exactly behind-the-meter, but they matter as well. In Netherlands, we have congestion on the grid that influences the optimization of what you're doing. It's a constraint and dynamic energy prices. So then, it becomes quite interesting as a problem. Right. So very briefly, flex measures is a platform that takes in a lot of data, like meter data or prices, all these things. And it gives you the best timing for your flexible assets as a very simplified picture of what it is. We have used it in a couple of areas, like I mentioned, bi-directional charging, in industry, in water sanitation, and now we're working on smart heating as well. Here's a little look on our dynamic visualization of what flex measures knows at any given time. So this is from the VEP UI of flex measures. You can replay what happened, what data flex measures knew, and what forecast it knew. But I want to spend 10 minutes, have this very brief tour. What if you were an energy startup? Let's say you work with smart heating, and you want to have the smart scheduling for your e-boiler, as an example. So these are things you would like to do. I will go through each of those. And I'll touch upon a couple of ways to interact with flex measures. You're writing your own flex measures, plug-in. There's a Python client, there's a command line interface, of course, there's an API. And I'll just, while I go through this list, everything will be touched for illustration, what are the things you can do. The brief picture would be that there's a house where there's the e-boiler, so your energy asset, with temperature readings. There's a flex measure server over here in the cloud. And all of these things are going to happen. So there's a little bit of an architecture diagram, but what we'll try to touch here. So the flex measures client will send temperature, it will ask the server to compute a schedule for the boiler. There's a data platform where we can get the prices. We'll have a cron tab because we will have to do some stuff just regularly. And let's keep that in mind. So this is the very first step. You don't have to read everything, but I'm just showing that we provide a cookie cutter template so you can quickly get up to speed, have your own code structure. So you choose a name and a description and you say, yeah, please give me the API blueprint. Blueprint is a word from the Flask system because flex measures is a Flask application. And you get some kind of boilerplate like this. And that's a boiler. This is the one endpoint we're doing here. What if we want to create a new customer for this project? This is a lot of code. This is basically the endpoint we wrote as an example. I'm not going to read everything. Basically, this is how you plug it in. It's going to be plugged in flex measures and available as an endpoint. We're creating a user and an account. And maybe this is the most interesting. So this is basically your business objects. I will go a little deeper here. This is the same code roughly. So we're creating the boiler as an asset. We're creating a couple of sensors. Here's two examples a bit bigger where we really define, we tell flex measures how to handle this. What kind of units are we handling and the event resolution and so that flex measures know what to do with them when data arrives. Schedules have to be made. And then if that happened, if somebody called this endpoint and your account was made and you would end up in the flex measures UI, you can see them here. Next step, let's say we measure the temperature locally. You have your own sensor and you want the temperature data to end up in flex measures as well. Then here's a small example how to use the flex measures client. Basically, it provides you with some nice code to work with more easily, but it actually uses the flex measures API in the background. For fun, we actually had the temperature reading in Fahrenheit, which we say when we send it to flex measures, the data is actually to be stored in Celsius and will automatically get it right. So this is where a lot of work goes, as you can imagine. But otherwise, this is just sending this reading. There's not much more. You'll do this regularly from your local script that runs on your Raspberry Pi, whatever you're doing there locally. One more step. So there's some external information we need. Temperature is a local reading from your local asset. Prices are a good example of information from some other third parties that just has to also be collected in flex measures. One other example is weather forecasts. In this example, I'm showing that we actually wrote a plugin for that. So we're cloning this plugin we wrote. NSEU is the organization of European transmission system operators, and they provide a data platform so you can get various things like prices, but also just a head allocations for all the transmission zones. And so we say we want the Dutch transmission zone. Please give me the prices for that. I'll talk and we configure everything. And actually then this is the command. So through flex measures CLI, this plugin has registered a group of commands, for instance, to import a head prices. Also, all of this is public how we wrote the plugin. So if you call this regularly, let's say one time per day, you'll have the next day head prices always in your system. Small visualization of one day of prices in the flex measures CLI. Excuse me. Okay, now I'm not sure how much time do I have. Eight minutes. All right, that's not too bad. But the main part now is you want to actually tell flex measures to give you an optimized schedule for your boiler. And here I'll show, I could do that via the flex measures client as well, but I'll just show how to use the API directly. This is not so interesting, of course, you have to have an authentication token. But I have to spend a bit more time here. A lot of time we spend when we made flex measures is how you configure the problem. How do you tell flex measures the constraints of the problem in the back flex measures will actually take your information about your setup and your problem. Basically, you could call that business rules, and really translate that dynamically into a linear program. So flex measures contains, I think three different algorithms, basically, we have one that's focusing on storage based problems. And that's what we also use for heat, heat batteries, we call them. We have one for, if you just want to allocate processes. But it's a very important part for developing a new application that you can tell the flex measures server, this is how I want you to treat this problem. Here's the constraint you don't know about, or here's a local thing you don't know about. And that's where we're working on two things, the flex model and flex context. So flex context would be, well, these are the prices that are relevant. We also have a project where we don't use prices, but we use the CO2 signal, the CO2 content of the grid that is anticipated. But the flex model is a bit more detailed. So this is not all the things you can do. But basically, wishing, well, the state of charge of this heat battery is this many kilowatt hours. So that's local knowledge you have. Here's some constraints. I can't go under this. We don't want to go under this. And also, here's a target for you. In the morning, I need to have this much energy content in my battery. I think this could also be a percentage. We're pretty flexible there. Some other constraints. You can see how these translate actually into constraints of a problem. And then you call our API to say, well, for this, the fill rate that I want a schedule for that, please start. And that will actually trigger a scheduling job. And then flex motors will usually pass this on to a worker. So we, in our implementations, we have a web worker and computation workers that will handle those. And then you can call this, get endpoint to check if your computation is ready. It will usually not be ready after three seconds, but soon after. And then, yeah, you get your values here. So then you can implement these settings locally. You can, let's say you ask for a schedule for 12 hours, then your local gateway has the plan for 12 hours. If there's anything that changes on the ground, you just ask for a new one. You'll update as we go. So that's general behavior. I'm almost done with, with a, you know, two of the force here. One thing we want to maybe do is in flex measures have a nice dashboard that has the most crucial data on top of each other for some inspection. And then, well, you can actually put that on the boiler asset. And then you, in flex measures, you have these nicely stacked, right? You want to see what you've been using for optimization on top. Although this comes from a different asset. This is something for everybody. All the assets can use this. And we use, as you remember, we had like four sensors or so that are relevant, but we just decided these two other ones we want to see. So we can easily see that in a period of low prices, flex measures has tried to, you know, fill the, fill the boiler at those times. Some signal here. I'll skip over this a bit because, yeah, I originally had a 25 minutes idea about this. Just as very quickly, we also noticed it's very important to also do some reporting. In flex measures, give some logic about that, that you combine some sensor data so you get the outputs of what happened, for instance, like costs. You know, that's very important. Sorry. And that can become a C like a minus well that you regularly say, okay, now the day has happened, we optimize as we could. Let's calculate how much energy costs we had here. So combine just the prices and the fill rate, which happened. But we also saw already that's that's many more interesting computations that people want. So this is a very simple multiplication. But we've made a pretty complicated architecture so you can actually have a lot of bring a couple sensors together for a new result that even can be used further in your next optimization or so. It's a very flexible system we've built here. And this is the project website. From there, you'll find the the GitHub, you find the read the docs, you'll find more information like I was interviewed for Python podcast where maybe I go into more detail. The mailing list contact, everything's there. You can also just write me directly, of course, if you're interested in doing something yourself and joining our TSC, the technical steering committee, everybody's welcome. And that's it. Yeah, there's lots of things to do, of course, I've touched upon a couple things, applications like vehicle to grid or smart heating and industry. But the roadway is still, of course, filled. There's so so much things in the energy behind the meter and a bit above to optimize. Thanks. We have time for question, then. If someone wants to ask one question, you said that you create a linear program. And what solver do you use to solve this program? What kind of solver? Yeah, we have we work with two solvers now. You could, of course, also use Cplex, but we've used two open source ones. All right, now they don't come to my head. Sorry. Hi. Yeah, we switched to that one. And we had a different one before that are both possible. So you can just those are shipped with a Docker image even so you can just configure that which one you want to use. But you can also we use pyomo as a representation for the problem. So everything that works with pyomo, which is you can use that as well. Thank you so much.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 11.0, "text": " Welcome. Thanks for having me. My talk was actually about one o'clock this afternoon,", "tokens": [50364, 4027, 13, 2561, 337, 1419, 385, 13, 1222, 751, 390, 767, 466, 472, 277, 6, 9023, 341, 6499, 11, 50914], "temperature": 0.0, "avg_logprob": -0.22945137023925782, "compression_ratio": 1.3127962085308056, "no_speech_prob": 0.4316437542438507}, {"id": 1, "seek": 0, "start": 11.0, "end": 21.080000000000002, "text": " but I'll jump in now. This is the right \u2013 am I too loud? It's fine. Okay. Well, I am Nicholas", "tokens": [50914, 457, 286, 603, 3012, 294, 586, 13, 639, 307, 264, 558, 1662, 669, 286, 886, 6588, 30, 467, 311, 2489, 13, 1033, 13, 1042, 11, 286, 669, 22924, 51418], "temperature": 0.0, "avg_logprob": -0.22945137023925782, "compression_ratio": 1.3127962085308056, "no_speech_prob": 0.4316437542438507}, {"id": 2, "seek": 0, "start": 21.080000000000002, "end": 29.52, "text": " from Germany living in Amsterdam. I'm co-founder of CITA, Energy Flexibility, and we co-founded", "tokens": [51418, 490, 7244, 2647, 294, 28291, 13, 286, 478, 598, 12, 33348, 295, 383, 3927, 32, 11, 14939, 29208, 2841, 11, 293, 321, 598, 12, 49547, 51840], "temperature": 0.0, "avg_logprob": -0.22945137023925782, "compression_ratio": 1.3127962085308056, "no_speech_prob": 0.4316437542438507}, {"id": 3, "seek": 2952, "start": 29.52, "end": 36.4, "text": " the FlexMeasures project. I will briefly talk about the FlexMeasures project. Last time", "tokens": [50364, 264, 29208, 12671, 20044, 1716, 13, 286, 486, 10515, 751, 466, 264, 29208, 12671, 20044, 1716, 13, 5264, 565, 50708], "temperature": 0.0, "avg_logprob": -0.26950785171153935, "compression_ratio": 1.6605504587155964, "no_speech_prob": 0.04475782811641693}, {"id": 4, "seek": 2952, "start": 36.4, "end": 41.08, "text": " at Boston, we also had to talk about some specifics. I like to introduce a project with", "tokens": [50708, 412, 12333, 11, 321, 611, 632, 281, 751, 466, 512, 28454, 13, 286, 411, 281, 5366, 257, 1716, 365, 50942], "temperature": 0.0, "avg_logprob": -0.26950785171153935, "compression_ratio": 1.6605504587155964, "no_speech_prob": 0.04475782811641693}, {"id": 5, "seek": 2952, "start": 41.08, "end": 48.64, "text": " some specific applications. So last year, we talked about our Vehicle to Grid implementation,", "tokens": [50942, 512, 2685, 5821, 13, 407, 1036, 1064, 11, 321, 2825, 466, 527, 41230, 3520, 281, 42905, 11420, 11, 51320], "temperature": 0.0, "avg_logprob": -0.26950785171153935, "compression_ratio": 1.6605504587155964, "no_speech_prob": 0.04475782811641693}, {"id": 6, "seek": 2952, "start": 48.64, "end": 54.480000000000004, "text": " where we use flex measures and home assistant. And today also, I'll go more on the developer", "tokens": [51320, 689, 321, 764, 5896, 8000, 293, 1280, 10994, 13, 400, 965, 611, 11, 286, 603, 352, 544, 322, 264, 10754, 51612], "temperature": 0.0, "avg_logprob": -0.26950785171153935, "compression_ratio": 1.6605504587155964, "no_speech_prob": 0.04475782811641693}, {"id": 7, "seek": 5448, "start": 54.48, "end": 61.68, "text": " perspective as a developer, you would actually work with flex measures. I only have 15 minutes,", "tokens": [50364, 4585, 382, 257, 10754, 11, 291, 576, 767, 589, 365, 5896, 8000, 13, 286, 787, 362, 2119, 2077, 11, 50724], "temperature": 0.0, "avg_logprob": -0.2031770462685443, "compression_ratio": 1.5062240663900415, "no_speech_prob": 0.06347544491291046}, {"id": 8, "seek": 5448, "start": 61.68, "end": 68.92, "text": " so I will fly over it a bit. Don't worry. I mean, let's not read every line of code.", "tokens": [50724, 370, 286, 486, 3603, 670, 309, 257, 857, 13, 1468, 380, 3292, 13, 286, 914, 11, 718, 311, 406, 1401, 633, 1622, 295, 3089, 13, 51086], "temperature": 0.0, "avg_logprob": -0.2031770462685443, "compression_ratio": 1.5062240663900415, "no_speech_prob": 0.06347544491291046}, {"id": 9, "seek": 5448, "start": 68.92, "end": 75.03999999999999, "text": " It's just to give you an impression. How would it be like? With flex measures as an introduction,", "tokens": [51086, 467, 311, 445, 281, 976, 291, 364, 9995, 13, 1012, 576, 309, 312, 411, 30, 2022, 5896, 8000, 382, 364, 9339, 11, 51392], "temperature": 0.0, "avg_logprob": -0.2031770462685443, "compression_ratio": 1.5062240663900415, "no_speech_prob": 0.06347544491291046}, {"id": 10, "seek": 5448, "start": 75.03999999999999, "end": 79.12, "text": " we have been focusing on behind-the-meter optimization. So that's these other things", "tokens": [51392, 321, 362, 668, 8416, 322, 2261, 12, 3322, 12, 33058, 19618, 13, 407, 300, 311, 613, 661, 721, 51596], "temperature": 0.0, "avg_logprob": -0.2031770462685443, "compression_ratio": 1.5062240663900415, "no_speech_prob": 0.06347544491291046}, {"id": 11, "seek": 7912, "start": 79.2, "end": 85.04, "text": " you find behind-the-meter. So there's enough complexity to run an optimization and find", "tokens": [50368, 291, 915, 2261, 12, 3322, 12, 33058, 13, 407, 456, 311, 1547, 14024, 281, 1190, 364, 19618, 293, 915, 50660], "temperature": 0.0, "avg_logprob": -0.13681623068722812, "compression_ratio": 1.5648535564853556, "no_speech_prob": 0.034674085676670074}, {"id": 12, "seek": 7912, "start": 85.04, "end": 90.24000000000001, "text": " the best running times for the things that are flexible here, which are usually EV charging,", "tokens": [50660, 264, 1151, 2614, 1413, 337, 264, 721, 300, 366, 11358, 510, 11, 597, 366, 2673, 15733, 11379, 11, 50920], "temperature": 0.0, "avg_logprob": -0.13681623068722812, "compression_ratio": 1.5648535564853556, "no_speech_prob": 0.034674085676670074}, {"id": 13, "seek": 7912, "start": 90.24000000000001, "end": 100.08000000000001, "text": " batteries. And today, we talk about hot water storage. These things are not exactly behind-the-meter,", "tokens": [50920, 13070, 13, 400, 965, 11, 321, 751, 466, 2368, 1281, 6725, 13, 1981, 721, 366, 406, 2293, 2261, 12, 3322, 12, 33058, 11, 51412], "temperature": 0.0, "avg_logprob": -0.13681623068722812, "compression_ratio": 1.5648535564853556, "no_speech_prob": 0.034674085676670074}, {"id": 14, "seek": 7912, "start": 100.08000000000001, "end": 105.68, "text": " but they matter as well. In Netherlands, we have congestion on the grid that influences the", "tokens": [51412, 457, 436, 1871, 382, 731, 13, 682, 20873, 11, 321, 362, 40816, 322, 264, 10748, 300, 21222, 264, 51692], "temperature": 0.0, "avg_logprob": -0.13681623068722812, "compression_ratio": 1.5648535564853556, "no_speech_prob": 0.034674085676670074}, {"id": 15, "seek": 10568, "start": 105.68, "end": 112.0, "text": " optimization of what you're doing. It's a constraint and dynamic energy prices. So then,", "tokens": [50364, 19618, 295, 437, 291, 434, 884, 13, 467, 311, 257, 25534, 293, 8546, 2281, 7901, 13, 407, 550, 11, 50680], "temperature": 0.0, "avg_logprob": -0.1440532438216671, "compression_ratio": 1.5637860082304527, "no_speech_prob": 0.00825176015496254}, {"id": 16, "seek": 10568, "start": 112.0, "end": 122.08000000000001, "text": " it becomes quite interesting as a problem. Right. So very briefly, flex measures is a platform", "tokens": [50680, 309, 3643, 1596, 1880, 382, 257, 1154, 13, 1779, 13, 407, 588, 10515, 11, 5896, 8000, 307, 257, 3663, 51184], "temperature": 0.0, "avg_logprob": -0.1440532438216671, "compression_ratio": 1.5637860082304527, "no_speech_prob": 0.00825176015496254}, {"id": 17, "seek": 10568, "start": 122.08000000000001, "end": 128.4, "text": " that takes in a lot of data, like meter data or prices, all these things. And it gives you the best", "tokens": [51184, 300, 2516, 294, 257, 688, 295, 1412, 11, 411, 9255, 1412, 420, 7901, 11, 439, 613, 721, 13, 400, 309, 2709, 291, 264, 1151, 51500], "temperature": 0.0, "avg_logprob": -0.1440532438216671, "compression_ratio": 1.5637860082304527, "no_speech_prob": 0.00825176015496254}, {"id": 18, "seek": 10568, "start": 128.4, "end": 135.20000000000002, "text": " timing for your flexible assets as a very simplified picture of what it is. We have used it in a", "tokens": [51500, 10822, 337, 428, 11358, 9769, 382, 257, 588, 26335, 3036, 295, 437, 309, 307, 13, 492, 362, 1143, 309, 294, 257, 51840], "temperature": 0.0, "avg_logprob": -0.1440532438216671, "compression_ratio": 1.5637860082304527, "no_speech_prob": 0.00825176015496254}, {"id": 19, "seek": 13520, "start": 135.2, "end": 143.51999999999998, "text": " couple of areas, like I mentioned, bi-directional charging, in industry, in water sanitation,", "tokens": [50364, 1916, 295, 3179, 11, 411, 286, 2835, 11, 3228, 12, 18267, 41048, 11379, 11, 294, 3518, 11, 294, 1281, 50146, 11, 50780], "temperature": 0.0, "avg_logprob": -0.14433720376756456, "compression_ratio": 1.435, "no_speech_prob": 0.005139132030308247}, {"id": 20, "seek": 13520, "start": 143.51999999999998, "end": 150.23999999999998, "text": " and now we're working on smart heating as well. Here's a little look on our dynamic visualization", "tokens": [50780, 293, 586, 321, 434, 1364, 322, 4069, 15082, 382, 731, 13, 1692, 311, 257, 707, 574, 322, 527, 8546, 25801, 51116], "temperature": 0.0, "avg_logprob": -0.14433720376756456, "compression_ratio": 1.435, "no_speech_prob": 0.005139132030308247}, {"id": 21, "seek": 13520, "start": 150.23999999999998, "end": 155.35999999999999, "text": " of what flex measures knows at any given time. So this is from the VEP UI of flex measures. You", "tokens": [51116, 295, 437, 5896, 8000, 3255, 412, 604, 2212, 565, 13, 407, 341, 307, 490, 264, 691, 8929, 15682, 295, 5896, 8000, 13, 509, 51372], "temperature": 0.0, "avg_logprob": -0.14433720376756456, "compression_ratio": 1.435, "no_speech_prob": 0.005139132030308247}, {"id": 22, "seek": 15536, "start": 155.36, "end": 165.68, "text": " can replay what happened, what data flex measures knew, and what forecast it knew. But I want to", "tokens": [50364, 393, 23836, 437, 2011, 11, 437, 1412, 5896, 8000, 2586, 11, 293, 437, 14330, 309, 2586, 13, 583, 286, 528, 281, 50880], "temperature": 0.0, "avg_logprob": -0.1647851053873698, "compression_ratio": 1.4974358974358974, "no_speech_prob": 0.04766356945037842}, {"id": 23, "seek": 15536, "start": 165.68, "end": 173.68, "text": " spend 10 minutes, have this very brief tour. What if you were an energy startup? Let's say you work", "tokens": [50880, 3496, 1266, 2077, 11, 362, 341, 588, 5353, 3512, 13, 708, 498, 291, 645, 364, 2281, 18578, 30, 961, 311, 584, 291, 589, 51280], "temperature": 0.0, "avg_logprob": -0.1647851053873698, "compression_ratio": 1.4974358974358974, "no_speech_prob": 0.04766356945037842}, {"id": 24, "seek": 15536, "start": 173.68, "end": 182.32000000000002, "text": " with smart heating, and you want to have the smart scheduling for your e-boiler, as an example.", "tokens": [51280, 365, 4069, 15082, 11, 293, 291, 528, 281, 362, 264, 4069, 29055, 337, 428, 308, 12, 1763, 5441, 11, 382, 364, 1365, 13, 51712], "temperature": 0.0, "avg_logprob": -0.1647851053873698, "compression_ratio": 1.4974358974358974, "no_speech_prob": 0.04766356945037842}, {"id": 25, "seek": 18232, "start": 183.2, "end": 190.48, "text": " So these are things you would like to do. I will go through each of those. And I'll touch upon a", "tokens": [50408, 407, 613, 366, 721, 291, 576, 411, 281, 360, 13, 286, 486, 352, 807, 1184, 295, 729, 13, 400, 286, 603, 2557, 3564, 257, 50772], "temperature": 0.0, "avg_logprob": -0.20325462185606666, "compression_ratio": 1.6379310344827587, "no_speech_prob": 0.005967103876173496}, {"id": 26, "seek": 18232, "start": 190.48, "end": 195.04, "text": " couple of ways to interact with flex measures. You're writing your own flex measures, plug-in.", "tokens": [50772, 1916, 295, 2098, 281, 4648, 365, 5896, 8000, 13, 509, 434, 3579, 428, 1065, 5896, 8000, 11, 5452, 12, 259, 13, 51000], "temperature": 0.0, "avg_logprob": -0.20325462185606666, "compression_ratio": 1.6379310344827587, "no_speech_prob": 0.005967103876173496}, {"id": 27, "seek": 18232, "start": 195.04, "end": 200.79999999999998, "text": " There's a Python client, there's a command line interface, of course, there's an API. And I'll", "tokens": [51000, 821, 311, 257, 15329, 6423, 11, 456, 311, 257, 5622, 1622, 9226, 11, 295, 1164, 11, 456, 311, 364, 9362, 13, 400, 286, 603, 51288], "temperature": 0.0, "avg_logprob": -0.20325462185606666, "compression_ratio": 1.6379310344827587, "no_speech_prob": 0.005967103876173496}, {"id": 28, "seek": 18232, "start": 200.79999999999998, "end": 207.68, "text": " just, while I go through this list, everything will be touched for illustration, what are the", "tokens": [51288, 445, 11, 1339, 286, 352, 807, 341, 1329, 11, 1203, 486, 312, 9828, 337, 22645, 11, 437, 366, 264, 51632], "temperature": 0.0, "avg_logprob": -0.20325462185606666, "compression_ratio": 1.6379310344827587, "no_speech_prob": 0.005967103876173496}, {"id": 29, "seek": 20768, "start": 208.16, "end": 215.36, "text": " things you can do. The brief picture would be that there's a house where there's the e-boiler,", "tokens": [50388, 721, 291, 393, 360, 13, 440, 5353, 3036, 576, 312, 300, 456, 311, 257, 1782, 689, 456, 311, 264, 308, 12, 1763, 5441, 11, 50748], "temperature": 0.0, "avg_logprob": -0.10332542784670566, "compression_ratio": 1.6844444444444444, "no_speech_prob": 0.005564407911151648}, {"id": 30, "seek": 20768, "start": 215.36, "end": 221.28, "text": " so your energy asset, with temperature readings. There's a flex measure server over here in the", "tokens": [50748, 370, 428, 2281, 11999, 11, 365, 4292, 27319, 13, 821, 311, 257, 5896, 3481, 7154, 670, 510, 294, 264, 51044], "temperature": 0.0, "avg_logprob": -0.10332542784670566, "compression_ratio": 1.6844444444444444, "no_speech_prob": 0.005564407911151648}, {"id": 31, "seek": 20768, "start": 221.28, "end": 228.8, "text": " cloud. And all of these things are going to happen. So there's a little bit of an architecture diagram,", "tokens": [51044, 4588, 13, 400, 439, 295, 613, 721, 366, 516, 281, 1051, 13, 407, 456, 311, 257, 707, 857, 295, 364, 9482, 10686, 11, 51420], "temperature": 0.0, "avg_logprob": -0.10332542784670566, "compression_ratio": 1.6844444444444444, "no_speech_prob": 0.005564407911151648}, {"id": 32, "seek": 20768, "start": 228.8, "end": 234.4, "text": " but what we'll try to touch here. So the flex measures client will send temperature,", "tokens": [51420, 457, 437, 321, 603, 853, 281, 2557, 510, 13, 407, 264, 5896, 8000, 6423, 486, 2845, 4292, 11, 51700], "temperature": 0.0, "avg_logprob": -0.10332542784670566, "compression_ratio": 1.6844444444444444, "no_speech_prob": 0.005564407911151648}, {"id": 33, "seek": 23440, "start": 235.36, "end": 245.36, "text": " it will ask the server to compute a schedule for the boiler. There's a data platform where we can", "tokens": [50412, 309, 486, 1029, 264, 7154, 281, 14722, 257, 7567, 337, 264, 39228, 13, 821, 311, 257, 1412, 3663, 689, 321, 393, 50912], "temperature": 0.0, "avg_logprob": -0.10702953338623047, "compression_ratio": 1.4690721649484537, "no_speech_prob": 0.0054561379365623}, {"id": 34, "seek": 23440, "start": 245.36, "end": 252.0, "text": " get the prices. We'll have a cron tab because we will have to do some stuff just regularly.", "tokens": [50912, 483, 264, 7901, 13, 492, 603, 362, 257, 941, 266, 4421, 570, 321, 486, 362, 281, 360, 512, 1507, 445, 11672, 13, 51244], "temperature": 0.0, "avg_logprob": -0.10702953338623047, "compression_ratio": 1.4690721649484537, "no_speech_prob": 0.0054561379365623}, {"id": 35, "seek": 23440, "start": 254.72, "end": 260.8, "text": " And let's keep that in mind. So this is the very first step. You don't have to read everything,", "tokens": [51380, 400, 718, 311, 1066, 300, 294, 1575, 13, 407, 341, 307, 264, 588, 700, 1823, 13, 509, 500, 380, 362, 281, 1401, 1203, 11, 51684], "temperature": 0.0, "avg_logprob": -0.10702953338623047, "compression_ratio": 1.4690721649484537, "no_speech_prob": 0.0054561379365623}, {"id": 36, "seek": 26080, "start": 260.8, "end": 266.64, "text": " but I'm just showing that we provide a cookie cutter template so you can quickly get up to", "tokens": [50364, 457, 286, 478, 445, 4099, 300, 321, 2893, 257, 14417, 25531, 12379, 370, 291, 393, 2661, 483, 493, 281, 50656], "temperature": 0.0, "avg_logprob": -0.11471918496218594, "compression_ratio": 1.517094017094017, "no_speech_prob": 0.005172571633011103}, {"id": 37, "seek": 26080, "start": 266.64, "end": 272.56, "text": " speed, have your own code structure. So you choose a name and a description and you say,", "tokens": [50656, 3073, 11, 362, 428, 1065, 3089, 3877, 13, 407, 291, 2826, 257, 1315, 293, 257, 3855, 293, 291, 584, 11, 50952], "temperature": 0.0, "avg_logprob": -0.11471918496218594, "compression_ratio": 1.517094017094017, "no_speech_prob": 0.005172571633011103}, {"id": 38, "seek": 26080, "start": 272.56, "end": 279.12, "text": " yeah, please give me the API blueprint. Blueprint is a word from the Flask system because flex", "tokens": [50952, 1338, 11, 1767, 976, 385, 264, 9362, 35868, 13, 2177, 29017, 307, 257, 1349, 490, 264, 3235, 3863, 1185, 570, 5896, 51280], "temperature": 0.0, "avg_logprob": -0.11471918496218594, "compression_ratio": 1.517094017094017, "no_speech_prob": 0.005172571633011103}, {"id": 39, "seek": 26080, "start": 279.12, "end": 284.32, "text": " measures is a Flask application. And you get some kind of boilerplate like this.", "tokens": [51280, 8000, 307, 257, 3235, 3863, 3861, 13, 400, 291, 483, 512, 733, 295, 39228, 37008, 411, 341, 13, 51540], "temperature": 0.0, "avg_logprob": -0.11471918496218594, "compression_ratio": 1.517094017094017, "no_speech_prob": 0.005172571633011103}, {"id": 40, "seek": 28432, "start": 285.28, "end": 291.04, "text": " And that's a boiler. This is the one endpoint we're doing here. What if we want to create a new", "tokens": [50412, 400, 300, 311, 257, 39228, 13, 639, 307, 264, 472, 35795, 321, 434, 884, 510, 13, 708, 498, 321, 528, 281, 1884, 257, 777, 50700], "temperature": 0.0, "avg_logprob": -0.12440660264756945, "compression_ratio": 1.6508620689655173, "no_speech_prob": 0.005184233654290438}, {"id": 41, "seek": 28432, "start": 291.04, "end": 298.4, "text": " customer for this project? This is a lot of code. This is basically the endpoint we wrote as an", "tokens": [50700, 5474, 337, 341, 1716, 30, 639, 307, 257, 688, 295, 3089, 13, 639, 307, 1936, 264, 35795, 321, 4114, 382, 364, 51068], "temperature": 0.0, "avg_logprob": -0.12440660264756945, "compression_ratio": 1.6508620689655173, "no_speech_prob": 0.005184233654290438}, {"id": 42, "seek": 28432, "start": 298.4, "end": 305.12, "text": " example. I'm not going to read everything. Basically, this is how you plug it in. It's going to be", "tokens": [51068, 1365, 13, 286, 478, 406, 516, 281, 1401, 1203, 13, 8537, 11, 341, 307, 577, 291, 5452, 309, 294, 13, 467, 311, 516, 281, 312, 51404], "temperature": 0.0, "avg_logprob": -0.12440660264756945, "compression_ratio": 1.6508620689655173, "no_speech_prob": 0.005184233654290438}, {"id": 43, "seek": 28432, "start": 305.12, "end": 310.15999999999997, "text": " plugged in flex measures and available as an endpoint. We're creating a user and an account.", "tokens": [51404, 25679, 294, 5896, 8000, 293, 2435, 382, 364, 35795, 13, 492, 434, 4084, 257, 4195, 293, 364, 2696, 13, 51656], "temperature": 0.0, "avg_logprob": -0.12440660264756945, "compression_ratio": 1.6508620689655173, "no_speech_prob": 0.005184233654290438}, {"id": 44, "seek": 31016, "start": 310.88000000000005, "end": 314.96000000000004, "text": " And maybe this is the most interesting. So this is basically your business objects.", "tokens": [50400, 400, 1310, 341, 307, 264, 881, 1880, 13, 407, 341, 307, 1936, 428, 1606, 6565, 13, 50604], "temperature": 0.0, "avg_logprob": -0.12037109542679, "compression_ratio": 1.5958333333333334, "no_speech_prob": 0.0024152391124516726}, {"id": 45, "seek": 31016, "start": 314.96000000000004, "end": 323.04, "text": " I will go a little deeper here. This is the same code roughly. So we're creating the boiler as an", "tokens": [50604, 286, 486, 352, 257, 707, 7731, 510, 13, 639, 307, 264, 912, 3089, 9810, 13, 407, 321, 434, 4084, 264, 39228, 382, 364, 51008], "temperature": 0.0, "avg_logprob": -0.12037109542679, "compression_ratio": 1.5958333333333334, "no_speech_prob": 0.0024152391124516726}, {"id": 46, "seek": 31016, "start": 323.04, "end": 329.44000000000005, "text": " asset. We're creating a couple of sensors. Here's two examples a bit bigger where we really define,", "tokens": [51008, 11999, 13, 492, 434, 4084, 257, 1916, 295, 14840, 13, 1692, 311, 732, 5110, 257, 857, 3801, 689, 321, 534, 6964, 11, 51328], "temperature": 0.0, "avg_logprob": -0.12037109542679, "compression_ratio": 1.5958333333333334, "no_speech_prob": 0.0024152391124516726}, {"id": 47, "seek": 31016, "start": 329.44000000000005, "end": 334.64000000000004, "text": " we tell flex measures how to handle this. What kind of units are we handling and the event resolution", "tokens": [51328, 321, 980, 5896, 8000, 577, 281, 4813, 341, 13, 708, 733, 295, 6815, 366, 321, 13175, 293, 264, 2280, 8669, 51588], "temperature": 0.0, "avg_logprob": -0.12037109542679, "compression_ratio": 1.5958333333333334, "no_speech_prob": 0.0024152391124516726}, {"id": 48, "seek": 33464, "start": 335.44, "end": 343.68, "text": " and so that flex measures know what to do with them when data arrives. Schedules have to be made.", "tokens": [50404, 293, 370, 300, 5896, 8000, 458, 437, 281, 360, 365, 552, 562, 1412, 20116, 13, 44926, 3473, 362, 281, 312, 1027, 13, 50816], "temperature": 0.0, "avg_logprob": -0.22597927000464463, "compression_ratio": 1.5980861244019138, "no_speech_prob": 0.0023321525659412146}, {"id": 49, "seek": 33464, "start": 345.12, "end": 351.84, "text": " And then if that happened, if somebody called this endpoint and your account was made and you", "tokens": [50888, 400, 550, 498, 300, 2011, 11, 498, 2618, 1219, 341, 35795, 293, 428, 2696, 390, 1027, 293, 291, 51224], "temperature": 0.0, "avg_logprob": -0.22597927000464463, "compression_ratio": 1.5980861244019138, "no_speech_prob": 0.0023321525659412146}, {"id": 50, "seek": 33464, "start": 352.71999999999997, "end": 354.88, "text": " would end up in the flex measures UI, you can see them here.", "tokens": [51268, 576, 917, 493, 294, 264, 5896, 8000, 15682, 11, 291, 393, 536, 552, 510, 13, 51376], "temperature": 0.0, "avg_logprob": -0.22597927000464463, "compression_ratio": 1.5980861244019138, "no_speech_prob": 0.0023321525659412146}, {"id": 51, "seek": 33464, "start": 357.28, "end": 361.2, "text": " Next step, let's say we measure the temperature locally. You have your own sensor", "tokens": [51496, 3087, 1823, 11, 718, 311, 584, 321, 3481, 264, 4292, 16143, 13, 509, 362, 428, 1065, 10200, 51692], "temperature": 0.0, "avg_logprob": -0.22597927000464463, "compression_ratio": 1.5980861244019138, "no_speech_prob": 0.0023321525659412146}, {"id": 52, "seek": 36120, "start": 362.15999999999997, "end": 364.96, "text": " and you want the temperature data to end up in flex measures as well.", "tokens": [50412, 293, 291, 528, 264, 4292, 1412, 281, 917, 493, 294, 5896, 8000, 382, 731, 13, 50552], "temperature": 0.0, "avg_logprob": -0.13490639176479605, "compression_ratio": 1.6515837104072397, "no_speech_prob": 0.00307273305952549}, {"id": 53, "seek": 36120, "start": 365.92, "end": 371.84, "text": " Then here's a small example how to use the flex measures client. Basically, it provides you with", "tokens": [50600, 1396, 510, 311, 257, 1359, 1365, 577, 281, 764, 264, 5896, 8000, 6423, 13, 8537, 11, 309, 6417, 291, 365, 50896], "temperature": 0.0, "avg_logprob": -0.13490639176479605, "compression_ratio": 1.6515837104072397, "no_speech_prob": 0.00307273305952549}, {"id": 54, "seek": 36120, "start": 371.84, "end": 379.03999999999996, "text": " some nice code to work with more easily, but it actually uses the flex measures API in the background.", "tokens": [50896, 512, 1481, 3089, 281, 589, 365, 544, 3612, 11, 457, 309, 767, 4960, 264, 5896, 8000, 9362, 294, 264, 3678, 13, 51256], "temperature": 0.0, "avg_logprob": -0.13490639176479605, "compression_ratio": 1.6515837104072397, "no_speech_prob": 0.00307273305952549}, {"id": 55, "seek": 36120, "start": 380.4, "end": 387.91999999999996, "text": " For fun, we actually had the temperature reading in Fahrenheit, which we say when we send it to", "tokens": [51324, 1171, 1019, 11, 321, 767, 632, 264, 4292, 3760, 294, 31199, 11, 597, 321, 584, 562, 321, 2845, 309, 281, 51700], "temperature": 0.0, "avg_logprob": -0.13490639176479605, "compression_ratio": 1.6515837104072397, "no_speech_prob": 0.00307273305952549}, {"id": 56, "seek": 38792, "start": 388.56, "end": 394.0, "text": " flex measures, the data is actually to be stored in Celsius and will automatically get it right.", "tokens": [50396, 5896, 8000, 11, 264, 1412, 307, 767, 281, 312, 12187, 294, 22658, 293, 486, 6772, 483, 309, 558, 13, 50668], "temperature": 0.0, "avg_logprob": -0.15406534623126594, "compression_ratio": 1.565891472868217, "no_speech_prob": 0.0012375533115118742}, {"id": 57, "seek": 38792, "start": 394.0, "end": 396.64000000000004, "text": " So this is where a lot of work goes, as you can imagine.", "tokens": [50668, 407, 341, 307, 689, 257, 688, 295, 589, 1709, 11, 382, 291, 393, 3811, 13, 50800], "temperature": 0.0, "avg_logprob": -0.15406534623126594, "compression_ratio": 1.565891472868217, "no_speech_prob": 0.0012375533115118742}, {"id": 58, "seek": 38792, "start": 399.28000000000003, "end": 402.8, "text": " But otherwise, this is just sending this reading. There's not much more.", "tokens": [50932, 583, 5911, 11, 341, 307, 445, 7750, 341, 3760, 13, 821, 311, 406, 709, 544, 13, 51108], "temperature": 0.0, "avg_logprob": -0.15406534623126594, "compression_ratio": 1.565891472868217, "no_speech_prob": 0.0012375533115118742}, {"id": 59, "seek": 38792, "start": 405.12, "end": 409.68, "text": " You'll do this regularly from your local script that runs on your Raspberry Pi,", "tokens": [51224, 509, 603, 360, 341, 11672, 490, 428, 2654, 5755, 300, 6676, 322, 428, 41154, 17741, 11, 51452], "temperature": 0.0, "avg_logprob": -0.15406534623126594, "compression_ratio": 1.565891472868217, "no_speech_prob": 0.0012375533115118742}, {"id": 60, "seek": 38792, "start": 409.68, "end": 417.20000000000005, "text": " whatever you're doing there locally. One more step. So there's some external information we need.", "tokens": [51452, 2035, 291, 434, 884, 456, 16143, 13, 1485, 544, 1823, 13, 407, 456, 311, 512, 8320, 1589, 321, 643, 13, 51828], "temperature": 0.0, "avg_logprob": -0.15406534623126594, "compression_ratio": 1.565891472868217, "no_speech_prob": 0.0012375533115118742}, {"id": 61, "seek": 41720, "start": 417.2, "end": 423.03999999999996, "text": " Temperature is a local reading from your local asset. Prices are a good example of information", "tokens": [50364, 34864, 1503, 307, 257, 2654, 3760, 490, 428, 2654, 11999, 13, 430, 24373, 366, 257, 665, 1365, 295, 1589, 50656], "temperature": 0.0, "avg_logprob": -0.14106454604711288, "compression_ratio": 1.5951219512195123, "no_speech_prob": 0.0033032752107828856}, {"id": 62, "seek": 41720, "start": 423.03999999999996, "end": 426.71999999999997, "text": " from some other third parties that just has to also be collected in flex measures.", "tokens": [50656, 490, 512, 661, 2636, 8265, 300, 445, 575, 281, 611, 312, 11087, 294, 5896, 8000, 13, 50840], "temperature": 0.0, "avg_logprob": -0.14106454604711288, "compression_ratio": 1.5951219512195123, "no_speech_prob": 0.0033032752107828856}, {"id": 63, "seek": 41720, "start": 428.15999999999997, "end": 434.48, "text": " One other example is weather forecasts. In this example, I'm showing that we actually wrote", "tokens": [50912, 1485, 661, 1365, 307, 5503, 49421, 13, 682, 341, 1365, 11, 286, 478, 4099, 300, 321, 767, 4114, 51228], "temperature": 0.0, "avg_logprob": -0.14106454604711288, "compression_ratio": 1.5951219512195123, "no_speech_prob": 0.0033032752107828856}, {"id": 64, "seek": 41720, "start": 435.12, "end": 442.08, "text": " a plugin for that. So we're cloning this plugin we wrote.", "tokens": [51260, 257, 23407, 337, 300, 13, 407, 321, 434, 596, 16638, 341, 23407, 321, 4114, 13, 51608], "temperature": 0.0, "avg_logprob": -0.14106454604711288, "compression_ratio": 1.5951219512195123, "no_speech_prob": 0.0033032752107828856}, {"id": 65, "seek": 44208, "start": 442.47999999999996, "end": 449.91999999999996, "text": " NSEU is the organization of European transmission system operators, and they provide a data platform", "tokens": [50384, 426, 5879, 52, 307, 264, 4475, 295, 6473, 11574, 1185, 19077, 11, 293, 436, 2893, 257, 1412, 3663, 50756], "temperature": 0.0, "avg_logprob": -0.29365137885598575, "compression_ratio": 1.5940170940170941, "no_speech_prob": 0.01303863525390625}, {"id": 66, "seek": 44208, "start": 449.91999999999996, "end": 456.96, "text": " so you can get various things like prices, but also just a head allocations for all the transmission zones.", "tokens": [50756, 370, 291, 393, 483, 3683, 721, 411, 7901, 11, 457, 611, 445, 257, 1378, 12660, 763, 337, 439, 264, 11574, 16025, 13, 51108], "temperature": 0.0, "avg_logprob": -0.29365137885598575, "compression_ratio": 1.5940170940170941, "no_speech_prob": 0.01303863525390625}, {"id": 67, "seek": 44208, "start": 458.64, "end": 463.68, "text": " And so we say we want the Dutch transmission zone. Please give me the prices for that.", "tokens": [51192, 400, 370, 321, 584, 321, 528, 264, 15719, 11574, 6668, 13, 2555, 976, 385, 264, 7901, 337, 300, 13, 51444], "temperature": 0.0, "avg_logprob": -0.29365137885598575, "compression_ratio": 1.5940170940170941, "no_speech_prob": 0.01303863525390625}, {"id": 68, "seek": 44208, "start": 464.96, "end": 468.08, "text": " I'll talk and we configure everything. And actually then this is the command.", "tokens": [51508, 286, 603, 751, 293, 321, 22162, 1203, 13, 400, 767, 550, 341, 307, 264, 5622, 13, 51664], "temperature": 0.0, "avg_logprob": -0.29365137885598575, "compression_ratio": 1.5940170940170941, "no_speech_prob": 0.01303863525390625}, {"id": 69, "seek": 46808, "start": 468.24, "end": 476.15999999999997, "text": " So through flex measures CLI, this plugin has registered a group of commands,", "tokens": [50372, 407, 807, 5896, 8000, 12855, 40, 11, 341, 23407, 575, 13968, 257, 1594, 295, 16901, 11, 50768], "temperature": 0.0, "avg_logprob": -0.22916782766148663, "compression_ratio": 1.4640883977900552, "no_speech_prob": 0.013433383777737617}, {"id": 70, "seek": 46808, "start": 477.28, "end": 483.28, "text": " for instance, to import a head prices. Also, all of this is public how we wrote the plugin.", "tokens": [50824, 337, 5197, 11, 281, 974, 257, 1378, 7901, 13, 2743, 11, 439, 295, 341, 307, 1908, 577, 321, 4114, 264, 23407, 13, 51124], "temperature": 0.0, "avg_logprob": -0.22916782766148663, "compression_ratio": 1.4640883977900552, "no_speech_prob": 0.013433383777737617}, {"id": 71, "seek": 46808, "start": 485.28, "end": 492.0, "text": " So if you call this regularly, let's say one time per day, you'll have the next day head prices", "tokens": [51224, 407, 498, 291, 818, 341, 11672, 11, 718, 311, 584, 472, 565, 680, 786, 11, 291, 603, 362, 264, 958, 786, 1378, 7901, 51560], "temperature": 0.0, "avg_logprob": -0.22916782766148663, "compression_ratio": 1.4640883977900552, "no_speech_prob": 0.013433383777737617}, {"id": 72, "seek": 49200, "start": 492.0, "end": 500.88, "text": " always in your system. Small visualization of one day of prices in the flex measures CLI.", "tokens": [50364, 1009, 294, 428, 1185, 13, 15287, 25801, 295, 472, 786, 295, 7901, 294, 264, 5896, 8000, 12855, 40, 13, 50808], "temperature": 0.0, "avg_logprob": -0.18672369718551635, "compression_ratio": 1.4485981308411215, "no_speech_prob": 0.0380798764526844}, {"id": 73, "seek": 49200, "start": 502.48, "end": 508.16, "text": " Excuse me. Okay, now I'm not sure how much time do I have.", "tokens": [50888, 11359, 385, 13, 1033, 11, 586, 286, 478, 406, 988, 577, 709, 565, 360, 286, 362, 13, 51172], "temperature": 0.0, "avg_logprob": -0.18672369718551635, "compression_ratio": 1.4485981308411215, "no_speech_prob": 0.0380798764526844}, {"id": 74, "seek": 49200, "start": 510.72, "end": 515.68, "text": " Eight minutes. All right, that's not too bad. But the main part now is you want to actually", "tokens": [51300, 17708, 2077, 13, 1057, 558, 11, 300, 311, 406, 886, 1578, 13, 583, 264, 2135, 644, 586, 307, 291, 528, 281, 767, 51548], "temperature": 0.0, "avg_logprob": -0.18672369718551635, "compression_ratio": 1.4485981308411215, "no_speech_prob": 0.0380798764526844}, {"id": 75, "seek": 49200, "start": 516.56, "end": 520.32, "text": " tell flex measures to give you an optimized schedule for your boiler.", "tokens": [51592, 980, 5896, 8000, 281, 976, 291, 364, 26941, 7567, 337, 428, 39228, 13, 51780], "temperature": 0.0, "avg_logprob": -0.18672369718551635, "compression_ratio": 1.4485981308411215, "no_speech_prob": 0.0380798764526844}, {"id": 76, "seek": 52200, "start": 522.72, "end": 528.08, "text": " And here I'll show, I could do that via the flex measures client as well, but I'll just show", "tokens": [50400, 400, 510, 286, 603, 855, 11, 286, 727, 360, 300, 5766, 264, 5896, 8000, 6423, 382, 731, 11, 457, 286, 603, 445, 855, 50668], "temperature": 0.0, "avg_logprob": -0.14099836349487305, "compression_ratio": 1.4627659574468086, "no_speech_prob": 0.004936464596539736}, {"id": 77, "seek": 52200, "start": 528.08, "end": 534.64, "text": " how to use the API directly. This is not so interesting, of course, you have to have an", "tokens": [50668, 577, 281, 764, 264, 9362, 3838, 13, 639, 307, 406, 370, 1880, 11, 295, 1164, 11, 291, 362, 281, 362, 364, 50996], "temperature": 0.0, "avg_logprob": -0.14099836349487305, "compression_ratio": 1.4627659574468086, "no_speech_prob": 0.004936464596539736}, {"id": 78, "seek": 52200, "start": 534.64, "end": 544.0, "text": " authentication token. But I have to spend a bit more time here. A lot of time we spend when we", "tokens": [50996, 26643, 14862, 13, 583, 286, 362, 281, 3496, 257, 857, 544, 565, 510, 13, 316, 688, 295, 565, 321, 3496, 562, 321, 51464], "temperature": 0.0, "avg_logprob": -0.14099836349487305, "compression_ratio": 1.4627659574468086, "no_speech_prob": 0.004936464596539736}, {"id": 79, "seek": 54400, "start": 544.0, "end": 551.52, "text": " made flex measures is how you configure the problem. How do you tell flex measures", "tokens": [50364, 1027, 5896, 8000, 307, 577, 291, 22162, 264, 1154, 13, 1012, 360, 291, 980, 5896, 8000, 50740], "temperature": 0.0, "avg_logprob": -0.13868256409962973, "compression_ratio": 1.7875647668393781, "no_speech_prob": 0.03494643792510033}, {"id": 80, "seek": 54400, "start": 552.64, "end": 557.2, "text": " the constraints of the problem in the back flex measures will actually take your information", "tokens": [50796, 264, 18491, 295, 264, 1154, 294, 264, 646, 5896, 8000, 486, 767, 747, 428, 1589, 51024], "temperature": 0.0, "avg_logprob": -0.13868256409962973, "compression_ratio": 1.7875647668393781, "no_speech_prob": 0.03494643792510033}, {"id": 81, "seek": 54400, "start": 557.2, "end": 562.16, "text": " about your setup and your problem. Basically, you could call that business rules,", "tokens": [51024, 466, 428, 8657, 293, 428, 1154, 13, 8537, 11, 291, 727, 818, 300, 1606, 4474, 11, 51272], "temperature": 0.0, "avg_logprob": -0.13868256409962973, "compression_ratio": 1.7875647668393781, "no_speech_prob": 0.03494643792510033}, {"id": 82, "seek": 54400, "start": 563.52, "end": 569.6, "text": " and really translate that dynamically into a linear program. So flex measures contains,", "tokens": [51340, 293, 534, 13799, 300, 43492, 666, 257, 8213, 1461, 13, 407, 5896, 8000, 8306, 11, 51644], "temperature": 0.0, "avg_logprob": -0.13868256409962973, "compression_ratio": 1.7875647668393781, "no_speech_prob": 0.03494643792510033}, {"id": 83, "seek": 56960, "start": 570.5600000000001, "end": 578.24, "text": " I think three different algorithms, basically, we have one that's focusing on storage based", "tokens": [50412, 286, 519, 1045, 819, 14642, 11, 1936, 11, 321, 362, 472, 300, 311, 8416, 322, 6725, 2361, 50796], "temperature": 0.0, "avg_logprob": -0.15500857321064124, "compression_ratio": 1.5854700854700854, "no_speech_prob": 0.002157833892852068}, {"id": 84, "seek": 56960, "start": 578.24, "end": 586.16, "text": " problems. And that's what we also use for heat, heat batteries, we call them. We have one for,", "tokens": [50796, 2740, 13, 400, 300, 311, 437, 321, 611, 764, 337, 3738, 11, 3738, 13070, 11, 321, 818, 552, 13, 492, 362, 472, 337, 11, 51192], "temperature": 0.0, "avg_logprob": -0.15500857321064124, "compression_ratio": 1.5854700854700854, "no_speech_prob": 0.002157833892852068}, {"id": 85, "seek": 56960, "start": 586.16, "end": 592.0, "text": " if you just want to allocate processes. But it's a very important part for developing a new", "tokens": [51192, 498, 291, 445, 528, 281, 35713, 7555, 13, 583, 309, 311, 257, 588, 1021, 644, 337, 6416, 257, 777, 51484], "temperature": 0.0, "avg_logprob": -0.15500857321064124, "compression_ratio": 1.5854700854700854, "no_speech_prob": 0.002157833892852068}, {"id": 86, "seek": 56960, "start": 592.0, "end": 598.08, "text": " application that you can tell the flex measures server, this is how I want you to treat this", "tokens": [51484, 3861, 300, 291, 393, 980, 264, 5896, 8000, 7154, 11, 341, 307, 577, 286, 528, 291, 281, 2387, 341, 51788], "temperature": 0.0, "avg_logprob": -0.15500857321064124, "compression_ratio": 1.5854700854700854, "no_speech_prob": 0.002157833892852068}, {"id": 87, "seek": 59808, "start": 598.08, "end": 602.48, "text": " problem. Here's the constraint you don't know about, or here's a local thing you don't know about.", "tokens": [50364, 1154, 13, 1692, 311, 264, 25534, 291, 500, 380, 458, 466, 11, 420, 510, 311, 257, 2654, 551, 291, 500, 380, 458, 466, 13, 50584], "temperature": 0.0, "avg_logprob": -0.12836945658982402, "compression_ratio": 1.6741071428571428, "no_speech_prob": 0.016443518921732903}, {"id": 88, "seek": 59808, "start": 603.2800000000001, "end": 610.1600000000001, "text": " And that's where we're working on two things, the flex model and flex context. So flex context", "tokens": [50624, 400, 300, 311, 689, 321, 434, 1364, 322, 732, 721, 11, 264, 5896, 2316, 293, 5896, 4319, 13, 407, 5896, 4319, 50968], "temperature": 0.0, "avg_logprob": -0.12836945658982402, "compression_ratio": 1.6741071428571428, "no_speech_prob": 0.016443518921732903}, {"id": 89, "seek": 59808, "start": 610.1600000000001, "end": 616.72, "text": " would be, well, these are the prices that are relevant. We also have a project where we don't", "tokens": [50968, 576, 312, 11, 731, 11, 613, 366, 264, 7901, 300, 366, 7340, 13, 492, 611, 362, 257, 1716, 689, 321, 500, 380, 51296], "temperature": 0.0, "avg_logprob": -0.12836945658982402, "compression_ratio": 1.6741071428571428, "no_speech_prob": 0.016443518921732903}, {"id": 90, "seek": 59808, "start": 616.72, "end": 622.1600000000001, "text": " use prices, but we use the CO2 signal, the CO2 content of the grid that is anticipated.", "tokens": [51296, 764, 7901, 11, 457, 321, 764, 264, 3002, 17, 6358, 11, 264, 3002, 17, 2701, 295, 264, 10748, 300, 307, 23267, 13, 51568], "temperature": 0.0, "avg_logprob": -0.12836945658982402, "compression_ratio": 1.6741071428571428, "no_speech_prob": 0.016443518921732903}, {"id": 91, "seek": 62216, "start": 623.12, "end": 627.52, "text": " But the flex model is a bit more detailed. So this is not all the things you can do.", "tokens": [50412, 583, 264, 5896, 2316, 307, 257, 857, 544, 9942, 13, 407, 341, 307, 406, 439, 264, 721, 291, 393, 360, 13, 50632], "temperature": 0.0, "avg_logprob": -0.13990538318951926, "compression_ratio": 1.5954545454545455, "no_speech_prob": 0.009924123995006084}, {"id": 92, "seek": 62216, "start": 628.64, "end": 634.9599999999999, "text": " But basically, wishing, well, the state of charge of this heat battery is this many kilowatt", "tokens": [50688, 583, 1936, 11, 30049, 11, 731, 11, 264, 1785, 295, 4602, 295, 341, 3738, 5809, 307, 341, 867, 41295, 1591, 51004], "temperature": 0.0, "avg_logprob": -0.13990538318951926, "compression_ratio": 1.5954545454545455, "no_speech_prob": 0.009924123995006084}, {"id": 93, "seek": 62216, "start": 634.9599999999999, "end": 641.76, "text": " hours. So that's local knowledge you have. Here's some constraints. I can't go under this.", "tokens": [51004, 2496, 13, 407, 300, 311, 2654, 3601, 291, 362, 13, 1692, 311, 512, 18491, 13, 286, 393, 380, 352, 833, 341, 13, 51344], "temperature": 0.0, "avg_logprob": -0.13990538318951926, "compression_ratio": 1.5954545454545455, "no_speech_prob": 0.009924123995006084}, {"id": 94, "seek": 62216, "start": 642.4, "end": 648.0799999999999, "text": " We don't want to go under this. And also, here's a target for you. In the morning,", "tokens": [51376, 492, 500, 380, 528, 281, 352, 833, 341, 13, 400, 611, 11, 510, 311, 257, 3779, 337, 291, 13, 682, 264, 2446, 11, 51660], "temperature": 0.0, "avg_logprob": -0.13990538318951926, "compression_ratio": 1.5954545454545455, "no_speech_prob": 0.009924123995006084}, {"id": 95, "seek": 64808, "start": 648.88, "end": 655.2800000000001, "text": " I need to have this much energy content in my battery. I think this could also be a percentage.", "tokens": [50404, 286, 643, 281, 362, 341, 709, 2281, 2701, 294, 452, 5809, 13, 286, 519, 341, 727, 611, 312, 257, 9668, 13, 50724], "temperature": 0.0, "avg_logprob": -0.11430873292865175, "compression_ratio": 1.4516129032258065, "no_speech_prob": 0.013413920067250729}, {"id": 96, "seek": 64808, "start": 656.64, "end": 662.48, "text": " We're pretty flexible there. Some other constraints. You can see how these translate", "tokens": [50792, 492, 434, 1238, 11358, 456, 13, 2188, 661, 18491, 13, 509, 393, 536, 577, 613, 13799, 51084], "temperature": 0.0, "avg_logprob": -0.11430873292865175, "compression_ratio": 1.4516129032258065, "no_speech_prob": 0.013413920067250729}, {"id": 97, "seek": 64808, "start": 662.48, "end": 670.96, "text": " actually into constraints of a problem. And then you call our API to say, well, for this,", "tokens": [51084, 767, 666, 18491, 295, 257, 1154, 13, 400, 550, 291, 818, 527, 9362, 281, 584, 11, 731, 11, 337, 341, 11, 51508], "temperature": 0.0, "avg_logprob": -0.11430873292865175, "compression_ratio": 1.4516129032258065, "no_speech_prob": 0.013413920067250729}, {"id": 98, "seek": 67096, "start": 671.76, "end": 677.76, "text": " the fill rate that I want a schedule for that, please start. And that will actually trigger", "tokens": [50404, 264, 2836, 3314, 300, 286, 528, 257, 7567, 337, 300, 11, 1767, 722, 13, 400, 300, 486, 767, 7875, 50704], "temperature": 0.0, "avg_logprob": -0.16816955737853317, "compression_ratio": 1.7302325581395348, "no_speech_prob": 0.03632502630352974}, {"id": 99, "seek": 67096, "start": 678.48, "end": 686.4000000000001, "text": " a scheduling job. And then flex motors will usually pass this on to a worker. So we, in our", "tokens": [50740, 257, 29055, 1691, 13, 400, 550, 5896, 25035, 486, 2673, 1320, 341, 322, 281, 257, 11346, 13, 407, 321, 11, 294, 527, 51136], "temperature": 0.0, "avg_logprob": -0.16816955737853317, "compression_ratio": 1.7302325581395348, "no_speech_prob": 0.03632502630352974}, {"id": 100, "seek": 67096, "start": 686.4000000000001, "end": 691.84, "text": " implementations, we have a web worker and computation workers that will handle those. And then you", "tokens": [51136, 4445, 763, 11, 321, 362, 257, 3670, 11346, 293, 24903, 5600, 300, 486, 4813, 729, 13, 400, 550, 291, 51408], "temperature": 0.0, "avg_logprob": -0.16816955737853317, "compression_ratio": 1.7302325581395348, "no_speech_prob": 0.03632502630352974}, {"id": 101, "seek": 67096, "start": 691.84, "end": 697.0400000000001, "text": " can call this, get endpoint to check if your computation is ready. It will usually not be", "tokens": [51408, 393, 818, 341, 11, 483, 35795, 281, 1520, 498, 428, 24903, 307, 1919, 13, 467, 486, 2673, 406, 312, 51668], "temperature": 0.0, "avg_logprob": -0.16816955737853317, "compression_ratio": 1.7302325581395348, "no_speech_prob": 0.03632502630352974}, {"id": 102, "seek": 69704, "start": 697.04, "end": 703.92, "text": " ready after three seconds, but soon after. And then, yeah, you get your values here.", "tokens": [50364, 1919, 934, 1045, 3949, 11, 457, 2321, 934, 13, 400, 550, 11, 1338, 11, 291, 483, 428, 4190, 510, 13, 50708], "temperature": 0.0, "avg_logprob": -0.10886396964391072, "compression_ratio": 1.6255506607929515, "no_speech_prob": 0.012253654189407825}, {"id": 103, "seek": 69704, "start": 705.52, "end": 710.64, "text": " So then you can implement these settings locally. You can, let's say you ask for a schedule for", "tokens": [50788, 407, 550, 291, 393, 4445, 613, 6257, 16143, 13, 509, 393, 11, 718, 311, 584, 291, 1029, 337, 257, 7567, 337, 51044], "temperature": 0.0, "avg_logprob": -0.10886396964391072, "compression_ratio": 1.6255506607929515, "no_speech_prob": 0.012253654189407825}, {"id": 104, "seek": 69704, "start": 710.64, "end": 716.24, "text": " 12 hours, then your local gateway has the plan for 12 hours. If there's anything that changes", "tokens": [51044, 2272, 2496, 11, 550, 428, 2654, 28532, 575, 264, 1393, 337, 2272, 2496, 13, 759, 456, 311, 1340, 300, 2962, 51324], "temperature": 0.0, "avg_logprob": -0.10886396964391072, "compression_ratio": 1.6255506607929515, "no_speech_prob": 0.012253654189407825}, {"id": 105, "seek": 69704, "start": 718.24, "end": 724.3199999999999, "text": " on the ground, you just ask for a new one. You'll update as we go. So that's general behavior.", "tokens": [51424, 322, 264, 2727, 11, 291, 445, 1029, 337, 257, 777, 472, 13, 509, 603, 5623, 382, 321, 352, 13, 407, 300, 311, 2674, 5223, 13, 51728], "temperature": 0.0, "avg_logprob": -0.10886396964391072, "compression_ratio": 1.6255506607929515, "no_speech_prob": 0.012253654189407825}, {"id": 106, "seek": 72432, "start": 725.0400000000001, "end": 733.7600000000001, "text": " I'm almost done with, with a, you know, two of the force here. One thing we want to maybe do is", "tokens": [50400, 286, 478, 1920, 1096, 365, 11, 365, 257, 11, 291, 458, 11, 732, 295, 264, 3464, 510, 13, 1485, 551, 321, 528, 281, 1310, 360, 307, 50836], "temperature": 0.0, "avg_logprob": -0.1772686510669942, "compression_ratio": 1.6266094420600858, "no_speech_prob": 0.006323505192995071}, {"id": 107, "seek": 72432, "start": 733.7600000000001, "end": 741.2800000000001, "text": " in flex measures have a nice dashboard that has the most crucial data on top of each other for", "tokens": [50836, 294, 5896, 8000, 362, 257, 1481, 18342, 300, 575, 264, 881, 11462, 1412, 322, 1192, 295, 1184, 661, 337, 51212], "temperature": 0.0, "avg_logprob": -0.1772686510669942, "compression_ratio": 1.6266094420600858, "no_speech_prob": 0.006323505192995071}, {"id": 108, "seek": 72432, "start": 741.2800000000001, "end": 748.72, "text": " some inspection. And then, well, you can actually put that on the boiler asset. And then you,", "tokens": [51212, 512, 22085, 13, 400, 550, 11, 731, 11, 291, 393, 767, 829, 300, 322, 264, 39228, 11999, 13, 400, 550, 291, 11, 51584], "temperature": 0.0, "avg_logprob": -0.1772686510669942, "compression_ratio": 1.6266094420600858, "no_speech_prob": 0.006323505192995071}, {"id": 109, "seek": 72432, "start": 749.36, "end": 753.5200000000001, "text": " in flex measures, you have these nicely stacked, right? You want to see what you've been using", "tokens": [51616, 294, 5896, 8000, 11, 291, 362, 613, 9594, 28867, 11, 558, 30, 509, 528, 281, 536, 437, 291, 600, 668, 1228, 51824], "temperature": 0.0, "avg_logprob": -0.1772686510669942, "compression_ratio": 1.6266094420600858, "no_speech_prob": 0.006323505192995071}, {"id": 110, "seek": 75352, "start": 753.52, "end": 758.64, "text": " for optimization on top. Although this comes from a different asset. This is something for everybody.", "tokens": [50364, 337, 19618, 322, 1192, 13, 5780, 341, 1487, 490, 257, 819, 11999, 13, 639, 307, 746, 337, 2201, 13, 50620], "temperature": 0.0, "avg_logprob": -0.0930201666695731, "compression_ratio": 1.6, "no_speech_prob": 0.00605470547452569}, {"id": 111, "seek": 75352, "start": 759.68, "end": 765.4399999999999, "text": " All the assets can use this. And we use, as you remember, we had like four sensors or so that", "tokens": [50672, 1057, 264, 9769, 393, 764, 341, 13, 400, 321, 764, 11, 382, 291, 1604, 11, 321, 632, 411, 1451, 14840, 420, 370, 300, 50960], "temperature": 0.0, "avg_logprob": -0.0930201666695731, "compression_ratio": 1.6, "no_speech_prob": 0.00605470547452569}, {"id": 112, "seek": 75352, "start": 765.4399999999999, "end": 770.64, "text": " are relevant, but we just decided these two other ones we want to see. So we can easily see that", "tokens": [50960, 366, 7340, 11, 457, 321, 445, 3047, 613, 732, 661, 2306, 321, 528, 281, 536, 13, 407, 321, 393, 3612, 536, 300, 51220], "temperature": 0.0, "avg_logprob": -0.0930201666695731, "compression_ratio": 1.6, "no_speech_prob": 0.00605470547452569}, {"id": 113, "seek": 75352, "start": 773.84, "end": 780.72, "text": " in a period of low prices, flex measures has tried to, you know, fill the, fill the boiler at those", "tokens": [51380, 294, 257, 2896, 295, 2295, 7901, 11, 5896, 8000, 575, 3031, 281, 11, 291, 458, 11, 2836, 264, 11, 2836, 264, 39228, 412, 729, 51724], "temperature": 0.0, "avg_logprob": -0.0930201666695731, "compression_ratio": 1.6, "no_speech_prob": 0.00605470547452569}, {"id": 114, "seek": 78072, "start": 780.72, "end": 792.32, "text": " times. Some signal here. I'll skip over this a bit because, yeah, I originally had a 25 minutes idea", "tokens": [50364, 1413, 13, 2188, 6358, 510, 13, 286, 603, 10023, 670, 341, 257, 857, 570, 11, 1338, 11, 286, 7993, 632, 257, 3552, 2077, 1558, 50944], "temperature": 0.0, "avg_logprob": -0.2007519006729126, "compression_ratio": 1.4922279792746114, "no_speech_prob": 0.007639118004590273}, {"id": 115, "seek": 78072, "start": 792.32, "end": 800.5600000000001, "text": " about this. Just as very quickly, we also noticed it's very important to also do some reporting.", "tokens": [50944, 466, 341, 13, 1449, 382, 588, 2661, 11, 321, 611, 5694, 309, 311, 588, 1021, 281, 611, 360, 512, 10031, 13, 51356], "temperature": 0.0, "avg_logprob": -0.2007519006729126, "compression_ratio": 1.4922279792746114, "no_speech_prob": 0.007639118004590273}, {"id": 116, "seek": 78072, "start": 801.6, "end": 805.12, "text": " In flex measures, give some logic about that, that you combine some sensor data so you get", "tokens": [51408, 682, 5896, 8000, 11, 976, 512, 9952, 466, 300, 11, 300, 291, 10432, 512, 10200, 1412, 370, 291, 483, 51584], "temperature": 0.0, "avg_logprob": -0.2007519006729126, "compression_ratio": 1.4922279792746114, "no_speech_prob": 0.007639118004590273}, {"id": 117, "seek": 80512, "start": 806.08, "end": 810.64, "text": " the outputs of what happened, for instance, like costs. You know, that's very important. Sorry.", "tokens": [50412, 264, 23930, 295, 437, 2011, 11, 337, 5197, 11, 411, 5497, 13, 509, 458, 11, 300, 311, 588, 1021, 13, 4919, 13, 50640], "temperature": 0.0, "avg_logprob": -0.1785066348990214, "compression_ratio": 1.570281124497992, "no_speech_prob": 0.022265423089265823}, {"id": 118, "seek": 80512, "start": 812.0, "end": 817.44, "text": " And that can become a C like a minus well that you regularly say, okay, now the day has happened,", "tokens": [50708, 400, 300, 393, 1813, 257, 383, 411, 257, 3175, 731, 300, 291, 11672, 584, 11, 1392, 11, 586, 264, 786, 575, 2011, 11, 50980], "temperature": 0.0, "avg_logprob": -0.1785066348990214, "compression_ratio": 1.570281124497992, "no_speech_prob": 0.022265423089265823}, {"id": 119, "seek": 80512, "start": 817.44, "end": 824.16, "text": " we optimize as we could. Let's calculate how much energy costs we had here. So combine just the", "tokens": [50980, 321, 19719, 382, 321, 727, 13, 961, 311, 8873, 577, 709, 2281, 5497, 321, 632, 510, 13, 407, 10432, 445, 264, 51316], "temperature": 0.0, "avg_logprob": -0.1785066348990214, "compression_ratio": 1.570281124497992, "no_speech_prob": 0.022265423089265823}, {"id": 120, "seek": 80512, "start": 824.16, "end": 830.72, "text": " prices and the fill rate, which happened. But we also saw already that's that's many more interesting", "tokens": [51316, 7901, 293, 264, 2836, 3314, 11, 597, 2011, 13, 583, 321, 611, 1866, 1217, 300, 311, 300, 311, 867, 544, 1880, 51644], "temperature": 0.0, "avg_logprob": -0.1785066348990214, "compression_ratio": 1.570281124497992, "no_speech_prob": 0.022265423089265823}, {"id": 121, "seek": 83072, "start": 831.6, "end": 838.48, "text": " computations that people want. So this is a very simple multiplication. But we've made a pretty", "tokens": [50408, 2807, 763, 300, 561, 528, 13, 407, 341, 307, 257, 588, 2199, 27290, 13, 583, 321, 600, 1027, 257, 1238, 50752], "temperature": 0.0, "avg_logprob": -0.127264439374551, "compression_ratio": 1.5805084745762712, "no_speech_prob": 0.014886461198329926}, {"id": 122, "seek": 83072, "start": 838.48, "end": 844.64, "text": " complicated architecture so you can actually have a lot of bring a couple sensors together", "tokens": [50752, 6179, 9482, 370, 291, 393, 767, 362, 257, 688, 295, 1565, 257, 1916, 14840, 1214, 51060], "temperature": 0.0, "avg_logprob": -0.127264439374551, "compression_ratio": 1.5805084745762712, "no_speech_prob": 0.014886461198329926}, {"id": 123, "seek": 83072, "start": 845.44, "end": 850.48, "text": " for a new result that even can be used further in your next optimization or so. It's a very", "tokens": [51100, 337, 257, 777, 1874, 300, 754, 393, 312, 1143, 3052, 294, 428, 958, 19618, 420, 370, 13, 467, 311, 257, 588, 51352], "temperature": 0.0, "avg_logprob": -0.127264439374551, "compression_ratio": 1.5805084745762712, "no_speech_prob": 0.014886461198329926}, {"id": 124, "seek": 83072, "start": 850.48, "end": 859.2, "text": " flexible system we've built here. And this is the project website. From there, you'll find the", "tokens": [51352, 11358, 1185, 321, 600, 3094, 510, 13, 400, 341, 307, 264, 1716, 3144, 13, 3358, 456, 11, 291, 603, 915, 264, 51788], "temperature": 0.0, "avg_logprob": -0.127264439374551, "compression_ratio": 1.5805084745762712, "no_speech_prob": 0.014886461198329926}, {"id": 125, "seek": 85920, "start": 859.2, "end": 866.88, "text": " the GitHub, you find the read the docs, you'll find more information like I was interviewed for", "tokens": [50364, 264, 23331, 11, 291, 915, 264, 1401, 264, 45623, 11, 291, 603, 915, 544, 1589, 411, 286, 390, 19770, 337, 50748], "temperature": 0.0, "avg_logprob": -0.17679780179804022, "compression_ratio": 1.559670781893004, "no_speech_prob": 0.0153797073289752}, {"id": 126, "seek": 85920, "start": 866.88, "end": 872.0, "text": " Python podcast where maybe I go into more detail. The mailing list contact, everything's there.", "tokens": [50748, 15329, 7367, 689, 1310, 286, 352, 666, 544, 2607, 13, 440, 41612, 1329, 3385, 11, 1203, 311, 456, 13, 51004], "temperature": 0.0, "avg_logprob": -0.17679780179804022, "compression_ratio": 1.559670781893004, "no_speech_prob": 0.0153797073289752}, {"id": 127, "seek": 85920, "start": 873.9200000000001, "end": 878.8000000000001, "text": " You can also just write me directly, of course, if you're interested in doing something yourself", "tokens": [51100, 509, 393, 611, 445, 2464, 385, 3838, 11, 295, 1164, 11, 498, 291, 434, 3102, 294, 884, 746, 1803, 51344], "temperature": 0.0, "avg_logprob": -0.17679780179804022, "compression_ratio": 1.559670781893004, "no_speech_prob": 0.0153797073289752}, {"id": 128, "seek": 85920, "start": 878.8000000000001, "end": 885.44, "text": " and joining our TSC, the technical steering committee, everybody's welcome. And that's it.", "tokens": [51344, 293, 5549, 527, 314, 20839, 11, 264, 6191, 14823, 7482, 11, 2201, 311, 2928, 13, 400, 300, 311, 309, 13, 51676], "temperature": 0.0, "avg_logprob": -0.17679780179804022, "compression_ratio": 1.559670781893004, "no_speech_prob": 0.0153797073289752}, {"id": 129, "seek": 88544, "start": 885.44, "end": 889.7600000000001, "text": " Yeah, there's lots of things to do, of course, I've touched upon a couple things,", "tokens": [50364, 865, 11, 456, 311, 3195, 295, 721, 281, 360, 11, 295, 1164, 11, 286, 600, 9828, 3564, 257, 1916, 721, 11, 50580], "temperature": 0.0, "avg_logprob": -0.2244569939303111, "compression_ratio": 1.5288461538461537, "no_speech_prob": 0.009409802034497261}, {"id": 130, "seek": 88544, "start": 889.7600000000001, "end": 896.32, "text": " applications like vehicle to grid or smart heating and industry. But the roadway is still,", "tokens": [50580, 5821, 411, 5864, 281, 10748, 420, 4069, 15082, 293, 3518, 13, 583, 264, 3060, 676, 307, 920, 11, 50908], "temperature": 0.0, "avg_logprob": -0.2244569939303111, "compression_ratio": 1.5288461538461537, "no_speech_prob": 0.009409802034497261}, {"id": 131, "seek": 88544, "start": 896.32, "end": 901.12, "text": " of course, filled. There's so so much things in the energy behind the meter and a bit above to", "tokens": [50908, 295, 1164, 11, 6412, 13, 821, 311, 370, 370, 709, 721, 294, 264, 2281, 2261, 264, 9255, 293, 257, 857, 3673, 281, 51148], "temperature": 0.0, "avg_logprob": -0.2244569939303111, "compression_ratio": 1.5288461538461537, "no_speech_prob": 0.009409802034497261}, {"id": 132, "seek": 88544, "start": 901.7600000000001, "end": 909.6800000000001, "text": " optimize. Thanks. We have time for question, then.", "tokens": [51180, 19719, 13, 2561, 13, 492, 362, 565, 337, 1168, 11, 550, 13, 51576], "temperature": 0.0, "avg_logprob": -0.2244569939303111, "compression_ratio": 1.5288461538461537, "no_speech_prob": 0.009409802034497261}, {"id": 133, "seek": 90968, "start": 910.0799999999999, "end": 914.0, "text": " If someone wants to ask one question,", "tokens": [50384, 759, 1580, 2738, 281, 1029, 472, 1168, 11, 50580], "temperature": 0.0, "avg_logprob": -0.23037890384071752, "compression_ratio": 1.4835164835164836, "no_speech_prob": 0.010705968365073204}, {"id": 134, "seek": 90968, "start": 918.64, "end": 924.2399999999999, "text": " you said that you create a linear program. And what solver do you use to solve this program?", "tokens": [50812, 291, 848, 300, 291, 1884, 257, 8213, 1461, 13, 400, 437, 1404, 331, 360, 291, 764, 281, 5039, 341, 1461, 30, 51092], "temperature": 0.0, "avg_logprob": -0.23037890384071752, "compression_ratio": 1.4835164835164836, "no_speech_prob": 0.010705968365073204}, {"id": 135, "seek": 90968, "start": 927.68, "end": 931.76, "text": " What kind of solver? Yeah, we have we work with two solvers now.", "tokens": [51264, 708, 733, 295, 1404, 331, 30, 865, 11, 321, 362, 321, 589, 365, 732, 1404, 840, 586, 13, 51468], "temperature": 0.0, "avg_logprob": -0.23037890384071752, "compression_ratio": 1.4835164835164836, "no_speech_prob": 0.010705968365073204}, {"id": 136, "seek": 90968, "start": 933.8399999999999, "end": 937.92, "text": " You could, of course, also use Cplex, but we've used two open source ones.", "tokens": [51572, 509, 727, 11, 295, 1164, 11, 611, 764, 383, 18945, 11, 457, 321, 600, 1143, 732, 1269, 4009, 2306, 13, 51776], "temperature": 0.0, "avg_logprob": -0.23037890384071752, "compression_ratio": 1.4835164835164836, "no_speech_prob": 0.010705968365073204}, {"id": 137, "seek": 93968, "start": 940.0799999999999, "end": 945.04, "text": " All right, now they don't come to my head. Sorry.", "tokens": [50384, 1057, 558, 11, 586, 436, 500, 380, 808, 281, 452, 1378, 13, 4919, 13, 50632], "temperature": 0.0, "avg_logprob": -0.24149217276737608, "compression_ratio": 1.5373831775700935, "no_speech_prob": 0.006233862601220608}, {"id": 138, "seek": 93968, "start": 947.68, "end": 952.16, "text": " Hi. Yeah, we switched to that one. And we had a different one before that are both possible.", "tokens": [50764, 2421, 13, 865, 11, 321, 16858, 281, 300, 472, 13, 400, 321, 632, 257, 819, 472, 949, 300, 366, 1293, 1944, 13, 50988], "temperature": 0.0, "avg_logprob": -0.24149217276737608, "compression_ratio": 1.5373831775700935, "no_speech_prob": 0.006233862601220608}, {"id": 139, "seek": 93968, "start": 952.16, "end": 956.88, "text": " So you can just those are shipped with a Docker image even so you can just configure that which", "tokens": [50988, 407, 291, 393, 445, 729, 366, 25312, 365, 257, 33772, 3256, 754, 370, 291, 393, 445, 22162, 300, 597, 51224], "temperature": 0.0, "avg_logprob": -0.24149217276737608, "compression_ratio": 1.5373831775700935, "no_speech_prob": 0.006233862601220608}, {"id": 140, "seek": 93968, "start": 956.88, "end": 963.04, "text": " one you want to use. But you can also we use pyomo as a representation for the problem. So", "tokens": [51224, 472, 291, 528, 281, 764, 13, 583, 291, 393, 611, 321, 764, 10664, 13395, 382, 257, 10290, 337, 264, 1154, 13, 407, 51532], "temperature": 0.0, "avg_logprob": -0.24149217276737608, "compression_ratio": 1.5373831775700935, "no_speech_prob": 0.006233862601220608}, {"id": 141, "seek": 96304, "start": 963.12, "end": 966.88, "text": " everything that works with pyomo, which is you can use that as well.", "tokens": [50368, 1203, 300, 1985, 365, 10664, 13395, 11, 597, 307, 291, 393, 764, 300, 382, 731, 13, 50556], "temperature": 0.0, "avg_logprob": -0.1701063743004432, "compression_ratio": 1.1012658227848102, "no_speech_prob": 0.004190338309854269}, {"id": 142, "seek": 96304, "start": 969.28, "end": 973.1999999999999, "text": " Thank you so much.", "tokens": [50676, 1044, 291, 370, 709, 13, 50872], "temperature": 0.0, "avg_logprob": -0.1701063743004432, "compression_ratio": 1.1012658227848102, "no_speech_prob": 0.004190338309854269}], "language": "en"}