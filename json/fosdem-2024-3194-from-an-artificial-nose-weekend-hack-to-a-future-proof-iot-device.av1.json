{"text": " That was helpful. Thank you. Thanks for joining. This is going to be a talk about a fun project that I started, I think it's almost four years now, so I feel like I'm sort of milking the idea, but it's pretty cool. It's back in 2019, I guess. I ended up building an artificial nose using some cool tech, and I'm going to talk a bit about the tech behind it and how I ended up moving the project from a really, really dirty weekend hack into something that's hopefully more future-proof and using cool things like Zephyr. So, a few words about myself. I'm a Benjamin. I'm based in France for the past year, almost to the day, actually. I've been working as a developer advocate for the Zephyr project at the Linux Foundation, and I do many things, including as a good French person, I guess, baking bread. And I don't know about you guys, but I've been trying to perfect my bread recipe for probably over 30 years. Like, I'm still not really happy about the way it turns out. Like, it's a bit random, right? And so, back, I think, in the really first few weeks of COVID, with like being stuck at home, lots of times on my hands, I was like, maybe technology can help me improve my bread recipe. What if I could figure out a device with maybe some AI in the mix that I could like train to figure out when my sourdough starter would be perfectly fermented? In my head, at least, the idea would be that I would buy AI, figure out when the sourdough kind of looks all right, bake the bread, figure out if the bread is good or not, give it a, like, oh, it's a nine out of 10. Like, it's really crispy, really nice. And then do the training that way, right? And so, the idea would be to smell the sourdough starter to capture some information, which in my head, at least, I'm not a chemist, I'm not a food chemist, but measuring things like the amount of volatilagony compounds and CO, CO2, whatever, there has to be a correlation and like the perfectly ripe sourdough starter, there has to be a way to identify it, right? And so, back in 2019, there was also this sort of cool kid on the block, new cool kid on the block, which was, and which is, tiny ML and things like TensorFlow Lite, finally available on micro controllers, things like that, right? And the thing is, I know really little about neural networks myself, like, for some reason, the math, like, whenever I would open a book about neural networks, and like, oh, yeah, it's easy, you're going to recognize handwritten digits, like, this is a bitmap, you go through some layers, blah, blah, blah, oh, you recognize the digits, that was going way over my head. The thing is, playing with physical things, more tangible things, I actually was a role in just a few hours, really, and with the help of some tools, some of you might have heard about something like, called edge impulse, it's not strictly speaking open source, although it's based on TensorFlow Lite for micros, but it helped me train a model, basically, taking some Arduino, like, an Arduino compatible device, this is a WIO terminal, a Cortex-M4, taking a gas sensor, feeding the data and like, capturing the data quite often, taking this data into some kind of training algorithms, and I would be able to figure out the difference, not necessarily between good bread and bad bread, because remember, COVID, like, flour wasn't even available in the supermarkets, but booze that I had in my house, so I actually figured that it was able to make the difference between not only, like, rum and whiskey, but it was actually accurate enough that two, like, one really pitted whiskey and one slightly less, so it would make up the difference, right? And I started to talk about the project, because I found it really cool, like, not do the silly bread thingy, but something slightly more useful, which is figuring out in the human breath, when there are, when you can spot the markers for fungal pneumonia, Kaleb, the kid almost died, basically, when he was really young and the doctors couldn't diagnose the disease, turns out that since then, there's now literature available out there that says that, yeah, there are some markers, and he sort of built a proof of concept for that, so that felt really good, but what didn't feel really good is that the code that was from day one available on GitHub of that project that I have to put together is horrible. It's like 2000 lines of boilerplate, copy paste, typical Arduino code, right? Like, I mean, I've been gathering bits here and there, of course it works, but it's really, really bad. Small, just like really quickly, because I think it's worth mentioning, how does a machine smell anyways, because we're all, I think, familiar, or we all think of things like temperature sensors and humidity and illuminance, like that certainly comes to mind, because we actually also use them every day, but there's also sensors that can smell, they measure the concentration of particular chemicals in the air. The way it works is basically just a chemical reaction between a tiny slice of metal oxide semiconductor, and based on how many of the offset compounds can be found in the air, you can measure a variation in the change in resistance, right? The more VOCs, voltallogonic compounds would be in the air, the higher the resistance, for example, which means that I could measure, like, start acquiring data, putting my sensor on top of bottles of alcohol and tea and coffee and whatnot, and capture basically what I would call the fingerprint or the olfactory fingerprint of a particular smell, and then with a bunch of AI and ML, basically figuring out what in this raw data identifies a smell, and so my intuition would be not knowing, again, a thing about signal extraction and all that kind of thing, would be, oh, well, but if this is whiskey, then if I were to write down what makes whiskey so special, it would be probably something like, oh, yeah, when you smell whiskey, nitrogen dioxide goes up, carbon monoxide, not so much, VOC goes up as well, maybe in a slightly more steady way, and so basically what happens then, the way the model works, is just that, except that it's a machine doing it, looking at the raw data, doing some basic statistics to extract the mean, the mean, the max, the standard deviation, like, all those things that could potentially characterize the smell, and then this pre-processing, this DSP, if you will, then goes through a typical neural network, so this is fun, you get to the point where you have this funny looking thing, like you can even go the extra mile and, like, sort of, 3D print, the enclosure, and there's, yeah, you have a lot of fun. I ended up building and packing, again, like, in those 2,000 lines of code, plus all the libraries, of course, that I'm pulling, I would have a GUI, I would have Wi-Fi integration, actually, that's something that I added eventually, and, like, whenever I smell something, I can push it using MQTT to a server, there's, of course, tons of hardware interactions, and all that needs to work at the same time, except that if you do it the Arduino way, and the lazy way, I guess, then you end up just doing this, which is, again, not necessarily, like, if you're lazy and just, like, eager to get your POC and your thing working, you end up putting a lot of code in, essentially, a superloop, and so, as often as possible, I need to do all this, which is acquiring sensor data, which, by the way, you don't need to do that often for getting good accuracy, like, the way the device works is that I just sample the gas sensor readings 10 times a second, it's not all that much, so every 100 milliseconds, I would read sensor data, and then I need a bit of time to actually run data through the AI model, which, again, doesn't really take a lot. The model, at the end of the day, is really simple, so you really only need a couple milliseconds there, fair enough, and then there's the world GUI aspect, which, again, if you're lazy, I'm not even, like, whenever a button is pressed, it's not even interrupt driven, so you need to figure out, like, if a button is being pressed right in the loop, not ideal, but you do that, and then, if you want, you then post results to an IoT server, and then you don't even know how long it's going to take, right? Like, if this is synchronous, it might be a problem. Enter an autos, right? That's basically, for the first few years of the project, it was sitting there on GitHub, this really crappy thing where people would open issues to be like, really, I mean, yes, I would put the ready to flash, like, firmware for people to use, but anyone who wanted to basically tweak the code, they were just scared, and so the thing is, I ended up, yeah, using Zephyr to try and rewrite, and also to myself, frankly, to learn some of the best practices there, I ended up trying to leverage some of the features of Zephyr, which is beyond being an autos, which hopefully would help me move away from the super loop, also get a better solution for targeting multiple architectures. Like, originally, I would be targeting the weird terminal, which is some D51 Cortex-M4, but I actually don't mind ESP32, and having the same code, same portable code, and portable build infrastructure, test infrastructure, I don't mind getting that, plus all the libraries that also come pre-packaged, and yeah, that's basically what I did. So, from this point, I guess, the presentation is more about telling you, like, how I replaced some of the concepts or some of the things that I had in my Arduino code, and point you to some interesting areas in Zephyr of, like, features and subsystems that are available that you maybe didn't know existed, and, but frankly, I didn't know existed either. Sensor acquisition, that might be the sort of the easy part, but I really like the fact that now my V2 version, if you will, of the NOS, I have essentially, and literally, a dedicated thread that acquires the data exactly at the sampling rate that I require for my model to perform accurately, right? That's like, that could be an issue. If I do the super loop thing, and for some reason, the UI takes longer to refresh or communicating with the the cloud takes longer, then it will basically shift the sampling rate for the gas sensor data, which basically means that I will start feeding crap into my AI model at all. So, you may want to sometimes put the sensor to sleep and make sure that it doesn't draw energy unnecessarily, so it's actually also integrated in the Zephyr APIs. Then comes the TensorFlow Lite aspect. So, I'm basically pulling TensorFlow Lite as a library in my application and leveraging something that's called ZBUS that makes it, especially for someone like me who's not necessarily a hardcore embedded developer, I basically have this high-level framework where, okay, I have my sensor acquisition thread that does its stuff, basically puts the sensor readings in a ring buffer, and whenever there is data that's available for the rest of the world and the rest of my app to do something out of, then it's effectively like there's an eventing system where, effectively, my inference thread really gets data, like subscribes to sensor readings so that it does the stuff and figure out what is it smelling like, and also uses ZBUS to put the result on the same, like using the same topic mechanism, if you will, so that, guess what, the GUI, for example, can in turn subscribe to this piece of information to do something useful out of. No need for fifo's and cues and semaphores, like it's actually really nice, and the overhead is minimal. So, there's that, and then for the GUI, that's one thing that's really nice with Zephyr is that you have LVGL, it just works, like there's obviously in Zephyr tons of drivers already available for a wide variety of display controllers, but then on top of that you even have, like, the high-level framework that is LVGL for creating a GUI with, like, chart, like, this gauge, this gauge, and I never know how to pronounce it, like, this gauge, and the charts, like, those are effectively widgets that subscribe to the data that comes and is being sent on ZBUS and just displays it, and the code is really, really straightforward, it integrates also with things like the Zephyr input system, like, if you have buttons, keypads, touch screens, that basically send events, you can have the LVGL app automatically react to that, right, so that's nice, and as you may notice, this is not a photo of LVGL running on the actual device, it is a screenshot of LVGL running in a desktop environment, because you can actually run the full artificial nose code in a fully emulated environment, if you will, on a POSIX OS, including the GUI aspect, so that's pretty nice, and like I said, it really feels like you're writing, like, really high-level applications, I have, I'm defining, and, like, I have a listener that wants to be notified whenever there is an inference result that's being made available by, probably, by the TensorFlow light for micro task and thread, and when that's happening, then it's pretty straightforward, you get the data, you really get it actually as an actual, like, typed message, like, so it's something like you can actually really make a good sense out of, in my case, the inference result would contain both a label telling me it's smelling coffee, whiskey, whatever, and a confidence level, based on how confident the model is that it is effectively whiskey or coffee, and so I can actually display that on my UI, and the code is really, like, literally moved from, yeah, 2,000 lines of code, I didn't count, but it's a couple hundred max, so there's that, and then this is sort of nice to have, if you were to do more than just a kind of prototype toy project, you could think about having the device, probably with something less stupid as the enclosure, but in the ceiling of the restrooms here in the building, so that whenever it smells pretty bad, you know that it's time to send someone to clean the place, but you don't want to send someone to clean the place, like, twice a day if, like, nothing happened, like, if it's, you're on the weekend, or it's like a day where there's strikes or whatever, or there's COVID and everyone is at home, so the device would need to be communicating somehow in a way, like, remotely, and for adding that to my project, it was also pretty straightforward, because there was a, like, full blown networking stack in Zephyr for, like, TCP, IP, and, like, co-op and MQTT, and, like, all the variants, all the flavors, and all the kind of connectivity options you may want to use, they're all there, and so effectively, and I can maybe quickly switch to a really quick demo, which is, I have, so, well, this is the version with the enclosure, this is the version, which is actually the WIO terminal, this one is M5 stack core 2, so this is effectively an ESP32, this is the sensor, it's already configured and already connected to Wi-Fi, so if I were to, I think I need to stop sharing maybe, if I were to connect to my MQTT, yeah, connected to an MQTT broker, and in real time, so this is really, like, reaching the internet and then my laptop connecting to the very same broker that this guy is connected to, and, yeah, apparently it's smelling ambient air, I guess it's more, like, nerdy or geeky air, and if I put, so this is, yeah, well, that was fast, actually, this is lemon, and for the anecdote, I, I mean, not that you care, but I actually forgot to bring the lemon from home, so I bought this one just this morning, so it's different lemon, I guess that the one I use for training the model, but it apparently works just the same, so that's, there's that, and what else, yeah, and many, many other things that are pretty cool in Zephyr, the fact that it leverages K-configured and device tree, just like Linux does, makes for pretty neat code when it comes to, oh, I want my GUI to be slightly different if my screen is large, I want to put, to cramp more into the UI, well, that's an information that you can get really easily from device tree, right, if my screen is wider than 300 pixels, blah, testing framework, CI integration, every time I commit something and push something and make a modification to the artificial nose, it gets built immediately, A1, basically, by the way, I wasn't working on Microsoft back then, and they are absolutely no problem with me putting everything on GitHub, so kudos to them for that, so now the new URL, if you wanted to check out the Zephyr version would be the same, with Zephyr in the name, you can find all the parts online, I don't get any royalties or whatever for that, but seed has actually sort of been like nice, ready to use bundle where you can order all the parts, and that's it, questions! Hello, thank you very much, so there is some abstraction where you can use different sensors, but surely the sensors don't give the same values for... Great question, I had a slide, I've removed the slide, removed the notes, I forgot, one thing that I would love to see happen to kind of answer your question is some kind of open data set, open ontology to actually describe smells in a consistent way, because you're right, like you would have sensors that are giving you readings in terms of like unitless concentration, like it's going between zero and 100% of VOC concentration, some would be talking PPM, some would be whatever, some would have like weird calibration things, there's, yeah, it's, you're right, so you would probably need to retrain the model, it's not like you can, at least with this code, it's not like you can easily be like, okay I'm going to switch from Bosch to Aliexpress, and it's going to work just the same, like you need to, yeah, I hope this answers the question. One more, yeah. We would like to know how it did it work with the sourdough and your baguettes? That's super, everyone asks the question, I never, like I never done the whole thing, like because back COVID, there was no flour, it would have been painful to bake dozens and dozens of baguettes and eat them anyways, and this is more fun to play with just random things like spices or booze, and the sourdough thing probably works, frankly, probably could be done more in a more simple way too, like maybe you just need a alcohol sensor and just measure the peak, and maybe that's it, I don't know. Thanks everyone. Okay, thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 11.92, "text": " That was helpful. Thank you. Thanks for joining. This is going to be a talk about a fun project", "tokens": [50364, 663, 390, 4961, 13, 1044, 291, 13, 2561, 337, 5549, 13, 639, 307, 516, 281, 312, 257, 751, 466, 257, 1019, 1716, 50960], "temperature": 0.0, "avg_logprob": -0.19927793973452085, "compression_ratio": 1.422680412371134, "no_speech_prob": 0.34668871760368347}, {"id": 1, "seek": 0, "start": 11.92, "end": 17.92, "text": " that I started, I think it's almost four years now, so I feel like I'm sort of milking the", "tokens": [50960, 300, 286, 1409, 11, 286, 519, 309, 311, 1920, 1451, 924, 586, 11, 370, 286, 841, 411, 286, 478, 1333, 295, 1962, 5092, 264, 51260], "temperature": 0.0, "avg_logprob": -0.19927793973452085, "compression_ratio": 1.422680412371134, "no_speech_prob": 0.34668871760368347}, {"id": 2, "seek": 0, "start": 17.92, "end": 24.8, "text": " idea, but it's pretty cool. It's back in 2019, I guess. I ended up building an artificial", "tokens": [51260, 1558, 11, 457, 309, 311, 1238, 1627, 13, 467, 311, 646, 294, 6071, 11, 286, 2041, 13, 286, 4590, 493, 2390, 364, 11677, 51604], "temperature": 0.0, "avg_logprob": -0.19927793973452085, "compression_ratio": 1.422680412371134, "no_speech_prob": 0.34668871760368347}, {"id": 3, "seek": 2480, "start": 24.8, "end": 32.64, "text": " nose using some cool tech, and I'm going to talk a bit about the tech behind it and how I ended", "tokens": [50364, 6690, 1228, 512, 1627, 7553, 11, 293, 286, 478, 516, 281, 751, 257, 857, 466, 264, 7553, 2261, 309, 293, 577, 286, 4590, 50756], "temperature": 0.0, "avg_logprob": -0.13529413040370158, "compression_ratio": 1.5245901639344261, "no_speech_prob": 0.44314318895339966}, {"id": 4, "seek": 2480, "start": 32.64, "end": 41.36, "text": " up moving the project from a really, really dirty weekend hack into something that's hopefully", "tokens": [50756, 493, 2684, 264, 1716, 490, 257, 534, 11, 534, 9360, 6711, 10339, 666, 746, 300, 311, 4696, 51192], "temperature": 0.0, "avg_logprob": -0.13529413040370158, "compression_ratio": 1.5245901639344261, "no_speech_prob": 0.44314318895339966}, {"id": 5, "seek": 2480, "start": 41.36, "end": 48.24, "text": " more future-proof and using cool things like Zephyr. So, a few words about myself. I'm a", "tokens": [51192, 544, 2027, 12, 15690, 293, 1228, 1627, 721, 411, 1176, 595, 3495, 81, 13, 407, 11, 257, 1326, 2283, 466, 2059, 13, 286, 478, 257, 51536], "temperature": 0.0, "avg_logprob": -0.13529413040370158, "compression_ratio": 1.5245901639344261, "no_speech_prob": 0.44314318895339966}, {"id": 6, "seek": 4824, "start": 48.24, "end": 56.24, "text": " Benjamin. I'm based in France for the past year, almost to the day, actually. I've been working as", "tokens": [50364, 22231, 13, 286, 478, 2361, 294, 6190, 337, 264, 1791, 1064, 11, 1920, 281, 264, 786, 11, 767, 13, 286, 600, 668, 1364, 382, 50764], "temperature": 0.0, "avg_logprob": -0.11872141033995386, "compression_ratio": 1.5612648221343874, "no_speech_prob": 0.708568274974823}, {"id": 7, "seek": 4824, "start": 56.24, "end": 62.64, "text": " a developer advocate for the Zephyr project at the Linux Foundation, and I do many things, including", "tokens": [50764, 257, 10754, 14608, 337, 264, 1176, 595, 3495, 81, 1716, 412, 264, 18734, 10335, 11, 293, 286, 360, 867, 721, 11, 3009, 51084], "temperature": 0.0, "avg_logprob": -0.11872141033995386, "compression_ratio": 1.5612648221343874, "no_speech_prob": 0.708568274974823}, {"id": 8, "seek": 4824, "start": 62.64, "end": 71.12, "text": " as a good French person, I guess, baking bread. And I don't know about you guys, but I've been", "tokens": [51084, 382, 257, 665, 5522, 954, 11, 286, 2041, 11, 12102, 5961, 13, 400, 286, 500, 380, 458, 466, 291, 1074, 11, 457, 286, 600, 668, 51508], "temperature": 0.0, "avg_logprob": -0.11872141033995386, "compression_ratio": 1.5612648221343874, "no_speech_prob": 0.708568274974823}, {"id": 9, "seek": 4824, "start": 71.12, "end": 76.72, "text": " trying to perfect my bread recipe for probably over 30 years. Like, I'm still not really happy about", "tokens": [51508, 1382, 281, 2176, 452, 5961, 6782, 337, 1391, 670, 2217, 924, 13, 1743, 11, 286, 478, 920, 406, 534, 2055, 466, 51788], "temperature": 0.0, "avg_logprob": -0.11872141033995386, "compression_ratio": 1.5612648221343874, "no_speech_prob": 0.708568274974823}, {"id": 10, "seek": 7672, "start": 77.44, "end": 84.08, "text": " the way it turns out. Like, it's a bit random, right? And so, back, I think, in the really first few", "tokens": [50400, 264, 636, 309, 4523, 484, 13, 1743, 11, 309, 311, 257, 857, 4974, 11, 558, 30, 400, 370, 11, 646, 11, 286, 519, 11, 294, 264, 534, 700, 1326, 50732], "temperature": 0.0, "avg_logprob": -0.12402273381798012, "compression_ratio": 1.5375494071146245, "no_speech_prob": 0.01174539141356945}, {"id": 11, "seek": 7672, "start": 84.08, "end": 90.56, "text": " weeks of COVID, with like being stuck at home, lots of times on my hands, I was like, maybe technology", "tokens": [50732, 3259, 295, 4566, 11, 365, 411, 885, 5541, 412, 1280, 11, 3195, 295, 1413, 322, 452, 2377, 11, 286, 390, 411, 11, 1310, 2899, 51056], "temperature": 0.0, "avg_logprob": -0.12402273381798012, "compression_ratio": 1.5375494071146245, "no_speech_prob": 0.01174539141356945}, {"id": 12, "seek": 7672, "start": 90.56, "end": 97.84, "text": " can help me improve my bread recipe. What if I could figure out a device with maybe some AI", "tokens": [51056, 393, 854, 385, 3470, 452, 5961, 6782, 13, 708, 498, 286, 727, 2573, 484, 257, 4302, 365, 1310, 512, 7318, 51420], "temperature": 0.0, "avg_logprob": -0.12402273381798012, "compression_ratio": 1.5375494071146245, "no_speech_prob": 0.01174539141356945}, {"id": 13, "seek": 7672, "start": 98.72, "end": 106.48, "text": " in the mix that I could like train to figure out when my sourdough starter would be perfectly", "tokens": [51464, 294, 264, 2890, 300, 286, 727, 411, 3847, 281, 2573, 484, 562, 452, 11006, 67, 581, 22465, 576, 312, 6239, 51852], "temperature": 0.0, "avg_logprob": -0.12402273381798012, "compression_ratio": 1.5375494071146245, "no_speech_prob": 0.01174539141356945}, {"id": 14, "seek": 10648, "start": 106.48, "end": 114.32000000000001, "text": " fermented? In my head, at least, the idea would be that I would buy AI, figure out when the sourdough", "tokens": [50364, 38649, 30, 682, 452, 1378, 11, 412, 1935, 11, 264, 1558, 576, 312, 300, 286, 576, 2256, 7318, 11, 2573, 484, 562, 264, 11006, 67, 581, 50756], "temperature": 0.0, "avg_logprob": -0.10974324716104043, "compression_ratio": 1.7012987012987013, "no_speech_prob": 0.01609843410551548}, {"id": 15, "seek": 10648, "start": 114.32000000000001, "end": 119.76, "text": " kind of looks all right, bake the bread, figure out if the bread is good or not, give it a, like,", "tokens": [50756, 733, 295, 1542, 439, 558, 11, 16562, 264, 5961, 11, 2573, 484, 498, 264, 5961, 307, 665, 420, 406, 11, 976, 309, 257, 11, 411, 11, 51028], "temperature": 0.0, "avg_logprob": -0.10974324716104043, "compression_ratio": 1.7012987012987013, "no_speech_prob": 0.01609843410551548}, {"id": 16, "seek": 10648, "start": 119.76, "end": 125.36, "text": " oh, it's a nine out of 10. Like, it's really crispy, really nice. And then do the training that way,", "tokens": [51028, 1954, 11, 309, 311, 257, 4949, 484, 295, 1266, 13, 1743, 11, 309, 311, 534, 17509, 11, 534, 1481, 13, 400, 550, 360, 264, 3097, 300, 636, 11, 51308], "temperature": 0.0, "avg_logprob": -0.10974324716104043, "compression_ratio": 1.7012987012987013, "no_speech_prob": 0.01609843410551548}, {"id": 17, "seek": 10648, "start": 125.36, "end": 133.44, "text": " right? And so, the idea would be to smell the sourdough starter to capture some information,", "tokens": [51308, 558, 30, 400, 370, 11, 264, 1558, 576, 312, 281, 4316, 264, 11006, 67, 581, 22465, 281, 7983, 512, 1589, 11, 51712], "temperature": 0.0, "avg_logprob": -0.10974324716104043, "compression_ratio": 1.7012987012987013, "no_speech_prob": 0.01609843410551548}, {"id": 18, "seek": 13344, "start": 133.44, "end": 138.96, "text": " which in my head, at least, I'm not a chemist, I'm not a food chemist, but measuring things like", "tokens": [50364, 597, 294, 452, 1378, 11, 412, 1935, 11, 286, 478, 406, 257, 4771, 468, 11, 286, 478, 406, 257, 1755, 4771, 468, 11, 457, 13389, 721, 411, 50640], "temperature": 0.0, "avg_logprob": -0.12710645463731554, "compression_ratio": 1.6725663716814159, "no_speech_prob": 0.0035873553715646267}, {"id": 19, "seek": 13344, "start": 138.96, "end": 145.6, "text": " the amount of volatilagony compounds and CO, CO2, whatever, there has to be a correlation and like", "tokens": [50640, 264, 2372, 295, 1996, 267, 388, 559, 2526, 21810, 293, 3002, 11, 3002, 17, 11, 2035, 11, 456, 575, 281, 312, 257, 20009, 293, 411, 50972], "temperature": 0.0, "avg_logprob": -0.12710645463731554, "compression_ratio": 1.6725663716814159, "no_speech_prob": 0.0035873553715646267}, {"id": 20, "seek": 13344, "start": 146.4, "end": 151.44, "text": " the perfectly ripe sourdough starter, there has to be a way to identify it, right? And so,", "tokens": [51012, 264, 6239, 31421, 11006, 67, 581, 22465, 11, 456, 575, 281, 312, 257, 636, 281, 5876, 309, 11, 558, 30, 400, 370, 11, 51264], "temperature": 0.0, "avg_logprob": -0.12710645463731554, "compression_ratio": 1.6725663716814159, "no_speech_prob": 0.0035873553715646267}, {"id": 21, "seek": 13344, "start": 152.32, "end": 157.92, "text": " back in 2019, there was also this sort of cool kid on the block, new cool kid on the block,", "tokens": [51308, 646, 294, 6071, 11, 456, 390, 611, 341, 1333, 295, 1627, 1636, 322, 264, 3461, 11, 777, 1627, 1636, 322, 264, 3461, 11, 51588], "temperature": 0.0, "avg_logprob": -0.12710645463731554, "compression_ratio": 1.6725663716814159, "no_speech_prob": 0.0035873553715646267}, {"id": 22, "seek": 15792, "start": 157.92, "end": 165.44, "text": " which was, and which is, tiny ML and things like TensorFlow Lite, finally available on micro", "tokens": [50364, 597, 390, 11, 293, 597, 307, 11, 5870, 21601, 293, 721, 411, 37624, 32986, 11, 2721, 2435, 322, 4532, 50740], "temperature": 0.0, "avg_logprob": -0.1632830810546875, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.09067302197217941}, {"id": 23, "seek": 15792, "start": 165.44, "end": 172.72, "text": " controllers, things like that, right? And the thing is, I know really little about neural networks", "tokens": [50740, 26903, 11, 721, 411, 300, 11, 558, 30, 400, 264, 551, 307, 11, 286, 458, 534, 707, 466, 18161, 9590, 51104], "temperature": 0.0, "avg_logprob": -0.1632830810546875, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.09067302197217941}, {"id": 24, "seek": 15792, "start": 172.72, "end": 179.35999999999999, "text": " myself, like, for some reason, the math, like, whenever I would open a book about neural networks,", "tokens": [51104, 2059, 11, 411, 11, 337, 512, 1778, 11, 264, 5221, 11, 411, 11, 5699, 286, 576, 1269, 257, 1446, 466, 18161, 9590, 11, 51436], "temperature": 0.0, "avg_logprob": -0.1632830810546875, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.09067302197217941}, {"id": 25, "seek": 15792, "start": 179.35999999999999, "end": 184.88, "text": " and like, oh, yeah, it's easy, you're going to recognize handwritten digits, like, this is a bitmap,", "tokens": [51436, 293, 411, 11, 1954, 11, 1338, 11, 309, 311, 1858, 11, 291, 434, 516, 281, 5521, 1011, 26859, 27011, 11, 411, 11, 341, 307, 257, 857, 24223, 11, 51712], "temperature": 0.0, "avg_logprob": -0.1632830810546875, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.09067302197217941}, {"id": 26, "seek": 18488, "start": 184.88, "end": 192.4, "text": " you go through some layers, blah, blah, blah, oh, you recognize the digits, that was going way", "tokens": [50364, 291, 352, 807, 512, 7914, 11, 12288, 11, 12288, 11, 12288, 11, 1954, 11, 291, 5521, 264, 27011, 11, 300, 390, 516, 636, 50740], "temperature": 0.0, "avg_logprob": -0.11427818735440572, "compression_ratio": 1.648068669527897, "no_speech_prob": 0.007090982515364885}, {"id": 27, "seek": 18488, "start": 192.4, "end": 200.56, "text": " over my head. The thing is, playing with physical things, more tangible things, I actually was a", "tokens": [50740, 670, 452, 1378, 13, 440, 551, 307, 11, 2433, 365, 4001, 721, 11, 544, 27094, 721, 11, 286, 767, 390, 257, 51148], "temperature": 0.0, "avg_logprob": -0.11427818735440572, "compression_ratio": 1.648068669527897, "no_speech_prob": 0.007090982515364885}, {"id": 28, "seek": 18488, "start": 200.56, "end": 205.84, "text": " role in just a few hours, really, and with the help of some tools, some of you might have heard", "tokens": [51148, 3090, 294, 445, 257, 1326, 2496, 11, 534, 11, 293, 365, 264, 854, 295, 512, 3873, 11, 512, 295, 291, 1062, 362, 2198, 51412], "temperature": 0.0, "avg_logprob": -0.11427818735440572, "compression_ratio": 1.648068669527897, "no_speech_prob": 0.007090982515364885}, {"id": 29, "seek": 18488, "start": 205.84, "end": 210.8, "text": " about something like, called edge impulse, it's not strictly speaking open source, although it's", "tokens": [51412, 466, 746, 411, 11, 1219, 4691, 26857, 11, 309, 311, 406, 20792, 4124, 1269, 4009, 11, 4878, 309, 311, 51660], "temperature": 0.0, "avg_logprob": -0.11427818735440572, "compression_ratio": 1.648068669527897, "no_speech_prob": 0.007090982515364885}, {"id": 30, "seek": 21080, "start": 210.8, "end": 218.08, "text": " based on TensorFlow Lite for micros, but it helped me train a model, basically, taking some Arduino,", "tokens": [50364, 2361, 322, 37624, 32986, 337, 15547, 11, 457, 309, 4254, 385, 3847, 257, 2316, 11, 1936, 11, 1940, 512, 39539, 11, 50728], "temperature": 0.0, "avg_logprob": -0.18490224271207242, "compression_ratio": 1.5, "no_speech_prob": 0.006359534803777933}, {"id": 31, "seek": 21080, "start": 218.72, "end": 227.36, "text": " like, an Arduino compatible device, this is a WIO terminal, a Cortex-M4, taking a gas sensor,", "tokens": [50760, 411, 11, 364, 39539, 18218, 4302, 11, 341, 307, 257, 343, 15167, 14709, 11, 257, 28522, 3121, 12, 44, 19, 11, 1940, 257, 4211, 10200, 11, 51192], "temperature": 0.0, "avg_logprob": -0.18490224271207242, "compression_ratio": 1.5, "no_speech_prob": 0.006359534803777933}, {"id": 32, "seek": 21080, "start": 228.64000000000001, "end": 234.48000000000002, "text": " feeding the data and like, capturing the data quite often, taking this data into some kind of", "tokens": [51256, 12919, 264, 1412, 293, 411, 11, 23384, 264, 1412, 1596, 2049, 11, 1940, 341, 1412, 666, 512, 733, 295, 51548], "temperature": 0.0, "avg_logprob": -0.18490224271207242, "compression_ratio": 1.5, "no_speech_prob": 0.006359534803777933}, {"id": 33, "seek": 23448, "start": 235.35999999999999, "end": 241.6, "text": " training algorithms, and I would be able to figure out the difference, not necessarily between good", "tokens": [50408, 3097, 14642, 11, 293, 286, 576, 312, 1075, 281, 2573, 484, 264, 2649, 11, 406, 4725, 1296, 665, 50720], "temperature": 0.0, "avg_logprob": -0.11346220288957869, "compression_ratio": 1.5179487179487179, "no_speech_prob": 0.058871082961559296}, {"id": 34, "seek": 23448, "start": 241.6, "end": 247.83999999999997, "text": " bread and bad bread, because remember, COVID, like, flour wasn't even available in the supermarkets,", "tokens": [50720, 5961, 293, 1578, 5961, 11, 570, 1604, 11, 4566, 11, 411, 11, 7693, 2067, 380, 754, 2435, 294, 264, 1687, 48850, 11, 51032], "temperature": 0.0, "avg_logprob": -0.11346220288957869, "compression_ratio": 1.5179487179487179, "no_speech_prob": 0.058871082961559296}, {"id": 35, "seek": 23448, "start": 247.83999999999997, "end": 257.36, "text": " but booze that I had in my house, so I actually figured that it was able to make the difference", "tokens": [51032, 457, 23113, 1381, 300, 286, 632, 294, 452, 1782, 11, 370, 286, 767, 8932, 300, 309, 390, 1075, 281, 652, 264, 2649, 51508], "temperature": 0.0, "avg_logprob": -0.11346220288957869, "compression_ratio": 1.5179487179487179, "no_speech_prob": 0.058871082961559296}, {"id": 36, "seek": 25736, "start": 257.36, "end": 264.0, "text": " between not only, like, rum and whiskey, but it was actually accurate enough that two, like,", "tokens": [50364, 1296, 406, 787, 11, 411, 11, 8347, 293, 34648, 11, 457, 309, 390, 767, 8559, 1547, 300, 732, 11, 411, 11, 50696], "temperature": 0.0, "avg_logprob": -0.13815329472223917, "compression_ratio": 1.706140350877193, "no_speech_prob": 0.1399277001619339}, {"id": 37, "seek": 25736, "start": 264.0, "end": 270.16, "text": " one really pitted whiskey and one slightly less, so it would make up the difference, right? And I", "tokens": [50696, 472, 534, 280, 3944, 34648, 293, 472, 4748, 1570, 11, 370, 309, 576, 652, 493, 264, 2649, 11, 558, 30, 400, 286, 51004], "temperature": 0.0, "avg_logprob": -0.13815329472223917, "compression_ratio": 1.706140350877193, "no_speech_prob": 0.1399277001619339}, {"id": 38, "seek": 25736, "start": 270.16, "end": 277.36, "text": " started to talk about the project, because I found it really cool, like, not do the silly bread thingy,", "tokens": [51004, 1409, 281, 751, 466, 264, 1716, 11, 570, 286, 1352, 309, 534, 1627, 11, 411, 11, 406, 360, 264, 11774, 5961, 551, 88, 11, 51364], "temperature": 0.0, "avg_logprob": -0.13815329472223917, "compression_ratio": 1.706140350877193, "no_speech_prob": 0.1399277001619339}, {"id": 39, "seek": 25736, "start": 277.36, "end": 283.2, "text": " but something slightly more useful, which is figuring out in the human breath, when there are,", "tokens": [51364, 457, 746, 4748, 544, 4420, 11, 597, 307, 15213, 484, 294, 264, 1952, 6045, 11, 562, 456, 366, 11, 51656], "temperature": 0.0, "avg_logprob": -0.13815329472223917, "compression_ratio": 1.706140350877193, "no_speech_prob": 0.1399277001619339}, {"id": 40, "seek": 28320, "start": 283.84, "end": 291.12, "text": " when you can spot the markers for fungal pneumonia, Kaleb, the kid almost died, basically, when he was", "tokens": [50396, 562, 291, 393, 4008, 264, 19175, 337, 1019, 9800, 43097, 11, 591, 26053, 11, 264, 1636, 1920, 4539, 11, 1936, 11, 562, 415, 390, 50760], "temperature": 0.0, "avg_logprob": -0.15237031233938117, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.035940080881118774}, {"id": 41, "seek": 28320, "start": 291.12, "end": 296.8, "text": " really young and the doctors couldn't diagnose the disease, turns out that since then, there's now", "tokens": [50760, 534, 2037, 293, 264, 8778, 2809, 380, 36238, 264, 4752, 11, 4523, 484, 300, 1670, 550, 11, 456, 311, 586, 51044], "temperature": 0.0, "avg_logprob": -0.15237031233938117, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.035940080881118774}, {"id": 42, "seek": 28320, "start": 296.8, "end": 301.68, "text": " literature available out there that says that, yeah, there are some markers, and he sort of", "tokens": [51044, 10394, 2435, 484, 456, 300, 1619, 300, 11, 1338, 11, 456, 366, 512, 19175, 11, 293, 415, 1333, 295, 51288], "temperature": 0.0, "avg_logprob": -0.15237031233938117, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.035940080881118774}, {"id": 43, "seek": 28320, "start": 301.68, "end": 307.28, "text": " built a proof of concept for that, so that felt really good, but what didn't feel really good is", "tokens": [51288, 3094, 257, 8177, 295, 3410, 337, 300, 11, 370, 300, 2762, 534, 665, 11, 457, 437, 994, 380, 841, 534, 665, 307, 51568], "temperature": 0.0, "avg_logprob": -0.15237031233938117, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.035940080881118774}, {"id": 44, "seek": 30728, "start": 307.35999999999996, "end": 313.35999999999996, "text": " that the code that was from day one available on GitHub of that project that I have to put together", "tokens": [50368, 300, 264, 3089, 300, 390, 490, 786, 472, 2435, 322, 23331, 295, 300, 1716, 300, 286, 362, 281, 829, 1214, 50668], "temperature": 0.0, "avg_logprob": -0.16191190735906616, "compression_ratio": 1.5868055555555556, "no_speech_prob": 0.10204761475324631}, {"id": 45, "seek": 30728, "start": 313.91999999999996, "end": 320.15999999999997, "text": " is horrible. It's like 2000 lines of boilerplate, copy paste, typical Arduino code, right? Like,", "tokens": [50696, 307, 9263, 13, 467, 311, 411, 8132, 3876, 295, 39228, 37008, 11, 5055, 9163, 11, 7476, 39539, 3089, 11, 558, 30, 1743, 11, 51008], "temperature": 0.0, "avg_logprob": -0.16191190735906616, "compression_ratio": 1.5868055555555556, "no_speech_prob": 0.10204761475324631}, {"id": 46, "seek": 30728, "start": 320.15999999999997, "end": 325.76, "text": " I mean, I've been gathering bits here and there, of course it works, but it's really, really bad.", "tokens": [51008, 286, 914, 11, 286, 600, 668, 13519, 9239, 510, 293, 456, 11, 295, 1164, 309, 1985, 11, 457, 309, 311, 534, 11, 534, 1578, 13, 51288], "temperature": 0.0, "avg_logprob": -0.16191190735906616, "compression_ratio": 1.5868055555555556, "no_speech_prob": 0.10204761475324631}, {"id": 47, "seek": 30728, "start": 327.52, "end": 330.64, "text": " Small, just like really quickly, because I think it's worth mentioning,", "tokens": [51376, 15287, 11, 445, 411, 534, 2661, 11, 570, 286, 519, 309, 311, 3163, 18315, 11, 51532], "temperature": 0.0, "avg_logprob": -0.16191190735906616, "compression_ratio": 1.5868055555555556, "no_speech_prob": 0.10204761475324631}, {"id": 48, "seek": 30728, "start": 331.35999999999996, "end": 336.96, "text": " how does a machine smell anyways, because we're all, I think, familiar, or we all think of", "tokens": [51568, 577, 775, 257, 3479, 4316, 13448, 11, 570, 321, 434, 439, 11, 286, 519, 11, 4963, 11, 420, 321, 439, 519, 295, 51848], "temperature": 0.0, "avg_logprob": -0.16191190735906616, "compression_ratio": 1.5868055555555556, "no_speech_prob": 0.10204761475324631}, {"id": 49, "seek": 33696, "start": 337.03999999999996, "end": 342.47999999999996, "text": " things like temperature sensors and humidity and illuminance, like that certainly comes to mind,", "tokens": [50368, 721, 411, 4292, 14840, 293, 24751, 293, 28593, 719, 11, 411, 300, 3297, 1487, 281, 1575, 11, 50640], "temperature": 0.0, "avg_logprob": -0.1673966646194458, "compression_ratio": 1.632034632034632, "no_speech_prob": 0.005528177134692669}, {"id": 50, "seek": 33696, "start": 342.47999999999996, "end": 346.15999999999997, "text": " because we actually also use them every day, but there's also sensors that can smell,", "tokens": [50640, 570, 321, 767, 611, 764, 552, 633, 786, 11, 457, 456, 311, 611, 14840, 300, 393, 4316, 11, 50824], "temperature": 0.0, "avg_logprob": -0.1673966646194458, "compression_ratio": 1.632034632034632, "no_speech_prob": 0.005528177134692669}, {"id": 51, "seek": 33696, "start": 347.35999999999996, "end": 354.4, "text": " they measure the concentration of particular chemicals in the air. The way it works is basically", "tokens": [50884, 436, 3481, 264, 9856, 295, 1729, 16152, 294, 264, 1988, 13, 440, 636, 309, 1985, 307, 1936, 51236], "temperature": 0.0, "avg_logprob": -0.1673966646194458, "compression_ratio": 1.632034632034632, "no_speech_prob": 0.005528177134692669}, {"id": 52, "seek": 33696, "start": 354.4, "end": 362.08, "text": " just a chemical reaction between a tiny slice of metal oxide semiconductor, and based on how many", "tokens": [51236, 445, 257, 7313, 5480, 1296, 257, 5870, 13153, 295, 5760, 28421, 45310, 11, 293, 2361, 322, 577, 867, 51620], "temperature": 0.0, "avg_logprob": -0.1673966646194458, "compression_ratio": 1.632034632034632, "no_speech_prob": 0.005528177134692669}, {"id": 53, "seek": 36208, "start": 362.96, "end": 369.76, "text": " of the offset compounds can be found in the air, you can measure a variation in the change", "tokens": [50408, 295, 264, 18687, 21810, 393, 312, 1352, 294, 264, 1988, 11, 291, 393, 3481, 257, 12990, 294, 264, 1319, 50748], "temperature": 0.0, "avg_logprob": -0.1774655245663075, "compression_ratio": 1.6515837104072397, "no_speech_prob": 0.006994600873440504}, {"id": 54, "seek": 36208, "start": 369.76, "end": 377.28, "text": " in resistance, right? The more VOCs, voltallogonic compounds would be in the air, the higher the", "tokens": [50748, 294, 7335, 11, 558, 30, 440, 544, 15216, 33290, 11, 5962, 336, 664, 11630, 21810, 576, 312, 294, 264, 1988, 11, 264, 2946, 264, 51124], "temperature": 0.0, "avg_logprob": -0.1774655245663075, "compression_ratio": 1.6515837104072397, "no_speech_prob": 0.006994600873440504}, {"id": 55, "seek": 36208, "start": 377.28, "end": 384.47999999999996, "text": " resistance, for example, which means that I could measure, like, start acquiring data,", "tokens": [51124, 7335, 11, 337, 1365, 11, 597, 1355, 300, 286, 727, 3481, 11, 411, 11, 722, 37374, 1412, 11, 51484], "temperature": 0.0, "avg_logprob": -0.1774655245663075, "compression_ratio": 1.6515837104072397, "no_speech_prob": 0.006994600873440504}, {"id": 56, "seek": 36208, "start": 384.47999999999996, "end": 391.28, "text": " putting my sensor on top of bottles of alcohol and tea and coffee and whatnot, and capture", "tokens": [51484, 3372, 452, 10200, 322, 1192, 295, 15923, 295, 7658, 293, 5817, 293, 4982, 293, 25882, 11, 293, 7983, 51824], "temperature": 0.0, "avg_logprob": -0.1774655245663075, "compression_ratio": 1.6515837104072397, "no_speech_prob": 0.006994600873440504}, {"id": 57, "seek": 39128, "start": 391.28, "end": 397.35999999999996, "text": " basically what I would call the fingerprint or the olfactory fingerprint of a particular smell,", "tokens": [50364, 1936, 437, 286, 576, 818, 264, 30715, 420, 264, 2545, 69, 21840, 30715, 295, 257, 1729, 4316, 11, 50668], "temperature": 0.0, "avg_logprob": -0.14291838382152802, "compression_ratio": 1.7022222222222223, "no_speech_prob": 0.0009661747608333826}, {"id": 58, "seek": 39128, "start": 397.91999999999996, "end": 405.84, "text": " and then with a bunch of AI and ML, basically figuring out what in this raw data identifies a", "tokens": [50696, 293, 550, 365, 257, 3840, 295, 7318, 293, 21601, 11, 1936, 15213, 484, 437, 294, 341, 8936, 1412, 34597, 257, 51092], "temperature": 0.0, "avg_logprob": -0.14291838382152802, "compression_ratio": 1.7022222222222223, "no_speech_prob": 0.0009661747608333826}, {"id": 59, "seek": 39128, "start": 405.84, "end": 414.0, "text": " smell, and so my intuition would be not knowing, again, a thing about signal extraction and all", "tokens": [51092, 4316, 11, 293, 370, 452, 24002, 576, 312, 406, 5276, 11, 797, 11, 257, 551, 466, 6358, 30197, 293, 439, 51500], "temperature": 0.0, "avg_logprob": -0.14291838382152802, "compression_ratio": 1.7022222222222223, "no_speech_prob": 0.0009661747608333826}, {"id": 60, "seek": 39128, "start": 414.0, "end": 419.44, "text": " that kind of thing, would be, oh, well, but if this is whiskey, then if I were to write down what", "tokens": [51500, 300, 733, 295, 551, 11, 576, 312, 11, 1954, 11, 731, 11, 457, 498, 341, 307, 34648, 11, 550, 498, 286, 645, 281, 2464, 760, 437, 51772], "temperature": 0.0, "avg_logprob": -0.14291838382152802, "compression_ratio": 1.7022222222222223, "no_speech_prob": 0.0009661747608333826}, {"id": 61, "seek": 41944, "start": 419.44, "end": 424.4, "text": " makes whiskey so special, it would be probably something like, oh, yeah, when you smell whiskey,", "tokens": [50364, 1669, 34648, 370, 2121, 11, 309, 576, 312, 1391, 746, 411, 11, 1954, 11, 1338, 11, 562, 291, 4316, 34648, 11, 50612], "temperature": 0.0, "avg_logprob": -0.08008665941199478, "compression_ratio": 1.6115702479338843, "no_speech_prob": 0.003641191404312849}, {"id": 62, "seek": 41944, "start": 424.4, "end": 431.52, "text": " nitrogen dioxide goes up, carbon monoxide, not so much, VOC goes up as well, maybe in a slightly", "tokens": [50612, 17903, 19590, 1709, 493, 11, 5954, 1108, 46053, 11, 406, 370, 709, 11, 15216, 34, 1709, 493, 382, 731, 11, 1310, 294, 257, 4748, 50968], "temperature": 0.0, "avg_logprob": -0.08008665941199478, "compression_ratio": 1.6115702479338843, "no_speech_prob": 0.003641191404312849}, {"id": 63, "seek": 41944, "start": 432.48, "end": 438.24, "text": " more steady way, and so basically what happens then, the way the model works, is just that, except", "tokens": [51016, 544, 13211, 636, 11, 293, 370, 1936, 437, 2314, 550, 11, 264, 636, 264, 2316, 1985, 11, 307, 445, 300, 11, 3993, 51304], "temperature": 0.0, "avg_logprob": -0.08008665941199478, "compression_ratio": 1.6115702479338843, "no_speech_prob": 0.003641191404312849}, {"id": 64, "seek": 41944, "start": 438.24, "end": 443.76, "text": " that it's a machine doing it, looking at the raw data, doing some basic statistics to extract the", "tokens": [51304, 300, 309, 311, 257, 3479, 884, 309, 11, 1237, 412, 264, 8936, 1412, 11, 884, 512, 3875, 12523, 281, 8947, 264, 51580], "temperature": 0.0, "avg_logprob": -0.08008665941199478, "compression_ratio": 1.6115702479338843, "no_speech_prob": 0.003641191404312849}, {"id": 65, "seek": 44376, "start": 443.84, "end": 451.84, "text": " mean, the mean, the max, the standard deviation, like, all those things that could potentially", "tokens": [50368, 914, 11, 264, 914, 11, 264, 11469, 11, 264, 3832, 25163, 11, 411, 11, 439, 729, 721, 300, 727, 7263, 50768], "temperature": 0.0, "avg_logprob": -0.12232196097280465, "compression_ratio": 1.6609442060085837, "no_speech_prob": 0.007803715765476227}, {"id": 66, "seek": 44376, "start": 451.84, "end": 460.64, "text": " characterize the smell, and then this pre-processing, this DSP, if you will, then goes through a typical", "tokens": [50768, 38463, 264, 4316, 11, 293, 550, 341, 659, 12, 41075, 278, 11, 341, 15816, 47, 11, 498, 291, 486, 11, 550, 1709, 807, 257, 7476, 51208], "temperature": 0.0, "avg_logprob": -0.12232196097280465, "compression_ratio": 1.6609442060085837, "no_speech_prob": 0.007803715765476227}, {"id": 67, "seek": 44376, "start": 460.64, "end": 467.28, "text": " neural network, so this is fun, you get to the point where you have this funny looking thing,", "tokens": [51208, 18161, 3209, 11, 370, 341, 307, 1019, 11, 291, 483, 281, 264, 935, 689, 291, 362, 341, 4074, 1237, 551, 11, 51540], "temperature": 0.0, "avg_logprob": -0.12232196097280465, "compression_ratio": 1.6609442060085837, "no_speech_prob": 0.007803715765476227}, {"id": 68, "seek": 44376, "start": 467.28, "end": 473.12, "text": " like you can even go the extra mile and, like, sort of, 3D print, the enclosure, and there's,", "tokens": [51540, 411, 291, 393, 754, 352, 264, 2857, 12620, 293, 11, 411, 11, 1333, 295, 11, 805, 35, 4482, 11, 264, 34093, 11, 293, 456, 311, 11, 51832], "temperature": 0.0, "avg_logprob": -0.12232196097280465, "compression_ratio": 1.6609442060085837, "no_speech_prob": 0.007803715765476227}, {"id": 69, "seek": 47312, "start": 473.12, "end": 479.28000000000003, "text": " yeah, you have a lot of fun. I ended up building and packing, again, like, in those 2,000 lines of", "tokens": [50364, 1338, 11, 291, 362, 257, 688, 295, 1019, 13, 286, 4590, 493, 2390, 293, 20815, 11, 797, 11, 411, 11, 294, 729, 568, 11, 1360, 3876, 295, 50672], "temperature": 0.0, "avg_logprob": -0.1229617530052815, "compression_ratio": 1.6141078838174274, "no_speech_prob": 0.0010141667444258928}, {"id": 70, "seek": 47312, "start": 479.28000000000003, "end": 485.68, "text": " code, plus all the libraries, of course, that I'm pulling, I would have a GUI, I would have", "tokens": [50672, 3089, 11, 1804, 439, 264, 15148, 11, 295, 1164, 11, 300, 286, 478, 8407, 11, 286, 576, 362, 257, 17917, 40, 11, 286, 576, 362, 50992], "temperature": 0.0, "avg_logprob": -0.1229617530052815, "compression_ratio": 1.6141078838174274, "no_speech_prob": 0.0010141667444258928}, {"id": 71, "seek": 47312, "start": 486.56, "end": 491.28000000000003, "text": " Wi-Fi integration, actually, that's something that I added eventually, and, like, whenever I smell", "tokens": [51036, 14035, 12, 13229, 10980, 11, 767, 11, 300, 311, 746, 300, 286, 3869, 4728, 11, 293, 11, 411, 11, 5699, 286, 4316, 51272], "temperature": 0.0, "avg_logprob": -0.1229617530052815, "compression_ratio": 1.6141078838174274, "no_speech_prob": 0.0010141667444258928}, {"id": 72, "seek": 47312, "start": 491.28000000000003, "end": 497.04, "text": " something, I can push it using MQTT to a server, there's, of course, tons of hardware interactions,", "tokens": [51272, 746, 11, 286, 393, 2944, 309, 1228, 376, 48, 28178, 281, 257, 7154, 11, 456, 311, 11, 295, 1164, 11, 9131, 295, 8837, 13280, 11, 51560], "temperature": 0.0, "avg_logprob": -0.1229617530052815, "compression_ratio": 1.6141078838174274, "no_speech_prob": 0.0010141667444258928}, {"id": 73, "seek": 49704, "start": 497.20000000000005, "end": 503.04, "text": " and all that needs to work at the same time, except that if you do it the Arduino way,", "tokens": [50372, 293, 439, 300, 2203, 281, 589, 412, 264, 912, 565, 11, 3993, 300, 498, 291, 360, 309, 264, 39539, 636, 11, 50664], "temperature": 0.0, "avg_logprob": -0.12113865216573079, "compression_ratio": 1.669603524229075, "no_speech_prob": 0.014015438966453075}, {"id": 74, "seek": 49704, "start": 503.6, "end": 509.52000000000004, "text": " and the lazy way, I guess, then you end up just doing this, which is, again, not necessarily,", "tokens": [50692, 293, 264, 14847, 636, 11, 286, 2041, 11, 550, 291, 917, 493, 445, 884, 341, 11, 597, 307, 11, 797, 11, 406, 4725, 11, 50988], "temperature": 0.0, "avg_logprob": -0.12113865216573079, "compression_ratio": 1.669603524229075, "no_speech_prob": 0.014015438966453075}, {"id": 75, "seek": 49704, "start": 509.52000000000004, "end": 518.08, "text": " like, if you're lazy and just, like, eager to get your POC and your thing working, you end up putting", "tokens": [50988, 411, 11, 498, 291, 434, 14847, 293, 445, 11, 411, 11, 18259, 281, 483, 428, 22299, 34, 293, 428, 551, 1364, 11, 291, 917, 493, 3372, 51416], "temperature": 0.0, "avg_logprob": -0.12113865216573079, "compression_ratio": 1.669603524229075, "no_speech_prob": 0.014015438966453075}, {"id": 76, "seek": 49704, "start": 518.08, "end": 526.0, "text": " a lot of code in, essentially, a superloop, and so, as often as possible, I need to do all this,", "tokens": [51416, 257, 688, 295, 3089, 294, 11, 4476, 11, 257, 1687, 46623, 11, 293, 370, 11, 382, 2049, 382, 1944, 11, 286, 643, 281, 360, 439, 341, 11, 51812], "temperature": 0.0, "avg_logprob": -0.12113865216573079, "compression_ratio": 1.669603524229075, "no_speech_prob": 0.014015438966453075}, {"id": 77, "seek": 52600, "start": 526.72, "end": 532.4, "text": " which is acquiring sensor data, which, by the way, you don't need to do that often for getting", "tokens": [50400, 597, 307, 37374, 10200, 1412, 11, 597, 11, 538, 264, 636, 11, 291, 500, 380, 643, 281, 360, 300, 2049, 337, 1242, 50684], "temperature": 0.0, "avg_logprob": -0.09094973112407484, "compression_ratio": 1.6327433628318584, "no_speech_prob": 0.001262729405425489}, {"id": 78, "seek": 52600, "start": 532.4, "end": 539.68, "text": " good accuracy, like, the way the device works is that I just sample the gas sensor readings", "tokens": [50684, 665, 14170, 11, 411, 11, 264, 636, 264, 4302, 1985, 307, 300, 286, 445, 6889, 264, 4211, 10200, 27319, 51048], "temperature": 0.0, "avg_logprob": -0.09094973112407484, "compression_ratio": 1.6327433628318584, "no_speech_prob": 0.001262729405425489}, {"id": 79, "seek": 52600, "start": 540.8, "end": 547.12, "text": " 10 times a second, it's not all that much, so every 100 milliseconds, I would read sensor data,", "tokens": [51104, 1266, 1413, 257, 1150, 11, 309, 311, 406, 439, 300, 709, 11, 370, 633, 2319, 34184, 11, 286, 576, 1401, 10200, 1412, 11, 51420], "temperature": 0.0, "avg_logprob": -0.09094973112407484, "compression_ratio": 1.6327433628318584, "no_speech_prob": 0.001262729405425489}, {"id": 80, "seek": 52600, "start": 547.12, "end": 553.52, "text": " and then I need a bit of time to actually run data through the AI model, which, again,", "tokens": [51420, 293, 550, 286, 643, 257, 857, 295, 565, 281, 767, 1190, 1412, 807, 264, 7318, 2316, 11, 597, 11, 797, 11, 51740], "temperature": 0.0, "avg_logprob": -0.09094973112407484, "compression_ratio": 1.6327433628318584, "no_speech_prob": 0.001262729405425489}, {"id": 81, "seek": 55352, "start": 553.52, "end": 558.48, "text": " doesn't really take a lot. The model, at the end of the day, is really simple, so you really only", "tokens": [50364, 1177, 380, 534, 747, 257, 688, 13, 440, 2316, 11, 412, 264, 917, 295, 264, 786, 11, 307, 534, 2199, 11, 370, 291, 534, 787, 50612], "temperature": 0.0, "avg_logprob": -0.08566018563729745, "compression_ratio": 1.7789855072463767, "no_speech_prob": 0.00445700716227293}, {"id": 82, "seek": 55352, "start": 558.48, "end": 564.72, "text": " need a couple milliseconds there, fair enough, and then there's the world GUI aspect, which, again,", "tokens": [50612, 643, 257, 1916, 34184, 456, 11, 3143, 1547, 11, 293, 550, 456, 311, 264, 1002, 17917, 40, 4171, 11, 597, 11, 797, 11, 50924], "temperature": 0.0, "avg_logprob": -0.08566018563729745, "compression_ratio": 1.7789855072463767, "no_speech_prob": 0.00445700716227293}, {"id": 83, "seek": 55352, "start": 564.72, "end": 570.4, "text": " if you're lazy, I'm not even, like, whenever a button is pressed, it's not even interrupt driven,", "tokens": [50924, 498, 291, 434, 14847, 11, 286, 478, 406, 754, 11, 411, 11, 5699, 257, 2960, 307, 17355, 11, 309, 311, 406, 754, 12729, 9555, 11, 51208], "temperature": 0.0, "avg_logprob": -0.08566018563729745, "compression_ratio": 1.7789855072463767, "no_speech_prob": 0.00445700716227293}, {"id": 84, "seek": 55352, "start": 570.4, "end": 576.3199999999999, "text": " so you need to figure out, like, if a button is being pressed right in the loop, not ideal, but", "tokens": [51208, 370, 291, 643, 281, 2573, 484, 11, 411, 11, 498, 257, 2960, 307, 885, 17355, 558, 294, 264, 6367, 11, 406, 7157, 11, 457, 51504], "temperature": 0.0, "avg_logprob": -0.08566018563729745, "compression_ratio": 1.7789855072463767, "no_speech_prob": 0.00445700716227293}, {"id": 85, "seek": 55352, "start": 576.3199999999999, "end": 582.3199999999999, "text": " you do that, and then, if you want, you then post results to an IoT server, and then you don't even", "tokens": [51504, 291, 360, 300, 11, 293, 550, 11, 498, 291, 528, 11, 291, 550, 2183, 3542, 281, 364, 30112, 7154, 11, 293, 550, 291, 500, 380, 754, 51804], "temperature": 0.0, "avg_logprob": -0.08566018563729745, "compression_ratio": 1.7789855072463767, "no_speech_prob": 0.00445700716227293}, {"id": 86, "seek": 58232, "start": 582.32, "end": 586.0, "text": " know how long it's going to take, right? Like, if this is synchronous, it might be a problem.", "tokens": [50364, 458, 577, 938, 309, 311, 516, 281, 747, 11, 558, 30, 1743, 11, 498, 341, 307, 44743, 11, 309, 1062, 312, 257, 1154, 13, 50548], "temperature": 0.0, "avg_logprob": -0.12800554709859413, "compression_ratio": 1.602510460251046, "no_speech_prob": 0.009098313748836517}, {"id": 87, "seek": 58232, "start": 586.88, "end": 593.6800000000001, "text": " Enter an autos, right? That's basically, for the first few years of the project, it was sitting", "tokens": [50592, 10399, 364, 1476, 329, 11, 558, 30, 663, 311, 1936, 11, 337, 264, 700, 1326, 924, 295, 264, 1716, 11, 309, 390, 3798, 50932], "temperature": 0.0, "avg_logprob": -0.12800554709859413, "compression_ratio": 1.602510460251046, "no_speech_prob": 0.009098313748836517}, {"id": 88, "seek": 58232, "start": 593.6800000000001, "end": 598.6400000000001, "text": " there on GitHub, this really crappy thing where people would open issues to be like, really,", "tokens": [50932, 456, 322, 23331, 11, 341, 534, 36531, 551, 689, 561, 576, 1269, 2663, 281, 312, 411, 11, 534, 11, 51180], "temperature": 0.0, "avg_logprob": -0.12800554709859413, "compression_ratio": 1.602510460251046, "no_speech_prob": 0.009098313748836517}, {"id": 89, "seek": 58232, "start": 599.7600000000001, "end": 606.1600000000001, "text": " I mean, yes, I would put the ready to flash, like, firmware for people to use, but anyone who wanted", "tokens": [51236, 286, 914, 11, 2086, 11, 286, 576, 829, 264, 1919, 281, 7319, 11, 411, 11, 30289, 337, 561, 281, 764, 11, 457, 2878, 567, 1415, 51556], "temperature": 0.0, "avg_logprob": -0.12800554709859413, "compression_ratio": 1.602510460251046, "no_speech_prob": 0.009098313748836517}, {"id": 90, "seek": 60616, "start": 606.56, "end": 611.76, "text": " to basically tweak the code, they were just scared, and so the thing is, I ended up, yeah,", "tokens": [50384, 281, 1936, 29879, 264, 3089, 11, 436, 645, 445, 5338, 11, 293, 370, 264, 551, 307, 11, 286, 4590, 493, 11, 1338, 11, 50644], "temperature": 0.0, "avg_logprob": -0.1124987555022287, "compression_ratio": 1.6565217391304348, "no_speech_prob": 0.023980576545000076}, {"id": 91, "seek": 60616, "start": 611.76, "end": 618.0799999999999, "text": " using Zephyr to try and rewrite, and also to myself, frankly, to learn some of the best practices", "tokens": [50644, 1228, 1176, 595, 3495, 81, 281, 853, 293, 28132, 11, 293, 611, 281, 2059, 11, 11939, 11, 281, 1466, 512, 295, 264, 1151, 7525, 50960], "temperature": 0.0, "avg_logprob": -0.1124987555022287, "compression_ratio": 1.6565217391304348, "no_speech_prob": 0.023980576545000076}, {"id": 92, "seek": 60616, "start": 618.0799999999999, "end": 625.12, "text": " there, I ended up trying to leverage some of the features of Zephyr, which is beyond being an", "tokens": [50960, 456, 11, 286, 4590, 493, 1382, 281, 13982, 512, 295, 264, 4122, 295, 1176, 595, 3495, 81, 11, 597, 307, 4399, 885, 364, 51312], "temperature": 0.0, "avg_logprob": -0.1124987555022287, "compression_ratio": 1.6565217391304348, "no_speech_prob": 0.023980576545000076}, {"id": 93, "seek": 60616, "start": 625.12, "end": 632.9599999999999, "text": " autos, which hopefully would help me move away from the super loop, also get a better solution for", "tokens": [51312, 1476, 329, 11, 597, 4696, 576, 854, 385, 1286, 1314, 490, 264, 1687, 6367, 11, 611, 483, 257, 1101, 3827, 337, 51704], "temperature": 0.0, "avg_logprob": -0.1124987555022287, "compression_ratio": 1.6565217391304348, "no_speech_prob": 0.023980576545000076}, {"id": 94, "seek": 63296, "start": 632.96, "end": 638.08, "text": " targeting multiple architectures. Like, originally, I would be targeting the weird terminal, which is", "tokens": [50364, 17918, 3866, 6331, 1303, 13, 1743, 11, 7993, 11, 286, 576, 312, 17918, 264, 3657, 14709, 11, 597, 307, 50620], "temperature": 0.0, "avg_logprob": -0.1820105703253495, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.03399297595024109}, {"id": 95, "seek": 63296, "start": 639.0400000000001, "end": 645.2, "text": " some D51 Cortex-M4, but I actually don't mind ESP32, and having the same code,", "tokens": [50668, 512, 413, 18682, 28522, 3121, 12, 44, 19, 11, 457, 286, 767, 500, 380, 1575, 12564, 47, 11440, 11, 293, 1419, 264, 912, 3089, 11, 50976], "temperature": 0.0, "avg_logprob": -0.1820105703253495, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.03399297595024109}, {"id": 96, "seek": 63296, "start": 646.24, "end": 651.36, "text": " same portable code, and portable build infrastructure, test infrastructure, I don't mind", "tokens": [51028, 912, 21800, 3089, 11, 293, 21800, 1322, 6896, 11, 1500, 6896, 11, 286, 500, 380, 1575, 51284], "temperature": 0.0, "avg_logprob": -0.1820105703253495, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.03399297595024109}, {"id": 97, "seek": 63296, "start": 651.36, "end": 657.2800000000001, "text": " getting that, plus all the libraries that also come pre-packaged, and yeah, that's basically what I did.", "tokens": [51284, 1242, 300, 11, 1804, 439, 264, 15148, 300, 611, 808, 659, 12, 9539, 2980, 11, 293, 1338, 11, 300, 311, 1936, 437, 286, 630, 13, 51580], "temperature": 0.0, "avg_logprob": -0.1820105703253495, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.03399297595024109}, {"id": 98, "seek": 65728, "start": 657.28, "end": 665.04, "text": " So, from this point, I guess, the presentation is more about telling you, like, how I replaced some", "tokens": [50364, 407, 11, 490, 341, 935, 11, 286, 2041, 11, 264, 5860, 307, 544, 466, 3585, 291, 11, 411, 11, 577, 286, 10772, 512, 50752], "temperature": 0.0, "avg_logprob": -0.1059761252454532, "compression_ratio": 1.6435185185185186, "no_speech_prob": 0.003645337652415037}, {"id": 99, "seek": 65728, "start": 665.04, "end": 670.56, "text": " of the concepts or some of the things that I had in my Arduino code, and point you to some", "tokens": [50752, 295, 264, 10392, 420, 512, 295, 264, 721, 300, 286, 632, 294, 452, 39539, 3089, 11, 293, 935, 291, 281, 512, 51028], "temperature": 0.0, "avg_logprob": -0.1059761252454532, "compression_ratio": 1.6435185185185186, "no_speech_prob": 0.003645337652415037}, {"id": 100, "seek": 65728, "start": 671.52, "end": 676.24, "text": " interesting areas in Zephyr of, like, features and subsystems that are available that you", "tokens": [51076, 1880, 3179, 294, 1176, 595, 3495, 81, 295, 11, 411, 11, 4122, 293, 2090, 9321, 82, 300, 366, 2435, 300, 291, 51312], "temperature": 0.0, "avg_logprob": -0.1059761252454532, "compression_ratio": 1.6435185185185186, "no_speech_prob": 0.003645337652415037}, {"id": 101, "seek": 65728, "start": 676.24, "end": 679.76, "text": " maybe didn't know existed, and, but frankly, I didn't know existed either.", "tokens": [51312, 1310, 994, 380, 458, 13135, 11, 293, 11, 457, 11939, 11, 286, 994, 380, 458, 13135, 2139, 13, 51488], "temperature": 0.0, "avg_logprob": -0.1059761252454532, "compression_ratio": 1.6435185185185186, "no_speech_prob": 0.003645337652415037}, {"id": 102, "seek": 67976, "start": 680.64, "end": 686.8, "text": " Sensor acquisition, that might be the sort of the easy part, but I really like the fact that now", "tokens": [50408, 318, 23153, 21668, 11, 300, 1062, 312, 264, 1333, 295, 264, 1858, 644, 11, 457, 286, 534, 411, 264, 1186, 300, 586, 50716], "temperature": 0.0, "avg_logprob": -0.13480247060457864, "compression_ratio": 1.5956521739130434, "no_speech_prob": 0.02632279507815838}, {"id": 103, "seek": 67976, "start": 687.76, "end": 694.72, "text": " my V2 version, if you will, of the NOS, I have essentially, and literally, a dedicated thread", "tokens": [50764, 452, 691, 17, 3037, 11, 498, 291, 486, 11, 295, 264, 426, 4367, 11, 286, 362, 4476, 11, 293, 3736, 11, 257, 8374, 7207, 51112], "temperature": 0.0, "avg_logprob": -0.13480247060457864, "compression_ratio": 1.5956521739130434, "no_speech_prob": 0.02632279507815838}, {"id": 104, "seek": 67976, "start": 694.72, "end": 700.64, "text": " that acquires the data exactly at the sampling rate that I require for my model to perform", "tokens": [51112, 300, 6667, 3145, 264, 1412, 2293, 412, 264, 21179, 3314, 300, 286, 3651, 337, 452, 2316, 281, 2042, 51408], "temperature": 0.0, "avg_logprob": -0.13480247060457864, "compression_ratio": 1.5956521739130434, "no_speech_prob": 0.02632279507815838}, {"id": 105, "seek": 67976, "start": 700.64, "end": 704.16, "text": " accurately, right? That's like, that could be an issue. If I do the super loop thing,", "tokens": [51408, 20095, 11, 558, 30, 663, 311, 411, 11, 300, 727, 312, 364, 2734, 13, 759, 286, 360, 264, 1687, 6367, 551, 11, 51584], "temperature": 0.0, "avg_logprob": -0.13480247060457864, "compression_ratio": 1.5956521739130434, "no_speech_prob": 0.02632279507815838}, {"id": 106, "seek": 70416, "start": 704.7199999999999, "end": 708.64, "text": " and for some reason, the UI takes longer to refresh or communicating with the", "tokens": [50392, 293, 337, 512, 1778, 11, 264, 15682, 2516, 2854, 281, 15134, 420, 17559, 365, 264, 50588], "temperature": 0.0, "avg_logprob": -0.13548755645751953, "compression_ratio": 1.6157205240174672, "no_speech_prob": 0.0068981703370809555}, {"id": 107, "seek": 70416, "start": 708.64, "end": 718.8, "text": " the cloud takes longer, then it will basically shift the sampling rate for the gas sensor data,", "tokens": [50588, 264, 4588, 2516, 2854, 11, 550, 309, 486, 1936, 5513, 264, 21179, 3314, 337, 264, 4211, 10200, 1412, 11, 51096], "temperature": 0.0, "avg_logprob": -0.13548755645751953, "compression_ratio": 1.6157205240174672, "no_speech_prob": 0.0068981703370809555}, {"id": 108, "seek": 70416, "start": 718.8, "end": 725.76, "text": " which basically means that I will start feeding crap into my AI model at all. So, you may want to", "tokens": [51096, 597, 1936, 1355, 300, 286, 486, 722, 12919, 12426, 666, 452, 7318, 2316, 412, 439, 13, 407, 11, 291, 815, 528, 281, 51444], "temperature": 0.0, "avg_logprob": -0.13548755645751953, "compression_ratio": 1.6157205240174672, "no_speech_prob": 0.0068981703370809555}, {"id": 109, "seek": 70416, "start": 725.76, "end": 731.76, "text": " sometimes put the sensor to sleep and make sure that it doesn't draw energy unnecessarily, so it's", "tokens": [51444, 2171, 829, 264, 10200, 281, 2817, 293, 652, 988, 300, 309, 1177, 380, 2642, 2281, 16799, 3289, 11, 370, 309, 311, 51744], "temperature": 0.0, "avg_logprob": -0.13548755645751953, "compression_ratio": 1.6157205240174672, "no_speech_prob": 0.0068981703370809555}, {"id": 110, "seek": 73176, "start": 731.84, "end": 738.24, "text": " actually also integrated in the Zephyr APIs. Then comes the TensorFlow Lite aspect. So, I'm", "tokens": [50368, 767, 611, 10919, 294, 264, 1176, 595, 3495, 81, 21445, 13, 1396, 1487, 264, 37624, 32986, 4171, 13, 407, 11, 286, 478, 50688], "temperature": 0.0, "avg_logprob": -0.15878624139830125, "compression_ratio": 1.5483870967741935, "no_speech_prob": 0.0010640205582603812}, {"id": 111, "seek": 73176, "start": 738.24, "end": 743.92, "text": " basically pulling TensorFlow Lite as a library in my application and leveraging something that's", "tokens": [50688, 1936, 8407, 37624, 32986, 382, 257, 6405, 294, 452, 3861, 293, 32666, 746, 300, 311, 50972], "temperature": 0.0, "avg_logprob": -0.15878624139830125, "compression_ratio": 1.5483870967741935, "no_speech_prob": 0.0010640205582603812}, {"id": 112, "seek": 73176, "start": 743.92, "end": 749.68, "text": " called ZBUS that makes it, especially for someone like me who's not necessarily a hardcore embedded", "tokens": [50972, 1219, 1176, 33, 3447, 300, 1669, 309, 11, 2318, 337, 1580, 411, 385, 567, 311, 406, 4725, 257, 28196, 16741, 51260], "temperature": 0.0, "avg_logprob": -0.15878624139830125, "compression_ratio": 1.5483870967741935, "no_speech_prob": 0.0010640205582603812}, {"id": 113, "seek": 73176, "start": 749.68, "end": 757.28, "text": " developer, I basically have this high-level framework where, okay, I have my sensor acquisition", "tokens": [51260, 10754, 11, 286, 1936, 362, 341, 1090, 12, 12418, 8388, 689, 11, 1392, 11, 286, 362, 452, 10200, 21668, 51640], "temperature": 0.0, "avg_logprob": -0.15878624139830125, "compression_ratio": 1.5483870967741935, "no_speech_prob": 0.0010640205582603812}, {"id": 114, "seek": 75728, "start": 757.36, "end": 764.4, "text": " thread that does its stuff, basically puts the sensor readings in a ring buffer, and whenever", "tokens": [50368, 7207, 300, 775, 1080, 1507, 11, 1936, 8137, 264, 10200, 27319, 294, 257, 4875, 21762, 11, 293, 5699, 50720], "temperature": 0.0, "avg_logprob": -0.1437067644936698, "compression_ratio": 1.7560975609756098, "no_speech_prob": 0.012220552191138268}, {"id": 115, "seek": 75728, "start": 765.28, "end": 769.12, "text": " there is data that's available for the rest of the world and the rest of my app", "tokens": [50764, 456, 307, 1412, 300, 311, 2435, 337, 264, 1472, 295, 264, 1002, 293, 264, 1472, 295, 452, 724, 50956], "temperature": 0.0, "avg_logprob": -0.1437067644936698, "compression_ratio": 1.7560975609756098, "no_speech_prob": 0.012220552191138268}, {"id": 116, "seek": 75728, "start": 769.12, "end": 775.1999999999999, "text": " to do something out of, then it's effectively like there's an eventing system where,", "tokens": [50956, 281, 360, 746, 484, 295, 11, 550, 309, 311, 8659, 411, 456, 311, 364, 2280, 278, 1185, 689, 11, 51260], "temperature": 0.0, "avg_logprob": -0.1437067644936698, "compression_ratio": 1.7560975609756098, "no_speech_prob": 0.012220552191138268}, {"id": 117, "seek": 75728, "start": 776.4, "end": 784.24, "text": " effectively, my inference thread really gets data, like subscribes to sensor readings so that it does", "tokens": [51320, 8659, 11, 452, 38253, 7207, 534, 2170, 1412, 11, 411, 2325, 6446, 281, 10200, 27319, 370, 300, 309, 775, 51712], "temperature": 0.0, "avg_logprob": -0.1437067644936698, "compression_ratio": 1.7560975609756098, "no_speech_prob": 0.012220552191138268}, {"id": 118, "seek": 78424, "start": 784.24, "end": 793.04, "text": " the stuff and figure out what is it smelling like, and also uses ZBUS to put the result on the same,", "tokens": [50364, 264, 1507, 293, 2573, 484, 437, 307, 309, 35471, 411, 11, 293, 611, 4960, 1176, 33, 3447, 281, 829, 264, 1874, 322, 264, 912, 11, 50804], "temperature": 0.0, "avg_logprob": -0.11561875594289679, "compression_ratio": 1.471794871794872, "no_speech_prob": 0.01401445735245943}, {"id": 119, "seek": 78424, "start": 793.04, "end": 798.8, "text": " like using the same topic mechanism, if you will, so that, guess what, the GUI, for example, can", "tokens": [50804, 411, 1228, 264, 912, 4829, 7513, 11, 498, 291, 486, 11, 370, 300, 11, 2041, 437, 11, 264, 17917, 40, 11, 337, 1365, 11, 393, 51092], "temperature": 0.0, "avg_logprob": -0.11561875594289679, "compression_ratio": 1.471794871794872, "no_speech_prob": 0.01401445735245943}, {"id": 120, "seek": 78424, "start": 800.48, "end": 806.96, "text": " in turn subscribe to this piece of information to do something useful out of. No need for", "tokens": [51176, 294, 1261, 3022, 281, 341, 2522, 295, 1589, 281, 360, 746, 4420, 484, 295, 13, 883, 643, 337, 51500], "temperature": 0.0, "avg_logprob": -0.11561875594289679, "compression_ratio": 1.471794871794872, "no_speech_prob": 0.01401445735245943}, {"id": 121, "seek": 80696, "start": 807.0400000000001, "end": 813.6, "text": " fifo's and cues and semaphores, like it's actually really nice, and the overhead is minimal. So,", "tokens": [50368, 5782, 78, 311, 293, 32192, 293, 4361, 13957, 2706, 11, 411, 309, 311, 767, 534, 1481, 11, 293, 264, 19922, 307, 13206, 13, 407, 11, 50696], "temperature": 0.0, "avg_logprob": -0.2020970265799706, "compression_ratio": 1.6581196581196582, "no_speech_prob": 0.07139216363430023}, {"id": 122, "seek": 80696, "start": 814.4000000000001, "end": 819.6800000000001, "text": " there's that, and then for the GUI, that's one thing that's really nice with Zephyr is that you", "tokens": [50736, 456, 311, 300, 11, 293, 550, 337, 264, 17917, 40, 11, 300, 311, 472, 551, 300, 311, 534, 1481, 365, 1176, 595, 3495, 81, 307, 300, 291, 51000], "temperature": 0.0, "avg_logprob": -0.2020970265799706, "compression_ratio": 1.6581196581196582, "no_speech_prob": 0.07139216363430023}, {"id": 123, "seek": 80696, "start": 819.6800000000001, "end": 826.32, "text": " have LVGL, it just works, like there's obviously in Zephyr tons of drivers already available for", "tokens": [51000, 362, 441, 53, 19440, 11, 309, 445, 1985, 11, 411, 456, 311, 2745, 294, 1176, 595, 3495, 81, 9131, 295, 11590, 1217, 2435, 337, 51332], "temperature": 0.0, "avg_logprob": -0.2020970265799706, "compression_ratio": 1.6581196581196582, "no_speech_prob": 0.07139216363430023}, {"id": 124, "seek": 80696, "start": 827.36, "end": 832.64, "text": " a wide variety of display controllers, but then on top of that you even have, like, the high-level", "tokens": [51384, 257, 4874, 5673, 295, 4674, 26903, 11, 457, 550, 322, 1192, 295, 300, 291, 754, 362, 11, 411, 11, 264, 1090, 12, 12418, 51648], "temperature": 0.0, "avg_logprob": -0.2020970265799706, "compression_ratio": 1.6581196581196582, "no_speech_prob": 0.07139216363430023}, {"id": 125, "seek": 83264, "start": 833.52, "end": 841.4399999999999, "text": " framework that is LVGL for creating a GUI with, like, chart, like, this gauge,", "tokens": [50408, 8388, 300, 307, 441, 53, 19440, 337, 4084, 257, 17917, 40, 365, 11, 411, 11, 6927, 11, 411, 11, 341, 17924, 11, 50804], "temperature": 0.0, "avg_logprob": -0.14189715081072868, "compression_ratio": 1.6575342465753424, "no_speech_prob": 0.00923454761505127}, {"id": 126, "seek": 83264, "start": 841.4399999999999, "end": 846.8, "text": " this gauge, and I never know how to pronounce it, like, this gauge, and the charts, like, those are", "tokens": [50804, 341, 17924, 11, 293, 286, 1128, 458, 577, 281, 19567, 309, 11, 411, 11, 341, 17924, 11, 293, 264, 17767, 11, 411, 11, 729, 366, 51072], "temperature": 0.0, "avg_logprob": -0.14189715081072868, "compression_ratio": 1.6575342465753424, "no_speech_prob": 0.00923454761505127}, {"id": 127, "seek": 83264, "start": 846.8, "end": 854.4, "text": " effectively widgets that subscribe to the data that comes and is being sent on ZBUS and just", "tokens": [51072, 8659, 43355, 300, 3022, 281, 264, 1412, 300, 1487, 293, 307, 885, 2279, 322, 1176, 33, 3447, 293, 445, 51452], "temperature": 0.0, "avg_logprob": -0.14189715081072868, "compression_ratio": 1.6575342465753424, "no_speech_prob": 0.00923454761505127}, {"id": 128, "seek": 83264, "start": 854.4, "end": 858.64, "text": " displays it, and the code is really, really straightforward, it integrates also with things", "tokens": [51452, 20119, 309, 11, 293, 264, 3089, 307, 534, 11, 534, 15325, 11, 309, 3572, 1024, 611, 365, 721, 51664], "temperature": 0.0, "avg_logprob": -0.14189715081072868, "compression_ratio": 1.6575342465753424, "no_speech_prob": 0.00923454761505127}, {"id": 129, "seek": 85864, "start": 858.64, "end": 866.24, "text": " like the Zephyr input system, like, if you have buttons, keypads, touch screens, that basically", "tokens": [50364, 411, 264, 1176, 595, 3495, 81, 4846, 1185, 11, 411, 11, 498, 291, 362, 9905, 11, 2141, 79, 5834, 11, 2557, 11171, 11, 300, 1936, 50744], "temperature": 0.0, "avg_logprob": -0.09973915885476504, "compression_ratio": 1.6754385964912282, "no_speech_prob": 0.003977668005973101}, {"id": 130, "seek": 85864, "start": 866.24, "end": 873.92, "text": " send events, you can have the LVGL app automatically react to that, right, so that's nice, and as you", "tokens": [50744, 2845, 3931, 11, 291, 393, 362, 264, 441, 53, 19440, 724, 6772, 4515, 281, 300, 11, 558, 11, 370, 300, 311, 1481, 11, 293, 382, 291, 51128], "temperature": 0.0, "avg_logprob": -0.09973915885476504, "compression_ratio": 1.6754385964912282, "no_speech_prob": 0.003977668005973101}, {"id": 131, "seek": 85864, "start": 873.92, "end": 882.3199999999999, "text": " may notice, this is not a photo of LVGL running on the actual device, it is a screenshot of LVGL", "tokens": [51128, 815, 3449, 11, 341, 307, 406, 257, 5052, 295, 441, 53, 19440, 2614, 322, 264, 3539, 4302, 11, 309, 307, 257, 27712, 295, 441, 53, 19440, 51548], "temperature": 0.0, "avg_logprob": -0.09973915885476504, "compression_ratio": 1.6754385964912282, "no_speech_prob": 0.003977668005973101}, {"id": 132, "seek": 85864, "start": 882.3199999999999, "end": 887.2, "text": " running in a desktop environment, because you can actually run the full artificial nose", "tokens": [51548, 2614, 294, 257, 14502, 2823, 11, 570, 291, 393, 767, 1190, 264, 1577, 11677, 6690, 51792], "temperature": 0.0, "avg_logprob": -0.09973915885476504, "compression_ratio": 1.6754385964912282, "no_speech_prob": 0.003977668005973101}, {"id": 133, "seek": 88720, "start": 887.44, "end": 897.76, "text": " code in a fully emulated environment, if you will, on a POSIX OS, including the GUI aspect,", "tokens": [50376, 3089, 294, 257, 4498, 846, 6987, 2823, 11, 498, 291, 486, 11, 322, 257, 430, 4367, 21124, 12731, 11, 3009, 264, 17917, 40, 4171, 11, 50892], "temperature": 0.0, "avg_logprob": -0.14913800321979287, "compression_ratio": 1.4673366834170853, "no_speech_prob": 0.004380699247121811}, {"id": 134, "seek": 88720, "start": 897.76, "end": 905.84, "text": " so that's pretty nice, and like I said, it really feels like you're writing, like, really high-level", "tokens": [50892, 370, 300, 311, 1238, 1481, 11, 293, 411, 286, 848, 11, 309, 534, 3417, 411, 291, 434, 3579, 11, 411, 11, 534, 1090, 12, 12418, 51296], "temperature": 0.0, "avg_logprob": -0.14913800321979287, "compression_ratio": 1.4673366834170853, "no_speech_prob": 0.004380699247121811}, {"id": 135, "seek": 88720, "start": 906.88, "end": 914.48, "text": " applications, I have, I'm defining, and, like, I have a listener that wants to be notified whenever", "tokens": [51348, 5821, 11, 286, 362, 11, 286, 478, 17827, 11, 293, 11, 411, 11, 286, 362, 257, 31569, 300, 2738, 281, 312, 18013, 5699, 51728], "temperature": 0.0, "avg_logprob": -0.14913800321979287, "compression_ratio": 1.4673366834170853, "no_speech_prob": 0.004380699247121811}, {"id": 136, "seek": 91448, "start": 915.2, "end": 921.6800000000001, "text": " there is an inference result that's being made available by, probably, by the TensorFlow light", "tokens": [50400, 456, 307, 364, 38253, 1874, 300, 311, 885, 1027, 2435, 538, 11, 1391, 11, 538, 264, 37624, 1442, 50724], "temperature": 0.0, "avg_logprob": -0.11533142417989752, "compression_ratio": 1.7236842105263157, "no_speech_prob": 0.015052472241222858}, {"id": 137, "seek": 91448, "start": 921.6800000000001, "end": 930.08, "text": " for micro task and thread, and when that's happening, then it's pretty straightforward, you get", "tokens": [50724, 337, 4532, 5633, 293, 7207, 11, 293, 562, 300, 311, 2737, 11, 550, 309, 311, 1238, 15325, 11, 291, 483, 51144], "temperature": 0.0, "avg_logprob": -0.11533142417989752, "compression_ratio": 1.7236842105263157, "no_speech_prob": 0.015052472241222858}, {"id": 138, "seek": 91448, "start": 930.88, "end": 936.32, "text": " the data, you really get it actually as an actual, like, typed message, like, so it's something like", "tokens": [51184, 264, 1412, 11, 291, 534, 483, 309, 767, 382, 364, 3539, 11, 411, 11, 33941, 3636, 11, 411, 11, 370, 309, 311, 746, 411, 51456], "temperature": 0.0, "avg_logprob": -0.11533142417989752, "compression_ratio": 1.7236842105263157, "no_speech_prob": 0.015052472241222858}, {"id": 139, "seek": 91448, "start": 936.32, "end": 942.08, "text": " you can actually really make a good sense out of, in my case, the inference result would contain both", "tokens": [51456, 291, 393, 767, 534, 652, 257, 665, 2020, 484, 295, 11, 294, 452, 1389, 11, 264, 38253, 1874, 576, 5304, 1293, 51744], "temperature": 0.0, "avg_logprob": -0.11533142417989752, "compression_ratio": 1.7236842105263157, "no_speech_prob": 0.015052472241222858}, {"id": 140, "seek": 94208, "start": 942.64, "end": 947.9200000000001, "text": " a label telling me it's smelling coffee, whiskey, whatever, and a confidence level,", "tokens": [50392, 257, 7645, 3585, 385, 309, 311, 35471, 4982, 11, 34648, 11, 2035, 11, 293, 257, 6687, 1496, 11, 50656], "temperature": 0.0, "avg_logprob": -0.14573550977204974, "compression_ratio": 1.634703196347032, "no_speech_prob": 0.004814636427909136}, {"id": 141, "seek": 94208, "start": 948.5600000000001, "end": 953.9200000000001, "text": " based on how confident the model is that it is effectively whiskey or coffee, and so I can", "tokens": [50688, 2361, 322, 577, 6679, 264, 2316, 307, 300, 309, 307, 8659, 34648, 420, 4982, 11, 293, 370, 286, 393, 50956], "temperature": 0.0, "avg_logprob": -0.14573550977204974, "compression_ratio": 1.634703196347032, "no_speech_prob": 0.004814636427909136}, {"id": 142, "seek": 94208, "start": 954.64, "end": 959.76, "text": " actually display that on my UI, and the code is really, like, literally moved from, yeah,", "tokens": [50992, 767, 4674, 300, 322, 452, 15682, 11, 293, 264, 3089, 307, 534, 11, 411, 11, 3736, 4259, 490, 11, 1338, 11, 51248], "temperature": 0.0, "avg_logprob": -0.14573550977204974, "compression_ratio": 1.634703196347032, "no_speech_prob": 0.004814636427909136}, {"id": 143, "seek": 94208, "start": 959.76, "end": 967.6800000000001, "text": " 2,000 lines of code, I didn't count, but it's a couple hundred max, so there's that, and then", "tokens": [51248, 568, 11, 1360, 3876, 295, 3089, 11, 286, 994, 380, 1207, 11, 457, 309, 311, 257, 1916, 3262, 11469, 11, 370, 456, 311, 300, 11, 293, 550, 51644], "temperature": 0.0, "avg_logprob": -0.14573550977204974, "compression_ratio": 1.634703196347032, "no_speech_prob": 0.004814636427909136}, {"id": 144, "seek": 96768, "start": 968.56, "end": 977.3599999999999, "text": " this is sort of nice to have, if you were to do more than just a kind of prototype toy project,", "tokens": [50408, 341, 307, 1333, 295, 1481, 281, 362, 11, 498, 291, 645, 281, 360, 544, 813, 445, 257, 733, 295, 19475, 12058, 1716, 11, 50848], "temperature": 0.0, "avg_logprob": -0.09275122906299348, "compression_ratio": 1.7264573991031391, "no_speech_prob": 0.005886945407837629}, {"id": 145, "seek": 96768, "start": 977.3599999999999, "end": 983.1999999999999, "text": " you could think about having the device, probably with something less stupid as the enclosure, but", "tokens": [50848, 291, 727, 519, 466, 1419, 264, 4302, 11, 1391, 365, 746, 1570, 6631, 382, 264, 34093, 11, 457, 51140], "temperature": 0.0, "avg_logprob": -0.09275122906299348, "compression_ratio": 1.7264573991031391, "no_speech_prob": 0.005886945407837629}, {"id": 146, "seek": 96768, "start": 983.1999999999999, "end": 990.7199999999999, "text": " in the ceiling of the restrooms here in the building, so that whenever it smells pretty bad,", "tokens": [51140, 294, 264, 13655, 295, 264, 1472, 32346, 510, 294, 264, 2390, 11, 370, 300, 5699, 309, 10036, 1238, 1578, 11, 51516], "temperature": 0.0, "avg_logprob": -0.09275122906299348, "compression_ratio": 1.7264573991031391, "no_speech_prob": 0.005886945407837629}, {"id": 147, "seek": 96768, "start": 990.7199999999999, "end": 996.4799999999999, "text": " you know that it's time to send someone to clean the place, but you don't want to send someone to", "tokens": [51516, 291, 458, 300, 309, 311, 565, 281, 2845, 1580, 281, 2541, 264, 1081, 11, 457, 291, 500, 380, 528, 281, 2845, 1580, 281, 51804], "temperature": 0.0, "avg_logprob": -0.09275122906299348, "compression_ratio": 1.7264573991031391, "no_speech_prob": 0.005886945407837629}, {"id": 148, "seek": 99648, "start": 996.48, "end": 1001.84, "text": " clean the place, like, twice a day if, like, nothing happened, like, if it's, you're on the weekend,", "tokens": [50364, 2541, 264, 1081, 11, 411, 11, 6091, 257, 786, 498, 11, 411, 11, 1825, 2011, 11, 411, 11, 498, 309, 311, 11, 291, 434, 322, 264, 6711, 11, 50632], "temperature": 0.0, "avg_logprob": -0.12912495930989584, "compression_ratio": 1.673728813559322, "no_speech_prob": 0.004961496219038963}, {"id": 149, "seek": 99648, "start": 1001.84, "end": 1006.64, "text": " or it's like a day where there's strikes or whatever, or there's COVID and everyone is at home,", "tokens": [50632, 420, 309, 311, 411, 257, 786, 689, 456, 311, 16750, 420, 2035, 11, 420, 456, 311, 4566, 293, 1518, 307, 412, 1280, 11, 50872], "temperature": 0.0, "avg_logprob": -0.12912495930989584, "compression_ratio": 1.673728813559322, "no_speech_prob": 0.004961496219038963}, {"id": 150, "seek": 99648, "start": 1006.64, "end": 1015.84, "text": " so the device would need to be communicating somehow in a way, like, remotely, and for adding that", "tokens": [50872, 370, 264, 4302, 576, 643, 281, 312, 17559, 6063, 294, 257, 636, 11, 411, 11, 20824, 11, 293, 337, 5127, 300, 51332], "temperature": 0.0, "avg_logprob": -0.12912495930989584, "compression_ratio": 1.673728813559322, "no_speech_prob": 0.004961496219038963}, {"id": 151, "seek": 99648, "start": 1016.88, "end": 1021.84, "text": " to my project, it was also pretty straightforward, because there was a, like, full blown networking", "tokens": [51384, 281, 452, 1716, 11, 309, 390, 611, 1238, 15325, 11, 570, 456, 390, 257, 11, 411, 11, 1577, 16479, 17985, 51632], "temperature": 0.0, "avg_logprob": -0.12912495930989584, "compression_ratio": 1.673728813559322, "no_speech_prob": 0.004961496219038963}, {"id": 152, "seek": 102184, "start": 1021.9200000000001, "end": 1029.2, "text": " stack in Zephyr for, like, TCP, IP, and, like, co-op and MQTT, and, like, all the variants,", "tokens": [50368, 8630, 294, 1176, 595, 3495, 81, 337, 11, 411, 11, 48965, 11, 8671, 11, 293, 11, 411, 11, 598, 12, 404, 293, 376, 48, 28178, 11, 293, 11, 411, 11, 439, 264, 21669, 11, 50732], "temperature": 0.0, "avg_logprob": -0.1521999224097328, "compression_ratio": 1.7136563876651982, "no_speech_prob": 0.08120791614055634}, {"id": 153, "seek": 102184, "start": 1029.2, "end": 1034.96, "text": " all the flavors, and all the kind of connectivity options you may want to use, they're all there,", "tokens": [50732, 439, 264, 16303, 11, 293, 439, 264, 733, 295, 21095, 3956, 291, 815, 528, 281, 764, 11, 436, 434, 439, 456, 11, 51020], "temperature": 0.0, "avg_logprob": -0.1521999224097328, "compression_ratio": 1.7136563876651982, "no_speech_prob": 0.08120791614055634}, {"id": 154, "seek": 102184, "start": 1034.96, "end": 1043.3600000000001, "text": " and so effectively, and I can maybe quickly switch to a really quick demo, which is, I have, so, well,", "tokens": [51020, 293, 370, 8659, 11, 293, 286, 393, 1310, 2661, 3679, 281, 257, 534, 1702, 10723, 11, 597, 307, 11, 286, 362, 11, 370, 11, 731, 11, 51440], "temperature": 0.0, "avg_logprob": -0.1521999224097328, "compression_ratio": 1.7136563876651982, "no_speech_prob": 0.08120791614055634}, {"id": 155, "seek": 102184, "start": 1043.3600000000001, "end": 1047.6000000000001, "text": " this is the version with the enclosure, this is the version, which is actually the WIO terminal,", "tokens": [51440, 341, 307, 264, 3037, 365, 264, 34093, 11, 341, 307, 264, 3037, 11, 597, 307, 767, 264, 343, 15167, 14709, 11, 51652], "temperature": 0.0, "avg_logprob": -0.1521999224097328, "compression_ratio": 1.7136563876651982, "no_speech_prob": 0.08120791614055634}, {"id": 156, "seek": 104760, "start": 1047.6, "end": 1055.28, "text": " this one is M5 stack core 2, so this is effectively an ESP32, this is the sensor, it's already", "tokens": [50364, 341, 472, 307, 376, 20, 8630, 4965, 568, 11, 370, 341, 307, 8659, 364, 12564, 47, 11440, 11, 341, 307, 264, 10200, 11, 309, 311, 1217, 50748], "temperature": 0.0, "avg_logprob": -0.11565457114690467, "compression_ratio": 1.5204678362573099, "no_speech_prob": 0.0036354418843984604}, {"id": 157, "seek": 104760, "start": 1055.28, "end": 1063.52, "text": " configured and already connected to Wi-Fi, so if I were to, I think I need to stop sharing maybe,", "tokens": [50748, 30538, 293, 1217, 4582, 281, 14035, 12, 13229, 11, 370, 498, 286, 645, 281, 11, 286, 519, 286, 643, 281, 1590, 5414, 1310, 11, 51160], "temperature": 0.0, "avg_logprob": -0.11565457114690467, "compression_ratio": 1.5204678362573099, "no_speech_prob": 0.0036354418843984604}, {"id": 158, "seek": 104760, "start": 1064.7199999999998, "end": 1069.4399999999998, "text": " if I were to connect to my MQTT, yeah, connected to an MQTT broker,", "tokens": [51220, 498, 286, 645, 281, 1745, 281, 452, 376, 48, 28178, 11, 1338, 11, 4582, 281, 364, 376, 48, 28178, 26502, 11, 51456], "temperature": 0.0, "avg_logprob": -0.11565457114690467, "compression_ratio": 1.5204678362573099, "no_speech_prob": 0.0036354418843984604}, {"id": 159, "seek": 106944, "start": 1069.6000000000001, "end": 1078.0, "text": " and in real time, so this is really, like, reaching the internet and then my laptop connecting to the", "tokens": [50372, 293, 294, 957, 565, 11, 370, 341, 307, 534, 11, 411, 11, 9906, 264, 4705, 293, 550, 452, 10732, 11015, 281, 264, 50792], "temperature": 0.0, "avg_logprob": -0.1138379617170854, "compression_ratio": 1.7633928571428572, "no_speech_prob": 0.05739903822541237}, {"id": 160, "seek": 106944, "start": 1078.0, "end": 1083.8400000000001, "text": " very same broker that this guy is connected to, and, yeah, apparently it's smelling ambient air,", "tokens": [50792, 588, 912, 26502, 300, 341, 2146, 307, 4582, 281, 11, 293, 11, 1338, 11, 7970, 309, 311, 35471, 22997, 1988, 11, 51084], "temperature": 0.0, "avg_logprob": -0.1138379617170854, "compression_ratio": 1.7633928571428572, "no_speech_prob": 0.05739903822541237}, {"id": 161, "seek": 106944, "start": 1083.8400000000001, "end": 1092.0800000000002, "text": " I guess it's more, like, nerdy or geeky air, and if I put, so this is, yeah, well, that was fast,", "tokens": [51084, 286, 2041, 309, 311, 544, 11, 411, 11, 18219, 3173, 420, 36162, 88, 1988, 11, 293, 498, 286, 829, 11, 370, 341, 307, 11, 1338, 11, 731, 11, 300, 390, 2370, 11, 51496], "temperature": 0.0, "avg_logprob": -0.1138379617170854, "compression_ratio": 1.7633928571428572, "no_speech_prob": 0.05739903822541237}, {"id": 162, "seek": 106944, "start": 1092.0800000000002, "end": 1098.24, "text": " actually, this is lemon, and for the anecdote, I, I mean, not that you care, but I actually forgot", "tokens": [51496, 767, 11, 341, 307, 11356, 11, 293, 337, 264, 49845, 11, 286, 11, 286, 914, 11, 406, 300, 291, 1127, 11, 457, 286, 767, 5298, 51804], "temperature": 0.0, "avg_logprob": -0.1138379617170854, "compression_ratio": 1.7633928571428572, "no_speech_prob": 0.05739903822541237}, {"id": 163, "seek": 109824, "start": 1098.24, "end": 1104.0, "text": " to bring the lemon from home, so I bought this one just this morning, so it's different lemon,", "tokens": [50364, 281, 1565, 264, 11356, 490, 1280, 11, 370, 286, 4243, 341, 472, 445, 341, 2446, 11, 370, 309, 311, 819, 11356, 11, 50652], "temperature": 0.0, "avg_logprob": -0.14353666855738714, "compression_ratio": 1.6478260869565218, "no_speech_prob": 0.010635443963110447}, {"id": 164, "seek": 109824, "start": 1104.0, "end": 1108.72, "text": " I guess that the one I use for training the model, but it apparently works just the same,", "tokens": [50652, 286, 2041, 300, 264, 472, 286, 764, 337, 3097, 264, 2316, 11, 457, 309, 7970, 1985, 445, 264, 912, 11, 50888], "temperature": 0.0, "avg_logprob": -0.14353666855738714, "compression_ratio": 1.6478260869565218, "no_speech_prob": 0.010635443963110447}, {"id": 165, "seek": 109824, "start": 1109.52, "end": 1117.2, "text": " so that's, there's that, and what else, yeah, and many, many other things that are pretty cool in", "tokens": [50928, 370, 300, 311, 11, 456, 311, 300, 11, 293, 437, 1646, 11, 1338, 11, 293, 867, 11, 867, 661, 721, 300, 366, 1238, 1627, 294, 51312], "temperature": 0.0, "avg_logprob": -0.14353666855738714, "compression_ratio": 1.6478260869565218, "no_speech_prob": 0.010635443963110447}, {"id": 166, "seek": 109824, "start": 1117.2, "end": 1121.92, "text": " Zephyr, the fact that it leverages K-configured and device tree, just like Linux does, makes for", "tokens": [51312, 1176, 595, 3495, 81, 11, 264, 1186, 300, 309, 12451, 1660, 591, 12, 1671, 20646, 3831, 293, 4302, 4230, 11, 445, 411, 18734, 775, 11, 1669, 337, 51548], "temperature": 0.0, "avg_logprob": -0.14353666855738714, "compression_ratio": 1.6478260869565218, "no_speech_prob": 0.010635443963110447}, {"id": 167, "seek": 112192, "start": 1122.4, "end": 1129.76, "text": " pretty neat code when it comes to, oh, I want my GUI to be slightly different if my screen is large,", "tokens": [50388, 1238, 10654, 3089, 562, 309, 1487, 281, 11, 1954, 11, 286, 528, 452, 17917, 40, 281, 312, 4748, 819, 498, 452, 2568, 307, 2416, 11, 50756], "temperature": 0.0, "avg_logprob": -0.1037780132490335, "compression_ratio": 1.6083333333333334, "no_speech_prob": 0.2300417423248291}, {"id": 168, "seek": 112192, "start": 1130.4, "end": 1136.0800000000002, "text": " I want to put, to cramp more into the UI, well, that's an information that you can get really", "tokens": [50788, 286, 528, 281, 829, 11, 281, 941, 1215, 544, 666, 264, 15682, 11, 731, 11, 300, 311, 364, 1589, 300, 291, 393, 483, 534, 51072], "temperature": 0.0, "avg_logprob": -0.1037780132490335, "compression_ratio": 1.6083333333333334, "no_speech_prob": 0.2300417423248291}, {"id": 169, "seek": 112192, "start": 1136.0800000000002, "end": 1142.5600000000002, "text": " easily from device tree, right, if my screen is wider than 300 pixels, blah, testing framework,", "tokens": [51072, 3612, 490, 4302, 4230, 11, 558, 11, 498, 452, 2568, 307, 11842, 813, 6641, 18668, 11, 12288, 11, 4997, 8388, 11, 51396], "temperature": 0.0, "avg_logprob": -0.1037780132490335, "compression_ratio": 1.6083333333333334, "no_speech_prob": 0.2300417423248291}, {"id": 170, "seek": 112192, "start": 1142.5600000000002, "end": 1148.0, "text": " CI integration, every time I commit something and push something and make a modification to the", "tokens": [51396, 37777, 10980, 11, 633, 565, 286, 5599, 746, 293, 2944, 746, 293, 652, 257, 26747, 281, 264, 51668], "temperature": 0.0, "avg_logprob": -0.1037780132490335, "compression_ratio": 1.6083333333333334, "no_speech_prob": 0.2300417423248291}, {"id": 171, "seek": 114800, "start": 1148.08, "end": 1154.48, "text": " artificial nose, it gets built immediately, A1, basically, by the way, I wasn't working on", "tokens": [50368, 11677, 6690, 11, 309, 2170, 3094, 4258, 11, 316, 16, 11, 1936, 11, 538, 264, 636, 11, 286, 2067, 380, 1364, 322, 50688], "temperature": 0.0, "avg_logprob": -0.08909300657419059, "compression_ratio": 1.5403225806451613, "no_speech_prob": 0.011481726542115211}, {"id": 172, "seek": 114800, "start": 1154.48, "end": 1158.88, "text": " Microsoft back then, and they are absolutely no problem with me putting everything on GitHub,", "tokens": [50688, 8116, 646, 550, 11, 293, 436, 366, 3122, 572, 1154, 365, 385, 3372, 1203, 322, 23331, 11, 50908], "temperature": 0.0, "avg_logprob": -0.08909300657419059, "compression_ratio": 1.5403225806451613, "no_speech_prob": 0.011481726542115211}, {"id": 173, "seek": 114800, "start": 1158.88, "end": 1166.8, "text": " so kudos to them for that, so now the new URL, if you wanted to check out the Zephyr version would", "tokens": [50908, 370, 350, 35063, 281, 552, 337, 300, 11, 370, 586, 264, 777, 12905, 11, 498, 291, 1415, 281, 1520, 484, 264, 1176, 595, 3495, 81, 3037, 576, 51304], "temperature": 0.0, "avg_logprob": -0.08909300657419059, "compression_ratio": 1.5403225806451613, "no_speech_prob": 0.011481726542115211}, {"id": 174, "seek": 114800, "start": 1166.8, "end": 1172.48, "text": " be the same, with Zephyr in the name, you can find all the parts online, I don't get any royalties", "tokens": [51304, 312, 264, 912, 11, 365, 1176, 595, 3495, 81, 294, 264, 1315, 11, 291, 393, 915, 439, 264, 3166, 2950, 11, 286, 500, 380, 483, 604, 36364, 26471, 51588], "temperature": 0.0, "avg_logprob": -0.08909300657419059, "compression_ratio": 1.5403225806451613, "no_speech_prob": 0.011481726542115211}, {"id": 175, "seek": 117248, "start": 1172.48, "end": 1178.0, "text": " or whatever for that, but seed has actually sort of been like nice, ready to use bundle where you", "tokens": [50364, 420, 2035, 337, 300, 11, 457, 8871, 575, 767, 1333, 295, 668, 411, 1481, 11, 1919, 281, 764, 24438, 689, 291, 50640], "temperature": 0.0, "avg_logprob": -0.3386406287168845, "compression_ratio": 1.3097345132743363, "no_speech_prob": 0.09530055522918701}, {"id": 176, "seek": 117248, "start": 1178.0, "end": 1182.08, "text": " can order all the parts, and that's it, questions!", "tokens": [50640, 393, 1668, 439, 264, 3166, 11, 293, 300, 311, 309, 11, 1651, 0, 50844], "temperature": 0.0, "avg_logprob": -0.3386406287168845, "compression_ratio": 1.3097345132743363, "no_speech_prob": 0.09530055522918701}, {"id": 177, "seek": 120248, "start": 1203.2, "end": 1210.4, "text": " Hello, thank you very much, so there is some abstraction where you can use different sensors,", "tokens": [50400, 2425, 11, 1309, 291, 588, 709, 11, 370, 456, 307, 512, 37765, 689, 291, 393, 764, 819, 14840, 11, 50760], "temperature": 0.0, "avg_logprob": -0.20616926798006383, "compression_ratio": 1.645, "no_speech_prob": 0.04181811586022377}, {"id": 178, "seek": 120248, "start": 1210.4, "end": 1214.32, "text": " but surely the sensors don't give the same values for...", "tokens": [50760, 457, 11468, 264, 14840, 500, 380, 976, 264, 912, 4190, 337, 485, 50956], "temperature": 0.0, "avg_logprob": -0.20616926798006383, "compression_ratio": 1.645, "no_speech_prob": 0.04181811586022377}, {"id": 179, "seek": 120248, "start": 1215.3600000000001, "end": 1220.08, "text": " Great question, I had a slide, I've removed the slide, removed the notes, I forgot,", "tokens": [51008, 3769, 1168, 11, 286, 632, 257, 4137, 11, 286, 600, 7261, 264, 4137, 11, 7261, 264, 5570, 11, 286, 5298, 11, 51244], "temperature": 0.0, "avg_logprob": -0.20616926798006383, "compression_ratio": 1.645, "no_speech_prob": 0.04181811586022377}, {"id": 180, "seek": 120248, "start": 1220.08, "end": 1226.08, "text": " one thing that I would love to see happen to kind of answer your question is some kind of open", "tokens": [51244, 472, 551, 300, 286, 576, 959, 281, 536, 1051, 281, 733, 295, 1867, 428, 1168, 307, 512, 733, 295, 1269, 51544], "temperature": 0.0, "avg_logprob": -0.20616926798006383, "compression_ratio": 1.645, "no_speech_prob": 0.04181811586022377}, {"id": 181, "seek": 122608, "start": 1226.6399999999999, "end": 1234.56, "text": " data set, open ontology to actually describe smells in a consistent way, because you're right,", "tokens": [50392, 1412, 992, 11, 1269, 6592, 1793, 281, 767, 6786, 10036, 294, 257, 8398, 636, 11, 570, 291, 434, 558, 11, 50788], "temperature": 0.0, "avg_logprob": -0.17559727226815572, "compression_ratio": 1.6355140186915889, "no_speech_prob": 0.22673925757408142}, {"id": 182, "seek": 122608, "start": 1234.56, "end": 1239.6, "text": " like you would have sensors that are giving you readings in terms of like unitless", "tokens": [50788, 411, 291, 576, 362, 14840, 300, 366, 2902, 291, 27319, 294, 2115, 295, 411, 4985, 1832, 51040], "temperature": 0.0, "avg_logprob": -0.17559727226815572, "compression_ratio": 1.6355140186915889, "no_speech_prob": 0.22673925757408142}, {"id": 183, "seek": 122608, "start": 1240.48, "end": 1246.56, "text": " concentration, like it's going between zero and 100% of VOC concentration, some would be", "tokens": [51084, 9856, 11, 411, 309, 311, 516, 1296, 4018, 293, 2319, 4, 295, 15216, 34, 9856, 11, 512, 576, 312, 51388], "temperature": 0.0, "avg_logprob": -0.17559727226815572, "compression_ratio": 1.6355140186915889, "no_speech_prob": 0.22673925757408142}, {"id": 184, "seek": 122608, "start": 1246.56, "end": 1253.28, "text": " talking PPM, some would be whatever, some would have like weird calibration things,", "tokens": [51388, 1417, 430, 18819, 11, 512, 576, 312, 2035, 11, 512, 576, 362, 411, 3657, 38732, 721, 11, 51724], "temperature": 0.0, "avg_logprob": -0.17559727226815572, "compression_ratio": 1.6355140186915889, "no_speech_prob": 0.22673925757408142}, {"id": 185, "seek": 125328, "start": 1253.92, "end": 1257.52, "text": " there's, yeah, it's, you're right, so you would probably need to retrain the model,", "tokens": [50396, 456, 311, 11, 1338, 11, 309, 311, 11, 291, 434, 558, 11, 370, 291, 576, 1391, 643, 281, 1533, 7146, 264, 2316, 11, 50576], "temperature": 0.0, "avg_logprob": -0.15930863839608653, "compression_ratio": 1.7471698113207548, "no_speech_prob": 0.030008459463715553}, {"id": 186, "seek": 125328, "start": 1257.52, "end": 1263.2, "text": " it's not like you can, at least with this code, it's not like you can easily be like,", "tokens": [50576, 309, 311, 406, 411, 291, 393, 11, 412, 1935, 365, 341, 3089, 11, 309, 311, 406, 411, 291, 393, 3612, 312, 411, 11, 50860], "temperature": 0.0, "avg_logprob": -0.15930863839608653, "compression_ratio": 1.7471698113207548, "no_speech_prob": 0.030008459463715553}, {"id": 187, "seek": 125328, "start": 1263.2, "end": 1268.8, "text": " okay I'm going to switch from Bosch to Aliexpress, and it's going to work just the same, like you", "tokens": [50860, 1392, 286, 478, 516, 281, 3679, 490, 22264, 339, 281, 967, 414, 87, 11637, 11, 293, 309, 311, 516, 281, 589, 445, 264, 912, 11, 411, 291, 51140], "temperature": 0.0, "avg_logprob": -0.15930863839608653, "compression_ratio": 1.7471698113207548, "no_speech_prob": 0.030008459463715553}, {"id": 188, "seek": 125328, "start": 1268.8, "end": 1275.52, "text": " need to, yeah, I hope this answers the question. One more, yeah. We would like to know how it", "tokens": [51140, 643, 281, 11, 1338, 11, 286, 1454, 341, 6338, 264, 1168, 13, 1485, 544, 11, 1338, 13, 492, 576, 411, 281, 458, 577, 309, 51476], "temperature": 0.0, "avg_logprob": -0.15930863839608653, "compression_ratio": 1.7471698113207548, "no_speech_prob": 0.030008459463715553}, {"id": 189, "seek": 125328, "start": 1276.6399999999999, "end": 1282.96, "text": " did it work with the sourdough and your baguettes? That's super, everyone asks the question, I never,", "tokens": [51532, 630, 309, 589, 365, 264, 11006, 67, 581, 293, 428, 3411, 84, 16049, 30, 663, 311, 1687, 11, 1518, 8962, 264, 1168, 11, 286, 1128, 11, 51848], "temperature": 0.0, "avg_logprob": -0.15930863839608653, "compression_ratio": 1.7471698113207548, "no_speech_prob": 0.030008459463715553}, {"id": 190, "seek": 128296, "start": 1283.52, "end": 1290.24, "text": " like I never done the whole thing, like because back COVID, there was no flour, it would have", "tokens": [50392, 411, 286, 1128, 1096, 264, 1379, 551, 11, 411, 570, 646, 4566, 11, 456, 390, 572, 7693, 11, 309, 576, 362, 50728], "temperature": 0.0, "avg_logprob": -0.13929933246813322, "compression_ratio": 1.6398305084745763, "no_speech_prob": 0.010606112889945507}, {"id": 191, "seek": 128296, "start": 1290.24, "end": 1296.48, "text": " been painful to bake dozens and dozens of baguettes and eat them anyways, and this is more fun to", "tokens": [50728, 668, 11697, 281, 16562, 18431, 293, 18431, 295, 3411, 84, 16049, 293, 1862, 552, 13448, 11, 293, 341, 307, 544, 1019, 281, 51040], "temperature": 0.0, "avg_logprob": -0.13929933246813322, "compression_ratio": 1.6398305084745763, "no_speech_prob": 0.010606112889945507}, {"id": 192, "seek": 128296, "start": 1296.48, "end": 1303.92, "text": " play with just random things like spices or booze, and the sourdough thing probably works, frankly,", "tokens": [51040, 862, 365, 445, 4974, 721, 411, 19608, 420, 23113, 1381, 11, 293, 264, 11006, 67, 581, 551, 1391, 1985, 11, 11939, 11, 51412], "temperature": 0.0, "avg_logprob": -0.13929933246813322, "compression_ratio": 1.6398305084745763, "no_speech_prob": 0.010606112889945507}, {"id": 193, "seek": 128296, "start": 1304.88, "end": 1311.2, "text": " probably could be done more in a more simple way too, like maybe you just need a alcohol sensor", "tokens": [51460, 1391, 727, 312, 1096, 544, 294, 257, 544, 2199, 636, 886, 11, 411, 1310, 291, 445, 643, 257, 7658, 10200, 51776], "temperature": 0.0, "avg_logprob": -0.13929933246813322, "compression_ratio": 1.6398305084745763, "no_speech_prob": 0.010606112889945507}, {"id": 194, "seek": 131120, "start": 1311.2, "end": 1322.56, "text": " and just measure the peak, and maybe that's it, I don't know. Thanks everyone. Okay, thank you.", "tokens": [50364, 293, 445, 3481, 264, 10651, 11, 293, 1310, 300, 311, 309, 11, 286, 500, 380, 458, 13, 2561, 1518, 13, 1033, 11, 1309, 291, 13, 50932], "temperature": 0.0, "avg_logprob": -0.1998472043446132, "compression_ratio": 1.0674157303370786, "no_speech_prob": 0.007649553008377552}], "language": "en"}