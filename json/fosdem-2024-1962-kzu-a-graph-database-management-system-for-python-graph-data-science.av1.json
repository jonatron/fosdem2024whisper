{"text": " Next we have Prashant Rao with Kuzu, a graph database management system for Python graph data science. All right. Good afternoon, everyone. So my name is Prashant. I'm an AI engineer at Kuzu. So I'll be talking about graph databases today. Just a quick show of hands, how many people have worked with graph databases or heard of them? Fair number. Okay. So you're in the right room today. So I'll outline a bit about what I'm going to cover. I'll start with what graphs are for those who are not familiar. And then when you need graph modeling, I'll also cover some of the features of a competent graph database management system and what that means. And that leads into the vision that Kuzu has, both as a GDBMS or that is a graph database management system and as the go-to solution for graph data science. And I'll end with a walkthrough on how Kuzu makes graph data science workflows easier for the developer. So the first question we must ask is, what are graphs or networks as they're sometimes called? They are an abstract representation of entities and relationships. Essentially an entity is represented as a node and the way these are connected together is represented by an edge, which is the relationship shown in this figure. And as the figure in the bottom shows, these can get pretty complex and reveal really interesting structures about connected data. And that's exactly what we see in the real world. Graphs are actually one of the most natural ways to represent data. Social networks are of course something we are very familiar with, but graphs are very prevalent in many other domains, all the way from drug interactions to molecular networks to traffic networks. In the world of finance, you analyze transactions for things like fraud and they also are very common in knowledge graphs that encode factual information about the world. Kuzu is a graph database management system, which is a class of database management systems. So I'll start by giving a general overview about GDBMS. You generally have three components to any database system. You have the data model, you have the query language, and you have the system implementation. From the data model perspective, graph data models differ from the conventional relational data model in the sense that you typically represent the data as nodes and edges. And you have key value properties on these nodes or edges. In this example, with this triangle you see here, you have a cyclic relationship of transactions between people, one, two, and three, where the nodes one, two, and three have property information on the name and the edges have the amount of the transaction as a property. So this is called the property graph model of graphs. And it's very, very common and prevalent in the industry. But there's also another data model called RDF, resource description framework, which has a similar concept of subject, predicates, and objects, which represent a triple. The triple is a basic unit of data in the graph, but it's the same idea as the property graph model except the implementation is different. From a query language perspective, every graph database management system needs a high-level query language that's designed specifically with graph syntax. And an example of this is shown here. This is the Cypher query language, which Kuzu implements. And incidentally, Cypher is the same language that was invented and popularized by Neo4j, if anybody's used that before. But what this example query snippet shows is you have node information, A and B, of type account, and you're matching on those nodes. And then you're running a query, a joint query equivalent in a way that reminds you a lot of SQL. It's very declarative and it's very high-level reminiscent of SQL. From a system implementation standpoint, universally, I think it's hard to come with a statement that covers all graph systems, but in general, they implement storage structures, indices, and operators that are specific to graphs. One example is the shortest path operator. These are operators that are not prevalent in relational systems but are very common in graph systems. There are many reasons why you might need graph modeling, but I'll cover just a couple of them in these next two slides. For an example, let's take this query where we are trying to find direct or indirect possible sources of money flow into a person's account from a particular location. So in this example, the person is Alice, represented by node B in this Cypher query, and we are matching on the owner of that account, which is Alice, but also matching on account A, whose location is Canada. The key here is that the middle portion, which is the transfer star, that star syntax is a high-level general syntax called clean star. It's used to implement indirect and recursive joins. As you can see, the query is quite concise. It's quite readable. You can do this sort of query in SQL, but it's a recursive query and it's not as easy. It's going to be a lot more verbose and not that easy to read. One other example of this would be the shortest path query, which is a lot harder to do in recursive SQL, but in Cypher, it's very, very straightforward. It's just an additional clause that you add attached onto the previous query. Another case where you need graph modeling is in heterogeneous data. This example here shows an example of Dbpedia, which is a structured version of Wikipedia, and we're taking this example of the location we're in right now, University, Liberator and Brussels. On the left is the way it's stored in structured form, where you have key value properties, and each of these properties links to other properties. But on the right, we schematically represent that as a graph. As you can see, the university is linked to the city of Brussels. It's also linked to the country of Belgium, what affiliations it has, and each of these individual resources can be linked to other resources. This actually expresses the power of a graph model, because doing this with a tabular form of data would be almost impossible, because that's how Wikipedia is structured. It's a lot of connected information. This leads us to the question of what is a feature set of a competent graph database. We list a few of them here, but I think it's very difficult to go through each of them in the time we have. We do have a blog post that covers this in much more detail. It's called What Every GDBMS Should Do and Division. But in a nutshell, every GDBMS has to support things like many to many growing joins, recursive joins on top of heterogeneous data sets, for example, knowledge graphs. Another thing that we can highlight here is the schema querying aspect, where in this last example, you have account information and transaction edges, and you're able to query on the type of the edge. Let's say you have two different kinds of transactions. You don't want each of those on either side of the middle node to be the same transaction type. You're able to say, you apply a predicate on the edge to say that you don't want nodes of a particular type. This is the sort of thing that you can't do in SQL. You can only do this in a graph model. The vision of Kuzu as a graph database management system is it aims to represent the state of the art of how graphs should be stored, indexed, and queried. It does this by being highly scalable to several terabytes of data. It's very fast in terms of query speed. It supports the property graph model, which we described earlier. It also supports the RDF data model, which is going to be coming in the next release. It does so via a high-level query language, Cypher. It's easy to use and uses an embeddable architecture. We like to think of ourselves as like duck DB or SQLite, but for graphs. If you ever come across either of the other two relational systems, Kuzu is like a graph analog to those systems. I should also note here that Kuzu is based on many years of research at the University of Waterloo. It's now being developed in an independent company called Kuzu Inc, which we're from. The other big vision that Kuzu has from a data science perspective, specifically graph data science perspective, is to be the go-to back end for graph modeling and data science. Essentially the vision here is if you look at the bottom half of this figure, you have a lot of data sitting in disparate sources like data lakes, warehouses, relational databases all the way from Postgres and many others. There's a lot of interoperability challenges that you have with these data sources. Even though you have structured data, in many cases working with them as a graph is quite challenging because of the movement of data across the systems into a powerful graph database back end. Kuzu aims to be a simpler way and sort of an interface to that. In the upper half, the aim of this is to make graph data science much more accessible in the sense that we provide zero copy access to the data by writing out the format that is native to those libraries. For example, PyTorchumetric, NetworkX. These are popular graph data science libraries and machine learning libraries in Python. By being well integrated with the Python data science ecosystem, we believe this makes it a lot more achievable. I'll quickly walk through an example of how Kuzu makes graph data science easier in terms of a workflow. Let's consider this real world, a simple example, a toy example, where you have two different data sources. You have people and the movies that they watched. You also have people and their friends and where they live. These are two different data sets. Your goal is to use the information from this data to build a movie recommender system where a person who has watched certain movies gets recommended other movies. There are many ways you can build such a recommendation system. One we'll cover here is using a graph neural network, specifically using link prediction where you're trying to predict a recommended edge between a person and a movie. This is a very simple example where you have data set one which has the persons and the movies with some additional metadata, could be age or any other attributes. Then data set two has persons and what friends those persons have and where they live. For those who have not worked with graph machine learning before, it's a very high level overview in this slide where the goal of graph machine learning is to embed the nodes and the surroundings space into a vector space. The benefit of this is that it incorporates the structure of the graph based on the nodes and their surrounding neighbors. The idea is that you perform a computation on the graph nodes and transform the features of that graph into a feature vector like the array shown there. The idea is very similar to the kind of vectors that you may have seen in other domains like computer vision or natural language processing where the only difference is that in those domains you are considering the similarity between words in a sentence or pixels in an image whereas in this case you're considering the similarity of the topology of the graph itself. All of that is great but when you're working with the data, you're immediately faced with a problem. The data you have might exist in different sources. For example, the movies watch may exist in Postgres and the person friends may exist in other structured data sources that you export to CSV or Parquet or something similar. You need to bring them together to form a graph. Conceptually, this is how a graph would look. You have nodes that represent the persons. You have edges that represent the movies that they watched in the first graph and then in the second one you have edges that represent friendship between people and what cities they live in. The moment you do that, you have another problem where you potentially have overlapping data or duplicate data between these two subgraphs. In one of them you have the persons and the cities and the other ones you have persons and movies. Many of them might be the same people. There is some deduplication logic that's required where you have to merge people with the same attributes and there's some custom logic that needs to be put in terms of how you decide whether something is a duplicate. Once you do that, you have the final result where you have some nodes that are dangling in the sense that they have no edges that attach them to other nodes. These actually don't inform the machine learning model and would need to be removed. To do all of this is actually quite tedious if you were to write your own custom logic in your own language of choice. Where Kuzu comes in and where it's very powerful is the ability to just install an embeddable library using pip install Kuzu in Python. Once you have that, you're very rapidly able to run query execution to create the tables, load the data in and perform deduplication logic and dangling node removal using a high-level query language like Cypher in a way that scales to the size of the data that you have. In many ways, you don't have to worry about the scalability problem because now you have a high-level query language supporting your operations in the middle stages. Once you have all of the data and the features that are loaded into a graph, you essentially can walk through this process where you not only have the data in the right form, but you're able to actually encode the features into the graph and store that on disk. One of the biggest limitations with PyTorch geometric is if you ever worked with it before, is it's very memory intensive when you're working with large graphs. Kuzu helps a lot in this regard by persisting the features onto disk. That's exactly where I think we want to highlight this point. I think we are almost out of time, but I'll wrap up by saying the key points to take away. Kuzu is an in-process analytical graph database system, kind of like DuckTB is in the SQL world, but for graphs. It's highly scalable and optimized for multi-core parallelism and very well integrated with the PyData ecosystem, including NumPy, PyAro, NetworkX, PyTorch, and so on. It supports both the property graph model as well as the RDF graph model via Cypher, a high-level query language. It's embeddable and very easy to use from your application. It's also accessible with other language bindings, not just Python. If you come from other languages, those options exist as well. That's it from us. Kuzu is an open source, very permissive, licensed, MIT licensed project. I'd love for everyone to give it a try and reach out to us on Discord. We're always open to chatting more about graph use cases. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 11.44, "text": " Next we have Prashant Rao with Kuzu, a graph database management system for Python graph", "tokens": [50364, 3087, 321, 362, 2114, 1299, 394, 7591, 78, 365, 591, 48323, 11, 257, 4295, 8149, 4592, 1185, 337, 15329, 4295, 50936], "temperature": 0.0, "avg_logprob": -0.33663997134646856, "compression_ratio": 1.4397590361445782, "no_speech_prob": 0.06532993167638779}, {"id": 1, "seek": 0, "start": 11.44, "end": 15.08, "text": " data science.", "tokens": [50936, 1412, 3497, 13, 51118], "temperature": 0.0, "avg_logprob": -0.33663997134646856, "compression_ratio": 1.4397590361445782, "no_speech_prob": 0.06532993167638779}, {"id": 2, "seek": 0, "start": 15.08, "end": 20.32, "text": " All right.", "tokens": [51118, 1057, 558, 13, 51380], "temperature": 0.0, "avg_logprob": -0.33663997134646856, "compression_ratio": 1.4397590361445782, "no_speech_prob": 0.06532993167638779}, {"id": 3, "seek": 0, "start": 20.32, "end": 22.16, "text": " Good afternoon, everyone.", "tokens": [51380, 2205, 6499, 11, 1518, 13, 51472], "temperature": 0.0, "avg_logprob": -0.33663997134646856, "compression_ratio": 1.4397590361445782, "no_speech_prob": 0.06532993167638779}, {"id": 4, "seek": 0, "start": 22.16, "end": 23.32, "text": " So my name is Prashant.", "tokens": [51472, 407, 452, 1315, 307, 2114, 1299, 394, 13, 51530], "temperature": 0.0, "avg_logprob": -0.33663997134646856, "compression_ratio": 1.4397590361445782, "no_speech_prob": 0.06532993167638779}, {"id": 5, "seek": 0, "start": 23.32, "end": 25.6, "text": " I'm an AI engineer at Kuzu.", "tokens": [51530, 286, 478, 364, 7318, 11403, 412, 591, 48323, 13, 51644], "temperature": 0.0, "avg_logprob": -0.33663997134646856, "compression_ratio": 1.4397590361445782, "no_speech_prob": 0.06532993167638779}, {"id": 6, "seek": 0, "start": 25.6, "end": 27.76, "text": " So I'll be talking about graph databases today.", "tokens": [51644, 407, 286, 603, 312, 1417, 466, 4295, 22380, 965, 13, 51752], "temperature": 0.0, "avg_logprob": -0.33663997134646856, "compression_ratio": 1.4397590361445782, "no_speech_prob": 0.06532993167638779}, {"id": 7, "seek": 2776, "start": 27.76, "end": 32.2, "text": " Just a quick show of hands, how many people have worked with graph databases or heard", "tokens": [50364, 1449, 257, 1702, 855, 295, 2377, 11, 577, 867, 561, 362, 2732, 365, 4295, 22380, 420, 2198, 50586], "temperature": 0.0, "avg_logprob": -0.14418938248245805, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00655101565644145}, {"id": 8, "seek": 2776, "start": 32.2, "end": 33.2, "text": " of them?", "tokens": [50586, 295, 552, 30, 50636], "temperature": 0.0, "avg_logprob": -0.14418938248245805, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00655101565644145}, {"id": 9, "seek": 2776, "start": 33.2, "end": 34.2, "text": " Fair number.", "tokens": [50636, 12157, 1230, 13, 50686], "temperature": 0.0, "avg_logprob": -0.14418938248245805, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00655101565644145}, {"id": 10, "seek": 2776, "start": 34.2, "end": 35.2, "text": " Okay.", "tokens": [50686, 1033, 13, 50736], "temperature": 0.0, "avg_logprob": -0.14418938248245805, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00655101565644145}, {"id": 11, "seek": 2776, "start": 35.2, "end": 37.04, "text": " So you're in the right room today.", "tokens": [50736, 407, 291, 434, 294, 264, 558, 1808, 965, 13, 50828], "temperature": 0.0, "avg_logprob": -0.14418938248245805, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00655101565644145}, {"id": 12, "seek": 2776, "start": 37.04, "end": 39.68, "text": " So I'll outline a bit about what I'm going to cover.", "tokens": [50828, 407, 286, 603, 16387, 257, 857, 466, 437, 286, 478, 516, 281, 2060, 13, 50960], "temperature": 0.0, "avg_logprob": -0.14418938248245805, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00655101565644145}, {"id": 13, "seek": 2776, "start": 39.68, "end": 43.6, "text": " I'll start with what graphs are for those who are not familiar.", "tokens": [50960, 286, 603, 722, 365, 437, 24877, 366, 337, 729, 567, 366, 406, 4963, 13, 51156], "temperature": 0.0, "avg_logprob": -0.14418938248245805, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00655101565644145}, {"id": 14, "seek": 2776, "start": 43.6, "end": 48.68000000000001, "text": " And then when you need graph modeling, I'll also cover some of the features of a competent", "tokens": [51156, 400, 550, 562, 291, 643, 4295, 15983, 11, 286, 603, 611, 2060, 512, 295, 264, 4122, 295, 257, 29998, 51410], "temperature": 0.0, "avg_logprob": -0.14418938248245805, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00655101565644145}, {"id": 15, "seek": 2776, "start": 48.68000000000001, "end": 52.400000000000006, "text": " graph database management system and what that means.", "tokens": [51410, 4295, 8149, 4592, 1185, 293, 437, 300, 1355, 13, 51596], "temperature": 0.0, "avg_logprob": -0.14418938248245805, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00655101565644145}, {"id": 16, "seek": 2776, "start": 52.400000000000006, "end": 57.36, "text": " And that leads into the vision that Kuzu has, both as a GDBMS or that is a graph database", "tokens": [51596, 400, 300, 6689, 666, 264, 5201, 300, 591, 48323, 575, 11, 1293, 382, 257, 460, 27735, 10288, 420, 300, 307, 257, 4295, 8149, 51844], "temperature": 0.0, "avg_logprob": -0.14418938248245805, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00655101565644145}, {"id": 17, "seek": 5736, "start": 57.36, "end": 62.6, "text": " management system and as the go-to solution for graph data science.", "tokens": [50364, 4592, 1185, 293, 382, 264, 352, 12, 1353, 3827, 337, 4295, 1412, 3497, 13, 50626], "temperature": 0.0, "avg_logprob": -0.1586376760423798, "compression_ratio": 1.6356589147286822, "no_speech_prob": 0.000789514509961009}, {"id": 18, "seek": 5736, "start": 62.6, "end": 67.52, "text": " And I'll end with a walkthrough on how Kuzu makes graph data science workflows easier", "tokens": [50626, 400, 286, 603, 917, 365, 257, 1792, 11529, 322, 577, 591, 48323, 1669, 4295, 1412, 3497, 43461, 3571, 50872], "temperature": 0.0, "avg_logprob": -0.1586376760423798, "compression_ratio": 1.6356589147286822, "no_speech_prob": 0.000789514509961009}, {"id": 19, "seek": 5736, "start": 67.52, "end": 69.96, "text": " for the developer.", "tokens": [50872, 337, 264, 10754, 13, 50994], "temperature": 0.0, "avg_logprob": -0.1586376760423798, "compression_ratio": 1.6356589147286822, "no_speech_prob": 0.000789514509961009}, {"id": 20, "seek": 5736, "start": 69.96, "end": 74.88, "text": " So the first question we must ask is, what are graphs or networks as they're sometimes", "tokens": [50994, 407, 264, 700, 1168, 321, 1633, 1029, 307, 11, 437, 366, 24877, 420, 9590, 382, 436, 434, 2171, 51240], "temperature": 0.0, "avg_logprob": -0.1586376760423798, "compression_ratio": 1.6356589147286822, "no_speech_prob": 0.000789514509961009}, {"id": 21, "seek": 5736, "start": 74.88, "end": 75.88, "text": " called?", "tokens": [51240, 1219, 30, 51290], "temperature": 0.0, "avg_logprob": -0.1586376760423798, "compression_ratio": 1.6356589147286822, "no_speech_prob": 0.000789514509961009}, {"id": 22, "seek": 5736, "start": 75.88, "end": 81.36, "text": " They are an abstract representation of entities and relationships.", "tokens": [51290, 814, 366, 364, 12649, 10290, 295, 16667, 293, 6159, 13, 51564], "temperature": 0.0, "avg_logprob": -0.1586376760423798, "compression_ratio": 1.6356589147286822, "no_speech_prob": 0.000789514509961009}, {"id": 23, "seek": 5736, "start": 81.36, "end": 86.36, "text": " Essentially an entity is represented as a node and the way these are connected together", "tokens": [51564, 23596, 364, 13977, 307, 10379, 382, 257, 9984, 293, 264, 636, 613, 366, 4582, 1214, 51814], "temperature": 0.0, "avg_logprob": -0.1586376760423798, "compression_ratio": 1.6356589147286822, "no_speech_prob": 0.000789514509961009}, {"id": 24, "seek": 8636, "start": 86.36, "end": 90.92, "text": " is represented by an edge, which is the relationship shown in this figure.", "tokens": [50364, 307, 10379, 538, 364, 4691, 11, 597, 307, 264, 2480, 4898, 294, 341, 2573, 13, 50592], "temperature": 0.0, "avg_logprob": -0.10088912860767262, "compression_ratio": 1.7064846416382253, "no_speech_prob": 0.005619860254228115}, {"id": 25, "seek": 8636, "start": 90.92, "end": 96.0, "text": " And as the figure in the bottom shows, these can get pretty complex and reveal really interesting", "tokens": [50592, 400, 382, 264, 2573, 294, 264, 2767, 3110, 11, 613, 393, 483, 1238, 3997, 293, 10658, 534, 1880, 50846], "temperature": 0.0, "avg_logprob": -0.10088912860767262, "compression_ratio": 1.7064846416382253, "no_speech_prob": 0.005619860254228115}, {"id": 26, "seek": 8636, "start": 96.0, "end": 99.6, "text": " structures about connected data.", "tokens": [50846, 9227, 466, 4582, 1412, 13, 51026], "temperature": 0.0, "avg_logprob": -0.10088912860767262, "compression_ratio": 1.7064846416382253, "no_speech_prob": 0.005619860254228115}, {"id": 27, "seek": 8636, "start": 99.6, "end": 102.8, "text": " And that's exactly what we see in the real world.", "tokens": [51026, 400, 300, 311, 2293, 437, 321, 536, 294, 264, 957, 1002, 13, 51186], "temperature": 0.0, "avg_logprob": -0.10088912860767262, "compression_ratio": 1.7064846416382253, "no_speech_prob": 0.005619860254228115}, {"id": 28, "seek": 8636, "start": 102.8, "end": 106.4, "text": " Graphs are actually one of the most natural ways to represent data.", "tokens": [51186, 21884, 82, 366, 767, 472, 295, 264, 881, 3303, 2098, 281, 2906, 1412, 13, 51366], "temperature": 0.0, "avg_logprob": -0.10088912860767262, "compression_ratio": 1.7064846416382253, "no_speech_prob": 0.005619860254228115}, {"id": 29, "seek": 8636, "start": 106.4, "end": 110.2, "text": " Social networks are of course something we are very familiar with, but graphs are very", "tokens": [51366, 9909, 9590, 366, 295, 1164, 746, 321, 366, 588, 4963, 365, 11, 457, 24877, 366, 588, 51556], "temperature": 0.0, "avg_logprob": -0.10088912860767262, "compression_ratio": 1.7064846416382253, "no_speech_prob": 0.005619860254228115}, {"id": 30, "seek": 8636, "start": 110.2, "end": 114.84, "text": " prevalent in many other domains, all the way from drug interactions to molecular networks", "tokens": [51556, 30652, 294, 867, 661, 25514, 11, 439, 264, 636, 490, 4110, 13280, 281, 19046, 9590, 51788], "temperature": 0.0, "avg_logprob": -0.10088912860767262, "compression_ratio": 1.7064846416382253, "no_speech_prob": 0.005619860254228115}, {"id": 31, "seek": 11484, "start": 114.84, "end": 116.72, "text": " to traffic networks.", "tokens": [50364, 281, 6419, 9590, 13, 50458], "temperature": 0.0, "avg_logprob": -0.13914337786999378, "compression_ratio": 1.6194331983805668, "no_speech_prob": 0.0011844136752188206}, {"id": 32, "seek": 11484, "start": 116.72, "end": 122.76, "text": " In the world of finance, you analyze transactions for things like fraud and they also are very", "tokens": [50458, 682, 264, 1002, 295, 10719, 11, 291, 12477, 16856, 337, 721, 411, 14560, 293, 436, 611, 366, 588, 50760], "temperature": 0.0, "avg_logprob": -0.13914337786999378, "compression_ratio": 1.6194331983805668, "no_speech_prob": 0.0011844136752188206}, {"id": 33, "seek": 11484, "start": 122.76, "end": 127.36, "text": " common in knowledge graphs that encode factual information about the world.", "tokens": [50760, 2689, 294, 3601, 24877, 300, 2058, 1429, 48029, 1589, 466, 264, 1002, 13, 50990], "temperature": 0.0, "avg_logprob": -0.13914337786999378, "compression_ratio": 1.6194331983805668, "no_speech_prob": 0.0011844136752188206}, {"id": 34, "seek": 11484, "start": 127.36, "end": 133.04, "text": " Kuzu is a graph database management system, which is a class of database management systems.", "tokens": [50990, 591, 48323, 307, 257, 4295, 8149, 4592, 1185, 11, 597, 307, 257, 1508, 295, 8149, 4592, 3652, 13, 51274], "temperature": 0.0, "avg_logprob": -0.13914337786999378, "compression_ratio": 1.6194331983805668, "no_speech_prob": 0.0011844136752188206}, {"id": 35, "seek": 11484, "start": 133.04, "end": 137.52, "text": " So I'll start by giving a general overview about GDBMS.", "tokens": [51274, 407, 286, 603, 722, 538, 2902, 257, 2674, 12492, 466, 460, 27735, 10288, 13, 51498], "temperature": 0.0, "avg_logprob": -0.13914337786999378, "compression_ratio": 1.6194331983805668, "no_speech_prob": 0.0011844136752188206}, {"id": 36, "seek": 11484, "start": 137.52, "end": 141.24, "text": " You generally have three components to any database system.", "tokens": [51498, 509, 5101, 362, 1045, 6677, 281, 604, 8149, 1185, 13, 51684], "temperature": 0.0, "avg_logprob": -0.13914337786999378, "compression_ratio": 1.6194331983805668, "no_speech_prob": 0.0011844136752188206}, {"id": 37, "seek": 14124, "start": 141.24, "end": 145.96, "text": " You have the data model, you have the query language, and you have the system implementation.", "tokens": [50364, 509, 362, 264, 1412, 2316, 11, 291, 362, 264, 14581, 2856, 11, 293, 291, 362, 264, 1185, 11420, 13, 50600], "temperature": 0.0, "avg_logprob": -0.10712082489677098, "compression_ratio": 1.8755555555555556, "no_speech_prob": 0.0047445399686694145}, {"id": 38, "seek": 14124, "start": 145.96, "end": 151.24, "text": " From the data model perspective, graph data models differ from the conventional relational", "tokens": [50600, 3358, 264, 1412, 2316, 4585, 11, 4295, 1412, 5245, 743, 490, 264, 16011, 38444, 50864], "temperature": 0.0, "avg_logprob": -0.10712082489677098, "compression_ratio": 1.8755555555555556, "no_speech_prob": 0.0047445399686694145}, {"id": 39, "seek": 14124, "start": 151.24, "end": 157.28, "text": " data model in the sense that you typically represent the data as nodes and edges.", "tokens": [50864, 1412, 2316, 294, 264, 2020, 300, 291, 5850, 2906, 264, 1412, 382, 13891, 293, 8819, 13, 51166], "temperature": 0.0, "avg_logprob": -0.10712082489677098, "compression_ratio": 1.8755555555555556, "no_speech_prob": 0.0047445399686694145}, {"id": 40, "seek": 14124, "start": 157.28, "end": 162.52, "text": " And you have key value properties on these nodes or edges.", "tokens": [51166, 400, 291, 362, 2141, 2158, 7221, 322, 613, 13891, 420, 8819, 13, 51428], "temperature": 0.0, "avg_logprob": -0.10712082489677098, "compression_ratio": 1.8755555555555556, "no_speech_prob": 0.0047445399686694145}, {"id": 41, "seek": 14124, "start": 162.52, "end": 166.96, "text": " In this example, with this triangle you see here, you have a cyclic relationship of transactions", "tokens": [51428, 682, 341, 1365, 11, 365, 341, 13369, 291, 536, 510, 11, 291, 362, 257, 38154, 1050, 2480, 295, 16856, 51650], "temperature": 0.0, "avg_logprob": -0.10712082489677098, "compression_ratio": 1.8755555555555556, "no_speech_prob": 0.0047445399686694145}, {"id": 42, "seek": 16696, "start": 166.96, "end": 172.76000000000002, "text": " between people, one, two, and three, where the nodes one, two, and three have property", "tokens": [50364, 1296, 561, 11, 472, 11, 732, 11, 293, 1045, 11, 689, 264, 13891, 472, 11, 732, 11, 293, 1045, 362, 4707, 50654], "temperature": 0.0, "avg_logprob": -0.15956370613791726, "compression_ratio": 1.7442748091603053, "no_speech_prob": 0.0033648584503680468}, {"id": 43, "seek": 16696, "start": 172.76000000000002, "end": 178.60000000000002, "text": " information on the name and the edges have the amount of the transaction as a property.", "tokens": [50654, 1589, 322, 264, 1315, 293, 264, 8819, 362, 264, 2372, 295, 264, 14425, 382, 257, 4707, 13, 50946], "temperature": 0.0, "avg_logprob": -0.15956370613791726, "compression_ratio": 1.7442748091603053, "no_speech_prob": 0.0033648584503680468}, {"id": 44, "seek": 16696, "start": 178.60000000000002, "end": 181.4, "text": " So this is called the property graph model of graphs.", "tokens": [50946, 407, 341, 307, 1219, 264, 4707, 4295, 2316, 295, 24877, 13, 51086], "temperature": 0.0, "avg_logprob": -0.15956370613791726, "compression_ratio": 1.7442748091603053, "no_speech_prob": 0.0033648584503680468}, {"id": 45, "seek": 16696, "start": 181.4, "end": 185.20000000000002, "text": " And it's very, very common and prevalent in the industry.", "tokens": [51086, 400, 309, 311, 588, 11, 588, 2689, 293, 30652, 294, 264, 3518, 13, 51276], "temperature": 0.0, "avg_logprob": -0.15956370613791726, "compression_ratio": 1.7442748091603053, "no_speech_prob": 0.0033648584503680468}, {"id": 46, "seek": 16696, "start": 185.20000000000002, "end": 189.52, "text": " But there's also another data model called RDF, resource description framework, which", "tokens": [51276, 583, 456, 311, 611, 1071, 1412, 2316, 1219, 49488, 37, 11, 7684, 3855, 8388, 11, 597, 51492], "temperature": 0.0, "avg_logprob": -0.15956370613791726, "compression_ratio": 1.7442748091603053, "no_speech_prob": 0.0033648584503680468}, {"id": 47, "seek": 16696, "start": 189.52, "end": 194.92000000000002, "text": " has a similar concept of subject, predicates, and objects, which represent a triple.", "tokens": [51492, 575, 257, 2531, 3410, 295, 3983, 11, 47336, 1024, 11, 293, 6565, 11, 597, 2906, 257, 15508, 13, 51762], "temperature": 0.0, "avg_logprob": -0.15956370613791726, "compression_ratio": 1.7442748091603053, "no_speech_prob": 0.0033648584503680468}, {"id": 48, "seek": 19492, "start": 194.92, "end": 199.44, "text": " The triple is a basic unit of data in the graph, but it's the same idea as the property", "tokens": [50364, 440, 15508, 307, 257, 3875, 4985, 295, 1412, 294, 264, 4295, 11, 457, 309, 311, 264, 912, 1558, 382, 264, 4707, 50590], "temperature": 0.0, "avg_logprob": -0.14235552530440074, "compression_ratio": 1.7239057239057238, "no_speech_prob": 0.003066977020353079}, {"id": 49, "seek": 19492, "start": 199.44, "end": 203.11999999999998, "text": " graph model except the implementation is different.", "tokens": [50590, 4295, 2316, 3993, 264, 11420, 307, 819, 13, 50774], "temperature": 0.0, "avg_logprob": -0.14235552530440074, "compression_ratio": 1.7239057239057238, "no_speech_prob": 0.003066977020353079}, {"id": 50, "seek": 19492, "start": 203.11999999999998, "end": 207.72, "text": " From a query language perspective, every graph database management system needs a high-level", "tokens": [50774, 3358, 257, 14581, 2856, 4585, 11, 633, 4295, 8149, 4592, 1185, 2203, 257, 1090, 12, 12418, 51004], "temperature": 0.0, "avg_logprob": -0.14235552530440074, "compression_ratio": 1.7239057239057238, "no_speech_prob": 0.003066977020353079}, {"id": 51, "seek": 19492, "start": 207.72, "end": 212.2, "text": " query language that's designed specifically with graph syntax.", "tokens": [51004, 14581, 2856, 300, 311, 4761, 4682, 365, 4295, 28431, 13, 51228], "temperature": 0.0, "avg_logprob": -0.14235552530440074, "compression_ratio": 1.7239057239057238, "no_speech_prob": 0.003066977020353079}, {"id": 52, "seek": 19492, "start": 212.2, "end": 213.79999999999998, "text": " And an example of this is shown here.", "tokens": [51228, 400, 364, 1365, 295, 341, 307, 4898, 510, 13, 51308], "temperature": 0.0, "avg_logprob": -0.14235552530440074, "compression_ratio": 1.7239057239057238, "no_speech_prob": 0.003066977020353079}, {"id": 53, "seek": 19492, "start": 213.79999999999998, "end": 217.39999999999998, "text": " This is the Cypher query language, which Kuzu implements.", "tokens": [51308, 639, 307, 264, 10295, 79, 511, 14581, 2856, 11, 597, 591, 48323, 704, 17988, 13, 51488], "temperature": 0.0, "avg_logprob": -0.14235552530440074, "compression_ratio": 1.7239057239057238, "no_speech_prob": 0.003066977020353079}, {"id": 54, "seek": 19492, "start": 217.39999999999998, "end": 222.44, "text": " And incidentally, Cypher is the same language that was invented and popularized by Neo4j,", "tokens": [51488, 400, 9348, 379, 11, 10295, 79, 511, 307, 264, 912, 2856, 300, 390, 14479, 293, 3743, 1602, 538, 24458, 19, 73, 11, 51740], "temperature": 0.0, "avg_logprob": -0.14235552530440074, "compression_ratio": 1.7239057239057238, "no_speech_prob": 0.003066977020353079}, {"id": 55, "seek": 19492, "start": 222.44, "end": 224.64, "text": " if anybody's used that before.", "tokens": [51740, 498, 4472, 311, 1143, 300, 949, 13, 51850], "temperature": 0.0, "avg_logprob": -0.14235552530440074, "compression_ratio": 1.7239057239057238, "no_speech_prob": 0.003066977020353079}, {"id": 56, "seek": 22464, "start": 224.64, "end": 231.6, "text": " But what this example query snippet shows is you have node information, A and B, of", "tokens": [50364, 583, 437, 341, 1365, 14581, 35623, 302, 3110, 307, 291, 362, 9984, 1589, 11, 316, 293, 363, 11, 295, 50712], "temperature": 0.0, "avg_logprob": -0.16971809695465395, "compression_ratio": 1.569672131147541, "no_speech_prob": 0.002499355236068368}, {"id": 57, "seek": 22464, "start": 231.6, "end": 236.27999999999997, "text": " type account, and you're matching on those nodes.", "tokens": [50712, 2010, 2696, 11, 293, 291, 434, 14324, 322, 729, 13891, 13, 50946], "temperature": 0.0, "avg_logprob": -0.16971809695465395, "compression_ratio": 1.569672131147541, "no_speech_prob": 0.002499355236068368}, {"id": 58, "seek": 22464, "start": 236.27999999999997, "end": 243.2, "text": " And then you're running a query, a joint query equivalent in a way that reminds you a lot", "tokens": [50946, 400, 550, 291, 434, 2614, 257, 14581, 11, 257, 7225, 14581, 10344, 294, 257, 636, 300, 12025, 291, 257, 688, 51292], "temperature": 0.0, "avg_logprob": -0.16971809695465395, "compression_ratio": 1.569672131147541, "no_speech_prob": 0.002499355236068368}, {"id": 59, "seek": 22464, "start": 243.2, "end": 244.2, "text": " of SQL.", "tokens": [51292, 295, 19200, 13, 51342], "temperature": 0.0, "avg_logprob": -0.16971809695465395, "compression_ratio": 1.569672131147541, "no_speech_prob": 0.002499355236068368}, {"id": 60, "seek": 22464, "start": 244.2, "end": 248.83999999999997, "text": " It's very declarative and it's very high-level reminiscent of SQL.", "tokens": [51342, 467, 311, 588, 16694, 1166, 293, 309, 311, 588, 1090, 12, 12418, 44304, 295, 19200, 13, 51574], "temperature": 0.0, "avg_logprob": -0.16971809695465395, "compression_ratio": 1.569672131147541, "no_speech_prob": 0.002499355236068368}, {"id": 61, "seek": 22464, "start": 248.83999999999997, "end": 253.56, "text": " From a system implementation standpoint, universally, I think it's hard to come with", "tokens": [51574, 3358, 257, 1185, 11420, 15827, 11, 43995, 11, 286, 519, 309, 311, 1152, 281, 808, 365, 51810], "temperature": 0.0, "avg_logprob": -0.16971809695465395, "compression_ratio": 1.569672131147541, "no_speech_prob": 0.002499355236068368}, {"id": 62, "seek": 25356, "start": 254.12, "end": 260.4, "text": " a statement that covers all graph systems, but in general, they implement storage structures,", "tokens": [50392, 257, 5629, 300, 10538, 439, 4295, 3652, 11, 457, 294, 2674, 11, 436, 4445, 6725, 9227, 11, 50706], "temperature": 0.0, "avg_logprob": -0.1551027498747173, "compression_ratio": 1.7166666666666666, "no_speech_prob": 0.0026684636250138283}, {"id": 63, "seek": 25356, "start": 260.4, "end": 263.32, "text": " indices, and operators that are specific to graphs.", "tokens": [50706, 43840, 11, 293, 19077, 300, 366, 2685, 281, 24877, 13, 50852], "temperature": 0.0, "avg_logprob": -0.1551027498747173, "compression_ratio": 1.7166666666666666, "no_speech_prob": 0.0026684636250138283}, {"id": 64, "seek": 25356, "start": 263.32, "end": 266.28000000000003, "text": " One example is the shortest path operator.", "tokens": [50852, 1485, 1365, 307, 264, 31875, 3100, 12973, 13, 51000], "temperature": 0.0, "avg_logprob": -0.1551027498747173, "compression_ratio": 1.7166666666666666, "no_speech_prob": 0.0026684636250138283}, {"id": 65, "seek": 25356, "start": 266.28000000000003, "end": 270.0, "text": " These are operators that are not prevalent in relational systems but are very common", "tokens": [51000, 1981, 366, 19077, 300, 366, 406, 30652, 294, 38444, 3652, 457, 366, 588, 2689, 51186], "temperature": 0.0, "avg_logprob": -0.1551027498747173, "compression_ratio": 1.7166666666666666, "no_speech_prob": 0.0026684636250138283}, {"id": 66, "seek": 25356, "start": 270.0, "end": 273.0, "text": " in graph systems.", "tokens": [51186, 294, 4295, 3652, 13, 51336], "temperature": 0.0, "avg_logprob": -0.1551027498747173, "compression_ratio": 1.7166666666666666, "no_speech_prob": 0.0026684636250138283}, {"id": 67, "seek": 25356, "start": 273.0, "end": 276.12, "text": " There are many reasons why you might need graph modeling, but I'll cover just a couple", "tokens": [51336, 821, 366, 867, 4112, 983, 291, 1062, 643, 4295, 15983, 11, 457, 286, 603, 2060, 445, 257, 1916, 51492], "temperature": 0.0, "avg_logprob": -0.1551027498747173, "compression_ratio": 1.7166666666666666, "no_speech_prob": 0.0026684636250138283}, {"id": 68, "seek": 25356, "start": 276.12, "end": 279.24, "text": " of them in these next two slides.", "tokens": [51492, 295, 552, 294, 613, 958, 732, 9788, 13, 51648], "temperature": 0.0, "avg_logprob": -0.1551027498747173, "compression_ratio": 1.7166666666666666, "no_speech_prob": 0.0026684636250138283}, {"id": 69, "seek": 27924, "start": 279.32, "end": 285.84000000000003, "text": " For an example, let's take this query where we are trying to find direct or indirect possible", "tokens": [50368, 1171, 364, 1365, 11, 718, 311, 747, 341, 14581, 689, 321, 366, 1382, 281, 915, 2047, 420, 19523, 1944, 50694], "temperature": 0.0, "avg_logprob": -0.11806946416055003, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.013163624331355095}, {"id": 70, "seek": 27924, "start": 285.84000000000003, "end": 291.0, "text": " sources of money flow into a person's account from a particular location.", "tokens": [50694, 7139, 295, 1460, 3095, 666, 257, 954, 311, 2696, 490, 257, 1729, 4914, 13, 50952], "temperature": 0.0, "avg_logprob": -0.11806946416055003, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.013163624331355095}, {"id": 71, "seek": 27924, "start": 291.0, "end": 296.8, "text": " So in this example, the person is Alice, represented by node B in this Cypher query,", "tokens": [50952, 407, 294, 341, 1365, 11, 264, 954, 307, 16004, 11, 10379, 538, 9984, 363, 294, 341, 10295, 79, 511, 14581, 11, 51242], "temperature": 0.0, "avg_logprob": -0.11806946416055003, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.013163624331355095}, {"id": 72, "seek": 27924, "start": 296.8, "end": 303.32, "text": " and we are matching on the owner of that account, which is Alice, but also matching", "tokens": [51242, 293, 321, 366, 14324, 322, 264, 7289, 295, 300, 2696, 11, 597, 307, 16004, 11, 457, 611, 14324, 51568], "temperature": 0.0, "avg_logprob": -0.11806946416055003, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.013163624331355095}, {"id": 73, "seek": 27924, "start": 303.32, "end": 306.84000000000003, "text": " on account A, whose location is Canada.", "tokens": [51568, 322, 2696, 316, 11, 6104, 4914, 307, 6309, 13, 51744], "temperature": 0.0, "avg_logprob": -0.11806946416055003, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.013163624331355095}, {"id": 74, "seek": 30684, "start": 306.91999999999996, "end": 311.84, "text": " The key here is that the middle portion, which is the transfer star, that star syntax", "tokens": [50368, 440, 2141, 510, 307, 300, 264, 2808, 8044, 11, 597, 307, 264, 5003, 3543, 11, 300, 3543, 28431, 50614], "temperature": 0.0, "avg_logprob": -0.1156663388277577, "compression_ratio": 1.6448979591836734, "no_speech_prob": 0.0030162592884153128}, {"id": 75, "seek": 30684, "start": 311.84, "end": 315.44, "text": " is a high-level general syntax called clean star.", "tokens": [50614, 307, 257, 1090, 12, 12418, 2674, 28431, 1219, 2541, 3543, 13, 50794], "temperature": 0.0, "avg_logprob": -0.1156663388277577, "compression_ratio": 1.6448979591836734, "no_speech_prob": 0.0030162592884153128}, {"id": 76, "seek": 30684, "start": 315.44, "end": 321.28, "text": " It's used to implement indirect and recursive joins.", "tokens": [50794, 467, 311, 1143, 281, 4445, 19523, 293, 20560, 488, 24397, 13, 51086], "temperature": 0.0, "avg_logprob": -0.1156663388277577, "compression_ratio": 1.6448979591836734, "no_speech_prob": 0.0030162592884153128}, {"id": 77, "seek": 30684, "start": 321.28, "end": 323.84, "text": " As you can see, the query is quite concise.", "tokens": [51086, 1018, 291, 393, 536, 11, 264, 14581, 307, 1596, 44882, 13, 51214], "temperature": 0.0, "avg_logprob": -0.1156663388277577, "compression_ratio": 1.6448979591836734, "no_speech_prob": 0.0030162592884153128}, {"id": 78, "seek": 30684, "start": 323.84, "end": 325.32, "text": " It's quite readable.", "tokens": [51214, 467, 311, 1596, 49857, 13, 51288], "temperature": 0.0, "avg_logprob": -0.1156663388277577, "compression_ratio": 1.6448979591836734, "no_speech_prob": 0.0030162592884153128}, {"id": 79, "seek": 30684, "start": 325.32, "end": 330.47999999999996, "text": " You can do this sort of query in SQL, but it's a recursive query and it's not as easy.", "tokens": [51288, 509, 393, 360, 341, 1333, 295, 14581, 294, 19200, 11, 457, 309, 311, 257, 20560, 488, 14581, 293, 309, 311, 406, 382, 1858, 13, 51546], "temperature": 0.0, "avg_logprob": -0.1156663388277577, "compression_ratio": 1.6448979591836734, "no_speech_prob": 0.0030162592884153128}, {"id": 80, "seek": 30684, "start": 330.47999999999996, "end": 334.44, "text": " It's going to be a lot more verbose and not that easy to read.", "tokens": [51546, 467, 311, 516, 281, 312, 257, 688, 544, 9595, 541, 293, 406, 300, 1858, 281, 1401, 13, 51744], "temperature": 0.0, "avg_logprob": -0.1156663388277577, "compression_ratio": 1.6448979591836734, "no_speech_prob": 0.0030162592884153128}, {"id": 81, "seek": 33444, "start": 334.44, "end": 338.44, "text": " One other example of this would be the shortest path query, which is a lot harder to do in", "tokens": [50364, 1485, 661, 1365, 295, 341, 576, 312, 264, 31875, 3100, 14581, 11, 597, 307, 257, 688, 6081, 281, 360, 294, 50564], "temperature": 0.0, "avg_logprob": -0.14777351638018074, "compression_ratio": 1.6348122866894197, "no_speech_prob": 0.0002689904940780252}, {"id": 82, "seek": 33444, "start": 338.44, "end": 342.64, "text": " recursive SQL, but in Cypher, it's very, very straightforward.", "tokens": [50564, 20560, 488, 19200, 11, 457, 294, 10295, 79, 511, 11, 309, 311, 588, 11, 588, 15325, 13, 50774], "temperature": 0.0, "avg_logprob": -0.14777351638018074, "compression_ratio": 1.6348122866894197, "no_speech_prob": 0.0002689904940780252}, {"id": 83, "seek": 33444, "start": 342.64, "end": 348.56, "text": " It's just an additional clause that you add attached onto the previous query.", "tokens": [50774, 467, 311, 445, 364, 4497, 25925, 300, 291, 909, 8570, 3911, 264, 3894, 14581, 13, 51070], "temperature": 0.0, "avg_logprob": -0.14777351638018074, "compression_ratio": 1.6348122866894197, "no_speech_prob": 0.0002689904940780252}, {"id": 84, "seek": 33444, "start": 348.56, "end": 353.04, "text": " Another case where you need graph modeling is in heterogeneous data.", "tokens": [51070, 3996, 1389, 689, 291, 643, 4295, 15983, 307, 294, 20789, 31112, 1412, 13, 51294], "temperature": 0.0, "avg_logprob": -0.14777351638018074, "compression_ratio": 1.6348122866894197, "no_speech_prob": 0.0002689904940780252}, {"id": 85, "seek": 33444, "start": 353.04, "end": 360.36, "text": " This example here shows an example of Dbpedia, which is a structured version of Wikipedia,", "tokens": [51294, 639, 1365, 510, 3110, 364, 1365, 295, 413, 65, 3452, 654, 11, 597, 307, 257, 18519, 3037, 295, 28999, 11, 51660], "temperature": 0.0, "avg_logprob": -0.14777351638018074, "compression_ratio": 1.6348122866894197, "no_speech_prob": 0.0002689904940780252}, {"id": 86, "seek": 33444, "start": 360.36, "end": 364.24, "text": " and we're taking this example of the location we're in right now, University, Liberator", "tokens": [51660, 293, 321, 434, 1940, 341, 1365, 295, 264, 4914, 321, 434, 294, 558, 586, 11, 3535, 11, 14175, 1639, 51854], "temperature": 0.0, "avg_logprob": -0.14777351638018074, "compression_ratio": 1.6348122866894197, "no_speech_prob": 0.0002689904940780252}, {"id": 87, "seek": 36424, "start": 364.24, "end": 366.32, "text": " and Brussels.", "tokens": [50364, 293, 38717, 13, 50468], "temperature": 0.0, "avg_logprob": -0.1574755695378669, "compression_ratio": 1.7925311203319503, "no_speech_prob": 0.018955355510115623}, {"id": 88, "seek": 36424, "start": 366.32, "end": 373.64, "text": " On the left is the way it's stored in structured form, where you have key value properties,", "tokens": [50468, 1282, 264, 1411, 307, 264, 636, 309, 311, 12187, 294, 18519, 1254, 11, 689, 291, 362, 2141, 2158, 7221, 11, 50834], "temperature": 0.0, "avg_logprob": -0.1574755695378669, "compression_ratio": 1.7925311203319503, "no_speech_prob": 0.018955355510115623}, {"id": 89, "seek": 36424, "start": 373.64, "end": 376.36, "text": " and each of these properties links to other properties.", "tokens": [50834, 293, 1184, 295, 613, 7221, 6123, 281, 661, 7221, 13, 50970], "temperature": 0.0, "avg_logprob": -0.1574755695378669, "compression_ratio": 1.7925311203319503, "no_speech_prob": 0.018955355510115623}, {"id": 90, "seek": 36424, "start": 376.36, "end": 381.0, "text": " But on the right, we schematically represent that as a graph.", "tokens": [50970, 583, 322, 264, 558, 11, 321, 22627, 5030, 2906, 300, 382, 257, 4295, 13, 51202], "temperature": 0.0, "avg_logprob": -0.1574755695378669, "compression_ratio": 1.7925311203319503, "no_speech_prob": 0.018955355510115623}, {"id": 91, "seek": 36424, "start": 381.0, "end": 384.04, "text": " As you can see, the university is linked to the city of Brussels.", "tokens": [51202, 1018, 291, 393, 536, 11, 264, 5454, 307, 9408, 281, 264, 2307, 295, 38717, 13, 51354], "temperature": 0.0, "avg_logprob": -0.1574755695378669, "compression_ratio": 1.7925311203319503, "no_speech_prob": 0.018955355510115623}, {"id": 92, "seek": 36424, "start": 384.04, "end": 388.84000000000003, "text": " It's also linked to the country of Belgium, what affiliations it has, and each of these", "tokens": [51354, 467, 311, 611, 9408, 281, 264, 1941, 295, 28094, 11, 437, 14863, 763, 309, 575, 11, 293, 1184, 295, 613, 51594], "temperature": 0.0, "avg_logprob": -0.1574755695378669, "compression_ratio": 1.7925311203319503, "no_speech_prob": 0.018955355510115623}, {"id": 93, "seek": 36424, "start": 388.84000000000003, "end": 393.84000000000003, "text": " individual resources can be linked to other resources.", "tokens": [51594, 2609, 3593, 393, 312, 9408, 281, 661, 3593, 13, 51844], "temperature": 0.0, "avg_logprob": -0.1574755695378669, "compression_ratio": 1.7925311203319503, "no_speech_prob": 0.018955355510115623}, {"id": 94, "seek": 39384, "start": 393.84, "end": 398.76, "text": " This actually expresses the power of a graph model, because doing this with a tabular form", "tokens": [50364, 639, 767, 39204, 264, 1347, 295, 257, 4295, 2316, 11, 570, 884, 341, 365, 257, 4421, 1040, 1254, 50610], "temperature": 0.0, "avg_logprob": -0.16922501859993772, "compression_ratio": 1.6441281138790036, "no_speech_prob": 0.003111540339887142}, {"id": 95, "seek": 39384, "start": 398.76, "end": 402.79999999999995, "text": " of data would be almost impossible, because that's how Wikipedia is structured.", "tokens": [50610, 295, 1412, 576, 312, 1920, 6243, 11, 570, 300, 311, 577, 28999, 307, 18519, 13, 50812], "temperature": 0.0, "avg_logprob": -0.16922501859993772, "compression_ratio": 1.6441281138790036, "no_speech_prob": 0.003111540339887142}, {"id": 96, "seek": 39384, "start": 402.79999999999995, "end": 406.71999999999997, "text": " It's a lot of connected information.", "tokens": [50812, 467, 311, 257, 688, 295, 4582, 1589, 13, 51008], "temperature": 0.0, "avg_logprob": -0.16922501859993772, "compression_ratio": 1.6441281138790036, "no_speech_prob": 0.003111540339887142}, {"id": 97, "seek": 39384, "start": 406.71999999999997, "end": 410.84, "text": " This leads us to the question of what is a feature set of a competent graph database.", "tokens": [51008, 639, 6689, 505, 281, 264, 1168, 295, 437, 307, 257, 4111, 992, 295, 257, 29998, 4295, 8149, 13, 51214], "temperature": 0.0, "avg_logprob": -0.16922501859993772, "compression_ratio": 1.6441281138790036, "no_speech_prob": 0.003111540339887142}, {"id": 98, "seek": 39384, "start": 410.84, "end": 417.32, "text": " We list a few of them here, but I think it's very difficult to go through each of them", "tokens": [51214, 492, 1329, 257, 1326, 295, 552, 510, 11, 457, 286, 519, 309, 311, 588, 2252, 281, 352, 807, 1184, 295, 552, 51538], "temperature": 0.0, "avg_logprob": -0.16922501859993772, "compression_ratio": 1.6441281138790036, "no_speech_prob": 0.003111540339887142}, {"id": 99, "seek": 39384, "start": 417.32, "end": 418.64, "text": " in the time we have.", "tokens": [51538, 294, 264, 565, 321, 362, 13, 51604], "temperature": 0.0, "avg_logprob": -0.16922501859993772, "compression_ratio": 1.6441281138790036, "no_speech_prob": 0.003111540339887142}, {"id": 100, "seek": 39384, "start": 418.64, "end": 422.44, "text": " We do have a blog post that covers this in much more detail.", "tokens": [51604, 492, 360, 362, 257, 6968, 2183, 300, 10538, 341, 294, 709, 544, 2607, 13, 51794], "temperature": 0.0, "avg_logprob": -0.16922501859993772, "compression_ratio": 1.6441281138790036, "no_speech_prob": 0.003111540339887142}, {"id": 101, "seek": 42244, "start": 422.44, "end": 427.2, "text": " It's called What Every GDBMS Should Do and Division.", "tokens": [50364, 467, 311, 1219, 708, 2048, 460, 27735, 10288, 6454, 1144, 293, 17183, 13, 50602], "temperature": 0.0, "avg_logprob": -0.19353957970937094, "compression_ratio": 1.55078125, "no_speech_prob": 0.024889890104532242}, {"id": 102, "seek": 42244, "start": 427.2, "end": 434.96, "text": " But in a nutshell, every GDBMS has to support things like many to many growing joins, recursive", "tokens": [50602, 583, 294, 257, 37711, 11, 633, 460, 27735, 10288, 575, 281, 1406, 721, 411, 867, 281, 867, 4194, 24397, 11, 20560, 488, 50990], "temperature": 0.0, "avg_logprob": -0.19353957970937094, "compression_ratio": 1.55078125, "no_speech_prob": 0.024889890104532242}, {"id": 103, "seek": 42244, "start": 434.96, "end": 440.08, "text": " joins on top of heterogeneous data sets, for example, knowledge graphs.", "tokens": [50990, 24397, 322, 1192, 295, 20789, 31112, 1412, 6352, 11, 337, 1365, 11, 3601, 24877, 13, 51246], "temperature": 0.0, "avg_logprob": -0.19353957970937094, "compression_ratio": 1.55078125, "no_speech_prob": 0.024889890104532242}, {"id": 104, "seek": 42244, "start": 440.08, "end": 444.12, "text": " Another thing that we can highlight here is the schema querying aspect, where in this last", "tokens": [51246, 3996, 551, 300, 321, 393, 5078, 510, 307, 264, 34078, 7083, 1840, 4171, 11, 689, 294, 341, 1036, 51448], "temperature": 0.0, "avg_logprob": -0.19353957970937094, "compression_ratio": 1.55078125, "no_speech_prob": 0.024889890104532242}, {"id": 105, "seek": 42244, "start": 444.12, "end": 451.44, "text": " example, you have account information and transaction edges, and you're able to query", "tokens": [51448, 1365, 11, 291, 362, 2696, 1589, 293, 14425, 8819, 11, 293, 291, 434, 1075, 281, 14581, 51814], "temperature": 0.0, "avg_logprob": -0.19353957970937094, "compression_ratio": 1.55078125, "no_speech_prob": 0.024889890104532242}, {"id": 106, "seek": 45144, "start": 451.44, "end": 453.48, "text": " on the type of the edge.", "tokens": [50364, 322, 264, 2010, 295, 264, 4691, 13, 50466], "temperature": 0.0, "avg_logprob": -0.1791452478479456, "compression_ratio": 1.7327188940092166, "no_speech_prob": 0.00967019610106945}, {"id": 107, "seek": 45144, "start": 453.48, "end": 455.92, "text": " Let's say you have two different kinds of transactions.", "tokens": [50466, 961, 311, 584, 291, 362, 732, 819, 3685, 295, 16856, 13, 50588], "temperature": 0.0, "avg_logprob": -0.1791452478479456, "compression_ratio": 1.7327188940092166, "no_speech_prob": 0.00967019610106945}, {"id": 108, "seek": 45144, "start": 455.92, "end": 460.6, "text": " You don't want each of those on either side of the middle node to be the same transaction", "tokens": [50588, 509, 500, 380, 528, 1184, 295, 729, 322, 2139, 1252, 295, 264, 2808, 9984, 281, 312, 264, 912, 14425, 50822], "temperature": 0.0, "avg_logprob": -0.1791452478479456, "compression_ratio": 1.7327188940092166, "no_speech_prob": 0.00967019610106945}, {"id": 109, "seek": 45144, "start": 460.6, "end": 461.6, "text": " type.", "tokens": [50822, 2010, 13, 50872], "temperature": 0.0, "avg_logprob": -0.1791452478479456, "compression_ratio": 1.7327188940092166, "no_speech_prob": 0.00967019610106945}, {"id": 110, "seek": 45144, "start": 461.6, "end": 467.96, "text": " You're able to say, you apply a predicate on the edge to say that you don't want nodes", "tokens": [50872, 509, 434, 1075, 281, 584, 11, 291, 3079, 257, 3852, 8700, 322, 264, 4691, 281, 584, 300, 291, 500, 380, 528, 13891, 51190], "temperature": 0.0, "avg_logprob": -0.1791452478479456, "compression_ratio": 1.7327188940092166, "no_speech_prob": 0.00967019610106945}, {"id": 111, "seek": 45144, "start": 467.96, "end": 469.6, "text": " of a particular type.", "tokens": [51190, 295, 257, 1729, 2010, 13, 51272], "temperature": 0.0, "avg_logprob": -0.1791452478479456, "compression_ratio": 1.7327188940092166, "no_speech_prob": 0.00967019610106945}, {"id": 112, "seek": 45144, "start": 469.6, "end": 472.08, "text": " This is the sort of thing that you can't do in SQL.", "tokens": [51272, 639, 307, 264, 1333, 295, 551, 300, 291, 393, 380, 360, 294, 19200, 13, 51396], "temperature": 0.0, "avg_logprob": -0.1791452478479456, "compression_ratio": 1.7327188940092166, "no_speech_prob": 0.00967019610106945}, {"id": 113, "seek": 45144, "start": 472.08, "end": 475.48, "text": " You can only do this in a graph model.", "tokens": [51396, 509, 393, 787, 360, 341, 294, 257, 4295, 2316, 13, 51566], "temperature": 0.0, "avg_logprob": -0.1791452478479456, "compression_ratio": 1.7327188940092166, "no_speech_prob": 0.00967019610106945}, {"id": 114, "seek": 47548, "start": 475.48, "end": 481.92, "text": " The vision of Kuzu as a graph database management system is it aims to represent the state of", "tokens": [50364, 440, 5201, 295, 591, 48323, 382, 257, 4295, 8149, 4592, 1185, 307, 309, 24683, 281, 2906, 264, 1785, 295, 50686], "temperature": 0.0, "avg_logprob": -0.11254427773611886, "compression_ratio": 1.6338582677165354, "no_speech_prob": 0.002016306621953845}, {"id": 115, "seek": 47548, "start": 481.92, "end": 487.48, "text": " the art of how graphs should be stored, indexed, and queried.", "tokens": [50686, 264, 1523, 295, 577, 24877, 820, 312, 12187, 11, 8186, 292, 11, 293, 7083, 1091, 13, 50964], "temperature": 0.0, "avg_logprob": -0.11254427773611886, "compression_ratio": 1.6338582677165354, "no_speech_prob": 0.002016306621953845}, {"id": 116, "seek": 47548, "start": 487.48, "end": 491.68, "text": " It does this by being highly scalable to several terabytes of data.", "tokens": [50964, 467, 775, 341, 538, 885, 5405, 38481, 281, 2940, 1796, 24538, 295, 1412, 13, 51174], "temperature": 0.0, "avg_logprob": -0.11254427773611886, "compression_ratio": 1.6338582677165354, "no_speech_prob": 0.002016306621953845}, {"id": 117, "seek": 47548, "start": 491.68, "end": 494.92, "text": " It's very fast in terms of query speed.", "tokens": [51174, 467, 311, 588, 2370, 294, 2115, 295, 14581, 3073, 13, 51336], "temperature": 0.0, "avg_logprob": -0.11254427773611886, "compression_ratio": 1.6338582677165354, "no_speech_prob": 0.002016306621953845}, {"id": 118, "seek": 47548, "start": 494.92, "end": 498.48, "text": " It supports the property graph model, which we described earlier.", "tokens": [51336, 467, 9346, 264, 4707, 4295, 2316, 11, 597, 321, 7619, 3071, 13, 51514], "temperature": 0.0, "avg_logprob": -0.11254427773611886, "compression_ratio": 1.6338582677165354, "no_speech_prob": 0.002016306621953845}, {"id": 119, "seek": 47548, "start": 498.48, "end": 504.8, "text": " It also supports the RDF data model, which is going to be coming in the next release.", "tokens": [51514, 467, 611, 9346, 264, 49488, 37, 1412, 2316, 11, 597, 307, 516, 281, 312, 1348, 294, 264, 958, 4374, 13, 51830], "temperature": 0.0, "avg_logprob": -0.11254427773611886, "compression_ratio": 1.6338582677165354, "no_speech_prob": 0.002016306621953845}, {"id": 120, "seek": 50480, "start": 504.8, "end": 508.64, "text": " It does so via a high-level query language, Cypher.", "tokens": [50364, 467, 775, 370, 5766, 257, 1090, 12, 12418, 14581, 2856, 11, 10295, 79, 511, 13, 50556], "temperature": 0.0, "avg_logprob": -0.19930431577894422, "compression_ratio": 1.5372549019607844, "no_speech_prob": 0.0031158295460045338}, {"id": 121, "seek": 50480, "start": 508.64, "end": 512.32, "text": " It's easy to use and uses an embeddable architecture.", "tokens": [50556, 467, 311, 1858, 281, 764, 293, 4960, 364, 12240, 67, 712, 9482, 13, 50740], "temperature": 0.0, "avg_logprob": -0.19930431577894422, "compression_ratio": 1.5372549019607844, "no_speech_prob": 0.0031158295460045338}, {"id": 122, "seek": 50480, "start": 512.32, "end": 516.8, "text": " We like to think of ourselves as like duck DB or SQLite, but for graphs.", "tokens": [50740, 492, 411, 281, 519, 295, 4175, 382, 411, 12482, 26754, 420, 19200, 642, 11, 457, 337, 24877, 13, 50964], "temperature": 0.0, "avg_logprob": -0.19930431577894422, "compression_ratio": 1.5372549019607844, "no_speech_prob": 0.0031158295460045338}, {"id": 123, "seek": 50480, "start": 516.8, "end": 521.4, "text": " If you ever come across either of the other two relational systems, Kuzu is like a graph", "tokens": [50964, 759, 291, 1562, 808, 2108, 2139, 295, 264, 661, 732, 38444, 3652, 11, 591, 48323, 307, 411, 257, 4295, 51194], "temperature": 0.0, "avg_logprob": -0.19930431577894422, "compression_ratio": 1.5372549019607844, "no_speech_prob": 0.0031158295460045338}, {"id": 124, "seek": 50480, "start": 521.4, "end": 523.5600000000001, "text": " analog to those systems.", "tokens": [51194, 16660, 281, 729, 3652, 13, 51302], "temperature": 0.0, "avg_logprob": -0.19930431577894422, "compression_ratio": 1.5372549019607844, "no_speech_prob": 0.0031158295460045338}, {"id": 125, "seek": 50480, "start": 523.5600000000001, "end": 527.84, "text": " I should also note here that Kuzu is based on many years of research at the University", "tokens": [51302, 286, 820, 611, 3637, 510, 300, 591, 48323, 307, 2361, 322, 867, 924, 295, 2132, 412, 264, 3535, 51516], "temperature": 0.0, "avg_logprob": -0.19930431577894422, "compression_ratio": 1.5372549019607844, "no_speech_prob": 0.0031158295460045338}, {"id": 126, "seek": 50480, "start": 527.84, "end": 529.44, "text": " of Waterloo.", "tokens": [51516, 295, 8772, 38511, 13, 51596], "temperature": 0.0, "avg_logprob": -0.19930431577894422, "compression_ratio": 1.5372549019607844, "no_speech_prob": 0.0031158295460045338}, {"id": 127, "seek": 52944, "start": 529.44, "end": 535.8800000000001, "text": " It's now being developed in an independent company called Kuzu Inc, which we're from.", "tokens": [50364, 467, 311, 586, 885, 4743, 294, 364, 6695, 2237, 1219, 591, 48323, 7779, 11, 597, 321, 434, 490, 13, 50686], "temperature": 0.0, "avg_logprob": -0.14901412112041584, "compression_ratio": 1.6908396946564885, "no_speech_prob": 0.003423378337174654}, {"id": 128, "seek": 52944, "start": 535.8800000000001, "end": 539.48, "text": " The other big vision that Kuzu has from a data science perspective, specifically graph", "tokens": [50686, 440, 661, 955, 5201, 300, 591, 48323, 575, 490, 257, 1412, 3497, 4585, 11, 4682, 4295, 50866], "temperature": 0.0, "avg_logprob": -0.14901412112041584, "compression_ratio": 1.6908396946564885, "no_speech_prob": 0.003423378337174654}, {"id": 129, "seek": 52944, "start": 539.48, "end": 545.32, "text": " data science perspective, is to be the go-to back end for graph modeling and data science.", "tokens": [50866, 1412, 3497, 4585, 11, 307, 281, 312, 264, 352, 12, 1353, 646, 917, 337, 4295, 15983, 293, 1412, 3497, 13, 51158], "temperature": 0.0, "avg_logprob": -0.14901412112041584, "compression_ratio": 1.6908396946564885, "no_speech_prob": 0.003423378337174654}, {"id": 130, "seek": 52944, "start": 545.32, "end": 551.5200000000001, "text": " Essentially the vision here is if you look at the bottom half of this figure, you have", "tokens": [51158, 23596, 264, 5201, 510, 307, 498, 291, 574, 412, 264, 2767, 1922, 295, 341, 2573, 11, 291, 362, 51468], "temperature": 0.0, "avg_logprob": -0.14901412112041584, "compression_ratio": 1.6908396946564885, "no_speech_prob": 0.003423378337174654}, {"id": 131, "seek": 52944, "start": 551.5200000000001, "end": 558.8800000000001, "text": " a lot of data sitting in disparate sources like data lakes, warehouses, relational databases", "tokens": [51468, 257, 688, 295, 1412, 3798, 294, 14548, 473, 7139, 411, 1412, 25595, 11, 17464, 29578, 11, 38444, 22380, 51836], "temperature": 0.0, "avg_logprob": -0.14901412112041584, "compression_ratio": 1.6908396946564885, "no_speech_prob": 0.003423378337174654}, {"id": 132, "seek": 55888, "start": 558.92, "end": 562.32, "text": " all the way from Postgres and many others.", "tokens": [50366, 439, 264, 636, 490, 10223, 45189, 293, 867, 2357, 13, 50536], "temperature": 0.0, "avg_logprob": -0.13496024634248466, "compression_ratio": 1.620253164556962, "no_speech_prob": 0.0009511044481769204}, {"id": 133, "seek": 55888, "start": 562.32, "end": 566.68, "text": " There's a lot of interoperability challenges that you have with these data sources.", "tokens": [50536, 821, 311, 257, 688, 295, 728, 7192, 2310, 4759, 300, 291, 362, 365, 613, 1412, 7139, 13, 50754], "temperature": 0.0, "avg_logprob": -0.13496024634248466, "compression_ratio": 1.620253164556962, "no_speech_prob": 0.0009511044481769204}, {"id": 134, "seek": 55888, "start": 566.68, "end": 570.8, "text": " Even though you have structured data, in many cases working with them as a graph is quite", "tokens": [50754, 2754, 1673, 291, 362, 18519, 1412, 11, 294, 867, 3331, 1364, 365, 552, 382, 257, 4295, 307, 1596, 50960], "temperature": 0.0, "avg_logprob": -0.13496024634248466, "compression_ratio": 1.620253164556962, "no_speech_prob": 0.0009511044481769204}, {"id": 135, "seek": 55888, "start": 570.8, "end": 575.08, "text": " challenging because of the movement of data across the systems into a powerful graph database", "tokens": [50960, 7595, 570, 295, 264, 3963, 295, 1412, 2108, 264, 3652, 666, 257, 4005, 4295, 8149, 51174], "temperature": 0.0, "avg_logprob": -0.13496024634248466, "compression_ratio": 1.620253164556962, "no_speech_prob": 0.0009511044481769204}, {"id": 136, "seek": 55888, "start": 575.08, "end": 576.08, "text": " back end.", "tokens": [51174, 646, 917, 13, 51224], "temperature": 0.0, "avg_logprob": -0.13496024634248466, "compression_ratio": 1.620253164556962, "no_speech_prob": 0.0009511044481769204}, {"id": 137, "seek": 55888, "start": 576.08, "end": 582.2, "text": " Kuzu aims to be a simpler way and sort of an interface to that.", "tokens": [51224, 591, 48323, 24683, 281, 312, 257, 18587, 636, 293, 1333, 295, 364, 9226, 281, 300, 13, 51530], "temperature": 0.0, "avg_logprob": -0.13496024634248466, "compression_ratio": 1.620253164556962, "no_speech_prob": 0.0009511044481769204}, {"id": 138, "seek": 58220, "start": 582.2, "end": 589.9200000000001, "text": " In the upper half, the aim of this is to make graph data science much more accessible", "tokens": [50364, 682, 264, 6597, 1922, 11, 264, 5939, 295, 341, 307, 281, 652, 4295, 1412, 3497, 709, 544, 9515, 50750], "temperature": 0.0, "avg_logprob": -0.18454545916933002, "compression_ratio": 1.6614173228346456, "no_speech_prob": 0.005881385412067175}, {"id": 139, "seek": 58220, "start": 589.9200000000001, "end": 596.44, "text": " in the sense that we provide zero copy access to the data by writing out the format that", "tokens": [50750, 294, 264, 2020, 300, 321, 2893, 4018, 5055, 2105, 281, 264, 1412, 538, 3579, 484, 264, 7877, 300, 51076], "temperature": 0.0, "avg_logprob": -0.18454545916933002, "compression_ratio": 1.6614173228346456, "no_speech_prob": 0.005881385412067175}, {"id": 140, "seek": 58220, "start": 596.44, "end": 597.84, "text": " is native to those libraries.", "tokens": [51076, 307, 8470, 281, 729, 15148, 13, 51146], "temperature": 0.0, "avg_logprob": -0.18454545916933002, "compression_ratio": 1.6614173228346456, "no_speech_prob": 0.005881385412067175}, {"id": 141, "seek": 58220, "start": 597.84, "end": 600.6, "text": " For example, PyTorchumetric, NetworkX.", "tokens": [51146, 1171, 1365, 11, 9953, 51, 284, 339, 449, 17475, 11, 12640, 55, 13, 51284], "temperature": 0.0, "avg_logprob": -0.18454545916933002, "compression_ratio": 1.6614173228346456, "no_speech_prob": 0.005881385412067175}, {"id": 142, "seek": 58220, "start": 600.6, "end": 606.08, "text": " These are popular graph data science libraries and machine learning libraries in Python.", "tokens": [51284, 1981, 366, 3743, 4295, 1412, 3497, 15148, 293, 3479, 2539, 15148, 294, 15329, 13, 51558], "temperature": 0.0, "avg_logprob": -0.18454545916933002, "compression_ratio": 1.6614173228346456, "no_speech_prob": 0.005881385412067175}, {"id": 143, "seek": 58220, "start": 606.08, "end": 610.9200000000001, "text": " By being well integrated with the Python data science ecosystem, we believe this makes it", "tokens": [51558, 3146, 885, 731, 10919, 365, 264, 15329, 1412, 3497, 11311, 11, 321, 1697, 341, 1669, 309, 51800], "temperature": 0.0, "avg_logprob": -0.18454545916933002, "compression_ratio": 1.6614173228346456, "no_speech_prob": 0.005881385412067175}, {"id": 144, "seek": 61092, "start": 610.9599999999999, "end": 613.88, "text": " a lot more achievable.", "tokens": [50366, 257, 688, 544, 3538, 17915, 13, 50512], "temperature": 0.0, "avg_logprob": -0.22444094443807797, "compression_ratio": 1.6888888888888889, "no_speech_prob": 0.001147422124631703}, {"id": 145, "seek": 61092, "start": 613.88, "end": 619.52, "text": " I'll quickly walk through an example of how Kuzu makes graph data science easier in terms", "tokens": [50512, 286, 603, 2661, 1792, 807, 364, 1365, 295, 577, 591, 48323, 1669, 4295, 1412, 3497, 3571, 294, 2115, 50794], "temperature": 0.0, "avg_logprob": -0.22444094443807797, "compression_ratio": 1.6888888888888889, "no_speech_prob": 0.001147422124631703}, {"id": 146, "seek": 61092, "start": 619.52, "end": 621.16, "text": " of a workflow.", "tokens": [50794, 295, 257, 20993, 13, 50876], "temperature": 0.0, "avg_logprob": -0.22444094443807797, "compression_ratio": 1.6888888888888889, "no_speech_prob": 0.001147422124631703}, {"id": 147, "seek": 61092, "start": 621.16, "end": 626.9599999999999, "text": " Let's consider this real world, a simple example, a toy example, where you have two different", "tokens": [50876, 961, 311, 1949, 341, 957, 1002, 11, 257, 2199, 1365, 11, 257, 12058, 1365, 11, 689, 291, 362, 732, 819, 51166], "temperature": 0.0, "avg_logprob": -0.22444094443807797, "compression_ratio": 1.6888888888888889, "no_speech_prob": 0.001147422124631703}, {"id": 148, "seek": 61092, "start": 626.9599999999999, "end": 627.9599999999999, "text": " data sources.", "tokens": [51166, 1412, 7139, 13, 51216], "temperature": 0.0, "avg_logprob": -0.22444094443807797, "compression_ratio": 1.6888888888888889, "no_speech_prob": 0.001147422124631703}, {"id": 149, "seek": 61092, "start": 627.9599999999999, "end": 631.12, "text": " You have people and the movies that they watched.", "tokens": [51216, 509, 362, 561, 293, 264, 6233, 300, 436, 6337, 13, 51374], "temperature": 0.0, "avg_logprob": -0.22444094443807797, "compression_ratio": 1.6888888888888889, "no_speech_prob": 0.001147422124631703}, {"id": 150, "seek": 61092, "start": 631.12, "end": 635.04, "text": " You also have people and their friends and where they live.", "tokens": [51374, 509, 611, 362, 561, 293, 641, 1855, 293, 689, 436, 1621, 13, 51570], "temperature": 0.0, "avg_logprob": -0.22444094443807797, "compression_ratio": 1.6888888888888889, "no_speech_prob": 0.001147422124631703}, {"id": 151, "seek": 61092, "start": 635.04, "end": 637.16, "text": " These are two different data sets.", "tokens": [51570, 1981, 366, 732, 819, 1412, 6352, 13, 51676], "temperature": 0.0, "avg_logprob": -0.22444094443807797, "compression_ratio": 1.6888888888888889, "no_speech_prob": 0.001147422124631703}, {"id": 152, "seek": 63716, "start": 637.16, "end": 641.3199999999999, "text": " Your goal is to use the information from this data to build a movie recommender system", "tokens": [50364, 2260, 3387, 307, 281, 764, 264, 1589, 490, 341, 1412, 281, 1322, 257, 3169, 2748, 260, 1185, 50572], "temperature": 0.0, "avg_logprob": -0.20671265080290022, "compression_ratio": 1.7794117647058822, "no_speech_prob": 0.002008984796702862}, {"id": 153, "seek": 63716, "start": 641.3199999999999, "end": 644.8, "text": " where a person who has watched certain movies gets recommended other movies.", "tokens": [50572, 689, 257, 954, 567, 575, 6337, 1629, 6233, 2170, 9628, 661, 6233, 13, 50746], "temperature": 0.0, "avg_logprob": -0.20671265080290022, "compression_ratio": 1.7794117647058822, "no_speech_prob": 0.002008984796702862}, {"id": 154, "seek": 63716, "start": 644.8, "end": 648.36, "text": " There are many ways you can build such a recommendation system.", "tokens": [50746, 821, 366, 867, 2098, 291, 393, 1322, 1270, 257, 11879, 1185, 13, 50924], "temperature": 0.0, "avg_logprob": -0.20671265080290022, "compression_ratio": 1.7794117647058822, "no_speech_prob": 0.002008984796702862}, {"id": 155, "seek": 63716, "start": 648.36, "end": 653.56, "text": " One we'll cover here is using a graph neural network, specifically using link prediction", "tokens": [50924, 1485, 321, 603, 2060, 510, 307, 1228, 257, 4295, 18161, 3209, 11, 4682, 1228, 2113, 17630, 51184], "temperature": 0.0, "avg_logprob": -0.20671265080290022, "compression_ratio": 1.7794117647058822, "no_speech_prob": 0.002008984796702862}, {"id": 156, "seek": 63716, "start": 653.56, "end": 659.3199999999999, "text": " where you're trying to predict a recommended edge between a person and a movie.", "tokens": [51184, 689, 291, 434, 1382, 281, 6069, 257, 9628, 4691, 1296, 257, 954, 293, 257, 3169, 13, 51472], "temperature": 0.0, "avg_logprob": -0.20671265080290022, "compression_ratio": 1.7794117647058822, "no_speech_prob": 0.002008984796702862}, {"id": 157, "seek": 63716, "start": 659.3199999999999, "end": 663.36, "text": " This is a very simple example where you have data set one which has the persons and the", "tokens": [51472, 639, 307, 257, 588, 2199, 1365, 689, 291, 362, 1412, 992, 472, 597, 575, 264, 14453, 293, 264, 51674], "temperature": 0.0, "avg_logprob": -0.20671265080290022, "compression_ratio": 1.7794117647058822, "no_speech_prob": 0.002008984796702862}, {"id": 158, "seek": 66336, "start": 663.36, "end": 668.44, "text": " movies with some additional metadata, could be age or any other attributes.", "tokens": [50364, 6233, 365, 512, 4497, 26603, 11, 727, 312, 3205, 420, 604, 661, 17212, 13, 50618], "temperature": 0.0, "avg_logprob": -0.19009763141011082, "compression_ratio": 1.6885964912280702, "no_speech_prob": 0.0012979268794879317}, {"id": 159, "seek": 66336, "start": 668.44, "end": 675.6800000000001, "text": " Then data set two has persons and what friends those persons have and where they live.", "tokens": [50618, 1396, 1412, 992, 732, 575, 14453, 293, 437, 1855, 729, 14453, 362, 293, 689, 436, 1621, 13, 50980], "temperature": 0.0, "avg_logprob": -0.19009763141011082, "compression_ratio": 1.6885964912280702, "no_speech_prob": 0.0012979268794879317}, {"id": 160, "seek": 66336, "start": 675.6800000000001, "end": 679.6, "text": " For those who have not worked with graph machine learning before, it's a very high level overview", "tokens": [50980, 1171, 729, 567, 362, 406, 2732, 365, 4295, 3479, 2539, 949, 11, 309, 311, 257, 588, 1090, 1496, 12492, 51176], "temperature": 0.0, "avg_logprob": -0.19009763141011082, "compression_ratio": 1.6885964912280702, "no_speech_prob": 0.0012979268794879317}, {"id": 161, "seek": 66336, "start": 679.6, "end": 686.72, "text": " in this slide where the goal of graph machine learning is to embed the nodes and the surroundings", "tokens": [51176, 294, 341, 4137, 689, 264, 3387, 295, 4295, 3479, 2539, 307, 281, 12240, 264, 13891, 293, 264, 25314, 51532], "temperature": 0.0, "avg_logprob": -0.19009763141011082, "compression_ratio": 1.6885964912280702, "no_speech_prob": 0.0012979268794879317}, {"id": 162, "seek": 66336, "start": 686.72, "end": 689.32, "text": " space into a vector space.", "tokens": [51532, 1901, 666, 257, 8062, 1901, 13, 51662], "temperature": 0.0, "avg_logprob": -0.19009763141011082, "compression_ratio": 1.6885964912280702, "no_speech_prob": 0.0012979268794879317}, {"id": 163, "seek": 68932, "start": 689.32, "end": 695.6800000000001, "text": " The benefit of this is that it incorporates the structure of the graph based on the nodes", "tokens": [50364, 440, 5121, 295, 341, 307, 300, 309, 50193, 264, 3877, 295, 264, 4295, 2361, 322, 264, 13891, 50682], "temperature": 0.0, "avg_logprob": -0.12459144359681665, "compression_ratio": 1.7951219512195122, "no_speech_prob": 0.0030984466429799795}, {"id": 164, "seek": 68932, "start": 695.6800000000001, "end": 698.88, "text": " and their surrounding neighbors.", "tokens": [50682, 293, 641, 11498, 12512, 13, 50842], "temperature": 0.0, "avg_logprob": -0.12459144359681665, "compression_ratio": 1.7951219512195122, "no_speech_prob": 0.0030984466429799795}, {"id": 165, "seek": 68932, "start": 698.88, "end": 704.6800000000001, "text": " The idea is that you perform a computation on the graph nodes and transform the features", "tokens": [50842, 440, 1558, 307, 300, 291, 2042, 257, 24903, 322, 264, 4295, 13891, 293, 4088, 264, 4122, 51132], "temperature": 0.0, "avg_logprob": -0.12459144359681665, "compression_ratio": 1.7951219512195122, "no_speech_prob": 0.0030984466429799795}, {"id": 166, "seek": 68932, "start": 704.6800000000001, "end": 710.0400000000001, "text": " of that graph into a feature vector like the array shown there.", "tokens": [51132, 295, 300, 4295, 666, 257, 4111, 8062, 411, 264, 10225, 4898, 456, 13, 51400], "temperature": 0.0, "avg_logprob": -0.12459144359681665, "compression_ratio": 1.7951219512195122, "no_speech_prob": 0.0030984466429799795}, {"id": 167, "seek": 68932, "start": 710.0400000000001, "end": 715.0400000000001, "text": " The idea is very similar to the kind of vectors that you may have seen in other domains like", "tokens": [51400, 440, 1558, 307, 588, 2531, 281, 264, 733, 295, 18875, 300, 291, 815, 362, 1612, 294, 661, 25514, 411, 51650], "temperature": 0.0, "avg_logprob": -0.12459144359681665, "compression_ratio": 1.7951219512195122, "no_speech_prob": 0.0030984466429799795}, {"id": 168, "seek": 71504, "start": 715.04, "end": 719.52, "text": " computer vision or natural language processing where the only difference is that in those", "tokens": [50364, 3820, 5201, 420, 3303, 2856, 9007, 689, 264, 787, 2649, 307, 300, 294, 729, 50588], "temperature": 0.0, "avg_logprob": -0.16894612709681192, "compression_ratio": 1.7717842323651452, "no_speech_prob": 0.005033658817410469}, {"id": 169, "seek": 71504, "start": 719.52, "end": 724.8, "text": " domains you are considering the similarity between words in a sentence or pixels in an", "tokens": [50588, 25514, 291, 366, 8079, 264, 32194, 1296, 2283, 294, 257, 8174, 420, 18668, 294, 364, 50852], "temperature": 0.0, "avg_logprob": -0.16894612709681192, "compression_ratio": 1.7717842323651452, "no_speech_prob": 0.005033658817410469}, {"id": 170, "seek": 71504, "start": 724.8, "end": 730.12, "text": " image whereas in this case you're considering the similarity of the topology of the graph", "tokens": [50852, 3256, 9735, 294, 341, 1389, 291, 434, 8079, 264, 32194, 295, 264, 1192, 1793, 295, 264, 4295, 51118], "temperature": 0.0, "avg_logprob": -0.16894612709681192, "compression_ratio": 1.7717842323651452, "no_speech_prob": 0.005033658817410469}, {"id": 171, "seek": 71504, "start": 730.12, "end": 733.28, "text": " itself.", "tokens": [51118, 2564, 13, 51276], "temperature": 0.0, "avg_logprob": -0.16894612709681192, "compression_ratio": 1.7717842323651452, "no_speech_prob": 0.005033658817410469}, {"id": 172, "seek": 71504, "start": 733.28, "end": 737.5999999999999, "text": " All of that is great but when you're working with the data, you're immediately faced with", "tokens": [51276, 1057, 295, 300, 307, 869, 457, 562, 291, 434, 1364, 365, 264, 1412, 11, 291, 434, 4258, 11446, 365, 51492], "temperature": 0.0, "avg_logprob": -0.16894612709681192, "compression_ratio": 1.7717842323651452, "no_speech_prob": 0.005033658817410469}, {"id": 173, "seek": 71504, "start": 737.5999999999999, "end": 738.5999999999999, "text": " a problem.", "tokens": [51492, 257, 1154, 13, 51542], "temperature": 0.0, "avg_logprob": -0.16894612709681192, "compression_ratio": 1.7717842323651452, "no_speech_prob": 0.005033658817410469}, {"id": 174, "seek": 71504, "start": 738.5999999999999, "end": 741.4399999999999, "text": " The data you have might exist in different sources.", "tokens": [51542, 440, 1412, 291, 362, 1062, 2514, 294, 819, 7139, 13, 51684], "temperature": 0.0, "avg_logprob": -0.16894612709681192, "compression_ratio": 1.7717842323651452, "no_speech_prob": 0.005033658817410469}, {"id": 175, "seek": 74144, "start": 741.44, "end": 746.12, "text": " For example, the movies watch may exist in Postgres and the person friends may exist", "tokens": [50364, 1171, 1365, 11, 264, 6233, 1159, 815, 2514, 294, 10223, 45189, 293, 264, 954, 1855, 815, 2514, 50598], "temperature": 0.0, "avg_logprob": -0.18382718541600682, "compression_ratio": 1.8484848484848484, "no_speech_prob": 0.011229450814425945}, {"id": 176, "seek": 74144, "start": 746.12, "end": 752.4000000000001, "text": " in other structured data sources that you export to CSV or Parquet or something similar.", "tokens": [50598, 294, 661, 18519, 1412, 7139, 300, 291, 10725, 281, 48814, 420, 3457, 19343, 420, 746, 2531, 13, 50912], "temperature": 0.0, "avg_logprob": -0.18382718541600682, "compression_ratio": 1.8484848484848484, "no_speech_prob": 0.011229450814425945}, {"id": 177, "seek": 74144, "start": 752.4000000000001, "end": 755.1600000000001, "text": " You need to bring them together to form a graph.", "tokens": [50912, 509, 643, 281, 1565, 552, 1214, 281, 1254, 257, 4295, 13, 51050], "temperature": 0.0, "avg_logprob": -0.18382718541600682, "compression_ratio": 1.8484848484848484, "no_speech_prob": 0.011229450814425945}, {"id": 178, "seek": 74144, "start": 755.1600000000001, "end": 757.9200000000001, "text": " Conceptually, this is how a graph would look.", "tokens": [51050, 47482, 671, 11, 341, 307, 577, 257, 4295, 576, 574, 13, 51188], "temperature": 0.0, "avg_logprob": -0.18382718541600682, "compression_ratio": 1.8484848484848484, "no_speech_prob": 0.011229450814425945}, {"id": 179, "seek": 74144, "start": 757.9200000000001, "end": 760.08, "text": " You have nodes that represent the persons.", "tokens": [51188, 509, 362, 13891, 300, 2906, 264, 14453, 13, 51296], "temperature": 0.0, "avg_logprob": -0.18382718541600682, "compression_ratio": 1.8484848484848484, "no_speech_prob": 0.011229450814425945}, {"id": 180, "seek": 74144, "start": 760.08, "end": 764.96, "text": " You have edges that represent the movies that they watched in the first graph and then in", "tokens": [51296, 509, 362, 8819, 300, 2906, 264, 6233, 300, 436, 6337, 294, 264, 700, 4295, 293, 550, 294, 51540], "temperature": 0.0, "avg_logprob": -0.18382718541600682, "compression_ratio": 1.8484848484848484, "no_speech_prob": 0.011229450814425945}, {"id": 181, "seek": 74144, "start": 764.96, "end": 769.7600000000001, "text": " the second one you have edges that represent friendship between people and what cities", "tokens": [51540, 264, 1150, 472, 291, 362, 8819, 300, 2906, 13216, 1296, 561, 293, 437, 6486, 51780], "temperature": 0.0, "avg_logprob": -0.18382718541600682, "compression_ratio": 1.8484848484848484, "no_speech_prob": 0.011229450814425945}, {"id": 182, "seek": 76976, "start": 769.76, "end": 773.28, "text": " they live in.", "tokens": [50364, 436, 1621, 294, 13, 50540], "temperature": 0.0, "avg_logprob": -0.15698822613420158, "compression_ratio": 1.8627450980392157, "no_speech_prob": 0.027315376326441765}, {"id": 183, "seek": 76976, "start": 773.28, "end": 777.28, "text": " The moment you do that, you have another problem where you potentially have overlapping data", "tokens": [50540, 440, 1623, 291, 360, 300, 11, 291, 362, 1071, 1154, 689, 291, 7263, 362, 33535, 1412, 50740], "temperature": 0.0, "avg_logprob": -0.15698822613420158, "compression_ratio": 1.8627450980392157, "no_speech_prob": 0.027315376326441765}, {"id": 184, "seek": 76976, "start": 777.28, "end": 780.4399999999999, "text": " or duplicate data between these two subgraphs.", "tokens": [50740, 420, 23976, 1412, 1296, 613, 732, 1422, 34091, 82, 13, 50898], "temperature": 0.0, "avg_logprob": -0.15698822613420158, "compression_ratio": 1.8627450980392157, "no_speech_prob": 0.027315376326441765}, {"id": 185, "seek": 76976, "start": 780.4399999999999, "end": 784.2, "text": " In one of them you have the persons and the cities and the other ones you have persons", "tokens": [50898, 682, 472, 295, 552, 291, 362, 264, 14453, 293, 264, 6486, 293, 264, 661, 2306, 291, 362, 14453, 51086], "temperature": 0.0, "avg_logprob": -0.15698822613420158, "compression_ratio": 1.8627450980392157, "no_speech_prob": 0.027315376326441765}, {"id": 186, "seek": 76976, "start": 784.2, "end": 786.4, "text": " and movies.", "tokens": [51086, 293, 6233, 13, 51196], "temperature": 0.0, "avg_logprob": -0.15698822613420158, "compression_ratio": 1.8627450980392157, "no_speech_prob": 0.027315376326441765}, {"id": 187, "seek": 76976, "start": 786.4, "end": 788.88, "text": " Many of them might be the same people.", "tokens": [51196, 5126, 295, 552, 1062, 312, 264, 912, 561, 13, 51320], "temperature": 0.0, "avg_logprob": -0.15698822613420158, "compression_ratio": 1.8627450980392157, "no_speech_prob": 0.027315376326441765}, {"id": 188, "seek": 76976, "start": 788.88, "end": 793.56, "text": " There is some deduplication logic that's required where you have to merge people with the same", "tokens": [51320, 821, 307, 512, 4172, 84, 4770, 399, 9952, 300, 311, 4739, 689, 291, 362, 281, 22183, 561, 365, 264, 912, 51554], "temperature": 0.0, "avg_logprob": -0.15698822613420158, "compression_ratio": 1.8627450980392157, "no_speech_prob": 0.027315376326441765}, {"id": 189, "seek": 76976, "start": 793.56, "end": 798.08, "text": " attributes and there's some custom logic that needs to be put in terms of how you decide", "tokens": [51554, 17212, 293, 456, 311, 512, 2375, 9952, 300, 2203, 281, 312, 829, 294, 2115, 295, 577, 291, 4536, 51780], "temperature": 0.0, "avg_logprob": -0.15698822613420158, "compression_ratio": 1.8627450980392157, "no_speech_prob": 0.027315376326441765}, {"id": 190, "seek": 79808, "start": 798.08, "end": 800.2, "text": " whether something is a duplicate.", "tokens": [50364, 1968, 746, 307, 257, 23976, 13, 50470], "temperature": 0.0, "avg_logprob": -0.1343288825730146, "compression_ratio": 1.7279151943462898, "no_speech_prob": 0.040635742247104645}, {"id": 191, "seek": 79808, "start": 800.2, "end": 805.12, "text": " Once you do that, you have the final result where you have some nodes that are dangling", "tokens": [50470, 3443, 291, 360, 300, 11, 291, 362, 264, 2572, 1874, 689, 291, 362, 512, 13891, 300, 366, 21892, 1688, 50716], "temperature": 0.0, "avg_logprob": -0.1343288825730146, "compression_ratio": 1.7279151943462898, "no_speech_prob": 0.040635742247104645}, {"id": 192, "seek": 79808, "start": 805.12, "end": 809.72, "text": " in the sense that they have no edges that attach them to other nodes.", "tokens": [50716, 294, 264, 2020, 300, 436, 362, 572, 8819, 300, 5085, 552, 281, 661, 13891, 13, 50946], "temperature": 0.0, "avg_logprob": -0.1343288825730146, "compression_ratio": 1.7279151943462898, "no_speech_prob": 0.040635742247104645}, {"id": 193, "seek": 79808, "start": 809.72, "end": 814.48, "text": " These actually don't inform the machine learning model and would need to be removed.", "tokens": [50946, 1981, 767, 500, 380, 1356, 264, 3479, 2539, 2316, 293, 576, 643, 281, 312, 7261, 13, 51184], "temperature": 0.0, "avg_logprob": -0.1343288825730146, "compression_ratio": 1.7279151943462898, "no_speech_prob": 0.040635742247104645}, {"id": 194, "seek": 79808, "start": 814.48, "end": 818.84, "text": " To do all of this is actually quite tedious if you were to write your own custom logic", "tokens": [51184, 1407, 360, 439, 295, 341, 307, 767, 1596, 38284, 498, 291, 645, 281, 2464, 428, 1065, 2375, 9952, 51402], "temperature": 0.0, "avg_logprob": -0.1343288825730146, "compression_ratio": 1.7279151943462898, "no_speech_prob": 0.040635742247104645}, {"id": 195, "seek": 79808, "start": 818.84, "end": 821.48, "text": " in your own language of choice.", "tokens": [51402, 294, 428, 1065, 2856, 295, 3922, 13, 51534], "temperature": 0.0, "avg_logprob": -0.1343288825730146, "compression_ratio": 1.7279151943462898, "no_speech_prob": 0.040635742247104645}, {"id": 196, "seek": 79808, "start": 821.48, "end": 826.1600000000001, "text": " Where Kuzu comes in and where it's very powerful is the ability to just install an embeddable", "tokens": [51534, 2305, 591, 48323, 1487, 294, 293, 689, 309, 311, 588, 4005, 307, 264, 3485, 281, 445, 3625, 364, 12240, 67, 712, 51768], "temperature": 0.0, "avg_logprob": -0.1343288825730146, "compression_ratio": 1.7279151943462898, "no_speech_prob": 0.040635742247104645}, {"id": 197, "seek": 82616, "start": 826.16, "end": 829.8, "text": " library using pip install Kuzu in Python.", "tokens": [50364, 6405, 1228, 8489, 3625, 591, 48323, 294, 15329, 13, 50546], "temperature": 0.0, "avg_logprob": -0.14614410211544226, "compression_ratio": 1.6300813008130082, "no_speech_prob": 0.003474847413599491}, {"id": 198, "seek": 82616, "start": 829.8, "end": 835.1999999999999, "text": " Once you have that, you're very rapidly able to run query execution to create the tables,", "tokens": [50546, 3443, 291, 362, 300, 11, 291, 434, 588, 12910, 1075, 281, 1190, 14581, 15058, 281, 1884, 264, 8020, 11, 50816], "temperature": 0.0, "avg_logprob": -0.14614410211544226, "compression_ratio": 1.6300813008130082, "no_speech_prob": 0.003474847413599491}, {"id": 199, "seek": 82616, "start": 835.1999999999999, "end": 842.3199999999999, "text": " load the data in and perform deduplication logic and dangling node removal using a high-level", "tokens": [50816, 3677, 264, 1412, 294, 293, 2042, 4172, 84, 4770, 399, 9952, 293, 21892, 1688, 9984, 17933, 1228, 257, 1090, 12, 12418, 51172], "temperature": 0.0, "avg_logprob": -0.14614410211544226, "compression_ratio": 1.6300813008130082, "no_speech_prob": 0.003474847413599491}, {"id": 200, "seek": 82616, "start": 842.3199999999999, "end": 847.64, "text": " query language like Cypher in a way that scales to the size of the data that you have.", "tokens": [51172, 14581, 2856, 411, 10295, 79, 511, 294, 257, 636, 300, 17408, 281, 264, 2744, 295, 264, 1412, 300, 291, 362, 13, 51438], "temperature": 0.0, "avg_logprob": -0.14614410211544226, "compression_ratio": 1.6300813008130082, "no_speech_prob": 0.003474847413599491}, {"id": 201, "seek": 82616, "start": 847.64, "end": 851.4399999999999, "text": " In many ways, you don't have to worry about the scalability problem because now you have", "tokens": [51438, 682, 867, 2098, 11, 291, 500, 380, 362, 281, 3292, 466, 264, 15664, 2310, 1154, 570, 586, 291, 362, 51628], "temperature": 0.0, "avg_logprob": -0.14614410211544226, "compression_ratio": 1.6300813008130082, "no_speech_prob": 0.003474847413599491}, {"id": 202, "seek": 85144, "start": 851.44, "end": 856.6, "text": " a high-level query language supporting your operations in the middle stages.", "tokens": [50364, 257, 1090, 12, 12418, 14581, 2856, 7231, 428, 7705, 294, 264, 2808, 10232, 13, 50622], "temperature": 0.0, "avg_logprob": -0.1928296863523304, "compression_ratio": 1.726643598615917, "no_speech_prob": 0.0036961014848202467}, {"id": 203, "seek": 85144, "start": 856.6, "end": 860.9200000000001, "text": " Once you have all of the data and the features that are loaded into a graph, you essentially", "tokens": [50622, 3443, 291, 362, 439, 295, 264, 1412, 293, 264, 4122, 300, 366, 13210, 666, 257, 4295, 11, 291, 4476, 50838], "temperature": 0.0, "avg_logprob": -0.1928296863523304, "compression_ratio": 1.726643598615917, "no_speech_prob": 0.0036961014848202467}, {"id": 204, "seek": 85144, "start": 860.9200000000001, "end": 867.32, "text": " can walk through this process where you not only have the data in the right form, but you're", "tokens": [50838, 393, 1792, 807, 341, 1399, 689, 291, 406, 787, 362, 264, 1412, 294, 264, 558, 1254, 11, 457, 291, 434, 51158], "temperature": 0.0, "avg_logprob": -0.1928296863523304, "compression_ratio": 1.726643598615917, "no_speech_prob": 0.0036961014848202467}, {"id": 205, "seek": 85144, "start": 867.32, "end": 873.08, "text": " able to actually encode the features into the graph and store that on disk.", "tokens": [51158, 1075, 281, 767, 2058, 1429, 264, 4122, 666, 264, 4295, 293, 3531, 300, 322, 12355, 13, 51446], "temperature": 0.0, "avg_logprob": -0.1928296863523304, "compression_ratio": 1.726643598615917, "no_speech_prob": 0.0036961014848202467}, {"id": 206, "seek": 85144, "start": 873.08, "end": 877.4000000000001, "text": " One of the biggest limitations with PyTorch geometric is if you ever worked with it before,", "tokens": [51446, 1485, 295, 264, 3880, 15705, 365, 9953, 51, 284, 339, 33246, 307, 498, 291, 1562, 2732, 365, 309, 949, 11, 51662], "temperature": 0.0, "avg_logprob": -0.1928296863523304, "compression_ratio": 1.726643598615917, "no_speech_prob": 0.0036961014848202467}, {"id": 207, "seek": 85144, "start": 877.4000000000001, "end": 880.6, "text": " is it's very memory intensive when you're working with large graphs.", "tokens": [51662, 307, 309, 311, 588, 4675, 18957, 562, 291, 434, 1364, 365, 2416, 24877, 13, 51822], "temperature": 0.0, "avg_logprob": -0.1928296863523304, "compression_ratio": 1.726643598615917, "no_speech_prob": 0.0036961014848202467}, {"id": 208, "seek": 88060, "start": 880.64, "end": 885.16, "text": " Kuzu helps a lot in this regard by persisting the features onto disk.", "tokens": [50366, 591, 48323, 3665, 257, 688, 294, 341, 3843, 538, 13233, 278, 264, 4122, 3911, 12355, 13, 50592], "temperature": 0.0, "avg_logprob": -0.2007157952935846, "compression_ratio": 1.5583941605839415, "no_speech_prob": 0.003314880421385169}, {"id": 209, "seek": 88060, "start": 885.16, "end": 889.76, "text": " That's exactly where I think we want to highlight this point.", "tokens": [50592, 663, 311, 2293, 689, 286, 519, 321, 528, 281, 5078, 341, 935, 13, 50822], "temperature": 0.0, "avg_logprob": -0.2007157952935846, "compression_ratio": 1.5583941605839415, "no_speech_prob": 0.003314880421385169}, {"id": 210, "seek": 88060, "start": 889.76, "end": 895.64, "text": " I think we are almost out of time, but I'll wrap up by saying the key points to take away.", "tokens": [50822, 286, 519, 321, 366, 1920, 484, 295, 565, 11, 457, 286, 603, 7019, 493, 538, 1566, 264, 2141, 2793, 281, 747, 1314, 13, 51116], "temperature": 0.0, "avg_logprob": -0.2007157952935846, "compression_ratio": 1.5583941605839415, "no_speech_prob": 0.003314880421385169}, {"id": 211, "seek": 88060, "start": 895.64, "end": 900.72, "text": " Kuzu is an in-process analytical graph database system, kind of like DuckTB is in the SQL", "tokens": [51116, 591, 48323, 307, 364, 294, 12, 41075, 29579, 4295, 8149, 1185, 11, 733, 295, 411, 29266, 51, 33, 307, 294, 264, 19200, 51370], "temperature": 0.0, "avg_logprob": -0.2007157952935846, "compression_ratio": 1.5583941605839415, "no_speech_prob": 0.003314880421385169}, {"id": 212, "seek": 88060, "start": 900.72, "end": 903.16, "text": " world, but for graphs.", "tokens": [51370, 1002, 11, 457, 337, 24877, 13, 51492], "temperature": 0.0, "avg_logprob": -0.2007157952935846, "compression_ratio": 1.5583941605839415, "no_speech_prob": 0.003314880421385169}, {"id": 213, "seek": 88060, "start": 903.16, "end": 908.28, "text": " It's highly scalable and optimized for multi-core parallelism and very well integrated with", "tokens": [51492, 467, 311, 5405, 38481, 293, 26941, 337, 4825, 12, 12352, 8952, 1434, 293, 588, 731, 10919, 365, 51748], "temperature": 0.0, "avg_logprob": -0.2007157952935846, "compression_ratio": 1.5583941605839415, "no_speech_prob": 0.003314880421385169}, {"id": 214, "seek": 90828, "start": 908.92, "end": 914.9599999999999, "text": " the PyData ecosystem, including NumPy, PyAro, NetworkX, PyTorch, and so on.", "tokens": [50396, 264, 9953, 35, 3274, 11311, 11, 3009, 22592, 47, 88, 11, 9953, 32, 340, 11, 12640, 55, 11, 9953, 51, 284, 339, 11, 293, 370, 322, 13, 50698], "temperature": 0.0, "avg_logprob": -0.1779961219200721, "compression_ratio": 1.5647058823529412, "no_speech_prob": 0.0014725064393132925}, {"id": 215, "seek": 90828, "start": 914.9599999999999, "end": 918.8, "text": " It supports both the property graph model as well as the RDF graph model via Cypher,", "tokens": [50698, 467, 9346, 1293, 264, 4707, 4295, 2316, 382, 731, 382, 264, 49488, 37, 4295, 2316, 5766, 10295, 79, 511, 11, 50890], "temperature": 0.0, "avg_logprob": -0.1779961219200721, "compression_ratio": 1.5647058823529412, "no_speech_prob": 0.0014725064393132925}, {"id": 216, "seek": 90828, "start": 918.8, "end": 920.76, "text": " a high-level query language.", "tokens": [50890, 257, 1090, 12, 12418, 14581, 2856, 13, 50988], "temperature": 0.0, "avg_logprob": -0.1779961219200721, "compression_ratio": 1.5647058823529412, "no_speech_prob": 0.0014725064393132925}, {"id": 217, "seek": 90828, "start": 920.76, "end": 924.8, "text": " It's embeddable and very easy to use from your application.", "tokens": [50988, 467, 311, 12240, 67, 712, 293, 588, 1858, 281, 764, 490, 428, 3861, 13, 51190], "temperature": 0.0, "avg_logprob": -0.1779961219200721, "compression_ratio": 1.5647058823529412, "no_speech_prob": 0.0014725064393132925}, {"id": 218, "seek": 90828, "start": 924.8, "end": 929.0799999999999, "text": " It's also accessible with other language bindings, not just Python.", "tokens": [51190, 467, 311, 611, 9515, 365, 661, 2856, 14786, 1109, 11, 406, 445, 15329, 13, 51404], "temperature": 0.0, "avg_logprob": -0.1779961219200721, "compression_ratio": 1.5647058823529412, "no_speech_prob": 0.0014725064393132925}, {"id": 219, "seek": 90828, "start": 929.0799999999999, "end": 933.1999999999999, "text": " If you come from other languages, those options exist as well.", "tokens": [51404, 759, 291, 808, 490, 661, 8650, 11, 729, 3956, 2514, 382, 731, 13, 51610], "temperature": 0.0, "avg_logprob": -0.1779961219200721, "compression_ratio": 1.5647058823529412, "no_speech_prob": 0.0014725064393132925}, {"id": 220, "seek": 90828, "start": 933.1999999999999, "end": 934.1999999999999, "text": " That's it from us.", "tokens": [51610, 663, 311, 309, 490, 505, 13, 51660], "temperature": 0.0, "avg_logprob": -0.1779961219200721, "compression_ratio": 1.5647058823529412, "no_speech_prob": 0.0014725064393132925}, {"id": 221, "seek": 93420, "start": 934.22, "end": 939.1600000000001, "text": " Kuzu is an open source, very permissive, licensed, MIT licensed project.", "tokens": [50365, 591, 48323, 307, 364, 1269, 4009, 11, 588, 4784, 891, 488, 11, 25225, 11, 13100, 25225, 1716, 13, 50612], "temperature": 0.6, "avg_logprob": -0.37302271525065106, "compression_ratio": 1.3503184713375795, "no_speech_prob": 0.07678326219320297}, {"id": 222, "seek": 93420, "start": 939.1600000000001, "end": 943.0, "text": " I'd love for everyone to give it a try and reach out to us on Discord.", "tokens": [50612, 286, 1116, 959, 337, 1518, 281, 976, 309, 257, 853, 293, 2524, 484, 281, 505, 322, 32623, 13, 50804], "temperature": 0.6, "avg_logprob": -0.37302271525065106, "compression_ratio": 1.3503184713375795, "no_speech_prob": 0.07678326219320297}, {"id": 223, "seek": 93420, "start": 943.0, "end": 945.34, "text": " We're always open to chatting more about graph use cases.", "tokens": [50804, 492, 434, 1009, 1269, 281, 24654, 544, 466, 4295, 764, 3331, 13, 50921], "temperature": 0.6, "avg_logprob": -0.37302271525065106, "compression_ratio": 1.3503184713375795, "no_speech_prob": 0.07678326219320297}, {"id": 224, "seek": 93420, "start": 945.34, "end": 945.84, "text": " Thank you.", "tokens": [50921, 1044, 291, 13, 50946], "temperature": 0.6, "avg_logprob": -0.37302271525065106, "compression_ratio": 1.3503184713375795, "no_speech_prob": 0.07678326219320297}], "language": "en"}