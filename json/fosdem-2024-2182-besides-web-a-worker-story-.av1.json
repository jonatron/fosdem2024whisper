{"text": " Okay, awesome. The mic is on, hopefully. All right, good afternoon everyone. So I'm going to talk to you about a worker story, which is something we did at work recently. And for once, it was like not using Rails. That's awesome. Not using web at all. That's what motivated me to tell you this story. So before we start, I would like to know who here is the Rails developer? Who would like? Yeah, awesome. Who would say that they are Ruby, but not Rails developer? Okay, awesome. That's great. Love it. I didn't expect that. Awesome. All right, first of all, who am I? Because if you don't know who am I, you might not rely on whatever I'm going to say. So I've been Ruby and mostly Rails developer for 10 years. I've been working with Kevin for almost that period. More recently, I have become a lead dev, then a manager, then a CTO. So I'm doing a lot of new responsibilities now, which also gives me a new perspective on a lot of programming topic, actually getting new perspective when you start making a decision about people and processes and stuff like that. And finally, I've been a teacher for more than six years. I've given a lecture at EPL and Le Wagon. Hopefully, we'll do that again. I feel like a deep-footed lover for teaching and sharing knowledge. And this is also why I'm here today. So I was saying the point of this talk is talking about Ruby, but not about Rails, not about web. And this was the first time for me. I was like a new experience. And it's strange to see how much changes when you start doing that, how much you realize Rails was giving to you once you don't have that anymore. I have some notes. By the way, all my slides are going to be minimalistic. I'm not going to show you a single line of code. I'm also going to forget a lot of stuff, which is why everything I intend to tell you is written in notes available directly in this. So hopefully, you will get everything I intend to say because I'm going to forget part of that. So the main message of this talk is like it's doable. It sounds strange that this is my message, but as most Rails developers sometimes, when we think about Ruby program, we're not even sure we can do it. We're not even sure how would we approach that. So the main message is like, yes, it's doable. There's a lot of tools. There's a lot of process. There's a lot of help along the way. And you can possibly, you can very likely, sorry, get most of your tools and knowledge used in a normal, not web Ruby application. The second news is you can also get all of your Rails knowledge useful in Ruby application if you get things right. So the story I'm going to tell is about like a worker. What is a worker in our case, in my case? It's like microservice. The specificity, why do we call it a worker? Because it's not a web microservice. It's a microservice which is consuming messages from a queue and very likely is going to process files, so it's going to get files from a bucket, process them locally, put them on another bucket. We have, we are using the word worker because we have like lots of them. That's simple definition. We have lots of them. So I'm going to talk about like one of them, but it could be any of them. So we think start with a loop. The whole story starts with a loop because when I started this, I really like I opened my editor and I saw something which I hadn't seen since school. It's an empty directory. It's very strange. Like really first as a Rails developer, I'm really used to Rails new and then you get like everything. You get folders, tree, substructure. You get the config directory, you get the app directory. You, like there's drawers everywhere about what you expect to put things. In this case, I just like create a new folder and it was empty. I'm a firm believer in emergent design. So I started immediately like new file, worker.rb, make a loop, while true, read, perform, delete message. I'm done. It was nice. Like it was, I knew it was not the end, but it was capturing whatever I was, I knew about my process. It was a single level of abstraction. So I knew it was a good start, but it wasn't. It wasn't a good start because I was already forgetting like my main tool when doing Rails apps, which was going to be my main tool when doing any app. It's tests. Anybody who knows me know that I'm a firm believer in tests. And it's a policy. It's not a religion, but it's a policy. This is how I write code. I do believe in it, but you mileage may vary. But for me, it was the beginning. And it's funny because I knew I was going to write loop, the loop of my program, but I was also starting another loop, the loop of my process. And this is what tests are for me. Test first does not mean you do test, then you do code, then you're done. Test first means your first step in the journey is test. Then code, then test, then code, then test, then code, then test, then code. That's what it means to me to do test. But I did it wrong. I started with code. So I tried again. I deleted my file. I created a spec directory. I created a spec file explaining what I knew about it. And I was happier because test is the file that depicts my best understanding of what I currently believe is the success. And I need that because I'm going to write code right after the word. And once you're deep in the code, you're super focused. You forget about landscape. You don't know what comes next. You might have a story. You might have specification requirements. You name it. But I do believe that a story or specification is like coordinates of where you're supposed to land. The whole puzzle, the whole activity of development, of programming, is like playing golf in the fog by night. You know where you are at the beginning. You sort of know when you want to land. But after your first shot, you're going to be lost. It doesn't matter even anymore what you're supposed to land because you've given your first shot and you don't even know where you are anymore. I'm using tests as torches in the night. So I read my specs. I write some tests. This is my belief. I'm going to follow that path. And then I shoot my first shot. Hopefully I'm going to reach my first torch in the night. When I have reached that one, I'm going to go to my second torch again and again. But my loop is that my test is only my best understanding of my success. So my test is going to evolve. I'm going to move my torches and I'm going to move my ball. And this is how they make sense together. Back to the story. I wrote my test, was happy with my understanding, run it, and it failed. It was a catastrophe. And why did it fail? Well, because it couldn't find our spec. Because I didn't bundle it. Because it couldn't find bundler. Like, that is how empty the whole story was. Like, I didn't even have bundler. Okay, so bundling is always easy. Bringing my dependency, starting my gem file. I need to run my spec. Run it again. Well, it still fails. But for a better reason. And that's the whole point of TG, right? You have to fail, but for a better reason than the previous failure. So now it's failing because it doesn't know about what is a queue, what is the method we see in the queue, what is a message, what is a processor, what does perform even means. Well, that makes me happy. Because now I can actually write more tests about what do I believe is a queue at this stage. Why do I believe is a processor, what do I believe should do the receive method. And this was really the starting of both my loops. I got my main loop back, but I got my working loop as well. I got a lot of tests. I knew that trying to make them go green would just generate more tests. Trying to make them go green. I got my actual work loop. Right. So, test code, test code, test code. I was in the middle of it. And every single of the code file was starting with like probably five to ten require or require relative. And I wasn't happy with that. First of all, because it is boilerplate, it's noise. I don't like noise. Also, because I want my code files to be about the responsibility they're supposed to hold. And knowing what files contains the dependency that this file depends upon, it's not the responsibility of each file to know where do I store the other responsibilities. That was wrong. And this is not something we have with Rails. I realized that we actually get something super nice from Rails is put any file in any sub directory of app folder, and you get it. It's like magic. Once you have to start all your require by hand, it felt wrong. So, I Googled. I got a few options. And the best one, which is actually the one which is currently adopted by Rails, was using SideFerq. Hopefully, I'm pronouncing it right. It's written in my speaker mode. And that stuff helped me, like, auto load the constants I was looking for by looking them up in my lib directory. Default config. I'm happy as far as I know this is what I need. But reading the rest of SideFerq, I also realized that this enables you to use short names. So, if you are in the same namespace, you can just mention a constant by a short name. Well, obviously, I want that. I'm doing that in Rails, so I want that again. It's also handling multithread code loading. I have no idea if I'm going to need that, but I certainly don't want to handle that myself. It sounds like something I really don't want to handle myself. And it also handle code reloading, which is not something I'm going to use because of TDD. But again, this is my approach. I know that most people don't do that. And code reloading is a very important part of code loading. So, SideFerq was like my first take, my first really great companion that I found along the way. The second one was dry container. Now, small disclaimer, I knew from the stuff that I was going to use dry gems because I wanted to. And as Kevin said, it's also a little bit about finding joy. So, I wanted to heavily rely on dry gems, but I wanted to wait until the use case was there. I wanted, because I did not only want to skip the requires, I wanted to not know the classes. I wanted to not call new in the middle of my code. My code is about business logic. Most of the code is about business logic. I wanted to separate, sorry, the logic about creating objects and the logic about like, I need something. And most of the time, when you're in a controller, in a Rails controller, you don't even care like where does the request object comes from. You're just like, okay, I want a request object. Just make it happen. If you're in a view, you don't care about what the view context comes from. You just have it. You just want it. And it's really comfortable to write code with just focusing on like using the stuff you need, not focusing on how you get them. So, this is what dry container brings. I've been using dry system, which is like dry container for handling all of that, and dry injector. And dry injector basically works hand in hand with dry container and allows you to call your services, call your dependencies by the small name, by the first name. You give a name to an object and then you can basically say, okay, I want this object. I don't want this class. I don't want to instantiate that class. I want specifically that object. And I'm going to use it. And I don't even care what its class is for. I want that object by name. Interestingly, this had almost no effect on the test. Even though it's a very different approach, I still had most of my tests instantiate object by themselves. Why? Because unit tests actually give a lot of fake dependencies. That's the point of unit, right? You want to test a single unit. So I was still building my subject into tests manually. And for the larger, the broader tests, I actually wanted to use the container set up correctly because I wanted to test that things were correctly wired together. So even though dry containers is like, oh, some you can stub and fake and change whatever you want. I didn't stub it because I was either using it and testing it or not using it at all in my test. And... Sorry. Yep. Yeah, I'm still in time. Dry container also brings something else, which is quite interesting. It's a settings, a settings object. And I realized very soon that the settings object was the object that I was injecting everywhere. Almost every part of my system needed to access settings. So I was injecting it everywhere. It was awesome. And dry settings provide some really interesting value. First of all, it allows any of the settings to be overridden by environment variable, which is quite important. If you know about 12 factors, it is one of the aspects you want for your config to be overridden by the environment that your program runs in. So that was the first part. And the second part is that you can coerce, you can define the type of your settings. Because if you work with environment variables, everything is a string. But when you work in your system, not everything is a string. We do have a lot of strings, but we have dates, we have integers. We have a lot of system. And usually what we do is we just parse them. Dry types allows you to create all types, name them for starters. Also naming things is probably the most important stuff we do in our work, I believe. You can name your type and get them correctly and get your settings in the proper types, which brings me to my next slide about dry types. So dry type creates a contract. It says, okay, this value, this settings, it has to be a phone number. And I'm going to explain exactly what is a phone number. And I'm also going to coerce like a string into a phone number, which means at the end of the day, I either have an error or I do have a phone number, which is exactly the object I want. And it makes a big difference. I don't know if any of you have ever created a class like phone number, like age, like bucket name. If you read correctly the literature about object-oriented design, we are supposed to do that. We are sort of supposed to do that, like subclass string when we want to make a first name. To be honest with you, I've never done that in my life. I've always used string and it's not a first name. It's a string. I know it's a first name. I know I'm not going to use all the methods of string, but the variable is name, first name, that's enough. Using types allows us to actually have proper types, more meaningful types, without creating full-blown classes for everything. Well, settings is one thing. But this contract, it can really be used for something else. It can be used for app input. When you are working in a web application, app input is a request. This is where most of our payload comes from. In our case, the app input was messaged from a queue, but the concept was very similar. As soon as we got one message, we treated it in a very similar fashion as we would have treated a request. When working with app input as a web, there's a very known pattern for handling that input, for validating that input, for correcting that input to everything that you wanted. These are form objects. We basically reused the same. I realized that I'm doing my slide in the wrong order, but you don't care because you don't have the order. But that's okay. We used kind of form object in the form of a dry contract. It comes from dry validation, that is the gem we have been using. Dry validation is really about two pillars. The first one is about typing. Eventually, it leverages dry types. It ensures that you get the keys of your payload that you expect, that you get the values that you expect, that basically your data is of the type you expect, that's the schema, that's the structure. Once you have the proper types, you still have business logic to handle. This is the second pillar of dry validation. A typical example would be if you have to handle a deadline. Imagine that somewhere in your payload there's a deadline. The first pillar would ensure that the deadline is actually a date because you get a string. Hopefully it's an ISO 8601 string, but it could be anything else. You want to coerce that in a string, you want to ensure that you have a string. If it's not coerceable into a string, you want the first error. But now that you have a string, you also need to validate that this actual date is in the future. This is what the second pillar is. You can create rules, business rules. That means that once your payload goes through the dry validation mechanism, you actually get a very valid, very reliable payload from a typing perspective, but also from a business perspective. Once we have that payload, what do we want to do with that? We actually want to process it. For that, we are using a pattern which is named Interactor. At least we used to use a gem which is named Interactor. You can think of an Interactor a little bit like an operation in Trailblazer. I don't know if anybody has used Trailblazer previously. No? Okay. All right. I'm going to go back. The idea of an Interactor is that this is the entry point to your business layer. Because the entry point to your application to most of the web application are the controllers. This is how... I'm not talking about the rules. Let's consider that the entry point is the controller. But that's not true because sometimes your entry point is your test. Sometimes your entry point is a rate task. Sometimes your entry point is an active job. Sometimes your entry point is a channel. So you actually get a lot of entry points into your app. But at the business level, you don't really care if you want to delete a user because of a GraphQL request, of a REST request, of an active job. You want to delete a user. It's the same business unit. And this is how we encapsulate things we are using in Interactor. One Interactor is responsible for one business unit. And well, very fortunately, DRI has a solution for us. It's a name DRI Transaction. So their name for it is a transaction. It allows you to create a series of steps. It relies on DRI Modad because each step can give you a result. And if the result is a success, then the next step is going to happen. If the result is a failure, then the next step is not going to be done. You're going to keep your failure. This is known as the railway oriented programming. Nothing related to rails. It's just because you either stay on your success track, like train track, or at each step you have a junction to your failure track. Well, the thing is we didn't use DRI Transaction. So I wanted to let you know because I would really recommend that you use it. I wanted to use it, but also we have a team of several developers who are used to our Interactors. And it sounded like a better idea to use what everybody knew than trying to reinvent the wheel. We had something, it's working well, everybody knows it well. So this is like my manager voice talking. If it's end broken, broken, don't fix it. But if you're doing it from the start, give a chance to DRI Transaction and DRI Modad. At this point in the talk, I hoped to try my own definition of DRI Modad, of Monad, what is a Monad, which is probably going to take the next two hours. So let's keep it. So the end of this slide is about why do we want to do all that validation early? And this was also something a bit new. First of all, like failing early is a good idea. But it was not enough because doing the business validation at each step would have made more sense. It's just easier to keep the business steps together. It makes more sense if you want to check some permission, then delete a record, then send an email. It makes sense that you do everything related to sending the email at the sending email step. It doesn't really make sense to already check stuff from the start. But the thing is, in Rails, we are very much used to a highly rollback-able environment because most of what we do, well, sending email doesn't count, but most of what we do is manipulate the database. And this is a huge comfort being able to say, my record.transaction do blah, blah, blah, blah, blah, blah, blah, blah, blah, blah. If anything goes wrong, just roll back and done, nothing has happened. When you're doing a microservice, at least what we are doing, nothing is rollback-able. Everything you do, if you send an API request to something, if you delete a file, download a file, create a file, there's no rollback to that. And this is why it was so important to check as much as we could right from the start. All right, next step. Next step, next challenge. The next challenge was an interesting one, as every challenge, because it was about design and design opinion. And there's no truth, there's no strong truth in design opinion. So what was the challenge exactly? The challenge was that we realized we were not using dry containers properly. It felt like we were supposed to use it in a new way. Why was that? The reason was that we are very used to object-oriented design, object-oriented programming, which means we are putting together state and behavior in small objects, and they are responsible for doing that stuff. And the dry system, the dry container, was pushing us to use stateless objects, because that's what you could enjoy if you want to inject something everywhere. It better be stateless. But the code we wanted to write, because we have a lot of experience with that, was stateful. We don't want a command wrapper. We want a command execution specifically about this option. We want to ask a specific invocation. We don't want the full program. So it was very important to be able to write the code that we wanted to write, but it was also important to use the tools properly. And initially what we did is we had that big interactor, or big entry point, get injected with a ton of stuff from the container. It was getting all the services that it would eventually use, and that interactor was instantiating all the small objects, the small life cycle objects that it was going to use, and it was instantiating those objects, giving them their state, so maybe the current date, the current user, the current payload, and all the dependencies that the objects needed. So maybe there's a command service, maybe there's an API client, so the interactor was instantiating all of that, which means the interactor knew about almost everything. There's a name for that. GodObject. And it's a bad name. So we knew we were doing something wrong. We had a small discussion, and we realized that actually the literature again had a solution made for that. There's a pattern made for that. The pattern is factory. So what we eventually did is that we created new services, factories, very shallow services. Each factory was injected with the services that it needed, and the interactor was simply injected with the factories, and the interactor was just asking the factory, well, give me a command invocation specifically about this file, about this API, about this payload. And it's not a fun because it was so difficult to realize at first that we needed that, but at the same time it was so obvious what was the solution. It also raised an interesting comparison with a former colleague of mine who told me he was like a functional programmer. He, I'm not going to say despised, but he despised object-oriented programming. Well, I said it. And he told me, you know, an object is just a set of partially applied function. He was very like this day in for like, oh, it's just a set of partially applied function. We have like, we have object at home. Well, it's not the same. But to be honest, like, introducing those factories gave me that feeling because we had like those functions. We were partially applying all the dependencies. That's like first partial application, and then we were partially applying the state. It also opened our mind about what is stateless, what is stateful. Usually state is like all your instance variables. It's not really true. You don't see things like this anymore. Like your dependencies might still make you stateless. And your state is really what makes an object throwable. So if it's a reusable object, it's stateless. If it's like a one-use object, it's stateful. That's sort of our new definition of that. And factories helps us creating one-use object because factories are all stateless object. Well, I felt bad creating the slide without mentioning a single dry gem. So I also want to bring one here, is the dry initializer gem. And to be honest, this is my favorite, and it's so small. The thing is this is so small that it's crazy that this is my favorite gem. It creates contractors. It just creates an initialized method. But why does it matter? Because if you are very strict about it, all your initializer very probably look the same. It's like you pass them arguments, and then you store them into instance variable. Nothing more because doing business in initializer is a bad idea. So you always get the same initializer times and again, and it makes no sense, and it creates noise. And if you're used to more style guides, it has to be at the top of the file, and it also takes a very important part, focus, because top of the file is very important. So dry initializer, just do that. It says you can create one line for each dependency or state that you want. You can give it a type. You don't have to, but if you have a drive type, you might want to. You can give it a default value, and you automatically get an initializer that accepts them, and you automatically create an ATTR reader for each of the dependencies. You don't want the reader. You don't have to, but by default, you get that. And that's it, and you just transform something very long and noisy into a series of lines. We used to have ATTR reader anyways. That's most of our classes have ATTR, one line for ATTR reader anyways. So it changed nothing in terms of noise. It changed everything in terms of clarity, intention, and anyone reading a file now gets something directly by reading those lines. And yeah, I'm still on time. Well, we were done with the code application. Of course, we had additional challenges, but eventually using those tools and approaches, we reached up the end of the application, and we were done, right? Well, no, we still had to package it. We still had to deploy it, because as long as we were actually solving problems, we had nothing. This is again a time when we realized how rich is the Rails ecosystem, because for deployment, you either get services like Heroku or similar services, or using Capistrano, which does everything for you. You write one CAP file and everything is magic. When we had to deploy, we were like, yeah, we have files with code, but we still have no application. So we get some help from partners about that. We use Docker Compose locally for creating containers. We use Kubernetes remotely for deploying them. We use Helm for actually doing the deployment. And this led us to realize that we still had problems, because we had no observability. We had very difficult access to the log files, so there was still a lot of stuff we didn't have. So what we did is we introduced Yabbaida from Evil Martian. I don't know if anybody is from Evil Martian here, but if you are and if you watch us, like, thank you, you're awesome Evil Martian. So we used Yabbaida, which is an observability framework. It allows you to mention what you want to observe, create metrics, without having to care like where you intend to put those metrics, what we intend to do with those metrics. And then another part of Yabbaida, you can mention, like, actually what you want to do. You can separate the two. So your business logic is not riddled with, like, technical details about monitoring. So this observability allows us to expose some metrics, which in turn enabled us to create autoscaling to measure health. So these are typically stuff that you get for free in Rails if you're using your relic or data. But we had to do it by hand. And we finally reached our latest challenge, because we are not experts in Helm or Kubernetes. We are actually very noob in that. So we had partners helping us. But those partners are also responsible for, like, running and ensuring that our app is working properly. So the way the agreement we had with them is they handled their own repo with everything they do about us. And we have our own repo with our code base. And the problem we realized, and we still haven't solved, is that part of the application is actually in the infrastructure. And this is something we are not used to do in Rails. But typically the queue we use have a dead-letter queue. If you try to read something and it fails, so you release, you retry to receive, it fails. After sometimes that message, you put it into a dead-letter because you don't want to lose waste more time trying to handle that. Another aspect is buckets have life cycle. If a file is forgotten there after 24 hours, you want to delete that file. You don't want to pay fees for that file for the rest of your life. And this is application logic. Even though it fits in infrastructure, like it is application logic. And this bothers me because application logic, anyone who clones a repo should be able to see everything, to know everything. They don't have to be master at everything. They don't have to change everything. But cloning a single repo should explain everything there is to know about this app. So at the moment we still have those two repo. One is like focusing on the infrastructure. One is focusing on the code base. Hopefully we will solve that very soon. But with that done, we actually had the app deployed, monitors scaled, we learned quite a lot. We actually made a blueprint out of that, so we are creating several other workers right out of that. And we feel much more confident actually using Ruby for something else than web application. So thank you, everyone, for your time. Thank you. Any questions? We have two minutes of questions, hopefully. You've talked a lot about... I mean, first you never talked about Rails, but you actually miss it a lot. It's pretty funny that it was not about Rails, but actually... Anyway, you talked a lot about types. Is that something more to bring to the rest of the ecosystem? Yeah, that's a very good question. So the question is, I talked a lot about types. Do I want to bring that into Rails? Actually, the interactor is something we do in Rails already, which means we are using dry validation already, which means we are using dry types already. To be fully honest, we don't use it enough. We sort of use it when we realize that we should have used it before. So it's like not good enough, but it is something we are using, and types have been very helpful in the past already. And there's a lot of other tools that we have discovered here, because we had to, and I very much hope that we are going to use them. But also, my first slide means that I'm no CTO, I'm no manager, which means I don't get to make those calls anymore. And it's very important to me that the one who writes the app are responsible for writing it, maintaining it, running it, so I can influence, I can give my opinion, but I don't make those calls anymore. Yes? You said that you use dry monot. What has been, can you tell me more about your experience, because I used it quite extensively in the past before they introduced these two notations. And it was very sticky to the code as in, it made Ruby not look like Ruby, like something else. So, if there is something changed there, how's your experience? All right, so the question is, do I use dry monot? What do I think of the do notation, and how Ruby-esque does it feel? Is that right? Yes. Okay. So I am not using dry monot, except for like toy projects. So we are not using dry monot in this, so our own take is using our own interactors. So whatever I'm going to say is out of my experience on toy projects. I've learned initially about monads in Haskell. This is still very painful to me 10 years later. So my take on monads is like, most of the time, it's like not the right tool. And it's something that people, the learning curve for understanding what is a monad is so high that once you've earned the right to understand what it is, you want to put it everywhere. A little bit like meta-programming. So this is my take on monads. I wouldn't force them into anyone who is not very comfortable using them. I do believe that it is a very elegant solution, but I also do believe that sometimes a bunch of if-else makes the team happier than using the best tool for the occasion. And I don't have any opinion about the do notation and how Ruby-esque it feels. All right, thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 5.0, "text": " Okay, awesome.", "tokens": [50364, 1033, 11, 3476, 13, 50614], "temperature": 0.0, "avg_logprob": -0.2426972181900688, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.41681796312332153}, {"id": 1, "seek": 0, "start": 5.0, "end": 10.0, "text": " The mic is on, hopefully.", "tokens": [50614, 440, 3123, 307, 322, 11, 4696, 13, 50864], "temperature": 0.0, "avg_logprob": -0.2426972181900688, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.41681796312332153}, {"id": 2, "seek": 0, "start": 10.0, "end": 12.0, "text": " All right, good afternoon everyone.", "tokens": [50864, 1057, 558, 11, 665, 6499, 1518, 13, 50964], "temperature": 0.0, "avg_logprob": -0.2426972181900688, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.41681796312332153}, {"id": 3, "seek": 0, "start": 12.0, "end": 15.0, "text": " So I'm going to talk to you about a worker story,", "tokens": [50964, 407, 286, 478, 516, 281, 751, 281, 291, 466, 257, 11346, 1657, 11, 51114], "temperature": 0.0, "avg_logprob": -0.2426972181900688, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.41681796312332153}, {"id": 4, "seek": 0, "start": 15.0, "end": 18.0, "text": " which is something we did at work recently.", "tokens": [51114, 597, 307, 746, 321, 630, 412, 589, 3938, 13, 51264], "temperature": 0.0, "avg_logprob": -0.2426972181900688, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.41681796312332153}, {"id": 5, "seek": 0, "start": 18.0, "end": 22.0, "text": " And for once, it was like not using Rails.", "tokens": [51264, 400, 337, 1564, 11, 309, 390, 411, 406, 1228, 48526, 13, 51464], "temperature": 0.0, "avg_logprob": -0.2426972181900688, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.41681796312332153}, {"id": 6, "seek": 0, "start": 22.0, "end": 23.0, "text": " That's awesome.", "tokens": [51464, 663, 311, 3476, 13, 51514], "temperature": 0.0, "avg_logprob": -0.2426972181900688, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.41681796312332153}, {"id": 7, "seek": 0, "start": 23.0, "end": 24.0, "text": " Not using web at all.", "tokens": [51514, 1726, 1228, 3670, 412, 439, 13, 51564], "temperature": 0.0, "avg_logprob": -0.2426972181900688, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.41681796312332153}, {"id": 8, "seek": 0, "start": 24.0, "end": 29.0, "text": " That's what motivated me to tell you this story.", "tokens": [51564, 663, 311, 437, 14515, 385, 281, 980, 291, 341, 1657, 13, 51814], "temperature": 0.0, "avg_logprob": -0.2426972181900688, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.41681796312332153}, {"id": 9, "seek": 2900, "start": 29.0, "end": 33.0, "text": " So before we start, I would like to know who here is the Rails developer?", "tokens": [50364, 407, 949, 321, 722, 11, 286, 576, 411, 281, 458, 567, 510, 307, 264, 48526, 10754, 30, 50564], "temperature": 0.0, "avg_logprob": -0.10987600430037624, "compression_ratio": 1.630952380952381, "no_speech_prob": 0.01112321950495243}, {"id": 10, "seek": 2900, "start": 33.0, "end": 34.0, "text": " Who would like?", "tokens": [50564, 2102, 576, 411, 30, 50614], "temperature": 0.0, "avg_logprob": -0.10987600430037624, "compression_ratio": 1.630952380952381, "no_speech_prob": 0.01112321950495243}, {"id": 11, "seek": 2900, "start": 34.0, "end": 35.0, "text": " Yeah, awesome.", "tokens": [50614, 865, 11, 3476, 13, 50664], "temperature": 0.0, "avg_logprob": -0.10987600430037624, "compression_ratio": 1.630952380952381, "no_speech_prob": 0.01112321950495243}, {"id": 12, "seek": 2900, "start": 35.0, "end": 40.0, "text": " Who would say that they are Ruby, but not Rails developer?", "tokens": [50664, 2102, 576, 584, 300, 436, 366, 19907, 11, 457, 406, 48526, 10754, 30, 50914], "temperature": 0.0, "avg_logprob": -0.10987600430037624, "compression_ratio": 1.630952380952381, "no_speech_prob": 0.01112321950495243}, {"id": 13, "seek": 2900, "start": 40.0, "end": 41.0, "text": " Okay, awesome.", "tokens": [50914, 1033, 11, 3476, 13, 50964], "temperature": 0.0, "avg_logprob": -0.10987600430037624, "compression_ratio": 1.630952380952381, "no_speech_prob": 0.01112321950495243}, {"id": 14, "seek": 2900, "start": 41.0, "end": 42.0, "text": " That's great.", "tokens": [50964, 663, 311, 869, 13, 51014], "temperature": 0.0, "avg_logprob": -0.10987600430037624, "compression_ratio": 1.630952380952381, "no_speech_prob": 0.01112321950495243}, {"id": 15, "seek": 2900, "start": 42.0, "end": 43.0, "text": " Love it.", "tokens": [51014, 5956, 309, 13, 51064], "temperature": 0.0, "avg_logprob": -0.10987600430037624, "compression_ratio": 1.630952380952381, "no_speech_prob": 0.01112321950495243}, {"id": 16, "seek": 2900, "start": 43.0, "end": 44.0, "text": " I didn't expect that.", "tokens": [51064, 286, 994, 380, 2066, 300, 13, 51114], "temperature": 0.0, "avg_logprob": -0.10987600430037624, "compression_ratio": 1.630952380952381, "no_speech_prob": 0.01112321950495243}, {"id": 17, "seek": 2900, "start": 44.0, "end": 45.0, "text": " Awesome.", "tokens": [51114, 10391, 13, 51164], "temperature": 0.0, "avg_logprob": -0.10987600430037624, "compression_ratio": 1.630952380952381, "no_speech_prob": 0.01112321950495243}, {"id": 18, "seek": 2900, "start": 45.0, "end": 48.0, "text": " All right, first of all, who am I?", "tokens": [51164, 1057, 558, 11, 700, 295, 439, 11, 567, 669, 286, 30, 51314], "temperature": 0.0, "avg_logprob": -0.10987600430037624, "compression_ratio": 1.630952380952381, "no_speech_prob": 0.01112321950495243}, {"id": 19, "seek": 2900, "start": 48.0, "end": 53.0, "text": " Because if you don't know who am I, you might not rely on whatever I'm going to say.", "tokens": [51314, 1436, 498, 291, 500, 380, 458, 567, 669, 286, 11, 291, 1062, 406, 10687, 322, 2035, 286, 478, 516, 281, 584, 13, 51564], "temperature": 0.0, "avg_logprob": -0.10987600430037624, "compression_ratio": 1.630952380952381, "no_speech_prob": 0.01112321950495243}, {"id": 20, "seek": 2900, "start": 53.0, "end": 57.0, "text": " So I've been Ruby and mostly Rails developer for 10 years.", "tokens": [51564, 407, 286, 600, 668, 19907, 293, 5240, 48526, 10754, 337, 1266, 924, 13, 51764], "temperature": 0.0, "avg_logprob": -0.10987600430037624, "compression_ratio": 1.630952380952381, "no_speech_prob": 0.01112321950495243}, {"id": 21, "seek": 5700, "start": 57.0, "end": 62.0, "text": " I've been working with Kevin for almost that period.", "tokens": [50364, 286, 600, 668, 1364, 365, 9954, 337, 1920, 300, 2896, 13, 50614], "temperature": 0.0, "avg_logprob": -0.11368340136958104, "compression_ratio": 1.595330739299611, "no_speech_prob": 0.028373122215270996}, {"id": 22, "seek": 5700, "start": 62.0, "end": 68.0, "text": " More recently, I have become a lead dev, then a manager, then a CTO.", "tokens": [50614, 5048, 3938, 11, 286, 362, 1813, 257, 1477, 1905, 11, 550, 257, 6598, 11, 550, 257, 383, 15427, 13, 50914], "temperature": 0.0, "avg_logprob": -0.11368340136958104, "compression_ratio": 1.595330739299611, "no_speech_prob": 0.028373122215270996}, {"id": 23, "seek": 5700, "start": 68.0, "end": 74.0, "text": " So I'm doing a lot of new responsibilities now, which also gives me a new perspective", "tokens": [50914, 407, 286, 478, 884, 257, 688, 295, 777, 16190, 586, 11, 597, 611, 2709, 385, 257, 777, 4585, 51214], "temperature": 0.0, "avg_logprob": -0.11368340136958104, "compression_ratio": 1.595330739299611, "no_speech_prob": 0.028373122215270996}, {"id": 24, "seek": 5700, "start": 74.0, "end": 79.0, "text": " on a lot of programming topic, actually getting new perspective when you start making a decision", "tokens": [51214, 322, 257, 688, 295, 9410, 4829, 11, 767, 1242, 777, 4585, 562, 291, 722, 1455, 257, 3537, 51464], "temperature": 0.0, "avg_logprob": -0.11368340136958104, "compression_ratio": 1.595330739299611, "no_speech_prob": 0.028373122215270996}, {"id": 25, "seek": 5700, "start": 79.0, "end": 82.0, "text": " about people and processes and stuff like that.", "tokens": [51464, 466, 561, 293, 7555, 293, 1507, 411, 300, 13, 51614], "temperature": 0.0, "avg_logprob": -0.11368340136958104, "compression_ratio": 1.595330739299611, "no_speech_prob": 0.028373122215270996}, {"id": 26, "seek": 5700, "start": 82.0, "end": 86.0, "text": " And finally, I've been a teacher for more than six years.", "tokens": [51614, 400, 2721, 11, 286, 600, 668, 257, 5027, 337, 544, 813, 2309, 924, 13, 51814], "temperature": 0.0, "avg_logprob": -0.11368340136958104, "compression_ratio": 1.595330739299611, "no_speech_prob": 0.028373122215270996}, {"id": 27, "seek": 8600, "start": 86.0, "end": 89.0, "text": " I've given a lecture at EPL and Le Wagon.", "tokens": [50364, 286, 600, 2212, 257, 7991, 412, 462, 21593, 293, 1456, 343, 6709, 13, 50514], "temperature": 0.0, "avg_logprob": -0.16339415692268533, "compression_ratio": 1.492822966507177, "no_speech_prob": 0.02156016230583191}, {"id": 28, "seek": 8600, "start": 89.0, "end": 91.0, "text": " Hopefully, we'll do that again.", "tokens": [50514, 10429, 11, 321, 603, 360, 300, 797, 13, 50614], "temperature": 0.0, "avg_logprob": -0.16339415692268533, "compression_ratio": 1.492822966507177, "no_speech_prob": 0.02156016230583191}, {"id": 29, "seek": 8600, "start": 91.0, "end": 95.0, "text": " I feel like a deep-footed lover for teaching and sharing knowledge.", "tokens": [50614, 286, 841, 411, 257, 2452, 12, 13498, 292, 18009, 337, 4571, 293, 5414, 3601, 13, 50814], "temperature": 0.0, "avg_logprob": -0.16339415692268533, "compression_ratio": 1.492822966507177, "no_speech_prob": 0.02156016230583191}, {"id": 30, "seek": 8600, "start": 95.0, "end": 99.0, "text": " And this is also why I'm here today.", "tokens": [50814, 400, 341, 307, 611, 983, 286, 478, 510, 965, 13, 51014], "temperature": 0.0, "avg_logprob": -0.16339415692268533, "compression_ratio": 1.492822966507177, "no_speech_prob": 0.02156016230583191}, {"id": 31, "seek": 8600, "start": 99.0, "end": 107.0, "text": " So I was saying the point of this talk is talking about Ruby, but not about Rails, not about", "tokens": [51014, 407, 286, 390, 1566, 264, 935, 295, 341, 751, 307, 1417, 466, 19907, 11, 457, 406, 466, 48526, 11, 406, 466, 51414], "temperature": 0.0, "avg_logprob": -0.16339415692268533, "compression_ratio": 1.492822966507177, "no_speech_prob": 0.02156016230583191}, {"id": 32, "seek": 8600, "start": 107.0, "end": 110.0, "text": " web.", "tokens": [51414, 3670, 13, 51564], "temperature": 0.0, "avg_logprob": -0.16339415692268533, "compression_ratio": 1.492822966507177, "no_speech_prob": 0.02156016230583191}, {"id": 33, "seek": 8600, "start": 110.0, "end": 112.0, "text": " And this was the first time for me.", "tokens": [51564, 400, 341, 390, 264, 700, 565, 337, 385, 13, 51664], "temperature": 0.0, "avg_logprob": -0.16339415692268533, "compression_ratio": 1.492822966507177, "no_speech_prob": 0.02156016230583191}, {"id": 34, "seek": 11200, "start": 112.0, "end": 114.0, "text": " I was like a new experience.", "tokens": [50364, 286, 390, 411, 257, 777, 1752, 13, 50464], "temperature": 0.0, "avg_logprob": -0.10209071308100989, "compression_ratio": 1.6569037656903767, "no_speech_prob": 0.1737586110830307}, {"id": 35, "seek": 11200, "start": 114.0, "end": 121.0, "text": " And it's strange to see how much changes when you start doing that, how much you realize", "tokens": [50464, 400, 309, 311, 5861, 281, 536, 577, 709, 2962, 562, 291, 722, 884, 300, 11, 577, 709, 291, 4325, 50814], "temperature": 0.0, "avg_logprob": -0.10209071308100989, "compression_ratio": 1.6569037656903767, "no_speech_prob": 0.1737586110830307}, {"id": 36, "seek": 11200, "start": 121.0, "end": 126.0, "text": " Rails was giving to you once you don't have that anymore.", "tokens": [50814, 48526, 390, 2902, 281, 291, 1564, 291, 500, 380, 362, 300, 3602, 13, 51064], "temperature": 0.0, "avg_logprob": -0.10209071308100989, "compression_ratio": 1.6569037656903767, "no_speech_prob": 0.1737586110830307}, {"id": 37, "seek": 11200, "start": 126.0, "end": 128.0, "text": " I have some notes.", "tokens": [51064, 286, 362, 512, 5570, 13, 51164], "temperature": 0.0, "avg_logprob": -0.10209071308100989, "compression_ratio": 1.6569037656903767, "no_speech_prob": 0.1737586110830307}, {"id": 38, "seek": 11200, "start": 128.0, "end": 131.0, "text": " By the way, all my slides are going to be minimalistic.", "tokens": [51164, 3146, 264, 636, 11, 439, 452, 9788, 366, 516, 281, 312, 13206, 3142, 13, 51314], "temperature": 0.0, "avg_logprob": -0.10209071308100989, "compression_ratio": 1.6569037656903767, "no_speech_prob": 0.1737586110830307}, {"id": 39, "seek": 11200, "start": 131.0, "end": 133.0, "text": " I'm not going to show you a single line of code.", "tokens": [51314, 286, 478, 406, 516, 281, 855, 291, 257, 2167, 1622, 295, 3089, 13, 51414], "temperature": 0.0, "avg_logprob": -0.10209071308100989, "compression_ratio": 1.6569037656903767, "no_speech_prob": 0.1737586110830307}, {"id": 40, "seek": 11200, "start": 133.0, "end": 139.0, "text": " I'm also going to forget a lot of stuff, which is why everything I intend to tell you is written", "tokens": [51414, 286, 478, 611, 516, 281, 2870, 257, 688, 295, 1507, 11, 597, 307, 983, 1203, 286, 19759, 281, 980, 291, 307, 3720, 51714], "temperature": 0.0, "avg_logprob": -0.10209071308100989, "compression_ratio": 1.6569037656903767, "no_speech_prob": 0.1737586110830307}, {"id": 41, "seek": 13900, "start": 139.0, "end": 142.0, "text": " in notes available directly in this.", "tokens": [50364, 294, 5570, 2435, 3838, 294, 341, 13, 50514], "temperature": 0.0, "avg_logprob": -0.14503503086591008, "compression_ratio": 1.6041666666666667, "no_speech_prob": 0.01591072417795658}, {"id": 42, "seek": 13900, "start": 142.0, "end": 148.0, "text": " So hopefully, you will get everything I intend to say because I'm going to forget part of that.", "tokens": [50514, 407, 4696, 11, 291, 486, 483, 1203, 286, 19759, 281, 584, 570, 286, 478, 516, 281, 2870, 644, 295, 300, 13, 50814], "temperature": 0.0, "avg_logprob": -0.14503503086591008, "compression_ratio": 1.6041666666666667, "no_speech_prob": 0.01591072417795658}, {"id": 43, "seek": 13900, "start": 148.0, "end": 154.0, "text": " So the main message of this talk is like it's doable.", "tokens": [50814, 407, 264, 2135, 3636, 295, 341, 751, 307, 411, 309, 311, 41183, 13, 51114], "temperature": 0.0, "avg_logprob": -0.14503503086591008, "compression_ratio": 1.6041666666666667, "no_speech_prob": 0.01591072417795658}, {"id": 44, "seek": 13900, "start": 154.0, "end": 160.0, "text": " It sounds strange that this is my message, but as most Rails developers sometimes, when we think", "tokens": [51114, 467, 3263, 5861, 300, 341, 307, 452, 3636, 11, 457, 382, 881, 48526, 8849, 2171, 11, 562, 321, 519, 51414], "temperature": 0.0, "avg_logprob": -0.14503503086591008, "compression_ratio": 1.6041666666666667, "no_speech_prob": 0.01591072417795658}, {"id": 45, "seek": 13900, "start": 160.0, "end": 164.0, "text": " about Ruby program, we're not even sure we can do it.", "tokens": [51414, 466, 19907, 1461, 11, 321, 434, 406, 754, 988, 321, 393, 360, 309, 13, 51614], "temperature": 0.0, "avg_logprob": -0.14503503086591008, "compression_ratio": 1.6041666666666667, "no_speech_prob": 0.01591072417795658}, {"id": 46, "seek": 13900, "start": 164.0, "end": 167.0, "text": " We're not even sure how would we approach that.", "tokens": [51614, 492, 434, 406, 754, 988, 577, 576, 321, 3109, 300, 13, 51764], "temperature": 0.0, "avg_logprob": -0.14503503086591008, "compression_ratio": 1.6041666666666667, "no_speech_prob": 0.01591072417795658}, {"id": 47, "seek": 16700, "start": 167.0, "end": 169.0, "text": " So the main message is like, yes, it's doable.", "tokens": [50364, 407, 264, 2135, 3636, 307, 411, 11, 2086, 11, 309, 311, 41183, 13, 50464], "temperature": 0.0, "avg_logprob": -0.0935193266824027, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.00807552132755518}, {"id": 48, "seek": 16700, "start": 169.0, "end": 170.0, "text": " There's a lot of tools.", "tokens": [50464, 821, 311, 257, 688, 295, 3873, 13, 50514], "temperature": 0.0, "avg_logprob": -0.0935193266824027, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.00807552132755518}, {"id": 49, "seek": 16700, "start": 170.0, "end": 171.0, "text": " There's a lot of process.", "tokens": [50514, 821, 311, 257, 688, 295, 1399, 13, 50564], "temperature": 0.0, "avg_logprob": -0.0935193266824027, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.00807552132755518}, {"id": 50, "seek": 16700, "start": 171.0, "end": 173.0, "text": " There's a lot of help along the way.", "tokens": [50564, 821, 311, 257, 688, 295, 854, 2051, 264, 636, 13, 50664], "temperature": 0.0, "avg_logprob": -0.0935193266824027, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.00807552132755518}, {"id": 51, "seek": 16700, "start": 173.0, "end": 179.0, "text": " And you can possibly, you can very likely, sorry, get most of your tools and knowledge", "tokens": [50664, 400, 291, 393, 6264, 11, 291, 393, 588, 3700, 11, 2597, 11, 483, 881, 295, 428, 3873, 293, 3601, 50964], "temperature": 0.0, "avg_logprob": -0.0935193266824027, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.00807552132755518}, {"id": 52, "seek": 16700, "start": 179.0, "end": 184.0, "text": " used in a normal, not web Ruby application.", "tokens": [50964, 1143, 294, 257, 2710, 11, 406, 3670, 19907, 3861, 13, 51214], "temperature": 0.0, "avg_logprob": -0.0935193266824027, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.00807552132755518}, {"id": 53, "seek": 16700, "start": 184.0, "end": 191.0, "text": " The second news is you can also get all of your Rails knowledge useful in Ruby application", "tokens": [51214, 440, 1150, 2583, 307, 291, 393, 611, 483, 439, 295, 428, 48526, 3601, 4420, 294, 19907, 3861, 51564], "temperature": 0.0, "avg_logprob": -0.0935193266824027, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.00807552132755518}, {"id": 54, "seek": 16700, "start": 191.0, "end": 194.0, "text": " if you get things right.", "tokens": [51564, 498, 291, 483, 721, 558, 13, 51714], "temperature": 0.0, "avg_logprob": -0.0935193266824027, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.00807552132755518}, {"id": 55, "seek": 19400, "start": 194.0, "end": 198.0, "text": " So the story I'm going to tell is about like a worker.", "tokens": [50364, 407, 264, 1657, 286, 478, 516, 281, 980, 307, 466, 411, 257, 11346, 13, 50564], "temperature": 0.0, "avg_logprob": -0.13548444627641557, "compression_ratio": 1.737991266375546, "no_speech_prob": 0.002559396205469966}, {"id": 56, "seek": 19400, "start": 198.0, "end": 202.0, "text": " What is a worker in our case, in my case?", "tokens": [50564, 708, 307, 257, 11346, 294, 527, 1389, 11, 294, 452, 1389, 30, 50764], "temperature": 0.0, "avg_logprob": -0.13548444627641557, "compression_ratio": 1.737991266375546, "no_speech_prob": 0.002559396205469966}, {"id": 57, "seek": 19400, "start": 202.0, "end": 203.0, "text": " It's like microservice.", "tokens": [50764, 467, 311, 411, 15547, 25006, 13, 50814], "temperature": 0.0, "avg_logprob": -0.13548444627641557, "compression_ratio": 1.737991266375546, "no_speech_prob": 0.002559396205469966}, {"id": 58, "seek": 19400, "start": 203.0, "end": 205.0, "text": " The specificity, why do we call it a worker?", "tokens": [50814, 440, 2685, 507, 11, 983, 360, 321, 818, 309, 257, 11346, 30, 50914], "temperature": 0.0, "avg_logprob": -0.13548444627641557, "compression_ratio": 1.737991266375546, "no_speech_prob": 0.002559396205469966}, {"id": 59, "seek": 19400, "start": 205.0, "end": 208.0, "text": " Because it's not a web microservice.", "tokens": [50914, 1436, 309, 311, 406, 257, 3670, 15547, 25006, 13, 51064], "temperature": 0.0, "avg_logprob": -0.13548444627641557, "compression_ratio": 1.737991266375546, "no_speech_prob": 0.002559396205469966}, {"id": 60, "seek": 19400, "start": 208.0, "end": 213.0, "text": " It's a microservice which is consuming messages from a queue and very likely is going to process", "tokens": [51064, 467, 311, 257, 15547, 25006, 597, 307, 19867, 7897, 490, 257, 18639, 293, 588, 3700, 307, 516, 281, 1399, 51314], "temperature": 0.0, "avg_logprob": -0.13548444627641557, "compression_ratio": 1.737991266375546, "no_speech_prob": 0.002559396205469966}, {"id": 61, "seek": 19400, "start": 213.0, "end": 219.0, "text": " files, so it's going to get files from a bucket, process them locally, put them on another bucket.", "tokens": [51314, 7098, 11, 370, 309, 311, 516, 281, 483, 7098, 490, 257, 13058, 11, 1399, 552, 16143, 11, 829, 552, 322, 1071, 13058, 13, 51614], "temperature": 0.0, "avg_logprob": -0.13548444627641557, "compression_ratio": 1.737991266375546, "no_speech_prob": 0.002559396205469966}, {"id": 62, "seek": 21900, "start": 220.0, "end": 225.0, "text": " We have, we are using the word worker because we have like lots of them.", "tokens": [50414, 492, 362, 11, 321, 366, 1228, 264, 1349, 11346, 570, 321, 362, 411, 3195, 295, 552, 13, 50664], "temperature": 0.0, "avg_logprob": -0.12879232259897086, "compression_ratio": 1.7013574660633484, "no_speech_prob": 0.00973484292626381}, {"id": 63, "seek": 21900, "start": 225.0, "end": 226.0, "text": " That's simple definition.", "tokens": [50664, 663, 311, 2199, 7123, 13, 50714], "temperature": 0.0, "avg_logprob": -0.12879232259897086, "compression_ratio": 1.7013574660633484, "no_speech_prob": 0.00973484292626381}, {"id": 64, "seek": 21900, "start": 226.0, "end": 227.0, "text": " We have lots of them.", "tokens": [50714, 492, 362, 3195, 295, 552, 13, 50764], "temperature": 0.0, "avg_logprob": -0.12879232259897086, "compression_ratio": 1.7013574660633484, "no_speech_prob": 0.00973484292626381}, {"id": 65, "seek": 21900, "start": 227.0, "end": 232.0, "text": " So I'm going to talk about like one of them, but it could be any of them.", "tokens": [50764, 407, 286, 478, 516, 281, 751, 466, 411, 472, 295, 552, 11, 457, 309, 727, 312, 604, 295, 552, 13, 51014], "temperature": 0.0, "avg_logprob": -0.12879232259897086, "compression_ratio": 1.7013574660633484, "no_speech_prob": 0.00973484292626381}, {"id": 66, "seek": 21900, "start": 232.0, "end": 235.0, "text": " So we think start with a loop.", "tokens": [51014, 407, 321, 519, 722, 365, 257, 6367, 13, 51164], "temperature": 0.0, "avg_logprob": -0.12879232259897086, "compression_ratio": 1.7013574660633484, "no_speech_prob": 0.00973484292626381}, {"id": 67, "seek": 21900, "start": 235.0, "end": 241.0, "text": " The whole story starts with a loop because when I started this, I really like I opened", "tokens": [51164, 440, 1379, 1657, 3719, 365, 257, 6367, 570, 562, 286, 1409, 341, 11, 286, 534, 411, 286, 5625, 51464], "temperature": 0.0, "avg_logprob": -0.12879232259897086, "compression_ratio": 1.7013574660633484, "no_speech_prob": 0.00973484292626381}, {"id": 68, "seek": 21900, "start": 241.0, "end": 246.0, "text": " my editor and I saw something which I hadn't seen since school.", "tokens": [51464, 452, 9839, 293, 286, 1866, 746, 597, 286, 8782, 380, 1612, 1670, 1395, 13, 51714], "temperature": 0.0, "avg_logprob": -0.12879232259897086, "compression_ratio": 1.7013574660633484, "no_speech_prob": 0.00973484292626381}, {"id": 69, "seek": 24600, "start": 246.0, "end": 249.0, "text": " It's an empty directory.", "tokens": [50364, 467, 311, 364, 6707, 21120, 13, 50514], "temperature": 0.0, "avg_logprob": -0.16166127769692432, "compression_ratio": 1.68, "no_speech_prob": 0.010748440399765968}, {"id": 70, "seek": 24600, "start": 249.0, "end": 250.0, "text": " It's very strange.", "tokens": [50514, 467, 311, 588, 5861, 13, 50564], "temperature": 0.0, "avg_logprob": -0.16166127769692432, "compression_ratio": 1.68, "no_speech_prob": 0.010748440399765968}, {"id": 71, "seek": 24600, "start": 250.0, "end": 256.0, "text": " Like really first as a Rails developer, I'm really used to Rails new and then you get", "tokens": [50564, 1743, 534, 700, 382, 257, 48526, 10754, 11, 286, 478, 534, 1143, 281, 48526, 777, 293, 550, 291, 483, 50864], "temperature": 0.0, "avg_logprob": -0.16166127769692432, "compression_ratio": 1.68, "no_speech_prob": 0.010748440399765968}, {"id": 72, "seek": 24600, "start": 256.0, "end": 257.0, "text": " like everything.", "tokens": [50864, 411, 1203, 13, 50914], "temperature": 0.0, "avg_logprob": -0.16166127769692432, "compression_ratio": 1.68, "no_speech_prob": 0.010748440399765968}, {"id": 73, "seek": 24600, "start": 257.0, "end": 260.0, "text": " You get folders, tree, substructure.", "tokens": [50914, 509, 483, 31082, 11, 4230, 11, 4594, 2885, 13, 51064], "temperature": 0.0, "avg_logprob": -0.16166127769692432, "compression_ratio": 1.68, "no_speech_prob": 0.010748440399765968}, {"id": 74, "seek": 24600, "start": 260.0, "end": 264.0, "text": " You get the config directory, you get the app directory.", "tokens": [51064, 509, 483, 264, 6662, 21120, 11, 291, 483, 264, 724, 21120, 13, 51264], "temperature": 0.0, "avg_logprob": -0.16166127769692432, "compression_ratio": 1.68, "no_speech_prob": 0.010748440399765968}, {"id": 75, "seek": 24600, "start": 264.0, "end": 270.0, "text": " You, like there's drawers everywhere about what you expect to put things.", "tokens": [51264, 509, 11, 411, 456, 311, 38302, 5315, 466, 437, 291, 2066, 281, 829, 721, 13, 51564], "temperature": 0.0, "avg_logprob": -0.16166127769692432, "compression_ratio": 1.68, "no_speech_prob": 0.010748440399765968}, {"id": 76, "seek": 24600, "start": 270.0, "end": 275.0, "text": " In this case, I just like create a new folder and it was empty.", "tokens": [51564, 682, 341, 1389, 11, 286, 445, 411, 1884, 257, 777, 10820, 293, 309, 390, 6707, 13, 51814], "temperature": 0.0, "avg_logprob": -0.16166127769692432, "compression_ratio": 1.68, "no_speech_prob": 0.010748440399765968}, {"id": 77, "seek": 27500, "start": 275.0, "end": 278.0, "text": " I'm a firm believer in emergent design.", "tokens": [50364, 286, 478, 257, 6174, 23892, 294, 4345, 6930, 1715, 13, 50514], "temperature": 0.0, "avg_logprob": -0.11182926819387791, "compression_ratio": 1.6511627906976745, "no_speech_prob": 0.0015184752410277724}, {"id": 78, "seek": 27500, "start": 278.0, "end": 285.0, "text": " So I started immediately like new file, worker.rb, make a loop, while true, read, perform, delete", "tokens": [50514, 407, 286, 1409, 4258, 411, 777, 3991, 11, 11346, 13, 81, 65, 11, 652, 257, 6367, 11, 1339, 2074, 11, 1401, 11, 2042, 11, 12097, 50864], "temperature": 0.0, "avg_logprob": -0.11182926819387791, "compression_ratio": 1.6511627906976745, "no_speech_prob": 0.0015184752410277724}, {"id": 79, "seek": 27500, "start": 285.0, "end": 286.0, "text": " message.", "tokens": [50864, 3636, 13, 50914], "temperature": 0.0, "avg_logprob": -0.11182926819387791, "compression_ratio": 1.6511627906976745, "no_speech_prob": 0.0015184752410277724}, {"id": 80, "seek": 27500, "start": 286.0, "end": 288.0, "text": " I'm done.", "tokens": [50914, 286, 478, 1096, 13, 51014], "temperature": 0.0, "avg_logprob": -0.11182926819387791, "compression_ratio": 1.6511627906976745, "no_speech_prob": 0.0015184752410277724}, {"id": 81, "seek": 27500, "start": 288.0, "end": 289.0, "text": " It was nice.", "tokens": [51014, 467, 390, 1481, 13, 51064], "temperature": 0.0, "avg_logprob": -0.11182926819387791, "compression_ratio": 1.6511627906976745, "no_speech_prob": 0.0015184752410277724}, {"id": 82, "seek": 27500, "start": 289.0, "end": 295.0, "text": " Like it was, I knew it was not the end, but it was capturing whatever I was, I knew about", "tokens": [51064, 1743, 309, 390, 11, 286, 2586, 309, 390, 406, 264, 917, 11, 457, 309, 390, 23384, 2035, 286, 390, 11, 286, 2586, 466, 51364], "temperature": 0.0, "avg_logprob": -0.11182926819387791, "compression_ratio": 1.6511627906976745, "no_speech_prob": 0.0015184752410277724}, {"id": 83, "seek": 27500, "start": 295.0, "end": 296.0, "text": " my process.", "tokens": [51364, 452, 1399, 13, 51414], "temperature": 0.0, "avg_logprob": -0.11182926819387791, "compression_ratio": 1.6511627906976745, "no_speech_prob": 0.0015184752410277724}, {"id": 84, "seek": 27500, "start": 296.0, "end": 299.0, "text": " It was a single level of abstraction.", "tokens": [51414, 467, 390, 257, 2167, 1496, 295, 37765, 13, 51564], "temperature": 0.0, "avg_logprob": -0.11182926819387791, "compression_ratio": 1.6511627906976745, "no_speech_prob": 0.0015184752410277724}, {"id": 85, "seek": 27500, "start": 299.0, "end": 303.0, "text": " So I knew it was a good start, but it wasn't.", "tokens": [51564, 407, 286, 2586, 309, 390, 257, 665, 722, 11, 457, 309, 2067, 380, 13, 51764], "temperature": 0.0, "avg_logprob": -0.11182926819387791, "compression_ratio": 1.6511627906976745, "no_speech_prob": 0.0015184752410277724}, {"id": 86, "seek": 30300, "start": 303.0, "end": 311.0, "text": " It wasn't a good start because I was already forgetting like my main tool when doing Rails", "tokens": [50364, 467, 2067, 380, 257, 665, 722, 570, 286, 390, 1217, 25428, 411, 452, 2135, 2290, 562, 884, 48526, 50764], "temperature": 0.0, "avg_logprob": -0.09605506681046395, "compression_ratio": 1.658878504672897, "no_speech_prob": 0.007253153249621391}, {"id": 87, "seek": 30300, "start": 311.0, "end": 315.0, "text": " apps, which was going to be my main tool when doing any app.", "tokens": [50764, 7733, 11, 597, 390, 516, 281, 312, 452, 2135, 2290, 562, 884, 604, 724, 13, 50964], "temperature": 0.0, "avg_logprob": -0.09605506681046395, "compression_ratio": 1.658878504672897, "no_speech_prob": 0.007253153249621391}, {"id": 88, "seek": 30300, "start": 315.0, "end": 316.0, "text": " It's tests.", "tokens": [50964, 467, 311, 6921, 13, 51014], "temperature": 0.0, "avg_logprob": -0.09605506681046395, "compression_ratio": 1.658878504672897, "no_speech_prob": 0.007253153249621391}, {"id": 89, "seek": 30300, "start": 316.0, "end": 321.0, "text": " Anybody who knows me know that I'm a firm believer in tests.", "tokens": [51014, 19082, 567, 3255, 385, 458, 300, 286, 478, 257, 6174, 23892, 294, 6921, 13, 51264], "temperature": 0.0, "avg_logprob": -0.09605506681046395, "compression_ratio": 1.658878504672897, "no_speech_prob": 0.007253153249621391}, {"id": 90, "seek": 30300, "start": 321.0, "end": 322.0, "text": " And it's a policy.", "tokens": [51264, 400, 309, 311, 257, 3897, 13, 51314], "temperature": 0.0, "avg_logprob": -0.09605506681046395, "compression_ratio": 1.658878504672897, "no_speech_prob": 0.007253153249621391}, {"id": 91, "seek": 30300, "start": 322.0, "end": 324.0, "text": " It's not a religion, but it's a policy.", "tokens": [51314, 467, 311, 406, 257, 7561, 11, 457, 309, 311, 257, 3897, 13, 51414], "temperature": 0.0, "avg_logprob": -0.09605506681046395, "compression_ratio": 1.658878504672897, "no_speech_prob": 0.007253153249621391}, {"id": 92, "seek": 30300, "start": 324.0, "end": 326.0, "text": " This is how I write code.", "tokens": [51414, 639, 307, 577, 286, 2464, 3089, 13, 51514], "temperature": 0.0, "avg_logprob": -0.09605506681046395, "compression_ratio": 1.658878504672897, "no_speech_prob": 0.007253153249621391}, {"id": 93, "seek": 30300, "start": 326.0, "end": 331.0, "text": " I do believe in it, but you mileage may vary.", "tokens": [51514, 286, 360, 1697, 294, 309, 11, 457, 291, 43121, 815, 10559, 13, 51764], "temperature": 0.0, "avg_logprob": -0.09605506681046395, "compression_ratio": 1.658878504672897, "no_speech_prob": 0.007253153249621391}, {"id": 94, "seek": 33100, "start": 331.0, "end": 334.0, "text": " But for me, it was the beginning.", "tokens": [50364, 583, 337, 385, 11, 309, 390, 264, 2863, 13, 50514], "temperature": 0.0, "avg_logprob": -0.08230246550647925, "compression_ratio": 2.0427350427350426, "no_speech_prob": 0.020447591319680214}, {"id": 95, "seek": 33100, "start": 334.0, "end": 339.0, "text": " And it's funny because I knew I was going to write loop, the loop of my program, but I", "tokens": [50514, 400, 309, 311, 4074, 570, 286, 2586, 286, 390, 516, 281, 2464, 6367, 11, 264, 6367, 295, 452, 1461, 11, 457, 286, 50764], "temperature": 0.0, "avg_logprob": -0.08230246550647925, "compression_ratio": 2.0427350427350426, "no_speech_prob": 0.020447591319680214}, {"id": 96, "seek": 33100, "start": 339.0, "end": 343.0, "text": " was also starting another loop, the loop of my process.", "tokens": [50764, 390, 611, 2891, 1071, 6367, 11, 264, 6367, 295, 452, 1399, 13, 50964], "temperature": 0.0, "avg_logprob": -0.08230246550647925, "compression_ratio": 2.0427350427350426, "no_speech_prob": 0.020447591319680214}, {"id": 97, "seek": 33100, "start": 343.0, "end": 346.0, "text": " And this is what tests are for me.", "tokens": [50964, 400, 341, 307, 437, 6921, 366, 337, 385, 13, 51114], "temperature": 0.0, "avg_logprob": -0.08230246550647925, "compression_ratio": 2.0427350427350426, "no_speech_prob": 0.020447591319680214}, {"id": 98, "seek": 33100, "start": 346.0, "end": 350.0, "text": " Test first does not mean you do test, then you do code, then you're done.", "tokens": [51114, 9279, 700, 775, 406, 914, 291, 360, 1500, 11, 550, 291, 360, 3089, 11, 550, 291, 434, 1096, 13, 51314], "temperature": 0.0, "avg_logprob": -0.08230246550647925, "compression_ratio": 2.0427350427350426, "no_speech_prob": 0.020447591319680214}, {"id": 99, "seek": 33100, "start": 350.0, "end": 353.0, "text": " Test first means your first step in the journey is test.", "tokens": [51314, 9279, 700, 1355, 428, 700, 1823, 294, 264, 4671, 307, 1500, 13, 51464], "temperature": 0.0, "avg_logprob": -0.08230246550647925, "compression_ratio": 2.0427350427350426, "no_speech_prob": 0.020447591319680214}, {"id": 100, "seek": 33100, "start": 353.0, "end": 357.0, "text": " Then code, then test, then code, then test, then code, then test, then code.", "tokens": [51464, 1396, 3089, 11, 550, 1500, 11, 550, 3089, 11, 550, 1500, 11, 550, 3089, 11, 550, 1500, 11, 550, 3089, 13, 51664], "temperature": 0.0, "avg_logprob": -0.08230246550647925, "compression_ratio": 2.0427350427350426, "no_speech_prob": 0.020447591319680214}, {"id": 101, "seek": 33100, "start": 357.0, "end": 359.0, "text": " That's what it means to me to do test.", "tokens": [51664, 663, 311, 437, 309, 1355, 281, 385, 281, 360, 1500, 13, 51764], "temperature": 0.0, "avg_logprob": -0.08230246550647925, "compression_ratio": 2.0427350427350426, "no_speech_prob": 0.020447591319680214}, {"id": 102, "seek": 33100, "start": 359.0, "end": 360.0, "text": " But I did it wrong.", "tokens": [51764, 583, 286, 630, 309, 2085, 13, 51814], "temperature": 0.0, "avg_logprob": -0.08230246550647925, "compression_ratio": 2.0427350427350426, "no_speech_prob": 0.020447591319680214}, {"id": 103, "seek": 36000, "start": 360.0, "end": 361.0, "text": " I started with code.", "tokens": [50364, 286, 1409, 365, 3089, 13, 50414], "temperature": 0.0, "avg_logprob": -0.10471612215042114, "compression_ratio": 1.5783132530120483, "no_speech_prob": 0.008726987056434155}, {"id": 104, "seek": 36000, "start": 361.0, "end": 363.0, "text": " So I tried again.", "tokens": [50414, 407, 286, 3031, 797, 13, 50514], "temperature": 0.0, "avg_logprob": -0.10471612215042114, "compression_ratio": 1.5783132530120483, "no_speech_prob": 0.008726987056434155}, {"id": 105, "seek": 36000, "start": 363.0, "end": 364.0, "text": " I deleted my file.", "tokens": [50514, 286, 22981, 452, 3991, 13, 50564], "temperature": 0.0, "avg_logprob": -0.10471612215042114, "compression_ratio": 1.5783132530120483, "no_speech_prob": 0.008726987056434155}, {"id": 106, "seek": 36000, "start": 364.0, "end": 366.0, "text": " I created a spec directory.", "tokens": [50564, 286, 2942, 257, 1608, 21120, 13, 50664], "temperature": 0.0, "avg_logprob": -0.10471612215042114, "compression_ratio": 1.5783132530120483, "no_speech_prob": 0.008726987056434155}, {"id": 107, "seek": 36000, "start": 366.0, "end": 371.0, "text": " I created a spec file explaining what I knew about it.", "tokens": [50664, 286, 2942, 257, 1608, 3991, 13468, 437, 286, 2586, 466, 309, 13, 50914], "temperature": 0.0, "avg_logprob": -0.10471612215042114, "compression_ratio": 1.5783132530120483, "no_speech_prob": 0.008726987056434155}, {"id": 108, "seek": 36000, "start": 371.0, "end": 381.0, "text": " And I was happier because test is the file that depicts my best understanding of what", "tokens": [50914, 400, 286, 390, 20423, 570, 1500, 307, 264, 3991, 300, 48949, 452, 1151, 3701, 295, 437, 51414], "temperature": 0.0, "avg_logprob": -0.10471612215042114, "compression_ratio": 1.5783132530120483, "no_speech_prob": 0.008726987056434155}, {"id": 109, "seek": 36000, "start": 381.0, "end": 385.0, "text": " I currently believe is the success.", "tokens": [51414, 286, 4362, 1697, 307, 264, 2245, 13, 51614], "temperature": 0.0, "avg_logprob": -0.10471612215042114, "compression_ratio": 1.5783132530120483, "no_speech_prob": 0.008726987056434155}, {"id": 110, "seek": 38500, "start": 386.0, "end": 391.0, "text": " And I need that because I'm going to write code right after the word.", "tokens": [50414, 400, 286, 643, 300, 570, 286, 478, 516, 281, 2464, 3089, 558, 934, 264, 1349, 13, 50664], "temperature": 0.0, "avg_logprob": -0.0995178415317728, "compression_ratio": 1.6712328767123288, "no_speech_prob": 0.2521510720252991}, {"id": 111, "seek": 38500, "start": 391.0, "end": 395.0, "text": " And once you're deep in the code, you're super focused.", "tokens": [50664, 400, 1564, 291, 434, 2452, 294, 264, 3089, 11, 291, 434, 1687, 5178, 13, 50864], "temperature": 0.0, "avg_logprob": -0.0995178415317728, "compression_ratio": 1.6712328767123288, "no_speech_prob": 0.2521510720252991}, {"id": 112, "seek": 38500, "start": 395.0, "end": 397.0, "text": " You forget about landscape.", "tokens": [50864, 509, 2870, 466, 9661, 13, 50964], "temperature": 0.0, "avg_logprob": -0.0995178415317728, "compression_ratio": 1.6712328767123288, "no_speech_prob": 0.2521510720252991}, {"id": 113, "seek": 38500, "start": 397.0, "end": 400.0, "text": " You don't know what comes next.", "tokens": [50964, 509, 500, 380, 458, 437, 1487, 958, 13, 51114], "temperature": 0.0, "avg_logprob": -0.0995178415317728, "compression_ratio": 1.6712328767123288, "no_speech_prob": 0.2521510720252991}, {"id": 114, "seek": 38500, "start": 400.0, "end": 401.0, "text": " You might have a story.", "tokens": [51114, 509, 1062, 362, 257, 1657, 13, 51164], "temperature": 0.0, "avg_logprob": -0.0995178415317728, "compression_ratio": 1.6712328767123288, "no_speech_prob": 0.2521510720252991}, {"id": 115, "seek": 38500, "start": 401.0, "end": 404.0, "text": " You might have specification requirements.", "tokens": [51164, 509, 1062, 362, 31256, 7728, 13, 51314], "temperature": 0.0, "avg_logprob": -0.0995178415317728, "compression_ratio": 1.6712328767123288, "no_speech_prob": 0.2521510720252991}, {"id": 116, "seek": 38500, "start": 404.0, "end": 406.0, "text": " You name it.", "tokens": [51314, 509, 1315, 309, 13, 51414], "temperature": 0.0, "avg_logprob": -0.0995178415317728, "compression_ratio": 1.6712328767123288, "no_speech_prob": 0.2521510720252991}, {"id": 117, "seek": 38500, "start": 406.0, "end": 412.0, "text": " But I do believe that a story or specification is like coordinates of where you're supposed", "tokens": [51414, 583, 286, 360, 1697, 300, 257, 1657, 420, 31256, 307, 411, 21056, 295, 689, 291, 434, 3442, 51714], "temperature": 0.0, "avg_logprob": -0.0995178415317728, "compression_ratio": 1.6712328767123288, "no_speech_prob": 0.2521510720252991}, {"id": 118, "seek": 38500, "start": 412.0, "end": 414.0, "text": " to land.", "tokens": [51714, 281, 2117, 13, 51814], "temperature": 0.0, "avg_logprob": -0.0995178415317728, "compression_ratio": 1.6712328767123288, "no_speech_prob": 0.2521510720252991}, {"id": 119, "seek": 41400, "start": 414.0, "end": 425.0, "text": " The whole puzzle, the whole activity of development, of programming, is like playing golf in the", "tokens": [50364, 440, 1379, 12805, 11, 264, 1379, 5191, 295, 3250, 11, 295, 9410, 11, 307, 411, 2433, 12880, 294, 264, 50914], "temperature": 0.0, "avg_logprob": -0.12109634663799021, "compression_ratio": 1.6899563318777293, "no_speech_prob": 0.009428409859538078}, {"id": 120, "seek": 41400, "start": 425.0, "end": 427.0, "text": " fog by night.", "tokens": [50914, 13648, 538, 1818, 13, 51014], "temperature": 0.0, "avg_logprob": -0.12109634663799021, "compression_ratio": 1.6899563318777293, "no_speech_prob": 0.009428409859538078}, {"id": 121, "seek": 41400, "start": 427.0, "end": 429.0, "text": " You know where you are at the beginning.", "tokens": [51014, 509, 458, 689, 291, 366, 412, 264, 2863, 13, 51114], "temperature": 0.0, "avg_logprob": -0.12109634663799021, "compression_ratio": 1.6899563318777293, "no_speech_prob": 0.009428409859538078}, {"id": 122, "seek": 41400, "start": 429.0, "end": 432.0, "text": " You sort of know when you want to land.", "tokens": [51114, 509, 1333, 295, 458, 562, 291, 528, 281, 2117, 13, 51264], "temperature": 0.0, "avg_logprob": -0.12109634663799021, "compression_ratio": 1.6899563318777293, "no_speech_prob": 0.009428409859538078}, {"id": 123, "seek": 41400, "start": 432.0, "end": 436.0, "text": " But after your first shot, you're going to be lost.", "tokens": [51264, 583, 934, 428, 700, 3347, 11, 291, 434, 516, 281, 312, 2731, 13, 51464], "temperature": 0.0, "avg_logprob": -0.12109634663799021, "compression_ratio": 1.6899563318777293, "no_speech_prob": 0.009428409859538078}, {"id": 124, "seek": 41400, "start": 436.0, "end": 441.0, "text": " It doesn't matter even anymore what you're supposed to land because you've given your first", "tokens": [51464, 467, 1177, 380, 1871, 754, 3602, 437, 291, 434, 3442, 281, 2117, 570, 291, 600, 2212, 428, 700, 51714], "temperature": 0.0, "avg_logprob": -0.12109634663799021, "compression_ratio": 1.6899563318777293, "no_speech_prob": 0.009428409859538078}, {"id": 125, "seek": 41400, "start": 441.0, "end": 443.0, "text": " shot and you don't even know where you are anymore.", "tokens": [51714, 3347, 293, 291, 500, 380, 754, 458, 689, 291, 366, 3602, 13, 51814], "temperature": 0.0, "avg_logprob": -0.12109634663799021, "compression_ratio": 1.6899563318777293, "no_speech_prob": 0.009428409859538078}, {"id": 126, "seek": 44300, "start": 443.0, "end": 446.0, "text": " I'm using tests as torches in the night.", "tokens": [50364, 286, 478, 1228, 6921, 382, 3930, 3781, 294, 264, 1818, 13, 50514], "temperature": 0.0, "avg_logprob": -0.07475660668044794, "compression_ratio": 1.7964601769911503, "no_speech_prob": 0.004413507413119078}, {"id": 127, "seek": 44300, "start": 446.0, "end": 448.0, "text": " So I read my specs.", "tokens": [50514, 407, 286, 1401, 452, 27911, 13, 50614], "temperature": 0.0, "avg_logprob": -0.07475660668044794, "compression_ratio": 1.7964601769911503, "no_speech_prob": 0.004413507413119078}, {"id": 128, "seek": 44300, "start": 448.0, "end": 449.0, "text": " I write some tests.", "tokens": [50614, 286, 2464, 512, 6921, 13, 50664], "temperature": 0.0, "avg_logprob": -0.07475660668044794, "compression_ratio": 1.7964601769911503, "no_speech_prob": 0.004413507413119078}, {"id": 129, "seek": 44300, "start": 449.0, "end": 450.0, "text": " This is my belief.", "tokens": [50664, 639, 307, 452, 7107, 13, 50714], "temperature": 0.0, "avg_logprob": -0.07475660668044794, "compression_ratio": 1.7964601769911503, "no_speech_prob": 0.004413507413119078}, {"id": 130, "seek": 44300, "start": 450.0, "end": 452.0, "text": " I'm going to follow that path.", "tokens": [50714, 286, 478, 516, 281, 1524, 300, 3100, 13, 50814], "temperature": 0.0, "avg_logprob": -0.07475660668044794, "compression_ratio": 1.7964601769911503, "no_speech_prob": 0.004413507413119078}, {"id": 131, "seek": 44300, "start": 452.0, "end": 455.0, "text": " And then I shoot my first shot.", "tokens": [50814, 400, 550, 286, 3076, 452, 700, 3347, 13, 50964], "temperature": 0.0, "avg_logprob": -0.07475660668044794, "compression_ratio": 1.7964601769911503, "no_speech_prob": 0.004413507413119078}, {"id": 132, "seek": 44300, "start": 455.0, "end": 458.0, "text": " Hopefully I'm going to reach my first torch in the night.", "tokens": [50964, 10429, 286, 478, 516, 281, 2524, 452, 700, 27822, 294, 264, 1818, 13, 51114], "temperature": 0.0, "avg_logprob": -0.07475660668044794, "compression_ratio": 1.7964601769911503, "no_speech_prob": 0.004413507413119078}, {"id": 133, "seek": 44300, "start": 458.0, "end": 463.0, "text": " When I have reached that one, I'm going to go to my second torch again and again.", "tokens": [51114, 1133, 286, 362, 6488, 300, 472, 11, 286, 478, 516, 281, 352, 281, 452, 1150, 27822, 797, 293, 797, 13, 51364], "temperature": 0.0, "avg_logprob": -0.07475660668044794, "compression_ratio": 1.7964601769911503, "no_speech_prob": 0.004413507413119078}, {"id": 134, "seek": 44300, "start": 463.0, "end": 469.0, "text": " But my loop is that my test is only my best understanding of my success.", "tokens": [51364, 583, 452, 6367, 307, 300, 452, 1500, 307, 787, 452, 1151, 3701, 295, 452, 2245, 13, 51664], "temperature": 0.0, "avg_logprob": -0.07475660668044794, "compression_ratio": 1.7964601769911503, "no_speech_prob": 0.004413507413119078}, {"id": 135, "seek": 44300, "start": 469.0, "end": 470.0, "text": " So my test is going to evolve.", "tokens": [51664, 407, 452, 1500, 307, 516, 281, 16693, 13, 51714], "temperature": 0.0, "avg_logprob": -0.07475660668044794, "compression_ratio": 1.7964601769911503, "no_speech_prob": 0.004413507413119078}, {"id": 136, "seek": 47000, "start": 470.0, "end": 473.0, "text": " I'm going to move my torches and I'm going to move my ball.", "tokens": [50364, 286, 478, 516, 281, 1286, 452, 3930, 3781, 293, 286, 478, 516, 281, 1286, 452, 2594, 13, 50514], "temperature": 0.0, "avg_logprob": -0.1159694084754357, "compression_ratio": 1.7637130801687764, "no_speech_prob": 0.0033149232622236013}, {"id": 137, "seek": 47000, "start": 473.0, "end": 476.0, "text": " And this is how they make sense together.", "tokens": [50514, 400, 341, 307, 577, 436, 652, 2020, 1214, 13, 50664], "temperature": 0.0, "avg_logprob": -0.1159694084754357, "compression_ratio": 1.7637130801687764, "no_speech_prob": 0.0033149232622236013}, {"id": 138, "seek": 47000, "start": 476.0, "end": 477.0, "text": " Back to the story.", "tokens": [50664, 5833, 281, 264, 1657, 13, 50714], "temperature": 0.0, "avg_logprob": -0.1159694084754357, "compression_ratio": 1.7637130801687764, "no_speech_prob": 0.0033149232622236013}, {"id": 139, "seek": 47000, "start": 477.0, "end": 483.0, "text": " I wrote my test, was happy with my understanding, run it, and it failed.", "tokens": [50714, 286, 4114, 452, 1500, 11, 390, 2055, 365, 452, 3701, 11, 1190, 309, 11, 293, 309, 7612, 13, 51014], "temperature": 0.0, "avg_logprob": -0.1159694084754357, "compression_ratio": 1.7637130801687764, "no_speech_prob": 0.0033149232622236013}, {"id": 140, "seek": 47000, "start": 483.0, "end": 485.0, "text": " It was a catastrophe.", "tokens": [51014, 467, 390, 257, 36043, 13, 51114], "temperature": 0.0, "avg_logprob": -0.1159694084754357, "compression_ratio": 1.7637130801687764, "no_speech_prob": 0.0033149232622236013}, {"id": 141, "seek": 47000, "start": 485.0, "end": 487.0, "text": " And why did it fail?", "tokens": [51114, 400, 983, 630, 309, 3061, 30, 51214], "temperature": 0.0, "avg_logprob": -0.1159694084754357, "compression_ratio": 1.7637130801687764, "no_speech_prob": 0.0033149232622236013}, {"id": 142, "seek": 47000, "start": 487.0, "end": 490.0, "text": " Well, because it couldn't find our spec.", "tokens": [51214, 1042, 11, 570, 309, 2809, 380, 915, 527, 1608, 13, 51364], "temperature": 0.0, "avg_logprob": -0.1159694084754357, "compression_ratio": 1.7637130801687764, "no_speech_prob": 0.0033149232622236013}, {"id": 143, "seek": 47000, "start": 490.0, "end": 492.0, "text": " Because I didn't bundle it.", "tokens": [51364, 1436, 286, 994, 380, 24438, 309, 13, 51464], "temperature": 0.0, "avg_logprob": -0.1159694084754357, "compression_ratio": 1.7637130801687764, "no_speech_prob": 0.0033149232622236013}, {"id": 144, "seek": 47000, "start": 492.0, "end": 494.0, "text": " Because it couldn't find bundler.", "tokens": [51464, 1436, 309, 2809, 380, 915, 13882, 1918, 13, 51564], "temperature": 0.0, "avg_logprob": -0.1159694084754357, "compression_ratio": 1.7637130801687764, "no_speech_prob": 0.0033149232622236013}, {"id": 145, "seek": 47000, "start": 494.0, "end": 497.0, "text": " Like, that is how empty the whole story was.", "tokens": [51564, 1743, 11, 300, 307, 577, 6707, 264, 1379, 1657, 390, 13, 51714], "temperature": 0.0, "avg_logprob": -0.1159694084754357, "compression_ratio": 1.7637130801687764, "no_speech_prob": 0.0033149232622236013}, {"id": 146, "seek": 47000, "start": 497.0, "end": 499.0, "text": " Like, I didn't even have bundler.", "tokens": [51714, 1743, 11, 286, 994, 380, 754, 362, 13882, 1918, 13, 51814], "temperature": 0.0, "avg_logprob": -0.1159694084754357, "compression_ratio": 1.7637130801687764, "no_speech_prob": 0.0033149232622236013}, {"id": 147, "seek": 49900, "start": 499.0, "end": 501.0, "text": " Okay, so bundling is always easy.", "tokens": [50364, 1033, 11, 370, 13882, 1688, 307, 1009, 1858, 13, 50464], "temperature": 0.0, "avg_logprob": -0.1203495281845776, "compression_ratio": 1.6853932584269662, "no_speech_prob": 0.0031510689295828342}, {"id": 148, "seek": 49900, "start": 501.0, "end": 504.0, "text": " Bringing my dependency, starting my gem file.", "tokens": [50464, 45241, 452, 33621, 11, 2891, 452, 7173, 3991, 13, 50614], "temperature": 0.0, "avg_logprob": -0.1203495281845776, "compression_ratio": 1.6853932584269662, "no_speech_prob": 0.0031510689295828342}, {"id": 149, "seek": 49900, "start": 504.0, "end": 506.0, "text": " I need to run my spec.", "tokens": [50614, 286, 643, 281, 1190, 452, 1608, 13, 50714], "temperature": 0.0, "avg_logprob": -0.1203495281845776, "compression_ratio": 1.6853932584269662, "no_speech_prob": 0.0031510689295828342}, {"id": 150, "seek": 49900, "start": 506.0, "end": 507.0, "text": " Run it again.", "tokens": [50714, 8950, 309, 797, 13, 50764], "temperature": 0.0, "avg_logprob": -0.1203495281845776, "compression_ratio": 1.6853932584269662, "no_speech_prob": 0.0031510689295828342}, {"id": 151, "seek": 49900, "start": 507.0, "end": 508.0, "text": " Well, it still fails.", "tokens": [50764, 1042, 11, 309, 920, 18199, 13, 50814], "temperature": 0.0, "avg_logprob": -0.1203495281845776, "compression_ratio": 1.6853932584269662, "no_speech_prob": 0.0031510689295828342}, {"id": 152, "seek": 49900, "start": 508.0, "end": 509.0, "text": " But for a better reason.", "tokens": [50814, 583, 337, 257, 1101, 1778, 13, 50864], "temperature": 0.0, "avg_logprob": -0.1203495281845776, "compression_ratio": 1.6853932584269662, "no_speech_prob": 0.0031510689295828342}, {"id": 153, "seek": 49900, "start": 509.0, "end": 511.0, "text": " And that's the whole point of TG, right?", "tokens": [50864, 400, 300, 311, 264, 1379, 935, 295, 314, 38, 11, 558, 30, 50964], "temperature": 0.0, "avg_logprob": -0.1203495281845776, "compression_ratio": 1.6853932584269662, "no_speech_prob": 0.0031510689295828342}, {"id": 154, "seek": 49900, "start": 511.0, "end": 515.0, "text": " You have to fail, but for a better reason than the previous failure.", "tokens": [50964, 509, 362, 281, 3061, 11, 457, 337, 257, 1101, 1778, 813, 264, 3894, 7763, 13, 51164], "temperature": 0.0, "avg_logprob": -0.1203495281845776, "compression_ratio": 1.6853932584269662, "no_speech_prob": 0.0031510689295828342}, {"id": 155, "seek": 49900, "start": 515.0, "end": 520.0, "text": " So now it's failing because it doesn't know about what is a queue,", "tokens": [51164, 407, 586, 309, 311, 18223, 570, 309, 1177, 380, 458, 466, 437, 307, 257, 18639, 11, 51414], "temperature": 0.0, "avg_logprob": -0.1203495281845776, "compression_ratio": 1.6853932584269662, "no_speech_prob": 0.0031510689295828342}, {"id": 156, "seek": 49900, "start": 520.0, "end": 524.0, "text": " what is the method we see in the queue, what is a message,", "tokens": [51414, 437, 307, 264, 3170, 321, 536, 294, 264, 18639, 11, 437, 307, 257, 3636, 11, 51614], "temperature": 0.0, "avg_logprob": -0.1203495281845776, "compression_ratio": 1.6853932584269662, "no_speech_prob": 0.0031510689295828342}, {"id": 157, "seek": 49900, "start": 524.0, "end": 527.0, "text": " what is a processor, what does perform even means.", "tokens": [51614, 437, 307, 257, 15321, 11, 437, 775, 2042, 754, 1355, 13, 51764], "temperature": 0.0, "avg_logprob": -0.1203495281845776, "compression_ratio": 1.6853932584269662, "no_speech_prob": 0.0031510689295828342}, {"id": 158, "seek": 52700, "start": 527.0, "end": 529.0, "text": " Well, that makes me happy.", "tokens": [50364, 1042, 11, 300, 1669, 385, 2055, 13, 50464], "temperature": 0.0, "avg_logprob": -0.0906868186048282, "compression_ratio": 1.67, "no_speech_prob": 0.019543271511793137}, {"id": 159, "seek": 52700, "start": 529.0, "end": 536.0, "text": " Because now I can actually write more tests about what do I believe is a queue at this stage.", "tokens": [50464, 1436, 586, 286, 393, 767, 2464, 544, 6921, 466, 437, 360, 286, 1697, 307, 257, 18639, 412, 341, 3233, 13, 50814], "temperature": 0.0, "avg_logprob": -0.0906868186048282, "compression_ratio": 1.67, "no_speech_prob": 0.019543271511793137}, {"id": 160, "seek": 52700, "start": 536.0, "end": 541.0, "text": " Why do I believe is a processor, what do I believe should do the receive method.", "tokens": [50814, 1545, 360, 286, 1697, 307, 257, 15321, 11, 437, 360, 286, 1697, 820, 360, 264, 4774, 3170, 13, 51064], "temperature": 0.0, "avg_logprob": -0.0906868186048282, "compression_ratio": 1.67, "no_speech_prob": 0.019543271511793137}, {"id": 161, "seek": 52700, "start": 541.0, "end": 548.0, "text": " And this was really the starting of both my loops.", "tokens": [51064, 400, 341, 390, 534, 264, 2891, 295, 1293, 452, 16121, 13, 51414], "temperature": 0.0, "avg_logprob": -0.0906868186048282, "compression_ratio": 1.67, "no_speech_prob": 0.019543271511793137}, {"id": 162, "seek": 52700, "start": 548.0, "end": 552.0, "text": " I got my main loop back, but I got my working loop as well.", "tokens": [51414, 286, 658, 452, 2135, 6367, 646, 11, 457, 286, 658, 452, 1364, 6367, 382, 731, 13, 51614], "temperature": 0.0, "avg_logprob": -0.0906868186048282, "compression_ratio": 1.67, "no_speech_prob": 0.019543271511793137}, {"id": 163, "seek": 52700, "start": 552.0, "end": 553.0, "text": " I got a lot of tests.", "tokens": [51614, 286, 658, 257, 688, 295, 6921, 13, 51664], "temperature": 0.0, "avg_logprob": -0.0906868186048282, "compression_ratio": 1.67, "no_speech_prob": 0.019543271511793137}, {"id": 164, "seek": 55300, "start": 553.0, "end": 557.0, "text": " I knew that trying to make them go green would just generate more tests.", "tokens": [50364, 286, 2586, 300, 1382, 281, 652, 552, 352, 3092, 576, 445, 8460, 544, 6921, 13, 50564], "temperature": 0.0, "avg_logprob": -0.12699619928995767, "compression_ratio": 1.6766169154228856, "no_speech_prob": 0.012956206686794758}, {"id": 165, "seek": 55300, "start": 557.0, "end": 558.0, "text": " Trying to make them go green.", "tokens": [50564, 20180, 281, 652, 552, 352, 3092, 13, 50614], "temperature": 0.0, "avg_logprob": -0.12699619928995767, "compression_ratio": 1.6766169154228856, "no_speech_prob": 0.012956206686794758}, {"id": 166, "seek": 55300, "start": 558.0, "end": 562.0, "text": " I got my actual work loop.", "tokens": [50614, 286, 658, 452, 3539, 589, 6367, 13, 50814], "temperature": 0.0, "avg_logprob": -0.12699619928995767, "compression_ratio": 1.6766169154228856, "no_speech_prob": 0.012956206686794758}, {"id": 167, "seek": 55300, "start": 562.0, "end": 564.0, "text": " Right.", "tokens": [50814, 1779, 13, 50914], "temperature": 0.0, "avg_logprob": -0.12699619928995767, "compression_ratio": 1.6766169154228856, "no_speech_prob": 0.012956206686794758}, {"id": 168, "seek": 55300, "start": 564.0, "end": 568.0, "text": " So, test code, test code, test code.", "tokens": [50914, 407, 11, 1500, 3089, 11, 1500, 3089, 11, 1500, 3089, 13, 51114], "temperature": 0.0, "avg_logprob": -0.12699619928995767, "compression_ratio": 1.6766169154228856, "no_speech_prob": 0.012956206686794758}, {"id": 169, "seek": 55300, "start": 568.0, "end": 569.0, "text": " I was in the middle of it.", "tokens": [51114, 286, 390, 294, 264, 2808, 295, 309, 13, 51164], "temperature": 0.0, "avg_logprob": -0.12699619928995767, "compression_ratio": 1.6766169154228856, "no_speech_prob": 0.012956206686794758}, {"id": 170, "seek": 55300, "start": 569.0, "end": 577.0, "text": " And every single of the code file was starting with like probably five to ten require or require relative.", "tokens": [51164, 400, 633, 2167, 295, 264, 3089, 3991, 390, 2891, 365, 411, 1391, 1732, 281, 2064, 3651, 420, 3651, 4972, 13, 51564], "temperature": 0.0, "avg_logprob": -0.12699619928995767, "compression_ratio": 1.6766169154228856, "no_speech_prob": 0.012956206686794758}, {"id": 171, "seek": 55300, "start": 577.0, "end": 580.0, "text": " And I wasn't happy with that.", "tokens": [51564, 400, 286, 2067, 380, 2055, 365, 300, 13, 51714], "temperature": 0.0, "avg_logprob": -0.12699619928995767, "compression_ratio": 1.6766169154228856, "no_speech_prob": 0.012956206686794758}, {"id": 172, "seek": 58000, "start": 581.0, "end": 584.0, "text": " First of all, because it is boilerplate, it's noise.", "tokens": [50414, 2386, 295, 439, 11, 570, 309, 307, 39228, 37008, 11, 309, 311, 5658, 13, 50564], "temperature": 0.0, "avg_logprob": -0.0991129970550537, "compression_ratio": 1.706896551724138, "no_speech_prob": 0.016042005270719528}, {"id": 173, "seek": 58000, "start": 584.0, "end": 585.0, "text": " I don't like noise.", "tokens": [50564, 286, 500, 380, 411, 5658, 13, 50614], "temperature": 0.0, "avg_logprob": -0.0991129970550537, "compression_ratio": 1.706896551724138, "no_speech_prob": 0.016042005270719528}, {"id": 174, "seek": 58000, "start": 585.0, "end": 591.0, "text": " Also, because I want my code files to be about the responsibility they're supposed to hold.", "tokens": [50614, 2743, 11, 570, 286, 528, 452, 3089, 7098, 281, 312, 466, 264, 6357, 436, 434, 3442, 281, 1797, 13, 50914], "temperature": 0.0, "avg_logprob": -0.0991129970550537, "compression_ratio": 1.706896551724138, "no_speech_prob": 0.016042005270719528}, {"id": 175, "seek": 58000, "start": 591.0, "end": 599.0, "text": " And knowing what files contains the dependency that this file depends upon,", "tokens": [50914, 400, 5276, 437, 7098, 8306, 264, 33621, 300, 341, 3991, 5946, 3564, 11, 51314], "temperature": 0.0, "avg_logprob": -0.0991129970550537, "compression_ratio": 1.706896551724138, "no_speech_prob": 0.016042005270719528}, {"id": 176, "seek": 58000, "start": 599.0, "end": 604.0, "text": " it's not the responsibility of each file to know where do I store the other responsibilities.", "tokens": [51314, 309, 311, 406, 264, 6357, 295, 1184, 3991, 281, 458, 689, 360, 286, 3531, 264, 661, 16190, 13, 51564], "temperature": 0.0, "avg_logprob": -0.0991129970550537, "compression_ratio": 1.706896551724138, "no_speech_prob": 0.016042005270719528}, {"id": 177, "seek": 58000, "start": 604.0, "end": 605.0, "text": " That was wrong.", "tokens": [51564, 663, 390, 2085, 13, 51614], "temperature": 0.0, "avg_logprob": -0.0991129970550537, "compression_ratio": 1.706896551724138, "no_speech_prob": 0.016042005270719528}, {"id": 178, "seek": 58000, "start": 605.0, "end": 607.0, "text": " And this is not something we have with Rails.", "tokens": [51614, 400, 341, 307, 406, 746, 321, 362, 365, 48526, 13, 51714], "temperature": 0.0, "avg_logprob": -0.0991129970550537, "compression_ratio": 1.706896551724138, "no_speech_prob": 0.016042005270719528}, {"id": 179, "seek": 60700, "start": 607.0, "end": 615.0, "text": " I realized that we actually get something super nice from Rails is put any file in any sub directory of app folder,", "tokens": [50364, 286, 5334, 300, 321, 767, 483, 746, 1687, 1481, 490, 48526, 307, 829, 604, 3991, 294, 604, 1422, 21120, 295, 724, 10820, 11, 50764], "temperature": 0.0, "avg_logprob": -0.16335148854298634, "compression_ratio": 1.5137254901960784, "no_speech_prob": 0.01546478271484375}, {"id": 180, "seek": 60700, "start": 615.0, "end": 616.0, "text": " and you get it.", "tokens": [50764, 293, 291, 483, 309, 13, 50814], "temperature": 0.0, "avg_logprob": -0.16335148854298634, "compression_ratio": 1.5137254901960784, "no_speech_prob": 0.01546478271484375}, {"id": 181, "seek": 60700, "start": 616.0, "end": 617.0, "text": " It's like magic.", "tokens": [50814, 467, 311, 411, 5585, 13, 50864], "temperature": 0.0, "avg_logprob": -0.16335148854298634, "compression_ratio": 1.5137254901960784, "no_speech_prob": 0.01546478271484375}, {"id": 182, "seek": 60700, "start": 617.0, "end": 624.0, "text": " Once you have to start all your require by hand, it felt wrong.", "tokens": [50864, 3443, 291, 362, 281, 722, 439, 428, 3651, 538, 1011, 11, 309, 2762, 2085, 13, 51214], "temperature": 0.0, "avg_logprob": -0.16335148854298634, "compression_ratio": 1.5137254901960784, "no_speech_prob": 0.01546478271484375}, {"id": 183, "seek": 60700, "start": 624.0, "end": 625.0, "text": " So, I Googled.", "tokens": [51214, 407, 11, 286, 45005, 1493, 13, 51264], "temperature": 0.0, "avg_logprob": -0.16335148854298634, "compression_ratio": 1.5137254901960784, "no_speech_prob": 0.01546478271484375}, {"id": 184, "seek": 60700, "start": 625.0, "end": 627.0, "text": " I got a few options.", "tokens": [51264, 286, 658, 257, 1326, 3956, 13, 51364], "temperature": 0.0, "avg_logprob": -0.16335148854298634, "compression_ratio": 1.5137254901960784, "no_speech_prob": 0.01546478271484375}, {"id": 185, "seek": 60700, "start": 627.0, "end": 633.0, "text": " And the best one, which is actually the one which is currently adopted by Rails, was using SideFerq.", "tokens": [51364, 400, 264, 1151, 472, 11, 597, 307, 767, 264, 472, 597, 307, 4362, 12175, 538, 48526, 11, 390, 1228, 19026, 37, 260, 80, 13, 51664], "temperature": 0.0, "avg_logprob": -0.16335148854298634, "compression_ratio": 1.5137254901960784, "no_speech_prob": 0.01546478271484375}, {"id": 186, "seek": 60700, "start": 633.0, "end": 635.0, "text": " Hopefully, I'm pronouncing it right.", "tokens": [51664, 10429, 11, 286, 478, 14144, 2175, 309, 558, 13, 51764], "temperature": 0.0, "avg_logprob": -0.16335148854298634, "compression_ratio": 1.5137254901960784, "no_speech_prob": 0.01546478271484375}, {"id": 187, "seek": 63500, "start": 635.0, "end": 637.0, "text": " It's written in my speaker mode.", "tokens": [50364, 467, 311, 3720, 294, 452, 8145, 4391, 13, 50464], "temperature": 0.0, "avg_logprob": -0.11655356030945384, "compression_ratio": 1.5942622950819672, "no_speech_prob": 0.013139164075255394}, {"id": 188, "seek": 63500, "start": 637.0, "end": 648.0, "text": " And that stuff helped me, like, auto load the constants I was looking for by looking them up in my lib directory.", "tokens": [50464, 400, 300, 1507, 4254, 385, 11, 411, 11, 8399, 3677, 264, 35870, 286, 390, 1237, 337, 538, 1237, 552, 493, 294, 452, 22854, 21120, 13, 51014], "temperature": 0.0, "avg_logprob": -0.11655356030945384, "compression_ratio": 1.5942622950819672, "no_speech_prob": 0.013139164075255394}, {"id": 189, "seek": 63500, "start": 648.0, "end": 649.0, "text": " Default config.", "tokens": [51014, 9548, 5107, 6662, 13, 51064], "temperature": 0.0, "avg_logprob": -0.11655356030945384, "compression_ratio": 1.5942622950819672, "no_speech_prob": 0.013139164075255394}, {"id": 190, "seek": 63500, "start": 649.0, "end": 652.0, "text": " I'm happy as far as I know this is what I need.", "tokens": [51064, 286, 478, 2055, 382, 1400, 382, 286, 458, 341, 307, 437, 286, 643, 13, 51214], "temperature": 0.0, "avg_logprob": -0.11655356030945384, "compression_ratio": 1.5942622950819672, "no_speech_prob": 0.013139164075255394}, {"id": 191, "seek": 63500, "start": 652.0, "end": 660.0, "text": " But reading the rest of SideFerq, I also realized that this enables you to use short names.", "tokens": [51214, 583, 3760, 264, 1472, 295, 19026, 37, 260, 80, 11, 286, 611, 5334, 300, 341, 17077, 291, 281, 764, 2099, 5288, 13, 51614], "temperature": 0.0, "avg_logprob": -0.11655356030945384, "compression_ratio": 1.5942622950819672, "no_speech_prob": 0.013139164075255394}, {"id": 192, "seek": 63500, "start": 660.0, "end": 664.0, "text": " So, if you are in the same namespace, you can just mention a constant by a short name.", "tokens": [51614, 407, 11, 498, 291, 366, 294, 264, 912, 5288, 17940, 11, 291, 393, 445, 2152, 257, 5754, 538, 257, 2099, 1315, 13, 51814], "temperature": 0.0, "avg_logprob": -0.11655356030945384, "compression_ratio": 1.5942622950819672, "no_speech_prob": 0.013139164075255394}, {"id": 193, "seek": 66400, "start": 664.0, "end": 665.0, "text": " Well, obviously, I want that.", "tokens": [50364, 1042, 11, 2745, 11, 286, 528, 300, 13, 50414], "temperature": 0.0, "avg_logprob": -0.08373456682477678, "compression_ratio": 1.8550185873605949, "no_speech_prob": 0.0784994438290596}, {"id": 194, "seek": 66400, "start": 665.0, "end": 667.0, "text": " I'm doing that in Rails, so I want that again.", "tokens": [50414, 286, 478, 884, 300, 294, 48526, 11, 370, 286, 528, 300, 797, 13, 50514], "temperature": 0.0, "avg_logprob": -0.08373456682477678, "compression_ratio": 1.8550185873605949, "no_speech_prob": 0.0784994438290596}, {"id": 195, "seek": 66400, "start": 667.0, "end": 672.0, "text": " It's also handling multithread code loading.", "tokens": [50514, 467, 311, 611, 13175, 2120, 355, 2538, 3089, 15114, 13, 50764], "temperature": 0.0, "avg_logprob": -0.08373456682477678, "compression_ratio": 1.8550185873605949, "no_speech_prob": 0.0784994438290596}, {"id": 196, "seek": 66400, "start": 672.0, "end": 676.0, "text": " I have no idea if I'm going to need that, but I certainly don't want to handle that myself.", "tokens": [50764, 286, 362, 572, 1558, 498, 286, 478, 516, 281, 643, 300, 11, 457, 286, 3297, 500, 380, 528, 281, 4813, 300, 2059, 13, 50964], "temperature": 0.0, "avg_logprob": -0.08373456682477678, "compression_ratio": 1.8550185873605949, "no_speech_prob": 0.0784994438290596}, {"id": 197, "seek": 66400, "start": 676.0, "end": 680.0, "text": " It sounds like something I really don't want to handle myself.", "tokens": [50964, 467, 3263, 411, 746, 286, 534, 500, 380, 528, 281, 4813, 2059, 13, 51164], "temperature": 0.0, "avg_logprob": -0.08373456682477678, "compression_ratio": 1.8550185873605949, "no_speech_prob": 0.0784994438290596}, {"id": 198, "seek": 66400, "start": 680.0, "end": 684.0, "text": " And it also handle code reloading, which is not something I'm going to use because of TDD.", "tokens": [51164, 400, 309, 611, 4813, 3089, 25628, 278, 11, 597, 307, 406, 746, 286, 478, 516, 281, 764, 570, 295, 314, 20818, 13, 51364], "temperature": 0.0, "avg_logprob": -0.08373456682477678, "compression_ratio": 1.8550185873605949, "no_speech_prob": 0.0784994438290596}, {"id": 199, "seek": 66400, "start": 684.0, "end": 686.0, "text": " But again, this is my approach.", "tokens": [51364, 583, 797, 11, 341, 307, 452, 3109, 13, 51464], "temperature": 0.0, "avg_logprob": -0.08373456682477678, "compression_ratio": 1.8550185873605949, "no_speech_prob": 0.0784994438290596}, {"id": 200, "seek": 66400, "start": 686.0, "end": 689.0, "text": " I know that most people don't do that.", "tokens": [51464, 286, 458, 300, 881, 561, 500, 380, 360, 300, 13, 51614], "temperature": 0.0, "avg_logprob": -0.08373456682477678, "compression_ratio": 1.8550185873605949, "no_speech_prob": 0.0784994438290596}, {"id": 201, "seek": 66400, "start": 689.0, "end": 693.0, "text": " And code reloading is a very important part of code loading.", "tokens": [51614, 400, 3089, 25628, 278, 307, 257, 588, 1021, 644, 295, 3089, 15114, 13, 51814], "temperature": 0.0, "avg_logprob": -0.08373456682477678, "compression_ratio": 1.8550185873605949, "no_speech_prob": 0.0784994438290596}, {"id": 202, "seek": 69300, "start": 693.0, "end": 703.0, "text": " So, SideFerq was like my first take, my first really great companion that I found along the way.", "tokens": [50364, 407, 11, 19026, 37, 260, 80, 390, 411, 452, 700, 747, 11, 452, 700, 534, 869, 22363, 300, 286, 1352, 2051, 264, 636, 13, 50864], "temperature": 0.0, "avg_logprob": -0.09299557025615986, "compression_ratio": 1.5958333333333334, "no_speech_prob": 0.003787610912695527}, {"id": 203, "seek": 69300, "start": 703.0, "end": 706.0, "text": " The second one was dry container.", "tokens": [50864, 440, 1150, 472, 390, 4016, 10129, 13, 51014], "temperature": 0.0, "avg_logprob": -0.09299557025615986, "compression_ratio": 1.5958333333333334, "no_speech_prob": 0.003787610912695527}, {"id": 204, "seek": 69300, "start": 706.0, "end": 711.0, "text": " Now, small disclaimer, I knew from the stuff that I was going to use dry gems because I wanted to.", "tokens": [51014, 823, 11, 1359, 40896, 11, 286, 2586, 490, 264, 1507, 300, 286, 390, 516, 281, 764, 4016, 29296, 570, 286, 1415, 281, 13, 51264], "temperature": 0.0, "avg_logprob": -0.09299557025615986, "compression_ratio": 1.5958333333333334, "no_speech_prob": 0.003787610912695527}, {"id": 205, "seek": 69300, "start": 711.0, "end": 716.0, "text": " And as Kevin said, it's also a little bit about finding joy.", "tokens": [51264, 400, 382, 9954, 848, 11, 309, 311, 611, 257, 707, 857, 466, 5006, 6258, 13, 51514], "temperature": 0.0, "avg_logprob": -0.09299557025615986, "compression_ratio": 1.5958333333333334, "no_speech_prob": 0.003787610912695527}, {"id": 206, "seek": 69300, "start": 716.0, "end": 722.0, "text": " So, I wanted to heavily rely on dry gems, but I wanted to wait until the use case was there.", "tokens": [51514, 407, 11, 286, 1415, 281, 10950, 10687, 322, 4016, 29296, 11, 457, 286, 1415, 281, 1699, 1826, 264, 764, 1389, 390, 456, 13, 51814], "temperature": 0.0, "avg_logprob": -0.09299557025615986, "compression_ratio": 1.5958333333333334, "no_speech_prob": 0.003787610912695527}, {"id": 207, "seek": 72200, "start": 722.0, "end": 731.0, "text": " I wanted, because I did not only want to skip the requires, I wanted to not know the classes.", "tokens": [50364, 286, 1415, 11, 570, 286, 630, 406, 787, 528, 281, 10023, 264, 7029, 11, 286, 1415, 281, 406, 458, 264, 5359, 13, 50814], "temperature": 0.0, "avg_logprob": -0.11754222143264044, "compression_ratio": 1.8732394366197183, "no_speech_prob": 0.023417189717292786}, {"id": 208, "seek": 72200, "start": 731.0, "end": 734.0, "text": " I wanted to not call new in the middle of my code.", "tokens": [50814, 286, 1415, 281, 406, 818, 777, 294, 264, 2808, 295, 452, 3089, 13, 50964], "temperature": 0.0, "avg_logprob": -0.11754222143264044, "compression_ratio": 1.8732394366197183, "no_speech_prob": 0.023417189717292786}, {"id": 209, "seek": 72200, "start": 734.0, "end": 736.0, "text": " My code is about business logic.", "tokens": [50964, 1222, 3089, 307, 466, 1606, 9952, 13, 51064], "temperature": 0.0, "avg_logprob": -0.11754222143264044, "compression_ratio": 1.8732394366197183, "no_speech_prob": 0.023417189717292786}, {"id": 210, "seek": 72200, "start": 736.0, "end": 738.0, "text": " Most of the code is about business logic.", "tokens": [51064, 4534, 295, 264, 3089, 307, 466, 1606, 9952, 13, 51164], "temperature": 0.0, "avg_logprob": -0.11754222143264044, "compression_ratio": 1.8732394366197183, "no_speech_prob": 0.023417189717292786}, {"id": 211, "seek": 72200, "start": 738.0, "end": 745.0, "text": " I wanted to separate, sorry, the logic about creating objects and the logic about like, I need something.", "tokens": [51164, 286, 1415, 281, 4994, 11, 2597, 11, 264, 9952, 466, 4084, 6565, 293, 264, 9952, 466, 411, 11, 286, 643, 746, 13, 51514], "temperature": 0.0, "avg_logprob": -0.11754222143264044, "compression_ratio": 1.8732394366197183, "no_speech_prob": 0.023417189717292786}, {"id": 212, "seek": 72200, "start": 745.0, "end": 749.0, "text": " And most of the time, when you're in a controller, in a Rails controller,", "tokens": [51514, 400, 881, 295, 264, 565, 11, 562, 291, 434, 294, 257, 10561, 11, 294, 257, 48526, 10561, 11, 51714], "temperature": 0.0, "avg_logprob": -0.11754222143264044, "compression_ratio": 1.8732394366197183, "no_speech_prob": 0.023417189717292786}, {"id": 213, "seek": 74900, "start": 749.0, "end": 752.0, "text": " you don't even care like where does the request object comes from.", "tokens": [50364, 291, 500, 380, 754, 1127, 411, 689, 775, 264, 5308, 2657, 1487, 490, 13, 50514], "temperature": 0.0, "avg_logprob": -0.1145265367296007, "compression_ratio": 1.7405857740585775, "no_speech_prob": 0.02510867640376091}, {"id": 214, "seek": 74900, "start": 752.0, "end": 754.0, "text": " You're just like, okay, I want a request object.", "tokens": [50514, 509, 434, 445, 411, 11, 1392, 11, 286, 528, 257, 5308, 2657, 13, 50614], "temperature": 0.0, "avg_logprob": -0.1145265367296007, "compression_ratio": 1.7405857740585775, "no_speech_prob": 0.02510867640376091}, {"id": 215, "seek": 74900, "start": 754.0, "end": 756.0, "text": " Just make it happen.", "tokens": [50614, 1449, 652, 309, 1051, 13, 50714], "temperature": 0.0, "avg_logprob": -0.1145265367296007, "compression_ratio": 1.7405857740585775, "no_speech_prob": 0.02510867640376091}, {"id": 216, "seek": 74900, "start": 756.0, "end": 764.0, "text": " If you're in a view, you don't care about what the view context comes from.", "tokens": [50714, 759, 291, 434, 294, 257, 1910, 11, 291, 500, 380, 1127, 466, 437, 264, 1910, 4319, 1487, 490, 13, 51114], "temperature": 0.0, "avg_logprob": -0.1145265367296007, "compression_ratio": 1.7405857740585775, "no_speech_prob": 0.02510867640376091}, {"id": 217, "seek": 74900, "start": 764.0, "end": 765.0, "text": " You just have it.", "tokens": [51114, 509, 445, 362, 309, 13, 51164], "temperature": 0.0, "avg_logprob": -0.1145265367296007, "compression_ratio": 1.7405857740585775, "no_speech_prob": 0.02510867640376091}, {"id": 218, "seek": 74900, "start": 765.0, "end": 766.0, "text": " You just want it.", "tokens": [51164, 509, 445, 528, 309, 13, 51214], "temperature": 0.0, "avg_logprob": -0.1145265367296007, "compression_ratio": 1.7405857740585775, "no_speech_prob": 0.02510867640376091}, {"id": 219, "seek": 74900, "start": 766.0, "end": 772.0, "text": " And it's really comfortable to write code with just focusing on like using the stuff you need,", "tokens": [51214, 400, 309, 311, 534, 4619, 281, 2464, 3089, 365, 445, 8416, 322, 411, 1228, 264, 1507, 291, 643, 11, 51514], "temperature": 0.0, "avg_logprob": -0.1145265367296007, "compression_ratio": 1.7405857740585775, "no_speech_prob": 0.02510867640376091}, {"id": 220, "seek": 74900, "start": 772.0, "end": 775.0, "text": " not focusing on how you get them.", "tokens": [51514, 406, 8416, 322, 577, 291, 483, 552, 13, 51664], "temperature": 0.0, "avg_logprob": -0.1145265367296007, "compression_ratio": 1.7405857740585775, "no_speech_prob": 0.02510867640376091}, {"id": 221, "seek": 74900, "start": 775.0, "end": 778.0, "text": " So, this is what dry container brings.", "tokens": [51664, 407, 11, 341, 307, 437, 4016, 10129, 5607, 13, 51814], "temperature": 0.0, "avg_logprob": -0.1145265367296007, "compression_ratio": 1.7405857740585775, "no_speech_prob": 0.02510867640376091}, {"id": 222, "seek": 77800, "start": 779.0, "end": 785.0, "text": " I've been using dry system, which is like dry container for handling all of that, and dry injector.", "tokens": [50414, 286, 600, 668, 1228, 4016, 1185, 11, 597, 307, 411, 4016, 10129, 337, 13175, 439, 295, 300, 11, 293, 4016, 10711, 284, 13, 50714], "temperature": 0.0, "avg_logprob": -0.08952019132416823, "compression_ratio": 1.890295358649789, "no_speech_prob": 0.0038017171900719404}, {"id": 223, "seek": 77800, "start": 785.0, "end": 792.0, "text": " And dry injector basically works hand in hand with dry container and allows you to call your services,", "tokens": [50714, 400, 4016, 10711, 284, 1936, 1985, 1011, 294, 1011, 365, 4016, 10129, 293, 4045, 291, 281, 818, 428, 3328, 11, 51064], "temperature": 0.0, "avg_logprob": -0.08952019132416823, "compression_ratio": 1.890295358649789, "no_speech_prob": 0.0038017171900719404}, {"id": 224, "seek": 77800, "start": 792.0, "end": 795.0, "text": " call your dependencies by the small name, by the first name.", "tokens": [51064, 818, 428, 36606, 538, 264, 1359, 1315, 11, 538, 264, 700, 1315, 13, 51214], "temperature": 0.0, "avg_logprob": -0.08952019132416823, "compression_ratio": 1.890295358649789, "no_speech_prob": 0.0038017171900719404}, {"id": 225, "seek": 77800, "start": 795.0, "end": 800.0, "text": " You give a name to an object and then you can basically say, okay, I want this object.", "tokens": [51214, 509, 976, 257, 1315, 281, 364, 2657, 293, 550, 291, 393, 1936, 584, 11, 1392, 11, 286, 528, 341, 2657, 13, 51464], "temperature": 0.0, "avg_logprob": -0.08952019132416823, "compression_ratio": 1.890295358649789, "no_speech_prob": 0.0038017171900719404}, {"id": 226, "seek": 77800, "start": 800.0, "end": 801.0, "text": " I don't want this class.", "tokens": [51464, 286, 500, 380, 528, 341, 1508, 13, 51514], "temperature": 0.0, "avg_logprob": -0.08952019132416823, "compression_ratio": 1.890295358649789, "no_speech_prob": 0.0038017171900719404}, {"id": 227, "seek": 77800, "start": 801.0, "end": 803.0, "text": " I don't want to instantiate that class.", "tokens": [51514, 286, 500, 380, 528, 281, 9836, 13024, 300, 1508, 13, 51614], "temperature": 0.0, "avg_logprob": -0.08952019132416823, "compression_ratio": 1.890295358649789, "no_speech_prob": 0.0038017171900719404}, {"id": 228, "seek": 77800, "start": 803.0, "end": 806.0, "text": " I want specifically that object.", "tokens": [51614, 286, 528, 4682, 300, 2657, 13, 51764], "temperature": 0.0, "avg_logprob": -0.08952019132416823, "compression_ratio": 1.890295358649789, "no_speech_prob": 0.0038017171900719404}, {"id": 229, "seek": 80600, "start": 806.0, "end": 807.0, "text": " And I'm going to use it.", "tokens": [50364, 400, 286, 478, 516, 281, 764, 309, 13, 50414], "temperature": 0.0, "avg_logprob": -0.10138527263294567, "compression_ratio": 1.5685483870967742, "no_speech_prob": 0.004496437497437}, {"id": 230, "seek": 80600, "start": 807.0, "end": 809.0, "text": " And I don't even care what its class is for.", "tokens": [50414, 400, 286, 500, 380, 754, 1127, 437, 1080, 1508, 307, 337, 13, 50514], "temperature": 0.0, "avg_logprob": -0.10138527263294567, "compression_ratio": 1.5685483870967742, "no_speech_prob": 0.004496437497437}, {"id": 231, "seek": 80600, "start": 809.0, "end": 811.0, "text": " I want that object by name.", "tokens": [50514, 286, 528, 300, 2657, 538, 1315, 13, 50614], "temperature": 0.0, "avg_logprob": -0.10138527263294567, "compression_ratio": 1.5685483870967742, "no_speech_prob": 0.004496437497437}, {"id": 232, "seek": 80600, "start": 814.0, "end": 819.0, "text": " Interestingly, this had almost no effect on the test.", "tokens": [50764, 30564, 11, 341, 632, 1920, 572, 1802, 322, 264, 1500, 13, 51014], "temperature": 0.0, "avg_logprob": -0.10138527263294567, "compression_ratio": 1.5685483870967742, "no_speech_prob": 0.004496437497437}, {"id": 233, "seek": 80600, "start": 819.0, "end": 827.0, "text": " Even though it's a very different approach, I still had most of my tests instantiate object by themselves.", "tokens": [51014, 2754, 1673, 309, 311, 257, 588, 819, 3109, 11, 286, 920, 632, 881, 295, 452, 6921, 9836, 13024, 2657, 538, 2969, 13, 51414], "temperature": 0.0, "avg_logprob": -0.10138527263294567, "compression_ratio": 1.5685483870967742, "no_speech_prob": 0.004496437497437}, {"id": 234, "seek": 80600, "start": 827.0, "end": 828.0, "text": " Why?", "tokens": [51414, 1545, 30, 51464], "temperature": 0.0, "avg_logprob": -0.10138527263294567, "compression_ratio": 1.5685483870967742, "no_speech_prob": 0.004496437497437}, {"id": 235, "seek": 80600, "start": 828.0, "end": 831.0, "text": " Because unit tests actually give a lot of fake dependencies.", "tokens": [51464, 1436, 4985, 6921, 767, 976, 257, 688, 295, 7592, 36606, 13, 51614], "temperature": 0.0, "avg_logprob": -0.10138527263294567, "compression_ratio": 1.5685483870967742, "no_speech_prob": 0.004496437497437}, {"id": 236, "seek": 80600, "start": 831.0, "end": 832.0, "text": " That's the point of unit, right?", "tokens": [51614, 663, 311, 264, 935, 295, 4985, 11, 558, 30, 51664], "temperature": 0.0, "avg_logprob": -0.10138527263294567, "compression_ratio": 1.5685483870967742, "no_speech_prob": 0.004496437497437}, {"id": 237, "seek": 80600, "start": 832.0, "end": 835.0, "text": " You want to test a single unit.", "tokens": [51664, 509, 528, 281, 1500, 257, 2167, 4985, 13, 51814], "temperature": 0.0, "avg_logprob": -0.10138527263294567, "compression_ratio": 1.5685483870967742, "no_speech_prob": 0.004496437497437}, {"id": 238, "seek": 83500, "start": 835.0, "end": 839.0, "text": " So I was still building my subject into tests manually.", "tokens": [50364, 407, 286, 390, 920, 2390, 452, 3983, 666, 6921, 16945, 13, 50564], "temperature": 0.0, "avg_logprob": -0.14908557467990452, "compression_ratio": 1.7148760330578512, "no_speech_prob": 0.005057992413640022}, {"id": 239, "seek": 83500, "start": 839.0, "end": 847.0, "text": " And for the larger, the broader tests, I actually wanted to use the container set up correctly", "tokens": [50564, 400, 337, 264, 4833, 11, 264, 13227, 6921, 11, 286, 767, 1415, 281, 764, 264, 10129, 992, 493, 8944, 50964], "temperature": 0.0, "avg_logprob": -0.14908557467990452, "compression_ratio": 1.7148760330578512, "no_speech_prob": 0.005057992413640022}, {"id": 240, "seek": 83500, "start": 847.0, "end": 851.0, "text": " because I wanted to test that things were correctly wired together.", "tokens": [50964, 570, 286, 1415, 281, 1500, 300, 721, 645, 8944, 27415, 1214, 13, 51164], "temperature": 0.0, "avg_logprob": -0.14908557467990452, "compression_ratio": 1.7148760330578512, "no_speech_prob": 0.005057992413640022}, {"id": 241, "seek": 83500, "start": 851.0, "end": 857.0, "text": " So even though dry containers is like, oh, some you can stub and fake and change whatever you want.", "tokens": [51164, 407, 754, 1673, 4016, 17089, 307, 411, 11, 1954, 11, 512, 291, 393, 20266, 293, 7592, 293, 1319, 2035, 291, 528, 13, 51464], "temperature": 0.0, "avg_logprob": -0.14908557467990452, "compression_ratio": 1.7148760330578512, "no_speech_prob": 0.005057992413640022}, {"id": 242, "seek": 83500, "start": 857.0, "end": 864.0, "text": " I didn't stub it because I was either using it and testing it or not using it at all in my test.", "tokens": [51464, 286, 994, 380, 20266, 309, 570, 286, 390, 2139, 1228, 309, 293, 4997, 309, 420, 406, 1228, 309, 412, 439, 294, 452, 1500, 13, 51814], "temperature": 0.0, "avg_logprob": -0.14908557467990452, "compression_ratio": 1.7148760330578512, "no_speech_prob": 0.005057992413640022}, {"id": 243, "seek": 86500, "start": 865.0, "end": 868.0, "text": " And...", "tokens": [50364, 400, 485, 50514], "temperature": 0.0, "avg_logprob": -0.2609968730381557, "compression_ratio": 1.5153374233128833, "no_speech_prob": 0.0038271367084234953}, {"id": 244, "seek": 86500, "start": 868.0, "end": 869.0, "text": " Sorry.", "tokens": [50514, 4919, 13, 50564], "temperature": 0.0, "avg_logprob": -0.2609968730381557, "compression_ratio": 1.5153374233128833, "no_speech_prob": 0.0038271367084234953}, {"id": 245, "seek": 86500, "start": 869.0, "end": 870.0, "text": " Yep.", "tokens": [50564, 7010, 13, 50614], "temperature": 0.0, "avg_logprob": -0.2609968730381557, "compression_ratio": 1.5153374233128833, "no_speech_prob": 0.0038271367084234953}, {"id": 246, "seek": 86500, "start": 870.0, "end": 874.0, "text": " Yeah, I'm still in time.", "tokens": [50614, 865, 11, 286, 478, 920, 294, 565, 13, 50814], "temperature": 0.0, "avg_logprob": -0.2609968730381557, "compression_ratio": 1.5153374233128833, "no_speech_prob": 0.0038271367084234953}, {"id": 247, "seek": 86500, "start": 874.0, "end": 882.0, "text": " Dry container also brings something else, which is quite interesting.", "tokens": [50814, 31562, 10129, 611, 5607, 746, 1646, 11, 597, 307, 1596, 1880, 13, 51214], "temperature": 0.0, "avg_logprob": -0.2609968730381557, "compression_ratio": 1.5153374233128833, "no_speech_prob": 0.0038271367084234953}, {"id": 248, "seek": 86500, "start": 882.0, "end": 884.0, "text": " It's a settings, a settings object.", "tokens": [51214, 467, 311, 257, 6257, 11, 257, 6257, 2657, 13, 51314], "temperature": 0.0, "avg_logprob": -0.2609968730381557, "compression_ratio": 1.5153374233128833, "no_speech_prob": 0.0038271367084234953}, {"id": 249, "seek": 86500, "start": 884.0, "end": 890.0, "text": " And I realized very soon that the settings object was the object that I was injecting everywhere.", "tokens": [51314, 400, 286, 5334, 588, 2321, 300, 264, 6257, 2657, 390, 264, 2657, 300, 286, 390, 10711, 278, 5315, 13, 51614], "temperature": 0.0, "avg_logprob": -0.2609968730381557, "compression_ratio": 1.5153374233128833, "no_speech_prob": 0.0038271367084234953}, {"id": 250, "seek": 89000, "start": 890.0, "end": 895.0, "text": " Almost every part of my system needed to access settings.", "tokens": [50364, 12627, 633, 644, 295, 452, 1185, 2978, 281, 2105, 6257, 13, 50614], "temperature": 0.0, "avg_logprob": -0.0677858453047903, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.06718710064888}, {"id": 251, "seek": 89000, "start": 895.0, "end": 897.0, "text": " So I was injecting it everywhere.", "tokens": [50614, 407, 286, 390, 10711, 278, 309, 5315, 13, 50714], "temperature": 0.0, "avg_logprob": -0.0677858453047903, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.06718710064888}, {"id": 252, "seek": 89000, "start": 897.0, "end": 898.0, "text": " It was awesome.", "tokens": [50714, 467, 390, 3476, 13, 50764], "temperature": 0.0, "avg_logprob": -0.0677858453047903, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.06718710064888}, {"id": 253, "seek": 89000, "start": 898.0, "end": 904.0, "text": " And dry settings provide some really interesting value.", "tokens": [50764, 400, 4016, 6257, 2893, 512, 534, 1880, 2158, 13, 51064], "temperature": 0.0, "avg_logprob": -0.0677858453047903, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.06718710064888}, {"id": 254, "seek": 89000, "start": 904.0, "end": 910.0, "text": " First of all, it allows any of the settings to be overridden by environment variable,", "tokens": [51064, 2386, 295, 439, 11, 309, 4045, 604, 295, 264, 6257, 281, 312, 670, 81, 6171, 538, 2823, 7006, 11, 51364], "temperature": 0.0, "avg_logprob": -0.0677858453047903, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.06718710064888}, {"id": 255, "seek": 89000, "start": 910.0, "end": 912.0, "text": " which is quite important.", "tokens": [51364, 597, 307, 1596, 1021, 13, 51464], "temperature": 0.0, "avg_logprob": -0.0677858453047903, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.06718710064888}, {"id": 256, "seek": 89000, "start": 912.0, "end": 918.0, "text": " If you know about 12 factors, it is one of the aspects you want for your config to be overridden", "tokens": [51464, 759, 291, 458, 466, 2272, 6771, 11, 309, 307, 472, 295, 264, 7270, 291, 528, 337, 428, 6662, 281, 312, 670, 81, 6171, 51764], "temperature": 0.0, "avg_logprob": -0.0677858453047903, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.06718710064888}, {"id": 257, "seek": 91800, "start": 918.0, "end": 921.0, "text": " by the environment that your program runs in.", "tokens": [50364, 538, 264, 2823, 300, 428, 1461, 6676, 294, 13, 50514], "temperature": 0.0, "avg_logprob": -0.0781934169622568, "compression_ratio": 1.8731707317073172, "no_speech_prob": 0.02110411785542965}, {"id": 258, "seek": 91800, "start": 921.0, "end": 923.0, "text": " So that was the first part.", "tokens": [50514, 407, 300, 390, 264, 700, 644, 13, 50614], "temperature": 0.0, "avg_logprob": -0.0781934169622568, "compression_ratio": 1.8731707317073172, "no_speech_prob": 0.02110411785542965}, {"id": 259, "seek": 91800, "start": 923.0, "end": 932.0, "text": " And the second part is that you can coerce, you can define the type of your settings.", "tokens": [50614, 400, 264, 1150, 644, 307, 300, 291, 393, 598, 260, 384, 11, 291, 393, 6964, 264, 2010, 295, 428, 6257, 13, 51064], "temperature": 0.0, "avg_logprob": -0.0781934169622568, "compression_ratio": 1.8731707317073172, "no_speech_prob": 0.02110411785542965}, {"id": 260, "seek": 91800, "start": 932.0, "end": 937.0, "text": " Because if you work with environment variables, everything is a string.", "tokens": [51064, 1436, 498, 291, 589, 365, 2823, 9102, 11, 1203, 307, 257, 6798, 13, 51314], "temperature": 0.0, "avg_logprob": -0.0781934169622568, "compression_ratio": 1.8731707317073172, "no_speech_prob": 0.02110411785542965}, {"id": 261, "seek": 91800, "start": 937.0, "end": 940.0, "text": " But when you work in your system, not everything is a string.", "tokens": [51314, 583, 562, 291, 589, 294, 428, 1185, 11, 406, 1203, 307, 257, 6798, 13, 51464], "temperature": 0.0, "avg_logprob": -0.0781934169622568, "compression_ratio": 1.8731707317073172, "no_speech_prob": 0.02110411785542965}, {"id": 262, "seek": 91800, "start": 940.0, "end": 945.0, "text": " We do have a lot of strings, but we have dates, we have integers.", "tokens": [51464, 492, 360, 362, 257, 688, 295, 13985, 11, 457, 321, 362, 11691, 11, 321, 362, 41674, 13, 51714], "temperature": 0.0, "avg_logprob": -0.0781934169622568, "compression_ratio": 1.8731707317073172, "no_speech_prob": 0.02110411785542965}, {"id": 263, "seek": 91800, "start": 945.0, "end": 947.0, "text": " We have a lot of system.", "tokens": [51714, 492, 362, 257, 688, 295, 1185, 13, 51814], "temperature": 0.0, "avg_logprob": -0.0781934169622568, "compression_ratio": 1.8731707317073172, "no_speech_prob": 0.02110411785542965}, {"id": 264, "seek": 94700, "start": 947.0, "end": 950.0, "text": " And usually what we do is we just parse them.", "tokens": [50364, 400, 2673, 437, 321, 360, 307, 321, 445, 48377, 552, 13, 50514], "temperature": 0.0, "avg_logprob": -0.09118905631444787, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.017020229250192642}, {"id": 265, "seek": 94700, "start": 950.0, "end": 955.0, "text": " Dry types allows you to create all types, name them for starters.", "tokens": [50514, 31562, 3467, 4045, 291, 281, 1884, 439, 3467, 11, 1315, 552, 337, 35131, 13, 50764], "temperature": 0.0, "avg_logprob": -0.09118905631444787, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.017020229250192642}, {"id": 266, "seek": 94700, "start": 955.0, "end": 960.0, "text": " Also naming things is probably the most important stuff we do in our work, I believe.", "tokens": [50764, 2743, 25290, 721, 307, 1391, 264, 881, 1021, 1507, 321, 360, 294, 527, 589, 11, 286, 1697, 13, 51014], "temperature": 0.0, "avg_logprob": -0.09118905631444787, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.017020229250192642}, {"id": 267, "seek": 94700, "start": 960.0, "end": 967.0, "text": " You can name your type and get them correctly and get your settings in the proper types,", "tokens": [51014, 509, 393, 1315, 428, 2010, 293, 483, 552, 8944, 293, 483, 428, 6257, 294, 264, 2296, 3467, 11, 51364], "temperature": 0.0, "avg_logprob": -0.09118905631444787, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.017020229250192642}, {"id": 268, "seek": 94700, "start": 967.0, "end": 974.0, "text": " which brings me to my next slide about dry types.", "tokens": [51364, 597, 5607, 385, 281, 452, 958, 4137, 466, 4016, 3467, 13, 51714], "temperature": 0.0, "avg_logprob": -0.09118905631444787, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.017020229250192642}, {"id": 269, "seek": 94700, "start": 974.0, "end": 976.0, "text": " So dry type creates a contract.", "tokens": [51714, 407, 4016, 2010, 7829, 257, 4364, 13, 51814], "temperature": 0.0, "avg_logprob": -0.09118905631444787, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.017020229250192642}, {"id": 270, "seek": 97600, "start": 976.0, "end": 982.0, "text": " It says, okay, this value, this settings, it has to be a phone number.", "tokens": [50364, 467, 1619, 11, 1392, 11, 341, 2158, 11, 341, 6257, 11, 309, 575, 281, 312, 257, 2593, 1230, 13, 50664], "temperature": 0.0, "avg_logprob": -0.10923789471996073, "compression_ratio": 1.7336683417085428, "no_speech_prob": 0.01685955747961998}, {"id": 271, "seek": 97600, "start": 982.0, "end": 985.0, "text": " And I'm going to explain exactly what is a phone number.", "tokens": [50664, 400, 286, 478, 516, 281, 2903, 2293, 437, 307, 257, 2593, 1230, 13, 50814], "temperature": 0.0, "avg_logprob": -0.10923789471996073, "compression_ratio": 1.7336683417085428, "no_speech_prob": 0.01685955747961998}, {"id": 272, "seek": 97600, "start": 985.0, "end": 991.0, "text": " And I'm also going to coerce like a string into a phone number, which means at the end of the day,", "tokens": [50814, 400, 286, 478, 611, 516, 281, 598, 260, 384, 411, 257, 6798, 666, 257, 2593, 1230, 11, 597, 1355, 412, 264, 917, 295, 264, 786, 11, 51114], "temperature": 0.0, "avg_logprob": -0.10923789471996073, "compression_ratio": 1.7336683417085428, "no_speech_prob": 0.01685955747961998}, {"id": 273, "seek": 97600, "start": 991.0, "end": 997.0, "text": " I either have an error or I do have a phone number, which is exactly the object I want.", "tokens": [51114, 286, 2139, 362, 364, 6713, 420, 286, 360, 362, 257, 2593, 1230, 11, 597, 307, 2293, 264, 2657, 286, 528, 13, 51414], "temperature": 0.0, "avg_logprob": -0.10923789471996073, "compression_ratio": 1.7336683417085428, "no_speech_prob": 0.01685955747961998}, {"id": 274, "seek": 97600, "start": 997.0, "end": 1000.0, "text": " And it makes a big difference.", "tokens": [51414, 400, 309, 1669, 257, 955, 2649, 13, 51564], "temperature": 0.0, "avg_logprob": -0.10923789471996073, "compression_ratio": 1.7336683417085428, "no_speech_prob": 0.01685955747961998}, {"id": 275, "seek": 100000, "start": 1000.0, "end": 1010.0, "text": " I don't know if any of you have ever created a class like phone number, like age, like bucket name.", "tokens": [50364, 286, 500, 380, 458, 498, 604, 295, 291, 362, 1562, 2942, 257, 1508, 411, 2593, 1230, 11, 411, 3205, 11, 411, 13058, 1315, 13, 50864], "temperature": 0.0, "avg_logprob": -0.07503351105584039, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.017162831500172615}, {"id": 276, "seek": 100000, "start": 1010.0, "end": 1017.0, "text": " If you read correctly the literature about object-oriented design, we are supposed to do that.", "tokens": [50864, 759, 291, 1401, 8944, 264, 10394, 466, 2657, 12, 27414, 1715, 11, 321, 366, 3442, 281, 360, 300, 13, 51214], "temperature": 0.0, "avg_logprob": -0.07503351105584039, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.017162831500172615}, {"id": 277, "seek": 100000, "start": 1017.0, "end": 1024.0, "text": " We are sort of supposed to do that, like subclass string when we want to make a first name.", "tokens": [51214, 492, 366, 1333, 295, 3442, 281, 360, 300, 11, 411, 1422, 11665, 6798, 562, 321, 528, 281, 652, 257, 700, 1315, 13, 51564], "temperature": 0.0, "avg_logprob": -0.07503351105584039, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.017162831500172615}, {"id": 278, "seek": 100000, "start": 1024.0, "end": 1028.0, "text": " To be honest with you, I've never done that in my life.", "tokens": [51564, 1407, 312, 3245, 365, 291, 11, 286, 600, 1128, 1096, 300, 294, 452, 993, 13, 51764], "temperature": 0.0, "avg_logprob": -0.07503351105584039, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.017162831500172615}, {"id": 279, "seek": 102800, "start": 1028.0, "end": 1031.0, "text": " I've always used string and it's not a first name.", "tokens": [50364, 286, 600, 1009, 1143, 6798, 293, 309, 311, 406, 257, 700, 1315, 13, 50514], "temperature": 0.0, "avg_logprob": -0.08373791238536006, "compression_ratio": 1.7231404958677685, "no_speech_prob": 0.013953517191112041}, {"id": 280, "seek": 102800, "start": 1031.0, "end": 1032.0, "text": " It's a string.", "tokens": [50514, 467, 311, 257, 6798, 13, 50564], "temperature": 0.0, "avg_logprob": -0.08373791238536006, "compression_ratio": 1.7231404958677685, "no_speech_prob": 0.013953517191112041}, {"id": 281, "seek": 102800, "start": 1032.0, "end": 1033.0, "text": " I know it's a first name.", "tokens": [50564, 286, 458, 309, 311, 257, 700, 1315, 13, 50614], "temperature": 0.0, "avg_logprob": -0.08373791238536006, "compression_ratio": 1.7231404958677685, "no_speech_prob": 0.013953517191112041}, {"id": 282, "seek": 102800, "start": 1033.0, "end": 1040.0, "text": " I know I'm not going to use all the methods of string, but the variable is name, first name, that's enough.", "tokens": [50614, 286, 458, 286, 478, 406, 516, 281, 764, 439, 264, 7150, 295, 6798, 11, 457, 264, 7006, 307, 1315, 11, 700, 1315, 11, 300, 311, 1547, 13, 50964], "temperature": 0.0, "avg_logprob": -0.08373791238536006, "compression_ratio": 1.7231404958677685, "no_speech_prob": 0.013953517191112041}, {"id": 283, "seek": 102800, "start": 1040.0, "end": 1045.0, "text": " Using types allows us to actually have proper types, more meaningful types,", "tokens": [50964, 11142, 3467, 4045, 505, 281, 767, 362, 2296, 3467, 11, 544, 10995, 3467, 11, 51214], "temperature": 0.0, "avg_logprob": -0.08373791238536006, "compression_ratio": 1.7231404958677685, "no_speech_prob": 0.013953517191112041}, {"id": 284, "seek": 102800, "start": 1045.0, "end": 1050.0, "text": " without creating full-blown classes for everything.", "tokens": [51214, 1553, 4084, 1577, 12, 5199, 648, 5359, 337, 1203, 13, 51464], "temperature": 0.0, "avg_logprob": -0.08373791238536006, "compression_ratio": 1.7231404958677685, "no_speech_prob": 0.013953517191112041}, {"id": 285, "seek": 102800, "start": 1050.0, "end": 1054.0, "text": " Well, settings is one thing.", "tokens": [51464, 1042, 11, 6257, 307, 472, 551, 13, 51664], "temperature": 0.0, "avg_logprob": -0.08373791238536006, "compression_ratio": 1.7231404958677685, "no_speech_prob": 0.013953517191112041}, {"id": 286, "seek": 102800, "start": 1054.0, "end": 1057.0, "text": " But this contract, it can really be used for something else.", "tokens": [51664, 583, 341, 4364, 11, 309, 393, 534, 312, 1143, 337, 746, 1646, 13, 51814], "temperature": 0.0, "avg_logprob": -0.08373791238536006, "compression_ratio": 1.7231404958677685, "no_speech_prob": 0.013953517191112041}, {"id": 287, "seek": 105700, "start": 1057.0, "end": 1060.0, "text": " It can be used for app input.", "tokens": [50364, 467, 393, 312, 1143, 337, 724, 4846, 13, 50514], "temperature": 0.0, "avg_logprob": -0.09363454182942708, "compression_ratio": 1.6683168316831682, "no_speech_prob": 0.029296869412064552}, {"id": 288, "seek": 105700, "start": 1060.0, "end": 1064.0, "text": " When you are working in a web application, app input is a request.", "tokens": [50514, 1133, 291, 366, 1364, 294, 257, 3670, 3861, 11, 724, 4846, 307, 257, 5308, 13, 50714], "temperature": 0.0, "avg_logprob": -0.09363454182942708, "compression_ratio": 1.6683168316831682, "no_speech_prob": 0.029296869412064552}, {"id": 289, "seek": 105700, "start": 1064.0, "end": 1067.0, "text": " This is where most of our payload comes from.", "tokens": [50714, 639, 307, 689, 881, 295, 527, 30918, 1487, 490, 13, 50864], "temperature": 0.0, "avg_logprob": -0.09363454182942708, "compression_ratio": 1.6683168316831682, "no_speech_prob": 0.029296869412064552}, {"id": 290, "seek": 105700, "start": 1067.0, "end": 1072.0, "text": " In our case, the app input was messaged from a queue, but the concept was very similar.", "tokens": [50864, 682, 527, 1389, 11, 264, 724, 4846, 390, 2082, 2980, 490, 257, 18639, 11, 457, 264, 3410, 390, 588, 2531, 13, 51114], "temperature": 0.0, "avg_logprob": -0.09363454182942708, "compression_ratio": 1.6683168316831682, "no_speech_prob": 0.029296869412064552}, {"id": 291, "seek": 105700, "start": 1072.0, "end": 1082.0, "text": " As soon as we got one message, we treated it in a very similar fashion as we would have treated a request.", "tokens": [51114, 1018, 2321, 382, 321, 658, 472, 3636, 11, 321, 8668, 309, 294, 257, 588, 2531, 6700, 382, 321, 576, 362, 8668, 257, 5308, 13, 51614], "temperature": 0.0, "avg_logprob": -0.09363454182942708, "compression_ratio": 1.6683168316831682, "no_speech_prob": 0.029296869412064552}, {"id": 292, "seek": 108200, "start": 1082.0, "end": 1089.0, "text": " When working with app input as a web, there's a very known pattern for handling that input,", "tokens": [50364, 1133, 1364, 365, 724, 4846, 382, 257, 3670, 11, 456, 311, 257, 588, 2570, 5102, 337, 13175, 300, 4846, 11, 50714], "temperature": 0.0, "avg_logprob": -0.16659701767788138, "compression_ratio": 1.6619718309859155, "no_speech_prob": 0.012462769635021687}, {"id": 293, "seek": 108200, "start": 1089.0, "end": 1093.0, "text": " for validating that input, for correcting that input to everything that you wanted.", "tokens": [50714, 337, 7363, 990, 300, 4846, 11, 337, 47032, 300, 4846, 281, 1203, 300, 291, 1415, 13, 50914], "temperature": 0.0, "avg_logprob": -0.16659701767788138, "compression_ratio": 1.6619718309859155, "no_speech_prob": 0.012462769635021687}, {"id": 294, "seek": 108200, "start": 1093.0, "end": 1096.0, "text": " These are form objects.", "tokens": [50914, 1981, 366, 1254, 6565, 13, 51064], "temperature": 0.0, "avg_logprob": -0.16659701767788138, "compression_ratio": 1.6619718309859155, "no_speech_prob": 0.012462769635021687}, {"id": 295, "seek": 108200, "start": 1096.0, "end": 1101.0, "text": " We basically reused the same.", "tokens": [51064, 492, 1936, 319, 4717, 264, 912, 13, 51314], "temperature": 0.0, "avg_logprob": -0.16659701767788138, "compression_ratio": 1.6619718309859155, "no_speech_prob": 0.012462769635021687}, {"id": 296, "seek": 108200, "start": 1101.0, "end": 1108.0, "text": " I realized that I'm doing my slide in the wrong order, but you don't care because you don't have the order.", "tokens": [51314, 286, 5334, 300, 286, 478, 884, 452, 4137, 294, 264, 2085, 1668, 11, 457, 291, 500, 380, 1127, 570, 291, 500, 380, 362, 264, 1668, 13, 51664], "temperature": 0.0, "avg_logprob": -0.16659701767788138, "compression_ratio": 1.6619718309859155, "no_speech_prob": 0.012462769635021687}, {"id": 297, "seek": 108200, "start": 1108.0, "end": 1110.0, "text": " But that's okay.", "tokens": [51664, 583, 300, 311, 1392, 13, 51764], "temperature": 0.0, "avg_logprob": -0.16659701767788138, "compression_ratio": 1.6619718309859155, "no_speech_prob": 0.012462769635021687}, {"id": 298, "seek": 111000, "start": 1110.0, "end": 1116.0, "text": " We used kind of form object in the form of a dry contract.", "tokens": [50364, 492, 1143, 733, 295, 1254, 2657, 294, 264, 1254, 295, 257, 4016, 4364, 13, 50664], "temperature": 0.0, "avg_logprob": -0.14012330301691978, "compression_ratio": 1.6847290640394088, "no_speech_prob": 0.007648695260286331}, {"id": 299, "seek": 111000, "start": 1116.0, "end": 1121.0, "text": " It comes from dry validation, that is the gem we have been using.", "tokens": [50664, 467, 1487, 490, 4016, 24071, 11, 300, 307, 264, 7173, 321, 362, 668, 1228, 13, 50914], "temperature": 0.0, "avg_logprob": -0.14012330301691978, "compression_ratio": 1.6847290640394088, "no_speech_prob": 0.007648695260286331}, {"id": 300, "seek": 111000, "start": 1121.0, "end": 1126.0, "text": " Dry validation is really about two pillars.", "tokens": [50914, 31562, 24071, 307, 534, 466, 732, 26729, 13, 51164], "temperature": 0.0, "avg_logprob": -0.14012330301691978, "compression_ratio": 1.6847290640394088, "no_speech_prob": 0.007648695260286331}, {"id": 301, "seek": 111000, "start": 1126.0, "end": 1128.0, "text": " The first one is about typing.", "tokens": [51164, 440, 700, 472, 307, 466, 18444, 13, 51264], "temperature": 0.0, "avg_logprob": -0.14012330301691978, "compression_ratio": 1.6847290640394088, "no_speech_prob": 0.007648695260286331}, {"id": 302, "seek": 111000, "start": 1128.0, "end": 1131.0, "text": " Eventually, it leverages dry types.", "tokens": [51264, 17586, 11, 309, 12451, 1660, 4016, 3467, 13, 51414], "temperature": 0.0, "avg_logprob": -0.14012330301691978, "compression_ratio": 1.6847290640394088, "no_speech_prob": 0.007648695260286331}, {"id": 303, "seek": 111000, "start": 1131.0, "end": 1137.0, "text": " It ensures that you get the keys of your payload that you expect, that you get the values that you expect,", "tokens": [51414, 467, 28111, 300, 291, 483, 264, 9317, 295, 428, 30918, 300, 291, 2066, 11, 300, 291, 483, 264, 4190, 300, 291, 2066, 11, 51714], "temperature": 0.0, "avg_logprob": -0.14012330301691978, "compression_ratio": 1.6847290640394088, "no_speech_prob": 0.007648695260286331}, {"id": 304, "seek": 113700, "start": 1137.0, "end": 1144.0, "text": " that basically your data is of the type you expect, that's the schema, that's the structure.", "tokens": [50364, 300, 1936, 428, 1412, 307, 295, 264, 2010, 291, 2066, 11, 300, 311, 264, 34078, 11, 300, 311, 264, 3877, 13, 50714], "temperature": 0.0, "avg_logprob": -0.08931652704874675, "compression_ratio": 1.6336633663366336, "no_speech_prob": 0.010318243876099586}, {"id": 305, "seek": 113700, "start": 1144.0, "end": 1150.0, "text": " Once you have the proper types, you still have business logic to handle.", "tokens": [50714, 3443, 291, 362, 264, 2296, 3467, 11, 291, 920, 362, 1606, 9952, 281, 4813, 13, 51014], "temperature": 0.0, "avg_logprob": -0.08931652704874675, "compression_ratio": 1.6336633663366336, "no_speech_prob": 0.010318243876099586}, {"id": 306, "seek": 113700, "start": 1150.0, "end": 1155.0, "text": " This is the second pillar of dry validation.", "tokens": [51014, 639, 307, 264, 1150, 27592, 295, 4016, 24071, 13, 51264], "temperature": 0.0, "avg_logprob": -0.08931652704874675, "compression_ratio": 1.6336633663366336, "no_speech_prob": 0.010318243876099586}, {"id": 307, "seek": 113700, "start": 1155.0, "end": 1160.0, "text": " A typical example would be if you have to handle a deadline.", "tokens": [51264, 316, 7476, 1365, 576, 312, 498, 291, 362, 281, 4813, 257, 20615, 13, 51514], "temperature": 0.0, "avg_logprob": -0.08931652704874675, "compression_ratio": 1.6336633663366336, "no_speech_prob": 0.010318243876099586}, {"id": 308, "seek": 113700, "start": 1160.0, "end": 1163.0, "text": " Imagine that somewhere in your payload there's a deadline.", "tokens": [51514, 11739, 300, 4079, 294, 428, 30918, 456, 311, 257, 20615, 13, 51664], "temperature": 0.0, "avg_logprob": -0.08931652704874675, "compression_ratio": 1.6336633663366336, "no_speech_prob": 0.010318243876099586}, {"id": 309, "seek": 116300, "start": 1163.0, "end": 1168.0, "text": " The first pillar would ensure that the deadline is actually a date because you get a string.", "tokens": [50364, 440, 700, 27592, 576, 5586, 300, 264, 20615, 307, 767, 257, 4002, 570, 291, 483, 257, 6798, 13, 50614], "temperature": 0.0, "avg_logprob": -0.1254977136850357, "compression_ratio": 1.84765625, "no_speech_prob": 0.00982789695262909}, {"id": 310, "seek": 116300, "start": 1168.0, "end": 1173.0, "text": " Hopefully it's an ISO 8601 string, but it could be anything else.", "tokens": [50614, 10429, 309, 311, 364, 25042, 1649, 4550, 16, 6798, 11, 457, 309, 727, 312, 1340, 1646, 13, 50864], "temperature": 0.0, "avg_logprob": -0.1254977136850357, "compression_ratio": 1.84765625, "no_speech_prob": 0.00982789695262909}, {"id": 311, "seek": 116300, "start": 1173.0, "end": 1176.0, "text": " You want to coerce that in a string, you want to ensure that you have a string.", "tokens": [50864, 509, 528, 281, 598, 260, 384, 300, 294, 257, 6798, 11, 291, 528, 281, 5586, 300, 291, 362, 257, 6798, 13, 51014], "temperature": 0.0, "avg_logprob": -0.1254977136850357, "compression_ratio": 1.84765625, "no_speech_prob": 0.00982789695262909}, {"id": 312, "seek": 116300, "start": 1176.0, "end": 1179.0, "text": " If it's not coerceable into a string, you want the first error.", "tokens": [51014, 759, 309, 311, 406, 598, 260, 384, 712, 666, 257, 6798, 11, 291, 528, 264, 700, 6713, 13, 51164], "temperature": 0.0, "avg_logprob": -0.1254977136850357, "compression_ratio": 1.84765625, "no_speech_prob": 0.00982789695262909}, {"id": 313, "seek": 116300, "start": 1179.0, "end": 1185.0, "text": " But now that you have a string, you also need to validate that this actual date is in the future.", "tokens": [51164, 583, 586, 300, 291, 362, 257, 6798, 11, 291, 611, 643, 281, 29562, 300, 341, 3539, 4002, 307, 294, 264, 2027, 13, 51464], "temperature": 0.0, "avg_logprob": -0.1254977136850357, "compression_ratio": 1.84765625, "no_speech_prob": 0.00982789695262909}, {"id": 314, "seek": 116300, "start": 1185.0, "end": 1187.0, "text": " This is what the second pillar is.", "tokens": [51464, 639, 307, 437, 264, 1150, 27592, 307, 13, 51564], "temperature": 0.0, "avg_logprob": -0.1254977136850357, "compression_ratio": 1.84765625, "no_speech_prob": 0.00982789695262909}, {"id": 315, "seek": 116300, "start": 1187.0, "end": 1190.0, "text": " You can create rules, business rules.", "tokens": [51564, 509, 393, 1884, 4474, 11, 1606, 4474, 13, 51714], "temperature": 0.0, "avg_logprob": -0.1254977136850357, "compression_ratio": 1.84765625, "no_speech_prob": 0.00982789695262909}, {"id": 316, "seek": 119000, "start": 1190.0, "end": 1195.0, "text": " That means that once your payload goes through the dry validation mechanism,", "tokens": [50364, 663, 1355, 300, 1564, 428, 30918, 1709, 807, 264, 4016, 24071, 7513, 11, 50614], "temperature": 0.0, "avg_logprob": -0.0676646439925484, "compression_ratio": 1.6342857142857143, "no_speech_prob": 0.01544240117073059}, {"id": 317, "seek": 119000, "start": 1195.0, "end": 1201.0, "text": " you actually get a very valid, very reliable payload from a typing perspective,", "tokens": [50614, 291, 767, 483, 257, 588, 7363, 11, 588, 12924, 30918, 490, 257, 18444, 4585, 11, 50914], "temperature": 0.0, "avg_logprob": -0.0676646439925484, "compression_ratio": 1.6342857142857143, "no_speech_prob": 0.01544240117073059}, {"id": 318, "seek": 119000, "start": 1201.0, "end": 1205.0, "text": " but also from a business perspective.", "tokens": [50914, 457, 611, 490, 257, 1606, 4585, 13, 51114], "temperature": 0.0, "avg_logprob": -0.0676646439925484, "compression_ratio": 1.6342857142857143, "no_speech_prob": 0.01544240117073059}, {"id": 319, "seek": 119000, "start": 1205.0, "end": 1210.0, "text": " Once we have that payload, what do we want to do with that?", "tokens": [51114, 3443, 321, 362, 300, 30918, 11, 437, 360, 321, 528, 281, 360, 365, 300, 30, 51364], "temperature": 0.0, "avg_logprob": -0.0676646439925484, "compression_ratio": 1.6342857142857143, "no_speech_prob": 0.01544240117073059}, {"id": 320, "seek": 119000, "start": 1210.0, "end": 1215.0, "text": " We actually want to process it.", "tokens": [51364, 492, 767, 528, 281, 1399, 309, 13, 51614], "temperature": 0.0, "avg_logprob": -0.0676646439925484, "compression_ratio": 1.6342857142857143, "no_speech_prob": 0.01544240117073059}, {"id": 321, "seek": 121500, "start": 1215.0, "end": 1219.0, "text": " For that, we are using a pattern which is named Interactor.", "tokens": [50364, 1171, 300, 11, 321, 366, 1228, 257, 5102, 597, 307, 4926, 5751, 15104, 13, 50564], "temperature": 0.0, "avg_logprob": -0.12103351699971707, "compression_ratio": 1.6563876651982379, "no_speech_prob": 0.01555812731385231}, {"id": 322, "seek": 121500, "start": 1219.0, "end": 1222.0, "text": " At least we used to use a gem which is named Interactor.", "tokens": [50564, 1711, 1935, 321, 1143, 281, 764, 257, 7173, 597, 307, 4926, 5751, 15104, 13, 50714], "temperature": 0.0, "avg_logprob": -0.12103351699971707, "compression_ratio": 1.6563876651982379, "no_speech_prob": 0.01555812731385231}, {"id": 323, "seek": 121500, "start": 1222.0, "end": 1226.0, "text": " You can think of an Interactor a little bit like an operation in Trailblazer.", "tokens": [50714, 509, 393, 519, 295, 364, 5751, 15104, 257, 707, 857, 411, 364, 6916, 294, 30080, 36138, 4527, 13, 50914], "temperature": 0.0, "avg_logprob": -0.12103351699971707, "compression_ratio": 1.6563876651982379, "no_speech_prob": 0.01555812731385231}, {"id": 324, "seek": 121500, "start": 1226.0, "end": 1230.0, "text": " I don't know if anybody has used Trailblazer previously.", "tokens": [50914, 286, 500, 380, 458, 498, 4472, 575, 1143, 30080, 36138, 4527, 8046, 13, 51114], "temperature": 0.0, "avg_logprob": -0.12103351699971707, "compression_ratio": 1.6563876651982379, "no_speech_prob": 0.01555812731385231}, {"id": 325, "seek": 121500, "start": 1230.0, "end": 1232.0, "text": " No? Okay.", "tokens": [51114, 883, 30, 1033, 13, 51214], "temperature": 0.0, "avg_logprob": -0.12103351699971707, "compression_ratio": 1.6563876651982379, "no_speech_prob": 0.01555812731385231}, {"id": 326, "seek": 121500, "start": 1232.0, "end": 1234.0, "text": " All right. I'm going to go back.", "tokens": [51214, 1057, 558, 13, 286, 478, 516, 281, 352, 646, 13, 51314], "temperature": 0.0, "avg_logprob": -0.12103351699971707, "compression_ratio": 1.6563876651982379, "no_speech_prob": 0.01555812731385231}, {"id": 327, "seek": 121500, "start": 1234.0, "end": 1239.0, "text": " The idea of an Interactor is that this is the entry point to your business layer.", "tokens": [51314, 440, 1558, 295, 364, 5751, 15104, 307, 300, 341, 307, 264, 8729, 935, 281, 428, 1606, 4583, 13, 51564], "temperature": 0.0, "avg_logprob": -0.12103351699971707, "compression_ratio": 1.6563876651982379, "no_speech_prob": 0.01555812731385231}, {"id": 328, "seek": 123900, "start": 1239.0, "end": 1244.0, "text": " Because the entry point to your application to most of the web application are the controllers.", "tokens": [50364, 1436, 264, 8729, 935, 281, 428, 3861, 281, 881, 295, 264, 3670, 3861, 366, 264, 26903, 13, 50614], "temperature": 0.0, "avg_logprob": -0.11552016799514359, "compression_ratio": 2.157142857142857, "no_speech_prob": 0.029819071292877197}, {"id": 329, "seek": 123900, "start": 1244.0, "end": 1248.0, "text": " This is how... I'm not talking about the rules.", "tokens": [50614, 639, 307, 577, 485, 286, 478, 406, 1417, 466, 264, 4474, 13, 50814], "temperature": 0.0, "avg_logprob": -0.11552016799514359, "compression_ratio": 2.157142857142857, "no_speech_prob": 0.029819071292877197}, {"id": 330, "seek": 123900, "start": 1248.0, "end": 1251.0, "text": " Let's consider that the entry point is the controller.", "tokens": [50814, 961, 311, 1949, 300, 264, 8729, 935, 307, 264, 10561, 13, 50964], "temperature": 0.0, "avg_logprob": -0.11552016799514359, "compression_ratio": 2.157142857142857, "no_speech_prob": 0.029819071292877197}, {"id": 331, "seek": 123900, "start": 1251.0, "end": 1255.0, "text": " But that's not true because sometimes your entry point is your test.", "tokens": [50964, 583, 300, 311, 406, 2074, 570, 2171, 428, 8729, 935, 307, 428, 1500, 13, 51164], "temperature": 0.0, "avg_logprob": -0.11552016799514359, "compression_ratio": 2.157142857142857, "no_speech_prob": 0.029819071292877197}, {"id": 332, "seek": 123900, "start": 1255.0, "end": 1257.0, "text": " Sometimes your entry point is a rate task.", "tokens": [51164, 4803, 428, 8729, 935, 307, 257, 3314, 5633, 13, 51264], "temperature": 0.0, "avg_logprob": -0.11552016799514359, "compression_ratio": 2.157142857142857, "no_speech_prob": 0.029819071292877197}, {"id": 333, "seek": 123900, "start": 1257.0, "end": 1259.0, "text": " Sometimes your entry point is an active job.", "tokens": [51264, 4803, 428, 8729, 935, 307, 364, 4967, 1691, 13, 51364], "temperature": 0.0, "avg_logprob": -0.11552016799514359, "compression_ratio": 2.157142857142857, "no_speech_prob": 0.029819071292877197}, {"id": 334, "seek": 123900, "start": 1259.0, "end": 1262.0, "text": " Sometimes your entry point is a channel.", "tokens": [51364, 4803, 428, 8729, 935, 307, 257, 2269, 13, 51514], "temperature": 0.0, "avg_logprob": -0.11552016799514359, "compression_ratio": 2.157142857142857, "no_speech_prob": 0.029819071292877197}, {"id": 335, "seek": 123900, "start": 1262.0, "end": 1267.0, "text": " So you actually get a lot of entry points into your app.", "tokens": [51514, 407, 291, 767, 483, 257, 688, 295, 8729, 2793, 666, 428, 724, 13, 51764], "temperature": 0.0, "avg_logprob": -0.11552016799514359, "compression_ratio": 2.157142857142857, "no_speech_prob": 0.029819071292877197}, {"id": 336, "seek": 126700, "start": 1267.0, "end": 1272.0, "text": " But at the business level, you don't really care if you want to delete a user", "tokens": [50364, 583, 412, 264, 1606, 1496, 11, 291, 500, 380, 534, 1127, 498, 291, 528, 281, 12097, 257, 4195, 50614], "temperature": 0.0, "avg_logprob": -0.11042743979148495, "compression_ratio": 1.6696428571428572, "no_speech_prob": 0.005631706677377224}, {"id": 337, "seek": 126700, "start": 1272.0, "end": 1277.0, "text": " because of a GraphQL request, of a REST request, of an active job.", "tokens": [50614, 570, 295, 257, 21884, 13695, 5308, 11, 295, 257, 497, 14497, 5308, 11, 295, 364, 4967, 1691, 13, 50864], "temperature": 0.0, "avg_logprob": -0.11042743979148495, "compression_ratio": 1.6696428571428572, "no_speech_prob": 0.005631706677377224}, {"id": 338, "seek": 126700, "start": 1277.0, "end": 1281.0, "text": " You want to delete a user. It's the same business unit.", "tokens": [50864, 509, 528, 281, 12097, 257, 4195, 13, 467, 311, 264, 912, 1606, 4985, 13, 51064], "temperature": 0.0, "avg_logprob": -0.11042743979148495, "compression_ratio": 1.6696428571428572, "no_speech_prob": 0.005631706677377224}, {"id": 339, "seek": 126700, "start": 1281.0, "end": 1287.0, "text": " And this is how we encapsulate things we are using in Interactor.", "tokens": [51064, 400, 341, 307, 577, 321, 38745, 5256, 721, 321, 366, 1228, 294, 5751, 15104, 13, 51364], "temperature": 0.0, "avg_logprob": -0.11042743979148495, "compression_ratio": 1.6696428571428572, "no_speech_prob": 0.005631706677377224}, {"id": 340, "seek": 126700, "start": 1287.0, "end": 1291.0, "text": " One Interactor is responsible for one business unit.", "tokens": [51364, 1485, 5751, 15104, 307, 6250, 337, 472, 1606, 4985, 13, 51564], "temperature": 0.0, "avg_logprob": -0.11042743979148495, "compression_ratio": 1.6696428571428572, "no_speech_prob": 0.005631706677377224}, {"id": 341, "seek": 126700, "start": 1291.0, "end": 1296.0, "text": " And well, very fortunately, DRI has a solution for us.", "tokens": [51564, 400, 731, 11, 588, 25511, 11, 413, 5577, 575, 257, 3827, 337, 505, 13, 51814], "temperature": 0.0, "avg_logprob": -0.11042743979148495, "compression_ratio": 1.6696428571428572, "no_speech_prob": 0.005631706677377224}, {"id": 342, "seek": 129600, "start": 1297.0, "end": 1300.0, "text": " It's a name DRI Transaction.", "tokens": [50414, 467, 311, 257, 1315, 413, 5577, 6531, 2894, 13, 50564], "temperature": 0.0, "avg_logprob": -0.13429074538381477, "compression_ratio": 1.7675438596491229, "no_speech_prob": 0.0329001322388649}, {"id": 343, "seek": 129600, "start": 1300.0, "end": 1302.0, "text": " So their name for it is a transaction.", "tokens": [50564, 407, 641, 1315, 337, 309, 307, 257, 14425, 13, 50664], "temperature": 0.0, "avg_logprob": -0.13429074538381477, "compression_ratio": 1.7675438596491229, "no_speech_prob": 0.0329001322388649}, {"id": 344, "seek": 129600, "start": 1302.0, "end": 1306.0, "text": " It allows you to create a series of steps.", "tokens": [50664, 467, 4045, 291, 281, 1884, 257, 2638, 295, 4439, 13, 50864], "temperature": 0.0, "avg_logprob": -0.13429074538381477, "compression_ratio": 1.7675438596491229, "no_speech_prob": 0.0329001322388649}, {"id": 345, "seek": 129600, "start": 1306.0, "end": 1311.0, "text": " It relies on DRI Modad because each step can give you a result.", "tokens": [50864, 467, 30910, 322, 413, 5577, 6583, 345, 570, 1184, 1823, 393, 976, 291, 257, 1874, 13, 51114], "temperature": 0.0, "avg_logprob": -0.13429074538381477, "compression_ratio": 1.7675438596491229, "no_speech_prob": 0.0329001322388649}, {"id": 346, "seek": 129600, "start": 1311.0, "end": 1317.0, "text": " And if the result is a success, then the next step is going to happen.", "tokens": [51114, 400, 498, 264, 1874, 307, 257, 2245, 11, 550, 264, 958, 1823, 307, 516, 281, 1051, 13, 51414], "temperature": 0.0, "avg_logprob": -0.13429074538381477, "compression_ratio": 1.7675438596491229, "no_speech_prob": 0.0329001322388649}, {"id": 347, "seek": 129600, "start": 1317.0, "end": 1320.0, "text": " If the result is a failure, then the next step is not going to be done.", "tokens": [51414, 759, 264, 1874, 307, 257, 7763, 11, 550, 264, 958, 1823, 307, 406, 516, 281, 312, 1096, 13, 51564], "temperature": 0.0, "avg_logprob": -0.13429074538381477, "compression_ratio": 1.7675438596491229, "no_speech_prob": 0.0329001322388649}, {"id": 348, "seek": 129600, "start": 1320.0, "end": 1322.0, "text": " You're going to keep your failure.", "tokens": [51564, 509, 434, 516, 281, 1066, 428, 7763, 13, 51664], "temperature": 0.0, "avg_logprob": -0.13429074538381477, "compression_ratio": 1.7675438596491229, "no_speech_prob": 0.0329001322388649}, {"id": 349, "seek": 129600, "start": 1322.0, "end": 1325.0, "text": " This is known as the railway oriented programming.", "tokens": [51664, 639, 307, 2570, 382, 264, 25812, 21841, 9410, 13, 51814], "temperature": 0.0, "avg_logprob": -0.13429074538381477, "compression_ratio": 1.7675438596491229, "no_speech_prob": 0.0329001322388649}, {"id": 350, "seek": 132500, "start": 1325.0, "end": 1327.0, "text": " Nothing related to rails.", "tokens": [50364, 6693, 4077, 281, 27649, 13, 50464], "temperature": 0.0, "avg_logprob": -0.09945293608165923, "compression_ratio": 1.6355932203389831, "no_speech_prob": 0.002427534433081746}, {"id": 351, "seek": 132500, "start": 1327.0, "end": 1332.0, "text": " It's just because you either stay on your success track, like train track,", "tokens": [50464, 467, 311, 445, 570, 291, 2139, 1754, 322, 428, 2245, 2837, 11, 411, 3847, 2837, 11, 50714], "temperature": 0.0, "avg_logprob": -0.09945293608165923, "compression_ratio": 1.6355932203389831, "no_speech_prob": 0.002427534433081746}, {"id": 352, "seek": 132500, "start": 1332.0, "end": 1336.0, "text": " or at each step you have a junction to your failure track.", "tokens": [50714, 420, 412, 1184, 1823, 291, 362, 257, 33718, 281, 428, 7763, 2837, 13, 50914], "temperature": 0.0, "avg_logprob": -0.09945293608165923, "compression_ratio": 1.6355932203389831, "no_speech_prob": 0.002427534433081746}, {"id": 353, "seek": 132500, "start": 1336.0, "end": 1340.0, "text": " Well, the thing is we didn't use DRI Transaction.", "tokens": [50914, 1042, 11, 264, 551, 307, 321, 994, 380, 764, 413, 5577, 6531, 2894, 13, 51114], "temperature": 0.0, "avg_logprob": -0.09945293608165923, "compression_ratio": 1.6355932203389831, "no_speech_prob": 0.002427534433081746}, {"id": 354, "seek": 132500, "start": 1340.0, "end": 1343.0, "text": " So I wanted to let you know because I would really recommend that you use it.", "tokens": [51114, 407, 286, 1415, 281, 718, 291, 458, 570, 286, 576, 534, 2748, 300, 291, 764, 309, 13, 51264], "temperature": 0.0, "avg_logprob": -0.09945293608165923, "compression_ratio": 1.6355932203389831, "no_speech_prob": 0.002427534433081746}, {"id": 355, "seek": 132500, "start": 1343.0, "end": 1348.0, "text": " I wanted to use it, but also we have a team of several developers", "tokens": [51264, 286, 1415, 281, 764, 309, 11, 457, 611, 321, 362, 257, 1469, 295, 2940, 8849, 51514], "temperature": 0.0, "avg_logprob": -0.09945293608165923, "compression_ratio": 1.6355932203389831, "no_speech_prob": 0.002427534433081746}, {"id": 356, "seek": 132500, "start": 1348.0, "end": 1350.0, "text": " who are used to our Interactors.", "tokens": [51514, 567, 366, 1143, 281, 527, 5751, 578, 830, 13, 51614], "temperature": 0.0, "avg_logprob": -0.09945293608165923, "compression_ratio": 1.6355932203389831, "no_speech_prob": 0.002427534433081746}, {"id": 357, "seek": 135000, "start": 1350.0, "end": 1354.0, "text": " And it sounded like a better idea to use what everybody knew", "tokens": [50364, 400, 309, 17714, 411, 257, 1101, 1558, 281, 764, 437, 2201, 2586, 50564], "temperature": 0.0, "avg_logprob": -0.1150799212248429, "compression_ratio": 1.5826771653543308, "no_speech_prob": 0.00622651306912303}, {"id": 358, "seek": 135000, "start": 1354.0, "end": 1356.0, "text": " than trying to reinvent the wheel.", "tokens": [50564, 813, 1382, 281, 33477, 264, 5589, 13, 50664], "temperature": 0.0, "avg_logprob": -0.1150799212248429, "compression_ratio": 1.5826771653543308, "no_speech_prob": 0.00622651306912303}, {"id": 359, "seek": 135000, "start": 1356.0, "end": 1358.0, "text": " We had something, it's working well, everybody knows it well.", "tokens": [50664, 492, 632, 746, 11, 309, 311, 1364, 731, 11, 2201, 3255, 309, 731, 13, 50764], "temperature": 0.0, "avg_logprob": -0.1150799212248429, "compression_ratio": 1.5826771653543308, "no_speech_prob": 0.00622651306912303}, {"id": 360, "seek": 135000, "start": 1358.0, "end": 1362.0, "text": " So this is like my manager voice talking.", "tokens": [50764, 407, 341, 307, 411, 452, 6598, 3177, 1417, 13, 50964], "temperature": 0.0, "avg_logprob": -0.1150799212248429, "compression_ratio": 1.5826771653543308, "no_speech_prob": 0.00622651306912303}, {"id": 361, "seek": 135000, "start": 1362.0, "end": 1365.0, "text": " If it's end broken, broken, don't fix it.", "tokens": [50964, 759, 309, 311, 917, 5463, 11, 5463, 11, 500, 380, 3191, 309, 13, 51114], "temperature": 0.0, "avg_logprob": -0.1150799212248429, "compression_ratio": 1.5826771653543308, "no_speech_prob": 0.00622651306912303}, {"id": 362, "seek": 135000, "start": 1365.0, "end": 1370.0, "text": " But if you're doing it from the start, give a chance to DRI Transaction and DRI Modad.", "tokens": [51114, 583, 498, 291, 434, 884, 309, 490, 264, 722, 11, 976, 257, 2931, 281, 413, 5577, 6531, 2894, 293, 413, 5577, 6583, 345, 13, 51364], "temperature": 0.0, "avg_logprob": -0.1150799212248429, "compression_ratio": 1.5826771653543308, "no_speech_prob": 0.00622651306912303}, {"id": 363, "seek": 135000, "start": 1370.0, "end": 1377.0, "text": " At this point in the talk, I hoped to try my own definition of DRI Modad,", "tokens": [51364, 1711, 341, 935, 294, 264, 751, 11, 286, 19737, 281, 853, 452, 1065, 7123, 295, 413, 5577, 6583, 345, 11, 51714], "temperature": 0.0, "avg_logprob": -0.1150799212248429, "compression_ratio": 1.5826771653543308, "no_speech_prob": 0.00622651306912303}, {"id": 364, "seek": 137700, "start": 1377.0, "end": 1382.0, "text": " of Monad, what is a Monad, which is probably going to take the next two hours.", "tokens": [50364, 295, 4713, 345, 11, 437, 307, 257, 4713, 345, 11, 597, 307, 1391, 516, 281, 747, 264, 958, 732, 2496, 13, 50614], "temperature": 0.0, "avg_logprob": -0.13184324264526368, "compression_ratio": 1.5751072961373391, "no_speech_prob": 0.015926415100693703}, {"id": 365, "seek": 137700, "start": 1382.0, "end": 1384.0, "text": " So let's keep it.", "tokens": [50614, 407, 718, 311, 1066, 309, 13, 50714], "temperature": 0.0, "avg_logprob": -0.13184324264526368, "compression_ratio": 1.5751072961373391, "no_speech_prob": 0.015926415100693703}, {"id": 366, "seek": 137700, "start": 1386.0, "end": 1394.0, "text": " So the end of this slide is about why do we want to do all that validation early?", "tokens": [50814, 407, 264, 917, 295, 341, 4137, 307, 466, 983, 360, 321, 528, 281, 360, 439, 300, 24071, 2440, 30, 51214], "temperature": 0.0, "avg_logprob": -0.13184324264526368, "compression_ratio": 1.5751072961373391, "no_speech_prob": 0.015926415100693703}, {"id": 367, "seek": 137700, "start": 1394.0, "end": 1397.0, "text": " And this was also something a bit new.", "tokens": [51214, 400, 341, 390, 611, 746, 257, 857, 777, 13, 51364], "temperature": 0.0, "avg_logprob": -0.13184324264526368, "compression_ratio": 1.5751072961373391, "no_speech_prob": 0.015926415100693703}, {"id": 368, "seek": 137700, "start": 1397.0, "end": 1399.0, "text": " First of all, like failing early is a good idea.", "tokens": [51364, 2386, 295, 439, 11, 411, 18223, 2440, 307, 257, 665, 1558, 13, 51464], "temperature": 0.0, "avg_logprob": -0.13184324264526368, "compression_ratio": 1.5751072961373391, "no_speech_prob": 0.015926415100693703}, {"id": 369, "seek": 137700, "start": 1399.0, "end": 1406.0, "text": " But it was not enough because doing the business validation at each step would have made more sense.", "tokens": [51464, 583, 309, 390, 406, 1547, 570, 884, 264, 1606, 24071, 412, 1184, 1823, 576, 362, 1027, 544, 2020, 13, 51814], "temperature": 0.0, "avg_logprob": -0.13184324264526368, "compression_ratio": 1.5751072961373391, "no_speech_prob": 0.015926415100693703}, {"id": 370, "seek": 140600, "start": 1406.0, "end": 1410.0, "text": " It's just easier to keep the business steps together.", "tokens": [50364, 467, 311, 445, 3571, 281, 1066, 264, 1606, 4439, 1214, 13, 50564], "temperature": 0.0, "avg_logprob": -0.0595318857828776, "compression_ratio": 1.6844919786096257, "no_speech_prob": 0.01798449456691742}, {"id": 371, "seek": 140600, "start": 1410.0, "end": 1418.0, "text": " It makes more sense if you want to check some permission, then delete a record, then send an email.", "tokens": [50564, 467, 1669, 544, 2020, 498, 291, 528, 281, 1520, 512, 11226, 11, 550, 12097, 257, 2136, 11, 550, 2845, 364, 3796, 13, 50964], "temperature": 0.0, "avg_logprob": -0.0595318857828776, "compression_ratio": 1.6844919786096257, "no_speech_prob": 0.01798449456691742}, {"id": 372, "seek": 140600, "start": 1418.0, "end": 1423.0, "text": " It makes sense that you do everything related to sending the email at the sending email step.", "tokens": [50964, 467, 1669, 2020, 300, 291, 360, 1203, 4077, 281, 7750, 264, 3796, 412, 264, 7750, 3796, 1823, 13, 51214], "temperature": 0.0, "avg_logprob": -0.0595318857828776, "compression_ratio": 1.6844919786096257, "no_speech_prob": 0.01798449456691742}, {"id": 373, "seek": 140600, "start": 1423.0, "end": 1428.0, "text": " It doesn't really make sense to already check stuff from the start.", "tokens": [51214, 467, 1177, 380, 534, 652, 2020, 281, 1217, 1520, 1507, 490, 264, 722, 13, 51464], "temperature": 0.0, "avg_logprob": -0.0595318857828776, "compression_ratio": 1.6844919786096257, "no_speech_prob": 0.01798449456691742}, {"id": 374, "seek": 142800, "start": 1429.0, "end": 1437.0, "text": " But the thing is, in Rails, we are very much used to a highly rollback-able environment", "tokens": [50414, 583, 264, 551, 307, 11, 294, 48526, 11, 321, 366, 588, 709, 1143, 281, 257, 5405, 3373, 3207, 12, 712, 2823, 50814], "temperature": 0.4, "avg_logprob": -0.23146022762264218, "compression_ratio": 1.759825327510917, "no_speech_prob": 0.005327489227056503}, {"id": 375, "seek": 142800, "start": 1437.0, "end": 1441.0, "text": " because most of what we do, well, sending email doesn't count,", "tokens": [50814, 570, 881, 295, 437, 321, 360, 11, 731, 11, 7750, 3796, 1177, 380, 1207, 11, 51014], "temperature": 0.4, "avg_logprob": -0.23146022762264218, "compression_ratio": 1.759825327510917, "no_speech_prob": 0.005327489227056503}, {"id": 376, "seek": 142800, "start": 1441.0, "end": 1444.0, "text": " but most of what we do is manipulate the database.", "tokens": [51014, 457, 881, 295, 437, 321, 360, 307, 20459, 264, 8149, 13, 51164], "temperature": 0.4, "avg_logprob": -0.23146022762264218, "compression_ratio": 1.759825327510917, "no_speech_prob": 0.005327489227056503}, {"id": 377, "seek": 142800, "start": 1444.0, "end": 1451.0, "text": " And this is a huge comfort being able to say, my record.transaction do blah, blah, blah, blah, blah, blah, blah, blah, blah, blah.", "tokens": [51164, 400, 341, 307, 257, 2603, 3400, 885, 1075, 281, 584, 11, 452, 2136, 13, 24999, 2894, 360, 12288, 11, 12288, 11, 12288, 11, 12288, 11, 12288, 11, 12288, 11, 12288, 11, 12288, 11, 12288, 11, 12288, 13, 51514], "temperature": 0.4, "avg_logprob": -0.23146022762264218, "compression_ratio": 1.759825327510917, "no_speech_prob": 0.005327489227056503}, {"id": 378, "seek": 142800, "start": 1451.0, "end": 1455.0, "text": " If anything goes wrong, just roll back and done, nothing has happened.", "tokens": [51514, 759, 1340, 1709, 2085, 11, 445, 3373, 646, 293, 1096, 11, 1825, 575, 2011, 13, 51714], "temperature": 0.4, "avg_logprob": -0.23146022762264218, "compression_ratio": 1.759825327510917, "no_speech_prob": 0.005327489227056503}, {"id": 379, "seek": 145500, "start": 1455.0, "end": 1460.0, "text": " When you're doing a microservice, at least what we are doing, nothing is rollback-able.", "tokens": [50364, 1133, 291, 434, 884, 257, 15547, 25006, 11, 412, 1935, 437, 321, 366, 884, 11, 1825, 307, 3373, 3207, 12, 712, 13, 50614], "temperature": 0.0, "avg_logprob": -0.12551282183958754, "compression_ratio": 1.6266666666666667, "no_speech_prob": 0.013814747333526611}, {"id": 380, "seek": 145500, "start": 1460.0, "end": 1468.0, "text": " Everything you do, if you send an API request to something, if you delete a file, download a file, create a file, there's no rollback to that.", "tokens": [50614, 5471, 291, 360, 11, 498, 291, 2845, 364, 9362, 5308, 281, 746, 11, 498, 291, 12097, 257, 3991, 11, 5484, 257, 3991, 11, 1884, 257, 3991, 11, 456, 311, 572, 3373, 3207, 281, 300, 13, 51014], "temperature": 0.0, "avg_logprob": -0.12551282183958754, "compression_ratio": 1.6266666666666667, "no_speech_prob": 0.013814747333526611}, {"id": 381, "seek": 145500, "start": 1468.0, "end": 1475.0, "text": " And this is why it was so important to check as much as we could right from the start.", "tokens": [51014, 400, 341, 307, 983, 309, 390, 370, 1021, 281, 1520, 382, 709, 382, 321, 727, 558, 490, 264, 722, 13, 51364], "temperature": 0.0, "avg_logprob": -0.12551282183958754, "compression_ratio": 1.6266666666666667, "no_speech_prob": 0.013814747333526611}, {"id": 382, "seek": 145500, "start": 1476.0, "end": 1479.0, "text": " All right, next step.", "tokens": [51414, 1057, 558, 11, 958, 1823, 13, 51564], "temperature": 0.0, "avg_logprob": -0.12551282183958754, "compression_ratio": 1.6266666666666667, "no_speech_prob": 0.013814747333526611}, {"id": 383, "seek": 145500, "start": 1480.0, "end": 1482.0, "text": " Next step, next challenge.", "tokens": [51614, 3087, 1823, 11, 958, 3430, 13, 51714], "temperature": 0.0, "avg_logprob": -0.12551282183958754, "compression_ratio": 1.6266666666666667, "no_speech_prob": 0.013814747333526611}, {"id": 384, "seek": 148200, "start": 1483.0, "end": 1492.0, "text": " The next challenge was an interesting one, as every challenge, because it was about design and design opinion.", "tokens": [50414, 440, 958, 3430, 390, 364, 1880, 472, 11, 382, 633, 3430, 11, 570, 309, 390, 466, 1715, 293, 1715, 4800, 13, 50864], "temperature": 0.0, "avg_logprob": -0.1120387760560904, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.03745117783546448}, {"id": 385, "seek": 148200, "start": 1492.0, "end": 1498.0, "text": " And there's no truth, there's no strong truth in design opinion.", "tokens": [50864, 400, 456, 311, 572, 3494, 11, 456, 311, 572, 2068, 3494, 294, 1715, 4800, 13, 51164], "temperature": 0.0, "avg_logprob": -0.1120387760560904, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.03745117783546448}, {"id": 386, "seek": 148200, "start": 1498.0, "end": 1500.0, "text": " So what was the challenge exactly?", "tokens": [51164, 407, 437, 390, 264, 3430, 2293, 30, 51264], "temperature": 0.0, "avg_logprob": -0.1120387760560904, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.03745117783546448}, {"id": 387, "seek": 148200, "start": 1500.0, "end": 1508.0, "text": " The challenge was that we realized we were not using dry containers properly.", "tokens": [51264, 440, 3430, 390, 300, 321, 5334, 321, 645, 406, 1228, 4016, 17089, 6108, 13, 51664], "temperature": 0.0, "avg_logprob": -0.1120387760560904, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.03745117783546448}, {"id": 388, "seek": 150800, "start": 1508.0, "end": 1512.0, "text": " It felt like we were supposed to use it in a new way.", "tokens": [50364, 467, 2762, 411, 321, 645, 3442, 281, 764, 309, 294, 257, 777, 636, 13, 50564], "temperature": 0.0, "avg_logprob": -0.060250745303388954, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.008536786772310734}, {"id": 389, "seek": 150800, "start": 1512.0, "end": 1514.0, "text": " Why was that?", "tokens": [50564, 1545, 390, 300, 30, 50664], "temperature": 0.0, "avg_logprob": -0.060250745303388954, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.008536786772310734}, {"id": 390, "seek": 150800, "start": 1516.0, "end": 1522.0, "text": " The reason was that we are very used to object-oriented design, object-oriented programming,", "tokens": [50764, 440, 1778, 390, 300, 321, 366, 588, 1143, 281, 2657, 12, 27414, 1715, 11, 2657, 12, 27414, 9410, 11, 51064], "temperature": 0.0, "avg_logprob": -0.060250745303388954, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.008536786772310734}, {"id": 391, "seek": 150800, "start": 1522.0, "end": 1530.0, "text": " which means we are putting together state and behavior in small objects, and they are responsible for doing that stuff.", "tokens": [51064, 597, 1355, 321, 366, 3372, 1214, 1785, 293, 5223, 294, 1359, 6565, 11, 293, 436, 366, 6250, 337, 884, 300, 1507, 13, 51464], "temperature": 0.0, "avg_logprob": -0.060250745303388954, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.008536786772310734}, {"id": 392, "seek": 153000, "start": 1531.0, "end": 1537.0, "text": " And the dry system, the dry container, was pushing us to use stateless objects,", "tokens": [50414, 400, 264, 4016, 1185, 11, 264, 4016, 10129, 11, 390, 7380, 505, 281, 764, 2219, 4272, 6565, 11, 50714], "temperature": 0.0, "avg_logprob": -0.11499962983308015, "compression_ratio": 1.5577889447236182, "no_speech_prob": 0.04568297788500786}, {"id": 393, "seek": 153000, "start": 1537.0, "end": 1542.0, "text": " because that's what you could enjoy if you want to inject something everywhere.", "tokens": [50714, 570, 300, 311, 437, 291, 727, 2103, 498, 291, 528, 281, 10711, 746, 5315, 13, 50964], "temperature": 0.0, "avg_logprob": -0.11499962983308015, "compression_ratio": 1.5577889447236182, "no_speech_prob": 0.04568297788500786}, {"id": 394, "seek": 153000, "start": 1542.0, "end": 1544.0, "text": " It better be stateless.", "tokens": [50964, 467, 1101, 312, 2219, 4272, 13, 51064], "temperature": 0.0, "avg_logprob": -0.11499962983308015, "compression_ratio": 1.5577889447236182, "no_speech_prob": 0.04568297788500786}, {"id": 395, "seek": 153000, "start": 1544.0, "end": 1549.0, "text": " But the code we wanted to write, because we have a lot of experience with that, was stateful.", "tokens": [51064, 583, 264, 3089, 321, 1415, 281, 2464, 11, 570, 321, 362, 257, 688, 295, 1752, 365, 300, 11, 390, 1785, 906, 13, 51314], "temperature": 0.0, "avg_logprob": -0.11499962983308015, "compression_ratio": 1.5577889447236182, "no_speech_prob": 0.04568297788500786}, {"id": 396, "seek": 153000, "start": 1549.0, "end": 1554.0, "text": " We don't want a command wrapper.", "tokens": [51314, 492, 500, 380, 528, 257, 5622, 46906, 13, 51564], "temperature": 0.0, "avg_logprob": -0.11499962983308015, "compression_ratio": 1.5577889447236182, "no_speech_prob": 0.04568297788500786}, {"id": 397, "seek": 155400, "start": 1555.0, "end": 1561.0, "text": " We want a command execution specifically about this option.", "tokens": [50414, 492, 528, 257, 5622, 15058, 4682, 466, 341, 3614, 13, 50714], "temperature": 0.0, "avg_logprob": -0.10613169389612534, "compression_ratio": 1.6518987341772151, "no_speech_prob": 0.0302899070084095}, {"id": 398, "seek": 155400, "start": 1561.0, "end": 1564.0, "text": " We want to ask a specific invocation.", "tokens": [50714, 492, 528, 281, 1029, 257, 2685, 1048, 27943, 13, 50864], "temperature": 0.0, "avg_logprob": -0.10613169389612534, "compression_ratio": 1.6518987341772151, "no_speech_prob": 0.0302899070084095}, {"id": 399, "seek": 155400, "start": 1564.0, "end": 1566.0, "text": " We don't want the full program.", "tokens": [50864, 492, 500, 380, 528, 264, 1577, 1461, 13, 50964], "temperature": 0.0, "avg_logprob": -0.10613169389612534, "compression_ratio": 1.6518987341772151, "no_speech_prob": 0.0302899070084095}, {"id": 400, "seek": 155400, "start": 1566.0, "end": 1571.0, "text": " So it was very important to be able to write the code that we wanted to write,", "tokens": [50964, 407, 309, 390, 588, 1021, 281, 312, 1075, 281, 2464, 264, 3089, 300, 321, 1415, 281, 2464, 11, 51214], "temperature": 0.0, "avg_logprob": -0.10613169389612534, "compression_ratio": 1.6518987341772151, "no_speech_prob": 0.0302899070084095}, {"id": 401, "seek": 155400, "start": 1571.0, "end": 1575.0, "text": " but it was also important to use the tools properly.", "tokens": [51214, 457, 309, 390, 611, 1021, 281, 764, 264, 3873, 6108, 13, 51414], "temperature": 0.0, "avg_logprob": -0.10613169389612534, "compression_ratio": 1.6518987341772151, "no_speech_prob": 0.0302899070084095}, {"id": 402, "seek": 157500, "start": 1576.0, "end": 1581.0, "text": " And initially what we did is we had that big interactor, or big entry point,", "tokens": [50414, 400, 9105, 437, 321, 630, 307, 321, 632, 300, 955, 4648, 284, 11, 420, 955, 8729, 935, 11, 50664], "temperature": 0.0, "avg_logprob": -0.1509945240426571, "compression_ratio": 1.8507462686567164, "no_speech_prob": 0.022001922130584717}, {"id": 403, "seek": 157500, "start": 1581.0, "end": 1586.0, "text": " get injected with a ton of stuff from the container.", "tokens": [50664, 483, 36967, 365, 257, 2952, 295, 1507, 490, 264, 10129, 13, 50914], "temperature": 0.0, "avg_logprob": -0.1509945240426571, "compression_ratio": 1.8507462686567164, "no_speech_prob": 0.022001922130584717}, {"id": 404, "seek": 157500, "start": 1586.0, "end": 1589.0, "text": " It was getting all the services that it would eventually use,", "tokens": [50914, 467, 390, 1242, 439, 264, 3328, 300, 309, 576, 4728, 764, 11, 51064], "temperature": 0.0, "avg_logprob": -0.1509945240426571, "compression_ratio": 1.8507462686567164, "no_speech_prob": 0.022001922130584717}, {"id": 405, "seek": 157500, "start": 1589.0, "end": 1594.0, "text": " and that interactor was instantiating all the small objects,", "tokens": [51064, 293, 300, 4648, 284, 390, 9836, 72, 990, 439, 264, 1359, 6565, 11, 51314], "temperature": 0.0, "avg_logprob": -0.1509945240426571, "compression_ratio": 1.8507462686567164, "no_speech_prob": 0.022001922130584717}, {"id": 406, "seek": 157500, "start": 1594.0, "end": 1597.0, "text": " the small life cycle objects that it was going to use,", "tokens": [51314, 264, 1359, 993, 6586, 6565, 300, 309, 390, 516, 281, 764, 11, 51464], "temperature": 0.0, "avg_logprob": -0.1509945240426571, "compression_ratio": 1.8507462686567164, "no_speech_prob": 0.022001922130584717}, {"id": 407, "seek": 157500, "start": 1597.0, "end": 1601.0, "text": " and it was instantiating those objects, giving them their state,", "tokens": [51464, 293, 309, 390, 9836, 72, 990, 729, 6565, 11, 2902, 552, 641, 1785, 11, 51664], "temperature": 0.0, "avg_logprob": -0.1509945240426571, "compression_ratio": 1.8507462686567164, "no_speech_prob": 0.022001922130584717}, {"id": 408, "seek": 160100, "start": 1601.0, "end": 1605.0, "text": " so maybe the current date, the current user, the current payload,", "tokens": [50364, 370, 1310, 264, 2190, 4002, 11, 264, 2190, 4195, 11, 264, 2190, 30918, 11, 50564], "temperature": 0.0, "avg_logprob": -0.09994046041898638, "compression_ratio": 1.742081447963801, "no_speech_prob": 0.005494287703186274}, {"id": 409, "seek": 160100, "start": 1605.0, "end": 1608.0, "text": " and all the dependencies that the objects needed.", "tokens": [50564, 293, 439, 264, 36606, 300, 264, 6565, 2978, 13, 50714], "temperature": 0.0, "avg_logprob": -0.09994046041898638, "compression_ratio": 1.742081447963801, "no_speech_prob": 0.005494287703186274}, {"id": 410, "seek": 160100, "start": 1608.0, "end": 1611.0, "text": " So maybe there's a command service, maybe there's an API client,", "tokens": [50714, 407, 1310, 456, 311, 257, 5622, 2643, 11, 1310, 456, 311, 364, 9362, 6423, 11, 50864], "temperature": 0.0, "avg_logprob": -0.09994046041898638, "compression_ratio": 1.742081447963801, "no_speech_prob": 0.005494287703186274}, {"id": 411, "seek": 160100, "start": 1611.0, "end": 1614.0, "text": " so the interactor was instantiating all of that,", "tokens": [50864, 370, 264, 4648, 284, 390, 9836, 72, 990, 439, 295, 300, 11, 51014], "temperature": 0.0, "avg_logprob": -0.09994046041898638, "compression_ratio": 1.742081447963801, "no_speech_prob": 0.005494287703186274}, {"id": 412, "seek": 160100, "start": 1614.0, "end": 1619.0, "text": " which means the interactor knew about almost everything.", "tokens": [51014, 597, 1355, 264, 4648, 284, 2586, 466, 1920, 1203, 13, 51264], "temperature": 0.0, "avg_logprob": -0.09994046041898638, "compression_ratio": 1.742081447963801, "no_speech_prob": 0.005494287703186274}, {"id": 413, "seek": 160100, "start": 1619.0, "end": 1621.0, "text": " There's a name for that.", "tokens": [51264, 821, 311, 257, 1315, 337, 300, 13, 51364], "temperature": 0.0, "avg_logprob": -0.09994046041898638, "compression_ratio": 1.742081447963801, "no_speech_prob": 0.005494287703186274}, {"id": 414, "seek": 160100, "start": 1621.0, "end": 1622.0, "text": " GodObject.", "tokens": [51364, 1265, 45483, 1020, 13, 51414], "temperature": 0.0, "avg_logprob": -0.09994046041898638, "compression_ratio": 1.742081447963801, "no_speech_prob": 0.005494287703186274}, {"id": 415, "seek": 160100, "start": 1622.0, "end": 1624.0, "text": " And it's a bad name.", "tokens": [51414, 400, 309, 311, 257, 1578, 1315, 13, 51514], "temperature": 0.0, "avg_logprob": -0.09994046041898638, "compression_ratio": 1.742081447963801, "no_speech_prob": 0.005494287703186274}, {"id": 416, "seek": 160100, "start": 1624.0, "end": 1627.0, "text": " So we knew we were doing something wrong.", "tokens": [51514, 407, 321, 2586, 321, 645, 884, 746, 2085, 13, 51664], "temperature": 0.0, "avg_logprob": -0.09994046041898638, "compression_ratio": 1.742081447963801, "no_speech_prob": 0.005494287703186274}, {"id": 417, "seek": 162700, "start": 1627.0, "end": 1632.0, "text": " We had a small discussion, and we realized that actually the literature", "tokens": [50364, 492, 632, 257, 1359, 5017, 11, 293, 321, 5334, 300, 767, 264, 10394, 50614], "temperature": 0.0, "avg_logprob": -0.09311902004739513, "compression_ratio": 1.825242718446602, "no_speech_prob": 0.006684060674160719}, {"id": 418, "seek": 162700, "start": 1632.0, "end": 1634.0, "text": " again had a solution made for that.", "tokens": [50614, 797, 632, 257, 3827, 1027, 337, 300, 13, 50714], "temperature": 0.0, "avg_logprob": -0.09311902004739513, "compression_ratio": 1.825242718446602, "no_speech_prob": 0.006684060674160719}, {"id": 419, "seek": 162700, "start": 1634.0, "end": 1636.0, "text": " There's a pattern made for that.", "tokens": [50714, 821, 311, 257, 5102, 1027, 337, 300, 13, 50814], "temperature": 0.0, "avg_logprob": -0.09311902004739513, "compression_ratio": 1.825242718446602, "no_speech_prob": 0.006684060674160719}, {"id": 420, "seek": 162700, "start": 1636.0, "end": 1638.0, "text": " The pattern is factory.", "tokens": [50814, 440, 5102, 307, 9265, 13, 50914], "temperature": 0.0, "avg_logprob": -0.09311902004739513, "compression_ratio": 1.825242718446602, "no_speech_prob": 0.006684060674160719}, {"id": 421, "seek": 162700, "start": 1638.0, "end": 1643.0, "text": " So what we eventually did is that we created new services, factories,", "tokens": [50914, 407, 437, 321, 4728, 630, 307, 300, 321, 2942, 777, 3328, 11, 24813, 11, 51164], "temperature": 0.0, "avg_logprob": -0.09311902004739513, "compression_ratio": 1.825242718446602, "no_speech_prob": 0.006684060674160719}, {"id": 422, "seek": 162700, "start": 1643.0, "end": 1645.0, "text": " very shallow services.", "tokens": [51164, 588, 20488, 3328, 13, 51264], "temperature": 0.0, "avg_logprob": -0.09311902004739513, "compression_ratio": 1.825242718446602, "no_speech_prob": 0.006684060674160719}, {"id": 423, "seek": 162700, "start": 1645.0, "end": 1650.0, "text": " Each factory was injected with the services that it needed,", "tokens": [51264, 6947, 9265, 390, 36967, 365, 264, 3328, 300, 309, 2978, 11, 51514], "temperature": 0.0, "avg_logprob": -0.09311902004739513, "compression_ratio": 1.825242718446602, "no_speech_prob": 0.006684060674160719}, {"id": 424, "seek": 162700, "start": 1650.0, "end": 1654.0, "text": " and the interactor was simply injected with the factories,", "tokens": [51514, 293, 264, 4648, 284, 390, 2935, 36967, 365, 264, 24813, 11, 51714], "temperature": 0.0, "avg_logprob": -0.09311902004739513, "compression_ratio": 1.825242718446602, "no_speech_prob": 0.006684060674160719}, {"id": 425, "seek": 165400, "start": 1654.0, "end": 1656.0, "text": " and the interactor was just asking the factory,", "tokens": [50364, 293, 264, 4648, 284, 390, 445, 3365, 264, 9265, 11, 50464], "temperature": 0.0, "avg_logprob": -0.11708663345931412, "compression_ratio": 1.5851063829787233, "no_speech_prob": 0.007545000873506069}, {"id": 426, "seek": 165400, "start": 1656.0, "end": 1662.0, "text": " well, give me a command invocation specifically about this file,", "tokens": [50464, 731, 11, 976, 385, 257, 5622, 1048, 27943, 4682, 466, 341, 3991, 11, 50764], "temperature": 0.0, "avg_logprob": -0.11708663345931412, "compression_ratio": 1.5851063829787233, "no_speech_prob": 0.007545000873506069}, {"id": 427, "seek": 165400, "start": 1662.0, "end": 1667.0, "text": " about this API, about this payload.", "tokens": [50764, 466, 341, 9362, 11, 466, 341, 30918, 13, 51014], "temperature": 0.0, "avg_logprob": -0.11708663345931412, "compression_ratio": 1.5851063829787233, "no_speech_prob": 0.007545000873506069}, {"id": 428, "seek": 165400, "start": 1667.0, "end": 1673.0, "text": " And it's not a fun because it was so difficult to realize at first that we needed that,", "tokens": [51014, 400, 309, 311, 406, 257, 1019, 570, 309, 390, 370, 2252, 281, 4325, 412, 700, 300, 321, 2978, 300, 11, 51314], "temperature": 0.0, "avg_logprob": -0.11708663345931412, "compression_ratio": 1.5851063829787233, "no_speech_prob": 0.007545000873506069}, {"id": 429, "seek": 165400, "start": 1673.0, "end": 1678.0, "text": " but at the same time it was so obvious what was the solution.", "tokens": [51314, 457, 412, 264, 912, 565, 309, 390, 370, 6322, 437, 390, 264, 3827, 13, 51564], "temperature": 0.0, "avg_logprob": -0.11708663345931412, "compression_ratio": 1.5851063829787233, "no_speech_prob": 0.007545000873506069}, {"id": 430, "seek": 167800, "start": 1678.0, "end": 1684.0, "text": " It also raised an interesting comparison with a former colleague of mine", "tokens": [50364, 467, 611, 6005, 364, 1880, 9660, 365, 257, 5819, 13532, 295, 3892, 50664], "temperature": 0.0, "avg_logprob": -0.14653289794921875, "compression_ratio": 1.8152610441767068, "no_speech_prob": 0.014240512624382973}, {"id": 431, "seek": 167800, "start": 1684.0, "end": 1686.0, "text": " who told me he was like a functional programmer.", "tokens": [50664, 567, 1907, 385, 415, 390, 411, 257, 11745, 32116, 13, 50764], "temperature": 0.0, "avg_logprob": -0.14653289794921875, "compression_ratio": 1.8152610441767068, "no_speech_prob": 0.014240512624382973}, {"id": 432, "seek": 167800, "start": 1686.0, "end": 1692.0, "text": " He, I'm not going to say despised, but he despised object-oriented programming.", "tokens": [50764, 634, 11, 286, 478, 406, 516, 281, 584, 4887, 2640, 11, 457, 415, 4887, 2640, 2657, 12, 27414, 9410, 13, 51064], "temperature": 0.0, "avg_logprob": -0.14653289794921875, "compression_ratio": 1.8152610441767068, "no_speech_prob": 0.014240512624382973}, {"id": 433, "seek": 167800, "start": 1692.0, "end": 1693.0, "text": " Well, I said it.", "tokens": [51064, 1042, 11, 286, 848, 309, 13, 51114], "temperature": 0.0, "avg_logprob": -0.14653289794921875, "compression_ratio": 1.8152610441767068, "no_speech_prob": 0.014240512624382973}, {"id": 434, "seek": 167800, "start": 1693.0, "end": 1698.0, "text": " And he told me, you know, an object is just a set of partially applied function.", "tokens": [51114, 400, 415, 1907, 385, 11, 291, 458, 11, 364, 2657, 307, 445, 257, 992, 295, 18886, 6456, 2445, 13, 51364], "temperature": 0.0, "avg_logprob": -0.14653289794921875, "compression_ratio": 1.8152610441767068, "no_speech_prob": 0.014240512624382973}, {"id": 435, "seek": 167800, "start": 1698.0, "end": 1702.0, "text": " He was very like this day in for like, oh, it's just a set of partially applied function.", "tokens": [51364, 634, 390, 588, 411, 341, 786, 294, 337, 411, 11, 1954, 11, 309, 311, 445, 257, 992, 295, 18886, 6456, 2445, 13, 51564], "temperature": 0.0, "avg_logprob": -0.14653289794921875, "compression_ratio": 1.8152610441767068, "no_speech_prob": 0.014240512624382973}, {"id": 436, "seek": 167800, "start": 1702.0, "end": 1704.0, "text": " We have like, we have object at home.", "tokens": [51564, 492, 362, 411, 11, 321, 362, 2657, 412, 1280, 13, 51664], "temperature": 0.0, "avg_logprob": -0.14653289794921875, "compression_ratio": 1.8152610441767068, "no_speech_prob": 0.014240512624382973}, {"id": 437, "seek": 167800, "start": 1704.0, "end": 1706.0, "text": " Well, it's not the same.", "tokens": [51664, 1042, 11, 309, 311, 406, 264, 912, 13, 51764], "temperature": 0.0, "avg_logprob": -0.14653289794921875, "compression_ratio": 1.8152610441767068, "no_speech_prob": 0.014240512624382973}, {"id": 438, "seek": 170600, "start": 1707.0, "end": 1711.0, "text": " But to be honest, like, introducing those factories gave me that feeling", "tokens": [50414, 583, 281, 312, 3245, 11, 411, 11, 15424, 729, 24813, 2729, 385, 300, 2633, 50614], "temperature": 0.0, "avg_logprob": -0.12975753739822743, "compression_ratio": 1.699530516431925, "no_speech_prob": 0.0031398956198245287}, {"id": 439, "seek": 170600, "start": 1711.0, "end": 1714.0, "text": " because we had like those functions.", "tokens": [50614, 570, 321, 632, 411, 729, 6828, 13, 50764], "temperature": 0.0, "avg_logprob": -0.12975753739822743, "compression_ratio": 1.699530516431925, "no_speech_prob": 0.0031398956198245287}, {"id": 440, "seek": 170600, "start": 1714.0, "end": 1718.0, "text": " We were partially applying all the dependencies.", "tokens": [50764, 492, 645, 18886, 9275, 439, 264, 36606, 13, 50964], "temperature": 0.0, "avg_logprob": -0.12975753739822743, "compression_ratio": 1.699530516431925, "no_speech_prob": 0.0031398956198245287}, {"id": 441, "seek": 170600, "start": 1718.0, "end": 1720.0, "text": " That's like first partial application,", "tokens": [50964, 663, 311, 411, 700, 14641, 3861, 11, 51064], "temperature": 0.0, "avg_logprob": -0.12975753739822743, "compression_ratio": 1.699530516431925, "no_speech_prob": 0.0031398956198245287}, {"id": 442, "seek": 170600, "start": 1720.0, "end": 1723.0, "text": " and then we were partially applying the state.", "tokens": [51064, 293, 550, 321, 645, 18886, 9275, 264, 1785, 13, 51214], "temperature": 0.0, "avg_logprob": -0.12975753739822743, "compression_ratio": 1.699530516431925, "no_speech_prob": 0.0031398956198245287}, {"id": 443, "seek": 170600, "start": 1723.0, "end": 1728.0, "text": " It also opened our mind about what is stateless, what is stateful.", "tokens": [51214, 467, 611, 5625, 527, 1575, 466, 437, 307, 2219, 4272, 11, 437, 307, 1785, 906, 13, 51464], "temperature": 0.0, "avg_logprob": -0.12975753739822743, "compression_ratio": 1.699530516431925, "no_speech_prob": 0.0031398956198245287}, {"id": 444, "seek": 170600, "start": 1728.0, "end": 1732.0, "text": " Usually state is like all your instance variables.", "tokens": [51464, 11419, 1785, 307, 411, 439, 428, 5197, 9102, 13, 51664], "temperature": 0.0, "avg_logprob": -0.12975753739822743, "compression_ratio": 1.699530516431925, "no_speech_prob": 0.0031398956198245287}, {"id": 445, "seek": 173200, "start": 1732.0, "end": 1734.0, "text": " It's not really true.", "tokens": [50364, 467, 311, 406, 534, 2074, 13, 50464], "temperature": 0.0, "avg_logprob": -0.10646405062832676, "compression_ratio": 1.6382978723404256, "no_speech_prob": 0.007529450114816427}, {"id": 446, "seek": 173200, "start": 1734.0, "end": 1736.0, "text": " You don't see things like this anymore.", "tokens": [50464, 509, 500, 380, 536, 721, 411, 341, 3602, 13, 50564], "temperature": 0.0, "avg_logprob": -0.10646405062832676, "compression_ratio": 1.6382978723404256, "no_speech_prob": 0.007529450114816427}, {"id": 447, "seek": 173200, "start": 1736.0, "end": 1742.0, "text": " Like your dependencies might still make you stateless.", "tokens": [50564, 1743, 428, 36606, 1062, 920, 652, 291, 2219, 4272, 13, 50864], "temperature": 0.0, "avg_logprob": -0.10646405062832676, "compression_ratio": 1.6382978723404256, "no_speech_prob": 0.007529450114816427}, {"id": 448, "seek": 173200, "start": 1742.0, "end": 1748.0, "text": " And your state is really what makes an object throwable.", "tokens": [50864, 400, 428, 1785, 307, 534, 437, 1669, 364, 2657, 3507, 712, 13, 51164], "temperature": 0.0, "avg_logprob": -0.10646405062832676, "compression_ratio": 1.6382978723404256, "no_speech_prob": 0.007529450114816427}, {"id": 449, "seek": 173200, "start": 1748.0, "end": 1752.0, "text": " So if it's a reusable object, it's stateless.", "tokens": [51164, 407, 498, 309, 311, 257, 41807, 2657, 11, 309, 311, 2219, 4272, 13, 51364], "temperature": 0.0, "avg_logprob": -0.10646405062832676, "compression_ratio": 1.6382978723404256, "no_speech_prob": 0.007529450114816427}, {"id": 450, "seek": 173200, "start": 1752.0, "end": 1755.0, "text": " If it's like a one-use object, it's stateful.", "tokens": [51364, 759, 309, 311, 411, 257, 472, 12, 438, 2657, 11, 309, 311, 1785, 906, 13, 51514], "temperature": 0.0, "avg_logprob": -0.10646405062832676, "compression_ratio": 1.6382978723404256, "no_speech_prob": 0.007529450114816427}, {"id": 451, "seek": 173200, "start": 1755.0, "end": 1757.0, "text": " That's sort of our new definition of that.", "tokens": [51514, 663, 311, 1333, 295, 527, 777, 7123, 295, 300, 13, 51614], "temperature": 0.0, "avg_logprob": -0.10646405062832676, "compression_ratio": 1.6382978723404256, "no_speech_prob": 0.007529450114816427}, {"id": 452, "seek": 175700, "start": 1757.0, "end": 1760.0, "text": " And factories helps us creating one-use object", "tokens": [50364, 400, 24813, 3665, 505, 4084, 472, 12, 438, 2657, 50514], "temperature": 0.0, "avg_logprob": -0.1568225281579154, "compression_ratio": 1.773109243697479, "no_speech_prob": 0.002695540664717555}, {"id": 453, "seek": 175700, "start": 1760.0, "end": 1764.0, "text": " because factories are all stateless object.", "tokens": [50514, 570, 24813, 366, 439, 2219, 4272, 2657, 13, 50714], "temperature": 0.0, "avg_logprob": -0.1568225281579154, "compression_ratio": 1.773109243697479, "no_speech_prob": 0.002695540664717555}, {"id": 454, "seek": 175700, "start": 1764.0, "end": 1768.0, "text": " Well, I felt bad creating the slide without mentioning a single dry gem.", "tokens": [50714, 1042, 11, 286, 2762, 1578, 4084, 264, 4137, 1553, 18315, 257, 2167, 4016, 7173, 13, 50914], "temperature": 0.0, "avg_logprob": -0.1568225281579154, "compression_ratio": 1.773109243697479, "no_speech_prob": 0.002695540664717555}, {"id": 455, "seek": 175700, "start": 1770.0, "end": 1776.0, "text": " So I also want to bring one here, is the dry initializer gem.", "tokens": [51014, 407, 286, 611, 528, 281, 1565, 472, 510, 11, 307, 264, 4016, 5883, 6545, 7173, 13, 51314], "temperature": 0.0, "avg_logprob": -0.1568225281579154, "compression_ratio": 1.773109243697479, "no_speech_prob": 0.002695540664717555}, {"id": 456, "seek": 175700, "start": 1776.0, "end": 1779.0, "text": " And to be honest, this is my favorite, and it's so small.", "tokens": [51314, 400, 281, 312, 3245, 11, 341, 307, 452, 2954, 11, 293, 309, 311, 370, 1359, 13, 51464], "temperature": 0.0, "avg_logprob": -0.1568225281579154, "compression_ratio": 1.773109243697479, "no_speech_prob": 0.002695540664717555}, {"id": 457, "seek": 175700, "start": 1779.0, "end": 1782.0, "text": " The thing is this is so small that it's crazy that this is my favorite gem.", "tokens": [51464, 440, 551, 307, 341, 307, 370, 1359, 300, 309, 311, 3219, 300, 341, 307, 452, 2954, 7173, 13, 51614], "temperature": 0.0, "avg_logprob": -0.1568225281579154, "compression_ratio": 1.773109243697479, "no_speech_prob": 0.002695540664717555}, {"id": 458, "seek": 175700, "start": 1782.0, "end": 1784.0, "text": " It creates contractors.", "tokens": [51614, 467, 7829, 28377, 13, 51714], "temperature": 0.0, "avg_logprob": -0.1568225281579154, "compression_ratio": 1.773109243697479, "no_speech_prob": 0.002695540664717555}, {"id": 459, "seek": 175700, "start": 1784.0, "end": 1786.0, "text": " It just creates an initialized method.", "tokens": [51714, 467, 445, 7829, 364, 5883, 1602, 3170, 13, 51814], "temperature": 0.0, "avg_logprob": -0.1568225281579154, "compression_ratio": 1.773109243697479, "no_speech_prob": 0.002695540664717555}, {"id": 460, "seek": 178600, "start": 1786.0, "end": 1788.0, "text": " But why does it matter?", "tokens": [50364, 583, 983, 775, 309, 1871, 30, 50464], "temperature": 0.0, "avg_logprob": -0.1010427474975586, "compression_ratio": 1.7, "no_speech_prob": 0.00417686440050602}, {"id": 461, "seek": 178600, "start": 1788.0, "end": 1791.0, "text": " Because if you are very strict about it,", "tokens": [50464, 1436, 498, 291, 366, 588, 10910, 466, 309, 11, 50614], "temperature": 0.0, "avg_logprob": -0.1010427474975586, "compression_ratio": 1.7, "no_speech_prob": 0.00417686440050602}, {"id": 462, "seek": 178600, "start": 1791.0, "end": 1795.0, "text": " all your initializer very probably look the same.", "tokens": [50614, 439, 428, 5883, 6545, 588, 1391, 574, 264, 912, 13, 50814], "temperature": 0.0, "avg_logprob": -0.1010427474975586, "compression_ratio": 1.7, "no_speech_prob": 0.00417686440050602}, {"id": 463, "seek": 178600, "start": 1795.0, "end": 1797.0, "text": " It's like you pass them arguments,", "tokens": [50814, 467, 311, 411, 291, 1320, 552, 12869, 11, 50914], "temperature": 0.0, "avg_logprob": -0.1010427474975586, "compression_ratio": 1.7, "no_speech_prob": 0.00417686440050602}, {"id": 464, "seek": 178600, "start": 1797.0, "end": 1800.0, "text": " and then you store them into instance variable.", "tokens": [50914, 293, 550, 291, 3531, 552, 666, 5197, 7006, 13, 51064], "temperature": 0.0, "avg_logprob": -0.1010427474975586, "compression_ratio": 1.7, "no_speech_prob": 0.00417686440050602}, {"id": 465, "seek": 178600, "start": 1800.0, "end": 1804.0, "text": " Nothing more because doing business in initializer is a bad idea.", "tokens": [51064, 6693, 544, 570, 884, 1606, 294, 5883, 6545, 307, 257, 1578, 1558, 13, 51264], "temperature": 0.0, "avg_logprob": -0.1010427474975586, "compression_ratio": 1.7, "no_speech_prob": 0.00417686440050602}, {"id": 466, "seek": 178600, "start": 1804.0, "end": 1807.0, "text": " So you always get the same initializer times and again,", "tokens": [51264, 407, 291, 1009, 483, 264, 912, 5883, 6545, 1413, 293, 797, 11, 51414], "temperature": 0.0, "avg_logprob": -0.1010427474975586, "compression_ratio": 1.7, "no_speech_prob": 0.00417686440050602}, {"id": 467, "seek": 178600, "start": 1807.0, "end": 1809.0, "text": " and it makes no sense, and it creates noise.", "tokens": [51414, 293, 309, 1669, 572, 2020, 11, 293, 309, 7829, 5658, 13, 51514], "temperature": 0.0, "avg_logprob": -0.1010427474975586, "compression_ratio": 1.7, "no_speech_prob": 0.00417686440050602}, {"id": 468, "seek": 178600, "start": 1809.0, "end": 1812.0, "text": " And if you're used to more style guides,", "tokens": [51514, 400, 498, 291, 434, 1143, 281, 544, 3758, 17007, 11, 51664], "temperature": 0.0, "avg_logprob": -0.1010427474975586, "compression_ratio": 1.7, "no_speech_prob": 0.00417686440050602}, {"id": 469, "seek": 178600, "start": 1812.0, "end": 1814.0, "text": " it has to be at the top of the file,", "tokens": [51664, 309, 575, 281, 312, 412, 264, 1192, 295, 264, 3991, 11, 51764], "temperature": 0.0, "avg_logprob": -0.1010427474975586, "compression_ratio": 1.7, "no_speech_prob": 0.00417686440050602}, {"id": 470, "seek": 181400, "start": 1814.0, "end": 1817.0, "text": " and it also takes a very important part, focus,", "tokens": [50364, 293, 309, 611, 2516, 257, 588, 1021, 644, 11, 1879, 11, 50514], "temperature": 0.0, "avg_logprob": -0.10737927498355988, "compression_ratio": 1.836, "no_speech_prob": 0.005171886179596186}, {"id": 471, "seek": 181400, "start": 1817.0, "end": 1819.0, "text": " because top of the file is very important.", "tokens": [50514, 570, 1192, 295, 264, 3991, 307, 588, 1021, 13, 50614], "temperature": 0.0, "avg_logprob": -0.10737927498355988, "compression_ratio": 1.836, "no_speech_prob": 0.005171886179596186}, {"id": 472, "seek": 181400, "start": 1819.0, "end": 1821.0, "text": " So dry initializer, just do that.", "tokens": [50614, 407, 4016, 5883, 6545, 11, 445, 360, 300, 13, 50714], "temperature": 0.0, "avg_logprob": -0.10737927498355988, "compression_ratio": 1.836, "no_speech_prob": 0.005171886179596186}, {"id": 473, "seek": 181400, "start": 1821.0, "end": 1828.0, "text": " It says you can create one line for each dependency or state that you want.", "tokens": [50714, 467, 1619, 291, 393, 1884, 472, 1622, 337, 1184, 33621, 420, 1785, 300, 291, 528, 13, 51064], "temperature": 0.0, "avg_logprob": -0.10737927498355988, "compression_ratio": 1.836, "no_speech_prob": 0.005171886179596186}, {"id": 474, "seek": 181400, "start": 1828.0, "end": 1830.0, "text": " You can give it a type. You don't have to,", "tokens": [51064, 509, 393, 976, 309, 257, 2010, 13, 509, 500, 380, 362, 281, 11, 51164], "temperature": 0.0, "avg_logprob": -0.10737927498355988, "compression_ratio": 1.836, "no_speech_prob": 0.005171886179596186}, {"id": 475, "seek": 181400, "start": 1830.0, "end": 1832.0, "text": " but if you have a drive type, you might want to.", "tokens": [51164, 457, 498, 291, 362, 257, 3332, 2010, 11, 291, 1062, 528, 281, 13, 51264], "temperature": 0.0, "avg_logprob": -0.10737927498355988, "compression_ratio": 1.836, "no_speech_prob": 0.005171886179596186}, {"id": 476, "seek": 181400, "start": 1832.0, "end": 1834.0, "text": " You can give it a default value,", "tokens": [51264, 509, 393, 976, 309, 257, 7576, 2158, 11, 51364], "temperature": 0.0, "avg_logprob": -0.10737927498355988, "compression_ratio": 1.836, "no_speech_prob": 0.005171886179596186}, {"id": 477, "seek": 181400, "start": 1834.0, "end": 1837.0, "text": " and you automatically get an initializer that accepts them,", "tokens": [51364, 293, 291, 6772, 483, 364, 5883, 6545, 300, 33538, 552, 11, 51514], "temperature": 0.0, "avg_logprob": -0.10737927498355988, "compression_ratio": 1.836, "no_speech_prob": 0.005171886179596186}, {"id": 478, "seek": 181400, "start": 1837.0, "end": 1842.0, "text": " and you automatically create an ATTR reader for each of the dependencies.", "tokens": [51514, 293, 291, 6772, 1884, 364, 8872, 25936, 15149, 337, 1184, 295, 264, 36606, 13, 51764], "temperature": 0.0, "avg_logprob": -0.10737927498355988, "compression_ratio": 1.836, "no_speech_prob": 0.005171886179596186}, {"id": 479, "seek": 184200, "start": 1842.0, "end": 1845.0, "text": " You don't want the reader. You don't have to, but by default, you get that.", "tokens": [50364, 509, 500, 380, 528, 264, 15149, 13, 509, 500, 380, 362, 281, 11, 457, 538, 7576, 11, 291, 483, 300, 13, 50514], "temperature": 0.0, "avg_logprob": -0.1418976181919135, "compression_ratio": 1.7255813953488373, "no_speech_prob": 0.008646680973470211}, {"id": 480, "seek": 184200, "start": 1845.0, "end": 1848.0, "text": " And that's it, and you just transform something very long and noisy", "tokens": [50514, 400, 300, 311, 309, 11, 293, 291, 445, 4088, 746, 588, 938, 293, 24518, 50664], "temperature": 0.0, "avg_logprob": -0.1418976181919135, "compression_ratio": 1.7255813953488373, "no_speech_prob": 0.008646680973470211}, {"id": 481, "seek": 184200, "start": 1848.0, "end": 1850.0, "text": " into a series of lines.", "tokens": [50664, 666, 257, 2638, 295, 3876, 13, 50764], "temperature": 0.0, "avg_logprob": -0.1418976181919135, "compression_ratio": 1.7255813953488373, "no_speech_prob": 0.008646680973470211}, {"id": 482, "seek": 184200, "start": 1853.0, "end": 1856.0, "text": " We used to have ATTR reader anyways.", "tokens": [50914, 492, 1143, 281, 362, 8872, 25936, 15149, 13448, 13, 51064], "temperature": 0.0, "avg_logprob": -0.1418976181919135, "compression_ratio": 1.7255813953488373, "no_speech_prob": 0.008646680973470211}, {"id": 483, "seek": 184200, "start": 1856.0, "end": 1861.0, "text": " That's most of our classes have ATTR, one line for ATTR reader anyways.", "tokens": [51064, 663, 311, 881, 295, 527, 5359, 362, 8872, 25936, 11, 472, 1622, 337, 8872, 25936, 15149, 13448, 13, 51314], "temperature": 0.0, "avg_logprob": -0.1418976181919135, "compression_ratio": 1.7255813953488373, "no_speech_prob": 0.008646680973470211}, {"id": 484, "seek": 184200, "start": 1861.0, "end": 1863.0, "text": " So it changed nothing in terms of noise.", "tokens": [51314, 407, 309, 3105, 1825, 294, 2115, 295, 5658, 13, 51414], "temperature": 0.0, "avg_logprob": -0.1418976181919135, "compression_ratio": 1.7255813953488373, "no_speech_prob": 0.008646680973470211}, {"id": 485, "seek": 184200, "start": 1863.0, "end": 1866.0, "text": " It changed everything in terms of clarity, intention,", "tokens": [51414, 467, 3105, 1203, 294, 2115, 295, 16992, 11, 7789, 11, 51564], "temperature": 0.0, "avg_logprob": -0.1418976181919135, "compression_ratio": 1.7255813953488373, "no_speech_prob": 0.008646680973470211}, {"id": 486, "seek": 186600, "start": 1866.0, "end": 1872.0, "text": " and anyone reading a file now gets something directly by reading those lines.", "tokens": [50364, 293, 2878, 3760, 257, 3991, 586, 2170, 746, 3838, 538, 3760, 729, 3876, 13, 50664], "temperature": 0.0, "avg_logprob": -0.12394508155616554, "compression_ratio": 1.712, "no_speech_prob": 0.008243889547884464}, {"id": 487, "seek": 186600, "start": 1872.0, "end": 1875.0, "text": " And yeah, I'm still on time.", "tokens": [50664, 400, 1338, 11, 286, 478, 920, 322, 565, 13, 50814], "temperature": 0.0, "avg_logprob": -0.12394508155616554, "compression_ratio": 1.712, "no_speech_prob": 0.008243889547884464}, {"id": 488, "seek": 186600, "start": 1875.0, "end": 1880.0, "text": " Well, we were done with the code application.", "tokens": [50814, 1042, 11, 321, 645, 1096, 365, 264, 3089, 3861, 13, 51064], "temperature": 0.0, "avg_logprob": -0.12394508155616554, "compression_ratio": 1.712, "no_speech_prob": 0.008243889547884464}, {"id": 489, "seek": 186600, "start": 1880.0, "end": 1883.0, "text": " Of course, we had additional challenges,", "tokens": [51064, 2720, 1164, 11, 321, 632, 4497, 4759, 11, 51214], "temperature": 0.0, "avg_logprob": -0.12394508155616554, "compression_ratio": 1.712, "no_speech_prob": 0.008243889547884464}, {"id": 490, "seek": 186600, "start": 1883.0, "end": 1886.0, "text": " but eventually using those tools and approaches,", "tokens": [51214, 457, 4728, 1228, 729, 3873, 293, 11587, 11, 51364], "temperature": 0.0, "avg_logprob": -0.12394508155616554, "compression_ratio": 1.712, "no_speech_prob": 0.008243889547884464}, {"id": 491, "seek": 186600, "start": 1886.0, "end": 1890.0, "text": " we reached up the end of the application, and we were done, right?", "tokens": [51364, 321, 6488, 493, 264, 917, 295, 264, 3861, 11, 293, 321, 645, 1096, 11, 558, 30, 51564], "temperature": 0.0, "avg_logprob": -0.12394508155616554, "compression_ratio": 1.712, "no_speech_prob": 0.008243889547884464}, {"id": 492, "seek": 186600, "start": 1890.0, "end": 1892.0, "text": " Well, no, we still had to package it.", "tokens": [51564, 1042, 11, 572, 11, 321, 920, 632, 281, 7372, 309, 13, 51664], "temperature": 0.0, "avg_logprob": -0.12394508155616554, "compression_ratio": 1.712, "no_speech_prob": 0.008243889547884464}, {"id": 493, "seek": 186600, "start": 1892.0, "end": 1895.0, "text": " We still had to deploy it, because as long as we were actually solving problems,", "tokens": [51664, 492, 920, 632, 281, 7274, 309, 11, 570, 382, 938, 382, 321, 645, 767, 12606, 2740, 11, 51814], "temperature": 0.0, "avg_logprob": -0.12394508155616554, "compression_ratio": 1.712, "no_speech_prob": 0.008243889547884464}, {"id": 494, "seek": 189500, "start": 1895.0, "end": 1897.0, "text": " we had nothing.", "tokens": [50364, 321, 632, 1825, 13, 50464], "temperature": 0.0, "avg_logprob": -0.12358271345800283, "compression_ratio": 1.5569620253164558, "no_speech_prob": 0.007067325059324503}, {"id": 495, "seek": 189500, "start": 1897.0, "end": 1902.0, "text": " This is again a time when we realized how rich is the Rails ecosystem,", "tokens": [50464, 639, 307, 797, 257, 565, 562, 321, 5334, 577, 4593, 307, 264, 48526, 11311, 11, 50714], "temperature": 0.0, "avg_logprob": -0.12358271345800283, "compression_ratio": 1.5569620253164558, "no_speech_prob": 0.007067325059324503}, {"id": 496, "seek": 189500, "start": 1902.0, "end": 1908.0, "text": " because for deployment, you either get services like Heroku or similar services,", "tokens": [50714, 570, 337, 19317, 11, 291, 2139, 483, 3328, 411, 3204, 13275, 420, 2531, 3328, 11, 51014], "temperature": 0.0, "avg_logprob": -0.12358271345800283, "compression_ratio": 1.5569620253164558, "no_speech_prob": 0.007067325059324503}, {"id": 497, "seek": 189500, "start": 1908.0, "end": 1913.0, "text": " or using Capistrano, which does everything for you.", "tokens": [51014, 420, 1228, 8363, 468, 81, 3730, 11, 597, 775, 1203, 337, 291, 13, 51264], "temperature": 0.0, "avg_logprob": -0.12358271345800283, "compression_ratio": 1.5569620253164558, "no_speech_prob": 0.007067325059324503}, {"id": 498, "seek": 189500, "start": 1913.0, "end": 1916.0, "text": " You write one CAP file and everything is magic.", "tokens": [51264, 509, 2464, 472, 33636, 3991, 293, 1203, 307, 5585, 13, 51414], "temperature": 0.0, "avg_logprob": -0.12358271345800283, "compression_ratio": 1.5569620253164558, "no_speech_prob": 0.007067325059324503}, {"id": 499, "seek": 189500, "start": 1916.0, "end": 1921.0, "text": " When we had to deploy, we were like, yeah, we have files with code,", "tokens": [51414, 1133, 321, 632, 281, 7274, 11, 321, 645, 411, 11, 1338, 11, 321, 362, 7098, 365, 3089, 11, 51664], "temperature": 0.0, "avg_logprob": -0.12358271345800283, "compression_ratio": 1.5569620253164558, "no_speech_prob": 0.007067325059324503}, {"id": 500, "seek": 189500, "start": 1921.0, "end": 1924.0, "text": " but we still have no application.", "tokens": [51664, 457, 321, 920, 362, 572, 3861, 13, 51814], "temperature": 0.0, "avg_logprob": -0.12358271345800283, "compression_ratio": 1.5569620253164558, "no_speech_prob": 0.007067325059324503}, {"id": 501, "seek": 192400, "start": 1924.0, "end": 1928.0, "text": " So we get some help from partners about that.", "tokens": [50364, 407, 321, 483, 512, 854, 490, 4462, 466, 300, 13, 50564], "temperature": 0.0, "avg_logprob": -0.08818411340518874, "compression_ratio": 1.6127659574468085, "no_speech_prob": 0.0014889505691826344}, {"id": 502, "seek": 192400, "start": 1928.0, "end": 1931.0, "text": " We use Docker Compose locally for creating containers.", "tokens": [50564, 492, 764, 33772, 6620, 541, 16143, 337, 4084, 17089, 13, 50714], "temperature": 0.0, "avg_logprob": -0.08818411340518874, "compression_ratio": 1.6127659574468085, "no_speech_prob": 0.0014889505691826344}, {"id": 503, "seek": 192400, "start": 1931.0, "end": 1934.0, "text": " We use Kubernetes remotely for deploying them.", "tokens": [50714, 492, 764, 23145, 20824, 337, 34198, 552, 13, 50864], "temperature": 0.0, "avg_logprob": -0.08818411340518874, "compression_ratio": 1.6127659574468085, "no_speech_prob": 0.0014889505691826344}, {"id": 504, "seek": 192400, "start": 1934.0, "end": 1937.0, "text": " We use Helm for actually doing the deployment.", "tokens": [50864, 492, 764, 6128, 76, 337, 767, 884, 264, 19317, 13, 51014], "temperature": 0.0, "avg_logprob": -0.08818411340518874, "compression_ratio": 1.6127659574468085, "no_speech_prob": 0.0014889505691826344}, {"id": 505, "seek": 192400, "start": 1937.0, "end": 1940.0, "text": " And this led us to realize that we still had problems,", "tokens": [51014, 400, 341, 4684, 505, 281, 4325, 300, 321, 920, 632, 2740, 11, 51164], "temperature": 0.0, "avg_logprob": -0.08818411340518874, "compression_ratio": 1.6127659574468085, "no_speech_prob": 0.0014889505691826344}, {"id": 506, "seek": 192400, "start": 1940.0, "end": 1943.0, "text": " because we had no observability.", "tokens": [51164, 570, 321, 632, 572, 9951, 2310, 13, 51314], "temperature": 0.0, "avg_logprob": -0.08818411340518874, "compression_ratio": 1.6127659574468085, "no_speech_prob": 0.0014889505691826344}, {"id": 507, "seek": 192400, "start": 1943.0, "end": 1947.0, "text": " We had very difficult access to the log files,", "tokens": [51314, 492, 632, 588, 2252, 2105, 281, 264, 3565, 7098, 11, 51514], "temperature": 0.0, "avg_logprob": -0.08818411340518874, "compression_ratio": 1.6127659574468085, "no_speech_prob": 0.0014889505691826344}, {"id": 508, "seek": 192400, "start": 1947.0, "end": 1953.0, "text": " so there was still a lot of stuff we didn't have.", "tokens": [51514, 370, 456, 390, 920, 257, 688, 295, 1507, 321, 994, 380, 362, 13, 51814], "temperature": 0.0, "avg_logprob": -0.08818411340518874, "compression_ratio": 1.6127659574468085, "no_speech_prob": 0.0014889505691826344}, {"id": 509, "seek": 195300, "start": 1953.0, "end": 1957.0, "text": " So what we did is we introduced Yabbaida from Evil Martian.", "tokens": [50364, 407, 437, 321, 630, 307, 321, 7268, 398, 455, 4231, 2887, 490, 20528, 5807, 952, 13, 50564], "temperature": 0.0, "avg_logprob": -0.11485819897409212, "compression_ratio": 1.7708333333333333, "no_speech_prob": 0.008345690555870533}, {"id": 510, "seek": 195300, "start": 1957.0, "end": 1960.0, "text": " I don't know if anybody is from Evil Martian here,", "tokens": [50564, 286, 500, 380, 458, 498, 4472, 307, 490, 20528, 5807, 952, 510, 11, 50714], "temperature": 0.0, "avg_logprob": -0.11485819897409212, "compression_ratio": 1.7708333333333333, "no_speech_prob": 0.008345690555870533}, {"id": 511, "seek": 195300, "start": 1960.0, "end": 1966.0, "text": " but if you are and if you watch us, like, thank you, you're awesome Evil Martian.", "tokens": [50714, 457, 498, 291, 366, 293, 498, 291, 1159, 505, 11, 411, 11, 1309, 291, 11, 291, 434, 3476, 20528, 5807, 952, 13, 51014], "temperature": 0.0, "avg_logprob": -0.11485819897409212, "compression_ratio": 1.7708333333333333, "no_speech_prob": 0.008345690555870533}, {"id": 512, "seek": 195300, "start": 1966.0, "end": 1970.0, "text": " So we used Yabbaida, which is an observability framework.", "tokens": [51014, 407, 321, 1143, 398, 455, 4231, 2887, 11, 597, 307, 364, 9951, 2310, 8388, 13, 51214], "temperature": 0.0, "avg_logprob": -0.11485819897409212, "compression_ratio": 1.7708333333333333, "no_speech_prob": 0.008345690555870533}, {"id": 513, "seek": 195300, "start": 1970.0, "end": 1975.0, "text": " It allows you to mention what you want to observe, create metrics,", "tokens": [51214, 467, 4045, 291, 281, 2152, 437, 291, 528, 281, 11441, 11, 1884, 16367, 11, 51464], "temperature": 0.0, "avg_logprob": -0.11485819897409212, "compression_ratio": 1.7708333333333333, "no_speech_prob": 0.008345690555870533}, {"id": 514, "seek": 195300, "start": 1975.0, "end": 1978.0, "text": " without having to care like where you intend to put those metrics,", "tokens": [51464, 1553, 1419, 281, 1127, 411, 689, 291, 19759, 281, 829, 729, 16367, 11, 51614], "temperature": 0.0, "avg_logprob": -0.11485819897409212, "compression_ratio": 1.7708333333333333, "no_speech_prob": 0.008345690555870533}, {"id": 515, "seek": 195300, "start": 1978.0, "end": 1980.0, "text": " what we intend to do with those metrics.", "tokens": [51614, 437, 321, 19759, 281, 360, 365, 729, 16367, 13, 51714], "temperature": 0.0, "avg_logprob": -0.11485819897409212, "compression_ratio": 1.7708333333333333, "no_speech_prob": 0.008345690555870533}, {"id": 516, "seek": 198000, "start": 1980.0, "end": 1983.0, "text": " And then another part of Yabbaida, you can mention, like,", "tokens": [50364, 400, 550, 1071, 644, 295, 398, 455, 4231, 2887, 11, 291, 393, 2152, 11, 411, 11, 50514], "temperature": 0.0, "avg_logprob": -0.14473159033972938, "compression_ratio": 1.603846153846154, "no_speech_prob": 0.0031685936264693737}, {"id": 517, "seek": 198000, "start": 1983.0, "end": 1984.0, "text": " actually what you want to do.", "tokens": [50514, 767, 437, 291, 528, 281, 360, 13, 50564], "temperature": 0.0, "avg_logprob": -0.14473159033972938, "compression_ratio": 1.603846153846154, "no_speech_prob": 0.0031685936264693737}, {"id": 518, "seek": 198000, "start": 1984.0, "end": 1985.0, "text": " You can separate the two.", "tokens": [50564, 509, 393, 4994, 264, 732, 13, 50614], "temperature": 0.0, "avg_logprob": -0.14473159033972938, "compression_ratio": 1.603846153846154, "no_speech_prob": 0.0031685936264693737}, {"id": 519, "seek": 198000, "start": 1985.0, "end": 1991.0, "text": " So your business logic is not riddled with, like, technical details about monitoring.", "tokens": [50614, 407, 428, 1606, 9952, 307, 406, 3973, 43130, 365, 11, 411, 11, 6191, 4365, 466, 11028, 13, 50914], "temperature": 0.0, "avg_logprob": -0.14473159033972938, "compression_ratio": 1.603846153846154, "no_speech_prob": 0.0031685936264693737}, {"id": 520, "seek": 198000, "start": 1991.0, "end": 1996.0, "text": " So this observability allows us to expose some metrics,", "tokens": [50914, 407, 341, 9951, 2310, 4045, 505, 281, 19219, 512, 16367, 11, 51164], "temperature": 0.0, "avg_logprob": -0.14473159033972938, "compression_ratio": 1.603846153846154, "no_speech_prob": 0.0031685936264693737}, {"id": 521, "seek": 198000, "start": 1996.0, "end": 2000.0, "text": " which in turn enabled us to create autoscaling to measure health.", "tokens": [51164, 597, 294, 1261, 15172, 505, 281, 1884, 1476, 10466, 4270, 281, 3481, 1585, 13, 51364], "temperature": 0.0, "avg_logprob": -0.14473159033972938, "compression_ratio": 1.603846153846154, "no_speech_prob": 0.0031685936264693737}, {"id": 522, "seek": 198000, "start": 2000.0, "end": 2003.0, "text": " So these are typically stuff that you get for free in Rails", "tokens": [51364, 407, 613, 366, 5850, 1507, 300, 291, 483, 337, 1737, 294, 48526, 51514], "temperature": 0.0, "avg_logprob": -0.14473159033972938, "compression_ratio": 1.603846153846154, "no_speech_prob": 0.0031685936264693737}, {"id": 523, "seek": 198000, "start": 2003.0, "end": 2006.0, "text": " if you're using your relic or data.", "tokens": [51514, 498, 291, 434, 1228, 428, 1039, 299, 420, 1412, 13, 51664], "temperature": 0.0, "avg_logprob": -0.14473159033972938, "compression_ratio": 1.603846153846154, "no_speech_prob": 0.0031685936264693737}, {"id": 524, "seek": 200600, "start": 2006.0, "end": 2011.0, "text": " But we had to do it by hand.", "tokens": [50364, 583, 321, 632, 281, 360, 309, 538, 1011, 13, 50614], "temperature": 0.0, "avg_logprob": -0.15362035036087035, "compression_ratio": 1.49746192893401, "no_speech_prob": 0.054720375686883926}, {"id": 525, "seek": 200600, "start": 2011.0, "end": 2015.0, "text": " And we finally reached our latest challenge,", "tokens": [50614, 400, 321, 2721, 6488, 527, 6792, 3430, 11, 50814], "temperature": 0.0, "avg_logprob": -0.15362035036087035, "compression_ratio": 1.49746192893401, "no_speech_prob": 0.054720375686883926}, {"id": 526, "seek": 200600, "start": 2015.0, "end": 2019.0, "text": " because we are not experts in Helm or Kubernetes.", "tokens": [50814, 570, 321, 366, 406, 8572, 294, 6128, 76, 420, 23145, 13, 51014], "temperature": 0.0, "avg_logprob": -0.15362035036087035, "compression_ratio": 1.49746192893401, "no_speech_prob": 0.054720375686883926}, {"id": 527, "seek": 200600, "start": 2019.0, "end": 2022.0, "text": " We are actually very noob in that.", "tokens": [51014, 492, 366, 767, 588, 572, 996, 294, 300, 13, 51164], "temperature": 0.0, "avg_logprob": -0.15362035036087035, "compression_ratio": 1.49746192893401, "no_speech_prob": 0.054720375686883926}, {"id": 528, "seek": 200600, "start": 2022.0, "end": 2024.0, "text": " So we had partners helping us.", "tokens": [51164, 407, 321, 632, 4462, 4315, 505, 13, 51264], "temperature": 0.0, "avg_logprob": -0.15362035036087035, "compression_ratio": 1.49746192893401, "no_speech_prob": 0.054720375686883926}, {"id": 529, "seek": 200600, "start": 2024.0, "end": 2029.0, "text": " But those partners are also responsible for, like, running and ensuring that", "tokens": [51264, 583, 729, 4462, 366, 611, 6250, 337, 11, 411, 11, 2614, 293, 16882, 300, 51514], "temperature": 0.0, "avg_logprob": -0.15362035036087035, "compression_ratio": 1.49746192893401, "no_speech_prob": 0.054720375686883926}, {"id": 530, "seek": 200600, "start": 2029.0, "end": 2031.0, "text": " our app is working properly.", "tokens": [51514, 527, 724, 307, 1364, 6108, 13, 51614], "temperature": 0.0, "avg_logprob": -0.15362035036087035, "compression_ratio": 1.49746192893401, "no_speech_prob": 0.054720375686883926}, {"id": 531, "seek": 203100, "start": 2031.0, "end": 2037.0, "text": " So the way the agreement we had with them is they handled their own repo", "tokens": [50364, 407, 264, 636, 264, 8106, 321, 632, 365, 552, 307, 436, 18033, 641, 1065, 49040, 50664], "temperature": 0.0, "avg_logprob": -0.11162209510803223, "compression_ratio": 1.7123893805309736, "no_speech_prob": 0.029395917430520058}, {"id": 532, "seek": 203100, "start": 2037.0, "end": 2039.0, "text": " with everything they do about us.", "tokens": [50664, 365, 1203, 436, 360, 466, 505, 13, 50764], "temperature": 0.0, "avg_logprob": -0.11162209510803223, "compression_ratio": 1.7123893805309736, "no_speech_prob": 0.029395917430520058}, {"id": 533, "seek": 203100, "start": 2039.0, "end": 2043.0, "text": " And we have our own repo with our code base.", "tokens": [50764, 400, 321, 362, 527, 1065, 49040, 365, 527, 3089, 3096, 13, 50964], "temperature": 0.0, "avg_logprob": -0.11162209510803223, "compression_ratio": 1.7123893805309736, "no_speech_prob": 0.029395917430520058}, {"id": 534, "seek": 203100, "start": 2043.0, "end": 2046.0, "text": " And the problem we realized, and we still haven't solved,", "tokens": [50964, 400, 264, 1154, 321, 5334, 11, 293, 321, 920, 2378, 380, 13041, 11, 51114], "temperature": 0.0, "avg_logprob": -0.11162209510803223, "compression_ratio": 1.7123893805309736, "no_speech_prob": 0.029395917430520058}, {"id": 535, "seek": 203100, "start": 2046.0, "end": 2050.0, "text": " is that part of the application is actually in the infrastructure.", "tokens": [51114, 307, 300, 644, 295, 264, 3861, 307, 767, 294, 264, 6896, 13, 51314], "temperature": 0.0, "avg_logprob": -0.11162209510803223, "compression_ratio": 1.7123893805309736, "no_speech_prob": 0.029395917430520058}, {"id": 536, "seek": 203100, "start": 2050.0, "end": 2053.0, "text": " And this is something we are not used to do in Rails.", "tokens": [51314, 400, 341, 307, 746, 321, 366, 406, 1143, 281, 360, 294, 48526, 13, 51464], "temperature": 0.0, "avg_logprob": -0.11162209510803223, "compression_ratio": 1.7123893805309736, "no_speech_prob": 0.029395917430520058}, {"id": 537, "seek": 203100, "start": 2053.0, "end": 2058.0, "text": " But typically the queue we use have a dead-letter queue.", "tokens": [51464, 583, 5850, 264, 18639, 321, 764, 362, 257, 3116, 12, 21248, 18639, 13, 51714], "temperature": 0.0, "avg_logprob": -0.11162209510803223, "compression_ratio": 1.7123893805309736, "no_speech_prob": 0.029395917430520058}, {"id": 538, "seek": 205800, "start": 2058.0, "end": 2062.0, "text": " If you try to read something and it fails, so you release,", "tokens": [50364, 759, 291, 853, 281, 1401, 746, 293, 309, 18199, 11, 370, 291, 4374, 11, 50564], "temperature": 0.0, "avg_logprob": -0.0999284646449945, "compression_ratio": 1.7341269841269842, "no_speech_prob": 0.009585618041455746}, {"id": 539, "seek": 205800, "start": 2062.0, "end": 2064.0, "text": " you retry to receive, it fails.", "tokens": [50564, 291, 1533, 627, 281, 4774, 11, 309, 18199, 13, 50664], "temperature": 0.0, "avg_logprob": -0.0999284646449945, "compression_ratio": 1.7341269841269842, "no_speech_prob": 0.009585618041455746}, {"id": 540, "seek": 205800, "start": 2064.0, "end": 2067.0, "text": " After sometimes that message, you put it into a dead-letter", "tokens": [50664, 2381, 2171, 300, 3636, 11, 291, 829, 309, 666, 257, 3116, 12, 21248, 50814], "temperature": 0.0, "avg_logprob": -0.0999284646449945, "compression_ratio": 1.7341269841269842, "no_speech_prob": 0.009585618041455746}, {"id": 541, "seek": 205800, "start": 2067.0, "end": 2072.0, "text": " because you don't want to lose waste more time trying to handle that.", "tokens": [50814, 570, 291, 500, 380, 528, 281, 3624, 5964, 544, 565, 1382, 281, 4813, 300, 13, 51064], "temperature": 0.0, "avg_logprob": -0.0999284646449945, "compression_ratio": 1.7341269841269842, "no_speech_prob": 0.009585618041455746}, {"id": 542, "seek": 205800, "start": 2072.0, "end": 2075.0, "text": " Another aspect is buckets have life cycle.", "tokens": [51064, 3996, 4171, 307, 32191, 362, 993, 6586, 13, 51214], "temperature": 0.0, "avg_logprob": -0.0999284646449945, "compression_ratio": 1.7341269841269842, "no_speech_prob": 0.009585618041455746}, {"id": 543, "seek": 205800, "start": 2075.0, "end": 2079.0, "text": " If a file is forgotten there after 24 hours, you want to delete that file.", "tokens": [51214, 759, 257, 3991, 307, 11832, 456, 934, 4022, 2496, 11, 291, 528, 281, 12097, 300, 3991, 13, 51414], "temperature": 0.0, "avg_logprob": -0.0999284646449945, "compression_ratio": 1.7341269841269842, "no_speech_prob": 0.009585618041455746}, {"id": 544, "seek": 205800, "start": 2079.0, "end": 2082.0, "text": " You don't want to pay fees for that file for the rest of your life.", "tokens": [51414, 509, 500, 380, 528, 281, 1689, 13370, 337, 300, 3991, 337, 264, 1472, 295, 428, 993, 13, 51564], "temperature": 0.0, "avg_logprob": -0.0999284646449945, "compression_ratio": 1.7341269841269842, "no_speech_prob": 0.009585618041455746}, {"id": 545, "seek": 205800, "start": 2082.0, "end": 2084.0, "text": " And this is application logic.", "tokens": [51564, 400, 341, 307, 3861, 9952, 13, 51664], "temperature": 0.0, "avg_logprob": -0.0999284646449945, "compression_ratio": 1.7341269841269842, "no_speech_prob": 0.009585618041455746}, {"id": 546, "seek": 208400, "start": 2084.0, "end": 2088.0, "text": " Even though it fits in infrastructure, like it is application logic.", "tokens": [50364, 2754, 1673, 309, 9001, 294, 6896, 11, 411, 309, 307, 3861, 9952, 13, 50564], "temperature": 0.0, "avg_logprob": -0.09162039716704552, "compression_ratio": 1.9058823529411764, "no_speech_prob": 0.06549972295761108}, {"id": 547, "seek": 208400, "start": 2088.0, "end": 2094.0, "text": " And this bothers me because application logic, anyone who clones a repo", "tokens": [50564, 400, 341, 33980, 385, 570, 3861, 9952, 11, 2878, 567, 43803, 257, 49040, 50864], "temperature": 0.0, "avg_logprob": -0.09162039716704552, "compression_ratio": 1.9058823529411764, "no_speech_prob": 0.06549972295761108}, {"id": 548, "seek": 208400, "start": 2094.0, "end": 2097.0, "text": " should be able to see everything, to know everything.", "tokens": [50864, 820, 312, 1075, 281, 536, 1203, 11, 281, 458, 1203, 13, 51014], "temperature": 0.0, "avg_logprob": -0.09162039716704552, "compression_ratio": 1.9058823529411764, "no_speech_prob": 0.06549972295761108}, {"id": 549, "seek": 208400, "start": 2097.0, "end": 2099.0, "text": " They don't have to be master at everything.", "tokens": [51014, 814, 500, 380, 362, 281, 312, 4505, 412, 1203, 13, 51114], "temperature": 0.0, "avg_logprob": -0.09162039716704552, "compression_ratio": 1.9058823529411764, "no_speech_prob": 0.06549972295761108}, {"id": 550, "seek": 208400, "start": 2099.0, "end": 2101.0, "text": " They don't have to change everything.", "tokens": [51114, 814, 500, 380, 362, 281, 1319, 1203, 13, 51214], "temperature": 0.0, "avg_logprob": -0.09162039716704552, "compression_ratio": 1.9058823529411764, "no_speech_prob": 0.06549972295761108}, {"id": 551, "seek": 208400, "start": 2101.0, "end": 2106.0, "text": " But cloning a single repo should explain everything there is to know about this app.", "tokens": [51214, 583, 596, 16638, 257, 2167, 49040, 820, 2903, 1203, 456, 307, 281, 458, 466, 341, 724, 13, 51464], "temperature": 0.0, "avg_logprob": -0.09162039716704552, "compression_ratio": 1.9058823529411764, "no_speech_prob": 0.06549972295761108}, {"id": 552, "seek": 208400, "start": 2106.0, "end": 2108.0, "text": " So at the moment we still have those two repo.", "tokens": [51464, 407, 412, 264, 1623, 321, 920, 362, 729, 732, 49040, 13, 51564], "temperature": 0.0, "avg_logprob": -0.09162039716704552, "compression_ratio": 1.9058823529411764, "no_speech_prob": 0.06549972295761108}, {"id": 553, "seek": 208400, "start": 2108.0, "end": 2110.0, "text": " One is like focusing on the infrastructure.", "tokens": [51564, 1485, 307, 411, 8416, 322, 264, 6896, 13, 51664], "temperature": 0.0, "avg_logprob": -0.09162039716704552, "compression_ratio": 1.9058823529411764, "no_speech_prob": 0.06549972295761108}, {"id": 554, "seek": 208400, "start": 2110.0, "end": 2113.0, "text": " One is focusing on the code base.", "tokens": [51664, 1485, 307, 8416, 322, 264, 3089, 3096, 13, 51814], "temperature": 0.0, "avg_logprob": -0.09162039716704552, "compression_ratio": 1.9058823529411764, "no_speech_prob": 0.06549972295761108}, {"id": 555, "seek": 211300, "start": 2113.0, "end": 2117.0, "text": " Hopefully we will solve that very soon.", "tokens": [50364, 10429, 321, 486, 5039, 300, 588, 2321, 13, 50564], "temperature": 0.0, "avg_logprob": -0.13112600813520717, "compression_ratio": 1.6069868995633187, "no_speech_prob": 0.006719532888382673}, {"id": 556, "seek": 211300, "start": 2117.0, "end": 2122.0, "text": " But with that done, we actually had the app deployed,", "tokens": [50564, 583, 365, 300, 1096, 11, 321, 767, 632, 264, 724, 17826, 11, 50814], "temperature": 0.0, "avg_logprob": -0.13112600813520717, "compression_ratio": 1.6069868995633187, "no_speech_prob": 0.006719532888382673}, {"id": 557, "seek": 211300, "start": 2122.0, "end": 2125.0, "text": " monitors scaled, we learned quite a lot.", "tokens": [50814, 26518, 36039, 11, 321, 3264, 1596, 257, 688, 13, 50964], "temperature": 0.0, "avg_logprob": -0.13112600813520717, "compression_ratio": 1.6069868995633187, "no_speech_prob": 0.006719532888382673}, {"id": 558, "seek": 211300, "start": 2125.0, "end": 2127.0, "text": " We actually made a blueprint out of that,", "tokens": [50964, 492, 767, 1027, 257, 35868, 484, 295, 300, 11, 51064], "temperature": 0.0, "avg_logprob": -0.13112600813520717, "compression_ratio": 1.6069868995633187, "no_speech_prob": 0.006719532888382673}, {"id": 559, "seek": 211300, "start": 2127.0, "end": 2131.0, "text": " so we are creating several other workers right out of that.", "tokens": [51064, 370, 321, 366, 4084, 2940, 661, 5600, 558, 484, 295, 300, 13, 51264], "temperature": 0.0, "avg_logprob": -0.13112600813520717, "compression_ratio": 1.6069868995633187, "no_speech_prob": 0.006719532888382673}, {"id": 560, "seek": 211300, "start": 2131.0, "end": 2136.0, "text": " And we feel much more confident actually using Ruby for something else", "tokens": [51264, 400, 321, 841, 709, 544, 6679, 767, 1228, 19907, 337, 746, 1646, 51514], "temperature": 0.0, "avg_logprob": -0.13112600813520717, "compression_ratio": 1.6069868995633187, "no_speech_prob": 0.006719532888382673}, {"id": 561, "seek": 211300, "start": 2136.0, "end": 2139.0, "text": " than web application.", "tokens": [51514, 813, 3670, 3861, 13, 51664], "temperature": 0.0, "avg_logprob": -0.13112600813520717, "compression_ratio": 1.6069868995633187, "no_speech_prob": 0.006719532888382673}, {"id": 562, "seek": 211300, "start": 2139.0, "end": 2141.0, "text": " So thank you, everyone, for your time.", "tokens": [51664, 407, 1309, 291, 11, 1518, 11, 337, 428, 565, 13, 51764], "temperature": 0.0, "avg_logprob": -0.13112600813520717, "compression_ratio": 1.6069868995633187, "no_speech_prob": 0.006719532888382673}, {"id": 563, "seek": 214100, "start": 2141.0, "end": 2143.0, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 50464], "temperature": 0.0, "avg_logprob": -0.30894501601593405, "compression_ratio": 1.6235294117647059, "no_speech_prob": 0.02842715196311474}, {"id": 564, "seek": 214100, "start": 2149.0, "end": 2152.0, "text": " Any questions? We have two minutes of questions, hopefully.", "tokens": [50764, 2639, 1651, 30, 492, 362, 732, 2077, 295, 1651, 11, 4696, 13, 50914], "temperature": 0.0, "avg_logprob": -0.30894501601593405, "compression_ratio": 1.6235294117647059, "no_speech_prob": 0.02842715196311474}, {"id": 565, "seek": 214100, "start": 2154.0, "end": 2156.0, "text": " You've talked a lot about...", "tokens": [51014, 509, 600, 2825, 257, 688, 466, 485, 51114], "temperature": 0.0, "avg_logprob": -0.30894501601593405, "compression_ratio": 1.6235294117647059, "no_speech_prob": 0.02842715196311474}, {"id": 566, "seek": 214100, "start": 2156.0, "end": 2159.0, "text": " I mean, first you never talked about Rails,", "tokens": [51114, 286, 914, 11, 700, 291, 1128, 2825, 466, 48526, 11, 51264], "temperature": 0.0, "avg_logprob": -0.30894501601593405, "compression_ratio": 1.6235294117647059, "no_speech_prob": 0.02842715196311474}, {"id": 567, "seek": 214100, "start": 2159.0, "end": 2162.0, "text": " but you actually miss it a lot.", "tokens": [51264, 457, 291, 767, 1713, 309, 257, 688, 13, 51414], "temperature": 0.0, "avg_logprob": -0.30894501601593405, "compression_ratio": 1.6235294117647059, "no_speech_prob": 0.02842715196311474}, {"id": 568, "seek": 214100, "start": 2162.0, "end": 2166.0, "text": " It's pretty funny that it was not about Rails, but actually...", "tokens": [51414, 467, 311, 1238, 4074, 300, 309, 390, 406, 466, 48526, 11, 457, 767, 485, 51614], "temperature": 0.0, "avg_logprob": -0.30894501601593405, "compression_ratio": 1.6235294117647059, "no_speech_prob": 0.02842715196311474}, {"id": 569, "seek": 214100, "start": 2166.0, "end": 2168.0, "text": " Anyway, you talked a lot about types.", "tokens": [51614, 5684, 11, 291, 2825, 257, 688, 466, 3467, 13, 51714], "temperature": 0.0, "avg_logprob": -0.30894501601593405, "compression_ratio": 1.6235294117647059, "no_speech_prob": 0.02842715196311474}, {"id": 570, "seek": 216800, "start": 2168.0, "end": 2171.0, "text": " Is that something more to bring to the rest of the ecosystem?", "tokens": [50364, 1119, 300, 746, 544, 281, 1565, 281, 264, 1472, 295, 264, 11311, 30, 50514], "temperature": 0.0, "avg_logprob": -0.07741688959526294, "compression_ratio": 1.7675276752767528, "no_speech_prob": 0.011204988695681095}, {"id": 571, "seek": 216800, "start": 2171.0, "end": 2173.0, "text": " Yeah, that's a very good question.", "tokens": [50514, 865, 11, 300, 311, 257, 588, 665, 1168, 13, 50614], "temperature": 0.0, "avg_logprob": -0.07741688959526294, "compression_ratio": 1.7675276752767528, "no_speech_prob": 0.011204988695681095}, {"id": 572, "seek": 216800, "start": 2173.0, "end": 2176.0, "text": " So the question is, I talked a lot about types.", "tokens": [50614, 407, 264, 1168, 307, 11, 286, 2825, 257, 688, 466, 3467, 13, 50764], "temperature": 0.0, "avg_logprob": -0.07741688959526294, "compression_ratio": 1.7675276752767528, "no_speech_prob": 0.011204988695681095}, {"id": 573, "seek": 216800, "start": 2176.0, "end": 2179.0, "text": " Do I want to bring that into Rails?", "tokens": [50764, 1144, 286, 528, 281, 1565, 300, 666, 48526, 30, 50914], "temperature": 0.0, "avg_logprob": -0.07741688959526294, "compression_ratio": 1.7675276752767528, "no_speech_prob": 0.011204988695681095}, {"id": 574, "seek": 216800, "start": 2179.0, "end": 2182.0, "text": " Actually, the interactor is something we do in Rails already,", "tokens": [50914, 5135, 11, 264, 4648, 284, 307, 746, 321, 360, 294, 48526, 1217, 11, 51064], "temperature": 0.0, "avg_logprob": -0.07741688959526294, "compression_ratio": 1.7675276752767528, "no_speech_prob": 0.011204988695681095}, {"id": 575, "seek": 216800, "start": 2182.0, "end": 2184.0, "text": " which means we are using dry validation already,", "tokens": [51064, 597, 1355, 321, 366, 1228, 4016, 24071, 1217, 11, 51164], "temperature": 0.0, "avg_logprob": -0.07741688959526294, "compression_ratio": 1.7675276752767528, "no_speech_prob": 0.011204988695681095}, {"id": 576, "seek": 216800, "start": 2184.0, "end": 2187.0, "text": " which means we are using dry types already.", "tokens": [51164, 597, 1355, 321, 366, 1228, 4016, 3467, 1217, 13, 51314], "temperature": 0.0, "avg_logprob": -0.07741688959526294, "compression_ratio": 1.7675276752767528, "no_speech_prob": 0.011204988695681095}, {"id": 577, "seek": 216800, "start": 2187.0, "end": 2190.0, "text": " To be fully honest, we don't use it enough.", "tokens": [51314, 1407, 312, 4498, 3245, 11, 321, 500, 380, 764, 309, 1547, 13, 51464], "temperature": 0.0, "avg_logprob": -0.07741688959526294, "compression_ratio": 1.7675276752767528, "no_speech_prob": 0.011204988695681095}, {"id": 578, "seek": 216800, "start": 2190.0, "end": 2193.0, "text": " We sort of use it when we realize that we should have used it before.", "tokens": [51464, 492, 1333, 295, 764, 309, 562, 321, 4325, 300, 321, 820, 362, 1143, 309, 949, 13, 51614], "temperature": 0.0, "avg_logprob": -0.07741688959526294, "compression_ratio": 1.7675276752767528, "no_speech_prob": 0.011204988695681095}, {"id": 579, "seek": 216800, "start": 2193.0, "end": 2196.0, "text": " So it's like not good enough,", "tokens": [51614, 407, 309, 311, 411, 406, 665, 1547, 11, 51764], "temperature": 0.0, "avg_logprob": -0.07741688959526294, "compression_ratio": 1.7675276752767528, "no_speech_prob": 0.011204988695681095}, {"id": 580, "seek": 219600, "start": 2196.0, "end": 2198.0, "text": " but it is something we are using,", "tokens": [50364, 457, 309, 307, 746, 321, 366, 1228, 11, 50464], "temperature": 0.0, "avg_logprob": -0.10056196697174556, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.007502991706132889}, {"id": 581, "seek": 219600, "start": 2198.0, "end": 2201.0, "text": " and types have been very helpful in the past already.", "tokens": [50464, 293, 3467, 362, 668, 588, 4961, 294, 264, 1791, 1217, 13, 50614], "temperature": 0.0, "avg_logprob": -0.10056196697174556, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.007502991706132889}, {"id": 582, "seek": 219600, "start": 2201.0, "end": 2205.0, "text": " And there's a lot of other tools that we have discovered here,", "tokens": [50614, 400, 456, 311, 257, 688, 295, 661, 3873, 300, 321, 362, 6941, 510, 11, 50814], "temperature": 0.0, "avg_logprob": -0.10056196697174556, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.007502991706132889}, {"id": 583, "seek": 219600, "start": 2205.0, "end": 2209.0, "text": " because we had to, and I very much hope that we are going to use them.", "tokens": [50814, 570, 321, 632, 281, 11, 293, 286, 588, 709, 1454, 300, 321, 366, 516, 281, 764, 552, 13, 51014], "temperature": 0.0, "avg_logprob": -0.10056196697174556, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.007502991706132889}, {"id": 584, "seek": 219600, "start": 2209.0, "end": 2214.0, "text": " But also, my first slide means that I'm no CTO, I'm no manager,", "tokens": [51014, 583, 611, 11, 452, 700, 4137, 1355, 300, 286, 478, 572, 383, 15427, 11, 286, 478, 572, 6598, 11, 51264], "temperature": 0.0, "avg_logprob": -0.10056196697174556, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.007502991706132889}, {"id": 585, "seek": 219600, "start": 2214.0, "end": 2217.0, "text": " which means I don't get to make those calls anymore.", "tokens": [51264, 597, 1355, 286, 500, 380, 483, 281, 652, 729, 5498, 3602, 13, 51414], "temperature": 0.0, "avg_logprob": -0.10056196697174556, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.007502991706132889}, {"id": 586, "seek": 219600, "start": 2217.0, "end": 2221.0, "text": " And it's very important to me that the one who writes the app", "tokens": [51414, 400, 309, 311, 588, 1021, 281, 385, 300, 264, 472, 567, 13657, 264, 724, 51614], "temperature": 0.0, "avg_logprob": -0.10056196697174556, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.007502991706132889}, {"id": 587, "seek": 219600, "start": 2221.0, "end": 2224.0, "text": " are responsible for writing it, maintaining it, running it,", "tokens": [51614, 366, 6250, 337, 3579, 309, 11, 14916, 309, 11, 2614, 309, 11, 51764], "temperature": 0.0, "avg_logprob": -0.10056196697174556, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.007502991706132889}, {"id": 588, "seek": 222400, "start": 2224.0, "end": 2227.0, "text": " so I can influence, I can give my opinion,", "tokens": [50364, 370, 286, 393, 6503, 11, 286, 393, 976, 452, 4800, 11, 50514], "temperature": 0.0, "avg_logprob": -0.19331012301974826, "compression_ratio": 1.502415458937198, "no_speech_prob": 0.021931322291493416}, {"id": 589, "seek": 222400, "start": 2227.0, "end": 2230.0, "text": " but I don't make those calls anymore.", "tokens": [50514, 457, 286, 500, 380, 652, 729, 5498, 3602, 13, 50664], "temperature": 0.0, "avg_logprob": -0.19331012301974826, "compression_ratio": 1.502415458937198, "no_speech_prob": 0.021931322291493416}, {"id": 590, "seek": 222400, "start": 2232.0, "end": 2234.0, "text": " Yes?", "tokens": [50764, 1079, 30, 50864], "temperature": 0.0, "avg_logprob": -0.19331012301974826, "compression_ratio": 1.502415458937198, "no_speech_prob": 0.021931322291493416}, {"id": 591, "seek": 222400, "start": 2234.0, "end": 2237.0, "text": " You said that you use dry monot.", "tokens": [50864, 509, 848, 300, 291, 764, 4016, 1108, 310, 13, 51014], "temperature": 0.0, "avg_logprob": -0.19331012301974826, "compression_ratio": 1.502415458937198, "no_speech_prob": 0.021931322291493416}, {"id": 592, "seek": 222400, "start": 2237.0, "end": 2241.0, "text": " What has been, can you tell me more about your experience,", "tokens": [51014, 708, 575, 668, 11, 393, 291, 980, 385, 544, 466, 428, 1752, 11, 51214], "temperature": 0.0, "avg_logprob": -0.19331012301974826, "compression_ratio": 1.502415458937198, "no_speech_prob": 0.021931322291493416}, {"id": 593, "seek": 222400, "start": 2241.0, "end": 2244.0, "text": " because I used it quite extensively in the past", "tokens": [51214, 570, 286, 1143, 309, 1596, 32636, 294, 264, 1791, 51364], "temperature": 0.0, "avg_logprob": -0.19331012301974826, "compression_ratio": 1.502415458937198, "no_speech_prob": 0.021931322291493416}, {"id": 594, "seek": 222400, "start": 2244.0, "end": 2247.0, "text": " before they introduced these two notations.", "tokens": [51364, 949, 436, 7268, 613, 732, 406, 763, 13, 51514], "temperature": 0.0, "avg_logprob": -0.19331012301974826, "compression_ratio": 1.502415458937198, "no_speech_prob": 0.021931322291493416}, {"id": 595, "seek": 222400, "start": 2247.0, "end": 2251.0, "text": " And it was very sticky to the code as in,", "tokens": [51514, 400, 309, 390, 588, 14470, 281, 264, 3089, 382, 294, 11, 51714], "temperature": 0.0, "avg_logprob": -0.19331012301974826, "compression_ratio": 1.502415458937198, "no_speech_prob": 0.021931322291493416}, {"id": 596, "seek": 225100, "start": 2252.0, "end": 2257.0, "text": " it made Ruby not look like Ruby, like something else.", "tokens": [50414, 309, 1027, 19907, 406, 574, 411, 19907, 11, 411, 746, 1646, 13, 50664], "temperature": 0.0, "avg_logprob": -0.2048956995425017, "compression_ratio": 1.6261261261261262, "no_speech_prob": 0.008393296971917152}, {"id": 597, "seek": 225100, "start": 2257.0, "end": 2261.0, "text": " So, if there is something changed there, how's your experience?", "tokens": [50664, 407, 11, 498, 456, 307, 746, 3105, 456, 11, 577, 311, 428, 1752, 30, 50864], "temperature": 0.0, "avg_logprob": -0.2048956995425017, "compression_ratio": 1.6261261261261262, "no_speech_prob": 0.008393296971917152}, {"id": 598, "seek": 225100, "start": 2261.0, "end": 2264.0, "text": " All right, so the question is, do I use dry monot?", "tokens": [50864, 1057, 558, 11, 370, 264, 1168, 307, 11, 360, 286, 764, 4016, 1108, 310, 30, 51014], "temperature": 0.0, "avg_logprob": -0.2048956995425017, "compression_ratio": 1.6261261261261262, "no_speech_prob": 0.008393296971917152}, {"id": 599, "seek": 225100, "start": 2264.0, "end": 2266.0, "text": " What do I think of the do notation,", "tokens": [51014, 708, 360, 286, 519, 295, 264, 360, 24657, 11, 51114], "temperature": 0.0, "avg_logprob": -0.2048956995425017, "compression_ratio": 1.6261261261261262, "no_speech_prob": 0.008393296971917152}, {"id": 600, "seek": 225100, "start": 2266.0, "end": 2269.0, "text": " and how Ruby-esque does it feel?", "tokens": [51114, 293, 577, 19907, 12, 47457, 775, 309, 841, 30, 51264], "temperature": 0.0, "avg_logprob": -0.2048956995425017, "compression_ratio": 1.6261261261261262, "no_speech_prob": 0.008393296971917152}, {"id": 601, "seek": 225100, "start": 2269.0, "end": 2270.0, "text": " Is that right?", "tokens": [51264, 1119, 300, 558, 30, 51314], "temperature": 0.0, "avg_logprob": -0.2048956995425017, "compression_ratio": 1.6261261261261262, "no_speech_prob": 0.008393296971917152}, {"id": 602, "seek": 225100, "start": 2270.0, "end": 2271.0, "text": " Yes.", "tokens": [51314, 1079, 13, 51364], "temperature": 0.0, "avg_logprob": -0.2048956995425017, "compression_ratio": 1.6261261261261262, "no_speech_prob": 0.008393296971917152}, {"id": 603, "seek": 225100, "start": 2271.0, "end": 2272.0, "text": " Okay.", "tokens": [51364, 1033, 13, 51414], "temperature": 0.0, "avg_logprob": -0.2048956995425017, "compression_ratio": 1.6261261261261262, "no_speech_prob": 0.008393296971917152}, {"id": 604, "seek": 225100, "start": 2272.0, "end": 2276.0, "text": " So I am not using dry monot, except for like toy projects.", "tokens": [51414, 407, 286, 669, 406, 1228, 4016, 1108, 310, 11, 3993, 337, 411, 12058, 4455, 13, 51614], "temperature": 0.0, "avg_logprob": -0.2048956995425017, "compression_ratio": 1.6261261261261262, "no_speech_prob": 0.008393296971917152}, {"id": 605, "seek": 225100, "start": 2276.0, "end": 2278.0, "text": " So we are not using dry monot in this,", "tokens": [51614, 407, 321, 366, 406, 1228, 4016, 1108, 310, 294, 341, 11, 51714], "temperature": 0.0, "avg_logprob": -0.2048956995425017, "compression_ratio": 1.6261261261261262, "no_speech_prob": 0.008393296971917152}, {"id": 606, "seek": 227800, "start": 2278.0, "end": 2281.0, "text": " so our own take is using our own interactors.", "tokens": [50364, 370, 527, 1065, 747, 307, 1228, 527, 1065, 4648, 830, 13, 50514], "temperature": 0.0, "avg_logprob": -0.11596360296573278, "compression_ratio": 1.5822784810126582, "no_speech_prob": 0.01980859413743019}, {"id": 607, "seek": 227800, "start": 2281.0, "end": 2286.0, "text": " So whatever I'm going to say is out of my experience on toy projects.", "tokens": [50514, 407, 2035, 286, 478, 516, 281, 584, 307, 484, 295, 452, 1752, 322, 12058, 4455, 13, 50764], "temperature": 0.0, "avg_logprob": -0.11596360296573278, "compression_ratio": 1.5822784810126582, "no_speech_prob": 0.01980859413743019}, {"id": 608, "seek": 227800, "start": 2286.0, "end": 2289.0, "text": " I've learned initially about monads in Haskell.", "tokens": [50764, 286, 600, 3264, 9105, 466, 1108, 5834, 294, 8646, 43723, 13, 50914], "temperature": 0.0, "avg_logprob": -0.11596360296573278, "compression_ratio": 1.5822784810126582, "no_speech_prob": 0.01980859413743019}, {"id": 609, "seek": 227800, "start": 2289.0, "end": 2293.0, "text": " This is still very painful to me 10 years later.", "tokens": [50914, 639, 307, 920, 588, 11697, 281, 385, 1266, 924, 1780, 13, 51114], "temperature": 0.0, "avg_logprob": -0.11596360296573278, "compression_ratio": 1.5822784810126582, "no_speech_prob": 0.01980859413743019}, {"id": 610, "seek": 227800, "start": 2293.0, "end": 2297.0, "text": " So my take on monads is like, most of the time,", "tokens": [51114, 407, 452, 747, 322, 1108, 5834, 307, 411, 11, 881, 295, 264, 565, 11, 51314], "temperature": 0.0, "avg_logprob": -0.11596360296573278, "compression_ratio": 1.5822784810126582, "no_speech_prob": 0.01980859413743019}, {"id": 611, "seek": 227800, "start": 2297.0, "end": 2300.0, "text": " it's like not the right tool.", "tokens": [51314, 309, 311, 411, 406, 264, 558, 2290, 13, 51464], "temperature": 0.0, "avg_logprob": -0.11596360296573278, "compression_ratio": 1.5822784810126582, "no_speech_prob": 0.01980859413743019}, {"id": 612, "seek": 227800, "start": 2300.0, "end": 2303.0, "text": " And it's something that people,", "tokens": [51464, 400, 309, 311, 746, 300, 561, 11, 51614], "temperature": 0.0, "avg_logprob": -0.11596360296573278, "compression_ratio": 1.5822784810126582, "no_speech_prob": 0.01980859413743019}, {"id": 613, "seek": 227800, "start": 2303.0, "end": 2306.0, "text": " the learning curve for understanding what is a monad", "tokens": [51614, 264, 2539, 7605, 337, 3701, 437, 307, 257, 1108, 345, 51764], "temperature": 0.0, "avg_logprob": -0.11596360296573278, "compression_ratio": 1.5822784810126582, "no_speech_prob": 0.01980859413743019}, {"id": 614, "seek": 230600, "start": 2306.0, "end": 2310.0, "text": " is so high that once you've earned the right to understand what it is,", "tokens": [50364, 307, 370, 1090, 300, 1564, 291, 600, 12283, 264, 558, 281, 1223, 437, 309, 307, 11, 50564], "temperature": 0.0, "avg_logprob": -0.09099759658177693, "compression_ratio": 1.5727272727272728, "no_speech_prob": 0.00536780059337616}, {"id": 615, "seek": 230600, "start": 2310.0, "end": 2312.0, "text": " you want to put it everywhere.", "tokens": [50564, 291, 528, 281, 829, 309, 5315, 13, 50664], "temperature": 0.0, "avg_logprob": -0.09099759658177693, "compression_ratio": 1.5727272727272728, "no_speech_prob": 0.00536780059337616}, {"id": 616, "seek": 230600, "start": 2312.0, "end": 2315.0, "text": " A little bit like meta-programming.", "tokens": [50664, 316, 707, 857, 411, 19616, 12, 32726, 2810, 13, 50814], "temperature": 0.0, "avg_logprob": -0.09099759658177693, "compression_ratio": 1.5727272727272728, "no_speech_prob": 0.00536780059337616}, {"id": 617, "seek": 230600, "start": 2315.0, "end": 2317.0, "text": " So this is my take on monads.", "tokens": [50814, 407, 341, 307, 452, 747, 322, 1108, 5834, 13, 50914], "temperature": 0.0, "avg_logprob": -0.09099759658177693, "compression_ratio": 1.5727272727272728, "no_speech_prob": 0.00536780059337616}, {"id": 618, "seek": 230600, "start": 2317.0, "end": 2322.0, "text": " I wouldn't force them into anyone who is not very comfortable using them.", "tokens": [50914, 286, 2759, 380, 3464, 552, 666, 2878, 567, 307, 406, 588, 4619, 1228, 552, 13, 51164], "temperature": 0.0, "avg_logprob": -0.09099759658177693, "compression_ratio": 1.5727272727272728, "no_speech_prob": 0.00536780059337616}, {"id": 619, "seek": 230600, "start": 2322.0, "end": 2326.0, "text": " I do believe that it is a very elegant solution,", "tokens": [51164, 286, 360, 1697, 300, 309, 307, 257, 588, 21117, 3827, 11, 51364], "temperature": 0.0, "avg_logprob": -0.09099759658177693, "compression_ratio": 1.5727272727272728, "no_speech_prob": 0.00536780059337616}, {"id": 620, "seek": 230600, "start": 2326.0, "end": 2331.0, "text": " but I also do believe that sometimes a bunch of if-else", "tokens": [51364, 457, 286, 611, 360, 1697, 300, 2171, 257, 3840, 295, 498, 12, 44408, 51614], "temperature": 0.0, "avg_logprob": -0.09099759658177693, "compression_ratio": 1.5727272727272728, "no_speech_prob": 0.00536780059337616}, {"id": 621, "seek": 233100, "start": 2331.0, "end": 2338.0, "text": " makes the team happier than using the best tool for the occasion.", "tokens": [50364, 1669, 264, 1469, 20423, 813, 1228, 264, 1151, 2290, 337, 264, 9674, 13, 50714], "temperature": 0.0, "avg_logprob": -0.18332364824083117, "compression_ratio": 1.31496062992126, "no_speech_prob": 0.013103969395160675}, {"id": 622, "seek": 233100, "start": 2338.0, "end": 2342.0, "text": " And I don't have any opinion about the do notation and how Ruby-esque it feels.", "tokens": [50714, 400, 286, 500, 380, 362, 604, 4800, 466, 264, 360, 24657, 293, 577, 19907, 12, 47457, 309, 3417, 13, 50914], "temperature": 0.0, "avg_logprob": -0.18332364824083117, "compression_ratio": 1.31496062992126, "no_speech_prob": 0.013103969395160675}, {"id": 623, "seek": 233100, "start": 2345.0, "end": 2347.0, "text": " All right, thank you.", "tokens": [51064, 1057, 558, 11, 1309, 291, 13, 51164], "temperature": 0.0, "avg_logprob": -0.18332364824083117, "compression_ratio": 1.31496062992126, "no_speech_prob": 0.013103969395160675}], "language": "en"}