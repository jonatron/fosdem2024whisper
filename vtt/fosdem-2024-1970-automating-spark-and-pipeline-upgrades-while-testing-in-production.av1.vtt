WEBVTT

00:00.000 --> 00:23.200
Okay, that's it.

00:23.200 --> 00:25.200
Please take a seat and we'll get started.

00:25.200 --> 00:35.600
So Holden is going to talk about automating spark upgrades and also lots of testing in

00:35.600 --> 00:36.600
production.

00:36.600 --> 00:40.000
That's going to be interesting.

00:40.000 --> 00:45.560
Testing in production is the best place to test when the alternative is no tests, which

00:45.560 --> 00:46.760
it often is.

00:46.760 --> 00:48.200
Okay, cool.

00:48.200 --> 00:55.680
So let me know if you can't hear me because I'm very easily distracted and get excited

00:55.680 --> 00:59.840
and I might not notice that I'm not talking directly into the microphone, so please grab

00:59.840 --> 01:03.200
my attention if I screw up.

01:03.200 --> 01:04.760
So yeah, I'm Holden.

01:04.760 --> 01:06.080
My pronouns are she or her.

01:06.080 --> 01:07.520
It's tattooed on my wrist.

01:07.520 --> 01:10.200
Super convenient when I wake up in the morning.

01:10.200 --> 01:12.520
I'm on the Spark PMC.

01:12.520 --> 01:16.560
You can think of this as like having tenure, except it doesn't guarantee I get paid.

01:16.560 --> 01:21.560
It just guarantees that I have work to do, so it's like the shady version of tenure.

01:21.560 --> 01:28.320
And I've worked at a whole bunch of different companies, not super relevant, but I've seen

01:28.320 --> 01:33.040
a lot of mistakes made in production and I have made a lot of mistakes in production

01:33.040 --> 01:36.040
so you can learn from some of my mistakes.

01:36.040 --> 01:40.640
My employer who sent me here, Netflix, is hiring and I would be remiss if I did not

01:40.640 --> 01:42.120
mention that.

01:42.120 --> 01:46.480
They're actually finally hiring remote people after who knows how many years.

01:46.480 --> 01:48.040
I'm a co-author of a bunch of books.

01:48.040 --> 01:52.480
Some of them are related to HPC-ish stuff.

01:52.480 --> 01:57.480
I get the highest royalties on scaling Python with Ray, so I think it's a fantastic book

01:57.480 --> 02:00.320
and everyone should buy several copies with your corporate credit card.

02:00.320 --> 02:06.360
If you don't have a corporate credit card, the internet will provide.

02:06.360 --> 02:11.080
You can follow me on social media and there's lots of pictures of my dog.

02:11.080 --> 02:14.520
If you're into that stuff, there's a lot of complaining about American healthcare.

02:14.520 --> 02:17.360
If you enjoy Shaddenfreude, highly recommend it.

02:17.360 --> 02:18.360
It's great.

02:18.360 --> 02:21.480
I also do a lot of open source live streams.

02:21.480 --> 02:25.480
If you like seeing people struggle with computers, once again, it's great.

02:25.480 --> 02:26.960
You can watch me fail.

02:26.960 --> 02:31.040
The code for today's talk and a lot of my other code is on my GitHub.

02:31.040 --> 02:33.160
You can check it out.

02:33.160 --> 02:37.160
And there will be more pictures of my dog.

02:37.160 --> 02:42.520
In addition to who I am professionally, I'm trans, queer, Canadian, in America on a green

02:42.520 --> 02:45.400
card, I make great life choices.

02:45.400 --> 02:49.240
It was a great time to move to America and part of the broader leather community.

02:49.240 --> 02:51.000
I can make that joke now because I have a green card.

02:51.000 --> 02:54.840
It's slightly more difficult for them to kick me out.

02:54.840 --> 02:56.440
This is not directly related.

02:56.440 --> 03:00.480
There is no secret Canadian code modification tools.

03:00.480 --> 03:02.480
Everything we use is open source.

03:02.480 --> 03:04.920
There's no secret Canadian GitHub alternative.

03:04.920 --> 03:06.920
If you go to GitHub.ca, you don't find...

03:06.920 --> 03:08.680
Actually, I don't know what you find.

03:08.680 --> 03:10.240
Maybe you do find something cool.

03:10.240 --> 03:13.040
I'm imagining you don't.

03:13.040 --> 03:18.320
But this is something that I like mentioning because I think for us who are building big

03:18.320 --> 03:22.520
data products or machine learning things, it's super important that we look around and

03:22.520 --> 03:25.840
we see like, hey, who is on my team?

03:25.840 --> 03:28.960
And if you realize you're hanging out with only Canadians, that's fantastic.

03:28.960 --> 03:30.160
Enjoy the poutine.

03:30.160 --> 03:33.000
But maybe it's time to get some other perspectives.

03:33.000 --> 03:34.880
And if you don't know what poutine is, you're missing out.

03:34.880 --> 03:36.560
You should try it someday.

03:36.560 --> 03:38.560
Cheese curds and gravy and French fries.

03:38.560 --> 03:40.680
Best thing ever.

03:40.680 --> 03:42.000
Okay.

03:42.000 --> 03:43.840
So what is our problem?

03:43.840 --> 03:46.760
And so why do we care about automating upgrades?

03:46.760 --> 03:51.280
So fundamentally, our problem is we have unsupported versions of our big data tools and other data

03:51.280 --> 03:53.840
tools running in production.

03:53.840 --> 03:57.600
And this is a problem because when things go wrong, I get woken up.

03:57.600 --> 04:03.240
I don't like getting woken up to figure out what I did five years ago.

04:03.240 --> 04:05.480
And that's just not fun.

04:05.480 --> 04:09.880
The other option is sometimes I get woken up when I'm trying to focus.

04:09.880 --> 04:13.160
That also, sorry, not woken up, interrupted when I'm trying to focus.

04:13.160 --> 04:16.960
And this is important because we are also getting Spark 4 soon.

04:16.960 --> 04:19.200
That's super exciting, super lovely.

04:19.200 --> 04:23.480
There's going to be all kinds of new breaking API changes.

04:23.480 --> 04:25.760
And that's just going to be so much fun, right?

04:25.760 --> 04:26.760
Like, yeah.

04:26.760 --> 04:27.760
Anyways.

04:27.760 --> 04:31.440
And so I don't know about you, but I'm not looking forward to going back and trying to

04:31.440 --> 04:36.200
figure out all of the different things that I've built over the years and upgrading them,

04:36.200 --> 04:37.200
right?

04:37.200 --> 04:41.360
Like, I know I'm going to have to do it, but that is not the thing that excites me in

04:41.360 --> 04:46.080
my life, which leads into, like, why do we have these problems?

04:46.080 --> 04:48.520
Why do we have old things running in production?

04:48.520 --> 04:51.320
We have it because APIs change and code breaks.

04:51.320 --> 04:52.680
And then people are just like, you know what?

04:52.680 --> 04:54.400
I don't want to upgrade.

04:54.400 --> 04:56.000
Just keep running on the old version.

04:56.000 --> 04:57.360
It totally worked.

04:57.360 --> 04:58.640
It's fine.

04:58.640 --> 05:00.760
What could go wrong?

05:00.760 --> 05:02.960
The other one is like, this isn't fun, right?

05:02.960 --> 05:03.960
I don't know.

05:03.960 --> 05:08.880
Does anyone here wake up in the morning excited to upgrade their API usage?

05:08.880 --> 05:09.880
Yeah.

05:09.880 --> 05:10.880
Okay.

05:10.880 --> 05:12.680
So this is zero people, right?

05:12.680 --> 05:17.360
And the other possibility is, right, like, we could try and keep this old software alive,

05:17.360 --> 05:18.840
but we don't want to.

05:18.840 --> 05:22.720
So, how are we going to work around our problem?

05:22.720 --> 05:25.560
So we're going to use software, and then we're also going to have to deal a little bit with

05:25.600 --> 05:26.560
humans, right?

05:26.560 --> 05:29.440
We're going to do automated code updating.

05:29.440 --> 05:30.800
It's super fun.

05:30.800 --> 05:31.800
So much fun.

05:31.800 --> 05:34.200
If you took a compilers class, this is going to look very familiar.

05:34.200 --> 05:36.760
If you didn't take a compilers class, this is so cool.

05:36.760 --> 05:39.280
AppSection.x3s are really cool.

05:39.280 --> 05:43.400
And we're also going to do automated testing and validation and prod.

05:43.400 --> 05:45.360
So the social problem is much harder.

05:45.360 --> 05:47.120
I am completely unqualified to solve it.

05:47.120 --> 05:50.720
I work with other people who are much better at talking to humans.

05:50.720 --> 05:51.920
They did a fantastic job.

05:51.920 --> 05:53.360
They made newsletters.

05:53.360 --> 05:55.320
They tried to make the project exciting.

05:55.320 --> 05:56.960
That failed.

05:56.960 --> 05:59.240
And then they tried to make the project required.

05:59.240 --> 06:00.800
That failed.

06:00.800 --> 06:01.880
And then we set deadlines.

06:01.880 --> 06:02.880
They slipped.

06:02.880 --> 06:06.880
But for sure, totally, we're definitely going to hit our new deadline for real.

06:06.880 --> 06:07.880
Okay.

06:07.880 --> 06:11.520
And now, let's go and see how else we addressed it.

06:11.520 --> 06:15.600
So the other thing that we did is, like, hey, we have this problem that humans don't want

06:15.600 --> 06:16.720
to do a thing.

06:16.720 --> 06:19.800
What about if we made it so they didn't have to do as much work?

06:19.800 --> 06:22.640
And so that's sort of the approach that we took.

06:22.640 --> 06:24.640
We can automate a bunch of this.

06:24.640 --> 06:28.520
And the other part is, like, so we've got API changes, which we mentioned.

06:28.520 --> 06:33.000
And then the other thing that we have is testing code as a nightmare, especially code that

06:33.000 --> 06:38.280
you inherited and is called untitled underscore seven dot ipod dot notebook.

06:38.280 --> 06:43.560
I don't know what it does, let alone I can't make tests for it.

06:43.560 --> 06:45.280
It's terrible.

06:45.280 --> 06:47.120
So yeah, we have a problem.

06:47.120 --> 06:49.600
We're going to fix it with computers.

06:49.600 --> 06:54.680
Google has a lot of really lovely code mod tools that I saw while I was there.

06:54.680 --> 06:56.640
Super fantastic.

06:56.640 --> 07:00.120
This encouraged some counterproductive behavior.

07:00.120 --> 07:05.880
I don't know if any of you have used Google APIs and watched them change underneath you.

07:05.880 --> 07:11.520
So this is a double-edged sword, and we should heed the warnings before we go, like, super,

07:11.520 --> 07:15.160
super all in on this.

07:15.160 --> 07:16.920
So what are we going to do?

07:16.920 --> 07:19.080
So how are we going to move on?

07:19.080 --> 07:22.800
Basically speaking, we're not going to use regular expressions.

07:22.800 --> 07:26.800
For the most part, there's going to be a few times when regular expressions are like the

07:26.800 --> 07:29.640
simple hacky way, and we're just going to do it.

07:29.640 --> 07:31.280
For Scala, we use ScalaFix.

07:31.280 --> 07:33.880
For Python, we use something called PySparkler.

07:33.880 --> 07:35.880
For SQL, we use SQL Fluff.

07:35.880 --> 07:41.360
And for Java, we looked at it, and we were like, we don't have that many Java pipelines.

07:41.360 --> 07:43.640
Get them to update their code by hand.

07:43.640 --> 07:45.760
It's fine.

07:45.760 --> 07:47.160
We know where they work.

07:47.160 --> 07:48.160
Okay.

07:48.680 --> 07:50.480
So how do we figure out what rules to make?

07:50.480 --> 07:54.040
So we could read the release notes, but they're not very complete.

07:54.040 --> 07:58.600
We could look at the MIMA changes, and so Spark has a binary compatibility checker that

07:58.600 --> 08:04.040
it uses, but, oh, dear God, there is just so, so many things in there.

08:04.040 --> 08:08.280
Or we could do my favorite approach, which is run it in production, see what breaks,

08:08.280 --> 08:09.760
and then fix it afterwards.

08:09.760 --> 08:13.600
So we went with the YOLO approach, which is just like we're going to try migrating some

08:13.600 --> 08:15.320
things as it fails.

08:15.320 --> 08:18.600
We'll add the rules that it turns out we needed to add.

08:18.600 --> 08:20.400
So what do these rules look like?

08:20.400 --> 08:23.320
Today, we're just going to look at Scala and SQL.

08:23.320 --> 08:26.200
If you love Python, you can check out the GitHub repo.

08:26.200 --> 08:29.240
It's got some samples there.

08:29.240 --> 08:35.680
So in ScalaFix, we override this function called fix.

08:35.680 --> 08:39.520
We take an implicit semantic document that's really just the syntax tree, so that's the

08:39.520 --> 08:41.760
parsed version of the source code.

08:41.760 --> 08:46.360
And we specify the things that we're interested in looking in, and then we can write a recursive

08:46.360 --> 08:51.400
function which will match on this tree and generate a patch.

08:51.400 --> 08:56.600
And so here, we can see like, hey, do we see something that's calling the JSON reader?

08:56.600 --> 09:00.840
Because the JSON reader, certainly no one would use that ever, so they cited it was

09:00.840 --> 09:04.920
a great idea to change that API because who has JSON data?

09:04.920 --> 09:08.160
That was a joke, by the way.

09:08.160 --> 09:09.400
Everyone has JSON data.

09:09.400 --> 09:13.640
And so it turns out like, yeah, this actually happens a whole bunch.

09:13.640 --> 09:16.280
So we should write a rule for this.

09:16.280 --> 09:20.800
Do we see someone trying to read JSON data from an RDD?

09:20.800 --> 09:23.520
And if so, this is the path we're going to add.

09:23.520 --> 09:29.240
Now the really cool thing here is that we're matching on a syntax tree to produce new syntax

09:29.240 --> 09:30.240
tree.

09:30.240 --> 09:34.680
I can just say, like, swap this part of the syntax tree for this string, and then underneath

09:34.680 --> 09:38.560
the hood, Scala fixes very smart, turns it into a syntax tree.

09:38.560 --> 09:39.560
Everything's happy.

09:39.560 --> 09:40.560
I'm quite happy.

09:40.560 --> 09:47.000
I've got a bunch of sketchy hacks, and they're all inside of a function, sorry, a library

09:47.000 --> 09:48.720
called utils.

09:48.720 --> 09:49.720
So it's great.

09:49.720 --> 09:56.640
We hide all of our mistakes inside of utils because only nerds look inside of utils.Scala.

09:56.640 --> 09:57.640
Huzzah.

09:57.640 --> 10:02.800
And here you see we're recursing on the tree, and we just return nothing if we don't find

10:02.800 --> 10:05.440
any matches.

10:05.440 --> 10:12.560
SQL very similar, but the AST is a little bit fuzzier because we're using SQL Fluff,

10:12.560 --> 10:18.160
and it has to support a whole bunch of different versions of SQL, not just Spark SQL.

10:18.160 --> 10:19.600
Things are a little fuzzy.

10:19.600 --> 10:24.040
So we go ahead and we look and say, like, hey, do we see someone calling this function

10:24.040 --> 10:25.960
that we know has changed?

10:25.960 --> 10:29.680
If so, go ahead and extract out the part that we care about.

10:29.680 --> 10:36.360
And so we go ahead and we grab the third element because, God, whatever, don't worry

10:36.360 --> 10:37.640
about it.

10:37.640 --> 10:40.400
Magic number, totally fine, no mistakes.

10:40.400 --> 10:43.760
And then we go ahead and we say, like, hey, what is the type of this element?

10:43.760 --> 10:46.800
If it's a keyword and it's cast, we know we're good.

10:46.800 --> 10:47.800
The types are matching.

10:47.800 --> 10:49.600
Everything's fine.

10:49.600 --> 10:56.080
Otherwise, if it's not a keyword and the type is cast, we probably need to go ahead and

10:56.080 --> 10:57.080
change this.

10:57.080 --> 10:58.080
Because the types change.

10:58.080 --> 11:02.520
We actually need to add explicit casts into this function.

11:02.520 --> 11:08.160
And so we go ahead and we check it, and then we say, like, okay, function name, no, if

11:08.160 --> 11:09.640
it's cast, we're fine.

11:09.640 --> 11:13.120
If not, we go ahead and we produce these edits.

11:13.120 --> 11:16.280
Now unfortunately, SQL Fluff isn't quite as amazing.

11:16.280 --> 11:19.400
We can't just give it a string and have everything work.

11:19.400 --> 11:22.560
We have to produce, like, the chunk of the syntax tree.

11:22.560 --> 11:26.080
But this is still better than writing regular expressions, right?

11:26.080 --> 11:27.160
So much better.

11:27.160 --> 11:29.040
So this is totally fine.

11:29.040 --> 11:31.520
Everything's great.

11:31.520 --> 11:32.840
How do we know if it works?

11:32.840 --> 11:35.280
So there's a bunch of different things that we could do.

11:35.280 --> 11:38.880
We could try and make tests, but realistically, that's not going to happen.

11:38.880 --> 11:43.920
What we do is we do side-by-side writes and we use icebergs ability to stage commits.

11:43.920 --> 11:47.920
You can do the same thing with Delta Lake or Lake FS.

11:47.920 --> 11:48.920
They're all open source.

11:48.920 --> 11:53.120
I don't know how to do it with Delta Lake because I haven't used it, but I'm sure that

11:53.120 --> 11:56.040
you can do it.

11:56.040 --> 11:58.920
You might be saying, like, holding this sounds like you're running all of your data pipelines

11:58.920 --> 11:59.920
twice.

11:59.920 --> 12:00.920
Isn't that expensive?

12:00.920 --> 12:01.920
The answer is yes.

12:01.920 --> 12:03.120
Does it catch everything?

12:03.120 --> 12:05.320
The answer is no.

12:05.320 --> 12:08.000
But it's a hell of a lot better than just, right?

12:08.000 --> 12:13.520
We've got hope and a little bit of data, and together, are better than hope alone.

12:13.520 --> 12:17.920
So now we're going to come out and it crashed last night, but it's totally probably going

12:17.920 --> 12:19.920
to work today.

12:19.920 --> 12:23.880
Yeah, thank you.

12:23.880 --> 12:24.880
Thank you.

12:25.320 --> 12:31.000
We see I made a backup copy just in case it fails.

12:31.000 --> 12:38.440
What our demo does is it builds a regular Spark project, and it also makes a copy of

12:38.440 --> 12:40.200
it first.

12:40.200 --> 12:42.640
This is a Spark 2.4 project.

12:42.640 --> 12:48.480
Did I break it?

12:48.480 --> 12:49.480
Hello?

12:49.480 --> 12:50.480
Oh.

12:50.480 --> 12:51.480
Okay.

12:51.480 --> 12:52.480
We're back.

12:52.480 --> 12:53.480
Yay.

12:53.480 --> 12:54.480
Okay, cool.

12:54.480 --> 13:01.560
So you see here we've got everyone's favorite big data example, word count.

13:01.560 --> 13:07.920
And so, okay, this is going to go ahead and it's going to add the Scalifix plugin to our

13:07.920 --> 13:08.920
example.

13:08.920 --> 13:11.200
So we're just going to go ahead and say, like, yes, add Scalifix.

13:11.200 --> 13:16.440
And now it's going to run Scalifix, and it's going to run Scalifix with our additional

13:16.440 --> 13:19.760
rules that we created.

13:19.760 --> 13:21.760
So much fun.

13:22.120 --> 13:23.440
It's probably going to work.

13:23.440 --> 13:25.400
This is where it crashed yesterday.

13:25.400 --> 13:27.880
Everyone sent good vibes to my computer.

13:27.880 --> 13:29.880
Come on.

13:29.880 --> 13:32.880
Come on.

13:32.880 --> 13:34.880
How's that?

13:34.880 --> 13:36.680
Okay.

13:36.680 --> 13:39.480
You can see I subscribed to printlin debugging.

13:39.480 --> 13:42.320
Oh, well.

13:42.320 --> 13:46.400
And now, so it's run the first set of rules which do automated migrations, and now it's

13:46.400 --> 13:51.360
doing a second set of rules, and the second set of rules warns about things that we didn't

13:51.400 --> 13:55.960
think were important enough to create rules to automatically migrate, but we wanted developers

13:55.960 --> 13:57.600
to be aware of.

13:57.600 --> 14:02.400
And one of them is the group by key function change behavior between Spark 2 and Spark 3,

14:02.400 --> 14:04.800
because who uses group by key?

14:04.800 --> 14:09.880
Turns out everyone, very few people depended on the specific weird behavior, though.

14:09.880 --> 14:13.520
And so it's just warning, like, hey, I see you're doing this, and I applied a regular

14:13.520 --> 14:18.760
expression and I see some, like, bad words, not bad words in that ones that I use, but

14:18.760 --> 14:20.880
bad words in that, like, they're bad.

14:20.920 --> 14:21.920
Okay.

14:21.920 --> 14:23.480
And we say, like, everything's fine.

14:23.480 --> 14:27.160
It says we should review our changes, but we're not going to just, like, real developers.

14:27.160 --> 14:31.720
We're just going to hit enter and see if it works.

14:31.720 --> 14:37.320
And now it's going to go ahead and replace Spark 2.4.8 with Spark 3.3.1, and it's going

14:37.320 --> 14:44.640
to run these two pipelines side by side and compare their output.

14:44.640 --> 14:48.760
And so we will see if the demo finishes, ooh, five minutes left.

14:48.760 --> 14:49.760
Okay.

14:49.760 --> 14:52.400
We'll probably finish inside of five minutes.

14:52.400 --> 14:54.960
If it doesn't, we'll give up on the demo.

14:54.960 --> 14:55.960
That's okay.

14:55.960 --> 14:57.480
That's okay.

14:57.480 --> 15:01.840
So here we see it's running these two pipelines side by side.

15:01.840 --> 15:04.560
You can tell because Spark loves logging.

15:04.560 --> 15:06.040
And it passed.

15:06.040 --> 15:07.040
Yay.

15:07.040 --> 15:08.040
Okay.

15:08.040 --> 15:10.040
And then this, this, okay.

15:10.040 --> 15:11.040
Hmm.

15:11.040 --> 15:12.040
Okay.

15:12.040 --> 15:17.200
Well, this part didn't, and that's how you know it's a real demo, is that it failed at

15:17.200 --> 15:21.520
the final end part where it's copying the jar to a new special location, but that's,

15:21.520 --> 15:22.520
that's okay.

15:22.520 --> 15:25.760
The important part of the demo worked.

15:25.760 --> 15:31.920
So we'll call that mostly a win.

15:31.920 --> 15:33.920
And if we want, actually, yeah.

15:33.920 --> 15:34.920
Okay.

15:34.920 --> 15:37.920
I'm going to go.

15:37.920 --> 15:44.160
Oh, thank you.

15:44.160 --> 15:47.360
My lovely assistant.

15:47.360 --> 15:52.880
And so I wanted you to see that like, yes, this actually did update some code.

15:52.880 --> 16:00.440
So we go here, SRC main Scala, Spark demo project, word count dot Scala.

16:00.440 --> 16:06.120
And then we're going to go ahead and we're going to look at the regular version of this.

16:06.120 --> 16:08.240
Oh, God.

16:08.240 --> 16:09.840
Emax, come on.

16:09.840 --> 16:11.360
Now is not the time.

16:11.720 --> 16:14.320
Eight megs and constantly swapping.

16:14.320 --> 16:17.680
I can make that joke as an Emax user.

16:17.680 --> 16:18.680
Okay.

16:18.680 --> 16:24.800
So here we actually do see like it has made some small changes between the two of them.

16:24.800 --> 16:27.120
And, oh, sorry.

16:27.120 --> 16:28.120
Yeah.

16:28.120 --> 16:33.000
So here we see, for example, we have this old pattern of creating the spark context and

16:33.000 --> 16:36.080
it's been swapped for the new pattern of creating the spark context.

16:36.080 --> 16:39.200
And it's done other similar updates to the code.

16:39.200 --> 16:41.240
And the important thing is it now works.

16:41.240 --> 16:42.240
And this is fantastic.

16:42.240 --> 16:44.800
I think it's really cool.

16:44.800 --> 16:45.800
Thank you.

16:45.800 --> 16:46.800
Thank you.

16:46.800 --> 16:48.800
Hand for my assistant, please.

16:48.800 --> 16:52.120
Thank you.

16:52.120 --> 16:56.440
So I'm super stoked that the demo did not crash.

16:56.440 --> 17:03.680
Unlike last night, I switched it back to I was running a nightly build of the JVM and

17:03.680 --> 17:06.400
not surprisingly that didn't go well.

17:06.400 --> 17:07.640
Okay.

17:07.640 --> 17:11.480
So this is all cool, but like where does this fail?

17:11.480 --> 17:14.480
So this kind of fails when it comes to dependencies, right?

17:14.480 --> 17:17.520
Like we can only update the code that you've got.

17:17.520 --> 17:19.000
We don't rewrite byte code.

17:19.000 --> 17:20.920
We just rewrite source code.

17:20.920 --> 17:25.640
So if you're depending on something that doesn't support the new version of spark, it's not

17:25.640 --> 17:26.640
going to work out.

17:26.640 --> 17:32.560
The good news is for us, we got to this so late that all of our dependencies were upgraded.

17:32.560 --> 17:39.240
So there's something to be said for waiting right until the software goes end of life.

17:39.240 --> 17:41.400
Don't tell the security people.

17:41.400 --> 17:43.760
I said that.

17:43.760 --> 17:47.320
The other one that doesn't work super well with is programming language changes.

17:47.320 --> 17:50.600
In theory, that was actually the original purpose of ScalaFix.

17:50.600 --> 17:56.520
In practice, this didn't work so well for Scala 211 specifically because it's just so

17:56.520 --> 17:57.520
old.

17:57.520 --> 18:02.240
We had a bunch of Scala 211 code.

18:02.240 --> 18:06.320
So in conclusion, you should definitely check out the repo.

18:06.320 --> 18:07.320
It's here.

18:07.320 --> 18:08.320
It's spark-upgrade.

18:08.320 --> 18:12.280
It is in my personal GitHub, but a whole bunch of other people have contributed to it.

18:12.280 --> 18:13.280
They're awesome.

18:13.280 --> 18:14.280
I'm lazy.

18:14.280 --> 18:16.920
I wouldn't do all of this work myself.

18:16.920 --> 18:19.400
Thanks to my employer again for sending me here.

18:19.400 --> 18:22.880
I'm super excited that I get to hang out with a bunch of other nerds.

18:22.880 --> 18:27.480
The good news from this talk is that we haven't made a system so powerful that the spark people

18:27.480 --> 18:30.600
don't care about making breaking API changes.

18:30.600 --> 18:35.480
The bad news is we haven't made a system that's so powerful that we can't just not

18:35.480 --> 18:37.720
care about breaking API changes.

18:37.720 --> 18:41.200
The excellent news is that my dog is cute as fuck.

18:41.200 --> 18:42.200
He's here.

18:42.200 --> 18:46.000
I said that at the end of my talk just in case I'm not allowed to swear.

18:46.000 --> 18:47.000
He's really cute.

18:47.000 --> 18:48.200
His name is Professor Timbit.

18:48.200 --> 18:50.600
I miss him so, so much.

18:50.600 --> 18:54.200
Y'all are lovely, but I miss my dog.

18:54.200 --> 18:57.160
Hopefully there's time for a question, maybe.

18:57.160 --> 18:58.360
Yes?

18:58.440 --> 19:00.680
We can also do...

19:00.680 --> 19:01.680
Thank you.

19:01.680 --> 19:02.680
Thank you all.

19:02.680 --> 19:11.680
Have a couple of minutes for questions.

19:11.680 --> 19:18.600
Thank you very much for the talk.

19:18.600 --> 19:19.800
Very interesting.

19:19.800 --> 19:22.480
One general question out of curiosity.

19:22.480 --> 19:26.880
How long did it take to convert everything?

19:26.880 --> 19:30.880
Because you just showed like, I don't know how big the script was, but I can imagine

19:30.880 --> 19:36.040
just how big the repositories that you guys have.

19:36.040 --> 19:37.040
Totally.

19:37.040 --> 19:39.320
So that's a great question.

19:39.320 --> 19:41.920
It takes a really, really long time to convert everything.

19:41.920 --> 19:47.240
And we actually, internally, we have a whole bunch of different projects.

19:47.240 --> 19:52.400
One of them is a project that goes through all of the repositories because we have a

19:52.400 --> 19:58.400
whole bunch of different repositories, and it generates PRs to these projects.

19:58.400 --> 20:03.680
And that code runs daily.

20:03.680 --> 20:05.880
And it doesn't actually catch everything.

20:05.880 --> 20:10.960
So what we do is we generate the changes, and then, as I mentioned, we sort of did the

20:10.960 --> 20:13.840
YOLO run in production approach to life.

20:13.840 --> 20:19.160
So we'll look at these changes, and especially for SQL, it'll be like, hey, we do this shadow

20:19.160 --> 20:20.160
run.

20:20.160 --> 20:21.360
Does it look like it works?

20:21.360 --> 20:26.520
And if not, we actually flag it for review rather than raising the PR so that we can

20:26.520 --> 20:31.480
go back and say, hey, do I need to add a new rule, or is this a one-off special case where

20:31.480 --> 20:34.640
we'll just have a developer deal with it?

20:34.640 --> 20:39.040
So I know that's not exactly an answer, but several hours.

20:39.040 --> 20:40.040
Okay.

20:40.040 --> 20:41.040
Thanks.

20:41.040 --> 20:42.040
Any other questions?

20:42.040 --> 20:43.040
Yeah.

20:43.040 --> 20:44.040
There's one right there.

20:44.040 --> 20:45.040
No.

20:45.040 --> 20:55.040
How many rules did you end up coming up with for this migration from two to three?

20:55.040 --> 20:57.800
And do you anticipate going from three to four?

20:57.800 --> 20:58.800
What?

20:58.800 --> 21:00.440
Do you anticipate going from three to four?

21:00.440 --> 21:01.440
Oh, yeah.

21:01.440 --> 21:02.440
Okay.

21:02.440 --> 21:03.440
So two questions.

21:03.440 --> 21:04.440
I love them.

21:04.440 --> 21:07.440
I don't remember how many rules we came up with.

21:07.440 --> 21:12.360
For Scala, it wasn't a huge number, and that's because while there are a lot of breaking

21:12.360 --> 21:21.080
API changes in Scala, our usage of the APIs in Scala is more narrow, and so I'm very thankful

21:21.080 --> 21:25.160
for that.

21:25.160 --> 21:33.920
For SQL, I think we ended up with around 20, maybe between 10 and 20.

21:33.920 --> 21:42.840
And for Python, I haven't kept track, mostly because that code has been working really

21:42.840 --> 21:46.720
well, and so some of my other teammates have been working more on the Python side, so I

21:46.720 --> 21:49.800
don't remember how many rules we made there.

21:49.800 --> 21:52.400
But they're all in the GitHub.

21:52.400 --> 21:55.600
As for do we anticipate going from Spark three to four?

21:55.600 --> 21:57.320
Yes.

21:57.320 --> 22:01.760
Probably not like the same month Spark four is released.

22:01.760 --> 22:07.360
I love Spark, and we'll make Spark four available internally, but we're not going to go ahead

22:07.360 --> 22:11.760
and start pushing users to migrate to it right away.

22:11.760 --> 22:18.760
We normally wait a little bit for things to stabilize before we start doing managed migrations

22:18.760 --> 22:27.120
just because it's better for our sanity, and there's more fixes to the code base in general.

22:27.120 --> 22:29.320
Cool.

22:29.320 --> 22:31.000
We got another question.

22:31.440 --> 22:33.240
Any more questions?

22:33.240 --> 22:34.240
Okay.

22:34.240 --> 22:35.240
Cool.

22:35.240 --> 22:36.240
Hazar.

22:36.240 --> 22:37.240
Actually, hold on.

22:37.240 --> 22:39.760
You can keep talking because the next speaker is on the bus.

22:39.760 --> 22:40.760
Oh, okay.

22:40.760 --> 22:45.000
So with the next speaker is on the bus, I'm super excited, and we can go ahead and we can

22:45.000 --> 22:50.960
actually look at more of the changes that it made to the code, which I sort of skimmed

22:50.960 --> 22:55.480
over because I didn't want to eat into the next person's time.

22:55.480 --> 23:00.640
So it's kind of basic, right?

23:00.640 --> 23:08.280
But we can see here, this is the side-by-side for the Scala one, and we can actually go

23:08.280 --> 23:15.280
ahead and what we're going to do is we're going to go outside of our end-to-end, and

23:15.280 --> 23:20.960
we're going to go ahead and we're going to look at some of the other SQL rules.

23:20.960 --> 23:24.520
Oh, fancy.

23:24.680 --> 23:26.680
I don't...

23:26.680 --> 23:27.680
Okay.

23:27.680 --> 23:30.680
Oh, this is so that it's better to read.

23:30.680 --> 23:31.680
Okay.

23:31.680 --> 23:32.680
Okay.

23:32.680 --> 23:33.680
Okay.

23:33.680 --> 23:34.680
Cool.

23:34.680 --> 23:35.680
Fantastic.

23:35.680 --> 23:36.680
And we're going to go ahead.

23:36.680 --> 23:41.680
I need my lovely assistant again.

23:41.680 --> 23:44.680
Thank you.

23:44.680 --> 23:50.040
Thank you so much.

23:50.040 --> 23:53.160
Hand for my new lovely assistant.

23:53.160 --> 24:00.760
So here we see one of the things that changed between Spark 2 and Spark 3 is that previously

24:00.760 --> 24:06.120
you would be able to do just an arbitrary cast to things as integers, and even if they

24:06.120 --> 24:09.960
weren't integers, it would do kind of a fuzzy conversion.

24:09.960 --> 24:14.240
But in practice, if you wanted to parse a string as an integer rather than casting

24:14.240 --> 24:17.760
string to an integer, you should use int at.

24:17.760 --> 24:21.480
And so here we see we've got something similar.

24:21.840 --> 24:23.840
We use a lot of print debugging.

24:23.840 --> 24:27.280
It's not great.

24:27.280 --> 24:31.640
But what we do here is we return this lint result, and what it's just doing is it's taking

24:31.640 --> 24:37.760
this expression and swapping it to an int when we see a cast with a data type of int.

24:37.760 --> 24:38.760
So much fun.

24:38.760 --> 24:43.720
There's a lot more rules, but I didn't do a git pull on this because the demo barely

24:43.720 --> 24:49.160
worked, and I was just like, let's not tempt fate and do a git pull because I hadn't tested

24:49.160 --> 24:51.280
the end-to-end demo.

24:51.280 --> 24:53.040
But this is kind of cool.

24:53.040 --> 24:56.320
We've got similar updates to our format string.

24:56.320 --> 24:57.320
Super fun.

24:57.320 --> 24:58.480
Oh, right.

24:58.480 --> 25:03.040
And then char versus string types also got updated.

25:03.040 --> 25:05.880
Super fun there as well.

25:05.880 --> 25:07.400
And where was another one?

25:07.400 --> 25:09.560
I want to find it.

25:09.560 --> 25:11.520
Sorry.

25:11.520 --> 25:14.400
Then we've got, there's a rule down at the bottom.

25:14.400 --> 25:15.400
Oh, no.

25:15.400 --> 25:16.400
Okay.

25:16.400 --> 25:19.920
I guess the rule that I was looking for isn't in this version of the code.

25:19.920 --> 25:26.680
Let's go back to ScalaFix.

25:26.680 --> 25:33.760
So the other cool thing about this, sorry, doot, doot, doot.

25:33.760 --> 25:39.880
So one of the really cool things about ScalaFix, just while we're waiting, is that you can

25:39.880 --> 25:41.160
test your rules.

25:41.160 --> 25:47.680
And so, for example, like, I wrote these accumulators, and this is the old bad style

25:47.680 --> 25:51.880
of writing accumulators, and I was like, okay, let's make sure that it updates to the

25:51.880 --> 25:54.640
new good style of accumulators.

25:54.640 --> 25:59.800
And this is super convenient because I don't have to manually construct syntax trees.

25:59.800 --> 26:02.880
ScalaFix just has built-in functionality for this.

26:02.880 --> 26:07.600
And we see here what this rule does is it actually throws out a bunch of situations.

26:07.600 --> 26:10.680
And it's actually going to generate a bunch of warning messages.

26:10.680 --> 26:15.880
But there's situations where, like, this doesn't directly translate to the new API easily.

26:15.880 --> 26:19.840
So we just told users, like, hey, you need to make a change here.

26:19.840 --> 26:23.760
But we'll get it to compile, and then it'll pass the test, and it'll yell at you because

26:23.760 --> 26:25.280
you're trying to access a null.

26:25.280 --> 26:26.280
It's not perfect.

26:26.280 --> 26:30.040
Like, this is very much like a, how would I say this?

26:30.040 --> 26:32.680
This is a very mediocre rule.

26:32.680 --> 26:38.600
But in practice, we didn't find all that many people were creating accumulators with fixed

26:38.600 --> 26:40.760
values to start at.

26:40.760 --> 26:45.760
But the one that we did see was people creating accumulators that explicitly started at zero

26:45.760 --> 26:51.720
long, and so that we just converted to a long accumulator.

26:51.720 --> 26:57.360
And then the other one that I saw here was I also added some tests to make sure that,

26:57.360 --> 27:02.240
like, I had a rule which was applying itself too eagerly.

27:02.240 --> 27:06.680
So I also created a test which was just, like, make sure that this rule doesn't do anything

27:06.680 --> 27:11.600
if it's not, like, encountering the thing that I wanted it to do.

27:11.600 --> 27:15.680
So we can also make essentially negative tests for AST transformations.

27:15.680 --> 27:17.200
That's super convenient.

27:17.200 --> 27:24.480
How much time do I need to kill?

27:24.480 --> 27:28.880
How much time do I need to kill?

27:28.880 --> 27:31.320
Do we know how long the bus is going to be?

27:31.320 --> 27:32.920
Okay, cool.

27:32.920 --> 27:34.040
Okay.

27:34.040 --> 27:38.080
So we see another one, the group by key thing that I told you about.

27:38.080 --> 27:41.360
We actually had two different situations.

27:41.360 --> 27:46.720
These are ones that we could automatically rewrite, and so that's what we do here.

27:46.720 --> 27:51.200
And so here we see, like, the situation where someone was explicitly using the column name

27:51.200 --> 27:53.560
in a way which we could detect.

27:53.560 --> 27:58.800
But then we also have the situation where, like, we weren't super sure, and so these

27:58.800 --> 28:01.160
ones we did with a warning.

28:01.160 --> 28:06.200
And so we said, like, hey, this should generate a warning because we don't know for sure what's

28:06.200 --> 28:08.080
going on here.

28:08.080 --> 28:11.400
So we want to generate the warning, but in the other situations where we could do the

28:11.400 --> 28:16.160
full rewrite, we made sure that the full rewrite was able to be applied, which I think is kind

28:16.160 --> 28:22.840
of cool from sort of, like, a point of view of you don't have to get everything right,

28:22.840 --> 28:27.440
and you can, like, add these warnings in places where, like, it's worth it to let people know

28:27.440 --> 28:32.440
their code might not work, but, you know, it's not 100% required.

28:32.720 --> 28:33.800
Um...

28:33.800 --> 28:35.240
Choo-choo-choo.

28:35.240 --> 28:36.240
Cool.

28:38.760 --> 28:40.240
Let's see here.

28:41.600 --> 28:43.160
Ah...

28:43.920 --> 28:45.120
Just a quick interruption.

28:45.120 --> 28:46.800
The next speaker is going to be late.

28:46.800 --> 28:52.200
He texted us that he's still on the bus, so we're letting Holden entertain you.

28:52.760 --> 28:53.720
Oh, I got an idea.

28:53.720 --> 28:54.720
I got an idea.

28:54.720 --> 28:55.720
Hi.

28:55.720 --> 28:56.720
I'm just a speaker.

28:56.720 --> 28:57.720
What does that mean?

28:57.720 --> 28:58.720
Where am I?

28:58.720 --> 28:59.720
Oh.

29:00.440 --> 29:01.440
Yeah, I got a...

29:01.440 --> 29:05.320
I think I got another minute of something fun that I want to talk about if it's okay.

29:05.320 --> 29:09.600
So the other thing that we sort of, like, lost over was the, like, side-by-side comparison

29:09.600 --> 29:11.880
in pipeline runs, right?

29:11.880 --> 29:14.640
And so that's totally really...

29:14.640 --> 29:16.120
I think it's really neat, right?

29:16.120 --> 29:22.360
Like, because it's super important because people don't write tests at the end of the

29:22.360 --> 29:25.280
day, and that makes me sad.

29:25.280 --> 29:30.240
But we've got this pipeline comparison project, and...

29:30.240 --> 29:31.240
Oh, God.

29:31.240 --> 29:33.560
I'm just remembering how ugly this code is.

29:33.560 --> 29:36.560
Please don't judge me.

29:36.560 --> 29:42.160
This code was originally written at a conference and then made it into production, as you can

29:42.160 --> 29:47.520
tell by the fact that it's called domagic.py.

29:47.520 --> 29:49.040
Very sorry.

29:49.040 --> 29:51.240
Very sorry.

29:51.240 --> 29:57.760
So yeah, so this domagic.py does a bunch of really interesting and terrible things.

29:57.760 --> 30:02.000
And I was mentioning how we mostly don't do regular expressions, but we do a little bit.

30:02.000 --> 30:06.920
And one of the things is when you've got Spark 2 versus Spark 3 and you've got Scala or Java

30:06.920 --> 30:09.320
code, you're going to need different jars.

30:09.320 --> 30:13.280
Whereas in Python and SQL, like, we could maybe just be using the same files, or we

30:13.280 --> 30:16.520
can use the same files with a little bit of a transformation.

30:16.520 --> 30:21.920
But so for the jars, we use a really nasty, really terrible, regular expression to just

30:21.920 --> 30:27.520
kind of extract what we think the version 3 version of our jar is going to be.

30:27.520 --> 30:31.320
And then this is convenient because we can run it side by side.

30:31.320 --> 30:35.440
And then so we've got sort of different options.

30:35.440 --> 30:39.560
Here we've got it so that you can specify the input table.

30:39.560 --> 30:46.400
But I actually did a hack that I'm super proud of because I'm a bad person.

30:46.400 --> 30:55.040
Where we made this plug-in, Iceberg Spark WAP plug-in, where what we do is, oh god, we

30:55.040 --> 31:01.760
use the Iceberg listener and we output this string any time something happens to the logs.

31:01.760 --> 31:05.840
And so if anyone's touching a table while their job is running, we know what tables

31:05.840 --> 31:09.960
it's worth so we can go back and run our comparison on these two tables.

31:09.960 --> 31:13.920
We actually have some special code that goes ahead and looks at these tables before doing

31:13.920 --> 31:20.000
the comparison and says, if the user updated more than 1,000 partitions worth of data,

31:20.000 --> 31:24.440
just don't bother and tell the user they're responsible for validating their data.

31:24.440 --> 31:32.480
And if they're touching more than 1,000 tables, sorry, 1,000 partitions in a table, they should

31:32.480 --> 31:34.800
really have some reliable tests.

31:34.800 --> 31:40.560
For the people who are touching five or 100, like I get it, untitled underscore seven, it's

31:40.560 --> 31:41.960
great in production.

31:42.320 --> 31:49.240
When you're updating that much data, maybe it's not time to depend on Holden's sketchy

31:49.240 --> 31:52.800
do magic dot py.

31:52.800 --> 31:56.080
So I think this is really cool.

31:56.080 --> 32:05.280
And we're going to go back to our friend Pipeline Compare and down to our friend Table Compare.

32:05.280 --> 32:09.360
And so Table Compare is really basic.

32:09.360 --> 32:15.720
And there's actually an updated version internally that I need to bring out that does better

32:15.720 --> 32:17.520
tolerances.

32:17.520 --> 32:21.760
But we just go ahead and we compare these two tables with sort of traditional drawing,

32:21.760 --> 32:27.600
which is part of why we had this limit on the number of partitions.

32:27.600 --> 32:31.320
Because when we didn't have this limit on the number of partitions and we tried to do

32:31.320 --> 32:35.760
these comparisons with some of the pipelines that ran on all of the user data, everyone

32:35.760 --> 32:37.120
was very sad.

32:37.120 --> 32:40.400
And we took down production.

32:40.400 --> 32:42.400
I hope that part.

32:42.400 --> 32:49.240
Yeah, anyways, there was an incident and I got woken up when we did not have that.

32:49.240 --> 32:51.600
And so, yeah, all kinds of fun.

32:51.600 --> 32:56.480
But you see here the thing, the magic here is the snapshot ID, because the other thing

32:56.480 --> 33:01.280
that we output in our listener is what snapshot IDs we're writing to.

33:01.280 --> 33:02.480
Super convenient.

33:02.480 --> 33:07.040
And Iceberg allows us to read from snapshots even if they never got committed.

33:07.040 --> 33:10.920
There's a new thing in the new version of Iceberg that allows for branching that would

33:10.920 --> 33:16.860
be even better because then we would have named things rather than random git hashes.

33:16.860 --> 33:22.960
But we're not running that and it's also not supported in the really old versions of Spark.

33:22.960 --> 33:26.800
And because we want to do the migrations from the really old to the really new, I went

33:26.800 --> 33:28.880
with sort of the lowest common denominator.

33:29.360 --> 33:31.240
And that's kind of how we ended up there.

33:31.240 --> 33:35.000
Okay, that's all that I had that I thought was interesting.

33:35.000 --> 33:38.760
And I think there was someone else who had something that was interesting.

33:38.760 --> 33:40.760
Do you want to come and do your interesting bit?

33:42.680 --> 33:44.280
Thanks to Holden for filling in.

33:44.280 --> 33:51.280
Does anyone have any questions?

33:51.280 --> 33:53.280
Does anyone have any questions?

34:08.280 --> 34:09.280
That's that?

34:09.280 --> 34:10.280
Yeah, all right.

34:10.280 --> 34:11.880
First of all, thank you for the talk.

34:11.880 --> 34:14.480
I have a quick question in the summary of your talk.

34:14.480 --> 34:19.280
You also mentioned that if time permits, you might have an overview of the changes coming

34:19.280 --> 34:21.440
in Spark 4.

34:21.440 --> 34:22.880
Do you have this overview?

34:22.880 --> 34:29.040
Yeah, so if you're interested in the changes coming in Spark 4, the place to look is the

34:29.040 --> 34:30.880
Spark Jira.

34:30.880 --> 34:34.960
And there's actually like this meta tracking Jira that's in there.

34:34.960 --> 34:39.120
And you can see sort of like the things that we're planning on coming.

34:39.120 --> 34:46.600
Historically, I would say without naming names, there's a particular vendor that loves to

34:46.600 --> 34:54.600
show up at the last minute with the giant piles of code and just kind of yolo it as

34:54.600 --> 34:57.760
a nice surprise for everyone.

34:57.760 --> 35:00.640
So this Jira will give you a good idea of what's coming.

35:00.640 --> 35:08.600
But my guess is there will be a surprise that we find out about in June, just based on history.

35:08.600 --> 35:09.800
I could be wrong.

35:09.800 --> 35:12.120
Maybe everything is actually planned this time.

35:12.120 --> 35:14.120
That would be a pleasant surprise.

35:14.120 --> 35:19.440
But there's a non-zero chance that there will be something new in June too.

35:19.440 --> 35:20.440
Cool.

35:20.440 --> 35:21.440
Okay.

35:21.440 --> 35:23.000
Take it away, my friend.

35:23.000 --> 35:24.000
Or no, you don't.

35:24.000 --> 35:25.000
Oh, okay.

35:25.000 --> 35:28.600
You've got a USB key.

35:28.600 --> 35:33.560
I think my employer would be mad if I let you plug the USB key into my work laptop.

35:33.560 --> 35:35.160
I enjoy being employed.

35:35.160 --> 35:36.720
No, no.

35:36.720 --> 35:37.760
I just had more time to kill.

