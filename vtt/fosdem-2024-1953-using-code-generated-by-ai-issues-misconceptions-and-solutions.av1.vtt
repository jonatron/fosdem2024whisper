WEBVTT

00:00.000 --> 00:08.000
We also have the Matrix Room Up and Running, which is great.

00:08.000 --> 00:11.760
And I have the pleasure of introducing you to Andrew.

00:11.760 --> 00:15.000
You live near Oxford, which I believe is pretty cool.

00:15.000 --> 00:17.280
I'm a Texan, I wouldn't know.

00:17.280 --> 00:19.580
You love the Oxford music scene?

00:19.580 --> 00:25.680
You once played croquet for Cambridge University against Oxford, and he has a great joke for

00:25.680 --> 00:27.240
you.

00:27.240 --> 00:30.040
What is brown and sticky?

00:30.040 --> 00:32.640
A stick.

00:32.640 --> 00:33.640
Take it away, Andrew.

00:33.640 --> 00:34.640
My kids like that.

00:34.640 --> 00:41.560
Happy Fosfemme, everyone.

00:41.560 --> 00:43.080
So it's great to see everyone here.

00:43.080 --> 00:50.080
I am a lawyer and I've been advising on AI for quite a long time.

00:50.080 --> 00:51.080
You can hear me.

00:51.080 --> 00:52.600
That's better.

00:52.600 --> 00:58.280
Clearly, the emergence of large language models has meant that there's a lot more analysis

00:58.280 --> 01:00.160
going on in the legal context behind that.

01:00.160 --> 01:03.320
So I just thought I'd spent half an hour or so just going through some of my thought

01:03.320 --> 01:11.640
processes when I'm analysing mainly copyright law as it relates to AI machine learning and

01:11.640 --> 01:14.120
large language models.

01:14.120 --> 01:17.880
You may have heard a number of myths.

01:17.880 --> 01:22.560
So the first one is what models are essentially data.

01:22.560 --> 01:28.360
Data are facts and facts can't be covered by copyright.

01:28.360 --> 01:31.200
So statement number one.

01:31.200 --> 01:35.320
Statement number two, you may be aware that in various jurisdictions throughout the world

01:35.320 --> 01:42.240
there are different exemptions that exist in copyright law to enable you to gather and

01:42.240 --> 01:48.800
use data to ingest data for machine learning and data mining purposes.

01:48.800 --> 01:57.080
So you may hear that gathering training data within one of these copyright exemptions solves

01:57.080 --> 01:59.320
any copyright problems that you may have.

01:59.320 --> 02:04.160
So you really don't have to worry about any copyright issues.

02:04.160 --> 02:11.520
The third thing that you may hear is that output that is generated by generative AI cannot

02:11.600 --> 02:15.040
be subject to copyright.

02:15.040 --> 02:24.000
And the fourth one is that as a result AI generated code cannot trigger copy left obligations.

02:24.000 --> 02:28.080
So let's look at some of these statements in slightly greater depth.

02:28.080 --> 02:33.080
Now I'm going to do this in a slightly strange way because I've only got half an hour or

02:33.080 --> 02:34.080
so.

02:34.080 --> 02:37.800
I'm not able to go through all of my thought processes in great depth.

02:37.880 --> 02:42.240
What I propose to do is to give you the conclusions of my thinking first and then I'll give you

02:42.240 --> 02:45.640
a flavor of some of the thought processes that led to them.

02:45.640 --> 02:48.400
So you will by necessity only be getting part of the picture.

02:48.400 --> 02:51.360
I do apologize for that.

02:51.360 --> 02:57.160
So first of all, my belief is that a large language model is capable of containing and

02:57.160 --> 03:01.880
I put containing in inverted commas there because what that means is subject to a certain

03:01.880 --> 03:03.640
amount of interpretation.

03:03.640 --> 03:09.080
And I believe that it can contain copyright works or derivative works of copyright works.

03:09.080 --> 03:18.560
Secondly, I believe that if the training data was ingested under a copyright exemption,

03:18.560 --> 03:23.840
that doesn't automatically mean that that exempts any output from copyright protection

03:23.840 --> 03:24.840
as well.

03:24.840 --> 03:31.680
Third, the generated output is likely to be subject to copyright.

03:31.720 --> 03:35.520
This is a statement that will vary significantly from jurisdiction to jurisdiction.

03:35.520 --> 03:39.440
I'm licensed to practice in England and Wales and it's certainly true there.

03:39.440 --> 03:44.920
It may not be quite as true in other jurisdictions, but certainly from my jurisdiction's perspective

03:44.920 --> 03:53.040
that generated output is likely to be subject to copyright.

03:53.040 --> 04:01.360
And also under the English and Welsh jurisdiction, the output that's generated by a prompt view

04:01.400 --> 04:07.800
of entered belongs to you or possibly to your employer.

04:07.800 --> 04:15.640
But even having said that, then it means that AI generated output can be infringing and

04:15.640 --> 04:23.120
similarly it can also trigger copy left effects.

04:23.120 --> 04:29.120
So what I'm going to talk about now is a few things that you need to bear in mind about

04:29.240 --> 04:36.240
copyright and about the process of generating models and generating outputs from generative AI.

04:36.240 --> 04:39.000
So again, I'm going through these fairly quickly.

04:39.000 --> 04:42.080
I'm not necessarily going to link them in detail together.

04:42.080 --> 04:46.360
But when analyzing this, the three things you need to bear in mind from a copyright perspective

04:46.360 --> 04:50.320
are the copyright can potentially impinge at three points.

04:50.320 --> 04:57.840
So first of all, the point when the training data is ingested and the model is created in the first place.

04:57.960 --> 05:04.280
Secondly, and this is the one that people tend to forget about when the whole model is transferred

05:04.280 --> 05:06.760
from distributed from one place to another.

05:06.760 --> 05:13.520
And this is particularly relevant when that model is distributed over jurisdictional boundaries.

05:13.520 --> 05:21.600
And the third one is that we need to consider from a copyright perspective the point at which those results were output.

05:21.600 --> 05:27.640
So there's also potential of copyright impinging at that point as well.

05:27.640 --> 05:31.560
Now, there are a few things that you need to understand about copyright.

05:31.560 --> 05:35.800
And all the developers I've met have a pretty good grasp of copyright in theory,

05:35.800 --> 05:41.160
but there are always some areas around the edges that they're potentially a little unsure about.

05:41.160 --> 05:43.760
Many lawyers are unsure about these as well.

05:43.760 --> 05:50.760
And a lot of the arguments that we employ when we're talking about copyright analysis of large language models,

05:50.760 --> 05:53.560
they do tend to involve these edge cases.

05:53.600 --> 06:01.120
So there's a few things that you need to bear in mind when you are considering the application of copyright to AI,

06:01.120 --> 06:04.640
and these are just characteristics of copyright in general.

06:04.640 --> 06:09.880
So first of all, it's possible that more than one copyright can exist in a work simultaneously.

06:09.880 --> 06:14.520
So for example, if I write an opera that's based on the Lord of the Rings,

06:14.520 --> 06:21.360
then my creative input has gone into writing that opera, and I just like to tell you now it wouldn't be a very good one.

06:21.400 --> 06:27.080
And that will therefore be both a copyright work that I've created,

06:27.080 --> 06:30.400
but it's also a derivative work of Lord of the Rings.

06:30.400 --> 06:37.240
So if you want to perform that opera, you're going to need both a license from Middle Earth Enterprises,

06:37.240 --> 06:43.160
which is the organization that holds the rights or the relevant performing rights in the Lord of the Rings,

06:43.160 --> 06:45.120
but you're also going to need a license from me as well.

06:45.120 --> 06:49.680
So there's at least two copyrights being held in this opera simultaneously,

06:49.680 --> 06:56.440
and you're going to need licenses from both of those copyright holders in order to perform the work.

06:56.440 --> 06:59.560
And the classic example here is the Linux kernel,

06:59.560 --> 07:06.000
which will have many thousands, possibly tens of thousands of different copyright holders simultaneously,

07:06.000 --> 07:15.400
which is the main reason that we will never see it re-licensed under any license other than GPL version 2 only.

07:15.440 --> 07:22.640
So if you wanted to re-license it, then you would basically need to have permission from all of those copyright holders,

07:22.640 --> 07:26.240
or you would need to extract their copyright works from the kernel. That's never going to happen.

07:29.000 --> 07:35.160
So just stepping back a little bit, software is covered by copyright in just about the same way as literary works are.

07:35.160 --> 07:44.600
This is sort of the legal fiction that was established back in the day when the legal systems were thinking about how software should be protected under copyright.

07:44.600 --> 07:47.720
Indeed, if it should be protected at all.

07:47.720 --> 08:00.160
And one very key characteristic, one key piece of the philosophy behind copyright is this distinction between an idea and an expression.

08:00.160 --> 08:07.080
And again, this distinction is very clearly laid out in US copyright law.

08:07.080 --> 08:10.360
It's also laid out in European copyright law, but not quite so clearly.

08:10.440 --> 08:22.520
But the copyright directive, the software directive does make explicit reference to this distinction between the ideas and the facts and the expression of those ideas.

08:22.520 --> 08:29.120
So basically the facts themselves cannot be subject to copyright, but the expression of those facts can.

08:29.120 --> 08:32.720
And so one thing to bear in mind.

08:32.720 --> 08:37.160
Another thing to bear in mind is that copyright infringement is not subject to intent.

08:37.400 --> 08:41.200
It doesn't matter whether you intended to infringe copyright or not.

08:41.200 --> 08:50.320
If you do an act which causes copyright to be breached, if you copy something, believing that it was yours to copy or believing that you had a license to copy it.

08:50.320 --> 08:59.520
Then from a civil law perspective, we're not talking about the criminal law here, but from civil law perspective, that still counts as copyright infringement.

08:59.520 --> 09:10.360
And the third thing to realize is that if someone produces a work independently, which is the same as an existing copyright work, then each copyright owner will retain their own copyright in that work.

09:10.360 --> 09:12.280
So there's no infringement.

09:12.280 --> 09:21.040
So if I write a little melody and then somebody else independently comes up with an absolutely identical melody, they haven't copied me.

09:21.040 --> 09:23.400
They've had no opportunity to listen to that melody.

09:23.400 --> 09:29.560
Then they would equally hold the copyright in their melody as I hold in my melody.

09:29.560 --> 09:41.640
So those are three things that tend to be a little bit counterintuitive about copyright and their concepts that I draw on when I'm talking about the rest of my analysis here.

09:41.640 --> 09:44.000
OK, so let's look at one issue.

09:44.040 --> 09:54.280
So we take the premise that a model is essentially a set of statistical facts about the information or the training material.

09:54.280 --> 09:59.320
Does it mean that it is capable of containing derivative works?

09:59.320 --> 10:04.160
OK, let's look at changing the subject completely.

10:04.160 --> 10:06.680
Right, let's look at a WAV file.

10:06.720 --> 10:18.120
So you could also argue that a WAV file is just a set of facts about how far a speaker cone is from a fixed point at a particular period of time.

10:18.120 --> 10:22.000
And we know, obviously, that a WAV file can be infringing.

10:22.000 --> 10:34.200
A WAV file can take a piece of copyrighted music and the number of lawsuits that exist that cover copyrighted music encapsulated in electronic file formats is obviously huge.

10:34.240 --> 10:44.600
There's absolutely no doubt at all that music encapsulated in a WAV file, which you can argue is just a set, you know, selection of facts can be copyrighted.

10:44.600 --> 10:54.400
And just because you so just turning over to the concept of a model, people would say that you can't reverse engineer a model easily to find out that what is within it.

10:54.400 --> 10:59.360
I mean, it is just a set of information about statistical relationships.

10:59.400 --> 11:07.880
But just because you can't reverse engineer the model to determine its contents doesn't mean that it doesn't contain potentially derivative works.

11:07.880 --> 11:12.400
And I'll go into that in a little bit more detail later.

11:12.400 --> 11:29.240
But if we go back to the audio example, I mean, if you look at a more complex audio file format like Agvorbis, for example, you know, if you're just given that file, you're going to find it impossible, I would say, to reverse engineer it and get the music back out again.

11:29.280 --> 11:37.160
Unless you actually know how it was encoded in the first place, a WAV file is sufficiently simple that you probably could reverse engineer it and figure out the music was in there.

11:37.640 --> 11:42.280
But an Agvorbis file, you're just not going to be able to do that unless you know the encoding scheme in the first place.

11:42.600 --> 11:47.640
But nobody's going to argue that a Vorbis encoded file cannot be infringing.

11:48.600 --> 12:00.120
And there is, of course, a way that you can get AI models to reveal whether they contain any derivative works, and that is if it's part of a generative AI, you can just simply ask them.

12:00.120 --> 12:04.120
And I will give a few examples of that shortly.

12:04.120 --> 12:12.120
So some of you may be familiar with this poem, which was written by Lewis Carroll.

12:12.600 --> 12:14.600
And I'll just read the first line.

12:14.600 --> 12:18.600
It was Brillock and the Slythe Toves did Gire and Gimbal in the WAV.

12:18.600 --> 12:26.600
Now, for those of you who aren't native English speakers, the words that I've placed in yellow up here, they're just nonsense words.

12:26.600 --> 12:32.600
They were just made up specifically for this poem.

12:32.600 --> 12:40.600
Now, it's important to realize that Jabberwocky is no longer in copyright, which is partially why it's easy for me to talk about it here, because I don't have to worry about that.

12:41.080 --> 12:51.080
But because these are nonsense words and they only exist in this particular poem, or in derivatives of the poem that have been ingested later,

12:51.080 --> 13:05.080
then it turns out to be a great test of whether an AI has had access to this particular work as part of its ingestion process, if you can get it to disgorge these words later in some way.

13:05.560 --> 13:13.560
So I did a few experiments with chat GPT and I asked it to write a poem entitled Jabberwocky and it wrote Jabberwocky.

13:13.560 --> 13:15.560
So the result was verbatim.

13:15.560 --> 13:19.560
Didn't even try to change anything at all.

13:19.560 --> 13:25.560
So we know that chat GPT has ingested Jabberwocky.

13:25.560 --> 13:31.560
The chances of this being developed independently, produced independently, are infinitesimal.

13:32.040 --> 13:36.040
Did it know that it was out of copyright?

13:36.040 --> 13:42.040
I'm not suggesting that there's any copyright infringement going on here, clearly because Jabberwocky is out of copyright anyway.

13:42.040 --> 13:56.040
So it may be that in choosing the training materials that great care was taken to make sure that there were no copyright materials or materials which didn't have an appropriate license being ingested.

13:56.520 --> 14:00.520
So we did quite a few other tests on this basis.

14:00.520 --> 14:06.520
We found a number of works that actually are in copyright, contained within various large language models.

14:06.520 --> 14:12.520
I have to stress that this doesn't mean again that OpenAI is necessarily infringing.

14:12.520 --> 14:18.520
They might have attained a license to these particular works.

14:18.520 --> 14:24.520
But it does demonstrate that it's possible for LLM to contain copyright works.

14:25.000 --> 14:33.000
The argument that the LLM just contains facts doesn't really hold a great deal of water when you analyze it along these lines.

14:33.000 --> 14:41.000
And indeed, there are plenty of studies now subsequently showing that copyright works do exist in various LLMs.

14:41.000 --> 14:53.000
There's one from the copilot itself, which is some research showing that from time to time copilot will disgorge some verbatim copyright works.

14:53.480 --> 15:02.480
So the conclusion here is that we really can't believe AI can be used to essentially launder copyright works.

15:02.480 --> 15:13.480
You can't take a copyright work, feed it into an LLM and then claim that because the same copyright work has come out the other side, that it's no longer subject to copyright of some sort.

15:13.960 --> 15:21.960
So is it possible to have AI extract the ideas and leave the expression?

15:21.960 --> 15:29.960
And we can remember that ideas themselves don't attract copyright, but the expression does.

15:29.960 --> 15:41.960
Now there's a great video here. I put the QR code up there for it, which shows the difference or the similarity of two songs.

15:41.960 --> 15:45.960
One called My Sweet Lord by George Harrison, which you may be familiar with.

15:45.960 --> 15:51.960
And the other one called He's So Fine by the chiffons that you may not be quite so familiar with.

15:51.960 --> 16:07.960
And in a nutshell, in a case some time ago, George Harrison was sued by the chiffons for releasing My Sweet Lord, which does to my untrained musical ear sound very, very similar to He's So Fine.

16:07.960 --> 16:22.960
And the crux of the case was that although it was never established that Harrison had consciously copied He's So Fine, and if you recall, we said earlier that intent has nothing to play here.

16:22.960 --> 16:25.960
So whether he'd meant to or not was by the by.

16:25.960 --> 16:29.960
The fact is that if he had copied, then infringement would have occurred.

16:29.960 --> 16:39.960
The judge said that Harrison had the opportunity to hear He's So Fine because it was a quite popular song at the time.

16:39.960 --> 16:42.960
It would have been played in shops on the radio and so on and so forth.

16:42.960 --> 16:54.960
So there's a high probability that he would have heard it and somehow subconsciously it would have entered his mind and it would have become part of his thought process when he wrote My Sweet Lord.

16:54.960 --> 17:00.960
And there's a reference to the case there on the slide.

17:00.960 --> 17:21.960
So it seems to me quite logical that the courts are going to follow a similar reasoning with AI in that if a generative AI produces some material which appears to be copyright infringing and it can be demonstrated that that material was part of the training data,

17:21.960 --> 17:39.960
then the courts are likely to come to the conclusion that infringement is happening, notwithstanding that we can't really work out how exactly it's encoded if that's the correct word to use within the AI model in the first place.

17:39.960 --> 17:45.960
So let's look at a different case now which is sort of straining this idea, expression, distinction.

17:45.960 --> 17:50.960
So this is a photograph that was pretty popular in London a few years ago.

17:50.960 --> 17:57.960
It was in a lot of tourist places where you were buying souvenirs and so on.

17:57.960 --> 18:04.960
And it's a pretty striking picture of a red London bus crossing Westminster Bridge.

18:04.960 --> 18:12.960
So the picture that I've just shown you, which was on a drinks coaster, reproduced here on the left.

18:12.960 --> 18:25.960
And on the right, another company called New English Tees Limited decided that it would be nice to have a similar sort of image, but they didn't want to pay a license fee to the holders of the first image.

18:25.960 --> 18:40.960
So they asked a photographer to go and take a picture from roughly the same location of a London bus and then they got somebody to retouch it so the London bus was red and everything else was in monochrome.

18:41.960 --> 18:49.960
And you would imagine that that is about as clear an example of an idea versus an expression as possible.

18:49.960 --> 19:00.960
The expressions of these two photographs, but the idea is basically a red double-decker London bus crossing Westminster Bridge, which is all in monochrome.

19:00.960 --> 19:08.960
And it's not a particularly good case because this was only a very decision at the lower court, so it's not particularly binding.

19:08.960 --> 19:14.960
But nonetheless, it was determined that there was potential infringement going on here.

19:14.960 --> 19:25.960
So I went onto Dali and I used this as a prompt, which to me seems to be a fairly reasonable explanation or the distillation into an idea.

19:25.960 --> 19:34.960
And you'll see that Dali using that prompt has produced something that under that particular legal doctrine, this is almost certainly infringing.

19:34.960 --> 19:37.960
But hopefully not in Belgium.

19:43.960 --> 19:51.960
So that's an example of where you can have court cases that do not help this analysis a great deal.

19:51.960 --> 20:02.960
So what can help us in circumstances when we are using generative AI and we're trying to avoid infringement situations?

20:02.960 --> 20:06.960
I mean, there are different ways to do this. First of all, you can filter what is ingested.

20:06.960 --> 20:13.960
So if you limit your training data to things that are not in copyright anymore or things that you have a specific license for that allows,

20:13.960 --> 20:21.960
this is sufficiently broad that allows it to be used to generate materials using an AI or their subject to an exemption,

20:21.960 --> 20:26.960
again, that's broad enough to enable you to do that, then that may assist you.

20:26.960 --> 20:33.960
But the trouble is that then that is going to fairly dramatically reduce the pool of things that you're able to do to generate the model in the first place,

20:33.960 --> 20:40.960
which of course means that your model is not going to be as good as it potentially could be. But that's something to bear in mind.

20:40.960 --> 20:43.960
The second thing is to review the algorithm.

20:43.960 --> 20:50.960
If it turns out that your algorithm produces a model that's only two megabytes in size,

20:50.960 --> 20:57.960
then there's not going to be much space to fit a whole bunch of copyright works inside their derivatives or otherwise.

20:57.960 --> 21:04.960
So that's going to be a pretty strong argument that what comes out of it is unlikely to be infringing because it was going to be pretty difficult

21:04.960 --> 21:11.960
to actually fit anything inside there that could potentially be a derivative work in the first place.

21:11.960 --> 21:16.960
And the third option is clearly to filter what's output.

21:16.960 --> 21:25.960
You look at the output of the AI and at that point you determine whether that is potentially derivative work and sort of block its onwards transmission.

21:25.960 --> 21:33.960
There's potentially some infringement happening at the period where it's reduced, but if you're not distributing any further, that's kind of the limit the issues there.

21:33.960 --> 21:38.960
And there are a number of technologies available that could potentially help with doing that.

21:38.960 --> 21:46.960
So YouTube's content ID, for example, Getty Images has got some software for plagiarism to section and so on.

21:46.960 --> 21:57.960
So without going into detail, it's very easy for me to say that, but without going into detail, it's possible those sort of techniques can be used to determine whether the output is potentially infringing.

21:57.960 --> 22:07.960
And indeed, this is already being used in certain cases, including co-pilot at the moment.

22:07.960 --> 22:12.960
So if you've got co-pilot duplication detection that intends to do that.

22:12.960 --> 22:21.960
Those of you who are involved in open source compliance are probably familiar with snippet matching services like BlackDark or FOS ID or Scannos,

22:21.960 --> 22:34.960
which use a database of existing code and they have quite sophisticated algorithms to make sure that you can't defeat these algorithms simply by obfuscating the code.

22:34.960 --> 22:39.960
But how effective those algorithms are is obviously is variable.

22:39.960 --> 22:44.960
But I think it's likely that specialist products are going to be developed.

22:44.960 --> 22:58.960
And I happen to get in touch with the founder of one of the developers of one of these scanning software companies a couple of weeks ago and mentioned to him and said,

22:58.960 --> 23:09.960
you know, to your knowledge of the developments of foot to help with this situation of filtering the output of generative AI to see that it was potentially infringing.

23:09.960 --> 23:13.960
And he basically said that he couldn't tell me anymore unless I signed an NDA.

23:13.960 --> 23:19.960
So you can take that as you will.

23:19.960 --> 23:26.960
So few sort of final thoughts that I have here.

23:26.960 --> 23:39.960
I don't believe that permissively licensed knowledge base or permissively licensed corpus of materials used to ingest and create the model is the answer.

23:39.960 --> 23:44.960
There are a number of models available that say that we're only using permissively licensed code.

23:44.960 --> 23:48.960
That doesn't mean that, you know, there are no compliance obligations.

23:48.960 --> 23:54.960
I mean, you know, pretty much all of the licenses in question will have attribution requirements.

23:54.960 --> 23:57.960
So how do you follow those through onto the output?

23:57.960 --> 24:08.960
So you're taking a sort of risk based approach way of saying, well, you think that piece somebody who's licensed the code under Apache is less likely to get unhappy than somebody who's licensed it under GPL.

24:08.960 --> 24:10.960
But it's not a legal analysis.

24:10.960 --> 24:12.960
It's really a risk based analysis there.

24:12.960 --> 24:14.960
So you still got to be careful about that.

24:14.960 --> 24:16.960
Not a magic bullet.

24:16.960 --> 24:24.960
The other thing to be aware of is that different jurisdictions have very different rules about where the machine generated code is subject to copyright.

24:24.960 --> 24:26.960
So we touched on this earlier.

24:26.960 --> 24:35.960
There's a specific clause in the UK Copyright Act that says that machine generated works are subject to copyright.

24:35.960 --> 24:40.960
And that copyright will be owned by the person who made the arrangements.

24:40.960 --> 24:44.960
Now, it's a bit difficult to determine what made the arrangements means.

24:44.960 --> 24:50.960
Is it the person who created the model or is it the person who created the software that uses the model to produce the output?

24:50.960 --> 24:53.960
Or is it the person who put the prompt in?

24:53.960 --> 25:00.960
My gut feel is that it probably means that it's the person who put the prompt in to generate the output, but it's not been determined judicially.

25:00.960 --> 25:12.960
And there is one case which has got nothing to do with AI, but it's got to do with image generation that suggests that the person who wrote the software, in this case some game software,

25:12.960 --> 25:16.960
is the person who made the arrangements, not the person who was playing the game.

25:16.960 --> 25:23.960
So that's a little bit problematic, but I say it's only one case and it didn't go to the appeal clause.

25:23.960 --> 25:33.960
One other thing to bear in mind is that quite often, if you're looking at two pieces of copyright work and they're quite long and extensive and they potentially have mistakes in them

25:33.960 --> 25:47.960
and they are identical, including the mistakes, then you're going to make the assumption that the only way that Work B came into existence with all of those mistakes, etc.

25:47.960 --> 25:50.960
is that Work A was copied.

25:50.960 --> 26:03.960
Now, up until now, that's been a pretty reasonable assumption to make, but of course it's entirely possible that using Generative AI, two people could put the same very similar prompt in, or identical prompt in,

26:03.960 --> 26:19.960
and that prompt would generate identical output works, and therefore we can't automatically assume that a long and complex work that has mistakes in it is essentially only going to be owned by one person from a copyright perspective.

26:19.960 --> 26:22.960
So that's just a sort of cautionary word.

26:22.960 --> 26:30.960
So one thing that really does worry me here is the potential that AI can be used to automate a clean room rewrite, so we can use AI.

26:30.960 --> 26:35.960
Again, I've done some analysis on this, but I won't share the details now because I don't have time.

26:35.960 --> 26:45.960
But if you take a piece of code and you ask the AI to analyze the code and produce it to a functional description, and then you take that functional description and insert it into another AI

26:45.960 --> 26:53.960
and say, please write code to this functional description, then does that mean that because you've been through an automated process that has basically stripped out the expression,

26:53.960 --> 27:06.960
taking it to the functional description, which is purely an idea which we know does not attract copyright, and then reproduced a piece of software from that that somehow we've developed an automated way of copyright washing?

27:06.960 --> 27:18.960
An awful lot, I think several billion, if not trillion, dollars says that is not going to be allowed to happen, so we just need to be aware of that of a possibility.

27:18.960 --> 27:23.960
So that's a sort of whistle-stop tour through my various thoughts on the topic.

27:23.960 --> 27:27.960
Thank you very much for taking care, taking the time to listen to me.

27:27.960 --> 27:29.960
Do we have time for a couple of questions potentially?

27:29.960 --> 27:30.960
Two questions right over there.

27:30.960 --> 27:31.960
Fantastic.

27:31.960 --> 27:56.960
So one of the questions we have, I'm going to have to move up.

27:56.960 --> 28:00.960
So, I mean you might as well have a look at the whole thing.

28:00.960 --> 28:10.960
One question we had was if the model outputs a copy of an image who is infringing the AI machine or the human who asked the prompt.

28:10.960 --> 28:12.960
Good question.

28:12.960 --> 28:14.960
People infringe.

28:14.960 --> 28:21.960
So potentially it can be a legal person who can infringe, so it could be a company as well.

28:21.960 --> 28:25.960
But ultimately it's going to be who was doing the act of copying.

28:25.960 --> 28:34.960
So it's almost certainly going to be a human, but if the human is employed by an organisation, then it could be the organisation that would be infringing as well.

28:34.960 --> 28:43.960
While we've still got time, another question we had is there seems to have been some confusion about whether this was under US copyright law or England and Wales.

28:43.960 --> 28:45.960
Which ones are you talking about here?

28:45.960 --> 28:47.960
Any of you either?

28:47.960 --> 28:56.960
So what I'm saying was under the copyright of England and Wales, which is the same as the rest of the copyright law in the UK.

28:56.960 --> 29:11.960
But references that I made from time to time were about the idea of expression dichotomy for example is something that's much clearer under US law than it is under English law, but it still subsists.

29:11.960 --> 29:13.960
Thank you.

