WEBVTT

00:00.000 --> 00:05.000
All right.

00:05.000 --> 00:06.000
Well, hello everyone.

00:06.000 --> 00:07.000
Hope you all can hear me okay.

00:07.000 --> 00:08.000
My name is Forrest Burt.

00:08.000 --> 00:10.000
I'm a Solutions Architect at CIQ.

00:10.000 --> 00:12.000
I've worked with HPC for a few years now.

00:12.000 --> 00:15.000
I was a student sysadmin at a university over in the states

00:15.000 --> 00:17.000
for a while before joining CIQ a few years ago.

00:17.000 --> 00:19.000
So I've been there for about two and a half years.

00:19.000 --> 00:21.000
I've used Singularity since about 20,

00:21.000 --> 00:23.000
well, AppTainer nowadays,

00:23.000 --> 00:26.000
but I've been familiar with kind of the Singularity container ecosystem

00:26.000 --> 00:29.000
since about 2019 or so when I was originally deploying it

00:29.000 --> 00:30.000
at Darbuysi State.

00:30.000 --> 00:33.000
So I've been a big user of kind of the Singularity AppTainer ecosystem

00:33.000 --> 00:34.000
for a long time,

00:34.000 --> 00:36.000
and I've got a few updates to share with you guys

00:36.000 --> 00:39.000
about what's going on with it.

00:39.000 --> 00:42.000
A couple of years ago, let's see here we go,

00:42.000 --> 00:44.000
I gave a talk a couple of years ago at Fosdome 2022

00:44.000 --> 00:46.000
that kind of went over what was going on

00:46.000 --> 00:48.000
with AppTainer around that time

00:48.000 --> 00:50.000
and kind of how things were switching up.

00:50.000 --> 00:53.000
The long and the short of that story is in late 2021,

00:53.000 --> 00:56.000
the Singularity project, the open source side of it,

00:56.000 --> 00:59.000
decided that they had kind of felt they were reaching a mature phase

00:59.000 --> 01:01.000
with their technology.

01:01.000 --> 01:04.000
They decided that they wanted to maybe kind of move themselves

01:04.000 --> 01:07.000
into the Linux Foundation so that they could be managed under that

01:07.000 --> 01:10.000
and cross-pollinate easier with some of the projects from over there.

01:10.000 --> 01:13.000
The vote to do this was unanimous in favor,

01:13.000 --> 01:15.000
and so they moved over into the Linux Foundation,

01:15.000 --> 01:17.000
this open source side of Singularity,

01:17.000 --> 01:19.000
and in order to change or in order to,

01:19.000 --> 01:24.000
the Linux Foundation could get a trademark on the name,

01:24.000 --> 01:26.000
they had to change the name from Singularity to AppTainer.

01:26.000 --> 01:28.000
So that's how we got to this.

01:28.000 --> 01:31.000
Over the past few years, since the rebasing as well on version 1.1,

01:31.000 --> 01:33.000
we've done a few different things

01:33.000 --> 01:36.000
that have been kind of interesting that I'm here to discuss.

01:36.000 --> 01:38.000
First off, we've started leveraging the username space.

01:38.000 --> 01:41.000
As of kernel 5.10, we have username spaces,

01:41.000 --> 01:44.000
which give us those consumable UID mappings.

01:44.000 --> 01:47.000
So we're taking advantage of that to do some of the stuff

01:47.000 --> 01:51.000
that we used to need, set UID binaries and stuff like that for.

01:51.000 --> 01:54.000
We've got new recommendations that I'm going to go really briefly into

01:54.000 --> 01:58.000
about containerized MPI and how we're doing that these days,

01:58.000 --> 02:01.000
and then I've got a little bit of information about the OROS protocol

02:01.000 --> 02:06.000
and how that is increasing compatibility between AppTainer and OCI registries.

02:06.000 --> 02:09.000
So first off, as we know, we have username spaces.

02:09.000 --> 02:14.000
These are name spaces that we can create that allow us to do UID mappings.

02:14.000 --> 02:17.000
So you can take your 1001, map that to zero, something like that.

02:17.000 --> 02:20.000
This is useful for a number of things in AppTainer

02:20.000 --> 02:25.000
and allows us to essentially do most of what we needed to do beforehand

02:25.000 --> 02:33.000
with these set UID binaries, just now using these username spaces.

02:33.000 --> 02:39.000
So this gives us the ability to do all of our file system mounting using Fuse.

02:39.000 --> 02:42.000
This gives us the ability to do, for example, like with this,

02:42.000 --> 02:47.000
this standard pattern and singularity in AppTainer

02:47.000 --> 02:49.000
that we're needing to be able to go into a container.

02:49.000 --> 02:54.000
As you can see, in this case, creating a file under my user

02:54.000 --> 02:58.000
and then being able to shell into this container using fake root,

02:58.000 --> 03:02.000
get immediately mapped to root, see that that file we created is now shown as root,

03:02.000 --> 03:05.000
create another file and then be able to come out of that

03:05.000 --> 03:09.000
and still have that file we created while mapped in the container as root,

03:09.000 --> 03:12.000
still under our user that we were outside the container.

03:12.000 --> 03:16.000
This is important so we can do things like DNF and stuff like that during container builds.

03:16.000 --> 03:19.000
So, for example, when we want to do a build, in this case,

03:19.000 --> 03:22.000
we need to be able to run DNF, stuff like that.

03:22.000 --> 03:26.000
Whereas beforehand, this type of thing, if we wanted to do root build,

03:26.000 --> 03:29.000
you had to do add the fake root options, stuff like that.

03:29.000 --> 03:32.000
Nowadays, that's all just implied and, like I said,

03:32.000 --> 03:37.000
all these things that we used to use these suede binaries for

03:37.000 --> 03:40.000
are all now being done using username spaces.

03:40.000 --> 03:45.000
So that changes up a little bit of how AppTainer works on a security level.

03:45.000 --> 03:48.000
One thing to note...

03:52.000 --> 03:54.000
One thing to note is that some of the...

03:54.000 --> 03:59.000
because I'm sure you guys have seen some of the other security holes that come around with username spaces,

03:59.000 --> 04:04.000
but one thing to note is that because users can now do unprivileged installs,

04:04.000 --> 04:06.000
which there's a helper script out of the show site to do that,

04:06.000 --> 04:11.000
because users can now do unprivileged installs of their container...

04:12.000 --> 04:17.000
of their AppTainer software in their own, basically, environments,

04:17.000 --> 04:21.000
that renders some of the system-wide controls around this stuff, like the ECL and Valid.

04:21.000 --> 04:25.000
So you do have to kind of watch out for that and disable username spaces

04:25.000 --> 04:29.000
if you don't want your users to be able to tinker around with installing their own AppTainer

04:29.000 --> 04:31.000
and doing that type of thing.

04:31.000 --> 04:34.000
New recommendations for MPI jobs.

04:34.000 --> 04:39.000
As we know, usually when we want to do MPI, we're doing something like this,

04:39.000 --> 04:41.000
MPIexec sending these MPI...

04:41.000 --> 04:45.000
or setting up these MPI processes via SSH out on these compute nodes,

04:45.000 --> 04:48.000
wiring them up via MPI.

04:48.000 --> 04:52.000
When we do this with AppTainer,

04:56.000 --> 04:58.000
this doesn't quite work the exact same way,

04:58.000 --> 05:02.000
because if we try to do it this way,

05:02.000 --> 05:07.000
if we try to run, basically, MPIexec inside one of these containers on our host node,

05:07.000 --> 05:10.000
we end up getting out via SSH to these compute nodes

05:10.000 --> 05:15.000
and within the containerized environments that we're trying to spawn on these compute nodes,

05:15.000 --> 05:17.000
we...

05:17.000 --> 05:20.000
essentially, because of how these containers are namespaced,

05:20.000 --> 05:25.000
we can no longer figure out where exactly this calling program was out on its host node.

05:25.000 --> 05:27.000
So that doesn't quite work.

05:27.000 --> 05:30.000
So normally, when we want to use AppTainer via MPI,

05:30.000 --> 05:33.000
we have to MPIexec the AppTainer process itself,

05:33.000 --> 05:36.000
and then that wires everything up correctly.

05:36.000 --> 05:41.000
This can cause problems because that's a little brittle.

05:41.000 --> 05:45.000
You then have to match the MPI on the host, the MPI in the container,

05:45.000 --> 05:48.000
or you have to bind in the MPI from the host in the container.

05:48.000 --> 05:52.000
That creates very brittle containers that are very linked to a version of MPI.

05:52.000 --> 05:55.000
So one big thing that we've been looking at kind of in the community

05:55.000 --> 05:58.000
and at CIQ over the past little bit, especially my colleague Jonathan Anderson,

05:58.000 --> 06:04.000
has been using the PMI libraries to create more compatibility between these.

06:04.000 --> 06:08.000
So instead of having to have exactly the same version of MPI between this container,

06:08.000 --> 06:12.000
between the host, or even having to have MPI on your host at all,

06:12.000 --> 06:15.000
you just compile your slurm or something like that with this PMI2 support,

06:15.000 --> 06:20.000
compile your MPI in each one of these containers with PMI2 support,

06:20.000 --> 06:24.000
and you can leverage this PMI2 library to wire up all this communication,

06:24.000 --> 06:29.000
rather than having to do this more standard model that we're familiar with.

06:29.000 --> 06:31.000
There's a lot more to this.

06:31.000 --> 06:33.000
There's a lot of information you can go look at.

06:33.000 --> 06:39.000
We've done some webinars or some blog posts that kind of have some performance benchmarks, stuff like that.

06:39.000 --> 06:41.000
So there's a lot you can go look at here.

06:41.000 --> 06:46.000
The last thing that I have to say, well, fabric adapters,

06:46.000 --> 06:49.000
you can do this basically same thing with fabric adapters.

06:49.000 --> 06:53.000
If you just switch out your user driver or your basically user space drivers

06:53.000 --> 06:58.000
that you're using to communicate with those K-mods that are communicating with that fabric adapter, with libfabric,

06:58.000 --> 07:03.000
that provides a very similar kind of compatibility layer between a lot of the fabric adapters,

07:03.000 --> 07:08.000
like what we see that we've done with PMI2 there.

07:08.000 --> 07:14.000
So essentially, we can do this similar, like I said, kind of genericizing this build

07:14.000 --> 07:18.000
rather than having to link, in this case, down to a K-mod version,

07:18.000 --> 07:26.000
and ultimately ending up originally with a container that is very linked to a specific kernel version.

07:26.000 --> 07:31.000
In this case, we can, like I said, just use libfabric and have a lot more compatibility there.

07:31.000 --> 07:35.000
One other big thing is O-RAS, OCI Registries as Storage.

07:35.000 --> 07:40.000
Docker as a database or the Docker Hub as a database is no longer cool.

07:40.000 --> 07:47.000
So we've come up with ways to kind of formalize that concept of storing generic arbitrary artifacts inside of an OCI registry.

07:47.000 --> 07:55.000
So what we're doing these days, basically, because of this protocol,

07:55.000 --> 07:58.000
a lot of the OCI Registries have gone and implemented this.

07:58.000 --> 08:04.000
It allows you to store app tainer, sifts, helm charts, things like that, all within these OCI Registries.

08:04.000 --> 08:08.000
And so with that, I'm sure we're all very familiar with app tainer.

08:08.000 --> 08:17.000
You can pull images, do verification via PGP to eliminate a whole host of different potential security problems.

08:17.000 --> 08:24.000
You can also inspect files to ensure that they have their sign correctly.

08:24.000 --> 08:34.000
You can make sure that when you actually go to build a container from somewhere that you're pulling it out from, say, pushed up to even like an OCI registry at this point,

08:34.000 --> 08:44.000
you can check these key fingerprints versus what's uploaded out on sites like openpgp.org to ensure that what you're getting from this registry is what's actually showing up on your machine.

08:44.000 --> 08:48.000
So that's one of the big advantages of app tainer is that you can do this type of signing.

08:48.000 --> 08:59.000
And like I said, this used to be kind of a little bit more limiting because you weren't able to really store these in the same type of registries as everyone else is using.

08:59.000 --> 09:08.000
But nowadays, you know, you go to AWS, Azure, GCP, Oracle, most of the major clouds, all of their artifact registries support not only storing Docker containers,

09:08.000 --> 09:21.000
but these sifts alongside them. And you can, like I said, pull them down, get the exact same type of just these workflows that you would expect where if the fingerprints don't match,

09:21.000 --> 09:30.000
the container won't build that type of thing. One thing to also note, if you're thinking, well, what if you're upstream containers that you're actually building these, you know, your base images from are contaminated?

09:30.000 --> 09:40.000
One thing that you can do is also build from your basically the flat or basically the mirrors themselves.

09:40.000 --> 09:53.000
Using something like this allows you to pull directly from like, for example, Rocky Linux's mirrors build a container out of that. So you're not relying on anyone else's containers that they've uploaded.

09:53.000 --> 10:08.000
So that's all I have. Like I said, we have seen how username spaces have replaced all the setUid type stuff. We've seen how we kind of have new ways that we can utilize these more generic libraries and MPI so we're not creating as brittle containers.

10:08.000 --> 10:20.000
And then we've seen how O-ROS allows us to integrate these SIF containers with OCI registries. So I have a lot of links in here. I have more links right here that you can look at if you're interested in getting involved.

10:20.000 --> 10:23.000
And thank you all for your attention and for continuing to use Optaner.

