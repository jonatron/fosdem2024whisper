WEBVTT

00:00.000 --> 00:07.400
Hi, I'm Jonas Stechberger.

00:07.400 --> 00:11.920
I'll be talking about the inner workings of safe points.

00:11.920 --> 00:13.640
Essentially, what are safe points?

00:13.640 --> 00:17.240
You essentially have this nice little VM and you stop it.

00:17.240 --> 00:20.880
And as you saw, we have local safe points that only stop

00:20.880 --> 00:21.720
one VM.

00:21.720 --> 00:25.320
One VM, the other one, just float across.

00:25.320 --> 00:27.640
And the vicinity and the other stretch has worked.

00:27.640 --> 00:32.680
So the local safe points, they are quite cool because we

00:32.680 --> 00:34.400
stop a single thread.

00:34.400 --> 00:37.360
The thread doesn't modify its stack anymore.

00:37.360 --> 00:41.000
And it's nice to do things like garbage collection that just

00:41.000 --> 00:43.120
wants to operate on the thread stack.

00:43.120 --> 00:48.680
And we also have global safe points.

00:48.680 --> 00:51.680
They are also quite interesting.

00:51.680 --> 00:53.640
So essentially, you'll stop all the threads.

00:53.640 --> 00:57.400
That's cool when you want to do code deoptimizations and

00:57.400 --> 00:59.040
other stuff.

00:59.040 --> 01:01.200
That's what we're talking about, safe points.

01:01.200 --> 01:04.960
Safe points give either the state of the whole VM a

01:04.960 --> 01:08.920
guarantee to be stable or the state of the whole thread is

01:08.920 --> 01:10.280
guaranteed to be stable.

01:10.280 --> 01:16.200
And they are like one of the building blocks of the JVM.

01:16.200 --> 01:18.400
And they get even more important.

01:18.400 --> 01:23.600
I'll link their chat below because newer garbage collectors

01:23.600 --> 01:25.560
like concurrent etc.

01:25.560 --> 01:29.720
see use safe points, especially the thread local safe

01:29.720 --> 01:34.840
points to do work concurrently and to ensure that we can do

01:34.840 --> 01:41.920
as much work alongside concurrently every now and then

01:41.920 --> 01:45.720
at returns of methods instead of having a stop of all

01:45.720 --> 01:48.320
garbage collector as we have before.

01:48.320 --> 01:51.360
So essentially, when do we ask to be in a safe point?

01:51.360 --> 01:55.440
So when do we check he should be going to a safe point?

01:55.440 --> 01:57.320
We take here a typical method.

01:57.320 --> 01:58.520
It's just multi-blast.

01:58.520 --> 02:02.240
And so what we see here, we go into a safe point either

02:02.240 --> 02:07.280
when we return from a function, which is pretty neat.

02:07.280 --> 02:12.600
Or when we are at the back edge of a non-counted loop.

02:12.600 --> 02:17.160
So here in this example, we check at a safe point every

02:17.160 --> 02:20.400
time here when we're here or when we are at the end of the

02:20.400 --> 02:22.360
function, but beware of inlining.

02:22.360 --> 02:23.640
And that's a problem here.

02:23.640 --> 02:27.760
When we inline a function, then we don't have a safe point

02:27.760 --> 02:30.560
at the end of this inline function because the function

02:30.560 --> 02:33.600
doesn't exist anymore for the JVM.

02:33.600 --> 02:37.120
And then of course, we sometimes have loops.

02:37.120 --> 02:40.520
Some of you have written such for loops.

02:40.520 --> 02:44.640
And the problem is some years before, this didn't have a

02:44.640 --> 02:46.120
safe point anyway inside.

02:46.120 --> 02:49.200
And especially if B got really large, it meant that the

02:49.200 --> 02:52.640
JVM was taking quite a lot of time to reach the next safe

02:52.640 --> 02:53.000
point.

02:53.000 --> 02:55.960
So people started to do loop strip mining.

02:55.960 --> 02:58.920
And the idea is essentially you split this loop that we had

02:58.920 --> 03:04.000
before into an outer loop that usually iterates over

03:04.000 --> 03:08.040
increments like the value by a thousand typically, and an

03:08.040 --> 03:08.560
inner loop.

03:08.560 --> 03:10.760
And we have a safe point here.

03:10.760 --> 03:12.280
And that's quite interesting.

03:12.280 --> 03:13.160
That's quite good.

03:13.160 --> 03:14.440
It's called loop strip mining.

03:14.440 --> 03:19.160
And this reduced the latency in your JVM quite nicely.

03:19.920 --> 03:21.000
I'm Johannes Pechberger.

03:21.000 --> 03:24.240
I usually talk about profiles and sometimes about safe points.

03:24.240 --> 03:27.960
I work with an amazing team of talented engineers at the

03:27.960 --> 03:28.760
submachine team.

03:28.760 --> 03:31.120
We're the third biggest contributor to this little

03:31.120 --> 03:31.560
OpenShade.

03:31.560 --> 03:34.360
DK project that you might have heard about.

03:34.360 --> 03:38.600
And I sometimes fix bugs in template integrators.

03:38.600 --> 03:42.720
So template integrators like the thing when people say, oh,

03:42.720 --> 03:46.160
Java code is integrated in the lowest level of

03:46.160 --> 03:49.200
trig compilation, then they talk about template integrator

03:49.200 --> 03:52.520
because the template integrator turned O2 not produce

03:52.520 --> 03:54.720
safe point checks at the return of functions.

03:54.720 --> 03:58.080
And that's not great when you use this fact.

03:58.080 --> 04:00.280
So I sometimes fix bugs in the OpenShade.

04:00.280 --> 04:00.520
OK.

04:00.520 --> 04:03.640
And sometimes people call this work.

04:03.640 --> 04:09.640
And their back part of this fix us to all older LTS

04:09.640 --> 04:11.640
releases.

04:11.640 --> 04:15.320
What I'm not talking about is I'm not talking about how

04:15.360 --> 04:16.720
safe points suck.

04:16.720 --> 04:19.720
Because they sometimes suck, especially when you have

04:19.720 --> 04:21.280
profiles that are safe from bias.

04:21.280 --> 04:27.520
So they only sample your threat out safe point borders.

04:27.520 --> 04:30.480
As Nidson Barker says, safe point bias profiles are

04:30.480 --> 04:33.760
tricky, sneaky, filthy, all of the above.

04:33.760 --> 04:36.520
And if you want to know more about safe points and why they

04:36.520 --> 04:38.960
suck in profiling, ask this guy in the front.

04:38.960 --> 04:41.360
He knows a little bit about it.

04:41.360 --> 04:44.520
But more on the real topic of my talk.

04:44.560 --> 04:48.360
It's on implementation because we're all here to see some

04:48.360 --> 04:49.000
C code.

04:49.000 --> 04:50.880
Yay.

04:50.880 --> 04:55.400
In the beginning, I want to tell you how they code work.

04:55.400 --> 04:58.640
So essentially what we want to know, so essentially how

04:58.640 --> 05:02.320
safe points work, we have to insert these checks somewhere.

05:02.320 --> 05:04.960
And then the JVM goes into a safe point handler.

05:04.960 --> 05:07.560
And that's all amazing stuff like doing garbage

05:07.560 --> 05:08.680
collection work.

05:08.680 --> 05:13.360
Or hopefully in the future doing some safe point based

05:13.400 --> 05:17.560
deck walking to make profiling a little bit easier and to make

05:17.560 --> 05:19.200
profiling a little bit faster.

05:19.200 --> 05:22.240
But essentially what we could do in the search code, we could

05:22.240 --> 05:25.320
ask at every return, at every point where we run in search

05:25.320 --> 05:29.080
of safe point polygester, if threat is at safe point, please

05:29.080 --> 05:31.680
call safe point process.

05:31.680 --> 05:34.520
The thing is, this is like, probably this would compile in

05:34.520 --> 05:36.520
your check-in if you include some errors.

05:36.520 --> 05:39.120
And then in the last part, we did nothing.

05:39.120 --> 05:39.960
And it's quite cool.

05:39.960 --> 05:44.400
And it's slow, of course, because we have this branch

05:44.400 --> 05:46.360
everywhere.

05:46.360 --> 05:50.840
But the cool thing is, for once, that's pretty rare, this

05:50.840 --> 05:51.600
occasion.

05:53.760 --> 05:55.520
And so we can do some tricks.

05:55.520 --> 05:58.720
But what's in integrated mode, how it looks like, and here

05:58.720 --> 06:04.200
with the C++ code, how it actually looks like, that your

06:04.200 --> 06:08.840
template interpreter generates some code that calls

06:08.880 --> 06:12.280
test instruction that essentially sets a conditional

06:12.280 --> 06:12.720
bit.

06:12.720 --> 06:19.120
And it just tests that the polyg word, that the

06:19.120 --> 06:21.720
poll bit, is not zero.

06:21.720 --> 06:23.920
So that's just a simple check.

06:23.920 --> 06:27.880
That's how it's implemented in template interpreter.

06:27.880 --> 06:31.760
So we could essentially just implement this.

06:31.760 --> 06:33.400
And it's implemented this way.

06:33.400 --> 06:36.920
But we see that the first thing is, use pretty rarely.

06:39.040 --> 06:43.440
Because usually, we're not going to be at safe point.

06:43.440 --> 06:50.440
Because if we would get into this at every return, at every

06:50.440 --> 06:54.240
loopback edge, we would be just like being at safe points.

06:54.240 --> 06:56.480
And we wouldn't do some work with our JBMs.

06:56.480 --> 06:59.760
So usually, at safe point fails.

06:59.760 --> 07:03.280
And this is cool, because we now know that we can essentially

07:03.280 --> 07:04.320
make this a slow path.

07:04.320 --> 07:09.800
So it doesn't matter that much how fast it is if we get a

07:09.800 --> 07:12.040
fast path really fast.

07:12.040 --> 07:16.280
And one idea here is we could just read from a pointer.

07:16.280 --> 07:20.080
Because reading from a pointer in the fast path is quite

07:20.080 --> 07:23.760
fast, especially if there's a pointer that's in the cache

07:23.760 --> 07:24.720
or somewhere.

07:24.720 --> 07:26.120
It's nice.

07:26.120 --> 07:29.440
And the thing is, when we read from a pointer, there are two

07:29.440 --> 07:29.960
options.

07:29.960 --> 07:32.280
We could either read some data.

07:32.280 --> 07:33.120
Good.

07:33.600 --> 07:36.400
It's just a simple morph instruction.

07:36.400 --> 07:38.680
Or we can get a segmentation fault.

07:38.680 --> 07:41.080
And that's one of the things that JBM does.

07:41.080 --> 07:46.040
It uses segmentation faults for its own advantage.

07:46.040 --> 07:48.880
Because segmentation faults, yeah, they are somewhat

07:48.880 --> 07:53.400
expensive, but a fast path is really, really fast.

07:53.400 --> 07:56.160
So the idea is here in our method where we insert a

07:56.160 --> 07:57.000
check.

07:57.000 --> 08:00.840
We just access a so-called polling page.

08:00.840 --> 08:06.520
Because when we disable the save point, the fast path is

08:06.520 --> 08:09.760
yeah, it points to a good page, this pointer.

08:09.760 --> 08:13.000
But when we enable it, it points to the bad page.

08:13.000 --> 08:14.960
And we have a segmentation fault.

08:14.960 --> 08:17.920
And then essentially what segmentation fault does, it

08:17.920 --> 08:23.120
looks and looks, hey, did we want to access a save point,

08:23.120 --> 08:24.840
such a save point page?

08:24.840 --> 08:27.640
And I'm like, cool, we're probably at a save point.

08:27.640 --> 08:31.320
And that's one of the reasons why when you disable save

08:31.320 --> 08:35.680
points, when you do save point handling stuff around your

08:35.680 --> 08:39.680
JBM and want to be sneakily, so capturing save points, you

08:39.680 --> 08:40.720
got a lot of them.

08:40.720 --> 08:43.120
That doesn't help with debugging when you're

08:43.120 --> 08:46.920
out in GUB, when you're out in GDB, because you get a lot

08:46.920 --> 08:49.280
of save points.

08:49.280 --> 08:54.800
But anyways, before we go further to look into C++

08:55.360 --> 08:57.920
code, I was told by someone in the audience that people like

08:57.920 --> 08:59.240
cute cat images.

08:59.240 --> 09:02.800
And the thing is, working with the OpenJK is interesting.

09:02.800 --> 09:06.360
But sometimes you have to sometimes calm down, take a

09:06.360 --> 09:09.360
cat, stroke it, have a nice time.

09:09.360 --> 09:13.400
And then you go back to learning how the OpenJK works.

09:13.400 --> 09:15.840
So I learned this because I wanted to fix a bug.

09:15.840 --> 09:20.760
So essentially how save points are initialized, we have

09:20.760 --> 09:22.240
here a bad page and a good page.

09:22.240 --> 09:25.360
And then we use the magic method protect memory.

09:25.360 --> 09:30.480
Essentially what it does, we call nprotect.

09:30.480 --> 09:36.680
And thereby we make the bad page neither readable nor

09:36.680 --> 09:37.800
writable.

09:37.800 --> 09:41.120
And the good page, we make it just readable.

09:41.120 --> 09:43.440
So we don't need to make it writable.

09:43.440 --> 09:47.920
So essentially we use the memory management unit of our CPU

09:47.920 --> 09:49.200
to implement save points.

09:49.200 --> 09:51.840
And that's pretty nice.

09:51.880 --> 09:55.560
So how, for example, C1 implements save points is

09:55.560 --> 09:58.160
quite, quite simple with this.

09:58.160 --> 10:03.360
It just accesses the pointer like it just accesses the

10:03.360 --> 10:05.440
value that's at this address.

10:05.440 --> 10:07.400
That's our page.

10:07.400 --> 10:09.320
So it's really just a single address.

10:09.320 --> 10:12.320
And that's a single moth, which is nice.

10:12.320 --> 10:14.960
And there's, of course, the question, how could we arm

10:14.960 --> 10:15.200
these?

10:15.200 --> 10:18.400
So what do we do here?

10:18.440 --> 10:22.200
And essentially what we do, we, for one, set the polling

10:22.200 --> 10:25.720
page here when you arm it to like the arm value or like

10:25.720 --> 10:27.200
the bad page.

10:27.200 --> 10:31.400
And of course, we're not doing any of this segmentation

10:31.400 --> 10:33.800
fall trick in template interpreters.

10:33.800 --> 10:36.840
So we're also setting the polling word so that the

10:36.840 --> 10:39.000
template interpreter can also check it.

10:39.000 --> 10:42.040
And what we do when we do a global save point poll, we

10:42.040 --> 10:44.480
essentially do this for every stretch.

10:44.480 --> 10:46.200
That's pretty simple here.

10:46.200 --> 10:48.160
And of course, sometimes we want drag save points

10:48.160 --> 10:50.480
because they can get quite annoying.

10:50.480 --> 10:56.360
And if some of you saw this 1 billion row change, then you

10:56.360 --> 10:59.880
probably saw that some of the winning contenders did this

10:59.880 --> 11:04.040
able save points because they can get quite annoying.

11:04.040 --> 11:05.400
But usually they aren't.

11:05.400 --> 11:08.880
So essentially there are a few ways you can, for one, use

11:08.880 --> 11:11.760
Jvi events.

11:11.760 --> 11:14.840
And I've built a website called Jvi Events Collection, where

11:14.840 --> 11:17.960
you can see all Jvi events available, also the events for

11:17.960 --> 11:20.760
trial and for all the JV case here.

11:20.760 --> 11:25.080
And you see here that there is a save point begin event, and

11:25.080 --> 11:26.640
you also have a save point end event.

11:26.640 --> 11:29.800
So you can check which save points are created.

11:29.800 --> 11:33.000
And also you can just pass x lock save point.

11:33.000 --> 11:34.920
You get lots of output.

11:34.920 --> 11:38.160
And I did this for like a Renaissance benchmark.

11:38.160 --> 11:40.320
And this is like the distribution that I get.

11:40.320 --> 11:42.800
And essentially most of the save points are in this case

11:42.800 --> 11:47.040
related to G1 because G1 was my selected

11:47.040 --> 11:48.560
garbage collector.

11:48.560 --> 11:51.400
If you want to learn more about me on my team, just go to

11:51.400 --> 11:53.000
this link.

11:53.000 --> 11:56.480
I was Johannes Pechberger here telling you a bit about the

11:56.480 --> 11:57.840
inner workings of save points.

11:57.840 --> 12:00.040
I hope you learn a bit.

12:00.040 --> 12:03.040
You can find me on Twitter on GitHub on my team at

12:03.040 --> 12:03.840
that machine.doctor.

12:03.840 --> 12:05.520
Oh, that was all from me.

12:14.640 --> 12:16.360
Yes, of course, Rief.

12:16.360 --> 12:18.880
Four precious minutes.

12:18.880 --> 12:23.080
Any questions here from the keynotes or any corrections of

12:23.080 --> 12:24.520
the OK developers?

12:41.360 --> 12:43.480
Can I ask a choker?

12:43.560 --> 12:49.240
So the question was before Java 5, how did it work?

12:49.240 --> 12:52.440
Any of my colleagues that were present at this time in the

12:52.440 --> 12:55.200
training came?

12:55.200 --> 12:58.320
Any of the OpenTree care developers here, any ideas?

12:58.320 --> 12:59.400
I don't.

12:59.400 --> 13:02.320
I only started two years ago.

13:02.320 --> 13:03.440
No problem.

13:06.200 --> 13:10.640
If these people don't know, then nobody knows.

13:10.640 --> 13:14.520
But if you have some ideas, come to Forstner next year and

13:14.520 --> 13:15.560
tell people about it.

13:15.560 --> 13:17.160
Yes, history lens.

13:17.160 --> 13:18.520
No, other questions?

13:22.680 --> 13:23.320
None?

13:23.320 --> 13:23.800
Good.

13:23.800 --> 13:26.280
Then, what's the pleasure of talking to you?

13:26.280 --> 13:29.720
And if you want to learn a bit more about Python, I'm

13:29.720 --> 13:34.080
tomorrow at 4 PM in the Python Dev Room, telling you about

13:34.080 --> 13:35.120
Python monitoring.

13:35.120 --> 13:36.080
And that's all from me.

13:36.080 --> 13:37.040
Thank you.

