WEBVTT

00:00.000 --> 00:10.000
We're almost ready for our next talk.

00:10.000 --> 00:20.000
So if we could all quiet down a little beforehand, it would be great.

00:20.000 --> 00:21.000
Hey.

00:21.000 --> 00:22.000
Okay.

00:22.000 --> 00:23.000
It's about Rust.

00:23.000 --> 00:25.000
Shouldn't you all be excited?

00:25.000 --> 00:30.000
Okay.

00:30.000 --> 00:35.000
Daniel is going to talk about the case for a virtual Rust stateless codec driver.

00:35.000 --> 00:36.000
Daniel?

00:36.000 --> 00:37.000
Okay.

00:37.000 --> 00:38.000
Can you guys hear me?

00:38.000 --> 00:39.000
Is the microphone working?

00:39.000 --> 00:43.000
For those of you who don't know me, which I assume is going to be the majority, my name

00:43.000 --> 00:44.000
is Daniel Omeda.

00:44.000 --> 00:49.000
I worked for Collabra for three years, mainly doing codec stuff, the interface between just

00:49.000 --> 00:51.000
the streamer and the kernel.

00:51.000 --> 00:58.000
And as I've recently been working on doing decoders and Rust in user space, so now I'm

00:58.000 --> 01:00.000
fighting really hard to bring this to the kernel.

01:00.000 --> 01:05.000
And I'm halfway being hated by a lot of people just kidding.

01:05.000 --> 01:12.000
So yes, I'm here today to talk about the case for a virtual Rust stateless codec driver.

01:12.000 --> 01:16.000
I want everybody in the audience to really take a look at the title because we're going

01:16.000 --> 01:20.000
to go piece by piece every word that you guys see here.

01:20.000 --> 01:23.000
We're going to talk a little bit more about it.

01:23.000 --> 01:27.000
So I'm going to start with saying what a codec is and why we need codecs.

01:27.000 --> 01:32.000
Then I'm going to talk about hardware acceleration and codecs and why should we need that.

01:32.000 --> 01:38.000
After that, since now we have hardware, I'm going to talk about codec drivers because now

01:38.000 --> 01:39.000
we have hardware to drive.

01:39.000 --> 01:40.000
So how do drivers work?

01:40.000 --> 01:43.000
Now that we have a driver, we need a way to talk to the driver.

01:43.000 --> 01:48.000
I'm going to be speaking about the two major APIs in Vigil for Linux for you to be speaking

01:48.000 --> 01:51.000
to these drivers, the stateless and the stateful API.

01:51.000 --> 01:56.000
And after that, I'm going to talk about what is a virtual driver in this context and about

01:56.000 --> 01:58.000
Vizal, which is a virtual driver I wrote.

01:58.000 --> 02:04.000
And then lastly, I'm going to tie all of that back into Rust and hopefully why we need

02:04.000 --> 02:06.000
Rust in this particular context.

02:06.000 --> 02:10.000
So without much further ado, let's get started.

02:10.000 --> 02:13.000
And the first thing I want to talk, as I said, is about codecs.

02:13.000 --> 02:14.000
What are codecs?

02:14.000 --> 02:18.000
Basically codecs, they are a way for you to compress video data because without codecs

02:18.000 --> 02:20.000
you couldn't have video in the morning age.

02:20.000 --> 02:27.000
So if you have a 4K stream, for instance, and you do the math like 3, 840 times 2160 times

02:27.000 --> 02:33.000
3 bytes per pixel times 24 frames per second times two hours for a movie, this is going

02:33.000 --> 02:34.000
to be very huge.

02:34.000 --> 02:38.000
So in order for this to be even possible nowadays, you have to have a way to compress that.

02:38.000 --> 02:43.000
But thankfully, all video signals, they're full of exploitable redundancies that that's

02:43.000 --> 02:45.000
how video codecs work.

02:45.000 --> 02:49.000
They basically exploit these redundancies to shrink the amount of data that you have,

02:49.000 --> 02:55.000
therefore making, you know, storing videos on your computer or streaming videos through

02:55.000 --> 02:59.000
the internet and a lot of other user cases, even possible today.

02:59.000 --> 03:04.000
Usually this process is lossy, right?

03:04.000 --> 03:08.000
So you can have lossless compression, but usually you lose a little bit of data.

03:08.000 --> 03:13.000
But the objective is to arrive at a possible approximation such that you don't notice that

03:13.000 --> 03:19.000
you've lost a whole lot of detail, hopefully, but you've shrink the size of your image by

03:19.000 --> 03:21.000
a large amount.

03:21.000 --> 03:28.000
And for a given bit rate and power envelope, meaning for a given size of resulting file,

03:28.000 --> 03:33.000
the resulting file size, and for a given amount of heat that you're going to be generating

03:33.000 --> 03:38.000
or power that you're going to be consuming from the device.

03:38.000 --> 03:42.000
All right, so we want things to be fast and hopefully cool, right?

03:42.000 --> 03:46.000
Because nobody likes to be sitting on a laptop, does a scorching hot, or you don't really

03:46.000 --> 03:50.000
want to be using a whole lot of power, or, and you want things to be fast.

03:50.000 --> 03:52.000
So what's the solution for this?

03:52.000 --> 03:54.000
Is to have a hardware accelerator, for instance.

03:54.000 --> 04:00.000
So hardware accelerators tend to be more power efficient and faster, and it frees up the main CPU.

04:00.000 --> 04:04.000
So that your main CPU can basically hopefully do other stuff.

04:04.000 --> 04:08.000
But they're usually less flexible because you usually only get what you synthesize into

04:08.000 --> 04:09.000
hardware most of the time, right?

04:09.000 --> 04:12.000
And you're not going to be synthesizing all the profiles for all the codecs.

04:12.000 --> 04:20.000
You're only going to be synthesizing a small subset, and well, you kind of, this makes it a little bit less

04:20.000 --> 04:24.000
flexible than doing CPU encoding or decoding.

04:24.000 --> 04:26.000
And there is another key aspect of this.

04:26.000 --> 04:30.000
Now that you have hardware, you have hardware to drive.

04:30.000 --> 04:35.000
So now you need a driver, and you need an API to communicate with this driver.

04:35.000 --> 04:42.000
So you have now yet another piece that you have to have that you didn't need to have with a pure software

04:42.000 --> 04:45.000
slash CPU approach.

04:45.000 --> 04:51.000
And to understand these drivers, we first have to have a brief look at what is inside a bitstream.

04:51.000 --> 04:55.000
Let's say you're watching something on YouTube, or you've downloaded some video file on your PC.

04:55.000 --> 04:58.000
What exactly is in there?

04:58.000 --> 05:01.000
So basically we have two blocks in there.

05:01.000 --> 05:04.000
The most important thing actually is the data to decode, right?

05:04.000 --> 05:06.000
That's obviously the most important piece.

05:06.000 --> 05:12.000
So the data to decode, the actual compressed data takes the most amount of space, but that's not everything

05:12.000 --> 05:13.000
that's inside there.

05:13.000 --> 05:16.000
We also have a small block called the metadata block.

05:16.000 --> 05:19.000
And what exactly is the metadata block?

05:19.000 --> 05:26.000
It's data that's not going to be actually decoded per se, but it's very fundamental

05:26.000 --> 05:28.000
because it controls the decoding process.

05:28.000 --> 05:35.000
So it's data that the decoder will be consuming in real time in ingesting that metadata to actually,

05:35.000 --> 05:44.000
in real time, decide how is the decoding process is going to look like for each and every frame.

05:44.000 --> 05:47.000
So as I was saying, this metadata controls the decoding process.

05:47.000 --> 05:52.000
It may dictate to the decoder how the decoder is going to decode a particular frame,

05:52.000 --> 05:56.000
in which case it will only apply for that particular frame.

05:56.000 --> 06:02.000
Or it can apply to multiple frames, depending on the kind of metadata we're speaking about.

06:02.000 --> 06:08.000
So in frame-packed decoders you have things like PPS and SPS and VPS,

06:08.000 --> 06:12.000
which are metadata that stays for multiple frames.

06:12.000 --> 06:15.000
Or you can have metadata that's only for a single slice,

06:15.000 --> 06:19.000
which is only going to apply for that particular slice and that particular frame.

06:19.000 --> 06:22.000
And you also have the slice and or tile data,

06:22.000 --> 06:26.000
which is the data that you're going to be hopefully decompressing.

06:26.000 --> 06:28.000
So far so good, I imagine.

06:28.000 --> 06:30.000
So how can we talk to these devices?

06:30.000 --> 06:36.000
Because if you recall, now we have hardware to drive, so now we need to talk to the device somehow.

06:36.000 --> 06:40.000
In Vita-Felonics, we basically have two different types of APIs

06:40.000 --> 06:43.000
that you can use in order to talk to the codec.

06:43.000 --> 06:45.000
One of them is the Stagefool API.

06:45.000 --> 06:47.000
I like to think of the Stagefool API as a black box.

06:47.000 --> 06:50.000
So you just send in this data to the device.

06:50.000 --> 06:53.000
The device will do its magic, quote-unquote,

06:53.000 --> 06:56.000
and it will keep track of the metadata by itself.

06:56.000 --> 06:58.000
You don't need to do much.

06:58.000 --> 07:02.000
You're just sending the data and bam, hopefully you get decoded data back.

07:02.000 --> 07:04.000
Very interesting.

07:04.000 --> 07:07.000
If the Stagefool interface is a black box,

07:07.000 --> 07:11.000
I like to think of the stateless API as a clean slate,

07:11.000 --> 07:14.000
meaning for each and every frame,

07:14.000 --> 07:16.000
you in the user space have to extract that data

07:16.000 --> 07:21.000
and then send that data together with the compressed data to the driver.

07:21.000 --> 07:26.000
And then the driver will use this metadata that you have just parsed and send

07:26.000 --> 07:29.000
with the compressed data and it will decompress the data.

07:29.000 --> 07:35.000
So if the Stagefool API is a black box, the stateless API is a clean slate.

07:35.000 --> 07:41.000
For each and every frame, you have to submit data that will tell the device how to operate

07:41.000 --> 07:43.000
and then the device will basically forget about it

07:43.000 --> 07:46.000
and then on the next frame, you have to submit the new metadata

07:46.000 --> 07:50.000
and the new compressed data for the device to decode and so on and so forth.

07:50.000 --> 07:57.000
It doesn't really keep the state of the metadata within the device, hence the name, Stateless.

07:57.000 --> 08:00.000
I assume so far so good.

08:00.000 --> 08:03.000
So now we're going to be talking about virtual drivers.

08:03.000 --> 08:07.000
I'm going to talk about the virtual driver which I have written called Vizel.

08:07.000 --> 08:12.000
And Vizel is basically, as I said, a virtual stateless driver that just pretends it's decoding data.

08:12.000 --> 08:17.000
And why would a driver that just pretends that it's decoding data be useful,

08:17.000 --> 08:22.000
most people may be asking, well, it's useful as a developer aid, right?

08:22.000 --> 08:29.000
To help developers who are working on this particular niche to either develop new implementations

08:29.000 --> 08:31.000
or use your broken implementation.

08:31.000 --> 08:38.000
Let's say you found a bug, you can use Vizel to dump some debug data to help you fix the bug

08:38.000 --> 08:41.000
because Vizel is a driver that instead of decoding video,

08:41.000 --> 08:47.000
just dumps a bunch of data, useful debug data through debug.fs, through ftrace,

08:47.000 --> 08:52.000
and through the Viti for Linux task-patter generator.

08:52.000 --> 08:58.000
And what is Vizel good for, as I said, is good to help you to develop a new user land application.

08:58.000 --> 09:03.000
Usually you have a working application, then you use that, you trace the working application

09:03.000 --> 09:08.000
and use the trace provided by Vizel to develop a new one, that's one use case,

09:08.000 --> 09:15.000
helps you fix bugs, helps you test your user space when you don't have hardware available.

09:15.000 --> 09:18.000
So if you don't have hardware that can decode a particular codec,

09:18.000 --> 09:22.000
you can still use Vizel to test the just trimmer code, to test the FF impact code,

09:22.000 --> 09:25.000
to test the Chromium code, so on and so forth.

09:25.000 --> 09:28.000
And you can use Vizel for prototyping.

09:28.000 --> 09:31.000
So first of all, let's do a quick recap over here.

09:31.000 --> 09:36.000
I explained a little bit what codecs are, why we may need hardware acceleration.

09:36.000 --> 09:40.000
I said that when you use hardware acceleration, you're now going to have a driver,

09:40.000 --> 09:46.000
and to talk to this driver, you have two APIs, and now I said that we have in the media subsystem

09:46.000 --> 09:52.000
some virtual drivers, one of which is a virtual stateless codec driver.

09:53.000 --> 09:55.000
What is the problem?

09:55.000 --> 09:57.000
Well, the problem is this.

09:57.000 --> 09:59.000
Can you guys read this?

09:59.000 --> 10:01.000
It's readable in the slides, I think.

10:01.000 --> 10:04.000
So what is this?

10:04.000 --> 10:08.000
This is what you find when you open up a codec specification.

10:08.000 --> 10:11.000
I think that this is for AV1, which is the state of the art codec.

10:11.000 --> 10:14.000
And this is how you parse this thing.

10:14.000 --> 10:19.000
This is how you extract the data from the bitstream to send the data to a stateless codec,

10:19.000 --> 10:24.000
because as I said, a stateless codec needs the metadata to decode each and every single frame.

10:24.000 --> 10:29.000
So in user space, you have to go through everything in here and start parsing.

10:29.000 --> 10:34.000
And right from the outset, I see a few issues over here.

10:34.000 --> 10:42.000
So we are reading, on the second column, there's F, and in parentheses, there's a particular number.

10:42.000 --> 10:46.000
That's the number of bits that you're going to be reading for that particular syntax.

10:46.000 --> 10:49.000
Now, what happens if you have a bug?

10:49.000 --> 10:55.000
If you were to read, for instance, there's a type over there that says show existing frame,

10:55.000 --> 10:59.000
and you have to read a single bit from the bitstream in order to get the value for this.

10:59.000 --> 11:07.000
Let's say that instead of reading, say, one or two, you're at false, because you had a bug, whatever.

11:07.000 --> 11:13.000
So now that branch, so show existing frame, is not taken, because you had a bug in your implementation.

11:13.000 --> 11:17.000
And if that branch is not taken, now you're out of sync with the entire thing.

11:17.000 --> 11:24.000
So now you're going to be reading like, instead of reading frame to show map IDX, which would be the next field,

11:24.000 --> 11:26.000
you're now reading frame type.

11:26.000 --> 11:31.000
Let's say that you were to read all that stuff and eventually read that return over there, but you didn't,

11:31.000 --> 11:36.000
because you missed this branch, because you read that thing over there wrongly for whatever bug.

11:36.000 --> 11:43.000
So now, instead of returning, you're reading everything, thereby reading over the memory that you had in the first place.

11:43.000 --> 11:50.000
If you had that return over there, you would have only a given amount of memory, but you missed it, because you had a bug.

11:50.000 --> 11:54.000
And now you're reading more stuff, thereby reading after the end of the memory.

11:54.000 --> 11:58.000
This is a crash at the best of scenarios.

11:58.000 --> 12:03.000
At worst, it's, you know, you can corrupt stuff, this can go very badly.

12:03.000 --> 12:07.000
So this is very tricky, and this is very indented.

12:07.000 --> 12:17.000
You can see that whenever you see a pair of parentheses, this is like yet another syntax element that will have its own way to be parsed,

12:17.000 --> 12:21.000
and it can have if statements and for loops and etc.

12:21.000 --> 12:25.000
It can have other things with parentheses, which means yet more indentation basically.

12:25.000 --> 12:30.000
So this can get very hairy, very tricky, very fast.

12:30.000 --> 12:32.000
And you have pages and pages of this.

12:32.000 --> 12:37.000
I'm pretty sure they have at least 20 pages of this stuff to parse, just to send that to the driver.

12:37.000 --> 12:46.000
So this can get very complicated, and not only can this be very complex, but we're also reading the indexes for arrays,

12:46.000 --> 12:51.000
and we're also reading a few loop variables directly from the bitstream.

12:51.000 --> 12:57.000
So if we go back a little bit, let me see if I can find it from here.

12:58.000 --> 13:06.000
Yeah, so frame to show map IDX, well, you're reading that from the bitstream,

13:06.000 --> 13:11.000
and you're using that to index into another B of memory, which is the ref frame type array.

13:11.000 --> 13:17.000
And if you read that index wrong, now you're indexing into an array with the wrong index,

13:17.000 --> 13:24.000
and as we all know, see here, I assume, we know that this can be very broken, very fast.

13:24.000 --> 13:26.000
So yes, this is very hairy.

13:28.000 --> 13:30.000
So here is my pitch.

13:30.000 --> 13:32.000
Here is my pitch to use Rust.

13:32.000 --> 13:35.000
We're handling a whole lot of metadata performance, as I said.

13:35.000 --> 13:42.000
A whole bunch of data that we're getting from user space, and although we do do some vetting of that in the kernel,

13:42.000 --> 13:50.000
there's some functions in the kernel aimed at potentially detecting invalid input from user space.

13:51.000 --> 13:58.000
They're not, you know, that foolproof, and the attack surface here is so huge

13:58.000 --> 14:04.000
that no amount of ad-hoc in kernel validation would ever catch all the possible ways

14:04.000 --> 14:06.000
in which this can blow in your face.

14:06.000 --> 14:10.000
This metadata thing is very structured and very complex.

14:10.000 --> 14:16.000
The media fields can change based on the value of other fields.

14:16.000 --> 14:20.000
As I said, if you read true, then go here, otherwise take the other branch.

14:20.000 --> 14:23.000
This can get very complicated as well.

14:23.000 --> 14:29.000
And you also have to maybe juggle between multiple versions of the same metadata.

14:29.000 --> 14:38.000
For instance, in HVC, you can have multiple instances of a VPS or a PPS or a SPS,

14:38.000 --> 14:42.000
which you have parsed previously, but of which only one is active.

14:42.000 --> 14:46.000
So you have to juggle between multiple of these, and only one is active at a time.

14:46.000 --> 14:52.000
So there's plenty of pitchfaults that you can sort of shoot yourself in the face when doing this.

14:52.000 --> 14:57.000
And the problem is exacerbated in real drivers, because as you will recall,

14:57.000 --> 15:01.000
so far we have been talking about vise all about virtual drivers.

15:01.000 --> 15:05.000
And if that thing crashes, it's bad, but it's not the end of the world, although it's very bad.

15:05.000 --> 15:11.000
But in a real driver, you may use this broken metadata that you're sending to the driver

15:11.000 --> 15:14.000
and use this broken metadata to program the device.

15:14.000 --> 15:20.000
So now you may be changing the decoding process of the device and who knows which ways.

15:20.000 --> 15:25.000
You can hang the device at best or corrupt the state of the system at worst,

15:25.000 --> 15:29.000
and you may even have to reboot the system.

15:29.000 --> 15:33.000
It has happened to me multiple times that I had some bugs somewhere,

15:33.000 --> 15:39.000
and I had to reboot the machine in order to, because the device was stuck, basically.

15:39.000 --> 15:45.000
So I assume by now we have, you guys can see that we have value in having rust here,

15:45.000 --> 15:50.000
because most of what I have spoken about is check that compile time when you have rust.

15:50.000 --> 15:53.000
So when you have rust, you have memory safety.

15:53.000 --> 15:58.000
If you basically, all the issues I was talking about, about accessing invalid memory,

15:58.000 --> 16:03.000
by default are prevented and rust at compile time.

16:03.000 --> 16:07.000
You have just fixed yourself a bunch of different classes of bugs for free,

16:07.000 --> 16:10.000
just by switching the language.

16:10.000 --> 16:15.000
And I was speaking about virtual drivers all this time and about Vizel in particular,

16:15.000 --> 16:20.000
which is a virtual driver for testing codec drivers and codec user space,

16:20.000 --> 16:25.000
because I think virtual drivers are the perfect candidates to experiment,

16:25.000 --> 16:30.000
and Vizel in particular is a perfect candidate to be rewritten and rust.

16:30.000 --> 16:35.000
And we can make that even simpler, because Vizel has a bunch of F trace code and debug Fs code,

16:35.000 --> 16:37.000
and we don't need any of that.

16:37.000 --> 16:43.000
We can strip away basically all these things for now and just have a virtual driver that boots

16:43.000 --> 16:48.000
and that can pretend that it's decoding data without dumping debug data to user space.

16:48.000 --> 16:53.000
We don't need that in the first version of a rust driver in Vidafilinix.

16:53.000 --> 17:00.000
And I think the most important part of my pitch is if we make a virtual driver in rust

17:00.000 --> 17:04.000
and we make it work and we prove to everybody that this thing is working,

17:04.000 --> 17:08.000
it's not much more work to get a driver for real hardware,

17:08.000 --> 17:12.000
because then only the parts that touch as the real hardware,

17:12.000 --> 17:16.000
like getting the MAs and getting the interrupts working and blah, blah, blah,

17:16.000 --> 17:21.000
these pieces of the kernel, they're basically being worked by everybody else,

17:21.000 --> 17:26.000
because everybody else who's interacting with hardware have the same issues to fix.

17:26.000 --> 17:28.000
So they're also working on this.

17:28.000 --> 17:33.000
So if we fix the, if we come up with a Vidafilinix to specific bits,

17:33.000 --> 17:40.000
maybe in six months or one year, the situation of rust in the kernel will be more advanced.

17:40.000 --> 17:44.000
Therefore, we will have more abstractions for more areas of the kernel.

17:44.000 --> 17:47.000
Therefore, it will be easier to write a driver for real hardware.

17:47.000 --> 17:51.000
We'll have the Vidafilinix bits and we can hopefully profit from the work

17:51.000 --> 17:55.000
that other people have done in other areas of the kernel.

17:55.000 --> 18:00.000
So I have been trying to do this for six months or one year, I think.

18:00.000 --> 18:07.000
I have sent to the main list a simple Vidafilinix to driver.

18:07.000 --> 18:14.000
And what we have in this driver so far, we have the abstractions for a few of the Vidafilinix to data types.

18:14.000 --> 18:20.000
You have a very thin VB2 abstraction for mutual can spawn a queue to share memory,

18:20.000 --> 18:22.000
share buffers between users based on the driver.

18:22.000 --> 18:28.000
We have abstractions for some of the Vidafilinix to Ioc tools, not all of them.

18:28.000 --> 18:32.000
We have the necessary code to get the driver to probe because believe it or not,

18:32.000 --> 18:35.000
it's actually complicated to get a rust driver to probe in the kernel.

18:35.000 --> 18:38.000
There's a proc macro going on in the background, blah, blah, blah.

18:38.000 --> 18:45.000
So we also have the code to get the driver to probe, which is in and of itself is an achievement, I think.

18:45.000 --> 18:47.000
And we have a simple module.

18:47.000 --> 18:49.000
And what does the simple module does?

18:49.000 --> 18:52.000
It basically boots, I mean, I'm sorry, it probes.

18:52.000 --> 18:57.000
And whenever a NIOcto is called by user space, it just brings,

18:57.000 --> 19:00.000
hey, this Ioc tool has been called.

19:00.000 --> 19:02.000
I am able to process this Ioc tool in Rust.

19:02.000 --> 19:07.000
I'm able to translate all the arguments into Rust and basically returns.

19:07.000 --> 19:14.000
It just brings something to make sure that this Ioc tool translation layer between C and Rust is working.

19:14.000 --> 19:23.000
And from this, we can start to add functionality to the driver so that when it actually processes the Ioc tools,

19:23.000 --> 19:28.000
it stores states and actually carries out what the Ioc tool is supposed to do.

19:28.000 --> 19:32.000
And what do we need in order to get this thing going?

19:32.000 --> 19:37.000
We need support in Rust for referral to control so that we can send the metadata to the driver.

19:37.000 --> 19:43.000
We need support for some media controller bits so that we can have referral to requests,

19:43.000 --> 19:46.000
which is a way to tie this metadata to a particular frame.

19:46.000 --> 19:52.000
So we need Rust support for this in order to get stateless codecs to work in Rust.

19:52.000 --> 19:56.000
We need M2M support for device run and friends, which is just a framework

19:56.000 --> 20:02.000
who's scheduling the decode jobs in the kernel and deciding when a job should run in the hardware.

20:02.000 --> 20:06.000
And we need more Ioc tool support because we only have support for a few Ioc tools

20:06.000 --> 20:10.000
and a real driver needs much more.

20:10.000 --> 20:15.000
And most importantly, we're still waiting for the green lights from the maintainers.

20:15.000 --> 20:19.000
I have been talking to a whole lot of maintainers.

20:19.000 --> 20:21.000
I've been to the media summit.

20:21.000 --> 20:24.000
Some of the maintainers I think are in this room or not.

20:24.000 --> 20:29.000
I don't see them, but anyways, I got some feedback from them.

20:29.000 --> 20:32.000
And I think this summarizes it.

20:32.000 --> 20:38.000
In visual Linux, nowadays, the state of the subsystem is that the subsystem is a little bit overwhelmed.

20:38.000 --> 20:41.000
There's a bunch of patches being submitted.

20:41.000 --> 20:44.000
There's not enough people to review.

20:44.000 --> 20:50.000
And basically, people are overwhelmed and nobody really has the time to have yet another language in the subsystem,

20:50.000 --> 20:54.000
which I understand this is a completely valid thing to say.

20:54.000 --> 20:57.000
So there's not enough reviewers, not enough maintainers.

20:57.000 --> 21:03.000
Some C frameworks like the media controller have some longstanding problems which nobody has fixed yet.

21:03.000 --> 21:08.000
So one of the feedbacks I got was like, hey, maybe these issues should be fixed in C

21:08.000 --> 21:12.000
before we add yet another language, which is some valid feedback. I agree.

21:12.000 --> 21:16.000
There's a huge fear of breaking C code, which is impossible.

21:16.000 --> 21:21.000
Just by how this works, you're never modifying the C code.

21:21.000 --> 21:25.000
So this can never broke whatever C code is already in the kernel. I promise.

21:25.000 --> 21:32.000
And the other issue is who is going to maintain this layer,

21:32.000 --> 21:37.000
because one of the feedbacks I got was like, hey, if I change something in the C layer

21:37.000 --> 21:43.000
and just break the Rust code, who's responsible for keeping these two things in sync

21:43.000 --> 21:51.000
and fixing the Rust code, which again is a very valid argument to have.

21:51.000 --> 21:57.000
But we use Collabra. We want to unblock this effort, which is why we have been investing in the media subsystem.

21:57.000 --> 22:06.000
We're investing in CI and we're trying to change a little bit how maintainership in the Vifrel2 community works.

22:06.000 --> 22:11.000
We're trying to get it more like DRM where you have multiple commuters and where you can share the workload.

22:11.000 --> 22:20.000
So we are doing what we can in order to alleviate some of the issues so that we can proceed with this effort,

22:20.000 --> 22:26.000
which is why we're proposing this virtual driver, because we think that this is a good candidate for experimentation.

22:26.000 --> 22:30.000
This is not the scheduler or memory management or anything, which if you break that,

22:30.000 --> 22:33.000
you've broken the entire kernel, this is just a virtual driver.

22:33.000 --> 22:36.000
If it's broken, it's not going to be a huge deal.

22:36.000 --> 22:42.000
So summary here, say the drivers, they take a whole bunch of intrested data from user space.

22:42.000 --> 22:46.000
This can get hairy. This can let you shoot yourself in the foot very easily.

22:46.000 --> 22:56.000
So the attack surface is enormous and Rust is a perfect candidate to fix that at compile time, we think.

22:57.000 --> 23:04.000
And the Vizel virtual driver is a brand candidate to experiment and Rust and to be rewritten and Rust in our humble opinion,

23:04.000 --> 23:06.000
or in my humble opinion.

23:06.000 --> 23:12.000
And this is what I had to say to you guys today and hopefully this was interesting for you.

23:21.000 --> 23:22.000
Questions?

23:26.000 --> 23:27.000
Yes, sir.

23:39.000 --> 23:40.000
Hi, thank you for the talk.

23:40.000 --> 23:49.000
So I have very rough understanding of Rust, but I would like to get more idea how Rust would protect us from part of the issues that you described.

23:49.000 --> 23:54.000
So I understand how it protects us from accessing past the size of the array,

23:54.000 --> 24:01.000
but in case when you have the metadata, it changes because of the previous values that you are passing, right?

24:01.000 --> 24:07.000
How Rust would protect us from misinterpreting that new piece of data?

24:07.000 --> 24:16.000
Well, if you get metadata that's broken and this broken metadata leads you to access another part of memory which is invalid,

24:16.000 --> 24:19.000
that just panics basically.

24:19.000 --> 24:29.000
So it's not like, and see you can dereference any value you want, but in Rust you basically can't you panic.

24:29.000 --> 24:36.000
And then you compare that with the user space Rust implementation to also make sure that you're getting sanitized data.

24:36.000 --> 24:45.000
So basically the only thing that, the only protection that we get is that we will not access array that is out of bounds basically.

24:45.000 --> 24:47.000
Because...

24:47.000 --> 24:49.000
We can actually handle cleaning these access.

24:49.000 --> 24:51.000
Okay, so tell me more.

24:51.000 --> 24:54.000
We can have a clean exit to that bad access.

24:54.000 --> 24:59.000
Okay, so what's the benefit? I mean you can always define a C function, right?

24:59.000 --> 25:06.000
That will check the size of the array, how much data is there left and never access the buffer directly just through that function.

25:06.000 --> 25:09.000
That will always check if you are not out of bounds.

25:09.000 --> 25:10.000
You can.

25:10.000 --> 25:11.000
So then...

25:11.000 --> 25:12.000
It's a human factor.

25:12.000 --> 25:13.000
Yeah.

25:13.000 --> 25:15.000
You're forgetting the human factor.

25:15.000 --> 25:17.000
Of course, yes.

25:17.000 --> 25:19.000
So you can...

25:19.000 --> 25:24.000
The amount of work that is there to add the whole Rust bindings, I'm not saying it's bad, right?

25:24.000 --> 25:36.000
I'm just trying to weigh in the, adding a single function that you can use to access the metadata, the buffer that you have made the data in, and porting the whole thing to Rust.

25:36.000 --> 25:41.000
I can give you another example which is like error handling in Rust for instance is much better.

25:41.000 --> 25:51.000
So while in C if you get something, a wrong metadata, you may fail, and then you may have a bunch of go-tos that you have to go back in the exact reverse order, blah, blah, blah.

25:51.000 --> 25:53.000
And Rust, that's free.

25:53.000 --> 25:59.000
The compiler just wires up the calls from you in the right order always.

25:59.000 --> 26:04.000
So you can never forget to clean up after you're done if you have an error, you know?

26:04.000 --> 26:08.000
And you can say, well, you can just define your go-tos in the right way and be careful.

26:08.000 --> 26:12.000
Yes, C is just fine, hence why we have drivers in C working.

26:12.000 --> 26:15.000
But as humans we can forget, you know?

26:15.000 --> 26:21.000
So it's just a way to, you know, kind of close in on the human error factor, I'd say.

26:21.000 --> 26:26.000
Any more questions?

26:26.000 --> 26:28.000
Questions?

26:28.000 --> 26:36.000
Yeah, I was wondering, if you were theoretically to transpile your Rust to C, would that be acceptable then?

26:36.000 --> 26:38.000
To transpile to C?

26:38.000 --> 26:41.000
Yeah.

26:41.000 --> 26:49.000
I'm not aware of any way to transpile Rust to C, but you can have a C API for Rust.

26:49.000 --> 26:51.000
Somewhat easily.

26:51.000 --> 26:59.000
So you can define a header file and you can ask this, the Rust compiler, to provide you with C linkage, C-A-B-I.

26:59.000 --> 27:03.000
So that you can have a C API for your Rust code in the kernel even.

27:03.000 --> 27:09.000
The idea was that your code is being rejected because it's Rust and not C.

27:09.000 --> 27:10.000
I'm sorry?

27:10.000 --> 27:16.000
You said earlier in your slide that the maintainers reject your code because it's written in Rust.

27:16.000 --> 27:17.000
Yeah.

27:17.000 --> 27:23.000
But if you wrote Rust and transpiled to C and submitted the C result, would that make them happy?

27:23.000 --> 27:26.000
Yes, that's not really how it works.

27:26.000 --> 27:33.000
You can have a C API to your Rust code where you're not transpiling it and sending C code only.

27:33.000 --> 27:36.000
It's just not how the process works, you know?

27:36.000 --> 27:38.000
So you're not speaking the same thing.

27:38.000 --> 27:40.000
You're speaking about transpiling.

27:40.000 --> 27:48.000
But I'm speaking of having native Rust code and offering as well a C API to that Rust code.

27:48.000 --> 27:53.000
And I am not aware of any way for you to transpile Rust directly into C.

27:54.000 --> 27:57.000
And only send the C code as you're proposing.

28:02.000 --> 28:04.000
Okay, I think we're out of time.

28:05.000 --> 28:06.000
I think so.

28:07.000 --> 28:09.000
Thanks so much for your talk.

