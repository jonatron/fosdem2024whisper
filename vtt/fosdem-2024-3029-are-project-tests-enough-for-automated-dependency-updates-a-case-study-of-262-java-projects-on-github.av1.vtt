WEBVTT

00:00.000 --> 00:07.000
All right, everyone. So I guess this is the last session for today. And what I'm going

00:10.920 --> 00:17.040
to present now is about our project, Test Enough for Automated Appendice Updates. And

00:17.040 --> 00:21.040
before I delve into my presentation, does anyone actually have an answer to this? Who

00:21.040 --> 00:28.040
wants to attempt to answer the question here? It depends. Yeah, that's a great answer. And

00:28.080 --> 00:33.920
I think that's also in a way in the right direction. So a little bit about myself. So

00:33.920 --> 00:40.920
my name is Joseph Hyder. I'm a member of technical staff at Endolabs. It's a startup

00:41.040 --> 00:48.040
on more now a scale up based in Palo Alto in California. And before that, I mean, I'm

00:49.120 --> 00:53.600
still actually a PhD candidate at the Duff University of Technology in the Netherlands.

00:53.640 --> 01:00.640
So quite close by to Brussels here. And for the last, let's say like six, seven, eight

01:00.640 --> 01:06.640
years of my life, I've been quite involved in working on this, writing, security, but

01:06.640 --> 01:13.640
also developing techniques that are focused on trying to like apply program analysis to,

01:14.440 --> 01:19.000
for example, package repositories or trying to better understand what's going on within

01:19.040 --> 01:26.040
dependencies and dependency trees. And just like a little bit talk about what I mean with

01:26.600 --> 01:32.840
automated appendice updates. I guess most of you already know what it is. So essentially

01:32.840 --> 01:39.840
whenever there is a new release from Maven, Ruby Jam, Socargo or MPM, you would have a

01:40.520 --> 01:47.120
tool. I just did a couple of them, which is the Panda Bot or renovate or that few. So

01:47.160 --> 01:53.160
when there's a new release in your repository, usually a prerequisite is created. And then

01:53.160 --> 02:00.160
the, let's say like it creates a branch out of your repository, tries to build it. If

02:00.160 --> 02:04.560
that goes fine, so it goes usually to the next stage. If you have it configured to basically

02:04.560 --> 02:11.560
run the tests. And then if everything is fine, in this case, it's showed on X mark, but

02:11.720 --> 02:15.080
imagine if everything is fine, you will merge it. In some cases, if you know it's not a

02:15.120 --> 02:22.120
problem, you would merge it in any case. And I think for many of us, we have seen like,

02:22.160 --> 02:28.160
usually show something like this. It would update version 2.2 to 2.4. So that's like

02:28.280 --> 02:34.280
the essential thing that I'm focusing around. Like what I mean with automated dependence

02:34.280 --> 02:41.280
updates. And an interesting thing around automated dependence updates is that there's usually

02:41.360 --> 02:48.360
this promise that if you just run your tests, you are essentially able to catch any type

02:48.560 --> 02:55.560
of regression errors, any problems that might exist in your code. And me as a researcher

02:56.520 --> 03:03.520
that maybe sort of a bit questioning pattern, as I felt like, hmm, the test that we are usually

03:03.640 --> 03:08.160
having are projects, they're more focused on the your project test suite. And maybe not

03:08.200 --> 03:12.320
so much on the third party dependencies or third party libraries that you use in your

03:12.320 --> 03:19.320
code. So that may be sort of race three questions. The first question that I asked was, do we

03:22.880 --> 03:28.440
even write tests against dependencies in the first place? And then the second question

03:28.440 --> 03:35.440
is, do project tests with even cover usages of dependencies in the source code? And the

03:35.640 --> 03:41.280
last one is like, are even test sufficient alone just using tests to detect any bad updates

03:41.280 --> 03:48.280
that you might find in using these tools or doing automated dependency updates? And to

03:48.640 --> 03:55.640
study this, I looked into open source projects at the first, oh yeah, another question is,

03:57.560 --> 04:04.560
of course, should we even write test for dependencies? Because if we like to reuse components from

04:05.000 --> 04:10.040
open source package repositories, why should we even write tests for that? Because it kind

04:10.040 --> 04:15.520
of gives us the ergonomics that we can just use anything like it in our code and that's

04:15.520 --> 04:22.520
it. And this sort of like started like as an empirical study, that's sort of what this

04:24.840 --> 04:31.520
talk is primarily centered around. So the first thing that I looked at in 20 study was to

04:31.560 --> 04:37.520
see what is the statement coverage of function calls to dependencies. And this is similar

04:37.520 --> 04:44.280
to considering for example, like covered like life support, for example, like J. Coco as

04:44.280 --> 04:50.800
a tool. And then the other thing that we also focus in the study is how effective are tests

04:50.800 --> 04:56.600
using detecting updates with regression errors. So what we're doing here is that we are basically

04:56.640 --> 05:03.000
trying to find, I mean, either find or actually put regression errors in existing libraries,

05:03.000 --> 05:09.000
and then directly validate whether the project test suite can directly detect that or not.

05:09.000 --> 05:13.880
And that's also something called mutation testing analysis. And I think there was one

05:13.880 --> 05:20.880
talk about this earlier. And then the last thing around the studies that currently the

05:21.640 --> 05:27.600
sort of state of thought is to focus on just using test suites, but could we use another

05:27.600 --> 05:34.600
way to find any problems or early detect issues that might exist in updating our dependency.

05:39.160 --> 05:42.960
So yeah, the first question is like, how can we do some type of statement coverage or

05:42.960 --> 05:49.960
get an idea about what exactly are we using in third party libraries? So we did this in

05:50.400 --> 05:57.400
two ways. The first thing was to essentially, so this was of course in Java, we extracted

05:57.880 --> 06:03.320
all call sites that we will find in projects. And if those call sites points to third party

06:03.320 --> 06:09.040
libraries in bytecode, we consider that as a usage. And that's for trustive dependencies

06:09.040 --> 06:13.400
because now you're not, let's say like longer on your source code where you have the call

06:13.400 --> 06:18.240
set direct dependencies, you would also need to go to the trusty ones and here to sort

06:18.280 --> 06:23.520
of approximate that is not an exact measurement. We essentially build static whole graphs to

06:23.520 --> 06:30.520
kind of get an idea of what would be used in the chemistry of our project. And then

06:31.480 --> 06:38.480
last we did some instrumentation. So we essentially run the tests of a project and execute what

06:40.960 --> 06:45.240
functions were invoked in the dependencies. And this will give, let's say like some idea

06:45.240 --> 06:51.640
of what exactly is being used or not used at all. So essentially first we statically

06:51.640 --> 06:57.120
derive like, what are all the usages? And then by running the tests we know which of

06:57.120 --> 07:04.120
those functions were covered or not. So kind of similar to code coverage. And we did this

07:04.120 --> 07:11.120
for around 521 Gita projects. And what we found very interesting was that when we look

07:12.120 --> 07:17.120
at the direct dependencies of a project, so this is all the direct dependencies that

07:17.120 --> 07:24.120
were found, about 60% like when running the tests are, let's say like covered by it.

07:25.480 --> 07:31.480
But then when we go to trustive dependencies, we found that the median was only 20%. So

07:31.480 --> 07:38.480
which means that a lot of the transitive functions that may be used may not even be reachable

07:38.480 --> 07:45.480
by test. So they sort of like ring some alarm bells, right? Because that means essentially

07:45.640 --> 07:51.200
like if you have a dependency update and you don't have any test that is covering that

07:51.200 --> 07:56.600
area, that will basically give you a green tick and you might merge it. And I don't think

07:56.600 --> 08:01.080
many would do that. But that's, let's say like the implementation area that also kind

08:01.080 --> 08:08.080
of raises some questions around how effective using tests for automated updates. And yeah,

08:11.200 --> 08:15.040
the other question does this matter at all. And I think a very interesting one here is

08:15.040 --> 08:22.040
the log for shell case because I don't think many of us would have tests that is particularly

08:22.040 --> 08:27.200
targeting log libraries. But here is an instance where something we don't normally would test

08:27.240 --> 08:32.200
and would have tests in any case. If you would do an update, then yeah, there might be some

08:32.200 --> 08:39.040
breaking changes then yeah, there will be a problem here. Then going to the second part

08:39.040 --> 08:44.200
of the study, which was on test effectiveness. And I was measuring that we're doing mutation

08:44.200 --> 08:51.440
testing. So the underlying framework we used here was a pie test, but we modified pie test

08:51.520 --> 08:58.520
to do things a little bit differently. And yeah, to sort of like give a quick sort of

08:58.560 --> 09:05.060
idea of what mutation testing is, is that you essentially have a function, for example,

09:05.060 --> 09:12.060
return x plus y. And then you apply some type of mutation operator where you swap, let's

09:13.360 --> 09:19.520
say like the class. And then you would expect that your test suite will be able to cover

09:19.520 --> 09:25.240
this because here the behavior is completely changed, right? It's no longer an addition

09:25.240 --> 09:30.240
operator. So normally with mutation testing, you would give it your whole project source

09:30.240 --> 09:35.120
code. It will start trying to modify in the source code and then see whether the test

09:35.120 --> 09:41.040
suite is able to capture that or not. So what we did differently is that we essentially

09:41.040 --> 09:48.040
mutated functions in the dependency code and not the project code at all. And we only mutated

09:48.440 --> 09:53.440
those that were reachable by test. So I was saying earlier that we were running a test

09:53.440 --> 09:57.920
to know which functions were executed. So we used those functions to essentially apply

09:57.920 --> 10:02.840
those mutation operators. And then from there we can see if the test is able to capture

10:02.840 --> 10:09.840
that or not. And yeah, before I go into this also another alternative way that we investigated

10:10.160 --> 10:17.160
is called a change impact analysis. So here we sort of leverage static analysis and specifically

10:21.200 --> 10:28.200
using call graphs. So how it essentially works is that we have a version 1.02 and 1.03.

10:30.160 --> 10:36.800
We compute a diff and for the diff we will find out which functions changed. And for

10:36.840 --> 10:43.840
example here we know that in bar and bus function we can see that there is an arithmetic change

10:44.080 --> 10:50.280
like instead of y minus minus it's y plus plus. And then in the other, like in the bus

10:50.280 --> 10:57.280
function we see that there is a new method called. And then what do we do later? We practically

10:58.680 --> 11:05.200
build a call graph of the application and its dependencies. And then using reachability

11:05.280 --> 11:11.240
analysis, so what we do here is that we know that the bar and bus was changed. And here

11:11.240 --> 11:18.240
we have let's say like a reachable path from bar up to let's say like stats on the score

11:19.000 --> 11:24.560
JSON I mean. And also we have like bus here where we have a new function called to QX

11:24.560 --> 11:31.560
STR. And by using this we can directly figure out if there is a coaching and dependency

11:31.760 --> 11:38.040
whether you are reachable or not in the first place. And why this is like a very nice complement

11:38.040 --> 11:44.640
to dynamic test is that we are essentially leveraging by looking at the source code what

11:44.640 --> 11:49.760
are we actually using. And then as a complement to where tests might not be covering we can

11:49.760 --> 11:56.760
sort of find directly if there is any change that might affect like your project. That

11:57.040 --> 12:03.240
of course comes the more tricky part which is semantic changes. So I mean one thing it's

12:03.240 --> 12:08.440
nice that you can detect that the method change but sometimes you might just do a simple

12:08.440 --> 12:15.440
refactoring that you know just refactors are a huge method into a method with like a couple

12:15.440 --> 12:22.040
of smaller methods is that. So the truth is that it's extremely difficult to know what

12:22.080 --> 12:26.800
exactly is a semantic change because there's a lot of factors around it. So the only thing

12:26.800 --> 12:31.720
that we did was that we kind of took what was like behavioral changes. So we looked at

12:31.720 --> 12:37.440
only like data flow or control flow changes. So for example if you add a new method call

12:37.440 --> 12:43.800
we consider that as like a special change or if you did some major change on your if statements

12:43.800 --> 12:49.400
that may introduce a new logic of how the control flow works then we consider that as

12:49.480 --> 12:56.480
an interesting change to follow. And what it is like I implemented a tool called Uptatera

12:58.880 --> 13:05.880
which means update in Swedish. And so I applied this on.

13:10.800 --> 13:17.800
So it essentially shows like which function had a change. So for example Rx, Java, not

13:18.440 --> 13:23.640
facing subscriber on error and we can see that it's reachable from the project and then

13:23.640 --> 13:30.140
it shows exactly how it was reachable. Yeah through like the code. And then in the second

13:30.140 --> 13:36.520
section I would have like what is basically the major changes in that function. So this

13:36.520 --> 13:41.040
could sort of give you some context of what essentially changed. Other than just telling

13:41.040 --> 13:48.040
that either the test parsed or failed. And when using this mutation PyPlanet that was

13:52.840 --> 13:59.840
explaining we essentially generated 1 million artificial updates by introducing those regressions

14:00.160 --> 14:07.160
and we did this on 262 GitHub projects. And what we found was that when doing the sort

14:08.000 --> 14:15.000
of changes on project tests we found that on average projects are able to detect 37%

14:15.400 --> 14:22.400
of those which means that a lot of like changes may not may get unnoticed like in general.

14:24.120 --> 14:29.960
But if you use static analysis now that you sort of have the whole context we able to

14:29.960 --> 14:36.960
detect 72% of all those changes. But what we find more interesting is that we can see

14:37.160 --> 14:41.760
that interestingly here like from the context of the studies that there's basically no guarantees

14:41.760 --> 14:48.520
that tests can prevent bad updates and using either of those techniques is not good enough

14:48.520 --> 14:55.520
to ensure that updates are safe. Then of course the other thing is that static analysis is

14:56.000 --> 15:01.120
not perfect. There are also problems with it as well. So the problem is over approximation.

15:01.120 --> 15:07.760
So we have over approximation at two locations. One is the call graphs themselves because

15:07.760 --> 15:13.600
when it comes to dynamic dispatch if there are maybe 200 implementations that might stand

15:13.600 --> 15:19.200
from an interface call we have to link to all of them and that might generate false positives.

15:19.200 --> 15:25.680
And then the other case is also with the semantic changes that we are detecting because we also

15:26.040 --> 15:30.920
don't know exactly what type of semantic changes it is. But to sort of see how this worked

15:30.920 --> 15:37.920
in practice we also analyzed and applied this on 22 dependable PRs. And from the results

15:39.800 --> 15:46.400
what we found in general was that by using static analysis we were able to detect three

15:46.400 --> 15:50.800
unused dependencies. So here let's say like the test would just pass it whatever but in

15:50.840 --> 15:57.680
fact we found that the dependencies were not used at all. And we were able to prevent three

15:57.680 --> 16:04.680
breaking updates and one which actually was confirmed by our developer where the test

16:04.680 --> 16:09.720
were not able to detect. And then of course we found that there are let's say like false

16:09.720 --> 16:16.000
positives and as I mentioned there were many cases with refractorings and then of course

16:16.040 --> 16:22.080
this over approximated call paths. So if you use like a tool like Google here or static

16:22.080 --> 16:27.080
analysis it can help to prevent updates but then you also get a lot of noise as well as

16:27.080 --> 16:34.080
a result. So sort of coming to the end of more of the studies what are let's say like the

16:37.080 --> 16:44.080
recommendations that I have after looking into like on Github projects how tests are

16:44.160 --> 16:49.960
being made etc. So one thing I found missing when it comes to updating with test widths

16:49.960 --> 16:55.760
is that we don't have any form of confidence score. And what I mean with confidence score

16:55.760 --> 17:02.760
is that for example if we can stop measuring test coverage we can see for example if there

17:03.680 --> 17:09.160
is a change function in a third party library do we even have test that reaches that or

17:09.160 --> 17:14.840
not and that could directly give an indication whether like my test width is able to capture

17:14.840 --> 17:20.840
that or not. And another very interesting thing could be for example if you find that

17:20.840 --> 17:26.200
one of your libraries are very tightly integrated with your project it can also sort of give

17:26.200 --> 17:33.200
an indication whether you have let's say like enough test to cover that usage or not at all.

17:34.040 --> 17:38.360
And then by having sort of this score you can maybe get an indication where does let's

17:38.440 --> 17:44.440
say like how well am I just able to capture things in third party libraries or not. This

17:44.440 --> 17:49.320
is something that I would like to see in tooling in general. And then when it comes to the

17:49.320 --> 17:53.440
gaps in test coverage so this is related to the results I was saying like the statement

17:53.440 --> 18:00.440
coverage and effectiveness. So I believe more of having a hybrid solution so we're using

18:02.600 --> 18:07.600
tests or dynamic analysis is able to capture. I think we should use that because that is

18:07.640 --> 18:13.640
more precise. But then in areas of the code where we don't have any coverage so for example

18:13.640 --> 18:19.280
consider back to the look for J library where usually I wouldn't expect just to be much

18:19.280 --> 18:24.800
test coverage. Here it could be nice to complement the static analysis. So you sort of get a

18:24.800 --> 18:31.800
little bit better for both words here. And then another advantage that I might see having

18:32.040 --> 18:39.040
static analysis rather running tests is that we can maybe much more earlier to take potential

18:39.480 --> 18:44.840
like problems in compatibilities by having that rather than trying to run it through

18:44.840 --> 18:51.840
the build system consuming extra resources or tests etc. So those are less likely to main

18:51.880 --> 18:58.880
things that I find important to address. And then for users like myself of using this

18:59.840 --> 19:05.720
automated dependence updating tools. So although like reusing is free in the sense that we

19:05.720 --> 19:11.640
can easily just use a library but we often forget the operational and maintenance costs

19:11.640 --> 19:18.640
and those are not free. So trying to basically automate away everything by using tooling

19:18.760 --> 19:24.720
etc. is not always the solution. I think it's important to also consider that once we start

19:24.720 --> 19:30.080
adopting a library we also need to think about how we can maintain it but also understanding

19:30.080 --> 19:35.840
what potential risk might come from it. Could be for example that maintainer have a very

19:35.840 --> 19:40.600
different sort of handling when it comes to security vulnerabilities. It could also be

19:40.600 --> 19:44.880
with the release protocol like there could be disagreements on what is breaking change

19:44.880 --> 19:51.880
or not for clients. So I think having that aspect is one important thing. And the other

19:52.800 --> 19:58.760
thing is like of course not blindly trusting automated dependency updates and I guess no

19:58.760 --> 20:04.640
one really does this. And then that's another thing which could be debatable is to have

20:04.640 --> 20:09.240
essentially critical I mean having writing tests for critical dependencies and this could

20:09.240 --> 20:16.480
be a library that's very critical to your project. I think here maybe having tests could

20:16.520 --> 20:22.440
help let's say like capture early issues that might arise in dependencies and not come

20:22.440 --> 20:29.440
as an unwanted breaking change later on once you merge the automated PR.

20:32.200 --> 20:37.760
So if you want to let's say like know more about this work I have a paper so I also

20:37.760 --> 20:44.760
uploaded slides on the Fosnum website so you can click the link and the paper is open access

20:44.760 --> 20:52.760
and yeah this is concludes my talk more or less so happy to take any questions.

21:15.760 --> 21:22.760
So do you know if any of these bots like the pen about renovate are working on such a score

21:22.760 --> 21:28.760
so let's say the merge request to get like a warning. Hey your tests are not covering

21:28.760 --> 21:33.760
only 10 percent of the dependencies. Do you know if there is any work.

21:33.760 --> 21:40.760
So what I'm aware of is that there is a compatibility score that looks at for example for a particular

21:41.760 --> 21:48.760
dependency version updates if out of less than like 200 PRs if 100 of those were successful

21:49.760 --> 21:55.760
for other projects then it will give us a score that there's a 50 percent chance that you will

21:55.760 --> 22:00.760
succeed here. The only thing I find problematic is that every project has their own specific

22:00.760 --> 22:06.760
use case or context of how they use it so it could be misleading but I haven't heard anything

22:06.760 --> 22:13.760
that looks specifically into your test suite to see how I mean how it's able to do that.

22:24.760 --> 22:31.760
Thank you. You mentioned the number of 60 percent for the amount of tests for direct dependencies

22:32.760 --> 22:41.760
and I believe it was a lot less for transitive dependencies. Do you have any numbers on the amount of transitive dependencies

22:42.760 --> 22:51.760
in search change the chains actually. So I can can imagine that the 60 percent is cumulative in these.

22:52.760 --> 22:57.760
Do you mean for the statement coverage thing or the statement. Yeah the first one.

22:58.760 --> 23:06.760
So the first one the 60 percent was on like direct dependencies and then this 20 percent was on the transitive ones.

23:07.760 --> 23:13.760
Do you have any numbers of the amount of transitive dependencies so you can relate it to that 60 percent.

23:14.760 --> 23:19.760
Okay so I did this on 500 time projects but I might have the more specific numbers in the paper.

23:19.760 --> 23:32.760
Okay. You have been looking at detecting errors. Have you looked in the other side because you can use it in a hybrid mode

23:32.760 --> 23:39.760
that your tool maybe can tell me you can make this update for sure because all the code is changed.

23:40.760 --> 23:47.760
You don't care about it. For example if you look at low level right libraries like Apache Commons you only use a part of it

23:47.760 --> 23:56.760
but you want to keep up to date and some updates are more or less completely safe because you don't touch any code that has changed

23:56.760 --> 24:03.760
because only new features have been added or so and that would also help if I just know yes that's safe.

24:04.760 --> 24:11.760
Yeah that's a great question. So this is a little bit idea we had with introducing call graphs because the call graphs

24:11.760 --> 24:19.760
you can start learning what exactly is used. So even if you use like a major library and you just use maybe two utility classes

24:20.760 --> 24:26.760
and even if you go to like a major version of it you might not be affected by it and this is something that should be covered by the call graph

24:26.760 --> 24:35.760
so we will see for example that the utility classes there are no changes there but then in the rest of the package there's a lot of changes that you're unaffected by.

24:41.760 --> 24:43.760
Thank you.

24:59.760 --> 25:04.760
Did you check how the call graphs work with dynamic dependency injection?

25:05.760 --> 25:14.760
Yeah so we essentially if I understood the question right I mean so we did generate the dynamic call graphs like running the test

25:14.760 --> 25:24.760
and this is something that we essentially used to guide or rotation like testing framework to only do changes in those functions

25:24.760 --> 25:33.760
and not for example functions that the test didn't touch because otherwise we wouldn't know whether I mean the test we were able to

25:33.760 --> 25:35.760
detect changes or not.

