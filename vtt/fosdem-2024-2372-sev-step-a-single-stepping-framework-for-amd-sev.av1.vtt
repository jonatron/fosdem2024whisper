WEBVTT

00:00.000 --> 00:13.400
So, the next speaker is Luca Wilk from the University of Lubbeck and he will talk about

00:13.400 --> 00:15.720
some recent work he has been doing, actually, attack research.

00:15.720 --> 00:21.000
I'm very excited that the Dev Room from the start has had some consistent attack research

00:21.000 --> 00:25.200
line as well, which I think is very important for this new type of technology.

00:25.200 --> 00:27.200
So Luca, enlighten us.

00:28.200 --> 00:31.200
Yeah, thank you very much for the kind introduction.

00:31.200 --> 00:37.200
I will be talking about SCVSTEP, which is a single stepping framework for AMD SCV,

00:37.200 --> 00:42.200
and it's open source and available on GitHub, so feel free to check it out.

00:42.200 --> 00:49.200
And this was created as part of an academic paper, which is joint work with these great people down here.

00:49.200 --> 00:55.200
Okay, just a quick recap where we are in the trusted execution environment landscape.

00:55.200 --> 00:59.200
So as the name suggests, SCVSTEP is about AMD SCV.

00:59.200 --> 01:02.200
So we are in this confidential VM area here.

01:02.200 --> 01:09.200
However, single stepping is something that basically affects all TEs that are out there right now,

01:09.200 --> 01:11.200
so keep that in mind.

01:11.200 --> 01:18.200
Okay, with that out of the way, we can jump right in and explore what single stepping attacks actually are.

01:18.200 --> 01:21.200
So we start with a quite high level picture.

01:21.200 --> 01:27.200
What you want to do here is you want to take some kind of snapshot or observation of our protected application,

01:27.200 --> 01:29.200
and we use this for our tech.

01:29.200 --> 01:34.200
Now, if our TE runs normally, then it runs basically at full speed,

01:34.200 --> 01:39.200
and if we take these snapshots, we don't affect any synchronization with this TE process,

01:39.200 --> 01:43.200
and thus the observation and the data that we get is very blurry.

01:43.200 --> 01:47.200
But now if we start to interrupt the enclave at certain points,

01:47.200 --> 01:52.200
then we have these synchronous points in time where you can start to take our snapshots.

01:52.200 --> 01:58.200
So it's not running in parallel anymore, but the enclave is paused when we take our snapshots.

01:58.200 --> 02:01.200
And thus we already get a little bit more information.

02:01.200 --> 02:06.200
And now if we take this to the maximum resolution and we are able to interrupt the enclave

02:06.200 --> 02:12.200
after every single instruction reliably, then we get a pretty clear picture of what's going on.

02:12.200 --> 02:16.200
So I hope that already gave you like a good intuition.

02:16.200 --> 02:22.200
And now we go into what single-stepping attacks have actually been used for, mostly in academia.

02:22.200 --> 02:28.200
And these are all examples that have been done with SGX that really made this popular in academia

02:28.200 --> 02:31.200
because it made single-stepping very accessible.

02:31.200 --> 02:36.200
So the first attack avenue basic here is something called interrupt latency,

02:36.200 --> 02:41.200
and there you basically measure how long it takes from where you like started this attack

02:41.200 --> 02:46.200
to when you get like this callback that the enclave has been now interrupted or exited.

02:46.200 --> 02:51.200
And it has been shown that this timing actually revealed something about the kind of information

02:51.200 --> 02:53.200
that's running in the enclave.

02:53.200 --> 02:58.200
And for some instructions like different instructions, you can even learn something about the operands.

02:58.200 --> 03:02.200
So dividing by certain numbers takes longer than dividing by other numbers.

03:02.200 --> 03:07.200
And thus you really kind of instruction and maybe even the operand with these attacks.

03:07.200 --> 03:13.200
Then the second major attack avenue here is called interrupt counting or instruction counting.

03:13.200 --> 03:20.200
And here the idea is that certain algorithms and applications have secret dependent control flows,

03:20.200 --> 03:22.200
especially true for cryptographic algorithms.

03:22.200 --> 03:29.200
We have some secret key, and then I do some large integer multiplication or division and decode the dusted.

03:29.200 --> 03:34.200
Executes a different number of instructions depending on the secret data.

03:34.200 --> 03:40.200
And now when I do this senior stepping attacks, I can simply count the numbers of steps that I take.

03:40.200 --> 03:45.200
And then if I know on which code page I'm currently in, then I can learn something about the secret data

03:45.200 --> 03:48.200
just by observing the number of instructions.

03:48.200 --> 03:55.200
So in this tiny example here with a conditional jump, and in one case we skip over this move here,

03:55.200 --> 03:56.200
and the others we don't.

03:56.200 --> 03:59.200
So here we get two instructions executed here, three.

03:59.200 --> 04:04.200
And by knowing the code that's currently running, we can infer the value of the secret bit here.

04:04.200 --> 04:10.200
Then the third really popular attack avenue is not directly senior stepping, but closely related.

04:10.200 --> 04:12.200
It's called zero stepping.

04:12.200 --> 04:17.200
And here the idea is that we interrupt the enclave even more frequently.

04:17.200 --> 04:21.200
So before this able to actually execute a single instruction.

04:21.200 --> 04:26.200
So it doesn't make any progress on an architectural level, but on a micro-architectural level,

04:26.200 --> 04:27.200
it is first instruction.

04:27.200 --> 04:31.200
It's already starting to execute, then gets a board and roll it back.

04:31.200 --> 04:36.200
But on the micro-architectural state, there's actually still already stuff going on.

04:36.200 --> 04:39.200
And these attacks are able to measure this.

04:39.200 --> 04:46.200
And what we can do then is basically take an infinite number of measurements, but only running the enclave once.

04:46.200 --> 04:50.200
And this allows you to measure really, really tiny effects.

04:50.200 --> 04:55.200
And then the third column here is kind of the miscellaneous sketch all column.

04:55.200 --> 05:02.200
So as you can imagine, just by increasing this temporal resolution, you can improve basically any side channel attacks.

05:02.200 --> 05:08.200
So it has been used in many of these MDS attacks here, for example.

05:08.200 --> 05:14.200
Okay, so now that we know what senior stepping basically is and why it's really dangerous,

05:14.200 --> 05:16.200
we come to the main question of the stock here.

05:16.200 --> 05:18.200
Can ACVVM be single stepped?

05:18.200 --> 05:20.200
And if so, how?

05:20.200 --> 05:23.200
So let's take a look at the basic setup here.

05:23.200 --> 05:30.200
So this is like a very boiled down version of the control loop that's going on in the hypervisor, where we enter DVM here.

05:30.200 --> 05:35.200
Then we execute some instructions and then at some point we exit.

05:35.200 --> 05:42.200
So for senior stepping, the obvious question is, when we exit DVM here, this is what you want to control in our attack.

05:42.200 --> 05:46.200
And there are multiple reasons why this can happen.

05:46.200 --> 05:50.200
So we can configure certain instructions to be intercepted.

05:50.200 --> 05:56.200
And you can also use page for it by removing access rights in these nested page tables.

05:56.200 --> 06:02.200
However, none of these two methods give us the amount of control that we want because they are not instruction granular.

06:02.200 --> 06:08.200
However, you can also use external interrupts to force an exit from our VM.

06:08.200 --> 06:13.200
And this is actually what will allow us to achieve this instruction granularity.

06:13.200 --> 06:17.200
And for this, the attacker uses something that's called the APIC timer.

06:17.200 --> 06:22.200
It's a common timer on x86 used by the operating system.

06:22.200 --> 06:26.200
And by injecting this timer, we will force exits from DVM.

06:26.200 --> 06:28.200
So let's zoom in a little bit.

06:28.200 --> 06:31.200
This is a typical attack sequence here.

06:31.200 --> 06:34.200
In red, we have the coded ones in the hypervisor.

06:34.200 --> 06:36.200
It's controlled by the attacker.

06:36.200 --> 06:42.200
And on the right here, the blue, that's the three instructions from DVM that you just saw.

06:42.200 --> 06:46.200
So what do we need to do now to achieve senior stepping?

06:46.200 --> 06:54.200
Well, intuitively, you would think that you would need to hit this tiny window between these two instructions here to single step.

06:54.200 --> 07:02.200
However, luckily on x86, it's already sufficient if our interrupt hits somewhere during the execution of this instruction.

07:02.200 --> 07:10.200
Because then it will be held pending and will be basically recognized at instruction boundary.

07:10.200 --> 07:15.200
Okay, but if we just naively implement this and try to do this, then we are not quite there yet.

07:15.200 --> 07:21.200
And we will see that sometimes we will overshoot here and then we will execute two or more instructions.

07:21.200 --> 07:28.200
And this, of course, decreases our resolution because now we cannot guarantee that we do something after every instruction.

07:28.200 --> 07:34.200
Maybe we have bad luck and skip over very important memory access instructions also on.

07:34.200 --> 07:37.200
So this is really bad, this mighty stepping.

07:37.200 --> 07:42.200
And on the other side, we might undershoot a little bit and zero step.

07:42.200 --> 07:48.200
And this is not really dangerous because then we simply repeat, we don't miss out on any instructions.

07:48.200 --> 07:52.200
We just try again and it's a little bit less efficient.

07:52.200 --> 07:54.200
So why is this the case?

07:54.200 --> 08:01.200
And there has been some really nice papers on SGX and they show that this APIC timer has quite some jitter.

08:01.200 --> 08:03.200
So it's not cycle accurate.

08:03.200 --> 08:06.200
So it kind of makes sense that we see this behavior here.

08:06.200 --> 08:09.200
So what do we do about this?

08:09.200 --> 08:20.200
And the kind of obvious idea is, okay, we kind of need to make this window larger because our timer doesn't have the high enough resolution.

08:20.200 --> 08:24.200
So we kind of need to enlarge the window at which our timer can hit.

08:24.200 --> 08:29.200
And for this, we look at what's actually going on when we execute an instruction here.

08:29.200 --> 08:36.200
So first we have to fetch the instruction from memory from the code page and then the CPU can decode it,

08:36.200 --> 08:39.200
issue it to the pipeline and eventually retire it.

08:39.200 --> 08:47.200
So for the attack, the idea here is now that we make sure that this year takes a long time and we achieve this

08:47.200 --> 08:50.200
by simply flushing the page from the memory.

08:50.200 --> 08:54.200
So we flush the VMs TLB and that's when we enter it again.

08:54.200 --> 09:01.200
We need to do a page that we walk, which will take some time and this effectively prolongs this window here.

09:01.200 --> 09:04.200
That is required to execute the first instruction.

09:04.200 --> 09:12.200
And now although our timer still has this jitter, this window is large enough so that we can actually rely on the single step.

09:12.200 --> 09:18.200
And the ACV step at the time of publishing was the first frame that did this shortly afterwards.

09:18.200 --> 09:23.200
There were also some papers that did something similar and it's also open source.

09:23.200 --> 09:27.200
So we hope that other people will reuse it.

09:27.200 --> 09:34.200
Okay, so now let's take a little bit closer look at the ACV step framework itself.

09:34.200 --> 09:39.200
So besides reliably single stepping, we wanted to achieve two other goals.

09:39.200 --> 09:43.200
And this is reusability and interactivity for the attacks.

09:43.200 --> 09:47.200
And I will go over these two goals now in more detail.

09:47.200 --> 09:52.200
So for reusability, let's again look at our setup here.

09:52.200 --> 10:01.200
And since we want to program this APIC timer, we want to manipulate these page tables and maybe do some cache priming and probing.

10:01.200 --> 10:08.200
All of these things would benefit from being really close to entering and leaving DVM because this is the point.

10:08.200 --> 10:11.200
We have the lowest noise.

10:11.200 --> 10:17.200
However, this also means that we need to manipulate or change the kernel code and developing kernel code.

10:17.200 --> 10:23.200
It's quite hard. It's hard to debug. You're limited to see. You don't have any external libraries.

10:23.200 --> 10:26.200
So it's not the nicest programming environment.

10:26.200 --> 10:35.200
And also it makes reusing this for different attacks or for different papers quite hard because this environment is not so nice.

10:35.200 --> 10:40.200
And your tech logic is basically mixed together with these attack primitives.

10:40.200 --> 10:46.200
So instead what you want to do here is we only want to implement these bare primitives inside the kernel,

10:46.200 --> 10:52.200
like programming the timer, manipulating these page tables and cache priming and probing.

10:52.200 --> 10:56.200
And all of the other stuff is then moved out to user space.

10:56.200 --> 11:02.200
And we use an IOCTL API then to trigger this behavior from user space.

11:02.200 --> 11:06.200
So then here we have this much nicer programming environment.

11:06.200 --> 11:12.200
And other people can simply link against this library and write their attack code with it.

11:12.200 --> 11:21.200
And one tiny note is that this execution loop of DVM is asynchronous from our IOCTL API.

11:21.200 --> 11:25.200
So it changes only take effect the next time DVM exits.

11:25.200 --> 11:29.200
So we have some data variables here for communication,

11:29.200 --> 11:36.200
but this is something you kind of need in mind when you program these attacks.

11:36.200 --> 11:39.200
Okay, so we achieved this goal of usability.

11:39.200 --> 11:43.200
Let's move on to the second goal for interactivity.

11:43.200 --> 11:53.200
And to understand this a little bit better, I will go into more detail of how I envision this programming environment here in the user space library.

11:53.200 --> 11:57.200
And there we also basically want to have some kind of event loop.

11:57.200 --> 12:04.200
Initially we set up some configuration like I want to get a page forward once this page is accessed.

12:04.200 --> 12:09.200
And then we want basically to wait until this event happens.

12:09.200 --> 12:12.200
And when this event happens, we want to react to this event.

12:12.200 --> 12:22.200
We have usually in these attacks some kind of page forward sequence that would tell us when the VM is about to execute some certain function.

12:22.200 --> 12:29.200
And then maybe at this point we want to enable single stepping and do some steps to a cache attack, this kind of stuff.

12:29.200 --> 12:33.200
So this is basically the process event and the deved config part here.

12:33.200 --> 12:43.200
And the really important thing is that once we got this event, we also want the VM here to basically wait for us to process this event

12:43.200 --> 12:46.200
because we would allow it to resume.

12:46.200 --> 12:54.200
Then we would again lose this precise control you wanted to have to manipulate the environment after every instruction.

12:54.200 --> 13:05.200
So we now also need a way to basically communicate from the kernel side to a user space library to be able to send these events and wait for these acknowledgments.

13:05.200 --> 13:09.200
And for this we opted for a shared memory protocol.

13:09.200 --> 13:20.200
So the library and the kernel code here simply agree on a shared memory page and then use a simple protocol with some spin locks to basically implement this.

13:20.200 --> 13:23.200
Why is this not the most efficient?

13:23.200 --> 13:27.200
It is very low latency because it's just memory communication.

13:27.200 --> 13:38.200
You don't have any user space, kernel space context switch as with the IOCTL here and also reasonably to implement.

13:38.200 --> 13:42.200
Okay, and this is how we achieve this interactivity goal.

13:42.200 --> 13:46.200
This is basically the current state of the framework.

13:46.200 --> 13:53.200
But to close up, I also want to give an overview of ongoing and future work.

13:53.200 --> 14:05.200
So one thing I've been working on a little bit already and I would really like to continue on is to improve this API, this programming environment because right now it's kind of basically have these

14:05.200 --> 14:07.200
start, track, stop, track commands.

14:07.200 --> 14:16.200
And if you start to write your attack code as I've experienced myself, this can get quite messy and quite long really quick.

14:16.200 --> 14:20.200
So it would be cool to have some higher level abstractions for this.

14:20.200 --> 14:29.200
For example, a component that could track a certain page for a sequence for you and restart the tracking if you get some unexpected access and so on.

14:29.200 --> 14:40.200
And then some kind of mechanism or protocol to chain together these components so that you can structure your attack better.

14:40.200 --> 14:45.200
Also make it easier for people to get started by reusing these building blocks.

14:45.200 --> 14:52.200
And thinking about this even more, this is totally independent of the actuality underneath.

14:52.200 --> 15:05.200
So this is maybe something where the existing S3X step community could come together and could build these libraries at a higher level and then S3X step and SIV step.

15:05.200 --> 15:17.200
And I think the trust zone one is called load step could basically be initiated as drivers underneath that so that everyone could profit from this.

15:17.200 --> 15:18.200
Okay.

15:18.200 --> 15:20.200
And this is more or less it.

15:20.200 --> 15:25.200
You can again find the links for SIV step and also for SGX step, which I mentioned here.

15:25.200 --> 15:28.200
They are both open source and on GitHub.

15:28.200 --> 15:31.200
Feel free to check them out.

15:31.200 --> 15:38.200
Send me a pre request if you want to change something, create an issue that's something broken.

15:38.200 --> 15:40.200
And yeah, thank you so much.

15:40.200 --> 15:42.200
And I'm happy to answer questions now.

15:42.200 --> 15:58.200
Yeah.

15:58.200 --> 16:00.200
Yeah, thank you for the very interesting talk.

16:00.200 --> 16:03.200
A new Satchel attack for me.

16:03.200 --> 16:06.200
And now you've showed how to break things.

16:06.200 --> 16:13.200
Do you have some ideas how this kind of attack could be mitigated possibly?

16:13.200 --> 16:15.200
Yeah, so it's a really good question.

16:15.200 --> 16:22.200
So for S3X, there recently has been a paper which was does is called a X notify.

16:22.200 --> 16:35.200
And then basically the idea is to make the S3X and play interrupt aware and then execute some special handler that will pre fetch this first instruction that I showed so that you can't do this.

16:35.200 --> 16:46.200
I flushed the TAB and make everything really slow approach, but ensure that this the first instruction always executes really fast and this then mitigates this attack.

16:46.200 --> 16:54.200
And for TDX, which we just talked about, there's also some mitigation built into the TX module.

16:54.200 --> 17:08.200
And for SEV, we are currently looking into ideas how we could protect SEV VMs against this.

17:08.200 --> 17:18.200
Thank you. Thank you, Luca.

17:18.200 --> 17:20.200
Yes, we're back.

17:20.200 --> 17:33.200
So can you elaborate a bit on how much of this is SEV specific and how much of it is actually, let's say KVM step?

17:33.200 --> 17:46.200
Let's say if you don't have a mitigation in TDX, can you just launch this as is on any kind of VM or is this specific to SEV in any in any way? Thank you.

17:46.200 --> 18:02.200
So I don't think it's really specific to SEV because this ability to flush the TAB that should also be available with VMX with the hardware acceleration for Intel.

18:02.200 --> 18:04.200
I think that the basic primitive should apply.

18:04.200 --> 18:13.200
I also know that there has been like an internal prototype that's what's called TDX step that's on one of the Intel pages.

18:13.200 --> 18:18.200
So they basically build something similar for this.

18:18.200 --> 18:31.200
So I guess in principle, this should apply to all like VM based systems where the VM can be forced to exit by external interrupts.

18:31.200 --> 18:33.200
There's one more question.

18:33.200 --> 18:37.200
Can you repeat it if you have all the plans for TDX?

18:37.200 --> 18:39.200
It's definitely really interesting.

18:39.200 --> 18:54.200
The question was if you have also plans for TDX and as I've said, TDX is a bit in countermeasure, but I guess it would be of course interesting to try to figure out how this works exactly.

18:54.200 --> 18:56.200
If you can do something there.

