WEBVTT

00:00.000 --> 00:07.000
All right.

00:07.000 --> 00:08.000
Perfect.

00:08.000 --> 00:14.000
So, let's hope that we don't get this.

00:14.000 --> 00:15.000
Perfect.

00:15.000 --> 00:16.000
So.

00:16.000 --> 00:17.000
All right.

00:17.000 --> 00:27.000
We're going away from CERN, but we stay in Taitlan, so let's welcome Victor and give him some applause.

00:27.000 --> 00:31.000
Hello, everyone. Thank you so much for being here.

00:31.000 --> 00:41.000
In today's session, we are going to see how to deploy a hyperconverting infrastructure with F across the cloud edge continuum.

00:41.000 --> 00:44.000
But first, let me introduce myself.

00:44.000 --> 00:48.000
My name is Victor Palma, cloud engineer at Open Nebula.

00:48.000 --> 00:56.000
I come from Madrid, Spain, and I've been working for Open Nebula for more than two years.

00:56.000 --> 01:02.000
Developing an innovative new feature for the cloud edge world.

01:02.000 --> 01:14.000
So, first, we are going to start with some theory and then my idea is to show you a demo of all the things that we are going to see here.

01:14.000 --> 01:22.000
Well, first, we need to do the question of what is the cloud edge continuum?

01:22.000 --> 01:33.000
The cloud edge continuum is just an environment of nodes on the edge,

01:33.000 --> 01:44.000
distributed in multiple locations and everything interconnected using the same management layer.

01:44.000 --> 01:58.000
So, some advantages of the cloud edge continuum are the deployment of low latency applications.

01:58.000 --> 02:05.000
Since we are deploying our application near and closely to the final user,

02:05.000 --> 02:19.000
we can also reduce the energy consumption that our application does since we are deploying the application in a small data center, not in a big one.

02:19.000 --> 02:32.000
We can also reduce the vendor dependency since we are not deploying our application in a standard data center like cloud or AWS.

02:32.000 --> 02:41.000
We are deploying our application in multiple locations and managed by any provider that we want at any time.

02:41.000 --> 02:51.000
Then we can improve the user experience using the cloud edge continuum for our applications.

02:51.000 --> 02:58.000
Since it's related to the first point, since we are deploying our application near to the user,

02:58.000 --> 03:02.000
the experience and the latency is going to be low.

03:02.000 --> 03:15.000
We can also expand the service ability. It's very easy to duplicate and replicate our applications in different locations, different servers.

03:15.000 --> 03:21.000
We can deploy our application, for example, one cloud edge in Paris, another one in Madrid.

03:21.000 --> 03:31.000
If we want to replicate that, it's very easy to replicate the same infrastructure in Lisbon or London and so on.

03:31.000 --> 03:47.000
Finally, we can reduce data transfers and reduce security rigs since we are running all of this in a local location near to the user.

03:47.000 --> 04:00.000
The data transfer we need to transfer from our application to the user is more closely.

04:00.000 --> 04:12.000
How can we manage all of this? How can we manage the applications in the cloud edge continuum?

04:12.000 --> 04:19.000
First, we need to have a set of clusters of bare metal servers.

04:19.000 --> 04:28.000
Ideally, running KVNC is the mostly popular hypervisor.

04:28.000 --> 04:39.000
Then we need a uniform management layer for handling and managing all these locations, the private cloud associated with that.

04:39.000 --> 04:45.000
Then we need to interconnect all these clusters.

04:45.000 --> 05:02.000
Finally, we need to provide a multi-tenancy environment in order to create several users and groups and isolate each environment in the cloud edge.

05:03.000 --> 05:13.000
We are going to see now an example of how a cloud edge is inside.

05:13.000 --> 05:21.000
This example is a scenario for a 5G radio.

05:21.000 --> 05:35.000
We have this cloud edge node connected to the 5G radio using an edge land and two servers.

05:35.000 --> 05:42.000
The idea of the cloud edge is only to have a small number of servers.

05:42.000 --> 05:47.000
In this case, we have two, running the KVNC hypervisor.

05:47.000 --> 05:53.000
We can run in this hypervisor any application that we want.

05:53.000 --> 06:03.000
For example, a Kubernetes cluster for handling all the 5G code and workloads.

06:03.000 --> 06:15.000
We can also use the virtual GPUs of the server if it is available for data processing.

06:15.000 --> 06:26.000
All the servers inside this node are connected to the Internet through this public network using a single VLAN.

06:26.000 --> 06:38.000
The idea of the cloud edge node is to be autonomous as possible.

06:38.000 --> 06:51.000
If the single management ledger that we are going to use is not accessible, this site can work alone and without any problem.

06:51.000 --> 06:55.000
It can still provide service to the user.

06:55.000 --> 07:09.000
Now we are going to bring these ideas to life and see how all these concepts match together in order to create our cluster.

07:09.000 --> 07:14.000
How can we deploy the cloud edge in the node?

07:14.000 --> 07:18.000
We are going to use three main technologies.

07:18.000 --> 07:20.000
The first one is OpenNevola.

07:21.000 --> 07:29.000
It is a platform for orchestrating virtual workloads.

07:29.000 --> 07:37.000
Then we are going to use Terraform to automate the resources deployment.

07:37.000 --> 07:49.000
Then we are going to use Ansible for the configuration site for installing the packages that we are going to need.

07:49.000 --> 07:56.000
We don't need to use Ansible and Terraform directly.

07:56.000 --> 08:00.000
We are going to use these technologies through the OneProvision portal.

08:00.000 --> 08:15.000
That is our OpenNevola tool that allows us to automate all the configuration of the nodes and deploy the cloud edge nodes in an instant with a few steps.

08:16.000 --> 08:32.000
OneProvision supports several providers in order to create our own cloud node on the edge like GCloud, AWS, or GAYJax.

08:32.000 --> 08:38.000
Some of them are currently in development so not all are available.

08:38.000 --> 08:45.000
We are going to use AWS for the example of the today's issue.

08:47.000 --> 08:57.000
I would like to see more closely what is OpenNevola in order to understand the environment that we are going to see in the today's demo.

08:58.000 --> 09:11.000
OpenNevola, as I already said, is a platform that allows you to orchestrate and manage all your virtual machines, application containers, or Kubernetes clusters,

09:11.000 --> 09:18.000
all of them in the same way, in a very easy daily operation.

09:19.000 --> 09:35.000
You can deploy all these applications or all these workloads using your own private cloud or expand your cloud to the public cloud or on the edge.

09:36.000 --> 09:48.000
OpenNevola has integrations with several third-party tools like Terraform, Kubernetes, Ansible, and Docker.

09:48.000 --> 10:02.000
It also has its own built-in tools like a Sunstone UI, the graphical user interface, the web portal that we are going to use to interact with OpenNevola.

10:03.000 --> 10:14.000
We can create workloads in different hypervisors like BingWare, KBM, LXD, or file crackers.

10:14.000 --> 10:22.000
You can handle in the same way a micro-BM or a virtual machine. It doesn't matter for OpenNevola.

10:23.000 --> 10:37.000
Then, we have the possibility in OpenNevola to expand our cloud to the multi-cloud or to the hybrid cloud.

10:38.000 --> 10:58.000
In the case we have, for example, our own data center and we need more resources, we can deploy any infrastructure with automatic provision using, for example, providers like GCloud, AWS, or Equinix.

10:59.000 --> 11:12.000
Then, we have a uniform management for that resources with a homogeneous layer for users on workload management.

11:12.000 --> 11:28.000
Then, deploy the infrastructure, any application that we want. For example, as I already said, we can create Kubernetes clusters or Docker or virtual machines and so on.

11:29.000 --> 11:40.000
Well, we are going to use for the deployment of our cluster, thev as a storage solution.

11:40.000 --> 11:56.000
But why thev? We are going to see thev basically because it's an easy way to distribute the storage of our cloud, of the file, of our virtual machines,

11:56.000 --> 12:04.000
and share all the storage between the cloud etching nodes in a very, very easy way.

12:04.000 --> 12:19.000
So, thev at OpenNevola has implemented the storage basis on thev that with simple configuration, you can add multiple clusters or pools to OpenNevola.

12:19.000 --> 12:38.000
This storage implements replication and consistency and some important features for thev data storage in OpenNevola are snapshots, clone operations, encryption, et cetera.

12:38.000 --> 12:52.000
Regarding thev at the edge, as I already said, we need first a small number of nodes in our cloud etch node.

12:52.000 --> 12:58.000
Thev storage is going to be dedicated to store VMs in the scheme image.

12:59.000 --> 13:12.000
It's not necessary to have high storage requirements because we can use a multiple option for the storage.

13:12.000 --> 13:15.000
It has lowest storage requirements.

13:15.000 --> 13:31.000
And this is ideal for run in a HCI configuration because we can create nodes everywhere with a reduced cost.

13:32.000 --> 13:42.000
So, thev storage in OpenNevola consists of three different types of servers.

13:42.000 --> 13:53.000
We have the full nodes that run the Thev OSD and the monitor daemons as well, the KVN hyperbysos as well.

13:54.000 --> 14:07.000
We have the OSD nodes to run the Thev OSD daemons and the hypervisor only nodes that, as the name said, only runs the hypervisor.

14:08.000 --> 14:22.000
Here we have a sample of a comparison side by side from the point of view of the Thev storage from the AWS and from OpenNevola.

14:22.000 --> 14:40.000
For AWS we need to configure first a VPC, defining the metal bar servers, all the reaching tables, all the configuration that we need for our infrastructure.

14:41.000 --> 14:59.000
And from the OpenNevola point of view we just only need to create our host and automatically associate it with the Thev storage and we can start to create workloads on that servers.

15:00.000 --> 15:08.000
So, we are going to do a little demo on how we can do this using OpenNevola.

15:08.000 --> 15:12.000
So, let me...

15:17.000 --> 15:19.000
I don't know.

15:22.000 --> 15:24.000
Displays, sorry.

15:28.000 --> 15:31.000
Okay, that's better.

15:31.000 --> 15:45.000
So, this is the OneProvision portal that we are going to use to create the cloud HNO.

15:48.000 --> 15:57.000
Here we can see a general overview of the clusters, hosts and data storage that we have already in our infrastructure.

15:58.000 --> 16:03.000
So, we are going to take a look to each section.

16:03.000 --> 16:08.000
For example, here we can see the providers that we have already configured.

16:08.000 --> 16:14.000
I have configured here the AWS provider for Frankfurt.

16:14.000 --> 16:20.000
It's the example that we are going to see here, but we can create any provider that we want.

16:21.000 --> 16:26.000
For example, AWS or Reqinys or on-prem.

16:26.000 --> 16:43.000
Here you can select the location for the provider and when you finish this process, a provider is just a set of credentials that it's going to...

16:44.000 --> 17:02.000
OneProvision, the thing that OneProvision do is use the API endpoint of each provider in order to create the host on the servers, on the provider.

17:02.000 --> 17:10.000
So, it's just a set of credentials in order to connect to that endpoint.

17:11.000 --> 17:14.000
Using Terraform.

17:14.000 --> 17:21.000
Then we have the provision that are the provision providers.

17:21.000 --> 17:28.000
Here I have already a provision created.

17:28.000 --> 17:35.000
I'm going to show you this provision as an example, but we are going to see how the process is.

17:35.000 --> 17:45.000
I've already one created because deploying a note on the edge can take around 30 minutes.

17:45.000 --> 17:53.000
So, in order to avoid that, we can see here, for example, this class already created and running.

17:53.000 --> 17:59.000
For creating a new edge note, it's very easy.

17:59.000 --> 18:03.000
We just need to click on the add button.

18:03.000 --> 18:11.000
We can see here a description or the different options that we have, the support of virtualization technologies, etc.

18:11.000 --> 18:24.000
And we can set here if we want to create a edge cluster or if we want to create a HCI cluster using the app, that's the option that we are going to use.

18:24.000 --> 18:29.000
Next, we can select the provider that we want to use.

18:29.000 --> 18:36.000
In this case, it's going to be AWS Frankfurt.

18:36.000 --> 18:41.000
General attributes like the name, the description.

18:41.000 --> 18:53.000
And here we can tune in our note, setting the number of instances.

18:53.000 --> 19:02.000
The number of instances for only hypervisors or for only the OECD, etc., the DINIAS servers.

19:02.000 --> 19:09.000
The image that we want to use in the host.

19:09.000 --> 19:19.000
All of this configuration is also accessible through Jamel files.

19:19.000 --> 19:28.000
And we can set, for example, here if we want to use virtual machines or micro-VNs using LXC, etc.

19:28.000 --> 19:32.000
I'm going to back scenes.

19:32.000 --> 19:38.000
This takes some time, but the result is this.

19:38.000 --> 19:45.000
A cluster created in the edge in a very, very easy way.

19:45.000 --> 19:50.000
So what is the result of this?

19:50.000 --> 19:55.000
We are going to see here this is the main OpenEvula dashboard.

19:55.000 --> 20:03.000
The OpenEvula system is the user interface, the web user interface.

20:03.000 --> 20:10.000
So here we can see all the virtual machines that we already have.

20:10.000 --> 20:14.000
We have some VMs already running here.

20:14.000 --> 20:29.000
If we go to the exception, we can see here three nodes deployed on the edge inside this cluster.

20:29.000 --> 20:34.000
That is the cluster that we have created using OneProvision.

20:34.000 --> 20:44.000
We can create and deploy VMs in a very easy way, downloading an appliance for the OpenEvula marketplace.

20:44.000 --> 20:55.000
So for the Docker marketplace, if we want to deploy containers in our cloud, we are going to deploy a VM as an example.

20:55.000 --> 21:00.000
So for example, we can, this one, one of the Pine Linux.

21:00.000 --> 21:14.000
We can set here, for example, for example, we can even set the host that we want to use inside the cluster.

21:14.000 --> 21:21.000
For example, we are going to use this one, but we can change any configuration of that VM.

21:21.000 --> 21:25.000
We are going to instantiate the VM.

21:25.000 --> 21:31.000
And here we can see that the VM is starting to be created.

21:31.000 --> 21:43.000
So we are going to take a few seconds since it's an edge location, but it's booting and it's running.

21:43.000 --> 21:45.000
It's totally running.

21:45.000 --> 21:51.000
We can see here the host where the VM is running, the start time.

21:51.000 --> 22:00.000
A lot of configuration regarding the VM, like capacity or other storage and so on.

22:00.000 --> 22:04.000
And we can even connect to that VM.

22:04.000 --> 22:06.000
Oops, sorry.

22:06.000 --> 22:10.000
Maybe it's not so totally ready.

22:10.000 --> 22:13.000
And this one?

22:14.000 --> 22:26.000
Okay, I think that is the, I don't know if the Wi-Fi or maybe something is blocking the connection to the VM, but believe me, it's working.

22:29.000 --> 22:31.000
It's working on my machine.

22:32.000 --> 22:38.000
But that's all regarding the demo.

22:38.000 --> 22:48.000
As you can see, it's very easy to create filter machines in Open Nebula on the, using a Cloud Edge node.

22:48.000 --> 22:55.000
So returning to the slide.

22:56.000 --> 22:58.000
Okay.

22:58.000 --> 23:03.000
Well, that's the demo environment that we show you.

23:03.000 --> 23:22.000
As final conclusion, the necessity of this project and this integration with the Open Nebula are support for them in spaces, support for incremental backup in theft, adopt theft image, live migration.

23:22.000 --> 23:33.000
We want also to improve HCI configurations and integrate the one provision tool with the one deploy project that we already have.

23:33.000 --> 23:43.000
It's another public project that you can visit on GitHub that automates all the configuration and install of Open Nebula.

23:43.000 --> 23:49.000
And you are more than welcome to contribute to the repository on GitHub.

23:49.000 --> 23:54.000
And I also encourage you to contribute to our community.

23:54.000 --> 24:08.000
Join to the forum and share your experience using Open Nebula and help other users in order to create our Cloud open source community.

24:09.000 --> 24:16.000
So this project is funded by the European Union.

24:16.000 --> 24:21.000
So it's very interesting, the project.

24:21.000 --> 24:26.000
It's Cognite, so you can visit here the URL.

24:27.000 --> 24:37.000
And it's Cognite tries to provide a cognitive serverless experience to the European Union.

24:37.000 --> 24:53.000
So we can, the idea of this project is to using Open Nebula and one provision create a lot of Cloud Edge nodes in Europe in order to deploy application and gains independence.

24:54.000 --> 25:01.000
So that's all. Thank you very much for your attention.

25:09.000 --> 25:11.000
Questions?

25:12.000 --> 25:19.000
How do you deal with network outage, especially in the Edge?

25:19.000 --> 25:21.000
Sorry, can you repeat the question?

25:21.000 --> 25:27.000
How do you deal with network outage, especially in the Edge where the connection might not be stable?

25:27.000 --> 25:34.000
How can we handle the network connection when it's not stable?

25:34.000 --> 25:46.000
The idea of the Edge nodes are that in this kind of a scenario, the node is totally independent.

25:46.000 --> 25:57.000
So it's still working even if you don't have a connection to the Internet, at least to the region.

25:57.000 --> 26:00.000
I don't know if that answered your question.

26:07.000 --> 26:09.000
Yeah?

26:09.000 --> 26:15.000
Just to understand the configuration of the nodes in this form.

26:15.000 --> 26:27.000
So from the diagram I see that you can deploy, as I said, the storage subsystem on the same nodes we are running as the virtual machine.

26:27.000 --> 26:29.000
Is that correct?

26:29.000 --> 26:34.000
But you need dedicated nodes for the storage side and the VMs.

26:35.000 --> 26:50.000
He's asking about if we can deploy in the same node the storage and the virtual machines and the other workloads.

26:50.000 --> 26:52.000
Yeah, you can deploy in the same node.

26:52.000 --> 26:57.000
From OpenEvola point of view, it's only one node.

26:58.000 --> 27:08.000
But behind it's handled in the splitting between the nodes and the hypervisual nodes.

27:08.000 --> 27:17.000
But for the user that uses OpenNegulites, the host where he can deploy VMs and use their storage.

27:20.000 --> 27:22.000
So yeah.

27:22.000 --> 27:24.000
Any more?

27:27.000 --> 27:29.000
Thank you.

