WEBVTT

00:30.000 --> 00:40.000
So, I'm going to talk about the architecture.

00:40.000 --> 00:41.000
All right.

00:41.000 --> 00:44.880
Are we ready for the next session?

00:44.880 --> 00:47.280
So my name is Wim Hendricks.

00:47.280 --> 00:48.680
I work in Nokia.

00:48.680 --> 00:52.400
I'm heading the technology and architecture.

00:52.400 --> 00:55.800
In this talk, I'm going to talk about nephew.

00:55.800 --> 01:01.480
Nephils are about thousands of sites that potentially have to be working together to

01:01.480 --> 01:05.240
actually make this service happen to all of you who are using smartphones or tablets

01:05.240 --> 01:06.240
and what have you.

01:06.240 --> 01:12.760
So that's kind of the problem space that we are trying to work upon in nephew.

01:12.760 --> 01:15.560
And so there is basically a set of issues.

01:15.560 --> 01:17.680
One is the scale.

01:17.680 --> 01:21.160
The second is the heterogeneous environments of all these network connections and making

01:21.160 --> 01:24.200
them work seamlessly together.

01:24.200 --> 01:29.240
And then, of course, we are working into an environment where there is just not one single

01:29.240 --> 01:31.280
person in an organization involved.

01:31.280 --> 01:34.760
There is multiple roles within an organization who are actually involved.

01:34.760 --> 01:37.320
So that is what we call infra people.

01:37.320 --> 01:39.640
And that is the application side of people.

01:39.640 --> 01:41.520
There will be security people and so on and so forth.

01:41.520 --> 01:46.280
So we have to deal with all the roles and responsibilities in an organization who actually

01:46.280 --> 01:52.000
take care of certain aspects of that deployment that has to happen to make this service work.

01:52.000 --> 01:53.000
All right.

01:53.000 --> 01:57.840
Moreover, what you see is that if you look to, let's say, a mobile network, right, so

01:57.840 --> 02:01.400
we are talking sometimes about terabits of capacity.

02:01.400 --> 02:05.760
So that means that we are also, me being part of a vendor, right?

02:05.760 --> 02:10.840
So we used to basically own and control every piece of that stack, right?

02:10.840 --> 02:16.240
But because we are moving into this cloud-native environment, we have now desegregated stuff,

02:16.240 --> 02:17.240
right?

02:17.240 --> 02:21.720
The problem that we also face is that we are trying to have very tight control over the

02:21.720 --> 02:27.400
infra and we want to basically work in that cloud-native space, right?

02:27.400 --> 02:29.200
So the question is, how do you do that?

02:29.200 --> 02:33.480
Because you have to basically give away some of that control to other people, right?

02:33.480 --> 02:38.120
So if you can see, we are looking at this is a quite challenging space, right?

02:38.120 --> 02:43.360
And what has happened so far in the past is that every vendor, including ourselves, we

02:43.360 --> 02:47.680
basically said, okay, we control our own pace and then we have a bit of different vendors

02:47.680 --> 02:48.800
involved.

02:48.800 --> 02:53.720
And so what you will see is that you will end up being, connecting multiple components

02:53.720 --> 02:58.200
and components and components and it's actually quite challenging to do that in a cloud-native

02:58.200 --> 02:59.200
way.

02:59.200 --> 03:01.840
So we basically said, okay, can we do better, right?

03:01.840 --> 03:08.360
And this is where Nefio was born, in a sense, because we said, okay, all of these workloads,

03:08.360 --> 03:12.880
they are moving inside of a cloud-native space, meaning they are moving into a Kubernetes

03:12.880 --> 03:14.520
environment, right?

03:14.520 --> 03:17.640
And it's nice to basically do this aggregation.

03:17.640 --> 03:19.080
We can do microservices.

03:19.080 --> 03:23.640
We can basically put all these components onto a Kubernetes environment.

03:23.640 --> 03:30.080
Why don't we leverage that same framework to basically automate and orchestrate the configuration

03:30.080 --> 03:33.640
and the setup of that whole stack, right?

03:33.640 --> 03:35.320
And that's kind of, right?

03:35.320 --> 03:37.560
Now in Nefio, we basically do two things.

03:37.560 --> 03:42.640
We basically look at, on one hand, the application itself, right, which is 5G.

03:42.640 --> 03:48.320
And then we also look at a set of primitives that are not yet available to us that we would

03:48.320 --> 03:50.280
like to have to solve this problem, right?

03:50.280 --> 03:51.920
So we basically do two things.

03:51.920 --> 03:57.720
One is we are basically defining the use case that we are using to actually figure out what

03:57.720 --> 03:59.640
are the primitives that we are missing.

03:59.640 --> 04:04.520
And then we are basically adding those missing components inside of a Kubernetes framework

04:04.520 --> 04:09.200
to be able to address those problem spaces.

04:09.200 --> 04:11.320
And as such, I mean, we leverage KRM.

04:11.320 --> 04:16.720
So I haven't asked, so Kubernetes is probably a lot of people familiar with that.

04:16.720 --> 04:20.280
If you want to show hands, Kubernetes, I think we should be fairly familiar.

04:20.280 --> 04:21.960
Okay, pretty good.

04:21.960 --> 04:25.320
So we leverage, so you are familiar with the term of KRM, right?

04:25.320 --> 04:30.240
So KRM is the Kubernetes resource model, and we leverage that all the way, right?

04:30.240 --> 04:33.680
So that means we have a clearly defined API.

04:33.680 --> 04:36.280
We have the set of metadata.

04:36.280 --> 04:42.880
We leverage the desired versus observed state to basically figure out a declarative base

04:42.880 --> 04:44.200
of operation.

04:44.200 --> 04:47.240
We leverage the event-driven ecosystem and stuff like that.

04:47.240 --> 04:50.040
So we leverage that to the full extent.

04:50.040 --> 04:56.400
Now what we have seen in order to solve that problem at scale, we were missing a few primitives,

04:56.400 --> 04:57.400
right?

04:57.400 --> 05:02.920
And one of those primitives that we have been added to the component is what we call configuration

05:02.920 --> 05:04.840
as data, right?

05:04.840 --> 05:10.640
Because if you look to how Kubernetes works as its basis, you actually have a CRD or a

05:10.640 --> 05:15.320
Kubernetes resource that is basically triggering something, right?

05:15.320 --> 05:22.040
Now because we are dealing with this massively complex environment, right, we said, okay,

05:22.040 --> 05:24.640
a single unit is probably not sufficient for us.

05:24.640 --> 05:27.440
So we defined the concept of a package, right?

05:27.440 --> 05:33.440
So rather than having a single CRD, we actually built a package, and a package is a collection

05:33.440 --> 05:39.760
of KRM resources that you are going to use as a kind of what we call a blueprint or a

05:39.760 --> 05:41.080
service catalog, right?

05:41.080 --> 05:46.880
So it's basically think of it as a collection of KRM resources that do things together,

05:46.880 --> 05:48.160
right?

05:48.160 --> 05:52.680
The second thing that we did is today in order to use Kubernetes, you typically have to build

05:52.680 --> 05:55.600
a controller in code and stuff like that, right?

05:55.600 --> 05:58.640
So we added the capability better.

05:58.640 --> 06:03.800
You basically say I want to create a deployment and then there will be a replica set controller

06:03.800 --> 06:07.760
which basically says, okay, I'm going to select this node and I'm going to scale this out

06:07.760 --> 06:12.680
and I'm going to deploy a set of POTS over a number of resources, right?

06:12.680 --> 06:17.600
That's what typically happens today inside of Kubernetes and you have different methods

06:17.600 --> 06:18.600
to do so.

06:18.600 --> 06:22.040
You have deployment, you have replica sets and so on and so forth, or stateful sets,

06:22.040 --> 06:25.800
and you pick and choose the one that's familiar with you.

06:25.800 --> 06:32.320
Even that we work above a cluster level, what we do in nephew, we call it a term, what

06:32.320 --> 06:37.960
we call a package variant or a package variant set which basically says I want to have my

06:37.960 --> 06:44.160
package which I was talking about and I want to deploy that on these sites, right?

06:44.160 --> 06:49.680
And each of these sites will then be what we call specialized within their own context

06:49.680 --> 06:53.760
where the relative parameters, for example, this site needs this VLAN, this site needs

06:53.760 --> 06:57.400
this IP address, this size needs these PLM and ID's and stuff like that.

06:57.400 --> 07:02.080
So they will be specialized based on their specific context on where they get deployed

07:02.080 --> 07:07.040
and as a result, that's then being deployed on that particular cluster, right?

07:07.040 --> 07:11.960
So you see that if you look to the analogy of Kubernetes, we are working at the level,

07:11.960 --> 07:16.320
at the cluster level versus where as Kubernetes works at the node level scheduling type of

07:16.320 --> 07:17.320
level.

07:17.320 --> 07:21.840
So we work a level above but you see a lot of concepts that were born or that were basically

07:21.840 --> 07:23.880
derived from Kubernetes.

07:23.880 --> 07:28.320
We are leveraging within the framework that we are deploying within nephew in order to

07:28.320 --> 07:35.040
stay as close as possible to it so that we can leverage the benefits of that whole ecosystem.

07:35.040 --> 07:38.720
Now to put that into perspective, I try to explain that a little bit.

07:38.720 --> 07:41.000
So we have a concept of management clusters.

07:41.000 --> 07:46.520
So this is a regular Kubernetes cluster but we use it typically for our control engines,

07:46.520 --> 07:47.520
right?

07:47.520 --> 07:52.880
This is where our, what we call the configuration as data server which is ported in our implementation

07:52.880 --> 08:01.680
is used upon and then we schedule work, network functions onto those specific workloads, right?

08:01.680 --> 08:06.400
And how we do that is we basically have this concept of a package on the right hand side

08:06.400 --> 08:07.640
which is our blueprint.

08:07.640 --> 08:13.840
So think about someone as a vendor or as an operator, someone basically put that together,

08:13.840 --> 08:14.840
right?

08:14.840 --> 08:19.160
So we have the KRM resources that are needed for that particular environment and then we

08:19.160 --> 08:22.280
say, okay, I want to deploy that on 10,000 sites, right?

08:22.280 --> 08:28.760
When we do this, when we try to make variations of that package for a particular context,

08:28.760 --> 08:31.840
we also said, okay, let's divide and conquer, right?

08:31.840 --> 08:37.120
So because you could basically build a pipeline that is very narrow and very strict, right?

08:37.120 --> 08:39.960
But typically what we see is that you need flexibility, right?

08:39.960 --> 08:42.200
So you want to have a flexible system.

08:42.200 --> 08:47.280
And so we developed a concept, what we call the conditional dance of the choreography which

08:47.280 --> 08:54.560
is a set of primitives, I think of functions here that each do a specific thing.

08:54.560 --> 08:59.680
So for example, IP address, VLANs and so on and so forth.

08:59.680 --> 09:04.960
And each of them basically make sure that if those things are needed, they are basically

09:04.960 --> 09:11.400
being called upon and specialized those packages with a specific context for that type of environment.

09:11.400 --> 09:16.480
And that's how we can make this work in a very scalable and flexible and pluggable play

09:16.480 --> 09:21.760
and it's easily to extend that within a specific environment.

09:21.760 --> 09:24.440
So what did we do so far within Nefuse?

09:24.440 --> 09:27.080
We are a very early pro yet.

09:27.080 --> 09:31.960
So and it would be good if people would like to join us.

09:31.960 --> 09:37.120
So we have done, so we are just about to release release two, right?

09:37.120 --> 09:43.240
So what we have shown so far is basically the concept that I showed in the beginning.

09:43.240 --> 09:45.640
We have basically proven that with Free5GC.

09:45.640 --> 09:52.240
So Free5GC is an open source project that basically deploys the core side of a 5G type

09:52.240 --> 09:53.240
of network.

09:53.240 --> 09:58.640
So we have basically proven that we can use the machinery to actually deploy and show

09:58.640 --> 10:03.800
what I'm presenting here in the slides is actually working up to setting up a call, right?

10:03.800 --> 10:07.680
So we are using the whole network setup that actually connects all of these functions together.

10:07.680 --> 10:10.680
So all of that using the primitives that I was showing.

10:10.680 --> 10:15.000
And in release two we added OII which is another open source project mainly focused on the

10:15.000 --> 10:20.080
radio but also as the core so that we prove that we can do this not across one vendor

10:20.080 --> 10:22.640
but across multiple vendors, right?

10:22.640 --> 10:27.920
And so we are extending this whole framework with more primitives as we go along.

10:27.920 --> 10:32.000
As I said, we are a very young project, right?

10:32.000 --> 10:33.880
And so we seek for a lot of help.

10:33.880 --> 10:37.400
So if you are interested to join us, we would welcome.

10:37.400 --> 10:42.160
So please contact me or please look at one of those resources that are available here

10:42.160 --> 10:47.880
because this is all the information which you can have a look at to the operation.

10:47.880 --> 10:53.120
And what you see is that you can actually move rather more quickly than in an on-up

10:53.120 --> 10:56.960
type of approach but we are actually trying to solve a different level.

10:56.960 --> 11:02.240
So what we call the domain level whereas on-up is working at the orchestration level.

11:02.240 --> 11:03.240
Okay.

11:03.240 --> 11:11.920
And so is the same if we say the advantage of NetEar over VMware, orchestrator or other

11:11.920 --> 11:12.920
vendors?

11:12.920 --> 11:13.920
Yeah.

11:13.920 --> 11:20.680
So I think, see, okay, I'm of course trying to advocate it but personally I see the following.

11:20.680 --> 11:24.040
Kubernetes has been the orchestration for containers, right?

11:24.040 --> 11:26.040
That was where it is born.

11:26.040 --> 11:32.000
If you ask me, it has the right primitives to be an automation and orchestration platform

11:32.000 --> 11:33.480
for anything.

11:33.480 --> 11:38.880
So I see Kubernetes as an operating system to actually do any automation, right?

11:38.880 --> 11:40.640
That doesn't mean.

11:40.640 --> 11:46.960
And what is the advantage of that in my view is that, so when you have all of these different

11:46.960 --> 11:51.480
components, first of all, you have a huge ecosystem in open source that is developing

11:51.480 --> 11:54.400
and extending Kubernetes for lots of use cases, right?

11:54.400 --> 12:00.480
So you can deploy AWS resources, Google resources, you can deploy clusters, you can set up servers.

12:00.480 --> 12:05.040
So you first leverage a huge ecosystem that is being developed in open source which we

12:05.040 --> 12:09.080
should all love in this room, right?

12:09.080 --> 12:16.080
Secondly, that doesn't mean that you can as a vendor not benefit or do things specifically

12:16.080 --> 12:21.600
but the big advantage for you as a consumer when we do that is today when you do VMware

12:21.600 --> 12:27.400
orchestration, you build your own VMware orchestration server with your own database

12:27.400 --> 12:31.080
with your own and then you see it's not only VMware orchestration, you need a bit of this

12:31.080 --> 12:34.920
component and a bit of that component and a bit of this component and all of a sudden

12:34.920 --> 12:39.120
you have more servers to serve the network than actually the network.

12:39.120 --> 12:40.440
I'm exaggerating, right?

12:40.440 --> 12:46.840
But the advantage what I see personally is that you look at automation from these, the

12:46.840 --> 12:52.600
use case still will be specific to you and there will be a VMware specific controller,

12:52.600 --> 12:53.600
right?

12:53.600 --> 12:59.040
But if you build it on the same platform, you as a consumer, we benefit from not having

12:59.040 --> 13:03.680
to deploy another platform but leverage what we already have if that suits you.

13:03.680 --> 13:07.640
That doesn't mean you cannot deploy another Kubernetes instance for that specific environment,

13:07.640 --> 13:08.640
right?

13:08.640 --> 13:09.800
But at least the integration.

