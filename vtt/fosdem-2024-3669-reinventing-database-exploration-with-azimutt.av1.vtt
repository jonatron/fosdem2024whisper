WEBVTT

00:00.000 --> 00:07.000
Welcome everybody, let's get started on the next session.

00:07.000 --> 00:17.000
My name is David and it is my pleasure to introduce Loïc Nuchel, who will be speaking on reinventing database exploration with Azamut.

00:17.000 --> 00:25.000
Thanks a lot.

00:25.000 --> 00:29.000
Hi everyone, thanks a lot for coming to my talk.

00:29.000 --> 00:34.000
Indeed, I will talk about Azamut and how we can explore the database with it.

00:34.000 --> 00:38.000
My name is Loïc Nuchel and I am principal engineer at Dr.Libb.

00:38.000 --> 00:46.000
Basically, the whole talk is a story about how I started at Dr.Libb and now I am here talking to you about Azamut.

00:46.000 --> 00:48.000
Three years ago, I started at Dr.Libb.

00:48.000 --> 00:58.000
I joined the company so if you don't know Dr.Libb, it is a French company in healthcare, allowing patients to book appointments with doctors.

00:58.000 --> 01:05.000
Basically, it is built on big monoliths, on rubric and rails backed by PostgreSQL database.

01:05.000 --> 01:16.000
Basically, it is a huge monorepo and also a huge database with 800 tables inside and several petabytes of data.

01:17.000 --> 01:25.000
As an architect, I joined Dr.Libb to work with the team and help with architecture, improve the code and things like that.

01:25.000 --> 01:33.000
But also, for that, I have to understand what is inside the database, what are the models and what are the relations.

01:33.000 --> 01:38.000
The thing with rubric and rails is you don't define the properties inside the models.

01:38.000 --> 01:43.000
You just define the relations, but often the models are quite long.

01:43.000 --> 01:51.000
They can do like 1,000 lines long and sometimes the relation is as far as 100 lines or something like that.

01:51.000 --> 02:00.000
That is not really convenient and I had to look inside the database a lot to understand what are the things and how it works.

02:00.000 --> 02:08.000
Basically, that is me working at Dr.Libb for the first month and obviously, this is not very friendly.

02:08.000 --> 02:09.000
I had to find a tool.

02:09.000 --> 02:11.000
I looked for a lot of tools.

02:11.000 --> 02:18.000
They are called ERD, and they show tables with relation and nodes.

02:18.000 --> 02:21.000
As you can see, this is not very friendly.

02:21.000 --> 02:23.000
Here is the 10 tables.

02:23.000 --> 02:27.000
Imagine 800 and you will have some trouble.

02:27.000 --> 02:32.000
I tried quite a bunch just for you to have a look at what they look like.

02:32.000 --> 02:35.000
Basically, the NWAS NAP failed.

02:35.000 --> 02:37.000
For a few reasons.

02:37.000 --> 02:43.000
The first one and most of you find is all of the tools I could find will show everything.

02:43.000 --> 02:48.000
When you show 800 tables, you don't understand anything.

02:48.000 --> 02:53.000
The second one is most of them don't have an SQL or database import.

02:53.000 --> 02:57.000
The last one is they are not private.

02:57.000 --> 03:05.000
Basically, I had to upload the schema to the service and I don't want that for Dr.Libb.

03:05.000 --> 03:11.000
Basically, when we are a developer and we are in this situation, we do another tool.

03:11.000 --> 03:21.000
That's what I did with the big one goal to make it easy for large database like 800 tables again.

03:21.000 --> 03:28.000
You may see tables with a lot of columns like 100 or something like that sometimes.

03:28.000 --> 03:35.000
Locally, this is not for us, but this is a possibility to stay local and just have it in your browser.

03:35.000 --> 03:41.000
Not send any data to the service and of course open source.

03:41.000 --> 03:45.000
The first part was the schema exploration.

03:45.000 --> 03:50.000
When you load your schema into azimuth, you don't see anything.

03:50.000 --> 03:55.000
You just see a search bar and an empty screen with some situation.

03:55.000 --> 04:02.000
The goal is to look for tables with the search and just load the table you are entered in.

04:02.000 --> 04:07.000
Mostly, if you are working with a big database, you don't want to see everything.

04:07.000 --> 04:13.000
You just want to see one, ten tables around your scale, your feature or something like that.

04:13.000 --> 04:21.000
You can do some nice diagram like this with choosing the table and the column you want to show.

04:21.000 --> 04:25.000
Also, you can navigate from one table to another following the relation.

04:25.000 --> 04:34.000
Obviously, the foreign key with outgoing relation, but also the incoming relation coming from the primary key from the other relation.

04:34.000 --> 04:40.000
That's pretty nice to expand your diagram and explore what's around.

04:40.000 --> 04:46.000
Of course, you don't see everything. You want many layouts.

04:46.000 --> 04:56.000
One per scope, discovery, team or anything you want, but several layouts of your database to understand it.

04:56.000 --> 05:01.000
The last thing is sometimes in the database, you don't have foreign key for all the relation.

05:01.000 --> 05:05.000
Sometimes for performance reasons, sometimes for reliability.

05:05.000 --> 05:10.000
There are a lot of ideas around there, but sometimes you don't have the relation as foreign key.

05:10.000 --> 05:15.000
So, azimuth can infer and suggest them directly inside the diagram.

05:15.000 --> 05:19.000
The last feature on the stream exploration is a fine pass.

05:19.000 --> 05:27.000
If you want to join data from one table to another and you don't know really all the tables in between, it will be a good one.

05:27.000 --> 05:33.000
Basically, when developing this feature, I was very surprised about how many paths there are.

05:33.000 --> 05:35.000
You will be surprised too.

05:35.000 --> 05:40.000
Basically, that's also a good idea to have a look at that.

05:40.000 --> 05:47.000
The second thing is when people are starting using that, like on read-only on the database schema,

05:47.000 --> 05:50.000
they wanted to draft new features on it.

05:50.000 --> 05:54.000
Basically, doing some more design for the database.

05:54.000 --> 06:01.000
I made a DSL with an explicit goal to be very simple.

06:01.000 --> 06:08.000
Here is a bigger version if you want to read, to just write the table name and the column name with two space before.

06:08.000 --> 06:17.000
Then you can add some attributes like the types and some primariki, unique index, new label and things like that.

06:17.000 --> 06:28.000
The goal of this DSL is to be very simple, very quick to write, to go as fast as you and you can flow and your figure can type.

06:28.000 --> 06:35.000
When you do this kind of exploration, sometimes you have some discovery and sometimes you want to write them somewhere,

06:35.000 --> 06:41.000
maybe for your colleague but also for your future self, again the exploration.

06:41.000 --> 06:43.000
There is a lot of documentation.

06:43.000 --> 06:49.000
Of course, the SQL command from the table, so it's loaded and accessible into azimuth.

06:49.000 --> 06:59.000
Also, the nut into the table, this is the same thing as the SQL command but inside azimuth you can edit and view it easily.

06:59.000 --> 07:05.000
There is some tag also to find type easily and of course there is the same thing for the columns.

07:05.000 --> 07:08.000
So the SQL command, some nut you can add.

07:08.000 --> 07:16.000
The nut are in markdown so you can do the formatting with images if you want, links, lists and things like that.

07:16.000 --> 07:24.000
On the layout, you have one layout for what you want and you can document them with some memo inside.

07:24.000 --> 07:33.000
Same with markdown, you can put image, link, whatever you want to explain the whole schema, some part of the schema, you can have the color behind.

07:33.000 --> 07:41.000
You can also have table groups to show that tables are in the same position or in the same context.

07:41.000 --> 07:45.000
That's how you can do the documentation for azimuth.

07:45.000 --> 07:50.000
The last part I did not long ago is the data exploration.

07:50.000 --> 08:04.000
Basically, before we were only on the structure, on the database model, but sometimes you want to go a bit deeper and understand the data inside the database and how it's working, what you can do.

08:04.000 --> 08:06.000
I think this is quite interesting.

08:06.000 --> 08:15.000
When you open the detailed sidebar for the table, you have all the details but also you have all the columns with the sample of the data inside.

08:15.000 --> 08:22.000
This is random picked data, not just a row with everything but I avoid nulls and things like that.

08:22.000 --> 08:25.000
You have interesting data to show here.

08:25.000 --> 08:35.000
The same for a column, when you open the sidebar for a column, you have the most used value, the count of rows, the cardinalities, the number of nulls and things like that to know a bit.

08:35.000 --> 08:39.000
What is inside this specific row?

08:39.000 --> 08:44.000
That's for the quick access but you can also do some full query from it.

08:44.000 --> 08:53.000
We have a visual editor for very simple query, like a table with some filter, but also you can write any query you want to have the result.

08:53.000 --> 09:04.000
Basically, you have all the results on the right in a list so you can see different results and have some nice features to filter, to sort and things like that.

09:04.000 --> 09:10.000
The most interesting one is this small arrow here.

09:10.000 --> 09:14.000
You can click on it and see the relative row on this part.

09:14.000 --> 09:24.000
Here, I selected all the events, like on the CFP database, we have the event but they are linked to a group here.

09:24.000 --> 09:32.000
You can see in one click that it's the human talkspire group which is the link row on this event.

09:32.000 --> 09:46.000
This also works in a nested way so if you scroll down and see other relations in this sidebar, you can have multiple sidebars that are stacking to navigate from one row to another.

09:46.000 --> 09:59.000
Basically, this was quite interesting but the very nice thing here is you can add this specific row, so one row and data from a table into the diagram.

09:59.000 --> 10:13.000
You can add to the layout and see this row specifically so this is not a table anymore, this is a row of data with of course the table name and the table column, but also with specific data for a specific row.

10:13.000 --> 10:17.000
You can refresh the query again but with all the data.

10:17.000 --> 10:24.000
Same as the layout, you can navigate through the row inside the data.

10:24.000 --> 10:42.000
If you click on the primary queue again, you will have all the linked tables and for the table, all the linked rows, with a maximum of 20, because sometimes it can be very expensive, for example, event or if you have some tracking things, you can have thousands of them.

10:42.000 --> 10:51.000
Basically, you can see easily what are the linked row, what are the incoming links to this specific row and not just the table in the schema.

10:51.000 --> 10:56.000
And then if you click of course on a specific one, you can show it.

10:56.000 --> 11:07.000
And the same is for foreign key, so if you click on an outgoing relation, you can just show the relation with it.

11:07.000 --> 11:22.000
This allows to do some nice diagram with not only the table in the schema but also actual data from your database that sometimes is interesting to show that you have several rows in the same table like here.

11:22.000 --> 11:32.000
And of course you can mix both having on your layout, having your schema, so the table above and the table below.

11:32.000 --> 11:44.000
So this is very small, it's not intended to read, but on the right you can see there is several times the same different row on the same table, on a clear blue.

11:44.000 --> 11:50.000
So I think that's a very interesting way to navigate into the data.

11:50.000 --> 12:06.000
So if you want to try it out, so it's available on azimuth.app, but there is also a nice CLI to load any database almost here, so you can just do NPX azimuth explore and then your database URL.

12:06.000 --> 12:18.000
It can be of course a remote URL but also a local one, you will start to get away on your machine which is just a node server to proxy the query to your database.

12:18.000 --> 12:25.000
So it also works with local database which is like I think the one of the only tools that I can do that.

12:25.000 --> 12:43.000
So thanks a lot, you can try it on azimuth.app, it currently works with several database, so major relational database but also some document database.

12:43.000 --> 13:02.000
And basically for relational database when you have a json field, a json column, it inspects the json column selecting 100 non-empty row and infers the schema from it so you see directly the schema of your json column inside azimuth.

13:02.000 --> 13:28.000
So this project is fully open source, I've been working on it for a bit more than two years and basically I intend to develop it a lot more in 2024, so if you are interested with it, there is a survey with a QR code and I will be happy to have your feedback on what you thought about what I presented but also what are your current problems about the database,

13:28.000 --> 13:35.000
what you expect to see from a tool helping you interact with the database and so on.

13:35.000 --> 13:45.000
Thank you all, there is still two minutes so maybe I can run one or two questions.

13:45.000 --> 13:51.000
Is there any supplementation when you explore a state or really state database?

13:52.000 --> 14:11.000
Yeah, there is several things, so it's made for big database, so basically the table is 100 tables and the biggest schema I think is 1000 tables, 1,500 tables, so there is no issue extracting the schema.

14:12.000 --> 14:17.000
There is more issue and basically that thing I will address soon.

14:17.000 --> 14:38.000
When you explore that, basically if you have a lot of data inside your database, the quick show of the value into the table and the column can be quite hard to get, but after that you just run some queries.

14:38.000 --> 14:47.000
So you will have performance issue if you do queries that take a lot of data but the queries run on your database are not linked to azimuth.

