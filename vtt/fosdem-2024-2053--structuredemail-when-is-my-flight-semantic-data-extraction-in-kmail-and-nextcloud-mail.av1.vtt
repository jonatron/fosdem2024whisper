WEBVTT

00:00.000 --> 00:13.680
Okay. Okay. So, yeah, then we'll continue basically right where Hansjord left off.

00:13.680 --> 00:22.200
I'm Volker from KDE and I'll talk about how we do the semantic extraction in K-mail and

00:23.000 --> 00:34.160
specifically focusing on the travel use case. Many of you probably traveled here, so you might see

00:34.160 --> 00:40.200
why this could be useful. So, if you book your flight or your train or your hotel, you get the

00:40.200 --> 00:46.440
confirmation as an HTML monstrosity full of advertisements and fine print and somewhere in

00:46.440 --> 00:51.800
between is the information that you actually care about. So, you need to find that and transfer it

00:51.800 --> 00:57.320
into like your calendar or your travel app and that if you do it manually, right, there's tedious

00:57.320 --> 01:04.720
and error prone. So, why can't we have that automatically? And that's basically the point

01:04.720 --> 01:10.960
that got me into that topic. I was on the way home from a conference needed to find my departure

01:10.960 --> 01:17.800
gate and I was written in like light gray on white in that style. So, I did what you would do in

01:17.800 --> 01:23.280
that case like you read the email source code because that's easier to read and I stumbled

01:23.280 --> 01:29.400
about a nice compact summary of the trip and that was the schema.org Jason that Hansjord

01:29.400 --> 01:38.000
mentioned. So, just showing that in our email client right that should be easy. Six and a half years

01:38.000 --> 01:46.400
later, I'm not standing here and still talking about that subject, so as things usually go. So,

01:47.000 --> 01:55.320
Hansjord showed us already, right, it's the schema.org Jason that is something that I think

01:55.320 --> 02:02.160
Google proposed 10 or 15 years ago for websites and for HTML email. Meanwhile, managed by the W3C,

02:02.160 --> 02:08.720
so it's a proper open standard. As an ontology that tries to model the complexities of the real

02:08.720 --> 02:15.320
world, right, it has all the fun involved with that. But generally that is sane and something we

02:15.360 --> 02:28.480
can work with. Then, however, we got in touch with the harsh realities out there because there's not

02:28.480 --> 02:35.000
just that nice Jason format, there is also commonly used a micro data representation that basically

02:35.040 --> 02:45.280
embeds that tree of information in the HTML structure of the HTML email. Technically,

02:45.280 --> 02:51.520
that's possible and still well defined, but it then basically puts HTML parsing into your

02:51.520 --> 02:56.400
problem space with all the fun that that entails. Well, okay, so we implemented that as well.

02:56.400 --> 03:03.760
Then we discovered a third variant of encoding that information, basically syntactically

03:03.800 --> 03:10.000
invalid Jason. Comalist Jason is particularly popular, so we ended up adding workarounds for

03:10.000 --> 03:16.560
the Jason parser to deal with all of that. Then we found the actually much bigger problem and

03:16.560 --> 03:23.680
that is semantically incorrect data. I think the most extreme case was Air Berlin. They had the

03:23.680 --> 03:29.400
arrival and departure times for flights in the local time zone of the airports, as you would

03:29.440 --> 03:35.080
usually do it. But then they added the UTC offset of what is presumably their server location.

03:35.080 --> 03:41.000
So if you travel to the US, eight hour difference, you probably noticed that something is wrong.

03:41.000 --> 03:46.120
If you travel from here to Finland, a subtle one hour difference, super dangerous,

03:46.120 --> 03:52.080
you're under risk of missing your flight. Another common problem, there's an address and there's

03:52.120 --> 03:59.640
a geo-coordinate. They mismatch and not just by a few meters. We have to deal with that as well.

03:59.640 --> 04:06.760
Then of course the other big problem, this is by far not as widely used as we would wish.

04:06.760 --> 04:13.480
You find it with some airlines, some of the hotel and event booking platforms have it.

04:13.480 --> 04:19.800
It's super rare for trains. I think in Europe it's only a train line. In general, on a scale from

04:20.040 --> 04:26.320
Silicon Valley startup to 100 plus year old European national railway, it's clearly biased

04:26.320 --> 04:31.320
towards the former. It seems to be even less common in Asia than in Europe.

04:31.320 --> 04:40.520
That isn't really satisfying, but at that point we were hooked and we really wanted those features.

04:40.520 --> 04:48.920
We started to look where else we could get them from. There's actually a lot of stuff that we

04:48.960 --> 04:56.680
can extract data from in such emails. One particularly useful thing are flight and train ticket barcodes,

04:56.680 --> 05:02.520
which then moves PDF parsing and image processing in our problem space. It gets worse.

05:02.520 --> 05:10.040
That thing is an entire world on its own. I spoke a bit about that last year in the

05:10.040 --> 05:18.400
railways and open transport deff room. I tried to skip that here. Another thing commonly found

05:18.560 --> 05:25.440
on booking emails is Apple wallet parsers that zip files containing JSON. Parts of it is machine

05:25.440 --> 05:31.360
readable. Parts of it is visual representation, but at least for location and time in the barcode.

05:31.360 --> 05:36.880
That's a good starting point. Then of course there is the whole unstructured human readable part.

05:36.880 --> 05:46.040
For some of that we were able to build generic extractors. Something like an airline boarding

05:46.040 --> 05:51.960
pass. They might look very different from a visual and layout point of view, but they can all be

05:51.960 --> 05:59.080
very reliably identified using the barcode. The barcode only contains very basic information,

05:59.080 --> 06:04.120
like the day of travel, not the year or the time, and only the airport codes, but not the gate,

06:04.120 --> 06:10.280
and so on. All of that information that is really relevant for you is in that human readable text

06:10.280 --> 06:18.520
somewhere. It's possible to identify that and match it. For everything else we have

06:20.360 --> 06:23.640
provider specific extractor script. That's usually a few lines of

06:24.680 --> 06:32.280
JavaScript with regular expressions or X pass queries on the HTML. Not pretty, but it gets the

06:32.280 --> 06:41.480
job done. With all of those ways of getting data out, we still have the problem that the data

06:41.480 --> 06:49.400
quality isn't really on a level that we can work with. In particular we care about the very

06:49.400 --> 06:56.600
exact time, including the time zone. By time zone I really mean IA and A time zone ID, not UTC offset,

06:57.240 --> 07:01.560
because if you have a delay over a day-life saving time change, and yes that does happen,

07:02.200 --> 07:06.360
then you really need the exact time zone to know when your new departure time is.

07:07.640 --> 07:13.080
And the other aspect that is really important is the precise location. So as a geocoordinate,

07:13.800 --> 07:18.120
that in turn also helps with determining the time zone, but we want to have features like

07:18.120 --> 07:26.520
routing to your departure location or your hotel. And in order to improve on the input data,

07:27.800 --> 07:33.960
we use some external data sources like OpenStreetMap or VickyData to resolve airport or train

07:33.960 --> 07:42.520
station identifiers and get to the exact location. And we have a few things that apply domain knowledge.

07:42.600 --> 07:47.000
For example, if you email, we first to a flight from Brussels to Stuttgart,

07:47.000 --> 07:52.360
and mentions a flight time of about an hour. There's two airports with Brussels in the name.

07:53.000 --> 07:57.720
They are both close to, or at least both of them are in Belgium, so we know the country

07:57.720 --> 08:03.080
and time zone. There's also two airports with the name Stuttgart. One is in southern Germany,

08:03.080 --> 08:08.920
the other one is somewhere in the US. But based on the flight time, we know exactly which one of that

08:08.920 --> 08:14.120
is possible, right? And I may have uniquely identified the other airport and so on and so on.

08:15.560 --> 08:20.200
And then in the end, we have some validation and plausibility checks because they're still

08:20.200 --> 08:26.600
either incomplete or nonsense coming through, right? So if you would require time travel to

08:26.600 --> 08:35.400
make that trip, then it's likely wrong somehow. And that's then how it looks like in the integration.

08:35.400 --> 08:43.720
So we run the current email through the extractor. If it finds something, it shows a summary of that

08:43.720 --> 08:49.800
and offers you to add that to your calendar or to your travel app on the phone. This is in KML.

08:50.440 --> 08:56.360
Originally, the extractor started as a library for KML, but it's also available as a standalone

08:56.360 --> 09:01.640
command line tool by now. That's how we did the integration in NextCloud. Same thing, right? We

09:01.640 --> 09:07.480
showed a summary of what we found and you can add that to your calendar. There used to be a

09:07.480 --> 09:12.760
Thunderbird plugin, but Thunderbird changed the integration API and since then that stalled a

09:12.760 --> 09:17.480
bit. There's a lot of demand for that, so it would be nice to redirect that at some point.

09:18.840 --> 09:23.400
And then there's of course the dedicated travel app, it's a memory that we built out of all of this

09:24.200 --> 09:28.920
that Hans-Jörg had already mentioned, where you get a timeline of your trip and it then

09:28.920 --> 09:33.240
fills the gaps with local public transport and looks for the weather forecast and reminds you

09:33.240 --> 09:37.000
to bring a power plug converter if you're traveling to a country where you need that.

09:38.440 --> 09:44.760
And I mean, that is exactly the kind of high-level semantic features and workflows that we can

09:44.760 --> 09:50.040
build if we actually understand what you're dealing with in your emails or in your documents.

09:51.480 --> 09:57.080
So if you produce any kind of transactional email, you most likely have a machine-needable

09:57.160 --> 10:03.800
representation of what this is about, so please add that also to the email in some form, ideally in

10:04.360 --> 10:09.800
the format Hans-Jörg is working on, but as you have seen, we are not particularly picky in

10:11.240 --> 10:17.000
extracting, right? So anything that isn't regular expressions on human readable text would be

10:17.640 --> 10:25.080
a big help already. And then finally, I haven't mentioned that yet, all of that of course runs

10:25.080 --> 10:30.440
on your device, right? Unlike Google, Apple or TripIt, we don't read your email for this.

10:32.440 --> 10:37.240
That on the other hand means we have not as many training samples as they have,

10:37.880 --> 10:45.000
so we entirely rely on people donating us travel-related emails in some form, so

10:46.280 --> 10:50.600
that is one way to help. Yeah, and that's it. Thank you.

10:51.560 --> 10:55.560
Thank you.

10:57.800 --> 11:01.480
All right, again, we have our number one question to ask today.

11:05.160 --> 11:09.000
Do you have any statistics on signal to noise ratio? Essentially,

11:10.600 --> 11:17.880
how many times is the information wrong? Do you kind of any reviews or testing in terms of like,

11:18.600 --> 11:22.920
you say that incorrect information is better than no information, but does it ever get

11:22.920 --> 11:31.320
confusing to a user, for example? I mean, we try very, very hard to detect stuff that is not plausible

11:31.320 --> 11:41.880
or to fit out anything that we at least can detect. How much gets through that is not detectable and

11:41.880 --> 11:51.320
then confusing. I don't actually know because the samples we have work or are filtered out,

11:52.600 --> 11:58.280
but at least we don't get a lot of bug reports with I missed my flight because it showed something

11:58.280 --> 12:05.160
wrong, and usually it is individual providers and they are consistently wrong, so we can add

12:05.160 --> 12:11.160
workarounds for that to filter them out and not show anything for them, for example. But there is

12:11.240 --> 12:15.960
the risk for providers that we don't know. If they send out something that we can't detect,

12:17.080 --> 12:21.080
we might show you a wrong departure time, right? And that is a problem.

12:30.040 --> 12:37.000
But you could, I know you could not log, instead of not showing the possibly wrong information,

12:37.080 --> 12:41.560
you could not log it somewhere and then to make those statistics.

12:43.320 --> 12:47.320
I mean, log in the way that we get the information. Yeah, because it's not a website.

12:47.880 --> 12:50.920
That would go against the whole privacy idea that we are very...

12:50.920 --> 12:54.760
But if, I don't know, if user agree to send those kind of...

12:55.720 --> 13:03.000
We don't have like a data donation feature built into the app right now. That might be an interesting

13:03.000 --> 13:09.160
option. But some people send this to us then manually, basically. Yeah.

13:09.160 --> 13:13.480
I might, before I give some mic to Arndt, I might just comment on that because we talked already

13:13.480 --> 13:17.640
also at Mark to people and there is a lot of the email senders, right? So, and in general,

13:17.640 --> 13:22.280
there is some interest by them to support this in a way. So, I have a strong assumption, like,

13:22.280 --> 13:26.600
if there is such faulty data, there might be ways to incentivize at least the big senders,

13:26.600 --> 13:30.360
the big brands to do it right. So, I'm not so concerned about that.

13:33.000 --> 13:35.480
Yeah.

13:39.080 --> 13:46.280
Asking people to send bug reports is okay, but if you ever get a mail client to send something

13:47.320 --> 13:52.920
to you, to log it, you're going to get information about people's sex life.

13:52.920 --> 13:55.320
No matter what you try to get, you're going to get that.

13:55.400 --> 14:04.600
It just happens, trust me. And then you have GDPR problems because, well, you thought it was

14:04.600 --> 14:09.640
the name of an airline, but it actually was the name of a person. Yeah, I mean, that is,

14:10.600 --> 14:15.240
I mean, that's one of the motivation why we are so focused on doing this locally and

14:15.240 --> 14:21.160
with keeping control over this. Because, I mean, your personal travel is already quite sensitive.

14:21.240 --> 14:24.920
But if you combine that with everybody else, the amount of patterns you see,

14:25.640 --> 14:31.800
right, I mean, all of us travel to Brussels in the first weekend in February. If that happens once,

14:31.800 --> 14:37.880
right, that could be by chance. But if it happens in the next year as well, and after two or three

14:37.880 --> 14:42.680
times, that is not random, right? Then there is some relation between the people involved.

14:42.680 --> 14:47.560
And that allows you to do some scary network analysis.

14:51.400 --> 14:56.600
If you're looking for the structured data that's already there, it's the open travel alliance.

14:57.880 --> 15:05.000
First it was in XML horror. Now it's in JSON. So maybe that will be, can be implemented in the

15:06.200 --> 15:12.360
final structure. Open travel alliance. Yeah, I don't know that one yet. No, it's international.

15:12.360 --> 15:16.040
Everything is in there, the planes, the trains, boats. Okay.

15:16.200 --> 15:24.840
Yeah, we, from the scheme of the world stuff, we support flights, trains, buses,

15:26.520 --> 15:33.640
events, restaurant reservations, and ferries and boats. Yeah. But there's certainly more that

15:33.640 --> 15:40.760
can be done. One quick final question. I wanted to remark that the anonymization of data fields

15:40.760 --> 15:44.920
is possible without being able to trace it back to an individual human being.

15:45.480 --> 15:51.800
Because airlines are innumerable. So you can get to the proverbial shouts, whereas user names or

15:51.800 --> 15:57.320
people's names are not. And so you could hash everything into the WAHOOZA and still recognize

15:57.320 --> 16:01.240
whether or not you should have recognized the field differently than what you've actually

16:01.240 --> 16:07.160
rendered in a client in this case. Right. Yeah, but anonymization has turned out to be

16:07.240 --> 16:16.200
rather tricky on input data like PDFs, where we also rely on the proper structure. So as soon

16:16.200 --> 16:23.400
as you start to modify this, it's not sure that the extractor still detects it in the same way.

16:23.400 --> 16:30.360
And we often don't know what kind of sensitive information is even in there or what the fields

16:30.360 --> 16:35.560
in the back would mean when we start with a new format. Right. So it's very hard to predict what

16:35.560 --> 16:41.560
we need to strike out. Sure, yes. But I thought we were talking about the JSON.

16:42.600 --> 16:49.320
Once we have the JSON, sure. But the JSON alone is not really enough to fix the extractor. We

16:49.320 --> 16:57.160
need the source document in its original form without modification to see where it goes wrong

16:57.160 --> 17:03.160
in the extraction. So if there is proper JSON in the source, then yes, then the JSON is enough.

17:03.160 --> 17:08.440
But if our source is a PDF document attached to the email and the barcode in there, then

17:09.320 --> 17:14.200
I need the full thing to debug why we failed the extractor. I'm interested, but we'll take this

17:14.200 --> 17:20.600
offline, I suppose. Yeah. Yeah. Right. A short technical question is Bogo in the room. Ah,

17:20.600 --> 17:25.960
right. There he is. Great. All right. So thank you very much for that lively discussion. Thank

17:25.960 --> 17:34.040
you, Falka, for the presentation. Once applause again.

