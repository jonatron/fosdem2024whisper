WEBVTT

00:00.000 --> 00:09.000
Thank you all for joining us in a great, you don't.

00:09.000 --> 00:14.000
It's not working? Why is it not working?

00:14.000 --> 00:18.000
It is? Okay, good.

00:18.000 --> 00:24.000
Let's not correct. So thank you all for joining us and here to talk about next.

00:24.000 --> 00:26.000
AI.

00:26.000 --> 00:31.000
Exactly. Another approach to AI is just port fleet.

00:31.000 --> 00:35.000
Okay. Does this work well enough? You can hear it in the back and all that.

00:35.000 --> 00:38.000
Okay. I see thumbs up. That's wonderful.

00:38.000 --> 00:40.000
Yeah. Well, I had this. I'm your sport fleet.

00:40.000 --> 00:44.000
Direct communications co-founder at NextLoud.

00:44.000 --> 00:47.000
So, yeah, the thing we do at NextLoud is collaboration.

00:47.000 --> 00:50.000
That's of course what this room is all about.

00:50.000 --> 00:53.000
Now, there's this AI thing coming.

00:53.000 --> 00:59.000
And so I'm hoping to try and make this conversation a little bit interactive.

00:59.000 --> 01:04.000
I mean, there are other people here from Xweek and other projects who are working on,

01:04.000 --> 01:08.000
well, collaboration tools as well, open source collaboration tools.

01:08.000 --> 01:14.000
And, you know, this AI thing, I mean, there have been AI-ish tools being used for a long time,

01:14.000 --> 01:16.000
but a lot of them are also still quite new.

01:16.000 --> 01:20.000
So I'm kind of hoping that we can also have a bit of a conversation about it.

01:21.000 --> 01:25.000
Because, well, there are pros and cons. I mean, we'll get to all that stuff.

01:25.000 --> 01:31.000
Of course, the big thing here is, yeah, that we have, like, these big companies, right?

01:31.000 --> 01:37.000
They all want our data, and AI is for them another thing to use that data for.

01:37.000 --> 01:44.000
So, yeah, I mean, AI, I don't know how deep I want to go into what it is,

01:44.000 --> 01:47.000
because I think all of us know it a little bit.

01:47.000 --> 01:50.000
But we don't want to live in a world where there are five companies, you know,

01:50.000 --> 01:54.000
who run all our data, and that's kind of a little bit the case right now.

01:54.000 --> 02:00.000
I think that if Trump and his next presidency tells Microsoft to shut down their service in Europe,

02:00.000 --> 02:07.000
then basically you cannot get a new passport, you cannot, yeah, nobody can work at government here, for example, right?

02:07.000 --> 02:09.000
This is, I think, a bit of an issue.

02:09.000 --> 02:14.000
And, I mean, NextLoud is one of the projects that's working on solving that issue,

02:14.000 --> 02:20.000
essentially trying to give, well, companies, individuals, but also hopefully government,

02:20.000 --> 02:22.000
back the control over their data.

02:22.000 --> 02:24.000
We've built a collaboration platform.

02:24.000 --> 02:29.000
I'm guessing how many of you are not familiar with NextLoud?

02:29.000 --> 02:33.000
Yeah, okay, it's like six people.

02:33.000 --> 02:35.000
Google it.

02:35.000 --> 02:40.000
I will then not go into that, sorry, or duck-duck-go it, that would be better, obviously.

02:40.000 --> 02:46.000
So, as a company, we build an alternative for 365 in very quick, simple terms.

02:46.000 --> 02:54.000
And with alternative, we mean that as a government or a company, we think it's important that you have a choice.

02:54.000 --> 03:02.000
It's totally fine if you're happy that your data is at an American company and that U.S. buy agencies have access to it.

03:02.000 --> 03:07.000
If you're good with that, if that's not a threat to your business, that's fine.

03:07.000 --> 03:12.000
Government, I think it's by definition a threat, but that's their choice.

03:12.000 --> 03:15.000
But we think there should be, like, a choice.

03:15.000 --> 03:17.000
There should be an alternative.

03:17.000 --> 03:23.000
And an alternative is only an alternative, is it is, if it does what the other product does, obviously,

03:23.000 --> 03:28.000
and in a safe way and has enough ability to be used for a serious company.

03:28.000 --> 03:31.000
So, that's what we're building and we have built.

03:31.000 --> 03:37.000
That's why German and French and most European governments are in places already using Nexlout,

03:37.000 --> 03:42.000
be it cities, be it at a state level or federal level.

03:42.000 --> 03:46.000
So, as a company, we care a lot. Nexlout for us is a mission, it's a goal.

03:46.000 --> 03:51.000
It's like our way to try and make the world a tiny little bit better.

03:51.000 --> 03:56.000
And we want to work in an open, collaborative way.

03:56.000 --> 04:03.000
Therefore, we're very happy, of course, that it's used by thousands of governments and universities, et cetera, et cetera.

04:03.000 --> 04:05.000
And, of course, we're building this completely in the open.

04:05.000 --> 04:11.000
And again, that will be relevant because, of course, I think the future for AI will better be open,

04:11.000 --> 04:16.000
otherwise we are, well, just as crude as it is with collaboration platforms, honestly.

04:16.000 --> 04:20.000
And we have a wonderful community working with us and all this stuff, which is awesome.

04:20.000 --> 04:27.000
Also, as a company, we try to be open and transparent, not depending on venture capital, et cetera, but be self-owned.

04:27.000 --> 04:29.000
Anyhow, AI.

04:29.000 --> 04:36.000
So, AI is like, we've already introduced a ton of AI things over the years, like little things,

04:36.000 --> 04:42.000
and I will show some of them, but of course, with the latest LLMs and stuff, it's getting really complicated.

04:42.000 --> 04:44.000
I mean, there are tons of problems with it.

04:44.000 --> 04:46.000
I have a lot of potential, right?

04:46.000 --> 04:54.000
AI can help us make repetitive tasks easier, quicker, et cetera, but at the same time, Big Tech is basically loving it.

04:54.000 --> 04:57.000
They have all the data to be able to build the AI's.

04:57.000 --> 05:04.000
It costs tens or hundreds of millions right now to really train the proper LLMs, so they really have a bit of a monopoly here.

05:04.000 --> 05:09.000
And, yeah, the rest of us will have to just accept that they're using all our data to do it.

05:09.000 --> 05:13.000
And a lot of companies are already really realizing this is a problem for them, right?

05:13.000 --> 05:15.000
It's Citigroup and Goldman Sachs.

05:15.000 --> 05:19.000
They are actually not allowing their employees to use tools like chatGPT.

05:19.000 --> 05:29.000
I mean, if you're BMW and you're working on a new car and you're using an AI to generate some ideas or summarize some proposals,

05:29.000 --> 05:33.000
and you discover later that six months later Tesla, while designing their car,

05:33.000 --> 05:40.000
suddenly got some of your ideas coming into their AI planning, then there's a bit of an issue here.

05:40.000 --> 05:42.000
And, of course, this kind of stuff is happening.

05:42.000 --> 05:48.000
The company, like a while ago, Twitter and Zoom, they changed their terms of service to allow for training on user data.

05:48.000 --> 05:55.000
And, yeah, this is really an issue for business as well as, well, obviously, all our society.

05:55.000 --> 06:01.000
And then I'm not even talking about data biases in these models, carbon footprint.

06:01.000 --> 06:05.000
I mean, I think most of you are aware of all the issues with AI.

06:05.000 --> 06:11.000
So, honestly, I don't think the question is to AI or not, because there are too many benefits.

06:11.000 --> 06:14.000
The opportunities are really big, I think.

06:14.000 --> 06:21.000
I've been trying to make a bit of a list of that, but I was just changing it while standing here in line outside.

06:21.000 --> 06:23.000
So this is definitely not complete.

06:23.000 --> 06:27.000
So I'm just going to put it all on the screen and ask what's missing.

06:27.000 --> 06:31.000
I mean, I think there are some basics, you know, text to speech, speech to text,

06:31.000 --> 06:37.000
recognizing faces on photos and recognizing objects on it, et cetera.

06:37.000 --> 06:43.000
This is already, like Nexot has been shipping this for three years, four years already, these kind of things.

06:43.000 --> 06:48.000
It's just one model that you download and does this stuff, and translation and other one.

06:48.000 --> 06:52.000
It's fairly, I think it's, I mean, it's not simple.

06:52.000 --> 06:55.000
It's technically complicated stuff, but it works.

06:55.000 --> 06:56.000
And there are not huge risks.

06:56.000 --> 07:00.000
You don't need to send your data to Google anymore if you want text to speech,

07:00.000 --> 07:04.000
or if you want image recognition and being able to search for a dog

07:04.000 --> 07:07.000
and find all the pictures of your favorite pet.

07:07.000 --> 07:14.000
So this is already there, and it's not terribly complicated to use for a person.

07:14.000 --> 07:18.000
But of course, you now have all these new language models.

07:18.000 --> 07:23.000
I think there's really a big benefit, unlike dealing with information overload.

07:23.000 --> 07:25.000
You have tons of emails coming in.

07:25.000 --> 07:28.000
You have, I don't know, papers to read, et cetera.

07:28.000 --> 07:33.000
And these LLMs, they, I know they create a lot of fake content and hallucinate stuff.

07:33.000 --> 07:36.000
But the thing they're pretty reliable at is summarizing.

07:36.000 --> 07:38.000
And this is really quite important.

07:38.000 --> 07:40.000
I don't know how many emails you get, but I get a ton,

07:40.000 --> 07:47.000
and I would love to be able to summarize it or help select, you know, useful emails, et cetera.

07:47.000 --> 07:51.000
And this stuff is really possible, or, I don't know, meeting notes.

07:51.000 --> 07:53.000
And, yeah.

07:53.000 --> 07:57.000
So this is, I think, where these models can be super helpful.

07:57.000 --> 08:02.000
And you have, like, text generation, of course, they can do help out with this.

08:02.000 --> 08:06.000
You have also image analysis of various things.

08:06.000 --> 08:10.000
There have been some demos from Microsoft and Google already about a year ago,

08:10.000 --> 08:13.000
where they basically were showing that you have, like, a spreadsheet,

08:13.000 --> 08:16.000
and you select something in it, and then you type a question about it,

08:16.000 --> 08:18.000
and then it makes a graph that answers the question.

08:18.000 --> 08:21.000
This kind of stuff is also pretty magical.

08:21.000 --> 08:23.000
And there are tons of people in office all over the world

08:23.000 --> 08:26.000
that would benefit a lot from having this stuff.

08:26.000 --> 08:29.000
So I think, yeah, the benefits are really there.

08:29.000 --> 08:31.000
Another thing is, like, automation.

08:31.000 --> 08:33.000
Just talking about it with a colleague.

08:33.000 --> 08:37.000
This is, like, also a next step, you know, if you can say to the LLM,

08:37.000 --> 08:40.000
like, hey, send, make an appointment with another person,

08:40.000 --> 08:43.000
and then they try chat, and if that doesn't work, they try email.

08:43.000 --> 08:47.000
These kind of things would be really helpful, I think, in day-to-day work.

08:48.000 --> 08:50.000
So, yeah, I don't know.

08:50.000 --> 08:52.000
If there are other ideas or things that are missing,

08:52.000 --> 08:56.000
I'd love to hear it, actually, and make my list a little bit more complete,

08:56.000 --> 08:59.000
but we'll get to that, I think.

08:59.000 --> 09:01.000
So I just wanted to show a couple of examples,

09:01.000 --> 09:03.000
like we have this feature now, the Threads Summary,

09:03.000 --> 09:05.000
that makes a summary of your emails.

09:05.000 --> 09:08.000
Another example is, like, an Excel text.

09:08.000 --> 09:11.000
You can just select some text and say, hey, summarize it, create a headline.

09:11.000 --> 09:14.000
It's all quite simple to use.

09:14.000 --> 09:18.000
And image generation, of course, I mean, this is a horrible image,

09:18.000 --> 09:21.000
but, you know, you can make things that look good.

09:21.000 --> 09:24.000
And then you have the data analysis, and you have automation,

09:24.000 --> 09:26.000
all these other features we have ideas on.

09:26.000 --> 09:28.000
I'll share some things a bit later on.

09:28.000 --> 09:33.000
So I think we need to do AI in our collaboration platforms,

09:33.000 --> 09:35.000
like X-Wiki, you guys need to have a plan.

09:35.000 --> 09:38.000
I know only Office, but they integrated just chat GPT.

09:38.000 --> 09:41.000
I think we need a little bit more than just that,

09:41.000 --> 09:45.000
because, well, we're losing the on-prem capabilities, right?

09:45.000 --> 09:48.000
It's not competitive if you're just integrating chat GPT,

09:48.000 --> 09:51.000
then the data is sent to the U.S. anyway.

09:51.000 --> 09:54.000
So, yeah, that's not really a good solution.

09:54.000 --> 09:57.000
So the question is, how can we get this without the problems?

09:57.000 --> 10:00.000
And I think I'm in a room with open source people,

10:00.000 --> 10:03.000
so I think the answer for most of you is obvious,

10:03.000 --> 10:07.000
and this to me at least, just transparency and being open, yeah?

10:08.000 --> 10:11.000
And this is kind of the thing that we've been working on at NextLoud.

10:11.000 --> 10:13.000
We kind of made some rules for ourselves,

10:13.000 --> 10:15.000
so we have been doing AI as things,

10:15.000 --> 10:20.000
but when the whole text stuff from chat GPT came out,

10:20.000 --> 10:23.000
actually that was at the FOSDEM two years ago,

10:23.000 --> 10:26.000
we talked to people and each other,

10:26.000 --> 10:29.000
and we have some fairly smart people on board,

10:29.000 --> 10:32.000
also from the research community,

10:32.000 --> 10:36.000
and we tried to come up with, like, how can we handle this?

10:36.000 --> 10:38.000
Because we add more AI features,

10:38.000 --> 10:40.000
like we don't want to be left behind,

10:40.000 --> 10:43.000
and we need to be an alternative, as I said earlier,

10:43.000 --> 10:46.000
and you can only be an alternative if you offer similar features,

10:46.000 --> 10:48.000
otherwise who's going to use your product?

10:48.000 --> 10:51.000
But then how can you do that in an okayish way?

10:51.000 --> 10:55.000
So the idea we came up with was to at least create transparency,

10:55.000 --> 10:57.000
and of course, choice, I'll get to that next,

10:57.000 --> 10:59.000
but first the transparency.

10:59.000 --> 11:01.000
So we came up with the idea of creating a rating

11:01.000 --> 11:04.000
that has basically red, orange, yellow, green,

11:04.000 --> 11:08.000
and we would rate each of the integrations of AI features

11:08.000 --> 11:11.000
in NextCloud with this rating.

11:11.000 --> 11:13.000
So first, is it open source?

11:13.000 --> 11:17.000
Is the model available, and is the training data available?

11:17.000 --> 11:20.000
And so if a model has all three, it's green,

11:20.000 --> 11:22.000
if it has two of them, it's orange,

11:22.000 --> 11:24.000
if it has one of them, it's yellow,

11:24.000 --> 11:26.000
if it has none of them, it's red.

11:26.000 --> 11:29.000
So chat GPT integration, red.

11:29.000 --> 11:32.000
Completely on-prem model that is trained

11:32.000 --> 11:34.000
and has the training data available,

11:34.000 --> 11:37.000
for example, for speech to text, that can be green,

11:37.000 --> 11:40.000
and you have everything in between, of course.

11:40.000 --> 11:42.000
And the second thing is choice.

11:42.000 --> 11:45.000
So for us, it's really important that you, well, can choose, right?

11:45.000 --> 11:47.000
I mean, there are, again, legitimate users

11:47.000 --> 11:49.000
for something like chat GPT, and I mean,

11:49.000 --> 11:51.000
they're throwing so many billions at this problem

11:51.000 --> 11:53.000
that you can hardly argue that open source

11:53.000 --> 11:56.000
can really keep up to the latest stuff they're doing,

11:56.000 --> 11:58.000
and sometimes you just need it, fine?

11:58.000 --> 12:00.000
So in our user interface,

12:00.000 --> 12:04.000
we have these choices that you can have, like Opus,

12:04.000 --> 12:06.000
that's a translation exactly,

12:06.000 --> 12:08.000
so this would be a fully green one,

12:08.000 --> 12:11.000
and that's, well, we all know, chat GPT.

12:11.000 --> 12:13.000
So we try to make sure that for the various features

12:13.000 --> 12:15.000
that you can choose between these different models,

12:15.000 --> 12:17.000
on-prem, et cetera.

12:17.000 --> 12:20.000
So for us, of course, most of the work we put in

12:20.000 --> 12:25.000
on-prem and open source locally running AI features,

12:25.000 --> 12:28.000
because, well, that fits with our values as a company

12:28.000 --> 12:30.000
and, well, with our ethical AI rating,

12:30.000 --> 12:32.000
but the others are available.

12:32.000 --> 12:34.000
So at the moment, I made a list,

12:34.000 --> 12:36.000
but I'm sure there are many more you can use,

12:36.000 --> 12:38.000
like models like these in NextLoud.

12:38.000 --> 12:41.000
I have four of the various features.

12:41.000 --> 12:45.000
I'll show, well, actually, I'm showing examples right now.

12:45.000 --> 12:47.000
So this is just a bunch of the features we have.

12:47.000 --> 12:50.000
There is more, but suspicious login detection

12:50.000 --> 12:53.000
is something we developed like a really, really long time ago.

12:53.000 --> 12:56.000
It's basically a neural network

12:56.000 --> 12:58.000
that gets trained on your login data.

12:58.000 --> 13:01.000
It just runs completely local every time you log in.

13:01.000 --> 13:04.000
If you work nine to five from the Berlin office, let's say,

13:04.000 --> 13:10.000
and suddenly somebody at 3 a.m. logs in in your account from China,

13:10.000 --> 13:13.000
maybe there's something wrong, the model will detect that

13:13.000 --> 13:14.000
and give you a warning.

13:14.000 --> 13:17.000
Very simple, and we have had this for, I don't know,

13:17.000 --> 13:20.000
since 2020, so quite a while.

13:20.000 --> 13:22.000
And it's green, right?

13:22.000 --> 13:23.000
It runs fully local.

13:23.000 --> 13:26.000
There's nothing special about it, no data sent anywhere.

13:26.000 --> 13:29.000
We basically do a very similar thing with our mail app,

13:29.000 --> 13:32.000
where we basically train a neural network on subjects,

13:32.000 --> 13:35.000
sender, and email recipients, et cetera.

13:35.000 --> 13:39.000
And it creates a smart inbox trying to put important emails on top

13:39.000 --> 13:42.000
and the rest not, and again, no data sent anywhere,

13:42.000 --> 13:44.000
because it just runs on premise.

13:44.000 --> 13:48.000
I already mentioned phase recognition and stuff we did in 2022,

13:48.000 --> 13:50.000
I think, so this is all.

13:50.000 --> 13:52.000
But the problem with this is already,

13:52.000 --> 13:54.000
you need to download a multi-gigabyte file,

13:54.000 --> 13:57.000
which has, like, all the values needed for the neural network

13:57.000 --> 13:59.000
to recognize stuff.

13:59.000 --> 14:03.000
So we already had to re-architect a lot of the way Nexard works

14:03.000 --> 14:05.000
just to be able to download this big blob

14:05.000 --> 14:08.000
without creating all kinds of complexities for the users.

14:08.000 --> 14:11.000
And obviously, this problem gets bigger and bigger

14:11.000 --> 14:13.000
when you get to modern AIs.

14:13.000 --> 14:18.000
We even have music genre recognition using machine learning.

14:18.000 --> 14:21.000
It's yellow because it's trained on all the music on Spotify,

14:21.000 --> 14:24.000
which means the training data is actually copyrighted

14:24.000 --> 14:26.000
and therefore not open.

14:26.000 --> 14:32.000
And, yeah, we had, like, a pre-trained model to do call transcripts.

14:32.000 --> 14:34.000
We introduced that last year.

14:34.000 --> 14:37.000
That is nice. You have a call and the recording then gets text,

14:37.000 --> 14:41.000
speeds to text so that you get the text of the recording.

14:41.000 --> 14:44.000
Again, this model runs fully local, so that's cool.

14:44.000 --> 14:47.000
And speeds to text the other way around.

14:47.000 --> 14:50.000
Background blur, just a JavaScript thing that we upload

14:50.000 --> 14:53.000
in the browser, very simple translations.

14:53.000 --> 14:56.000
First, we made it with Deepol, which is not cool.

14:56.000 --> 14:59.000
So then we made one using the Opus corpus.

14:59.000 --> 15:02.000
You saw it earlier, and that is running fully local,

15:02.000 --> 15:04.000
so that's much better.

15:04.000 --> 15:08.000
So these are still mostly basic features, I think, today,

15:08.000 --> 15:10.000
and yet already pretty complicated.

15:10.000 --> 15:13.000
You need to keep an eye out where the data is being sent to,

15:13.000 --> 15:15.000
like with translation.

15:15.000 --> 15:17.000
But, of course, the big thing are LLMs,

15:17.000 --> 15:20.000
like the text operations.

15:20.000 --> 15:23.000
What we've been doing is to create, basically, NexLad Assistant.

15:23.000 --> 15:28.000
It uses the large language models, but open source on-prem ones

15:28.000 --> 15:30.000
that you can host yourself.

15:30.000 --> 15:32.000
It's like this little thing on the top.

15:32.000 --> 15:34.000
When you click on it, you get a dialogue.

15:34.000 --> 15:37.000
You can give a free prompt, or you can give a text to summarize

15:37.000 --> 15:39.000
and some other things.

15:39.000 --> 15:42.000
And it just runs this through one of the models that is supported by NexLad.

15:42.000 --> 15:46.000
And, again, you can put JetGPT here as model,

15:46.000 --> 15:50.000
or as back-end, but you can also then run your own LLM

15:50.000 --> 15:54.000
and connect that to NexLad, and then it can do all this stuff on-premise.

15:54.000 --> 15:56.000
So it's fairly simple.

15:56.000 --> 15:59.000
When it's running, then it'll get the results,

15:59.000 --> 16:02.000
and after a while you get the output of it.

16:02.000 --> 16:04.000
You can copy it into a document, et cetera.

16:04.000 --> 16:08.000
And, again, if you take a local model that is trained on public data,

16:08.000 --> 16:11.000
then it can be a fully green solution.

16:11.000 --> 16:13.000
So that's really cool.

16:13.000 --> 16:17.000
In places like NexLad Text, I already showed that,

16:17.000 --> 16:20.000
that you can select some text and then run this.

16:20.000 --> 16:22.000
Mail, I already showed this as well.

16:22.000 --> 16:26.000
In talk, like our video calling and JetSolution,

16:26.000 --> 16:30.000
you can translate a message, select it, and then choose translate,

16:30.000 --> 16:32.000
insert images and other stuff.

16:32.000 --> 16:34.000
We even made a little bot.

16:34.000 --> 16:36.000
This isn't the smartest bot.

16:36.000 --> 16:38.000
It's a very small model, but hey, it's fast.

16:38.000 --> 16:40.000
And you can ask it questions.

16:40.000 --> 16:42.000
Honestly, I wouldn't say such smart things.

16:42.000 --> 16:44.000
It's fairly shitty, I've noticed.

16:44.000 --> 16:47.000
But still, it works on your own server.

16:47.000 --> 16:49.000
That's kind of nice.

16:49.000 --> 16:51.000
So a lot is possible.

16:51.000 --> 16:53.000
One of the newer things we're working on is more of these services,

16:53.000 --> 16:55.000
because they're now companies like Amazon.

16:55.000 --> 16:58.000
They are running LLMs as a service.

16:58.000 --> 17:01.000
And other companies are doing this also purely in Europe,

17:01.000 --> 17:05.000
like you have ALEF, ALFA, and I think MIRROR or something.

17:05.000 --> 17:09.000
In France, there's also a company that is building local AI.

17:09.000 --> 17:11.000
So we're trying to support these, that you...

17:11.000 --> 17:13.000
You know, everybody can run these AIs,

17:13.000 --> 17:15.000
like you need a lot of heavy GPUs.

17:15.000 --> 17:17.000
It's a lot of compute.

17:17.000 --> 17:19.000
So you can use it as a service that at least it stays in Europe

17:19.000 --> 17:22.000
or at a company that you trust.

17:22.000 --> 17:25.000
Then I wouldn't recommend Amazon, per se, perhaps.

17:25.000 --> 17:28.000
For this, we also made it possible that you can put in some limits,

17:28.000 --> 17:34.000
otherwise users get a little creative and start to basically cost you a lot of money.

17:34.000 --> 17:36.000
And we worked on the interaction with this.

17:36.000 --> 17:38.000
I'll skip through this.

17:38.000 --> 17:43.000
A thing we're working on now is also to make all of this even smarter.

17:43.000 --> 17:50.000
A newer thing is the ability to take your documents that you have into account.

17:50.000 --> 17:55.000
So ContextChat is a feature of the Assistant that basically it has access to your documents,

17:55.000 --> 17:58.000
your emails, everything you have that gets indexed.

17:58.000 --> 18:00.000
Let me see.

18:00.000 --> 18:02.000
It's indexed into a vector database.

18:02.000 --> 18:06.000
So this runs as a separate service next to NextLoud.

18:06.000 --> 18:10.000
And then when you ask a question from the Assistant,

18:10.000 --> 18:15.000
it can actually answer using your documents, your company documentation, your emails, etc.

18:15.000 --> 18:18.000
So you can really do stuff like, you know,

18:18.000 --> 18:22.000
can you give me an idea of how we organize events, rather than in general,

18:22.000 --> 18:25.000
it can look at your documentation and then tell you, like,

18:25.000 --> 18:28.000
oh, you know, at your company, organize events this way.

18:28.000 --> 18:32.000
Or you can say, hey, can you give me a summary of the different requests

18:32.000 --> 18:35.000
that a colleague has emailed to me last week,

18:35.000 --> 18:39.000
and hopefully it'll give you all the to-dos that you got from that colleague in the last week.

18:39.000 --> 18:46.000
So this, yeah, has the context basically of what you are doing as a user at hand.

18:46.000 --> 18:53.000
It's, I think, really kind of, yeah, an important step forward to make this useful,

18:53.000 --> 18:56.000
because otherwise you're just getting the generic info that's in the LLM.

18:56.000 --> 18:59.000
As I said, they hallucinate stuff all the time.

18:59.000 --> 19:02.000
They're much better at, like, taking information and summarizing it,

19:02.000 --> 19:04.000
and that's, of course, what this does.

19:04.000 --> 19:10.000
I think it's much more reliable in that way, you know, vacation process, et cetera, et cetera.

19:10.000 --> 19:16.000
So that's a couple of things we've been doing lately on this, as well as in the context yet.

19:16.000 --> 19:19.000
So that's our approach to AI.

19:19.000 --> 19:23.000
I would really like to hear thoughts on that, and, like,

19:23.000 --> 19:26.000
I don't know what other projects are planning with this.

19:26.000 --> 19:30.000
One of these will be giving a talk after mine.

19:30.000 --> 19:37.000
But I know any feedback, questions, thoughts, fears, and anxieties?

19:37.000 --> 19:39.000
Okay, so is this working?

19:39.000 --> 19:41.000
Can anybody confirm in the back?

19:41.000 --> 19:44.000
Great, thank you very much.

19:44.000 --> 19:48.000
So any thoughts, questions? Let's start here.

19:48.000 --> 19:52.000
So you said your screenshot showed that...

19:52.000 --> 19:56.000
Yes, the screenshot showed that I need to double check the information that the assistant gave me.

19:56.000 --> 20:01.000
Notice that it doesn't give me the reference to the emails that it was quoting from.

20:01.000 --> 20:04.000
Is there a possibility to get that?

20:04.000 --> 20:12.000
Currently not, but thinking of the way this works, I mean, I have one developer here.

20:12.000 --> 20:17.000
They can interject, but I think that should actually be quite doable,

20:17.000 --> 20:20.000
because the way it works is it looks in this vector database

20:20.000 --> 20:24.000
and gives that information to the LLM to then summarize and give you the answer.

20:24.000 --> 20:28.000
And, well, in the vector database, I guess it knows where it came from,

20:28.000 --> 20:34.000
and therefore can then say what information was used to summarize that answer.

20:34.000 --> 20:38.000
So I would think this is possible, but I don't... I don't know.

20:38.000 --> 20:41.000
Yeah, I see a thumbs up. Excellent, okay.

20:41.000 --> 20:44.000
Any other questions, ideas?

20:44.000 --> 20:46.000
Okay.

20:46.000 --> 20:49.000
Or are we going to do this?

20:49.000 --> 20:53.000
Yes, for me, I am an e-aseptic.

20:53.000 --> 20:56.000
There's something... some examples.

20:56.000 --> 21:02.000
So it's good, something... when user is at the end,

21:02.000 --> 21:08.000
and he can correct what is said by the AI.

21:08.000 --> 21:15.000
So an example for translation, I have the word in Dutch, Académie de Sie.

21:15.000 --> 21:18.000
It's not universitaire, the translation in French.

21:18.000 --> 21:22.000
It's personne issue des milieux académiques.

21:22.000 --> 21:26.000
And that's any... the translator or a consultant don't give this response.

21:26.000 --> 21:28.000
Yeah, but it's...

21:28.000 --> 21:35.000
So you have a control, they say, from the user, also from the citizen in general,

21:35.000 --> 21:39.000
so when the user has no power of the system.

21:39.000 --> 21:43.000
You can't check a human translator either, though, unless you know the language

21:43.000 --> 21:46.000
at that point you didn't need them in the first place.

21:46.000 --> 21:52.000
So, yeah, you have to use this stuff in a skeptical way, but then... yeah.

21:52.000 --> 21:57.000
Yes, and the other thing is about consuming energy.

21:57.000 --> 22:03.000
So it was an emission in the RTBF about consuming of energy, of shaggivity.

22:03.000 --> 22:05.000
It was hard.

22:05.000 --> 22:08.000
Yeah, so the amount of energy that these models use is big.

22:08.000 --> 22:11.000
That's, by the way, one of the reasons I think they should be open source,

22:11.000 --> 22:15.000
is that the researchers who do stuff companies aren't interested in

22:15.000 --> 22:19.000
can try to optimize them and make them run with less energy.

22:19.000 --> 22:21.000
Yeah.

22:21.000 --> 22:25.000
Hi. I think another good use case for all these...

22:25.000 --> 22:34.000
If we combine these features, that would mean that we could have a super accessible environment,

22:34.000 --> 22:38.000
because if someone is blind or nearly blind,

22:38.000 --> 22:46.000
people could use all this text to speech if someone has autism, ADHD, whatever.

22:46.000 --> 22:54.000
You could try to find a shorter version, an easier, understandable version of a text or whatever,

22:54.000 --> 22:58.000
and combining this would help, I think.

22:58.000 --> 23:01.000
That is awesome. I'm going to add that to my slides right now,

23:01.000 --> 23:04.000
but I am completely making the laptop slow now.

23:04.000 --> 23:09.000
That's a really good point. Accessibility is a really important benefit.

23:09.000 --> 23:13.000
Actually, hint to the developer, bring it up in the team.

23:13.000 --> 23:15.000
Maybe we can already work on that.

23:22.000 --> 23:24.000
Yeah, any more?

23:24.000 --> 23:28.000
Yeah, just a question on the REC approach that you were describing before.

23:28.000 --> 23:35.000
Do you have any figure that you can share to which extent you tried the retrieval of the vector?

23:35.000 --> 23:37.000
Sorry, I did not hear the question.

23:37.000 --> 23:41.000
So when you were describing the rag, the retrieval of the augmented...

23:41.000 --> 23:43.000
The green, the colors, yes.

23:43.000 --> 23:47.000
No, the rag. When you're retrieving the vectors from the vector DB.

23:47.000 --> 23:48.000
Right.

23:48.000 --> 23:52.000
So can you give us some figures on to which extent you tried that?

23:52.000 --> 23:57.000
Talk to somebody, not me, in one of these, who knows the technical part there,

23:57.000 --> 24:02.000
and I'm not even sure we have somebody right here at the moment with that. Sorry.

24:02.000 --> 24:03.000
Okay.

24:03.000 --> 24:07.000
And we're out of time. I'm afraid. So this is probably it then.

24:07.000 --> 24:09.000
Somebody wants their microphone back.

24:09.000 --> 24:11.000
Alright, thank you all.

24:11.000 --> 24:13.000
Thank you very much, Josh.

