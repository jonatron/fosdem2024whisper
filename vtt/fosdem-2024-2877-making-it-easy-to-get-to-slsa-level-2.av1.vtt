WEBVTT

00:00.000 --> 00:08.640
Hello, hey everyone.

00:08.640 --> 00:13.320
Welcome to Making It Easy to Get to Salsa Level 2.

00:13.320 --> 00:14.320
Thanks for sticking around.

00:14.320 --> 00:17.720
It's last day of the conference, send me last talk.

00:17.720 --> 00:25.040
So, yeah, today we're going to be talking about salsa and compliance and hopefully how you

00:25.040 --> 00:28.040
can meet those compliance requirements as a play.

00:28.040 --> 00:32.440
My name is Theophilus and I'm going to be talking about Choc and open source framework.

00:32.440 --> 00:35.200
We developed that crash override.

00:35.200 --> 00:40.560
So I come from a security background and every time I hear the word compliance I get bored

00:40.560 --> 00:41.560
to death.

00:41.560 --> 00:44.280
It's kind of like a book sticking exercise.

00:44.280 --> 00:49.880
But hopefully we can discuss today about this and see how you can do this in your own organization

00:49.880 --> 00:53.880
easily while also get value for your org.

00:53.880 --> 00:57.560
Before jumping into the topic, let me kind of quickly set the scene and talk a little

00:57.560 --> 01:00.040
bit about software supply chain attacks.

01:00.040 --> 01:04.440
So in a software supply chain attack, the attackers compromise the build system or the

01:04.440 --> 01:08.640
package registry and get a foothold there.

01:08.640 --> 01:12.240
And over the past years we've been seeing an increase in these types of attacks.

01:12.240 --> 01:17.280
So there was a report say from Sonatype that said since 2019, year after year, we've been

01:17.280 --> 01:21.320
seeing a sevenfold increase in this type of attacks.

01:21.320 --> 01:26.640
The report came out in 2022 that said supply chain attacks basically surpassed malware

01:26.640 --> 01:29.360
based attacks by 40%.

01:29.360 --> 01:34.640
And last year around two out of three of US businesses were impacted by a supply chain

01:34.640 --> 01:35.960
attack.

01:35.960 --> 01:41.000
So you can take these numbers with a grain of salt, but the fact of the matter is there

01:41.000 --> 01:44.960
is a surge in these types of attacks.

01:44.960 --> 01:50.200
And this popularity on the attack realm drives policy changes.

01:50.200 --> 01:57.840
So in May 2021, there was an executive order by the White House that said software vendors

01:57.840 --> 02:04.200
must be provided and purchased with software of materials and provenance information.

02:04.200 --> 02:06.440
And quick show of hands.

02:06.440 --> 02:09.560
How many are familiar with the term S-bombs or provenance?

02:09.560 --> 02:10.720
Cool.

02:10.720 --> 02:15.120
How many of you have been deploying these in your pipelines or your organizations?

02:15.120 --> 02:16.880
Okay, great.

02:16.880 --> 02:17.880
There's also an S-bomb room.

02:17.880 --> 02:20.680
So today we're going to jump into these topics real quick.

02:20.680 --> 02:26.040
So we're going to discuss some concepts and then talk about the challenges people face

02:26.040 --> 02:29.720
when trying to deploy these things to production.

02:29.720 --> 02:34.280
Then we're going to talk about CHOC and how CHOC can help you solve these problems but

02:34.280 --> 02:38.400
achieve many, many more things and hopefully have a discussion in the end.

02:38.400 --> 02:43.320
So for those of you who are not familiar with software bill of materials or S-bombs, you

02:43.320 --> 02:46.120
can think of it like a list of ingredients for software.

02:46.120 --> 02:51.920
So you go to the supermarket, you see a package, then you read the labels and you get a list

02:51.920 --> 02:53.760
of all the ingredients that are in there.

02:53.760 --> 02:58.000
So an S-bomb is pretty much the same thing but for your software applications.

02:58.000 --> 03:02.720
So you get either an XML or a JSON and from that you can get a list of the packages, their

03:02.720 --> 03:05.520
versions, etc., etc.

03:05.520 --> 03:09.800
When we're talking about provenance, what we're talking about really is how did the

03:09.800 --> 03:10.800
artifact get here?

03:10.800 --> 03:14.920
Like who created it, who packaged it, how was it modified along the way until it actually

03:14.920 --> 03:20.120
reaches the user basically.

03:20.120 --> 03:26.320
So that is all good but if we think about a list of ingredients, what are the guarantees

03:26.320 --> 03:29.200
that what we get is actually what we're promised?

03:29.200 --> 03:33.760
So for instance you could have an NPM package and you can generate an S-bomb for your NPM

03:33.760 --> 03:37.760
package saying that these are the ingredients that are there but then in a package you could

03:37.760 --> 03:42.320
get a foothold somewhere in your build pipeline and inject something that was not originally

03:42.320 --> 03:43.440
there.

03:43.440 --> 03:48.280
So another key component here besides generating the S-bomb and the provenance formation is

03:48.280 --> 03:53.840
really having some attestation around the integrity of the generated artifacts.

03:53.840 --> 03:58.720
So anyone should be able to cryptographically verify that at least what we're promised has

03:58.720 --> 04:04.120
not been tampered with and that the contents of the S-bomb were coming from an original

04:04.120 --> 04:06.480
author, etc., etc.

04:06.480 --> 04:10.320
And what's really important here is we need to have some clear assumptions around the

04:10.320 --> 04:15.280
threat model aka what can an attacker compromise and what are the security guarantees we're

04:15.280 --> 04:18.240
getting depending on that.

04:18.240 --> 04:23.360
So do we require the attacker say to compromise our build pipeline or do we require the attacker

04:23.360 --> 04:27.320
to get a foothold on developers boxes?

04:27.320 --> 04:29.660
What's our threat model?

04:29.660 --> 04:33.800
And that's really important because if we think about DevOps pipelines in practice you

04:33.800 --> 04:39.120
have many components like developers are pushing codes, that code ends up in some provider

04:39.120 --> 04:44.000
like GitHub or GitLab, you have open source packages, you have container images, you have

04:44.000 --> 04:48.160
infrastructure code that modifies this code and pushes it out and then somehow it ends

04:48.160 --> 04:50.560
up in the service or the cloud.

04:50.560 --> 04:54.560
And as we're building out all these graphs of components attackers could get a foothold

04:54.560 --> 04:56.200
at various places.

04:56.200 --> 04:58.840
So this is where Salsa comes in.

04:58.840 --> 05:05.840
Salsa is an open SSF project and essentially gives us some framework to talk about the

05:05.840 --> 05:08.600
security posture of our applications.

05:08.600 --> 05:14.160
And we have different levels for the supply chain security of our artifacts.

05:14.160 --> 05:19.040
At level one essentially all we're doing is we are providing information about how the

05:19.040 --> 05:24.280
package was built and have a report but we don't really have guarantees around the report

05:24.280 --> 05:26.520
whether it has been tampered with or not.

05:26.520 --> 05:29.440
At level two we get signed provenance.

05:29.440 --> 05:33.840
Essentially at this point we say okay once the thing has been generated there has not

05:33.840 --> 05:38.560
been tampering on that artifact but you don't get guarantees around the build platform etc.

05:39.560 --> 05:44.960
And as you move up the layers you get stronger and stronger security guarantees.

05:44.960 --> 05:48.800
So today we're going to be talking about chocking how easy it is to get to Salsa level

05:48.800 --> 05:51.880
two if you deploy chocking to your built pipelines.

05:51.880 --> 05:56.920
So how does one start to do this?

05:56.920 --> 06:01.600
This is good, we all want to improve the security posture of our applications, we want to deploy

06:01.600 --> 06:05.400
these things in our organization, how does one start to do it?

06:05.400 --> 06:10.800
One could think that okay that surely a solved problem there must be tools for this already

06:10.800 --> 06:16.480
and you're right to some extent but the tooling ecosystem is really in its infancy and it's

06:16.480 --> 06:18.920
largely fragmented at this point.

06:18.920 --> 06:24.360
So it's not necessarily obvious to a newcomer which tool or framework they should pick and

06:24.360 --> 06:29.680
even if you say select a space like S-Bombs the outputs of different tools are inconsistent

06:29.680 --> 06:30.680
with each other.

06:30.680 --> 06:36.440
One tool get a certain report, another tool get some different report and there might

06:36.440 --> 06:40.120
be assumptions around how these things should be getting set up, how you should be deploying

06:40.120 --> 06:45.000
all these things so it's not a straightforward way and what's really really hard is thinking

06:45.000 --> 06:47.000
about how can you do this at scale.

06:47.000 --> 06:52.160
If you have a large organization with multiple repositories, different providers, how do you

06:52.160 --> 06:58.080
make it easy for your teams to just set this and let it run and have it be easy to consume

06:58.080 --> 07:02.440
the data and also generate data that are of interest to you.

07:02.440 --> 07:08.600
So yeah it's not an easy problem and hopefully Chalk will help here.

07:08.600 --> 07:15.720
The main idea behind Chalk is really we have some metadata that we care about and then

07:15.720 --> 07:19.760
we want to embed that metadata that we call Chalkmarks into the artifact.

07:19.760 --> 07:23.920
So the artifact could be a binary or it could be a docker image and you want to embed this

07:23.920 --> 07:27.240
metadata into the artifact during the build time or post build time.

07:27.240 --> 07:33.200
So you could have an L file in a box and then you can inject metadata into that L file

07:33.200 --> 07:37.240
and say okay that was indeed here, you can have information that you care about like

07:37.240 --> 07:41.520
the security settings on that box like if a partner is enabled or what are the users

07:41.520 --> 07:47.840
or the network connections, you embed that metadata on it and now that artifact is tagged

07:47.840 --> 07:53.200
and once you have that tagged artifact you basically let it go and it gets deployed somewhere

07:53.200 --> 07:54.400
in production.

07:54.400 --> 07:59.000
So think of Chalk pretty much like air tags for your code so you embed the air tags and

07:59.000 --> 08:04.280
then you're tracking it across the ecosystem of your infrastructure and once the artifact

08:04.280 --> 08:11.600
actually gets executed what's interesting is you can get back reports with metadata

08:11.600 --> 08:13.360
that you configured there.

08:13.360 --> 08:20.000
So essentially you can scan what has been out there in production, you can grab for all

08:20.000 --> 08:23.760
this metadata that has been embedded in the artifacts or you could configure the artifacts

08:24.120 --> 08:29.480
some cases to phone home and give you the report themselves and you could do this once

08:29.480 --> 08:36.160
or you could do it periodically for instance configuring Chalk to send you heartbeat reports.

08:36.160 --> 08:38.800
So let's see this in action.

08:38.800 --> 08:47.680
I have set up here a very very basic git repository and this repository all it does is it deploys

08:47.680 --> 08:49.360
a lambda function.

08:49.360 --> 08:55.280
So we have the main code of the lambda function here and as you can see there's nothing really

08:55.280 --> 09:00.960
special to it, we just sleep and return it to 100k and we're building this lambda function

09:00.960 --> 09:05.960
using a docker file and there's nothing specific to Chalk in this docker file pulling from

09:05.960 --> 09:12.960
a well known image and we're actually building the lambda using a github action.

09:12.960 --> 09:19.200
So during the github action we check out the code, we set up the build environment and

09:19.280 --> 09:21.360
then here we're setting up Chalk.

09:21.360 --> 09:28.080
So we're telling our build ecosystem that Chalk should drop this build of the image

09:28.080 --> 09:32.840
and embed metadata on it and what sort of metadata we choose to embed is completely

09:32.840 --> 09:33.840
up to us.

09:33.840 --> 09:36.560
It comes like Chalk comes with defaults.

09:36.560 --> 09:40.640
So these are the only lines of code we ever need to do for our build pipeline so that

09:40.640 --> 09:47.720
Chalk can embed sbombs and actually use, you know, provide cryptographic guarantees around

09:47.760 --> 09:53.720
the integrity of the generated reports and we're also creating attestation manifests using

09:53.720 --> 09:58.600
SIGS-Tor for those of you who are aware of that framework.

09:58.600 --> 10:02.560
So cool, let's go ahead and trigger this.

10:02.560 --> 10:09.160
I'm going to go here in the action, kind of re-trigger the action once more and what

10:09.160 --> 10:14.480
we're doing here is we're building a docker image and we're telling Chalk to encapsulate

10:14.480 --> 10:17.240
the whole build and inject metadata in here.

10:17.240 --> 10:20.840
And that metadata, we can choose how we want to emit it.

10:20.840 --> 10:25.840
So we can choose to emit a report in there or the CLI or in some destination that we

10:25.840 --> 10:28.640
care like S3 or some server.

10:28.640 --> 10:32.440
So I have here a dummy server that's running and it's waiting for reports.

10:32.440 --> 10:35.960
There's nothing here currently.

10:35.960 --> 10:41.240
And I'm going to go back into one of the previous actions and show you a report that was emitted

10:41.240 --> 10:43.160
by Chalk on the CLI.

10:43.160 --> 10:48.360
So during the build, after we've actually pushed the image, you can see down here we

10:48.360 --> 10:54.720
have a Chalk report and this is basically a JSON file that has metadata that we care

10:54.720 --> 10:55.720
about.

10:55.720 --> 11:00.280
So here we know that some image could build, that was a daytime, that was a docker file

11:00.280 --> 11:05.560
path, the exact contents of the docker file, the commit ID, the author of the committer,

11:05.560 --> 11:12.200
but you also get a cryptographic signature about the integrity of this report essentially.

11:12.200 --> 11:16.600
You get interesting things like the environment variables, arguments.

11:16.600 --> 11:22.120
You can configure this to be however you like it.

11:22.120 --> 11:27.320
And this is generated on the CLI, but we can send the exact report, the exact same report

11:27.320 --> 11:31.480
or variance of that report in other destinations.

11:31.480 --> 11:39.880
So going back here to the action we just triggered, hopefully once this completes, we will be

11:39.880 --> 11:42.920
seeing a report populated to our server.

11:42.920 --> 11:51.720
So not only will we see a report here on the CLI, but we'll also get the metadata in the

11:51.720 --> 11:53.560
endpoint we configured.

11:53.560 --> 11:54.720
What could possibly go wrong?

11:54.720 --> 11:58.000
This is just a live demo here.

11:58.000 --> 12:02.720
So you can make this as fine-grained as you like.

12:02.720 --> 12:05.080
So Chalk supports plugins.

12:05.080 --> 12:10.800
So if you want to run, say, your static analysis tools like SemGrid or CodeQL, you can embed

12:10.800 --> 12:17.040
this metadata into the report as part of your regular other metadata that you're tracking.

12:17.040 --> 12:18.760
So it looks like this got finished.

12:18.760 --> 12:20.200
So we did get a report here.

12:20.200 --> 12:25.080
And if I go here, essentially we see that we got a build operation, so that got sent

12:25.080 --> 12:27.080
over to our server.

12:27.080 --> 12:31.040
And this is essentially just a pre-defined rendering of the JSON, right?

12:31.040 --> 12:36.920
You can send it wherever you see fit and render it however you would like.

12:36.920 --> 12:38.480
But we get some interesting information.

12:38.480 --> 12:42.040
We get some signal that we collected S-Bomb and Signing data.

12:42.040 --> 12:47.640
And indeed, if I scroll down here, I do see that I have the full S-Bomb.

12:47.640 --> 12:51.680
And I can fetch information about the attestation of the artifact.

12:51.680 --> 12:58.480
But I also get a bunch of interesting metadata that might not have been obvious just by seeing

12:58.480 --> 12:59.480
the build.

12:59.480 --> 13:02.640
So I see here CloudProvider is Azure.

13:02.640 --> 13:06.240
And we have information about the actual Azure instance metadata in which the build

13:06.240 --> 13:07.240
happened.

13:07.240 --> 13:14.440
So essentially what happens here is GitHub runs their machines on Azure in this particular

13:14.440 --> 13:15.440
instance.

13:15.440 --> 13:19.440
And so that build triggered in one of the Azure instances.

13:19.440 --> 13:20.440
So that's nice.

13:20.440 --> 13:22.320
We can also see the build command.

13:22.320 --> 13:26.000
And you can see here how the normal build command is now wrapped under Choc.

13:26.000 --> 13:32.760
So Choc is in charge of the build and embeds the metadata into your image.

13:32.760 --> 13:33.760
So that's nice.

13:33.760 --> 13:39.320
What we did do here is we pushed this demo lambda essentially.

13:39.320 --> 13:42.400
You can see this was modified just now.

13:42.400 --> 13:46.280
So I'm going to go ahead and execute the image.

13:46.280 --> 13:52.120
And hopefully, if things work as expected, the lambda will execute.

13:52.120 --> 13:54.240
And I'm going to get a second report here.

13:54.240 --> 13:56.960
And that second report is an exec.

13:56.960 --> 14:02.400
And if I zoom into the exec, you now see that the command that got executed is actually

14:02.400 --> 14:04.760
running within the lambda environment.

14:04.760 --> 14:09.200
So Choc is wrapping the entry point of the execution for that Docker image and tells

14:09.200 --> 14:13.760
you like, hey, this Choc mark that you inserted, the metadata that you've all captured is still

14:13.760 --> 14:17.120
here, but now I'm executing in lambda.

14:17.120 --> 14:23.360
And indeed, if I go here and see the Cloud metadata, you can see the region, the role

14:23.440 --> 14:27.440
they are in, the account ID, et cetera, et cetera.

14:27.440 --> 14:36.600
So with this, we can basically say the metadata that we injected in our build pipeline here

14:36.600 --> 14:39.880
is still present throughout wherever we deploy the image.

14:39.880 --> 14:42.800
And we can keep track of where the thing actually executes.

14:42.800 --> 14:48.880
So if I take into this Choc mark, I'm sorry, let me zoom out here.

14:48.880 --> 14:53.120
I can see that there's two reports essentially associated with this.

14:53.120 --> 14:56.920
One was a build and the other one was an exec for the exact same hash.

14:56.920 --> 15:01.880
So the exact same hash that I build in that machine has been executed in the other machine.

15:01.880 --> 15:04.600
So what did we do here?

15:04.600 --> 15:11.480
First of all, with four lines of YAML in our GitHub action, we generate and distribute

15:11.480 --> 15:13.680
the desktops.

15:13.680 --> 15:18.880
And we also have provenance information because we can track where the build happened and

15:18.880 --> 15:22.560
where the actual image got executed.

15:22.560 --> 15:24.360
And we also get artifact integrity.

15:24.360 --> 15:26.200
So in our case, we're using cosine.

15:26.200 --> 15:30.040
You could use different frameworks to do this.

15:30.040 --> 15:33.480
But essentially, we're meeting the basic requirements here.

15:33.480 --> 15:34.800
So we're checking those boxes.

15:34.800 --> 15:38.920
And that's with minimal effort, in my opinion.

15:38.920 --> 15:42.560
Like all you need to do is you need to configure whatever destinations you want for these

15:42.560 --> 15:44.720
reports to be sent.

15:44.720 --> 15:47.120
So you say, OK, that's cool.

15:47.120 --> 15:50.040
What more can you do?

15:50.040 --> 15:58.960
So let's think about typical scenarios that happen during kind of live production environments.

15:58.960 --> 16:01.760
You might be on call for a given service.

16:01.760 --> 16:04.160
And you get a page in the middle of the night.

16:04.160 --> 16:05.600
And there is some issue.

16:05.600 --> 16:06.720
There's a bug.

16:06.720 --> 16:08.280
There's a vulnerability.

16:08.280 --> 16:09.080
Something is off.

16:09.080 --> 16:12.840
And you want to figure out, OK, what's the component that's responsible for this?

16:12.840 --> 16:18.640
You could have, say, a pretty complex application with multiple teams pushing code.

16:18.640 --> 16:23.000
And for large organizations, usually the pattern for resolving these issues is you cut

16:23.000 --> 16:24.440
the tickets to the team.

16:24.440 --> 16:27.600
You wait for somebody else to be seen and be like, hey, that's the responsibility of

16:27.600 --> 16:28.600
that person.

16:28.600 --> 16:29.960
Potentially, you grab into code.

16:29.960 --> 16:31.400
You say, OK, what was the last commit?

16:31.400 --> 16:32.720
Or you have metrics.

16:32.720 --> 16:34.920
And you track from your metrics what chains.

16:34.920 --> 16:37.120
And you try to correlate it to somebody else.

16:37.120 --> 16:43.960
If you're using Chalk for your build pipelines, it's much, much easier to correlate what exact

16:43.960 --> 16:48.880
version of an image is running where and what the components are.

16:48.880 --> 16:51.160
And potentially, like, who are the code owners, et cetera.

16:51.160 --> 16:56.120
Because if we go back here, you see that we have things like the cometer and the commit

16:56.120 --> 16:57.960
ID.

16:57.960 --> 16:59.480
So we have the commit ID.

16:59.480 --> 17:05.960
You can start building these profiles about ownership incrementally as you go.

17:05.960 --> 17:11.200
So instead of having a process which could potentially take a couple of hours to determine

17:11.200 --> 17:19.680
the root cause of an outage or an issue, you now can have this in a few clicks, hopefully.

17:19.680 --> 17:24.400
Another common use case is application inventory and change management.

17:24.400 --> 17:29.880
So say, for instance, you're part of a large organization.

17:29.880 --> 17:31.320
You want to deprecate the framework.

17:31.320 --> 17:33.800
You want to deprecate, say, AngularJS.

17:33.800 --> 17:36.360
So AngularJS is running production.

17:36.360 --> 17:38.440
And you want to figure out, OK, what is the impact?

17:38.440 --> 17:39.840
How many teams are using it?

17:39.840 --> 17:42.360
Is the code even live?

17:42.360 --> 17:44.720
And what was the last time things got executed?

17:44.720 --> 17:48.920
You can figure out, you can get reports around these things.

17:48.920 --> 17:53.480
More importantly, you can see how applications change over time.

17:53.480 --> 17:58.840
So many of the people we've been talking to have processes where, for instance, they do

17:58.840 --> 18:00.720
a sort of change management meeting.

18:00.720 --> 18:03.840
Like, once a week, they say, OK, what has changed?

18:03.840 --> 18:05.960
What has been deployed?

18:05.960 --> 18:07.720
Do we need to go through a security review?

18:07.720 --> 18:09.800
What's the exact list of changes?

18:09.800 --> 18:13.840
And that process is manual to a large extent.

18:13.840 --> 18:17.680
Using Choc, you can automate this, because you can generate an exact report of the diff

18:17.680 --> 18:23.440
and you can get some integrity guarantees around that report.

18:23.440 --> 18:27.680
But more importantly, besides these things, you can do much, much more rightly.

18:27.680 --> 18:31.040
It's not necessary that you can only Choc containers.

18:31.040 --> 18:37.120
You can run essentially tools of your choosing, or you can submit custom plugins for metadata

18:37.120 --> 18:39.040
surfacing.

18:39.040 --> 18:44.640
And currently, the open source implementation that we have on GitHub only supports the entry

18:44.640 --> 18:49.520
pod wrapping for containers, but we're working to expand Choc functionality with more and

18:49.520 --> 18:50.520
more features.

18:50.520 --> 18:55.880
You can still Choc L files and PYC files and jars, et cetera.

18:55.880 --> 18:58.760
So yeah, the framework is out there.

18:58.760 --> 18:59.760
It's written in NIM.

18:59.760 --> 19:03.760
NIM is a very, very cool statically compiled type safe language.

19:03.760 --> 19:09.720
So any fans of NIM here, feel free to contribute.

19:09.720 --> 19:12.560
And we're welcoming feature requests.

19:12.560 --> 19:13.840
And I think that's my talk.

19:13.840 --> 19:20.840
I'm happy to take questions or discuss this.

19:20.840 --> 19:27.840
Thank you.

19:27.840 --> 19:34.840
Thank you.

19:34.840 --> 19:35.840
Yep.

19:35.840 --> 19:40.840
You talked about large organization.

19:40.840 --> 19:43.840
I'm very open to second.

19:43.840 --> 19:48.840
Yes.

19:48.840 --> 19:59.000
So the question here is I brought up large organizations, but given a concrete example

19:59.000 --> 20:03.520
of what are some use cases that this would apply in, right?

20:03.520 --> 20:08.840
So just to make this clear, this does not only apply to a larger, a small organization.

20:08.840 --> 20:10.480
It applies to everyone.

20:10.480 --> 20:16.000
It's just that if you are having a single application with a single repository, pretty

20:16.000 --> 20:19.640
much you know exactly what version is deployed where.

20:19.640 --> 20:25.200
The complexities of these situations start to be amplified the bigger and bigger you

20:25.200 --> 20:26.200
get, right?

20:26.200 --> 20:30.400
So if you have, say, a web application, and that web application has multiple components

20:30.400 --> 20:37.600
that are live at any given time, or say you have a distributed service and you have microservices

20:37.600 --> 20:43.640
running, you have multiple teams committing different versions of their component at any

20:43.640 --> 20:45.240
given time.

20:45.240 --> 20:48.600
And potentially some of these teams change.

20:48.600 --> 20:53.160
So you could end up with a repository having outdated code, right?

20:53.160 --> 20:57.880
There's a mission now, something has failed, and you go into the code, say, what was the

20:57.880 --> 20:58.880
last commit?

20:58.880 --> 21:00.560
It was six months ago.

21:00.560 --> 21:05.000
The committer of that application has left the team, potentially has left the company.

21:05.000 --> 21:07.440
Who do you contact?

21:07.440 --> 21:11.160
How do you know that's actually that part that has been outdated?

21:11.160 --> 21:18.360
But if you keep track of your builds and your executions, you have the ability now to tap

21:18.360 --> 21:24.040
into all the history of, like, all the provenance of a certain artifact and surface metrics

21:24.040 --> 21:25.040
that you care about.

21:25.040 --> 21:30.000
So if you cared about, say, show me all the components that haven't been updated in the

21:30.000 --> 21:35.640
last month or that haven't been executed the last month, it's way, way easier to do this.

21:35.640 --> 21:37.960
I'm not sure if I answered the question.

21:37.960 --> 21:38.960
Yeah.

21:38.960 --> 21:39.960
Yeah.

21:39.960 --> 21:47.960
So you showed how to do it in a GitHub action, but could you generalize and do this manually

21:47.960 --> 21:53.000
in a one-prime or in a different pipeline environment as well?

21:53.000 --> 21:54.000
Yes, yes.

21:54.000 --> 21:59.360
Chalk, you can actually, if you go now, if you visit the GitHub repo or the website, you

21:59.360 --> 22:01.000
can just download it.

22:01.000 --> 22:02.120
And it's a binary that runs.

22:02.120 --> 22:08.480
You can run locally and embed metadata into any artifact that you care about on your machine.

22:08.480 --> 22:14.300
So you can download on your laptop and scan all the L files in your system or the jar

22:14.300 --> 22:18.360
files or whatever, or even scan a whole directory.

22:18.360 --> 22:20.520
You can specify whatever you want.

22:20.520 --> 22:24.680
And then you can configure metadata that you care about, and these will be embedded there.

22:24.680 --> 22:26.240
And you can then extract it.

22:26.240 --> 22:29.660
So you don't necessarily need to have Chalk report back to you or run it in a GitHub

22:29.660 --> 22:31.160
action.

22:31.160 --> 22:36.120
You can just use it to embed information and then surface it.

22:36.120 --> 22:39.960
So you can both insert and extract if that makes sense.

22:39.960 --> 22:40.960
Yep.

22:40.960 --> 22:46.360
So that's a great question.

22:46.360 --> 22:53.880
I think one of the big benefits of Chalk is that you can embed information even in generated

22:53.880 --> 22:55.360
images or artifacts, right?

22:55.360 --> 22:59.800
So if you're using, say you have some third party software like a library that you're

22:59.800 --> 23:04.280
consuming, perhaps you don't know where it came from, but you know that you saw it in

23:04.280 --> 23:07.000
a certain machine at a certain hash.

23:07.000 --> 23:13.120
And then you can use Chalk to encapsulate that information for your artifact.

23:13.120 --> 23:18.240
And basically, if you run a query across all your applications that say are importing

23:18.240 --> 23:22.880
a given library, you can see all the versions of that library that are running.

23:22.880 --> 23:27.760
So you can start building these application inventories very easily, even if it's a third

23:27.760 --> 23:29.000
party software.

23:29.000 --> 23:33.000
Is it the total of the bottom third party container?

23:33.000 --> 23:34.440
It's still the same premise, right?

23:34.440 --> 23:39.400
Because if you have a container, you have several layers.

23:39.400 --> 23:44.040
So you can start saying, okay, these are the layers I have seen here.

23:44.040 --> 23:49.920
And potentially you don't have the full information, but you can at least ensure that you can attest

23:49.960 --> 23:53.240
that, okay, these are, this is the hash that I have seen.

23:53.240 --> 23:58.600
We are starting to add support to actually wrap entry points of different layers if you'd

23:58.600 --> 23:59.600
like to.

23:59.600 --> 24:03.880
So you should be able to interpose yourself in another layer should you like to, but

24:03.880 --> 24:05.680
that's not currently up yet.

24:05.680 --> 24:08.040
It's not up on the open source limitation.

24:08.040 --> 24:09.040
Yeah?

24:09.040 --> 24:13.040
How does Chalk play together with the useful bits?

24:13.040 --> 24:17.240
Are they to include them in the library?

24:17.240 --> 24:19.080
That's a great question.

24:19.080 --> 24:21.800
No, you don't need to include any compiler.

24:21.800 --> 24:24.000
All you need is the binary.

24:24.000 --> 24:27.840
And then if you have a reducible build for, in your pipeline, you should still be able

24:27.840 --> 24:29.520
to achieve the same guarantees.

24:29.520 --> 24:36.240
For instance, if you have, say, an L file, we'll embed metadata into a section and that

24:36.240 --> 24:38.320
will survive stripping and all that.

24:38.320 --> 24:44.840
So once you have a build, then assuming you know that you're running with Chalk, right,

24:44.840 --> 24:49.040
and you don't modify the thing later on inappropriately, you would at least know that you're running

24:49.040 --> 24:50.040
with Chalk, right?

24:50.040 --> 24:53.040
So that if you're getting a report, that report has not been tampered with.

24:53.040 --> 24:54.040
Yep?

24:54.040 --> 24:59.040
Let's imagine I have a jar which I have Chalk, right?

24:59.040 --> 25:04.040
Then I modify it and zip change it.

25:04.040 --> 25:09.040
So at which point Q and V8 and then I Chalk it again.

25:09.040 --> 25:12.040
At which point how do you pull the code?

25:12.040 --> 25:13.040
Right.

25:13.040 --> 25:17.320
So the question is, suppose you have a jar, you Chalk it, and then you modify it and then

25:17.320 --> 25:18.820
you Chalk it again.

25:18.820 --> 25:20.740
How does the tool help you here?

25:20.740 --> 25:25.700
So Chalk does not allow you to have just a single Chalk mark within a binary.

25:25.700 --> 25:30.500
You can wrap Chalk marks within Chalk marks within Chalk marks essentially.

25:30.500 --> 25:35.380
So if you're making modifications and you'd want it to, you can maintain past information

25:35.380 --> 25:37.020
about past Chalk marks.

25:37.020 --> 25:43.260
Or if you're building a jar, say, out of other jars and those have Chalk marks, you can use

25:43.260 --> 25:46.700
this information and embed them into your final jar, if that makes sense.

25:46.700 --> 25:50.700
So you can wrap and encapsulate all the metadata from all the components.

25:50.700 --> 25:54.700
So I need to focus more on this.

25:54.700 --> 25:58.140
Well it wouldn't be more complex than just saying Chalk insert.

25:58.140 --> 26:07.140
Like Chalk would take care of all the build dependencies and make sure it injects it automatically.

26:07.140 --> 26:10.100
At least that's where we're heading at.

26:10.100 --> 26:13.820
It might not be full feature for all the flavors of what can be choked currently, but that's

26:13.820 --> 26:20.820
where we want to go for sure.

26:20.820 --> 26:24.100
Cool.

26:24.100 --> 26:24.300
Thank you.

