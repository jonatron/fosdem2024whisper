WEBVTT

00:00.000 --> 00:02.000
Yeah, it's done.

00:02.000 --> 00:07.000
Yeah, well, we're about to start, so meet your Euro.

00:07.000 --> 00:08.000
Yeah, really.

00:08.000 --> 00:09.000
You're already on it?

00:09.000 --> 00:10.000
Really?

00:10.000 --> 00:11.000
I don't think so.

00:11.000 --> 00:12.000
Already on it?

00:12.000 --> 00:13.000
Yeah.

00:13.000 --> 00:14.000
You think it's on it, right?

00:14.000 --> 00:15.000
Yeah.

00:15.000 --> 00:16.000
It's on where do you want it?

00:16.000 --> 00:17.000
Thank you.

00:17.000 --> 00:18.000
Thank you.

00:18.000 --> 00:19.000
Thank you.

00:19.000 --> 00:20.000
Thank you.

00:20.000 --> 00:21.000
Thank you.

00:21.000 --> 00:22.000
Thank you.

00:22.000 --> 00:23.000
Thank you.

00:23.000 --> 00:24.000
Thank you.

00:24.000 --> 00:25.000
Thank you.

00:25.000 --> 00:26.000
Thank you.

00:26.000 --> 00:27.000
Thank you.

00:27.000 --> 00:28.000
Thank you.

00:28.000 --> 00:29.000
Thank you.

00:29.000 --> 00:30.000
Hi, everybody.

00:30.000 --> 00:38.000
My name is Shivam and I work for KDAB and I also work this summer, Google Summer of Code

00:38.000 --> 00:44.000
with LLVM, working on this project, this mapping LLVM values to the corresponding source level

00:44.000 --> 00:45.000
expressions.

00:45.000 --> 00:47.000
And, but why?

00:47.000 --> 00:51.000
So the challenge of understanding the compiler optimizations.

00:51.000 --> 00:58.000
So, so compilers are basically performing different sorts of optimizations and it's not

00:58.000 --> 01:03.000
always possible that it's going to be optimized or basically vectorized.

01:03.000 --> 01:09.000
So, we basically our motivation was vectorization for the first because we wanted to include

01:09.000 --> 01:13.000
those optimization remarks in for the vectorization part.

01:13.000 --> 01:15.000
So, our motivation was vectorization.

01:15.000 --> 01:16.000
So, it's not always possible.

01:16.000 --> 01:19.000
So, your compiler can always vectorize your code.

01:19.000 --> 01:24.000
So, there's some sort of data dependencies there where that's why your compilers cannot

01:24.000 --> 01:26.000
actually vectorize all the time.

01:26.000 --> 01:33.000
So, on that cases you have to emit a good remarks and I'll let you know what currently

01:33.000 --> 01:35.000
clang actually generates as a remark.

01:35.000 --> 01:41.000
So, understanding why and how these optimization occurs is not always straightforward.

01:41.000 --> 01:47.000
Even the authors or vectorizer don't know what's going on if the vectorization didn't

01:47.000 --> 01:48.000
happen.

01:48.000 --> 01:50.000
So, consider this example.

01:50.000 --> 01:56.000
So, you can see there is a data dependencies between A of i and A of i plus 3.

01:56.000 --> 02:01.000
So, this loop clang will not be not able to vectorize this code.

02:01.000 --> 02:02.000
Okay.

02:02.000 --> 02:09.000
So, see this remark that produced with the clang which is that loop not vectorize.

02:09.000 --> 02:11.000
You can use pragma loop distribute.

02:11.000 --> 02:16.000
So, you can compile the tries to distribute the loop and it might be able to vectorize

02:16.000 --> 02:17.000
in some sense.

02:17.000 --> 02:19.000
But, just see the remarks.

02:19.000 --> 02:24.000
It's not clear that what actually gone wrong here and where's the data dependency.

02:24.000 --> 02:29.000
It's not telling you that where's the data dependency actually was and so you can improve

02:29.000 --> 02:30.000
the code itself.

02:30.000 --> 02:31.000
Right.

02:31.000 --> 02:36.000
So, it just that remarks and you can see this not actually clear.

02:36.000 --> 02:37.000
Right.

02:37.000 --> 02:46.000
So, it's a bit unclear and if you can have such this remarks nothing much just two expressions

02:46.000 --> 02:49.000
are the dependent source and the dependence destination for example.

02:49.000 --> 02:56.000
So, you know that okay there is a data dependencies between two to these two locations and so

02:56.000 --> 03:00.000
if you are aware of the code so you are going to modify your code and you might be able

03:00.000 --> 03:06.000
to modify in the way so you know that it will be possible for the compiler to vectorize

03:06.000 --> 03:07.000
now.

03:07.000 --> 03:12.000
So, you can modify the code by looking at this these expressions for example.

03:13.000 --> 03:20.000
So, yeah so it's going to surely enhance the remarks include the exact so if it includes

03:20.000 --> 03:26.000
the exact source and destination of the dependencies within the error for example and it will pinpoint

03:26.000 --> 03:34.000
the lines of those dependencies and let's look at the impact of these enhanced remarks

03:34.000 --> 03:39.000
so it would be clarity for the developers so they can quickly look where the dependencies

03:39.000 --> 03:49.000
are actually occurring and so they can improve their code and probably make it vectorizable

03:49.000 --> 03:54.000
and efficiency in the terms of that they can save time and improve efficiency by reducing

03:54.000 --> 03:59.000
the need for the deep debugging that where was the actual data dependencies so you can

03:59.000 --> 04:04.000
just look at the optimization remarks and you get the quite a lot of information that

04:04.000 --> 04:09.000
okay there is the data dependencies between two load and stores.

04:09.000 --> 04:17.000
So, let's look at the approach that we took for solve this problem or this project so

04:17.000 --> 04:23.000
approach was very simple to just utilize the debug information that available into the

04:23.000 --> 04:29.000
intermediate representation right so to recreate the variable and the function names lost during

04:29.000 --> 04:36.000
the optimization so the optimizations are actually a problem in our case because we

04:36.000 --> 04:44.000
currently don't know how to build those for example instructions that's lost into the

04:44.000 --> 04:50.000
optimization for example so if you see a multiplier if you see a MUL instruction in the IR so

04:50.000 --> 04:58.000
compiler might optimize that into shift left so the MUL was the original information that

04:58.000 --> 05:03.000
was actually available in the source code but right now we have shift left so we just

05:03.000 --> 05:07.000
lose the context that what was the actual source level information so that's still a

05:07.000 --> 05:15.000
problem for us and we have different approach for that but we didn't see to be so we see

05:15.000 --> 05:24.000
that it was not much a performance good so it was very bad so we wanted to clone the

05:24.000 --> 05:32.000
module so we have so we can look that what's happened after each optimizations so we can

05:32.000 --> 05:40.000
have the clone of the original IR and we can see that what's going on after every pass

05:40.000 --> 05:46.000
of optimization or every implementation passes so if you look at the different transformation

05:46.000 --> 05:53.000
pass and you have to look over that what's the thing that gets changed and anything that

05:53.000 --> 05:58.000
you have stored that okay there was the original instruction as MUL but right now it gets

05:58.000 --> 06:04.000
changed to shift left so you see that okay the MUL gets changed to shift left so you

06:04.000 --> 06:11.000
have to cache the expressions basically to reload the things in a new way so if there is

06:11.000 --> 06:20.000
no need for that so we will proceed after it so let's see how to utilize that information

06:20.000 --> 06:27.000
that available in the IR so LLVM uses a small set of infernsic functions if you are aware of so

06:27.000 --> 06:35.000
those are provided for the debug information so they contains different metadata so they have

06:35.000 --> 06:45.000
different arguments so these infernsic functions are named prefixed by this LLVM.debug

06:45.000 --> 06:51.000
and these things helps you to track the variables through the optimizations and code

06:51.000 --> 06:58.000
generation so if you look in the IR so if you dump your IR with the dash G symbol so you will

06:58.000 --> 07:06.000
get to know about the LLVM.debug.value or .declare so those contains everything related to the

07:06.000 --> 07:12.000
source level things so they contains the metadata information and the metadata are there for that

07:12.000 --> 07:19.000
so they can give you a lot more information about what was actually in the source so for example

07:19.000 --> 07:25.000
like variable names so when you trace the metadata so you can get the variable name from the actual source

07:25.000 --> 07:35.000
so for us these two infernsic functions were very important the debug.declare and the debug.value

07:36.000 --> 07:48.000
and let's try to understand a bit so if you can see the I is allocated and just below it you can see

07:48.000 --> 07:55.000
the call to the infernsic function which is .debug.declare and these you can see the three arguments

07:55.000 --> 08:03.000
in the infernsic function the first represents the first will always represent the address of the variable

08:03.000 --> 08:10.000
the second metadata always pointing to the for example you can see the DI local variable

08:10.000 --> 08:16.000
so which contains this is a metadata node and it contains the variable name so what was the actual name

08:16.000 --> 08:21.000
so you can see the actual name was I in the actual source expression so you can when you

08:21.000 --> 08:29.000
trace back the information so you can retrieve the name so these are these infernsic functions

08:29.000 --> 08:36.000
so the second can really help us a lot and the second was actually the source just the source

08:36.000 --> 08:43.000
information like name and the third argument is DI expression and generally DI expression is useful

08:43.000 --> 08:50.000
as a complex expression so you have expressions like for example int a is equals to b plus c

08:51.000 --> 09:00.000
a DI expression can hold that stuffs yeah and yeah so debug declare is used for that and the second

09:00.000 --> 09:08.000
is debug.value so .value is very similar to it it's just that when I is gets updated when a value is updated

09:08.000 --> 09:15.000
so debug value can up and so everything goes in the debug value for the same

09:16.000 --> 09:24.000
so we now have enough information to at least give a try to build the source expressions and only if the code is

09:24.000 --> 09:30.000
compiled with the debug info on so it's compiled using the dash g symbol

09:32.000 --> 09:41.000
so we use the we are infernsic as a bridge so our focus was on memory access and vectorization as I said

09:42.000 --> 09:52.000
so importance of the memory access pattern is so we really want this project for vectorization at first

09:52.000 --> 10:00.000
and then we also have a plan to give it a push into the debugger so debuggers can utilize this information

10:00.000 --> 10:09.000
to provide better remarks but the main goal initially was the vectorization pass

10:10.000 --> 10:16.000
vectorization is a transformation pass so a transformation pass can always query an analysis pass

10:16.000 --> 10:24.000
and what our work is our work was an analysis pass so this vectorization pass in LLVM can always query the

10:26.000 --> 10:35.000
analysis pass this transformation pass okay so project contribution is actually that we have we have

10:35.000 --> 10:45.000
built an analysis pass that can generate these mappings and provides a better remarks for the case of

10:45.000 --> 10:53.000
vectorization or any other things that requires it let's look at the implementation detail

10:55.000 --> 11:00.000
so for us the point of interest is load and store instruction because of the vectorization

11:01.000 --> 11:08.000
because we want to analyze the memory access patterns to actually emit in the vectorization so which is useful for the remark

11:09.000 --> 11:22.000
and for example just take a look at this C code and if you compile this with clag or to dash g and if you emit the LLVM

11:22.000 --> 11:32.000
just for showing you that what's going on so I think it should be visible so you can see the call to

11:32.000 --> 11:43.000
in intrinsic functions debug.7 so we can build these expressions from them so as I said so if you look these were

11:43.000 --> 11:58.000
the first is to multiply n1 but and we compile it with the optimization on so the multiply instruction gone away and it just updated by

11:58.000 --> 12:12.000
shift lift operator okay so that's why you can see the shift lift operator here and not multiply so that's a problem so that's

12:12.000 --> 12:19.000
a problem of accuracy of the expressions because we still not have a good plan of how to accurately generate the expressions

12:19.000 --> 12:30.000
because a lot many times these things gone away because of the optimizations on and it's always been a hard problem of how to actually debug

12:30.000 --> 12:38.000
in the case of when optimizations are actually gone so it's a classic problem which we still have to look so you can see the

12:39.000 --> 12:50.000
we can build these expressions from the instructions so yeah you can see this from example that computing the equivalent source expressions

12:50.000 --> 12:58.000
of interest will involve walking through the LLVM IR and using the information that provided in the debug in forensics

12:59.000 --> 13:09.000
so even though our current interest is load and store but we still have to build for every instructions because those load and store

13:09.000 --> 13:17.000
can contain any sort of an instruction when you trace back to them it's maybe any binary instruction it contains gap instructions

13:18.000 --> 13:29.000
so it might be contain any instructions and we have to we still have to build for them too and as I said that optimizations

13:29.000 --> 13:38.000
make it impossible to recover the original source expressions so as you see that for example the 2 into N1 is optimized to N1

13:38.000 --> 13:44.000
left shift 1 so which is recovering the original expression may not be possible every time

13:47.000 --> 13:55.000
so let's look at how we proceed it's just a basic algorithm that I just want to go through so we started by traversing the IR

13:55.000 --> 14:04.000
so we have we started with the traversing the IR we identify the operations that were there for example load and store

14:04.000 --> 14:11.000
source or main so current interest is load and store instructions so specifically look for those instructions in the IR

14:11.000 --> 14:21.000
and then trace those operands it might be any other instructions it might be inside any metadata so we can retrieve any information like name

14:21.000 --> 14:32.000
and utilizing those metadata information building the source expressions and then we reconstruct the expressions

14:32.000 --> 14:45.000
with all the information that we get so that's a bit all but just look at the current state so it's still not yet upstream to LLVM

14:45.000 --> 14:54.000
the PR is here so what I need from you or anyone you have experience or anyone you have active in that zone of optimizations

14:54.000 --> 15:06.000
or for example analysis passes or transformation passes in LLVM so I do like you to have a look at the patch if you have some experience try to review the code as well

15:06.000 --> 15:20.000
and give some feedback so we can proceed with much detail because it's still it's still a new analysis and still need a lot of work for struct as well

15:20.000 --> 15:29.000
so as I mentioned we need more review on the patch and some active work from me as well and if any of you interested please reach out

15:29.000 --> 15:39.000
and as I said the struct pose a unique challenge to when we try to build the expression for struct for example it was not quite easy

15:39.000 --> 15:47.000
it was very difficult to build the expression for struct because they pose a unique challenge if you see them in the intermediate representation

15:47.000 --> 16:00.000
it's very weird to look at them because I don't know how they actually gets there in the IR how they represent it it's not as simple as the giving expressions for an array

16:00.000 --> 16:11.000
so struct is still a problem accurate source level expression in case of optimization it's still a problem and there isn't always one to one mapping between the source code and IR

16:11.000 --> 16:24.000
so if you see that we still don't know what to do in these cases if you see there's a pointer and the PTR 0 so IR can generate the same code for these two patterns

16:24.000 --> 16:38.000
and we don't know which have to pick so that's still a problem one solution for this was that debug information also contain the information about the file

16:38.000 --> 16:50.000
so there is a DI file in the debug info so what was actually we were discussing is so we have still information about the file path

16:50.000 --> 17:00.000
so what we can do is we can actually open the file and just go on that line and retrieve the information what was the actual ground truth just look at that

17:00.000 --> 17:08.000
second thing was fall back and anything because we don't know what was there so just fall back to any of them

17:08.000 --> 17:20.000
so but the DI file was actually quite easy but it's not good performance wise if you see open the file and just retrieving just going on that line and retrieving that

17:20.000 --> 17:28.000
so it's not good performance wise so yeah that's it for the talk and thank you for listening and if you are interested in letting

17:28.000 --> 17:38.000
knowing more about this project and the algorithm please reach out to me on mail or for example discord so yeah thank you

17:38.000 --> 17:42.000
any questions

17:42.000 --> 17:45.000
yes

17:45.000 --> 17:56.000
why do you need to rebuild the entire sequence of expressions for each of the values

17:56.000 --> 18:07.000
why not the specific value of the value it is what the dependencies and the production line from the file just like after a year ago

18:07.000 --> 18:10.000
can you just free us the question

18:10.000 --> 18:19.000
so you know like when you admit after marks there's a tool called the operator that just put everything in line

18:19.000 --> 18:34.000
so between that and what you have here it seems that you know you would get excellent results in terms of debubbability if you just did what the operator does

18:34.000 --> 18:47.000
plus you specify which of the values are causing the dependence that what you said and what the reason for the failed optimization

18:47.000 --> 18:54.000
okay so the question is basically about using opt viewer right

18:54.000 --> 19:01.000
yeah I was just admitting a more limited view as you have here and not trying to reconstruct everything

19:01.000 --> 19:12.000
so we still not reconstructing everything for example so we still we still not focusing on creating whole I at or just mapping whole I at the expressions

19:12.000 --> 19:20.000
we still focusing on those loads and stores as I said so we still focusing on that right

19:20.000 --> 19:33.000
yeah yes yes yes

19:33.000 --> 19:42.000
yeah so we we still we still picking up the load and stores so if we see that is there any gap instructions because gap instruction actually contains a chain of instructions

19:42.000 --> 19:57.000
so so but we still have to build the loop for loads and stores and opt viewer still not good at emitting those remarks it's still very abstract in that sense if I remember it correctly

19:57.000 --> 20:07.000
so I'm not sure how to go with opt viewer but we still making it for load and stores and tracing back the information

20:07.000 --> 20:14.000
yeah yep

20:14.000 --> 20:23.000
yeah yes

20:23.000 --> 20:26.000
nope

20:26.000 --> 20:31.000
nope

20:31.000 --> 20:51.000
not sure but one thing I can guess that so basically opening a file is not something which is very good performance wise and and just choosing and just going on that line down because you can see that there could be a multiple lines of code in code base

20:51.000 --> 21:01.000
so you have to go on that particular line so it would need it would need it would be very bad in performance was I think

21:01.000 --> 21:03.000
okay

21:03.000 --> 21:27.000
and there is no and there is no theory about if it would be more beneficial to tell the programmer the error that or the sub optimal choice that you made was between line 27 28 compared to generating some arbitrary complex expression that might not be representative of what the program originally wrote

21:27.000 --> 21:34.000
I'm not sure

21:34.000 --> 21:41.000
okay

21:41.000 --> 21:45.000
okay

21:45.000 --> 22:04.000
yeah I think it would be fine then if you if you're choosing for emitting a remarks then then you know that this is not good performance right so if you want to look at the performance if you want to look at the actual correct remarks so you have to going deep in the performance

22:04.000 --> 22:23.000
thing then yeah then it would be possible and we have also we also talking about preserving the metadata in LVM as they go through but but in LVM metadata is designed in a way so we can drop we can drop at any time so we still cannot preserve the metadata information

22:23.000 --> 22:32.000
so it's still a challenge this lot move what going on on this side so yeah

23:02.000 --> 23:08.000
yeah

23:08.000 --> 23:12.000
yeah

23:12.000 --> 23:18.000
okay

23:18.000 --> 23:21.000
yeah

23:21.000 --> 23:23.000
thank you

23:23.000 --> 23:26.000
yeah

23:26.000 --> 23:33.000
okay

23:33.000 --> 23:38.000
thank you for joining when you leave make sure to take everything

23:38.000 --> 23:43.000
yeah

23:43.000 --> 23:47.000
yeah

23:47.000 --> 23:51.000
yeah

23:53.000 --> 23:56.000
yeah

