WEBVTT

00:00.000 --> 00:14.640
We're trying to get some fresh air into the room as well.

00:14.640 --> 00:16.640
Have to be creative.

00:16.640 --> 00:24.240
Okay, we'll get started with the next speaker now.

00:24.240 --> 00:27.960
Anthony is going to talk about productizing Jupiter notebooks.

00:27.960 --> 00:37.600
Please welcome the speaker.

00:37.600 --> 00:40.880
Hello, nice to meet you everyone.

00:40.880 --> 00:52.600
Yes, my name is Anton.

00:52.600 --> 00:54.920
Hello, hello, hello.

00:54.920 --> 00:55.920
Okay.

00:55.920 --> 01:03.680
So, as I was saying, I'm a software engineer programmer and I've been working on data engineering

01:03.680 --> 01:09.720
and data, disability data processing projects for the past 10 years in VMware.

01:09.720 --> 01:14.840
I'm glad that VMware decided to open source, invest in open sourcing for Stout Data Kids

01:14.840 --> 01:15.840
for the past three years.

01:15.840 --> 01:20.600
I've been focusing on maintaining and developing open source projects.

01:21.200 --> 01:31.040
Today, I'm going to talk about the challenges in productionizing Jupiter notebooks and show

01:31.040 --> 01:36.400
some possible solutions to those challenges using Stout Data Kids.

01:36.400 --> 01:38.400
So let's get started.

01:38.400 --> 01:47.200
You have been using Jupiter notebooks, if you can raise your hand.

01:47.200 --> 01:49.200
It's 20%.

01:49.200 --> 01:51.200
Hello.

01:51.200 --> 01:53.200
Okay.

01:53.200 --> 01:58.200
So, if you're a CEO, hello.

01:58.200 --> 01:59.200
Okay.

01:59.200 --> 02:02.440
A CEO at Jupiter notebooks are really versatile too.

02:02.440 --> 02:11.240
It helps a lot in terms of doing experiment, exploratory data analysis, POCs, like, things

02:11.240 --> 02:18.240
like, okay.

02:18.240 --> 02:21.240
Hello.

02:21.240 --> 02:32.240
Is it working now?

02:32.240 --> 02:34.240
Okay.

02:34.240 --> 02:41.240
So, with Jupiter, you can do a lot of things because it allows you to mix documentation

02:41.240 --> 02:46.240
with markdown, with visualizations, and also code in different languages.

02:46.240 --> 02:52.240
Still, there's quite a bit of struggle that you don't really deploy your notebooks directly

02:52.240 --> 02:53.240
in production.

02:53.240 --> 03:00.240
Most likely, you can correct me, but from my experience, you'll be redoing this using

03:00.240 --> 03:07.240
some kind of Python scripts or other type of applications of framework and not directly

03:07.240 --> 03:12.240
in the production, which is a bit of a double work often because you do experiments in

03:12.240 --> 03:18.240
notebooks and then you do actual productionizing separately.

03:18.240 --> 03:22.240
The other tool, generally, I'm going to talk about is for Stout Data Kids.

03:22.240 --> 03:24.240
So I'm going to quickly introduce it.

03:24.240 --> 03:28.240
For Stout Data Kids, it's an ETL framework, or EOT framework, depending on how you want

03:28.240 --> 03:29.240
to use it.

03:29.240 --> 03:37.240
It provides you with an SDK, which allows you to write basically steps and those steps.

03:37.240 --> 03:40.240
You can ingest data or process data.

03:40.240 --> 03:45.240
There are abstractions that make this a lot easier.

03:45.240 --> 03:47.240
So this is just Python.

03:47.240 --> 03:49.240
So you can install it with Python.

03:49.240 --> 03:54.240
And separately, there is control plane operations UI, which is the server part optional.

03:54.240 --> 03:58.240
That can be installed on top of Kubernetes.

03:58.240 --> 04:10.240
So let's now dive into Jupyter and what are the challenges to productionizing.

04:10.240 --> 04:12.240
So I've listed here five challenges.

04:12.240 --> 04:20.240
Though that's not exhaustive list, there's some of the most prevalent one in productionizing

04:20.240 --> 04:22.240
and using notebooks in production.

04:22.240 --> 04:25.240
I'm going to go over each one.

04:25.240 --> 04:31.240
I'm going to explain what I understand, the challenges, and then I'm going to show what

04:31.240 --> 04:35.240
a possible solution to that challenge is.

04:35.240 --> 04:40.240
So let's start with the first one.

04:40.240 --> 04:42.240
Reproducibility, right?

04:42.240 --> 04:49.240
So it's in this example, let's say that you have a notebook where you want to develop

04:49.240 --> 04:50.240
in three different cells.

04:50.240 --> 04:55.240
The first cell in the notebook, you set some variable to zero, then increment it, and then

04:55.240 --> 04:57.240
you print it.

04:57.240 --> 05:01.240
What would the result you would expect at the third cell?

05:01.240 --> 05:03.240
I imagine one.

05:03.240 --> 05:10.240
And that's what you would expect if this notebook is being run in production in an automated

05:10.240 --> 05:13.240
self-sufficient way.

05:13.240 --> 05:18.240
But that's not necessarily the result you do during development, right?

05:18.240 --> 05:23.240
It's quite possible that the user can execute the second cell twice.

05:23.240 --> 05:29.240
In this case, the result would be two.

05:29.240 --> 05:36.240
It's also possible that you execute the second cell, change the second cell after executing it.

05:36.240 --> 05:43.240
In this case, your result, if you deploy this job in automated pain production, wouldn't be one,

05:43.240 --> 05:45.240
as it's currently.

05:45.240 --> 05:47.240
It's possible to remove the cell.

05:47.240 --> 05:53.240
But because the notebooks run in state, again, the variable is one, and every call after

05:53.240 --> 05:58.240
it, it assumes it's one, even though if you deploy it in a scheduled automated way, it

05:58.240 --> 06:00.240
no longer be so.

06:00.240 --> 06:09.240
This means that notebooks are not really reproducible, and that you can start developing

06:09.240 --> 06:14.240
in a state that's diverging from one that will be in production.

06:14.240 --> 06:22.240
So what is that is clear trouble, because things may seem to work locally, and then when

06:22.240 --> 06:28.240
you deploy your job or notebook in production, all of a sudden things break.

06:28.240 --> 06:37.240
So what we can do, one thing, for example, we can do is with VDK, what we've thought of

06:37.240 --> 06:41.240
is the concept of, let's say that we have this kind of notebook, right?

06:41.240 --> 06:46.240
And we want to have a predictable way of which the execution is done.

06:46.240 --> 06:54.240
In VDK, we can mark certain cells as production ready and mark them in the order which they

06:54.240 --> 06:57.240
will be executed, which is top-down noise.

06:57.240 --> 07:01.240
So we have created a visual way that the first cell is executed first, the second, second,

07:01.240 --> 07:02.240
the third, third.

07:02.240 --> 07:07.240
If our state, which is on the left side, the current execution order is different than

07:07.240 --> 07:09.240
the one that's expected.

07:09.240 --> 07:18.240
We can issue warnings, and this allows also to smoke testing before deployment, your

07:18.240 --> 07:20.240
notebooks.

07:20.240 --> 07:26.240
It shows the predict exactly the order that you'd expect the cells to be executed.

07:26.240 --> 07:32.240
This is done by, there will be different ways, but for now this is done by setting

07:32.240 --> 07:40.240
a tag called VDK for each cell that you want to be running production.

07:40.240 --> 07:47.240
The order is always top-down.

07:47.240 --> 07:55.240
This solves some of, helps solve some of the problem by providing this kind of

07:55.240 --> 08:02.240
determined sequence in executing order of the cells, while it potentially detects

08:02.240 --> 08:09.240
divergence, and we'll see later it allows to test easier.

08:09.240 --> 08:14.240
The second challenge I want to speak about is code organization.

08:14.240 --> 08:21.240
Overall, in the notebooks, you expect to have quite a bit of irrelevant or maybe debugging

08:21.240 --> 08:22.240
code.

08:22.240 --> 08:27.240
That might be useful during development, but it's not something that you want to run during

08:27.240 --> 08:31.240
production in an automated scheduled manner.

08:31.240 --> 08:36.240
Like this very simple example, the first two cells import pandas and read CSV, and the

08:36.240 --> 08:38.240
third visualizes it.

08:38.240 --> 08:42.240
We can say that this is most likely relevant for your workflow, and this is something that

08:42.240 --> 08:48.240
you want during development, or if you want to share the notebook with a colleague.

08:48.240 --> 08:52.240
This is again, could be helped with VDK tags.

08:52.240 --> 08:57.240
As VDK tags, you talk only the cells that are relevant, and you think that they're going

08:57.240 --> 09:01.240
to need to be deployed in turn on schedule manner in production system.

09:01.240 --> 09:07.240
All the other cells will be completely ignored when the notebook is being executed.

09:07.240 --> 09:15.240
Like in this example, the first, second, and the third cells, which are on the right side,

09:15.240 --> 09:21.240
are covered in blue, will be expected to be executed in production, and we don't need

09:21.240 --> 09:32.240
the debugging code that's simply checking the data frame or visualizing being skipped.

09:32.240 --> 09:38.240
The third challenge I'm going to talk about is the execution model.

09:38.240 --> 09:44.240
In notebooks, generally, you have much more complex execution model.

09:44.240 --> 09:51.240
This is necessary because of the way the notebook needs to keep state and the way you want to

09:51.240 --> 09:56.240
be able to use multiple languages, but those kind of execution models are really bad for

09:56.240 --> 09:59.240
automation, or using notebooks as part of a workflow.

09:59.240 --> 10:07.240
They add a lot of extra work on top of this, and in order to execute your Python code,

10:07.240 --> 10:13.240
you need to go through a notebook server to the Ipython kernel, for example, if it's Python,

10:13.240 --> 10:15.240
and so on.

10:15.240 --> 10:18.240
Usually, the way you want things in production is much simpler.

10:18.240 --> 10:23.240
You have a Python script, and it executes on top of Python, or SQL script, and executes on top of

10:23.240 --> 10:25.240
some SQL, and that's it.

10:25.240 --> 10:29.240
You don't have a lot in the middle.

10:29.240 --> 10:35.240
Because with VDK, if you can extract exactly those kind of Python pieces and construct your

10:35.240 --> 10:41.240
Python script or SQL pieces, we can do the same thing, which is what VDK does.

10:41.240 --> 10:48.240
So when VDK executes a notebook, it basically would extract the Python and the SQL pieces and

10:48.240 --> 10:50.240
directly execute them.

10:50.240 --> 10:56.240
This would enable us to do things like reuse another notebook as a template, or almost as a

10:56.240 --> 11:00.240
function, in a similar way like this one.

11:00.240 --> 11:02.240
Let's say that we have a...

11:02.240 --> 11:08.240
This is some kind of job, or Python script, and we are going to execute another notebook,

11:08.240 --> 11:15.240
process notebook, Jupyter notebook, almost as a function with arguments and so on.

11:15.240 --> 11:22.240
You can also execute it within a workflow, and you can run automated tests, which will show how you

11:22.240 --> 11:27.240
can do that in a little bit, which is...

11:27.240 --> 11:33.240
Which goes to the fourth challenge that I want to talk about, and it is automated testing.

11:33.240 --> 11:36.240
You can see a CD.

11:36.240 --> 11:41.240
There is no doubt that automated testing overall, we were able to have a CD pipeline, it's

11:41.240 --> 11:45.240
cornerstone of having reliable software nowadays.

11:45.240 --> 11:50.240
Jupyter notebook do not really easily lend themselves to this kind of traditional testing

11:50.240 --> 11:57.240
paradigms, and also really vital if you want to push code to production, and make sure that

11:57.240 --> 12:03.240
any changes to be done, don't break out and things work as expected.

12:03.240 --> 12:10.240
In Jupyter notebook, there has been some attempts to solve this, and it has been quite a bit of a

12:10.240 --> 12:12.240
challenge.

12:12.240 --> 12:18.240
With VDK, we will be attempting as well.

12:18.240 --> 12:24.240
One of the things that you can do, because the pre-determined order that VDK tagging provides,

12:24.240 --> 12:30.240
and the fact that you can mark which cells need to be executed, and the fact that VDK

12:30.240 --> 12:37.240
skips a lot of the kernel and extra in the execution model, means that with VDK you can

12:37.240 --> 12:45.240
use command, for example, VDK run, which is provided in a Jupyter notebook with the VDK plugin,

12:45.240 --> 12:49.240
which will execute the job as it is supposed to be executed in production.

12:49.240 --> 12:55.240
One by one, each of the cells in the order that you expect them to be.

12:55.240 --> 13:02.240
Another, of course, you can also do this with CommonWide interface using CLI.

13:02.240 --> 13:13.240
Beyond that, if you end up using the control plan, which is the part that you deploy the job in production,

13:13.240 --> 13:19.240
the integration with the notebook UI would make it sure that if you create new deployment,

13:19.240 --> 13:26.240
it will prompt you to run basically end-to-end smoke test, the data job, as it's called,

13:26.240 --> 13:33.240
the notebook files, and to make sure that they execute correctly.

13:33.240 --> 13:40.240
Finally, because this notebook can be used practically as a function, that means that now you can test them

13:40.240 --> 13:44.240
using Python PyTest.

13:44.240 --> 13:51.240
You can write PyTest tests, the survivor code, VDK test, that helps with that,

13:51.240 --> 13:54.240
in which you specify your dependencies through plugins.

13:54.240 --> 14:04.240
For example, you can specify dependencies like SQL databases, it could be HTTP servers and so on,

14:04.240 --> 14:06.240
on a way sort of to mock them.

14:06.240 --> 14:11.240
For example, using PyTest HTTP server if you want to mock an HTTP API.

14:11.240 --> 14:20.240
You can verify the results after the notebook is executed.

14:20.240 --> 14:29.240
This is the link over here about different cases that can be used with PyTest and notebooks.

14:29.240 --> 14:37.240
This is pretty powerful because it allows you to actually be able to run automated tests of all your code

14:37.240 --> 14:41.240
that you want to productionize the notebook.

14:41.240 --> 14:49.240
Finally, another potential issue with notebooks is version control challenges.

14:49.240 --> 14:54.240
A notebook file tends to be this kind of JSON structure when you put it in version control,

14:54.240 --> 15:05.240
which contains all kinds of extra fields, including output and so on, which generally you want to clean.

15:05.240 --> 15:08.240
This is something that will style data kit and deployment.

15:08.240 --> 15:17.240
When you deploy data job to be in some kind of managed environment, it can strip all the necessary parts.

15:17.240 --> 15:24.240
Instead of having this kind of diff, maybe where the only relevant information really is just the source,

15:24.240 --> 15:32.240
the last three lines, you can have this diff, which is where you show run job input, right?

15:32.240 --> 15:37.240
There are actually no changes in this diff, despite what it appears.

15:37.240 --> 15:45.240
Those are the five challenges and potential solutions that I wanted to share with you.

15:45.240 --> 15:53.240
There's this kind of self-paced tutorial that's showing some of the things that I've shown,

15:53.240 --> 16:00.240
how it can be used and done, so you can actually try out your self-ings.

16:00.240 --> 16:06.240
Overall, if you'd like to discuss more about do you think those kind of challenges,

16:06.240 --> 16:13.240
reproducibility, co-organization, execution model, automated testing are really relevant for your use for notebooks?

16:13.240 --> 16:17.240
Do you think the solutions make sense? Do you see any other challenges that are important?

16:17.240 --> 16:25.240
I'll urge you to contact me. I'll be happy to talk about it. You can do this through LinkedIn.

16:25.240 --> 16:32.240
If you want, I would appreciate if you can take the survey, which would simply ask you, basically,

16:32.240 --> 16:36.240
what I ask you, do you have any comments? What did you like? What are you talking about?

16:36.240 --> 16:41.240
Do you have any other issues? And you can leave any contacts if you want to talk about more.

16:41.240 --> 16:44.240
Or you can just contact me directly through LinkedIn.

16:44.240 --> 16:49.240
And yeah, that's everything I wanted to share. Thank you very much for listening to me today.

16:55.240 --> 16:57.240
Thank you.

17:10.240 --> 17:17.240
This is going to be interesting. Okay. We have time for a couple of questions. Do we have any questions?

17:25.240 --> 17:32.240
If you can, please wait until the Q&A is done. That will be helpful. Yeah, there's a question there.

17:32.240 --> 17:35.240
Can you ask her question? Can you repeat the question?

17:35.240 --> 17:37.240
Yeah. Okay.

17:37.240 --> 17:40.240
Let me run it around. Okay.

17:40.240 --> 17:58.240
Thank you. I was wondering if I want to deploy VDK, does that replace my Jupyter Lab, my Jupyter Notebooks,

17:58.240 --> 18:06.240
or does VDK replace my existing Jupyter Notebooks server, or is it an add-on that goes with it?

18:11.240 --> 18:18.240
Okay. So does VDK replace existing Jupyter server? Is the question? No. Actually, it's Pugin,

18:18.240 --> 18:26.240
both Ipite and Pugin, and also Jupyter Pugin that provide this functionality.

18:26.240 --> 18:32.240
It basically, you can, you'll be running your Notebooks or the VDK also, they're called jobs,

18:32.240 --> 18:38.240
which is the directory of Notebook files or other scripts with VDK using either VDK run,

18:38.240 --> 18:46.240
as I showed, or the UI, or you can just run them as a Notebook.

18:46.240 --> 18:56.240
It provides on top of it some extra variables, the Pugin, or there's also programmatic way in Python to run them.

18:56.240 --> 19:03.240
But it doesn't really replace it more like co-exist on top of it.

19:09.240 --> 19:21.240
Thank you very much. It was very interesting. Doc, does VDK, say for example, I want to export my Python?

19:21.240 --> 19:30.240
For example, respecting the ordering rules in VDK, does that, if I wanted to export that from Jupyter,

19:30.240 --> 19:40.240
will that impact the Python that's produced by doing a pure Python.py export?

19:40.240 --> 19:48.240
So, you're saying that you want to export the Python which is marked with the VDK tag, for example, in a script?

19:48.240 --> 19:55.240
Yeah, it's possible. And I, assuming that the script runs with VDK run,

19:55.240 --> 19:59.240
it's supposed to be running in almost the same way in Python script.

19:59.240 --> 20:08.240
You might, VDK provides some kind of extra libraries like job input, which if you're using, you might need to just initialize yourself,

20:08.240 --> 20:12.240
but other than that, there's no reason not to work.

20:12.240 --> 20:31.240
Hi, thanks for the nice presentation. My question is what was the first requirement for you that you needed to productionize Jupyter notebooks?

20:31.240 --> 20:38.240
What was the purpose of first productionizing them instead of using the regular Python scripts?

20:39.240 --> 20:43.240
So, what is the purpose of productionizing the regular notebooks instead of using Python scripts?

20:43.240 --> 20:53.240
Well, I'm hoping that the idea is to prevent double work so that you can reuse the same basically environment that you are developing

20:53.240 --> 20:59.240
and not needing to redo the same things in Python scripts in separate environments.

20:59.240 --> 21:09.240
Make it easy also for people without needing to know a lot of pyn of internals and software developing engineering practices to productionize things.

21:09.240 --> 21:16.240
So, there's a point I think that this might break if you have some very complex applications.

21:16.240 --> 21:23.240
In this case, probably you still want to switch to using IntelliJ and Python and some kind of framework,

21:23.240 --> 21:29.240
but until some point it should be much easier for other people, I hope.

21:43.240 --> 21:49.240
Thanks for the talk, first of all. Just wanted to ask a couple of things about regarding dependencies.

21:50.240 --> 21:58.240
You know how Jupyter notebooks typically don't have any versions of specific dependencies stated at the top.

21:58.240 --> 22:02.240
Probably just says import specific packages here and there.

22:02.240 --> 22:11.240
Probably doesn't do anything about pip installing those unless you specifically put a show command at the top.

22:12.240 --> 22:19.240
So, how is it processing those dependencies? Is it like automatically interpreting it?

22:19.240 --> 22:27.240
Or we still need separate requirements or a PyProject or something else that specifies those dependencies?

22:29.240 --> 22:33.240
So, how dependencies specified in VLK?

22:33.240 --> 22:38.240
Yeah, VLK, basic VLK data chop is a directory which has a couple of special files.

22:38.240 --> 22:42.240
You can have Python, SQL files, notebook files like this one, but you also have requirements,

22:42.240 --> 22:49.240
the XT file where you specify your dependencies and it will either you install them locally

22:49.240 --> 22:52.240
or when deployed, it will automatically install them in the environment.

22:52.240 --> 22:54.240
That's how it handle it.

23:00.240 --> 23:02.240
Okay, thank you very much.

23:08.240 --> 23:10.240
Thank you.

