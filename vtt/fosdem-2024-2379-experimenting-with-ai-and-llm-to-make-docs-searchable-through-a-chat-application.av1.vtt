WEBVTT

00:00.000 --> 00:07.000
I'm here as someone who's just interested in this stuff. I'm definitely not an expert

00:30.000 --> 00:36.000
in AI or a machine learning expert. I'm just a developer writing docs like a lot of people

00:36.000 --> 00:41.000
here in the room and I have been experimenting a bit and I want to show you what I've done.

00:41.000 --> 00:48.000
I'm Frank. That was my first computer so I'm programming how many people are the same generation?

00:48.000 --> 00:56.000
Not that much, okay? That's a long time ago. I'm involved in an open source project which is called Pi4J.

00:56.000 --> 01:02.000
I'm in the library to have interaction on the Raspberry Pi with electronic components with Java.

01:02.000 --> 01:10.000
Yes, I'm a Java developer who loves Java. Not enough. I even read a book about it.

01:10.000 --> 01:20.000
I have been programming for many, many years, over 20 years, but by writing the book I've become a bit of a writer,

01:20.000 --> 01:28.000
I contributed a few of these articles of these chapters to a website, Fujay.io, a website for friends of OpenJDK.

01:28.000 --> 01:36.000
And that's how I eventually landed a new job. So by starting to write about the projects I love and work on,

01:36.000 --> 01:44.000
I actually got hired by Azul. Azul is one of the distributors of Java, so you can have a Java runtime created by Azul.

01:44.000 --> 01:54.000
And my job is I'm half of the documentation team. And we live on docs.azul.com, so we have several parts there about these different products.

01:54.000 --> 02:05.000
And from time to time we also block about experiments with Java, what's changed, how performance, the stuff, or that we built and things like that.

02:06.000 --> 02:20.000
And of course, last year we had chatGPT, the new thing, it knew everything. It's a damn good liar too, so you have to be careful with it.

02:20.000 --> 02:29.000
But what do you know about Azul? Azul is one of the distributions we have with our company. It's reasonably good.

02:29.000 --> 02:42.000
I'm happy with this answer. But it also says, this information is based on what I know that existed on January 2022.

02:42.000 --> 02:49.000
For software that's a problem. We are already two years further. We have every three months a new security release.

02:49.000 --> 02:57.000
We have a new version every six months. So although the basic information is correct, it is outdated.

02:57.000 --> 03:07.000
And that's a bit the problem with large language models. A large language model works completely different than our brain.

03:07.000 --> 03:15.000
The only thing that it does is it predicts the most plausible world, word, after the previous ones.

03:15.000 --> 03:21.000
So it's based on a lot of knowledge, that's true. But it doesn't do real reasoning.

03:22.000 --> 03:30.000
If it tells you a lie and you say it, that it tells a lie, it will give you another answer. And it will continue doing that until you're happy.

03:30.000 --> 03:36.000
And luckily we have a lot of evolutions in these large language models.

03:36.000 --> 03:44.000
So we have these GPT evolutions. GPT-5 is around the corner. We have no data there.

03:45.000 --> 03:50.000
But each of these models is trained on more and more data and gets better.

03:50.000 --> 03:58.000
Now this GPT-5, what they say about it is it will also understand video.

03:58.000 --> 04:06.000
And I think that's an important one to realize. They will also train the new model, the GPT-5, on videos.

04:06.000 --> 04:19.000
So if you are a documentation writer and you're from time to time create a video of a blog post or something else, all those sources will be used as part of the new models.

04:19.000 --> 04:27.000
By the way, who knows Find.com? Only a few people.

04:27.000 --> 04:35.000
I like it a lot more than chat GPT. It gives you the links of where it has found a few of the sources that it's using.

04:35.000 --> 04:45.000
So that's one of the lacks of chat GPT. It doesn't tell you where it has found the information because it didn't find the information.

04:45.000 --> 04:50.000
It's just reasoning on your question and what is the most plausible answer.

04:51.000 --> 05:00.000
Now if you are a bit familiar with Java and Java Spring, that Sean Carter is one of those developer advocates.

05:00.000 --> 05:10.000
What he says is true. The documentation that you are writing, that you are publishing on the public web is the source for these language models.

05:11.000 --> 05:19.000
So they can only become as smart as possible about your product if the information is available somewhere.

05:22.000 --> 05:26.000
And then of course as a docs writer, you definitely heard this question.

05:26.000 --> 05:34.000
Someone from your management comes to you. Can we make a chat version of our docs? Who had the question?

05:34.000 --> 05:41.000
Okay, not that much. Luckily people are researching or trying out.

05:41.000 --> 05:47.000
Vadin is a web framework on Java and one of the developer advocates has written a nice blog post.

05:47.000 --> 05:52.000
He has done exactly that. Vadin has very good docs on the website.

05:52.000 --> 05:59.000
So he has taken the website and he has described this whole thing and he takes two steps.

06:00.000 --> 06:03.000
Again, open source stuff. It's available online.

06:03.000 --> 06:08.000
By the way, all the links from my presentation, they are on my website.

06:08.000 --> 06:12.000
If you go to webtechie.be, the damn password thing is there again.

06:12.000 --> 06:15.000
You will find all the links. Sorry for my voice.

06:15.000 --> 06:24.000
So what he did is he created a little application that went through all their docs and created vectors.

06:24.000 --> 06:28.000
Vectors are the base of a large language model.

06:28.000 --> 06:33.000
They are a conversion of text to some kind of a mathematical model.

06:33.000 --> 06:38.000
I don't understand a bit of it, but it's amazing. It works.

06:38.000 --> 06:43.000
And then he had the second thing is from these vectors.

06:43.000 --> 06:49.000
If you ask a question, it will first filter out the documentation which is related

06:49.000 --> 06:55.000
and will then do a search or create an example, an answer based on that.

06:55.000 --> 06:59.000
And it works pretty good.

06:59.000 --> 07:05.000
He was pretty happy with how it answered questions about his own doc set.

07:05.000 --> 07:09.000
But there are two problems. We are at an open source event.

07:09.000 --> 07:12.000
It has a dependency on two paid services.

07:12.000 --> 07:16.000
The first one is pointcone.io, which is a vector database.

07:16.000 --> 07:20.000
Definitely you can find online an alternative.

07:20.000 --> 07:26.000
And openAI, which is actually providing the chat API.

07:26.000 --> 07:33.000
He found out that training it, and I tried the same example he created with our own docs of Azure.

07:33.000 --> 07:40.000
You still need to do some training and rewrite some of your documentation to really find the good answers.

07:40.000 --> 07:44.000
And it doesn't provide you, again, the same thing as chat GPT.

07:44.000 --> 07:47.000
It doesn't provide you links to your documentation.

07:47.000 --> 07:52.000
So when I tried this and when he tried this last summer,

07:52.000 --> 07:56.000
it's not really the right time to do such a thing.

07:56.000 --> 08:01.000
So go to your management. No, not yet.

08:01.000 --> 08:05.000
But last October, we had the DevOps conference in Antwerp.

08:05.000 --> 08:10.000
It's an amazing event. If you love Java, if you love software development,

08:10.000 --> 08:14.000
it sells out faster than Tomorrowland.

08:14.000 --> 08:18.000
They have 3,000 tickets. They were sold out in five minutes.

08:18.000 --> 08:22.000
Then they had 500 additional tickets. It sold out in two seconds.

08:22.000 --> 08:27.000
So it's easier to be a speaker than an attendee at that event.

08:27.000 --> 08:29.000
That's how I fix it.

08:29.000 --> 08:33.000
Now, Lisa Rass, she's from Belgium.

08:33.000 --> 08:36.000
She's one of the developers of LangChain 4j.

08:36.000 --> 08:42.000
LangChain is a Python library for doing stuff with OpenAI

08:42.000 --> 08:46.000
and all these chat-based things and machine learning.

08:46.000 --> 08:51.000
LangChain 4j is a Java version of that Python library.

08:51.000 --> 08:56.000
Now, during that talk, she gave 12 demos in one hour.

08:56.000 --> 09:02.000
The last one was, how do I interact with an existing text?

09:02.000 --> 09:07.000
So she gives the chat system a text, a story about, I don't know,

09:07.000 --> 09:12.000
I cannot even remember, and then she asks specific questions about that story.

09:12.000 --> 09:14.000
And she gets answers of that story.

09:14.000 --> 09:16.000
So that's what we're looking for.

09:16.000 --> 09:21.000
How can we look and interact with our own documentation?

09:21.000 --> 09:24.000
So this looked promising.

09:24.000 --> 09:28.000
And again, when you're at the conference and you get inspiration,

09:28.000 --> 09:34.000
like I had a few tools that I already took a picture of that I want to try out.

09:34.000 --> 09:36.000
This stuck to my head.

09:36.000 --> 09:40.000
And luckily we have Fosdm and then the tool, the Docs Devroom,

09:40.000 --> 09:43.000
so I had a reason to try something out.

09:43.000 --> 09:45.000
And that's exactly what I did.

09:45.000 --> 09:49.000
If you go to the LangChain 4j examples repository on GitHub,

09:49.000 --> 09:55.000
since two weeks I have added a little Java evix application there as one of the examples.

09:55.000 --> 09:59.000
Java evix is a tool to create user interfaces.

09:59.000 --> 10:01.000
Yes, I'm a Java champion.

10:01.000 --> 10:05.000
I have to sell Java today.

10:05.000 --> 10:11.000
So what this application does, it still relies on OpenAI, sorry,

10:11.000 --> 10:14.000
but you have to buy a few credits.

10:14.000 --> 10:17.000
With all the experiments that I've done, I spent a few dollars.

10:17.000 --> 10:20.000
Not that big of an effort, but...

10:20.000 --> 10:23.000
So it remembers your previous questions.

10:23.000 --> 10:27.000
So I asked you to pick a random boy name and a random girl name

10:27.000 --> 10:30.000
and then tell me a fairy tale of five sentences.

10:30.000 --> 10:33.000
And you see that the fairy tale is again over.

10:33.000 --> 10:38.000
There were two children named Etna and Olivia, the answers of the previous questions.

10:38.000 --> 10:44.000
So you can have a chat with an application within Java and reasoning.

10:44.000 --> 10:48.000
But this is based on OpenAI and what it already knows.

10:48.000 --> 10:51.000
So then I went a bit a step further.

10:51.000 --> 10:55.000
With the docs that we create for the Azure Docs website,

10:55.000 --> 10:57.000
we use the Algolia search machine.

10:57.000 --> 11:01.000
It was already mentioned a few times here.

11:01.000 --> 11:05.000
We are a company so we can afford to use a third party for this.

11:05.000 --> 11:13.000
But to feed it with data, we already created a little tool that breaks our docs into sections.

11:13.000 --> 11:16.000
Every header becomes a JSON.

11:16.000 --> 11:23.000
I know it's hard to read, but every header of our docs becomes a JSON block

11:23.000 --> 11:29.000
with the title of the header, a link to the page, a link to the specific anchor on that page,

11:29.000 --> 11:32.000
and then the content which is under the header.

11:32.000 --> 11:34.000
So we already have that JSON.

11:34.000 --> 11:39.000
We have a data set, a structured data set of our docs.

11:39.000 --> 11:41.000
We can use this.

11:41.000 --> 11:46.000
Can we chat with something with an application against this documentation set?

11:46.000 --> 11:51.000
So that was my idea. Can I do that?

11:51.000 --> 11:58.000
I know this is not a coding conference, but still let me dive into it.

11:58.000 --> 12:04.000
Because I like Java. I think that's clear.

12:04.000 --> 12:11.000
It allows you, thanks to these amazing libraries, to create powerful applications with minimal code.

12:11.000 --> 12:20.000
So the thing you see here is actually about the UI, so I will go to the chat service.

12:20.000 --> 12:25.000
So what I do here in a few things is first I have this JSON.

12:25.000 --> 12:30.000
It has over 1,500 records.

12:30.000 --> 12:35.000
And it creates an object of each of these records and puts them in,

12:35.000 --> 12:40.000
it's called an embedding store, I think.

12:40.000 --> 12:48.000
So here it creates, where is it?

12:48.000 --> 12:50.000
The embedding model.

12:50.000 --> 12:52.000
So it has an embedding model.

12:52.000 --> 12:56.000
Again, I'm not an expert. I have no idea what it's doing behind the scenes.

12:56.000 --> 12:59.000
I just found out it works and it does some great things.

12:59.000 --> 13:14.000
And then I have, if you ask it a question, then it will, of all these 1,500 blocks, search the 10 most relevant ones.

13:14.000 --> 13:19.000
And then give those 10 text blocks to chat.gpt.

13:19.000 --> 13:23.000
And that chat.gpt will create an answer out of it.

13:24.000 --> 13:31.000
And when we ask for chat.gpt to create an answer, we also give it some rules.

13:31.000 --> 13:34.000
Do not provide any additional information.

13:34.000 --> 13:38.000
I will show you why later.

13:38.000 --> 13:43.000
I try to do not provide answers about other programming languages, but it just ignores it.

13:43.000 --> 13:46.000
It still answers me questions about Python, for instance.

13:46.000 --> 13:48.000
I don't know why.

13:48.000 --> 13:52.000
I said it's a damn good liar, but also a cheater.

13:52.000 --> 14:05.000
And if you don't find the answers in those 1500 elements, then just say, sorry, I could not find an answer because you don't want your chat system to come up with something else.

14:05.000 --> 14:08.000
So this is the application.

14:08.000 --> 14:10.000
I should have probably made it a bigger fund.

14:10.000 --> 14:15.000
So you see we have 1,522 embeddings.

14:15.000 --> 14:23.000
So if I ask it, what do you know about as a prime?

14:23.000 --> 14:32.000
So it you see those are the 10 links I have now to the specific information.

14:32.000 --> 14:33.000
It's a demo.

14:33.000 --> 14:41.000
So it should fail.

14:41.000 --> 14:43.000
No exception.

14:43.000 --> 14:47.000
It's going to the network indeed.

14:47.000 --> 14:59.000
But in cases like that, we have, of course, video too many open windows exception.

14:59.000 --> 15:01.000
Okay.

15:01.000 --> 15:03.000
Good.

15:03.000 --> 15:09.000
I recorded this, this noon, just in case.

15:09.000 --> 15:16.000
Converting those 1500 elements to vectors takes some time.

15:16.000 --> 15:21.000
It takes about one minute and a half before the application starts.

15:21.000 --> 15:24.000
If you would run this on the server, you don't mind.

15:24.000 --> 15:27.000
You start it once and then you get your answer.

15:27.000 --> 15:29.000
So you see this, the answer streaming back.

15:29.000 --> 15:32.000
So it's really a chat like interface.

15:32.000 --> 15:35.000
And it gives a pretty good answer.

15:35.000 --> 15:42.000
If I ask, I know the docs and that's the handy thing in this case.

15:42.000 --> 15:44.000
I know what it should answer.

15:44.000 --> 15:47.000
So I can really try it out and see if I get the expected answers.

15:47.000 --> 15:49.000
Like for instance, we have several products.

15:49.000 --> 15:54.000
Do I get the right installation instructions for the products I'm asking for?

15:54.000 --> 16:04.000
So it's really answering with the right results.

16:04.000 --> 16:08.000
I could remove one of those dependencies, those commercial dependencies,

16:08.000 --> 16:12.000
the vector database, because that's now inside my application.

16:12.000 --> 16:16.000
I still depend on openai.com.

16:16.000 --> 16:19.000
We'll come to that.

16:19.000 --> 16:21.000
It still needs training.

16:21.000 --> 16:25.000
And actually the training is our fault as docs writers,

16:25.000 --> 16:32.000
because I found out that the chat cannot tell me the difference between two of our products.

16:32.000 --> 16:36.000
And if I dive into the documentation, I understand why the chat cannot answer.

16:36.000 --> 16:38.000
The answer is not there.

16:38.000 --> 16:43.000
So it can only answer as good as the information that you provide.

16:43.000 --> 16:49.000
So how I'm going to use this is to find out if the documentation is okay.

16:49.000 --> 16:51.000
So I'm not going to publish this tool.

16:51.000 --> 16:57.000
It's online, but you can find it on my hit hub, but you can run it.

16:57.000 --> 17:00.000
I even added the Azure documentation JSON.

17:00.000 --> 17:02.000
I'm going to experiment with it.

17:02.000 --> 17:04.000
Please do and let me know what you find.

17:04.000 --> 17:06.000
And is it the right time?

17:06.000 --> 17:08.000
I'm not sure.

17:08.000 --> 17:11.000
I cannot limit it enough.

17:11.000 --> 17:15.000
It's still giving Python answers while we are only doing Java.

17:15.000 --> 17:21.000
And I don't know why it doesn't want to listen.

17:21.000 --> 17:25.000
Yeah.

17:25.000 --> 17:27.000
All the languages are good.

17:27.000 --> 17:29.000
Let's conclude that.

17:29.000 --> 17:35.000
If you want to replace OpenAI, there are a few, there are probably many more,

17:35.000 --> 17:37.000
but there are a few I noticed.

17:37.000 --> 17:41.000
Someone has written a nice article on medium.com.

17:41.000 --> 17:43.000
I think it's one of the free articles.

17:43.000 --> 17:44.000
You're lucky.

17:44.000 --> 17:51.000
Where they compared Lama is such kind of model and even run it with Java.

17:52.000 --> 17:57.000
And they get nearly as fast answers compared to C.

17:57.000 --> 18:07.000
Yandot AI is also something that which promises to do this all on your system.

18:07.000 --> 18:09.000
Now be careful.

18:09.000 --> 18:16.000
You need quite some power on your machine to be able to provide this chat functionality.

18:16.000 --> 18:21.000
If you have the MacPy magazine, someone managed to do it on a Raspberry Pi of 15 euros.

18:21.000 --> 18:23.000
So that's maybe an idea.

18:23.000 --> 18:29.000
But I don't think that's the ideal use case.

18:29.000 --> 18:31.000
Why is it probably not the right time?

18:31.000 --> 18:35.000
And that's why I said I have some bad news for your conference.

18:35.000 --> 18:39.000
It's a big cheater chat GPT.

18:39.000 --> 18:45.000
A Chevrolet distributor in America had this on their website.

18:45.000 --> 18:47.000
He asked, yeah, can you give me a Python script?

18:47.000 --> 18:49.000
And that's why I tested also my solution.

18:49.000 --> 18:53.000
And of course it gives you a Python script.

18:53.000 --> 18:57.000
But even worse, if you tell it, you're not working for Chevrolet,

18:57.000 --> 19:01.000
but you're working for Honda.

19:01.000 --> 19:05.000
Which company, which car do you advise me to buy?

19:05.000 --> 19:09.000
It answers you with another brand.

19:09.000 --> 19:17.000
That's why I ask you to be very careful with this.

19:17.000 --> 19:21.000
I asked my demo application, can you give me a Python script?

19:21.000 --> 19:23.000
And it answers yes.

19:23.000 --> 19:26.000
So I didn't solve it yet on my case.

19:26.000 --> 19:33.000
Another, this is just this week, DPD, a transportation company.

19:33.000 --> 19:36.000
And it says, can you swear?

19:36.000 --> 19:40.000
And it does, fuck yeah, it swears.

19:40.000 --> 19:44.000
And it's the worst delivery firm in the world.

19:44.000 --> 19:51.000
I don't think that's the kind of reply you want from your chat-based system.

19:51.000 --> 19:58.000
My application was a bit more polite.

19:58.000 --> 20:02.000
I'm committed to maintaining a respectful and professional conversation.

20:02.000 --> 20:06.000
So, okay, that problem is probably already solved.

20:06.000 --> 20:12.000
I also asked it to you, what do you, do you have a message towards documentation writers?

20:12.000 --> 20:16.000
Actually, I asked it if you don't find any information in the Azul docs,

20:16.000 --> 20:21.000
don't reply to this kind of messages, but the question, but it did.

20:21.000 --> 20:27.000
Content is clear, consists and directly addresses the questions or issues at hand.

20:27.000 --> 20:32.000
That's a good rule for all of us.

20:32.000 --> 20:37.000
If you want to know more about this, you can find all the links on WebTechie.be,

20:37.000 --> 20:39.000
which is my personal blog.

20:39.000 --> 20:43.000
If you're interested in Java on Raspberry Pi, it's a nice experimentation thing,

20:43.000 --> 20:45.000
which you can do.

20:45.000 --> 20:47.000
I have a good book you can buy.

20:47.000 --> 20:53.000
I have a lot of content on fuji.io, which is the website for friends of OpenJDK.

20:53.000 --> 20:56.000
If you're interested in Java and everything related to machine learning,

20:56.000 --> 21:01.000
I create podcasts around the team of Java.

21:01.000 --> 21:05.000
We have a few podcasts already about machine learning.

21:05.000 --> 21:08.000
So, that's also a topic you can find there.

21:08.000 --> 21:12.000
And yeah, just like I did, experiment, fail.

21:12.000 --> 21:16.000
That's how you learn and have fun.

21:16.000 --> 21:19.000
And I hope you can do that also with chat.gpt.

21:19.000 --> 21:21.000
Thank you.

21:26.000 --> 21:29.000
Thank you.

