WEBVTT

00:00.000 --> 00:16.000
All right. Thanks for coming.

00:16.000 --> 00:23.000
So here is what I'm for this talk.

00:23.000 --> 00:30.000
Basically, I'm going to describe what my OpenStack closer and Star does.

00:30.000 --> 00:36.000
First a bit about myself. So that's me playing with my Atari computer.

00:36.000 --> 00:41.000
So I'm a depend developer. It's been like nearly 15 years.

00:41.000 --> 00:44.000
I maintain not only the whole of OpenStack since it existed,

00:44.000 --> 00:49.000
but also things like self-open this switch, a bit MQ, many, many more stuff.

00:49.000 --> 00:53.000
That's probably a bit too much.

00:53.000 --> 00:58.000
So I've been working on hosting since the beginning of my career

00:58.000 --> 01:05.000
and of a maniac doing cloud computing for the last six years.

01:05.000 --> 01:10.000
If you don't know what OpenStack is, maybe you've been living in a cave.

01:10.000 --> 01:13.000
But like we used to have this schematic, which is kind of fun

01:13.000 --> 01:16.000
because it has all wires all around.

01:16.000 --> 01:19.000
It doesn't mean much because when you really know about it,

01:19.000 --> 01:21.000
it's a little bit more simple than that.

01:21.000 --> 01:28.000
But it handles a lot of projects and it's simply not reasonable to do everything by hand.

01:28.000 --> 01:32.000
You have to use some kind of automation at some point.

01:32.000 --> 01:35.000
That's what OCI does.

01:35.000 --> 01:43.000
So you boot up your computers over PXE.

01:43.000 --> 01:48.000
So OpenStack cluster installer provides that.

01:48.000 --> 01:56.000
And from bare metal to fully provisioned OpenStack cluster,

01:56.000 --> 02:00.000
every single artifact is taken from the Debian archive.

02:00.000 --> 02:08.000
So the only thing you need is a Debian mirror and that's about it.

02:08.000 --> 02:14.000
Even the pipette manifest that OCI is using are packaged.

02:14.000 --> 02:21.000
It's a solution which is kind of mature because it's been five years we're using it.

02:21.000 --> 02:30.000
And so all the pictures you will see are actual real pictures from our data centers, by the way.

02:30.000 --> 02:33.000
So it supports many types of hardware.

02:33.000 --> 02:38.000
I recently added ARM supports because we're putting that in production as well.

02:38.000 --> 02:48.000
We use many brands so we do recognize lots of Dell's, Gigabyte, HPEs, Lenovo, Supermicro.

02:48.000 --> 02:54.000
And what it does is full hand-free automation.

02:54.000 --> 02:59.000
It means you plug in the server, you press the power and it can do everything for you,

02:59.000 --> 03:03.000
including IPMI, hardware profiling and red setup.

03:03.000 --> 03:11.000
It discovers the location so that it can put your servers in the correct availability zones, this type of things.

03:11.000 --> 03:23.000
So at the end of the setup, everything is free SSL encrypted

03:23.000 --> 03:28.000
so that even though you are supposed to set that up on a private network,

03:28.000 --> 03:33.000
it's still best to have SSL everywhere.

03:33.000 --> 03:42.000
And so in OCI, there's many roles, like there's controller, compute network,

03:42.000 --> 03:51.000
high-scasy volumes, Ceph, monitor, Ceph OSDs, SwiftProxy, SwiftDoor and DNS.

03:51.000 --> 03:53.000
And maybe a bit more, I forgot.

03:53.000 --> 03:59.000
So every single computer, you can decide what type of node it's going to be

03:59.000 --> 04:06.000
and you can define that in the hardware profile so that the process of enrolling that node will be automated.

04:06.000 --> 04:14.000
So we've been using that software in production for five years and a half.

04:14.000 --> 04:19.000
So it's not just for fun that I'm doing it.

04:19.000 --> 04:24.000
We have real customers and we are making millions out of it.

04:24.000 --> 04:34.000
So we have decently large Swift clusters, probably eight clusters in total

04:34.000 --> 04:39.000
with like 6,000 hard drives running.

04:39.000 --> 04:42.000
And it also powers our public cloud.

04:42.000 --> 04:49.000
So it's really a production-ready system that I have uploaded to Debian.

04:49.000 --> 04:58.000
So as I said earlier, the overall workflow is that you're going to PXC boot your servers.

04:58.000 --> 05:05.000
So it also handles secure boot, meaning that it uses shim, then grub,

05:05.000 --> 05:11.000
and then your live system will download the SquashFS system over the network

05:11.000 --> 05:14.000
using that's how a live build works, right?

05:14.000 --> 05:22.000
And then once the server has booted up, it's going to report all the hardware capabilities of your server.

05:22.000 --> 05:28.000
How many hard drives, their size, this type of CPU, all this type of information.

05:28.000 --> 05:32.000
So with that hardware discovery, which is kind of simple, it's a simple shell script.

05:32.000 --> 05:40.000
It's not like everything in that open stack cluster installer is made in a way so that it's easily hackable.

05:40.000 --> 05:42.000
Everybody's going to understand it.

05:42.000 --> 05:47.000
It's bash scripts most of the time, some pipettes manifest.

05:47.000 --> 05:53.000
There's some PHP, but you mostly do not need to touch it a lot.

05:53.000 --> 05:59.000
So once the machine is enrolled, we know it's rolled, we know it's IP address

05:59.000 --> 06:03.000
because it has a network manager to assign IP addresses.

06:03.000 --> 06:10.000
Then OCI will produce the pipettes node classifier.

06:10.000 --> 06:17.000
So that's a huge MF manifest that tells all the parameters to the node.

06:17.000 --> 06:24.000
And so that when the machine boots up for the first time in its operating system,

06:24.000 --> 06:32.000
then the system knows what to set up on that machine.

06:32.000 --> 06:40.000
So it's kind of dynamic because the ENC ML file is generated from the DVE,

06:40.000 --> 06:42.000
which you can interact with the CLI.

06:42.000 --> 06:45.000
So you can modify the DVE to, I don't know, add a GPU,

06:45.000 --> 06:52.000
and then on the next pipette run, it's going to install your GPU or anything like that.

06:52.000 --> 06:56.000
We also provide many types of networking options.

06:56.000 --> 07:03.000
We used to do L2 connections so that you have a lot of ARP,

07:03.000 --> 07:06.000
and then my network guys started to complain about it.

07:06.000 --> 07:12.000
So we implemented BGP to the host so that you have an L3,

07:12.000 --> 07:14.000
only connect to the tree between the hosts.

07:14.000 --> 07:22.000
So I'm not going to describe what BGP to the host is in a lot of details,

07:22.000 --> 07:28.000
but basically all the links that you see there are BGP connectivity

07:28.000 --> 07:32.000
between the host on the bottom and the switches on top,

07:32.000 --> 07:39.000
which provides redundancy because every device that you see is connected to two other devices,

07:39.000 --> 07:41.000
and then you can use multiple routes.

07:41.000 --> 07:53.000
So the way it's done is that it uses a link local IPv6 connectivity between the two devices,

07:53.000 --> 08:00.000
meaning that you will have absolutely no ARP between your whole rack.

08:00.000 --> 08:06.000
It's going to be only L2 connectivity over IPv6 on the link local.

08:07.000 --> 08:17.000
So it's probably a little bit small, but what you can see in this is...

08:17.000 --> 08:19.000
So you have...

08:19.000 --> 08:27.000
Here's the types of machines that you have when you do a DMI decode.

08:27.000 --> 08:31.000
That's the product name, and here is the switch host names.

08:31.000 --> 08:35.000
So data center, row, rack, location, and computer aggregates.

08:35.000 --> 08:39.000
So when the servers boot up, they see the switch names,

08:39.000 --> 08:44.000
and then I can deduct where they are physically in the data center.

08:44.000 --> 08:50.000
So thanks to that, we can classify them in availability zones.

08:50.000 --> 08:59.000
That as well is probably a little bit small, but this is the way we classify hardware.

08:59.000 --> 09:03.000
So here you give a name, whatever you want,

09:03.000 --> 09:08.000
and the role that you want for the machine.

09:08.000 --> 09:15.000
A product name can be multiple ones, like if you have many types of compute nodes that works.

09:15.000 --> 09:24.000
The amount of RAM, and that's the description of the red layout that you will want.

09:24.000 --> 09:29.000
It also supports software RAID if you want.

09:29.000 --> 09:35.000
That's what the system automatically setups as a command line,

09:35.000 --> 09:42.000
as if you were typing OCLI, CLI, and then some parameters, so it does that for you.

09:42.000 --> 09:51.000
And then this makes it enrolling compute nodes into some compute aggregates and availability zones.

09:51.000 --> 09:56.000
So once you define that, you can define it for all the roles you have in your cluster,

09:56.000 --> 10:00.000
and that's how it does the magic of, okay, server has booted,

10:00.000 --> 10:04.000
I'll put it as this role in the cluster in that availability zones,

10:04.000 --> 10:13.000
install the operating system, and do everything without touching the keyboard.

10:13.000 --> 10:22.000
There's other features that are fancy, so it's maybe going to be a little bit a feature catalog,

10:22.000 --> 10:26.000
because it does a lot of things that we actually needed in production.

10:26.000 --> 10:31.000
So you can set up a Swift cluster with OCI, without compute,

10:31.000 --> 10:37.000
and then you can define a compute cluster with another OCI instance,

10:37.000 --> 10:40.000
and then you can connect the two, and if you do that,

10:40.000 --> 10:45.000
then you have Glens and Cinderbackup that are going to use that other cluster.

10:45.000 --> 10:51.000
The point to do it is that most of the time we set up our Swift cluster in a cross data center way,

10:51.000 --> 10:59.000
with one availability in each data center, and that's not really what you want to do with a compute cloud, right?

10:59.000 --> 11:04.000
You want everything to be in the same data center, with VMs close to each other,

11:04.000 --> 11:08.000
and just define availability zones per rack, for example.

11:09.000 --> 11:14.000
So that's the advantage of doing that.

11:14.000 --> 11:17.000
So we also support GPUs.

11:17.000 --> 11:25.000
For Maniac, we have a huge demand from our customers to use GPUs.

11:25.000 --> 11:34.000
You can define as many GPUs as you want per compute, so if you have four, six, eight, it's fine.

11:34.000 --> 11:42.000
So we have a picture of some A100 NVIDIA GPUs.

11:42.000 --> 11:52.000
So just to activate GPU support, you enter the GPU name, the PCI vendor IDs,

11:52.000 --> 11:58.000
I believe these are for the T4 GPUs that you see on the screen.

11:58.000 --> 12:08.000
Then you define a NOVA flavor that is going to use the name that you defined on top.

12:08.000 --> 12:14.000
So you can have multiple types of GPUs in one server that's also supported.

12:14.000 --> 12:22.000
The only thing is that once you've activated GPU, you need to reboot the compute

12:22.000 --> 12:29.000
so that it knows it has GPU and therefore it's a blacklist NOVA kernel module.

12:29.000 --> 12:33.000
Otherwise, you won't be able to use it with virtualization.

12:36.000 --> 12:39.000
There's also support for CPU models.

12:39.000 --> 12:46.000
So most of the time, in one cluster, you will define one CPU model for the whole of your clusters.

12:46.000 --> 12:49.000
Let's say you have epic CPUs from AMD, you will do that.

12:49.000 --> 12:57.000
But then if you have a mix of CPU types, like let's say AMD and Intel,

12:57.000 --> 13:00.000
then you can also define it per compute.

13:04.000 --> 13:08.000
There's also the possibility to do a hyper-converged model,

13:08.000 --> 13:12.000
meaning that basically you put your safe storage in the compute.

13:13.000 --> 13:21.000
So I designed it, we tried it, and we were not very happy about the performance of it.

13:21.000 --> 13:29.000
So if you don't have a lot of money and it's not really for customer-facing stuff,

13:29.000 --> 13:34.000
you can do it, it works, but I do not recommend it if you do large-scale.

13:35.000 --> 13:42.000
If you do that, you can also provision things like nutrient dynamic routing agents.

13:42.000 --> 13:53.000
So yeah, we also support BGP announced IPs for your VMs, so that's why there's this.

13:53.000 --> 14:03.000
So at Infomaniac, we also provide public cloud, therefore we also support telemetry.

14:03.000 --> 14:08.000
So telemetry is the name in OpenStack for rating all the resources.

14:08.000 --> 14:12.000
That's not the actual billing, that's counting resources.

14:12.000 --> 14:19.000
Let's say you've used that type of flavor for two hours, then it's that price.

14:19.000 --> 14:23.000
And then billing with actual PDF and such, it's up to you to rate it.

14:25.000 --> 14:30.000
So with telemetry, people also can do auto-scaling, that's how it works with heat.

14:33.000 --> 14:45.000
So you can basically rate any type of resources that's more OpenStack-free than OCI,

14:45.000 --> 14:51.000
though we provide all the things you need to implement it yourself.

14:54.000 --> 15:00.000
So telemetry is a huge resource-demanding thing.

15:00.000 --> 15:04.000
So I just made a small calculation so that you understand that.

15:04.000 --> 15:10.000
If you have 6,000 meters and 20 metrics every five minutes, that's 400 metrics per second.

15:10.000 --> 15:15.000
That's a lot of metrics to process, and that's only VMs.

15:15.000 --> 15:21.000
In the production system, you won't only build VMs, but many other things like, I don't know,

15:21.000 --> 15:32.000
Glance images, Swift objects, public IPs, load balances, some polling will be done.

15:32.000 --> 15:43.000
And so all of that takes a lot of resources, and therefore we wrote dedicated roles for it.

15:43.000 --> 15:50.000
So there's the messaging nodes where Clouty processor will be hosted.

15:50.000 --> 15:57.000
There's the new key API, so new key is the thing that does the time series for the resources.

16:00.000 --> 16:10.000
This messaging node, we provisioned it with a lot of cores, so we have three of these nodes with 128 cores,

16:10.000 --> 16:15.000
and it handles about 5,000 VMs in one cluster just to give you a rough idea.

16:15.000 --> 16:20.000
So it has dedicated RabbitMQ for the notifications,

16:20.000 --> 16:26.000
dedicated Galera cluster so that it doesn't interfere with your control plane,

16:26.000 --> 16:29.000
and dedicated Ceph as well.

16:29.000 --> 16:38.000
So if you decide to do with telemetry, you can set up the special Ceph cluster and these three messaging nodes,

16:38.000 --> 16:45.000
but you don't have to. You can also don't set it up, and then it's going to use the three control nodes.

16:45.000 --> 16:52.000
Everything is a little bit like that in OCI, so let's say you add some compute nodes,

16:52.000 --> 16:56.000
then it's going to provision Nova on the control planes,

16:56.000 --> 17:06.000
and if you provision some messaging nodes, then it's going to remove all the new key API and Clouty from the control plane.

17:07.000 --> 17:09.000
So that's the rough idea about it.

17:12.000 --> 17:21.000
So if you want to test the results, you can try on a FormalActiveDecloud.

17:21.000 --> 17:25.000
We're cheaper than everybody that you see over here.

17:27.000 --> 17:32.000
And we give you a 300 USD trial for two months.

17:33.000 --> 17:41.000
So in the near future, we expect to implement more services like Magnum.

17:41.000 --> 17:46.000
If we do that, we are going to do it with the cluster API plugin from the Vex host.

17:46.000 --> 17:54.000
Otherwise, we may implement CubaseService, not an open stack with our old Boo solution.

17:54.000 --> 17:59.000
So we are still working on it. I can't really tell you.

18:00.000 --> 18:08.000
Malilla, we are not going to implement it until the Viettayo driver is done.

18:08.000 --> 18:14.000
So I'm not going to go into details, but the generic and the Ceph FS driver,

18:14.000 --> 18:17.000
we are not happy about it. We don't think it's pollution ready.

18:17.000 --> 18:22.000
And Chauvin is trying maybe for later.

18:23.000 --> 18:28.000
So I was scared to have too many slides.

18:28.000 --> 18:32.000
So I went a bit fast. I have some time remaining.

18:32.000 --> 18:36.000
Before I do that, I may show you a little bit how it works.

18:36.000 --> 18:44.000
So there's no actual demo. There's this that shows you how to interact with OCI.

18:44.000 --> 18:49.000
So I started working on the web interface, and then quickly I realized it was crap.

18:49.000 --> 18:55.000
And then I just did, I work every day with that CLI.

18:55.000 --> 18:59.000
So you see there it created a cluster.

18:59.000 --> 19:09.000
You can set up many options on the cluster like time server and I don't know, 40 options probably

19:09.000 --> 19:13.000
for every machines as well. You can do machine sets.

19:13.000 --> 19:17.000
So it turns in loop.

19:17.000 --> 19:27.000
What you see here is a virtualize environment that I have a machine with half a terabyte of RAM

19:27.000 --> 19:37.000
where I spawn 38 VMs just for OpenStack and nine more where I have a virtual switch environment.

19:37.000 --> 19:41.000
So that you can reproduce at home.

19:41.000 --> 19:48.000
The virtual switch can do the BGP, so it's fun because from the host you can trace routes to your VMs

19:48.000 --> 19:54.000
that are using the OpenStack workload.

19:54.000 --> 20:00.000
Okay, that other one.

20:00.000 --> 20:03.000
So there you will see a few machines by hand.

20:03.000 --> 20:11.000
So machine add three controllers on zones and so on.

20:11.000 --> 20:15.000
So I'm open for questions. There's a few minutes remaining.

20:15.000 --> 20:21.000
I haven't been in the game for quite a while, so I don't know what to do with the second stage.

20:21.000 --> 20:28.000
One of the problems that OpenStack was kind of upgrading.

20:28.000 --> 20:31.000
So how do you end up being upgrade between the two?

20:32.000 --> 20:37.000
Yeah, so how do I do upgrades?

20:37.000 --> 20:41.000
With a simple shell script.

20:41.000 --> 20:48.000
So I have written, so when you see OCCLI, it has a bash completion everywhere.

20:48.000 --> 21:00.000
And I wrote HAPC, which is HAProxy command that does controlling the backends which one you disable or enable.

21:00.000 --> 21:08.000
So it does that to disable the APIs when it's upgrading one node.

21:08.000 --> 21:18.000
So I don't know how to explain, but despite what everything said around, I wrote that script and it wasn't that hard.

21:18.000 --> 21:26.000
And it's kind of easy when you read it to understand how it works.

21:26.000 --> 21:29.000
So you upgrade the...

21:29.000 --> 21:34.000
First you upgrade the puppet machine. It's going to upgrade all the puppet manifests.

21:34.000 --> 21:42.000
So it disables all puppet everywhere, upgrades that machine, and then it basically does upgrade.

21:42.000 --> 21:49.000
Not really in fact, because I've calculated all the OpenStack dependencies, so that's the only thing it's going to upgrade.

21:49.000 --> 21:54.000
It's not going to upgrade your OpenVsuit when you do that, for example.

21:54.000 --> 21:59.000
And then, yeah, it just works.

21:59.000 --> 22:08.000
So I've tested with Tempest the upgrades from Victoria to Bobcat.

22:08.000 --> 22:13.000
I'm not completely finished, but it's going to be soon done.

22:13.000 --> 22:18.000
So if you don't know Tempest, there's functional testing of OpenStack.

22:18.000 --> 22:23.000
Any other question?

22:23.000 --> 22:26.000
All right.

