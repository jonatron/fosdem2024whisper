WEBVTT

00:00.000 --> 00:08.360
Okay, so yeah, I'm the filthy, uh,

00:08.360 --> 00:11.000
from over guy that asked the intrinsic question. Um,

00:12.320 --> 00:15.880
and my name is flow and nice to meet you. Um,

00:17.200 --> 00:18.640
last year, my colleague Adam,

00:19.040 --> 00:23.040
I had a talk here about, um, the open source VBC decoder, um,

00:23.040 --> 00:28.280
VV deck and the encoder VVank here at foster and I,

00:29.040 --> 00:33.400
I optimized the decoder for arm architectures in my master thesis,

00:33.420 --> 00:37.880
which I will talk about now. So basically that's this on the right.

00:37.880 --> 00:40.240
They can see the, um,

00:40.560 --> 00:42.600
Zindi optimization of VV deck.

00:43.080 --> 00:49.040
So VV deck is optimized for SSE 4.1 and AVX 2 4.2 was

00:49.040 --> 00:51.520
needed. So 4.1 was enough.

00:52.200 --> 00:56.560
And to be also able to run VV deck on arm architectures, um,

00:56.560 --> 01:00.880
the, the open source project Zindi everywhere is used,

01:01.200 --> 01:03.360
which basically like in this case,

01:03.360 --> 01:08.280
parts the SSE implementation to arm architectures in the justice by

01:08.720 --> 01:12.120
using, um, either built in functions, um,

01:13.000 --> 01:17.680
or neon intrinsics in this case because it's arm and, um,

01:17.720 --> 01:19.480
but it can also only use, um,

01:19.480 --> 01:24.280
scarline implementations and tells the compiler to like vectorize it automatically.

01:24.880 --> 01:29.680
So yeah, a combination of these. So my goal was to, um,

01:30.040 --> 01:34.560
yeah, make it faster for arm. Um,

01:34.640 --> 01:39.040
for that, uh, the first thing I did was identify the hotspots. Um,

01:39.320 --> 01:44.520
I was profiling VV deck using instruments since I was using this M1 PC here.

01:44.800 --> 01:49.400
And yeah, um, I divided the profiling into three steps.

01:49.600 --> 01:53.560
First of all, I identified the most time consuming functions. Um,

01:53.560 --> 01:58.520
with these I checked like the performance on arm versus the performance on X

01:58.520 --> 02:03.640
86. And the third part was since VV deck is implementing,

02:04.360 --> 02:08.920
uh, every Zindi function as a non vectorized version as well. Um,

02:08.960 --> 02:12.920
I compared by wanted to know like how much, uh,

02:13.200 --> 02:16.480
speed up does the Zindi implementation generates.

02:16.800 --> 02:18.240
And with all this information,

02:18.880 --> 02:21.000
I chose for the foremost promising function,

02:21.000 --> 02:24.600
which basically means I wanted to get the biggest bang for the buck.

02:25.200 --> 02:30.280
And yeah, I chose to optimize these four functions. Um,

02:30.300 --> 02:33.680
on the left you can see these, the names of these four functions.

02:34.520 --> 02:38.240
Don't mind the names. Um, the only thing that is interesting is like the speed

02:38.240 --> 02:41.040
up. And, um, yeah,

02:41.040 --> 02:44.600
this graphic shows the manual optimization optimization.

02:44.600 --> 02:48.480
So the optimization I did versus the automated, um,

02:49.480 --> 02:51.880
the automated optimization from Zindi everywhere.

02:52.720 --> 02:57.320
And I visualized this for one of the JVET video sequences for a quantization

02:57.320 --> 03:01.560
parameter of 43. And, uh, yeah,

03:01.560 --> 03:06.560
you can definitely see that like two functions have a really nice acceleration

03:07.520 --> 03:10.240
so compared to the Zindi everywhere implementation.

03:10.400 --> 03:11.080
So in this case,

03:11.080 --> 03:14.440
the apply load Zindi function and the X get SAD function,

03:15.120 --> 03:17.920
but generally speaking, uh,

03:17.920 --> 03:22.920
you can definitely notice that Zindi everywhere does a decent job and to,

03:23.280 --> 03:27.840
yeah, in comparison to like just optimizing with C and forensics.

03:28.760 --> 03:33.760
And yeah, after having a look at the single function accelerations,

03:34.840 --> 03:39.560
I also wanted to know like how much is the impact of the optimization of these

03:39.560 --> 03:42.560
four functions on the general, um,

03:42.800 --> 03:45.280
on the total acceleration of VV deck.

03:46.120 --> 03:49.800
So I measured 11 JVET video sequences two times, obviously,

03:49.880 --> 03:54.880
since I need to compare them and average that for every or for,

03:55.920 --> 04:00.920
um, common quantization parameters. And yeah,

04:01.400 --> 04:04.200
the range is between 3% and 9%.

04:05.280 --> 04:10.080
What is not definitely noticeable is that like with, um,

04:10.080 --> 04:14.960
decreasing quantization parameter, the speed up gets, um, lower.

04:15.000 --> 04:18.960
And this is because the bit rate is higher with lower quantization parameters.

04:19.440 --> 04:24.200
This may, uh, this is because, um, not this is because, but, um,

04:24.320 --> 04:29.320
and because of that, like the decoding of the entropy decoding is getting more

04:29.560 --> 04:34.000
complex and yeah, it gets a bigger piece of the cake.

04:35.120 --> 04:38.040
So yeah, that was basically my master thesis in a nutshell.

04:38.680 --> 04:41.400
And after that, um,

04:41.800 --> 04:45.560
I also integrated like Zimdi everywhere to, um,

04:46.320 --> 04:50.600
to, to port the AVX to implementation, to arm,

04:51.240 --> 04:54.520
which also led to a contribution, which was pretty nice.

04:54.760 --> 04:58.040
It led to a conclusion to Zimdi everywhere since there were some,

04:58.160 --> 05:01.880
some errors in the portation. And right now,

05:01.920 --> 05:06.920
since there's also an encoder, I'm repeating the optimization for VVNG.

05:07.920 --> 05:10.320
And in the future,

05:10.320 --> 05:15.320
we might also optimize for the scalable vector extension like directly,

05:18.040 --> 05:20.960
or the scalable matrix extension. So yeah,

05:21.640 --> 05:23.320
thank you for joining for us.

05:27.520 --> 05:30.240
If you have any questions for free to ask, you can also ask me at the,

05:30.280 --> 05:32.760
I don't know, post foster and drink up. I don't know.

05:32.760 --> 05:36.600
Yeah.

05:36.600 --> 05:37.440
I have one.

05:37.440 --> 05:41.000
So what is translating across all the speed presets when you do the encoding,

05:41.000 --> 05:45.240
the decoding improvements? Uh, what the presets? Sorry.

05:45.280 --> 05:47.560
So when you do the encoding, you have different presets, right?

05:47.560 --> 05:48.400
So I didn't know that's

05:52.000 --> 05:53.560
you are asking about the encoding.

05:54.360 --> 05:55.400
So after the encoding,

05:55.400 --> 05:56.160
when you decode, right,

05:56.720 --> 05:58.840
does it translate across all the presets for recording?

05:59.320 --> 06:01.640
Cause every preset may not have all the tools.

06:02.480 --> 06:03.520
Uh, yeah, that's true.

06:04.040 --> 06:08.360
So the question was like, um, they are different, um,

06:08.880 --> 06:11.560
like there are different presets in the encoding,

06:11.560 --> 06:16.720
which affect the functions called in the, um, decoding. This is, um, true.

06:17.560 --> 06:21.840
I mean, I did like, uh,

06:22.040 --> 06:24.040
I tried to get a general overview,

06:24.040 --> 06:28.600
which functions were used by like profiling several, um,

06:29.120 --> 06:32.400
yeah, several, um,

06:33.320 --> 06:36.400
settings and tried,

06:37.000 --> 06:37.480
uh, yeah,

06:37.480 --> 06:42.120
and tried to figure out which functions were used most and average that

06:42.120 --> 06:45.080
basically. So yeah,

06:45.080 --> 06:49.080
there's a like a bigger story behind that behind the profiling, obviously,

06:49.120 --> 06:50.840
since this was only a five minute talk.

06:52.080 --> 06:56.280
And yeah.

06:58.840 --> 07:02.080
Does this mean that I can use a Raspberry Pi now to decode it?

07:05.680 --> 07:08.040
Have you tried to use the ARM devices to see?

07:08.320 --> 07:10.080
Okay. So the question is, um,

07:10.120 --> 07:13.520
can I use a Raspberry Pi to, uh, to decode it?

07:14.160 --> 07:19.160
And I mean the Raspberry Pi is based on an ARM, right? And I would say,

07:19.160 --> 07:21.680
yeah, obviously you can write because, um,

07:21.720 --> 07:25.680
I mean, you could do it before as well because Zimdia everywhere was included

07:26.080 --> 07:29.120
and Zimdia everywhere ports, uh,

07:29.280 --> 07:33.280
the SSE implementation to ARM, which, um,

07:33.360 --> 07:35.640
I mean it doesn't do it like perfectly, obviously,

07:35.960 --> 07:37.440
but we actually, um,

07:37.440 --> 07:42.000
submitted a paper or some colleagues of me are submit to the paper at a mile

07:42.000 --> 07:46.400
high conference. Um, yeah, I mean, I can,

07:46.640 --> 07:50.720
I mean, I can even probably put it up on, for, on the foster side, maybe.

07:51.160 --> 07:53.520
If you want to see that where they, um,

07:54.520 --> 07:59.520
like measure the performance of Zimdia everywhere on ARM and,

08:00.520 --> 08:02.440
so much of examples of what platforms,

08:04.520 --> 08:06.000
I mean the platforms, uh,

08:06.040 --> 08:11.040
which are supported are also like visible on the GitHub repository.

08:11.280 --> 08:15.640
So, um, yeah, this is also, um, on foster website.

08:16.200 --> 08:20.760
Um, like when you go to my talk, like there's the VVDec repository linked to it.

08:21.480 --> 08:24.040
And there you can see it. Um, yeah.

08:34.080 --> 08:34.920
That's tight.

08:43.560 --> 08:44.400
There's another question.

08:44.640 --> 08:45.920
Why don't you probably,

08:45.920 --> 08:48.760
you're simply by hand instead of using the quality performance in June?

08:49.400 --> 08:52.160
I mean, obviously we are still the best, right?

08:52.840 --> 08:56.680
So we are still the best when it comes to decoding and encode.

09:02.240 --> 09:03.880
But, um, like VV,

09:04.160 --> 09:09.160
like VVDec and VVN is performing pretty well in comparison to other VVC,

09:10.400 --> 09:11.600
um, coders, I would say, right?

09:15.400 --> 09:23.200
Um, yeah, that's true. That's obviously true. I mean,

09:23.640 --> 09:26.000
of course we have a head start, but,

09:27.400 --> 09:31.680
yeah, but I mean, let's see, right? I think nothing better than a healthy competition.

09:44.400 --> 09:45.400
Yeah.

