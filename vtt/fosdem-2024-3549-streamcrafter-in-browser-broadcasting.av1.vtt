WEBVTT

00:00.000 --> 00:07.000
Hi everyone, my name is Marco. I'm one of the maintainers of

00:07.000 --> 00:12.000
MISSERVER and today I want to talk just a little bit about the

00:12.000 --> 00:17.000
streamcrafter which is a broadcasting studio which runs from

00:17.000 --> 00:23.000
any modern web browser. Any questions about that?

00:23.000 --> 00:27.000
Well, it looks like there's still a few minutes left so I'll go

00:27.000 --> 00:31.000
ahead and give a bit more context about the streamcrafter.

00:31.000 --> 00:35.000
First of all, this is developed by the MISSERVER team so I want to

00:35.000 --> 00:39.000
talk just a little bit about what MISSERVER is. Then I'll move on to the

00:39.000 --> 00:44.000
streamcrafter itself. I'll do a quick demo and talk about what will be next on the

00:44.000 --> 00:50.000
real map. First of all, what is MISSERVER? Well, it's a media server.

00:50.000 --> 00:56.000
It's completely open source and public domain right now and it has a very

00:56.000 --> 01:00.000
broad support in terms of which ingest protocols, delivery protocols,

01:00.000 --> 01:04.000
codecs, containers, remixes on the fly and it's very efficient in memory and

01:04.000 --> 01:13.000
CPU usage. We think it's a fairly cutting edge media server so to say.

01:13.000 --> 01:17.000
Hopefully we'll get some more contributors in the long term to work on the streamcrafter

01:17.000 --> 01:22.000
with us because we're all backend engineers and especially making the

01:22.000 --> 01:28.000
interface nice and snappy is not our strongest part but we're working on it.

01:28.000 --> 01:32.000
So what's the streamcrafter? Well, let's say you are developing a

01:32.000 --> 01:37.000
social media platform and I have to deal with a whole bunch of users who do not

01:37.000 --> 01:41.000
know anything about codecs or configuring OBS to get a lower latency or a higher

01:41.000 --> 01:46.000
quality. Basically, they just want to drag and drop their inputs and have a

01:46.000 --> 01:50.000
go live button and that should be it for them. So what we want to create here is

01:50.000 --> 01:56.000
something which is very intuitive to use and the system integrator can then set

01:56.000 --> 02:02.000
up which kind of delivery protocol they want to use and just drop it into their

02:02.000 --> 02:09.000
platform. It's a drop-in react component and it's also a composter of course so

02:09.000 --> 02:15.000
the user can add cameras or screen shares and in the future we also want to add

02:15.000 --> 02:20.000
the ability to pull in streams from this server or pull in the video and audio

02:20.000 --> 02:25.000
feeds from a web-articity conference call so that the streamer can just

02:25.000 --> 02:30.000
composite all of these video feeds and use the audio mixer to their liking and

02:30.000 --> 02:39.000
just broadcast that. Cool. So this is a slightly outdated overview of how the

02:39.000 --> 02:44.000
streamcrafter started. As you can see, it's not that complex. You have a way to

02:44.000 --> 02:49.000
add inputs and then you have a way to mix all these inputs together and process them

02:49.000 --> 02:54.000
at an overlay or a sound effect or whatever and then you need ways to broadcast this.

02:54.000 --> 02:59.000
Now one thing which you don't see on this image is how do you get this media data

02:59.000 --> 03:05.000
from the input to the compositor. So right now the default way this works is it all

03:05.000 --> 03:09.000
happens in the main thread which is not ideal because if you have a whole bunch of

03:09.000 --> 03:14.000
inputs it kind of slows down a bit. So we're moving to a web worker mode which is

03:14.000 --> 03:20.000
already implemented but web APIs aren't really there just yet to make it work

03:20.000 --> 03:25.000
really well. So at the moment what it does is the web worker will ask the main

03:25.000 --> 03:31.000
thread for new frames because during the broadcast and then the main thread will

03:31.000 --> 03:37.000
send back individual frames to the compositor and it works. It's not ideal

03:37.000 --> 03:43.000
but in the future we hope to make use of the media stream track processor API which

03:43.000 --> 03:48.000
isn't available in modern web browsers yet but it would allow you to just transfer the

03:48.000 --> 03:53.000
entire video buffer into the compositor and then it can do all its work in a separate

03:53.000 --> 04:01.000
thread and then broadcast that directly. So let's move on to the most exciting part

04:01.000 --> 04:06.000
which is going to be the demo.

04:25.000 --> 04:30.000
Let's move this a bit to the side. So as you can see the interface is not our

04:30.000 --> 04:37.000
strongest part but it's usable so we're going to just add a scene and add a couple

04:37.000 --> 04:46.000
of inputs. It's a bit difficult to use from... oh, that's after a good start when...

04:46.000 --> 04:54.000
oh shit. Looks like my mouse isn't working on the big screen.

05:01.000 --> 05:06.000
Cool, so it looks like we won't have a demo of this but feel free to visit the

05:06.000 --> 05:11.000
website video.strong.rocks and play around with the broadcaster.

05:17.000 --> 05:25.000
But basically you can just drop sources into the canvas and it will also have a way

05:25.000 --> 05:33.000
larger canvas screen on your own monitor than this little screen over here and it should

05:33.000 --> 05:39.000
stream in low latency and you can just share that link to a viewer anywhere else in the

05:39.000 --> 05:43.000
world and they will be able to view it.

05:56.000 --> 05:59.000
There it is.

05:59.000 --> 06:02.000
Yeah.

06:16.000 --> 06:18.000
Here's the inspiration here.

06:18.000 --> 06:21.000
Oh, yeah. Thank you.

06:22.000 --> 06:36.000
Cool. Can you add a second window and we can also put the player side by side.

06:36.000 --> 06:38.000
I'll let you.

06:38.000 --> 06:41.000
That's green. So second screen.

06:52.000 --> 07:03.000
Well, let's just start streaming first then. That's fine.

07:03.000 --> 07:21.000
Yeah, so we've added a scene. Now let's add... just add a tab screen share.

07:21.000 --> 07:28.000
And then you just drag that on top of there.

07:28.000 --> 07:34.000
I don't know. The scaling is a bit off but it should be better on your own monitor.

07:34.000 --> 07:38.000
You can crop layers if you want.

07:38.000 --> 07:51.000
Like if you only want to share this part of the screen and it will automatically fit the layer inside the...

07:52.000 --> 08:02.000
Automatically crop the input to fit inside the layer so that people don't have to worry about stretching the input and it looks off.

08:02.000 --> 08:12.000
Yeah, and then you just click start, share the link with your viewers and then they can view that instantly.

08:21.000 --> 08:31.000
Cool.

08:31.000 --> 08:41.000
Cool.

08:41.000 --> 08:51.000
Well, it looks like it's not responding anymore.

08:51.000 --> 09:03.000
So what's next? Well, as you can see the UI needs a bit of an oval.

09:03.000 --> 09:09.000
It needs to scale better for mobile devices and for low resolution screens.

09:09.000 --> 09:15.000
Secondly, a code refactor because currently it's a bit of a prototype grade code.

09:15.000 --> 09:19.000
We want to make it extensible and easily maintainable.

09:19.000 --> 09:25.000
We want to have a plugin feature so people can add their own processing to the video layers, for example.

09:25.000 --> 09:32.000
And lastly, integration. Currently you can broadcast in web RTC which is fine for low latency workflows.

09:32.000 --> 09:37.000
But maybe you want something with a bit higher quality at the cost of a bit of latency.

09:37.000 --> 09:43.000
And so we're thinking of a tight integration with Miss Server so you can stream media data.

09:43.000 --> 09:53.000
For example, in Matroska format using HTTP readable streams, streaming directly to Miss Server.

09:53.000 --> 09:59.000
And that way you will get a bit higher quality without the low latency of web RTC, of course.

09:59.000 --> 10:07.000
But it should look a bit better.

10:07.000 --> 10:17.000
Cool. Are there any questions?

10:17.000 --> 10:23.000
What format is the video from the RZTAP to Miss Server in this case?

10:23.000 --> 10:26.000
If you're using web RTC it will be, sorry.

10:26.000 --> 10:31.000
So what format is being streamed from the stream crafter to the media server?

10:31.000 --> 10:35.000
Well, if you're using web RTC it will be Opus Audio.

10:35.000 --> 10:40.000
So you might have to do a bit of audio transcoding to get to AAC.

10:40.000 --> 10:45.000
If you're streaming with the other options which we'll be adding in the later dates,

10:45.000 --> 10:55.000
you will be able to transmit in any other audio format which is supported by the browser.

10:55.000 --> 10:57.000
It will be VP9 if you...

10:57.000 --> 11:02.000
What's the video codec being transmitted? It will be VP9.

11:02.000 --> 11:08.000
But this is also something which you can modify if you're using a different caption.

11:08.000 --> 11:12.000
Regarding the video and audio, what are the limits of the codec?

11:12.000 --> 11:16.000
What you can do with it? Is it machine specific, browser specific?

11:16.000 --> 11:21.000
Where do the limits come from for the codecs?

11:21.000 --> 11:24.000
So what limitations are there on the video and audio codecs?

11:24.000 --> 11:27.000
Yeah, I think you're doing it inside a browser.

11:27.000 --> 11:30.000
What are the limitations of that program?

11:30.000 --> 11:34.000
Well, I think the biggest limitation is...

11:34.000 --> 11:39.000
It depends on which browser they're using, if they're using a modern browser or an old browser,

11:39.000 --> 11:47.000
for example, modern browsers have very wide support for basically anything you want.

11:47.000 --> 11:52.000
Of course, anything that's happening on the main thread can get a bit slower over time.

11:52.000 --> 11:56.000
That's why you want to move all the compositing to a separate web worker thread

11:56.000 --> 12:00.000
to keep the main thread nice and snappy.

12:00.000 --> 12:04.000
Because if you add lots and lots of inputs, you can notice the UI starts to slow down a little bit.

12:04.000 --> 12:06.000
That's what we're trying to prevent there.

12:06.000 --> 12:11.000
So in a new browser, if it has AV1 supporting the future, you'll be able to just...

12:11.000 --> 12:12.000
Yeah.

12:12.000 --> 12:13.000
...not AV1?

12:13.000 --> 12:20.000
AV1 wouldn't be supported right now. I don't think it's supported at the moment, but maybe in the long term.

12:26.000 --> 12:31.000
You're saying you will roll back-end to engineer, but this is all done in the browser, right?

12:31.000 --> 12:32.000
This is a direct, yeah.

12:32.000 --> 12:38.000
Well, I consider it a bit of back-end engineering because you have to transfer media data from to the web worker.

12:38.000 --> 12:41.000
You have to overlay them a little bit of math there.

12:41.000 --> 12:48.000
It is a little bit of back-end work, but you know, of course, the UI presenting it is all front-end work.

12:48.000 --> 12:50.000
Is there anything you should be running on a server?

12:50.000 --> 12:53.000
So this is all running inside the browser.

12:53.000 --> 12:59.000
It will be cool, of course, to offload it to, for example, a mis-server and do auto-compositing in the background

12:59.000 --> 13:03.000
because then you can maybe do a bit more fun stuff with it.

13:03.000 --> 13:10.000
But the idea is that you can just drop this into your existing platform and your users can start going live

13:10.000 --> 13:13.000
without any other setup required.

13:14.000 --> 13:19.000
Is the rendering hardware accelerated or does it need to be?

13:19.000 --> 13:22.000
This is currently not hardware accelerated now.

13:29.000 --> 13:32.000
What framework are you using for the UI?

13:32.000 --> 13:34.000
So what framework am I using?

13:34.000 --> 13:36.000
Currently, it's all written in React.

13:36.000 --> 13:42.000
We do want to put some of the processing into native JavaScript, maybe,

13:42.000 --> 13:46.000
but currently it's all hooks and components.

13:53.000 --> 13:56.000
I'm assuming it's open-source, but I'm just taking it out.

13:56.000 --> 13:57.000
Can I find it?

13:57.000 --> 13:58.000
Yes, sorry about that.

13:58.000 --> 14:00.000
So the question is, is it open-source?

14:00.000 --> 14:03.000
Yes, but we're still working out which exact lines we want to put out.

14:03.000 --> 14:04.000
We do have a repository.

14:04.000 --> 14:05.000
It's not public yet.

14:05.000 --> 14:08.000
I was supposed to do that before the talk.

14:08.000 --> 14:18.000
So, yeah, probably later today we'll have the GitHub repo up with the full roadmap and demo link.

14:21.000 --> 14:23.000
How many people are working on this?

14:23.000 --> 14:25.000
So how many people are working on this?

14:25.000 --> 14:27.000
Currently, it's just mostly me.

14:27.000 --> 14:31.000
It's products by the mis-server team.

14:31.000 --> 14:34.000
And hopefully, of course, in the long term, we'd like to have more contributors

14:34.000 --> 14:36.000
because it is an open-source project.

14:36.000 --> 14:40.000
It would be cool if we can have other people work on some nice plugins

14:40.000 --> 14:43.000
for more video processing or audio processing.

14:43.000 --> 14:46.000
But this was all written by me at the moment.

15:02.000 --> 15:06.000
Sorry, what would be the next steps to this project?

15:06.000 --> 15:08.000
We'll be the next steps.

15:08.000 --> 15:11.000
So we do have a full roadmap of other features we want to add.

15:11.000 --> 15:14.000
So, of course, the UI is the most important thing to fix

15:14.000 --> 15:18.000
because that's what the end user will be interacting with the most.

15:18.000 --> 15:21.000
We also want to have more publishing options

15:21.000 --> 15:25.000
because WebRTC does degrade the quality a little bit.

15:25.000 --> 15:28.000
We want that option for the integrator to say,

15:28.000 --> 15:32.000
you want to have the full quality and maybe at a higher latency.

15:32.000 --> 15:35.000
And also, more input options like currently,

15:35.000 --> 15:38.000
it only has screen shares and adding video and audio devices

15:38.000 --> 15:40.000
accessible by the browser.

15:40.000 --> 15:43.000
But it would be fun if you can add way more inputs than that.

15:43.000 --> 15:48.000
And we're not really focused on having advanced editor controls

15:48.000 --> 15:53.000
because that would be maybe too daunting for a normal person to use.

15:53.000 --> 15:56.000
It's more about having the flexibility for the system integrator

15:56.000 --> 15:59.000
to choose these kind of inputs, these kind of outputs.

16:20.000 --> 16:23.000
So the question is, how is this being uploaded?

16:23.000 --> 16:25.000
Is it being recorded or not?

16:25.000 --> 16:27.000
This is a very broad question.

16:27.000 --> 16:30.000
It's very broad because I do this solo, those jam sessions.

16:30.000 --> 16:34.000
And if I can just use my phone to do it and people can watch it,

16:34.000 --> 16:38.000
that's fine, but also I want to get the video afterwards.

16:38.000 --> 16:41.000
Yeah. So at the moment, it does not do recording.

16:41.000 --> 16:43.000
Of course, if you send it to a media server

16:43.000 --> 16:46.000
because it does support any web-based media server

16:46.000 --> 16:49.000
as well as the server-special signalling protocol.

16:49.000 --> 16:51.000
But if you send it to a media server,

16:51.000 --> 16:53.000
that can do the recording on the server side, of course.

16:53.000 --> 16:56.000
But adding recording from the browser directly,

16:56.000 --> 16:59.000
that wouldn't be too much of a feature to add, I think.

16:59.000 --> 17:01.000
It would be nice once you add to the web map.

17:01.000 --> 17:02.000
So thank you.

17:02.000 --> 17:03.000
I have a couple of questions.

17:03.000 --> 17:05.000
I don't know, should we have to...

17:05.000 --> 17:08.000
Yeah, no, that's fine. I think we have some time.

17:19.000 --> 17:20.000
One more question.

17:20.000 --> 17:24.000
What is the commercial app that is similar to this?

17:24.000 --> 17:25.000
Sorry.

17:25.000 --> 17:27.000
What is the reason that it is similar to this?

17:27.000 --> 17:29.000
Sorry, can you repeat the question?

17:29.000 --> 17:32.000
The commercial app is very commercial.

17:32.000 --> 17:35.000
But it is similar to this?

17:35.000 --> 17:38.000
Well, of course, so is there any commercial application

17:38.000 --> 17:40.000
currently already integrated or in the...

17:40.000 --> 17:43.000
Is it similar to this presentation in the content?

17:43.000 --> 17:46.000
You're talking about existing applications, which...

17:46.000 --> 17:51.000
Yeah, so, Restream, of course, they have web-based broadcasting suite.

17:51.000 --> 17:55.000
But they don't have the composing in the browser.

17:55.000 --> 18:00.000
The user can choose a layout and add a few, like the cameras and stuff.

18:00.000 --> 18:02.000
But it does look really nice.

18:02.000 --> 18:05.000
We want to get some ideas there from the user interface.

18:05.000 --> 18:12.000
I don't think there are many competitors in terms of what we do exactly.

18:13.000 --> 18:15.000
Of course, you have OBS, that's a client application

18:15.000 --> 18:18.000
which users to install and configure themselves.

18:19.000 --> 18:20.000
Sorry.

18:22.000 --> 18:24.000
Restream it. I have to check it out, but...

18:39.000 --> 18:40.000
Cool.

18:40.000 --> 18:42.000
Thank you.

