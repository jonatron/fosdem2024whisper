WEBVTT

00:00.000 --> 00:07.400
It's time.

00:07.400 --> 00:13.120
So thank you very much to Johannes Bergberg.

00:13.120 --> 00:19.280
He will be speaking about Python 3.12 new monitoring and debugging API.

00:19.280 --> 00:24.760
For those who were in the previous talk, there was a brief about the profiling features.

00:24.760 --> 00:29.280
Johannes is a JVM developer working on profilers at SAP.

00:29.280 --> 00:32.680
He also writes blogs about profiling and debugging topics.

00:32.680 --> 00:40.480
Thank you very much.

00:40.480 --> 00:43.120
Thank you for introducing me.

00:43.120 --> 00:47.400
Before we start, I want to introduce you to the concept of debugging, because I'm sure

00:47.400 --> 00:50.000
nobody of you have ever debunked.

00:50.000 --> 00:55.800
So the first bug that's what's like found was in the 50s when they found a moth that

00:55.800 --> 01:01.000
was in between their relays and it makes zip and the whole system like crash because

01:01.000 --> 01:04.200
like in the olden days it relays.

01:04.200 --> 01:09.800
At SCADAISCAR once wrote, if debugging is the process of removing Zafferbacks and pro

01:09.800 --> 01:12.260
pro-peering must be the process of putting them in.

01:12.260 --> 01:19.240
As I'm sure all of you are doing lots of programming, I'm sure you're also doing lots of debugging.

01:19.240 --> 01:20.920
So that's what we're here.

01:20.920 --> 01:22.760
So consider this example program.

01:22.760 --> 01:23.760
It's called a counterprong.

01:23.760 --> 01:30.400
It just counts the lines in this example in itself and it returns zero.

01:30.400 --> 01:32.320
And we're like, why?

01:32.320 --> 01:36.480
So that's the problem because the file actually has 26 lines.

01:36.480 --> 01:37.600
So let's look at the code.

01:37.600 --> 01:41.200
I'm going to see clans of the code.

01:41.200 --> 01:43.760
Make this shortly so you don't see what it's about.

01:43.760 --> 01:48.800
But the idea is we use the debugger through this because the debugger is a great to understand

01:48.800 --> 01:49.800
our system.

01:49.800 --> 01:56.800
And the cool thing is now with the new APIs that we get in Python 3.12, writing the debugger

01:56.800 --> 02:00.240
is far easier and far faster as I show you in the following.

02:00.240 --> 02:02.440
I'm Johannes Pechberger as you already heard.

02:02.440 --> 02:08.400
I work at SAP machine, which is the third biggest contributor to the OpenJK, which is

02:08.400 --> 02:11.320
like the major Java runtime.

02:11.320 --> 02:15.760
And I started talking to people about Python because I also like Python.

02:15.760 --> 02:20.960
So it's a bit easier to VM than JVM.

02:20.960 --> 02:24.960
The question is now, why do we need a monitoring and debugging API?

02:24.960 --> 02:30.760
Because when I'm from the Java world and in Java, we haven't built in debugging API.

02:30.760 --> 02:36.600
So we have the ability to set breakpoints, to ask for values, to walk the stack and have

02:36.600 --> 02:37.600
everything.

02:37.600 --> 02:44.800
But in Python, does the Python interpreter know about the concept of breakpoints?

02:44.800 --> 02:51.040
So because I'm here, not only, but with a few here, who of you thinks that the Python

02:51.040 --> 02:53.960
interpreter knows about the concept of breakpoints?

02:53.960 --> 02:57.160
Please raise your hand.

02:57.160 --> 02:58.680
And two of your things.

02:58.680 --> 03:02.000
It doesn't know about the concept of breakpoints.

03:02.000 --> 03:03.160
Okay.

03:03.160 --> 03:08.560
It's a trick question, of course, no, because otherwise I wouldn't be asking this question.

03:08.560 --> 03:13.080
So it doesn't know anything about breakpoints, which is not a bad thing.

03:13.080 --> 03:17.120
So any ideas how we could implement it?

03:17.120 --> 03:20.840
So the first idea that came to my mind was like, we have this code.

03:20.840 --> 03:26.560
This is actually the code that was part of the code.

03:26.560 --> 03:31.800
So the idea was we just place in front of every line a debug statement, like a debug

03:31.800 --> 03:35.240
method that we define somewhere.

03:35.240 --> 03:41.120
The idea is simply put in the debug method, we check are we currently at a breakpoint

03:41.120 --> 03:45.040
in this file online, and if yes, we open some kind of debank shell.

03:45.040 --> 03:53.720
If you've ever used PDB before, that's essentially what, so it's the PDB shoulder, we could be

03:53.720 --> 03:54.720
opening.

03:54.720 --> 03:57.360
But the question is how did we get this file online?

03:57.360 --> 04:00.400
And the easy answer is we have this get frame method.

04:00.400 --> 04:05.760
It has an underscore, and the important thing is it has an underscore because it's kind

04:05.760 --> 04:10.760
of in C-Python implementation detail, which is great.

04:10.760 --> 04:14.480
Because it's pretty slow in PyPy.

04:14.480 --> 04:19.960
But we have to live with it because that's the only way we can walk the stack.

04:19.960 --> 04:25.680
We've seen before that we can do some EBS stuff, which is nice, but usually most profiles,

04:25.680 --> 04:27.160
not most debuggers, don't do it.

04:27.160 --> 04:31.320
So the idea is here, we have O stack, and the bottom is like the main, and then the

04:31.320 --> 04:36.040
count count line is code line, and then our debug method, and essentially what we do,

04:36.040 --> 04:40.200
we can ask get frame, the zero frame, that's the top frame, because we currently in the

04:40.200 --> 04:44.160
debugging method, and so we ask it for the frame one.

04:44.160 --> 04:49.320
And also get it from the other frames, and essentially what we can get is get information

04:49.320 --> 04:54.720
on like which are the local variables, which is the file name, which is the line number,

04:54.720 --> 04:58.600
and such, and that's quite nice because this allows us to easily implement the debugging

04:58.600 --> 05:04.440
shell because we can just open the shell that contains these locals.

05:04.440 --> 05:08.640
And so that's how we implement our first debugging method.

05:08.640 --> 05:14.560
And it's nice, and it works, and we can even write some basic debuggers with it.

05:14.560 --> 05:19.720
The problem is we want to automate this because we don't want to put this DBG statement in

05:19.720 --> 05:21.160
front of everything.

05:21.160 --> 05:24.080
So how do we do this?

05:24.080 --> 05:29.320
And first I'm going to tell you about the pre-3.12 way so you know the pain points of

05:29.320 --> 05:31.080
debugger developers here.

05:31.080 --> 05:39.000
The pre-3.12 way was the way of this dot set trace, which was an arcane way to do it,

05:39.000 --> 05:45.760
but the idea is essentially we pass it a handler and this handler is called multiple times.

05:45.760 --> 05:52.320
Essentially this handler gets parsed the frame type, the frame, and an event type, which

05:52.320 --> 05:59.000
could be like call line return or exceptional opcode, and it would be called regular time.

05:59.000 --> 06:07.880
So when we then register it, we register a specific handler and this handler then is

06:07.880 --> 06:09.600
called at every call.

06:09.600 --> 06:14.880
So every time the method called call lines is called, it's called, and every time then

06:14.880 --> 06:18.200
also a method is called line, this use here is called.

06:18.200 --> 06:20.680
And that's nice, but we want no more.

06:20.680 --> 06:25.520
We want to know also we want to get a handler on every line.

06:25.520 --> 06:30.840
So what we do, we can return from this handler and inner handler that's called for every line

06:30.840 --> 06:35.920
and this has the same signature.

06:35.920 --> 06:42.400
So the idea is we essentially implement our debugger here by not using like our writing

06:42.400 --> 06:46.080
manual here with the DBG but just setting an inner handler.

06:46.080 --> 06:48.520
This is called at every line.

06:48.520 --> 06:53.920
And that's quite nice because it works, but you might expect to show later it's quite

06:53.920 --> 06:54.920
slow.

06:54.920 --> 06:57.840
But it's okay.

06:57.840 --> 07:03.080
We can even go to the opcode level, to the bytecode level in here.

07:03.080 --> 07:08.280
But the problem is, and the question here is do we need a line event for every function?

07:08.280 --> 07:15.880
Because we know when we set a breakpoint somewhere, we only need to like, set a breakpoint,

07:15.880 --> 07:19.520
set, we only need to like check the lines there.

07:19.520 --> 07:25.880
But for example, consider that we have here this con-con-lines and our user decides that

07:25.880 --> 07:29.920
he adds a breakpoint when we're in isCodeLine.

07:29.920 --> 07:35.920
So it's a breakpoint also and isCodeLine and in isCodeLine decides, hey, I want to add

07:35.920 --> 07:38.920
a breakpoint into code con-lines.

07:38.920 --> 07:47.000
The problem is when we haven't passed like inner handler to the method here for con-con-lines,

07:47.000 --> 07:50.280
we can't enable line tracing for con-con-lines.

07:50.280 --> 07:56.560
So we have to enable it for every, every line of our whole application, which is kind of

07:56.560 --> 07:57.560
a mess.

07:57.560 --> 07:58.560
So this is slow.

07:58.560 --> 08:02.200
So there are multiple ideas how to improve this.

08:02.200 --> 08:06.360
And one of the best ideas, and if you're a Python developer, you should do this.

08:06.360 --> 08:09.320
If you're a Python core developer, is to add a new API.

08:09.320 --> 08:16.120
And this API is called Python, and this API is defined in the PEP669 and it's really,

08:16.160 --> 08:17.160
really cool.

08:17.160 --> 08:21.960
And the cool thing is also this PEP is written in a style that you can easily digest.

08:21.960 --> 08:23.440
I come from the Java world.

08:23.440 --> 08:25.920
This is not always the case with the Java PEP.

08:25.920 --> 08:31.600
So I'm with the JEP, so I'm quite happy that Python does things a little bit better.

08:31.600 --> 08:37.680
So the JEP is called Low Impact Monitoring for C Python and hopefully other runtimes

08:37.680 --> 08:40.200
will support it in the future.

08:40.200 --> 08:42.640
And it's here since October.

08:42.680 --> 08:48.880
So the idea here is that we have more fine-train support, that we learn from the lessons that

08:48.880 --> 08:55.400
like having to enable the line handlers for every line is probably not the best thing.

08:55.400 --> 09:00.400
So typically when we develop, when we use this PEP, we define some shortcuts here in

09:00.400 --> 09:01.400
the top.

09:01.400 --> 09:07.120
So we don't run to write, is this not monitoring all the time because that's where the monitoring

09:07.120 --> 09:10.480
functions live.

09:10.480 --> 09:16.200
So we call it mon and events, it's also bit long, so we call it mon not events.

09:16.200 --> 09:20.160
Then we have to assign it the tool ideas, tool ideas.

09:20.160 --> 09:25.920
So the idea is that you can have multiple tools that are registered here.

09:25.920 --> 09:30.920
And for each tool we register some callbacks.

09:30.920 --> 09:35.480
So what we do here in our example, we register a callback for our tool.

09:35.480 --> 09:42.040
Our tool is a debugger, they're like six possible tool ideas, a tool idea is one of them is

09:42.040 --> 09:45.040
a debugger, another one is a profile.

09:45.040 --> 09:49.720
And we register here callback for the line because we want to still have like line callbacks

09:49.720 --> 09:50.720
sometimes.

09:50.720 --> 09:54.760
And we also register a callback for the start function.

09:54.760 --> 09:59.840
So for the start event, when a method is called, then we have these handlers and the start

09:59.840 --> 10:02.240
handler is just passed like the code object.

10:02.240 --> 10:08.440
That's what you get when you form a method for function called f underscore code.

10:08.440 --> 10:15.600
And the offset word is located in a byte code and for line handler, we get the line word

10:15.600 --> 10:16.600
in.

10:16.600 --> 10:22.480
And the cool thing is here we can return from this, as you see in the bottom, the line handler

10:22.480 --> 10:26.080
also can return either disable or any.

10:26.080 --> 10:31.440
And the cool thing is when we disable, it's disabled all the time for this specific line

10:31.440 --> 10:32.800
and it's called for coverage.

10:32.800 --> 10:38.000
So we can also make coverage testing easier.

10:38.000 --> 10:41.120
So yes, we enable them the start events and that's fine.

10:41.120 --> 10:47.720
And then we run our program, we get the start event for every function that we call and

10:47.720 --> 10:51.920
then at every time we ask, hey, do we have a break point as an function?

10:51.920 --> 10:55.480
If yes, we enable the line here.

10:55.480 --> 10:59.000
But only specifically for this function.

10:59.000 --> 11:01.080
And then for every line we check it.

11:01.080 --> 11:05.800
The cool thing is that these line events are emitted per fret.

11:05.800 --> 11:16.480
So the ideas that were set, sister, etc., it was emitted like in the main fret per interpreter.

11:16.480 --> 11:26.960
But here it's emitted for every line in the fret that the function is currently executing.

11:26.960 --> 11:27.960
And this is really cool.

11:27.960 --> 11:37.400
And Lukas Lange wrote in a PR discussion, the biggest opportunity of PEP 6.9 isn't

11:37.400 --> 11:38.400
even the speed.

11:38.400 --> 11:43.200
It's the fact that the debugger built on top of it will automatically support all threats

11:43.200 --> 11:46.480
and supports threats properly.

11:46.480 --> 11:53.680
And with the incoming changes with PEP 703, with making the global interpreter lock option

11:53.680 --> 11:56.720
in Cpython, it will get far more important.

11:56.720 --> 12:04.560
Because with then we will probably see multi-threading Python applications and then the old approach

12:04.560 --> 12:07.080
is just not usable anymore.

12:07.080 --> 12:12.760
So the idea is that we can enable events globally and locally.

12:12.760 --> 12:18.120
And the sum of both is like they're enabled events per function.

12:18.120 --> 12:22.560
And the cool thing here is the power is in the fine-train configuration.

12:22.560 --> 12:28.120
So you can set events in a function f for the function f while this function is running.

12:28.120 --> 12:29.400
So consider this example here.

12:29.400 --> 12:34.920
We have a simple line handler here and you register a callback for each line.

12:34.920 --> 12:39.160
And then in f you decide at some point, hey, I want to set the local events.

12:39.160 --> 12:41.600
I want enable line events.

12:41.600 --> 12:43.200
And later you disable them.

12:43.200 --> 12:44.200
And it works.

12:44.200 --> 12:48.400
So here we emit hello and then we emit like, hey, we're at line 18.

12:48.400 --> 12:52.400
We're just like the line that prints n, then we print n.

12:53.240 --> 12:54.240
And that's really cool.

12:54.240 --> 12:56.440
That wasn't possible before.

12:56.440 --> 13:02.240
That's really great because this enables us to only enable line events for the functions

13:02.240 --> 13:04.040
that we will need them.

13:04.040 --> 13:09.880
And so the question is, of course, what's far as there are several methods in this PEP

13:09.880 --> 13:10.960
and this API.

13:10.960 --> 13:14.040
And what's really fast is to register callbacks.

13:14.040 --> 13:19.880
We can easily switch out the callbacks and get the tools so we can say, oh, please get

13:19.880 --> 13:21.880
the tool ID.

13:21.880 --> 13:27.840
What's kind of fast is that setting local events because where it does it modifies the

13:27.840 --> 13:30.120
bytecode to the VMS executing.

13:30.120 --> 13:38.920
And what's pretty slow is to use the tool ID to start the debugger here and to set the

13:38.920 --> 13:46.760
global events because this potentially recompars or modifies all bytecode of every function.

13:46.760 --> 13:47.800
So do it all the way.

13:47.800 --> 13:49.160
So then it's fine.

13:49.160 --> 13:52.600
So back to the debugger.

13:52.600 --> 13:56.040
We had here our start handler and our line handler.

13:56.040 --> 13:58.600
And they look essentially the same as before.

13:58.600 --> 14:03.440
The only difference is that we enable the line breakpoints when we're needed.

14:03.440 --> 14:08.160
So they're different than events kinds because we've seen that line events are pretty powerful

14:08.160 --> 14:11.520
for implementing basic debuggers.

14:11.520 --> 14:15.080
One of them we've seen already the start events.

14:15.400 --> 14:21.000
There's the regime return, yield events for everything that you do in your Python application.

14:21.000 --> 14:24.000
And there are also then in-signary events.

14:24.000 --> 14:30.560
These are events that aren't like an A that you can't enable or disable because they come

14:30.560 --> 14:33.800
from, they are controlled by other events.

14:33.800 --> 14:38.280
So for example, you have to call event that is triggered whenever you call a function

14:38.280 --> 14:45.040
and then we have C relighted, a C raise whenever exception is flown in C code or whenever fact

14:45.040 --> 14:46.800
a C function returns.

14:46.800 --> 14:53.680
And there are of course then also other events that are not enabled locally but only globally.

14:53.680 --> 14:56.320
Essentially the idea is we cannot locate them properly.

14:56.320 --> 15:01.440
And the cool thing here is maybe you've seen that we have a new event called stop iteration

15:01.440 --> 15:07.360
because we think it was in this Python version we're not using in iterators.

15:07.360 --> 15:13.440
When we were returning from iterator previously we wrote an exception but that's pretty slow.

15:13.440 --> 15:19.040
So we don't throw an exception anymore but to debug this to still notice it we have a

15:19.040 --> 15:22.680
new stop iteration event.

15:22.680 --> 15:27.080
Of course what you'll be waiting for is performance because the performance is like the thing

15:27.080 --> 15:34.040
that besides the threading support is pretty neat.

15:34.040 --> 15:39.280
So what I did I looked around and I found some people also doing some performances but

15:39.280 --> 15:41.000
they were using Fibonacci functions.

15:41.440 --> 15:44.600
Now I'm like that's a bit small, that's not representative.

15:44.600 --> 15:49.760
So I started looking into Python benchmarking suites and there's this pi performance benchmarking

15:49.760 --> 15:51.840
suite and I just hacked it.

15:51.840 --> 15:56.680
I just wrote random code in it because you can do some kind of monkey patching in Python

15:56.680 --> 15:58.800
and it's great.

15:58.800 --> 16:04.560
In Java we have like private functions and everything in Python you don't have to care

16:04.560 --> 16:09.600
and that's why you like using Python you can do things that you're not supposed to do to

16:09.600 --> 16:11.720
get some change results.

16:11.720 --> 16:18.040
So if you want I'm using Python all the time when fixing bugs in the OpenJK to write test

16:18.040 --> 16:25.520
suite because it's faster in Python than to do in Java so you get the OpenJK, some bugs

16:25.520 --> 16:29.120
were fixed because I wrote some weird Python script here.

16:29.120 --> 16:34.800
But essentially what I was then going to test is I wanted to check the minimal implementation

16:34.800 --> 16:35.800
of a debugger.

16:35.800 --> 16:40.800
So minimal implementation with such trace, so debugger that doesn't have any breakpoints

16:40.800 --> 16:48.240
here is just call handler and then an inner handler calls it every line.

16:48.240 --> 16:57.560
Then the minimal implementation for monitoring API wouldn't enable any line events because

16:57.560 --> 17:02.480
when we don't set a breakpoint we don't need to set any line events.

17:02.480 --> 17:06.840
So that's how we implement this but I thought like it's a bit sneaky because we're comparing

17:06.840 --> 17:11.920
something that triggers an event that is relying with something that only triggers an event

17:11.920 --> 17:19.000
every function calls are also made a third comparison with like setting all the line

17:19.000 --> 17:24.560
events and it turns out that's still faster which is quite nice.

17:24.560 --> 17:29.840
So I use this Py for matchpoint suite that's quite representable and what I found is that

17:29.840 --> 17:32.160
it's really, really fast.

17:32.160 --> 17:40.360
So the CessetRace when you run it, when you run all the five benchmarks with CessetRace

17:40.360 --> 17:45.240
on you have a 3.5 times larger runtime.

17:45.240 --> 17:46.400
That's pretty slow.

17:46.400 --> 17:52.760
When you're using monitoring you only have a runtime increase of like a factor of 1.2

17:52.760 --> 17:59.400
which is like 20% slower which is pretty, pretty awesome because this means you can debug

17:59.400 --> 18:05.240
all your tight loops, you can debug your whole applications without worrying about like

18:05.240 --> 18:12.520
debating slowing down and when you enable all line events it's still 30% faster than

18:12.520 --> 18:18.120
with CessetRace and people here probably like RAS.

18:18.120 --> 18:22.520
That's essentially all the benchmarks that are in Py performance and what you see here

18:22.520 --> 18:24.240
are the orange bars.

18:24.240 --> 18:33.840
These are the bars for the monitoring solutions and here it's just at one so if the bar is

18:33.840 --> 18:38.320
not visible it means you don't have any overhead in this benchmark but essentially you see

18:38.320 --> 18:46.200
that the blue bars for CessetRace can get high, can get up to like 10, 12 so it's really

18:46.200 --> 18:47.200
good.

18:47.640 --> 18:53.040
At least in my opinion and then when we switch over and use CessetRace monitoring with all

18:53.040 --> 19:00.000
line events enabled it gets worse but still we see that it's still significantly faster.

19:00.000 --> 19:04.840
Another question is of course is this whole thing used because it's implemented and I'm

19:04.840 --> 19:11.200
working in OmTek so I noted when you implement a cool feature the chances are that nobody

19:11.200 --> 19:16.720
will use it for like a year but here in OmTek people started, but here in CPython people

19:16.720 --> 19:21.840
started using it especially the vendors like PyCharm.

19:21.840 --> 19:30.440
So it's not yet used in PVP and they're showing the second pie but IDEs like PyCharm with their

19:30.440 --> 19:38.120
version 2093.3 use it and they've seen significant performance improvements.

19:38.120 --> 19:43.960
And there's currently a pending pull request on GitHub so if you want to help PVP implement

19:43.960 --> 19:48.720
it go to this pull request and try another discussion here so I would really recommend

19:48.720 --> 19:54.800
it's an open source project to CPython and you can make PVP better so what not to like

19:54.800 --> 19:57.760
is simple.

19:57.760 --> 20:02.920
Here's a quote from the pull request from Chen Gao who wrote this pull request and he wrote

20:02.920 --> 20:07.600
after this change we will have the chance to build a much faster debugger for break

20:07.600 --> 20:11.640
points we don't need to trigger trace functions all the time and change for a line number

20:11.640 --> 20:13.440
so I'll show it to you.

20:13.440 --> 20:18.080
The bad news is it's almost impossible to do a completely backward compatible transition

20:18.080 --> 20:21.160
because the mechanism is quite different.

20:21.160 --> 20:26.240
So there's an ongoing discussion how to do this.

20:26.240 --> 20:31.160
You could take part there so scan this QR code, be part of the community, give something

20:31.160 --> 20:36.960
back and not just use CPython.

20:36.960 --> 20:43.080
So because I have like tiny tiny town left I want to just show you shortly how single

20:43.080 --> 20:47.080
stepping works because single stepping is just break points because essentially the

20:47.080 --> 20:53.200
idea is here when we have always take here with the Scona and step out of this for example

20:53.200 --> 21:01.640
we just check for the next line where only the frame before changed like the current

21:01.640 --> 21:04.680
code lines changed.

21:04.680 --> 21:08.720
Stepping is also pretty simple we just check that only like the line number changed it's

21:08.720 --> 21:15.400
also nice and then check in to is we check the next time where we just put the frame

21:15.400 --> 21:16.400
on top.

21:16.400 --> 21:22.160
So that's all from me I'm part of Northern Twitter you can find my team at sub machine

21:22.240 --> 21:27.560
A O so if you want to use a JVM use the sub machine it's the best JVM.

21:27.560 --> 21:32.320
I'm contractually obliged to say this.

21:32.320 --> 21:42.280
We work at SAP we're one of the many cool open source projects at SAP you can follow

21:42.280 --> 21:47.200
me on my blog where I write on DBegging, EBPS stuff and everything else.

21:47.200 --> 21:49.200
So thank you for being here.

21:52.160 --> 22:02.680
Thank you very much Johans we have time for probably two three questions maybe.

22:02.680 --> 22:05.680
Does anyone we have one there?

22:05.680 --> 22:20.960
Thank you very much for this talk and for this pep because it actually solves a lot of

22:20.960 --> 22:26.240
problems I had when I started back in the days developing a tool for performance analysis

22:26.240 --> 22:27.680
for Python.

22:27.680 --> 22:36.880
However at some point choose to use the C interface of set rays and profiling and whatever

22:36.880 --> 22:43.240
do your does your proposal as I said is implemented already also support the C interface?

22:43.240 --> 22:49.560
So I have to correct I'm not I have nothing to do with the nice people who implemented

22:49.680 --> 22:55.960
this sorry but so please ask them they're probably in some discord somewhere I'm just

22:55.960 --> 23:01.040
telling you about the good news because programmers usually don't want to go to conferences and

23:01.040 --> 23:06.520
speak in front of people so that's why I'll be giving talks on this.

23:06.520 --> 23:08.800
So sadly I don't know.

23:08.800 --> 23:12.920
Thank you do we have any more questions to Johans?

23:12.920 --> 23:16.520
Can raise your hand.

23:16.520 --> 23:18.280
No questions apparently.

23:18.320 --> 23:25.080
I just want to choose this opportunity to thank Mark Andre and David also known as Flypeg

23:25.080 --> 23:27.160
for organizing this dev room.

23:27.160 --> 23:29.080
You guys did an amazing work.

23:29.080 --> 23:37.800
Thank you very very much.

23:37.800 --> 23:39.120
And thanks Johans again.

