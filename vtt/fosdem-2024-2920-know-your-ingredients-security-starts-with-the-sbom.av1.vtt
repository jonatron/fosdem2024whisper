WEBVTT

00:00.000 --> 00:11.000
Okay, great. Good.

00:11.000 --> 00:19.000
All right, so welcome everybody. Thanks everyone for joining the hottest room at POSTA.

00:19.000 --> 00:24.000
My name is Steven Chin. I'm VP of Developer Relations at JFrog,

00:24.000 --> 00:29.000
and I'm going to talk a lot about different projects which help secure the open-source supply chain

00:29.000 --> 00:34.000
about why we need security, a bunch of different security incidents,

00:34.000 --> 00:38.000
both historical ones, but also new ones which you probably haven't heard about,

00:38.000 --> 00:40.000
a lot of new research and things going on.

00:40.000 --> 00:46.000
And hopefully we can all help to improve the open-source supply chain together.

00:46.000 --> 00:50.000
So I think a great analogy. Can you guys in the back hear me?

00:50.000 --> 00:55.000
Okay, good. So I think a great analogy for the software supply chain

00:55.000 --> 01:00.000
and how we think about it is to compare it to our food supply chain.

01:00.000 --> 01:07.000
And we know that the way that you get great cooking,

01:07.000 --> 01:11.000
great ingredients is starting by fresh ingredients.

01:11.000 --> 01:16.000
Having things which you know are safe, which come through the food supply chain,

01:16.000 --> 01:22.000
which aren't, don't have any people who are interfering with in the middle,

01:22.000 --> 01:25.000
who are not following good hygiene practices.

01:25.000 --> 01:31.000
And when you have an issue with your supply chain, you end up with spoiled ingredients

01:31.000 --> 01:33.000
and you know, kitchen disasters.

01:33.000 --> 01:37.000
So anyone here seeing the Gordon Ramsay kitchen disasters show?

01:37.000 --> 01:44.000
Okay, a lot of good fun. And these are not the free-range chicken you're looking for.

01:44.000 --> 01:49.000
We're hoping we can get better quality and better security out of our software supply chain

01:49.000 --> 01:56.000
so we can build enterprise applications which are hopefully very difficult for attackers to exploit.

01:56.000 --> 02:02.000
And this is how the USDA looks at kind of you know, the software supply chain,

02:02.000 --> 02:06.000
creating a healthy supply chain. But it's somewhat analogous to software.

02:06.000 --> 02:10.000
So you have a lot of production. You have you know, farms and things which are producing software.

02:10.000 --> 02:15.000
You have distribution and processing. So it goes through a bunch of different tall gates

02:15.000 --> 02:20.000
and different people in the process. Eventually it ends up in a restaurant and a retail location

02:20.000 --> 02:26.000
and then you have you know, home users or restaurants or other folks who are cooking the food.

02:26.000 --> 02:32.000
So if at any point in this process, if you have issues with your quality,

02:32.000 --> 02:36.000
if you have you know, infections, if you have bacteria entering into it,

02:36.000 --> 02:41.000
then that results in potential issues at the consumer side.

02:41.000 --> 02:47.000
So I think when we're looking at the software supply chain, we need to look at it through a different lens.

02:47.000 --> 02:53.000
And I think a good lens to look at it through is Salsa, which is one of the open SSF standards.

02:53.000 --> 03:02.000
And it really focuses on getting attestations of the different parts of the builds that your software has gone through.

03:02.000 --> 03:07.000
Kind of figuring out at each of these different gates, you know, is the source control secure?

03:07.000 --> 03:12.000
Have you done the right things with code reviews? Have you done through the right processes with builds?

03:12.000 --> 03:18.000
And when you have all of this information about the build, then you can figure out are you actually secure?

03:18.000 --> 03:25.000
And a key ingredient to how you know this is the case, and this is why we're all here in the software build materials room,

03:25.000 --> 03:30.000
is because you need to have that final index of your ingredients,

03:30.000 --> 03:36.000
where it can show you from end to end, and Salsa and both SPDX, Cycline DX,

03:36.000 --> 03:43.000
and S-bomb standards go really well together, because this way you have the attestation of what's happened in your build

03:43.000 --> 03:48.000
into your artifacts, and then you can put that together into a single document,

03:48.000 --> 03:52.000
which kind of shows you all of the things which verify the components,

03:52.000 --> 03:56.000
and then the potential issues with them, which you might have.

03:56.000 --> 04:01.000
And if you're not following these good practices in how you build software,

04:01.000 --> 04:04.000
how you get provenance of your software and how you attest to it,

04:04.000 --> 04:10.000
then you end up with issues like, for example, the log for shell incident.

04:10.000 --> 04:13.000
Now I think this by now is infamous.

04:13.000 --> 04:19.000
It sparked a whole second round of government security concerns over open source software,

04:19.000 --> 04:25.000
and really the challenge for big organizations, which we're trying to address the log for shell incident

04:25.000 --> 04:31.000
in production, was are my production systems affected?

04:31.000 --> 04:35.000
And it depended upon the version of log for J, which you were using.

04:35.000 --> 04:38.000
It depended upon whether you're using just log for J core,

04:38.000 --> 04:41.000
or whether you're using the full set of libraries.

04:41.000 --> 04:45.000
And the answer for most organizations was, well, I don't know if I'm affected in production,

04:45.000 --> 04:47.000
so I'm just going to patch everything.

04:47.000 --> 04:50.000
And that's very expensive, it's very difficult to do,

04:50.000 --> 04:54.000
and when you have libraries like this, which are used so much across the entire ecosystem,

04:54.000 --> 04:56.000
it's quite challenging as well.

04:56.000 --> 05:04.000
And I think what really started a lot of the government concern around software supply chain

05:04.000 --> 05:05.000
was an earlier incident.

05:05.000 --> 05:10.000
This sparked the Biden administration's litigation around this,

05:10.000 --> 05:12.000
which was the SolarWinds incident.

05:12.000 --> 05:18.000
A very different sort of incident because this one was a true software supply chain attack

05:18.000 --> 05:22.000
in the sense that they specifically attacked the build system.

05:22.000 --> 05:28.000
So they were using TeamCity, they got in right before the certification happened,

05:28.000 --> 05:30.000
the signing of the artifacts happened.

05:30.000 --> 05:33.000
So to the downstream people, which SolarWinds was providing,

05:33.000 --> 05:38.000
it looked like it was signed by the company and certified, and it wasn't a malicious,

05:38.000 --> 05:44.000
but in fact they had done a very good job of infecting it before that was properly signed.

05:44.000 --> 05:47.000
And so we'd like to prevent these sort of attacks from happening

05:47.000 --> 05:51.000
because it causes a lot of damage.

05:51.000 --> 05:56.000
It can cause potentially malicious entities to get access to information.

05:56.000 --> 06:02.000
It can cause privacy issues with consumers, and it costs a lot of money and cost

06:02.000 --> 06:06.000
according to IBM's data breach report in 2023,

06:06.000 --> 06:12.000
USD over 4.45 million and a 15% increase over three years.

06:12.000 --> 06:17.000
So this is a huge issue and it continues to get bigger for us as a software industry.

06:17.000 --> 06:20.000
Okay, so let's talk about some additional incidents.

06:20.000 --> 06:25.000
So anyone, which one of these is your package?

06:25.000 --> 06:30.000
So when we're talking about like delivering libraries and dependencies,

06:30.000 --> 06:35.000
one of the things that majority of software uses is it relies on open source components,

06:35.000 --> 06:39.000
it relies on leveraging that because we don't want to write the same code

06:39.000 --> 06:42.000
and it's actually more secure if we're leveraging open source libraries

06:42.000 --> 06:44.000
that have been peer reviewed, that have been patched,

06:44.000 --> 06:47.000
that are staying up to the latest standards.

06:47.000 --> 06:51.000
But what if you can compromise the systems in the middle,

06:51.000 --> 06:53.000
which are supplying this information?

06:53.000 --> 06:58.000
So the dependency confusion attack basically relies upon the fact that

06:58.000 --> 07:01.000
a lot of companies, organizations, and open source projects

07:01.000 --> 07:04.000
use some sort of package management or middleman.

07:04.000 --> 07:08.000
They'll set up repositories which will pull from upstream

07:08.000 --> 07:11.000
or pull from local corporate repos.

07:11.000 --> 07:15.000
If you can get the information about what the internal names of the corporate repos,

07:15.000 --> 07:19.000
this is an example of Yelp, then what you can do is you can upload those

07:19.000 --> 07:24.000
to NPM or other public repositories and especially you're spoofing these libraries.

07:24.000 --> 07:30.000
So as a developer, as a CI CD system, you're going through a potentially vulnerable

07:30.000 --> 07:35.000
package manager rather than getting awesome corporate lib 1.2,

07:35.000 --> 07:37.000
which is the latest version of your company's library.

07:37.000 --> 07:42.000
It goes and it sees, aha, there's a new version in a public repository.

07:42.000 --> 07:44.000
I'm going to serve that up instead.

07:44.000 --> 07:48.000
And as you know, bad things happen when kittens get access to nukes.

07:48.000 --> 07:51.000
So we don't want this to happen in our supply chain.

07:51.000 --> 07:57.000
Fortunately, all of the commercial package managers, including my company's

07:57.000 --> 07:59.000
Artifactory, are now patched for this.

07:59.000 --> 08:05.000
So by default, they will not go out to a public repository

08:05.000 --> 08:07.000
if it exists in a local repository.

08:07.000 --> 08:09.000
So this blocks that attack upstream.

08:09.000 --> 08:14.000
But Alex Bresson, who did this exploit, was very creative.

08:14.000 --> 08:17.000
He took an attack which was theoretical at the time.

08:17.000 --> 08:19.000
Nobody had actually exploited it.

08:19.000 --> 08:23.000
He attacked Google, Facebook, Apple, a whole bunch of companies

08:23.000 --> 08:27.000
and simultaneously claimed about a dozen bug bounties and ended up getting

08:27.000 --> 08:29.000
$130,000 USD for his effort.

08:29.000 --> 08:31.000
I'm sure you'll see that.

08:31.000 --> 08:38.000
Maybe instead of helping secure the supply chain, there's a more lucrative path.

08:38.000 --> 08:43.000
But I think it's also like researchers like him also, they're helping to

08:43.000 --> 08:49.000
expose the potential issues in the supply chain in a way where they're not

08:49.000 --> 08:51.000
introducing threats, right?

08:51.000 --> 08:54.000
So this is white hat hacking.

08:54.000 --> 08:56.000
And we need people like this to find the exploits.

08:56.000 --> 09:00.000
And also, this helps guide us for what we need to do for new standards of

09:00.000 --> 09:04.000
SPDX, for implementing things like VEX to make it easier for us to figure out

09:04.000 --> 09:06.000
what the vulnerability scope is.

09:06.000 --> 09:09.000
So I think that these sort of attackers actually are helping us a lot with

09:09.000 --> 09:11.000
the ecosystem.

09:11.000 --> 09:13.000
Now, another food example here.

09:13.000 --> 09:18.000
So if you have a recipe that calls for different types of rice, like for

09:18.000 --> 09:21.000
example, if you're doing a risotto, you wouldn't want to use like a mixed

09:21.000 --> 09:22.000
grain rice.

09:22.000 --> 09:24.000
Like you need a specific type of rice.

09:24.000 --> 09:28.000
And this is something else which attackers make a lot of use in the

09:28.000 --> 09:30.000
supply chain.

09:30.000 --> 09:35.000
So another common type of attack is called typosquadding.

09:35.000 --> 09:38.000
Another variant of this is leaving off namespaces.

09:38.000 --> 09:44.000
So as an example, our research team found an attacker which released to NPM a

09:44.000 --> 09:48.000
whole bunch of libraries from Azure.

09:48.000 --> 09:51.000
And they just left off the Azure prefix.

09:51.000 --> 09:55.000
So if you're a lazy developer and just typed in the package you wanted, if

09:55.000 --> 09:59.000
you left off the namespace, you would instead get a vulnerable library

09:59.000 --> 10:01.000
instead of the actual library you wanted.

10:01.000 --> 10:03.000
So a very clever attack.

10:03.000 --> 10:08.000
And the way they did this inside of NPM is they actually had a random account

10:08.000 --> 10:12.000
generator which would also generate a unique account for each of the different

10:12.000 --> 10:13.000
libraries they uploaded.

10:13.000 --> 10:18.000
So it also wasn't easy to systematically find, oh, well, this is a bad entity.

10:18.000 --> 10:19.000
I'm going to block them.

10:19.000 --> 10:22.000
So they managed to spread out the attack.

10:22.000 --> 10:26.000
They did it on 280 different packages on Azure, Azure tests, Azure tools,

10:26.000 --> 10:28.000
CattleLang.

10:28.000 --> 10:34.000
And then they could install any software they wanted on the person's computer.

10:34.000 --> 10:38.000
But basically it was set up for potentially exploiting data from personal

10:38.000 --> 10:39.000
machines.

10:39.000 --> 10:42.000
Later on, so our security research team found this.

10:42.000 --> 10:43.000
We reported it to NPM.

10:43.000 --> 10:45.000
They took all the packages down.

10:45.000 --> 10:47.000
And then we publicly disclosed it.

10:47.000 --> 10:53.000
Later on, a security research firm claimed that they were just testing out NPM.

10:53.000 --> 10:56.000
So this was like a company testing the waters.

10:56.000 --> 11:00.000
So it wasn't actually a malicious payload in any of the packages yet.

11:00.000 --> 11:03.000
But it had a lot of potential for doing that.

11:03.000 --> 11:06.000
And the security research firm wasn't exactly upfront about what they were

11:06.000 --> 11:07.000
testing either.

11:07.000 --> 11:09.000
So, okay.

11:09.000 --> 11:13.000
And then, of course, if you're building, if you're serving food, you want the

11:13.000 --> 11:17.000
ingredients to be very fresh, right?

11:17.000 --> 11:22.000
You can't make gourmet food if you start with a pile of rotten food and things

11:22.000 --> 11:24.000
which aren't fresh.

11:24.000 --> 11:29.000
And I think when we're looking at the software supply chain, actually a good

11:29.000 --> 11:35.000
analogy for this is the somewhat infamous picture of a stack of more things and

11:35.000 --> 11:41.000
more things and more things with very small, fragile components nested inside of

11:42.000 --> 11:47.000
the supply chain, which any of those, if you pulled out the banana, suddenly your

11:47.000 --> 11:49.000
whole supply chain falls apart.

11:49.000 --> 11:55.000
And I think a great classical example of this is the left pad incident.

11:55.000 --> 12:01.000
So basically, there was a package published on NPM under the Keek package for

12:01.000 --> 12:02.000
doing left pad.

12:02.000 --> 12:06.000
Not a lot of code, so it's not something that's hard to write.

12:06.000 --> 12:09.000
But as developers, we are very, very lazy.

12:09.000 --> 12:14.000
If there's, if you can possibly save a line of code by including a dependency,

12:14.000 --> 12:16.000
of course you would do that.

12:16.000 --> 12:21.000
And then this Keek package was later claimed by a company, which wanted to own

12:21.000 --> 12:22.000
that domain.

12:22.000 --> 12:24.000
NPM sided with the company.

12:24.000 --> 12:29.000
Cameron got upset about this and then pulled down, oh, actually the publisher

12:29.000 --> 12:32.000
of Keek got upset about this and pulled all his entities down.

12:32.000 --> 12:36.000
Later on, Cameron published an identical version of left pad to solve this

12:36.000 --> 12:37.000
problem.

12:37.000 --> 12:40.000
But this is the source code which caused this huge incident.

12:40.000 --> 12:45.000
And this is something that is not worth including a library dependency, a

12:45.000 --> 12:50.000
potential vulnerability for such a very trivial piece of code.

12:50.000 --> 12:53.000
So this is, again, a huge threat.

12:53.000 --> 12:57.000
Now, one of the ways you can find out what all your dependencies are and figure

12:57.000 --> 13:01.000
this out in a visual way is using Guac.

13:01.000 --> 13:03.000
So this is a new OpenSSF project.

13:03.000 --> 13:07.000
It just got added to the OpenSSF suite.

13:07.000 --> 13:12.000
What it does is it gives you a visualization of all of your dependencies,

13:12.000 --> 13:15.000
lets you see exactly what you're using, how you're importing,

13:15.000 --> 13:18.000
and has some nice visualization on top of it.

13:18.000 --> 13:23.000
And I think using things like this helps you to figure out what your risk is

13:23.000 --> 13:30.000
and what the potential scope is of your application and how vulnerable you are as a project.

13:31.000 --> 13:37.000
So everyone knows Coca-Cola and it's very secret, right?

13:37.000 --> 13:42.000
So the secret recipe is locked in a vault, very secure, nobody actually knows

13:42.000 --> 13:46.000
what is exactly in Coca-Cola, that's their trade secret.

13:46.000 --> 13:49.000
I think we pretty much all know what's in it now.

13:49.000 --> 13:56.000
But there's this aura of mystery about the recipe and the history behind it.

13:56.000 --> 14:01.000
And so how do we as software developers or as projects, open source projects,

14:01.000 --> 14:03.000
keep our secrets?

14:03.000 --> 14:07.000
And the reality is we do a very bad job of it.

14:07.000 --> 14:12.000
So this is all of the exposed secrets in different central repositories,

14:12.000 --> 14:20.000
which we found by scanning NPM, PyPy, RubyGems, crates.io, Docker Hub.

14:20.000 --> 14:25.000
Obviously Docker Hub being the biggest repository and having large containers,

14:25.000 --> 14:27.000
which came in a lot of other software.

14:27.000 --> 14:32.000
There was just a humongous number of secrets exposed, 5.78 million.

14:32.000 --> 14:39.000
But even the software repositories like NPM had 1.16 million, PyPy had 0.43 million.

14:39.000 --> 14:44.000
So there's a lot of accidental exposure of secrets in open source repositories.

14:44.000 --> 14:48.000
This is yet another attack vector which attackers get into open source projects

14:48.000 --> 14:53.000
and allows them to attack the CI CD infrastructure, cloud accounts,

14:53.000 --> 14:55.000
which the projects are using.

14:55.000 --> 15:03.000
And even there's often accidental leaks of corporate secrets inside of open source repositories.

15:03.000 --> 15:07.000
Because as a developer you're working in the daytime on your corporate projects.

15:07.000 --> 15:10.000
And then evenings and weekends you're working on open source projects.

15:10.000 --> 15:12.000
And there's a certain amount of crossover in that as well.

15:12.000 --> 15:17.000
So the top ways you can help to prevent this from happening in your own project.

15:17.000 --> 15:22.000
So first is not using automation to check for secrets exposures.

15:22.000 --> 15:26.000
So using something like Truffle Hog, some sort of commercial scanner like X-Ray,

15:26.000 --> 15:31.000
allows you to scan your packages before you check it in to make sure you don't have exposed secrets.

15:31.000 --> 15:37.000
This is how we found that we basically ran our tooling on top of central repositories to see exposed secrets.

15:37.000 --> 15:41.000
Second one is generating tokens with broad permissions that never expire.

15:41.000 --> 15:46.000
So you always want to have the tokens scoped as small as possible in terms of what they can do.

15:46.000 --> 15:51.000
And then setting expirations in a reasonably short time frame so you're rotating keys at the right times.

15:52.000 --> 15:55.000
Third one is no access moderation for the secret.

15:55.000 --> 16:04.000
So putting it inside of some of service like HashiCorp Vault or Docker Secrets or something will help to protect your secrets and tokens.

16:04.000 --> 16:08.000
Fourth is fixing a leak by unpublishing the token.

16:08.000 --> 16:11.000
So this is a really, really common mistake.

16:11.000 --> 16:15.000
But you can't simply check in a new revision which deletes the token.

16:15.000 --> 16:19.000
Because then, you know, Git has long history, it's going to remember it.

16:19.000 --> 16:24.000
Now, if you followed point two and you have very short-lived tokens or very small scope,

16:24.000 --> 16:29.000
that limits the damage because by the time somebody finds it, it's likely not useful anymore.

16:29.000 --> 16:36.000
But again, a big mistake, you actually have to go and rotate the token to fully mitigate the issue.

16:36.000 --> 16:40.000
And of course, you know, exposing unnecessary assets publicly.

16:40.000 --> 16:48.000
So we saw a lot of cases where in test libraries and other like code which was not the main library code,

16:48.000 --> 16:52.000
there were secrets exposed that were visible to infrastructure.

16:52.000 --> 17:00.000
And in some cases, it looked like that the test code or the other like side cards beside the main code base were not even meant to be published.

17:00.000 --> 17:02.000
They were kind of, you know, more internal code.

17:02.000 --> 17:07.000
Okay, so to safely use open source, we also need standards.

17:07.000 --> 17:11.000
I think if we've ever, you know, gone to a restaurant, this is really common.

17:11.000 --> 17:14.000
This is in New York City, they have like letter grading on restaurants.

17:14.000 --> 17:17.000
They have like, you know, reviewing of the source.

17:17.000 --> 17:23.000
And I think a great way of doing this for open source software is the new OpenSSF Score Cards project.

17:23.000 --> 17:29.000
So basically what this does is this gives you nice tooling for Git and a command line.

17:29.000 --> 17:31.000
It'll analyze your project.

17:31.000 --> 17:33.000
It will give you a score.

17:33.000 --> 17:38.000
It's kind of like up to you to interpret the score for the different things that it analyzes.

17:38.000 --> 17:43.000
But it tells you about code vulnerabilities, maintenance, continuous testing, build risk assessment,

17:43.000 --> 17:47.000
source risk assessment, so a wide set of different things on your project.

17:47.000 --> 17:54.000
And helps you figure out like how much risk is in your project, but also more importantly how much risk is in upstream projects.

17:54.000 --> 18:01.000
Because if you have dependencies on projects which are vulnerable, then your project itself is vulnerable.

18:01.000 --> 18:09.000
Okay, and I think, you know, given we're in 2024 and clearly the machines have been taking over.

18:09.000 --> 18:17.000
So it wouldn't be complete if we didn't talk about what's happening with security of machines, machine models,

18:17.000 --> 18:24.000
and some of the code which we're leveraging to make better use of AI infrastructure.

18:24.000 --> 18:28.000
And unfortunately it's not looking that good for us so far.

18:28.000 --> 18:37.000
So ML models, so the machine learning models which we all use and publish to public repositories like Huggingface,

18:37.000 --> 18:44.000
they are highly vulnerable and this is, we're already seeing a bunch of attacks against these public repositories

18:44.000 --> 18:49.000
with malicious actors injecting payloads into it.

18:49.000 --> 18:58.000
And it's not very hard to do so the H5 format, the Huggingface format actually gives you the ability to put inside of it

18:58.000 --> 19:05.000
information that is basically executable code that sits alongside your model.

19:05.000 --> 19:10.000
So the developers have figured this out and basically from the moment you install the model, they can run some code on your system.

19:10.000 --> 19:18.000
So as a developer there's always the possibility, there's already the possibility of simply using models inside of Huggingface

19:18.000 --> 19:23.000
and other public repositories could expose your development environment to risks.

19:23.000 --> 19:32.000
And basically this is an example of the base 64 payload and you can run whatever you want to inside of the model.

19:32.000 --> 19:38.000
Another attack for injecting malicious packages is exploiting the generative AI.

19:38.000 --> 19:50.000
So if you're using technologies like chatGPT and other generative AI technologies, what they'll often do is they'll suggest packages that you should use as part of your code.

19:50.000 --> 19:53.000
And AI algorithms are prone to hallucinations.

19:53.000 --> 20:03.000
Hucinations are actually quite predictable and a lot of the standard code queries which people ask for will include perfectly valid dependencies,

20:03.000 --> 20:09.000
but they'll also include fake dependencies which don't exist, packages which don't exist in NPM, PyPy, etc.

20:09.000 --> 20:17.000
So hackers have already figured out that by uploading the packages and putting malicious packages in the place of the libraries which the generative

20:17.000 --> 20:26.000
AI is producing you can effectively cause people using chatGPT to execute malicious code.

20:26.000 --> 20:33.000
So another potential exploit and now even the AI is introducing vulnerabilities into your code.

20:33.000 --> 20:42.000
So here are some examples of perfectly reasonable queries, for example requesting, generating an endpoint that returns file contents, right?

20:42.000 --> 20:51.000
So this code is vulnerable. If you now do a couple dot dot back dot dot slashes you're going to end up in other directories,

20:51.000 --> 21:01.000
you're going to get access to files you shouldn't. And now if we again ask chatGPT, like, okay, we'll give us a secure endpoint that returns a file for user input and prevents directory reversal.

21:01.000 --> 21:07.000
It gives us a more complicated example, but this is still exposed to URL exploits.

21:07.000 --> 21:15.000
So as developers we can't really trust the current generation of algorithms for code suggestions to give us secure code.

21:15.000 --> 21:28.000
And the attackers know this and this now makes a very easy class of security vulnerabilities which are likely to get injected into open source projects and other work simply by the fact that it's being recommended.

21:29.000 --> 21:38.000
And something we're going to be publishing soon. So this is kind of, you guys are getting the before official publication on this.

21:38.000 --> 21:55.000
So basically what we did is we went into hugging face, Kaggle and some of the public repositories, ran our detection on malicious packages to figure out like what the current exposure of developers is in the ecosystem.

21:56.000 --> 22:05.000
And we found over 60 models which contain malicious behavior. We analyzed the payloads. Some of them were not truly malicious, but some of them were malicious.

22:06.000 --> 22:24.000
And basically it allowed the attackers to run code on local environments. I believe we're scheduled in another week or so on the JFrog research blog to publish the results of this, but we're, of course, doing the right disclosures to the, to hugging face and Kaggle so they can take down the models before people actually extract the data.

22:25.000 --> 22:46.000
And we exploited it. And I think building awareness of these sort of attacks helps the entire open source security ecosystem because we're the ones both in, you know, in this room building software build material standards but also in the general open source security space you have to figure out solutions so these sort of attacks don't become the next solar winds.

22:47.000 --> 22:57.000
Okay, so you can find a little bit more about the stuff I've been talking about for research with the JFrog research team at our research blog. This isn't our like commercial blog, just the research guys publish here. So it's all the fun stuff.

22:58.000 --> 23:07.000
And hopefully together we can create a more secure software supply chain. So thank you very much for having me at the software build materials room today.

23:07.000 --> 23:31.000
Okay, if you guys don't mind, I want to do a quick selfie with the audience. So what's a good, what's a good security sign? Log for J, log for J. Okay, let's give a thumbs up for log for J. Cool.

23:31.000 --> 23:45.000
Alright, thanks everybody for joining. And I think we have five minutes for questions if folks want to ask questions or if you need a breather because this room is very hot. I feel free to leave the room as well.

23:50.000 --> 23:56.000
Any work on combining S-bombs with stored secrets and verification, things like that?

23:56.000 --> 24:13.000
I think that's a good question. So I don't know if there's any work going on now about getting secrets as part of software like S-bombs, but maybe that's a good addition for the standards. Yeah, thank you.

24:27.000 --> 24:45.000
Yeah, so the question is what kind of vulnerability is X-ray handles. So I would say we're clearly in the application security department, APSEC. So we find malicious dependencies. We find like secrets detection, like I mentioned.

24:46.000 --> 25:00.000
We do stuff. We actually can build SBDX Cyclone DX files with both regular vulnerability info and also the new VEC standard. We don't currently do anything with runtime security, although that's coming.

25:03.000 --> 25:10.000
Our package manager, Artifactory is open source. X-ray is proprietary. Yeah.

25:16.000 --> 25:22.000
Okay, so Kay asked if I've looked at any of the stuff that's happening in AI for SBDX.

25:22.000 --> 25:23.000
AI and data.

25:23.000 --> 25:33.000
AI and data. And so I know about the working group that's collaborating on this stuff, but I haven't looked at any of the new stuff. Yeah. But I'm very interested to see what you're doing.

25:33.000 --> 25:46.000
Okay, we'll do. Okay. Thanks everybody.

