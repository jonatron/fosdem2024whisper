WEBVTT

00:00.000 --> 00:08.440
All right, welcome everybody.

00:08.440 --> 00:12.240
We'll continue with Ruf, Seth and Data Security.

00:12.240 --> 00:14.080
So I'll hand it over to our speakers.

00:14.080 --> 00:15.080
Thank you.

00:15.080 --> 00:16.080
Thank you.

00:16.080 --> 00:25.360
Well, it's very nice to be at FOSDEM.

00:25.360 --> 00:26.360
It's first for me.

00:26.360 --> 00:31.440
I'm glad to have made it here.

00:31.440 --> 00:37.520
We work for IBM, but as you can hear from my voice, I had a little bit of a tough time

00:37.520 --> 00:38.520
traveling.

00:38.520 --> 00:47.720
So instead of wearing my corporate circular 223.7 compliant blue shirt, you get my academic

00:47.720 --> 00:53.720
look instead, which for those of you that are local gives you a great joke because it

00:53.720 --> 00:59.520
took me as a Harvard graduate 10 minutes to find the stairs to this floor.

00:59.520 --> 01:02.320
So anyway, jet lag.

01:02.320 --> 01:04.840
Let's call it jet lag.

01:04.840 --> 01:14.360
So my marketing manager taught me an important lesson years ago, which is it's my practice

01:14.360 --> 01:15.880
not to introduce yourself.

01:15.880 --> 01:20.640
So the short version is had the privilege of spending my entire career in open source

01:20.640 --> 01:21.640
or nearly so.

01:21.640 --> 01:26.200
I spent the last 10 years working on Seth.

01:26.200 --> 01:29.560
Before that, I was the product person for Ubuntu Server.

01:29.560 --> 01:38.080
And before that, I was the very much feared systems management at SUSE.

01:38.080 --> 01:43.480
A bunch of other things that I worked on was the maintainer of man for about 10 years.

01:43.480 --> 01:48.560
A picture there with the clouds is because they wrote a book on AWS, stuff like that.

01:48.560 --> 01:52.440
I think that's enough for me.

01:52.440 --> 01:58.960
Hi, everyone.

01:58.960 --> 02:02.360
I'm Sage McTaggart and I use they them pronouns.

02:02.360 --> 02:06.280
I'm also at IBM and working on cybersecurity.

02:06.280 --> 02:15.080
I come from a decision to leave academia and work at Red Hat and then we move to IBM.

02:15.080 --> 02:20.120
And in terms of that side of my background, I've done everything from theoretical computer

02:20.120 --> 02:26.720
science, focusing on things like formal language theory, oblivious computation to just plain

02:26.720 --> 02:28.800
storage system security.

02:28.800 --> 02:32.160
I strongly support open source.

02:32.160 --> 02:35.840
I love implementing the principles in my work.

02:35.840 --> 02:41.200
And I am really excited to talk about sort of the work that we've been doing on a security

02:41.200 --> 02:49.440
side within IBM because it's not all writing little toy languages for provable security.

02:49.440 --> 02:51.000
It's solving practical problems.

02:51.000 --> 02:59.400
So you'll hear a lot about that for me later.

02:59.400 --> 03:05.240
So I think this being the SDS Dev Room, we're going to spare you the introduction to SAF

03:05.240 --> 03:09.440
and the introduction to Rook.

03:09.440 --> 03:10.440
But they're awesome.

03:10.640 --> 03:13.040
Let's just sum it up as that.

03:13.040 --> 03:15.560
So let's start with security.

03:15.560 --> 03:21.720
So security practices are hard in a specific point of the infrastructure.

03:21.720 --> 03:26.720
Cherry picking practices without a model of the threat in the attacker is not a viable

03:26.720 --> 03:27.720
strategy.

03:27.720 --> 03:31.520
The joke usually goes that to make a computer secure, you cover it in concrete, drop it

03:31.520 --> 03:35.920
at the bottom of the ocean and all that.

03:35.920 --> 03:38.760
But that's not a very useful computer.

03:38.760 --> 03:44.800
If you want to protect from all possible threats, you get a machine that is not very helpful

03:44.800 --> 03:47.080
in solving any of your problems.

03:47.080 --> 03:54.680
So what you do is that you define security in the context of your application and your

03:54.680 --> 03:55.680
users.

03:55.680 --> 03:57.240
Who are your adversaries?

03:57.240 --> 04:01.280
Who is most likely to attack you and you prioritize that?

04:01.280 --> 04:07.520
Yes, there are some theories of security that say patch everything, protect from everything.

04:07.520 --> 04:12.960
But the reality is if you don't pick your priorities, then you have no priorities.

04:12.960 --> 04:15.800
If you are trying to do everything, you're doing nothing.

04:15.800 --> 04:22.240
So some of these actors want to cryptologue you and hold you for ransom.

04:22.240 --> 04:25.920
Others are just happy to delete your data and cause a disruption.

04:25.920 --> 04:28.240
These are very different threats.

04:28.240 --> 04:30.040
Script kiddies, who knows what they're up to?

04:30.040 --> 04:35.200
Just some excitement.

04:35.200 --> 04:36.840
Organized crime wants money back.

04:36.840 --> 04:43.560
So you profile your adversary and you define what your threat model looks like and then

04:43.560 --> 04:46.840
you start hardening for that threat model.

04:46.840 --> 04:48.360
So let's dive right in.

04:48.360 --> 04:51.160
The public security zone, let's start from the network.

04:51.160 --> 04:59.560
The public security zone in SF network is an entirely untrusted area of the cloud.

04:59.560 --> 05:05.080
It could be the internet as a whole or just networks external to your cluster.

05:05.080 --> 05:07.520
You have no authority over.

05:07.520 --> 05:13.360
Data transmissions crossing this zone should make use of encryption.

05:13.360 --> 05:19.760
Note that the public zone, as I just defined it, does not include the storage cluster front

05:19.760 --> 05:25.760
end, the SF public underscore network, which defines the storage front end and properly

05:25.760 --> 05:28.240
belongs in the storage access zone.

05:28.240 --> 05:33.280
So don't confuse the two.

05:33.280 --> 05:38.840
The SF client zone refers to networks accessing SF clients like the object gateway, the SF

05:38.840 --> 05:41.640
file system, or block storage.

05:41.640 --> 05:45.520
SF clients are not always excluded from the public security zone.

05:45.520 --> 05:51.000
For instance, it is possible to expose the object gateways as three-year swift interfaces

05:51.000 --> 05:53.080
in the public security zone.

05:53.080 --> 06:01.480
Next, the storage access zone is instead an internal network providing SF clients with

06:01.480 --> 06:05.400
access to the storage network itself.

06:05.400 --> 06:11.040
Finally, the cluster zone refers to the most internal network providing storage nodes with

06:11.040 --> 06:16.520
connectivity for application, hard beat, backfill, recovery, and all that.

06:16.520 --> 06:23.200
This zone includes the SF clusters backend network called the clustered network in SF.

06:23.200 --> 06:29.320
Operators often run clear text traffic in the cluster zone relying on the physical separation

06:29.320 --> 06:33.880
or VLAN segregation of the network from other traffic.

06:33.880 --> 06:39.120
This would not be a valid choice going back to the previous point if your threat model

06:39.120 --> 06:45.200
includes privileged adversarial insiders.

06:45.200 --> 06:47.960
But it's perfectly fine if you're dealing with script kiddies.

06:47.960 --> 06:51.720
So again, threat profile.

06:51.720 --> 06:58.640
These four zones are separately mapped and combined depending on the use case and threat

06:58.640 --> 07:03.600
model on your actual physical and VLAN network.

07:03.600 --> 07:08.640
Components spanning the boundary of two security zones with different trust or authentication

07:08.640 --> 07:12.040
requirements must be carefully configured.

07:12.040 --> 07:14.920
These are natural weak points.

07:14.920 --> 07:20.000
Maybe they're not natural weak points, but they are natural targets in network architecture

07:20.000 --> 07:24.840
and should be always configured to meet the requirements of the highest trust level of

07:24.840 --> 07:28.120
the two zones or the two or three zones.

07:28.800 --> 07:29.800
Connected.

07:29.800 --> 07:34.280
In many cases, the security controls should be a primary concern due to the likelihood

07:34.280 --> 07:38.800
of probing for misconfiguration.

07:38.800 --> 07:44.120
Operators should consider exceeding zone requirements at integration points, which for a storage

07:44.120 --> 07:50.920
product is usually easier to accomplish than it would be for something more generic like

07:50.920 --> 07:53.160
an operating system.

07:53.160 --> 07:57.640
For example, the cluster security zone can be isolated from other zones easily because

07:57.640 --> 08:00.320
there is no reason for it to connect to other zones.

08:00.320 --> 08:05.200
Conversely, an object gateway in the client security zone will need access to the cluster

08:05.200 --> 08:15.920
security zones monitors 6789 OSDs on 6800 all the way to however many OSDs you have

08:15.920 --> 08:23.600
and will likely expose its S3 API to the public security zone ports 80 and 443.

08:23.600 --> 08:29.680
I think that's right.

08:29.680 --> 08:32.680
There we go.

08:32.680 --> 08:34.680
Thank you.

08:34.680 --> 08:37.360
Hi, everybody.

08:37.360 --> 08:40.320
So many people might be curious.

08:40.320 --> 08:42.920
We moved to IBM about a year ago.

08:42.920 --> 08:46.880
What's it like to move companies as an open source product?

08:46.880 --> 08:50.400
And the security of a product, we worry a lot about that.

08:50.400 --> 08:52.160
We're going to discuss that, of course.

08:52.160 --> 08:57.560
But how do we support it in a realistic way within industry?

08:57.560 --> 09:02.760
We can obviously find, we can make a fork of an open source product that's no longer

09:02.760 --> 09:06.680
supported, but do you really want to be in charge of maintaining that, updating all of

09:06.680 --> 09:08.680
its dependencies?

09:08.680 --> 09:10.400
Not necessarily.

09:10.400 --> 09:15.440
So I'll be discussing some aspects of IBM product security, how that's been going in

09:15.440 --> 09:19.600
practice and in theory, and I'll discuss some of our accomplishments and what we're

09:19.600 --> 09:22.400
planning going forward.

09:22.400 --> 09:29.240
So in terms of product security, we follow a secure development life cycle with the goal

09:29.240 --> 09:32.600
of reducing risk and improving security for Seth and Rook.

09:32.600 --> 09:33.920
We suggest improvements.

09:33.920 --> 09:35.120
We pen test.

09:35.120 --> 09:37.160
We manifest all of our dependencies.

09:37.160 --> 09:39.000
We review vulnerabilities.

09:39.000 --> 09:41.480
We track weaknesses.

09:41.480 --> 09:43.640
We review them at any exploits.

09:43.640 --> 09:47.560
We're approving all of our Arata releases, making sure all the details are correct so

09:47.560 --> 09:55.160
that anybody, customer or not, can look and say, okay, what does this release fix?

09:55.160 --> 10:02.320
And as a result, we've been trying to modify this to work within a different model from

10:02.320 --> 10:05.640
Red Hat to IBM.

10:05.640 --> 10:11.480
And one thing that we've done is we've manifested and documented all of our dependencies.

10:11.480 --> 10:13.320
That's a challenge.

10:13.320 --> 10:16.480
I'm not sure if I can officially call it an S-bomb.

10:16.480 --> 10:18.160
That would be a legal question.

10:18.160 --> 10:21.400
But getting there was a challenge.

10:21.400 --> 10:27.600
There are thousands and thousands of dependencies of dependencies, things like that.

10:27.600 --> 10:31.000
We've also automated things like security scanning.

10:31.000 --> 10:34.200
Customers want clean scans, and this is true also in open source.

10:34.200 --> 10:40.920
We get emails on the security list saying, hey, MEND found 200 vulnerabilities, 80% of

10:40.920 --> 10:45.200
them are false positives, half those CVEs have been rejected, but what are you going

10:45.200 --> 10:46.880
to do to fix it?

10:46.880 --> 10:52.800
So we're working to reduce even our lowest risk vulnerabilities as long as it's actually

10:52.800 --> 10:54.320
a vulnerability.

10:54.320 --> 10:59.600
We're onboarded fully with IBM P-Cert, and we're fixing all of our prior vulnerabilities

10:59.600 --> 11:01.960
no matter how low risk.

11:01.960 --> 11:06.160
That might seem silly, but it's a common compliance request.

11:06.160 --> 11:11.640
And in theory, somebody could find an exploit for even a very low CVE, and then it suddenly

11:11.640 --> 11:14.280
is no longer such a low risk CVE.

11:14.280 --> 11:17.640
Suddenly it's actually an implemented one.

11:17.640 --> 11:23.400
And we're also trying to make our lives easier for the programming team and my work easier

11:23.400 --> 11:29.000
as well by automating all most of our dependencies.

11:29.000 --> 11:33.640
We'll see how realistic it is to do all, but most is definitely true.

11:33.640 --> 11:39.520
This can oftentimes break builds though, because sometimes the code might have been refactored,

11:39.520 --> 11:40.520
details might change.

11:40.520 --> 11:43.920
It's not just as simple as update this number.

11:43.920 --> 11:49.480
So we're building that into our release cycle, and we're starting by prioritizing libraries

11:49.480 --> 11:56.480
and dependencies with many CVEs per release, which thankfully they're finding the CVEs,

11:56.480 --> 12:01.360
but we want to start with the known ones first.

12:01.360 --> 12:03.000
So we'll be doing that.

12:03.000 --> 12:08.080
We're continuing to do our work of reviewing existing vulnerabilities, regular security

12:08.080 --> 12:12.920
updates, and just improving our code security preemptively.

12:12.920 --> 12:18.560
We've gotten a lot of upstream engagement since moving to IBM, people emailing the

12:18.560 --> 12:24.080
stuff security list, multiple people with hundreds of vulnerabilities, lots of individual

12:24.080 --> 12:30.760
people emailing it with one or two that we investigate and we're signing CVEs.

12:30.760 --> 12:36.440
We're doing just a lot more there, and we've been implementing more changes based on customer

12:36.440 --> 12:43.920
and upstream requests, such as an update to the OS that the containers are running on.

12:43.920 --> 12:50.120
So we're eventually, in addition to all this, going to be following IBM standards to fix

12:50.120 --> 12:53.720
our vulnerabilities and ensure compliance.

12:53.720 --> 12:58.200
Currently we're fixing all of the backlog of very low risk bugs and vulnerabilities

12:58.200 --> 13:05.800
that we had, and we aim to be fully within IBM SLA and requirements by end of 2024.

13:05.800 --> 13:10.200
That should just give you an idea of how secure upstream stuff is going to be, because again,

13:10.200 --> 13:14.600
these are getting ported between Red Hat, upstream, and IBM.

13:14.600 --> 13:22.600
So how are we going to do this, given that we have a very small security team and a slightly

13:22.600 --> 13:25.560
larger but still very small build team?

13:25.560 --> 13:26.880
The answer is automation.

13:26.880 --> 13:34.720
A lot of this work has historically been very manual, very in-depth, and that's just not

13:34.720 --> 13:41.400
realistic when we're talking about the number of vulnerabilities, the number of people involved,

13:41.400 --> 13:43.560
and the product.

13:43.560 --> 13:49.360
By tracking dependencies, we're finding hundreds of things that we might not have even known

13:49.360 --> 13:52.360
about a while though, because we're like, oh, well, it doesn't really matter.

13:52.360 --> 13:54.400
It's just used in the build process.

13:54.400 --> 13:55.920
Actually it does matter.

13:55.960 --> 14:00.960
So we're trying to write our own internal software for a lot of this work.

14:00.960 --> 14:06.000
We're trying to figure out how to open source it so you aren't just like, hmm, this is some

14:06.000 --> 14:11.400
random IBM specific website that you have to log on to their VPN to get our container,

14:11.400 --> 14:13.120
and this code makes no sense.

14:13.120 --> 14:18.280
No, we want it to actually be available, and that's a challenge, but it's one that we are

14:18.280 --> 14:22.000
investigating, and our commitment remains open source.

14:22.000 --> 14:28.080
So where we're able to open source any of this internal software, it will be open sourced.

14:28.080 --> 14:34.040
If it is incredibly specific, it may not be very useful if it's public, but anything

14:34.040 --> 14:36.760
useful we want to share with industry.

14:36.760 --> 14:39.320
And we're also sharing that within IBM.

14:39.320 --> 14:45.400
For example, one software that we wrote is to find all of our dependencies for our licensing

14:45.400 --> 14:46.400
needs.

14:46.400 --> 14:52.120
So it's about sharing this ethos of open source within our company of, hey, take the software,

14:52.120 --> 14:56.240
you might licensing team, you're spending days filling out spreadsheets.

14:56.240 --> 15:00.820
This is something that by sharing and improving on, your work is easier.

15:00.820 --> 15:05.120
So we're sharing this open source ethos there.

15:05.120 --> 15:09.080
We've also, in terms of automation, we've automated most of our compliance scans via

15:09.080 --> 15:14.080
Jenkins and our build pipeline, reducing the work of incident response from a multi-person

15:14.080 --> 15:20.000
team to something that can be done by one person as part of their job.

15:20.000 --> 15:25.280
And we're documenting all the core parts of the role, trying to define it, and trying

15:25.280 --> 15:28.680
to define what a security process looks like.

15:28.680 --> 15:34.960
Similar to how we did a secure software lifecycle at Red Hat, we're trying to define now, what

15:34.960 --> 15:38.600
does this job look like, what does the documentation look like?

15:38.600 --> 15:44.320
And again, if anything is able to be open sourced or is of use to industry, we definitely

15:44.320 --> 15:47.040
want to share it.

15:47.040 --> 15:53.440
In terms of other new work, again, fixing all CVE fixes, they'll be ported.

15:53.440 --> 15:56.920
New collaboration produces many new challenges.

15:56.920 --> 15:59.360
But it's overall going really well.

15:59.360 --> 16:03.360
Some things that we've done, we've worked to improve the call home functionality and

16:03.360 --> 16:07.880
security for IBM support by applying open source principles.

16:07.880 --> 16:14.200
If a vulnerability is there, customer smells it, people will see it.

16:14.200 --> 16:16.040
Visible bugs are good.

16:16.040 --> 16:18.880
When we know a bug, we can fix it.

16:18.880 --> 16:23.640
So we're working on using stuff also as a back end for AI.

16:23.640 --> 16:27.400
We're happy to talk more, reach out to us, collaborate with us.

16:27.400 --> 16:29.920
What do you want to see with our collaboration with IBM?

16:29.920 --> 16:32.240
Feel free to discuss with us.

16:32.360 --> 16:36.960
I also want to briefly discuss some of our new cryptography work.

16:36.960 --> 16:41.200
So we've been working with IBM research here a bit.

16:41.200 --> 16:44.000
We've been talking with them about confidential and quantum computing.

16:44.000 --> 16:46.200
Now, those are two separate things.

16:46.200 --> 16:51.760
In terms of confidential computing, many of you may be aware of what that is.

16:51.760 --> 16:55.680
It uses a trusted computing module, so you don't necessarily have to trust the server

16:55.680 --> 16:56.920
that CEP is running on.

16:56.920 --> 16:59.280
You just have to trust the TCM within it.

16:59.280 --> 17:04.040
We're talking with IBM research about how would this best fit in with SAP?

17:04.040 --> 17:06.640
If it's viable, we'll be implementing it.

17:06.640 --> 17:12.440
With quantum computing, this is a priority for IBM, and they want to make a lot more

17:12.440 --> 17:14.840
software quantum safe, for example.

17:14.840 --> 17:20.240
So one thing that we're doing there is we're documenting all places where we use cryptography,

17:20.240 --> 17:26.040
determining if it's quantum safer because who the quantum safe requirements are coming

17:26.040 --> 17:28.760
out this year as are the libraries.

17:29.720 --> 17:33.400
We're seeing, are we using public key encryption?

17:33.400 --> 17:37.680
Are we using symmetric encryption, asymmetric encryption?

17:37.680 --> 17:39.560
Where exactly are we using it?

17:39.560 --> 17:44.480
And where can we plug and play in these open source quantum safe cryptography libraries

17:44.480 --> 17:46.280
as they become available?

17:46.280 --> 17:53.240
So those are some of our goals and things that we're working on collaborating with them with.

17:53.240 --> 17:58.720
These are not yet in CEP releases, but this is sort of a road map to the future of

17:59.280 --> 18:00.680
collaboration with IBM.

18:02.200 --> 18:07.880
And moving on to talk a little bit more about how CEP currently does encryption and key management.

18:07.880 --> 18:13.160
Currently, what we do is we encrypt our data at rest.

18:13.160 --> 18:20.080
We have a choice, but most people choose to encrypt their data at rest using the Linux

18:20.080 --> 18:22.960
unified key setup, aka Lux.

18:22.960 --> 18:27.920
All the data, metadata of a CEP storage cluster can be secured using a variety of DM

18:27.920 --> 18:29.640
encrypt configurations.

18:29.640 --> 18:32.120
Almost all of our customers choose to do that.

18:32.120 --> 18:38.440
We implement security best practices by locating our monitor, our Mons on a separate host from

18:38.440 --> 18:43.440
the OSDs that ensures anti-affinity of the keys in the data that they encrypt.

18:43.440 --> 18:48.080
This means that a driver host is physically separated from its decryption keys,

18:48.080 --> 18:52.640
which increases security and is just generally a best practice.

18:52.640 --> 18:57.120
Our object store gateway has some additional capabilities, including encryption at ingest

18:57.160 --> 19:01.960
in time, the use of per user keys, key rotation using tools like Vault.

19:01.960 --> 19:07.320
We support AWS, SS, E, KMS, and others.

19:07.320 --> 19:14.000
We have department of defense ciphers certified under FIPS 140-2 as supplied by reline appropriate

19:14.000 --> 19:15.920
versions.

19:15.920 --> 19:22.160
And for encryption and transit, we have network communication that can be secured by turning

19:22.160 --> 19:26.600
on the CEP protocol encryption and messenger version 2.1.

19:26.600 --> 19:32.520
We do allow clear text as a backup, but it isn't our only option.

19:32.520 --> 19:36.800
You can definitely certify your encryption and transit or use encryption and transit

19:36.800 --> 19:38.560
as well.

19:38.560 --> 19:48.520
And we also have the protocols where the CEP protocol is physically or logically isolated,

19:48.520 --> 19:52.560
but if you again want more security, messenger version 2.

19:52.680 --> 19:57.440
The back end protocols are not encrypted by default, but you absolutely can.

19:57.440 --> 20:00.360
And it gives it just a teeny little bit of latency.

20:00.360 --> 20:05.120
It doesn't really impact the performance that much, especially when CPU overhead is accounted

20:05.120 --> 20:08.160
for.

20:08.160 --> 20:13.560
Looking at more specific protocols for encryption and transit, S3 is usually secured between

20:13.560 --> 20:19.120
the RGW and the S3 client with TLS, port 443.

20:19.200 --> 20:25.120
You can also support plain HTTP on port 80, depending on the nature of your data.

20:25.120 --> 20:30.320
And if you want it to be secured or not, we have a special case with our TLS termination

20:30.320 --> 20:32.640
at HA proxy.

20:32.640 --> 20:38.080
And the link between HA proxy and RGW is in clear text, so it has to be located within

20:38.080 --> 20:40.200
the appropriate security zone.

20:40.200 --> 20:44.600
But as we saw earlier, the security zones are a great feature of Saffron Rook.

20:44.600 --> 20:47.160
So that makes it easier.

20:47.200 --> 20:53.480
And of course, with your network, you want to follow your best practices such as firewalling

20:53.480 --> 20:54.840
individual nodes.

20:54.840 --> 20:57.400
You only want to expose a clear list of ports.

20:57.400 --> 21:03.200
But assuming that you're doing that, that really covers a lot of our encryption and transit.

21:03.200 --> 21:07.640
And let's talk a little bit now about Rook specific and not just Saff.

21:07.640 --> 21:12.800
So Rook can use custom resource definitions to chain code many of these settings.

21:12.800 --> 21:18.360
We can configure our trust certificates for our RGW SWEB server.

21:18.360 --> 21:22.200
Rook supports at rest data encryption, as discussed earlier.

21:22.200 --> 21:27.400
And again, we have in-flight Saff protocol encryption as of 1.9.

21:27.400 --> 21:32.600
Kubernetes user permission system also applies to the persistent volumes here.

21:32.600 --> 21:36.000
Permissions, quotas, all that comes from Kubernetes.

21:36.000 --> 21:38.240
Nothing Rook needs to do here.

21:38.240 --> 21:45.160
And Rook also supports a key management software in the CSI driver, allowing individual volumes

21:45.160 --> 21:47.720
to be encrypted with their own key.

21:47.720 --> 21:49.760
This really limits the scope per key.

21:49.760 --> 21:52.320
Again, security best practices.

21:52.320 --> 21:58.440
So we can follow those like key rotation, revocation, limiting scope from each key.

21:58.440 --> 22:06.720
This really limits the scope of our unencrypted traffic, and it also limits the scope of each key.

22:06.720 --> 22:13.160
And going on to the control plane, as popular as by Ansible, SSH is used by Seth Edmund,

22:13.160 --> 22:18.920
Seth Ansible, and other deployment day one tools to provide a secure command line path

22:18.920 --> 22:23.080
for installation and upgrade operations as part of post management.

22:23.080 --> 22:29.440
We do this so that the dashboard is usually, unless you configure it specifically, is not

22:29.440 --> 22:31.160
exposed to the world.

22:31.160 --> 22:33.880
People can't even see our Grafana dashboard.

22:33.880 --> 22:35.800
It's great.

22:35.800 --> 22:43.320
And also, although we don't want our dashboard to be exposed to the world, it needs to be

22:43.320 --> 22:46.760
reachable by the operator's workstation to be of use.

22:46.760 --> 22:49.080
So that's our control plane here.

22:49.080 --> 22:56.040
And we're doing that with SSH and how we install Saff by default.

22:56.040 --> 22:58.480
The manager supports the whole infrastructure.

22:58.480 --> 23:01.080
It needs to be reachable on the storage access zone.

23:01.080 --> 23:03.080
So we use SSH for this.

23:03.080 --> 23:08.200
And you can see some of our details, such as our port ranges and details like that.

23:08.200 --> 23:15.120
Of course, the operator can modify this to have it suit your local threat model.

23:15.120 --> 23:19.280
But by default, we just try to make it as secure by default so people don't have to

23:19.280 --> 23:22.560
think too much about it.

23:22.560 --> 23:27.800
And with identity and access, Seth's use of shared secret keys protects clusters from

23:27.800 --> 23:31.440
man in the middle attacks by default.

23:31.440 --> 23:35.960
A good practice here is to grant key ring read and write permissions only for the current

23:35.960 --> 23:38.080
user and route.

23:38.080 --> 23:42.360
Limit your client admin user to be restricted to route only.

23:42.360 --> 23:47.320
You don't want all users to be root as per security best practices.

23:47.320 --> 23:53.920
And similarly with RGW, we want to treat the administrator's key and secret with appropriate

23:53.920 --> 23:55.000
respect.

23:55.000 --> 23:58.520
Use your number of administrative users.

23:58.520 --> 24:04.480
And to do so, we support AWS S3, the equivalent model for OpenStack, and the equivalent model

24:04.480 --> 24:06.160
for OpenStack Swift.

24:06.160 --> 24:13.000
Again, that helps your keys and secrets remain secure by using these external software for

24:13.000 --> 24:15.360
your key management.

24:15.360 --> 24:19.400
Your RGW user data is stored within Saff pools.

24:19.400 --> 24:24.840
These are secured previously discussed with data at risk.

24:24.840 --> 24:32.960
We also, in terms of keys, we can couple with OIDC providers such as Keycloak, and those

24:32.960 --> 24:40.000
can be backed with your organization's identity provider for an even more granular role or

24:40.000 --> 24:46.120
attribute access depending on the needs for your system and your threat model.

24:46.120 --> 24:52.280
So for identity and access, we also support LDAP and Active Directory users.

24:52.280 --> 24:58.240
We recommend secure LDAP and we support OpenStack Keystone to authenticate object gateway users

24:58.240 --> 25:01.360
in OpenStack Clouds.

25:01.360 --> 25:07.760
And for auditing, which is another important part of security, we of course support auditing.

25:07.760 --> 25:10.000
Operator actions against a cluster are logged.

25:10.000 --> 25:15.720
You need to periodically remove your logs and you can aggregate them to your log management

25:15.720 --> 25:17.720
system where's appropriate.

25:17.720 --> 25:20.520
Here's an example of what that might look like.

25:20.520 --> 25:22.960
You can see where they're stored.

25:22.960 --> 25:26.440
We can see this example here.

25:26.440 --> 25:32.760
And you know, an action might start on one node, it might propagate to others, and we're

25:32.760 --> 25:33.760
still logging everything.

25:33.760 --> 25:39.080
So I'm going to turn it over to Federico for the end.

25:39.080 --> 25:41.080
And here is data retention.

25:41.080 --> 25:43.080
Thank you.

25:43.080 --> 25:45.080
Yeah.

25:46.080 --> 25:48.080
Alrighty.

25:48.080 --> 25:52.080
Let's see if we can get it through to the end.

25:52.080 --> 26:01.080
So, once they raise the lead, it generally cannot be recovered for practical use.

26:01.080 --> 26:05.080
But like with everything, there are exceptions.

26:05.080 --> 26:14.080
RBD is a new facility called the Trashbin that makes use of spare capacity to preserve

26:14.080 --> 26:19.080
deleted images dynamically until the space is needed.

26:19.080 --> 26:22.080
There are a certain number of days that's elapsed.

26:22.080 --> 26:28.080
You can turn this on or off, but obviously this affects user data retention.

26:28.080 --> 26:36.080
Similarly, in RGW, RGW is an implementation of the S3 protocol in most use cases.

26:36.080 --> 26:38.080
S3 is versioned.

26:38.080 --> 26:43.080
So your data is versioned there unless you configure pools to be not versioned.

26:43.080 --> 26:50.080
So if you're storing user data in RGW, you need to watch that your configurations are,

26:50.080 --> 26:58.080
that your pool configurations are versioned according to the data retention that you want for that data.

26:58.080 --> 27:10.080
Otherwise, obviously the administrator can purge the versioning of RGW buckets, but that's one more thing that you have to account for to ensure compliance.

27:10.080 --> 27:14.080
Then there is explicit secure deletion.

27:14.080 --> 27:17.080
That's the other thing that we usually get asked about.

27:17.080 --> 27:24.080
The data is still on the clusters on the disk.

27:24.080 --> 27:28.080
And like in most storage systems, you cannot just go and say,

27:28.080 --> 27:31.080
I'm trying to overwrite everything to sanitize that.

27:31.080 --> 27:37.080
It won't even work on a standard SSD these days, at least not reliably, which is what you care about.

27:37.080 --> 27:41.080
In the distributed network system, obviously it's not going to work.

27:41.080 --> 27:45.080
So the solution there is doing the right thing from the beginning.

27:45.080 --> 27:47.080
Implement at rest encryption.

27:47.080 --> 27:52.080
When you want to sanitize your media, you forget the encryption key and you're done.

27:52.080 --> 27:54.080
Very easy, very simple.

27:54.080 --> 27:56.080
Also, this is other advantages.

27:56.080 --> 28:03.080
You may want to sanitize your media typically because you have to return them under an RMA policy to have a warranty replacement.

28:03.080 --> 28:08.080
If you try to replace a drive that's being shredded, shot with a shotgun,

28:08.080 --> 28:13.080
or done all sort of untoward things to physically destroy it,

28:13.080 --> 28:18.080
most likely your warranty provider will not send you a new drive for it.

28:18.080 --> 28:22.080
So again, using encryption is the right strategy here.

28:22.080 --> 28:29.080
Also, the majority of drives today does this on hardware for you, so you don't even need to manage.

28:29.080 --> 28:35.080
Set up an encryption key and set up a process to wipe it when the time comes.

28:35.080 --> 28:41.080
Then there is one more scenario, which is when you want to prevent sanitizing of data,

28:41.080 --> 28:44.080
aka ransomware.

28:44.080 --> 28:53.080
So the most interesting bit in CEPHER is that RGW is a second factor authentication thing,

28:53.080 --> 28:59.080
and you can deploy this as a protection against ransomware attacks

28:59.080 --> 29:11.080
so that you essentially ask for a second factor for actions that a ransomware attack would use to re-encrypt your data.

29:11.080 --> 29:16.080
Hardening is relating to binaries.

29:16.080 --> 29:18.080
Hardening options are highly vendor dependent.

29:18.080 --> 29:21.080
These are Red Hat and IBM choices.

29:21.080 --> 29:25.080
Other binaries from other vendors may be different.

29:25.080 --> 29:31.080
Now, we ship with a Silinox on by default, and I don't think that surprises anybody,

29:31.080 --> 29:36.080
given that it's our local religion at Red Hat, and we carried it over to IBM.

29:36.080 --> 29:43.080
FIPS 140, two ciphers like Sage was saying earlier are supported out of REL,

29:43.080 --> 29:49.080
so whenever REL is certified for FIPS 140 or two or now three with REL 9,

29:49.080 --> 29:52.080
those versions can be used with stuff.

29:52.080 --> 29:54.080
They're older versions of REL than the current ones.

29:54.080 --> 30:03.080
There is lag, CISA needs to do the certification, but the option is there.

30:03.080 --> 30:09.080
We're not going to go into these hardening options, but you should be aware that they exist,

30:09.080 --> 30:13.080
and you should be knowing what your vendor uses.

30:13.080 --> 30:18.080
And some bookmarks for you to close.

30:18.080 --> 30:22.080
There are some interesting resources on Kubernetes from Acura Security,

30:22.080 --> 30:25.080
and from a book from O'Reilly called Hacking Kubernetes.

30:25.080 --> 30:29.080
It goes into very much into detail about storage in Chapter 6.

30:29.080 --> 30:32.080
That's Michael Hausenblass' previous book.

30:32.080 --> 30:35.080
The Data Security and Hardening Guide comes from our product,

30:35.080 --> 30:38.080
and it's basically a written version of this talk,

30:38.080 --> 30:42.080
so if you want more, that's where you find it.

30:42.080 --> 30:47.080
Encrypted Secret Data at Rest is essentially another version

30:47.080 --> 30:51.080
of what's in Rani's article.

30:51.080 --> 30:59.080
And the last one is to decrypt those binary flags that I was describing one slide ago.

30:59.080 --> 31:01.080
If you don't know what the GCC flags look like,

31:01.080 --> 31:05.080
or what the kernel hardening options look like,

31:05.080 --> 31:08.080
there is a link there with the linker flags for GCC.

31:08.080 --> 31:11.080
There is also one, we ran out of space.

31:11.080 --> 31:18.080
There is a convenient page on Ubuntu Server project team page

31:18.080 --> 31:23.080
with all the kernel hardening options, so you can find what they are.

31:23.080 --> 31:30.080
And then you look for your vendor, what the setting for that specific option is.

31:30.080 --> 31:32.080
And that's it.

