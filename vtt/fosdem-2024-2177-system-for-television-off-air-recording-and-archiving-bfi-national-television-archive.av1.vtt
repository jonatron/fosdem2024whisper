WEBVTT

00:00.000 --> 00:15.040
So, our next speaker is Joanna White and we talk about the system of television affair

00:15.040 --> 00:17.200
recording and archiving.

00:17.200 --> 00:20.840
BFI National Television Archive.

00:20.840 --> 00:23.400
Welcome, Herr.

00:23.400 --> 00:24.400
Thank you.

00:24.400 --> 00:28.920
Thank you.

00:28.920 --> 00:30.520
It's wonderful to be here today.

00:30.520 --> 00:33.680
Thank you for coming and thank you to FOS STEM for letting us speak here.

00:33.680 --> 00:38.160
I am Joanna White, developer at the BFI National Archive in the Data and Digital Preservation

00:38.160 --> 00:39.160
Department.

00:39.160 --> 00:43.480
Today I'll be talking briefly about STORA, System for Television Offair Recording and

00:43.480 --> 00:44.480
Archiving.

00:44.480 --> 00:46.400
It's a project that we've built in-house.

00:46.400 --> 00:50.960
So the BFI or the British Film Institute promote and preserve film and television across the

00:50.960 --> 00:56.600
UK and the BFI National Archives Department within the BFI and is also one of the largest

00:56.600 --> 00:58.920
archives in the world.

00:58.920 --> 01:02.920
So we have nearly one million digitized moving image assets in our digital preservation

01:02.920 --> 01:05.640
infrastructure or DPI as we call it.

01:05.640 --> 01:10.280
That means they've been ingested into our Spectralogic tape libraries for long-term preservation

01:10.280 --> 01:14.880
and they've also been catalogued in our collections information database, what we call SID.

01:14.880 --> 01:19.760
By far the largest collection of moving image materials in our off-air is our off-air television

01:19.760 --> 01:24.760
recordings with nearly 650,000 program files in DPI.

01:24.760 --> 01:26.800
You can see a selection of them here displayed.

01:26.800 --> 01:28.800
This is our staff DPI browser.

01:28.800 --> 01:29.800
It's internal.

01:29.800 --> 01:34.000
There's also a further 800,000 preserved.

01:34.000 --> 01:39.440
This is off-air recordings waiting to be processed and ingested and seeded in a future project.

01:39.440 --> 01:44.200
So the BFI is the body designated by OFCOM as the National Television Archive.

01:44.200 --> 01:48.960
Under the Provision and the Broadcasting Act of 1990, the designation allows us to record,

01:49.040 --> 01:54.800
observe and make accessible TV off-air under section 75 of the Copyright Designs and Patents

01:54.800 --> 01:59.600
Act of 1988 and later the Copyright and Rights and Performance Regulations 2014.

01:59.600 --> 02:02.440
Okay, that's the official bit.

02:02.440 --> 02:07.560
The BFI National Archive began recording off-air TV to one-inch real videotapes as you can

02:07.560 --> 02:12.720
see here in 1985 with the permission of select UK broadcasters.

02:12.720 --> 02:17.880
Programs were captured, curatorially chosen, captured by teams who would work there around

02:17.920 --> 02:19.760
the clock in shifts.

02:19.760 --> 02:25.960
In 2015, off-air TV recording became an automated process for us when we started collecting

02:25.960 --> 02:28.360
live TV programs 24-7.

02:28.360 --> 02:33.840
To do this, the BBC agreed to provide us with a fork of their Redux Off-air Capture Project,

02:33.840 --> 02:34.920
which you can see here.

02:34.920 --> 02:39.440
We worked with BBC developers to integrate it into our digital preservation infrastructure.

02:39.440 --> 02:46.320
The goal was to store MPEG TS files to our Spectrologic Tape Libraries for long-term storage.

02:46.320 --> 02:48.280
This is built on open-source technology.

02:48.280 --> 02:52.520
It's run from Linux, installed servers and uses open-source tools to record both television

02:52.520 --> 02:54.840
and radio programming for the BBC.

02:54.840 --> 02:57.800
At the BFI, we just use it for off-air television.

02:57.800 --> 03:02.560
So in May 2022, BBC Redux was shut down.

03:02.560 --> 03:07.240
In anticipation, the head of my department, head of data and digital preservation, Stephen

03:07.240 --> 03:11.720
McConnacky, launched our own R&D project the year before.

03:11.720 --> 03:16.120
Along with two BFI engineers, John Daniel and Brian Fattarini, we built the software recording

03:16.120 --> 03:22.300
solution to emulate many features of Redux with the name not to disrupt our existing

03:22.300 --> 03:25.880
DPI ingest workflows during that change over period.

03:25.880 --> 03:30.280
So like Redux, Stora records satellite-streamed UK broadcasts.

03:30.280 --> 03:34.440
The channels are a mix of high definition and standard definition streams, many broadcasting

03:34.440 --> 03:36.040
24 hours a day.

03:36.040 --> 03:41.640
One full day of off-air recording captures around 500 programs to our storage.

03:41.640 --> 03:48.400
That's roughly 850 gigabytes of data, and that's roughly 300 terabytes every year.

03:48.400 --> 03:53.200
So we receive our signals from Astra Satellites, which broadcast mostly direct-to-home TV channels

03:53.200 --> 03:54.200
in Europe.

03:54.200 --> 03:57.520
It is nice to be considered still in Europe in this regard.

03:57.520 --> 04:02.200
They're received by our satellite dishes, passed through Quattro low-noise blocks before

04:02.200 --> 04:06.080
passing through TVS, TV, PCI receiver cards.

04:06.080 --> 04:09.880
The signals are routed through patch fields to a multi-switch, which selects band and

04:09.880 --> 04:11.280
polarization.

04:11.320 --> 04:16.280
We use three multi-switches for Stora so we can have 24 potential multiplexes.

04:16.280 --> 04:20.720
We've got a SESPA application, which demuques each channel's MPEG transport stream into

04:20.720 --> 04:27.320
a single program transport stream, creating a Unicast real-time transport protocol, or

04:27.320 --> 04:32.680
RTP stream, and a Unicast user datagram protocol, or UDP stream.

04:32.680 --> 04:34.360
We need both for our recording method.

04:34.360 --> 04:38.160
If you'd like to know more about the hardware setup, I can put you in touch with my colleague.

04:38.160 --> 04:40.960
It's not my area, I'm afraid.

04:40.960 --> 04:45.000
For those of you who are familiar with BBC Redux, you may recognise the folder naming

04:45.000 --> 04:48.160
convention and the contents of the folders.

04:48.160 --> 04:53.520
As I said, we have automated ingest workflows that needed this structure to be maintained.

04:53.520 --> 04:58.360
The folder path comprises recording date, channel name, and individual program broadcast

04:58.360 --> 05:01.640
time data in the name of the folder.

05:01.640 --> 05:05.720
We've got also the Unic event ID, which is for the program that's being shown, in this

05:05.720 --> 05:07.800
case 476.

05:07.800 --> 05:11.680
With the folder, you'll find three files, the Info CSV.

05:11.680 --> 05:16.200
This file contains program information, including channel, title, description, etc.

05:16.200 --> 05:19.360
Next, we have the Stream MPEG TS file.

05:19.360 --> 05:21.880
This is the recording captured from the broadcast.

05:21.880 --> 05:26.320
This is not encoded stream, but it's just dumped directly to storage, so it contains

05:26.320 --> 05:32.600
the packetised elementary streams, which wrap the main data stream, usually H264, video

05:32.600 --> 05:38.720
codec, AC3, or MPEG audio, subtitles, also in there, and information tables.

05:38.720 --> 05:43.000
You can view all this data really nicely when you look at it in VLC.

05:43.000 --> 05:48.120
Finally, we have the subtitles in there, which contains an extracted transcript of all the

05:48.120 --> 05:49.680
spoken word from the program.

05:49.680 --> 05:54.680
It's formatted as a Web Video Text Tracks format, or Web VTT.

05:54.680 --> 05:58.480
Making sure that we don't lose any of this information is really critical to our preservation

05:58.480 --> 06:01.160
goals.

06:01.160 --> 06:05.040
Storage code has been made possible by a wonderful collection of open source tools, which you

06:05.040 --> 06:06.040
can see here.

06:06.040 --> 06:10.080
We have Linux Ubuntu operating systems, and we use Linux command line tools throughout

06:10.080 --> 06:11.560
the code.

06:11.560 --> 06:19.440
Storage is written in Python, and a few external libraries such as Tenacity and Python VLC.

06:19.440 --> 06:24.120
Python VLC allows us to work easily in the code with the amazing software VLC from Video

06:24.120 --> 06:25.120
LAN.

06:25.120 --> 06:28.080
You'll probably see them, I'll foster them in the hats.

06:28.440 --> 06:32.040
VLC relies on the outstanding FFMPEG libraries to operate.

06:32.040 --> 06:36.600
FFMPEG is kind of worshipped at the BFI and in many archives globally.

06:36.600 --> 06:42.320
LibdVBT passes service information in the UDP streams, and it's key to how the scripts

06:42.320 --> 06:44.200
record the programs.

06:44.200 --> 06:50.840
Media Info provides detailed technical metadata for analysis of the MPEG TS files.

06:50.840 --> 06:56.080
CC Extractor extracts the subtitles from the MPEG TS file, saving them to a separate formatted

06:56.080 --> 07:01.280
file, and Nagios Core provides a monitoring service for real-time alerts when streams

07:01.280 --> 07:03.840
fail or recordings stop for us.

07:03.840 --> 07:07.760
So I'll quickly talk you through how storage uses these pieces of software.

07:07.760 --> 07:15.360
We'll look first at the recording script, which makes the file contain the MPEG transport

07:15.360 --> 07:16.360
stream.

07:16.360 --> 07:20.600
They used to have two recording methods for the storage code base, but they've been merged

07:20.600 --> 07:21.840
into one script now recently.

07:21.840 --> 07:23.800
I'll unpack that shortly.

07:23.840 --> 07:28.720
Both methods capture the MPEG transport stream using VLC, but they differ in how they start

07:28.720 --> 07:31.000
and stop the recording methods.

07:31.000 --> 07:35.440
So the first script I wrote utilizes electronic program-grade metadata, which you can see

07:35.440 --> 07:36.640
at the top.

07:36.640 --> 07:41.080
We get this from a commercial supplier, retrieved daily from their REST API.

07:41.080 --> 07:47.200
The EPG data is converted in Python into a JSON schedule for a single day's programs.

07:47.200 --> 07:50.160
One is created every day for every channel.

07:50.160 --> 07:53.680
Recordings are then prompted to start and stop from this JSON schedule.

07:53.680 --> 07:58.760
The script loops through every scheduled item before it then exits at the end of the last

07:58.760 --> 08:01.520
program, which usually just after midnight.

08:01.520 --> 08:05.280
And then we have shell restart scripts that run from Prontab, which immediately restart

08:05.280 --> 08:10.080
the script again, and it picks up the next day's schedule and carries on.

08:10.080 --> 08:11.720
Quick shout out here.

08:11.720 --> 08:16.840
I'm quite a new developer, and when I had this project placed on my plate, it was a little

08:16.840 --> 08:19.560
bit overwhelming, but I came across this script.

08:19.560 --> 08:26.120
It was on ActiveState code written in 2015, weirdly also written by somebody named J-White,

08:26.120 --> 08:27.120
J-White88.

08:27.120 --> 08:30.040
If anyone knows them, please thank them for me.

08:30.040 --> 08:31.040
Nobody knows them.

08:31.040 --> 08:34.560
I'm going to assume time travel is a thing by the time I'm 88, and I come back in time

08:34.560 --> 08:38.640
and give this to myself, which is a nice idea.

08:38.640 --> 08:42.440
So onto the second and better method for recording the off-air streams.

08:42.440 --> 08:47.640
It monitors the user data-gram protocol stream, UDP stream, and it gets the service information

08:47.640 --> 08:52.800
data, watches for changes in the event ID field for that broadcast stream.

08:52.800 --> 08:54.960
You can see that in the top.

08:54.960 --> 08:57.920
The event ID is that unique identifier for a program.

08:57.920 --> 09:02.920
The script stores the last five event IDs that have been broadcast, and if a new one

09:02.920 --> 09:07.200
turns up, then it knows that there's a new recording that needs to be triggered.

09:07.200 --> 09:12.760
So it should potentially loop indefinitely, monitoring a UDP stream in this way, creating

09:12.760 --> 09:16.920
and placing TV shows into their own unique folder paths, which you've seen.

09:16.920 --> 09:22.160
And these event IDs changes usually always fall right at the beginning of a new program

09:22.160 --> 09:23.400
as it starts to record.

09:23.400 --> 09:28.880
So it's a really very neat way to start and stop the recordings in the schedule.

09:28.880 --> 09:33.160
And another shout-out is needed here for the open-source project Libdvbt.

09:33.160 --> 09:38.680
I think it's a fork from a VLC library, I'm not sure, but it's by Michael Krufke.

09:38.680 --> 09:45.280
It's the stream parser and service information aggregator library for MPEG-2 transport streams.

09:45.280 --> 09:49.840
The recording script calls up dvbt from a Python sub-process spawn shell, captures the

09:49.840 --> 09:53.200
Libdvbt JSON-formatted response.

09:53.200 --> 09:57.120
The command has a time-out flag, which usually ensures the information is returned to you

09:57.120 --> 09:59.840
within two, three, four, five seconds.

09:59.840 --> 10:03.800
This response is reformatted and exported into a Python dictionary, and this provides

10:03.800 --> 10:08.760
the trigger for the VLC record start-stop process.

10:08.760 --> 10:14.280
So just to visualize how this method works, it does require us to have two streams, which

10:14.280 --> 10:17.160
is a little bit awkward, but doesn't really cause us any problems.

10:17.160 --> 10:21.280
So here you can see that the script monitors UDP stream waiting for an event ID number

10:21.280 --> 10:25.640
change in that stream, so from two, six, five, two, four, five, two, six, four, two, six,

10:25.640 --> 10:26.800
five.

10:26.800 --> 10:32.040
When the event ID changes, it's sensed the current VLC streaming recording is stopped

10:32.040 --> 10:36.560
on the RTP stream, and the new folder is created with the start time and duration of the next

10:36.560 --> 10:37.560
program.

10:37.560 --> 10:44.280
So in this folder, the RTP stream is placed, captured by VLC.

10:44.280 --> 10:47.480
And this is the code used to start and stop the VLC recording.

10:47.480 --> 10:52.960
The Python bind needs to create a VLC instance from the instance class in Python VLC and

10:52.960 --> 10:55.240
initiate a new media player object.

10:55.240 --> 11:00.040
Both are called into the main script to start and stop the recordings.

11:00.040 --> 11:05.440
We use the demuxt dump command, which uses a VLC unique codec from the demuxt library,

11:05.440 --> 11:11.880
a tool developed essentially for debugging, but it actually dumps the content directly

11:11.880 --> 11:14.600
to file without decoding it.

11:14.600 --> 11:19.520
I have the append flag also in there so that if a recording breaks midway through a program

11:19.520 --> 11:25.080
and then starts again, it will append it to the existing file and not overwrite it.

11:25.080 --> 11:29.200
If that happens, a restart warning text file is placed into the channel folder with the

11:29.200 --> 11:33.920
date and timestamps so that we can know that there's potentially a break in the stream.

11:33.920 --> 11:36.760
This is pretty rare though, it doesn't happen very often.

11:36.760 --> 11:41.960
So we also rely on media info software in the get stream info script.

11:41.960 --> 11:46.360
It uses the Python sub process again to spawn a media info call capturing the program start

11:46.360 --> 11:48.040
duration metadata.

11:48.040 --> 11:51.760
This is all then dumped into a CSV file.

11:51.760 --> 11:55.440
And then to extract the WebVTT files, we use the software CC extractor.

11:55.440 --> 11:58.240
We launch the software and the Python script again from sub process.

11:58.240 --> 12:01.680
Sub process is so important to these processes.

12:01.680 --> 12:06.520
This is a simple command that flags the WebVTT output format and then creates the file that

12:06.520 --> 12:07.800
you can see here.

12:07.800 --> 12:13.480
We then import this data into our SID database, which is viewable and searchable and provides

12:13.480 --> 12:18.440
a rich text metadata for the curatorial teams.

12:18.440 --> 12:23.960
Lastly, we have Nagios, which is an event monitoring system, which issues alerts when

12:23.960 --> 12:25.040
problems are detected.

12:25.040 --> 12:29.800
We have separate channel alerts for recording failures, which is identified by comparing

12:29.800 --> 12:36.080
a checksum between the current stream MPEG TS file and one four seconds earlier.

12:36.080 --> 12:40.160
And then we also have a stream check, which looks in the Cesbo software for an on air

12:40.160 --> 12:41.560
equals true for every channel.

12:41.560 --> 12:48.320
If either of those fail, then we get a display that says critical, but also we get an email

12:48.320 --> 12:51.760
that's sent to us with the context for what the failure is.

12:51.760 --> 12:56.280
Okay, so that's a rough guide to the store.

12:56.280 --> 13:00.360
In particular, how the code interacts with these open source projects.

13:00.360 --> 13:04.360
The open source repository contains all the store of scripts, descriptions for the code

13:04.360 --> 13:08.800
base, dependencies, environmental variables, and quantum launch details.

13:08.800 --> 13:09.800
It has an MIT license.

13:09.800 --> 13:13.880
I hope it may be of some interest here.

13:13.880 --> 13:16.680
But as a relatively new developer, I'm quite welcome.

13:16.680 --> 13:19.160
I welcome kind of feedback and advice.

13:19.160 --> 13:23.600
None of the team in the data and digital preservation department have computer science backgrounds.

13:23.600 --> 13:26.040
They're all archivists or TV people.

13:26.040 --> 13:29.840
I used to be a cameraman and an independent documentary maker.

13:29.840 --> 13:33.200
To be able to stand here and talk about this project like Stora, with just a few years

13:33.200 --> 13:36.440
coding experience is really mind blowing for me.

13:36.440 --> 13:40.920
And particularly at a time when accurately recording our televised social history is

13:40.920 --> 13:43.200
really just so critical.

13:43.200 --> 13:47.440
So this has really been made possible thanks to the open source tools we use and the developers

13:47.440 --> 13:48.680
we see in the room here.

13:48.680 --> 13:51.560
Thank you from the archiving world.

13:51.560 --> 13:55.560
And there's also quickly a growing interest in audio visual archives globally to try and

13:55.560 --> 13:58.520
work more with open source software and standards.

13:58.520 --> 14:02.000
Many of us meet annually at a conference called the No Time to Wait conference, which happens

14:02.000 --> 14:03.120
here in Europe.

14:03.120 --> 14:05.760
We welcome new attendees, who are developers, definitely.

14:05.760 --> 14:10.240
This conference has been connected with the development of the FFE1 codec, which was originally

14:10.240 --> 14:15.960
an FFMPEG project picked up and expanded by archivists working as developers.

14:15.960 --> 14:20.760
This codec is critical to the BFI's long term preservation of thousands of video and film

14:20.800 --> 14:21.800
assets.

14:21.800 --> 14:27.440
So the maintenance and upkeep of projects like FFMPEG is really very important to us.

14:27.440 --> 14:32.080
Traditionally archives have relied on expensive proprietary hardware, software and codecs that

14:32.080 --> 14:33.680
are not scalable.

14:33.680 --> 14:37.360
They keep their information behind paywalls and they're not likely to offer the kind

14:37.360 --> 14:41.680
of technical support we need long enough into the future for long term preservation.

14:41.680 --> 14:46.080
So having open workflows and standards developed within our own community is incredibly empowering

14:46.080 --> 14:47.080
for us.

14:47.080 --> 14:51.200
And yeah, this is the community where it's happening most, I would say, at the moment

14:51.200 --> 14:52.200
in the UK, in Europe.

14:52.200 --> 14:53.200
That's it.

14:53.200 --> 14:54.200
Thank you.

14:54.200 --> 14:55.200
Thank you.

14:55.200 --> 15:05.280
The next talk will be in five minutes.

