WEBVTT

00:00.000 --> 00:07.000
Real-time processing.

00:07.000 --> 00:10.000
A very brief background.

00:10.000 --> 00:12.000
So I'm Sylvain, Fox 4 Golf Kilo Radio,

00:12.000 --> 00:15.000
this is my amateur radio call sign.

00:15.000 --> 00:18.000
Very briefly about myself, for those who don't know me yet.

00:18.000 --> 00:22.000
I'm the founder of a small company in France, doing SDR.

00:22.000 --> 00:25.000
The name is SDR Technologies.

00:25.000 --> 00:29.000
I'm the most important here to introduce the story about GPU,

00:29.000 --> 00:31.000
and it is the next lines.

00:31.000 --> 00:37.000
So I was working for ONERA, the French Aerospace and, well, military,

00:37.000 --> 00:41.000
I would say affiliated to the Ministry of Defense Research Lab.

00:41.000 --> 00:46.000
And that explains how this started, and I will come back to this in a slide.

00:46.000 --> 00:52.000
So very briefly, the outline of the talk will be that I will explain the motivation

00:52.000 --> 00:58.000
and then try to explain the approach I took when I tested this GPU

00:58.000 --> 01:02.000
and why it came, why I had the idea to use this for DDC.

01:02.000 --> 01:07.000
And you will see, and I tried to take a few minutes to explain the background,

01:07.000 --> 01:10.000
not of the code, because it's on GitHub and you can read it,

01:10.000 --> 01:13.000
and I'm quite sure you will improve it a lot, no doubt.

01:13.000 --> 01:17.000
But just to explain for those who are not yet, who are not familiar with GPU,

01:17.000 --> 01:25.000
and why it can be useful, and what kind of things you can do with it

01:25.000 --> 01:28.000
as long as you take the time to write code in this.

01:28.000 --> 01:32.000
So very briefly, the story started a while ago when I was working at ONERA

01:32.000 --> 01:37.000
where we have radars, and I just took some pictures that you may have seen already.

01:37.000 --> 01:41.000
One is the Nostradamus, it's an HF over the horizon radar,

01:41.000 --> 01:44.000
and the other one is Grav, very famous.

01:44.000 --> 01:48.000
So these two radars were designed and operated in not my team

01:48.000 --> 01:52.000
because I was not leading the team, but in the team I was working in.

01:52.000 --> 01:55.000
One of the key problems here is that you have a lot of channels.

01:55.000 --> 01:57.000
One antenna is one channel,

01:57.000 --> 02:00.000
means that you gather a huge amount of data.

02:00.000 --> 02:04.000
And one of the key problems is how do you process this data in real time.

02:04.000 --> 02:08.000
And at that time, in my, don't remember exactly the year,

02:08.000 --> 02:13.000
NVIDIA released the Tegrar K1, which was very small stuff,

02:13.000 --> 02:19.000
but looking promising, sorry, in particular for embedded systems.

02:19.000 --> 02:23.000
So my boss said, can you have a look at this

02:23.000 --> 02:27.000
and tell us if that can bring anything to the game.

02:27.000 --> 02:32.000
And just to make also the story very short, the answer was yes, it's useful,

02:32.000 --> 02:37.000
and that made my decision to leave the research team and found my company.

02:37.000 --> 02:41.000
So yes, the quick answer is yes, it works.

02:41.000 --> 02:44.000
Okay, so now let's go back to more serious things.

02:44.000 --> 02:49.000
This is from the leaflet, I would say, from the Tegrar K1 at that time.

02:49.000 --> 02:59.000
They were promising something like 326 gigaflops, oh, five watts, 99 euros for the deathboard.

02:59.000 --> 03:02.000
You say, who? Does this really work?

03:02.000 --> 03:04.000
And that was the idea.

03:04.000 --> 03:10.000
That was the idea was to test this if that can be used for software-defined radio.

03:11.000 --> 03:16.000
I'm assuming here that most of you have a very brief and very quick idea of what a GPU is,

03:16.000 --> 03:20.000
so I will just take a few seconds to explain.

03:20.000 --> 03:25.000
I'm just realizing that if I move to the screen, nobody will see from the remote, I guess.

03:25.000 --> 03:29.000
Yeah, okay, I'll try. Sorry.

03:29.000 --> 03:35.000
So just to explain the model, this architecture has two things inside.

03:35.000 --> 03:40.000
You have the ARM ARM processor, this GPU, this is the four cores, this one,

03:40.000 --> 03:46.000
and you have the CUDA cores, 192 cores next to it.

03:46.000 --> 03:50.000
And the good thing is that they share the same memory.

03:50.000 --> 03:56.000
Okay, if you have a PC, you have your core, whatever you want,

03:56.000 --> 03:59.000
and in one of the slots you have the GPU cards,

03:59.000 --> 04:03.000
and they have to transmit, they have to share data through the PCI bus.

04:03.000 --> 04:06.000
In this one, it's a bus, it's kind of PCI bus,

04:06.000 --> 04:09.000
but you will see that the performances are much more interesting.

04:09.000 --> 04:13.000
The second thing is that one core does one symbol operation at a time.

04:13.000 --> 04:20.000
So in this very simple example, I'm adding AC is equal to A plus B,

04:20.000 --> 04:27.000
and the code is just saying for each CPU, each CUDA core, take A, take B,

04:27.000 --> 04:30.000
make the sum, and store in C. That's pretty simple.

04:34.000 --> 04:37.000
So the key point here is that there are three things.

04:37.000 --> 04:42.000
One is push the data, the second is push the code, then run the code,

04:42.000 --> 04:44.000
and fetch the results.

04:44.000 --> 04:49.000
Keep in mind that you have to push the data, and this costs a lot, of course.

04:49.000 --> 04:56.000
So coming back to our SDR and DSP, what are the things that may need power?

04:56.000 --> 04:58.000
Well, just examples.

04:59.000 --> 05:04.000
The one I will elaborate this morning is the DDC, digital down converter,

05:04.000 --> 05:10.000
but you have many others, like I have not yet, and I will not describe this morning,

05:10.000 --> 05:12.000
I have not yet investigated so much.

05:12.000 --> 05:14.000
Feel free to take a seat, no worries.

05:16.000 --> 05:21.000
Interpolation, decimation, clock recovery, synchronization, pattern detection, and so on and so on.

05:21.000 --> 05:27.000
One of the key issues here is that some algorithms are extremely difficult to run in parallel

05:27.000 --> 05:30.000
while others, it's much simpler.

05:31.000 --> 05:34.000
And some of them just don't work in parallel easily.

05:35.000 --> 05:41.000
So in this example, let's focus on something simple, which is multiband DDC.

05:41.000 --> 05:47.000
So we'll assume that we have a white band signal coming from a white band SDR, whatever it is.

05:47.000 --> 05:49.000
I took DHF example.

05:49.000 --> 05:56.000
So here, for example, we have a receiver that is transferring to the memory.

05:57.000 --> 06:03.000
To the stuff, the device, a 50 mega samples per second bandwidth.

06:04.000 --> 06:07.000
And we want to extract from this small subbands.

06:08.000 --> 06:15.000
OK, so I took examples of DHF bands, one at 7 megs, another one at 14 megs, and so on.

06:15.000 --> 06:16.000
That's just examples.

06:16.000 --> 06:22.000
The core thing is how do we extract the subbands from the single white band signal?

06:23.000 --> 06:26.000
So for one channel, it's pretty easy.

06:26.000 --> 06:27.000
And that's the classical stuff.

06:27.000 --> 06:28.000
This is a DDC.

06:28.000 --> 06:33.000
So you basically translate the frequency and then you make some low pass filtering.

06:33.000 --> 06:36.000
And then you throw away all the samples you don't need.

06:36.000 --> 06:37.000
That's very classical.

06:37.000 --> 06:39.000
I have not invented anything here.

06:42.000 --> 06:49.000
And I guess you all know by heart what is a low pass filter, but just take a few seconds to remind how it works.

06:49.000 --> 06:53.000
On one hand, you have the input, the samples coming from the SDR.

06:53.000 --> 06:57.000
On the other hand, you have the filter you want to apply for the low pass filtering.

06:57.000 --> 07:04.000
And you make a convolution, basically some modifications and additions, and you retrieve the output.

07:04.000 --> 07:05.000
OK.

07:06.000 --> 07:09.000
Now let's look a bit more in my example.

07:09.000 --> 07:11.000
How many taps do we really have?

07:11.000 --> 07:18.000
So for this example, let's assume that we have a 50 megahertz, so 50 mega samples per second bandwidth incoming.

07:19.000 --> 07:22.000
And we want three kilohertz just to extract the audio.

07:22.000 --> 07:24.000
This is a fully digital system.

07:24.000 --> 07:29.000
So at the end, we want audio, plain old voice, someone speaking.

07:29.000 --> 07:32.000
And we assume that three kilohertz is enough.

07:32.000 --> 07:40.000
There's a lot of different approaches to estimate exactly, to estimate as accurately as possible the number of taps we need.

07:40.000 --> 07:42.000
I saw many, I tried to find an example.

07:42.000 --> 07:45.000
I saw plenty and pages from you, Marcus.

07:46.000 --> 07:50.000
Many of, I was going to copy and paste some of yours to avoid questions.

07:50.000 --> 07:53.000
No, I'm joking, of course.

07:53.000 --> 07:56.000
Well, there's many ways to estimate the number of taps.

07:56.000 --> 08:04.000
And one of the approaches is this, I don't remember, yes, the Iris approximation, sorry.

08:04.000 --> 08:09.000
And so if you do the calculation, you arrive at 50,500 taps.

08:09.000 --> 08:10.000
OK.

08:10.000 --> 08:12.000
50,500, so what?

08:13.000 --> 08:14.000
So what?

08:15.000 --> 08:18.000
Now let's go back to this stuff.

08:18.000 --> 08:29.000
So to do the convolution with 50,500 taps here, you need to do this 50,500 times for each sample.

08:29.000 --> 08:42.000
It means that to get one value out of the FIR filter, the Lopez filter, you need to take 50,500 inputs, 50,500 coefficients, do the multiplications, do the sum.

08:42.000 --> 08:43.000
And you have one sample.

08:43.000 --> 08:46.000
And you have to do this for every incoming sample.

08:46.000 --> 08:51.000
That begins to be a huge amount of processing.

08:51.000 --> 09:01.000
Of course, if you have, you have all experienced many low cost SDR applications running on low cost PCs and they do this in real time.

09:01.000 --> 09:02.000
So how do they do it?

09:02.000 --> 09:04.000
Of course, there are tricks.

09:04.000 --> 09:14.000
One of the most, the easiest one is to divide by two instead of going straight from 50 megs to 3 kilohertz, which is nice, but probably not the best one.

09:14.000 --> 09:17.000
You do this step by step by dividing by two.

09:17.000 --> 09:25.000
So you take the first band, apply a half band filter, so you have less, you have the half of samples and you repeat this several times.

09:25.000 --> 09:39.000
That's very interesting because each time you remove a lot of samples and if you do this clearly, you can have 50% of the coefficients that are zero if you compute the fear in a good way.

09:39.000 --> 09:42.000
So that removes you a lot of computation.

09:42.000 --> 09:51.000
Of course, yes, but this is not ideal because you will hardly be able to reuse the computation you've made for the other channels.

09:51.000 --> 10:04.000
You will reduce a lot the throughput, the number of calculations you need for one of the channels, but then the next one you will want to reuse some of the calculation you've made and that's not easy.

10:04.000 --> 10:08.000
So at the end, this doesn't work so good.

10:08.000 --> 10:12.000
So, so can this stuff help?

10:12.000 --> 10:15.000
So I just put two examples here.

10:15.000 --> 10:18.000
On the top you have the Jetson XAVNX.

10:18.000 --> 10:29.000
I know that in an open source conference promoting a brand like NVDA is probably not the best idea, but just to make the story short, I have no sponsoring from NVDA.

10:29.000 --> 10:38.000
Okay, so just to be figures and facts, the first one is the XAVNX, so it's roughly 500 euros, roughly.

10:38.000 --> 10:51.000
And this one has 384 cores and the next in line is the NVDA 800, which is not the same price, 20,000 roughly, and has 6,912 cores.

10:51.000 --> 10:56.000
Okay, the interesting thing is the two FFT benchmarks are put below it.

10:56.000 --> 11:07.000
So if you look at the Jetson XAVNX to perform an FFT of, sorry, I'll say it this way, 2 power 19, which is quite a lot.

11:07.000 --> 11:10.000
So it's 310 microseconds.

11:10.000 --> 11:12.000
That's quite a lot.

11:12.000 --> 11:25.000
But of course, if you look at the most expensive one, you have 170 microseconds for 2 power 23, which is a huge FFT.

11:25.000 --> 11:26.000
A huge FFT.

11:26.000 --> 11:35.000
You can do this with an FPGA, but to get those size, it's becoming fun and extremely tricky to do it.

11:35.000 --> 11:45.000
Okay, so and for the XAVNX, you see that if you go up to the power of 2 at the power of 23, it's 7 milliseconds.

11:45.000 --> 11:47.000
That's a huge number.

11:47.000 --> 11:49.000
It's quite fast.

11:49.000 --> 11:52.000
So how can we use this?

11:52.000 --> 11:57.000
Of course, if you look back to your DSP lessons, that's pretty simple, in fact.

11:57.000 --> 12:04.000
A convolution can be, I mean, applying an FIR to a signal is just making a convolution.

12:04.000 --> 12:06.000
And the convolution, you can use the FFT.

12:06.000 --> 12:07.000
That's pretty simple.

12:07.000 --> 12:09.000
I mean, that's pretty known.

12:09.000 --> 12:21.000
You take the input signal, you do the FFT, you take your filter, you do the FFT here, and then you make a product of the two vectors.

12:21.000 --> 12:22.000
There is a bug.

12:22.000 --> 12:23.000
It's FFT minus 1.

12:23.000 --> 12:24.000
There is a bug here.

12:24.000 --> 12:25.000
Inverse FFT.

12:25.000 --> 12:28.000
And you get your output.

12:28.000 --> 12:34.000
So basically, you do FFT, FFT multiplication, inverse FFT, and you have your output.

12:34.000 --> 12:36.000
That is for one single block.

12:36.000 --> 12:37.000
Okay?

12:37.000 --> 12:38.000
That's quite good.

12:38.000 --> 12:41.000
It works well.

12:41.000 --> 12:44.000
But this is for a steady signal, not a stream.

12:44.000 --> 12:52.000
So if you want to do this for a stream, there is an improved version of this algorithm, which is called the overlap save or overlap hat.

12:52.000 --> 12:57.000
I use the overlap save, which is basically sliding a window, sliding blocks,

12:57.000 --> 13:01.000
moving the input, doing the computation, and so on and so on and repeat this.

13:01.000 --> 13:05.000
The key point here is that you use always the same filter.

13:05.000 --> 13:10.000
So you can compute the FFT of the filter once and keep it.

13:10.000 --> 13:14.000
And the input, you will see, can be reused several times.

13:14.000 --> 13:20.000
So basically, if you do this in the GPU, the performances are quite interesting.

13:20.000 --> 13:21.000
And this is what I did.

13:21.000 --> 13:24.000
And this is what I'm going to show you here.

13:24.000 --> 13:29.000
So the idea is, this is the architecture of the code I'm proposing.

13:29.000 --> 13:32.000
You receive the samples from the SDR.

13:32.000 --> 13:35.000
You do a first FFT.

13:35.000 --> 13:38.000
So you push the samples into the GPU RAM.

13:38.000 --> 13:39.000
Okay?

13:39.000 --> 13:43.000
Then your code does a first FFT or the incoming block.

13:43.000 --> 13:49.000
You assume that you've done previously at the init the FFT for the several filters you want to apply.

13:49.000 --> 13:52.000
So here in this example, I have two.

13:52.000 --> 14:01.000
You do the connexer product, modifications for both FFT, the reverse FFT, and the decimation.

14:01.000 --> 14:05.000
And you're done.

14:05.000 --> 14:06.000
There is one trick.

14:06.000 --> 14:08.000
I will come back to it in a few slides.

14:08.000 --> 14:13.000
So basically, it means that, sorry, if I go back to this slide, excuse me,

14:13.000 --> 14:15.000
you do this FFT in fact only once.

14:15.000 --> 14:18.000
You reuse it for the different channels you want.

14:18.000 --> 14:22.000
You have done the FFT for the filters once.

14:22.000 --> 14:32.000
So in practice for each new incoming block of samples, you have to do one FFT here, modifications, FFT minus one, and decimation.

14:32.000 --> 14:34.000
And that can be quite fast.

14:34.000 --> 14:40.000
All this doesn't need data to move from the GPU memory to the main CPU memory.

14:40.000 --> 14:43.000
But that's quite fast in fact.

14:43.000 --> 14:53.000
Then one trick and why I have ended with using the CUDA and proprietary API and the NVDA stuff.

14:53.000 --> 14:57.000
I've heard from guys in this room that you can now do this in OpenCL.

14:57.000 --> 14:59.000
I have not tested, to be honest.

14:59.000 --> 15:02.000
One of the trick is that if you don't pay attention to the scheduling,

15:02.000 --> 15:08.000
the different channels will be the different codes will run in series, in sequence, FFT and so on and so on.

15:08.000 --> 15:17.000
So you will have to wait for the last block of sequence of operations to be finished before you can retrieve all the samples.

15:17.000 --> 15:21.000
And you wait, you may end up waiting quite a lot.

15:21.000 --> 15:29.000
But if you use this trick just to compile option, switch, then the scheduling inside the GPU is different.

15:29.000 --> 15:31.000
And then everything run in parallel.

15:31.000 --> 15:35.000
And the difference is quite large, quite big, to be honest.

15:35.000 --> 15:38.000
The difference is much faster this way.

15:38.000 --> 15:46.000
One last thing is that if we only do what I proposed, then you miss the frequency shifting.

15:46.000 --> 15:49.000
There is a problem, the output frequency is not a good one.

15:49.000 --> 15:54.000
So you need to apply the NCO to shift in frequency the signal.

15:54.000 --> 15:58.000
And of course it's much more efficient to do this at the end because you have less samples.

15:58.000 --> 16:00.000
So it's much faster.

16:00.000 --> 16:04.000
You do the shifts at the very end and you just use the fact that you have some aliasing.

16:04.000 --> 16:10.000
So the code compensates for the aliasing and that's the frequency shift at the very end.

16:10.000 --> 16:12.000
Just look at the code.

16:12.000 --> 16:15.000
That's easier this way.

16:15.000 --> 16:17.000
So what am I proposing this morning?

16:17.000 --> 16:21.000
So you have in GitHub a lib, an example.

16:21.000 --> 16:26.000
That's a code that is quite old from me, but it works.

16:26.000 --> 16:33.000
And the key thing is that you have to allocate maximum number of channels you will use in the beginning,

16:33.000 --> 16:39.000
basically because it will allocate in the GPU the RAM for the different operations.

16:39.000 --> 16:41.000
Then the code is thread safe.

16:41.000 --> 16:47.000
That is to say that you can add, remove, shift, replace, change the number of channels you use,

16:47.000 --> 16:51.000
the size of the channels and so on in real time.

16:51.000 --> 16:53.000
This is CUDA based.

16:53.000 --> 16:57.000
I know that maybe OpenCL could do something that I have not tested.

16:57.000 --> 17:04.000
And I have only tested this with NVDA GPUs.

17:04.000 --> 17:07.000
So just to give an example of what you can get with this.

17:07.000 --> 17:11.000
So I just benchmarked this with two different architectures, the one I had,

17:11.000 --> 17:18.000
but I'm sure that I will receive tons of PR to add new figures in the tables on GitHub for sure.

17:18.000 --> 17:22.000
So practically speaking on my machine at home, it's a well,

17:22.000 --> 17:29.000
average PC with a GT RTX 2060 with one single channel.

17:29.000 --> 17:36.000
So throughput is just a bench test code where it's just pushing data to the GPU,

17:36.000 --> 17:39.000
making the computation and retrieving the samples.

17:39.000 --> 17:44.000
So with one channel, it's roughly 600 mega-samples per second.

17:44.000 --> 17:48.000
With two channels, 530.

17:48.000 --> 17:49.000
OK.

17:49.000 --> 17:55.000
Just as a baseline for comparison with the Jetson XADI-NX,

17:55.000 --> 17:59.000
depending on the FST size, that changes quite a lot.

17:59.000 --> 18:05.000
And you can reach up to 156 mega-samples per second with two channels.

18:05.000 --> 18:06.000
One channel, sorry.

18:06.000 --> 18:09.000
And 117 with two channels.

18:09.000 --> 18:13.000
The filters were 7200 taps.

18:13.000 --> 18:15.000
Excuse me, that's average.

18:15.000 --> 18:17.000
You can change this in the code.

18:17.000 --> 18:23.000
I'm checking the time because I know Mark will kick me out soon.

18:23.000 --> 18:29.000
So just to come to the, just one of the interesting things is that

18:29.000 --> 18:35.000
if you look at the figures here, you see that the GPU is roughly 80% used.

18:35.000 --> 18:37.000
The PCI is 36%.

18:37.000 --> 18:39.000
So there's room for improvements.

18:39.000 --> 18:45.000
And if you look at the CPU, one core is 100% and the others are relaxed.

18:45.000 --> 18:48.000
So it means that maybe there's room for much faster, in fact,

18:48.000 --> 18:50.000
because we are far from overloading the machine.

18:50.000 --> 18:55.000
And in fact, if you look in detail, where is the bottleneck?

18:55.000 --> 18:58.000
It appears that the bottleneck is the memory copy.

18:58.000 --> 19:02.000
The synchronization between copying the memory from host to device,

19:02.000 --> 19:07.000
wasting for the threads to start, waiting for the kernels to stop.

19:07.000 --> 19:09.000
All this synchronization takes a lot of time.

19:09.000 --> 19:11.000
And if you start to plot this in time,

19:11.000 --> 19:13.000
NVGA comes with the tool.

19:13.000 --> 19:16.000
I don't remember the name, where you can see the different threads

19:16.000 --> 19:17.000
in time, how they work.

19:17.000 --> 19:21.000
And you clearly see that there's, the bottlenecks come from the synchronization

19:21.000 --> 19:29.000
from the host and so there's room for improvement, for sure.

19:29.000 --> 19:34.000
So if you want to tune this, you will see that the, of course,

19:34.000 --> 19:40.000
the size of the FFT used has a strong impact on the performances.

19:40.000 --> 19:45.000
But that really depends on the performances of the GPU you're using.

19:45.000 --> 19:50.000
As I said, moving the data from host to GPU is extremely expensive.

19:50.000 --> 19:58.000
In the example I was doing, copy from host to device in complex float,

19:58.000 --> 20:02.000
I could use complex ints, raw data from the SDR,

20:02.000 --> 20:08.000
and there is in the code one example where you can convert the ints 16 to float

20:08.000 --> 20:10.000
directly, so it's cheaper.

20:10.000 --> 20:17.000
I mean, the amount of data you would copy from the host to the device is much smaller.

20:17.000 --> 20:20.000
And I was using LibUSB in real life.

20:20.000 --> 20:22.000
I mean, not in the example, but in real life.

20:22.000 --> 20:24.000
So it's also very expensive.

20:24.000 --> 20:29.000
LibUSB is far from optimized, from optimal, I would say, more than optimized.

20:29.000 --> 20:34.000
And of course, one of the important things is that the CPU, as it's not,

20:34.000 --> 20:39.000
well, that's the different cores of room for other things.

20:39.000 --> 20:44.000
It means that you can do other tasks like paint and eye spectrum on the screen,

20:44.000 --> 20:49.000
like send emails, like listen to music, whatever you want.

20:49.000 --> 20:52.000
I think that's all thoughts.

20:52.000 --> 20:53.000
Thank you very much.

20:53.000 --> 20:55.000
I didn't want to spend too much time.

20:55.000 --> 20:59.000
And I'll be happy to reply to questions if you have any.

20:59.000 --> 21:00.000
Thank you very much.

21:00.000 --> 21:08.000
Yes.

21:08.000 --> 21:09.000
Yes, please.

21:09.000 --> 21:14.000
You said you did the frequency shift at the very end after this,

21:14.000 --> 21:19.000
and is it possible to already do at least a significant part of the frequency shift

21:19.000 --> 21:22.000
by just offsetting the FFTs?

21:22.000 --> 21:23.000
That's what I do.

21:23.000 --> 21:25.000
I rotate the FFT.

21:25.000 --> 21:27.000
I rotate, yes.

21:27.000 --> 21:30.000
But then you have a reminder, because if you do this,

21:30.000 --> 21:35.000
you have the shift you perform is an integral fraction of the incoming.

21:35.000 --> 21:39.000
So you need a post fine tune.

21:39.000 --> 21:40.000
And that's exactly this.

21:40.000 --> 21:41.000
Yeah, you're right.

21:41.000 --> 21:42.000
That's what I'm doing.

21:42.000 --> 21:43.000
Yes?

21:43.000 --> 21:47.000
You didn't see an IIR, FIR, or CIC filter?

21:47.000 --> 21:48.000
Just FIR.

21:48.000 --> 21:52.000
Yeah, because it's just FFT and Chronicle products.

21:52.000 --> 21:56.000
That was the simplest approach.

21:56.000 --> 21:57.000
Thank you.

21:57.000 --> 21:58.000
Yeah?

21:58.000 --> 22:02.000
Was there any attempt to match this into the radio?

22:02.000 --> 22:03.000
Not yet, to be honest.

22:03.000 --> 22:05.000
I'm not good enough in the radio.

22:05.000 --> 22:08.000
I had a discussion with Jean-Michel, a side discussion,

22:08.000 --> 22:10.000
and there's a plan to do it.

22:10.000 --> 22:15.000
The point, I mean, I was not able to do it for them.

22:15.000 --> 22:19.000
I don't have enough practice in C-Blocks, so I said,

22:19.000 --> 22:22.000
OK, let's do this with the guys who know.

22:22.000 --> 22:24.000
So we will come with a proposal.

22:24.000 --> 22:26.000
Yes, that's the idea.

22:26.000 --> 22:29.000
Typically, the idea would be to have something, if we can do it,

22:29.000 --> 22:33.000
that would permit to have messages to change, to add, and remove channels,

22:33.000 --> 22:36.000
or tune the channels in radio directly.

22:36.000 --> 22:38.000
Because one of the points is that you need to allocate

22:38.000 --> 22:41.000
to define how many channels you want to use.

22:41.000 --> 22:44.000
So depending on the applications, you might need different numbers

22:44.000 --> 22:45.000
of channels.

22:45.000 --> 22:47.000
That's why I wasn't able to do it.

22:47.000 --> 22:49.000
Any other question?

22:49.000 --> 22:50.000
From the audience?

22:50.000 --> 22:51.000
Yes?

22:51.000 --> 22:52.000
Just a small question.

22:52.000 --> 22:54.000
You used a single precision floating point.

22:54.000 --> 22:57.000
Very good question, in fact.

22:57.000 --> 23:00.000
Single except this one, the frequency shift.

23:00.000 --> 23:04.000
Because in CUDA, the sine and cost functions are nightmare.

23:04.000 --> 23:06.000
They produce a lot of noise.

23:06.000 --> 23:11.000
So in the code, it's written, double precision, don't touch this.

23:11.000 --> 23:15.000
Because otherwise, the noise is going up very quickly.

23:15.000 --> 23:18.000
Anything else?

23:18.000 --> 23:20.000
OK, thank you very much.

23:20.000 --> 23:26.000
So there's more folks pressing in.

23:26.000 --> 23:36.000
So if I can ask you to give a little bit more space.

23:36.000 --> 23:43.000
You didn't need to kick me out.

23:43.000 --> 23:45.000
That's quite fine.

23:45.000 --> 23:47.000
Bonjour.

25:06.000 --> 25:08.000
Thank you.

