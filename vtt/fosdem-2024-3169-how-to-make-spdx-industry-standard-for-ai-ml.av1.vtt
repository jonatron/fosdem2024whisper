WEBVTT

00:00.000 --> 00:05.000
I think it's good.

00:05.000 --> 00:10.000
Okay, thank you.

00:10.000 --> 00:15.000
So, yes, it's going to be very quick because it's a 15-minute talk,

00:15.000 --> 00:17.000
so it's kind of like lightning speed.

00:17.000 --> 00:20.000
So if you want to get anything from the slides,

00:20.000 --> 00:23.000
this is your chance, and it won't be a long time,

00:23.000 --> 00:27.000
so just like take a picture, and then we'll move on from there.

00:27.000 --> 00:29.000
Right, three, two, one, go.

00:29.000 --> 00:31.000
Check. Yeah, I love open source.

00:31.000 --> 00:36.000
I am working in open as a self, so please come to our stand and talk to us.

00:36.000 --> 00:39.000
So, yeah, I don't have to copy this, but you come to our stand.

00:39.000 --> 00:40.000
That's what you have to do.

00:40.000 --> 00:42.000
So it's just downstairs at level two.

00:42.000 --> 00:49.000
So, who have read, let's say you open a pack of Crips,

00:49.000 --> 00:51.000
who have read the ingredient list?

00:51.000 --> 00:53.000
Anybody? Yes?

00:53.000 --> 00:55.000
Some of them don't care, some of them don't care what you're eating.

00:55.000 --> 00:59.000
Okay, so this is what you need to know.

00:59.000 --> 01:03.000
So you need to know what you're eating because you may be allergic to some of the ingredients,

01:03.000 --> 01:05.000
or maybe like, you know, it's not very healthy,

01:05.000 --> 01:08.000
I should not eat that much sugar and that kind of thing.

01:08.000 --> 01:14.000
So that's why it's almost like a universal standard that we have to list

01:14.000 --> 01:18.000
what is actually the ingredients of the things that you are buying,

01:18.000 --> 01:24.000
like a pack of Crips, or a cake, or a soda, whatever you're drinking.

01:24.000 --> 01:30.000
So, that consumer group now is like, you know, the scope has been expanding.

01:30.000 --> 01:34.000
It's not just for food or some hardware that you're buying,

01:34.000 --> 01:36.000
but also software that you're using.

01:36.000 --> 01:41.000
We just like, you know, talk about, you know, in Europe we have the CRA and PLD.

01:41.000 --> 01:44.000
You know, PLD is now going to maybe encourage software,

01:44.000 --> 01:46.000
so we have to be careful about those.

01:46.000 --> 01:52.000
So, I know this is the S-bomb death room, so maybe a lot of you are already expert in it,

01:52.000 --> 01:56.000
but just for those maybe people watching online that is new to the concept.

01:56.000 --> 02:02.000
So, a bit of materials is, you know, we have to list all the components in your software,

02:02.000 --> 02:08.000
including those open source, that, you know, all the dependencies that you are actually using.

02:08.000 --> 02:13.000
So, yeah, so you have to list not just what you're using,

02:13.000 --> 02:17.000
but also the detail about what you're using, like for example, the license that, you know,

02:17.000 --> 02:18.000
is part of the component.

02:18.000 --> 02:21.000
And you should know anyway, because, you know, check the license,

02:21.000 --> 02:24.000
maybe you have to be open source if you're using some open source software.

02:24.000 --> 02:27.000
So, you know, for people who don't check, then ooh, alarm.

02:27.000 --> 02:32.000
Also, the versions, because, you know, versions can be very different,

02:32.000 --> 02:34.000
especially like different major versions,

02:34.000 --> 02:35.000
there's very different from each other.

02:35.000 --> 02:39.000
So, if you don't actually know what your dependencies,

02:39.000 --> 02:42.000
which version you're using, that's also a big no-no.

02:42.000 --> 02:45.000
So, these all these things kind of like, you know, your pack of crisps,

02:45.000 --> 02:47.000
that like, you know, you have to list your ingredients

02:47.000 --> 02:50.000
and you have to know what you're eating, what you're consuming.

02:50.000 --> 02:54.000
So, go back to the pack of crisps.

02:54.000 --> 02:59.000
So, do you know that actually you can't just say like, you know, list whatever you like,

02:59.000 --> 03:03.000
you know, because there's actually some standard that you have,

03:03.000 --> 03:05.000
you know, when you look at all the packaging,

03:05.000 --> 03:08.000
they have a certain format that they will have to follow

03:08.000 --> 03:10.000
and they list their ingredients.

03:11.000 --> 03:14.000
So, for example, I use a U.K. of Monaz and example,

03:14.000 --> 03:17.000
because I live there, you know, I do care what I'm eating.

03:17.000 --> 03:21.000
So, if your food or drink has two or more ingredients in it,

03:21.000 --> 03:24.000
then you must list all of the ingredients.

03:24.000 --> 03:26.000
So, basically it means that you can't skip an ingredient,

03:26.000 --> 03:29.000
even though it's like tiny, teeny amount.

03:29.000 --> 03:32.000
Also, it needs to be in order of weight.

03:32.000 --> 03:35.000
So, usually if you see like, oh, how much sugar,

03:35.000 --> 03:37.000
for example, I'm very concerned about that,

03:37.000 --> 03:40.000
like how much sugar you have in the food that you're eating.

03:40.000 --> 03:43.000
So, you see, like, where they are.

03:43.000 --> 03:45.000
So, if they're the first thing in their list,

03:45.000 --> 03:48.000
probably like most of the things you're eating are sugar, right?

03:48.000 --> 03:54.000
So, yeah, because it's list in order of weight from the most, you know,

03:54.000 --> 03:59.000
percent of weight first, so that's mostly what you're eating.

03:59.000 --> 04:02.000
Also, if there's any like allergen,

04:02.000 --> 04:05.000
because in the U.K. there's like a list, I think it's like 12,

04:05.000 --> 04:10.000
but I may be wrong, allergens that need to be clearly, you know, shown.

04:10.000 --> 04:14.000
So, those will be, you need to highlight them with maybe different forms,

04:14.000 --> 04:18.000
different color, or different background color to make sure that, you know,

04:18.000 --> 04:22.000
people are allergic to those, very aware of they should not touch that thing.

04:22.000 --> 04:27.000
So, also for S-bomb, we want to have some format, right?

04:27.000 --> 04:30.000
Because, for example, I'm allergic to, let's say, I'm not really,

04:30.000 --> 04:33.000
but if I'm allergic to nuts, right?

04:33.000 --> 04:38.000
Then the standard format of how to list the ingredients

04:38.000 --> 04:43.000
make me very easy to have a look and see, oh, I should not touch this chocolate

04:43.000 --> 04:46.000
because there's some nuts in it and I would be allergic

04:46.000 --> 04:49.000
and I get really sick or ill or maybe die if I eat it.

04:49.000 --> 04:54.000
So, we need some formats to show, you know,

04:54.000 --> 04:57.000
what the software is actually made of, right?

04:57.000 --> 05:02.000
So, that's why S-B-D-X is coming in to kind of have a standard

05:02.000 --> 05:06.000
that you could, so I have to speed up again, like, running, like,

05:06.000 --> 05:10.000
so it's very good that it's kind of like a standard-sized machine

05:10.000 --> 05:14.000
and human readable, so it's very good to make it very clear

05:14.000 --> 05:17.000
that everybody can just easily consume that information.

05:17.000 --> 05:23.000
So, in X-B-T-S-2.3, it's pretty good for software

05:23.000 --> 05:28.000
because, like, it's, you know, it will show all the, like, common, you know,

05:28.000 --> 05:32.000
CEV advisory, they've all been linked and referenced to it, it's quite clear.

05:32.000 --> 05:36.000
Also, it meets the, yes, executive order of, you know,

05:36.000 --> 05:40.000
the S-Bomb need to be, you know, meeting those standards

05:40.000 --> 05:45.000
and it also needs to, you know, have the ISO standard,

05:45.000 --> 05:48.000
so it's standard, it's very easy, it's very consumable.

05:48.000 --> 05:51.000
So, and also, what with Cosine, you know,

05:51.000 --> 05:54.000
Sixth Door, I love Sixth Door, I work over on SSF-Y,

05:54.000 --> 05:56.000
I come to our stand to get a sticker.

05:56.000 --> 06:01.000
So, S-B-T-S-2.3 is good, so if you are using any, like, software,

06:01.000 --> 06:05.000
like, you know, maybe, apply today, but we can make it better, right?

06:05.000 --> 06:09.000
So, traditional software build material, like, for example,

06:09.000 --> 06:13.000
for concrete or for boats or for cars, the hardware is already covered.

06:13.000 --> 06:17.000
Now, you know, we have software, now we're doing it,

06:17.000 --> 06:19.000
you know, S-B-T-S-2.3 is pretty good for that,

06:19.000 --> 06:22.000
but if you think about what we are having in the future, right,

06:22.000 --> 06:25.000
we have AI, machine learning, these are the, you know,

06:25.000 --> 06:27.000
the words that everybody is talking about.

06:27.000 --> 06:30.000
They have a huge component that we actually traditionally,

06:30.000 --> 06:33.000
like, software we don't have, for example, a lot of data.

06:33.000 --> 06:35.000
We have the AI model and all this stuff,

06:35.000 --> 06:39.000
so we have to cover them as well to hit the target, I would say.

06:39.000 --> 06:44.000
So, there's the new model, you know, S-B-T-S-3.3,

06:44.000 --> 06:48.000
so now is the release candidate, so you can already have a look.

06:48.000 --> 06:51.000
So, it has new model that will cover, you know,

06:51.000 --> 06:54.000
security data and AI, which is great.

06:54.000 --> 06:56.000
It will support database better, so for those like, you know,

06:56.000 --> 06:58.000
machine learning, you know, using a lot of data,

06:58.000 --> 07:00.000
then it's also covered up.

07:00.000 --> 07:02.000
So, domain-specific information as well.

07:02.000 --> 07:06.000
So, yeah, so I think for those, if you are like,

07:06.000 --> 07:09.000
if your software is actually, you know, going to like AI and stuff,

07:09.000 --> 07:12.000
so maybe you should look at model 3.3.

07:12.000 --> 07:16.000
So, that's great, but I have been to a lot of AI and machine learning conferences,

07:16.000 --> 07:20.000
nobody is talking about S-Bomb and S-B-T-S, which is, ah!

07:20.000 --> 07:23.000
So, for them, actually, they really need to care about it

07:23.000 --> 07:27.000
because for AI and machine learning applications,

07:27.000 --> 07:31.000
there's a lot of like risk that make them vulnerable.

07:31.000 --> 07:34.000
For example, data is a big problem.

07:34.000 --> 07:37.000
We have like, you know, data bleach and other stuff that happen all the time.

07:37.000 --> 07:41.000
Every time we heard about it, it's a big yike, so we don't, we won't avoid those.

07:41.000 --> 07:44.000
So, also, the system is very complex, right?

07:44.000 --> 07:45.000
This was a black box.

07:45.000 --> 07:47.000
We always talk about machine learning models.

07:47.000 --> 07:49.000
We don't know what's actually going on, so it's like,

07:49.000 --> 07:51.000
very scary stuff.

07:51.000 --> 07:55.000
So, also AI Bloom, now all the, you know, VC money is going to AI,

07:55.000 --> 07:57.000
and everybody's talking about AI and stuff.

07:57.000 --> 07:59.000
So, they may want to rush to get things done,

07:59.000 --> 08:05.000
so we need to please the, you know, the funding, you know, the funders, right?

08:05.000 --> 08:09.000
So, yeah, so they may be less careful about what they're doing,

08:09.000 --> 08:11.000
just need to get it done, you know?

08:11.000 --> 08:14.000
Also, there are new vulnerabilities that is not like, you know,

08:14.000 --> 08:16.000
there's new technology, there are new vulnerabilities.

08:16.000 --> 08:20.000
Now, there are some people hacking around like, problem injection and having fun,

08:20.000 --> 08:23.000
but it can be very serious if it's not just fun,

08:23.000 --> 08:25.000
if people are using it for malicious thing,

08:25.000 --> 08:29.000
it could be very bad, like, consequences coming up.

08:29.000 --> 08:35.000
So, we need to, we need to make the community adopt it very quickly.

08:35.000 --> 08:38.000
So, I always think about that, like, for any tools,

08:38.000 --> 08:42.000
if you want a very good adoption, you need, you know, good tool, and outreach.

08:42.000 --> 08:45.000
So, those two go hand in hand, you can't just skip one of them.

08:45.000 --> 08:49.000
Very bad tool, going to tell people, people still don't like it.

08:49.000 --> 08:51.000
Very good tool, but nobody know about it, nobody use it.

08:51.000 --> 08:53.000
So, you need both.

08:53.000 --> 09:00.000
First of all, you know, now, you know, for example, we want a very profile for S-bombs,

09:00.000 --> 09:04.000
because, you know, also it needs to be easy to start,

09:04.000 --> 09:06.000
we don't want something very complex, because, you know,

09:06.000 --> 09:09.000
AI machine learning people, they want to, you know, make, you know,

09:09.000 --> 09:11.000
work on their model, but not care about these, like,

09:11.000 --> 09:13.000
compliances and things like that.

09:13.000 --> 09:15.000
Also, we want to make it a universal standard,

09:15.000 --> 09:17.000
instead of shopping around, they have to choose which one to use.

09:17.000 --> 09:19.000
We want to make it universal, so it's like,

09:19.000 --> 09:21.000
no brainer, just go for that one.

09:21.000 --> 09:23.000
Also, satisfy the policies, that's very important,

09:23.000 --> 09:26.000
because at the end of the day, you have to satisfy the government policies,

09:26.000 --> 09:31.000
so you can make it an adoptable production-ready product.

09:31.000 --> 09:34.000
So, outreach, we have to, like, show more examples,

09:34.000 --> 09:36.000
show people that you can use it that way, so it's like,

09:36.000 --> 09:37.000
very easy for them to learn.

09:37.000 --> 09:40.000
You have to have use cases, show that some companies,

09:40.000 --> 09:42.000
they have some, yeah, exactly.

09:42.000 --> 09:45.000
Some companies, you know, if they make a successful case of using that,

09:45.000 --> 09:48.000
make sure everybody knows about it and follow.

09:48.000 --> 09:51.000
Education, tell the machine and AI community that, like,

09:51.000 --> 09:55.000
you should care about security and compliances and all this stuff.

09:55.000 --> 09:58.000
You can't just, like, you know, make it work and voila,

09:58.000 --> 10:01.000
and you know, everybody's happy to get all the VCs money, right?

10:01.000 --> 10:06.000
So, SPDX 3.0 is pretty thorough, it's pretty good,

10:06.000 --> 10:09.000
so this is good, keep on continuing doing the good thing.

10:10.000 --> 10:13.000
Also, communication with policy makers, so I'm sure that, like,

10:13.000 --> 10:16.000
there's, that is ongoing because, you know,

10:16.000 --> 10:18.000
at least foundation, we have some people, you know,

10:18.000 --> 10:21.000
keep talking to policy makers and that's a good thing.

10:21.000 --> 10:26.000
So, how can we make it into, like, a very well-adapted model?

10:26.000 --> 10:30.000
So, outreach is a key, so we need to create universal standards,

10:30.000 --> 10:32.000
so that's why we need to make more outreach,

10:32.000 --> 10:35.000
tell people that, follow this, this is a very good standard,

10:35.000 --> 10:38.000
and go to the, where the community is, right?

10:38.000 --> 10:42.000
Like, go to those, where people, like, go, this AIML people are,

10:42.000 --> 10:44.000
they go to their conference, you know, those machine learning

10:44.000 --> 10:46.000
conferences and stuff, like, go there and tell them

10:46.000 --> 10:48.000
what they should care about.

10:48.000 --> 10:49.000
And also understand their need as well,

10:49.000 --> 10:51.000
it's a bi-directional communication,

10:51.000 --> 10:53.000
we want to see how we can make it easier for them,

10:53.000 --> 10:56.000
or what can cover what they're concerned, maybe, you know,

10:56.000 --> 10:59.000
their consumer, the consumer of their product care about

10:59.000 --> 11:01.000
these kind of things, so we can cover that for them.

11:01.000 --> 11:05.000
So, so at the end of the day, after understanding their needs,

11:05.000 --> 11:07.000
it will go back to a good tool, so it's kind of like

11:07.000 --> 11:10.000
a very good cycle that we can keep doing that.

11:10.000 --> 11:13.000
So, cost action, that's the last thing, adopt,

11:13.000 --> 11:17.000
SPDX 2.3, if you're, like, you know, now ready,

11:17.000 --> 11:21.000
so just adopt it, but you can also help try the release

11:21.000 --> 11:24.000
candidate, you know, try, you know, help contributing to the

11:24.000 --> 11:29.000
new 3.0 model, also engaging in outreach activity,

11:29.000 --> 11:32.000
go and tell people, use it, right?

11:32.000 --> 11:36.000
And also keep communication, like, that's the part I love most.

11:36.000 --> 11:39.000
Communicating with policymaker and the user, we have to get

11:39.000 --> 11:42.000
everybody involved and have a good communication going on.

11:42.000 --> 11:45.000
So, that's the end, I hope I didn't overrun too much,

11:45.000 --> 11:50.000
so, yeah, let's make SPDX in the system, ML, and get the slides,

11:50.000 --> 11:53.000
and talk to me at the stand, thank you.

