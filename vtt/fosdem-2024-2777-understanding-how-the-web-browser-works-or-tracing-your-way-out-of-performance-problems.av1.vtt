WEBVTT

00:00.000 --> 00:11.560
Hello. Can you hear me all right? Welcome to the next installment in your regular scheduled

00:11.560 --> 00:16.360
entertainment. I think that's the great benefit of being scheduled after such great talks

00:16.360 --> 00:21.600
that everyone is in and with no break you can't leave. So you're kind of stuck with

00:21.600 --> 00:27.160
me for the next half an hour. So welcome. I hope you enjoy.

00:27.160 --> 00:33.400
So this is a very ambitious talk or at least as title suggests that it is. So let me actually

00:33.400 --> 00:40.240
start with talking what it really is about. And this talk is really about me and my experience.

00:40.240 --> 00:46.680
And hope, frustrations, aspirations, experience and some illustrations. So I'm Alex. I have

00:46.680 --> 00:53.520
been doing web performance, mobile web performance at Google in Chromium for the last eight or

00:53.520 --> 00:59.080
so years. So this talk is going to be pretty much about that. This is not going to be a

00:59.080 --> 01:06.920
practical talk. So because we don't have time. This is the first reason. The second is that

01:06.920 --> 01:13.840
there are way too many rough edges. So I wouldn't recommend this at this point to start to reproduce

01:13.840 --> 01:18.920
this. But hopefully this will be a source of inspiration. And those of you who are desperate

01:18.920 --> 01:25.720
enough and frustrated enough and have seen the problems outlined in this talk too many

01:25.720 --> 01:32.400
times, hopefully they will be brave enough to venture and try. There is a practical guide

01:32.400 --> 01:40.760
that I would recommend in the recent web performance calendar by the one and only great Annie Sullivan.

01:40.760 --> 01:45.880
I would recommend you go and check it out, preferably after this talk. But you know, I

01:46.200 --> 01:52.120
can't prohibit you from doing so. So this talk really is about problem solving and working

01:52.120 --> 01:56.920
with complex systems and trying to make sense of them. So the examples will be from Chromium.

01:56.920 --> 02:01.840
I will talk about Perfetto. But I think these examples hopefully will be an inspiration for

02:01.840 --> 02:06.320
a great variety of projects, both when building your sites and building other and working

02:06.320 --> 02:15.600
with other complex systems as well. So let's talk about performance and improvement performance.

02:15.960 --> 02:22.200
If you want to improve performance, as I imagine you are not totally adverse to, given that

02:22.200 --> 02:27.800
you are in this room, then I want to remind certain trivial things that you probably already

02:27.800 --> 02:33.080
know. The first is that performance problems are nasty. They are unpolite and they don't

02:33.080 --> 02:39.280
have the common courtesy of locating themselves in a nice isolated area of code in your project

02:39.280 --> 02:45.040
that you can master and just work on and don't bother with the rest of the stuff. So because

02:45.080 --> 02:50.720
of that, kind of knowing what to improve and where to improve and how to improve takes a

02:50.720 --> 02:56.520
substantial effort of the performance work. And the fact that more and more web is mind

02:56.520 --> 03:02.880
boggling complex with new APIs, both performance and non-performance, browsers getting more

03:02.880 --> 03:09.120
complex and bigger every day, various sites, drawing in diversity and in complexity and

03:09.160 --> 03:15.400
libraries and so on. So these all leads to all of us working on performance, spending a lot of

03:15.400 --> 03:20.400
time on a regular basis trying to understand what the hell is going on here. And what are

03:20.400 --> 03:25.080
the approaches? So the first approach that I have to mention is you can go and read the code.

03:26.680 --> 03:30.440
You are a very brave person and I wish you the very best of luck if you decide to do it, but

03:30.440 --> 03:34.840
it's not very practical. So modern projects are layers of up and layers of obstructions and then

03:34.880 --> 03:39.680
you have a listener and then you have 30 possible callbacks or entry points and then good luck.

03:40.480 --> 03:45.840
Usually, I give up at this point when I see like, hey, no, this is probably one of these 30 things.

03:46.720 --> 03:53.040
The second one is printf and it's possible variations. So it's console, it's log, it's other,

03:53.680 --> 04:02.800
just log it statements. And the second is the buggers. So GDB, LLDB, RR, Chrome DevTools, some of

04:02.800 --> 04:09.040
them are better than the others. But all of them, these approaches effectively don't scale to complex

04:09.040 --> 04:16.040
systems, especially if you talk about indeterminism when you test sometimes reproduces and the error

04:16.040 --> 04:21.320
sometimes reproduces sometimes doesn't then you are in a bit of fun. So when you have multiple

04:21.320 --> 04:26.880
processes and multiple architectures, multiple architecture components, then all of these,

04:26.880 --> 04:31.480
you know, these tools don't work particularly well. So they focus on low level details. Hey,

04:31.520 --> 04:37.400
what is this variable? And most often you want to know, hey, what this component is doing? And am I

04:37.440 --> 04:43.800
doing a good job? So enter tracing. How many of you are familiar with tracing in some form or the other?

04:46.120 --> 04:51.320
Some of them. So pretty much tracing is structured logging and visualization. I will go into this a

04:51.320 --> 04:56.200
little bit more further down the line. But as far as chromium is concerned, from the practical

04:56.440 --> 05:02.520
perspective, it means turning these annotations. So here we have a request resource from Java

05:02.520 --> 05:09.680
function that is being annotated with tracement macro. So we in C++, we emit some information when we

05:09.680 --> 05:14.920
enter this function. And we emit some information that we exit this function when tracing is enabled.

05:14.920 --> 05:23.000
And this will allow us to look at this nice timeline. Pretty much the x axis is time advancing in

05:23.040 --> 05:27.280
time. And here you can see that we have entered this function here, you have exited this function.

05:27.280 --> 05:32.680
And you can see which other functions were called inside of it, how long it took. And you can see

05:33.240 --> 05:39.120
zooming out what else the system has been doing across different threads across different processes,

05:39.120 --> 05:46.120
which is I think a good starting point and the basic infrastructure talk about. So if you wanted to

05:46.120 --> 05:51.160
use it to trade yourself, you can actually go to your IPF at a depth. And the examples in this

05:51.240 --> 05:57.280
talk are pretty much all from open Chrome example. So if you have a laptop, then you can go and follow

05:57.280 --> 06:04.440
it. Then the links to the slides should be on the FOSDEM site for this talk. But we'll back

06:04.440 --> 06:10.640
talking about how to make this useful. So you have this wonderful instrumentation. And this

06:10.640 --> 06:16.680
already is, you can use it as a fancy fprintf with search functionality. You can just record a lot

06:16.720 --> 06:22.280
of information and then look at it. But this is basically instrumenting the code you're already

06:22.280 --> 06:27.480
working on as a fancy fprintf. It's powerful and flexible, but not necessarily most convenient.

06:27.480 --> 06:36.840
And it doesn't win either compared to fprintf or debuggers out of the box. For fprintf, the basic

06:36.840 --> 06:40.840
debug loop is still faster. You had a single statement, you don't have to bother with opening

06:40.840 --> 06:48.280
anything anywhere. You just see the console output and you're done. So it gets less pleasant when

06:48.280 --> 06:53.400
you have to do it multiple times. And with debuggers, every all information is present. You can take

06:53.400 --> 06:58.920
you a bit of time to find it, but you don't have to bother with adding more annotations,

06:58.920 --> 07:05.080
recompiling and wasting time there. So like, and it's unrealistic to have all of the functions

07:05.080 --> 07:10.360
instrumented and captured in this race, because it's too much information both to record, which adds

07:10.440 --> 07:16.280
all of overhead and slow downs, but also it's a lot of information to go through and looking at it is

07:16.280 --> 07:22.760
not pleasant and not fast. So I will talk about finding opportunities for scaling this instrumentation

07:22.760 --> 07:28.120
and finding the opportunities where a few instrumentation points can give us a lot of information

07:28.120 --> 07:34.600
and substantially advance our ability to reason about what the code is doing. And enter Chrome task

07:34.600 --> 07:42.600
schedule. Chromium is implemented based on an event loop model. So we have a bunch of name threads.

07:42.600 --> 07:47.080
We have browser process with a browser main thread where which is responsible for coordinating

07:47.080 --> 07:51.080
everything. We have the render process with the main thread, which is responsible for running

07:51.080 --> 07:59.000
JavaScript, bling DOM and whatever. Or we have worker pulls, sorry, dedicated workers, which

07:59.000 --> 08:05.320
sites can create using new worker API. There is a thread pool for miscellaneous background work.

08:05.320 --> 08:11.560
And these is pretty much all there is and various place in the code. In the code base,

08:11.560 --> 08:15.720
I think we have, you know, a few thousand places. So maybe 10,000 nowadays,

08:15.720 --> 08:20.680
which basically post tasks. They get a task runner from somewhere and they post a task.

08:20.680 --> 08:26.600
No, the from here macro will talk about this in a second. But otherwise it's just a fancy lambda

08:26.600 --> 08:35.400
with some of safety thrown in. And here it is. So you post this task somewhere, you know, some

08:35.400 --> 08:41.960
thread or thread pool picks this up and it will run this task. Voila. And this is a great point

08:41.960 --> 08:48.120
for tracing instrumentation. And this is a great point to start looking at. So what it gives us,

08:48.760 --> 08:53.800
it gives us that we will have pretty much all of the places running Chromium and code.

08:54.440 --> 08:59.160
We will know about them and we will have some basic information. Here specifically look at

08:59.160 --> 09:05.080
posted from information. This is the result of from here macro expansion, which using some of the

09:05.080 --> 09:12.520
C macro tricks, give automatically without any further support, gives us file name on the function.

09:12.520 --> 09:17.640
So at least for every function, you have a basic idea of where this information, where

09:17.640 --> 09:21.960
this task has been posted from. And you can go to that part of the code base and start

09:21.960 --> 09:25.800
understanding what the hell is going on and why this task might be running.

09:27.720 --> 09:35.240
So then we can zoom out and we also have instrumentation for post task. And the post task and run

09:35.240 --> 09:41.720
tasks conveniently are linked through a flow event. And what this actually means that you,

09:41.720 --> 09:46.520
instead of looking at a single task, which might or might not be useful, you can also explore

09:46.600 --> 09:52.520
which tasks this came from and which tasks the task it came from came from here because of,

09:52.520 --> 09:59.000
I can't really zoom out and I can't really make it interactive. So I can't show the entire

10:00.280 --> 10:04.520
to all threads involved. So this is a view of a single thread. But hey, you can see I selected

10:04.520 --> 10:10.680
a single task. I can see an incoming flow that is coming from a thread pool. And as you can see

10:10.680 --> 10:16.120
that that thread pool task is coming from another task from the main thread. And so you can see

10:16.120 --> 10:23.480
that actually all of these smaller tasks running after a larger task, they have been posted from

10:23.480 --> 10:32.040
it. And these are, we know, these are related. So this is pretty much a very good starting point,

10:32.040 --> 10:37.720
but it doesn't give us everything. So there are a few other chalk points that might be useful to

10:37.720 --> 10:45.240
instrument and that have been useful to instrument that can, that improve our ability to reason about

10:45.800 --> 10:53.240
what is going on. Task scheduling is inherently inter-intro process. So it doesn't tell us about

10:53.240 --> 10:58.680
inter-pros communication, but fortunately in Chromium we have Mojo, which is an IPC subsystem,

10:58.680 --> 11:03.960
which we can also instrument and get pretty much the same information. But for cross-pros

11:03.960 --> 11:10.920
communication, we can know who is sending messages and we can connect the place which posted the

11:10.920 --> 11:16.200
message and places that received the message and to be able to trace this back through the flow.

11:17.320 --> 11:22.680
Capturing console logs and DV logs and debug logs and the both logs is also not a great source of

11:22.680 --> 11:28.040
information. If someone bothered to log it somewhere in the system, that's probably already useful

11:28.040 --> 11:33.240
for us. And being able to correlate this additional source with data with actual tasks that Chromium

11:33.240 --> 11:39.000
is using have been proven useful in many investigations. Capturing, instrumenting all of the

11:39.000 --> 11:45.400
blink binings and pretty much capturing all of the JavaScript functions, JavaScript calls that

11:45.400 --> 11:50.920
end up being implemented in blink is another great way to reason about what is going on and what

11:50.920 --> 11:59.320
the website is doing on and a couple of other similar infrastructure pieces. So the key takeaway

11:59.320 --> 12:05.640
here is that, hey, if you have complex systems, then probably you would do some good to instrument

12:05.640 --> 12:11.720
some of the widely used things and if you are familiar with this codebase, you will be able to

12:11.720 --> 12:18.680
make some informed judgment of what is going on and you will be able to spot outliers, something

12:18.680 --> 12:24.040
taking too long, log being held in case of performance regression or a functional regression

12:24.040 --> 12:31.160
or a flaky test, etc. And that's already a great step forward. So you have, you can look at it,

12:31.160 --> 12:35.800
you can like, if your test is flaky, you can run a thousand times, it will fail five times,

12:35.800 --> 12:41.080
you can open five phrases, look and see if you're lucky enough, you will be able to spot

12:42.120 --> 12:49.320
noticeable difference. But this is still not good enough for me. And the problem is that,

12:49.320 --> 12:55.560
despite having visibility into everything we're doing, this is very, very, very expertise intensive.

12:55.560 --> 13:01.400
So in order to be able to make good use of it, you have to kind of know everything. You have to

13:01.400 --> 13:07.400
know a lot about Chromium architecture. So as some of my colleagues say, you have to have a PhD

13:07.400 --> 13:13.320
in tracing and Chromium architecture to truly make this useful. And I have an inspiration of, hey,

13:13.320 --> 13:21.000
let's get it to the point that anyone, so any web developer can open and trace and instead of being

13:21.080 --> 13:28.920
discouraged and being intimidated by all of this mumbo jumbo, they can learn something about how

13:28.920 --> 13:37.080
Chromium actually works and get more knowledge about this. So an inspiration that I have is

13:37.080 --> 13:41.640
this slide and this diagram from a life of a delegation, talk from Chromium University,

13:42.360 --> 13:47.640
that is kind of similar to what we have already seen. It's a kind of a virtual timeline with a kind

13:47.720 --> 13:53.400
of boxers being connected by arrows. But if you look at it, then even if you are not deeply familiar

13:53.400 --> 13:59.160
with the browser architecture, then you probably kind of make some sense and you can make some

13:59.160 --> 14:05.240
educated guesses of what is going on. For example, if you see network stack doing start URL request

14:05.240 --> 14:12.040
as a one off stage, it's something that you can develop or get a reasonably good intuition for.

14:13.080 --> 14:17.400
And that's kind of the status quo that we currently have, which is pretty much exactly

14:17.400 --> 14:21.720
the same information, but slightly less useful, slightly less easier to read and slightly more

14:21.720 --> 14:28.040
intimidating. So for example, you can see tasks, you can see that hey, some of them are related to

14:28.040 --> 14:32.760
URL load the client, so you're getting information from the network. Someone, a navigation client,

14:32.760 --> 14:39.880
which kind of you know the navigation stack, you kind of guess what it is, but the level of

14:39.960 --> 14:47.400
intuitiveness is starkly different. So there are existing examples where we already do this in

14:47.400 --> 14:52.920
Chromium and we like take the care to reconstruct the high level events and the high level timeline

14:52.920 --> 14:59.560
for specific things. For example, this is an example of event latency. So specifically breaking down

14:59.560 --> 15:06.120
the timeline of steps and sequence of steps involved in presenting a frame. We're doing great on time.

15:06.920 --> 15:12.600
So the downside is that it's plumbing is very expensive and scaling this up is very difficult.

15:13.320 --> 15:17.160
When you have a big project, you have information, you need information from different

15:18.040 --> 15:22.920
you know corners of this project and plumbing is very expensive, both in terms of serialization

15:22.920 --> 15:26.920
costs, in terms of layering concerns, in terms of the amount of plumbing code that you need to

15:26.920 --> 15:32.440
maintain. And this you know difficult to scale and you know we haven't implemented this for too many

15:32.440 --> 15:39.320
exciting things. So let me talk about Perfetto a little bit. So Perfetto is the new generation

15:39.320 --> 15:45.800
tracing framework born from the ashes of Chromium tracing by a few great folks who have been working

15:45.800 --> 15:51.960
on Chromium tracing, got fed up with it, learned all of the mistakes that happened there and all of

15:51.960 --> 15:56.600
the things that we should shouldn't have done in the first place. And Voila Perfetto, which is

15:56.600 --> 16:02.440
nowadays widely used for Chromium and Android tracing. So it has fancy new UI, it has more

16:02.440 --> 16:10.200
efficient format, but the thing that brings a special place in my heart for it is the new

16:10.200 --> 16:16.440
SQL data model and query engine. So essentially everything that you can see in the UI is backed

16:16.440 --> 16:22.280
by a data model and UI is just running queries in the data model, against this data model and

16:22.280 --> 16:28.680
presenting it. And presenting it and you can very easily do it yourself. And you know we trace

16:28.680 --> 16:33.320
processor actually is compiled as a was module and running in your browser in a background

16:33.320 --> 16:42.600
thread. Voila web, we have gone, we've came very far. And this allows us to separate recording

16:42.600 --> 16:47.320
the trace and emitting the low level instrumentation and actually analyzing it and building high

16:47.320 --> 16:53.080
level data models. So this is probably the best example of Perfetto powers. I could

16:53.080 --> 16:59.400
hit it in a single slide. You can replicate this yourself if you go to Perfetto, if you go to

17:01.160 --> 17:07.240
open the Chrome trace, if you type colon into the search box, you will enter the SQL query mode

17:07.240 --> 17:15.000
and then you can copy and paste the query that I inserted there. Once again, you should have

17:15.000 --> 17:22.840
access to the slides and then it will pretty much give you the list of top 100 longest tasks that

17:22.840 --> 17:28.840
we ended up running there, which is already useful for analysis and can allow you to build more and

17:28.840 --> 17:36.600
more complex data models through different tables within SQL, which is kind of cool. So what are

17:36.600 --> 17:42.120
the next steps here? So I am right now trying to build in a navigation instrumentation,

17:42.200 --> 17:48.840
fancy navigation instrumentation as a proof of concept. The current prototype is kind of there,

17:48.840 --> 17:53.320
so you can see that we have a timeline. This is all pretty much based on the same low level

17:53.320 --> 18:01.880
information, but presents it in a more fancy version. And this then can be further integrated

18:01.880 --> 18:06.840
with the documentation. So this is just a not standalone box with a couple of words scribble

18:06.920 --> 18:12.440
on it, but we can also link to parts of Chromium documentation that outline what this stage

18:12.440 --> 18:19.080
is actually about, what are the concepts that you need to think about and make it generally more

18:19.080 --> 18:26.120
useful. One of the major complexities, why we haven't done this before, is that the complexity

18:26.120 --> 18:30.840
in a number of corner cases. When you talk about navigation, when you talk about typing the URL

18:30.840 --> 18:35.960
into the OmniBox, there are like a mind boggling complex number of cases from redirects to

18:37.160 --> 18:43.320
navigation, turning it to downloads to server returning to O4 and canceling the navigation

18:43.320 --> 18:49.320
that you kind of need to think about. And building this instrumentation without being able to test

18:49.320 --> 18:57.560
it is kind of a losing game. And the Sequel support actually allows us to feasibly write this

18:57.880 --> 19:06.840
testing coverage for these corner cases. I think I'm 15 out of 50 at this point, so some work to do.

19:08.920 --> 19:14.920
So yeah, I think that's all of the main content that I have. I have a bonus demo,

19:15.480 --> 19:20.040
which is kind of about DevTools, but I can also take questions.

19:28.200 --> 19:38.520
Eyeballing is, so the question is what's the best way of comparing these traces? I think eyeballing

19:38.520 --> 19:45.240
is probably a good place to start. So there are some early experiments of opening the traces

19:45.240 --> 19:50.920
times, say to some it and being able to link the timelines, but this is greatly depends on what

19:50.920 --> 20:02.120
kind of problem you're looking at. For example, if you are comparing the traces from tests,

20:02.120 --> 20:10.520
then the workload is more repeatable and you can actually go further in comparing it. For example,

20:10.520 --> 20:14.600
writing some Sequel queries and instructing some high-level metrics can get you very, very far

20:15.480 --> 20:21.560
and spotting if any high-level metrics changed or any derived things changed.

20:22.280 --> 20:27.960
If it's user's interactive, then probably eyeballing and going from there and seeing

20:27.960 --> 20:35.800
how much variance there is. Yes. Yes, some Sequel statement there.

20:44.600 --> 20:51.720
Yes, great question. The question is we have Sequel, but where is the database? The answer is it's

20:51.720 --> 20:58.280
all done locally. So this is Sequelite compiled into a WOS module with some helpers on top.

20:58.920 --> 21:04.520
So when you're opening a trace, it's running in your background thread in Sequelite instance.

21:04.520 --> 21:05.320
Everything is local.

21:11.400 --> 21:12.040
More questions?

21:15.320 --> 21:23.560
If not, I can actually go and show you my favorite House Party trick, which is an illustration of

21:23.560 --> 21:27.640
why it's actually quite important, I think, to think about data presentation. Sorry?

21:28.600 --> 21:34.680
More questions? No. Let me try to do this. Can you see what's going on?

21:35.240 --> 21:47.240
So let me open a trace in the performance in ground deftos that I have recorded earlier this morning.

21:47.240 --> 21:52.680
And this is something that you should be already familiar with, but the thing that some of you

21:52.680 --> 21:57.640
might not have realized, that there is nothing inherently magical or special about these deftal

21:58.360 --> 22:05.560
traces, apart from very good UI and a lot of UX thoughts that went into that. But fundamentally,

22:05.560 --> 22:12.280
they are just JSON-chrome traces, just with a bunch of categories. And you can actually open

22:12.280 --> 22:18.920
the very same information in Perfetto and actually look at it. And you already can see that the

22:18.920 --> 22:24.040
usefulness of this information is a bit different. We have to zoom and find our relevant parts,

22:24.120 --> 22:28.680
and we have been exposed with a low-level information, but no high-level insights.

22:28.680 --> 22:32.600
But then we have the network tracing. And the best way to illustrate that,

22:33.160 --> 22:40.440
further, is look at one of the network requests. Let me... Not this one. I want to find a network

22:40.440 --> 22:48.200
request from the deftools with the URL. And you can see that it... Some high-level stats, and you

22:48.200 --> 22:53.960
can see where it fits with other stuff. Psyllium shots also help. But then I can search by this

22:53.960 --> 23:03.400
URL, and I can also find the request ID and find all of the events, the low-level events that

23:03.400 --> 23:08.600
Chrome is tracing has actually meted. So all of the information about this network request is there.

23:08.600 --> 23:14.600
So if you can be bothered, you can actually go and correlate and go to all of these specific events

23:14.600 --> 23:21.160
and correlate them and reconstruct the same level, high-level takeaways. But it's going to be a little

23:21.160 --> 23:28.040
bit slower, a little bit less useful, and you won't actually be using it that much yourself, probably.

23:28.840 --> 23:32.040
So, yeah.

