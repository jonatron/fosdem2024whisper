WEBVTT

00:00.000 --> 00:07.000
Who's using Postgres in here?

00:07.000 --> 00:08.000
Yay!

00:08.000 --> 00:17.080
Thanks for being here on Sunday and our next speaker, Charlie, is going to talk about reducing

00:17.080 --> 00:20.800
the costs and reducing the costs.

00:20.800 --> 00:21.800
Those things out there.

00:21.800 --> 00:22.800
And other things as well.

00:22.800 --> 00:23.800
Good luck.

00:23.800 --> 00:24.800
Thank you.

00:24.800 --> 00:25.800
Thank you.

00:25.800 --> 00:26.800
Good evening.

00:26.800 --> 00:29.720
So yes, welcome.

00:29.720 --> 00:34.320
Today we're going to talk about how to reduce costs and improve performance.

00:34.320 --> 00:39.000
Doing really easy stuff, really easy things.

00:39.000 --> 00:41.880
Well my name is Charlie Batista.

00:41.880 --> 00:46.880
The presentation is not about me and this was made by ChatGPT so we can get these lights

00:46.880 --> 00:47.880
later.

00:47.880 --> 00:48.880
Sorry.

00:48.880 --> 00:49.880
Okay.

00:49.880 --> 00:50.880
Okay.

00:50.880 --> 00:52.880
Good to go.

00:52.880 --> 00:53.880
Nice.

00:53.880 --> 00:58.200
So what we're going to talk today, so we're going to have a bit of a review on what's

00:58.200 --> 00:59.200
about this talk.

00:59.200 --> 01:03.600
So we're going to review some concepts on how the hardware works, right?

01:03.600 --> 01:13.200
So try to understand a little bit what is cash, how Postgres stores data, and the summary.

01:13.200 --> 01:14.200
And thank you guys.

01:14.200 --> 01:15.200
You are good to go.

01:15.200 --> 01:16.680
So I think it's gone.

01:16.680 --> 01:17.680
See you next year.

01:17.680 --> 01:29.520
I'll be a bit fast because I have a lot of slides and not much off time so I will try

01:29.520 --> 01:30.520
to get.

01:30.520 --> 01:33.120
If you have questions at any time just raise your hand.

01:33.120 --> 01:34.120
That's fine.

01:34.120 --> 01:35.120
So just interrupt me.

01:35.120 --> 01:37.880
Or if you would like to, you can also wait for the end.

01:37.880 --> 01:41.080
We try to answer as many questions as you can.

01:41.080 --> 01:42.720
So what is this talk about?

01:42.720 --> 01:49.160
So this talk is not about go there and modeling a business.

01:49.160 --> 01:51.840
It's about how to model database, right?

01:51.840 --> 01:57.600
We try to understand a little bit how the underneath hardware works and how we can play

01:57.600 --> 02:01.080
nice with this and how Postgres can play nice with this, right?

02:01.080 --> 02:07.520
So we see some concepts about how computer stores data, how Postgres stores data.

02:07.520 --> 02:14.040
And it may be get a little low level but I'll try to keep it as more higher level as possible

02:14.040 --> 02:16.800
so we can all follow together.

02:16.800 --> 02:22.680
And we hope that the end of this talk will be able to understand a little bit and save

02:22.680 --> 02:25.960
some money, especially for those running on cloud, right?

02:25.960 --> 02:30.920
You know that space and these and those things cost a lot of money.

02:30.920 --> 02:33.600
And well, that said, let's start.

02:33.600 --> 02:36.600
We're going to do a quick review on the hardware.

02:36.600 --> 02:42.760
So I suppose most of you guys have seen this picture before.

02:42.760 --> 02:46.120
So this is the memory architecture.

02:46.120 --> 02:49.000
So how the memory is divided on the hardware.

02:49.000 --> 02:52.560
If you see down here, we have those secondary storage.

02:52.560 --> 02:58.640
This is your hard drive, SSD, HD type if anybody still use that thing.

02:58.640 --> 02:59.840
So this is the thing.

02:59.840 --> 03:05.160
If you see it's quite large but it's slow and usually inefficient.

03:05.160 --> 03:08.480
The latency is high.

03:08.480 --> 03:14.320
As we go up to the top, we go to the CPU registers, they get really, really fast.

03:14.320 --> 03:18.640
That's where the magic happens but they also get really, really expensive, right?

03:18.640 --> 03:25.800
We want to do our best to always use them in a very efficient way.

03:25.800 --> 03:28.120
Things to understand about memory.

03:28.120 --> 03:30.600
Memory is either volatile or non-volatile.

03:30.600 --> 03:32.680
That down here is non-volatile.

03:32.680 --> 03:36.120
That's where you save your data and you should save your data there if you want them the

03:36.120 --> 03:37.520
next day.

03:37.520 --> 03:43.840
Because if something happens and power loss or whatever, so everything that is up memory

03:43.840 --> 03:48.480
on those non-volatile, they're going to be lost, right?

03:48.480 --> 03:56.000
So also, as I said, the down is cheaper, the upper is higher price.

03:56.000 --> 04:00.000
Memory can also be basically accessed in three different ways.

04:00.000 --> 04:05.560
We have random access, direct access and sequential access.

04:05.560 --> 04:11.040
We'll see that most of the times we're doing random access, especially in RAM, RAM is basically

04:11.040 --> 04:13.160
random by nature.

04:13.160 --> 04:19.840
We also always try to do, when you go to the hard driver, to do sequential access both

04:19.840 --> 04:23.680
write and read and you try to understand why.

04:23.680 --> 04:31.040
So if you see here, see I have four CPU cores and I have the IO controller.

04:31.040 --> 04:36.560
One thing that you need to realize is the CPU is not connected to your disk.

04:36.560 --> 04:42.040
There is no physical cable or path away that the CPU talks to your hard drive.

04:42.040 --> 04:46.720
It doesn't matter if it's SSD, ADDD, tape or whatever.

04:46.720 --> 04:49.760
It needs to go to the memory controller.

04:49.760 --> 04:53.640
The memory has physical direct access to the hard drive.

04:53.640 --> 04:59.040
So every time that you need something, your CPU asks the memory and the memory catches

04:59.040 --> 05:01.280
that thing inside of the hard drive.

05:01.280 --> 05:08.360
And then it moves up all the way to the CPU.

05:08.360 --> 05:13.120
Also a very interesting thing that most of the developers do not realize is we don't

05:13.120 --> 05:16.720
write bytes on hard drive.

05:16.720 --> 05:22.720
When you're a software, open a text file and you save your name, my name is Charlie, five

05:22.720 --> 05:29.520
characters, five bytes, no, I still save one block in which most of the systems are four

05:29.520 --> 05:30.760
kilobytes.

05:30.760 --> 05:39.520
For that very simple operation of five characters, I'm dealing with four kilobytes block on the

05:39.520 --> 05:41.120
operational system.

05:41.120 --> 05:42.560
And that is for everything.

05:42.560 --> 05:44.880
The database also do the same.

05:44.880 --> 05:54.240
So if we can start doing more work with those four kilobytes block, things can go faster.

05:54.240 --> 05:57.520
That's one of the main ideas.

05:57.520 --> 06:02.960
Another thing that you see here, ADDD, they're really slow but still have a lot of companies

06:02.960 --> 06:08.120
and people using them because they're quite inexpensive nowadays.

06:08.120 --> 06:12.000
But random IEO is terrible, is low, is horrible.

06:12.000 --> 06:16.080
Every time that you need to do a random IEO there is horrible.

06:16.080 --> 06:19.360
And the problem is it's a mechanical device.

06:19.360 --> 06:24.400
So most of the people believe that the performance problem is on the plate, that the spinning

06:24.400 --> 06:25.400
plate.

06:25.400 --> 06:26.760
Actually that one is fast.

06:26.760 --> 06:33.560
The problem is on top of the spinning plate you have a literal ah that needs to move back

06:33.560 --> 06:34.760
and forward.

06:34.760 --> 06:39.000
And this movement is really, really slow.

06:39.000 --> 06:40.160
Really, really slow.

06:40.160 --> 06:46.040
So if you do a random IEO and the arm keeps, needs to keep moving back and forward, that's

06:46.040 --> 06:48.480
going to be horrible or whatever application.

06:48.480 --> 06:50.240
And especially for database.

06:50.240 --> 06:52.200
That's going to be really, really bad.

06:52.200 --> 06:58.560
So on SSDs, it's not that bad but it's still, the performance or random IEO is still not

06:58.560 --> 07:02.320
as the same as the sequential IEO.

07:02.320 --> 07:03.640
Both writes and reads.

07:03.640 --> 07:09.280
So writes are closer but they're still not as the same.

07:09.280 --> 07:17.760
So this is a little bit about what I mean about sequential axis.

07:17.760 --> 07:20.920
Sequential axis is when you write one block after another.

07:20.920 --> 07:23.640
Sequential and random is when you have that mess.

07:23.640 --> 07:30.880
So most of college people there when you go to their bedroom they had random axis there.

07:30.880 --> 07:34.800
So you can think about that thing.

07:34.800 --> 07:35.800
So but yeah.

07:35.800 --> 07:38.000
What is this cache?

07:38.000 --> 07:41.400
We're talking about improving performance and talking about those things but what does

07:41.400 --> 07:46.320
it has to do with cache and performance and database?

07:46.320 --> 07:55.920
So cache on its very simplistic definition, I got it from the Wikipedia, it is a hardware

07:55.920 --> 08:01.960
or software component that stores data so you can access them in the future in a faster

08:01.960 --> 08:03.680
way.

08:03.680 --> 08:06.080
We have many, many different levels of cache.

08:06.080 --> 08:13.480
So we have natural cache, we have hard drives cache, we have application cache, most of

08:13.480 --> 08:18.120
the database they do have the application cache and we also have the CPU cache.

08:18.120 --> 08:23.280
This is the one that we really interest for us today.

08:23.280 --> 08:26.240
And we have some definitions here.

08:26.240 --> 08:28.200
So what is a cache heat?

08:28.200 --> 08:29.200
Anybody?

08:29.200 --> 08:30.200
Come on guys.

08:30.320 --> 08:32.320
Exactly.

08:32.320 --> 08:41.520
Let's say for example I want to do a select and I want to get the Charlie, the first

08:41.520 --> 08:47.120
time that I do select and get Charlie's information and goes for the disk up to memory CPU.

08:47.120 --> 08:49.520
So but it stays there.

08:49.520 --> 08:53.280
The database doesn't throw it back because next time that I do a select for a Charlie's

08:53.280 --> 08:55.400
information again the memory is not there.

08:55.400 --> 08:57.240
The information is on the memory.

08:57.600 --> 09:03.320
If luckily on the CPU cache, remember that high top we also have cache there close to

09:03.320 --> 09:05.960
the CPU which is really, really fast.

09:05.960 --> 09:09.480
This is a cache heat and a cache miss is the opposite.

09:09.480 --> 09:14.240
So if I do a select and that row has never been selected before it needs to go to the

09:14.240 --> 09:16.080
hard driver so that's a miss.

09:16.080 --> 09:20.560
It needs to go and then all the way so that's going to be really, really slow very inefficient.

09:20.560 --> 09:29.520
So if you have a heat ratio higher so more cache heat than cache misses the better and

09:29.520 --> 09:31.520
the faster is our application.

09:31.520 --> 09:35.200
So we always try to improve that metric there.

09:35.200 --> 09:37.560
It's a very important metric.

09:37.560 --> 09:40.680
We also have some writing policies.

09:40.680 --> 09:44.480
So we have the write through and write back policies.

09:44.480 --> 09:52.320
So the write through policy is when you send information to the cache especially when we

09:52.320 --> 09:57.640
save in data to the cache so the database is saving data it can keep the information

09:57.640 --> 10:03.680
in the cache now and save later or can immediately save that information both in the cache and

10:03.680 --> 10:05.160
in the hard driver.

10:05.160 --> 10:09.680
So a write through is immediately save that information.

10:09.680 --> 10:13.400
So it stays in the cache but then immediately saves information.

10:13.400 --> 10:14.880
So what's the problem with that?

10:14.880 --> 10:16.560
The problem is latency.

10:16.560 --> 10:19.680
So we increase latency when you use that policy.

10:19.680 --> 10:21.320
Oh is it all bad?

10:21.320 --> 10:23.080
Some applications are fine with that.

10:23.080 --> 10:30.720
So some applications that need higher reliability will implement that policy.

10:30.720 --> 10:33.600
And so we have tradeoffs here.

10:33.600 --> 10:34.840
The other one, the write back.

10:34.840 --> 10:42.720
So the information stays on the cache and eventually that's up to the CPU if it's a CPU cache or

10:42.720 --> 10:48.640
up to the aggregate of the application to eventually save that data back to the hard

10:48.640 --> 10:49.640
driver.

10:49.640 --> 10:56.680
Remember, everything that's up there if we have power loss we might have a problem.

10:56.680 --> 11:04.600
So in this case we might improve a lot of performance but we may lose in reliability.

11:04.600 --> 11:08.200
So we need to have that tradeoff.

11:08.200 --> 11:11.480
And then we have the prefetch.

11:11.480 --> 11:13.200
Different CPUs, they're very smart.

11:13.200 --> 11:15.240
At least they tend to be very smart.

11:15.240 --> 11:26.800
So those theory that when you go to cache, the information that you get now you probably

11:26.800 --> 11:30.000
will get more information around that data.

11:30.000 --> 11:32.720
So we call it cache locality.

11:32.720 --> 11:40.120
So based on locality if I have Maria, Charlie and John, if I select Charlie, the probability

11:40.120 --> 11:46.560
that they'll need data from Maria and John is higher than that I get down the line.

11:46.560 --> 11:50.360
So it's playing about probability.

11:50.360 --> 11:54.600
We also have the time locality.

11:54.600 --> 11:59.440
So the information that they just accessed now has higher chance that they're going to

11:59.440 --> 12:02.680
access in the future, like in five minutes and a few minutes.

12:02.680 --> 12:09.920
So what this prefetch does, when we ask for one block for the CPU, the CPU, oh, this guy's

12:09.960 --> 12:13.080
accessing this block so he's probably going to need the next block.

12:13.080 --> 12:18.040
So the CPU prefetch loads in advance that block and puts in cache.

12:18.040 --> 12:20.680
So if I need that block, it's already in cache.

12:20.680 --> 12:24.280
The CPU doesn't need to go back to fetch that information again.

12:24.280 --> 12:26.120
So that's improved performance.

12:26.120 --> 12:28.040
That's awesome, right?

12:28.040 --> 12:30.240
Now comes the problem.

12:30.240 --> 12:32.440
Cache are expensive.

12:32.440 --> 12:35.840
So when it gets close to the CPU, they get really, really expensive.

12:35.840 --> 12:41.120
If you're going to buy a laptop or device or whatever and you choose the CPU i9, i20,

12:41.120 --> 12:46.320
you're going to see they have those L1 cache, L2 cache, and they're usually in gigabytes,

12:46.320 --> 12:47.320
right?

12:47.320 --> 12:48.320
Thatabytes.

12:48.320 --> 12:49.320
They're usually in kilobytes.

12:49.320 --> 12:52.440
You're going to get kilobytes of cache.

12:52.440 --> 12:55.640
What can you do with kilobytes nowadays?

12:55.640 --> 12:57.280
Almost nothing, right?

12:57.280 --> 13:00.080
Another problem is what we call cache line.

13:00.080 --> 13:03.920
The cache line is literally the line that the cache is divided.

13:03.920 --> 13:10.080
So the cache is divided in many lines and each line has a specific size and usually depends

13:10.080 --> 13:12.400
on the CPU word size.

13:12.400 --> 13:14.400
What's that CPU word size?

13:14.400 --> 13:20.880
So if I have a 64-bit CPU, the CPU word size is going to be 64-bits and the cache line

13:20.880 --> 13:25.160
likely would be 64-bits.

13:25.160 --> 13:27.080
So why likely?

13:27.080 --> 13:34.440
Because when we go to the CPU, we start not counting the time in times anymore, in seconds

13:34.440 --> 13:35.440
or nanoseconds.

13:35.440 --> 13:39.800
Now we're counting the time in clock cycles.

13:39.800 --> 13:44.280
So inside of the CPU, it has those things that they call registered that are really,

13:44.280 --> 13:45.280
really fast.

13:45.280 --> 13:48.640
It takes only one clock cycle for the CPU to get information there.

13:48.640 --> 13:50.640
So it's really fast.

13:50.640 --> 13:57.040
When we go to the cache, the L1 cache, it usually takes between three to seven clock

13:57.040 --> 13:58.040
cycles.

13:58.040 --> 14:01.080
It depends on the CPU and depends on the cache.

14:01.080 --> 14:03.840
So things start to slow down.

14:03.840 --> 14:07.200
People always tell you memory is really fast.

14:07.200 --> 14:11.600
Memory takes 215 clock cycles.

14:11.600 --> 14:16.400
Can be 100 times slower than the CPU cache.

14:16.400 --> 14:22.520
So memory for the CPU point of view is really, really, really, really slow.

14:22.520 --> 14:25.040
So we don't want to go there.

14:25.040 --> 14:26.720
Can you imagine your hard driver?

14:26.720 --> 14:33.000
They didn't even put here because I don't know the number of years of data to fit there.

14:33.000 --> 14:34.880
That's insanely slow.

14:34.880 --> 14:38.800
So that's why we always try to put information there.

14:38.800 --> 14:42.640
Remember that thing that I said about the line size?

14:42.640 --> 14:45.960
So we might have a problem.

14:45.960 --> 14:49.720
We want to fit everything inside that size.

14:49.720 --> 14:51.840
We don't want to waste that thing.

14:51.840 --> 14:56.200
So can you guys spot a problem in this here?

14:56.200 --> 14:58.440
I put a really simple algorithm here.

14:58.440 --> 15:02.120
So a tip is not the code or anything.

15:02.120 --> 15:03.120
It compiles.

15:03.120 --> 15:05.920
So that's not a problem.

15:05.920 --> 15:06.920
Anybody?

15:06.920 --> 15:07.920
On the line.

15:07.920 --> 15:08.920
On the line.

15:08.920 --> 15:10.160
That's exactly on the line.

15:10.160 --> 15:15.160
So most of the developers, at least a lot of them, will believe that information will

15:15.160 --> 15:16.720
fit in memory just like this.

15:16.720 --> 15:20.280
So we have the int, the boolean, the int, the boolean again.

15:20.280 --> 15:23.080
The problem is it won't.

15:23.080 --> 15:24.080
Why?

15:24.080 --> 15:25.080
Let me see if this thing works.

15:25.080 --> 15:26.080
Can you see?

15:26.080 --> 15:27.920
No, that pointer doesn't work.

15:27.920 --> 15:33.480
So you see from 0 to 7, it has 8 blocks, little blocks.

15:33.480 --> 15:37.120
So it is 64 bits there.

15:37.120 --> 15:39.360
8 bytes or 64 bits.

15:39.360 --> 15:42.960
This is in this example the size of my cache line.

15:42.960 --> 15:51.240
So because the CPU can only fetch one word size at a time, it can only fetch that information.

15:51.240 --> 15:59.120
So the boolean that is only one bit here will have to go to the next page.

15:59.120 --> 16:00.760
And see all those white stuff?

16:00.760 --> 16:01.880
We call it padding.

16:01.880 --> 16:03.880
It's waste.

16:03.880 --> 16:06.360
Waste of money and waste of time.

16:06.360 --> 16:13.560
So in this example here, if we go back, we have one cube, big blocks, right?

16:13.560 --> 16:17.520
We could fit them in two big blocks if we aligned them properly.

16:17.520 --> 16:21.560
So we will have two CPU blocks to fetch that information.

16:21.560 --> 16:25.880
But actually, we're going to have four, double the time.

16:25.880 --> 16:28.400
And we only have four variables here.

16:28.400 --> 16:33.000
So we mess it up things really, really quickly.

16:33.200 --> 16:38.320
Keep that in mind because that's going to be really important for our discussion here moving on.

16:38.320 --> 16:42.640
So yeah, how POSC is organized the data?

16:42.640 --> 16:47.840
So POSC and most of the database has its own file organization.

16:47.840 --> 16:49.560
Those are the most common one.

16:49.560 --> 16:50.880
We have the B3s.

16:50.880 --> 16:55.560
I just put here in ascending order.

16:55.560 --> 16:56.640
So no special things.

16:56.640 --> 17:00.280
It's not that one uses more or less on B3 or one is better on others.

17:00.280 --> 17:01.560
It's not the point.

17:01.600 --> 17:04.560
So but POSC uses what we call hip files.

17:04.560 --> 17:08.120
Hip files are really interesting things because they are very simple.

17:08.120 --> 17:10.960
If not the simplest one, it's one of the most simple.

17:10.960 --> 17:12.880
How a hip file does work?

17:12.880 --> 17:17.240
So it's basically one spaghetti of information.

17:17.240 --> 17:18.760
You put one block after another.

17:18.760 --> 17:19.320
That's it.

17:19.320 --> 17:20.440
That's a hip file.

17:20.440 --> 17:23.760
There's no order, no guarantee of order.

17:23.760 --> 17:25.000
There's nothing special.

17:25.000 --> 17:27.960
You just have one block after another.

17:27.960 --> 17:29.200
This is a hip file.

17:29.200 --> 17:31.280
So it's very simplistic implementation, right?

17:31.320 --> 17:35.640
But it can also be very efficient because remember the locality thing.

17:35.640 --> 17:41.040
So if you just have one block and if you prefetch all that information,

17:41.040 --> 17:42.480
that's going to be sequential.

17:44.360 --> 17:47.680
A problem for indexes, sometimes people do not understand why POSC

17:47.680 --> 17:51.600
please do not pick that amazing nice index that I just created for my application.

17:51.600 --> 17:53.000
So it was there.

17:53.000 --> 17:54.760
I have an index there.

17:54.760 --> 17:58.960
Sometimes, you know, but the database doesn't pick it up.

17:58.960 --> 18:01.600
And a lot of people, they want to facilitate the database to pick things up

18:01.600 --> 18:03.560
because they think there's nothing in the database.

18:03.560 --> 18:06.280
Well, sometimes they also do and then they realize they're not.

18:06.280 --> 18:07.040
But it happens.

18:07.040 --> 18:11.520
So one of the problems is the index is a B3, most of them.

18:11.520 --> 18:15.040
So B3 by nature is random.

18:15.040 --> 18:17.720
The access is random because you have one block here, another here,

18:17.720 --> 18:19.240
another here, another there.

18:19.240 --> 18:25.600
So you are changing the access pattern from sequential to random.

18:25.600 --> 18:31.520
Remember how random lies expensive, especially on the ADD thing that they spin in this?

18:31.520 --> 18:35.360
Yeah, that would be horrible, even for a really efficient index.

18:35.360 --> 18:42.360
So that's why the database say, nah, not today, maybe tomorrow, you know, today I'm fine.

18:42.360 --> 18:45.360
I just do a full table scan, let's just get everything.

18:45.360 --> 18:51.360
And more often than we sometimes think it's faster.

18:51.360 --> 18:58.840
So but if files in postgres, they have some very interesting properties that go back here.

18:58.840 --> 19:01.640
If I put somewhere, no, here, no, here.

19:01.640 --> 19:06.240
Well, they are eight kilobytes.

19:06.240 --> 19:10.760
So the block on the hip file, I think, yeah, eight kilobytes size.

19:10.760 --> 19:15.040
And each file has the limit of one gigabyte.

19:15.040 --> 19:18.680
So it means that we can only have one gigabyte table in postgres, right?

19:18.680 --> 19:22.240
No, limit one gigabyte, just create another one, and another one, another one.

19:22.240 --> 19:27.920
I have one terabyte information that I'm going to have 1025 files.

19:27.920 --> 19:32.160
So be mindful of that, because depending on the file system that you use,

19:32.160 --> 19:36.720
some file systems, they do not play well with many, many files on the same folder.

19:36.720 --> 19:37.400
Right?

19:37.400 --> 19:38.960
Be mindful of that as well.

19:38.960 --> 19:42.400
That might be a problem.

19:42.400 --> 19:45.640
So it's of eight kilobytes size.

19:45.640 --> 19:47.080
Keep that information in mind as well.

19:47.080 --> 19:50.600
That's also going to be quite important when we move on.

19:50.600 --> 19:54.280
So as I said, one row is just appended after another.

19:54.280 --> 19:55.880
So not in fancy.

19:55.880 --> 19:58.800
There's no fancy organization or whatever.

19:58.800 --> 20:04.520
And if you go for postgres, insert all your data in a nice way, index it there, okay, yeah.

20:04.520 --> 20:07.640
And if you do an update on that data, and then you search again,

20:07.640 --> 20:10.280
if you do not put another thereby, that's going to mess up your order.

20:10.280 --> 20:12.400
So be also mindful about that.

20:12.400 --> 20:16.960
So the hit files has no guarantee of order at all.

20:16.960 --> 20:18.400
Right?

20:18.400 --> 20:20.800
So this is basically how it's organized.

20:20.800 --> 20:26.000
And every single block, it has its own organization.

20:26.000 --> 20:28.800
So it has a header.

20:28.800 --> 20:30.200
The header has a lot of data.

20:30.200 --> 20:34.280
I put the information here, as I said, I'm not going to go through all of them,

20:34.280 --> 20:35.480
because that's not the point.

20:35.480 --> 20:39.000
But you can go and search on the documentation.

20:39.000 --> 20:40.960
They're really nice.

20:40.960 --> 20:45.440
Now what matters for our discussion here is how these things are organized.

20:45.440 --> 20:46.440
Right?

20:46.440 --> 20:47.440
So this is inside of the block.

20:47.440 --> 20:51.240
This is a picture of the block inside of the database, inside of postgres.

20:51.240 --> 20:54.920
So we have the header, and then we have the data.

20:54.920 --> 21:00.120
Nice thing is data is started and stored by the end, not by the beginning.

21:00.120 --> 21:05.080
We have an index, sorry, a pointer that points to the data.

21:05.080 --> 21:11.800
So the data goes towards the center from the end of the block, and the point also goes

21:11.800 --> 21:13.480
toward to the center.

21:13.480 --> 21:17.480
So when they get close together, that means I don't have space anymore on that block.

21:17.480 --> 21:18.480
Right?

21:18.480 --> 21:19.480
The block is full.

21:19.480 --> 21:22.080
The database needs to create another block to put more information.

21:22.080 --> 21:26.920
Also, postgres doesn't split the data between blocks.

21:26.920 --> 21:31.320
If your block doesn't fit inside, if your data doesn't fit inside one block that is

21:31.320 --> 21:36.000
8 kilobytes, actually we'll see that if it doesn't fit inside half of the block, it's

21:36.000 --> 21:37.320
going to do something else.

21:37.320 --> 21:41.000
Otherwise, you're not going to lose your data.

21:41.000 --> 21:43.400
But yeah, the database will handle that.

21:43.400 --> 21:52.280
So also, those rows here that we see here, those tuples, tuples and rows, we call them

21:52.280 --> 21:53.720
interchangeably the same thing.

21:53.720 --> 21:56.600
So the rows here, they also have their own organization.

21:56.600 --> 21:58.640
I put here all those things.

21:58.640 --> 22:03.120
And I will go for a couple of things that are important for the discussion, not all

22:03.120 --> 22:04.120
of them.

22:04.120 --> 22:06.560
They are fixed size.

22:06.560 --> 22:10.880
Well, they have a header as well, that the header is fixed size.

22:10.880 --> 22:17.080
A question, does anybody know how postgres stores new?

22:17.080 --> 22:22.120
If I have a table and I have a lot of columns that can be new, anybody?

22:22.120 --> 22:24.120
The null bit map.

22:24.120 --> 22:25.120
Sorry?

22:25.120 --> 22:26.120
The null bit map.

22:26.120 --> 22:27.120
The null bit map.

22:27.120 --> 22:34.120
Does anybody know what is a bit map?

22:34.120 --> 22:35.120
Okay.

22:35.120 --> 22:40.640
Yeah, a bunch of bits.

22:40.640 --> 22:46.040
So you have what we call map, actually, you have the sequence of bits.

22:46.040 --> 22:50.360
You have 11111010100001.

22:50.360 --> 22:51.680
That's the map of bits.

22:51.680 --> 22:56.560
So what postgres does, it has this sequence of things.

22:56.560 --> 23:03.000
And the position of the one of zero on that thing is the position of the column inside

23:03.000 --> 23:04.320
of your row.

23:04.320 --> 23:07.160
So if it's zero, it means there's no null.

23:07.160 --> 23:10.040
If it's one, that means you have a null.

23:10.040 --> 23:14.680
So it's highly efficient and compact the way that stores null inside of postgres.

23:14.680 --> 23:15.680
Yeah.

23:15.680 --> 23:18.720
This is how it works.

23:18.720 --> 23:26.440
And also what is very important here, this is, again, another photo of the row, is this

23:26.440 --> 23:28.240
padding.

23:28.240 --> 23:30.240
Remember the CPU padding?

23:30.240 --> 23:35.040
Well, the database also tries to keep things aligned with the CPU.

23:35.040 --> 23:43.040
So if things don't align with the CPU, the database will add padding.

23:43.040 --> 23:46.760
And we'll see how nice that can play.

23:46.760 --> 23:47.760
Right?

23:47.760 --> 23:53.240
Remember that I said if the data doesn't fit there, the postgres will save somewhere else.

23:53.240 --> 23:55.440
This is what we call toast.

23:55.440 --> 23:59.680
This is the oversized attribute storage technique.

23:59.680 --> 24:03.600
And usually goes really well with coffee.

24:03.600 --> 24:11.800
So postgres uses another file, that's not your data file, to put the information that

24:11.800 --> 24:14.240
doesn't fit inside of the block.

24:14.240 --> 24:19.080
And then it puts a reference inside of the block, a pointer, to the beginning of the

24:19.080 --> 24:20.880
data on the other file.

24:20.880 --> 24:24.360
So the database does it automatically, you don't have to do anything about that thing.

24:24.360 --> 24:31.080
So every time that you have text, VACA, 3000 and something, that, you're going to have

24:31.080 --> 24:36.360
a toast because that won't fit in 8 kilobytes page.

24:36.360 --> 24:45.200
So there are a lot of improvements since being created with compression and those things.

24:45.200 --> 24:47.600
So it plays quite well.

24:47.600 --> 24:56.080
And when we understand how those things work, we can also change our data organization.

24:56.080 --> 25:01.960
But that by itself would be another talk.

25:01.960 --> 25:05.360
But I can give a just a small example here.

25:05.360 --> 25:12.960
So let's say we have the table user, where the user does the authentication, right?

25:12.960 --> 25:19.040
So for the authentication to work, we only need to compare the username and password.

25:19.040 --> 25:22.840
But then when the user has been authenticated, sometimes you want to show the pictures, the

25:22.840 --> 25:28.200
bio and a lot of information that's there in the toast.

25:28.200 --> 25:35.840
So if we create a table with only that information for the authentication, the authentication process

25:35.840 --> 25:41.560
that's a complicated process can go really, really fast because you can fit a lot of things

25:41.560 --> 25:45.080
inside one block space.

25:45.080 --> 25:47.400
And the database doesn't need to go to the toast.

25:47.400 --> 25:50.720
We have the toast in the information and the modeling.

25:50.720 --> 25:55.760
So and then when we need to show the information from the user, we can use, still use that

25:55.760 --> 26:00.200
same primary key that we have a reference for for an key and get that data on that very

26:00.200 --> 26:02.960
specific time.

26:02.960 --> 26:07.880
And for most of the applications, the authentication is a hot path.

26:07.880 --> 26:10.720
Everybody knows goes to the authentication.

26:10.720 --> 26:14.640
But really few people go to the bio page.

26:14.640 --> 26:19.120
So we can improve the performance of our application just doing nothing.

26:19.120 --> 26:20.800
Really simple changes.

26:20.800 --> 26:23.980
And we get a boost on the performance.

26:23.980 --> 26:28.700
So we already got the things, the performance improvement.

26:28.700 --> 26:29.700
How those works.

26:29.700 --> 26:37.700
So as I said, when it's filled a percentage of the block, it will be saved elsewhere and

26:37.700 --> 26:40.980
has a pointer to those things.

26:40.980 --> 26:44.100
And now we come to what really matters.

26:44.100 --> 26:48.100
So if the data is too large, they go into toast.

26:48.100 --> 26:51.540
But what if I have too many small problems?

26:51.540 --> 26:57.380
Well, if you have too many small post-process has a limit of how many columns you can fit

26:57.380 --> 27:00.940
inside of your table.

27:00.940 --> 27:06.780
Because in that case, it won't fit on the block, right?

27:06.780 --> 27:15.260
So the question is, if we have too many columns, how does it do if it doesn't split?

27:15.260 --> 27:17.740
So you just have the maximum of columns.

27:17.740 --> 27:22.340
Depending on the data type we're using, for example, if you're using big inch, that is

27:22.340 --> 27:26.740
eight bytes, so you have that number.

27:26.740 --> 27:29.220
If you're using smaller inch, you can fit more.

27:29.220 --> 27:34.060
So but you have a hard limit because of the block size.

27:34.060 --> 27:35.340
That is what it does.

27:35.340 --> 27:38.740
If it doesn't fit, you need to split the table in more than two, three, four, whatever many

27:38.740 --> 27:39.980
times you need.

27:39.980 --> 27:40.980
But that would be insane.

27:40.980 --> 27:43.980
Like have hundred or six, 64 columns inside of the table.

27:43.980 --> 27:48.980
Can you repeat the question because you're not talking about it?

27:48.980 --> 27:56.620
So the question is, the post puts the information outside because it's a larger than the block.

27:56.620 --> 28:02.500
But if we have too many rows, too many columns inside of the row, how post-process handles

28:02.500 --> 28:03.620
that?

28:03.620 --> 28:04.620
So that was the question.

28:04.620 --> 28:10.900
And again, post-process just has a lot of limits on the number that you can put there.

28:10.900 --> 28:12.940
More than that, you need to create more than one table.

28:12.940 --> 28:15.900
That would be the solution.

28:15.900 --> 28:19.500
Now we come to the data alignment and padding.

28:19.500 --> 28:24.660
So remember that I said the database also does padding and post-process also does.

28:24.660 --> 28:32.620
So the natural alignment on post-process padding is of eight bytes or 64 bits.

28:32.620 --> 28:34.580
That's the natural alignment.

28:34.580 --> 28:36.820
So what does that mean?

28:36.820 --> 28:44.900
It means that every time that you put one integer, integer is four bytes, you need to

28:44.900 --> 28:48.860
put another integer together to get a perfect alignment.

28:48.860 --> 28:54.380
If you put an integer of four bytes and a big integer just after that integer, so that

28:54.380 --> 29:01.620
big integer is going to go to the next one because it doesn't fit the natural alignment.

29:01.620 --> 29:05.700
And you can ask me, well, what's the problem?

29:05.700 --> 29:06.700
Just go to the next one.

29:06.700 --> 29:07.860
Not a big deal.

29:07.860 --> 29:15.100
So every type has its own alignment here, as you can see.

29:15.100 --> 29:21.020
Shaw has basically no alignment needed because it's variable.

29:21.020 --> 29:23.300
It doesn't mean that's good to use car.

29:23.300 --> 29:26.900
Actually it's good to put at the end, not at the beginning.

29:26.900 --> 29:29.020
And we'll see why.

29:29.020 --> 29:33.740
So we see that Shaw has alignment of two bytes.

29:33.740 --> 29:34.740
It means, yep.

29:34.740 --> 29:45.740
So does the order of the fields or can optimize the order of the fields?

29:45.740 --> 29:50.580
So when I decide my table, do I need to think this?

29:50.580 --> 29:51.580
I got it.

29:51.580 --> 29:58.420
So the question is, does the database automatically reorganize internally to put it in the best

29:58.420 --> 29:59.420
way?

29:59.420 --> 30:05.540
Or does the DBA need himself to change the order of the fields, the columns, to put

30:05.540 --> 30:06.540
in the best way?

30:06.540 --> 30:07.540
The database does not.

30:07.540 --> 30:10.040
This is work of the DBA.

30:10.040 --> 30:13.060
The DBA has to do this work, and it's a really good question.

30:13.060 --> 30:16.860
And we'll see sooner or later why it happens.

30:16.860 --> 30:20.300
As we see here, every type has its own alignment.

30:20.300 --> 30:21.940
This is on post-presokumentation.

30:21.940 --> 30:23.820
It's just a copy and paste.

30:23.820 --> 30:31.700
So the two bytes on most machine, that means that one will occupy two bytes there.

30:31.700 --> 30:34.820
So for example, we are aligned with eight bytes.

30:34.820 --> 30:43.260
So I can fit four of those data types one after another that does eight bytes.

30:43.260 --> 30:49.180
However, if I put one of two bytes in a big integer that's eight bytes by itself, we're

30:49.180 --> 30:52.820
going to have six bytes, pageant, waste.

30:53.820 --> 30:55.820
Remember, pageant is waste.

30:55.820 --> 31:00.820
Most of the time, waste of money, especially if we're running on cloud.

31:00.820 --> 31:02.820
All right.

31:02.820 --> 31:11.820
And it's really possible to optimize those things to make them to work in a better way.

31:11.820 --> 31:16.820
And this is an example.

31:16.820 --> 31:22.820
So in this example here, what I did, yes, let's say I create that table.

31:22.820 --> 31:25.820
See, we have a really few columns there, not many.

31:25.820 --> 31:33.820
I just put in a random order, like I put an integer, and then I put a bar card, and then a timestamp.

31:33.820 --> 31:35.820
So that was a very small table.

31:35.820 --> 31:38.820
I only inserted one million rows.

31:38.820 --> 31:51.820
So on that one million rows, I got a certain size, and then I organized it just to align better, to remove the pattern.

31:51.820 --> 31:57.820
The alignment saved me 25% of space.

31:59.820 --> 32:04.820
How much would be 25% less in your build on AWS of storage?

32:05.820 --> 32:08.820
We make and buy a burger, right?

32:10.820 --> 32:12.820
We never know.

32:12.820 --> 32:17.820
So we'll see a couple of our examples.

32:17.820 --> 32:19.820
Wait for people to take photos.

32:21.820 --> 32:22.820
All right.

32:22.820 --> 32:23.820
Yeah, question?

32:23.820 --> 32:36.820
Jason B, it has its own, if I test the Jason B data type, that's the question, right?

32:36.820 --> 32:47.820
So Jason B has its own specificities, so, and most of it doesn't go inside of the block, because most of the time it doesn't fit inside of the block, right?

32:48.820 --> 32:53.820
The problem about Jason B, it has its own algorithm of optimizations.

32:53.820 --> 33:03.820
So, but I haven't answered your question, I did not, but that would be really interesting one to do, to see how that works, how that plays together.

33:03.820 --> 33:14.820
Especially because Jason B has a binary format, so the binary itself, algorithm should be able to do a lot of optimizations on the way.

33:14.820 --> 33:17.820
But yeah, I'll take notes of that one, because now I'm curious.

33:17.820 --> 33:19.820
Another question?

33:30.820 --> 33:37.820
So the question is, if there is any analyzer tool that we can use to see how much space we're wasting, right?

33:37.820 --> 33:38.820
Not that I know.

33:38.820 --> 33:40.820
That might have there, but not that I know.

33:40.820 --> 33:43.820
That also would be a really nice open source tool to develop, you know?

33:43.820 --> 33:46.820
People looking for ideas, that's a nice one.

33:47.820 --> 33:54.820
Back to Jason B, the data base, the table.

33:54.820 --> 34:04.820
Like, there are a few things about the Jason B, is that like 60 bytes, 32 bytes, 64 bytes, how do you organize the database?

34:04.820 --> 34:08.820
Okay, the question is back to Jason B, how does it organize it?

34:08.820 --> 34:11.820
It's organized in 64, 32 bytes.

34:11.820 --> 34:15.820
I don't have an answer for that question, because I really have no idea.

34:15.820 --> 34:19.820
I haven't played with Jason B much.

34:19.820 --> 34:28.820
Most of the work I'm doing with those things, performance, and how I would say, netrodata types, right?

34:28.820 --> 34:32.820
So, but yeah, I don't have an answer for that either.

34:33.820 --> 34:38.820
How long do you take to review everything and optimize it?

34:38.820 --> 34:43.820
And are there any tools to make the process much quicker, like any automated scripts?

34:43.820 --> 34:51.820
The question is how long does it take to do the full reveal and the process, and if there is two?

34:51.820 --> 34:53.820
Well, I don't know of two.

34:53.820 --> 34:58.820
And the time, it highly depends how complex your database.

34:58.820 --> 35:05.820
If you have a small database, like the one that they use for the TPCC, it took me like a few minutes, right?

35:05.820 --> 35:09.820
But to have really complex database, it can take you some time.

35:09.820 --> 35:12.820
But it's time that works it.

35:20.820 --> 35:26.820
The question is if the alignment only works on Postgres or if the other database is as well.

35:29.820 --> 35:34.820
If I'm not mistaken, Oracle also does, but its implementation is specific.

35:34.820 --> 35:36.820
It's from database to database.

35:36.820 --> 35:43.820
And I have not played with those, especially because this type of documentation is not highly available.

35:43.820 --> 35:49.820
And if you do not have documentation, you really need to go to the binary and it's really time consuming.

35:49.820 --> 35:53.820
And I haven't been working with other databases for like 15 years.

35:53.820 --> 35:55.820
So yeah, but they probably do.

35:59.820 --> 36:11.820
The question is if we have a way to ask Postgres how the alignment is, right?

36:11.820 --> 36:18.820
If we have tooling, yes, we do have some extensions that we can go deep and see how the organization is.

36:18.820 --> 36:22.820
We even have some extension that we can check the memory for from time to time.

36:23.820 --> 36:26.820
Okay, moving on because I only have 15 minutes.

36:26.820 --> 36:27.820
Thanks, sir.

36:27.820 --> 36:30.820
Probably now it's less because he's been showing me that for five minutes.

36:32.820 --> 36:36.820
So, okay, what are the implications about those things, right?

36:36.820 --> 36:38.820
I showed you one example.

36:38.820 --> 36:48.820
Now I'm going to show you another one that they use a tool named sysbench that they did a TPCC-like experimentation to see.

36:49.820 --> 36:52.820
So this is just an example of one of the tables.

36:52.820 --> 36:54.820
This is how sysbench created the table.

36:54.820 --> 36:55.820
This is normal stuff.

36:55.820 --> 36:57.820
And you see it's really small table.

36:57.820 --> 36:58.820
There's not much.

36:58.820 --> 37:01.820
And most of the columns are integers.

37:01.820 --> 37:05.820
So nothing going on there, right?

37:05.820 --> 37:07.820
And this is what I did.

37:07.820 --> 37:11.820
Besides the flashing thing, did you guys not see anything?

37:14.820 --> 37:16.820
I changed some orders of the column.

37:16.820 --> 37:18.820
It's a shame that this point is not working.

37:18.820 --> 37:20.820
But yeah, I changed some orders.

37:20.820 --> 37:32.820
See, I put all the integers on the top and then I put the small integers on the way that they are in pairs to improve the alignment.

37:32.820 --> 37:34.820
And then I put the other columns.

37:34.820 --> 37:35.820
See that I put the timestamp.

37:35.820 --> 37:41.820
A timestamp, if I'm not mistaken, is also eight or four bytes.

37:42.820 --> 37:48.820
And after that one, I put the another small inch because they can still use the same space on the alignment.

37:48.820 --> 37:50.820
So I have four and two, still have six.

37:50.820 --> 37:54.820
So the only padding that I'm going to have is after that one.

37:54.820 --> 37:58.820
So I tried to minimize the padding as small as I could.

37:58.820 --> 38:00.820
Back to the other one.

38:00.820 --> 38:02.820
See, it's just not that bad.

38:02.820 --> 38:05.820
We had an integer as small as small integer and then an integer.

38:05.820 --> 38:06.820
So not so bad.

38:06.820 --> 38:11.820
So it shouldn't be of huge difference.

38:11.820 --> 38:15.820
So this is what happened.

38:15.820 --> 38:20.820
See the new on the left, the schema name.

38:20.820 --> 38:24.820
The schema new are where I created the new ones.

38:24.820 --> 38:27.820
The schema public are the old things.

38:27.820 --> 38:35.820
If you see the total size of the orderline one is 3,000 megabytes or three gigabytes, 3.8, to be more fair.

38:36.820 --> 38:40.820
The old one was 4.1.

38:40.820 --> 38:46.820
It's about like 15% increase, right?

38:46.820 --> 38:53.820
And also interesting, look at the index size.

38:53.820 --> 38:58.820
We also have improvement on the index size and they have exactly the same indexes.

38:58.820 --> 38:59.820
Let's go back.

38:59.820 --> 39:05.820
See the index, the primary key here, we have the column one, two, three, four, and then another two columns for the other index.

39:05.820 --> 39:07.820
And the same.

39:07.820 --> 39:09.820
Exactly the same indexes.

39:09.820 --> 39:10.820
Don't change the name.

39:10.820 --> 39:13.820
Exactly the same color, exactly the same order of the columns.

39:13.820 --> 39:16.820
I didn't even play on the index for the optimization.

39:16.820 --> 39:17.820
I just left them there.

39:17.820 --> 39:19.820
I just did for the table, right?

39:19.820 --> 39:21.820
And this is what happens.

39:21.820 --> 39:32.820
And I'm highlighting here for one of them how much space is saved.

39:32.820 --> 39:34.820
One table.

39:34.820 --> 39:37.820
And a very small table, right?

39:37.820 --> 39:40.820
So, but how does it play with performance?

39:40.820 --> 39:44.820
Because, okay, one thing is I can save any space on this and performance.

39:44.820 --> 39:47.820
So obviously it does a TPCC type test, right?

39:47.820 --> 39:49.820
Try it to use as well.

39:49.820 --> 40:02.820
The answer is I got an average 8.4 performance improvement.

40:02.820 --> 40:11.820
About around, on average, for this example, this load, 19% disk space production.

40:11.820 --> 40:18.820
I'm cutting down at 19% of my disk space views on cloud providers.

40:18.820 --> 40:23.820
I think that's why they never approve my talks on their conferences.

40:23.820 --> 40:28.820
Now thinking about that, I think it makes sense, right?

40:28.820 --> 40:36.820
The latency, I reduced it about 15% latency improvement.

40:36.820 --> 40:39.820
Just shuffling the columns around.

40:39.820 --> 40:42.820
The application does not even need to do.

40:42.820 --> 40:53.820
And I'll tell you, when I created those tables, because the SIS bench has its fixed structure on those, the insert and updates,

40:53.820 --> 40:55.820
I had to trick the SIS bench.

40:55.820 --> 41:07.820
I had to create views and then rows inside of Postgres to make those views insertable, updateable and deleteable.

41:07.820 --> 41:13.820
So on top of this, I still have latency on the database I had to put because of the tooling.

41:13.820 --> 41:18.820
And even though I got almost 9% improvement.

41:18.820 --> 41:24.820
Can I just clarify, I'm confused, your average write and read around 8.2, 8.5.

41:24.820 --> 41:28.820
So I thought the latency would be around between those two numbers.

41:28.820 --> 41:31.820
But obviously you mean latency in a different sense, or you're measuring?

41:31.820 --> 41:37.820
Latency on the application side, because latency is not about how fast or as low you get the data,

41:37.820 --> 41:40.820
but also at the end how fast or as low you process the data.

41:40.820 --> 41:43.820
So you have more data in smaller blocks.

41:43.820 --> 41:47.820
So on the application side, latency is going to be a lot better.

41:47.820 --> 41:51.820
So I'm also improving the application for free.

41:51.820 --> 42:03.820
You have some kind of improvement, but what are the things you need to do to reorganize the columns?

42:03.820 --> 42:09.820
So your question is what happens if I need to go to the table and reorganize the columns, right?

42:09.820 --> 42:14.820
So, yeah, if you already have an application, you may need to do the trick that I did here.

42:14.820 --> 42:20.820
Right, first create the new table, so you're going to double that for a certain moment type.

42:20.820 --> 42:27.820
You create the new tables, and then you create views and you create rules inside of the database.

42:27.820 --> 42:36.820
So where your application will insert, update, and delete, obviously select as well on those views until you change.

42:36.820 --> 42:45.820
Or if you use a tool like, if I'm not mistaken, PG...

42:45.820 --> 42:47.820
I forgot the name of the tool, you know.

42:47.820 --> 42:57.820
Actually, the guy had a really nice talk on Friday on PG Day that you can do online data change for your thing.

42:57.820 --> 43:00.820
So your application does not even need to know that you're changing the database.

43:00.820 --> 43:03.820
So you have a few different options.

43:03.820 --> 43:06.820
What's the name of the tool? PG Online Scammer Change?

43:06.820 --> 43:09.820
That's from ISQL.

43:09.820 --> 43:15.820
Oh, PG, okay, yeah. PG Online Scammer Change, that's true. Thank you.

43:15.820 --> 43:22.820
Why was there is a reason for the project not doing the organization for you?

43:22.820 --> 43:26.820
The question is, is there is a reason that the PostgreSQL does not do the organization?

43:26.820 --> 43:36.820
Yes, because even though we can have really smart things on there, the database doesn't know the full story.

43:36.820 --> 43:40.820
So it may try to reorganize the data and mess up the things on the way.

43:40.820 --> 43:43.820
So it's always safer for the DBA to do those things.

43:43.820 --> 43:48.820
And at the end of the day, the database should keep the data and retrieve the data for you.

43:48.820 --> 43:52.820
So you need to know how the data plays inside as well.

43:52.820 --> 44:04.820
Yeah, I wonder if it's important which columns can be known and how often these rows actually contain those columns?

44:04.820 --> 44:11.820
So the question is, is it important for the column to be known or not and how often it plays?

44:11.820 --> 44:17.820
So it is important, not for the column itself, but the following ones.

44:17.820 --> 44:22.820
Remember, PostgreSQL doesn't store the know, right? It stores on the bitmap.

44:22.820 --> 44:28.820
So then will be a pointer there and nothing on that place, right?

44:28.820 --> 44:38.820
So yeah, it does play a role. I haven't tested that to see how much impact that would be, especially because I just used the tooling, right?

44:38.820 --> 44:42.820
So but yeah, it definitely should have some impact, for sure.

44:42.820 --> 44:47.820
Would it be fair to say that this benchmark measures bit tree more than anything?

44:47.820 --> 44:54.820
And let's say that we're not prioritizing latency, but rather we're doing like the same sort of dense joints and we want more bandwidth.

44:54.820 --> 45:01.820
Is it true that if there's something like grid, right, we're going to be able to get as much bigger improvement in bandwidth points?

45:01.820 --> 45:05.820
Can you rephrase that? I don't think I understood the question.

45:05.820 --> 45:12.820
So for this benchmark, it seems like it measures bitmap scan.

45:12.820 --> 45:15.820
So this is like a bit tree benchmark.

45:15.820 --> 45:21.820
And let's say that we're not after latency reduction, but rather we want to get more bandwidth.

45:21.820 --> 45:26.820
Let's say in a case where we would have distinct or time-based joints.

45:26.820 --> 45:34.820
Could we use something like grid to effectively get a much bigger set in bandwidth if it's going to be dense enough?

45:34.820 --> 45:43.820
If I understood it correctly, the question is it's fair to say that the benchmark mostly tested the bit tree performance, right?

45:43.820 --> 45:48.820
So not really the density, if more density of data that would improve.

45:48.820 --> 45:55.820
Well, actually, as I explained, post-crisis, especially for insertion and things, we're going to have on the heap file.

45:55.820 --> 46:05.820
So we often do not do, at least in this type of benchmark, not do with the bit trees and performance would be really marginal,

46:05.820 --> 46:08.820
especially if you saw we don't have many indexes.

46:08.820 --> 46:14.820
It's like most of the tables here are the primary key, and I feel them, they're only one index.

46:14.820 --> 46:21.820
And the only bit tree structure on post-crisis for this example are the indexes, because the table itself, they are not.

46:21.820 --> 46:23.820
They're just heap files, right?

46:23.820 --> 46:33.820
So in that sense, I would not fully agree, but definitely density would play, like if you could have more dense tables.

46:33.820 --> 46:39.820
And the example that I gave for the authentication, so what do you do when you change?

46:39.820 --> 46:42.820
You just put a few columns there for the authentication.

46:42.820 --> 46:45.820
You are increasing the density of the information you have on that table.

46:45.820 --> 46:49.820
So on the same block instead of having three or three, that will have a thousand, right?

46:49.820 --> 46:58.820
It's a lot more dense, so that per se makes it a lot faster, especially if you think about that, time is also wasted on the network, as you mentioned.

46:58.820 --> 47:05.820
And network is not only the bandwidth of the network inside of the computer itself.

47:05.820 --> 47:10.820
Well, we have five minutes. Let's rush to the end.

47:10.820 --> 47:13.820
So this is a summary.

47:13.820 --> 47:15.820
So post-crisis stories.

47:15.820 --> 47:23.820
And actually, if you, now wait for the photos, almost, okay?

47:23.820 --> 47:27.820
So if you want to take something, this is the summary.

47:27.820 --> 47:33.820
Every data type has its own alignment on post-crisis and can cause padding.

47:33.820 --> 47:36.820
And it's really, really dangerous.

47:36.820 --> 47:45.820
So we can get really, really mass with all data, especially because most of the tables in our application has like 20, 20 something columns.

47:45.820 --> 47:49.820
And we are not careful on how we put them.

47:49.820 --> 47:52.820
Yeah, we can mess up.

47:52.820 --> 47:55.820
Questions? I think we have two minutes.

47:55.820 --> 47:56.820
Possibly, yeah.

47:56.820 --> 47:58.820
Yeah, possibly.

47:58.820 --> 48:03.820
When you have fields with varying size, like the text field, what are the problems?

48:03.820 --> 48:06.820
The text, the VARCA, right?

48:06.820 --> 48:18.820
So they do not play well with padding because as the variable, so the database doesn't know how to optimize them on that way.

48:18.820 --> 48:22.820
So it highly depends on how your information is put.

48:22.820 --> 48:25.820
And that's usually best to let them to the end.

48:34.820 --> 48:39.820
Sorry, can you say that again?

48:39.820 --> 48:42.820
Okay.

48:42.820 --> 48:46.820
Uh-huh.

48:46.820 --> 48:55.820
Yeah, the question is, if I test it on larger database because smaller database might just fit fully in memory.

48:55.820 --> 48:57.820
So yes, I did.

48:57.820 --> 49:06.820
And what you need to realize is all the data, all the padding that we have here goes to memory and all the pad that goes to memory goes to network.

49:06.820 --> 49:09.820
So in all the padding that goes to network goes to your application.

49:09.820 --> 49:17.820
So you're wasting space in your hard drive, in your memory, in your CPU cache, in your network and your application.

49:17.820 --> 49:19.820
What are the numbers?

49:19.820 --> 49:22.820
Well, it highly depends on application to application.

49:22.820 --> 49:24.820
So I would say that's empirical.

49:24.820 --> 49:31.820
There's no science on that one that you can get up to 30% performance improvements.

49:31.820 --> 49:33.820
That's all.

49:33.820 --> 49:35.820
If you have more questions, thank you guys.

49:35.820 --> 49:37.820
Here is my link again.

49:37.820 --> 49:39.820
Thank you.

