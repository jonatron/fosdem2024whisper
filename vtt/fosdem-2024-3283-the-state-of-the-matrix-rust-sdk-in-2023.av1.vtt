WEBVTT

00:00.000 --> 00:11.240
Hi, everyone. So today I'm going to talk about the state of the rest SDK in 2023. So all

00:11.240 --> 00:16.400
the things that we've accomplished as of last year and some of our future plans as well.

00:16.400 --> 00:22.320
So first of all, who am I and how did I get into the rest SDK? Well, I'm Benjamin BouviÃ©.

00:22.320 --> 00:27.800
I'm a software engineer in the Rust team at Element. Prior to that, I worked in a game

00:27.800 --> 00:33.600
engine, well, a game dev company on a game engine that was written in Rust and WebAssembly.

00:33.600 --> 00:38.840
And prior to that, I was a compiler engineer in the SpiderMonkey team, which is the JavaScript

00:38.840 --> 00:44.480
engine, powering Firefox, where I did Rust and WebAssembly. So you can sense that there is a

00:44.480 --> 00:52.240
common theme here. And back in the days at Mozilla, we were using IRC. And so I wrote a few

00:52.240 --> 00:58.680
bots that were just pulling out jokes from the internet and posting them on the channels. And

00:58.680 --> 01:04.360
then at some point, we decided to use this new cool thing called Matrix. And so I rewrote my

01:04.360 --> 01:10.920
bots so that they could also run on the Matrix using JavaScript at the time, because when you

01:10.920 --> 01:16.440
work at Mozilla, you have to bet on JavaScript all the time. And then a few years later, I decided to

01:16.480 --> 01:23.040
rewrite it in Rust because I like Rust. And I made this framework system called Trinity that would

01:23.040 --> 01:29.160
use Rust for interacting with the Matrix system. And then you can actually write the bot

01:29.160 --> 01:34.600
comments themselves using WebAssembly, which is pretty sweet. And I experimented to

01:34.600 --> 01:40.320
neutralize it in production. It's mostly a fun project. And that's how I started to use the

01:40.320 --> 01:47.440
Rust SDK. So what is the Rust SDK? Very good question. So it's a Rust library implementing the

01:47.440 --> 01:54.680
client server API to allow you to implement clients easily if you want to use Rust in your

01:54.680 --> 02:00.600
project. So the code is available on GitHub under the FHT2 license. And it does all the things

02:00.600 --> 02:05.160
that you would expect from a Matrix client. Logging in, logging out, sending messages,

02:05.520 --> 02:11.480
receiving messages. But I guess the most interesting thing is that you get into an encryption for

02:11.480 --> 02:16.960
free. And you don't have to worry about the, excuse my French, gory details in the sense that you

02:16.960 --> 02:22.000
don't have to learn about Olm, Meg Olm, like sending, uploading your keys, claiming keys,

02:22.000 --> 02:28.640
querying keys and all of that stuff, which is very fine. And that we handle for you. Some

02:28.680 --> 02:36.000
history for this Rust SDK. So there was in the past one project that was called Ruma for Rust

02:36.000 --> 02:45.000
Matrix, which modeled all the events that are happening in a Matrix room timeline. And also all

02:45.000 --> 02:50.440
the requests and responses to the endpoints. And the goal at the time, I think, was to try to create

02:50.440 --> 02:56.120
a home server in Rust. Eventually that didn't happen for the Ruma project itself. But people

02:56.160 --> 03:00.920
realized that it was a good idea to actually model all those events, request and responses, and

03:00.920 --> 03:07.800
reuse them across other projects. And there was another Rust home server that started to be

03:07.800 --> 03:17.280
written and that is conduit. And like in another timeline in the world, so there was Damir, who is

03:17.320 --> 03:26.240
now the team leader at the Rust SDK team at Element. He was doing Rust on his part like free

03:26.240 --> 03:33.840
time. And he maintained a small plugin so that you can use WeChat with Matrix. And that was written

03:33.840 --> 03:40.240
in Python. And so as he was trying to learn Rust, he decided to rewrite it in Rust. And the thing

03:40.320 --> 03:47.120
is, well, he did so. He searched for library written in Rust to do that. And there was none. So he

03:47.120 --> 03:52.520
decided to start one. And that's how the Matrix Rust SDK started. And from the outset, it started

03:52.520 --> 03:58.920
to use Ruma because it made sense. And that allowed to reuse massive amounts of code, which was very

03:58.920 --> 04:05.120
nice. And Damir, being a crypto engineer, he also implemented all the crypto stack, which was very

04:05.120 --> 04:12.480
sweet. And then that was first in the Matrix Rust SDK. And all of that code was pulled out and

04:12.480 --> 04:18.680
extracted as an independent library called Vodose Mac, which apparently in question means

04:18.720 --> 04:26.360
amphibian. And it's like a big pun across languages like Olm, Megolm, and like all of these just

04:26.360 --> 04:34.680
refers to amphibians, it seems. And yeah, so that's how it goes. All right. So why Rust, you would

04:34.720 --> 04:42.920
ask, well, this is my minute for the Rust evangelizing taskforce. So I mean, you're probably convinced

04:42.920 --> 04:48.680
if you're here already, but it's like at the same time high level and super fast. It allows you to

04:48.680 --> 04:55.520
write code in a very fast fashion without having to worry about lots of low level details and

04:55.520 --> 05:00.920
issues. It is secure and memory safe, which is very nice for a library because you want to have

05:00.960 --> 05:07.480
something very robust. It has an amazing tooling and ecosystem, like all the packages, the crates that

05:07.480 --> 05:13.760
are published on craze.io give you all the things that you want to have. And like the cargo, the

05:14.040 --> 05:18.720
tool that does it all is just wonderful. You can run tests and, you know, the documentation and all

05:18.720 --> 05:23.720
of that. You just want to also very important for the rest of this talk. It is compatible with

05:24.080 --> 05:30.280
foreign function interfaces. So you can call into other native languages that speak the CABI. So

05:30.320 --> 05:35.960
it's quite important to see. And one of the things that is maybe a bit undervalued in the Rust

05:35.960 --> 05:42.800
community is that it's actually also in trying to empower you to write a multithreaded code without

05:43.040 --> 05:47.920
you having to know too much about it, trying to make it very accessible. And it's a value that was in

05:47.920 --> 05:53.240
the community first, and you can find it in all the places. It transpires in translates to all the

05:53.520 --> 05:59.200
places in Rust from the error messages that just hold your hands and try to explain you what you did

05:59.240 --> 06:05.440
wrong and try to tell you how to fix the problem that you run into, et cetera, et cetera. So it's very

06:05.440 --> 06:14.200
sweet to use. And yeah, being a former C++ programmer, so there was this notice in one of the

06:14.200 --> 06:20.880
offices where I worked before that read, you must be this tall to write multithreaded code. And it's

06:20.960 --> 06:28.120
apparently at three meters high on the wall. So this is something of the past. Like with Rust, you

06:28.160 --> 06:32.520
can just be fearless when you're writing multithreaded code because there is this thing called the

06:32.520 --> 06:40.120
ownership model. And that makes it really easy to also model concurrent implementation of anything

06:40.160 --> 06:49.640
really. So that's really, really nice. So why the Rust SDK? Well, there was this story where we had

06:49.720 --> 06:55.080
three apps, basically Android apps, the iOS apps and the web version that is also powering the desktop

06:55.120 --> 07:02.120
version. And they all were using a different SDK and a different crypto stack. So that means that if

07:02.120 --> 07:06.560
you are serious about your security, and you want to, for instance, audit your cryptography, now you

07:06.560 --> 07:11.160
have to do it in three places and make sure that every single implementation actually does what it's

07:11.160 --> 07:16.960
supposed to do, which is a bit of a nightmare. And now you have also per platform issues. You can have

07:16.960 --> 07:21.680
a bug in one stack, and then you need to check whether the other stacks also have it, et cetera,

07:21.720 --> 07:29.400
et cetera. Well, now we are saying, no, we have only a single stack for the element apps, and it's

07:29.400 --> 07:35.920
written in Rust. In particular, it's a single crypto stack. You have very high test coverage. As I'm

07:35.920 --> 07:44.560
speaking, it's like more than 83% of test coverage in the Rust SDK. The VodoZemac library, the

07:44.600 --> 07:49.800
crypto stack is being first as well, which is very important in terms of finding issues, security

07:49.880 --> 07:54.280
issues. So that means it's a single place where you can add features, you can code once, where you use

07:54.280 --> 08:02.240
everywhere the old Java Dream that everybody knows and loves about. All right, who's using it? So there

08:02.240 --> 08:08.760
is Fractal, the GTK-based Matrix client, which is using it. There is IMB, terminal UI client, if you

08:08.760 --> 08:14.880
like, Veeam bindings and all of that. There's the new generation of element apps. The element X apps

08:15.200 --> 08:21.320
are only using that, which is pretty sweet. And also the crypto stack, as it could be extracted, and it's

08:21.320 --> 08:28.400
also like there are specific bindings just for the crypto stack. And so it could be used in the current

08:28.400 --> 08:35.560
generation of element apps. And it's another codename element R. And I guess that you can imagine what

08:35.560 --> 08:44.800
the R stands for at this point. Rust. All right. So what happened since the last first time? Well,

08:45.000 --> 08:51.960
the previous release of the Rust SDK was in October 22. So we made a new release this year. Yay! At the

08:51.960 --> 09:02.400
beginning of this month. Thank you. So it's still not 1.0, still quite experimental. We're breaking

09:02.400 --> 09:08.320
APIs all the time, but trying to do a better job at writing, changing logs and all of that. And we'll

09:08.360 --> 09:15.520
see how it goes. So new features. So you probably heard about sliding sync last year. And this year,

09:15.560 --> 09:22.320
the new kind of sync synchronization that makes it so that logging into a new device and retrieving

09:22.320 --> 09:30.120
events is always instant, even if you haven't opened the app for months or years. So we entirely

09:30.400 --> 09:37.040
support that. There is the basic feature that you can subscribe to specific rooms and list of rooms

09:37.240 --> 09:42.480
of which we get a sliding window that is computed by the server. But we're getting rid of that, as

09:42.520 --> 09:48.080
Matthew said. And it also implements a modular design in the sense that you have opt-in extensions for

09:48.080 --> 09:53.280
read receipts and typing notices and many other things. And all of that is supported in the SDK. As you

09:53.280 --> 09:59.880
can see on the right, it's quite verbose because, well, it's a very versatile and general like API to

09:59.880 --> 10:05.280
give you the most control so that you can build higher level primitives on top of that. We'll get back

10:05.360 --> 10:12.400
to that. And it's vitrugated behind the experimental sliding sync cargo feature. And you can, we basically

10:12.400 --> 10:20.120
use it in production in element X. So it's quite stable, actually. There's also support for OIDC,

10:20.120 --> 10:25.920
so OpenID Connect. It's a cross stack effort moving from the custom metrics authentication to

10:25.920 --> 10:32.960
OpenID Connect. If you have a metrics authentication service running, so it's another service running

10:32.960 --> 10:40.440
on your server alongside the Synapse or your own server, it can act as an actual OIDC provider or

10:40.440 --> 10:44.560
specialized proxy to an upstream provider. So if you have a GitLab instance, for instance, you can

10:45.000 --> 10:50.920
connect it to the metrics authentication system and then have your GitLab users log into matrix for

10:50.920 --> 10:55.920
free, like that. And so that's the server side part. It's also written in REST, which is pretty

10:55.920 --> 11:01.720
sweet because that means that the request and responses can be actually reused in the client, the

11:02.480 --> 11:10.360
REST metrics SDK. And the SDK implements all of that already. And we are also using it in production

11:10.360 --> 11:17.480
in element X. So it gives you all the things that you would like to do with OIDC, create, reload,

11:17.480 --> 11:23.160
metadata, register on your OIDC client, do the login flow in all the steps and all of that. And

11:23.160 --> 11:30.840
it's also behind the cargo feature at this point. Among the big news, we have a new default storage

11:30.880 --> 11:38.240
backend. So the storage backend are implemented using traits, which are REST for interfaces. The

11:38.240 --> 11:44.720
previous defaults when you wanted to persist things on disk was sled. And now it's been replaced to

11:44.720 --> 11:52.680
SQLite because, well, pretty much everybody knows about SQL. And it's also much faster for our

11:52.680 --> 11:58.520
use case. We still have an in memory backend if you don't care about losing states and an index DB

11:58.640 --> 12:07.120
backend that is used when you're compiling for the web to WebAssembly. Some new cryptography

12:07.120 --> 12:11.960
features. So there is this new thing called secret storage. And it's mostly an implementation

12:11.960 --> 12:18.600
detail, but it gives you an encrypted key valley store that is backed in the user account data. And

12:18.600 --> 12:24.320
where you can put any information that you would like to share across all your devices in a secure

12:24.320 --> 12:28.440
way. Like the server doesn't know about this information. It cannot peek into it and know what

12:28.880 --> 12:35.760
is in there because it's also encrypted. On top of that, we implemented key backup and restoration. So

12:35.760 --> 12:41.640
that means that when you have a new device, well, when you're using elementics, for instance, it

12:41.640 --> 12:49.400
will store all the room keys that are used for decrypting room messages in encrypted rooms in the

12:49.400 --> 12:54.320
secret storage. And then another device can restore them so that you can actually see the

12:54.400 --> 13:00.640
history of events before you joined with that new device. Also, in addition to that, we made it so

13:00.640 --> 13:07.360
that the cross-signing automatically happens and you don't have to worry about this at all. That's

13:07.360 --> 13:14.080
what's used to verify your own devices and other people's devices. And it's also like some of the

13:14.080 --> 13:23.520
private keys are stored in that secret storage as well. And speaking of high-level primitives, so

13:23.560 --> 13:30.600
we made a new crate, new package called the Matrix SDK UI. It is highly experimental and also highly

13:30.600 --> 13:37.040
opinionated in the sense that we're enabling a few cargo features by default. And we are trying to

13:37.040 --> 13:43.680
make it so that we implement the best practices in terms of user experience and performance. And

13:43.680 --> 13:48.600
it's also as robust and tested as the rest of the SDK, which is very sweet. And we use sliding sync

13:48.640 --> 13:54.440
as a foundation for all these new high-level features. One of these features is the room list

13:54.440 --> 14:01.120
service, which, as its name suggests, gives you a list of the rooms. Yes, it does it so in a way

14:01.120 --> 14:09.880
that we try to make it to show something to the user as soon as possible. So that's how you feel

14:09.880 --> 14:16.800
that the app is kind of instant when you open the app, because it will try to load just one event

14:16.880 --> 14:22.400
for all the rooms you were in, or for no, a few rooms you were in. So you have something to display.

14:22.400 --> 14:29.280
And then in the background, once that's done, it will try to fetch more events. And also you can

14:29.280 --> 14:34.280
configure it to say, this is a set of visible rooms in my apps. So because when you have an app,

14:34.280 --> 14:40.080
you cannot show like a thousand rooms, you will only show a subset, right? So you can configure it

14:40.080 --> 14:46.200
to say, this is the ones that are actually rendered on the screen. And those are prioritized so that

14:46.240 --> 14:54.920
you get more events for these rooms. Another thing we added was the encryption service. So it's

14:54.920 --> 14:59.120
basically a sliding thing that is just running encryption on the side, and it gives you access

14:59.120 --> 15:04.320
to more concurrency with the other one. So think of it this way, the room list service, the one I

15:04.320 --> 15:09.200
just talked about, when you're scrolling on a mobile app, it will change the list of rooms that are

15:09.200 --> 15:14.640
shown on the screen, right? So that now means that it's sending new requests to ask for things. And

15:15.240 --> 15:20.000
if we did the encryption in the same request, but it's getting a bit technical, but that would

15:20.000 --> 15:25.240
mean that we would need to abort those requests and delay encryption. So now we have basically more

15:25.240 --> 15:31.720
concurrency and more performance. And we can do the encryption task in the background while you're

15:31.720 --> 15:37.520
still scrolling on the room list using this encryption service. And we also have a notification

15:37.520 --> 15:43.720
service. So that's very specialized client that just handles push notifications. So if you're

15:43.760 --> 15:48.720
given an event and a room identifier, we want to retrieve the event and maybe a bit of context,

15:48.720 --> 15:57.320
like what's your name, what's the name of the person who sent the message to you and all of that.

15:57.320 --> 16:04.160
It's also using a sliding thing for that. And it makes use of the encryption service because on

16:04.160 --> 16:09.040
an encrypted room, of course, you would get a push notification for an encrypted event and the

16:09.080 --> 16:14.640
server cannot know if it's a meaningful event, right? Maybe it's just a reaction, putting a

16:14.640 --> 16:21.440
thumbs up on one of your messages. So we decrypt the event in the client itself and then we decide

16:21.440 --> 16:30.560
whether it's worth sharing as a notification. The one fun thing, if you can call it fun, is on

16:30.560 --> 16:38.200
iOS, if you want to modify the notification in case it's encrypted, it's running a separate

16:38.280 --> 16:44.920
process. And that makes our life very hard because even if you're just decrypting data, the state of

16:44.920 --> 16:52.520
the cryptography keys is mutably changed, right? So now we have multiple states that is global

16:52.520 --> 16:58.480
across two processes that are sharing the same database. So we had to be a bit creative to solve

16:58.480 --> 17:04.360
that issue and we are basically enabling the writer head log in SQLite and using some data in

17:04.400 --> 17:10.960
the database to indicate who's the process that currently tries to read and write to the database.

17:10.960 --> 17:19.600
So basically implementing a text like that. All right. And since we added those two services,

17:19.600 --> 17:24.280
the encryption service and the room service, we wanted to make it very simple to just fire

17:24.280 --> 17:30.840
synchronization and forget about it. So we made some nice high-level service that just wraps

17:31.440 --> 17:37.760
the other two and you can just build it and start it and it will do all those things for you and

17:37.760 --> 17:41.880
implement all the best practices and you don't have to worry about any of this. And then you can

17:41.880 --> 17:47.600
just take listeners on that service and get information that is meaningful to do when we're

17:47.600 --> 17:55.560
rendering for a client. Now that we have a list of rooms and decrypted events, what do we do? Well,

17:55.600 --> 18:00.880
we want to display them and we have an API for that called the Timeline API. It's basically a

18:00.880 --> 18:06.920
room view MVC, so model view components on steroids. The thing is that in the matrix protocol,

18:06.920 --> 18:13.200
events are actually like atomic. It's an app and only database. So let's say you have a thumbs up

18:13.200 --> 18:20.240
reaction to a message that is a response to something else that would be two events, like the

18:20.280 --> 18:25.280
reaction itself and the message itself. So the timeline will aggregate all those different

18:25.280 --> 18:33.040
events into a single timeline item that is much more what you want to render as a client on the

18:33.040 --> 18:38.920
screen. So it makes it much simpler to render a single timeline like that. And it does a lot of

18:38.920 --> 18:44.120
things for you too. It can enter local echoes. So basically when you're sending a message to a

18:44.160 --> 18:52.440
room, you want to show it even before the server has returned that it received it. So it will do

18:52.440 --> 18:57.280
that and then reconcile the response from the server with the local state and all of that. So

18:57.280 --> 19:03.000
it's pretty sweet. And it's all observable, very reactive. So that's nice. You just get, like,

19:03.000 --> 19:09.600
as a user of that API, you get notification that one item has been added or removed or updated.

19:10.040 --> 19:19.960
And you can just, like, react according to that. So how is this all used in ElementX? We're using a

19:19.960 --> 19:27.920
Mozilla project called Unify, Unify FFI. It will automatically create bindings for you for calling

19:27.920 --> 19:34.520
interest from other languages. So at this point, we generate bindings for Swift on iOS and Kotlin

19:34.600 --> 19:41.080
and Android. It can also generate bindings for other languages. And we use that for Go, for testing

19:41.080 --> 19:47.120
purposes, I think. It requires a bit of integration with the foreign languages runtime. And over the

19:47.120 --> 19:52.840
years, we've contributed a few PRs to this project. So we made it so that you can just use

19:52.840 --> 20:01.600
procedural macros for exporting your types and your input blocks to other languages. And we also

20:01.680 --> 20:07.760
added this year's support for async code. So you don't have to block when calling into an async

20:07.760 --> 20:13.840
function on the Rust side. It will just look as an async function on the Kotlin or Swift side. And

20:13.840 --> 20:18.640
you have actual concurrency and background processing happening, which is pretty sweet for

20:18.640 --> 20:25.600
performance. And reactive programming in Rust. How do we do it? Well, the principle of reactive

20:25.600 --> 20:31.280
programming is you have some data and you want to make it observable so people can subscribe to it.

20:31.360 --> 20:36.320
And then they will get notifications. And I mentioned the Timeline API that will notify you

20:36.320 --> 20:40.320
when there is a new Timeline item that has been added, removed, et cetera. So we're using

20:41.120 --> 20:47.200
crates that we created ourselves, IBOL. And there's also an extension that is

20:48.320 --> 20:53.520
div-based for collections because when you have a vector with a thousand entries in it,

20:53.520 --> 20:58.480
you don't want to say, oh, now there's a new thing that has been pushed into the vector.

20:58.560 --> 21:04.560
I hear all the 1,001 entries for that vector. No, you just want to hear that

21:05.440 --> 21:12.240
there's a new entry and that's its position, right? It also has some extra querying facilities.

21:12.240 --> 21:19.360
So you can batch all these updates, div updates. So you don't have to cross the FFI language

21:19.360 --> 21:24.000
boundary too often. That has an inherent cost that we want to avoid, some overhead that we want to

21:24.000 --> 21:30.960
avoid. And for your batch transaction, well, for your batch to be quite precise, you need to have

21:30.960 --> 21:34.400
also transactions to say, this is the beginning of the batch, this is the end of the batch.

21:35.520 --> 21:43.280
And also you can do some filtering on these stream of events, limiting, sorting. So it's kind of

21:43.840 --> 21:49.520
mapping to things that you would do on SQL in general. It's pretty sweet and that's what we're

21:49.520 --> 21:56.240
using, for instance, to filter the rooms in the room list immediately on the client side.

21:58.320 --> 22:04.880
All right. So some of the future work that we're going to do, well, I intentionally remain a bit

22:04.880 --> 22:09.440
vague here, but we're going to eventually support all the major features a matrix client would expect.

22:11.120 --> 22:18.000
We are already working on Scrantum cryptography. And as of today, I think there has been a PR

22:18.400 --> 22:24.080
against Voters and Mac to have something that is compatible with Libsignal and with what they do. So

22:24.080 --> 22:29.520
that's pretty exciting. And there is a general theme of doing more things client side. When you have

22:30.080 --> 22:35.360
end to end encryption, your server kind of becomes dumb sometimes because it cannot peak into the

22:35.360 --> 22:42.320
encrypted event. And so you have to resolve a lot of things on the client side. If you get a

22:42.960 --> 22:47.440
new event in a room, does that trigger a notification for an encrypted room? Well,

22:47.440 --> 22:51.600
you have to push a notification and it's the clients that will decide whether or not it

22:51.600 --> 22:57.680
resolves into an actual notification. And even for sorting the room list, you have to do it

22:57.680 --> 23:02.320
client side because if there is some room activity, you want to sort by room activity, just show me

23:02.320 --> 23:08.480
the room that have some activity. Well, it's the same thing. If the event was encrypted, you don't

23:08.960 --> 23:13.280
know if it was just a thumbs up reaction. Maybe that doesn't justify putting the room at the top.

23:14.080 --> 23:20.000
If it was something meaningful like an actual message. So that means that this task has to be

23:20.000 --> 23:25.360
done on the client now. And yeah, we're also computing the other badges client side in the

23:25.360 --> 23:32.720
rest SDK. So we are trying to be very careful to not get into static notifications situations

23:32.720 --> 23:38.720
because it's a pain for everyone, us included. And yeah, that's pretty much it. All right.

23:39.440 --> 23:44.720
Just a few things. Well, first to all the contributors of the rest SDK special shout out

23:44.720 --> 23:52.320
to Kevin Komei from the fractal community. It's done like a bunch of work in the rest SDK,

23:52.320 --> 23:59.280
including most of the support for OIDC on the client side, which was MaceFPR. And if you want

23:59.280 --> 24:05.600
to be on this slide next year, you can contribute to we have a few issues that are tagged as good

24:05.600 --> 24:12.160
first issues or help pointed if you want. And I would like to take this opportunity also to

24:12.160 --> 24:17.760
thank elements for donating all of my work to the matrix organization. You can also be a supporter

24:17.760 --> 24:23.840
of matrix if you want by following one of these two links. Thank you for listening.

24:24.480 --> 24:27.280
And I would be happy to answer any questions if you have any.

24:36.640 --> 24:39.840
To the internet asking why have you moved away from sled?

24:41.120 --> 24:47.200
Why have we moved away from sled? That's a good question. So I think in terms of performance,

24:47.840 --> 24:54.400
so slay this, if I recall correctly, I wasn't there when that happened. So it's kind of hard to

24:54.400 --> 25:00.000
answer this precisely, but I think that it's a key value store embedded key value store. And

25:00.000 --> 25:09.840
the performance was not great, especially on mobile devices. And we just figured that using

25:09.840 --> 25:15.280
SQLite that has been like performance tested and improved and tuned over the years was

25:16.000 --> 25:23.120
a right thing to do. And also the way you structure your data using a SQL database is quite

25:23.120 --> 25:28.000
different from the way you would structure it with a key value store. So it's just like

25:28.720 --> 25:33.920
slightly easier to perform requests when you have a SQL database because you know all of that.

25:36.400 --> 25:44.800
Yeah. Any other question? The internet also asks how is your developer experience when using

25:44.800 --> 25:52.320
UniFi, UniFFI in general? Are there any hard edges? That's a good question. So there's, oh yes,

25:52.320 --> 26:01.440
so when using UniFi across, for calling rest across other languages, have there been hard edges?

26:01.440 --> 26:08.640
Yes. It's been a few cases where we have a memory leak that is identified. Well, Kotlin uses the

26:08.640 --> 26:18.080
GVM and GVM as a garbage collector. And so we accidentally, and when I say we, I think it's

26:18.080 --> 26:25.840
like the UniFi group in general, introduced some leaks by having the equivalent of premises or

26:25.840 --> 26:33.520
futures leak sometimes. So that was a problem, but usually it's, I would say it's 90% of the time

26:33.520 --> 26:39.280
it's stable. And the 10% of the time where there is an issue, it's high priority for us because

26:39.280 --> 26:46.080
obviously it breaks our apps. So we fix it, we try to fix it as quick as possible and we

26:46.080 --> 26:53.200
contribute back. But most of the time it works fine for Kotlin and Swift. So the support and

26:53.200 --> 27:01.040
stability is also per language, I suppose, since you have to create bindings for each language.

27:01.040 --> 27:08.640
So yeah, I cannot speak for the Python or Go generation on the UniFi side. But usually,

27:08.640 --> 27:15.040
since Mozilla also use UniFi, they have to provide high stability guarantees as well. So they are

27:15.040 --> 27:22.320
pretty reactive and also fixing bugs. So it's working well. Yes.

27:22.640 --> 27:26.000
I was wondering about the startup times.

27:26.400 --> 27:53.920
Yeah, so the question was, what about startup times for the rest of the time? I think there were

27:54.000 --> 28:00.720
two questions. The first one was just starting the SDK itself and then when you're syncing a list

28:00.720 --> 28:07.440
of rooms, do you get instant and response and all of that? And well, it's native code, so you don't

28:07.440 --> 28:14.800
have to boot up an entire VM for the SDK itself. So it's pretty fast. It will restore the state

28:14.800 --> 28:23.120
from the disk. So that can be a slow step. But even like for users who have thousands and thousands

28:23.120 --> 28:31.360
of rooms open and I'm looking at Matthew on the side of the room, our general benchmark runner,

28:32.800 --> 28:39.920
it's pretty fast. And for receiving a room list, we are also tracking these performance of our time.

28:41.440 --> 28:47.120
Pretty much instant. And every time there is an improvement that needs to be done, we'll do it.

28:48.080 --> 28:52.960
Yeah. I mean, we are in sync with the synchronization times where about

28:53.840 --> 29:00.000
between five to 20 minutes, if you are a very heavy weight user of Matrix,

29:00.000 --> 29:05.600
now it's really up to three seconds. So consider that an improvement.

29:10.640 --> 29:12.800
Any other questions? Yes?

29:17.840 --> 29:27.440
What's the state of supporting extensible events in the rest SDK? So I think that's a question for

29:27.440 --> 29:36.000
Ruma. And since we're using Ruma for passing the events, and I'm pretty sure that so the rest type

29:36.000 --> 29:42.080
system is quite extensive in the sense that you can have union types. And for each event that can

29:42.080 --> 29:48.320
be extended, I suppose that you can have there is a variant in that unit tab that says it's a custom

29:48.320 --> 29:53.520
event. If you're referring to a specific MSC, I don't know what it is. And I'm sorry about that.

29:54.240 --> 30:01.520
Was that a custom MSC or? No. No. Okay. Just events in general. So yes, you will end up in

30:01.520 --> 30:07.120
these case where we have, you will match on this union type or the event and it will say,

30:07.120 --> 30:12.400
well, it's something I don't know about. So I'm just ending it over to you and you do something with this.

30:14.640 --> 30:16.640
Yes?

30:37.280 --> 30:40.800
Can we also provide a question for the rest of the SDK?

30:40.800 --> 30:45.440
I'll rephrase this question as are there plans to use the rest SDK for web?

30:46.400 --> 30:52.320
Because it's not used. So right now, as we are speaking, as of last week, people have started,

30:54.320 --> 31:01.440
well, have enabled by default for new logins on Element Web, I think. So that may be the nightly

31:01.440 --> 31:12.160
version using the rest cryptography for Element Web. We have a separate repository for bindings

31:12.160 --> 31:18.160
that are for WebAssembly because there's no meaning in using Unify for that. We can directly compile

31:18.160 --> 31:23.200
the rest to WebAssembly. So no need to have an intermediary in the middle. And I think the

31:23.200 --> 31:29.840
long-term goal is to use the rest SDK everywhere for the Element apps at least. So don't, don't

31:31.520 --> 31:35.440
take my word as granted, but I think that this is going to happen. Yeah.

31:38.400 --> 31:40.400
Any other question? Yes?

31:55.360 --> 32:00.640
That's a very good question. So the question is, is search in scope for the rest SDK and what

32:00.640 --> 32:06.880
kind of features would be out of scope for the rest SDK? So to respond for search, that depends

32:06.880 --> 32:13.120
if you mean room search or message search, full text search. And well, actually it doesn't depend

32:13.120 --> 32:20.800
because the answer for both is yes. We're going to try to take care of that. For full text, we,

32:20.800 --> 32:27.680
there was a previous client made by Element called Hydrogen. That was a web client and that could do

32:27.760 --> 32:33.920
that and had the fancy system to actually index the messages on your client and then share

32:35.360 --> 32:41.120
parts of the index with your other clients devices. So we're probably going to reuse and

32:41.120 --> 32:46.320
reimplement some of that in the rest SDK at some point. Yeah. In terms of what features are out

32:46.320 --> 32:55.520
of scope for the rest SDK, it's kind of hard to tell, but I think that everything that is like

32:56.480 --> 33:03.520
high level UI related like rendering widgets, but not in the sense of widget API, but actually

33:03.520 --> 33:08.160
UI widgets and stuff like that is not something that we want to implement or provide.

33:10.240 --> 33:17.920
And then I think that, well, the MSCs that have proven to be features that have been

33:17.920 --> 33:23.600
proven to be not very useful will probably not be implemented. It's not clear what's not in the

33:23.600 --> 33:31.440
roadmap at this point. Sorry, it's not a very satisfying answer, but yes, question here.

33:54.160 --> 34:10.080
So the question was using the rest SDK can store a lot of data if you're listening to lots of events

34:10.080 --> 34:16.800
and is there any way to limit that amount of data that is stored on this? Well, as I was saying,

34:16.800 --> 34:22.720
the storage is implemented as a trait. So one could always implement a different version of the

34:22.720 --> 34:28.320
Scallot backend and decide to drop items at some point. One thing that we wanted to make

34:28.320 --> 34:34.160
it is the ability to store events locally. And that's connected to the previous question. If you

34:34.160 --> 34:40.240
want to be able to do full text search, well, you have no other choice, but decrypting all the events

34:40.240 --> 34:45.280
and storing them locally, at least in memory for some time to do the indexing. And then the indexes

34:45.280 --> 34:51.200
have to go to the disk. And that means that, yeah, the size of the index can grow a lot.

34:51.760 --> 34:57.040
And so we would probably have to implement some kind of garbage collection and say, well, we kind

34:57.040 --> 35:04.320
of forget about like old data, older than like a month, year or something like that. And we only care

35:04.320 --> 35:16.320
about the most recent data. All right, thank you very much.

