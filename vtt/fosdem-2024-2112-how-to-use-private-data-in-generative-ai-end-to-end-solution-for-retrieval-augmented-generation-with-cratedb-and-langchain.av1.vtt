WEBVTT

00:00.000 --> 00:10.480
in the morning on Sunday. It's nice to see all here, looking very bright and early. So

00:10.480 --> 00:15.920
we shall get straight into it. Let me welcome the first presenter of the day, Maria and

00:15.920 --> 00:26.840
Christian from CrateDB, who are going to be talking about privacy and generative AI.

00:26.840 --> 00:34.400
Thank you. Good morning from our side. Pleasure to open the Dev Room today and thanks for

00:34.400 --> 00:38.880
being here that early on a Sunday morning. We're going to talk about a very interesting

00:38.880 --> 00:44.480
topic, generative AI, how to use your own data and how we can build such applications

00:44.480 --> 00:49.480
also based on open source software. I think everyone is used to open AI and chat GPT,

00:49.480 --> 00:55.560
but you never know what happens with your data in these cases. So very, very brief overview.

00:55.560 --> 01:01.080
This is gen AI. I think everyone in the room played around with it already. Just a very

01:01.080 --> 01:09.200
quick summary of the basics here. You have your source data of any kind of sort of data.

01:09.200 --> 01:16.360
It can be text, it can be code, images, audio, videos. Everything is transformed. We are

01:16.360 --> 01:22.560
encoders, but billions of parameters that we use, a lot of text, a lot of input to train

01:22.560 --> 01:28.400
the so-called foundational models. We as users formulate some prompts against it. We ask

01:28.400 --> 01:34.320
the models some questions. It does its job and it generates the output and a language

01:34.320 --> 01:42.040
model does nothing else than predicting the most likely next token that it should generate.

01:42.040 --> 01:50.880
That's all the magic behind. We see a very, very big potential. When I first tried chat

01:50.880 --> 01:56.960
GPT more than a year ago, it was amazing. It started to write code for me. It starts to generate

01:56.960 --> 02:03.600
articles. I even went to some tools out there, took 30 seconds of my video and all of a sudden I

02:03.600 --> 02:11.400
can be a virtual speaker. Very, very impressive, super fast, but there's also a bot assigned to

02:11.400 --> 02:17.480
it. Obviously, some quality issues. All of you heard of hallucinations. Last week we had the

02:17.520 --> 02:22.680
example of what color is the water. Is it blue or is it really transparent? Depending on your

02:22.680 --> 02:28.400
training data, if you use children's books, the water is obviously blue. If you use the real-world

02:28.400 --> 02:32.200
training data, water should be transparent. Same as snowflakes or not white. They are

02:32.200 --> 02:40.800
transparent technically. Also, a lot of ethical questions, a lot of governance questions. Official

02:40.800 --> 02:46.240
government people talking to deep fakes, not realizing it. Also, a big threat that we have in

02:46.320 --> 02:52.480
the future. We have to be aware of also some environmental impact. The key thing we want to

02:52.480 --> 03:01.200
talk about today is quality and reliability with the importance of current, of accurate, and also

03:01.200 --> 03:06.840
of private data that is not available publicly. Because all of these foundation and models have

03:06.840 --> 03:11.280
been trained on public data. What's in Github, what's on the internet, what is in the

03:11.360 --> 03:17.720
documentation. Yesterday I watched a presentation with a clear message to everyone writing docs. We

03:17.720 --> 03:22.960
are responsible for what these models tell us. If you write bad documentation, we get bad results

03:22.960 --> 03:33.760
from GEPT or other models. It has been trained on not so good training data. Here, for example,

03:33.760 --> 03:45.120
Maria figured out promo code, open AIS web. If you register there and put the code 20% off.

03:45.120 --> 03:51.600
But unfortunately it was not working. So asking GEPT, hey, how can I apply the promo code? I'm

03:51.600 --> 03:57.440
sorry I know about this promotion. That's something you don't want to happen if it's a company chat

03:57.520 --> 04:05.040
bot. You want to avoid this. So perfect example why we need this current and accurate data up to the

04:05.040 --> 04:12.040
minute, maybe even up to the second. We need this current data. And obviously non-public data,

04:12.040 --> 04:17.600
private data, it's internal documents, it's confidential documents, documentation that is not

04:17.680 --> 04:27.680
public. And also if you are working with, they use legal documents, they use the technical

04:27.680 --> 04:32.080
documentations, vectorize it, put it to a language model and then for the maintenance workers, they

04:32.080 --> 04:37.920
have an application ready. But this is information that also must not leak. And this brings us also

04:37.920 --> 04:44.320
into a little bit of a dilemma because there are multiple options to bring this private data into

04:44.400 --> 04:49.920
the foundation and models or to enhance this foundation and models. First thing, again, I think

04:49.920 --> 04:56.880
everyone in the room heard about it, is fine-tuning. Where you give some input data, you really change

04:56.880 --> 05:02.560
the parameters, the weights in the foundation and model so that the knowledge gets incorporated

05:02.560 --> 05:10.480
into your fine-tuned LLM. Very good. You put the domain knowledge in there, but there are also

05:10.560 --> 05:16.560
challenges, right? You don't solve the frequency issue of the data. It's still some static knowledge.

05:16.560 --> 05:23.520
So there's research out there that one single wrong training data record can kill the overall

05:23.520 --> 05:28.240
performance. One guy says the water is blue and all of a sudden the response of the chat, but it's

05:28.240 --> 05:35.360
all water is light blue or something like this. And it doesn't solve the problem of hallucinations.

05:35.360 --> 05:40.160
You might still get a lot of hallucinations and not talking about the resources that we need.

05:41.280 --> 05:50.320
So second option, retrieval augmented generation, which is kind of developed into kind of a

05:50.320 --> 05:57.120
standard when you want to work with your own data. So first step is you really need to make the

05:57.120 --> 06:03.520
existing data, whether it's videos, it's data from internal database documents available to create

06:03.520 --> 06:08.800
the embeddings, to calculate the vectors, how this knowledge is internally represented. And then

06:09.040 --> 06:13.760
as soon as your user asks a question in the knowledge assistant or the chatbot,

06:15.040 --> 06:19.600
there's a called retriever is then asked, hey, please give me the relevant context. And this

06:19.600 --> 06:26.880
can now be a similarity search in the vector database, or it can be a combination of various

06:26.880 --> 06:32.240
searches, a full text search, to your spatial search, a regular SQL query to get information out of

06:32.240 --> 06:38.320
your databases. This context is returned back to the retriever. It is put into a special prompt,

06:38.800 --> 06:43.200
as context, as additional information to the prompt, and together with the question,

06:43.920 --> 06:48.640
and this additional context, not a large language model can generate your answer. And you can put

06:48.640 --> 06:53.520
into the prompt, as we will see in the demo also, please use only this contextual data. If you

06:53.520 --> 06:58.800
don't know the answer, please say you don't know. Limits the hallucinations a lot, doesn't prevent

06:58.800 --> 07:07.840
them 100%. Good. I think I talked about disadvantages and challenges already. And one advantage I

07:07.840 --> 07:14.160
forgot to mention is access control. Now that you really get this context from either vector store

07:14.160 --> 07:22.160
a different database, maybe create, you can put fine-grained privileges there. The example

07:22.160 --> 07:25.920
application that I mentioned before, some of the maintenance workers are not allowed to use

07:25.920 --> 07:33.760
legal documents, for example. So they don't use the index, use the embeddings of the legal documents,

07:33.760 --> 07:38.720
but they are obviously allowed to use the technical documentation. And someone from the legal

07:38.720 --> 07:45.280
department, oh, what is the support contract with XYZ? Are we now in liability? Et cetera. Obviously,

07:45.280 --> 07:53.200
they need then different indexes, different search indexes. How to do this? How semantics

07:53.200 --> 08:02.960
represented? Key is the vectors. So, or embeddings. And the vector is nothing else than a series of

08:02.960 --> 08:08.560
decimal values or an array of decimal values with a lot of different embedding models out there

08:08.560 --> 08:15.920
already. And every model has its strengths and weaknesses. Some are more optimal if you use,

08:15.920 --> 08:22.480
for example, German text, if you use Chinese text or Indian text, right? A very different way how

08:22.480 --> 08:27.840
to come up with the semantics and to analyze how the attention mechanisms internally work,

08:27.840 --> 08:32.480
right? Because the sentences are built in a very, very different way. So you see different

08:32.560 --> 08:37.600
performance there or highly specialized models. You do an image recognition. Oh, it's a sleeping cat.

08:38.720 --> 08:44.720
And this can then be vectorized as well. And you can search for this context in your vector store.

08:47.760 --> 08:53.200
And now, if we think this one step further, how could an architecture look like for such a knowledge

08:53.200 --> 08:58.400
assistant or a chatbot? Prototype is always easy to build, but you need to think about a lot of

08:59.360 --> 09:06.320
a lot of additional topics. First of all, it starts with the data, right? The data that you want to

09:06.320 --> 09:11.520
train, that you want to vectorize, that you want to make available for your search. So we've shown

09:11.520 --> 09:17.440
here a landing zone from different sources, can be the original sources. You might copy it, depends

09:17.440 --> 09:22.240
on the architecture you want to build. And the important thing is the processing layer. How do

09:22.240 --> 09:27.600
you chunk your data? How do you create the vectors? And obviously, you need to store these chunks of

09:27.680 --> 09:34.880
information together with the vectors and provide proper data access control. Second part here,

09:34.880 --> 09:40.640
the LLM part, talked about it now multiple times. You need access to the embeddings,

09:40.640 --> 09:45.760
you need access to the large language models, and then also needs to be some logging. What do

09:45.760 --> 09:51.760
do you use a query? How much cost does it incur? Is the performance okay? A lot of logging that

09:51.760 --> 09:58.640
also occurs here. And intentionally, an LLM gateway put in front of it because it needs to be

09:59.280 --> 10:06.480
changeable. Chatbots with a lot of functionalities don't want to go into all the details, obviously

10:06.480 --> 10:11.360
monitoring and reporting. And the beauty of it, you can build all of that with open source tools

10:11.360 --> 10:17.520
nowadays. And also the embeddings and language models can be open sourced, a lot of alternatives

10:17.520 --> 10:25.040
out there. Now, why create a long chain? You need a robust data management. As we have seen,

10:25.040 --> 10:28.960
there's a lot of different data sources involved here, data stores, whether it's logging, whether

10:28.960 --> 10:34.480
it's semantics, your agents communicate in JSON. So you need to store all of this information,

10:34.480 --> 10:39.600
ideally in one store, not five, six different databases here that you need to operate,

10:39.600 --> 10:45.600
you need to learn the language, et cetera. And also long chain, other opportunities are also

10:45.600 --> 10:50.240
out there. Think of Haystack and others that you could use. But all of these frameworks give you

10:50.240 --> 10:55.040
a very good set of building blocks. You can just use them. It's available in Python, JavaScript,

10:55.040 --> 11:01.520
there are also Java ports out there, ports to other languages are now available. Everything you

11:01.520 --> 11:07.280
need is already in these libraries to come up with your overall architecture. And that's now the

11:07.280 --> 11:14.400
point to hand it over to Maria. She will guide you through a demo where we want to use it, try to

11:14.400 --> 11:20.720
simulate how you can use support tickets, internal data. Here we took some Twitter posts from Microsoft.

11:20.720 --> 11:26.880
We will vectorize them and we'll show how a support or a customer can then interact with this chat

11:26.880 --> 11:33.120
bot, ask certain questions. It won't demonstrate it's not such a big effort. You can get started

11:33.120 --> 11:39.600
right away. And all the demo, we put the link here on the slide. You find also the link to the

11:39.680 --> 11:43.040
demo in the app or on the website for the talk.

11:49.120 --> 11:57.200
Thank you. Do you hear me? Okay. Awesome. Thank you. So you have heard a lot of theoretical

11:57.200 --> 12:02.080
aspects of the drug and how it works. I have a little bit more than 10 minutes to show you a

12:02.080 --> 12:08.800
practical example. But believe me, we can have hours long workshop on this topic. So essentially,

12:08.800 --> 12:16.240
the idea today is to show you how to augment some of the existing LLAMs with the private data and how

12:16.240 --> 12:22.880
to use it for the context of some specific questions that this LLAM has not seen so far.

12:23.600 --> 12:30.640
So we actually use data that capture customer interactions on Twitter and these customer

12:30.640 --> 12:36.560
interactions involve different questions from the users about Microsoft, Amazon, all these

12:37.360 --> 12:42.240
different products today and how actually the support from these big companies actually

12:42.240 --> 12:47.360
answer to these user questions. So this is not something that you usually see on the Internet

12:47.360 --> 12:51.840
very easily. So if you have maybe some problem with some Microsoft product, yeah, very often you

12:51.840 --> 12:58.560
can actually find the solution out there. But some very specific questions that are asked directly

12:58.560 --> 13:02.640
to customer support is probably a very good reason why it sells to the customer support. So you

13:02.640 --> 13:11.440
didn't find the answer to this out of the box. And we will use CradyBee as a vector store

13:12.160 --> 13:18.960
to support this example. So I think Kristina already gave you a good overview of what the CradyBee

13:19.840 --> 13:24.400
is. What is the long chain? Long chain is an open source Python project that actually is used to

13:24.400 --> 13:30.800
facilitate the development of LLAM applications. It's a pretty cool project that integrates a lot

13:30.800 --> 13:36.240
of large language models, a lot of models for calculating embeddings and actually something

13:36.240 --> 13:43.600
that helps you integrate some data source with some language model without thinking out of the box

13:43.600 --> 13:48.400
how the full engineering pipeline should look like. Actually you can just do this in a couple of

13:48.400 --> 13:54.160
lines of code. May I add one point here that I forgot to mention. Although you use long chains,

13:54.160 --> 14:00.480
very good starting point. What we have also seen for very advanced purposes, you want to directly

14:00.480 --> 14:04.240
interact with your data, with your source data, with your vector store and all of that is available

14:04.240 --> 14:09.600
in standard SQL, no matter which data model you're using. And CradyBee is an open source store,

14:09.600 --> 14:15.920
one of the easiest ways to run CradyBee is actually to use a Docker image. So a vector support in

14:15.920 --> 14:21.280
CradyBee has been available since 5.5 version, but if you actually always pull the latest image,

14:21.360 --> 14:28.480
you should not actually think about this. So once you run this Docker run command,

14:29.600 --> 14:36.320
we actually run the instance of CradyBee cluster and then we can access the admin UI in the local

14:36.320 --> 14:46.640
host. So currently I think because of the resolution of this screen, yes, not everything is available,

14:46.640 --> 14:54.000
but actually in this admin UI you have a couple of tabs that you can use actually to monitor your

14:54.000 --> 14:59.920
cluster to run some query in the console and also to have overview of the tables and the views that

14:59.920 --> 15:06.160
are available in your database. So let's go back to the example because the time is flying very fast.

15:06.160 --> 15:11.600
So what we need is the first step, we need a couple of import statements to make sure that the long

15:11.600 --> 15:18.160
chain and all libraries that we use in this example are available. What is also important is that

15:19.120 --> 15:31.600
you import CradyBee vector search interface that is available in one of the long chain versions,

15:31.600 --> 15:39.600
let's say, which is used to interact with the CradyBee. And as a next step, because we need

15:39.600 --> 15:44.560
to interact with the CradyBee instance, we need to specify how we interact. So this is done

15:46.000 --> 15:52.400
by specifying connection string. We are using open source version running on local host,

15:52.400 --> 15:58.560
but you also have option, for example, if you want to deploy CradyBee cloud cluster and at this

15:58.560 --> 16:05.360
point we also give option for all users to deploy one cluster that is free forever so you can just

16:05.360 --> 16:13.280
run it and use it for testing purposes. Finally, we need to specify the collection name that we are

16:13.280 --> 16:19.120
going to use in this notebook session. So if we run this piece of code, the connection string is

16:19.120 --> 16:26.240
now available and then we can start interacting with the CradyBee. So for purpose of this notebook,

16:27.120 --> 16:33.120
I rely on open AI models. Of course, there are long chain supports, so many different models,

16:33.120 --> 16:38.720
you can actually integrate many of them, but if you choose to use open AI, make sure that you have

16:38.720 --> 16:45.280
open AI key as a part of your environment variable. So now let's take a look at how the dataset looks

16:45.280 --> 16:50.880
like. This dataset is also available on our CradyBee dataset repository, which is also

16:51.840 --> 17:01.760
open source and it contains the customer interaction about Microsoft products. So

17:01.760 --> 17:07.760
essentially we would like to now kind of narrow the scope of this notebook for the

17:07.760 --> 17:16.240
for the illustration reasons and time reasons. So essentially this dataset has some information like

17:18.000 --> 17:23.920
who is the author of this question, whether it's unbound, outbound question, when it was created,

17:23.920 --> 17:31.040
what was the context of the question or the answer and actually whether this text is response

17:32.000 --> 17:38.960
to something or is it response tweet or is it created in response to something else.

17:39.520 --> 17:44.640
So essentially all this information and now the idea is to feed them to the large language model

17:44.640 --> 17:53.360
and to ask questions that could be for example seen in this dataset. So as a first step, if you

17:53.360 --> 18:01.200
remember this big rug image is to create embeddings. Embeddings is actually the representation of your

18:01.200 --> 18:10.000
data that is suitable for machine learning and AI purposes. So first as a first step we need to

18:10.000 --> 18:17.280
load the data from this dataset and for this we use CSV loader interface that is available in

18:17.280 --> 18:28.480
Longchain and now in this like few pieces of code we already we already creating embeddings for all

18:28.480 --> 18:35.440
the data set for all the entries in our dataset. So if I go back to the admin UI I can see two tables.

18:36.000 --> 18:46.240
So in the first table actually gives me a collection of entries. So as we as we define the

18:46.240 --> 18:51.840
the first collection we created is called customer data but essentially what is interesting now is to

18:51.920 --> 19:00.560
see like embeddings created for all the entries in this in this collection. So for example this is

19:00.560 --> 19:06.720
the instance of the of the document that we are actually using for the training purpose or for the

19:07.520 --> 19:15.760
context purposes and you can actually see how the embeddings look like. So if you use open AI

19:15.760 --> 19:26.480
embeddings usually the length of your of your vector is going to be 1040 something yes it would

19:26.480 --> 19:31.840
be size of 1040 something but you can also for example choose some other embedding algorithm for

19:31.840 --> 19:40.240
example hugging face as you can see suggested here which is which is open source and it can

19:40.800 --> 19:47.280
easily be used out of the box in just two lines of code. Now once we have these embeddings let's

19:47.280 --> 19:55.600
define our question and our question today is like okay I have some I have some order on my

19:55.600 --> 20:03.520
Microsoft Store but I want to update the shipping address and how I do this. I also here put alternative

20:03.520 --> 20:08.320
questions so like when you play with this notebook you can also put your own questions and see

20:08.400 --> 20:15.280
actually whether this data set has enough information to answer this question. So once the

20:15.280 --> 20:20.880
question is answered what we want to do is actually we want to find the context that is relevant to

20:20.880 --> 20:27.200
this question and this context is done by doing similarity search of the vector representation of

20:27.200 --> 20:34.000
our question compared to the vectors actually that we stored in the creative instance and this is

20:34.080 --> 20:41.680
actually done in just one line of code. As Christian suggested vector search is one way to find the

20:41.680 --> 20:48.160
relevant context of course kdb supports other types of searches like full text search or geospatial

20:48.160 --> 20:53.680
search or just key search keyword search so like you can use different type of searches combined

20:53.680 --> 21:00.400
together to find what is what is the relevant context for your question. Once we do this we are

21:00.400 --> 21:08.240
now ready to actually ask our LLM to answer our question and how we do this. First we need to create

21:08.240 --> 21:16.480
a prompt that explains LLM what his purpose is. So his purpose is today to be expert about

21:16.480 --> 21:22.080
Microsoft products and services and should use the context that you are going to actually give

21:22.080 --> 21:28.160
to the LLM to answer relevant questions but if the answer is not fine in the context it should

21:28.160 --> 21:35.600
reply with I don't know and this is very simple way to create a prompt that actually gives

21:35.600 --> 21:43.120
instructions to LLM how it should answer specific questions and finally we just need to create

21:44.480 --> 21:51.440
small chatbot by using some of the available models that are integrated with the long chain and also

21:52.080 --> 21:58.240
passing this context together with the user question. Once this is completed we can access

21:59.120 --> 22:05.040
the answer and in this case it says to update the shipping address you will need to cancel your

22:05.040 --> 22:10.480
current order and place a new one. Maybe that's something that is still up to date that is relevant

22:10.480 --> 22:14.960
maybe it's not relevant anymore but it's actually something we learned only from the dataset we

22:14.960 --> 22:22.560
provided so this is a way how to actually how you actually use your private data to teach LLM

22:22.560 --> 22:32.160
actually what should what should be the context for any incoming questions. So I hope you like this

22:32.160 --> 22:41.040
demo you can play with this notebook it's on our creative B examples repository and you also can see

22:41.120 --> 22:47.200
there are other similar notebooks for different different different types of examples for different

22:47.920 --> 22:54.880
prompt engineering examples or like how to create another another form of chatbots how to use another

22:54.880 --> 23:02.800
embedding algorithms so please let us know what you think give us a feedback open a new issue on

23:02.800 --> 23:10.880
this repository and we are looking forward actually to work with you on these topics. So I think that

23:11.760 --> 23:21.200
is all from us thank you for being part of this session maybe we have time for one question

23:23.840 --> 23:24.720
okay awesome

23:36.960 --> 23:37.840
do we have questions

23:41.520 --> 23:43.040
anyone

23:54.400 --> 24:00.000
thank you for the talk I have a question about the embeddings model because if you

24:00.880 --> 24:07.120
encode prompt with language model and use external embeddings model they cannot be in

24:07.120 --> 24:15.680
different spaces and if you do similarity search have you tested it and do you see the effect of

24:16.400 --> 24:17.360
different embeddings

24:25.360 --> 24:31.040
I mean it's a very important question now if you the way you create these embeddings is super

24:31.040 --> 24:36.320
important and you're usually limited to one embedding algorithm because you need to

24:37.440 --> 24:41.840
they need to have the same length and obviously they need to capture the same semantics

24:41.840 --> 24:46.720
simplifying a bit and this is also what I meant with the customers that we work with they were able

24:46.720 --> 24:52.240
to create different indexes right and then the retriever gets more and more complex as you've seen

24:52.240 --> 24:57.040
on this architecture slide this is a simplified example you maybe you need to query different

24:57.360 --> 25:03.040
different indexes created by different embedding algorithms you know so that you can search your

25:03.040 --> 25:07.520
images you can search your textual data right obviously you might use different things there

25:08.400 --> 25:14.400
and then re-rank the results come up with the really relevant context maybe from different

25:14.400 --> 25:18.640
indexes and maybe you also want to combine it with a full text search or limit it to

25:19.200 --> 25:23.760
customer support tickets from Europe trying to come up with a good example there are or to

25:24.320 --> 25:30.320
customers support tickets from the US with some geospatial inhibition but this is then the re-ranking

25:30.320 --> 25:37.760
of the results that really identifies the particular context that is really relevant for the question

25:38.800 --> 25:39.680
okay thanks a lot

25:42.480 --> 25:43.280
any more questions

25:46.880 --> 25:51.440
no so thank you very much for the very nice talk thank you

25:53.760 --> 25:54.980
you

