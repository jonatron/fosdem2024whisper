WEBVTT

00:00.000 --> 00:02.000
I

00:08.440 --> 00:10.440
Come on people

00:14.680 --> 00:20.880
Yeah, let's share up for Daniel because his first time speaker and everything's failing

00:21.680 --> 00:26.640
And it's off to a good start. Yeah, come on big applause. Thank you. You're doing awesome

00:30.160 --> 00:32.160
And

00:36.320 --> 00:41.520
You know the only certain thing about technology is gonna fail exactly when it doesn't need to

00:45.640 --> 00:51.520
Yeah, like I think I said already flakiness is not only happening in test obviously right

01:00.080 --> 01:02.080
So

01:02.800 --> 01:07.760
While we're waiting for this thing to happen I could ask a question about

01:08.720 --> 01:10.720
who actually

01:11.080 --> 01:16.720
Has has an idea what a flake would be in testing

01:21.320 --> 01:24.160
Okay, I should just repeat what you're going to say

01:25.640 --> 01:28.280
Yeah, yeah, go ahead you probably I don't know

01:30.360 --> 01:33.240
So you have an idea, but you don't want to tell me

01:39.240 --> 01:41.240
Exactly exactly so

01:42.400 --> 01:47.240
To me or I think to most people that agree about this topic

01:48.080 --> 01:53.560
Flaky test is a test that fails and passes and successive runs without changing any code

01:54.080 --> 01:57.640
Neither testing code nor the underlying production code

01:58.600 --> 02:00.040
Okay

02:00.040 --> 02:03.360
So, yeah, this talk will be about flaky test. Yeah

02:11.880 --> 02:19.880
Yeah, of course, of course flaky behavior is not determined by just being the test being flaky but also the software but I would

02:21.080 --> 02:26.240
Divide those two kids into different categories and how they are going to be handled this differently. So

02:26.800 --> 02:28.280
Yeah, but

02:28.280 --> 02:30.280
Let's wait. So

02:30.360 --> 02:35.520
Yeah, I'm going to start with introduction. My name is Daniel Hiller. I'm working at Red Hat

02:35.520 --> 02:38.480
I'm working on the upstream cupid project and there I'm

02:40.320 --> 02:42.320
Maintaining the cupid CIS system

02:44.840 --> 02:48.880
So this talk will be about flaky tests and

02:50.200 --> 02:53.500
How we should or how we are actually going to handle them

02:54.260 --> 02:57.460
I'm in our community of

02:58.100 --> 03:02.300
supporters for the cupid contributors. So I don't

03:02.940 --> 03:09.500
Say I have the silver bullet for handling that I would be happy to have any

03:10.460 --> 03:12.460
input from you folks

03:13.180 --> 03:15.900
And how we can improve and I would actually also

03:16.420 --> 03:21.940
Want to have some kind of extended Q&A session if the time is still there

03:22.380 --> 03:29.220
Somehow so that you might talk about what you have experienced and how you are going to handle it

03:29.980 --> 03:31.980
Just as a quick

03:32.620 --> 03:34.620
Thing how I think this should be going

03:37.540 --> 03:39.540
I'm going to start with

03:39.820 --> 03:43.300
Waterfeg is but yeah, you described it perfectly already. So it's fine

03:44.180 --> 03:46.180
and then

03:46.340 --> 03:48.340
What the impact of flakes is

03:48.900 --> 03:55.940
And then how we are doing or how we are how we can find flakes somehow and then at the last

03:56.100 --> 04:01.060
I'm half rate the flake process works and what tools we do have that support this

04:02.540 --> 04:04.540
and

04:04.780 --> 04:10.380
Yeah, in the end, I just want to describe what we're aiming to do in the future to improve this

04:11.900 --> 04:14.940
Just don't have internet and made up for some reason. Oh, no

04:15.420 --> 04:17.420
My email, okay

04:19.020 --> 04:26.700
Yeah, yeah, I think it's going really terribly wrong

04:27.420 --> 04:34.100
Sorry for all that by the way a packed room. I didn't expect that to be honest. So thank you all for coming

04:34.500 --> 04:37.140
Really great. I'm gonna help you out. Don't worry. So

04:37.820 --> 04:40.460
Tell me kind of a little bit more until we wait for the slides

04:41.060 --> 04:45.980
Can I give us a hint as to what you wanted to show us and just tell us the story about it?

04:46.220 --> 04:50.300
Yeah, without the slides just going to open it a bit because so I can

04:52.940 --> 04:54.940
Supposed to talk about

05:03.020 --> 05:08.020
You know pretend I'm stupid and I have no idea what's flaky and just you know tell it to me

05:08.940 --> 05:11.460
So I told you already about the agenda

05:12.580 --> 05:16.940
And yeah, the question of flakes was already answered

05:18.180 --> 05:20.180
so I

05:21.380 --> 05:30.460
Have two other questions. So that one is somehow like a little bit suggestive, I guess so who thinks handling flakes is important

05:31.300 --> 05:34.060
Like put your hand up a few you don't

05:34.900 --> 05:39.820
Who yeah, of course things handling of flakes is important

05:41.180 --> 05:45.020
Okay, I thought about that. So

05:54.940 --> 05:58.620
You save my day do you have a USB port

06:04.060 --> 06:06.060
I

06:08.380 --> 06:14.740
Hope so once again, it's on you need to put in a presentation mode

06:16.660 --> 06:19.780
There is on the right should be presentation. Yeah, that should be okay

06:22.180 --> 06:26.380
Yeah, okay, so the questions we already had

06:28.700 --> 06:33.340
Yeah, and another question who has to deal with flakes on a regular basis

06:34.540 --> 06:37.980
Wow, okay. Yeah, I expected something like that

06:39.420 --> 06:41.420
So yeah, like you

06:41.580 --> 06:43.180
correctly already said

06:43.180 --> 06:49.140
Flakes are caused either by production code, which is a bug of course or also by flaky test code

06:49.140 --> 06:52.500
This is also a bug, but it's handled differently like I already said

06:52.900 --> 06:59.740
So we are using prowl for our CI system which comes from the Kubernetes ecosystem. I'm not sure

07:00.500 --> 07:04.420
Whether you're familiar with it, but it's pretty flexible and it can just

07:05.540 --> 07:07.540
Start jobs from

07:07.740 --> 07:11.100
From GitHub events, which is exactly what we want and what we need

07:12.060 --> 07:14.060
this picture actually

07:15.300 --> 07:19.100
Shows on the top for example there is the commit ID

07:19.820 --> 07:22.620
I made I don't even see it like that there

07:22.940 --> 07:28.140
We're pointing this is the commit ID and these are the job runs that are defined

07:28.140 --> 07:34.860
So like the jobs on the CI system and this of course is a failed job and these are successful jobs

07:35.580 --> 07:41.580
so obviously you can see like this is the PR history for one of our PRs inside the

07:42.780 --> 07:44.340
Kubrick CI and

07:44.340 --> 07:47.060
What you can see here is that of course?

07:47.540 --> 07:53.420
There is jobs all run on the same commit ID, but some failed and some succeeded and

07:53.940 --> 07:57.500
That's exactly how we see where we have our flakiness

07:58.740 --> 08:00.580
Oh

08:00.580 --> 08:03.780
Wait a second. That's the wrong direction. Okay, so

08:04.380 --> 08:10.180
There is a really interesting survey that which is a major survey about flakiness in test

08:10.740 --> 08:13.260
Which is just called a survey of flaky tests

08:14.060 --> 08:19.980
Not really impressive about great stuff inside there something like that there you can read that

08:20.300 --> 08:23.820
79% percent of the flakes were for the lungs and

08:24.420 --> 08:28.220
More than 50% of flakes could not be reproduced in production

08:28.620 --> 08:32.900
In isolation, so which of course leads us to the conclusion that

08:33.860 --> 08:36.500
Ignoring fake heat as flaky test is okay, right?

08:37.700 --> 08:39.700
It's doesn't of course

08:42.220 --> 08:43.700
So

08:43.700 --> 08:49.900
When we're talking about CI we want to have a reliable signal of stability in our CI

08:50.340 --> 08:57.420
So because of course we want to know whether we can ship our product or not and so any failed test run

08:58.060 --> 09:00.060
signals us as the

09:00.740 --> 09:05.140
CI maintainers that the product is unstable and that we can ship it

09:06.260 --> 09:09.380
So if we are having flakes in our

09:10.140 --> 09:16.780
Production system, of course, they give us a wrong signal like that the product is unstable and that we can ship

09:17.780 --> 09:24.820
Which we later then have to verify the test code what exactly got wrong and then we notice it's a flaky test

09:24.980 --> 09:28.260
So this is wasted of course a lot of time

09:29.540 --> 09:30.820
so

09:30.820 --> 09:32.820
Not only does it waste

09:33.100 --> 09:35.100
the time of the

09:35.300 --> 09:41.420
Developers themselves who have to look at the test results somehow and determine whether this is the flaky test or not

09:41.940 --> 09:43.820
But it's also like

09:43.820 --> 09:46.060
when you have a CI that is somehow

09:47.060 --> 09:49.420
Determining whether a PR can get merged

09:50.860 --> 09:52.860
via the test

09:53.020 --> 09:55.420
And then you have a test result

09:56.340 --> 09:58.700
Of course the merge will not go through

09:59.100 --> 10:03.380
So this cost friction by the developers who have then somehow

10:03.980 --> 10:05.980
Maybe reissue another test

10:05.980 --> 10:10.620
So if they see it's flaky if they there is nothing to fix then they would just retest

10:11.580 --> 10:13.580
Which somehow?

10:13.820 --> 10:20.060
Yeah, sometimes you would just think okay, there was flakiness. I'm just going to retry not even looking at the test results somehow

10:20.700 --> 10:27.740
Which which I would call the retest trap and we have actually had retest like I

10:28.100 --> 10:32.980
Mean the highest number I've been seen like 25 times testing and retest on the same commit

10:33.500 --> 10:35.900
Do they have to oh I have to stay here. Okay

10:36.380 --> 10:38.380
Okay

10:38.940 --> 10:46.620
And also a very bad thing is like I'm not sure I guess any CI system has something like an acceleration system

10:47.020 --> 10:49.500
where for example, it's like testing like

10:50.660 --> 10:54.500
Multiple git commits at once so that it can merge them all together

10:54.500 --> 11:02.460
And of course if there is a flaky test this acceleration effect will just be reversed. It will not be effective

11:04.100 --> 11:07.780
Yeah, like I said another wasted wasted thing

11:08.380 --> 11:10.380
so also flaky test

11:10.980 --> 11:17.060
Trust issues at the developers themselves because they of course lose the trust in automated testing

11:17.460 --> 11:19.460
Which is really sad because that's

11:19.900 --> 11:22.500
All that we want to do we want to trust the test

11:22.500 --> 11:28.260
But if we can then then of course we are just ignoring test results, which is not a good idea

11:30.100 --> 11:36.820
So how so we want to minimize the impact in our CI so that people don't

11:39.380 --> 11:41.380
Experience that much friction

11:43.780 --> 11:45.780
Time flies

11:45.940 --> 11:47.940
so

11:48.100 --> 11:54.580
What we do there is we quarantine those tests we put them out of the set of stable tests and

11:54.980 --> 11:59.020
Put them in another set so that they are not run during pull request runs

11:59.900 --> 12:04.900
But we only want to do that as we want to do that as early as possible when we

12:05.300 --> 12:11.780
Detect the flakiness, but only as long as necessary because tests on themselves of course have value

12:13.860 --> 12:15.860
So otherwise it wouldn't be there

12:16.500 --> 12:18.600
What do we need for that? We need some

12:19.540 --> 12:22.580
like mechanism where we can put stable

12:23.420 --> 12:25.620
test from the set of stable test to the

12:26.260 --> 12:28.260
set of quarantine test

12:29.060 --> 12:33.660
Of course, we also need a report over the flakiness

12:33.860 --> 12:35.860
So we can triage

12:36.860 --> 12:42.460
Which flaky test we need to act upon first if you have a lot of flaky test that matters

12:42.700 --> 12:44.740
so because the higher

12:45.340 --> 12:48.780
The flakiness of the test is of course the highest impact

12:50.420 --> 12:55.860
And yeah, lots of data because of course you need to somehow analyze whether a test is even flaky or not

12:58.060 --> 13:02.940
So as I already said I already described this this is like a

13:03.740 --> 13:10.460
The latest commit on a merge PR where we have some flaky test or some failing test runs

13:10.620 --> 13:15.420
Which later on got green on the same commit so no changes on the code

13:17.700 --> 13:19.700
So

13:20.300 --> 13:24.900
This is not of course not saying us that is it is actually flaky

13:24.900 --> 13:31.020
But it might might be flaky and like you said it could either be in production code or in the test code itself

13:32.020 --> 13:34.180
But that doesn't matter in the end the

13:35.020 --> 13:38.780
Problem that we have is the fiction NCI and the wasted resources there

13:40.340 --> 13:45.140
So our flake process is pretty well pretty pretty rough

13:45.140 --> 13:47.140
I'd say are pretty pretty easy

13:47.460 --> 13:52.100
So we have regular meetings where we look at the at the results and at the flakes

13:52.100 --> 13:56.620
And then we decide what we want to do with those flakes. So first of all, of course

13:57.620 --> 14:00.500
You have to know whether a test is flaky or not

14:00.500 --> 14:07.020
You're looking at the test results and deciding whom you showed contact so that he fixes that because we don't fix the test

14:07.140 --> 14:12.500
Ourselves we let the developers do that because yeah, they created their mess. They should clean it up

14:14.500 --> 14:20.300
A problem is of course when people are gone from the project then someone else has to care, but yeah

14:21.180 --> 14:27.580
So we have the flaky test to the dev developers and at the time when it's been

14:28.780 --> 14:31.340
Corrected we bring those tests back in

14:32.380 --> 14:33.540
so

14:33.540 --> 14:36.140
the truth that we have is like we have the

14:36.780 --> 14:38.780
main thing that

14:39.420 --> 14:41.980
Decides whether a test is being run between

14:42.980 --> 14:49.220
For the pull request. It's just a just a note on the test itself. That is like

14:50.300 --> 14:52.780
There is in the test name. There is this quarantine

14:54.860 --> 15:00.180
Word which is the keyword which makes the test get ignored for the pull request runs

15:00.660 --> 15:05.420
We still do to do run those tests to have this stability signal

15:06.620 --> 15:11.660
But not in the pre-submit which are required for the pull request merges

15:12.340 --> 15:14.340
But in the periodic runs

15:15.260 --> 15:17.940
That run I think three times a day

15:18.700 --> 15:22.700
So that we still have a signal when we can take a test back in

15:23.780 --> 15:25.780
in order to

15:25.780 --> 15:27.780
Have the value added again

15:29.300 --> 15:34.660
So another thing is of course you need to report so we this is a not not really

15:35.180 --> 15:41.100
Nice looking but efficient thing like a heat map so where you see where the action is going on

15:41.100 --> 15:45.940
You see like the more reddish the colors are getting the worst the problem is

15:46.940 --> 15:53.500
This is in oh, no, I can't go there. So like on the top you can just see

15:54.500 --> 15:58.820
on which day how many failures were occurring and

16:00.100 --> 16:04.540
There is another like axis which is the per lane

16:05.820 --> 16:12.540
Failure so that we can pretty much see which lane is flaky and on which was the biggest impact for everything

16:16.420 --> 16:21.060
This is the first time I'm using this sorry. I'm just always switching the directions

16:21.900 --> 16:28.020
Okay, this is the detailed report about how flaky a test is or how flaky those tests are

16:28.260 --> 16:31.220
This is ordered by the number of failures

16:32.460 --> 16:35.340
Occuring for test this is a bit overwhelming

16:35.340 --> 16:42.220
I think but on the left column you just see the test name and on the on the upper column you see the

16:43.060 --> 16:45.420
number the test lanes that are

16:46.140 --> 16:48.140
The

16:50.980 --> 16:52.980
Versions of the latest three

16:52.980 --> 16:55.780
Like we have a lot of test lanes that have different

16:56.620 --> 17:04.140
Sigs which are maintaining them and this of course obviously creates a matrix of like like at least 12 really

17:04.740 --> 17:06.740
well, yeah, really

17:07.420 --> 17:11.700
Important lanes which absolutely have to be be stable

17:11.900 --> 17:20.580
Yeah, and this helps us like finding where which test we should look at and quarantine or which we shouldn't

17:23.100 --> 17:30.140
We have also long-term metrics where we can decide how we were doing in the past so like at least

17:31.060 --> 17:34.460
everyone of course wants to know whether they are improving or

17:36.060 --> 17:41.300
Getting worse in handling flakes that we have long-term metrics where we can look at how we were doing

17:41.700 --> 17:47.900
So how many merges per day for example or how many merge PRs with zero retest

17:47.900 --> 17:52.740
Which is the thing that we are measuring currently against the most because

17:53.420 --> 18:00.620
Obviously that number should be like 28 of 28, but we seldom reach that like flakies

18:03.380 --> 18:05.980
We also have a small report over the

18:06.180 --> 18:10.540
The tests that happen quarantine so that we can find them quickly because it's like

18:10.900 --> 18:13.540
Grapping over the code base is also of course doable

18:13.540 --> 18:19.500
But it is easier to just have some report that we can look at straight away during our meetings

18:19.500 --> 18:22.980
And then finally we have all the test grade which also

18:23.580 --> 18:27.020
Collects all the periodic results so that we can deduce

18:28.420 --> 18:30.140
Where to

18:30.140 --> 18:34.500
Whether the tests have been stable or not. So this is the tool I guess that

18:35.060 --> 18:38.460
guys from the from the Kubernetes ecosystem know that because

18:40.260 --> 18:45.020
Kubernetes also uses test grid for collecting all the test results so that you can quickly drill down

18:47.980 --> 18:50.720
Yeah, and we have also established

18:52.180 --> 18:58.580
Another lane that checks the test for stability which does a thing that

18:59.460 --> 19:01.460
that makes

19:01.460 --> 19:02.580
like

19:03.060 --> 19:09.140
Test dependencies for example visible you I guess you know what a test dependency is some tests that hasn't cleaned up and

19:09.420 --> 19:13.340
Leap the mess for other tests and then influencing them and then they might be failing

19:14.260 --> 19:16.620
Or the other way around they might not

19:17.420 --> 19:19.420
Was already sufficient for

19:19.660 --> 19:27.100
For the following tests and if you are just randomizing the test order you catch those cases which is like you have to have

19:27.220 --> 19:29.220
Isolated test cases, right?

19:30.140 --> 19:33.700
And also it tries to run it five times because

19:35.260 --> 19:40.700
Like I said before in the in this metadata in this meta report

19:41.700 --> 19:43.060
like

19:43.060 --> 19:50.060
Bit more than 80% of all the tests have been fed off the flaky test have been failing after about five times

19:50.340 --> 19:53.340
This is not that you catch all of them, but the majority

19:53.660 --> 19:59.980
Yeah, that's just the CI search tool so in a nutshell we

20:00.420 --> 20:04.580
Just do in regular intervals meetings that we look over the data somehow

20:05.020 --> 20:07.020
So like I described before

20:07.460 --> 20:11.180
What we want to do is of course we want to collect even more data like

20:11.620 --> 20:18.060
We want to run the majority of tests in the same way as we are doing in the flake lane like

20:18.460 --> 20:22.020
Running them five times after another and also running

20:22.460 --> 20:27.340
Randomizing always the order so that we have a better picture over how flaky our code base is

20:28.500 --> 20:33.020
And yeah, of course like we want to avoid this retest problem where you

20:33.900 --> 20:38.340
Blindly just retest your things so we are looking for ways to just

20:38.980 --> 20:40.980
Directly find that case

20:43.180 --> 20:46.500
Yeah, so it's pretty I've been

20:47.220 --> 20:49.340
Running through pretty quickly any questions

20:51.300 --> 20:53.300
Yeah

20:56.700 --> 21:01.340
So you've been talking about responsibility of devs to fix the flakiness

21:01.620 --> 21:09.380
So this kind of assumes that the flakiness is introduced either by new tests or by changes on tests or changes on the code base

21:09.500 --> 21:14.820
But what about flakiness that is introduced by the by your infrastructure actually like network latency or things like that

21:14.900 --> 21:22.140
Do we have we have those problems or is it something that you I didn't get the less could you repeat the last sentence? Sorry sorry so you

21:23.260 --> 21:30.100
You imply that the flakiness can either be introduced in new tests or changes in tests or changes in the code base

21:30.620 --> 21:36.660
but have you ever been confronted with flakiness introduced by your infrastructure your

21:37.460 --> 21:42.780
Like network latency or something like that and how do you detect them and how do you of course of course that that is also a problem

21:42.980 --> 21:48.580
But when you have like flakiness in your test infrastructure or even failures in the test infrastructure

21:48.740 --> 21:58.420
That's an entire different problem and what we have observed there is that a lot of tests are to fail then and that's why we look at first of all when we have like

21:59.180 --> 22:07.300
Rough estimate of like like have more than 20 tests failing at one run that might likely be because the test infrastructure is failing and

22:07.980 --> 22:09.300
actually

22:09.300 --> 22:15.300
We decided to just quickly verify that there is something going on in the infrastructure

22:16.020 --> 22:21.940
And then just disregard that run and yeah in earlier days. We had that problem pretty much often

22:22.060 --> 22:25.300
But in recent days it hasn't been happening anymore or

22:27.060 --> 22:29.060
Much less that's let's put it like that

22:31.540 --> 22:36.340
Of course of course we look so like what we are what we are having to test our

22:36.740 --> 22:39.660
E2e test like QBIT is a complex system

22:39.660 --> 22:47.060
It's an addition on Kubernetes so that you can run virtual machines and of course for testing that you for testing E2e

22:47.060 --> 22:50.940
You need a full Kubernetes cluster which with on which you will deploy

22:51.380 --> 22:55.940
The QBIT and that's what we're doing in DCI. So we are actually spinning up

22:56.260 --> 23:03.060
Some I would say a frozen cluster like the virtualized nodes that have been frozen and that are spun up on demand

23:03.100 --> 23:06.620
Like this takes around one and a half minutes to spin up such a cluster

23:07.500 --> 23:08.940
and

23:08.940 --> 23:15.180
Then you run all those tests somehow and we have like we have like always three versions of the thank you very much

23:15.180 --> 23:18.620
We are running out of time. Yeah, you can continue us. Thank you

