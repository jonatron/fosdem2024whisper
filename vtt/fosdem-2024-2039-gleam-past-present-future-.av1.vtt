WEBVTT

00:00.000 --> 00:09.000
Yes, good now it is

00:18.000 --> 00:21.000
Hello everybody, this is fantastically exciting

00:21.000 --> 00:25.000
Look how many people there are, I thought there was going to be like five of us having a lovely time

00:25.000 --> 00:28.000
But no, there's far too many of us, great

00:28.000 --> 00:30.000
I'm so excited, I'm going to take a photo

00:31.000 --> 00:33.000
Just so I can prove this happened

00:34.000 --> 00:35.000
Does everybody smile?

00:37.000 --> 00:39.000
Wonderful, thank you so much

00:39.000 --> 00:44.000
I'm ecstatic, so hello, I'm Louis, I'm the creator of the Gleam programming language

00:44.000 --> 00:47.000
If you want to talk to me, do so here

00:47.000 --> 00:54.000
I'm here to talk about Gleam, which is, you've just seen a new programming language for the Erlang virtual machine

00:54.000 --> 00:59.000
And it feels like we've had milestone, because the language has really matured especially over the last year

00:59.000 --> 01:05.000
And so I want to have a little bit of an indulgent look into the past, sort of where did it come from and how did it get started

01:05.000 --> 01:09.000
A little bit of a celebration of where we are now and look at some really cool projects

01:09.000 --> 01:16.000
And then I want to look into the future and say, what's coming next for Gleam, what can we bring to the beam?

01:16.000 --> 01:21.000
So, this slide is ever so slightly irrelevant after that last talk

01:21.000 --> 01:25.000
But I just want to stop by saying, what is Gleam, to get everybody on the same page

01:25.000 --> 01:30.000
It is a new functional programming language, it doesn't look like Ruby, it doesn't look like Prolog

01:30.000 --> 01:35.000
It kind of looks like Rust, C, JavaScript, that sort of thing perhaps

01:35.000 --> 01:42.000
And it runs on the Erlang VM, so it is a sibling of Elixir and Erlang

01:42.000 --> 01:50.000
But it is a bit different in that it is statically typed, unlike the other two dynamically typed languages, and most of the other ones

01:50.000 --> 01:57.000
And that means that it brings a new style of programming to the beam, and hopefully can draw in more beamy people

01:57.000 --> 02:06.000
It aims to be very small and consistent, and the point of that is that we want to make it as easy as possible to read code

02:06.000 --> 02:11.000
We want it as easy as possible to learn the language and to get productive with it

02:11.000 --> 02:17.000
And productivity is not just about having a good language, these days you often have really good tooling

02:17.000 --> 02:22.000
Gone are the days when you can just give someone a compiler and then you say, ok well everything else is up to you, you figure it out

02:22.000 --> 02:32.000
So we also have a really nice build tool that comes with a formatter and package management and a language server and all those sort of things you probably expect

02:32.000 --> 02:38.000
And also it can pass a JavaScript, which is probably less exciting to this room than most

02:38.000 --> 02:44.000
But maybe you don't have to write JavaScript if you do in your front-end, so maybe that's a cool thing

02:44.000 --> 02:54.000
So first up, the past, what did I mean? Yes good, ok, the past, the past, how did we get here?

02:54.000 --> 03:05.000
So this is a history of Gleam according to GitHub, and in the very beginning there was a little tiny little blip of activity and then nothing

03:05.000 --> 03:10.000
For absolutely ages, so what was that? What was the very first Gleam?

03:10.000 --> 03:15.000
It was this, this hideous thing, this is the very first Gleam syntax

03:15.000 --> 03:21.000
People keep saying that the first Gleam syntax was like a Haskell rip-off, it was not, it was this

03:21.000 --> 03:31.000
You see it's sort of C-style, it's got braces, but it has the Erlang thing of multiple function clauses, so your top level flow control is done that way

03:31.000 --> 03:35.000
And it looks like nothing and nobody's familiar with it and nobody really likes it

03:35.000 --> 03:41.000
And it has this perhaps cool idea of having the tests for functions actually be part of the function

03:41.000 --> 03:47.000
So maybe you could show that in documentation, and I thought this was great, this is the thing that the language is going to be all about

03:47.000 --> 03:54.000
But it looks kind of rubbish to me now, because you can't do any test setup, the only thing you can really do is give an input and an output

03:54.000 --> 03:59.000
Well maybe that's good if you're reversing a list, but other than that what can you really do with it?

03:59.000 --> 04:06.000
What else can it do? Nothing, it didn't have a type system, it didn't really have a design, I wasn't working in any direction

04:06.000 --> 04:12.000
You could return strings and maybe call a function, but that's kind of about it

04:12.000 --> 04:19.000
And it was just a really bad layer on top of Erlang, which asked the question, why? Why did this exist?

04:19.000 --> 04:22.000
Well it's kind of like today, I wanted to do a conference talk

04:23.000 --> 04:29.000
So there I am, looking at younger, Elixir London 2017

04:29.000 --> 04:35.000
And I did a talk on how to write a compiler, how to write a compiler that targeted the Beam virtual machine

04:35.000 --> 04:41.000
And it went really well, people liked the talk, I got to hang out with loads of my peers and then I took that project and threw it away

04:41.000 --> 04:45.000
And I didn't think about it ever again, sort of

04:45.000 --> 04:55.000
Because during this empty period where no work was being done really, I was doing my job, doing open source stuff

04:55.000 --> 05:03.000
And I kept thinking, I kept thinking back to that project and wondering, is there actually a point in making another Beam language?

05:03.000 --> 05:08.000
And this was spurred on further because I was writing all these really wonderful languages

05:08.000 --> 05:14.000
And every time I was writing one of them, I was thinking, oh I really wish I was using one of the other ones

05:14.000 --> 05:19.000
Every time I'm writing Elms, it's really difficult to do this IO thing in Elm

05:19.000 --> 05:23.000
I wish I was, oh there's no concurrency, I wish I was using Elixir, or I was writing JavaScript

05:23.000 --> 05:26.000
I really wish I had Rusts tooling

05:26.000 --> 05:33.000
And I sort of figured, maybe it's possible to take all the things I like from all of these languages and merge them into one

05:33.000 --> 05:38.000
Because I've sort of accepted the language that I wanted to be writing didn't exist, I felt like I tried them all at this point

05:38.000 --> 05:43.000
And so can I make that thing that brings it all together?

05:43.000 --> 05:49.000
And so after about a year and a half, the start-up I was working for was bought and trashed

05:49.000 --> 05:52.000
And suddenly I had a lot of free time on my hands

05:52.000 --> 05:57.000
And so I thought, this is the perfect time to resurrect this project

05:57.000 --> 06:03.000
So I remade the whole thing and this is the syntax people keep telling me is the very first Gloom syntax, but it's not

06:03.000 --> 06:08.000
It looks a little bit more like OCaml with bits of Elixir mixed in I think

06:08.000 --> 06:15.000
And this is in February 2018, okay, so maybe like a year and a half after that previous one

06:15.000 --> 06:22.000
And so I kept working on it an awful lot and then fast forward a year and a bit later to April 2019

06:22.000 --> 06:29.000
We've sadly scrapped all of the nice ML syntax and we've got a much more sort of JavaScript syntax

06:29.000 --> 06:34.000
And this is version 0.1 which I'm really excited about because it did something

06:34.000 --> 06:37.000
You could use it to write some small program whatsoever, which is really cool

06:37.000 --> 06:40.000
And it started to look a lot more like Moddingling

06:40.000 --> 06:43.000
Fast forward another half year

06:43.000 --> 06:47.000
We basically got the syntax as it is today, we did a little bit more, but that's kind of it

06:47.000 --> 06:52.000
You notice the differences here are, we've got one of those little pipes

06:52.000 --> 06:57.000
And if you look between the IO and the print line, we've got rid of that colon

06:57.000 --> 07:02.000
So that's the last of the little Erlang things, sorry Erlang fans

07:03.000 --> 07:09.000
What else happened? We used our first class modules as a feature that people love

07:09.000 --> 07:13.000
People absolutely love first class modules, that's something that you find in OCaml

07:13.000 --> 07:16.000
And really we do it a lot in Elixir and Erlang as well

07:16.000 --> 07:20.000
Because if you think about when we pass around an atom that is a reference to the module

07:20.000 --> 07:23.000
Well that's a first class module, we're passing it around, we don't have module functors

07:23.000 --> 07:26.000
But we do use them an awful lot in our APIs

07:26.000 --> 07:28.000
Good, I am actually on the right side

07:29.000 --> 07:33.000
And we also have row type records, which is a really cool way of

07:33.000 --> 07:38.000
A really cool type system feature that enables you to do these really interesting sorts of polymorphism

07:38.000 --> 07:46.000
With objects and variants that sort of looks like interfaces in an OO land

07:46.000 --> 07:50.000
But doesn't have that same sort of subtype thing, so these are two fantastically cool features

07:50.000 --> 07:54.000
And we also had a more complicated way of declaring types and data structures

07:54.000 --> 07:58.000
That was much more akin to what you find in Haskell

07:58.000 --> 08:04.000
So we got rid of all these really cool things and replaced them with a string concatenation operator

08:04.000 --> 08:10.000
The ability to use callbacks in a slightly nicer way and the ability to give names to arguments

08:10.000 --> 08:17.000
So we've swapped really sexy awesome functional programming stuff for things that are actually quite useful

08:17.000 --> 08:19.000
But not very exciting

08:19.000 --> 08:23.000
And this has kind of been the whole journey of Glim, this has been

08:23.000 --> 08:27.000
It's very easy when making something to get excited and distracted by all these things

08:27.000 --> 08:29.000
And it could be, we could do this, we could do that

08:29.000 --> 08:31.000
But what is actually the most useful thing?

08:31.000 --> 08:38.000
And it turns out just removing things and honing in on that call, that most useful, that most productive thing

08:38.000 --> 08:41.000
Is the most, hopefully, is the best thing to do

08:41.000 --> 08:44.000
And I think we've got a really nice place because of that

08:44.000 --> 08:49.000
One thing that we have added that is quite big actually is that JavaScript compilation

08:49.000 --> 08:52.000
So that wasn't in there originally, that sort of exploded after

08:52.000 --> 08:57.000
Which does make the ecosystem more complicated, but the language not so much

08:59.000 --> 09:01.000
We also got a build tool, as I mentioned earlier

09:01.000 --> 09:04.000
The idea is to have a really good batteries included one

09:04.000 --> 09:08.000
Originally we were using Rebar 3, which is the Erlang build tool

09:08.000 --> 09:10.000
And it's really good and it worked quite well for us

09:10.000 --> 09:15.000
But you could tell that we were using a tool that wasn't made for us

09:15.000 --> 09:19.000
The user experience wasn't as good as I wanted it to be

09:19.000 --> 09:23.000
And I didn't just want to match Erlang's developer experience

09:23.000 --> 09:25.000
Or even Elixir's developer experience

09:25.000 --> 09:27.000
I wanted to even best it in some fashions

09:27.000 --> 09:31.000
And I've been writing a lot of Rust and Go

09:31.000 --> 09:33.000
And they've got some really amazing tool

09:33.000 --> 09:37.000
And I thought, wow, let's take all this goodness that you find in these other ecosystems

09:37.000 --> 09:41.000
And let's pull them into the Beam ecosystem, make it grow even better

09:41.000 --> 09:45.000
We've integrated with the Hex package management

09:45.000 --> 09:48.000
We're all beamers together, it doesn't really matter what language you're writing

09:48.000 --> 09:50.000
We want to be able to all share the same code

09:50.000 --> 09:53.000
And all depend upon each other's projects and share and give back

09:53.000 --> 09:55.000
So we've integrated with Hex

09:55.000 --> 09:58.000
So rather than just having a few hundred packages written in Gleam

09:58.000 --> 10:02.000
We've also got the 20,000 packages that are written in Elixir and Erlang as well

10:02.000 --> 10:06.000
And then we've got a code formatter and a language server

10:06.000 --> 10:08.000
And lots of goodies like that

10:10.000 --> 10:16.000
So I said there's 20,000, a bit more than that packages on Hex

10:16.000 --> 10:18.000
On the package manager

10:18.000 --> 10:22.000
And about 200, a bit more than 200 of them are Gleam

10:22.000 --> 10:25.000
That makes it extremely difficult to find anything written in Gleam

10:25.000 --> 10:27.000
If you want to make a Gleam project

10:27.000 --> 10:31.000
So after a while we made the Gleam package index

10:31.000 --> 10:33.000
And what that is, that's a little window

10:33.000 --> 10:35.000
Just a little view that looks into Hex

10:35.000 --> 10:39.000
And allows you to see just the ones that are Gleam

10:39.000 --> 10:44.000
So if you want to find a library for HTML in this case

10:44.000 --> 10:46.000
You can type in HTML

10:46.000 --> 10:50.000
I didn't, I didn't, you're making, we'll talk about that later

10:50.000 --> 10:54.000
Anyway, and it will give you elicit packages that have the word HTML

10:54.000 --> 10:56.000
In the description or the name

10:56.000 --> 11:00.000
That somebody's library does not have HTML in the name or the description

11:00.000 --> 11:04.000
And then if you find something suitable you can use that in your project

11:04.000 --> 11:07.000
And if you don't then you can then make a decision about

11:07.000 --> 11:09.000
Whether you want to perhaps make something new

11:09.000 --> 11:12.000
Or if you want to pull something in from the wider ecosystem

11:15.000 --> 11:19.000
Internet points, everybody loves internet points

11:19.000 --> 11:23.000
So I know that Stiles on GitHub mean absolutely nothing

11:23.000 --> 11:26.000
But it's been really uplifting and really wonderful

11:26.000 --> 11:30.000
And I feel like a really good sign that loads of people have

11:30.000 --> 11:33.000
Have taken that two seconds to say, yeah this seems right

11:33.000 --> 11:35.000
This is kind of cool

11:35.000 --> 11:38.000
I've been doing this for an awful long time

11:38.000 --> 11:40.000
And I think I probably would have stopped by now

11:40.000 --> 11:42.000
If it wasn't for loads of lovely people

11:42.000 --> 11:45.000
Sharing their support in some small way

11:45.000 --> 11:48.000
Whether it be a Stiles on GitHub or a kind message on Discord

11:48.000 --> 11:51.000
Or absolutely loads of you turning up into this room today

11:51.000 --> 11:56.000
And so it's been absolutely lovely to see that line go up and up and up

11:56.000 --> 12:01.000
And I find it wild, I've plotted it here against two quite similar languages

12:01.000 --> 12:03.000
Microsoft's F-Sharp and O'Cammill

12:03.000 --> 12:06.000
And at some point in the last year or two

12:06.000 --> 12:09.000
We've ever taken both of them in terms of number of stars

12:09.000 --> 12:11.000
Which is absolutely incredible

12:11.000 --> 12:13.000
I'm really excited about ML types

12:13.000 --> 12:15.000
And also people really love the Beam I think

12:15.000 --> 12:18.000
So this is a really good sign for the future of the Beam

12:19.000 --> 12:21.000
What else have we got?

12:21.000 --> 12:23.000
Has anyone heard of Exism? Anyone a fan?

12:23.000 --> 12:26.000
Fantastic, for those who haven't, it's your lucky day

12:26.000 --> 12:32.000
This is a really wonderful website and project

12:32.000 --> 12:34.000
Where you can go to learn new programming languages

12:34.000 --> 12:37.000
And they've got tens and tens and tens of different languages on there

12:37.000 --> 12:42.000
And for a few years we've had a Gleam track

12:42.000 --> 12:45.000
And they give you an exercise, some instructions

12:45.000 --> 12:48.000
Maybe some hints, and then they give you a series of tests

12:48.000 --> 12:50.000
And you can solve it there in your browser

12:50.000 --> 12:53.000
Or you can use the command line and download it and use your favourite editor

12:53.000 --> 12:55.000
And then when you're happy with your solution

12:55.000 --> 12:58.000
You can submit it off and they do a bunch of automatic grading

12:58.000 --> 13:02.000
So they've gone some tests and they might do a bit of static analysis

13:02.000 --> 13:04.000
Like oh you've done this, maybe you didn't want to do that

13:05.000 --> 13:08.000
And then if you're feeling super brave, which is where the real value comes from

13:08.000 --> 13:13.000
You can submit it to get some mentoring from an experienced programmer

13:13.000 --> 13:16.000
There's loads of lovely people who are just sitting there

13:16.000 --> 13:21.000
Helping strangers improve their Erlang or Java or Gleam or whatever

13:21.000 --> 13:23.000
There's a really wonderful project

13:23.000 --> 13:28.000
And last year, with some help from the wonderful Erlang Ecosystem Foundation

13:28.000 --> 13:30.000
Who sponsored this work

13:30.000 --> 13:33.000
We went from not just having a set of challenges

13:33.000 --> 13:36.000
That you can use to practice your Gleam, but an entire course

13:36.000 --> 13:39.000
So you can start by not really knowing any Gleam

13:39.000 --> 13:41.000
And by going through this whole thing

13:41.000 --> 13:44.000
You can be taught individually all the different concepts

13:44.000 --> 13:47.000
And so they give you a concept

13:47.000 --> 13:50.000
Then they give you a little challenge that's focused on just that concept

13:50.000 --> 13:55.000
And then they will unlock all of the exercises that they think you should be able to do now

13:55.000 --> 13:57.000
Using those skills

13:57.000 --> 14:00.000
So it's a really fantastic resource and it's absolutely amazing that it's free

14:00.000 --> 14:02.000
So do check it out

14:04.000 --> 14:07.000
And it's been really well

14:07.000 --> 14:11.000
People have really taken to it this course

14:11.000 --> 14:13.000
So you can see in the middle

14:13.000 --> 14:17.000
Can you see where we launched the new syllabus?

14:17.000 --> 14:20.000
Suddenly the uptake went absolutely skyward, which is fantastic

14:20.000 --> 14:23.000
And this is not the number of people on the course

14:23.000 --> 14:26.000
There are about a thousand, just under a thousand

14:26.000 --> 14:29.000
This is how many solutions people are submitting

14:29.000 --> 14:31.000
So this is actually the activity

14:31.000 --> 14:33.000
It's absolutely wonderful

14:33.000 --> 14:36.000
30,000 submissions

14:36.000 --> 14:39.000
Which is a lot of learning, a lot of wasted time

14:39.000 --> 14:41.000
Who knows?

14:42.000 --> 14:44.000
So Exism is really cool

14:44.000 --> 14:46.000
And I really like that idea of being taught

14:46.000 --> 14:50.000
The individual concepts in a way that enables you to get somewhere

14:50.000 --> 14:52.000
And become productive

14:52.000 --> 14:54.000
And off the back of that

14:54.000 --> 14:59.000
And also inspired by the wonderful tutorial that Go has

14:59.000 --> 15:01.000
So we decided to take that idea of teaching the

15:01.000 --> 15:03.000
Breaking the language into concepts

15:03.000 --> 15:05.000
And teaching them in an incremental fashion

15:05.000 --> 15:08.000
Where each concept builds upon the last one

15:08.000 --> 15:11.000
And distilled it, minus all the exercises

15:11.000 --> 15:14.000
Into a sort of whistle-stopped tour of Gleam

15:14.000 --> 15:16.000
So if you go to the Gleam website today

15:16.000 --> 15:18.000
And at the very top there's that hero image

15:18.000 --> 15:20.000
That's got the tagline saying Gleam is great tour

15:20.000 --> 15:22.000
I don't think it says exactly that, but you get the idea

15:22.000 --> 15:24.000
And there's a big button that says

15:24.000 --> 15:26.000
Get started or try it or something like that

15:26.000 --> 15:28.000
And if you do that it will point you straight

15:28.000 --> 15:30.000
It will point you straight onto that first lesson

15:30.000 --> 15:32.000
And you can go from

15:32.000 --> 15:34.000
This looks kind of interesting

15:34.000 --> 15:35.000
Maybe I'll try it to

15:35.000 --> 15:37.000
Oh wow, I'm writing and learning Gleam

15:37.000 --> 15:39.000
All in your browser without having to

15:39.000 --> 15:41.000
Work at how to install Erlang

15:41.000 --> 15:43.000
And realizing that App has an Alte Deck package

15:43.000 --> 15:45.000
So you can't actually install it properly

15:45.000 --> 15:47.000
And oh how do I install Rebar

15:47.000 --> 15:49.000
And how do I do these things

15:49.000 --> 15:51.000
No, you just go straight in and you can start learning

15:51.000 --> 15:54.000
So hopefully people from other ecosystems

15:54.000 --> 15:56.000
Or people who are writing election Erlang

15:56.000 --> 15:58.000
Can turn up and go

15:58.000 --> 16:02.000
Oh I want to give this Gleam thing a try

16:02.000 --> 16:04.000
And then very quickly

16:04.000 --> 16:07.000
Get whisked into being a Gleam

16:07.000 --> 16:08.000
They can be hooked

16:08.000 --> 16:10.000
They can start working on the beam

16:11.000 --> 16:14.000
And this comes because

16:14.000 --> 16:16.000
A, the compiler is written in Rust

16:16.000 --> 16:19.000
So if you have Rust you can compile to WebAssembly

16:19.000 --> 16:21.000
WebAssembly is a very cool project

16:22.000 --> 16:24.000
And we can also compile to JavaScript

16:24.000 --> 16:26.000
So if you have those two things together

16:26.000 --> 16:28.000
You can run the compiler inside the browser

16:28.000 --> 16:30.000
And you can also execute the code inside the browser

16:30.000 --> 16:32.000
So we don't have to run any servers

16:32.000 --> 16:34.000
So even I can afford this

16:34.000 --> 16:37.000
And we don't have to worry about any security stuff

16:37.000 --> 16:39.000
Everything is just on the person's computer

16:39.000 --> 16:41.000
And it also means it's super fast

16:41.000 --> 16:44.000
You can get your feedback immediately

16:47.000 --> 16:49.000
So Gleam present, I'm going a bit slow

16:49.000 --> 16:51.000
I'm going to speed up a bit

16:51.000 --> 16:53.000
Where are we now?

16:53.000 --> 16:56.000
I want to look at some projects in the community

16:56.000 --> 16:57.000
That are really cool

16:57.000 --> 16:59.000
My original version of this

16:59.000 --> 17:01.000
The talk ended up being about an hour and a half long

17:01.000 --> 17:03.000
So I've had to go loads out

17:03.000 --> 17:05.000
So if you're not mentioned, very sorry

17:05.000 --> 17:07.000
First thing I want to say is that

17:07.000 --> 17:09.000
The Gleam Discord is wonderful

17:09.000 --> 17:12.000
I'm super lucky to have loads of lovely people

17:12.000 --> 17:13.000
Hang out there

17:13.000 --> 17:15.000
I can see some of them here today

17:15.000 --> 17:18.000
And there's just people helping each other

17:18.000 --> 17:19.000
And sharing cool projects

17:19.000 --> 17:20.000
And talking about the news

17:20.000 --> 17:22.000
Or talking about coffee or keyboards

17:22.000 --> 17:23.000
Or anything really

17:23.000 --> 17:25.000
It's a really lovely place to

17:25.000 --> 17:28.000
Either get help or to talk to people

17:28.000 --> 17:30.000
So do join

17:30.000 --> 17:32.000
The community is absolutely wonderful

17:32.000 --> 17:33.000
And delightful

17:33.000 --> 17:36.000
And I'm super lucky to have

17:36.000 --> 17:38.000
Working with them be my job these days

17:38.000 --> 17:40.000
So thank you so much everyone

17:40.000 --> 17:42.000
But now on to the things they've made

17:42.000 --> 17:45.000
The first thing I want to talk and boast about

17:45.000 --> 17:46.000
Is MIST

17:46.000 --> 17:48.000
And MIST is a pure Gleam

17:48.000 --> 17:50.000
HB1.1 server

17:50.000 --> 17:52.000
That sports HBHBS

17:52.000 --> 17:53.000
It has web sockets

17:53.000 --> 17:54.000
I believe

17:54.000 --> 17:56.000
Server-centered events are coming in the next version

17:56.000 --> 17:58.000
And they're working on HB2

17:58.000 --> 18:00.000
So the cool thing about this

18:00.000 --> 18:03.000
Is that it doesn't wrap an Erlang web server

18:03.000 --> 18:05.000
It is pure Gleam

18:05.000 --> 18:07.000
And it doesn't even use Erlang's OTP

18:07.000 --> 18:09.000
It uses Gleam's OTP

18:09.000 --> 18:11.000
It's an entirely new implementation

18:11.000 --> 18:14.000
And what's really cool

18:14.000 --> 18:16.000
Is that it's not just proving that you can use Gleam

18:16.000 --> 18:18.000
To make sophisticated things

18:18.000 --> 18:21.000
You know, implementing a fast HBHBS server

18:21.000 --> 18:23.000
Is quite challenging

18:23.000 --> 18:25.000
But you can also get really good performance

18:25.000 --> 18:26.000
Out of the ever end

18:26.000 --> 18:27.000
So here we've got a bunch of different web servers

18:27.000 --> 18:29.000
Graphed

18:29.000 --> 18:31.000
The ones at the top are MIST and Bandit

18:31.000 --> 18:33.000
Bandit being Elixir's new one

18:33.000 --> 18:36.000
Bandit has had a new version

18:36.000 --> 18:37.000
Since this benchmark was done

18:37.000 --> 18:39.000
So I think it's actually slightly faster now

18:39.000 --> 18:40.000
But they're about the same

18:40.000 --> 18:42.000
You'll notice we're even beating Go

18:42.000 --> 18:43.000
And everyone talks about how Go is super fast

18:43.000 --> 18:46.000
But no, we in the Erlang world can do better

18:46.000 --> 18:48.000
And we're obviously beating JavaScript

18:48.000 --> 18:50.000
But the thing I think is really cool

18:50.000 --> 18:52.000
Is that we are really beating Cowboy

18:52.000 --> 18:54.000
We are really building the one

18:54.000 --> 18:55.000
That we as the community have said

18:55.000 --> 18:57.000
This is the best fastest web server

18:57.000 --> 19:00.000
It shows that we have further that we can do

19:00.000 --> 19:03.000
And it shows that Gleam can be just as performance

19:03.000 --> 19:05.000
As Erlang

19:05.000 --> 19:08.000
So this really proves the language I think

19:08.000 --> 19:10.000
So I mentioned OTP

19:10.000 --> 19:12.000
Gleam has gone a different way for OTP

19:12.000 --> 19:16.000
Then shared out to Fred and his squid there

19:16.000 --> 19:18.000
Gleam has gone a different way with OTP

19:18.000 --> 19:20.000
With most of the other languages

19:20.000 --> 19:24.000
So Elixir and PureRail and other languages

19:24.000 --> 19:25.000
If they want to use OTP

19:25.000 --> 19:28.000
They put a very thin layer on top of Erlang OTP

19:28.000 --> 19:29.000
Well, Gleam doesn't do that

19:29.000 --> 19:33.000
Instead, Gleam takes the core concurrency primitives

19:33.000 --> 19:35.000
That you get from the Erlang runtime system

19:35.000 --> 19:38.000
And has made type safe versions of all of those

19:38.000 --> 19:41.000
And it's the same things like link, sport, monitor

19:41.000 --> 19:43.000
Send, receive

19:43.000 --> 19:45.000
And then it looks at the protocols that are implemented

19:45.000 --> 19:47.000
OTP says you've got to implement certain messages

19:47.000 --> 19:49.000
Like system messages

19:49.000 --> 19:51.000
And there's certain ways of sending

19:51.000 --> 19:53.000
Of doing synchronous requests and all that sort of stuff

19:53.000 --> 19:55.000
And we've implemented those same things

19:55.000 --> 19:57.000
From the ground up in a type safe way

19:57.000 --> 19:59.000
And what's really cool is that we've discovered it's possible

19:59.000 --> 20:00.000
For a long time people have said

20:00.000 --> 20:02.000
You can't have typed OTP

20:02.000 --> 20:04.000
Well, if you get the same

20:04.000 --> 20:07.000
If you get that same core primitives that you get inside Erlang

20:07.000 --> 20:09.000
You can build the same thing from the ground up

20:09.000 --> 20:10.000
So that's been really cool

20:10.000 --> 20:12.000
And the fact that it's been used to make miss

20:12.000 --> 20:13.000
Shows that it can work

20:13.000 --> 20:17.000
And it could be practical and useful in performance

20:17.000 --> 20:19.000
So it's all very good having a web server

20:19.000 --> 20:21.000
But you kind of need a...

20:21.000 --> 20:22.000
Probably need a web framework

20:22.000 --> 20:23.000
Unless you want to spend all your time

20:23.000 --> 20:25.000
Writing a parser for multi-part form bodies

20:25.000 --> 20:27.000
So we have Wisp

20:27.000 --> 20:30.000
Wisp is a really lovely little framework

20:30.000 --> 20:33.000
I can call it lovely because I made it

20:33.000 --> 20:35.000
So if you want to do a web thing

20:35.000 --> 20:37.000
That's a good place to start

20:37.000 --> 20:39.000
Databases are pretty handy as well

20:39.000 --> 20:41.000
We've got bindings for these sort

20:41.000 --> 20:43.000
And probably some others that I haven't found

20:43.000 --> 20:46.000
The first two, Postgres and SQLite

20:46.000 --> 20:47.000
They wrap Erlang projects

20:47.000 --> 20:49.000
All the SQLite one can even work on JavaScript

20:49.000 --> 20:52.000
If you're using Deno

20:52.000 --> 20:54.000
But the bottom two, they're really cool

20:54.000 --> 20:56.000
Because they're, again, written in pure Glean

20:56.000 --> 21:00.000
Using Glean OTP

21:00.000 --> 21:02.000
Now, this is a really cool one

21:02.000 --> 21:03.000
This isn't quite so beamy

21:03.000 --> 21:06.000
But so Glean can compile to JavaScript

21:06.000 --> 21:09.000
Okay, so how do I do a front-end in Glean?

21:09.000 --> 21:12.000
I don't want to be writing all this JavaScript

21:12.000 --> 21:15.000
For my Beam application

21:15.000 --> 21:16.000
If I can avoid it

21:16.000 --> 21:19.000
So Lustre is this really lovely library

21:19.000 --> 21:21.000
That's sort of quite similar to Elm

21:21.000 --> 21:24.000
Or perhaps some React

21:24.000 --> 21:26.000
State management systems

21:26.000 --> 21:29.000
That gives you a way to make a declarative DOM

21:29.000 --> 21:31.000
And then all you need to do is talk about

21:31.000 --> 21:33.000
What messages you're going to emit

21:33.000 --> 21:34.000
And then how you update the state

21:34.000 --> 21:36.000
Every time one of those messages come in

21:36.000 --> 21:38.000
And as an Erlanger, I look at this

21:38.000 --> 21:40.000
And I see a GenServer

21:40.000 --> 21:42.000
I think that the Elm architecture

21:42.000 --> 21:45.000
Is basically exactly the same as an Erlang GenServer

21:45.000 --> 21:47.000
Instead of calling it call, we're calling it

21:47.000 --> 21:50.000
Handlework, we're calling it updates

21:50.000 --> 21:52.000
And then we've got this HTML thing on the side

21:52.000 --> 21:54.000
Which I don't, who knows

21:54.000 --> 21:56.000
But what about live view?

21:56.000 --> 21:57.000
People like live view, right?

21:57.000 --> 21:58.000
That's the hotness at the moment

21:58.000 --> 22:00.000
So live view, in case you don't know

22:00.000 --> 22:02.000
Which I find that you almost certainly

22:02.000 --> 22:03.000
Do know in this room

22:03.000 --> 22:05.000
That's when you have that same sort of idea

22:05.000 --> 22:07.000
You get a declarative DOM that is on your front end

22:07.000 --> 22:09.000
But all your state updating

22:09.000 --> 22:11.000
Where you hold everything is on your back end

22:11.000 --> 22:13.000
And then they talk to each other over WebSockets

22:13.000 --> 22:15.000
And this results in a really lovely develop experience

22:15.000 --> 22:17.000
And you can do all sort of things that you can't

22:17.000 --> 22:20.000
Practically do if all the state is on the front end

22:20.000 --> 22:22.000
Well, us too can do that as well

22:22.000 --> 22:24.000
That last component I showed you

22:24.000 --> 22:26.000
There's nothing that says that has to run on the front end

22:26.000 --> 22:29.000
It could also run on the back end

22:29.000 --> 22:31.000
Just rendering it to HTML

22:31.000 --> 22:33.000
Or you could put it on both

22:33.000 --> 22:35.000
So you could just by saying

22:35.000 --> 22:36.000
Hey, start an actor with this

22:36.000 --> 22:38.000
And then here's WebSockets

22:38.000 --> 22:40.000
You can have live view with Luster

22:40.000 --> 22:43.000
And what's really cool is that you can now pick

22:43.000 --> 22:46.000
Which parts of your application is going to use

22:46.000 --> 22:48.000
Which architecture?

22:48.000 --> 22:49.000
You know, there's a criticism of live view

22:49.000 --> 22:51.000
That it means that certain actions

22:51.000 --> 22:54.000
That should be really snappy are quite slow

22:54.000 --> 22:56.000
And if you lose network connectivity

22:56.000 --> 22:58.000
Your whole application stops working

22:58.000 --> 23:00.000
Well, then maybe put those bits

23:00.000 --> 23:02.000
About making it be resilient to network failures

23:02.000 --> 23:04.000
Put those on the clients

23:04.000 --> 23:06.000
You can pick exactly what you want

23:08.000 --> 23:10.000
So we've got loads of servers and clients

23:10.000 --> 23:13.000
And API clients and middleware

23:13.000 --> 23:16.000
That are all part of this wider HDP ecosystem

23:16.000 --> 23:18.000
And one of the things that's really cool about this

23:18.000 --> 23:21.000
Is that there is a Gleam core library

23:21.000 --> 23:24.000
Called Gleam HDP that defines a few types for

23:24.000 --> 23:27.000
Requests and responses and headers and all these things

23:27.000 --> 23:29.000
And so all of these libraries

23:29.000 --> 23:31.000
Even though they've been made independently

23:31.000 --> 23:33.000
By different people, they can all work together

23:33.000 --> 23:35.000
They all share the same primitives

23:35.000 --> 23:37.000
And you can say, well I want that API client

23:37.000 --> 23:40.000
With that HDP client on the front end

23:40.000 --> 23:42.000
And that HDP client on the back end

23:42.000 --> 23:44.000
And I'm going to handle it with that server in my tests

23:44.000 --> 23:46.000
Fantastic, and it all just nits together

23:53.000 --> 23:55.000
Enough about Web

23:55.000 --> 23:57.000
There's lots of other cool places we can run code

23:57.000 --> 23:59.000
One of them, we probably will do an awful lot

23:59.000 --> 24:01.000
Is on the command line

24:01.000 --> 24:03.000
And there's this really lovely project called T-Shop

24:03.000 --> 24:05.000
Where you can

24:05.000 --> 24:08.000
It's a similar sort of Elm updated type thing

24:08.000 --> 24:10.000
But rather than being events coming from a DOM

24:10.000 --> 24:12.000
It's events coming from a terminal

24:12.000 --> 24:14.000
So you can make these really lovely interactive

24:14.000 --> 24:16.000
Tuis in Gleam

24:16.000 --> 24:18.000
Sadly at the moment you can't run this code on the Beam

24:18.000 --> 24:20.000
Because there's a few

24:20.000 --> 24:22.000
There's a few quirks of how

24:22.000 --> 24:24.000
The Beam handles standard input

24:24.000 --> 24:26.000
But hopefully we can make a proposal to

24:26.000 --> 24:28.000
The OTP team and they can expose

24:28.000 --> 24:30.000
A couple of functions that you can't get to

24:30.000 --> 24:32.000
And then we can have exactly the same thing

24:32.000 --> 24:35.000
In Elixir and Erlang and all sorts of other languages as well

24:37.000 --> 24:39.000
And because I've showed lots of libraries

24:39.000 --> 24:41.000
Let's look at an application

24:41.000 --> 24:43.000
I think this is really cool

24:43.000 --> 24:45.000
This is, I'm going to butcher the name

24:45.000 --> 24:47.000
Electrophonie, maybe

24:47.000 --> 24:50.000
Which is a music streaming app

24:50.000 --> 24:52.000
Similar to Spotify or such

24:52.000 --> 24:55.000
And it is written in Gleam

24:55.000 --> 24:57.000
Part of JavaScript using Luster

24:57.000 --> 25:00.000
And then because we've got this really excellent FFI

25:00.000 --> 25:02.000
So we can call into

25:02.000 --> 25:04.000
So we can call into other languages

25:04.000 --> 25:07.000
And we can use all these web APIs

25:07.000 --> 25:09.000
And do things like use the media keys

25:09.000 --> 25:11.000
Be on the lock screen of a phone

25:11.000 --> 25:14.000
Be in that little bit of the top of your computer

25:14.000 --> 25:16.000
Where the music thing is

25:16.000 --> 25:18.000
I don't know what it's called

25:19.000 --> 25:22.000
And, yeah, the ecosystem is really growing

25:23.000 --> 25:25.000
I think there's a name for that kind of curve

25:25.000 --> 25:27.000
I'm not sure what it is

25:28.000 --> 25:30.000
But we are now 1.2% of hex

25:30.000 --> 25:32.000
Which is a tiny number, but bear in mind

25:32.000 --> 25:34.000
We're not at version one yet

25:34.000 --> 25:36.000
And Elixir's been at version one for 10 years

25:36.000 --> 25:38.000
Something like that

25:38.000 --> 25:40.000
I think that's really impressive

25:40.000 --> 25:42.000
And I really hope that that is going to keep going

25:43.000 --> 25:46.000
So, where are we going?

25:46.000 --> 25:48.000
What comes next?

25:48.000 --> 25:51.000
So, Gleam isn't done

25:51.000 --> 25:54.000
A lot of things are very mature, but there are still things to work on

25:54.000 --> 25:57.000
And the thing I really want to focus on for the next year is the language server

25:57.000 --> 25:59.000
So, what is a language server?

25:59.000 --> 26:02.000
Just to make sure everybody's on the same page

26:02.000 --> 26:06.000
So, traditionally, if you are making a text editor, an IDE

26:06.000 --> 26:08.000
And you want to support a language or a plugin

26:08.000 --> 26:10.000
So that they can support a language

26:10.000 --> 26:13.000
You need to then work at how to learn all those things about the code layer

26:13.000 --> 26:15.000
Oh, how do I know if there's an error?

26:15.000 --> 26:17.000
How do I know what I can auto-complete with?

26:17.000 --> 26:19.000
How do I know what snippets would expand?

26:19.000 --> 26:21.000
How do I know what refactoring is I can do?

26:21.000 --> 26:23.000
You'd have to individually implement all those things

26:23.000 --> 26:27.000
But some clever clogs, I think at Microsoft, came up with this idea of

26:27.000 --> 26:29.000
We're going to have a language server, we're going to define a protocol

26:29.000 --> 26:32.000
That all the editors can speak and all these backends can speak

26:32.000 --> 26:34.000
And all you need to do is implement the protocol

26:34.000 --> 26:37.000
And then suddenly we can have one brain of an editor

26:37.000 --> 26:44.000
And that can talk to Elix and Vim and Emacs and VS Code and Zed

26:44.000 --> 26:46.000
And all these other cool ones

26:46.000 --> 26:47.000
And so we've got one of those

26:47.000 --> 26:51.000
Built into the binary that you get when you download Glim

26:51.000 --> 26:54.000
Excuse me

26:54.000 --> 27:00.000
And it works, but it doesn't work as well as I wanted to

27:00.000 --> 27:03.000
It's definitely the least mature part of the whole GLEE ecosystem

27:03.000 --> 27:05.000
And a big part of that is my fault

27:05.000 --> 27:08.000
I've been developing it entirely on Visual Studio Code

27:08.000 --> 27:13.000
And it means the protocol is a little ambiguous in places

27:13.000 --> 27:16.000
In a way that I find quite irritating but apparently is fine

27:16.000 --> 27:20.000
So all of the editors do slightly different things when you give it certain data

27:20.000 --> 27:23.000
So we need to spend more time working on the other editors

27:23.000 --> 27:25.000
And making sure that it's rock solid and works exactly the same

27:25.000 --> 27:26.000
And all the other ones

27:26.000 --> 27:29.000
And I switched a knee over them now so it's not going to be a problem anymore

27:29.000 --> 27:34.000
So first step, we're going to get it all working super reliably for everybody

27:34.000 --> 27:36.000
And then we're going to flesh it out to have everything

27:36.000 --> 27:40.000
We want to have the same experience that you're going to get with Rust Analyzer

27:40.000 --> 27:44.000
Or maybe even try and get close to what a JetBrains IDE might give you

27:44.000 --> 27:48.000
We want it to be a really excellent experience of all these different things

27:48.000 --> 27:53.000
Find references, renaming things, all sorts of refactorings

27:53.000 --> 27:55.000
And also code generators, I think are really cool

27:55.000 --> 27:59.000
There's loads of bits of trivial code that we bash out every single day about thinking about

27:59.000 --> 28:04.000
Well, if it's that easy, just press a button and have the tooling spit out for you

28:04.000 --> 28:07.000
And then you can choose to edit it in whatever way you want

28:07.000 --> 28:09.000
So breaking changes

28:09.000 --> 28:11.000
Over the last year we've had an awful lot of breaking changes

28:11.000 --> 28:17.000
Because there was a design and then suddenly a bunch of ULOT turned up and now we had users

28:17.000 --> 28:21.000
And then we realised that, oh, actually that original thing that I made up five years ago

28:21.000 --> 28:24.000
While I was sitting in my room wasn't the best idea

28:24.000 --> 28:28.000
There are problems, so we've made a load of breaking changes in order to refine them

28:28.000 --> 28:31.000
What breaking changes are coming next?

28:31.000 --> 28:34.000
Hopefully nothing, I think we're there

28:34.000 --> 28:37.000
I think we basically have the language to work exactly as it should

28:37.000 --> 28:39.000
Which is wonderful

28:39.000 --> 28:42.000
And that kind of begs the question

28:42.000 --> 28:44.000
Does that mean we can work towards a version one?

28:44.000 --> 28:47.000
Yeah, we're working towards a version one

28:47.000 --> 28:48.000
So what does that mean?

28:48.000 --> 28:52.000
When we get there, what's going to be the points of version one?

28:52.000 --> 28:54.000
And I think there are two pillars to this

28:54.000 --> 28:58.000
The first one is productivity for people who are using Gleam

28:58.000 --> 29:00.000
So that's going to be no breaking changes

29:00.000 --> 29:04.000
You can't build on top of foundation that's constantly changing on you

29:04.000 --> 29:06.000
We won't have no language bloat

29:06.000 --> 29:12.000
I'd be really proud of how we've really honed in on what makes Gleam good

29:12.000 --> 29:16.000
And by having a very small, concise, consistent surface area

29:16.000 --> 29:18.000
It makes it easy to work with

29:18.000 --> 29:19.000
And I want to keep that property

29:19.000 --> 29:22.000
I think it's very tempting for languages to hit version one and then go

29:22.000 --> 29:24.000
Oh, maybe we need this feature

29:24.000 --> 29:27.000
Or maybe we need typeplosses, maybe we need these things

29:27.000 --> 29:29.000
No, we're going to keep it super focused

29:29.000 --> 29:32.000
And it's going to say exactly that same language that you really love

29:32.000 --> 29:35.000
Or don't, you know, whatever it is, it's not going to change

29:35.000 --> 29:38.000
And we're going to keep working on improving the developer experience

29:38.000 --> 29:40.000
So more tooling, keep improving that

29:40.000 --> 29:43.000
If there's something that's annoying to do that everyone has to do

29:43.000 --> 29:44.000
Let's make a library for that

29:44.000 --> 29:46.000
You know, just keep solving those problems

29:46.000 --> 29:48.000
And document everything

29:48.000 --> 29:52.000
You know, we want to have cookbooks and guides and tutorials and examples

29:52.000 --> 29:54.000
And just make it really easy for you to go

29:54.000 --> 29:57.000
How do I do this in Gleam?

29:57.000 --> 29:59.000
Oh, look, it says here, here's how I do it

29:59.000 --> 30:01.000
Now I can get on

30:01.000 --> 30:04.000
And the next thing is sustainability

30:04.000 --> 30:06.000
I am not Microsoft

30:06.000 --> 30:09.000
I do not have 50 developers working on this

30:09.000 --> 30:11.000
I have me

30:11.000 --> 30:16.000
And some lovely people who are very kind enough to agree to join the core team

30:16.000 --> 30:19.000
Which means they're just called the core team and they do free work for me

30:19.000 --> 30:22.000
It's fantastic

30:22.000 --> 30:24.000
Thank you very much

30:24.000 --> 30:30.000
So we want to make sure that every bit of work that we're doing is as impactful as possible

30:30.000 --> 30:32.000
You know, it needs to be...

30:32.000 --> 30:36.000
Everything needs to be meaningful

30:36.000 --> 30:39.000
And if we can't justify it as being impactful for a large amount of people

30:39.000 --> 30:41.000
We just shouldn't do it

30:41.000 --> 30:44.000
We've got to make sure everything is efficient as possible

30:44.000 --> 30:46.000
Not just in the code, but in our practices as well

30:46.000 --> 30:48.000
We're going to document everything internal

30:48.000 --> 30:50.000
We're doing really well with this

30:50.000 --> 30:52.000
But I think we can do even better

30:52.000 --> 30:54.000
I would like people to go, oh, there's something...

30:54.000 --> 30:56.000
There's a quirk with the build tool

30:56.000 --> 30:57.000
I think this is a bug

30:57.000 --> 30:59.000
Okay, I'm going to look inside and see what it is

30:59.000 --> 31:01.000
And then just see loads of comments, loads of docs

31:01.000 --> 31:04.000
And then they can hopefully work out, oh, that's doing this, that's doing that

31:04.000 --> 31:06.000
I can make a contribution to this

31:06.000 --> 31:10.000
And the last two things are about funding the project

31:10.000 --> 31:12.000
So I work on this full-time

31:12.000 --> 31:17.000
And I work on this full-time thanks to GitHub sponsors primarily

31:17.000 --> 31:20.000
I really want to...

31:20.000 --> 31:22.000
So here, charted in the pink

31:22.000 --> 31:24.000
That's how much income we have for the project

31:24.000 --> 31:27.000
I'm super happy that it stayed super stable

31:27.000 --> 31:29.000
And up there in blue, that is the median

31:29.000 --> 31:32.000
For a lead developer in London, which is the city I live

31:32.000 --> 31:35.000
I really want to get that up to the blue line

31:35.000 --> 31:37.000
For obvious reasons

31:37.000 --> 31:38.000
But I'd like to do further than that

31:38.000 --> 31:42.000
I'd really like if we could afford to have like one...

31:42.000 --> 31:45.000
Two pizza team, is that too old?

31:45.000 --> 31:48.000
I want to have that core development team

31:48.000 --> 31:52.000
To be able to afford to work on this thing

31:52.000 --> 31:55.000
That I think is useful and important and productive

31:55.000 --> 31:57.000
And be able to work full-time

31:57.000 --> 31:59.000
And be rewarded appropriately

31:59.000 --> 32:01.000
It shouldn't be charity, I think, for these people

32:01.000 --> 32:04.000
They're doing this really useful work for the ecosystem

32:04.000 --> 32:07.000
And then if that stable foundation is there

32:07.000 --> 32:09.000
That means other people feel more confident

32:09.000 --> 32:13.000
Building their businesses and their projects and so on top of that

32:13.000 --> 32:16.000
So if you want to help out, do join the...

32:16.000 --> 32:19.000
Do start sponsoring or get your employer to

32:19.000 --> 32:23.000
So about half of that previous income comes from one place

32:23.000 --> 32:25.000
And that's from Fly, that's our big corporate sponsor

32:25.000 --> 32:27.000
They're the really wonderful deployment platform

32:27.000 --> 32:31.000
And the other half comes from people donating like five, ten, twenty dollars

32:31.000 --> 32:32.000
And they're both wonderful

32:32.000 --> 32:34.000
But it means there's quite a lot of...

32:34.000 --> 32:36.000
There's quite a lot of weights on one organisation

32:36.000 --> 32:38.000
I'd really like to spread that out

32:38.000 --> 32:40.000
So if we could have a bunch of smaller corporate sponsors

32:40.000 --> 32:43.000
I think that would be much better for the long-term health of the project

32:43.000 --> 32:45.000
And if you've got ideas for other things we can do

32:45.000 --> 32:47.000
So I know Elixir has a sort of quasi-support thing

32:47.000 --> 32:48.000
That you can sign up for

32:48.000 --> 32:50.000
If you've got some other ideas, get in touch with me

32:50.000 --> 32:52.000
I'd love to hear what your thoughts are

32:53.000 --> 32:58.000
So when is Glean version one?

32:58.000 --> 32:59.000
How much more have you got to do?

32:59.000 --> 33:02.000
Well the answer is now

33:02.000 --> 33:05.000
We're there, like we're completely ready

33:05.000 --> 33:07.000
And depending on how much you lot distract me

33:07.000 --> 33:08.000
For the next few days

33:08.000 --> 33:11.000
I hope to get a release candidate out today, tomorrow

33:11.000 --> 33:13.000
At some point in the immediate future

33:13.000 --> 33:15.000
So this is a really exciting time

33:15.000 --> 33:27.000
Good, so questions? Any questions?

33:27.000 --> 33:31.000
Thank you very much for creating Glean

33:31.000 --> 33:37.000
Could you elaborate more on what happens when we keep target minus JS?

33:37.000 --> 33:40.000
When we're targeting to JavaScript

33:40.000 --> 33:42.000
Repeat the question

33:42.000 --> 33:44.000
Yes, so the question is

33:44.000 --> 33:47.000
Can I explain what happens when we target compile to JavaScript?

33:47.000 --> 33:50.000
Okay, so we compile to...

33:50.000 --> 33:51.000
What can I say about it?

33:51.000 --> 33:53.000
So we compile to JavaScript source codes

33:53.000 --> 33:55.000
We don't add a runtime

33:55.000 --> 33:57.000
We keep very close to JavaScript

33:57.000 --> 33:59.000
So like your scripts end up being very small

33:59.000 --> 34:01.000
Suitable for use at a browser

34:01.000 --> 34:02.000
But because we don't have a runtime

34:02.000 --> 34:03.000
It means we don't have an implementation

34:03.000 --> 34:07.000
Of say like the Erlang concurrency inside JavaScript

34:07.000 --> 34:09.000
So you'll be using a different concurrency pattern

34:09.000 --> 34:11.000
If you're using Glean JavaScript

34:11.000 --> 34:12.000
If you're using Glean Erlang

34:12.000 --> 34:14.000
And that means there's certain incompatibilities

34:14.000 --> 34:16.000
Between the Erlang and JavaScript target

34:16.000 --> 34:18.000
You can't write a library that easily abstracts over both

34:18.000 --> 34:20.000
If it does file IO for it

34:20.000 --> 34:21.000
Well, that's a bad example

34:21.000 --> 34:26.000
If it does like HTTP requests, for example

34:26.000 --> 34:28.000
But it means, you know, that's the trade-off

34:28.000 --> 34:31.000
But then it means you can work very well with the Erlang...

34:31.000 --> 34:33.000
Sorry, with the JavaScript world

34:33.000 --> 34:36.000
We can run Glean in browser through...

34:36.000 --> 34:37.000
So again, sorry?

34:37.000 --> 34:40.000
Can we run Glean in browser through WebAssembly?

34:40.000 --> 34:43.000
Can you run Glean in browser through WebAssembly?

34:43.000 --> 34:45.000
No, but that's something we want to explore in future

34:45.000 --> 34:48.000
Not because we particularly want to do WebAssembly

34:48.000 --> 34:50.000
Sorry, not because we want to do it in the browser

34:50.000 --> 34:53.000
Because we could already do that with JavaScript

34:53.000 --> 34:56.000
But there's loads of other places you can use WebAssembly

34:56.000 --> 34:59.000
And I wanted to talk about this, but I didn't have enough time

34:59.000 --> 35:01.000
I think it would be really exciting

35:01.000 --> 35:04.000
If we had a good way of executing Glean inside the compiler

35:04.000 --> 35:06.000
Because there's loads of optimizations we can do

35:06.000 --> 35:09.000
We could start looking at certain kinds of like code generation

35:09.000 --> 35:12.000
Meta programming stuff that you can do in Alexa, for example

35:12.000 --> 35:14.000
You can't do in Glean

35:14.000 --> 35:16.000
But we can't do that because we don't have a copy of the beam

35:16.000 --> 35:19.000
This massive thing inside the Glean compiler

35:19.000 --> 35:22.000
So if we had like a little VM, maybe we could do that

35:22.000 --> 35:25.000
And WebAssembly is a really good little VM for this whole thing

35:25.000 --> 35:26.000
Thank you

35:28.000 --> 35:29.000
Any other questions?

35:32.000 --> 35:35.000
Yeah, I do have a question that you might use to point to

35:35.000 --> 35:37.000
I think it's a great question

35:37.000 --> 35:41.000
I think it was in the last year during the episode of code

35:41.000 --> 35:44.000
And it's a really great project

35:44.000 --> 35:50.000
But as you know, I think one of the main parts that draw me to the language

35:50.000 --> 35:54.000
Was the vibrant, pink color

35:54.000 --> 35:57.000
Is there a story behind it?

35:57.000 --> 35:58.000
Is it the color?

35:58.000 --> 36:00.000
Why is Glean pink? Great question

36:01.000 --> 36:02.000
Great question

36:03.000 --> 36:07.000
This was, what is this handle, K-Tec I think is

36:07.000 --> 36:10.000
And he just threw this idea it should be pink

36:10.000 --> 36:12.000
And I was like, oh really, why? That's really odd

36:12.000 --> 36:16.000
And I liked it because it's different

36:16.000 --> 36:18.000
You know, you see this pink and you don't go

36:18.000 --> 36:20.000
You know, if you see a blue you're like, is that TypeScript?

36:20.000 --> 36:23.000
Is it Python? You know, it's visually very different

36:23.000 --> 36:26.000
And the other thing is, I think it's quite friendly

36:26.000 --> 36:28.000
And hopefully it's welcoming to different people

36:28.000 --> 36:30.000
I hope that if someone sees a bright pink thing they go

36:30.000 --> 36:34.000
Oh that's cool, you know, maybe there's not going to be

36:34.000 --> 36:36.000
And it also says like, you know, be nice to each other

36:36.000 --> 36:38.000
No Nazis on the website, you know

36:38.000 --> 36:40.000
I'm hoping people will see that and get an idea of what we're about

36:40.000 --> 36:42.000
We're about being supportive and friendly

36:42.000 --> 36:43.000
And looking after each other

36:43.000 --> 36:46.000
So it's, look different and hopefully say something

36:46.000 --> 36:48.000
About the kind of vibe we want inside the community

36:48.000 --> 36:50.000
Well you work, thank you

36:56.000 --> 36:58.000
I mean, it's probably the best thing about Glean I think

37:01.000 --> 37:04.000
Currently you target both Glean and then Javister

37:04.000 --> 37:08.000
What do you plan to do to introduce other targets like WebAssembly?

37:08.000 --> 37:14.000
So I don't like to look at targets as well as, you know

37:14.000 --> 37:17.000
I think there's a problem and when people make in languages

37:17.000 --> 37:19.000
It's very easy for them to do things that are cool

37:19.000 --> 37:21.000
For a language maker to do

37:21.000 --> 37:24.000
So for example, it would be cool if I could target WebAssembly

37:24.000 --> 37:25.000
It would be cool if I had type classes

37:25.000 --> 37:27.000
I don't want to do it for those reasons

37:27.000 --> 37:30.000
I want to drive changes by them being impactful to the community

37:30.000 --> 37:32.000
And as I said with WebAssembly

37:32.000 --> 37:35.000
That can be a nice VM that you can embed in the compiler

37:35.000 --> 37:38.000
To enable compile time code execution

37:38.000 --> 37:41.000
You could use that to do like Glean script

37:41.000 --> 37:44.000
So you could just have just the binary on your server

37:44.000 --> 37:46.000
And you can use that to execute tiny little scripts

37:46.000 --> 37:49.000
When you don't want to have like a whole virtual machine installed

37:49.000 --> 37:50.000
On that computer for example

37:50.000 --> 37:52.000
All sorts of little things like that

37:52.000 --> 37:55.000
And so I think there is a good

37:56.000 --> 37:58.000
Argument in favour of having WebAssembly

37:58.000 --> 38:00.000
And so it's something and I would quite enjoy it

38:00.000 --> 38:02.000
So I'd like to explore it in future

38:02.000 --> 38:08.000
But it's not as high priority as like getting the language server

38:08.000 --> 38:11.000
Working really well, getting the documentation fantastic

38:11.000 --> 38:13.000
Making sure we've got like a really lovely

38:13.000 --> 38:14.000
Like Elixir Phoenix like experience

38:14.000 --> 38:16.000
To do web development in Glean

38:16.000 --> 38:18.000
So I would like it

38:18.000 --> 38:21.000
Maybe one day, don't hold your breath

38:25.000 --> 38:27.000
When you do message passing in Glean

38:27.000 --> 38:30.000
Does the messages support function cloners as well

38:30.000 --> 38:33.000
And if so, how does your type system handle it?

38:33.000 --> 38:35.000
As in you're asking

38:35.000 --> 38:37.000
When you're doing type OTP

38:37.000 --> 38:40.000
Can you send a function to another process?

38:40.000 --> 38:41.000
Yeah, function cloners

38:41.000 --> 38:43.000
Yes, okay, so

38:46.000 --> 38:48.000
So, it's quite tricky

38:48.000 --> 38:51.000
You can't, how much context do I give this

38:51.000 --> 38:53.000
Because I've thought about this for years

38:53.000 --> 38:54.000
And it's quite hard

38:54.000 --> 38:57.000
Yes, we can, you can pass any data to another function

38:57.000 --> 39:01.000
The key difference between message passing

39:01.000 --> 39:04.000
In typed Glean OTP and Erlang OTP

39:04.000 --> 39:08.000
Is that you need to have more than just a PID

39:08.000 --> 39:10.000
To send a message or something

39:10.000 --> 39:12.000
If you've used languages that have channels

39:12.000 --> 39:15.000
So for example, Go or Rust

39:15.000 --> 39:18.000
You don't just have like the handle for the thread

39:18.000 --> 39:19.000
And pass a message to it

39:19.000 --> 39:20.000
You've got to have a channel

39:20.000 --> 39:22.000
And you send a message via the channel

39:22.000 --> 39:23.000
So it's the same idea

39:23.000 --> 39:25.000
So we have this idea of a subject

39:25.000 --> 39:26.000
We don't call it a channel

39:26.000 --> 39:27.000
Because it would be confusing

39:27.000 --> 39:30.000
Because it still goes to a process inbox

39:30.000 --> 39:32.000
You can't give a channel to a different process

39:32.000 --> 39:34.000
And they start pulling from it

39:34.000 --> 39:37.000
And every channel is the thing that's typed

39:37.000 --> 39:39.000
Not the PID

39:39.000 --> 39:41.000
It looks like you should be able to do the PID

39:41.000 --> 39:43.000
But then you suddenly realize

39:43.000 --> 39:44.000
If you build from the ground up

39:44.000 --> 39:46.000
You can't implement synchronous

39:46.000 --> 39:49.000
You can't implement call, synchronous message passing

39:49.000 --> 39:52.000
If you have typed PIDs

39:52.000 --> 39:54.000
Because the type of the return

39:54.000 --> 39:56.000
Doesn't match the type of the PID

39:56.000 --> 39:57.000
So you need to have something more flexible

39:57.000 --> 39:58.000
So we have this thing

39:58.000 --> 40:00.000
And if you look under the hood in Erlang OTP

40:00.000 --> 40:04.000
They have the same abstraction

40:04.000 --> 40:06.000
We've got 14 seconds left

40:06.000 --> 40:09.000
And it's used to implement GenServit.co

40:09.000 --> 40:10.000
So they have this from thing

40:10.000 --> 40:13.000
So it's the same as the from field in GenServit.co

40:13.000 --> 40:15.000
That's the thing that you send messages around with

40:15.000 --> 40:16.000
I have three seconds left

40:16.000 --> 40:17.000
Thank you very much everybody

40:17.000 --> 40:19.000
Thank you very much

