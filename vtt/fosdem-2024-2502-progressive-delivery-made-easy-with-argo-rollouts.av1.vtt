WEBVTT

00:00.000 --> 00:13.000
Thank you for being here.

00:13.000 --> 00:25.000
I'm going to talk about progressive delivery and hopefully by the end of this talk you're going to know how to easily do canary deployments on Kubernetes.

00:25.000 --> 00:30.000
Who is using Kubernetes today?

00:30.000 --> 00:33.000
Raise your hand, please. Everybody.

00:33.000 --> 00:38.000
I'm not asking if everybody knows what Kubernetes is because you're in the wrong place.

00:38.000 --> 00:45.000
I'm a principal scientist on the Adobe Experience Manager Cloud Service. This is a content management system.

00:45.000 --> 00:53.000
I'm a long time open source contributor to Maven, Jenkins, Puppet, a few other things.

00:53.000 --> 00:58.000
I'm also part of the Google Developer Experts Program.

00:58.000 --> 01:05.000
But probably most of you know me because of what I did with Jenkins on Kubernetes.

01:05.000 --> 01:12.000
Some people will love it. Some people will hate me. We'll talk about that later.

01:12.000 --> 01:20.000
Actually, I just, before this talk, 15 minutes before, I realized, oh, this is 10 years ago.

01:20.000 --> 01:26.000
Time flies when people didn't know what Kubernetes was.

01:26.000 --> 01:30.000
So, what is progressive delivery?

01:30.000 --> 01:35.000
This also came, this was August 2018.

01:35.000 --> 01:40.000
This is when the term was coined at the LaunchDarly blog.

01:40.000 --> 01:44.000
And also was picked up by Red Monk.

01:44.000 --> 01:49.000
And I said, this is a great name for these things that everybody knows about.

01:49.000 --> 01:53.000
But the name kind of sums up very well what we're trying to do.

01:53.000 --> 01:58.000
So, I said, I'm going to steal this. That's the gist of it.

01:58.000 --> 02:02.000
So, it includes deployment strategies that avoid this.

02:02.000 --> 02:09.000
I'm going to push this to all my nodes, all my containers, all my files, whatever it is that you're running.

02:09.000 --> 02:12.000
I'm going to push this new version to all of them.

02:12.000 --> 02:17.000
And if it breaks, it breaks for everybody, we want to avoid that.

02:17.000 --> 02:24.000
So, you, with progressive delivery, you have new versions that do not replace the system versions.

02:24.000 --> 02:30.000
And you have both old and new versions running in parallel for an amount of time.

02:30.000 --> 02:35.000
But the interesting part is that this is happening in production.

02:35.000 --> 02:43.000
And you can evaluate both old version, new version during a period of time that you figure out what was the best time for you.

02:43.000 --> 02:52.000
And before saying that this is a successful thing that I need to roll to everybody in all my customers.

02:52.000 --> 02:59.000
So, continuous delivery is hard. I used to say, like, progressive delivery makes it continuous delivery easier to adopt.

02:59.000 --> 03:02.000
Because it reduces a lot of the risk associated with continuous delivery.

03:02.000 --> 03:07.000
Yeah, it's great that you commit something to main and it gets pushed to everybody.

03:07.000 --> 03:17.000
But what if that's breaking in production? Then you have these methods behind progressive delivery that will prevent you from breaking things.

03:17.000 --> 03:26.000
And give you these guardrails that will protect your users.

03:26.000 --> 03:31.000
The key points, avoiding downtime, limit the blast radius.

03:31.000 --> 03:36.000
You deploy something, it only affects a subset of your users, not all of them.

03:36.000 --> 03:40.000
And also shorten the time from your idea to production.

03:40.000 --> 03:47.000
So, from the time you create a commit until you push it to production, you can use these techniques.

03:47.000 --> 03:52.000
So, you can shorten really as much as possible that time.

03:52.000 --> 03:59.000
And it's not affecting your life customers, it could affect your maybe internal customers, employees, something like that.

03:59.000 --> 04:03.000
So, you can confidently push things to production.

04:03.000 --> 04:09.000
The name is great, but all the techniques already existed for a long time.

04:09.000 --> 04:18.000
We have rolling updates on Kubernetes. This is the standard way when you change something on your deployments.

04:18.000 --> 04:25.000
You just get a new pod with a new version. When that pod comes up, the old pods start going away.

04:25.000 --> 04:29.000
And you can configure that easily on Kubernetes.

04:29.000 --> 04:36.000
You can configure how many pods you want to come up, if you want them to come up a little by a little.

04:36.000 --> 04:41.000
If you want all of them to come up at once, and they will start rolling.

04:41.000 --> 04:51.000
So, Kubernetes has been around.

04:51.000 --> 04:56.000
Blue-green deployments, same thing. It's been around forever.

04:56.000 --> 04:59.000
Well, defined for some definition of ever.

04:59.000 --> 05:08.000
And you have green, what you consider the old version, which is green, the new version, which is blue, or the other one, we're on, I don't know.

05:08.000 --> 05:12.000
And you have both running at the same time.

05:12.000 --> 05:18.000
You evaluate or you start sending traffic to the new version.

05:18.000 --> 05:23.000
And if something happens, you just have to flip the switch to put back to the old version.

05:23.000 --> 05:27.000
So, this is a variation.

05:27.000 --> 05:33.000
The difference is, in a couple of days, you don't need to have all the machines running at the same time, all the containers.

05:33.000 --> 05:43.000
With blue-green, you need to have room for both versions running at the same time.

05:43.000 --> 05:54.000
Canary deployment is one of the most interesting ones, where you send a percentage of the traffic or a percentage of your users to the new version,

05:54.000 --> 05:58.000
and a percentage, a small percentage to the new version, and you keep growing.

05:58.000 --> 06:06.000
I mean, you could just do a small percentage, or you could keep growing that canary percentage.

06:06.000 --> 06:08.000
A lot of companies do this.

06:08.000 --> 06:22.000
First, this gets deployed to internal employees only, then some countries, some like New Zealand, or a percentage of users, depending on some characteristics of them.

06:22.000 --> 06:31.000
And they keep growing this canary pool over time until you reach 100%.

06:31.000 --> 06:41.000
Feature Flags, another interesting one, where it allows you to push things to production behind Feature Flags, so you can test them in production.

06:41.000 --> 06:46.000
And also, disable them after you deploy them.

06:46.000 --> 06:59.000
You push something, you realize, either it breaks for a lot of users, or it breaks for a percentage of users, you can switch that feature off using some tools,

06:59.000 --> 07:03.000
or using something as simple as environment variables.

07:03.000 --> 07:15.000
But yeah, there's tools that allow you to manage Feature Flags, so you don't have to deal with environment variables, things like that.

07:16.000 --> 07:24.000
Monitoring is the new testing, so you know the goal is to know when the users are experiencing issues in production,

07:24.000 --> 07:29.000
and the other characteristic, I think, is they react to the issues automatically.

07:29.000 --> 07:41.000
So if you deploy something that is bad, how you can automatically roll it back before some human has to go and figure out what happened.

07:42.000 --> 07:46.000
So did you know that 90% of the outages could be solved?

07:46.000 --> 07:50.000
There's a study that said 90% of the outages could be solved with progressive delivery.

07:50.000 --> 07:53.000
Did you know that? No? Because I just made that up.

07:57.000 --> 08:02.000
And one thing they need is, yeah, some requirement is having a good amount of metrics,

08:02.000 --> 08:06.000
or you need to know what's happening in your production system before you can react,

08:06.000 --> 08:13.000
knowing what users are seeing the new version, what users are breaking with the new version, what's happening here.

08:13.000 --> 08:15.000
So you need to have this visibility.

08:17.000 --> 08:23.000
And I always love to plug Devos Barat, which disappeared from the Twitter server,

08:23.000 --> 08:29.000
to make your resumant to prepogator or in-law server in automatic way, that's what DevOps is.

08:29.000 --> 08:33.000
Raise your hand if you have broken a lot of servers by doing this automatically.

08:36.000 --> 08:42.000
So yeah, what I love to say is if you're breaking something automatically,

08:42.000 --> 08:44.000
is that you haven't automated enough.

08:44.000 --> 08:47.000
I think that's the...

08:47.000 --> 08:50.000
When you get there, it's like, okay, maybe I should step back a little bit.

08:50.000 --> 08:52.000
Until you get there, you keep automating things.

08:55.000 --> 08:59.000
Now, more to the practical side, how can I do this in Kubernetes?

09:00.000 --> 09:06.000
Introduction, who's familiar with Ingress?

09:06.000 --> 09:09.000
Ingress in Kubernetes, okay, yes.

09:09.000 --> 09:12.000
Then, 10 years ago, this was not like this.

09:14.000 --> 09:18.000
So on Kubernetes, you have the load balancer, and you can have services,

09:18.000 --> 09:23.000
and from the load balancer, Kubernetes will send you to one service or another.

09:23.000 --> 09:27.000
So your load balancer would send traffic to one service or another.

09:28.000 --> 09:30.000
But this was kind of the old way.

09:30.000 --> 09:34.000
The new way is you have Ingress controllers on Kubernetes,

09:34.000 --> 09:38.000
where the Ingress controller is running on Kubernetes.

09:40.000 --> 09:45.000
I typically domain names, but you could also do headers.

09:45.000 --> 09:47.000
For each of these traffic, it's easy.

09:47.000 --> 09:50.000
You can do headers, you can do all sorts of things.

09:51.000 --> 09:55.000
And that Ingress is sending the traffic to whatever service you're running.

09:55.000 --> 09:59.000
So you can have one service A, one service B, and with their pods.

09:59.000 --> 10:03.000
And the Ingress is the one that's, okay, you configure this domain to go to the service,

10:03.000 --> 10:05.000
you configure this domain to go to this other server.

10:07.000 --> 10:09.000
And there's a lot of Ingress controllers out there.

10:11.000 --> 10:16.000
If you run on a cloud provider, you're going to have the AWS, the GC, whatever.

10:16.000 --> 10:23.000
And then you can have your own NGINX, ambassador, STO, traffic.

10:24.000 --> 10:25.000
That's a lot of it.

10:28.000 --> 10:31.000
And ARGO rollouts, anybody using ARGO?

10:32.000 --> 10:33.000
Wow, okay.

10:37.000 --> 10:38.000
What are you doing here?

10:38.000 --> 10:40.000
I mean, we already know this.

10:41.000 --> 10:44.000
So provides advanced deployment capabilities.

10:45.000 --> 10:48.000
All the things that I mentioned, blue, green, canary,

10:48.000 --> 10:52.000
category analysis, experimentation, there are variations over the same thing.

10:53.000 --> 10:58.000
ARGO rollouts provides that to you and makes it very easy to do it.

10:59.000 --> 11:03.000
And the good thing is you don't need to use ARGO CD, for it to use ARGO rollouts.

11:03.000 --> 11:06.000
You don't actually need to use anything else to use ARGO rollouts.

11:06.000 --> 11:10.000
You can run ARGO rollouts just with Kubernetes, nothing else.

11:10.000 --> 11:13.000
You don't need external dependencies.

11:14.000 --> 11:18.000
And, yeah, it allows you to do this very easily.

11:20.000 --> 11:22.000
I'm a bit on the architecture of ARGO rollouts.

11:22.000 --> 11:27.000
So we have the controller that is watching a new object called a rollout.

11:28.000 --> 11:36.000
So ARGO rollouts has this object that can replace or complement your existing deployments.

11:37.000 --> 11:40.000
And I think I'll go down there in a bit.

11:41.000 --> 11:45.000
So this rollout manages the replica sets.

11:46.000 --> 11:51.000
So these replica sets, typically, you would have your deployments with the replica sets,

11:52.000 --> 11:54.000
and now they become part of the rollout.

11:55.000 --> 12:03.000
And it has the concept of analysis run that will check metrics or any other external source

12:03.000 --> 12:09.000
that this analysis will decide is this rollout successful or not.

12:10.000 --> 12:16.000
And based on that, it's going to cancel the rollout or keep it going.

12:18.000 --> 12:21.000
So you get the traffic coming from the ingress into your services,

12:21.000 --> 12:30.000
and you can tell ARGO, OK, send me, send traffic to this new canary replica set

12:30.000 --> 12:32.000
or send it to the old one.

12:32.000 --> 12:36.000
The percentage base one, for that, you need a service match.

12:36.000 --> 12:41.000
So if you need to do something fancy like, oh, I want to send 1% of the traffic

12:41.000 --> 12:44.000
or I want some traffic that matches this header,

12:44.000 --> 12:47.000
then you need something like a service match

12:47.000 --> 12:52.000
or the integration with the ARGO rollouts integration with the ingress controller.

12:53.000 --> 13:02.000
But if you use bare Kubernetes without integration between rollouts, you can still do it.

13:03.000 --> 13:07.000
Basically, it will use the number of pods in the replica sets.

13:07.000 --> 13:15.000
So if you have 10 pods, you can tell ARGO, OK, one new pod is going to go to the new version,

13:15.000 --> 13:20.000
and now you have a 10%, 90% sort of split, more or less.

13:20.000 --> 13:25.000
You cannot do things fancy that require support from the ingress controller or a service match,

13:25.000 --> 13:27.000
but you can still do things.

13:28.000 --> 13:33.000
The rollout object, you have two ways of defining the rollout.

13:33.000 --> 13:38.000
One is you replace the deployment with the rollout and add extra fields,

13:38.000 --> 13:41.000
or you create a rollout that points to a deployment.

13:42.000 --> 13:46.000
I don't like a lot the way of replacing the deployment

13:46.000 --> 13:51.000
because then people that are not aware of the rollouts objects,

13:51.000 --> 13:54.000
they may go and see, oh, there's no deployments.

13:54.000 --> 13:56.000
What's going on here?

13:56.000 --> 14:00.000
So it requires you changing things.

14:00.000 --> 14:04.000
And for us, it requires also you have to change rambles,

14:04.000 --> 14:08.000
you have to change commands that people need to secure documentation and all that.

14:08.000 --> 14:11.000
So I don't know why the decision was made that way,

14:11.000 --> 14:16.000
but it's not something that I'm too happy about it.

14:16.000 --> 14:21.000
Of course, you require all the Jamel tools to write these things.

14:22.000 --> 14:25.000
And let's go to the demo now.

14:33.000 --> 14:35.000
So I have here...

14:46.000 --> 14:49.000
So I'm running the Argo Rollouts demo.

14:49.000 --> 14:54.000
This is hitting the backend and it's returning one color or another,

14:54.000 --> 14:57.000
depending on what is running on the backend.

14:57.000 --> 15:00.000
So right now I have the blue one.

15:04.000 --> 15:07.000
Let me see how can I do this easier.

15:12.000 --> 15:14.000
So what I'm going to do is to change,

15:14.000 --> 15:18.000
update my deployment to use a new image that is going to be green.

15:19.000 --> 15:24.000
And ring.

15:39.000 --> 15:42.000
I lost the terminal.

15:49.000 --> 15:55.000
Okay, so it updated the image and let me fit here in big

15:59.000 --> 16:01.000
To show what this is doing.

16:01.000 --> 16:17.000
Okay, I think I pushed twice and now I see two

16:17.000 --> 16:20.000
Rollouts happening at the same time.

16:20.000 --> 16:22.000
Otherwise it's not working.

16:22.000 --> 16:24.000
Here it is.

16:24.000 --> 16:33.000
Okay, so I have the green.

16:33.000 --> 16:38.000
The one that shows green is the one that was running and it's stable.

16:38.000 --> 16:43.000
So I think I have five pots running and I push a new change,

16:43.000 --> 16:45.000
which is the canary.

16:45.000 --> 16:51.000
And this should be using the green.

16:51.000 --> 16:53.000
Okay, there it is.

16:53.000 --> 16:58.000
So like 20% of the traffic is getting green.

16:58.000 --> 17:00.000
Right?

17:00.000 --> 17:05.000
And how I define this rollout, this one is at the bottom is

17:05.000 --> 17:09.000
just the standard deployment configuration.

17:09.000 --> 17:11.000
So what image do I want?

17:11.000 --> 17:14.000
What ports do I want to expose and so on.

17:14.000 --> 17:20.000
But at the top I have the strategy configuration from

17:20.000 --> 17:22.000
Marco rollouts.

17:22.000 --> 17:26.000
So I can say point to this analysis template.

17:26.000 --> 17:30.000
This is what defines what is successful, what is not successful.

17:30.000 --> 17:33.000
And I'll show you that in a bit.

17:33.000 --> 17:37.000
And it's, I have several steps.

17:37.000 --> 17:43.000
So set weight 20 and then do a pause, set weight 40,

17:43.000 --> 17:46.000
pause for 10 seconds, set weight 60.

17:46.000 --> 17:48.000
So this is percentage.

17:48.000 --> 17:52.000
Pause for 10 seconds, set weight 80.

17:52.000 --> 17:56.000
So this is my definition of a rollout.

17:56.000 --> 17:59.000
20% wait for me to manually do something.

17:59.000 --> 18:01.000
I only do that for demos in real life.

18:01.000 --> 18:05.000
That's a bit harder to do as you could still do it.

18:05.000 --> 18:09.000
But this is my definition of what the rollout is.

18:09.000 --> 18:12.000
So right now it's waiting because I set a pause and it's waiting

18:12.000 --> 18:14.000
for me to give you a key.

18:14.000 --> 18:16.000
I look at it, it says it looks okay.

18:16.000 --> 18:20.000
So I can do the promote.

18:20.000 --> 18:29.000
And this is going to continue through the rest of the steps.

18:29.000 --> 18:33.000
So hopefully we'll see this in like 60 seconds.

18:33.000 --> 18:43.000
It should continue the progression until everybody receives a green.

18:43.000 --> 18:47.000
A green color when they call the API.

18:47.000 --> 18:52.000
So this shows you just by creating a rollout object with this

18:52.000 --> 18:57.000
small section defining what your rollout is, you can do this.

18:57.000 --> 18:58.000
There's nothing else you need.

18:58.000 --> 19:00.000
Well, you need to install Argo.

19:00.000 --> 19:04.000
And what else can you do?

19:04.000 --> 19:09.000
Oh, yes, you can also have a preview version.

19:09.000 --> 19:12.000
So you can have another ingress pointing to your preview version.

19:12.000 --> 19:18.000
So you can even if I said I want zero traffic to go to the new version.

19:18.000 --> 19:22.000
All the existing traffic I wanted to go to the old version,

19:22.000 --> 19:25.000
but I want to see the new version in a new place.

19:25.000 --> 19:26.000
I can do that too.

19:26.000 --> 19:31.000
So that's very useful for preview environments sort of thing.

19:31.000 --> 19:34.000
So if I go back, okay.

19:34.000 --> 19:39.000
So while this continues running, this is running on Google Kubernetes

19:39.000 --> 19:45.000
and sending autopilot clusters, but you can run it in any Kubernetes.

19:45.000 --> 19:52.000
And the autopilot is pretty cool because you only pay for what you use.

19:52.000 --> 19:58.000
So if you scale things to zero, then you don't pay anything.

19:58.000 --> 20:00.000
What does it says here?

20:00.000 --> 20:01.000
Okay.

20:01.000 --> 20:03.000
So now green is the stable one.

20:03.000 --> 20:08.000
It says here, stable here.

20:08.000 --> 20:13.000
What if I want to do...

20:13.000 --> 20:17.000
I was talking about how does this protect me, right?

20:17.000 --> 20:23.000
What if I want to do a rollout that is broken?

20:23.000 --> 20:25.000
So...

20:25.000 --> 20:27.000
Let's see.

20:27.000 --> 20:29.000
This works.

20:29.000 --> 20:32.000
Right.

20:32.000 --> 20:34.000
Okay.

20:34.000 --> 20:37.000
So now I push an image that is bad.

20:37.000 --> 20:39.000
So I'm changing the deployment.

20:39.000 --> 20:41.000
Of course, you would do this with the GitOps.

20:41.000 --> 20:44.000
You would never push the production, but YOLO.

20:44.000 --> 20:53.000
And so I'm pushing the red image, but this red image is returning in 500 errors.

20:53.000 --> 21:03.000
And now Argo realized, oh, this is giving errors based on my analysis template that I'll show you.

21:03.000 --> 21:06.000
And this is in the graded status.

21:06.000 --> 21:14.000
And it went down and the scale it down, and my canary was set as failed.

21:14.000 --> 21:19.000
And you see that only a few percentage of traffic got the red dots,

21:19.000 --> 21:22.000
and then it was automatically rolled back.

21:22.000 --> 21:27.000
So I think this is the power of doing progressive delivery.

21:27.000 --> 21:32.000
Of course, this is very easy if your application is exploding.

21:32.000 --> 21:34.000
It's very easy to see.

21:34.000 --> 21:40.000
It's like, what if people ask me, oh, can we do this if a button doesn't work?

21:40.000 --> 21:41.000
Can we do this?

21:41.000 --> 21:43.000
Well, it depends what button.

21:43.000 --> 21:50.000
If it's the button that adds, imagine you're in Amazon, you break the button that adds things to the cart,

21:50.000 --> 21:53.000
and you get a metric that says nobody's adding things to the cart,

21:53.000 --> 21:55.000
maybe you're like, oh, something is really bad.

21:55.000 --> 21:57.000
Right.

21:57.000 --> 22:03.000
So let me show you the analysis template.

22:03.000 --> 22:08.000
Is this one?

22:08.000 --> 22:09.000
Yeah.

22:09.000 --> 22:16.000
In my case, my analysis template is a very complicated call that fails if this fails,

22:16.000 --> 22:18.000
if this doesn't return a 200.

22:18.000 --> 22:24.000
But again, you can integrate this with whatever you want, metrics.

22:24.000 --> 22:31.000
Argo rollouts also gives you a nice dashboard.

22:31.000 --> 22:35.000
If you are not into the command line, you can come here.

22:35.000 --> 22:40.000
And here.

22:40.000 --> 22:46.000
So where I can see the status of my rollout, what is strategy.

22:46.000 --> 22:52.000
As I said, Argo rollout supports multiple strategies on some of the more complex drivers.

22:52.000 --> 23:00.000
I can see my steps that I showed you before in the Jamel, 20, 40, 50, 80.

23:00.000 --> 23:06.000
And I can say what was the last image that I pushed,

23:06.000 --> 23:18.000
and I could click here and do the clickity clock instead of doing Jamel.

23:18.000 --> 23:23.000
Okay.

23:23.000 --> 23:28.000
So, yeah, what I mentioned before was if you're using service mesh,

23:28.000 --> 23:32.000
like Istio, then it integrates with a bunch of service mesh

23:32.000 --> 23:33.000
ingress providers.

23:33.000 --> 23:37.000
So you could go and say, I want 1% of traffic because Istio supports

23:37.000 --> 23:42.000
doing those things instead of saying more, because when you are using

23:42.000 --> 23:45.000
only pods, you don't have anyone here.

23:45.000 --> 23:48.000
Pod is going to receive the traffic or not.

23:48.000 --> 23:52.000
So it's more of an approximation.

23:52.000 --> 23:57.000
But with Istio and other advanced things, you can do more complex.

23:57.000 --> 24:06.000
We hook it up with Prometheus, also the support for multiple things to get metrics from.

24:06.000 --> 24:13.000
And, yeah, hopefully you'll learn how to do a progressive delivery

24:13.000 --> 24:16.000
canary deployment very easily.

24:16.000 --> 24:20.000
Just you need to do some Jamel here and there.

24:20.000 --> 24:24.000
Let me see.

24:24.000 --> 24:29.000
On here, this one.

24:29.000 --> 24:34.000
So you can have the other labels to the existing version,

24:34.000 --> 24:37.000
to the stable version as labels to the new version.

24:37.000 --> 24:41.000
So you can do other things with services on Kubernetes.

24:41.000 --> 24:50.000
You can pass what analysis you want to run and you set what steps to run.

24:50.000 --> 24:53.000
And everything else is just the template.

24:53.000 --> 24:55.000
And if in the deployment template.

24:55.000 --> 24:58.000
If you don't want to put the deployment template in the rollout object,

24:58.000 --> 25:03.000
you just point here, there's another option that says points to existing deployment.

25:03.000 --> 25:08.000
The only problem with that is that rollouts is not when you're migrating,

25:08.000 --> 25:11.000
rollouts is not going to scale down the deployment.

25:11.000 --> 25:15.000
A colleague of mine, she submitted a PR to Argus,

25:15.000 --> 25:17.000
which is going to be in the next version.

25:17.000 --> 25:22.000
So it will automatically, if you have like thousands of deployments,

25:22.000 --> 25:25.000
when you spin out a rollout with a deployment,

25:25.000 --> 25:28.000
I pointed to a deployment, when the rollout is successful,

25:28.000 --> 25:30.000
it's going to scale down the deployment.

25:30.000 --> 25:35.000
So that's how it will actually exist.

25:35.000 --> 25:44.000
Okay, so, yeah, and what's that thing?

25:44.000 --> 25:52.000
I lost my...

25:52.000 --> 25:55.000
Did I close it?

25:55.000 --> 26:08.000
Yeah.

26:08.000 --> 26:13.000
Okay, so, just a quick summary, you saw everything?

26:13.000 --> 26:22.000
And I hope that this helped you and you can try it and do it at home if you like it.

26:22.000 --> 26:26.000
And I have time for asking me two questions.

26:26.000 --> 26:30.000
Two questions.

26:30.000 --> 26:32.000
No questions. One question.

26:32.000 --> 26:39.000
I was wondering if you've been testing using the gateway API and some fingers in the waiting?

26:39.000 --> 26:43.000
So the question is if I tested using the gateway API instead of fingers,

26:43.000 --> 26:47.000
no, I have not been using the API yet,

26:47.000 --> 26:52.000
but I'm guessing that if there's no support already, there will be.

26:52.000 --> 26:58.000
Because...

26:58.000 --> 27:00.000
We did not.

27:00.000 --> 27:06.000
Yeah.

27:06.000 --> 27:14.000
Hello. So my question is that for, in case of buggy rollout,

27:14.000 --> 27:20.000
the particular traffic which is forward to the buggy instances,

27:20.000 --> 27:30.000
is it possible to automatically replicate it and send it to the stable versions after the fail?

27:30.000 --> 27:38.000
To ensure that even the traffic which hits the buggy rollout instances

27:38.000 --> 27:44.000
is served later by stable versions?

27:44.000 --> 27:46.000
So if it's...

27:46.000 --> 27:50.000
It's possible to run it back automatically, but also...

27:50.000 --> 27:54.000
Yeah, the individual traffic, individual request.

27:54.000 --> 27:58.000
So you don't want any user to see the spot?

27:58.000 --> 28:00.000
Yes.

28:00.000 --> 28:08.000
The other thing you could do, if you use a service mess,

28:08.000 --> 28:16.000
probably is send a clone the traffic and send a clone to the new version,

28:16.000 --> 28:19.000
but the actual traffic is going to the old version.

28:19.000 --> 28:23.000
And you could see if the new version is breaking or not.

28:23.000 --> 28:29.000
But also that's tricky because you need to make sure that it's not changing your state.

28:29.000 --> 28:34.000
If you are getting gets, it's fine if you are changing status.

28:34.000 --> 28:41.000
That's my point. Don't do the duplication in advance because it will go to the parallel execution,

28:41.000 --> 28:48.000
but do it only when the first execution failed because it's go to the canary instance.

28:48.000 --> 28:50.000
Yeah, I think you can do that.

28:50.000 --> 28:57.000
Send traffic to the new version, but it's a copy of the traffic that is not seen by any user.

28:57.000 --> 29:02.000
And then at some point you could say, okay, this is good. I'm promoting this.

29:02.000 --> 29:04.000
I think it's doable.

29:04.000 --> 29:06.000
Yeah, thank you.

29:06.000 --> 29:08.000
Okay.

29:27.000 --> 29:29.000
Thank you.

29:57.000 --> 30:00.000
Thank you.

