WEBVTT

00:00.000 --> 00:12.000
Next, we have Nishant and Mike with aerodynamic data models flying fast at the scale of DuckDV.

00:12.000 --> 00:23.000
Okay. Thanks so much. Great to be here. I'm Mike Driscoll. I'm the co-founder and CEO of Rail Data.

00:23.000 --> 00:34.000
Here with my colleague Nishant, also co-founder of Rail Data, and we're going to be talking about DuckDB and making super fast data applications with DuckDB.

00:34.000 --> 00:45.000
So really quickly, we're going to just talk about our product vision and how we ended up choosing a fast engine, ultimately what the criteria were for DuckDB.

00:45.000 --> 00:58.000
And then we're going to talk a little bit about some of the optimizations that we've made at the application data model and data engine layer to get Rail to be super fast for our needs.

00:58.000 --> 01:03.000
So I am going to be brave enough to do a live demo here, so we'll see how that goes.

01:03.000 --> 01:11.000
But first, what is Rail? Rail is an operational BI tool. A lot of BI tools out there, so what makes us different?

01:11.000 --> 01:23.000
Well, first of all, we have faster dashboards. We co-locate the data and compute. Queries are instant, even at billion record scale.

01:23.000 --> 01:35.000
We embrace BI as code, deploy globally but develop locally with GitHub workflows, and we do all of the ETL and SQL, and we embrace a metrics first philosophy.

01:36.000 --> 01:41.000
So all of the visualizations that you'll see here are automatically generated.

01:41.000 --> 01:51.000
So let's get into it. Let's do a demo. If you want to try it at home or in the safety of your own laptop, you can install Rail with that single curl command.

01:51.000 --> 01:59.000
And I'll go ahead and do that here. So I've already installed Rail, so we'll just go ahead and get started.

01:59.000 --> 02:10.000
So let's imagine we've downloaded it here, and I'm just going to run Rail, Start, my Fosden demo. Let's get that moving.

02:10.000 --> 02:22.000
So that's going to fire up a web browser here. And what I'm actually going to do is I'm going to show how we can basically add data, a source.

02:22.000 --> 02:30.000
This is going to be just a local file here because that's what I've got access to. So this is basically a Parquet file called GCP consumption metrics.

02:30.000 --> 02:39.000
It's got basically data from GCP that I collected on our cloud usage. I'm going to bring that in as a source.

02:39.000 --> 02:49.000
And what you'll see here is pretty fast. We imported 4.4 million records, and we can actually, with one click here, we're going to build a dashboard.

02:49.000 --> 02:56.000
So it's 4.5 million records with about seven columns. There's a timestamp there. Let's auto-generate a dashboard.

02:56.000 --> 03:05.000
And instantly we can look at some trends in this GCP data. Again, these are automatically generated dashboards.

03:05.000 --> 03:15.000
I'm actually going to zoom in on a particular area of the data here. And Rail lets me kind of slice and dice this data.

03:15.000 --> 03:24.000
I can take a look at what I've been paying for cloud storage. Wow, it looks like something was going on there sometime in 2021.

03:24.000 --> 03:30.000
I can zoom into that if I wanted to drill further and find out if there's a particular skew that was driving that.

03:30.000 --> 03:36.000
I can kind of get some insights with that, break this down and look at period over period comparisons.

03:36.000 --> 03:42.000
There's a lot of visualizations I can do. I can even create pivot tables here in Rail.

03:42.000 --> 03:53.000
And that's something that we've spent some time launching. But I won't go much further into Rail because we've only got a lightning talk here.

03:53.000 --> 04:02.000
I'm going to turn it over to my colleague, Nishant, to talk a little bit about what we've done to make Rail work really fast with DuckDB.

04:02.000 --> 04:11.000
Thanks, Mike. So there have been a lot of optimizations that we have done in order to make it snappy and faster, specifically at scale.

04:11.000 --> 04:21.000
So we have a three-in-one architecture where Rail starts with, as Mike showed, connecting to a source of data, then loading that source of data into Rail,

04:21.000 --> 04:29.000
storing that into an in-memory database, DuckDB, and then running these operational BI dashboards on the top.

04:30.000 --> 04:38.000
So why we chose DuckDB? What were our requirements? How we came to use DuckDB?

04:38.000 --> 04:47.000
There are a couple of things why we like DuckDB. The first one is speed. We were able to profile tens of GBs of data on your local laptop.

04:47.000 --> 04:53.000
So the demo we showed was just offline on this laptop only with subsequent performance.

04:53.000 --> 05:00.000
It's simple and lightweight, so it can be embedded into a very small binary size, which could be downloaded and easily started.

05:00.000 --> 05:06.000
It can scale up to hundreds of concurrent queries and scale up to hundreds of GBs of data.

05:06.000 --> 05:14.000
So the dashboard that you saw, there were almost 50-plus queries that were fired concurrently from that dashboard when that was loaded.

05:14.000 --> 05:22.000
Rail is open source, and we love open source technologies, so is DuckDB. So that was also one of the reasons to choose DuckDB as well.

05:22.000 --> 05:27.000
Here is another snapshot of DuckDB commits. This is again like a real dashboard.

05:27.000 --> 05:33.000
It's hosted on this demo URL if you want to dig further and slice and dice the different commits on GitHub.

05:33.000 --> 05:40.000
You can do that as well, but you can see that there are over 350 contributors on the DuckDB project, which is really great,

05:40.000 --> 05:44.000
and there is a good velocity with respect to all the contributions over there.

05:44.000 --> 05:53.000
Moving on to what specific optimizations we did across the stack, both in the front-end, the back-end, as well as the database side,

05:53.000 --> 05:57.000
what different optimizations we did in order to make it fast.

05:57.000 --> 06:02.000
It's not just one optimization that actually gave us the speed at scale.

06:02.000 --> 06:07.000
It was a series of small optimizations that added up to a subsequent performance,

06:07.000 --> 06:12.000
both starting from the application layer, the platform, and the engine.

06:12.000 --> 06:19.000
It was all across the stack, and I'll be going over those in detail one by one.

06:19.000 --> 06:27.000
The first thing you might have noticed is that the dashboard is very much focused on the time series where you can slice and dice filter on time.

06:27.000 --> 06:36.000
So we wanted the filtering on time to be very, very efficient, and DuckDB's storage format uses row groups to store the data.

06:36.000 --> 06:40.000
And with each row group, it also stores min-max of your timestamps.

06:40.000 --> 06:46.000
If you don't order your data correctly, you might end up with these min-max, which are spread all across the place.

06:46.000 --> 06:51.000
So when you run a query with a filter on a timestamp, you may need to scan all these row groups.

06:51.000 --> 07:00.000
So one optimization was to try to sort the data during your ingestion so that your min-max and indexes are more efficiently used.

07:00.000 --> 07:08.000
Here you can see there is a query which tries to figure out top-ten products by sales for like the first week of January.

07:08.000 --> 07:17.000
And on the left, when we are not ordered, it's scanning like two row groups, but it can scan only one row group and give the result back.

07:17.000 --> 07:25.000
There's one small tip that we noticed was that you also do not want to need to sort the data in a perfect way.

07:25.000 --> 07:32.000
If your input source is already partitioned by time, you can also just preserve the insertion order during ingestion.

07:32.000 --> 07:36.000
This is much faster than just resorting the whole dataset.

07:36.000 --> 07:47.000
Another thing we noticed was that we are doing a lot of filtering on dimensions, and comparing numbers is quite faster as compared to comparing strings.

07:47.000 --> 07:58.000
So there is a data type in DugDB which is enum, which you can use instead of string columns, which allows for faster comparisons and filtering on those columns.

07:58.000 --> 08:07.000
However, there was a trade-off that we had to do over there because now we are also converting a column type, which leads to higher ingestion time.

08:08.000 --> 08:16.000
Incremental ingestion also became harder for us because we now have to rewrite the column type where we need to add more values.

08:16.000 --> 08:19.000
For example, if there is a new user, there is a new campaign.

08:19.000 --> 08:28.000
If we are using it for that column, it doesn't work very well, but it works very well for columns like gender where the values are fixed and it doesn't change over time.

08:29.000 --> 08:34.000
The next optimization we did was query cancellation.

08:34.000 --> 08:46.000
As you go in the application, a user is interacting with different states, and if there are one state, when I click on the dashboard, it fires hundreds of queries.

08:46.000 --> 08:57.000
As those queries are, results are being streamed back and those queries are being executed, there are chances that the user sometimes goes ahead and changes the state of the dashboard by maybe adding a new filter.

08:58.000 --> 09:01.000
Clicking on another dimension value.

09:01.000 --> 09:05.000
All those things lead to a bunch of queries which are in the queue.

09:05.000 --> 09:09.000
We added a queue for those queries and we started cancelling those queries.

09:09.000 --> 09:18.000
This reduced the overall load on the database and saved almost 30-40% of the CPU cycles, which overall helped us to scale it even further.

09:21.000 --> 09:26.000
We also added a priority queue because not all workloads on your application are going to be the same.

09:26.000 --> 09:41.000
Interactive dashboard queries were the highest priority for us, so we wanted that interactive experience on the dashboard, but there are other workloads like schedule reports or API machine generated queries which could be executed at a lower priority.

09:41.000 --> 09:46.000
Having a priority queue helped us a lot in order to make the dashboards more interactive.

09:48.000 --> 09:52.000
This is an acronym Mike came with today around what you see is what you fetch.

09:53.000 --> 09:56.000
We implemented the delay execution in our dashboards.

09:56.000 --> 10:06.000
You can see in this slight animation that the rows are actually loaded dynamically as we are scrolling it down, then these things are fetched from the database.

10:06.000 --> 10:15.000
We believe that only compute what you want to show to your users, even though we have the scrolling experience here, but it is being dynamically computed.

10:16.000 --> 10:24.000
We do fetch like row groups and filter heavily on the data so that we don't end up computing things which we don't need to show to the user at all.

10:27.000 --> 10:39.000
Data modeling is also another technique which if you model your data correctly, you can reduce the overall complexity or overall data that needs to be scanned at the query time.

10:40.000 --> 10:49.000
You are essentially doing a trade off where you are pushing computations to your data modeling layer, to your ingestion rather than doing it at query time every time.

10:50.000 --> 10:54.000
Here is a data model which tries to do a bunch of things.

10:54.000 --> 10:56.000
I'll start with aggregation.

10:58.000 --> 11:00.000
This is like a sales data set.

11:00.000 --> 11:06.000
First, it tries to aggregate the data by day, which in itself reduces the amount of data by 10x.

11:06.000 --> 11:15.000
Just by doing that in my data models, I am now able to reduce the amount of data that needs to be scanned for each and every query by 10x, which improves the performance there.

11:16.000 --> 11:24.000
There are certain use cases where if the business needs allow you to retain certain amount of data, as the data gets old, the value gets decreased.

11:24.000 --> 11:33.000
If you are only looking at last few quarters of data, you may also choose to set some retention rules by applying a filter in your data modeling layer.

11:34.000 --> 11:43.000
You can order the data by timestamp as to you better utilize minmax indexes and finally, materialize the output of your model in real.

11:43.000 --> 11:49.000
That will store that as a materialized model so that it doesn't need to recompute the view every time.

11:50.000 --> 12:05.000
What we actually did here is that we leveraged SQL mainly for our data modeling layer, which allows you to set all these optimizations and do those in your data modeling layer itself.

12:05.000 --> 12:12.000
Here are a few resources around a blog post that we did on why we love REL.

12:12.000 --> 12:17.000
Here is a link on how would you like to try REL.

12:17.000 --> 12:24.000
It's a simple command as Mike showed, which you can use to download and try it yourself.

12:24.000 --> 12:27.000
I'll open up for questions.

12:43.000 --> 12:49.000
We can also grab questions on the hallway.

12:49.000 --> 13:02.000
Great question from the front of the audience.

13:02.000 --> 13:07.000
I think I recognize this gentleman as the creator of Click House.

13:08.000 --> 13:10.000
Great to see you, Alexi.

13:10.000 --> 13:13.000
Questions, how does it scale beyond one machine?

13:13.000 --> 13:14.000
It's a great question.

13:14.000 --> 13:25.000
Today REL runs, we do run DuckDB for single nodes, but we have been experimenting with other engines to achieve scale.

13:25.000 --> 13:31.000
So, fun fact is that Nishant and I worked together at the company that created Apache Druid.

13:31.000 --> 13:35.000
It was an advertising analytics business called MetaMarkets.

13:35.000 --> 13:40.000
We recently have been experimenting with Click House as well to achieve scale.

13:40.000 --> 13:51.000
So today REL's cloud version does use Apache Druid, and some of our customers have 50 terabytes or more of scale running this same application.

13:51.000 --> 14:02.000
What we like about saying like Click House is it may allow us to have the same sequel, dialect, same ergonomics from small scale to large scale without having to swap engines.

14:02.000 --> 14:08.000
So, but we look forward to trying that out more in the future.

14:08.000 --> 14:09.000
Great question.

14:09.000 --> 14:14.000
Other questions before we, I think we've got one minute left.

14:14.000 --> 14:17.000
Go ahead.

14:17.000 --> 14:21.000
Can we attach a mic for the base via Dr. D?

14:21.000 --> 14:23.000
Absolutely.

14:23.000 --> 14:31.000
I wouldn't recommend attaching per se, but maybe Nishant you can show in the demo.

14:32.000 --> 14:35.000
You can read from MySQL.

14:35.000 --> 14:37.000
You can read from Postgres.

14:37.000 --> 14:39.000
We support dozens of different connectors here.

14:39.000 --> 14:44.000
The key thing for REL is that we are not just attaching to a server.

14:44.000 --> 14:56.000
We're actually ingesting or orchestrating data into the compute, the in-memory compute engine, and then we co-locate the application very close to that database server.

14:57.000 --> 15:06.000
So, yeah, you can attach to any of these data sources and bring in, again, for real developer, you're right in your laptop.

15:06.000 --> 15:16.000
I have an example where I've got 100 billion events, 100 billion event systems can scale quite well on a single net.

15:19.000 --> 15:20.000
Okay.

15:20.000 --> 15:21.000
Thank you very much.

15:21.000 --> 15:23.000
We look forward to you trying it out and hearing from you on Discord.

15:23.000 --> 15:24.000
Bye-bye.

15:24.000 --> 15:25.000
Thank you.

