WEBVTT

00:00.000 --> 00:09.120
We'll see something very basic, the load average, the thing that you have on top, on top when

00:09.120 --> 00:11.680
you look at the performance of your server.

00:11.680 --> 00:17.080
Very basic, but with a lot of misunderstanding and the goal is really to understand if it's

00:17.080 --> 00:21.320
useful or not and at least how it works.

00:21.320 --> 00:26.520
I usually do that as a live demo, but I'm not sure about the Wi-Fi.

00:26.520 --> 00:30.080
I think I've lost the connection, but I have some recordings.

00:30.080 --> 00:34.720
Basically, what we will do, we will look at what we have in top.

00:34.720 --> 00:41.480
So this is not moving because I lost the connection, but we will see later on recordings.

00:41.480 --> 00:43.440
You can start to think about it.

00:43.440 --> 00:47.920
I have run something that you can see in the processes there.

00:47.920 --> 00:51.240
I have two CPUs.

00:51.240 --> 00:55.880
I have a load average of 32 for a long time.

00:55.880 --> 01:01.320
I don't know if you care, but I have 99% of weight I owe.

01:01.320 --> 01:06.640
Basically, my question to you is, do I have a problem or not?

01:06.640 --> 01:10.120
I am bound on a resource or not.

01:10.120 --> 01:18.800
If I'm bound on a resource, am I bound on CPU or I owe or memory or whatever?

01:18.800 --> 01:26.240
This simple question, I see a lot of people who cannot really explain it.

01:26.240 --> 01:32.000
The goal of the presentation will be to tell you that you can mostly ignore the numbers

01:32.000 --> 01:37.520
that are on top of top because those are about the systems, the processor, what you care

01:37.520 --> 01:42.720
about for your application performance is more the tasks that are running and this is

01:42.720 --> 01:45.240
probably more useful.

01:45.240 --> 01:51.280
Going back to the slides where I have the recordings of all the demos, so we will not

01:51.280 --> 01:54.800
try to reconnect to the Wi-Fi.

01:54.800 --> 02:03.800
Also, so that screenshot of what we have seen, people using the cloud, cloud providers like

02:03.800 --> 02:10.600
to provide nice graphs about performance and usually they put first the load average, the

02:10.600 --> 02:12.520
CPU usage.

02:12.920 --> 02:16.120
Typically, I have two processors.

02:16.120 --> 02:25.640
I have a load average of 30 and my CPU is doing nothing.

02:25.640 --> 02:28.160
Memory is 100%.

02:28.160 --> 02:34.920
What do they want to tell us with that because most systems will have usage at 100% and that's

02:34.920 --> 02:36.160
probably cool.

02:36.160 --> 02:40.600
We will look at that in the next 20 minutes.

02:41.560 --> 02:46.520
First, this is the recording of what I wanted to show you.

02:46.520 --> 02:49.560
That was what was running exactly the same.

02:49.560 --> 02:57.200
You see the load average, the number of CPU, the weight, IO, there.

02:57.200 --> 02:59.000
What do you think about it?

02:59.000 --> 03:04.120
Who thinks I'm bound on CPU?

03:04.120 --> 03:07.200
Who thinks I'm bound on IO?

03:07.240 --> 03:12.960
Who thinks I'm bound on IO because I have a weight IO?

03:14.840 --> 03:16.040
Less people.

03:16.040 --> 03:18.040
That's already good.

03:19.800 --> 03:26.760
Here, we see a high weight IO, but maybe I can advance on the recording.

03:26.760 --> 03:35.680
What I show in this case, when people think that I have a problem with IO, is just to

03:35.680 --> 03:36.920
run something else.

03:36.920 --> 03:43.640
Let me check where it is in the recording.

03:43.640 --> 03:48.680
If I have the wrong recording, I will just explain what I show usually.

03:53.680 --> 03:57.080
Sorry, maybe it's in the next recording.

03:57.080 --> 04:03.520
What we see is load average, high weight IO, but the most important, what I really care

04:03.520 --> 04:08.160
about is this, the state of the tasks.

04:08.160 --> 04:16.160
Who thinks I am bound on IO because of the D state?

04:18.160 --> 04:26.360
For me, this D state gives me a clue that most of my processors are waiting on IO.

04:26.360 --> 04:27.360
Probably.

04:27.360 --> 04:37.840
We see that it's not so exact science, but that's something that can give some clues.

04:37.840 --> 04:40.480
I'm lost in my slides.

04:40.480 --> 04:42.720
This is the next one.

04:42.720 --> 04:44.600
I'm running yes.

04:44.600 --> 04:46.240
You know the yes command?

04:46.240 --> 04:47.880
It displays yes.

04:47.880 --> 04:51.680
I'm still running the same IO there, the same throughput.

04:51.680 --> 04:56.440
I'm doing exactly the same, and my weight IO has decreased.

04:56.520 --> 05:05.080
This is how to solve weight IO, just run something else.

05:05.080 --> 05:11.400
I show that to explain that this weight IO is not about what your tasks are doing.

05:11.400 --> 05:15.080
It's about the CPUs.

05:15.080 --> 05:19.680
When you do IO, you don't need CPU, so you wait.

05:19.920 --> 05:28.160
If no one else wants to do something on the CPU, then the CPU state just remembers that,

05:28.160 --> 05:33.600
okay, I'm idle because someone is doing some IO.

05:33.600 --> 05:37.640
Now I'm running something else that uses this CPU.

05:37.640 --> 05:40.600
This CPU is not idle.

05:40.600 --> 05:46.760
This weight IO just means idle, and idle because the last one did some IO.

05:46.760 --> 05:54.000
The only information I have from weight IO is that the CPU could be used for something

05:54.000 --> 06:01.040
more useful than weighting, but doesn't really give me the information that I have a lot

06:01.040 --> 06:06.200
of IO because depending on the other workload, I will sit there or not.

06:06.200 --> 06:13.440
The state doesn't lie if my processes are all on the D state.

06:13.440 --> 06:25.440
At least they are not on the R state, the renewable state, so they are not using CPU.

06:25.440 --> 06:33.360
In the next one, what I do to understand better the kind of IO I'm doing, the kind of system

06:33.360 --> 06:42.400
call that puts this D state, I just run S trace on my processes, and I just did the

06:42.480 --> 06:48.960
S trace dash C to count them, and you see that most of the system calls are P writes.

06:48.960 --> 06:50.560
That's actually what I'm running there.

06:50.560 --> 06:58.920
I'm doing writes with the P write system call with direct IO.

06:58.920 --> 07:02.320
That's basically what I have there.

07:02.320 --> 07:09.040
If I want to understand really what is behind a state that is not the R state, the renewable

07:09.040 --> 07:13.480
state, I can trace the system calls to know exactly why.

07:13.480 --> 07:22.320
I will explain why I'm looking at that because even if D looks like disk, you can do some

07:22.320 --> 07:29.000
IOs that are not in D state, and you can have D state that has nothing to do with IO.

07:29.000 --> 07:32.760
So it can be misleading.

07:32.760 --> 07:39.120
The D state is uninterruptible calls.

07:39.120 --> 07:46.480
So your process has something to do that is not in CPU and does it in an uninterruptible

07:46.480 --> 07:48.320
state.

07:48.320 --> 07:54.520
Depending on the system call, it can do it uninterruptible or not.

07:54.520 --> 08:02.640
Often IO like the P write is using this, but there are some other kind of IOs.

08:02.640 --> 08:03.920
Any questions so far?

08:03.920 --> 08:06.240
Any remarks?

08:06.240 --> 08:08.800
Okay.

08:08.800 --> 08:13.540
So next one.

08:13.540 --> 08:19.840
I will run something else if I remember exactly what I'm doing here.

08:19.840 --> 08:21.480
I will run FIO.

08:21.480 --> 08:26.360
The difference is that I'm not calling the P write system call.

08:26.360 --> 08:33.920
I'm calling the Lib IO, asynchronous IO library.

08:33.920 --> 08:39.760
Basically I'm doing the same writing to the disk with direct IO and you can see the throughput

08:39.760 --> 08:43.360
is mostly the same.

08:43.360 --> 08:49.800
However, I'm not in D state anymore.

08:49.800 --> 08:56.800
So there are some IO who put the D state, but there are some IO who just put the sleep

08:56.800 --> 09:02.720
state, which is not uninterruptible.

09:02.720 --> 09:09.800
So very misleading when you see those things and try to guess what happens.

09:09.800 --> 09:11.720
If you are stressed, there is no guess.

09:11.720 --> 09:14.640
You know exactly the system call.

09:14.640 --> 09:18.600
And I think this is what I do just after.

09:18.600 --> 09:28.920
If I stress, I see that most of the IO calls here are IO get events and there is some IO

09:28.920 --> 09:29.920
submit.

09:29.920 --> 09:33.240
This is our asynchronous IO works.

09:33.240 --> 09:39.000
P write just ask the kernel, I want these blocks and wait to get those blocks.

09:39.000 --> 09:43.080
With asynchronous IO, it tells the kernel, I will need those blocks.

09:43.080 --> 09:52.160
So that's the submit and then can you work on something else and come back and say, oh,

09:52.160 --> 09:53.440
do you have my IO?

09:53.440 --> 09:55.160
If not, I will wait.

09:55.160 --> 10:00.280
The submit goes in this state, but it's very short because it's just a submit.

10:00.280 --> 10:08.640
The get events, if it waits, goes in sleep state, the S state, and not the D state.

10:09.000 --> 10:12.960
Depending on the kind of IO, you will see it at this state or not.

10:12.960 --> 10:21.080
And the wait IO there depends on the state, but more important, I don't know if I can

10:21.080 --> 10:22.080
go back.

10:22.080 --> 10:30.400
Well, I'm sure I can go back if I replay it.

10:30.400 --> 10:38.320
I guess that the load average was lower when I was running that because the D state counts

10:38.320 --> 10:42.440
in the load average, the S state doesn't.

10:42.440 --> 10:48.920
Means that some IO counts in the load average, some IO doesn't.

10:48.920 --> 10:55.200
Means that with load average, you don't really know what happens.

10:55.200 --> 11:00.200
Okay.

11:00.200 --> 11:03.760
The next one, I'm running something else.

11:03.760 --> 11:09.200
So those were direct writes by passing the buffer cache.

11:09.200 --> 11:13.880
And here I'm running reads and more I set direct equals zero to FIO.

11:13.880 --> 11:17.920
FIO just simulates different kind of IO.

11:17.920 --> 11:20.760
Typically I work with databases.

11:20.760 --> 11:25.360
I'm a developer advocate for UGA by DB that is a distributed SQL database compatible

11:25.360 --> 11:26.860
with Postgres.

11:26.860 --> 11:29.400
I've been working also a lot with Oracle.

11:29.400 --> 11:35.200
They do those kind of IO, Postgres does not do direct IO.

11:35.200 --> 11:36.200
It goes through buffer.

11:36.200 --> 11:37.400
Oracle, you have the choice.

11:37.400 --> 11:39.400
So really depends.

11:39.400 --> 11:47.400
Here, what I would like to show you, I don't see it from here, but I'm probably in the

11:47.400 --> 11:49.400
running state.

11:49.400 --> 11:53.400
Yeah, it was not sorted.

11:53.400 --> 11:59.200
But here, I'm mostly reading from memory, from the cache, from buffers.

11:59.200 --> 12:02.720
And this is why you see that much faster.

12:02.720 --> 12:08.080
And a difference, I'm using more CPU there.

12:08.080 --> 12:11.880
You access memory more than you access the disks.

12:11.880 --> 12:18.480
And then this is in CPU usage, the kernel part of the read.

12:18.480 --> 12:21.360
I mean, my application is doing the same.

12:21.360 --> 12:22.760
Just an IO call.

12:22.760 --> 12:26.880
So the user space CPU is still low.

12:26.880 --> 12:32.280
But on the system, on the kernel, what Linux does is read from memory.

12:32.280 --> 12:36.040
And this is where you have some system CPU there.

12:36.040 --> 12:40.200
That counts in the load average also.

12:40.200 --> 12:49.360
I just, okay, in the meantime, I did this trace to see the reads there.

12:49.360 --> 12:52.160
So I have periods, the same system call.

12:52.160 --> 12:56.160
What is different is what is behind.

12:56.160 --> 12:58.080
That it reads from buffer.

12:58.080 --> 13:01.160
And I don't know if you have seen it.

13:01.160 --> 13:07.720
When I was attaching with S trace, the state here was T. That's the state when you attach.

13:07.720 --> 13:09.360
And of course, it has a little overhead.

13:09.360 --> 13:13.240
You do that to troubleshoot.

13:13.240 --> 13:17.240
The important thing is the runable state.

13:17.240 --> 13:23.480
I'm saying that either I'm running in CPU or I want to run in CPU.

13:23.480 --> 13:28.640
And I don't know which one from those metrics.

13:28.640 --> 13:29.640
That's the point.

13:29.640 --> 13:30.640
I have only two CPUs.

13:30.640 --> 13:36.040
So I know that I cannot have more than two tasks running in CPU.

13:36.040 --> 13:37.040
They are running able.

13:37.040 --> 13:42.000
They are waiting in the run queue to be able to run on the CPU.

13:42.000 --> 13:44.160
Top will not show the figure.

13:44.160 --> 13:50.120
Load average will add those rating and those running.

13:50.120 --> 13:55.680
If you want to see the difference, you need to look at the statistics from the scheduler

13:55.680 --> 14:01.640
in slash proc scheduler statistics or VM stat is showing you the run queue.

14:01.640 --> 14:05.480
I'm saying that because I've seen a lot of people comparing the load average with the

14:05.480 --> 14:06.720
number of CPU.

14:06.720 --> 14:13.960
Like if load average is higher than the number of CPU, I have a problem.

14:13.960 --> 14:18.960
Maybe not because if the load average is due to IO, you don't really care about comparing

14:18.960 --> 14:20.840
with the CPU.

14:20.840 --> 14:26.960
And if the load average is high because you have a lot of processes in the run queue,

14:26.960 --> 14:31.480
then probably you have a problem because you have tasks who need to run something on the

14:31.480 --> 14:39.160
CPU and just cannot and are waiting in behind.

14:39.160 --> 14:44.720
So we have seen different kinds of IOs and they look differently.

14:44.720 --> 14:51.760
Many times where I've seen, especially on databases, where I've seen different teams,

14:51.760 --> 14:57.120
the Linux team looking at the system and the DBA team looking at the database.

14:57.120 --> 14:59.840
And in many companies, they don't really talk together.

14:59.840 --> 15:07.840
So one is guessing what the other is doing and a lot of misinterpretation on all that.

15:07.840 --> 15:12.200
It's very important if you look at the numbers from the system to understand what the database

15:12.200 --> 15:13.200
is doing.

15:13.200 --> 15:18.200
And also it's very important for the database administrator to look at the system because

15:18.200 --> 15:26.960
many things in the database metric will be different if the system is overloaded.

15:26.960 --> 15:32.480
I give a quick example on Oracle, you have wait events where you can know exactly how

15:32.480 --> 15:34.760
much time you spend on IO.

15:34.760 --> 15:38.040
But it's not exactly how much time you spend on IO.

15:38.040 --> 15:43.160
It's how much time between the time stamp it takes before the IO and after the IO.

15:43.160 --> 15:50.280
If your process is in the run queue, the database thinks that it is doing IO, but maybe the

15:50.280 --> 15:55.080
IO is done and it's just waiting to go back to the CPU just to set the counter on the

15:55.080 --> 15:56.080
time stamp.

15:56.080 --> 15:58.000
So that's also the message.

15:58.000 --> 16:02.760
I say that to database administrator, but applications, if you run on a system that

16:02.760 --> 16:08.320
is overloaded in CPU, then probably all of their metrics, because they require CPU cycles

16:08.320 --> 16:12.720
to get the number are probably wrong.

16:12.720 --> 16:15.480
So why did I call that silly metrics?

16:15.480 --> 16:18.400
I didn't came with this.

16:18.400 --> 16:25.400
If you want to understand what is what low-dverage measures, Linux is open source, so just look

16:25.400 --> 16:27.800
at the source of it.

16:27.800 --> 16:33.920
And you can look at the source, but more interesting are the comments which can explain the intention

16:33.920 --> 16:35.440
of the function.

16:35.440 --> 16:43.640
And so in Linux, the load average is defined as this file, so the source for load average

16:43.640 --> 16:51.400
contains the magic bits required to compute the global load average figure.

16:51.400 --> 16:55.680
It is a symmetric, but people think it is important.

16:55.680 --> 17:01.240
So you see why you see that first in top?

17:01.240 --> 17:08.280
It is silly, but some people think it is important, so let's give them something.

17:08.280 --> 17:13.960
And we go through the grid pane to make it work on big machine with T-class kernel.

17:13.960 --> 17:22.880
So the load average idea comes from Unix systems where it was really measuring the load in

17:22.880 --> 17:31.240
CPU and where it was easier to measure it because you just counted the ticks in the

17:31.240 --> 17:32.240
scheduler.

17:32.240 --> 17:38.920
Linux works differently and means that it is difficult to measure and maybe it makes

17:38.920 --> 17:42.400
no big sense.

17:42.400 --> 17:47.760
So yeah, good to know why this metric is there just because people coming from Unix

17:47.760 --> 17:54.080
were used to have this single graph showing the load and compare that with the application

17:54.080 --> 18:00.160
and what is done in the application, but if you don't look at the state of the processes,

18:00.160 --> 18:02.640
then it can be misleading.

18:02.640 --> 18:14.520
It's easy to understand exactly why we see this state, these IOCOLs in the load average,

18:14.520 --> 18:15.520
just the way it is calculated.

18:15.520 --> 18:18.760
There are two things that are interested in the way it is calculated.

18:18.760 --> 18:21.840
First, it is an average and that's also a problem.

18:21.840 --> 18:25.560
If you look at the load average, you will not see a peak of activity of five seconds

18:25.560 --> 18:27.560
because it is average.

18:28.200 --> 18:35.800
The other thing is that it counts the number of active, so the running state, which is

18:35.800 --> 18:41.000
more renewable because if you are in the run queue, you are not really running and it has

18:41.000 --> 18:49.440
the uninterruptible calls just because they thought that if we show only the CPU load,

18:49.440 --> 18:51.000
is it really the load of the machine?

18:51.000 --> 18:54.160
For example, you run a database doing a lot of IOCOL.

18:54.160 --> 18:59.840
Then we say that the load is low if everyone is waiting on the disk.

18:59.840 --> 19:07.080
Let's add an interoptable because in many cases, we have seen that those IOCOLs are

19:07.080 --> 19:13.440
uninterruptible calls, but they are not always, so it can be quite misleading.

19:13.440 --> 19:18.320
It doesn't mean that you don't have to look at it, but if you look at it and know what

19:18.320 --> 19:23.880
is behind, then it can give you some clues like the clue about IOCOL looking at other

19:23.920 --> 19:28.000
things, but more interesting is the process state.

19:28.000 --> 19:33.680
A process can have something to run in the CPU and then look at the scheduler statistics

19:33.680 --> 19:39.720
knowing if it waits for the CPU or there is CPU available and when it has some calls

19:39.720 --> 19:46.240
to do, they can be done in this state or as state and they will be accounted differently

19:46.240 --> 19:50.200
by the load average.

19:50.200 --> 19:52.200
Any questions so far?

19:53.200 --> 20:00.880
Okay, the next one is more about memory just because it's another thing that is misleading

20:00.880 --> 20:04.200
in some cases.

20:04.200 --> 20:10.000
I think it is quite clear in top that you can look at the available memory, but I see

20:10.000 --> 20:16.440
cloud provider showing the use memory or the free memory and here I just want to explain

20:16.440 --> 20:24.440
for those who don't know, if you do buffered IO like I did with direct equal zero.

20:24.440 --> 20:30.440
Okay, I thought we have five minutes now.

20:30.440 --> 20:35.440
Okay, perfect.

20:35.440 --> 20:37.440
So I will finish quickly on that.

20:37.440 --> 20:40.440
Do not look at the free memory.

20:40.440 --> 20:47.440
I'm just showing that if I do some IOs, it will take some free memory, but that is easily

20:47.440 --> 20:51.440
freed if it needs look at the available memory.

20:51.440 --> 20:57.440
That's the memory that is available to your process, but also think that it is available.

20:57.440 --> 21:03.440
You can use it, but if you use it, then another process doing buffered IO may not find its

21:03.440 --> 21:05.440
data in the case.

21:05.440 --> 21:12.440
So if it is available, doesn't mean that it's free from any impact on the others.

21:12.440 --> 21:21.440
Okay, I just put the last one while I'm talking and taking question.

21:21.440 --> 21:29.440
The idea there was just to show a really silly program doing V fork that has nothing to do

21:29.440 --> 21:35.440
with the data, but just to show that it will go to the state, it will increase the load

21:35.440 --> 21:40.440
average and that's the case I've seen in some system where the load average was thousands

21:40.440 --> 21:48.440
on a database having its file on NFS and network issues and then those uninterruptible calls

21:48.440 --> 21:53.440
increased the load average, but without any consequence because they weren't doing nothing.

21:53.440 --> 21:58.440
The only thing is that it's ugly when you look at the load average and the other thing is

21:58.440 --> 22:00.440
that they are uninterruptible.

22:00.440 --> 22:02.440
You cannot kill them.

22:02.440 --> 22:10.440
So you want to restart the system to have nicer numbers, but of course you wait for it.

22:10.440 --> 22:18.440
So just be careful, load average accounts some IO and accounts some CPU and you have some IO

22:18.440 --> 22:21.440
that you do not see there.

22:21.440 --> 22:25.440
Okay, do you have any questions, remarks?

22:25.440 --> 22:35.440
Thank you.

22:35.440 --> 22:39.440
What about pressure stall information?

22:39.440 --> 22:41.440
Very good question.

22:41.440 --> 22:47.440
If you have seen at the first screenshot I was running pressure stall information, which in my opinion

22:47.440 --> 22:49.440
is a better picture.

22:49.440 --> 22:57.440
The pressure stall information is counter telling you during the last 10 seconds, for example, how many,

22:57.440 --> 23:07.440
not how many, if there were some processes with pressure on CPU, so to run on CPU to get IO

23:07.440 --> 23:09.440
or to get some memory.

23:09.440 --> 23:13.440
So it really gives you an idea about the pressure itself.

23:13.440 --> 23:21.440
The only thing about pressure stall information I have is that in most of the kernels, the distributions

23:21.440 --> 23:25.440
I've seen, it is compiled in the kernel but not enabled by default.

23:25.440 --> 23:30.440
And then because it's not enabled by default, I've not seen it a lot.

23:30.440 --> 23:32.440
And then I think it's a good idea.

23:32.440 --> 23:39.440
Each time I used pressure stall information, it was giving me the right idea, but it's just a subset

23:39.440 --> 23:42.440
of the systems I've seen because it's not the default.

23:42.440 --> 23:49.440
And then maybe there are some cases that I don't know where it's not perfect, but I try to encourage people

23:49.440 --> 23:55.440
to enable pressure stall information where instead of looking at all that, you just see that you have some

23:55.440 --> 24:07.440
processes that could be faster if they were not on pressure, on RAM, IO, or CPU.

24:07.440 --> 24:09.440
Okay, I think we are just...

24:09.440 --> 24:11.440
Another question? If it's okay?

24:11.440 --> 24:18.440
So looking at a very generic use case, if you were to redesign the cloud provider's graphs,

24:18.440 --> 24:21.440
would you change it? What would you change it to?

24:21.440 --> 24:27.440
Could your list maybe the five most important metrics from a generic use case that you would put on a dashboard?

24:27.440 --> 24:34.440
On a dashboard, I think pressure stall information can be really nice on a dashboard because you can show that to user.

24:34.440 --> 24:39.440
User running on the cloud, for example, they want to know if they are on pressure on CPU or on IO

24:39.440 --> 24:41.440
because they pay for that.

24:41.440 --> 24:43.440
So those ones I would put that.

24:43.440 --> 24:50.440
Load average, maybe with a clear description that it is CPU plus some IO,

24:50.440 --> 24:58.440
and memory, available memory, not use memory because a system doing some IO, some buffered IO

24:58.440 --> 25:01.440
will always use all the memory in Linux.

25:01.440 --> 25:04.440
Maybe we have...

