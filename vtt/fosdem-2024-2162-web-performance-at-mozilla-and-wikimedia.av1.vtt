WEBVTT

00:00.000 --> 00:10.520
Hello, my name is Peter. I work for the Wikimedia Foundation in the quality and test team.

00:10.520 --> 00:16.500
So I have like three minutes, so I'm going to show you a couple of things. In the team,

00:16.500 --> 00:23.120
we want to make sure that we find regressions, right? And the cool thing about it is that

00:23.120 --> 00:28.720
we keep all our performance metrics in the open. So you can go to our Grafana instance,

00:28.720 --> 00:35.600
Grafana.wikimedia.org and see our metrics. Now I'm going to do a live demo. Oh, that didn't

00:35.600 --> 00:51.080
work out so good. So let's see. Okay. So, we have, I'm going to show you four dashboards.

00:51.080 --> 00:55.880
We have our real user monitoring dashboard with the data that we send from our read users

00:55.880 --> 01:03.200
back to Wikimedia. So I propose that you go to that dashboard and look out at our performance

01:03.200 --> 01:10.600
metrics. I think it's quite interesting because we don't have so many big websites that actually

01:10.600 --> 01:20.640
show their data. We also have another dashboard where we have all our synthetic tests. So

01:20.640 --> 01:25.880
you can use the drop downs to see the pages that we test and the performance data of that.

01:25.880 --> 01:30.000
So this is kind of like internal data, so maybe not so interesting for you. So I have

01:30.000 --> 01:39.000
two more dashboards that is more interesting. So we have the user network dashboard. Let's

01:39.000 --> 01:49.720
see. Here is actually what kind of network our users that use Chrome has. So we use the

01:49.800 --> 01:54.920
network information API and beacon back the data. So we can use the drop down and see

01:54.920 --> 02:04.440
what kind of network our users is using. And if we scroll down, you can also see what kind

02:04.440 --> 02:08.720
of connection type they have. So this is interesting because you can see what kind of connection

02:08.720 --> 02:15.640
different areas of the world have when they access Wikipedia. And the last thing I want

02:15.640 --> 02:29.800
to show you is the CPU benchmark. So as Beth said, it's important because different users

02:29.800 --> 02:34.440
have different devices, right? And for some of our users, we run a small JavaScript that

02:34.440 --> 02:39.600
we measure the time it takes to run and we beacon that data back. So we can see what

02:39.600 --> 02:47.000
kind of performance different devices have for different users all around the world.

02:47.000 --> 02:57.160
And we use that data to actually see and compare it to different devices. So we can use that

02:57.160 --> 03:04.600
data to tweak how we run our tests internally. So if you go to that page, you can see what

03:04.600 --> 03:11.600
kind of benchmark to use as a Wikipedia. Okay, that was all for me. Dave.

03:11.600 --> 03:14.600
Thanks, Peter.

03:35.600 --> 03:41.600
Hey, everybody. I'm Dave Hunt. I'm the, I'm going to stand over here so I'm not blocking

03:41.600 --> 03:47.600
the screen. I'm Dave Hunt. I'm the engineering manager for the performance tools team at

03:47.600 --> 03:54.600
Mozilla. And I'm going to show you a little bit about how we handle regressions for Firefox.

03:54.600 --> 04:00.600
And we have tests that test page load benchmarks. I'm going to use a real example of a recent

04:00.600 --> 04:05.600
regression. And I'm going to go pretty fast through these because I only have a few minutes.

04:05.600 --> 04:11.600
So obligatory slide with a quote from a famous person. So Galileo, Galilei said, measure

04:11.600 --> 04:17.600
what is measurable and make measurable what is not so. And I think this is something we

04:17.600 --> 04:23.600
try to do in our team. So here, this is a performance alert. We have a bunch of tests

04:23.600 --> 04:29.600
running on, we're not suddenly commit something to Mozilla Central, our repository for Firefox.

04:29.600 --> 04:34.600
When we notice a change in the baseline, we generate a regression. One of our performance

04:34.600 --> 04:39.600
sheriffs will be monitoring and triaging these alerts. In this case, this one was triaged

04:39.600 --> 04:45.600
by Andra. And this shows you the magnitude of the regression and the tests that have

04:45.600 --> 04:53.600
alerted. In this case, I filtered it down just for simplicity. This is Expedia. And we can see

04:54.600 --> 05:00.600
some of our speed index tests have regressed. The sheriff will do some investigation. This is the same

05:00.600 --> 05:07.600
test or one of those tests shown in graph view. You can see this is our baseline. There was a

05:07.600 --> 05:14.600
change. The sheriff actually has come in here to some retriggers and backfills just to narrow

05:14.600 --> 05:21.600
the regression range and identify a likely culprit. And then the sheriff will file a bug. So

05:21.600 --> 05:27.600
we file a bug in in bugzilla. Because we've identified the likely culprit, we'll also need

05:27.600 --> 05:33.600
info. They will request further information from the author of that patch so that they can be

05:33.600 --> 05:38.600
aware. Looks like there might have been regression. Maybe we need to back this out or maybe we need

05:38.600 --> 05:43.600
to fix it. And I'm just highlighting here as well links through to one of our other tools, the

05:43.600 --> 05:50.600
performance, sorry, the Firefox profiler. So we provide as much as we can to the engineer so

05:50.600 --> 05:55.600
they can confirm. Yes, it looks like it's my patch and also can have a little bit more of a deeper

05:55.600 --> 06:03.600
dive into what might have caused it. And then another tool that we have is perf compare. This

06:03.600 --> 06:08.600
allows engineers to, if they think they've got a fix or they think they have something that might

06:08.600 --> 06:13.600
affect performance, either positively or negatively, they can push that to our CI system, run the

06:14.600 --> 06:20.600
tests and see a comparison. And so here this is again that example, Xpedia contentful speed

06:20.600 --> 06:27.600
index. This is the before, in this case, the regression and a patch that should fix it. And we

06:27.600 --> 06:32.600
can see that the distribution of the results, we've run the tests multiple times. Distribution of

06:32.600 --> 06:40.600
the results is smaller. And so it indicates that perhaps this is fixed. And it was. So we also

06:40.600 --> 06:47.600
alert on improvements. This is the alert that came in a couple of days probably after the patch

06:47.600 --> 06:54.600
landed to fix it or to back this out. I think this change was a change in how aggressively we are

06:54.600 --> 07:01.600
garbage collecting. And so yeah, we get this and we can also look at the graph view. We can see

07:01.600 --> 07:06.600
the period of time that we had that regression and we can see that it is fixed and it's back to the

07:06.600 --> 07:15.600
baseline that we had before. We also capture videos. So again, another tool that is useful for the

07:15.600 --> 07:21.600
engineers to confirm. Yes, it looks like there really is a regression. In this case, this is the fix. So

07:21.600 --> 07:30.600
this is the slower and improved, the faster. I mentioned the Firefox profiler. I encourage everybody

07:30.600 --> 07:38.600
if you don't use it or haven't used it, check it out. Try it. Give us feedback. And finally, I just wanted to

07:38.600 --> 07:47.600
promote. Floring Kes is talking in Janssen at 1pm today. That's the main track on Firefox profiling. So

07:47.600 --> 07:53.600
you'll see a little bit of example of using the profiler for something other than necessarily web

07:53.600 --> 07:59.600
performance, but it's a very versatile tool. That's it.

