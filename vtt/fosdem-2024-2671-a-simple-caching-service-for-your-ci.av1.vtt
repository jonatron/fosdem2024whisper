WEBVTT

00:00.000 --> 00:13.760
So, hello everyone. So, as I said, my name is Remedio Raffa, I'm a principal tech lead

00:13.760 --> 00:19.860
at Lino. I've been working on Open Source Project for a long time now, and I've been

00:19.860 --> 00:26.400
at FOSDEM for many years now, it's not my first FOSDEM presentation. So, I've been working

00:26.400 --> 00:33.120
on VLC media player on V8, Javascript Engine, and I joined Lino some years ago working on

00:33.120 --> 00:39.520
Lava and on Automation and CI in general. So, today I wanted to speak a bit about a

00:39.520 --> 00:44.680
really tiny project that I created some years ago, which is called Keyscash. And in order

00:44.680 --> 00:52.000
to present it, I have to explain why we are using Keyscash in Lino. So, at Lino we contribute

00:52.000 --> 00:57.720
a lot to the Linux channel, and not only by developing new stuff, drivers, and a lot

00:57.720 --> 01:03.080
of different things, but we also contribute a lot by testing the Linux channel. We have

01:03.080 --> 01:10.800
a project called LKFT, Linux channel functional testing project. That is, if you go to the

01:10.800 --> 01:15.600
website, it's written that the goal is to improve the Linux channel quality on the ARM

01:15.600 --> 01:21.520
architecture, because we are now mainly about ARM, but not only. By performing regression

01:21.520 --> 01:26.600
testing and reporting on seleting Linux channel branches on the Android command channel in

01:26.600 --> 01:31.040
real time. Okay. That's what is written on the website. More or less, it's a project

01:31.040 --> 01:38.400
led by Leno. It's an automated system to build and test a set of Linux channel trees.

01:38.400 --> 01:46.400
We mainly care about LTS, obviously, mainline and next. And by contract, we have to provide

01:46.400 --> 01:54.320
a report in 48 hours. So, it's quite tight between an RC on an LTS trees. In 48 hours,

01:54.320 --> 02:00.360
we have to provide an SLA. We have to provide a report, all right. So, if you look back

02:00.360 --> 02:12.200
at 2023, we built and tested 396 different RCs, so only LTS channels. As we also care

02:12.200 --> 02:21.440
about mainline and next, we built 2,443 different channel commits. That's 1.1 million builds.

02:21.440 --> 02:28.760
So, 1.1 million channels were built by the system by LKFT. And we ran 297 million tests

02:28.760 --> 02:35.280
just in one year. And if you look at the Android parts, Android command channel, that's 580

02:35.280 --> 02:42.720
million tests. The tests are running both on virtual machines, so QMU and FVP. We have

02:42.720 --> 02:47.720
a specific system where we can instantiate in the cloud many machines for running QMU

02:47.720 --> 02:52.440
and FVP. That's a stock suite service that we created. We will not speak about it today.

02:52.440 --> 02:59.360
And we also have a physical lab. So, with physical devices in Cambridge, that is managed by a

02:59.440 --> 03:06.400
tool called Lava. That's a tool that I'm running inside in Salinaro. So, if you look at the

03:06.400 --> 03:11.520
LKFT, really simplified architecture because obviously it's way more complex than that.

03:11.520 --> 03:20.440
So, as I said, we care about LTS trees, mainline and next. So, we have GitLab repository that

03:20.440 --> 03:26.200
are just mirroring the different trees that we care about. And when there is changes,

03:27.160 --> 03:32.320
GitLab will pull it and we create a GitLab pipeline. The GitLab pipeline will send a set of

03:32.320 --> 03:37.640
instructions to our cloud service for building, called text build, that will run the builds.

03:37.640 --> 03:43.080
So, it will scale from zero machine to 5,000 machine in some seconds, do the builds, shut

03:43.080 --> 03:48.760
down the machine and then send the artifacts to an S3 like storage. So, the artifact will

03:48.760 --> 03:54.200
be the kernel, the TTB, the root file system, the modules, etc. And then these artifacts

03:54.200 --> 04:01.000
will be pulled by our lab in Cambridge to be tested on real devices. So, in the lab

04:01.000 --> 04:07.120
in Cambridge, we have some hundreds of boards, Raspberry Pi, Dragon boards, IKs, X15, etc.

04:07.120 --> 04:14.440
A lot of different boards. And at the same time, they will all pull the artifacts, deploy

04:14.440 --> 04:19.400
them on the hardware, depending on what kind of hardware you have, run the test and then

04:19.440 --> 04:24.520
report back. And obviously, everything will run in parallel and don't leave from the same

04:24.520 --> 04:34.520
storage. So, our CI system, as I said, will build and test artifacts, L, DTB, RAM, these

04:34.520 --> 04:41.680
modules, etc. And for each kernel, DTB and root file system, they will use multiple times

04:41.680 --> 04:48.480
because when we have one commit from the kernel, we'll build it for multiple architectures.

04:48.600 --> 04:57.120
We'll build it for x86, ARMv7, ARMv8, ARMv9, PPC, SH4, MIPS, etc. Then for each architecture,

04:57.120 --> 05:02.640
we'll have multiple configurations. I want to build with some virtio-specific configuration.

05:02.640 --> 05:09.320
I want to build in debug in release, etc. And then for each configuration, for each commit

05:09.320 --> 05:16.200
architecture configuration, I will run a set of tests. So, KSELTest, KUnit, libgperiod,

05:16.240 --> 05:23.880
the LTP, etc. Considering that LTP, for example, is broken into 20 different test suites that

05:23.880 --> 05:29.600
will be 20 different test jobs because it takes a lot of time to run. So, the CI system

05:29.600 --> 05:35.200
will run a lot of different jobs, of test jobs, that will actually pull the same artifacts

05:35.200 --> 05:40.840
all the time, which means that in the network, on the network in the lab in Cambridge, we

05:40.840 --> 05:45.840
have a lot of network usage and a lot of duplication. We are re-downloading always the same artifacts.

05:47.080 --> 05:55.480
So, that's normally really simple things to solve. You just add caching. So, just, I'm

05:55.480 --> 05:59.760
really adding that because that's really important. Our system, our CI system, the Lava

05:59.760 --> 06:06.520
Workers, will download multiple times the same artifacts at the same time in parallel. So,

06:06.520 --> 06:11.160
if you look for a caching proxy in the open-source community, you will obviously find that Squid

06:11.200 --> 06:18.360
is the main caching proxy and it's a perfectly good one. It's really working well. So, you

06:18.360 --> 06:23.480
should just install that on our network, point all the workers to it and it should work. Short

06:23.480 --> 06:32.480
answer is no, it's not working just because of the two reasons above. So, and also for another

06:32.480 --> 06:38.600
reason, this one. All artifacts, as I said, are published in an S3 like bucket. They are

06:38.640 --> 06:42.320
somewhere in the cloud. So, obviously, if you want to download them, you will download over

06:42.320 --> 06:49.320
HTTPS. You will not download a random binary from internet and run it in your local lab

06:49.320 --> 06:54.640
for testing. Not something that you will do. So, we have to validate. So, we use HTTPS to

06:54.640 --> 06:58.040
be sure that what we're downloading is what we're expecting. At least we are trusting

06:58.040 --> 07:06.320
the software. But when you add a Squid proxy in the connection, it will not work well with

07:06.360 --> 07:12.360
HTTPS. That written in the script documentation, you can make it work with that. It's not easy.

07:12.360 --> 07:17.360
The main problem is that as an HTTP client, when you connect to a website over HTTPS,

07:17.360 --> 07:21.760
you're expecting to get a certificate and the connection will be encrypted with the

07:21.760 --> 07:26.560
certificate and the certificate, you have to trust it. When you add Squid in the middle,

07:26.560 --> 07:32.400
Squid will have to connect on your BI to the server. So, the connection between Squid and

07:32.480 --> 07:38.980
the website is encrypted correctly. The certificate written by the website is a legit one, so it

07:38.980 --> 07:43.980
will work. But when Squid will have to decrypt the content to cache it and then re-encrypt

07:43.980 --> 07:48.980
it to send it back to you, it does not have the private certificate from the website,

07:48.980 --> 07:53.980
obviously. You don't have the private certificate of Google.com on your machine, so you cannot

07:53.980 --> 08:00.280
re-encrypt the traffic. So, Squid will need to have his own certificate and it will encrypt

08:00.360 --> 08:04.680
the traffic with its own asset certificate. And you will obviously not trust it. You will

08:04.680 --> 08:11.680
not trust your local Squid proxy to sign something from Google.com or AWS or any website

08:11.680 --> 08:16.880
or Linux Foundation. So, when the HTTP client receives the custom asset certificate, it

08:16.880 --> 08:22.160
will just say, no, I don't trust you. There is a workaround and it's written in the script

08:22.160 --> 08:26.600
documentation, obviously, which is create a wildcard certificate, which is a certificate

08:26.600 --> 08:33.600
that will be valid for absolutely every website on the planet, every DNS, so it's kind of

08:33.600 --> 08:40.600
a dangerous asset certificate. And you can install it on every of your HTTP clients.

08:40.840 --> 08:47.840
It's possible, but it's really crappy, honestly. That's the first problem. The second problem

08:47.840 --> 08:53.280
and that there is no way to work around it is that when Squid, when you try to download

08:53.640 --> 08:57.520
multiple times the same artifact in Squid, so, for example, you have two connections

08:57.520 --> 09:04.400
downloading the same root FS, Squid will download it twice and stream it back to the

09:04.400 --> 09:09.680
clients at the same time. And when it's downloaded, it's finished, then the third connection will

09:09.680 --> 09:14.160
have a cache version. But as long as it's not cached locally, it will re-download from

09:14.160 --> 09:20.560
the start. And as I said before, our system is by-designed running everything in parallel,

09:20.560 --> 09:25.560
so it's often the case that we have multiple downloads of the same artifact at the exact

09:25.560 --> 09:32.560
same time. So when using Squid, it was just not caching anything. Sorry. So that's why

09:33.760 --> 09:40.760
we created KeysCache. So Keys stands for keep it simple, stupid. It's a pretty simple and

09:40.960 --> 09:45.560
stupid caching service. But the main features that it has are exactly what we need for a

09:45.560 --> 09:51.680
API system. It allows to cache HTTPS resources without any acts or anything. It allows to

09:51.680 --> 09:56.760
download only once, even if you have multiple clients and they will all get a stream back,

09:56.760 --> 10:01.800
the stream of data back. And the reason why it's not, it's working for both cases is that

10:01.800 --> 10:06.600
it's not a transparent proxy. So it's not like clients that will know from an environment

10:06.600 --> 10:11.720
of the Bible that it has to go through a proxy. Instead, you have to prefix your URLs. So

10:11.760 --> 10:17.460
if you want to access example.com slash .fs.x4, for example, you have to prefix it by your

10:17.460 --> 10:24.460
KeysCache instance. So even if you're downloading over for HTTPS, your clients know that it

10:24.560 --> 10:30.280
goes to KeysCache and not example.com so that it's expecting a certificate from KeysCache,

10:30.280 --> 10:37.280
not from the original website. That's the first reason. And KeysCache also, we made

10:37.760 --> 10:44.760
it so it knows how to stream back to multiple clients, the same content. Fun thing, we also

10:45.080 --> 10:50.800
added a lot of automatic retries inside the KeysCache backends. So if for any reason,

10:50.800 --> 10:56.360
and it happens a lot, the connection between your network and the S3 like bucket breaks

10:56.360 --> 11:01.160
and it often breaks, honestly, KeysCache backend will automatically retries. This is a list

11:01.160 --> 11:08.160
of HTTP codes that we're retrying automatically. And it will also, so when it's retrying, it

11:08.240 --> 11:15.240
retries up to 50 times over a period of two hours because we had exponential backups.

11:15.280 --> 11:20.120
So sometimes a download will actually take two hours and 50 retries just because the

11:20.120 --> 11:26.040
S3 like bucket is just sometimes a bit buggy to answer. We also added partial download,

11:26.160 --> 11:31.200
which when you have, we do a retry, if the HTTP server knows how to do that, we only

11:31.200 --> 11:35.960
download the remaining content, not from the start. And the good thing is that with

11:35.960 --> 11:40.920
the automatic retries, the client will never see that there is a broken connection because

11:40.920 --> 11:45.280
from the client to KeysCache, the connection is kept alive. It's only the backends that

11:45.280 --> 11:52.280
sees the network issues. So it has been in production for 3.5 years. It downloaded 32

11:53.280 --> 12:00.120
terabits of data from internet and served 1.6 petabytes of data locally just for a really

12:00.120 --> 12:05.720
small tiny software, which is an expansion ratio of 51 times. So we divided the network

12:05.720 --> 12:12.720
usage by 51 just by having a small working proxy. It also improved a lot of stability

12:12.760 --> 12:19.760
thanks to the automatic retries, I said, up to 50 retries, which is insane. And it also

12:20.240 --> 12:26.240
lowered a lot of the S3 egress cost because you have to pay for egress in the cloud. When

12:26.240 --> 12:33.240
you, for 1.6 petabytes of data, that's a lot of money. So yeah, we saved around 150

12:34.880 --> 12:41.880
K of euros just by having a local proxy. Just because I have just two minutes, a look at

12:43.360 --> 12:48.760
the global architecture of the service, it suggests a Django application with a salary

12:49.160 --> 12:55.680
backends. So you have a reverse proxy and Ginex. It can be any reverse proxy in fact,

12:55.680 --> 13:02.680
that will receive an HTTP connection. It will send that to Giniacon, which is a Django

13:02.800 --> 13:08.800
runtime. The Django will see if the, we look at the database, but at the base, progress,

13:08.800 --> 13:14.040
to know if the artifact has been downloaded already or not. If it's a case, it will then

13:14.080 --> 13:18.440
look at the file system and just give that back to Ginex saying, please send that to

13:18.440 --> 13:23.720
the client. And I'm done with it. If it's not already downloaded, it will send a message

13:23.720 --> 13:29.400
to Redis that will spawn a salary task that will actually do the download and retry in

13:29.400 --> 13:35.120
the back end. And it's done only once. And it's then saving it to the file system, appending

13:35.120 --> 13:42.120
to a file, byte by byte. And at the same time, the Django process just reads the file on

13:42.120 --> 13:45.720
the file system and sends the bytes where they are available. And that's all. Waiting

13:45.720 --> 13:52.720
for the file, the file to be just finished. And if a second or third of many different

13:53.880 --> 13:59.400
users arrive for the same file, then they will just reuse what is already available in the

13:59.400 --> 14:06.400
file system and wait for the download to finish. And that's all. That's all. It's pretty simple

14:07.400 --> 14:12.400
and efficient. And it has been a really good use for us. And it might be useful for your

14:12.400 --> 14:17.400
CI system. So if you have any questions, I will be here after the talk. Thanks a lot.

14:17.400 --> 14:18.400
Thank you.

