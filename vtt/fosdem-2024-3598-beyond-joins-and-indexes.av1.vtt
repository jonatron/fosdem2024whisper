WEBVTT

00:00.000 --> 00:12.000
Good morning everyone. Thank you for coming to the Postgres Dev Room. This is our first

00:12.000 --> 00:19.480
opener. We're good? Yeah, we're good. The microphones working, yeah. My name is Bruce

00:19.480 --> 00:24.520
Momjin. I am one of the Postgres core team members and it's a pleasure to be here. I

00:24.520 --> 00:29.960
was told this is the death slot for a speaker but hey this is looking really good. So,

00:29.960 --> 00:37.800
thank you for coming. I promise you an interesting 50 minutes. I hope not to disappoint because

00:37.800 --> 00:43.760
I'm going to talk about some pretty complicated things and I hope they will be very interesting.

00:43.760 --> 00:47.400
They're certainly very interesting to me and hopefully they'll be interesting to you as

00:47.400 --> 00:54.360
well. As you know we have a whole span of Postgres talks today. I was looking through

00:54.360 --> 00:59.560
the list of talks and they look really interesting so I know you won't be disappointed.

01:00.560 --> 01:07.920
This talk is actually a follow up to another presentation that I've already done and I'm going to go over that in a

01:07.920 --> 01:14.920
minute. Probably the most interesting point here is this right here and this QR code which is a link to

01:14.920 --> 01:26.320
62 Postgres presentations, 2700 slides, 121 videos of me speaking about Postgres. So, if you are curious

01:26.360 --> 01:34.360
about Postgres and you'd like to know more about this presentation or others please feel free to go to that URL

01:34.360 --> 01:46.360
and hopefully that will help you. So, as I said before this is a follow on to a talk that I did,

01:46.360 --> 01:54.000
originally wrote in 2011. So, by the way these slides are online right now so if you want the slides and you want to

01:54.040 --> 02:00.040
look at them closer to your laptop for example just go to that URL you'll find those presentations right there.

02:00.040 --> 02:10.040
So, this is a follow on to a presentation I did in 2011 about the optimizer. I'm going to ask for a show of hands,

02:10.040 --> 02:18.040
how many people have either seen the slides, a video or me present that talk. Okay, not a whole lot.

02:18.080 --> 02:26.080
Alright, so that's good to know. That talk is basically giving you an introduction to the optimizer. As you may

02:26.080 --> 02:34.080
know, optimizer is a critical part of a database. It allows you the system to choose when to use indexes and which

02:34.080 --> 02:43.080
type of join methods to use, how the importance of statistics and things like limit clauses and so forth.

02:43.120 --> 02:51.120
So, if you're curious about looking at the precursor of this presentation, again this URL here at the bottom

02:51.120 --> 02:57.120
will work and if you download the slides you can just click on that little URL down there at the bottom

02:57.120 --> 03:05.120
and that will take you to that presentation. But that is not about what this talk is about. That talk is about

03:05.160 --> 03:12.160
the basics of the optimizer and this talk is about everything else which is why we call it beyond joins and indexes

03:12.160 --> 03:20.160
because it's beyond the concept of joins and indexes is what we talked about in the previous talk.

03:20.160 --> 03:31.160
We are going to talk about 43 other things that Postgres does beyond again using indexes and join types.

03:31.200 --> 03:39.200
There's a lot of them that are actually really, really interesting. I learned a lot in preparing this talk

03:39.200 --> 03:47.200
and I hope you'll learn a lot as I prepare it. I color coded some of all the sections although I kind of ran out of colors

03:47.200 --> 03:56.200
as you can see but you can see they're kind of grouped together. For example, the ones over here on the right,

03:56.240 --> 04:04.240
the mustard color, yellow I guess. The green ones are related to comment table expressions. I have a talk on my website

04:04.240 --> 04:11.240
about comment table expressions. These other ones are about parallelism. The red ones, the pink ones are related to

04:11.240 --> 04:16.240
aggregates and so forth. So again hopefully this is helpful to you.

04:16.280 --> 04:29.280
Another aspect of Postgres is the ability to control the optimizer. I will not specifically talk about all of the configuration

04:29.280 --> 04:37.240
parameters but this is a list of pretty much all the config parameters that Postgres allows you to use to control the

04:37.280 --> 04:44.280
optimizer. Again we have two URLs here that I think are very helpful for you to study that.

04:44.280 --> 04:53.280
The ones right up here are the ones that I covered in my previous talk so I'm not going to be discussing the ones

04:53.280 --> 05:00.280
from the previous talk here but I will cover all of these right here related to things like gather merge,

05:00.320 --> 05:08.320
parallel, hash ag, memo wise which is kind of a funny term, incremental sort and so forth. I will not be covering these

05:08.320 --> 05:16.320
although I do cover these in another talk about partitioning which again is on my website so if you're

05:16.320 --> 05:20.320
curious about partitioning that is where you would go for that.

05:20.320 --> 05:29.320
Now I would love to say that I have a grand story about all of the join types that weaves into a

05:29.360 --> 05:38.360
very poetic narrative but unfortunately I can't do that. As you can imagine the join types are kind of distinct.

05:38.360 --> 05:49.360
There is not a real great way of presenting them in a sort of a way that connects them together.

05:49.360 --> 05:56.360
So we're basically going to spend the next 45 minutes basically going through the individual types and explaining why

05:56.400 --> 06:03.400
they're used and why they're important. And again we're going to start with some really silly ones that are really

06:03.400 --> 06:10.400
kind of not very useful but as we get forward we'll start to see some really interesting ones and of course at the end

06:10.400 --> 06:18.400
we have some really bizarre ones in some ways. The first one we're going to talk about is called a result node.

06:18.400 --> 06:25.400
If any of you have ever round explained before and you see these node types in the explain plan that's what we're

06:25.440 --> 06:32.440
going to be talking about. So you probably see the things like index scan, sequential scan, merge join, hash join,

06:32.440 --> 06:38.440
nested loop. You see those node types before. Those node types are talking about my previous talk.

06:38.440 --> 06:45.440
What I'm going to talk about now are the node types that I did not cover in my previous talk which are actually

06:45.440 --> 06:53.440
really interesting. Another thing that you should be aware of is that this presentation was originally written as SQL.

06:53.480 --> 07:02.480
So I basically created an SQL script that had a whole bunch of queries with explain running and then I ran it and then

07:02.480 --> 07:10.480
I captured it and I put it up into the slide deck and colorized it and labeled it and so forth. So if you want to run

07:10.480 --> 07:19.480
this presentation download this SQL file right here at that URL and just run it through PSQL and it'll just like fly off

07:19.520 --> 07:28.520
your screen. The only problem is you don't get the colors. It's just all one color. But you can test it. You can see

07:28.520 --> 07:35.520
and reproduce what you're seeing basically by running that SQL. Probably no questions about the result type.

07:35.520 --> 07:42.520
The result type is basically result is just a constant. Whether it's a string or whatever it's just a constant.

07:42.560 --> 07:51.560
There's nothing fancy going on here. You're basically just saying select one. Another thing is I'm using colon explain

07:51.560 --> 07:58.560
and you're going to see that over and over again in the presentation. Colon explain basically just turns off the costs.

07:58.560 --> 08:05.560
It's just so it makes it simpler for you to see. You don't see numbers in here that really aren't adding anything to the presentation.

08:05.600 --> 08:14.600
That's a PSQL feature right there, the backslash set and the ability to run explain without costs. That will reproduce the presentation

08:14.600 --> 08:23.600
on your screen. This one you might not have seen before and you might be a little surprised. This is not part of the SQL that I

08:23.600 --> 08:31.600
used back in the 90s. I guess SQL 89 didn't have this. I don't, Vic isn't here. He would know when we added this.

08:31.640 --> 08:40.640
This part of the SQL standard, it's basically the values clause is basically like a select with a bunch of values.

08:40.640 --> 08:47.640
Except that it's kind of like select with a union and select with a union. Instead of doing that, you can just type values

08:47.640 --> 08:58.640
and it makes a row of one and the second row has the number two. It's basically a very kind of throw off the cuff kind of a clause.

08:58.680 --> 09:05.680
It has a special scan node which is called values and that's exactly what it looks like. Another thing you're going to see over and over

09:05.680 --> 09:16.680
again in this talk is things that are in blue are causes of things that are in red. If we look at this slide, for example,

09:16.680 --> 09:27.680
the cause is values in blue and the result is the value scan. That's the output. If you're ever looking at a slide,

09:27.720 --> 09:37.720
you say blue is the cause, red is the output that caused the result of the blue. You'll see that over and over again.

09:37.720 --> 09:49.720
Any questions so far? Great. Generate series. This is just an example. There are many other cases where functions generate multiple rows.

09:49.760 --> 10:00.760
But any function that generates multiple rows, it's going to create a node type called a function scan. Normally functions return

10:00.760 --> 10:09.760
one value. That's kind of the mathematical definition of a function. But of course in SQL, we've gone beyond that.

10:09.760 --> 10:18.760
We have the ability for functions to return multiple rows. Not only multiple values in a row, which you would use in an out clause,

10:18.800 --> 10:33.800
but actually multiple rows. That would be something like a function scan. This is our first legitimate output. This is a case where

10:33.800 --> 10:43.800
we're doing something called an incremental sort. I had trouble understanding what that actually was, but I think this should

10:43.840 --> 10:54.840
illustrate it to you. How many have seen incremental sort before in their plans? Anybody? A couple? Incremental sort is a case where

10:54.840 --> 11:05.840
you're sorting by multiple keys and the earlier part of the key is already sorted, but the latter part of the key is not sorted.

11:05.880 --> 11:15.880
It kind of makes sense. You're incrementally sorting. You've got the front part, the early fields are sorted, and the later parts are not.

11:15.880 --> 11:30.880
So here we have, I've created a table with a million rows, and I've created an index on the first column, x. I've analyzed it, so I've got

11:30.920 --> 11:41.920
statistics on it, and I add a column y on the end of it, and then I select from it, and I do it by x, y. What happens is you can see

11:41.920 --> 11:53.920
the system is smart enough to say, well, I can get part of it sorted by pulling off of the index I've already created, but I can't really do

11:53.960 --> 12:08.960
the y, so I'm going to do an index scan on the x table, and then I'm going to do an incremental sort on top of that, and I already have x sorted,

12:08.960 --> 12:20.960
I'm just going to add the y part. So if you didn't have this, effectively you couldn't use the index, and you'd have to basically resort the whole result set,

12:21.000 --> 12:25.000
obviously it would be much slower, that's why we got incremental sort.

12:25.000 --> 12:34.000
And what you're also going to see in this presentation is a lot of diagrams, because I love diagrams, they help me to see what's going on,

12:34.040 --> 12:44.040
visually. What you can see here is you can see that the table, originally all of the 3's are together, all of the 4's are together,

12:44.040 --> 12:54.040
but you can see all of the y fields, the second column, are all in random order, and effectively what incremental sort does, it knows that the first

12:54.040 --> 13:01.040
blue section is in order, doesn't need to touch that, and it merely sorts the second column.

13:01.080 --> 13:08.080
So we're going to see this kind of pattern over and over, I'll show you the SQL, I'll show you a diagram that kind of explains what it does.

13:08.080 --> 13:09.080
Any questions?

13:09.080 --> 13:11.080
Okay, great.

13:11.080 --> 13:25.080
Unique, you've probably seen this before, this is not necessarily the unique clause when you do DDL, you can actually create a column as unique,

13:25.120 --> 13:35.120
that is actually not what we're doing here, it's basically, typically would use if you're using a distinct clause on top of some kind of result.

13:35.120 --> 13:44.120
So here I'm generating numbers from 1 to 10, I'm ordering them and I'm saying make sure they are distinct, so what we're doing is we're basically doing a function scan,

13:44.120 --> 13:54.120
remember function scan we just saw that earlier, right, and then we're doing a sword on top of that, so all the values are sword together and I'm running unique on it,

13:54.160 --> 14:03.160
basically another way of doing this, this is the way of distinct, another way of needing unique is a union, I'm not sure how many of you remember,

14:03.160 --> 14:13.160
but union always does distinct removal, you know, a duplicate removal, right, unless you use the all clause, unique is always going to remove duplicate,

14:13.160 --> 14:19.160
so even though I'm just saying union, I'm not saying union distinct or anything, it automatically does it that way.

14:19.200 --> 14:28.200
So therefore, when I do 1, 2, I basically am going to take my new result sets, remember, we did remember,

14:28.200 --> 14:34.200
that was the first node type we learned was result, remember, way back, hey, four minutes ago,

14:34.200 --> 14:43.200
then we sort them so all the results are next, the duplicates are next to each other, and then all we have to do is get rid of the duplicates as we go forward,

14:43.240 --> 14:51.240
and again, similar case here, we have a bunch of random numbers, we sort them so all of the duplicates are now next to each other,

14:51.240 --> 15:02.240
you can see the sixes and the threes are next to each other, and then we run the unique on it, and all it does is compare and removes any duplicate next to each other entries,

15:02.240 --> 15:07.240
and we get our unique output, okay, great.

15:07.280 --> 15:18.280
Okay, append, this one exactly what I talked about before, remember I said that union will remove duplicates by default, that's true,

15:18.280 --> 15:27.280
but if you use the union all clause, right, it doesn't remove the duplicates, so we have a special node type just for that,

15:27.280 --> 15:36.280
it's called append, so when you say select one, union all, select two, we have our two result nodes, and we just append the values right on the end of each other.

15:36.320 --> 15:45.320
It's exactly what it looks like, this is my first result set, this is my second result set for the union, and I'm just sticking them, I'm just appending them next to each other.

15:45.320 --> 15:49.320
Very, very, very basic, very basic case.

15:49.320 --> 15:54.320
Okay, merge append, this one's good, okay.

15:54.320 --> 16:05.320
This is kind of weird because it combines two terms that we think we know, right, we just talked about append, we know what that does,

16:05.360 --> 16:19.360
okay, but then we have the merge, which sounds like a merge joined in me, right, it's kind of, you're going to see this pattern where we've got a node type we know,

16:19.360 --> 16:27.360
another node type we know, and if we put the two names together and it does something different, it's not ideal, it's trying to kind of match it,

16:27.400 --> 16:36.400
but this is, what will we have, okay, so what I'm doing here is I'm taking a values clause, which we talked about before, remember values clause,

16:36.400 --> 16:43.400
I'm taking another values clause, I'm union alling them, so I'm appending them together, right,

16:43.440 --> 17:00.440
okay, now I'm appending them together, but each of the unions is already ordered, this is the key aspect here, okay, remember we had append,

17:00.440 --> 17:07.440
append just sticks one on the end of another, I will tell you that putting this presentation together is like a jigsaw puzzle,

17:07.480 --> 17:15.480
because you've got all these node types and you can only talk about the first node, the second node type, if you talked about the first one,

17:15.480 --> 17:25.480
and getting it all to kind of fit in your brain is quite a challenge, I hope I've succeeded, but effectively what we have here is two values clauses,

17:25.480 --> 17:36.480
but these values clauses are automatically ordered, and therefore when we do a union all and we want the result to be ordered,

17:36.520 --> 17:46.520
okay, the stupid way to do it would be to just take the results of a pandemic and then sort the whole result,

17:46.520 --> 17:52.520
right, that would be the silly way to do it, because we already have our results ordered in two pieces,

17:52.520 --> 18:03.520
so what merge a pen does is it takes two result sets that are already ordered and maintains the ordering as it merges them together

18:03.560 --> 18:10.560
and it repends them together, okay, so here you can actually see that right here, we've got our sort,

18:10.560 --> 18:15.560
for the first one we've got our sort for the second one and now we do our merge a pen,

18:15.560 --> 18:19.560
and I apologize for the diagram, but this is the best I can do,

18:19.560 --> 18:26.560
what we have here on the left is the first result set, on the bottom we have the second result set,

18:26.600 --> 18:33.600
as you can see from the query we sorted the first result set here, we sorted the second result set here,

18:33.600 --> 18:40.600
and as we append them together we want to maintain the ordering that those result sets already had,

18:40.600 --> 18:46.600
and to do that we're going to take the lowest value from each result set and just repeat it,

18:46.600 --> 18:53.600
so the lowest value between these two is two, the lowest value between these two is three,

18:53.640 --> 18:59.640
the lowest value between these two is three, the lowest value between this and this is four,

18:59.640 --> 19:12.640
five, six, eight, eleven and twelve, okay, so by using merge a pen we've avoided having to resort the results,

19:12.640 --> 19:17.640
we basically kind of merge them together, and if you're familiar with the way a merge join works,

19:17.680 --> 19:24.680
that's kind of how it works, right, it takes two results and kind of compares them and kind of walks down,

19:24.680 --> 19:30.680
finding the minimum matching values as it merges them together, it's the same concept,

19:30.680 --> 19:37.680
this is what I'm kind of getting at, that the terms that we use here are not random,

19:37.680 --> 19:41.680
like the fact we call this a merge a pen actually has some logic to it,

19:41.720 --> 19:47.720
because we're taking what effectively is a merge join and we're sort of repurposing that concept

19:47.720 --> 19:53.720
to do a pen and retain the sorting, any questions?

19:53.720 --> 19:54.720
Yes sir?

19:54.720 --> 20:01.720
Do you know the same thing by using merge a pen instead of just, I don't think the answer.

20:01.720 --> 20:07.720
So the question is do I know how much time we're gaining by doing merge a pen versus just sorting,

20:07.760 --> 20:14.760
so we have, we're a cost based optimizer, so we know the cost of how, what it would take to sort the whole thing

20:14.760 --> 20:19.760
and what it would take to do merge a pen, so we are always reevaluating that,

20:19.760 --> 20:24.760
all we know as back end developers is we're going to run the cost of both of them

20:24.760 --> 20:28.760
and we're going to figure out which one is faster, I don't know how much benefit it is,

20:28.760 --> 20:35.760
of course it depends on the size of your result set, but we're only going to do merge a pen if it's a win,

20:35.800 --> 20:39.800
if it would be cheaper to do it the other way we do it the other way, right?

20:39.800 --> 20:41.800
Other questions?

20:41.800 --> 20:42.800
Yes sir?

20:42.800 --> 20:49.800
Does the query guarantee the order of the two set periods to leave out the order by?

20:49.800 --> 20:52.800
So the question is if I leave out these order bys,

20:52.800 --> 20:54.800
No, the other, the lower order by.

20:54.800 --> 20:56.800
I'm sorry?

20:56.800 --> 20:57.800
Is that the query?

20:57.800 --> 20:58.800
Yeah, this one here?

20:58.800 --> 20:59.800
No.

20:59.800 --> 21:00.800
This one here.

21:00.800 --> 21:01.800
This one?

21:01.800 --> 21:02.800
Yeah.

21:02.840 --> 21:06.840
Well, if I don't have this here, I'm not going to do a merge a pen,

21:06.840 --> 21:09.840
because I don't need to, I don't just, I'll just append them together,

21:09.840 --> 21:14.840
I don't need to merge them and maintain, the only reason we're doing that,

21:14.840 --> 21:18.840
you see how order by one is in blue, that has to be there,

21:18.840 --> 21:21.840
if that order by isn't there we aren't going to use merge a pen,

21:21.840 --> 21:24.840
because we don't need to preserve it, right?

21:24.840 --> 21:25.840
Yeah?

21:25.840 --> 21:28.840
In that case would the other two order bys also be removed?

21:28.880 --> 21:32.880
So the question is in that other case where the two other order bys also be removed,

21:32.880 --> 21:39.880
the answer is no, because the user would still get the order by of the first result,

21:39.880 --> 21:41.880
and then the second result would be right underneath it.

21:41.880 --> 21:46.880
So they've specified in the query that they want the order by, we're going to maintain that.

21:46.880 --> 21:52.880
But because they've added an order by after it, we're kind of overriding it

21:52.880 --> 21:54.880
and kind of using their order by.

21:54.920 --> 22:02.920
Now I'll admit this is a contrived example, we could have done an index scan to get this order by.

22:02.920 --> 22:06.920
So this is the fact that I've got two order bys up there, you see they're not in blue,

22:06.920 --> 22:09.920
they have to be there, but it could be some other query,

22:09.920 --> 22:13.920
we could be doing an index scan and pull the orders that way,

22:13.920 --> 22:16.920
and that way we don't have to do sorting again, could be anything, right?

22:16.920 --> 22:18.920
Yes.

22:18.960 --> 22:25.960
I told you earlier that we do this order by inside, you kind of like hit the optimizer,

22:25.960 --> 22:29.960
which I'm not supposed to, but I know that you need to restore them.

22:29.960 --> 22:31.960
So it will do this, right?

22:31.960 --> 22:37.960
But I mean in more complex cases it's not necessarily that you had to restore the other two.

22:37.960 --> 22:41.960
So the question is do we need to order by there?

22:41.960 --> 22:46.960
The fact is if there's no ordering of the two results, we aren't going to do order by,

22:47.000 --> 22:51.000
we're just going to do a big one huge sort and just run with it, right?

22:51.000 --> 22:53.000
The only reason we're doing that is that.

22:53.000 --> 23:00.000
Okay, so eight and nine, two new options here.

23:00.000 --> 23:06.000
One is called subquery scan and one is called hash set up.

23:06.000 --> 23:13.000
I know I'm not super proud of hash set up, it sounds like a, I don't know, some kind of science fiction thing,

23:13.040 --> 23:16.040
or I don't know what, but let's just look at this.

23:16.040 --> 23:25.040
So this is a query where we've got a thousand rows and we're saying select from the small table

23:25.040 --> 23:31.040
and then remove or subtract or whatever, how do you explain it?

23:31.040 --> 23:33.040
These other rows.

23:33.040 --> 23:35.040
Now we know by looking at this there are no rows.

23:35.040 --> 23:39.040
Okay, so just go work with me here, all right?

23:39.080 --> 23:45.080
The system doesn't know that, that I've actually removed the rows from the same table twice.

23:45.080 --> 23:47.080
We don't have an optimization for that.

23:47.080 --> 23:52.080
So what we're going to do here is we're going to run something called a subquery scan

23:52.080 --> 23:56.080
and we're going to run it twice because we've got two queries here

23:56.080 --> 24:00.080
and then, I'm sorry, subquery scan and then we're going to do hash set ups.

24:00.080 --> 24:05.080
And again, crazy, crazy diagram, I'm going to walk you through this.

24:05.120 --> 24:10.120
What we basically have, this is the outer part, the first part of the query

24:10.120 --> 24:13.120
and this is the except part of the query.

24:13.120 --> 24:17.120
The query, we're removing all the matches, okay?

24:17.120 --> 24:21.120
And what we're going to do, and this is kind of weird,

24:21.120 --> 24:27.120
is we're going to create, we're going to kind of append the two together

24:27.120 --> 24:32.120
and we're going to put one, a label one for the first query

24:32.160 --> 24:35.160
and a label two for the second query.

24:35.160 --> 24:38.160
Okay, so here's the first query, all with ones in the second column.

24:38.160 --> 24:41.160
Here's, same thing with all, two is in the second column.

24:41.160 --> 24:45.160
And then what we're going to do is we're going to hash them

24:45.160 --> 24:50.160
and we're going to hash them basically in a random order

24:50.160 --> 24:54.160
because again, hashing doesn't have any ordering to it.

24:54.160 --> 25:00.160
And we're going to look for the ones that basically all of the ones

25:00.200 --> 25:03.200
that don't have a two.

25:03.200 --> 25:08.200
So for example, the seven does not have a two match for the hash

25:08.200 --> 25:12.200
and therefore it's part of the output, the three and the six

25:12.200 --> 25:17.200
have a one but without a two and those aren't going to go out.

25:17.200 --> 25:22.200
A 12 is going to come out and the five and the eight and the eleven

25:22.200 --> 25:25.200
have a two without a one.

25:25.200 --> 25:28.200
Okay, so anything basically that has a one without a two,

25:28.240 --> 25:31.240
that's what we're going to output and that's how we're going to implement

25:31.240 --> 25:34.240
this except right here.

25:34.240 --> 25:38.240
Again, we have some, if you want to read this at some point,

25:38.240 --> 25:43.240
this is related to how we do intersect and accept and so forth.

25:43.240 --> 25:46.240
It's kind of interesting if you're curious for later,

25:46.240 --> 25:49.240
you really want to study the slides, feel free to read that.

25:49.240 --> 25:53.240
Setup is what we would use for intersect.

25:53.240 --> 25:57.240
Intersect again, another opportunity here.

25:57.280 --> 26:00.280
So we want to find the ones that are in both of them.

26:00.280 --> 26:04.280
So we have large intersect from large, again same issue.

26:04.280 --> 26:07.280
We do a subquery scan, we append them together, we sort them

26:07.280 --> 26:09.280
and we do set up.

26:09.280 --> 26:13.280
Again, similar diagram, here's the first part, here's the second part.

26:13.280 --> 26:17.280
We label with one, we label with two, we create a joined result,

26:17.280 --> 26:21.280
we create the hash but in this case,

26:21.280 --> 26:25.280
we're now looking for cases that have a one and a two.

26:25.320 --> 26:29.320
Remember before it was cases that have a one without a two?

26:29.320 --> 26:33.320
Now we're looking for cases with a one and a two.

26:33.320 --> 26:37.320
And you can imagine we're kind of using the same code, right?

26:37.320 --> 26:42.320
It's sort of the same idea, it's just the filter you put on at the end.

26:42.320 --> 26:46.320
Because remember this one was all the ones without twos.

26:46.320 --> 26:49.320
This is cases where there's a one and a two together.

26:49.320 --> 26:52.320
Three has a one and two together, five does not,

26:52.360 --> 26:56.360
six has a one and two together, seven, eight, eleven and twelve do not.

26:56.360 --> 27:00.360
So that's intersect.

27:00.360 --> 27:04.360
Any questions?

27:04.360 --> 27:08.360
Materialize, this was an interesting one.

27:08.360 --> 27:11.360
I had trouble kind of understanding what this was,

27:11.360 --> 27:15.360
because materialize to me, there's like a materialize command,

27:15.360 --> 27:19.360
SQL command, like for materialize views.

27:19.400 --> 27:22.400
That's what I thought, is it that?

27:22.400 --> 27:25.400
Again, we're reusing terms quite a bit here.

27:25.400 --> 27:29.400
So what we have is a query that's selection small,

27:29.400 --> 27:33.400
and it also selects from a copy of itself,

27:33.400 --> 27:36.400
but again, the optimizer doesn't know this.

27:36.400 --> 27:40.400
And we're doing a very weird comparison here,

27:40.400 --> 27:43.400
we're doing a not equals.

27:43.400 --> 27:46.400
As you imagine, equals is really easy to do,

27:46.440 --> 27:49.440
not equals is kind of awkward.

27:49.440 --> 27:52.440
So what we end up doing, and I know this is kind of weird,

27:52.440 --> 27:55.440
we basically take the inner side,

27:55.440 --> 28:00.440
and we actually create a memory copy of it.

28:00.440 --> 28:04.440
So we load the matching rows, remember this is a small table,

28:04.440 --> 28:08.440
in fact it says literally small, we know it's a small table.

28:08.440 --> 28:11.440
And it just loads that into memory,

28:11.440 --> 28:15.440
so we can do the not equal comparison much quicker,

28:15.480 --> 28:19.480
than it could if it had to read them out of shared buffers.

28:19.480 --> 28:22.480
That's all it's really doing.

28:22.480 --> 28:27.480
It knows because we're going to be hitting this thing

28:27.480 --> 28:30.480
over and over and over again for not equals,

28:30.480 --> 28:32.480
we don't want to keep hitting the shared buffers,

28:32.480 --> 28:34.480
so we just bring it in, bring a copy in,

28:34.480 --> 28:38.480
and we effectively just do a bazillion comparisons

28:38.480 --> 28:42.480
on our local copy of this very small table.

28:42.520 --> 28:47.520
Memo-wise is a weird one,

28:47.520 --> 28:51.520
that was at I believe in 14, I think, somebody?

28:51.520 --> 28:53.520
Yes sir.

28:53.520 --> 28:55.520
Sorry, what was the phone number?

28:55.520 --> 28:56.520
Yeah.

28:56.520 --> 28:59.520
The local memory, is it a working memory set?

28:59.520 --> 29:04.520
Yeah, this would be your working workman.

29:04.520 --> 29:06.520
Could be, yeah.

29:06.520 --> 29:08.520
So if I cranked up my workman, would a...

29:08.520 --> 29:09.520
Would you work...

29:09.560 --> 29:11.560
So the question is if you cranked up workman,

29:11.560 --> 29:15.560
would you be more likely to do materialize?

29:15.560 --> 29:18.560
Maybe, yeah, I could maybe.

29:18.560 --> 29:19.560
I think so.

29:19.560 --> 29:21.560
Give it a try, yeah.

29:21.560 --> 29:24.560
Okay, Memo-wise was introduced...

29:24.560 --> 29:26.560
Memo-wise is a weird term to me,

29:26.560 --> 29:30.560
like it's a memo, it's like a letter,

29:30.560 --> 29:31.560
like what is it, right?

29:31.560 --> 29:36.560
It turns out that Memo-wise is the sort of academic term

29:36.560 --> 29:38.560
for this thing, and I'll explain what this thing is.

29:38.600 --> 29:40.600
But that's how we got the word Memo-wise.

29:40.600 --> 29:43.600
We had a long discussion about what to call this,

29:43.600 --> 29:46.600
and somebody said, oh, that's Memo-wise.

29:46.600 --> 29:48.600
And we're like, what do you mean that's Memo-wise?

29:48.600 --> 29:50.600
And they sent us some academic paper,

29:50.600 --> 29:52.600
and they're like, oh, okay, that's what it is.

29:52.600 --> 29:54.600
All right, so let's take a look at what Memo-wise is.

29:54.600 --> 29:56.600
So it's kind of hard to set up,

29:56.600 --> 30:02.600
I need to create a table with duplicates

30:02.600 --> 30:06.600
that also is too small to make sense for a hash joint.

30:06.640 --> 30:09.640
I know that's like a big word, a lot of words.

30:09.640 --> 30:13.640
But effectively, what I have here

30:13.640 --> 30:15.640
is I'm going to do a join,

30:15.640 --> 30:19.640
and I have a small table,

30:19.640 --> 30:21.640
but it's not big enough to hash it,

30:21.640 --> 30:23.640
because hashing is expensive.

30:23.640 --> 30:26.640
And I need something that's too big

30:26.640 --> 30:28.640
for a hash joint on the other side.

30:28.640 --> 30:31.640
So it sounds like the requirements

30:31.640 --> 30:33.640
for this thing almost never happened,

30:33.640 --> 30:35.640
but it turns out that Memo-wise has a lot of things.

30:35.680 --> 30:37.680
But Memo-wise happens all the time.

30:37.680 --> 30:39.680
I don't know why,

30:39.680 --> 30:41.680
but when I read the description

30:41.680 --> 30:43.680
and when it's important, I was like,

30:43.680 --> 30:45.680
pfft, nobody's ever going to use this thing.

30:45.680 --> 30:48.680
But it turns out that it actually gets used quite a bit

30:48.680 --> 30:51.680
in real-world applications.

30:51.680 --> 30:54.680
But again, it's a case where we have a lot of duplicates,

30:54.680 --> 30:56.680
something's really big,

30:56.680 --> 30:59.680
something's really small, so you can memo-wise it,

30:59.680 --> 31:01.680
and something's really big,

31:01.680 --> 31:03.680
meaning you're going to do a lot of comparisons.

31:03.720 --> 31:05.720
So we have an index on the Memo-wise field.

31:05.720 --> 31:07.720
So here's the query we select

31:07.720 --> 31:09.720
from small with dupes,

31:09.720 --> 31:11.720
and we join it to a medium table.

31:11.720 --> 31:13.720
And here you see the Memo-wise clause right here.

31:13.720 --> 31:15.720
If you're curious, this blog post right here

31:15.720 --> 31:18.720
does a great job of explaining Memo-wise,

31:18.720 --> 31:20.720
and you can see right here,

31:20.720 --> 31:23.720
Postgres 14 is the release

31:23.720 --> 31:25.720
that that was added in,

31:25.720 --> 31:27.720
because that says Postgres 14 right there.

31:27.720 --> 31:29.720
14 later, right there.

31:29.720 --> 31:31.720
All right, so what does Memo-wise do?

31:31.760 --> 31:35.760
It basically creates a local memory cache

31:35.760 --> 31:39.760
of the table you're joining to.

31:39.760 --> 31:41.760
So basically it's a case where

31:41.760 --> 31:43.760
I know I have a lot of duplicates here.

31:43.760 --> 31:45.760
So here's, like, this is duplicate of that,

31:45.760 --> 31:47.760
this is duplicate of that, so forth.

31:47.760 --> 31:49.760
So I know I have a lot of duplicates,

31:49.760 --> 31:51.760
so I know I'm going to be hitting

31:51.760 --> 31:53.760
the cache over and over again.

31:53.760 --> 31:55.760
Right?

31:55.760 --> 31:57.760
So I'm going to be hitting

31:57.760 --> 31:59.760
the cache over and over again.

31:59.800 --> 32:01.800
Right?

32:01.800 --> 32:04.800
So instead of doing what potentially could be

32:04.800 --> 32:07.800
an index lookup

32:07.800 --> 32:09.800
over and over again

32:09.800 --> 32:11.800
into the index,

32:11.800 --> 32:14.800
I create a cache.

32:14.800 --> 32:16.800
And I basically say, okay, is this a match?

32:16.800 --> 32:19.800
If it is, then I can say that's a join.

32:19.800 --> 32:22.800
If it isn't, then I've got to go over here

32:22.800 --> 32:26.800
and check and refresh and make sure it's okay.

32:26.800 --> 32:28.800
It also has a negative cache.

32:28.840 --> 32:30.840
I'm not showing that, but there's a cache of stuff

32:30.840 --> 32:33.840
that isn't there as well, which I'm not going to show you.

32:33.840 --> 32:36.840
So the point of Memo-wise here,

32:36.840 --> 32:39.840
it's right here, inner-side lookups that return no-os

32:39.840 --> 32:41.840
are also recorded in the cache.

32:41.840 --> 32:43.840
So my point is that when you're going to do

32:43.840 --> 32:45.840
an index lookup over and over again,

32:45.840 --> 32:47.840
because you have a lot of duplicates,

32:47.840 --> 32:49.840
and you're going to be checking it over and over again,

32:49.840 --> 32:51.840
why don't we create a cache

32:51.840 --> 32:53.840
so we can remember the index lookups,

32:53.840 --> 32:55.840
and we don't have to keep doing them.

32:55.840 --> 32:57.840
But again, only in limited cases,

32:57.880 --> 33:00.880
table has to be small, has to be duplicates,

33:00.880 --> 33:02.880
has to be the inner-side,

33:02.880 --> 33:05.880
the Memo-wise side has to have an index,

33:05.880 --> 33:08.880
so we can refresh the cache when we need to.

33:08.880 --> 33:11.880
That makes sense, it sounds like crazy.

33:11.880 --> 33:14.880
I thought it sounded crazy, but it actually is really useful,

33:14.880 --> 33:17.880
and it's kind of cool.

33:17.880 --> 33:19.880
So if you see Memo-wise in the future,

33:19.880 --> 33:21.880
you'll be like, oh, that's kind of neat.

33:21.880 --> 33:25.880
Okay, any questions?

33:25.920 --> 33:29.920
Okay, let's launch into more of a section.

33:29.920 --> 33:33.920
Okay, I know we've kind of hit a bunch of sort of discrete topics.

33:33.920 --> 33:36.920
I'm going to move into an area where we have some coherence.

33:36.920 --> 33:38.920
We kind of move through.

33:38.920 --> 33:42.920
We're going to talk about grouping and aggregates now.

33:42.920 --> 33:47.920
So here's a query where we do a join,

33:47.920 --> 33:50.920
and we're saying x is less than 0, group by x.

33:50.920 --> 33:54.920
So I didn't know that you can do a group by

33:54.960 --> 33:58.960
i when there's no aggregates in the query.

33:58.960 --> 34:02.960
I learned that in doing this presentation.

34:02.960 --> 34:06.960
I thought a group by always had to have some aggregates out here,

34:06.960 --> 34:09.960
but turns out it doesn't.

34:09.960 --> 34:12.960
Basically removing, wearing, adding, what if I does the same thing?

34:12.960 --> 34:14.960
So here's a group clause.

34:14.960 --> 34:17.960
It's going to give me everything x less than 0.

34:17.960 --> 34:20.960
And all it does is it basically just removes the duplicates.

34:20.960 --> 34:22.960
That's all the group does.

34:23.000 --> 34:25.000
It says okay, 1, 1.

34:25.000 --> 34:27.000
Okay, that comes across 1, 2.

34:27.000 --> 34:29.000
I got two of those.

34:29.000 --> 34:31.000
I'm only going to get one of those.

34:31.000 --> 34:33.000
For these I would go across.

34:33.000 --> 34:35.000
I have three of these.

34:35.000 --> 34:37.000
I get one of those.

34:37.000 --> 34:40.000
So again, group by with aggregates is similar to distinct,

34:40.000 --> 34:43.000
except duplicate detection can consider more columns

34:43.000 --> 34:45.000
than those selected in the output.

34:45.000 --> 34:48.000
Again, I give you, that's an option for studying later,

34:48.000 --> 34:50.000
exactly what that means.

34:50.000 --> 34:52.000
You can try it out and see how it works.

34:52.040 --> 34:55.040
You can do a group of a single column,

34:55.040 --> 34:59.040
and that is actually a use for group alone.

34:59.040 --> 35:02.040
You notice I'm getting, notice I have,

35:02.040 --> 35:05.040
these are not unique.

35:05.040 --> 35:09.040
Like this and this and this, these are different,

35:09.040 --> 35:12.040
but they all generate one output.

35:12.040 --> 35:14.040
So it kind of trims off the one column.

35:14.040 --> 35:16.040
I know it sounds really silly,

35:16.040 --> 35:18.040
but there are actual use cases to this.

35:18.040 --> 35:20.040
So all the ones get output,

35:20.080 --> 35:21.080
choose in the first column,

35:21.080 --> 35:23.080
get output, all the freeze get output.

35:23.080 --> 35:26.080
Aggregate, everyone's familiar with this,

35:26.080 --> 35:28.080
the count command, we have a node type for that,

35:28.080 --> 35:31.080
just called aggregate, very easy to predict.

35:31.080 --> 35:33.080
Here's a group aggregate,

35:33.080 --> 35:38.080
which would be a group by with account on top of it.

35:38.080 --> 35:42.080
So this is an aggregate, again, makes sense, right?

35:42.080 --> 35:45.080
We learned aggregate, we learned group.

35:45.080 --> 35:48.080
What do we call the node type when we have aggregate

35:48.120 --> 35:49.120
and group together?

35:49.120 --> 35:51.120
Group aggregate, right, makes a lot of sense,

35:51.120 --> 35:53.120
so that's what we call it.

35:53.120 --> 35:56.120
And group aggregate effectively outputs

35:56.120 --> 35:59.120
the non-aggregate column once,

35:59.120 --> 36:02.120
and just like the group by, which we talked about,

36:02.120 --> 36:04.120
and then instead, for the second column,

36:04.120 --> 36:08.120
it runs an aggregate across that second column, right,

36:08.120 --> 36:10.120
which is what we're all familiar with.

36:10.120 --> 36:13.120
Oh, why do I find networks are available?

36:13.120 --> 36:15.120
Isn't that exciting?

36:15.160 --> 36:19.160
Okay, hash aggregate.

36:19.160 --> 36:23.160
So this is a case where it's not actually an aggregate,

36:23.160 --> 36:30.160
we're basically doing a distinct using a hash.

36:30.160 --> 36:35.160
There's no mention of aggregate here at all, right?

36:35.160 --> 36:38.160
But what effectively we do is we take all of our values,

36:38.160 --> 36:40.160
and we put them in a hash,

36:40.160 --> 36:43.160
and we merely have one value for each hash.

36:43.200 --> 36:46.200
It's very similar to group, the group clause.

36:46.200 --> 36:49.200
Remember how the group clause got rid of duplicates?

36:49.200 --> 36:52.200
This is a way of doing it, except instead of doing it by group,

36:52.200 --> 36:54.200
we're doing it by hash.

36:54.200 --> 36:57.200
Okay, instead of sorting, we can basically just create a hash

36:57.200 --> 36:59.200
and remove the duplicates that way,

36:59.200 --> 37:01.200
and that's what the distinct is.

37:01.200 --> 37:04.200
So normally I wouldn't think of distinct as related to group,

37:04.200 --> 37:08.200
but in fact, I can see now, kind of, okay.

37:08.200 --> 37:12.200
And I have lost my mic, so I'm sorry about that.

37:12.240 --> 37:14.240
I will fix that.

37:16.240 --> 37:18.240
There we go.

37:18.240 --> 37:20.240
Great, okay.

37:20.240 --> 37:23.240
Mixed aggregate, I'm not sure how many of you are familiar with rollup.

37:23.240 --> 37:26.240
I do have a Windows function talk on my website

37:26.240 --> 37:30.240
that explains what rollup does, okay.

37:30.240 --> 37:35.240
And effectively it does, the rollup is basically taking, again,

37:35.240 --> 37:40.240
the unique values and then rolling them up into an aggregate.

37:40.280 --> 37:43.280
Okay, and it also sorts it, which is different than the other one,

37:43.280 --> 37:46.280
because you notice that it's all sorted, okay.

37:46.280 --> 37:51.280
Window functions, again, I have a window function talk on my website,

37:51.280 --> 37:54.280
but again, these are all kind of grouped together.

37:54.280 --> 37:58.280
So this is a sum over the entire result set.

37:58.280 --> 38:00.280
It generates something called a window ag,

38:00.280 --> 38:05.280
and a window ag effectively just takes each individual roll,

38:05.320 --> 38:10.320
but it manages to output an aggregate across all the rows

38:10.320 --> 38:13.320
within the group.

38:13.320 --> 38:17.320
If that makes no sense to you, I recommend you take a look at my window talk.

38:17.320 --> 38:20.320
It is kind of unusual how this works,

38:20.320 --> 38:24.320
but effectively all we're doing here is it allows us to maintain

38:24.320 --> 38:26.320
the distinctness of the rows.

38:26.320 --> 38:29.320
Window functions allow aggregates across rows

38:29.320 --> 38:32.320
while the individual rows remain distinct.

38:32.360 --> 38:35.360
And that's exactly what's happening with the window ag.

38:35.360 --> 38:38.360
Okay, moving on to parallelism,

38:38.360 --> 38:42.360
we do have a nice reference here to the Postgres stocks about parallelism.

38:42.360 --> 38:47.360
I'm going to go over a bunch of parallelism nodes that are quite interesting.

38:47.360 --> 38:50.360
So here is parallel sequential scan,

38:50.360 --> 38:54.360
partial aggregate, gather and finalize aggregate, okay.

38:54.360 --> 38:57.360
So here we're doing a sum on the large table.

38:57.360 --> 39:00.360
So we have a big table, we're doing a sum,

39:00.400 --> 39:02.400
and we generate a whole bunch of parallelism here.

39:02.400 --> 39:05.400
Parallel sequential scan, a partial aggregate,

39:05.400 --> 39:10.400
something called a gather, and then a finalizer aggregate.

39:10.400 --> 39:16.400
So kind of like prepare for the diagram of craziness here.

39:16.400 --> 39:22.400
What we basically have, again, going from left to right,

39:22.400 --> 39:27.400
we have the first part of the sequential scan.

39:27.440 --> 39:30.440
Remember, we're only scanning one table,

39:30.440 --> 39:33.440
but we've broken it up into two parts,

39:33.440 --> 39:37.440
because we want to scan them in parallel, right.

39:37.440 --> 39:41.440
So here we're scanning, we're using one background worker

39:41.440 --> 39:44.440
to scan the first part of the table in parallel.

39:44.440 --> 39:47.440
This is called a parallel sequential scan.

39:47.440 --> 39:49.440
We're taking the second part of the table.

39:49.440 --> 39:53.440
We're also doing a parallel sequential scan on the second part of the table.

39:53.480 --> 39:57.480
We're also going to generate what's called a partial aggregate.

39:57.480 --> 40:01.480
That partial aggregate is going to be the aggregate result

40:01.480 --> 40:07.480
across all of the rows that our parallel sequential scan has processed.

40:07.480 --> 40:10.480
And now we have a partial sum right here.

40:10.480 --> 40:13.480
The same thing down here, this is a partial sum here.

40:13.480 --> 40:18.480
We then send both results to the parent,

40:18.480 --> 40:21.480
which generates something called a gather node.

40:21.520 --> 40:23.520
That kind of makes sense.

40:23.520 --> 40:27.520
Now the gather node is gathering results from parallel workers.

40:27.520 --> 40:29.520
And of course, because we're generating a sum,

40:29.520 --> 40:34.520
all we need to do is add together the two rows that we've gathered,

40:34.520 --> 40:38.520
27, 33, and we issue something called a finalized aggregate,

40:38.520 --> 40:41.520
and that generates my 60.

40:41.520 --> 40:43.520
Okay.

40:43.520 --> 40:46.520
Now again, this is just a two, but we could use a hundred ten.

40:46.520 --> 40:49.520
However many parallelism you decide to use.

40:49.560 --> 40:55.560
And again, it's scanning different parts of the table in parallel.

40:55.560 --> 40:56.560
Yes, sir.

40:56.560 --> 41:00.560
Why there is partial aggregate, finalized aggregate, and aggregate nodes,

41:00.560 --> 41:06.560
because they are just the same, but they are different parts.

41:06.560 --> 41:12.560
And using parallel here, you just aggregate on a smaller size table.

41:12.560 --> 41:17.560
But I don't know why you decided to call three different nodes,

41:17.600 --> 41:19.600
but basically they're the same.

41:19.600 --> 41:24.600
Okay, so the question is why are we doing, why do we have different,

41:24.600 --> 41:27.600
why is this not the same as that basically?

41:27.600 --> 41:32.600
And the reason is that for some, for the sum command, they're the same.

41:32.600 --> 41:38.600
But if I'm doing something like a max or standard deviation or something,

41:38.600 --> 41:42.600
we're going to have different operations to join these together.

41:42.600 --> 41:46.600
So sum is the simplest one, that's the one I use,

41:46.640 --> 41:49.640
but for other aggregates, these would be more complex.

41:49.640 --> 41:52.640
And we may do different things at different stages.

41:52.640 --> 41:57.640
But I see what you're saying, it's sort of, the point is that,

41:57.640 --> 42:00.640
it's just the way it's processed.

42:00.640 --> 42:02.640
They probably, some cases could be the same,

42:02.640 --> 42:06.640
other cases they can't, so we just call them different things.

42:06.640 --> 42:08.640
Okay.

42:08.640 --> 42:12.640
Gather, now we saw merge append.

42:12.680 --> 42:18.680
Now we have gather merge, which sounds kind of like, well, what happened?

42:18.680 --> 42:24.680
Okay. And what gather merge does is it effectively is going to take parallel workers

42:24.680 --> 42:26.680
and then just merge them together.

42:26.680 --> 42:31.680
Again, I have the same parallel scan here, I have a parallel scan here,

42:31.680 --> 42:33.680
I'm going to do a sort.

42:33.680 --> 42:37.680
So again, I'm not using aggregate here, I'm doing a sort.

42:37.720 --> 42:41.720
Okay. And now I've scanned part of it.

42:41.720 --> 42:43.720
You know, I keep doing that, that's not good.

42:44.720 --> 42:49.720
The reason is because of the way the clip, the clip doesn't go into my shirt properly,

42:49.720 --> 42:51.720
so I keep having to shove it in there.

42:51.720 --> 42:53.720
Alright.

42:53.720 --> 42:59.720
So basically we've sorted, within the background worker, our results,

42:59.720 --> 43:03.720
we sorted and now we're going to gather, merge, remember merge append

43:03.760 --> 43:05.760
or merge joint merge, merge append.

43:05.760 --> 43:08.760
We're going to take the lowest of this, the lowest of this,

43:08.760 --> 43:14.760
and then we're just going to keep doing it and then take those and merge the two ordered results together.

43:14.760 --> 43:16.760
Okay.

43:16.760 --> 43:18.760
Makes a lot of sense.

43:18.760 --> 43:22.760
Parallel append, all we're going to do here is we're going to append stuff together.

43:22.760 --> 43:25.760
This is one of the craziest diagrams I have, I think.

43:25.760 --> 43:30.760
So here we're doing, we're doing our background worker parallel scan

43:30.800 --> 43:36.800
and we're going to take the, we're going to append the two of the workers together

43:36.800 --> 43:39.800
because this is a join again and then we're going to take the other part,

43:39.800 --> 43:43.800
we're going to join that and then we're going to sort those

43:43.800 --> 43:45.800
and then we're going to merge them.

43:45.800 --> 43:51.800
So I know it sounds like kind of crazy, but what we're doing is we're doing four sorts

43:51.800 --> 43:56.800
and we're appending them in stages and then we're sorting those in batches.

43:56.840 --> 44:04.840
And then, so it's a combination of basically a parallel scan with a sort involved,

44:04.840 --> 44:06.840
which also happens in background workers.

44:06.840 --> 44:12.840
So again, it's just, it's just, this is the craziest diagram I think we have.

44:12.840 --> 44:15.840
Parallel hash, parallel hash join.

44:15.840 --> 44:20.840
Here we're doing a join, a join in parallel.

44:20.840 --> 44:22.840
Again, crazy diagram.

44:22.840 --> 44:24.840
Here's our parallel sequential scan.

44:24.880 --> 44:30.880
We're going to hash those together in a shared memory hash,

44:30.880 --> 44:33.880
which is kind of like mind blowing,

44:33.880 --> 44:36.880
but effectively we have dynamic shared memory

44:36.880 --> 44:42.880
and we're going to create for the background workers a shared hash table

44:42.880 --> 44:46.880
and they're going to join, push those into the parallel hash table

44:46.880 --> 44:51.880
and then once we get this shared hash,

44:51.920 --> 44:55.920
which has been built by multiple background workers,

44:55.920 --> 45:01.920
we're going to take our outer side and we're going to join against these,

45:01.920 --> 45:06.920
that shared hash into potential background workers.

45:06.920 --> 45:11.920
And then we're going to gather them together and get the result.

45:11.920 --> 45:15.920
So not only are we doing the sorting in parallel,

45:15.920 --> 45:18.920
we're actually creating the hash in parallel

45:18.960 --> 45:22.960
and we're doing the hash join in parallel

45:22.960 --> 45:26.960
and then we're returning the result.

45:26.960 --> 45:31.960
Okay, so I realize it's a lot, but that's exactly what it's doing.

45:31.960 --> 45:34.960
Okay, let's move on.

45:34.960 --> 45:38.960
Comment table expressions, again, have a nice talk about that on my website.

45:38.960 --> 45:42.960
Honestly, I don't get any money for advertising my talks,

45:42.960 --> 45:44.960
but you'd think so from this talk.

45:45.000 --> 45:49.000
So if we do a comment table expression with a materialized node,

45:49.000 --> 45:53.000
we just do something called a CT scan

45:53.000 --> 45:57.000
and effectively all we're doing we're scanning across the comment table expression we created.

45:57.000 --> 46:01.000
Okay, I got it.

46:01.000 --> 46:05.000
Work table scan, this is also with a recursive comment table expression.

46:05.000 --> 46:09.000
We would do that here. We're going to loop around through this

46:09.000 --> 46:13.000
and again we create something called a work table and a recursive union.

46:13.040 --> 46:16.040
This is a diagram from my other presentation.

46:16.040 --> 46:19.040
It talks about how comment table expressions work.

46:19.040 --> 46:22.040
And again, this is a diagram.

46:22.040 --> 46:26.040
It's basically looping in and creating this comment table expression.

46:26.040 --> 46:30.040
And then as you loop through the results,

46:30.040 --> 46:33.040
you're continuing to append to what we call a CT source,

46:33.040 --> 46:36.040
which would be used later in a query.

46:36.040 --> 46:39.040
I know if you're not familiar with comment table expressions,

46:39.040 --> 46:41.040
it's not going to make any sense.

46:41.080 --> 46:43.080
I apologize for that.

46:43.080 --> 46:45.080
I apologize for my microphone.

46:45.080 --> 46:49.080
Project set, this is a case where we have

46:49.080 --> 46:56.080
a function returning multiple rows in the target list.

46:56.080 --> 46:59.080
Not the from clause in the target list.

46:59.080 --> 47:02.080
Very interesting.

47:02.080 --> 47:06.080
Lock rows, if you do for update, we generate a lock rows node.

47:06.080 --> 47:10.080
If you do a table sample, we generate a sample scan.

47:10.120 --> 47:13.120
Not surprising.

47:13.120 --> 47:18.120
If you're using XML table, we actually have a table function scan.

47:18.120 --> 47:23.120
I think that is the only function call that uses that node type.

47:23.120 --> 47:27.120
Just a very special, very obscure case there.

47:27.120 --> 47:30.120
Foreign tables, if you're familiar with those,

47:30.120 --> 47:34.120
we have special foreign scans for those.

47:34.120 --> 47:39.120
If you've ever used CTids, we have a special Tids scan.

47:39.160 --> 47:43.160
CTids are the physical location of the values.

47:43.160 --> 47:47.160
We're basically using a Tids scan for that.

47:47.160 --> 47:49.160
This is what a Tids scan would do,

47:49.160 --> 47:53.160
effectively open a certain page and return a certain value in the page.

47:53.160 --> 47:56.160
Insert generates an insert node.

47:56.160 --> 47:58.160
Update generates an update node.

47:58.160 --> 48:01.160
Delete generates a delete node.

48:01.160 --> 48:03.160
Truncate does not, by the way.

48:03.160 --> 48:05.160
Truncate is different.

48:05.160 --> 48:08.160
Merge, the merge command generates a merge node.

48:08.200 --> 48:12.200
Exists generates something called a semi-join.

48:12.200 --> 48:16.200
A semi-join is very similar to a normal join,

48:16.200 --> 48:20.200
except it stops after the first intermatch.

48:20.200 --> 48:24.200
So it's similar to any other join, but it stops after the first.

48:24.200 --> 48:27.200
It doesn't keep going to find out how many matches there are.

48:27.200 --> 48:30.200
As soon as it finds one, it can stop.

48:30.200 --> 48:33.200
The in clause will use also a semi-join,

48:33.200 --> 48:37.200
and again, some details on how null handling works

48:37.240 --> 48:40.240
for in exists for those people who are curious.

48:40.240 --> 48:43.240
Not exists uses something called an anti-join.

48:43.240 --> 48:45.240
Not surprising.

48:45.240 --> 48:48.240
Anti-join for not exists.

48:48.240 --> 48:51.240
And not in is kind of weird.

48:51.240 --> 48:56.240
So technically exists and in are almost the same for nulls,

48:56.240 --> 49:01.240
but not exists and not in is actually different.

49:01.240 --> 49:05.240
And again, we kind of explain it in the query here.

49:05.280 --> 49:08.280
We also have something called an outer...

49:08.280 --> 49:12.280
We have a feature that I realized during writing this talk

49:12.280 --> 49:15.280
called an outer join removal.

49:15.280 --> 49:19.280
Notice I'm doing a left join on something where

49:19.280 --> 49:23.280
it actually removes the join itself,

49:23.280 --> 49:26.280
because it has a unique index and it knows

49:26.280 --> 49:30.280
there's only one possible match, so it actually got rid of the join,

49:30.280 --> 49:32.280
which I felt was like crazy.

49:32.280 --> 49:34.280
That optimized pretty smart.

49:34.320 --> 49:37.320
And finally, two things I didn't cover,

49:37.320 --> 49:40.320
tuple scan and custom scan.

49:40.320 --> 49:43.320
There are... There's documentation and postgres about it,

49:43.320 --> 49:45.320
but you don't see this very often.

49:45.320 --> 49:48.320
So that does complete what I wanted to do.

49:48.320 --> 49:52.320
I believe the time is exactly 9.50.

49:52.320 --> 49:54.360
Thank you.

