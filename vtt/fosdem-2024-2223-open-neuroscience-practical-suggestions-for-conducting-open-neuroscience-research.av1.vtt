WEBVTT

00:00.000 --> 00:01.000
Cool.

00:01.000 --> 00:02.000
Take it away.

00:02.000 --> 00:03.000
Cool.

00:03.000 --> 00:04.000
Howdy, y'all.

00:04.000 --> 00:05.000
I'm Danielle.

00:05.000 --> 00:06.000
It's nice to see you.

00:06.000 --> 00:07.000
Nice to meet you.

00:07.000 --> 00:10.000
And I'm super excited to talk to you about open neuroscience.

00:10.000 --> 00:13.000
And I'm really glad there's a lot of people here.

00:13.000 --> 00:18.000
I did not expect everybody to come because I know this is a developers conference.

00:18.000 --> 00:23.000
So I'm going to tell you first why you should care about open neuroscience.

00:23.000 --> 00:25.000
First point is that we all have brains, right?

00:25.000 --> 00:30.000
Any time I mention neuroscience, everybody gets really excited because we do have brains

00:30.000 --> 00:35.000
and that is essentially what we are, the integration between our brain and our body.

00:35.000 --> 00:40.000
But the issue is oftentimes our brains don't work the way we'd like them to, right?

00:40.000 --> 00:44.000
Raise your hand if you or somebody you know has ever struggled with mental health,

00:44.000 --> 00:46.000
neurological or psychiatric conditions.

00:46.000 --> 00:47.000
Right.

00:47.000 --> 00:50.000
Everybody's crazy and sad.

00:50.000 --> 00:57.000
And so, and this is not unique, right?

00:57.000 --> 01:02.000
Neurological and neuropsychiatric conditions are one of the greatest contributions to the

01:02.000 --> 01:03.000
global disease burdens, right?

01:03.000 --> 01:09.000
If we think about the fact that 28% of the global disease burden is neurological and

01:09.000 --> 01:13.000
neuropsychiatric, that's including communicable diseases which spread like wildfire.

01:13.000 --> 01:14.000
We all had COVID.

01:14.000 --> 01:17.000
And so we understand the importance of the world.

01:17.000 --> 01:22.000
And so we understand the importance of better neuroscience means better health.

01:22.000 --> 01:25.000
But more than that, why am I presenting this to you?

01:25.000 --> 01:30.000
You may get that implicitly, but I also think there is a long and storied history of

01:30.000 --> 01:32.000
neuroscience and computing.

01:32.000 --> 01:37.000
And so we have been learning from each other and influencing one another since the

01:37.000 --> 01:38.000
inception of our fields.

01:38.000 --> 01:41.000
And to exemplify this, I have two people up there.

01:41.000 --> 01:44.000
Everybody probably knows who John Vaughan Newman is, hooray.

01:44.000 --> 01:49.000
But Rafael Laurent de Neu was a very close collaborator with John Vaughan Newman, and

01:49.000 --> 01:51.000
he was a colleague of Ramoni Kahal.

01:51.000 --> 01:56.000
Out of curiosity, how many of you here do any form of neuro stuff?

01:56.000 --> 02:00.000
More than I thought.

02:00.000 --> 02:05.000
And so you will know Ramoni Kahal is the one who is responsible for any time you've seen

02:05.000 --> 02:09.000
a picture of a neuron, and it's in black and white, probably him.

02:09.000 --> 02:14.000
And so not only were they delving into the structure of neurons to understand how they

02:14.000 --> 02:20.000
functioned, this was seminal to the work of computing for how do we communicate information.

02:20.000 --> 02:25.000
And so you have interactions between Rafael Laurent de Neu, who is understanding how

02:25.000 --> 02:30.000
electricity communicates information through the structure of neurons with John Vaughan

02:30.000 --> 02:35.000
Newman coming together at these conferences on complex systems and biosciences.

02:35.000 --> 02:40.000
This continuing trend of neuroscience and computers have continued to influence them, right?

02:40.000 --> 02:44.000
Fast forward a little bit, you get Frank Rosenblatt and the perceptron, right?

02:44.000 --> 02:48.000
Based on neural networks, literally how neurons communicate with one another.

02:48.000 --> 02:51.000
And so here we are today.

02:51.000 --> 02:56.000
But not only have they continued to learn from each other since the inception of our fields,

02:56.000 --> 03:01.000
now in our kind of open neuroscience focus, we continue to learn from computing science

03:01.000 --> 03:04.000
how we can make neuroscience more applicable.

03:04.000 --> 03:07.000
And so we've all talked about the reproducibility crisis.

03:07.000 --> 03:12.000
I'm not going to spend too much time on it, but we can say that having open source technology,

03:12.000 --> 03:17.000
sharing your code, sharing data, and other techniques that I'll talk to you about today,

03:17.000 --> 03:22.000
are ways that we can improve the quality of neuroscience and therefore hopefully improve

03:22.000 --> 03:24.000
the quality of health for all of us.

03:24.000 --> 03:27.000
But another reason, some of you in this room may be academics.

03:27.000 --> 03:29.000
I hope some of you are academics.

03:29.000 --> 03:33.000
And if there is anything that funders are starting to like, it is the fact that we're

03:33.000 --> 03:34.000
going to be able to do this.

03:34.000 --> 03:39.000
It is the fact that you may have open source technology, or that your work may be reproducible

03:39.000 --> 03:44.000
and shareable, and not just because you have pretty figures, but the fact that funders themselves

03:44.000 --> 03:49.000
are realizing that open neuroscience is more robust, which means it's more often replicated,

03:49.000 --> 03:54.000
which means it's often more generalizable and holds true in ecologically valid and clinically

03:54.000 --> 03:56.000
translational applications.

03:56.000 --> 04:00.000
This means they get what they ask for with their investment back to them.

04:00.000 --> 04:07.000
And so I'm glad personally that funders care about open neuroscience because it then provides

04:07.000 --> 04:12.000
the means for researchers to do the extra time and effort that open practices often take,

04:12.000 --> 04:14.000
and we acknowledge that.

04:14.000 --> 04:20.000
I also think that open neuroscience helps facilitate a synergy between industry and academia.

04:20.000 --> 04:25.000
Oftentimes, industry has a ton of money, but they may be focused on research questions

04:25.000 --> 04:29.000
that are of interest to their stakeholders or profit shareholders,

04:29.000 --> 04:32.000
and maybe not so much time or interest for R&D.

04:32.000 --> 04:34.000
Academia is R&D.

04:34.000 --> 04:39.000
So if there is a little bit more open neuroscience from industry and from academia,

04:39.000 --> 04:41.000
perhaps we can help each other with this.

04:41.000 --> 04:44.000
So when I talk about open research, I'm not just talking about academia,

04:44.000 --> 04:47.000
I'm talking to industry people as well.

04:47.000 --> 04:53.000
And finally, the principles I'll discuss in open neuroscience, a lot of them are transdisciplinary.

04:53.000 --> 04:57.000
There will be some fund neuro-specific examples, which is why I hope you're here,

04:57.000 --> 05:00.000
but there are also many transdisciplinary principles.

05:00.000 --> 05:05.000
So I'm going to move through the different stages of a typical research experiment,

05:05.000 --> 05:08.000
data, preprocessing, analysis, dissemination,

05:08.000 --> 05:13.000
and for each one, I'll just talk about one or more aspects of open neuroscience,

05:13.000 --> 05:15.000
starting with the data we have.

05:15.000 --> 05:20.000
Specifically the fact that I will first talk about the type of data that I mean,

05:20.000 --> 05:22.000
and I mean neuroimaging data.

05:22.000 --> 05:25.000
So we have a beautiful drawing of a brain here.

05:25.000 --> 05:30.000
That was published in 1643, Andreas Vesalius and Dake, what is it?

05:30.000 --> 05:32.000
Dake, Humani Corp. porous day fabrica.

05:32.000 --> 05:34.000
I'm sorry if you're Italian, I just butchered to that.

05:34.000 --> 05:40.000
But he was a visionary in terms of how to visualize the brain.

05:40.000 --> 05:46.000
He was the one who came up with taking this 3D structure that we have and slicing it,

05:46.000 --> 05:51.000
thin sheet by thin sheet and drawing each sheet, and in doing so,

05:51.000 --> 05:54.000
sharing the visualization of how structures connected from top down,

05:54.000 --> 05:58.000
starting to give people a 3D visualization of brain function.

05:58.000 --> 06:03.000
Now that's really cool, but the issue is only the people who could do dissections,

06:03.000 --> 06:05.000
which were not very common,

06:05.000 --> 06:08.000
actually had a chance to interact with these structures themselves

06:08.000 --> 06:11.000
and see how these structures connected in 3D,

06:11.000 --> 06:14.000
and as we know in biology, structure often implicates function.

06:14.000 --> 06:18.000
But worse off is that the structures were dead.

06:18.000 --> 06:23.000
Yes, they can tell you structure, but brains are so complex and filled with electricity

06:23.000 --> 06:25.000
and neurotransmitters and fluids.

06:25.000 --> 06:30.000
A dead brain is a very poor representation of the complex emergent phenomena

06:30.000 --> 06:34.000
of this dynamical pink walnut that we all share.

06:34.000 --> 06:38.000
So this is where neuroimaging comes in, and this is the kind of shit that I do.

06:38.000 --> 06:40.000
This is the kind of stuff that I do.

06:40.000 --> 06:43.000
And so, it's late.

06:43.000 --> 06:46.000
And so these are the ways that I prefer to visualize the brain.

06:46.000 --> 06:49.000
I take the brain, I break it up into a bunch of regions,

06:49.000 --> 06:51.000
like in the top left-hand side,

06:51.000 --> 06:55.000
and then the gif just to the right of that, all those regions,

06:55.000 --> 06:57.000
you see how they connect over time.

06:57.000 --> 07:01.000
The brighter the color means two brain regions, I should have labeled them,

07:01.000 --> 07:06.000
but zero to, in this case, it was zero to 110 brain regions.

07:06.000 --> 07:09.000
I would use a different atlas now, we all improve.

07:09.000 --> 07:12.000
And the lighter the color between the two

07:12.000 --> 07:15.000
means the increased mutual information between them.

07:15.000 --> 07:19.000
And every frame in that is every couple of seconds.

07:19.000 --> 07:22.000
And so this is a person playing a cognitive task.

07:22.000 --> 07:24.000
It's a bit of a memory game.

07:24.000 --> 07:28.000
And we see how the brain evolves its connectivity over time.

07:28.000 --> 07:30.000
That's really cool.

07:30.000 --> 07:33.000
We also have images of how the brain lights up, if you will.

07:33.000 --> 07:35.000
We have better ways of visualizing brain structure.

07:35.000 --> 07:38.000
So this is the neuroimaging data that I'm talking about.

07:38.000 --> 07:41.000
So there's tons of types.

07:41.000 --> 07:44.000
We have EEG, MRI, anachronome, alphabet soup.

07:44.000 --> 07:49.000
The point being is each neuroimaging modality has its own challenges.

07:49.000 --> 07:53.000
In terms of its spatiotemporal resolution, let's take EEG, right?

07:53.000 --> 07:56.000
EEG caps, and I'm going to, this is going to come up later, so.

07:56.000 --> 08:00.000
EEG, raise your hand if you know what EEG is.

08:00.000 --> 08:02.000
Oh, yes!

08:02.000 --> 08:05.000
All right, I'm not going to bore you with a ton of background.

08:05.000 --> 08:09.000
But basically, for those of you who don't, it is a cap pictured here.

08:09.000 --> 08:13.000
It doesn't have to be a cap, but often a cap placed over your head

08:13.000 --> 08:18.000
computes the sum of the cortical electrical activity that we have.

08:18.000 --> 08:22.000
Problem, our brains are not just the outside of our brains, right?

08:22.000 --> 08:26.000
We have tons of nuclei and complex structures deeper within.

08:26.000 --> 08:30.000
That we don't really get with EEG, but EEG is a lot cheaper to use

08:30.000 --> 08:34.000
than my personal favorite, MRI, the superconducting magnetic donut

08:34.000 --> 08:37.000
that we have pictured to the right of the EEG.

08:37.000 --> 08:41.000
And that is a fantastic spatial resolution.

08:41.000 --> 08:44.000
And at the moment, we can get submillimeter resolution.

08:44.000 --> 08:45.000
That's pretty good.

08:45.000 --> 08:48.000
There's still thousands of neurons per voxel or 3D pixel,

08:48.000 --> 08:51.000
but the problem is temporal resolution, right?

08:51.000 --> 08:53.000
I speak quick, the brain moves even quicker.

08:53.000 --> 08:55.000
It's at the speed.

08:55.000 --> 09:00.000
But the issue is with fMRI, we're not measuring electrical activity.

09:00.000 --> 09:04.000
We're measuring the response of blood flow to increase brain activity.

09:04.000 --> 09:07.000
So right now, my language centers are firing, firing, firing,

09:07.000 --> 09:09.000
and it's like using a muscle, right?

09:09.000 --> 09:14.000
The blood flow will come to those brain regions, and that takes time.

09:14.000 --> 09:20.000
Time, that is essentially just a slow down representation of brain function.

09:20.000 --> 09:22.000
Thank goodness the brain is a scale free system,

09:22.000 --> 09:26.000
so we can at least learn some principles from slower temporal resolutions

09:26.000 --> 09:30.000
with EEG's faster temporal rosin and bad spatial resolution with fMRI's.

09:30.000 --> 09:34.000
All this is to say, there are challenges with each.

09:34.000 --> 09:37.000
But if you are going to collect data,

09:37.000 --> 09:40.000
we're going to talk about how you can do it in an open and reproducible manner,

09:40.000 --> 09:43.000
and step one is to think about it from the get-go.

09:43.000 --> 09:45.000
When you are creating your ethics protocol,

09:45.000 --> 09:47.000
when you are designing an experiment,

09:47.000 --> 09:50.000
and you think, okay, I'm just going to have my standard consent form

09:50.000 --> 09:52.000
that my lab or the university typically has,

09:52.000 --> 09:56.000
make sure there's a section about data sharing in your consent forms

09:56.000 --> 10:01.000
and be specific about what types of data you can and will ask participants to share.

10:01.000 --> 10:04.000
So if somebody takes an MRI scan, right,

10:04.000 --> 10:08.000
typically it's very easy to share a group level statistics.

10:08.000 --> 10:11.000
If I take everybody's brain and I do a bunch of processing,

10:11.000 --> 10:14.000
and then at that point it's probably in a standard Atlas space

10:14.000 --> 10:18.000
and you can't backtrack to get to any personal identifiable information.

10:18.000 --> 10:21.000
Problem? That's really boring,

10:21.000 --> 10:26.000
because all of the beauties and the complexity and the individual differences within each of us.

10:26.000 --> 10:30.000
So we have to balance this trade-off of being as open as possible

10:30.000 --> 10:33.000
while being as closed as necessary to protect patient

10:33.000 --> 10:35.000
and participant information.

10:35.000 --> 10:38.000
And so I encourage you to think about that from the outset

10:38.000 --> 10:43.000
and put it in your consent form so that you're not stymied by having all this data,

10:43.000 --> 10:47.000
realizing you can share some cool stuff without harming patient or participant privacy

10:47.000 --> 10:50.000
and realizing you didn't ask them if you could share it.

10:50.000 --> 10:54.000
And nobody likes to get an email or a call six months after you were paid 20 bucks

10:54.000 --> 10:57.000
to participate in a research experiment being like, by the way.

10:57.000 --> 10:59.000
So think about it from the outset.

10:59.000 --> 11:02.000
Another important thing when collecting data

11:02.000 --> 11:05.000
is to consider addressing gender bias.

11:05.000 --> 11:10.000
And so what I mean by this is in many different studies, in most studies,

11:10.000 --> 11:13.000
there's a typical bias to have male participants,

11:13.000 --> 11:17.000
and that is a problem because half the population has female brains.

11:17.000 --> 11:21.000
And so we could think about this with the success, or should I say failure,

11:21.000 --> 11:23.000
of a lot of drugs that go to market, right?

11:23.000 --> 11:27.000
This is not a neuroscience example, but typical medical trials

11:27.000 --> 11:31.000
often have male-dominated participant groups and participant samples.

11:31.000 --> 11:34.000
Then a drug gets approved, ha-zah, we think it's good.

11:34.000 --> 11:36.000
It goes to market, immediately pulled back,

11:36.000 --> 11:39.000
because the other half of the population that now takes that drug

11:39.000 --> 11:43.000
has adverse reactions that we're not accounted for during the clinical trials.

11:43.000 --> 11:48.000
Same stuff goes for doing experiments, get diverse brains.

11:48.000 --> 11:51.000
Which brings me to point three, breaks a weird cycle.

11:51.000 --> 11:53.000
Who knows what weird means as an acronym?

11:53.000 --> 11:54.000
Acronym.

11:54.000 --> 11:57.000
Nice, for those of you, good woke points.

11:58.000 --> 12:02.000
Weird stands for white, educated, industrialized, rich, and democratic.

12:02.000 --> 12:08.000
Most of the time, neuroimaging research is done in western countries,

12:08.000 --> 12:13.000
Australia, the United States, and leaves out a lot of the global south,

12:13.000 --> 12:17.000
often because neuroimaging experiments are expensive and use a lot of resources,

12:17.000 --> 12:21.000
that the global south typically does not have the R&D budget for.

12:21.000 --> 12:23.000
There's some really cool research out there on this.

12:23.000 --> 12:30.000
But point being is the state of neuroscience is not representative of the world's population.

12:30.000 --> 12:32.000
So we need to get better at diverse recruitment.

12:32.000 --> 12:35.000
So for example, I live in London now,

12:35.000 --> 12:41.000
and I looked at the most recent census data to see what's the kind of demography of London.

12:41.000 --> 12:45.000
And I found out only 46% of London is white,

12:45.000 --> 12:47.000
everything else breaks up into different categories.

12:47.000 --> 12:52.000
So I make sure that my study populations are representative of this,

12:52.000 --> 12:57.000
but it's not only cultural or racial ethnic, it's also socio-demographic.

12:57.000 --> 13:00.000
It's very easy for me to go to my university canteen and goes,

13:00.000 --> 13:03.000
who wants 20 pounds to participate in a cool neuroimaging project

13:03.000 --> 13:05.000
that you get a 3D printed brain at the end?

13:05.000 --> 13:06.000
Everybody loves that.

13:06.000 --> 13:10.000
Problem is that everybody there in Imperial College London

13:10.000 --> 13:13.000
tends to probably be very educated and potentially wealthy

13:13.000 --> 13:18.000
and therefore is not subject to the health impacts of the rest,

13:18.000 --> 13:21.000
that literally the rest of the population faces.

13:21.000 --> 13:26.000
So I make a conscious effort to do recruiting in local faith centers,

13:26.000 --> 13:29.000
and I'm talking go to your local Islamic Center,

13:29.000 --> 13:32.000
go to your local synagogue, go to your local Afro-Caribbean church,

13:32.000 --> 13:37.000
get people interested, and I'm not just saying like ask people to do research with you,

13:37.000 --> 13:39.000
show them why it's interesting.

13:39.000 --> 13:42.000
So most of the people I work with have heroin use disorder,

13:42.000 --> 13:45.000
I do addiction neuroscience and psychedelic neuroscience,

13:45.000 --> 13:50.000
and so I go to service users and I say, what would be helpful to you?

13:50.000 --> 13:53.000
What do you want to understand better about yourself?

13:53.000 --> 13:54.000
What would help you?

13:54.000 --> 13:56.000
Maybe not use crack this time.

13:56.000 --> 14:02.000
And so these are the sorts of dynamic conversations you can have with communities

14:02.000 --> 14:04.000
and make sure you have community investment in your research

14:04.000 --> 14:09.000
because the community will give you back that your time and your effort you put in.

14:09.000 --> 14:14.000
And again, better research samples means better generalizability, more robust data.

14:14.000 --> 14:15.000
Huzzah.

14:15.000 --> 14:17.000
Finally, we're going to break various participation.

14:17.000 --> 14:20.000
We talked about EEG earlier for a reason.

14:20.000 --> 14:25.000
If I'm running a neuroimaging experiment, I want to put an EEG cap on somebody's head.

14:25.000 --> 14:29.000
If you have an Afro or just thick and kinky hair,

14:29.000 --> 14:32.000
or you've got box sprays or dreads or banchanauts, whatever,

14:32.000 --> 14:35.000
it means the cap is not going to fit close to your skull,

14:35.000 --> 14:37.000
and I can't get your brain data.

14:37.000 --> 14:38.000
So there's two options.

14:38.000 --> 14:40.000
Participants either say, okay, thank you.

14:40.000 --> 14:41.000
Okay, sorry.

14:41.000 --> 14:46.000
Or they're really patient and kind people who let me move their hair

14:46.000 --> 14:49.000
and put electrodes one by one by one by one in their,

14:49.000 --> 14:52.000
on their scalp so that I can get that data.

14:52.000 --> 14:56.000
The problem is then that we all, I have to make sure I communicate to the participant,

14:56.000 --> 14:59.000
yes, the electrode conducting pace is water soluble,

14:59.000 --> 15:03.000
but maybe ask them, do you want to do this on a hair care day?

15:03.000 --> 15:07.000
And if you do, I want to make sure that I give extra remuneration to participants

15:07.000 --> 15:11.000
who have extra hair care considerations because if I do a study,

15:11.000 --> 15:13.000
my friend washes my hair in the sink.

15:13.000 --> 15:14.000
That's fine.

15:14.000 --> 15:15.000
That works for me.

15:15.000 --> 15:18.000
If somebody else who has to go home, spend a lot more time working on their hair,

15:18.000 --> 15:21.000
they should be reimbursed for that time.

15:21.000 --> 15:22.000
Right?

15:22.000 --> 15:26.000
So think about diversity from the outset of funding your experiments.

15:26.000 --> 15:28.000
I did, that was a long harangue, I'm sorry.

15:28.000 --> 15:32.000
But pros and cons of collecting data is that the pros are that it's customizable

15:32.000 --> 15:34.000
to your research paradigm.

15:34.000 --> 15:37.000
So I'm really interested in the relationship between reward processing,

15:37.000 --> 15:41.000
decision making, and attention, and how it goes wrong in addiction.

15:41.000 --> 15:44.000
Oftentimes it's really hard to get addicts in the scanner, right?

15:44.000 --> 15:48.000
They have a lot of well-founded trust in large structures like universities,

15:48.000 --> 15:50.000
healthcare systems, what have you.

15:50.000 --> 15:56.000
So I often need to go out and collect data, but when I'm developing my computational skill set

15:56.000 --> 16:01.000
and I can just use healthy brains, I'm going to avoid the time and resource expense

16:01.000 --> 16:04.000
of collecting data and utilize what is already out there.

16:04.000 --> 16:10.000
But if you are going to collect data, Danielle's pro tip is to test your analysis pipeline

16:10.000 --> 16:12.000
with a small pilot sample first.

16:12.000 --> 16:15.000
It's not only good for you for your downstream analysis,

16:15.000 --> 16:19.000
but it's great for registered reports, which have we heard of this earlier today at all?

16:19.000 --> 16:21.000
Or in general? Any nods?

16:21.000 --> 16:24.000
Somewhat, okay, not a lot of nods, so we're going to talk about it.

16:24.000 --> 16:28.000
So registered reports are when you say to a journal,

16:28.000 --> 16:29.000
I would like to do this study.

16:29.000 --> 16:32.000
Here's my introduction, here's my methods.

16:32.000 --> 16:35.000
Do you, and it goes through peer review, it's like half the paper goes through peer review.

16:35.000 --> 16:41.000
If they accept it, that means whether or not you have no results, that paper is published.

16:41.000 --> 16:43.000
That's pretty cool.

16:43.000 --> 16:47.000
And that actually gets over the trend where large journals have this,

16:47.000 --> 16:50.000
I don't know if you guys have seen the correlation between the higher impact the journal,

16:50.000 --> 16:56.000
the smaller the p-value a study typically has, and therefore the burying of no results.

16:56.000 --> 17:00.000
So it's really nice that some journals are happy to do registered reports,

17:00.000 --> 17:05.000
which it is more time and effort on early career researchers often or whoever's doing it.

17:05.000 --> 17:11.000
This is why it's nice to say to funders, I'm going to budget extra time to collect this data

17:11.000 --> 17:13.000
in a reproducible and ecologically valid manner.

17:13.000 --> 17:17.000
I'm going to develop my analysis pipeline with some pilot data and test it,

17:17.000 --> 17:20.000
and go to the time and effort of doing a registered report,

17:20.000 --> 17:23.000
then finish recruitment and study sampling.

17:23.000 --> 17:28.000
Open Science takes more time, but for neuroscience example,

17:28.000 --> 17:33.000
if you are going to collect data, data anonymization is important,

17:33.000 --> 17:37.000
because we want to share our data, but if somebody comes into an MRI scan,

17:37.000 --> 17:40.000
and I take an image of your brain, it's not just capturing your brain,

17:40.000 --> 17:42.000
it's capturing your beautiful faces as well.

17:42.000 --> 17:47.000
And so we need to think about how and why we're going to scramble that,

17:47.000 --> 17:54.000
and how we're going to take care of that before we upload this data to whatever open neuroscience data sharing repository.

17:54.000 --> 17:57.000
And I'll cover some of those in a bit.

17:57.000 --> 18:02.000
So I have some examples here of how some people just completely remove the skull,

18:02.000 --> 18:08.000
the other sorts of tissues and what have you, and just go straight up to uploading brains.

18:08.000 --> 18:14.000
You can do defacing algorithms, you can do blurring, masking, whatever.

18:14.000 --> 18:19.000
And so there's pros and cons to each of these, but I just wanted to give this as a highlight

18:19.000 --> 18:25.000
of how we need to think about participant safety before uploading data.

18:25.000 --> 18:29.000
But you could also just use previously available data, and we love this.

18:29.000 --> 18:32.000
My whole PhD was basically the Human Connectome Project.

18:32.000 --> 18:36.000
Pros, it's plug and play, it's well validated, it's easily citable,

18:36.000 --> 18:41.000
but the limitations are what I mentioned before, and it's the pros of collecting your own data.

18:41.000 --> 18:45.000
There's limited study populations, maybe you have the study population you want,

18:45.000 --> 18:48.000
but not the imaging condition you need, etc.

18:48.000 --> 18:53.000
But one thing I really like about open data sets is that even if I collect data,

18:53.000 --> 18:58.000
I can often try to reproduce even some of what I do in my collected data with an open data set,

18:58.000 --> 19:03.000
make sure that my results are replicable with these larger sample sizes

19:03.000 --> 19:06.000
than my lowly grants and funding can afford.

19:06.000 --> 19:09.000
And if you are just going to use open data from the outset,

19:09.000 --> 19:16.000
I encourage you to look from the outset for compatible databases that you can do test-re-test reliability.

19:16.000 --> 19:20.000
So I'm a big fan of using the Human Connectome Project, which is an American project,

19:20.000 --> 19:24.000
in conjunction with the Chinese Human Connectome Project.

19:24.000 --> 19:27.000
So lots of similarities in how the data was acquired,

19:27.000 --> 19:31.000
but you have a really different population from which that data was collected.

19:31.000 --> 19:32.000
Brilliant.

19:32.000 --> 19:34.000
Pre-processing and analysis.

19:34.000 --> 19:36.000
This is what I spend most of my time doing,

19:36.000 --> 19:39.000
and this is what I'm going to spend the least amount of time talking about,

19:39.000 --> 19:42.000
because this gets real technical real quick,

19:42.000 --> 19:44.000
and I don't know how much you know or care about this,

19:44.000 --> 19:47.000
but if you are interested, come find me.

19:47.000 --> 19:52.000
But the thing that I will say is that a lot of pre-processing and analysis

19:52.000 --> 19:55.000
uses a plethora of open-source technology,

19:55.000 --> 19:59.000
and choosing a toolbox can feel like an analysis multiverse.

19:59.000 --> 20:03.000
So when swimming through the sea of analysis techniques that you can use,

20:03.000 --> 20:08.000
one, I'll just leave you with a few tips, one of which is to use bids,

20:08.000 --> 20:10.000
or brain imaging data structure.

20:10.000 --> 20:12.000
It's a way of organizing your data,

20:12.000 --> 20:16.000
where a lot of open-source technology can take your data and shove it through their pipelines,

20:16.000 --> 20:18.000
give you shiny results, but better yet,

20:18.000 --> 20:20.000
if your data is in bid structure,

20:20.000 --> 20:23.000
and when you have properly anonymized it and gotten consent for it,

20:23.000 --> 20:26.000
uploaded it to a data sharing repository,

20:26.000 --> 20:28.000
everybody else can plug and play.

20:28.000 --> 20:31.000
It increases the ability for other researchers to use your data.

20:31.000 --> 20:32.000
We love it.

20:32.000 --> 20:35.000
Now, let's see if this demo will work.

20:35.000 --> 20:37.000
Who's heard of Neurosense?

20:37.000 --> 20:38.000
A few people?

20:38.000 --> 20:40.000
Hazard, but I'm glad most of you haven't,

20:40.000 --> 20:41.000
because that means this is fun and cool.

20:41.000 --> 20:42.000
Actually, I have it pre-loaded.

20:43.000 --> 20:47.000
Neurosense is one of these examples where a ton of data is uploaded,

20:47.000 --> 20:51.000
and we get to see what things look like.

20:51.000 --> 20:53.000
So Neurosense.org, so let's see.

20:53.000 --> 20:55.000
So all these studies that have done language,

20:55.000 --> 20:57.000
they just have language as a part of it, right?

20:57.000 --> 21:01.000
It could be listening, it could be talking, we're keeping it vague,

21:01.000 --> 21:04.000
but you can see how many studies did this say it was?

21:04.000 --> 21:06.000
A thousand one hundred?

21:06.000 --> 21:09.000
That's a lot of studies, and yes, there's some light,

21:09.000 --> 21:10.000
and you can just click through.

21:10.000 --> 21:12.000
You can download these maps.

21:12.000 --> 21:15.000
I won't get too much into why this is really useful

21:15.000 --> 21:18.000
to prevent a circularity of analysis, but it is.

21:18.000 --> 21:21.000
Somebody give me a term.

21:21.000 --> 21:23.000
Dementia.

21:23.000 --> 21:25.000
Dementia, thank you.

21:25.000 --> 21:28.000
Oh, you picked one that you knew was going to be up here, didn't you?

21:28.000 --> 21:29.000
I'm grateful.

21:29.000 --> 21:31.000
Only a hundred and forty-two.

21:31.000 --> 21:34.000
Well, ah, so maybe there's a hundred and forty studies

21:34.000 --> 21:36.000
of frontotemporal lovar dimension?

21:36.000 --> 21:37.000
Who's to say?

21:37.000 --> 21:39.000
Either way, the cool thing about this is not only

21:39.000 --> 21:42.000
can you see the areas of the brain, you can then see all of the studies

21:42.000 --> 21:48.000
that have contributed to those fMRI-based magnitude of the bold signal changes.

21:48.000 --> 21:52.000
You can also do a bunch of FAQs, fun neuroscience and analysis tool.

21:52.000 --> 21:53.000
That'd share it.

21:53.000 --> 21:55.000
Right.

21:55.000 --> 21:56.000
Dissemination.

21:56.000 --> 21:58.000
How are we going to share our stuff?

21:58.000 --> 22:01.000
Who has heard of paywall, the business of scholarship?

22:01.000 --> 22:04.000
If you haven't, you should watch it.

22:04.000 --> 22:08.000
It is a documentary on, and it's free and open source.

22:08.000 --> 22:11.000
If you go to that website, you get to watch the documentary.

22:11.000 --> 22:15.000
There is a terrible, just very boring joke about two minutes in.

22:15.000 --> 22:18.000
If you get past that, the rest is great.

22:18.000 --> 22:23.000
I always say, but the point of this documentary is that it talks about the history

22:23.000 --> 22:28.000
of the for-profit publishing industry and why it's just not great today.

22:28.000 --> 22:33.000
It's a necessary evil, but if you want to learn more about it, check out the documentary.

22:33.000 --> 22:36.000
However, if you're also a part of the academic sphere,

22:36.000 --> 22:40.000
where we need to just fill our CVs with DOI so funders are really happy,

22:40.000 --> 22:44.000
then there are other ways for you to do this other than traditional research outputs,

22:44.000 --> 22:47.000
many of which include things like preprints.

22:47.000 --> 22:49.000
Great, but also protocol papers.

22:49.000 --> 22:54.000
Protocol papers are peer reviewed, and they contribute to this kind of open methodology

22:54.000 --> 22:57.000
and gives you a space to really get into the guts of what you've spent,

22:57.000 --> 23:00.000
probably at least a year, really sweating over.

23:00.000 --> 23:03.000
All of the trials, all of the errors, all of the bugs,

23:03.000 --> 23:05.000
you can put that in a protocol paper.

23:05.000 --> 23:07.000
Otherwise, you just start publishing those.

23:07.000 --> 23:09.000
Registered reports we've talked about.

23:09.000 --> 23:12.000
There's a whole spectrum of open access.

23:12.000 --> 23:14.000
I'm not going to make you sit through it.

23:14.000 --> 23:16.000
These slides will be online, so that's there.

23:16.000 --> 23:18.000
Who's heard of Psyhub?

23:18.000 --> 23:20.000
Good, everybody, moving on.

23:20.000 --> 23:22.000
There are other means of dissemination.

23:22.000 --> 23:26.000
By the way, in the paywall of the documentary, Anna Kay,

23:26.000 --> 23:29.000
I forget her last name, the creator and coder for Psyhub,

23:29.000 --> 23:32.000
she features in it, which is very fun, so she gives cool interviews.

23:32.000 --> 23:35.000
Anyways, how am I doing on time?

23:35.000 --> 23:38.000
You've got like six minutes including questions.

23:38.000 --> 23:39.000
Cool, I'm almost done.

23:39.000 --> 23:41.000
Other means of dissemination.

23:41.000 --> 23:43.000
Y'all have heard of GitHub, but there's a few you haven't,

23:43.000 --> 23:46.000
and if you're a neuro nerd, Nitric is a good one.

23:46.000 --> 23:47.000
There are others.

23:47.000 --> 23:49.000
Open data, I told you to come back.

23:49.000 --> 23:54.000
These are all of the different data sharing repositories for mostly fMRI data,

23:54.000 --> 23:57.000
but there's also EEG data, MEG data.

23:57.000 --> 23:59.000
Have fun.

23:59.000 --> 24:04.000
These are more examples of why we should care about open data,

24:04.000 --> 24:06.000
funding agencies, researchers, the public.

24:06.000 --> 24:08.000
I kind of got over it.

24:08.000 --> 24:10.000
Parting words are going to be short and sweet,

24:10.000 --> 24:12.000
because I actually want to hear your words and questions.

24:12.000 --> 24:16.000
And it's just the simple fact that open neuroscience benefits everyone.

24:16.000 --> 24:18.000
Thank you all for your time and attention.

24:18.000 --> 24:20.000
Thank you.

24:20.000 --> 24:22.000
Thanks.

24:22.000 --> 24:24.000
Thanks.

24:29.000 --> 24:31.000
Questions, my friend?

24:31.000 --> 24:33.000
You in the yellow hoodie.

24:33.000 --> 24:35.000
Thanks a lot for the presentation.

24:35.000 --> 24:38.000
In terms of explainability of these analysis and thanks,

24:38.000 --> 24:41.000
I've read a lot of research papers,

24:41.000 --> 24:43.000
but a lot of them don't really include the code.

24:43.000 --> 24:47.000
And lately maybe it started from 2021.

24:47.000 --> 24:52.000
They had something, so the European Union started publishing some stuff,

24:52.000 --> 24:54.000
but they did not keep up.

24:54.000 --> 24:56.000
And it's not keeping up anymore.

24:56.000 --> 25:00.000
I think there's just only maybe some journals which are accepting and are enforcing that.

25:00.000 --> 25:02.000
So I believe that's going on.

25:02.000 --> 25:05.000
Poorly. I'm also frustrated.

25:05.000 --> 25:08.000
I read a paper. I see the coolest analysis.

25:08.000 --> 25:10.000
I'm like, how can I do this?

25:10.000 --> 25:13.000
And I control F code, control, yeah?

25:13.000 --> 25:16.000
Ah, I told you I was going to do that anyways.

25:16.000 --> 25:18.000
I stink. Okay.

25:18.000 --> 25:22.000
So what do I think about the state of open code sharing?

25:22.000 --> 25:26.000
There was some, you know, progress being made in Europe about it,

25:26.000 --> 25:28.000
but now it's kind of died back.

25:28.000 --> 25:32.000
I'm based in London and I don't see too much of this done in the American sphere as well,

25:32.000 --> 25:35.000
where I'm from. I say, y'all, you can tell.

25:35.000 --> 25:41.000
So I will say that the, to answer the question of the state of data sharing

25:41.000 --> 25:46.000
and neuroscientific papers to increase the interpretability of the analysis

25:46.000 --> 25:50.000
and also the ability for you to just play with it on your own, it's not great.

25:50.000 --> 25:52.000
I wish more journals enforced that.

25:52.000 --> 25:57.000
It's interesting to me that you have funders who ask about open source stuff,

25:57.000 --> 26:03.000
but then the other kind of top gatekeeper of academia publishing journals don't enforce it.

26:03.000 --> 26:07.000
And I think this is where grassroots efforts do so much,

26:07.000 --> 26:12.000
but if you make it policy and regulatory policy as well,

26:12.000 --> 26:14.000
then you'll have a lot more uptake.

26:14.000 --> 26:16.000
And then we can all do it a lot more.

26:16.000 --> 26:18.000
This is probably stuff that you think about yourself,

26:18.000 --> 26:20.000
and I'm sorry I don't have better answers for it.

26:20.000 --> 26:23.000
I also wish it to.

26:23.000 --> 26:27.000
Anyone else? Fun questions?

26:27.000 --> 26:31.000
None? Maybe you're shy. Talk to me after.

26:31.000 --> 26:33.000
Any more questions, my friends?

26:33.000 --> 26:35.000
We do have a minute. We have time for one.

26:35.000 --> 26:37.000
We have time for another as well.

26:37.000 --> 26:39.000
Yes.

26:39.000 --> 26:43.000
You've talked a little bit about scales.

26:43.000 --> 26:45.000
You've talked about the gene in the R.I.

26:45.000 --> 26:47.000
And I have one question.

26:47.000 --> 26:50.000
Immediately pop up when I see such a theory is,

26:50.000 --> 26:55.000
how does all of this relate to the multi-scale problem

26:55.000 --> 26:57.000
in the population of neuroscience?

26:57.000 --> 27:01.000
And...

27:01.000 --> 27:04.000
Yeah.

27:04.000 --> 27:06.000
It's a great question.

27:06.000 --> 27:08.000
It's something that I know the field is trying to...

27:08.000 --> 27:10.000
Oh, thank you for repeating the question.

27:10.000 --> 27:13.000
Yes. When I talked about scale-free systems,

27:13.000 --> 27:19.000
how does this relate to the aspect of multi-scale integration

27:19.000 --> 27:22.000
of neural data in understanding the brain?

27:22.000 --> 27:24.000
Is that a good summary of your question?

27:24.000 --> 27:25.000
Thank you.

27:25.000 --> 27:30.000
Okay. Then, for me, it's trying to harmonize multimodal imaging.

27:30.000 --> 27:34.000
I've not quite bridged the EEG MRI divide,

27:34.000 --> 27:37.000
but I'm starting a bit with PET MRI.

27:37.000 --> 27:42.000
So, in this sense, I am trying to develop a better understanding

27:42.000 --> 27:45.000
of how processes at the neurotransmitter level,

27:45.000 --> 27:48.000
positron emission tomography, to those of you who don't know,

27:48.000 --> 27:51.000
is a way of injecting somebody with a radioactive ligand.

27:51.000 --> 27:55.000
If it's glucose, your brain is an energetically greedy organ.

27:55.000 --> 27:58.000
It takes 20% of the body's cardiovascular output.

27:58.000 --> 28:01.000
If you're using more parts of your brain, you get more blood glucose.

28:01.000 --> 28:04.000
But you can also do it for mitochondrial activity,

28:04.000 --> 28:07.000
for different pathological proteins, regardless.

28:07.000 --> 28:11.000
You can see where cellular-level phenomena

28:11.000 --> 28:13.000
are moving throughout the brain,

28:13.000 --> 28:17.000
and then, because you can do PET and fMRI at the same time,

28:17.000 --> 28:20.000
start to see how those cellular-level processes

28:20.000 --> 28:24.000
relate to these macro-scale processes that we capture with fMRI.

28:24.000 --> 28:27.000
Since those are captured at roughly the same time scale,

28:27.000 --> 28:30.000
we can start to develop an understanding there.

28:30.000 --> 28:33.000
In terms of integrating EEG and fMRI, there's some really cool work

28:33.000 --> 28:36.000
I can maybe share with you a little later if you're interested,

28:36.000 --> 28:39.000
but I have not been able to do it personally yet.

28:42.000 --> 28:43.000
Thank you.

28:43.000 --> 28:44.000
I think it's time to wrap up.

28:44.000 --> 28:45.000
Cool. Thanks.

28:45.000 --> 28:46.000
Thank you.

