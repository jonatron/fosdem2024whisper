WEBVTT

00:00.000 --> 00:29.840
So, hello all.

00:29.840 --> 00:35.520
Thank you for being here till the last and I'm a first-time

00:35.520 --> 00:38.200
presenter so if I get a bit jittery, I'm sorry.

00:38.200 --> 00:43.600
So, the topic that I'm taking is open source AI for localization and accessibility.

00:43.600 --> 00:49.880
Well, the main idea is to use open source AI tools to elevate the

00:49.880 --> 00:55.480
content that you are actually receiving and to enhance the localizations that you can benefit from.

00:55.480 --> 01:22.760
So, okay, so sorry for that.

01:26.240 --> 01:30.360
So, essentially coming back to what I was saying, we can use open source AI to enhance the

01:30.360 --> 01:35.640
subtitling potential and to have voice-to-voice conversion of a lot of videos and audio content

01:35.640 --> 01:39.160
in addition to the text-to-text conversions that we are.

01:40.120 --> 01:42.840
So, you might be wondering what is the actual problem?

01:44.120 --> 01:49.080
So, well, I've seen that most of the time when I'm trying to access a dog.

01:49.880 --> 01:51.240
I'll be having this language issue.

01:52.200 --> 01:55.800
For example, I was working with the technology in the augmented reality realm

01:55.800 --> 01:58.680
and all the documentation was actually in Japanese.

01:58.680 --> 02:04.200
I tried reaching out to the developers over there but unfortunately the language barriers

02:04.200 --> 02:11.480
still hit hard and another case would be with the same guys actually had a few tutorials available

02:11.480 --> 02:14.280
on YouTube but the same case.

02:14.280 --> 02:19.960
I don't speak Japanese and I'm actually unable to convey my ideas to them in the language that I know.

02:20.680 --> 02:23.320
So, this was actually an issue that we were all facing.

02:24.600 --> 02:29.800
And then there's the, so you might be thinking, why can't you use something like Google Translate?

02:29.800 --> 02:31.960
Well, the obvious case is actually data safety.

02:32.520 --> 02:36.200
If I'm working on a cutting-edge technology, I don't want that to be leaked

02:36.200 --> 02:38.520
to other people without my concerns.

02:38.520 --> 02:41.800
Or like I want to release that into the public.

02:41.800 --> 02:47.160
I don't want someone else to just take my data and then release it or without my safety or my approval.

02:47.400 --> 02:53.720
And yeah, when it comes to usability, that's another factor and financials,

02:53.720 --> 02:55.880
when I was actually working as an independent developer,

02:56.440 --> 02:59.080
financials, the financial side was a big issue for me.

02:59.960 --> 03:05.880
I didn't have the money to bankroll something like $1,000 into a translation subscription for every month.

03:08.360 --> 03:11.720
So, let's actually elevate that with a bit more of a user's story.

03:12.520 --> 03:16.680
Suppose I'm a research student and you can actually take the case of augmented reality right now.

03:17.320 --> 03:21.880
I'm trying to work in this very niche case and people actually know about it,

03:22.680 --> 03:24.840
but I can't really converse with them.

03:25.480 --> 03:27.080
I'll be having a few issues like that.

03:28.120 --> 03:32.200
And one of the main problems that I'm facing is actually the lack of resources.

03:33.160 --> 03:37.720
And there could be resources, but they are present in another language that I'm not really

03:39.000 --> 03:41.160
able to understand with or converse with.

03:42.120 --> 03:46.840
So I would actually require the resources to be converted to another language that I speak of.

03:46.840 --> 03:49.400
And I want the conversions to have a diesel level of accuracy.

03:51.320 --> 03:52.440
So that's it.

03:52.440 --> 04:00.120
And for one of the solutions, I can obviously ask for people who actually talk the language

04:00.120 --> 04:04.120
and require their services, but it is expensive and it is time consuming.

04:04.120 --> 04:06.920
So a stop gap would be to use an AI solution.

04:08.440 --> 04:12.920
A similar case would be in the case of the docs manager.

05:16.840 --> 05:41.480
So before I go there, what do we actually have right now?

05:41.720 --> 05:53.800
We have a few text-to-text conversion engines like Indonesia or if you're from India,

05:53.800 --> 05:58.440
there's about 128 languages that are actually spoken and we actually have cover for two.

05:59.080 --> 06:03.880
So if they are from such cases, you will require more coverage and you will require more assistance.

06:04.840 --> 06:15.160
So to sum up with what I was actually talking about so far, we don't have an all-in-one solution

06:15.160 --> 06:19.720
where we can actually use all these, which can actually fulfill all these requirements,

06:19.720 --> 06:24.440
be it from text-to-text, text-to-video or the other way around.

06:25.640 --> 06:29.320
So that is some of the things that I would like to talk about.

06:30.280 --> 06:35.960
And yeah, if we are actually looking for an open source library, I would like to have one that

06:35.960 --> 06:41.880
focuses on the audio and the video translation side because enhancement and accessibility

06:41.880 --> 06:46.760
for the audio and the video side is what is actually helping us to improve the language models

06:46.760 --> 06:49.000
and is helping us to reach a wider audience.

06:50.200 --> 06:54.920
So solutions which can actually help me with the automatic translations can be a good choice.

06:54.920 --> 07:04.120
So just to recap it again, I think I'll just skip this part.

07:04.120 --> 07:07.800
So what I actually require is an open source model that can be executed locally

07:08.440 --> 07:12.920
and actually gives me a decent accuracy or a decent amount of execution time

07:13.640 --> 07:17.560
and helps me enhance the quality of the content that I'm delivering.

07:18.520 --> 07:28.520
So the one to watch for right now is called seamless M40 and it's a model for meta and it's under the MIT and

07:30.360 --> 07:37.160
okay, it's under the MIT and the Creative Commons Live Senses.

07:37.160 --> 07:39.960
So it actually gives you speech-to-speech translation,

07:40.520 --> 07:46.040
speech-to-text, text-to-speech, text-to-text and automatic speech recognition.

07:46.040 --> 07:47.800
So that's a pretty good one.

07:50.200 --> 07:54.200
And as we all have been trying to highlight for the last 10 minutes,

07:54.200 --> 07:56.680
we require that because we need an all-in-one solution.

07:57.880 --> 08:04.200
And I was just, I think I highlighted about all these parts like the super informative video

08:04.200 --> 08:06.680
or the precarious conversations that you are having.

08:06.680 --> 08:10.280
Like if I'm trying to have a conversation with, can I have a name, sir?

08:11.240 --> 08:15.000
Samath. So if I'm having to have a conversation with Samath in his name,

08:16.680 --> 08:21.000
if I'm having to have a conversation with Samath and for a moment let's just

08:21.000 --> 08:25.400
think Samath doesn't speak English, he speaks French, I speak English and it's hard.

08:25.960 --> 08:30.840
So that's the conversation or that's the moment that I would require and that's the moment where I

08:30.840 --> 08:36.040
require a tool like this. But if it's not French, it's some language that's actually not sort of

08:36.120 --> 08:40.920
documented. So say I'm just going to go with Sohili. So yeah.

08:42.600 --> 08:48.280
Okay. Okay. That was a random guess. So yeah. If I'm going with a language like Sohili and I'm

08:48.280 --> 08:52.520
speaking in English or if I'm speaking in my mother tongue called Malayalam, I'm just going to

08:52.520 --> 08:57.080
sit here and I'm trying to explain the concept to him, but he doesn't understand what I'm saying.

08:57.080 --> 09:00.920
I don't understand what he's saying. And that is the moment where we require such a tool.

09:00.920 --> 09:04.200
He might have cutting edge research in the domain, but unfortunately,

09:05.080 --> 09:06.840
it's only accessible to the native speakers.

09:09.080 --> 09:14.600
So as I said, that is where the benefits come in. It's with the universalization of

09:14.600 --> 09:21.880
the resources. Anyone from a large org, a creator, a student, a developer, and basically anyone

09:21.880 --> 09:28.600
who can make use of these technologies and come out with this. So far as the technology that I

09:28.600 --> 09:34.760
mentioned, the M4G is actually under an MIT and a Creative Commons license. So it can only be used

09:34.760 --> 09:42.440
for nonprofit uses. And I believe it should remain like that. So that's the summary. But before we

09:42.440 --> 09:55.320
go, I think there's something else that I can show. So, okay. Excuse me. Okay. Yeah.

09:58.840 --> 10:07.240
Okay. So just suppose I'm this really famous creator and I hope the mic has an arm.

10:14.680 --> 10:19.160
Okay. Sorry. That just played out in a way. So suppose I'm actually a really famous creator

10:19.720 --> 10:27.000
and I'm doing something about AI. So I want this content. I only speak English and I want this

10:27.000 --> 10:31.400
content to reach you guys everywhere. So let's watch the individual video first.

10:47.080 --> 10:55.080
Okay. So let's pause it over there. And maybe how good it would it be if you can actually hear the

10:55.080 --> 10:59.480
same thing in another language. Okay. Wait a second.

11:05.240 --> 11:12.840
So how many of you guys over here know Spanish? Okay. Just tell me whether this even remotely

11:12.840 --> 11:13.560
makes sense to you.

11:26.040 --> 11:33.000
So that's it. Yeah. I'm going to take, yeah. Yeah. It sounds good, right? Yeah. I'm just going to

11:33.000 --> 11:39.560
take it from those two guys. And yeah. The same thing can be actually in French, in Dutch,

11:41.720 --> 11:46.680
in Italian, and in Hindi. I do speak a bit of Hindi, so I can validate that. So yeah.

11:48.440 --> 11:52.440
So would you guys like to hear it in another language? It's going to be the same audio, but

11:52.440 --> 11:56.040
if, okay, for the French speaking guys, I'm just going to play this as well.

12:11.880 --> 12:19.080
So you can see the text, the audio and all this. The model that I'm just mentioned called the seamless

12:19.080 --> 12:29.080
M40 is actually doing all of this in a single model. And I feel it's about time we actually have

12:29.080 --> 12:33.800
a few of these solutions coming into open source as well. That's a totally open source model.

12:33.800 --> 12:38.040
Like this is what I dream of. And maybe I'll be back next year with something that's remotely

12:38.040 --> 12:49.240
close to this. So thank you. Yeah. So any questions?

12:53.320 --> 13:03.000
So the model we're talking about, it's not open source, but it's like usable for non-commercial.

13:03.320 --> 13:08.120
Or is it open source? The model's open source, but you cannot use it for commercial use.

13:09.720 --> 13:12.920
It's having the MIT and the Creative Commons license. Yeah.

13:12.920 --> 13:16.920
Is the training data made public? No, the training data is not public.

13:19.480 --> 13:21.640
It's the classic Facebook thing. Yeah.

13:33.320 --> 13:43.000
So it's speech recognition because it's a problem, the touch problem and now it must for use.

13:53.480 --> 14:00.440
Yeah. It runs on speech recognition. It runs on speech recognition and you're converting it to a

14:00.520 --> 14:04.680
base language and from there you're converting it to this thing. So suppose if I'm speaking

14:05.400 --> 14:10.680
in Hindi and you want the conversation to be in France, it's going to convert the

14:10.680 --> 14:15.400
Hindi's conversation to English and from English it's going to convert it to French.

14:19.240 --> 14:25.800
Talk about the latency between the speaker speaking and understanding all this thing and also

14:26.200 --> 14:34.200
the way. Okay. There are models that in the same model can actually offer capabilities

14:34.200 --> 14:38.600
near 100 milliseconds, but it's a lightweight model and you won't have the accuracy of the

14:38.600 --> 14:45.880
heavy weight one. So we actually have to trade off between accuracy and the speed. So the heavier

14:45.880 --> 14:50.760
the model is or the more parameters it has, you'll be getting more accurate results, but

14:50.840 --> 14:56.120
unfortunately the speed will be coming down and I saw a couple of other hands. Yeah.

14:59.720 --> 15:04.120
The model is 2.7 million parameters one and if you're talking about the actual size of the

15:04.120 --> 15:12.600
models in gigabyte, it's about eight gigabytes. Yeah. So just to clarify a few things that have

15:12.760 --> 15:19.400
already kind of been answered. The licensing is MIT and Creative Commons? Not or.

15:19.960 --> 15:28.120
And correct? Yeah. Oh, okay. And then the other thing is when you are translating from one language

15:28.120 --> 15:35.480
to another, you said that some of the models have a latency of about 100 milliseconds.

15:36.200 --> 15:42.840
And how long did those audio samples you showed us? How long did they take to run?

15:44.680 --> 15:48.280
It took me like three seconds, but I'm running it on a call up T for GPU. So

15:49.080 --> 15:53.400
it depends on the GPU. Right. Yeah, I'm sorry. Sure.

15:53.400 --> 16:03.400
So

16:11.240 --> 16:15.000
the proposed solution that I use over here is the same as the LLM thing.

16:15.000 --> 16:18.120
So you can actually use racks or you can just split the text up into smaller,

16:18.120 --> 16:22.920
smaller bits and then combine it into this. So for example, this model actually performs

16:22.920 --> 16:28.840
better if you have something like 20 seconds of audio. So what I do is if I have a one minute

16:28.840 --> 16:33.320
of audio, I'm going to split it into three chunks of 20 seconds each and it's going to go off from there.

16:46.120 --> 16:47.720
Sorry, I don't have a solution to that.

16:47.960 --> 16:51.720
Yeah. And I think you have a comment.

17:01.480 --> 17:01.960
Yeah, I think.

17:06.040 --> 17:07.720
Okay, sure.

17:08.680 --> 17:09.720
Okay.

17:09.720 --> 17:11.720
So I'm going to go ahead and ask you a question.

17:11.720 --> 17:13.720
Okay.

17:15.720 --> 17:21.720
You can run it locally, but it's going to depend on your GPU speed. That's it.

17:21.720 --> 17:27.720
It's possible to have a view of practical information, link and so on.

17:27.720 --> 17:29.720
Oh, sure.

17:29.720 --> 17:33.720
Okay. So yeah, I just close that a bit early one moment.

17:37.720 --> 17:39.720
Okay.

17:47.720 --> 17:49.720
You can hit me up over here.

17:53.720 --> 17:59.720
So my name is Nevin Koshy Daniel and that's the same for the Gmail ID. You can just text me over here.

18:00.440 --> 18:06.520
And if you're looking for the particular model, you can get it from seamless communications on the

18:06.520 --> 18:13.480
Facebook research page. Yeah. And someone did ask me a question about latency, right? So if you

18:13.480 --> 18:22.120
guys have a moment, then we can have something called seamless expressive. I am not 100% sure how

18:22.120 --> 18:33.320
this will work, but accept. Try the demo. Can you come over here please?

18:33.320 --> 18:35.320
Tate? Sure.

18:37.320 --> 18:39.320
Let's have a try with this.

18:43.320 --> 18:45.320
Do I have to say something in English?

18:45.320 --> 18:47.320
Yeah, I think so.

18:47.320 --> 18:49.320
Or do I have to speak French?

18:49.320 --> 18:53.320
Let's try it with French, I guess. No, I can't speak French. It's not going to work.

18:53.320 --> 18:55.320
Okay.

18:57.320 --> 19:01.320
Yeah, let's speak English and let's translate that to French.

19:01.320 --> 19:03.320
French? Sure.

19:07.320 --> 19:09.320
Oh, you have to allow audio permissions.

19:09.320 --> 19:11.320
Yeah.

19:11.320 --> 19:13.320
Don't worry, I'll just re-bump this out.

19:13.320 --> 19:15.320
Yeah, yeah, yeah, it's okay.

19:15.320 --> 19:17.320
Yeah, right.

19:17.320 --> 19:23.320
Can I use Linux and run this on my server?

19:23.320 --> 19:25.320
I hope that works.

19:25.320 --> 19:29.320
So yeah, it's going to take some time to generate the translation.

19:29.320 --> 19:31.320
Oh, wow.

19:31.320 --> 19:33.320
It's pretty quick.

19:33.320 --> 19:35.320
And...

19:35.320 --> 19:41.320
I don't speak French so for someone who knows the language, it's correct.

19:41.320 --> 19:43.320
It's correct.

19:43.320 --> 19:45.320
That's very cool.

19:45.320 --> 19:49.320
Okay, is the model doing both the translation and the text-to-speech?

19:49.320 --> 19:51.320
Yes.

19:51.320 --> 19:57.320
This model can do all the four things, text-to-text, text-to-speech, speech-to-text, and text-to-another language conversion.

19:57.320 --> 20:01.320
So all the four things, yeah, and automatic speech recognition as well.

20:01.320 --> 20:03.320
So the five things.

20:03.320 --> 20:05.320
To give you guys this...

20:05.320 --> 20:07.320
I am.

20:07.320 --> 20:09.320
Okay.

20:09.320 --> 20:11.320
That's pretty much everything, and thank you.

20:13.320 --> 20:15.320
Thank you.

20:43.320 --> 20:45.320
If you're gonna...

21:13.320 --> 21:15.320
Okay.

21:43.320 --> 21:45.320
Oh.

21:45.320 --> 21:47.320
Yeah, no, I can't see it very well either.

