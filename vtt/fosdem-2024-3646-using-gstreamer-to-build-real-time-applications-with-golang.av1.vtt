WEBVTT

00:00.000 --> 00:13.600
All right, well, welcome back everybody. Up next, the one and only Dan Jenkins is going

00:13.600 --> 00:18.760
to tell us all about G-Streamer and Golang. Take it away, please.

00:18.760 --> 00:25.600
Thank you. Hello, everyone. Can everyone hear me okay? Yeah? Good. Great. Cool. Okay.

00:25.600 --> 00:32.800
I forgot my clicker. Number one rookie thing to do. No, no, I've got my phone. So I'm good.

00:32.800 --> 00:36.720
But yeah, that's why I've got my phone. And it's going to look a little bit weird.

00:36.720 --> 00:44.160
I also forgot to buy I brought two European plugs with me. But one wasn't European. One was American.

00:44.160 --> 00:52.320
So my day did not start off well. So yes, G-Streamer and Golang. So a little bit about me.

00:53.040 --> 00:58.480
Very, oh, that's just going to get really annoying. I'm just going to click. Cool.

00:58.480 --> 01:04.640
Okay, so a little bit about me. So yes, I'm Dan Jenkins. I run a couple of companies.

01:05.360 --> 01:10.240
One called Everycast Labs, one called Nimbleape, and another one called Comcom.

01:11.040 --> 01:18.240
So Everycast Labs does broadcast stuff, bringing in remote talent into broadcast workflows.

01:18.800 --> 01:25.760
Nimbleape is a consultancy service, consultancy company based in the UK. And then Comcom is an

01:25.760 --> 01:32.720
event that we put on for open source people, our way of kind of giving back to the ecosystem that

01:32.720 --> 01:39.600
we build from. I was the very first Google developer expert in the world when it comes to WebRTC.

01:40.240 --> 01:46.720
I'm not saying I'm the best at WebRTC, but I'm the first that actually got accredited by Google's

01:46.720 --> 01:53.600
developer program. I love Lego, and I love real-time media. So yeah, Nimbleape, we're a consultancy,

01:54.560 --> 02:01.600
and if you've got hard problems that you want solved, come talk to us. And Everycast Labs,

02:01.600 --> 02:05.440
we've got that product that I was just talking about called Broadcast Bridge. And then Comcom.

02:06.080 --> 02:13.200
So Comcom is dear to my heart. Historically, it's been a residential event where we bring

02:13.200 --> 02:21.120
everyone, everyone stays in the same place. And then we've got three days of awesome real-time and

02:21.120 --> 02:29.760
open media content. And then we're back in 2024. Dates are still up in the air because of contracts,

02:30.720 --> 02:35.200
but it's not going to be residential this year. We're going to go on tour, so we're not just

02:35.200 --> 02:42.480
going to be in the UK. And that's quite exciting. So to the actual topic, GStreamer building real-time

02:42.480 --> 02:46.240
applications with Golang. So what are we actually going to talk about? We're going to talk about

02:46.240 --> 02:52.240
GStreamer, obviously. We're going to talk about Golang, obviously. But I want to introduce you to

02:52.240 --> 03:01.440
something called GoGST. GoGST has been around for a long time now, but kind of got itself into a

03:01.440 --> 03:07.520
bad state where it was not un-maintained, but there were lots of little forks and lots of little

03:07.520 --> 03:16.480
patches everywhere. And so we've kind of changed how that project's being managed now. And then

03:16.480 --> 03:22.080
also I want to introduce you to something called Pion. So let's take a look at GStreamer first.

03:22.080 --> 03:26.880
Who in the room has heard about GStreamer? Good. That's the answer I was looking for.

03:27.920 --> 03:36.080
So open source multimedia framework basically does everything that you chuck at it in some form.

03:37.040 --> 03:44.080
And I absolutely love GStreamer. So a lot of you might know GStreamer as something like this.

03:46.880 --> 03:52.240
I'm not going to ask you to tell me what that is, because I know that it's kind of taking in an RTSP

03:53.280 --> 03:56.640
source and then doing something with it and then outputting something at the end,

03:56.720 --> 04:07.360
via UDP, but all the stuff in the middle now. But GStreamer is actually super powerful and

04:07.360 --> 04:14.000
ultimately lets you do ingress, do something with it, and then egress. And it kind of boils down to

04:14.000 --> 04:22.720
something that's simple, right? GStreamer can do it all and can do a lot of things. So for us at

04:22.720 --> 04:28.880
everycast labs with our broadcast bridge product, we care about certain things. So GStreamer can do

04:28.880 --> 04:37.600
NDI, GStreamer can do WebRTC, GStreamer can do SRT, can do RTP, it can do HLS, it can do RTMP and

04:37.600 --> 04:45.840
RTSP, right? I'm not telling you anything that you don't know at this point. But for us, at least

04:45.840 --> 04:52.480
with broadcast bridge, GStreamer has a superpower and that superpower is app source and app sync.

04:52.480 --> 05:00.320
How many people in the room know about app source and app sync? Okay, good. That means like 60%

05:00.320 --> 05:07.120
of you are going to learn something now. The rest of you just sit and be happy. So yeah, this is

05:07.120 --> 05:14.160
what we use at broadcast bridge, in our broadcast bridge product. And that's because we don't write

05:14.160 --> 05:21.600
C. And so ultimately kind of adding code to plugins within GStreamer is really difficult for us.

05:22.480 --> 05:28.160
I know that's changing as time is going on. There are more and more Rust plugins, but at its core

05:28.160 --> 05:34.000
there are a load of stuff that we don't feel able to kind of contribute to if we find a problem.

05:34.880 --> 05:44.160
And so a lot of the time we don't like writing C like this, but we do like writing a lot of Go.

05:45.120 --> 05:51.040
And so we end up writing something like this. And this is Go GST.

05:53.680 --> 05:59.760
It was originally created by a guy with the GitHub handle, Tinyzimmer. I love the name.

06:00.880 --> 06:06.240
But now it's in its own GitHub organization. So it's under github.com.

06:06.800 --> 06:21.280
So it's under the new GitHub org and there's three main contributors. I think there's something like

06:21.280 --> 06:32.640
17 total, but there's three main ones. Tinyzimmer me and R.S. Willy. So Lesfawkes is better for

06:32.640 --> 06:42.320
everyone. So this other one, Big, Little Ben. That's from the LiveKit team. And the LiveKit

06:42.320 --> 06:52.160
team had their own fork of Go GST. And they had put a load of work into fixing bugs, but

06:53.360 --> 07:00.320
they were never getting merged back into the project as it was under the Tinyzimmer GitHub.

07:01.120 --> 07:07.440
So now it's forked out. Well, it's not actually forked. We forked it into its own organization

07:07.440 --> 07:12.800
and then did the GitHub magic where we unforked it and then the Tinyzimmer one is now a fork of us.

07:13.600 --> 07:20.800
So there's a lot of GitHub kind of organization going on to make it easier for everyone. Did you

07:20.800 --> 07:30.640
know that GitHub forks don't turn up in Google SEO results and they don't turn up in GitHub

07:30.640 --> 07:36.640
search results either? And search doesn't work in the repo. So yeah, and search doesn't work in the

07:36.640 --> 07:45.760
repo. So basically forks are dumb. I mean, they're not dumb. But forks are bad. We should not be

07:45.760 --> 07:53.040
relying on forks for a long-term thing whatsoever. So yeah, this is actually really great for everyone

07:53.040 --> 08:00.480
now. So less forks is better for everyone. And like I said earlier, BroadcastBridge uses a mixture

08:00.480 --> 08:09.600
of SRT, NDI, WebRTC, among a load of other things as well. And so why, you're probably asking,

08:10.560 --> 08:17.680
why would we even need to use AppSync and AppSync when the modules, the plugins are already in Gstreamer?

08:18.880 --> 08:24.480
Like Gstreamer already knows how to take in an SRT feed. It already knows how to output an NDI

08:24.480 --> 08:32.160
feed and it knows how to do WebRTC stuff. So why are we building on top of AppSync and AppSync?

08:33.120 --> 08:36.960
And it comes down to greater control like I was kind of alluding to earlier.

08:38.720 --> 08:46.560
We use Pion to do WebRTC. And that's not because the Gstreamer implementation isn't good. It's just

08:46.560 --> 08:55.200
that if we want to be able to do anything that isn't implemented into the Gstreamer implementation,

08:55.920 --> 09:01.840
then we'd need to get someone to actually go and change that code. And that's something that we're

09:02.720 --> 09:08.320
able to do. My team aren't capable of doing, but we don't go really, really, really well.

09:09.040 --> 09:12.800
And so we can definitely kind of go and take that greater control.

09:15.280 --> 09:20.720
Like I said, this means we're handling WebRTC in something that we really know. Like, ultimately,

09:24.160 --> 09:29.520
very few people in this room know about transcoding something from one codec to another. And we just

09:29.520 --> 09:38.320
rely on FFMpeg or Gstreamer or whatever to do it for us. It's the same with WebRTC for us. We

09:38.320 --> 09:45.040
really know what we're doing with WebRTC and we want to be able to kind of tweak things that we

09:45.040 --> 09:51.600
can't necessarily tweak with the Gstreamer implementation. But Pion is hugely, hugely

09:51.600 --> 09:57.840
powerful. And this is the other key thing and it's easily upgradeable. So when we actually find a bug

09:57.840 --> 09:59.280
in Pion, we can

11:58.160 --> 12:10.000
a Gstreamer pipeline and never leaving the C level. But cost isn't just measured in terms of

12:10.000 --> 12:17.920
compute. Cost is everything from building the feature all the way through to deploying the

12:17.920 --> 12:25.680
feature and running the feature. And you've got to look at the whole picture. Pion gives us huge,

12:25.760 --> 12:30.400
huge flexibility and we can move fast and we can add new features and ultimately that means

12:30.400 --> 12:36.320
that we win business. So let's take a quick look at AppSource. How many people are actually familiar

12:36.320 --> 12:45.760
with AppSource? Right. So AppSource is just another plugin, module, whatever they're called.

12:47.520 --> 12:55.120
And ultimately, you can put it inside of your pipeline and you can push data into Gstreamer

12:56.560 --> 13:04.480
using AppSource. You set a load of capabilities on that element, that AppSource element,

13:05.280 --> 13:11.200
telling it, oh, well, this media that I'm just about to push into you is this format and this

13:11.200 --> 13:17.920
frame rate and whatever else. And you can push in data or you can make, so you have to push

13:17.920 --> 13:23.360
data in obviously, but you can also make Gstreamer ask you for the data. So instead of just going,

13:23.440 --> 13:28.800
oh, I've got data, data, data, data, data. And then Gstreamer goes, oh, hold on. I can't do anything

13:28.800 --> 13:34.960
with this. Why are you sending me so much data? You can, Gstreamer can actually ask for it. Now,

13:34.960 --> 13:39.840
that's not hugely helpful when it comes to real-time applications because real-time applications,

13:39.840 --> 13:48.160
in the case of Pion, sending us web, getting RTP data from Pion, for example, that's real-time.

13:48.160 --> 13:52.400
And so we want to get that data from Pion and we want to pass it into Gstreamer straight away.

13:53.520 --> 14:00.080
Because we're getting it in this constant flow from Pion. Whereas if you were reading a,

14:01.200 --> 14:07.200
if you were reading a file and then you were passing those chunks into Gstreamer,

14:07.760 --> 14:13.360
well, you've got control over how fast you push those chunks in. And so why not let Gstreamer go,

14:13.360 --> 14:16.560
ah, I want a bit more data. I want a bit more data. I want a bit more data.

14:17.040 --> 14:24.320
Right. App sync is absolutely no different. It's a, it's a plug-in, it's a module. And,

14:24.320 --> 14:27.040
and when you put it into the pipeline, it becomes an element.

14:29.360 --> 14:35.280
And ultimately you get push data out of AppSync. And so imagine you've got AppSource and then you've

14:35.280 --> 14:40.560
got something in the middle, whether or not that's transforming it or transcoding it. And then you've

14:40.560 --> 14:46.160
got AppSync and you're connecting all these bits together. And so you're pushing data in. Gstreamer

14:46.160 --> 14:51.600
is then doing something with it. And then it's pushing it, it's passing it over to AppSync.

14:51.600 --> 14:59.280
And then AppSync sends it out to your application as data. Not as UDP, not, not via report or anything.

14:59.280 --> 15:06.480
It's giving you the, the, the raw buffer of data. So you get pushed your data from AppSync via the,

15:06.480 --> 15:12.080
the, the, the new sample signal and event. I've got some data here you go.

15:12.160 --> 15:22.800
Notice how this is all go lang. So, yeah, let's take a very quick look. So we've got our sync.

15:22.800 --> 15:28.400
So that's an AppSource, AppSync element that I've made. And I'm setting some callbacks on it.

15:28.960 --> 15:38.080
And then we've got new sample funk. And then that gives me, that gives me my, my sync.

15:38.640 --> 15:43.920
And then I'm going to tell it as a return. I'm going to tell it what the return, what the flow

15:43.920 --> 15:53.760
state is. And so I pull the sample. And then if the sample isn't end of, isn't nil, then,

15:53.760 --> 15:59.760
then we carry on. If it is nil, then I'm returning that we are at the end of the stream.

16:00.640 --> 16:06.000
And then buffer. So we get this, our sample. So we're pulling the sample.

16:07.040 --> 16:12.400
And then, and then we're getting the buffer out of that. And then ultimately reading some, some,

16:12.400 --> 16:19.200
some information from that, from that buffer map, changing it from big Indian to little Indian,

16:19.200 --> 16:23.840
I think, or something. And then, and then doing some stuff on it, doing some maths on it.

16:23.840 --> 16:28.640
Not a lot of like useful information there. Like in terms of like, what am I actually then going to

16:28.640 --> 16:36.400
go and do with it? Well, at the moment, it's just printing out RMS. But then you can go off and do

16:36.400 --> 16:44.320
whatever you want with it. For us, that means getting a video and audio data out of G streamer

16:44.320 --> 16:53.200
and chucking it into NDI. Oh, Dan, why are you not using NDI within G streamer? Well, I tell you

16:53.200 --> 16:58.800
number one, when we did our NDI integration, G streamer didn't have NDI. It was, it was completely

16:58.800 --> 17:03.920
separate. It was, it was a different repo. And it wasn't part of the G streamer rust plugins.

17:05.040 --> 17:11.920
And then B, we do extra stuff that G streamer doesn't know how to do yet. So we, we grab tally

17:11.920 --> 17:17.760
information from, from NDI. And to be able to do that, you need access to the underlying NDI sender.

17:18.720 --> 17:24.480
And, and so there's stuff that G streamer can't do yet. Something that we actually want to add in to

17:24.480 --> 17:31.040
G streamer. So that we can stop sending stuff via the NDI SDK directly and we can just let G streamer

17:31.040 --> 17:37.520
deal with it for us. But again, goes back to that cost analysis, right? At the moment, we can get that

17:37.520 --> 17:45.200
data out of G streamer using app sync and chuck it out via NDI. We can do that. And it's relatively

17:45.280 --> 17:50.800
cheap. But then there's a load of extra work for us to be able to kind of go in and figure out the

17:50.800 --> 17:56.640
right way of doing it in G streamer so that like tally information becomes available as a signal.

17:57.920 --> 18:06.320
So yeah, for us, this means that we have to handle RTP and RTCP from Pion. Because Pion,

18:07.360 --> 18:13.920
within WebRTC, WebRTC is made up of lots of standards. But ultimately the media is RTP.

18:14.640 --> 18:21.200
And the bit that tells you what the quality is and everything else that goes with it along with it

18:21.200 --> 18:30.080
is RTCP. So it's very easy to forget about things that are very important when you don't deal with

18:30.080 --> 18:39.040
them. Like RTCP. SFU people in the room will go, ah, you could never forget about RTCP. But as a

18:39.040 --> 18:46.000
web developer, the browser deals with all of this for us. And so it's very easy for us to go, ah,

18:46.000 --> 18:51.040
RTP, I'm going to get my media. I'm going to get my media. And then everything works really,

18:51.040 --> 18:56.880
really well when you're in a really nice network environment. But then you chuck in real life

18:56.880 --> 19:03.440
scenario and the audio in the video goes terrible. Why did the audio and video go terrible? Because

19:03.440 --> 19:11.280
there's no RTCP feedback mechanism to go, ah, something's going wrong. But yeah, GStreamer

19:11.280 --> 19:18.960
makes all of this easy. And very quickly on this very specific thing, we use RTP bin within GStreamer.

19:19.520 --> 19:27.120
So that's that middle bit for us. We use app source, chuck it into RTP bin, and then we do a

19:27.200 --> 19:36.160
load of transcoding and stuff as well. And then we get app sync. RTP bin is magical. If you deal

19:36.160 --> 19:46.160
with RTP at all with GStreamer, then you need to be using RTP bin. There's a lot of text there.

19:47.360 --> 19:53.760
But ultimately, it implements everything you need to be able to handle RTP and RTCP

19:54.720 --> 20:05.040
and demuxing of payloads. And it's just a very nice all in all thing that deals with

20:05.040 --> 20:13.120
everything using all of the separate, all the separate plugins. But it forces it all together

20:13.120 --> 20:23.920
nicely for you. So for us, that's connecting the app source sync pads to RTP bin. And you'll notice

20:23.920 --> 20:33.040
I say pads. So for us, you can see up the top there RTP bin. So we're requesting a pad from RTP bin

20:33.680 --> 20:40.160
in that format. So it's a receive RTCP sync. And then we're also requesting a pad of send RTCP

20:40.240 --> 20:49.840
sync source as well. We then go and make a new app sync and a new app source. And you can see

20:49.840 --> 20:58.960
they're labeled RTCP app sync and RTCP app source. We then add those to our pipeline because otherwise

20:58.960 --> 21:06.960
nothing works. All of your elements have got to be in a pipeline. And then we link our RTCP app source

21:07.840 --> 21:18.720
pad RTCP app source, get static pad source, link RTCP sync pad. Yes. So I'm getting the app,

21:18.720 --> 21:28.880
sorry. I'm grabbing the RTCP sync pad from the RTP bin. And I'm linking it over to the RTCP app source.

21:30.240 --> 21:35.840
So that's basically just saying RTP bin is going to give me some information up to RTCP

21:35.920 --> 21:41.280
information via a pad. And I'm connecting to that pad so that I can then grab that information and

21:41.280 --> 21:50.080
send it over, send it back via Pion up to my web RTCP. So you'll get RTP in, in this case, you'll get

21:50.080 --> 21:58.800
RTP in into RTP bin, but you'll get RTCP in and out. So you'll get told RTCP and you'll also send

21:58.800 --> 22:05.120
it back out as well. And like I say, don't forget about the RTCP. As you can tell, I forgot about the

22:05.120 --> 22:13.680
RTCP and ended up doing certain demos and going, ah, look, it's really great. And then someone went

22:13.680 --> 22:19.840
and tried it on a really crappy internet connection and went, no, Dan, it doesn't work. And, and made

22:19.840 --> 22:28.560
me look rather foolish. So you end up looking something like this. So does everyone know about

22:29.200 --> 22:31.600
the dot graphs that you can generate from GStreamer?

22:33.920 --> 22:41.040
A couple of nods, not that many. So you can, within GStreamer, you can tell it, I want you to export

22:41.040 --> 22:48.640
a dot graph file on anything, on, on a state change or whatever. You, you've got control over when it

22:48.640 --> 22:55.600
generates it. And so for, for me, we, when we've got debugging enabled, we enable a dot graph

22:56.160 --> 23:06.080
generation whenever state changes. And so ultimately, this looks really small and dumb. It's a PDF. So

23:06.080 --> 23:14.240
you can go in and, and look at it in high quality detail. Um, because it's not a PNG. So you've got

23:14.240 --> 23:18.640
lots of options. You can, the dot graph can be converted into lots of different formats.

23:19.360 --> 23:26.560
But the really cool thing about dot graphs is it tells you what's connected to what. And so it's

23:26.560 --> 23:34.240
really great for debugging. And so for us, we've got our app source, um, our app source and our,

23:35.440 --> 23:41.840
our two app sources. So one is, um, one is RTP, which is this one. And then this one is RTCP.

23:42.480 --> 23:48.160
And you can see, I'm coming off the camera. I'm sorry. Um, so you can see that this one's set

23:48.720 --> 23:55.200
with, um, with capabilities to say that this is RTCP. And this one is set with capabilities to say

23:55.200 --> 24:06.800
this is RTP. And so you can see those are linked to a pad within a GST bin, a GST RTP bin. And so

24:06.800 --> 24:12.800
those pads are then connected to an RTP session. The RTP session is then, um, connected to a

24:12.800 --> 24:19.520
demuxer. The demuxer is then connected to a jitter buffer. And the jitter buffer is then able to go.

24:19.520 --> 24:25.760
Oh, well, in this, in this RTP stream that I'm receiving, that's both audio and video,

24:26.480 --> 24:31.920
where it's demuxed it and then it automatically goes, ah, here's the video and here's the audio.

24:32.560 --> 24:34.080
Right. And then it chucks it back out,

24:36.880 --> 24:42.800
chucks it back out, creates some pads for me, which I then connect over to, well,

24:42.800 --> 24:47.760
there's an app sync up there and that's my RTCP app sync. But then you could see here

24:48.800 --> 24:53.680
that it's then connecting out Opus and VPA into my pipeline.

24:54.000 --> 25:02.720
And then this is like the rest of the pipeline, which we don't care about, but like, I get told

25:02.720 --> 25:08.320
it's Opus and I get told it's VPA. And so I'm able to decode it and do stuff with it,

25:09.200 --> 25:17.760
whether or not that's outputting to NDI or whatever. At the end of the, um, at the end of it is, um,

25:17.840 --> 25:22.560
is an app source, uh, sorry, an app, an app sync for sending out via NDI.

25:24.400 --> 25:30.160
So we, we got into go purely because of Pion and Pion gives us loads of control.

25:31.200 --> 25:38.640
It's basically WebRTC in pure Golang. If you ignore the fact that WebRTC does lots of like

25:38.640 --> 25:45.040
actual media stuff, but when you look at, say, the, just the, the network portion of it of sending,

25:45.040 --> 25:48.800
sending data from here and sending it there, then it's pure Golang.

25:50.400 --> 25:55.200
So yeah, you can do any of this with any of the G streamer bindings or you can just, you know,

25:55.200 --> 25:59.520
do it with actual G streamer C. I mean, who actually want to do that? I don't know.

26:00.560 --> 26:05.920
But you can go and use whatever bindings you want. And so there's really nice bindings for Python,

26:05.920 --> 26:10.640
Rust, um, and I haven't used any of the others. Um, I've definitely used the Python one and the,

26:10.640 --> 26:16.240
and the Rust one myself. Um, and the Golang one, I went on there this morning to take the screenshot

26:16.240 --> 26:20.640
and I was like, Oh, where's the Golang one? Um, so here's the pull request to add it to the list.

26:21.920 --> 26:27.040
So if you've got a problem and G streamer doesn't quite solve that problem,

26:27.760 --> 26:32.800
that's what this talks about. This talk is about the fact that you can make G streamer do what

26:32.800 --> 26:38.960
you want it to do using app source and app sync. You can build it yourself with app source and

26:38.960 --> 26:45.680
app sync. So why G streamer? Why not FFM peg? Whatever. G streamer does everything that we

26:45.680 --> 26:53.840
need it to do. It has a fantastic community, super friendly community. And ultimately it's just

26:53.840 --> 26:59.840
super flexible and does exactly what we need it to do. Um, which is not something that we felt as

26:59.840 --> 27:06.640
a team. FFM peg would give us, for example, G streamer has a lot of scaffolding, let's say,

27:06.800 --> 27:14.240
um, and, and gives us an awful lot, um, for free. Whereas G, uh, FFM pegs a little bit more, more

27:14.240 --> 27:21.920
work, right? So my last message is G streamer for the win. Um, so yeah, don't wait for others.

27:21.920 --> 27:26.560
Don't wait for others to build your plugin for you. You can go and build with G streamer,

27:26.560 --> 27:30.640
app source and sync. And that's me. Thank you very much.

