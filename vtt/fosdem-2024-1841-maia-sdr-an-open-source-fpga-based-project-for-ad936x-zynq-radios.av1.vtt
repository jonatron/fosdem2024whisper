WEBVTT

00:00.000 --> 00:10.000
So next speaker is Daniel Estes-Vest, did I get that correct?

00:10.000 --> 00:11.000
Yeah.

00:11.000 --> 00:12.000
Okay.

00:12.000 --> 00:18.000
And he will talk to us about Maya Estee or what, please.

00:18.000 --> 00:19.000
Thank you.

00:19.000 --> 00:20.000
Hello.

00:20.000 --> 00:21.000
I'm sorry for my voice.

00:21.000 --> 00:26.000
Hopefully I will manage to make it to the end of the talk.

00:26.000 --> 00:32.000
I think many of you have already seen this video or a similar demo of Maya's DR,

00:32.000 --> 00:38.000
but in any case I'm going to play it and talk over it to introduce what Maya's DR is.

00:38.000 --> 00:45.000
So this is an open source project with the goal of trying to get more people doing FPGA development

00:45.000 --> 00:47.000
for software defined radio.

00:47.000 --> 00:53.000
And at the moment what the project has is an alternative firmware for the Adam Pluto

00:53.000 --> 01:01.000
similar Zinc-based devices where what you can do is to use the full 61 MHz of bandwidth

01:01.000 --> 01:05.000
which is available in the radio frequency chip.

01:05.000 --> 01:11.000
And on the FPGA you can perform an FFT transform to computer waterfall.

01:11.000 --> 01:16.000
That waterfall is then showed on a web-based interface.

01:16.000 --> 01:18.000
So this is a demo with a cell phone.

01:18.000 --> 01:24.000
You can use that on your PC, on your mobile device, whatever you connect with USB.

01:24.000 --> 01:29.000
And then it just works.

01:29.000 --> 01:31.000
So the...

01:31.000 --> 01:34.000
There is no perfect audio.

01:34.000 --> 01:36.000
Okay, thank you.

01:36.000 --> 01:47.000
The FPGA design is coded in Amaranth which is a Python-based HDL and all the software is done in Rust.

01:48.000 --> 01:59.000
I introduced Maya's DR in 3D's Huffin in the software defined radio academy back in the summer.

01:59.000 --> 02:07.000
What is new since the summer, there is now support for all the devices, the Pluto Plus and the AntsDRs

02:07.000 --> 02:14.000
from Microphase and the nice thing about these AntsDRs is that rather than having the smaller Zinc-70-20,

02:15.000 --> 02:19.000
70-10 they have the larger Zinc-70-20.

02:19.000 --> 02:27.000
So that means that both the regular IIO stuff from analog devices and Maya's DR can fit together

02:27.000 --> 02:36.000
in one of these AntsDRs and you can use them both at the same time with HDR Plus Plus or GQRX or radio

02:36.000 --> 02:42.000
as well as with the web interface of Maya's DR, looking at the same signal.

02:42.000 --> 02:46.000
There is also a new feature which is Spectrum-pictured mode.

02:46.000 --> 02:51.000
It's an alternative to the previous mode which is average power.

02:51.000 --> 02:58.000
This is quite useful to detect burst short signals such as ADS-B or Bluetooth

02:58.000 --> 03:05.000
and the way this is implemented is there is actually a trick where you can basically reuse the same hardware on the FPGA

03:05.000 --> 03:10.000
either as a power integrator to compute average power or as a power comparator

03:10.000 --> 03:13.000
which is the thing you need to do to pick detection.

03:13.000 --> 03:19.000
And of course many backfixes, dependency updates and keeping up with the predict running.

03:19.000 --> 03:24.000
This talk is going to be quite different to the talk I gave at SDR Academy.

03:24.000 --> 03:27.000
It's going to be much more technical.

03:27.000 --> 03:31.000
The other talk was high level project based.

03:31.000 --> 03:36.000
In this I will show the key technical aspects of the project

03:36.000 --> 03:43.000
and my goal with this talk is if anyone sees something here and later on he tells me

03:43.000 --> 03:50.000
hey this looks quite interesting I would like to learn more about it or I know more about this stuff.

03:50.000 --> 03:56.000
Here is some additional information you might find useful or this component could be useful in my project.

03:56.000 --> 03:59.000
I would think this talk has been a huge success.

03:59.000 --> 04:07.000
The topics I will cover is the FFT, the DMA and the waterfall which is rendered in WebGL2 in the web browser

04:07.000 --> 04:13.000
and this is pretty much what you need for the demo I have shown because you do have a waterfall display

04:13.000 --> 04:19.000
you need to do FFTs, you need to send the data out of the FGA

04:19.000 --> 04:23.000
and then you need to use the GPU to render the image.

04:23.000 --> 04:33.000
The FFT is implemented in Amaranth as I said and you can even think of Amaranth in this case as a Python very large generator

04:33.000 --> 04:35.000
and this idea is nothing new.

04:35.000 --> 04:42.000
There are other open source FPGA implementations which use Python as a HDL code generator

04:42.000 --> 04:48.000
because oftentimes in an FFT implementation you want to have flexibility

04:48.000 --> 04:55.000
you want to tweak the pipeline stages or the bit widths or the structure of the FFT

04:55.000 --> 05:02.000
so having some way to generate the code or in this case expressing it directly in Python is quite useful.

05:02.000 --> 05:11.000
The focus is on good performance and low resource usage because the FPGA on the Pluto is not so large

05:11.000 --> 05:16.000
but we still want to get 60 MHz of bandwidth with good results.

05:16.000 --> 05:22.000
The architecture which is used is the single delay feedback decimation in frequency architecture

05:22.000 --> 05:29.000
that is the most common architecture of an FFT done in hardware as in an FPGA

05:29.000 --> 05:39.000
and I will show you some references and some diagrams if you ever want to learn how to implement an FFT on hardware

05:39.000 --> 05:44.000
or to do it yourself, I think these are quite good references

05:44.000 --> 05:48.000
they are the ones I used to learn how to do this.

05:48.000 --> 05:56.000
There is the option to do in RADX2, RADX4 and something which is called RADX2 to the power 2

05:56.000 --> 06:01.000
and I implemented these three options because they are the most commonly used

06:01.000 --> 06:05.000
and I wanted to do a trade-off of hardware resource usage

06:05.000 --> 06:10.000
and in the end RADX2 to the power 2 is the one which gives best results

06:10.000 --> 06:17.000
so that's the one which is the default but you could experiment and even individually select different RADXs

06:17.000 --> 06:22.000
on different pipeline stages because this is all Python classes so you can mix and match

06:22.000 --> 06:26.000
and construct your custom FFT if you need to.

06:26.000 --> 06:31.000
There is something on the FFT which is the Tweedle factor multiplication

06:31.000 --> 06:36.000
if you remember the FFT formula there are these exponential functions

06:36.000 --> 06:42.000
so that is often called Tweedle factors and you need to do a complex multiplication

06:42.000 --> 06:48.000
because everything is complex numbers here so for that you can use 3DSPs

06:48.000 --> 06:53.000
the DSP is the multiplier on the Siling's FPGAs

06:53.000 --> 06:57.000
and there is a trick to write the product of two complex numbers

06:57.000 --> 07:03.000
which usually has four multiplications as just three multiplications and some additions

07:03.000 --> 07:11.000
so you can use 3DSPs or a single DSP to save on FPGAs resources

07:11.000 --> 07:16.000
and the trick is the single DSP is running three times as fast as the rest of the logic

07:16.000 --> 07:24.000
so if you are doing 60 MHz then this is 6 times 3 I think is 180 something or whatever

07:24.000 --> 07:29.000
so that's how you manage to do your three multiplications per sample with just one multiplier

07:29.000 --> 07:35.000
you can configure the bit widths you use throughout the FFT pipeline

07:35.000 --> 07:43.000
and the truncation schedule because when you have an FFT usually you are summing up a lot of samples

07:43.000 --> 07:51.000
so if you keep growing your sample size in order not to truncate any of the least significant bits

07:51.000 --> 07:58.000
things get out of hand pretty quickly so you can select where you want to truncate those bits

07:59.000 --> 08:06.000
there's an optional window multiplication because if you are using these for spectrum display applications

08:06.000 --> 08:12.000
you not only do just the FFT you do a windowed FFT you use something like the black man window

08:12.000 --> 08:19.000
or whatever your humming window to smooth out the FFT have a nice roll off etc

08:19.000 --> 08:23.000
so there is this option to do it inside the FFT core

08:23.000 --> 08:29.000
since all of these is python the FFT is implemented by several python classes

08:29.000 --> 08:37.000
each of the python class has its own model which is a bit exact calculation of the same math

08:37.000 --> 08:44.000
that the FPGA is going to do and you can chain those classes to have the full bit exact model

08:44.000 --> 08:49.000
in python of the FFT and you can run that in simulations or whatever

08:49.000 --> 08:58.000
or compare it against non-pice FFT in continuous integration to make sure that your FFT is working

08:58.000 --> 09:08.000
this is also compared with simulations of the amount of code to make sure that the bit exact model is actually bit exact with the FPGA implementation

09:08.000 --> 09:14.000
this is all customizable so you have parameters in the constructor of the classes

09:14.000 --> 09:24.000
but for my SDR it's a 4k point FFT black man harris window 12-bit input because that's what we get from the ARF chip

09:24.000 --> 09:30.000
and a 10-bit output that's most convenient a thing if you don't want a huge output

09:30.000 --> 09:42.000
and we run with 62.5 MHz clock just to have enough clock speed to process the highest sample rate which is 61.44

09:43.000 --> 09:51.000
the resource usage is quite small only 6 dsp is one of those is for the window multiplication and 9.5 B ramps

09:51.000 --> 09:59.000
which is quite okay for the kind of storage that needs to go in show this in a minute

09:59.000 --> 10:10.000
so this is how the radix 2sqt FFT architecture looks like just let me briefly talk you through this

10:10.000 --> 10:21.000
so this is a 16 point FFT a radix 4 architecture would split this into 4 FFTs so you can see one here one there one there one there

10:21.000 --> 10:30.000
this is the divide and conquer approach on which FFT is based but the problem with radix 4 is that you are performing an FFT of size 4

10:30.000 --> 10:40.000
so you need to add four samples together and you also have this plus j minus j minus one so that's not so convenient for the FPGA

10:40.000 --> 10:49.000
so what we do is this FFT of size 4 we divide it into two again using FFTs of size 2 so you can see this is an FFT of size 2

10:49.000 --> 10:58.000
this is not a FFT of size 2 and here there are again two FFTs of size 2 now they are intertwined

10:59.000 --> 11:09.000
and the advantage by doing this is that the butterfly which is what this is called now only needs to add two samples together each time

11:09.000 --> 11:19.000
so that is less logic usage and compared to radix 2 which is the other alternative you get twice as less stages

11:19.000 --> 11:28.000
and what happens with the stages is each time you have a stage you need to multiply for by these complex exponentials by the two factors

11:28.000 --> 11:34.000
so if you get half the number of stages that means less multiplication so less DSPs

11:36.000 --> 11:46.000
and this is how it looks like once you draw the broad diagram because if you come back to the drawing the first FFT operates the first sample with the sample in the middle

11:46.000 --> 11:55.000
and so on and so forth so of course samples arrive in order what you need to do is to store your samples in a shift register

11:55.000 --> 12:03.000
so that when the sample in the middle comes in the first sample is already at the back here so that's basically how it looks like

12:05.000 --> 12:14.000
the DMA is the part that is used to copy the data from the FPGA to the DDR memory on the zinc

12:14.000 --> 12:22.000
and there are two use cases one is for the waterfall we want to copy one FFT at a time or rather one waterfall line at a time

12:22.000 --> 12:32.000
and the other one is the IQ recorder so another theater of my SDR is you can record up to 400 megabytes of IQ data on the DDR of the Pluto

12:32.000 --> 12:41.000
this is a continuous recording no samples are dropped and then when the recording is finished you can copy it over to your PC or mobile device using the USB 2

12:41.000 --> 12:49.000
of course it's going to be to take more time than to record because USB doesn't have enough bandwidth but still you can do it

12:49.000 --> 13:00.000
so there are two flavors of this DMA one is called Bram write and that copies the contents of a Bram this is used for the waterfall so the waterfall line is in a Bram

13:00.000 --> 13:12.000
and it copies it to a buffer in a ring in the DDR memory the other one is called stream write this reads data from an axis stream like interface

13:12.000 --> 13:25.000
and it writes all the data into a buffer this is what it's used for the IQ recorder the tricks here to get very low resource usage is to implement an axis 3 manager interface

13:25.000 --> 13:34.000
so if you work with silence IP everything is axis 4 but the fun thing about it is the silicon on the system on chip is axis 3

13:34.000 --> 13:43.000
so when you connect silence IP with the system on chip there's a silence protocol converter in the middle which is using some logic to do the conversion

13:43.000 --> 13:52.000
and the fun thing is axis 4 and axis 3 are quite similar one of the main differences is axis 4 allows for longer barsts

13:52.000 --> 14:02.000
so you have this protocol converter that will split the barst for you but even so if you are not using longer barsts then this protocol converter is basically doing nothing

14:02.000 --> 14:11.000
so rather than going with axis 4 we directly do axis 3 and comply with the shorter barsts and we can interface directly into the silicon

14:12.000 --> 14:22.000
the implementation is the most stupid thing ever the almost no control is required by software is just like pressing a button go record for the IQ recorder

14:22.000 --> 14:31.000
and for the waterfall it just runs on its own and it sends an interrupt to the CPU every time a new waterfall line has become bit to the ring buffer

14:31.000 --> 14:40.000
addresses and everything is hard coded at synthesis time so you can change it but you need to rebuild the FAA PGA image

14:40.000 --> 14:47.000
the upside we get is the brusseless usage is extremely low as you can see

15:10.000 --> 15:24.000
it's rather busy it's the interconnection of the zinc taken from Xilinx manual so let me walk you through even though it's fairly impossible to breathe

15:24.000 --> 15:32.000
here are the two CPU cores they are A9 ARM processors each of them has their own L1 cache

15:33.000 --> 15:45.000
the L2 cache is here and is shared by both CPUs in the middle is something called the SKU which is used to ensure coherence between all these three caches

15:45.000 --> 15:59.000
so if one processor writes to the cache the SKU will evict the line from the cache of the other CPU core so that they have a consistent view of the state of the system

15:59.000 --> 16:12.000
and then on the top right on the far right is the DDR controller so DDR is here basically we go from the CPU L1 cache coherence here L2 cache and finally DDR

16:12.000 --> 16:25.000
there are two ways of accessing the DDR from the FPGA one of the ways is through this port actually these are the two CPUs sorry this is the FPGA

16:25.000 --> 16:36.000
so you can go through what is called the ACP port which is the coherent port it will play the same role as another CPU so you get coherence for free but there are some downsides

16:36.000 --> 16:54.000
or you can go through any of these four ports which are the high performance ports they write pretty much directly on DDR but then what happens is you have changed something in DDR but the caches don't know about it so the software must manage your caches manually

16:54.000 --> 17:13.000
summing up the ACP port is good because it is fully coherent so hard work does the job for you the bad thing is there is only one such port and if we are writing continuously on DDR we are evicting cache lines which are actively used by the software

17:13.000 --> 17:28.000
because the eviction policy is random so we are basically disturbing the software usage of the cache it is not so good for performance on the other hand HP ports we have four of them but it doesn't disturb the L2 cache

17:28.000 --> 17:42.000
so it is completely independent of the software that is running but we need to manage coherence manually there are two ways of managing coherence manually one is not to do it which means mark the memory as uncacheable

17:42.000 --> 18:03.000
and that is simple but it is very very slow especially reads because for writes there is something which is called write combining that you can enable and it is still uncacheable but writes go in chunks so that is more efficient but reads even if you use neon instructions to do a mem copy out of these memory it is quite slow

18:03.000 --> 18:29.000
the other alternative is to mark these memory as regular DDR cacheable memory you need to manage cache invalidation manually so the good thing is you have fast accesses very fast like your regular DDR the bad thing is complex it gets really complex and really ugly because of one very specific thing which is here

18:30.000 --> 18:57.000
the Linux kernel has some nice DMA framework where you can manage caches for DMAs and all the things you need to do but we cannot really use this in this situation because we want to map a whole 400 megabyte buffer this is where our IQ recording sits in the DDR but this is a 32 bit platform so in 32 bit platforms you only have 4 gigabytes of virtual address memory

18:57.000 --> 19:23.000
and usually on a Linux system this is split as 3 gigabytes for the user space 1 gigabyte for the kernel and the kernel is already using many mappings in this 1 gigabyte space for lots of stuff so if you ask the kernel can you map for me this 400 megabyte DMA buffer it will say I am out of virtual memory I cannot do it within my 1 gigabyte address space

19:23.000 --> 19:44.000
so we cannot really map these DMA buffers into kernel space we need to map them into user space that's fine because we want to manage the data from user space but by doing so we cannot use the kernel framework to do cache invalidation for us we need to do it manually

19:44.000 --> 20:04.000
and the downside is the functions we need to call are basically private functions in the kernel they are not exported to outer 2 modules or any kernel modules so basically we need to patch the kernel to export those functions and be able to call them from our outer 3 kernel module

20:04.000 --> 20:32.000
and this is quite specific about this particular L2 cache and the L1 cache on the ARM CPUs this is basically what I was saying there's a Linux kernel module which manages the IQ recording and waterfall DMA buffers and takes care of doing cache invalidation when the memory is mapped by the user space

20:32.000 --> 20:40.000
so the user space always sees the fresh copy that the FPGA has written

20:40.000 --> 21:00.000
now let's talk a little bit about the WebGL waterfall this is coded in Rust using WebAssembly and WebGL so basically you are doing Rust but you are calling on a lot of JavaScript functionality which is present on the web browser to do all the WebGL rendering for you

21:00.000 --> 21:09.000
it uses a custom render entry and the waterfall data is stored as a 2D texture on the GPU memory

21:09.000 --> 21:36.000
this uses the same kind of doubly mapped buffer that we are using in radio for our buffers on the blocks because we want to have this nice scrolling waterfall which looks like a continuous thing it's not continuous it's a trick just 2 copies of the image are pasted onto the same rectangle and it can jump and you don't notice the difference because it mimics it's a periodic thing

21:37.000 --> 22:00.000
the fragment shader uses some GL function which is called texture and that performs a texture lookup so the 2D texture is actually power versus frequency and time and then you have your column map and you have those sliders to set the maximum power, minimum power, the column map you want etc

22:00.000 --> 22:11.000
so all of that is updated in real time for all the waterfall when you change the settings because it's the GPU for each render frame doing the full lookup on a 1D texture map

22:11.000 --> 22:28.000
usually when you are updating the waterfall you are doing so one line at a time because if you are rendering 30 frames per second you are only updating either one or no waterfall lines every 30th of a second

22:29.000 --> 22:43.000
so rather than copying all the 2D texture to the GPU each time there is something which is called text sub-image which lets you update a rectangle inside your 2D texture so that's the trick that it's used

22:43.000 --> 23:04.000
and then there are your usual frequency scales so you have text to mark the frequency axis there is something called lines draw mode to draw those and something which gets a lot of newcomers to WebGL I was a newcomer when doing this is now we are going to render some text

23:04.000 --> 23:21.000
but the problem is the GPU doesn't really have any text rendering functionalities and WebGL2 is rather low level so you can render text to show text what you need to do is to pre-render the text on some textures and then use the GPU to show those textures

23:21.000 --> 23:38.000
luckily we are running on the web browser so the web browser knows how to render text to something which is called 2D canvas so we use that we have the web browser write text outside of the screen and use that texture on the GPU that's the trick

23:39.000 --> 23:46.000
and in the interest of time I think I'm basically going to show a demo I had here

23:48.000 --> 24:01.000
so there is this web page which is a demo of the MySDR waterfall if you go to MySDR.org you can just open it and it should work in any recently modern web browser

24:01.000 --> 24:16.000
and you can see here this is recorded data this is actually a JPEG image just for the show but you have all the functionality of the waterfall you can scroll you can see signals and it keeps going

24:16.000 --> 24:34.000
and I think I have a couple more minutes so I can walk you through the code very very quickly this is the code of the waterfall demo you show just to show you that it's quite simple you can incorporate this on your own projects

24:35.000 --> 24:46.000
so basically what you have is we call this get window and document window and document our objects that you need to use in JavaScript to interact with the web browser

24:47.000 --> 25:02.000
we create a new waterfall associated with canvas which is on the HTML page we set up some parameters of the waterfall and the frequency your sample rate etc etc so we are calling a few methods of the waterfall to set those

25:03.000 --> 25:19.000
and then we have a generator in this case it's basically putting in the waterfall line by line taken from a JPEG image because this is a demo but usually it will take them from a web socket or any other source of data that you have

25:19.000 --> 25:31.000
and it's calling this potline function periodically so basically I'm out of time and the HTML is like this so it's really simple thank you

25:40.000 --> 25:44.000
I think we have time for one question where the next speaker comes

25:49.000 --> 25:57.000
is it difficult to optimize the HTML using Ambrant because it's lower level HTML like very long?

25:58.000 --> 26:10.000
no actually the question was if it's difficult to optimize the FFT implementation using Amant versus a lower level language such as Verloc

26:10.000 --> 26:25.000
and actually the fun thing is Ambrant is intended as a low level language even though it's Python and the author of Ambrant says it's even lower level than Verloc because it relies on describing flip-flops basically

26:25.000 --> 26:41.000
so for me it's the same mindset I would use with Verloc I had I want this logic I want these flip-flops and I can write it in Ambrant or Verloc so it's the same kind of low level but you have the full flexibility of Python

26:56.000 --> 27:10.000
it is either four so the question was in the 2DL Factor multiplication I had three multiplies but it's usually four so if you do it the normal way it's four multiplications two additions

27:11.000 --> 27:20.000
if you do a trick to group together some of the summands you can do it as three multiplications and I don't remember maybe four additions or something

27:21.000 --> 27:29.000
so yeah that's the trick if you look for it it dates back to Gauss and some Russian mathematician I think

27:34.000 --> 27:35.000
thank you

