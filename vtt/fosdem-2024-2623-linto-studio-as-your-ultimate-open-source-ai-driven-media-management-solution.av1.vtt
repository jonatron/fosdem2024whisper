WEBVTT

00:00.000 --> 00:16.940
Okay, great thing everyone. Thanks to come to discover linto. linto is your ultimate

00:16.940 --> 00:27.240
open source AI driven media management solution. So I'm Damien Lenn. I'm head of R&D engineering

00:27.240 --> 00:38.480
here for linto at Lina Gora and I'm proud. So what is linto? Essentially linto is a set

00:38.480 --> 00:48.320
of voice technologies that enables you the best on the open source side of voice tech.

00:48.320 --> 00:55.840
You can find in linto all the cognitive APIs that you are craving about like transcription

00:55.840 --> 01:04.760
with a live or batch transcription. We have a set of NLP APIs that enables you to add

01:04.760 --> 01:14.240
punctuation, name entities and topics identification or so on. And also we worked on speech synthesis.

01:14.240 --> 01:24.000
This is the first set of linto technologies. Leveraging those technologies we built a

01:24.000 --> 01:35.720
full-figured surrogate, I mean alternative to Alexa and Dialogflow to build agents, smart agents

01:35.720 --> 01:46.000
which includes chatbots, smart assistants, voicebots with custom full software work walls that work

01:46.000 --> 01:56.400
on the browser that's very neat. And finally we the past two years leveraging further our

01:56.400 --> 02:04.960
technologies we built a business oriented solution which is called linto app which is a media

02:04.960 --> 02:13.240
management platform that enables you to load media and to make to run these cognitive APIs

02:13.320 --> 02:24.880
to edit the transcription in a nutshell to turn routine recording into fully qualified data lake.

02:26.880 --> 02:36.640
So there's a lot of software's closed source that enables you the same kind of features but more or

02:36.680 --> 02:43.960
less all of them uses the APIs from the big players you know them. Okay so the question

02:43.960 --> 02:50.920
here is always the same what happens to my data when I use the services provided by author,

02:50.920 --> 03:00.480
dictation, happy scribe and so on. In a nutshell you just send your data to them.

03:01.480 --> 03:11.320
So linto studio I will present you a quick video to show you the platform but here you

03:11.320 --> 03:19.720
have all the functionalities and note the link which is currently displayed you will find the link

03:19.720 --> 03:28.800
to immediately just use our alpha version which is online free you can just create your account

03:28.920 --> 03:37.560
and try yourself just after the meeting and you will find the link to our github pages to download

03:37.560 --> 03:48.560
and work with the source code. So linto studio enables you to use the APIs I've been talking about

03:49.320 --> 04:02.080
to add automatic stamp with our modified run times for whisper.ai not a whisper by openai.

04:02.080 --> 04:12.920
We are so enabled to speakers and turn identification and all I've been talking about

04:13.680 --> 04:20.600
before just note that the platform is a web platform where you can collaborate in real time using

04:20.600 --> 04:30.440
organization roles and share resources within the platform. It's shipped with companion

04:30.440 --> 04:39.800
Android application that you can use to to recall. The final slide before I move to the quick video

04:40.680 --> 04:47.600
of course as my colleagues presented you a work on the large language models of course we want to

04:47.600 --> 04:56.440
also leverage these technologies within linto studio and add this kind of feature I'm drafting

04:56.440 --> 05:05.720
here on the picture to work with the documents loaded into the platform and ask some things with

05:05.800 --> 05:26.200
large language models. Okay so here I jump to the video. Okay so I recorded this yesterday. Here

05:26.280 --> 05:38.760
on the left I'm currently recording something within the sorry so I'm recording with live

05:38.760 --> 05:48.160
transcription. Okay whenever I'm done I just stop I can navigate local files and listen back what I

05:49.120 --> 05:56.920
recorded but what I want to do is to send this recording directly within the platform which is

05:56.920 --> 06:05.000
of course the big window displayed on the right so I can change I can send it to the platform

06:05.000 --> 06:14.120
I choose the language the model I want to use then the media I uploaded just lands into the

06:14.120 --> 06:24.480
platform and here I can see that the transcription here includes the capitalization and normalization

06:24.480 --> 06:34.040
I can also explore the platform as I tell you media management solution so it's a multi-user

06:34.040 --> 06:43.520
platform we where everyone can create accounts and use roles within organization so here I just

06:43.720 --> 06:56.280
showcase the way you might invite users and assign roles within a given organization here I show the

06:56.280 --> 07:04.520
share mechanisms which is total rip off from notion way of doing things and I'm proud of it it was

07:04.520 --> 07:12.640
flawlessly I can share with external users as well send email automatically when I just share

07:12.880 --> 07:22.480
transcription to a user okay here I jump to the editor where I can you see use AI insight which is our

07:22.480 --> 07:35.200
NLP APIs okay you just click on the one you want to use and start generation forum identifying stuff in

07:35.240 --> 07:44.320
your text like name entities or locations and decisions topics and put highlights you can also

07:44.320 --> 08:01.680
manipulate the text and add manual highlights to annotate the text okay also we have another

08:01.920 --> 08:12.400
editor which is also very neat where it's a place where you can basically just built the SRT or VTT

08:13.200 --> 08:23.160
and you work with the screens you have the center the current screen you can arrange arrange them

08:25.160 --> 08:31.480
the timing you can of course correct the text which enables you to add something that you want to

08:31.520 --> 08:42.560
rip on the video directly some close captions here's the way I want to navigate within the platform

08:42.560 --> 08:54.200
I just can use tags and fetch the document I'm looking for also using full search text and so on

08:55.200 --> 09:03.440
and once again I get back to this recording I can show you here that I can also correct add some

09:03.440 --> 09:10.960
correction corrections to the text change speakers which is a real-time collaboration with a

09:11.400 --> 09:22.680
reconciliation of multi multiple users editing the text and finally as you saw we can export the

09:22.680 --> 09:34.000
document okay that's our platform demonstrated in a nutshell I took 10 minutes for this presentation

09:34.600 --> 09:57.400
hoping for any questions from you so if I am if you thank you for this presentation I have two

09:57.400 --> 10:03.200
questions one of them is technical and the other one is about money I'll start with the money this

10:03.400 --> 10:10.480
specific project how is it sustained that do you have revenue for this specific project and so what's

10:10.480 --> 10:19.440
the business and then the second question was what kind of power of computing power do you need to

10:19.440 --> 10:34.800
run this for a small organization maybe okay so the goal here for our business is very clear we

10:34.800 --> 10:44.400
offer as linear go around services for tuning models okay so this particular platform is also

10:44.480 --> 10:53.880
intended to be a SAS service where the user will be at some point when we have time to develop

10:53.880 --> 11:05.160
a subscription for that users will be able to use our system as a SAS but the source remains

11:05.160 --> 11:11.680
free and it can be austere on premise with the same features like away like like always at

11:11.680 --> 11:19.600
the Nogura we have no premium plan or whatever but we just feel that it's convenient to just host

11:19.600 --> 11:29.040
directly a solution as a SAS offer the other question was about the computing power okay so it

11:29.080 --> 11:41.840
requires quite a lot but we batch the process of the transcriptions and the long models inferences

11:41.840 --> 11:50.560
we just provide the best default way of doing stuff and if you dig in the code you'll see that

11:50.920 --> 11:59.200
our runtime supports kind of everything you can dream of we can run on CPU of course it will be a

11:59.200 --> 12:07.560
little bit clumsy we work on CPU with Intel extensions for transformers and so on and we of

12:07.560 --> 12:15.920
course work on GPU if you want to process a large batch of transcriptions when the hosting on premises

12:21.280 --> 12:29.000
any other questions we got time for one more how do you handle a typically French language

12:29.000 --> 12:39.120
setting which is irony how do you handle because of the keywords and so on the typically French

12:40.080 --> 12:46.080
set which is irony meaning that the speaker means exactly the opposite of what he says

12:52.080 --> 13:03.360
he's asking how do you do with the irony of French language of course using the you know the

13:03.440 --> 13:19.320
irony mark you know this one thank you Damian all right we're gonna start the next talk here in two

13:19.320 --> 13:19.760
minutes

