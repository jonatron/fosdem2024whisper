WEBVTT

00:00.000 --> 00:05.000
Thank you.

00:05.000 --> 00:10.000
So hello everyone.

00:10.000 --> 00:17.000
My name is Hugo and here with my colleague Richard and Abbey from the 15 which will be present afterwards.

00:17.000 --> 00:25.000
And basically we thought that it would be a nice contribution basically to foster and to actually present a little bit what we do basically as a.

00:25.000 --> 00:34.000
In the storage topic we are the experts on the storage. There are other colleagues downstairs in the booth so feel free to pass by and get some stickers basically and have some discussions.

00:34.000 --> 00:43.000
So yeah the core of this talk is to present a little bit what non-theft storage technologies we use on disk, on tape and cloud storage.

00:43.000 --> 00:46.000
And to explain a little bit what we do with them basically.

00:46.000 --> 00:48.000
How many of you know CERN?

00:48.000 --> 00:49.000
CERN basically.

00:49.000 --> 00:53.000
Okay good. This is an easy start.

00:53.000 --> 00:58.000
So yeah CERN is the biggest laboratory basically for particle physics in the world.

00:58.000 --> 01:02.000
It's basically based in the frontier between France and Switzerland.

01:02.000 --> 01:06.000
And our goal basically is to really understand how basically the universe was constructed.

01:06.000 --> 01:14.000
And we have a lot of intelligent people, a lot of physicists that trying to basically understand the data that we produce in this accelerator.

01:14.000 --> 01:18.000
CERN is also the birthplace of the web as you know in 1899.

01:18.000 --> 01:22.000
CERN 10 Berners-Lee basically created the worldwide web there.

01:22.000 --> 01:24.000
And he gave it to the world basically.

01:24.000 --> 01:29.000
And actually this changed a little bit how basically in society we communicate and we do things.

01:29.000 --> 01:32.000
And we actually bring in this legacy. We really contribute a lot to open source.

01:32.000 --> 01:36.000
We try to do basically as open source as much as possible.

01:36.000 --> 01:39.000
Where we do not find something that we can find it open source.

01:39.000 --> 01:42.000
We try to build it ourselves and give it back to the community.

01:42.000 --> 01:47.000
And here you will find today a little bit of examples of these technologies that we use.

01:47.000 --> 01:49.000
But before we jump there.

01:49.000 --> 01:53.000
CERN is now a multi-b because of its large Hadron collider.

01:53.000 --> 01:57.000
So this is a tunnel of 27 kilometers of circumference.

01:57.000 --> 02:00.000
It's around 100 meters below on the ground.

02:00.000 --> 02:02.000
We have a lot of superconductive magnets.

02:02.000 --> 02:05.000
You can see basically in this picture there.

02:05.000 --> 02:12.000
And the idea is basically we have different particles, atomic particles that basically we try to collision amongst each other.

02:12.000 --> 02:15.000
And we have high resolution cameras.

02:15.000 --> 02:17.000
It's what we call the detectors.

02:17.000 --> 02:20.000
So here is just one example of one collision.

02:20.000 --> 02:25.000
So these big cameras have particles basically coming from opposite directions.

02:25.000 --> 02:27.000
And we try to basically align them.

02:27.000 --> 02:31.000
So we basically create a collision almost at the speed of light.

02:31.000 --> 02:34.000
We generate a lot of these pictures per second.

02:34.000 --> 02:38.000
Just to give you a rough number is around one petabyte a second.

02:38.000 --> 02:42.000
The throughput that is generated out of the detector, which we cannot handle.

02:42.000 --> 02:44.000
It's really impossible.

02:44.000 --> 02:50.000
So what happens is that we have four of these big cameras around basically the tunnel.

02:50.000 --> 02:54.000
And we have filters basically because not all the collisions are interested for physicists.

02:54.000 --> 02:56.000
Some of the collision they are already known.

02:56.000 --> 03:02.000
So we try to really know, detect the exotic cases that we would like to basically invest.

03:02.000 --> 03:08.000
Traditionally we have what we call basically the processing farm.

03:08.000 --> 03:12.000
And it has been always done with FPGAs and hardware.

03:12.000 --> 03:14.000
But now we are moving a little bit.

03:14.000 --> 03:22.000
Different experiments they use now, for example, GPUs, hyperalyses, basically processes in software to do this filtering.

03:22.000 --> 03:25.000
And we arrive roughly around one terabyte a second.

03:25.000 --> 03:30.000
This is the data that we have to handle to process and to distribute.

03:30.000 --> 03:33.000
So how we distribute this data?

03:33.000 --> 03:37.000
CERN as you can see here in the center is what we call the TR0, like an onion.

03:37.000 --> 03:39.000
We have TR0, TR1 and TR2.

03:39.000 --> 03:41.000
So CERN has its own data center.

03:41.000 --> 03:48.000
It's all the data generated and it really brings to this inner layer of the data center,

03:48.000 --> 03:54.000
which is stored on high, say, throughput, this buffer, and then copied to tape.

03:54.000 --> 03:58.000
And my colleague Richard will explain to you more details what these systems are about.

03:58.000 --> 04:03.000
After the data is stored at CERN, we know that we have a copy of the data we distributed.

04:03.000 --> 04:06.000
And this is what we call the worldwide LSE computing grid.

04:06.000 --> 04:12.000
So this is an international collaboration of many people, many different encounters, many different institutions around the world.

04:12.000 --> 04:17.000
And the idea is to distribute this data across all these 160 data centers in the world.

04:17.000 --> 04:21.000
So people, basically physicists, for example, are in Oxford.

04:21.000 --> 04:24.000
They can analyze the data sets they are interested in.

04:24.000 --> 04:27.000
And at the same time, in the case of a big catastrophe, basically,

04:27.000 --> 04:31.000
because CERN is built with public money from these institutions that believe in science,

04:31.000 --> 04:37.000
the idea is that we can also try to reconstruct, basically, the original data with the copies that we have around.

04:37.000 --> 04:43.000
Today, we start around one activate in disk and one activate in tape systems,

04:43.000 --> 04:46.000
and we'll dig a little bit in the technical details later.

04:46.000 --> 04:53.000
With a lot of things regarding computing at CERN, today we are only focusing on the storage and open source for science.

04:53.000 --> 04:57.000
But if you go to home.CERN, this is the domain that you can go and find more information,

04:57.000 --> 05:06.000
or just pass by the booth and we will tell you a little bit more about other dimensions, basically, of what we are trying to do.

05:06.000 --> 05:12.000
So this talk today is going to focus on three and four of these systems.

05:12.000 --> 05:17.000
So the CERN box, EOS, and tape part, me and Richard, we are going to cover it.

05:17.000 --> 05:23.000
My colleague, Abby, will talk a little bit about what is the theft infrastructure at CERN.

05:23.000 --> 05:25.000
So this is a high-level view of how it looks like.

05:25.000 --> 05:32.000
We have the tape system, we have EOS, which is our software defined storage disk system with commodity hard disk,

05:32.000 --> 05:38.000
because our goal is to really try to use the cheapest hardware that we can find to provide, basically, reliability for the data.

05:38.000 --> 05:41.000
So there is no goal-plated hard disk that we use.

05:41.000 --> 05:45.000
We really try to apply a cost factor to really be the cheapest.

05:45.000 --> 05:50.000
And then we have CERN box, which is a cloud storage platform that sits on top of EOS and theft,

05:50.000 --> 05:54.000
and this allows people, basically, to access the data in a draw-box-like fashion.

05:54.000 --> 05:59.000
We use Anklot, the storage solution for that, because not all the people at CERN are geeks,

05:59.000 --> 06:04.000
and they are basically SSH-ing into a computing cluster and going through Fuse and CD and getting data out,

06:04.000 --> 06:10.000
but they just use computers, they want to get some data, do some basically computations in Mella, for example,

06:10.000 --> 06:12.000
and then they run it into the computing farm.

06:12.000 --> 06:18.000
So it's very important to bring the data that is generated to the end-user devices.

06:18.000 --> 06:23.000
This is a little bit more, let's say, in-detail picture of what we do.

06:23.000 --> 06:27.000
So on the left part, as I mentioned, we have EOS that provides a Fuse later,

06:27.000 --> 06:34.000
and then we have CERN box that sits on top, and this provides access to basically, you know, 100 EOS devices,

06:34.000 --> 06:40.000
also to different computing clusters that are running basically just Linux, Boxes, Almanine right now.

06:40.000 --> 06:46.000
And we also support through Samba protocol on top of Fuse for Windows users,

06:46.000 --> 06:49.000
because we have also a big user Windows population at CERN,

06:49.000 --> 06:53.000
so it's important that we allow these people to also access the data,

06:53.000 --> 06:57.000
and we use the open source and implementation for that.

06:57.000 --> 07:04.000
JupyterLab, we have a system called SWAN, which is a branded JupyterLab environment,

07:04.000 --> 07:08.000
which also sits on top of our storage systems, because it's a very convenient way for people

07:08.000 --> 07:13.000
to just basically run some Python notebooks, for example, to run some interactive computations,

07:13.000 --> 07:17.000
and then from this platform, you can basically scale out the job to big computing farms

07:17.000 --> 07:24.000
using a GT-conder system, for example, for those of you who know the system.

07:24.000 --> 07:28.000
So this is a little bit the big picture of the things, and now I pass the ball to Richard,

07:28.000 --> 07:34.000
who will dig a little bit more in the different areas for the different systems that we use.

07:34.000 --> 07:44.000
There we are. Lovely. Thank you, Hugo.

07:44.000 --> 07:51.000
All right, so by now you understand that at CERN, we have a great challenge in dealing with the data coming in.

07:51.000 --> 07:53.000
We have a lot of data coming in at once.

07:53.000 --> 07:59.000
We store a lot of data over time, because most of the physics data is, in fact, kept in perpetuity,

07:59.000 --> 08:03.000
and we also cannot lose data, because this would upset the physicists,

08:03.000 --> 08:07.000
and of course, lost data equals wasted time at the LHC.

08:07.000 --> 08:14.000
So for this, to solve these kinds of problems, we have developed EOS as our disk storage system of choice.

08:14.000 --> 08:18.000
What is EOS? It is a storage platform, open source.

08:18.000 --> 08:28.000
It is made such that we can store data in an economically viable way with the public funding we receive.

08:29.000 --> 08:31.000
At the scales we operate at.

08:31.000 --> 08:36.000
It is elastic, adaptable, and scalable, so that we can even grow on it as we go along,

08:36.000 --> 08:41.000
and as we increase even in the future the LHC's capacities.

08:41.000 --> 08:45.000
EOS is also very flexible in how it works.

08:45.000 --> 08:51.000
So for one, we have from the start considered the use case of having not just hundreds,

08:51.000 --> 08:54.000
but even thousands of parallel users active at once.

08:54.000 --> 08:58.000
There are physicists on site accessing it, sometimes with multiple clients.

08:58.000 --> 09:06.000
There are physicists abroad, as mentioned, and there are high performance batch computing workloads running this kind of stuff.

09:06.000 --> 09:10.000
So this is from the grounds up in there.

09:10.000 --> 09:15.000
We also support multiple protocols and a variety of authentication methods.

09:15.000 --> 09:22.000
This way we not only can use EOS in the varied scientific system that we have running at CERN,

09:22.000 --> 09:26.000
but also at the other institutions working and collaborating with us.

09:29.000 --> 09:32.000
What does using EOS look like to the user?

09:32.000 --> 09:34.000
Well, in the end you get a file system.

09:34.000 --> 09:38.000
You can interact with EOS through the command line, through the shell.

09:38.000 --> 09:41.000
So you get an EOS shell, which you can drop into using the EOS command.

09:42.000 --> 09:47.000
You can also just run EOS commands directly, so you get your standard commands for interacting with file systems,

09:47.000 --> 09:49.000
LS, MKDR and such.

09:49.000 --> 09:54.000
And then there's also a script mode for more efficient workloads you want to run.

09:54.000 --> 10:02.000
You also get your POSIX-like file interface, so you can mount EOS in a number of ways to your system

10:02.000 --> 10:06.000
and just interact with it directly, as you would with your local file system as well.

10:06.000 --> 10:11.000
For Linux this happens through the EOS XT executable, so you get a few smarts with that.

10:11.000 --> 10:17.000
Or alternatively you use the SSHFS tool to get it running locally.

10:17.000 --> 10:23.000
This is also an option for Windows and for macOS, and for Windows there's also support for SAMBA.

10:23.000 --> 10:28.000
You can also thirdly interact with EOS remotely through remote protocols,

10:28.000 --> 10:31.000
HTTP for instance, and then there's also the root protocol.

10:31.000 --> 10:39.000
I won't go into the details in the interest of time, but this is just a protocol tied to the root framework that is used at CERN,

10:39.000 --> 10:49.000
not to be confused with the root user, completely separate, but just know that it exists and that it's particular to the high energy physics community.

10:51.000 --> 10:53.000
Just a little bit of EOS project history.

10:53.000 --> 10:57.000
It has been developed at CERN since just about 2010.

10:57.000 --> 11:04.000
The code base I think is 99% C++, so we really try to squeeze everything we can out of the system.

11:04.000 --> 11:13.000
Each major EOS release gets its own special name after a gemstone, so the most up-to-date one right now is diopside version 5.

11:13.000 --> 11:18.000
So if you actually go into our repositories and check them out, then you can look for these and you know what they mean.

11:21.000 --> 11:23.000
This one is the important slide.

11:23.000 --> 11:26.000
So if you remember only one slide from the EOS part, it's this one.

11:26.000 --> 11:29.000
Here we explain what the architecture looks like, roughly speaking.

11:29.000 --> 11:39.000
So EOS has two major components, a highly available low-latency namespace and then the disk storage instances themselves.

11:39.000 --> 11:44.000
So the namespace is what we call these MGMs, the metadata servers.

11:44.000 --> 11:51.000
They are storing key value pairs in memory using something called QuarkXDB, which is based on RoxxDB.

11:52.000 --> 12:00.000
And the idea here is that we keep them highly available in part by running multiple instances of these QuarkXDB instances in RAF mode.

12:00.000 --> 12:07.000
So for one real full-sized EOS instance on the MGM, you will have three QuarkXDB instances running.

12:07.000 --> 12:09.000
One will be the master.

12:09.000 --> 12:11.000
The two others will ensure that there's a quorum.

12:11.000 --> 12:18.000
So for each operation you do on EOS, there should be at least two of these agreeing that this was actually performed.

12:18.000 --> 12:21.000
And then if something falls over, hopefully the others can take over.

12:21.000 --> 12:23.000
That's the idea.

12:23.000 --> 12:27.000
The other component is the FST.

12:27.000 --> 12:32.000
These are just storage servers with really as many disks as you can fit into them.

12:32.000 --> 12:38.000
I think a rule of thumb is that you can get one petabyte out of one FST.

12:38.000 --> 12:42.000
So essentially these are the workhorses.

12:42.000 --> 12:43.000
They store data.

12:43.000 --> 12:46.000
They transfer data to other sites.

12:47.000 --> 13:00.000
So for the FST is connected to the MGM, your operation usually when you do something, it goes first to the MGM and then the data transfer actually happens to the FST itself.

13:00.000 --> 13:03.000
The replication of the data is handled by EOS.

13:03.000 --> 13:13.000
So EOS ensures that you get the correct number of copies of your data, that it is spread across independent disks and independent instances as desired, so you don't lose anything.

13:14.000 --> 13:17.000
There's also the option to use erasure coding.

13:19.000 --> 13:20.000
Numbers.

13:20.000 --> 13:22.000
What does EOS at certain that look like in numbers?

13:22.000 --> 13:29.000
Well, it's really almost a petabyte, almost, sorry, an exabyte worth of data stored on these EOS instances.

13:29.000 --> 13:36.000
We store roughly speaking 8 billion files in total spread across these 1,300 storage nodes.

13:36.000 --> 13:40.000
We have running, which in turn are running about 60k disks.

13:40.000 --> 13:46.000
We expect this amount of data to grow almost exponentially even in the coming years.

13:46.000 --> 13:48.000
The funding will probably not.

13:48.000 --> 13:56.000
So we really try to make this as efficient as possible and as performant as possible to get really a minus worth.

13:56.000 --> 14:03.000
Here is a more view of what the actual workflow and data access looks like at CERN.

14:03.000 --> 14:14.000
So during LHC operations, you will have a number of data streams coming in all at once as fast as possible, storing the largest amount of data possible.

14:14.000 --> 14:24.000
This is then after the filtering that is mentioned, but even then you get streams totaling up to 150-200 gigabytes per second just coming in to these various EOS instances.

14:24.000 --> 14:31.000
They are by the way split up, so the way we scale them is horizontally using multiple instances.

14:31.000 --> 14:40.000
You will have for instance one EOS instance tied to one larger experiment and then you will have some which are shared among the medium and smaller sized ones.

14:40.000 --> 14:46.000
While this is going on, while the data taking is going on, you will also have data going elsewhere.

14:46.000 --> 14:51.000
You will have about 40-50 gigabytes per second going to tape, which I will get back to in a moment.

14:51.000 --> 15:00.000
So this is for permanent archival for long term storage and also for getting some extra capacity of the, like, just for extra storage.

15:00.000 --> 15:07.000
And then at the same time the data sharing happening to this WLCG, the worldwide collaboration.

15:07.000 --> 15:09.000
On the right hand side you see then the batch workloads.

15:09.000 --> 15:19.000
So these are what physicists queue on the EOS system using HDConder for instance, which is a high throughput computing batch management software.

15:19.000 --> 15:29.000
This is where the actual, the physics data is actually analyzed and we gain insights about whether or not it confirms or weakens theories.

15:30.000 --> 15:34.000
If you're interested now in deploying EOS, good news is you have options.

15:34.000 --> 15:36.000
You don't need to start with the petabyte.

15:36.000 --> 15:44.000
You can, you know, you can scale it and you can move around this, this, yeah, this gradient of how you want to do it exactly.

15:44.000 --> 15:54.000
On the right hand side you have the more mature production grade experience where, you know, the client interacts with your EOS instance through some form of load balancer.

15:54.000 --> 16:01.000
It points it at the correct, the lead MGM, which is running these core DBA instances and the namespace as mentioned.

16:01.000 --> 16:06.000
These in turn connect to the FSTs for the storage.

16:06.000 --> 16:11.000
On the left hand side you have more of a development environment or a test environment.

16:11.000 --> 16:13.000
It's very convenient for that.

16:13.000 --> 16:19.000
So you can deploy it for instance in your Kubernetes cluster or containerized virtual machine, this kind of thing.

16:20.000 --> 16:26.000
You can, you don't need to use a hard, you know, just disk system underneath.

16:26.000 --> 16:29.000
You can also use shared file systems such as Ceph underneath.

16:29.000 --> 16:34.000
And then, yes, in the middle you have the other options such as a hybrid system.

16:34.000 --> 16:39.000
So if you just happen to have a spare Ceph cluster lying around, you can tie it into EOS as well.

16:41.000 --> 16:45.000
You can find more details about that in our various documentation links.

16:45.000 --> 16:49.000
There's also an extended edition of this talk available online.

16:49.000 --> 16:52.000
But before you check that out, let's speak about tape.

16:52.000 --> 16:57.000
So before everyone knew about CERN, now I want to do another one.

16:57.000 --> 17:01.000
Raise your hand if you've used magnetic tape storage.

17:01.000 --> 17:03.000
No.

17:03.000 --> 17:04.000
That's incredible.

17:04.000 --> 17:05.000
Fantastic.

17:05.000 --> 17:09.000
I'll do the intro anyways to magnetic tape storage.

17:09.000 --> 17:10.000
What is it?

17:10.000 --> 17:15.000
Effectively, magnetic tape storage is you store data on magnetizable media,

17:15.000 --> 17:20.000
but instead of doing it on spinning disks like in your HDDs, you do it on this flexible tape.

17:20.000 --> 17:27.000
The tape is coiled up in this cartridge, which is just a plastic shell around mostly with little extra bits and pieces.

17:27.000 --> 17:33.000
And, yeah, to get actually any data in and out of it, you have to put it into this tape drive.

17:33.000 --> 17:36.000
So the cartridge is very simple.

17:37.000 --> 17:43.000
The tape drive by itself doesn't speak to many things except to a tape server.

17:43.000 --> 17:48.000
So this happens over SCSI for us, so we have other options also available.

17:48.000 --> 17:56.000
The end effect is that, well, you get, how do you say this?

17:56.000 --> 18:03.000
No, actually, for just simple setups, you can use just, you know, a tape drive and some cartridges on your desk,

18:03.000 --> 18:06.000
but we ran out of desks a long time ago for that.

18:06.000 --> 18:09.000
So we put these into what are known as tape libraries.

18:09.000 --> 18:15.000
These are, they come in many shapes, but ours are shaped sort of like storage container-like

18:15.000 --> 18:22.000
with the side portions being lined with these slots for the cartridges and for the drives.

18:22.000 --> 18:25.000
And in the middle, you have robots picking up the cartridge physically

18:25.000 --> 18:28.000
and putting it into its corresponding drive when needed.

18:28.000 --> 18:37.000
What does this result in? It results in that you have very different sort of access patterns for magnetic tape versus disk.

18:37.000 --> 18:47.000
Tapes are most happy when you read and write in, you know, one sequence from the start to the end, one smooth motion, ideally.

18:47.000 --> 18:53.000
If you read in another way, you will have to, you know, stop, rewind perhaps, and this will slow things down.

18:53.000 --> 18:57.000
So whereas, disks are good at random access, tape excels at linear.

18:57.000 --> 19:03.000
In the linear case, tape can be good and even beat disk maybe on the writing part.

19:03.000 --> 19:06.000
When it's, the conditions are not right, it can be slower.

19:06.000 --> 19:11.000
So the way you manage your tape has to respect that sort of thing.

19:11.000 --> 19:14.000
Tape is generally used for long-term storage.

19:14.000 --> 19:23.000
Lots of people use it for archival purposes, though we do that as well, and we also use it actively as active storage.

19:23.000 --> 19:26.000
Here for reference is just what a tape library in our case looks like.

19:26.000 --> 19:28.000
Ours is all nice and dressed up.

19:28.000 --> 19:33.000
So you have this long container-sized thing.

19:33.000 --> 19:36.000
Now the explanation of tape is perhaps a bit negative.

19:36.000 --> 19:41.000
Like why would you use tape if it's not necessarily as fast as a disk or if it's this custom format?

19:41.000 --> 19:47.000
Well, at the end of the day, magnetic tape is quite cheap per terabyte as soon as you get over the cost of, you know,

19:47.000 --> 19:50.000
building up your tape library and filling it with contents.

19:50.000 --> 19:56.000
So to get the most out of our money, we do use this for storing lots of data.

19:56.000 --> 20:05.000
Magnetic tape also has low emissions actually at the end of the day because a cartridge, which is on storage somewhere, does not consume power.

20:05.000 --> 20:09.000
Only when it is actually read or written to will it consume power.

20:09.000 --> 20:13.000
So it's a nice little environmental boom there.

20:13.000 --> 20:15.000
And it's also good for cybersecurity.

20:15.000 --> 20:18.000
A cartridge lying in storage is safe.

20:18.000 --> 20:19.000
It can't be overwritten.

20:19.000 --> 20:21.000
It can't be encrypted by ransomware.

20:21.000 --> 20:29.000
So, and there's an actual, there's an actual time cost to moving it to a drive to be written to.

20:29.000 --> 20:32.000
You also have usually way fewer drives than tapes.

20:32.000 --> 20:38.000
So there's a bottleneck for any sort of attacker wanting to do something nasty.

20:38.000 --> 20:39.000
Finally, tapes are long-lasting.

20:39.000 --> 20:43.000
So as mentioned, we keep data in perpetuity effectively.

20:43.000 --> 20:51.000
And so the long shelf life of tape when compared to disk is a positive.

20:51.000 --> 20:52.000
Finally, what is CTA?

20:52.000 --> 20:55.000
CTA stands for the CERN Tape Archive.

20:55.000 --> 21:02.000
It refers both to the physical installation as well as the open source software we produce to run it.

21:02.000 --> 21:07.000
CTA is open source and it isn't designed to be used in conjunction with disk storage.

21:07.000 --> 21:12.000
So the predecessor to CTA was a hybrid system which did both things.

21:12.000 --> 21:14.000
It became fantastically complex.

21:14.000 --> 21:17.000
And so for the second edition, we decided to not do that.

21:17.000 --> 21:22.000
So we leave the disk stuff to the disk system, in this case EOS.

21:22.000 --> 21:28.000
Though you can also, thanks to the efforts from the community, use it with other disk storage systems such as Dcash.

21:28.000 --> 21:33.000
And then CTA concerns itself only with the tape side of things.

21:33.000 --> 21:37.000
So we only store the metadata associated with tape and these things.

21:37.000 --> 21:38.000
So what does CTA do?

21:38.000 --> 21:41.000
It keeps track of the files you have on tape.

21:41.000 --> 21:45.000
It keeps track of where, on which tapes they are.

21:45.000 --> 21:47.000
And it does dequeuing.

21:47.000 --> 21:52.000
So at CERN, at any given time, there will be lots of physicists wanting the data.

21:52.000 --> 21:55.000
There will be contention for the resources in the system.

21:55.000 --> 21:58.000
So CTA handles dequeuing system.

21:58.000 --> 22:02.000
What makes CTA special in contrast to other tape systems?

22:02.000 --> 22:05.000
It is very archive throughput oriented.

22:05.000 --> 22:09.000
So to accommodate this LHC data producing workflow.

22:09.000 --> 22:15.000
So really the focus for CTA is getting data as fast as possible from disk onto tape.

22:15.000 --> 22:19.000
So we give that sort of an advantage in contrast to retrieve operations.

22:19.000 --> 22:21.000
We use it actively.

22:21.000 --> 22:25.000
So not just as an archive where we ideally never retrieve the data because it's just a backup.

22:25.000 --> 22:32.000
We really do get the data back from tape on the regular for the analysis of the data.

22:32.000 --> 22:35.000
And yes, it has a grown user community.

22:35.000 --> 22:37.000
So the CTA software exists.

22:37.000 --> 22:39.000
So their SEO is not maybe not quite as good.

22:39.000 --> 22:45.000
We only need to beat the Chicago Transit Authority and the Cherenkov Telescope Array.

22:45.000 --> 22:48.000
And then we'll be there.

22:48.000 --> 22:50.000
Again numbers.

22:50.000 --> 22:54.000
We have about 750 petabytes of data on tape at CERN.

22:54.000 --> 22:58.000
50 of those are backup and miscellaneous IT data.

22:58.000 --> 23:00.000
The rest is physics.

23:00.000 --> 23:04.000
These are spread across 60,000 roughly speaking tape cartridges.

23:04.000 --> 23:10.000
They are accessed by the 180 to 200 tape drives with the corresponding servers.

23:10.000 --> 23:15.000
These are spread across five libraries on site.

23:15.000 --> 23:22.000
At CTA, at CERN CTA, we use special EOS SSD instances as disk buffer.

23:22.000 --> 23:26.000
So when the data comes in, we really want to have it go as fast as possible.

23:26.000 --> 23:30.000
And we want the data to spend as little time as possible in there.

23:30.000 --> 23:35.000
So we really want the disks to be quick to move the data quickly to tape

23:35.000 --> 23:39.000
and also the other way around.

23:39.000 --> 23:42.000
This is the important part for the CTA, for the CTA slides.

23:42.000 --> 23:44.000
This is what the architecture looks like.

23:44.000 --> 23:47.000
So on the left hand side, you have your data coming in,

23:47.000 --> 23:51.000
usually from the experiment's big EOS instances,

23:51.000 --> 23:55.000
from where it is transferred to our little disk buffer instance.

23:55.000 --> 24:00.000
This, for the user, happens basically by just copying the files to a special location

24:00.000 --> 24:05.000
called something like archive, and then the system takes care of the rest.

24:05.000 --> 24:08.000
The disk buffer through one of the special EOS components

24:08.000 --> 24:13.000
connects to the CTA frontend, which is the management instance,

24:13.000 --> 24:18.000
and queues the archival and retrieve requests.

24:18.000 --> 24:23.000
The frontend connects to the CTA catalog and the object store,

24:23.000 --> 24:26.000
the catalog here being our database, effectively.

24:26.000 --> 24:31.000
We use Oracle, sorry, but also Postgres is supported.

24:31.000 --> 24:36.000
So in there, we keep configuration for the system and the various metadata.

24:36.000 --> 24:39.000
And then in the object store, we keep our queuing information.

24:39.000 --> 24:40.000
This is CEP.

24:40.000 --> 24:44.000
So there, once something is queued, it goes in there.

24:44.000 --> 24:48.000
The tape servers also connect to these two components.

24:48.000 --> 24:53.000
There we have what is known as CTA tape D, the tape demon running.

24:53.000 --> 24:57.000
And the tape servers will check the catalog for their configuration.

24:57.000 --> 25:02.000
They will then check the object store to see if there are any tasks matching their configuration to do,

25:02.000 --> 25:03.000
and then they will execute them.

25:03.000 --> 25:09.000
So either retrieve data or store data through their corresponding drives,

25:09.000 --> 25:12.000
which are in the library.

25:12.000 --> 25:14.000
How do you interact with CTA as a user?

25:14.000 --> 25:17.000
Well, as a user, if you're an administrator, rather,

25:17.000 --> 25:19.000
you will use the CTA admin command line tool.

25:19.000 --> 25:21.000
This comes with the installation.

25:21.000 --> 25:23.000
So there you can do all your low-level operations.

25:23.000 --> 25:29.000
As well, we now try to make a push to publish our higher-level operator tools.

25:29.000 --> 25:32.000
So these are the things you use to manage your tape lifecycle,

25:32.000 --> 25:36.000
the general monitoring and automation of the system.

25:36.000 --> 25:39.000
So these you can then use as well.

25:39.000 --> 25:43.000
And they basically use the CTA admin command in JSON mode under the hood.

25:43.000 --> 25:46.000
Users just interact with CTA through EOS.

25:46.000 --> 25:48.000
So for them, it's just a special place on the disk system

25:48.000 --> 25:52.000
where it takes a bit longer to get your files back.

25:52.000 --> 25:56.000
If you are curious about using CTA, we have a dev setup that we run, virtualized.

25:56.000 --> 25:58.000
You don't need a full tape library.

25:58.000 --> 26:01.000
You can just use the dev setup.

26:01.000 --> 26:07.000
This runs thanks to another lovely open-source project called MHVTL.

26:07.000 --> 26:09.000
This is Mark Harvey's virtual tape library.

26:10.000 --> 26:13.000
It does require a special kernel module to run,

26:13.000 --> 26:16.000
but it's worth it in contrast to having the physical hardware we're needing that.

26:16.000 --> 26:22.000
So through that, you can deploy test instances or very small-scale instances,

26:22.000 --> 26:30.000
just for maybe doing development stuff on either a virtual machine or a Kubernetes cluster.

26:30.000 --> 26:34.000
The instructions for doing that can be found on our documentation.

26:35.000 --> 26:39.000
And with that, I hand back to Hugo to speak about CERNBOX.

26:42.000 --> 26:45.000
Okay, so we are moving from tape now to cloud storage.

26:47.000 --> 26:50.000
Okay, so what is CERNBOX actually?

26:50.000 --> 26:54.000
So CERNBOX is the cloud storage platform basically that we use at CERN

26:54.000 --> 27:00.000
to expose the data stored on EOS and Thf file systems up to the users in a convenient way.

27:01.000 --> 27:02.000
It's actually a global platform.

27:02.000 --> 27:08.000
The background that you see here on my slides actually are basically the locations of everyone basically working at CERN.

27:08.000 --> 27:14.000
CERN is a very distributed place, so you have people contributing from every corner of the globe, almost every corner.

27:14.000 --> 27:17.000
There is no people in the north pole.

27:19.000 --> 27:24.000
And the goal basically was in 2014, so this is the 10th anniversary of this project.

27:24.000 --> 27:26.000
It's also the 70th anniversary of CERN,

27:26.000 --> 27:31.000
and the goal basically was at that time to actually, we saw that many people were using commercial providers

27:31.000 --> 27:36.000
and actually we wanted to have the possibility to control the data where the user were putting it

27:36.000 --> 27:41.000
and actually have our own jurisdiction on it and actually be sovereign about the data.

27:41.000 --> 27:44.000
We generate this data. We should be able to control it.

27:44.000 --> 27:46.000
And this is how everything started.

27:47.000 --> 27:50.000
And we use basically Ancloud, as you probably know.

27:50.000 --> 27:53.000
This is an open source company in Germany.

27:54.000 --> 27:57.000
And we have been collaborating on using their solutions since 2013.

27:59.000 --> 28:04.000
So in a nutshell, today we have around 37,000 users using the system.

28:04.000 --> 28:08.000
On a multi-basis, we have around 10,000 to 12,000 users.

28:08.000 --> 28:11.000
We store around more than 3 billion files actually.

28:11.000 --> 28:12.000
This number has to be updated.

28:12.000 --> 28:17.000
And this system alone for user data, it contains around 20 petabytes of data.

28:18.000 --> 28:20.000
CERN provides four main things for users.

28:20.000 --> 28:22.000
The first is synchronization and sharing.

28:22.000 --> 28:24.000
It's the typical draw box use case.

28:24.000 --> 28:28.000
I just throw some data synchronizing with my devices, share it with people, with public links,

28:28.000 --> 28:30.000
internally in the organization.

28:31.000 --> 28:35.000
And actually it brings a use case, which is to give people access to the data offline.

28:35.000 --> 28:39.000
If I have the data synchronized, I just close my network connection, I go in the plane,

28:39.000 --> 28:40.000
I can work on my data.

28:40.000 --> 28:45.000
When I arrive to a place where I have internet back, I basically, I can just get it in automatically

28:45.000 --> 28:48.000
without having to manually upload the data.

28:49.000 --> 28:52.000
Another thing that we bring is actually web applications.

28:52.000 --> 28:54.000
So, Office kind of collaboration suite.

28:54.000 --> 28:56.000
We use only Office, Collaborator, Microsoft.

28:56.000 --> 28:59.000
So, we have a plethora of different applications.

28:59.000 --> 29:01.000
And also, scientific applications.

29:01.000 --> 29:06.000
So, some of the scientific applications for physicists, they're very complex to install on the laptop.

29:06.000 --> 29:12.000
So, we basically give them a web environment, usually through JupyterLab kind of platforms.

29:12.000 --> 29:15.000
And this facilitates basically the daily job of people,

29:15.000 --> 29:18.000
especially students that they're at the university, they want to do something

29:18.000 --> 29:22.000
and they don't want to spend time setting up complicated C++ tool changes

29:22.000 --> 29:25.000
to basically just build the software they have to use.

29:26.000 --> 29:31.000
Another aspect is that this service provides access to the underlying systems

29:31.000 --> 29:32.000
through an online file system.

29:32.000 --> 29:37.000
On Linux, we use the Fuse Layer library and Windows through Samba.

29:37.000 --> 29:42.000
And then we integrated with the specific physics protocols and software

29:42.000 --> 29:43.000
and computing farms.

29:43.000 --> 29:47.000
So, basically from CERNBOX, imagine the typical use case of a physicist.

29:47.000 --> 29:49.000
I have a little data set.

29:49.000 --> 29:51.000
I play with it in my laptop.

29:51.000 --> 29:54.000
Basically, from my laptop, I do some analysis.

29:54.000 --> 29:59.000
This analysis, it's basically living in the same storage where the computing farm is.

29:59.000 --> 30:02.000
So, with one command, I can say, OK, now scale out this job.

30:02.000 --> 30:06.000
This job will run the computing farm for hours, days, weeks.

30:06.000 --> 30:10.000
When the job is done, the results will automatically synchronize to my device.

30:10.000 --> 30:12.000
So, I can actually write a nice paper.

30:12.000 --> 30:16.000
So, this is the whole workflow that we're trying to optimize with this platform

30:16.000 --> 30:19.000
because people before were having to learn different tools,

30:19.000 --> 30:22.000
having to pull the data when they were available, etc.

30:22.000 --> 30:26.000
So, we really simplify the use cases for the scientist.

30:27.000 --> 30:31.000
Now, what makes this platform so special across these last 10 years

30:31.000 --> 30:33.000
are basically three things.

30:33.000 --> 30:37.000
I want to explain to you here, and maybe if I have some time, I will do a live demo.

30:37.000 --> 30:38.000
I'll do it right.

30:38.000 --> 30:41.000
First thing is that the data is not owned by a system user.

30:41.000 --> 30:44.000
You know, you use a platform like Ancload or NestCloud.

30:44.000 --> 30:48.000
All the data is owned by the system users they are running with, usually Apache or Nginx.

30:48.000 --> 30:50.000
And we didn't want this because we have a problem.

30:50.000 --> 30:52.000
This means that all the data is compromised.

30:52.000 --> 30:55.000
So, all the user data basically is owned by the user.

30:55.000 --> 30:58.000
So, we have a huge basically held up directory.

30:58.000 --> 31:01.000
Every user has a dedicated UID and group ID.

31:01.000 --> 31:04.000
And when we start this data, we really start it as the user ID.

31:04.000 --> 31:10.000
What this gives to the users is the possibility that they can access the data from a web interface,

31:10.000 --> 31:12.000
but also through the FuseLayer.

31:12.000 --> 31:15.000
It's the same UID that is being used from web and the file system.

31:15.000 --> 31:19.000
And this kind of magic is actually a kind of challenge for institutions right now

31:19.000 --> 31:21.000
because people are using web users.

31:21.000 --> 31:24.000
You have nice OAuth, basically UPNs, UIDs.

31:24.000 --> 31:27.000
But these don't reflect basically the unique side.

31:27.000 --> 31:29.000
These are difficult to match them basically.

31:29.000 --> 31:32.000
So, this is one of the nice things about the system.

31:32.000 --> 31:37.000
The other one is that traditionally, and this is something that Ancload has actually moved away from

31:37.000 --> 31:39.000
after many years.

31:39.000 --> 31:42.000
They use a new model basically that will explain their new product.

31:42.000 --> 31:45.000
But since years, you are using basically this platform.

31:45.000 --> 31:50.000
It was written in PHP and all the metadata was stored in a big SQL database.

31:50.000 --> 31:56.000
And the problem was that if someone was accessing the file system on the back of this platform,

31:56.000 --> 31:59.000
people using the web part will not see the data.

31:59.000 --> 32:03.000
They will have to run some synchronization jobs that will take hours

32:03.000 --> 32:06.000
to basically spawn the new data in the web interface

32:06.000 --> 32:10.000
because its identity was a synchronization between the SQL database and the storage.

32:10.000 --> 32:14.000
And you have two brains that think several different things, so you have conflicts as well.

32:14.000 --> 32:16.000
So, what we did is remove the database completely

32:16.000 --> 32:19.000
and all the operations were joined directly to the file system.

32:19.000 --> 32:23.000
So, for example, in Sanbos, we don't store anything on the database.

32:23.000 --> 32:25.000
Everything is stored on the storage system.

32:25.000 --> 32:29.000
We use standard attributes as much as we can to basically facilitate the operations.

32:29.000 --> 32:33.000
This gives us atomicity as well when we have to move files left and right,

32:33.000 --> 32:35.000
create versions, etc.

32:35.000 --> 32:37.000
The standard attributes that live with the data file.

32:37.000 --> 32:41.000
And this facilitates a lot basically operations.

32:41.000 --> 32:44.000
And now, Unclo with the new product, which is Unclo's infinite scale.

32:44.000 --> 32:45.000
They are actually also doing this.

32:45.000 --> 32:48.000
So, this is a way to step forward for scalability.

32:48.000 --> 32:54.000
And the third feature of this system is actually that from the web interface,

32:54.000 --> 32:55.000
you just set an ACL.

32:55.000 --> 32:58.000
Like, I want to give access to my colleague, Elvin, you know,

32:58.000 --> 33:01.000
read, write access to the folder called red.

33:01.000 --> 33:04.000
And what happens in the back is that also on the storage file system,

33:04.000 --> 33:06.000
there is an ACL set.

33:06.000 --> 33:09.000
In EOS, we use basically EOS ACLs.

33:09.000 --> 33:14.000
On Thephaphase, we use basically the Unix ACLs basically to give access

33:14.000 --> 33:15.000
based on UID and GroupID.

33:15.000 --> 33:19.000
And what this gives is that people from the web, they can access the data in Dropbox.

33:19.000 --> 33:22.000
And people from the, like, you know, Gix, usually Linux computing clusters,

33:22.000 --> 33:25.000
they can just basically CD into the places that they have access.

33:25.000 --> 33:27.000
And these ACLs are respected.

33:27.000 --> 33:31.000
And this basically combines the web world and the storage system world

33:31.000 --> 33:35.000
in a way that people, independent, whatever they are, which device they use,

33:35.000 --> 33:39.000
they always have access to the same data.

33:39.000 --> 33:44.000
And this is a little bit how it looks like the infrastructure behind.

33:44.000 --> 33:48.000
On the left side, we use the Unclo's infinite scale web clients.

33:48.000 --> 33:51.000
This is a single page application running on top of NG Nexa.

33:51.000 --> 33:52.000
So this is the web UI.

33:52.000 --> 33:55.000
Nice people just go there and use it.

33:55.000 --> 33:58.000
We also use the Unclo application for desktop and mobile people that want to

33:58.000 --> 34:02.000
access synchronized data from their laptops or from mobile devices like iOS and Android.

34:02.000 --> 34:04.000
They just use these applications.

34:04.000 --> 34:07.000
And then we run what we call the Riva server.

34:07.000 --> 34:12.000
So the story behind this project is that in 2017, until 2017,

34:12.000 --> 34:15.000
we were running PHP Unclo.

34:15.000 --> 34:17.000
And at that point, it didn't scale out for our needs.

34:17.000 --> 34:19.000
We were storing a lot of files.

34:19.000 --> 34:23.000
And PHP, I'm sorry, there were a lot of PHP fanatics,

34:23.000 --> 34:26.000
but it was not scaling as we wanted.

34:26.000 --> 34:30.000
So I re-broad the server, basically, of Unclo in Go.

34:30.000 --> 34:34.000
And this language was really focused on system performance and concurrency.

34:34.000 --> 34:36.000
And this is what we needed at that time.

34:36.000 --> 34:40.000
And then three years later, in 2020, Unclo's use actually took this component

34:40.000 --> 34:42.000
and actually is part of their new product.

34:42.000 --> 34:45.000
So we are pretty proud that they did this,

34:45.000 --> 34:49.000
because now everyone can profit basically from this integration.

34:49.000 --> 34:52.000
And how this server integrates with EOS and CFFS.

34:52.000 --> 34:54.000
For EOS, we use GRPC.

34:54.000 --> 34:58.000
I'll show you now, GRPC from Google, the open source project.

34:58.000 --> 35:01.000
Basically, client-server communication to EOS.

35:01.000 --> 35:05.000
EOS supports an GRPC server that we can communicate with protocol buffers.

35:05.000 --> 35:09.000
And also with the Xroot protocol, which is a protocol really for wide area networks,

35:09.000 --> 35:11.000
which for high latency.

35:11.000 --> 35:14.000
So it's a protocol that is optimized for that.

35:14.000 --> 35:16.000
And for CFFS, there is a nice binding for Go.

35:16.000 --> 35:19.000
So we use the live CFFS library basically from the server.

35:19.000 --> 35:23.000
We create virtual mounts inside the process, and then we access the information

35:23.000 --> 35:28.000
on behalf of the user that comes to talk to basically to the server.

35:28.000 --> 35:32.000
And yeah, here you have some documentation.

35:32.000 --> 35:36.000
Basically, we store everything on GitHub, open source.

35:36.000 --> 35:39.000
There are also some publications around this software,

35:39.000 --> 35:44.000
so you can really look like, basically, dig, dive into it more.

35:44.000 --> 35:47.000
You can really refer to that.

35:47.000 --> 35:50.000
And yeah, we are downstairs in the booth basically.

35:50.000 --> 35:55.000
So feel free to talk to us, because some of the systems are actually better to show you live,

35:55.000 --> 35:59.000
with common line, how it looks like, the rather gentle slides.

35:59.000 --> 36:02.000
And we are organizing a specific tech-week storage at CERN.

36:02.000 --> 36:04.000
It's basically available for everyone.

36:04.000 --> 36:08.000
So as you are passing by Geneva, or you are interested into these topics,

36:08.000 --> 36:10.000
please come. It's free.

36:10.000 --> 36:15.000
And yeah, it's a place basically we would discuss with people having different challenges

36:15.000 --> 36:17.000
about the storage.

36:17.000 --> 36:20.000
Yeah, and that's pretty much it.

36:20.000 --> 36:25.000
CERN basically is open all the year round, so feel free to come and visit us.

36:25.000 --> 36:29.000
If you are a student, basically, still studying some master's degrees.

36:29.000 --> 36:31.000
There are nice opportunities to come to CERN.

36:31.000 --> 36:33.000
It's how I came actually doing some internship.

36:33.000 --> 36:35.000
I liked what I did.

36:35.000 --> 36:38.000
I stayed there for a couple of years, then I left, and I came back.

36:38.000 --> 36:40.000
So it's a nice opportunity.

36:40.000 --> 36:44.000
It's public money founded by many countries basically that really believe in science.

36:44.000 --> 36:48.000
So feel free to profit from that, and that's it.

36:48.000 --> 37:00.000
You have time for questions?

37:00.000 --> 37:02.000
Yeah.

37:02.000 --> 37:05.000
You pick.

37:05.000 --> 37:09.000
Do you actually have external EOS installations?

37:09.000 --> 37:12.000
So the question is, do we have external EOS installations?

37:12.000 --> 37:14.000
Yes, we have plenty of them.

37:14.000 --> 37:17.000
I don't know all the places where they are,

37:17.000 --> 37:20.000
but I can tell you, for example, in Asia there are some institutions.

37:20.000 --> 37:23.000
Actually, yes, maybe we have a map.

37:23.000 --> 37:25.000
Yeah.

37:25.000 --> 37:27.000
Some of them.

37:27.000 --> 37:30.000
So these are the ones that have EOS and CTA, the tape archive,

37:30.000 --> 37:33.000
but there are other places that have only EOS deployed.

37:33.000 --> 37:36.000
And if you want more information, just pass by the booth later.

37:36.000 --> 37:42.000
I can give you more details.

37:42.000 --> 37:46.000
How much redundancy is in the CTA?

37:46.000 --> 37:49.000
It depends on how much you want to configure.

37:49.000 --> 37:53.000
The default is for the major experiments, you get one copy on tape,

37:53.000 --> 37:58.000
and then usually through the WSG there will be a collaborating institution

37:58.000 --> 38:02.000
that mirrors the data locally there on site for them.

38:02.000 --> 38:06.000
For small or medium sized experiments who don't have that kind of setup,

38:06.000 --> 38:08.000
we do do do will copy.

38:08.000 --> 38:12.000
So then you will get your files and at least we will guarantee you that you will get

38:12.000 --> 38:16.000
two copies and you could in theory set it to something else as well,

38:16.000 --> 38:18.000
but usually two is fine.

38:18.000 --> 38:22.000
We try to make sure and you can also configure this that the files

38:22.000 --> 38:24.000
actually end up in separate tape libraries.

38:24.000 --> 38:28.000
So that way you know if for some reason you know your building burns down

38:28.000 --> 38:30.000
or just that particular library gets damaged,

38:30.000 --> 38:34.000
hopefully you'll have it somewhere else and be safe there.

38:34.000 --> 38:36.000
Thanks.

38:36.000 --> 38:43.000
And on the topic of disk sizes, what do you use and how do you feel about

38:43.000 --> 38:50.000
the upcoming 20, 30, 40 terabyte individual disks that are you going to use?

38:50.000 --> 38:53.000
That is, do you want to take this one?

38:53.000 --> 38:55.000
Yeah, I can take it.

38:55.000 --> 38:59.000
So the question is basically what do we think about the new basically high density disks

38:59.000 --> 39:02.000
that are coming to the market and how we plan to use them.

39:02.000 --> 39:07.000
So depending on the use case for the physics use case, we really don't care

39:07.000 --> 39:11.000
because we have so many data that we have to ingest that even if they are high density

39:11.000 --> 39:13.000
it really doesn't make a huge impact.

39:13.000 --> 39:16.000
For the sandbox part of the project where we only have 20 petabytes

39:16.000 --> 39:19.000
with the new high density disks, this means that we could actually have just one rack

39:19.000 --> 39:20.000
with all the data.

39:20.000 --> 39:23.000
And this is not ideal for redundancy because then basically we are,

39:23.000 --> 39:26.000
you know, our single point of failure is the rack.

39:26.000 --> 39:31.000
And what we have in mind basically is to try to basically use the same data

39:31.000 --> 39:32.000
that we have in the past.

39:32.000 --> 39:35.000
And basically is to try to basically erase encoding basically the files.

39:35.000 --> 39:39.000
A US is a system that you can use replica based model or erasure encoding.

39:39.000 --> 39:44.000
And to find basically a good trade off, there is really not like a perfect solution

39:44.000 --> 39:47.000
but the idea is to find the correct erasure encoding across different racks

39:47.000 --> 39:53.000
and maybe even shared the storage server with other projects or other use cases

39:53.000 --> 39:56.000
so we can benefit basically to really fill the disks.

39:56.000 --> 40:02.000
And another use case that we have currently that we are investigating is the single-magnetic disk also

40:02.000 --> 40:06.000
what basically will have the impact to use them

40:06.000 --> 40:10.000
because it looks like the industry moving to the direction for single-magnetic recording.

40:10.000 --> 40:14.000
And yeah, it poses a challenge because this disk usually happens only

40:14.000 --> 40:19.000
and we have basically use cases where you have to handle random writes and random reads around

40:19.000 --> 40:22.000
and this can basically pose some challenges.

40:27.000 --> 40:33.000
You were saying that you have you're storing data indefinitely

40:33.000 --> 40:36.000
and the tapes have a duration life of 30 years.

40:36.000 --> 40:38.000
How soon is older than 30 years?

40:38.000 --> 40:43.000
So are you having this operation of having to copy all tapes

40:43.000 --> 40:46.000
as is how big is that challenge for you?

40:46.000 --> 40:51.000
Yes, so the question is if the lifespan of a magnetic tape is 30 years about

40:51.000 --> 40:55.000
and soon is older than that, how do you keep this data around?

40:55.000 --> 40:58.000
And for that we have continuous workflows in place.

40:58.000 --> 41:01.000
So this is part of these operator tools that I mentioned.

41:01.000 --> 41:03.000
There's one called REPAC.

41:03.000 --> 41:07.000
So effectively we have automation in place for periodically.

41:07.000 --> 41:11.000
Once we get to a new generation of tape media to take the old ones

41:11.000 --> 41:13.000
and then rewrite that data onto new media.

41:13.000 --> 41:18.000
So that way we always sort of stay on the wave of new technology

41:18.000 --> 41:21.000
or at least you know trading slightly behind it.

41:21.000 --> 41:24.000
We can't of course upgrade everything all at once

41:24.000 --> 41:26.000
because that's just way too much.

41:26.000 --> 41:31.000
There's an actual amount of time spent in reading from the end of one tape to the other.

41:31.000 --> 41:35.000
But yes, we continuously upgrade our media generation.

41:35.000 --> 41:39.000
So I think the oldest right now is LTO7 on site

41:39.000 --> 41:45.000
and we're moving slowly now to, for new data we're using LTO9, the newest enterprise.

41:45.000 --> 41:48.000
And so yes, continuously we will rewrite data onto new media.

41:48.000 --> 41:51.000
This also happens if media gets damaged for some reason.

41:54.000 --> 41:57.000
You guys also use decentralized cloud solutions.

41:59.000 --> 42:03.000
Is that considered a valid option in your stack for archival

42:03.000 --> 42:06.000
or is that like a proof of concept?

42:06.000 --> 42:08.000
For archival specifically.

42:08.000 --> 42:12.000
So the question was do we use decentralized cloud storage?

42:12.000 --> 42:13.000
Was that correct?

42:13.000 --> 42:14.000
File point.

42:14.000 --> 42:15.000
Come again?

42:15.000 --> 42:16.000
File point.

42:17.000 --> 42:18.000
File point.

42:18.000 --> 42:19.000
Oh sorry, file point.

42:19.000 --> 42:20.000
Ah sorry.

42:25.000 --> 42:28.000
I don't have the numbers for any cost analysis on that

42:28.000 --> 42:32.000
but I don't think so.

42:32.000 --> 42:36.000
It's going to be, I don't know how you can guarantee with,

42:36.000 --> 42:38.000
I'm ignorant about fine-cones perspective

42:38.000 --> 42:41.000
so I don't know if you can guarantee a specific timeframe

42:41.000 --> 42:44.000
for the retrieval of the data or for the access.

42:45.000 --> 42:46.000
There's also, at the end of the day,

42:46.000 --> 42:48.000
so once it is retrieved onto disk,

42:48.000 --> 42:53.000
we really, well, we need to put it on disk for working with it

42:53.000 --> 42:55.000
and the latency needs to be low.

42:55.000 --> 42:58.000
Like at some point we had another data center

42:58.000 --> 43:01.000
called Wigner off-site, far away.

43:01.000 --> 43:04.000
And just even for that the latency for the physics workflow

43:04.000 --> 43:06.000
was way too long.

43:06.000 --> 43:08.000
Like it's just, it wasn't workable.

43:08.000 --> 43:12.000
We have received many complaints so yes,

43:12.000 --> 43:15.000
it is nicer to have it on-site.

43:15.000 --> 43:19.000
Yeah, though come stop by and speak about file coin.

43:23.000 --> 43:28.000
Backplace has a lot of disk statistics that they publish every year.

43:28.000 --> 43:30.000
So you have it as well?

43:33.000 --> 43:37.000
Yeah, I can answer which one specifically for reliability or...

43:37.000 --> 43:38.000
What disks?

43:38.000 --> 43:42.000
They have half a kilo of it.

43:42.000 --> 43:45.000
Yeah, so the question is basically that back-place probably

43:45.000 --> 43:46.000
is basically some information,

43:46.000 --> 43:48.000
insights about the reliability of disk.

43:48.000 --> 43:49.000
Yes, we do.

43:49.000 --> 43:51.000
There are some papers around.

43:51.000 --> 43:53.000
I cannot refer now to my head,

43:53.000 --> 43:55.000
but we can pass by, we can find them.

43:55.000 --> 43:57.000
These are failing every day at CERN.

43:57.000 --> 43:59.000
Every single day we have disks that are broken.

43:59.000 --> 44:01.000
We have so many that is natural.

44:01.000 --> 44:04.000
And what we have built is basically just to make sure that

44:04.000 --> 44:07.000
when this fails that basically the software can take care

44:07.000 --> 44:10.000
to make sure that there is another replica valid on top.

44:10.000 --> 44:12.000
But I cannot give you the exact numbers,

44:12.000 --> 44:14.000
but we can figure it out.

44:18.000 --> 44:20.000
Short question, 50 seconds.

44:22.000 --> 44:23.000
Okay.

44:23.000 --> 44:25.000
Maybe I'll do that.

44:25.000 --> 44:27.000
Test the guys at the booth.

44:27.000 --> 44:29.000
You can ask as many questions as you want, I'm sure.

44:29.000 --> 44:31.000
We are all the weekend around so feel free.

44:31.000 --> 44:34.000
Yeah, so let's give them a round of applause.

44:37.000 --> 44:39.000
Thank you.

45:07.000 --> 45:09.000
Thank you.

