WEBVTT

00:00.000 --> 00:17.360
Okay, if I may have your attention again, it's time for next talk by Matthias Lorsen,

00:17.360 --> 00:24.560
this time about his unicernal and how he can run MPI code faster.

00:24.560 --> 00:26.560
Which is yours?

00:33.560 --> 00:37.560
So hello everyone, you take me well?

00:37.560 --> 00:39.560
Okay, thank you.

00:39.560 --> 00:49.560
I'm Matthias Lada, in this presentation I'm going to talk about the player in MPI applications using Total Unicernal.

00:49.560 --> 01:04.560
This is an exploratory work, so it's an area I am still investigating, so at the end of the presentation feel free to ask me any questions because I'm still benchmarking things, I'm not pretty sure where I'm going.

01:04.560 --> 01:24.560
So first I would like to present myself, I'm fascinated about practice system development and mutualization, and I have been working in these companies, this is my email, I did have a profile if you want to get in touch or you want to see some of my projects.

01:25.560 --> 01:32.560
This current project is not related with my current work, so it's something that I'm just doing when I have some free time.

01:32.560 --> 01:46.560
I would like to start by what is my intuition about what is an MPI application, I am not an expert on MPI, so it is what I understood since two years I have been working on this.

01:46.560 --> 01:55.560
So it is an application that compiles with the implementation of the MPI standard, so there exists several implementations of the MPI standard.

01:55.560 --> 02:11.560
The standard defines a set of APIs to synchronize and communicate parallel instances of the MPI application, so for example we have this sort of API, like MPI barrier broadcast and all reuse for example, so to set some of them.

02:12.560 --> 02:27.560
My impression is that the only performance matter when we deploy MPI applications, so I have a feeling that the virtualization is not very popular in HPC, at least my impression for the overhead that this adds.

02:28.560 --> 02:49.560
So my thought was that maybe MPI applications may benefit from the unicurners because for example Cisco are expensive, so in unicurners we remove that, we have calls, threads are cheaper than process, so you may know that we are not switching the page today,

02:49.560 --> 03:01.560
every time we are doing context switching in unicurner, depending on your application you can completely remove the scheduler because you are going to run only one thread per course or something like this.

03:01.560 --> 03:08.560
You can rely on communication and share memory for example, in the case of unicurners.

03:09.560 --> 03:23.560
And sometimes this is something that I just added, sometimes perform better than a general operating system as I guess and I say this because sometimes you can tweak your operating system to reach good performance, let's say.

03:26.560 --> 03:35.560
So yeah, well this is the diagram or the components that they are involved with when you are deploying an MPI application using a general proposal of the operating system.

03:35.560 --> 03:45.560
In this case I am thinking that the MPI application is running as a built-in machine but the diagram is more or less the same in case it is bare metal.

03:45.560 --> 04:03.560
So what we have is your MPI application, then it compiles with implementation of the MPI standard, for example OpenMPI and the OpenMPI is going to use some Cisco to communicate with the operating system to get some service like scaling file system, networking and so on.

04:03.560 --> 04:11.560
So what unicurners propose is well let's take a look at the data.

04:33.560 --> 04:38.560
Thank you.

05:03.560 --> 05:06.560
you

05:33.560 --> 05:35.560
you

05:36.560 --> 05:38.560
you

05:38.560 --> 05:40.560
you

05:40.560 --> 05:42.560
you

05:42.560 --> 05:44.560
you

05:44.560 --> 05:46.560
you

05:57.560 --> 05:59.560
about the scheduler.

05:59.560 --> 06:06.560
So the scheduler in tutorial is quite simple and also well here is no scheduler, it is the way that the tutorial creates threads.

06:06.560 --> 06:16.560
You have a dedicated API called a begin thread but it is a parameter that has to tell where the instance is going to run so you have to set up where the core is, I mean where you want that function to run.

06:18.560 --> 06:23.560
Otherwise it is going to choose all the times the booting core.

06:24.560 --> 06:42.560
The scheduler is quite simple, it is a cooperative scheduler, so I mean the thread is going to do something and then call this thread switch which is going to invoke the scheduler and each scheduler, I think I present that in the next one.

06:42.560 --> 07:00.560
Yeah, I mean each scheduler is independent one another so there is no communication between the instance so each core is scheduler completely independent one another and the algorithm is quite simple, it is going to choose the next thread that is ready, not more than that.

07:01.560 --> 07:18.560
And the idea behind that is that the idea was to have instance of the kernel that don't require any mechanism to synchronize the instance so there is no speed lock or something like this so all the access to the kernel data is lock free.

07:19.560 --> 07:40.560
So I just talked about the scheduler, now I am going to talk about the memory, also total memory is dedicated so when the kernel initialize is split the memory in rations and then all the allocations happen from that rations depending the core.

07:41.560 --> 07:57.560
So the splitting is quite simple, it is just split by the number of cores so you have two cores, you have two cores, you have three, so for a moment this algorithm is quite simple and maybe it could be improved for sure.

07:58.560 --> 08:20.560
So for example we have a memory allocator that since each ration is assigned to different core the way that we implement the allocator doesn't require any synchronization between the core, keep also the same idea that each instance runs independent one another.

08:21.560 --> 08:36.560
So for example when a thread has two allocator memories it is always coming from the same ration and also doesn't require any synchronization between the cores and so on.

08:36.560 --> 08:49.560
The idea behind this is also to try to leverage from technologies that integrate paths that you can have a known informer memory and then you have faster access to some rations.

08:49.560 --> 09:09.560
And in a general way all the kernel data in total is per CPU variables so it means that it doesn't require any synchronization between the core to access kernel data.

09:09.560 --> 09:29.560
And also to access faster to these CPU variables using the chs register for example and this is an improvement that I did a couple of months ago and so we have a table and it is faster access through the chs register which is pointing to that table.

09:29.560 --> 09:39.560
I don't remember exactly the mechanics but I think I have a blog that I wrote about that and all the access is log free.

09:39.560 --> 09:47.560
The only moment that we require synchronization between the cores is when we wanted to for example create a thread from one core to another.

09:47.560 --> 09:55.560
We need to synchronize somehow the cores to migrate one thread to another something like this but it's the only moment that we need it.

09:55.560 --> 10:03.560
Otherwise this is completely independent all the instance.

10:03.560 --> 10:10.560
And to end the principles of total I will be going to talk a bit about the core to core communication.

10:10.560 --> 10:17.560
And the idea was to even if you as a user you can implement anything on share memory as you want.

10:17.560 --> 10:28.560
I decided to implement the entire over share memory so each core has a set of big use that allows to get data from a remote core and say data to another core.

10:28.560 --> 10:34.560
And it was just a bit of I mean to have fun to do it like this.

10:34.560 --> 10:38.560
I mean I'm starting to see if I can implement the entire like this.

10:38.560 --> 10:47.560
And the idea is that the communication is core to core so we don't have only one queue per core.

10:47.560 --> 10:52.560
You have as many birch use as you need to communicate one to one for each core.

10:52.560 --> 11:04.560
I don't know how to say exactly but this makes that you don't require any protection to send or keep the exclusive access to this birch use.

11:04.560 --> 11:09.560
Because you have only one consumer or one producer and so on.

11:09.560 --> 11:28.560
And relying on this mechanism then I could implement the API from MPI like MPI Gutter broadcast and MPI scatter which are functions that require communication between the core.

11:28.560 --> 11:33.560
So from the root core to the root core and so on.

11:33.560 --> 11:37.560
So I think I will just talk a bit about the benchmark I have been done.

11:37.560 --> 11:41.560
I feel free to comment about this because I'm not really sure about the numbers I'm getting.

11:41.560 --> 11:56.560
What I did was to choose a set of well known benchmarks called also micro benchmark which is since that it is used for benchmark in different implementations of the MPI standard.

11:56.560 --> 12:04.560
And I pick up two of them the also barrier and also already use which what they do is just stress some function.

12:04.560 --> 12:14.560
So for example the also barrier stress the MPI barrier function which is something to synchronize the instance of an MPI application.

12:14.560 --> 12:19.560
It's just a software barrier let's say.

12:20.560 --> 12:25.560
And the other one they already use is stress the MPI already use function.

12:25.560 --> 12:36.560
Which is going to send some vector to the root core process something and get back the rest to the other cores or other instance.

12:36.560 --> 12:43.560
What I did was comparing with Linux Bermuda and Linux in IBM and I use it.

12:43.560 --> 13:00.560
I pick up this machine from the from a clinics which is an AMD epic with 24 cores and 64 sheen rate and the host I use it for the VN is a Wuntu with isolated cores.

13:00.560 --> 13:03.560
No sorry yeah with isolated course.

13:03.560 --> 13:07.560
And I ran the and I use it.

13:07.560 --> 13:09.560
KBM team was hypervisor.

13:09.560 --> 13:14.560
I'm sorry now the host was Wuntu and the guess was Fedora 38.

13:14.560 --> 13:21.560
What I did is in this particular case what I did was to use a huge VM with 16 cores.

13:21.560 --> 13:29.560
Maybe it's not the most common case for MPI people just have several nodes instead of putting everything on the same.

13:29.560 --> 13:40.560
In my case I was trying to play with this so I decided to use a huge VM let's say and then compare with total right.

13:40.560 --> 13:47.560
So this is how I launch the benchmark.

13:47.560 --> 13:56.560
So for example I am using 16 threads for example.

13:56.560 --> 14:10.560
I'm not an expert in MPI I'm not really sure if this I mean if the MPI run for example is really using one core per thread it will not be optimal otherwise I think.

14:10.560 --> 14:16.560
And I was launching for 1000 interaction so this is the result for the Linux Bermuda.

14:16.560 --> 14:20.560
No Linux in IBM sorry.

14:20.560 --> 14:25.560
So these are the numbers for the host barrier.

14:25.560 --> 14:30.560
Which is this test if I yeah.

14:30.560 --> 14:38.560
So you can see that there is quite huge difference between the Linux VM and the Unicolon.

14:38.560 --> 14:47.560
But still I have to read redo these numbers I'm not really sure about that I mean because there are one order of magnitude at least.

14:47.560 --> 14:55.560
At the beginning I was interested to compare with Linux Bermuda because I think we can achieve something like this in IBM.

14:55.560 --> 15:03.560
But then when I started to play with Linux VM I said well there is a huge already difference with the VM.

15:03.560 --> 15:13.560
And also I was comparing with the host already used as I said before in particular with that side of the vector.

15:13.560 --> 15:23.560
And also it's quite huge difference with the Unicolon.

15:23.560 --> 15:32.560
So in the two cases are 16 cores in the VM and the Unicolon too.

15:32.560 --> 15:38.560
And I think that's all about the benchmark.

15:38.560 --> 15:46.560
To have this number also I figured out that some issues in particular I don't know if you were measuring something in VMs.

15:46.560 --> 15:54.560
In particular in carry-in the early TCC register is not emulated so you have to be careful when you use that.

15:54.560 --> 16:01.560
For example you have to when you are doing numbers you have to check that the carry-in is still in time.

16:01.560 --> 16:07.560
So if you make the difference it's not going to work always so you have to be careful about that.

16:07.560 --> 16:10.560
That's all I think.

16:37.560 --> 16:44.560
The question is a question.

16:44.560 --> 16:46.560
It's a question.

16:46.560 --> 16:50.560
It's a pity I'm not doing...

16:50.560 --> 16:56.560
The question was why I'm not doing communication between the VMs using this implementation.

16:56.560 --> 17:08.560
Basically this implementation can only run on a single node but people are using MPI on classes with tens or hundreds or thousands of nodes.

17:08.560 --> 17:12.560
Why?

17:12.560 --> 17:15.560
Do you have any plans to extend that?

17:15.560 --> 17:19.560
Well I'm thinking about that because it's not the first time that they mention this.

17:19.560 --> 17:26.560
Maybe create an interface, I mean use butyonet or butyvisoc to communicate with other instance.

17:26.560 --> 17:29.560
You will have multiple VMs running that.

17:29.560 --> 17:34.560
But for the moment maybe I will do it soon.

17:34.560 --> 17:37.560
I'm not really worried about that.

17:37.560 --> 17:42.560
What questions?

17:42.560 --> 17:53.560
Which MPI implementation are you implementing?

17:53.560 --> 17:59.560
Because there are different kind of versions of MPI or Pitch or so on.

17:59.560 --> 18:03.560
Which one are you based on?

18:03.560 --> 18:10.560
I'm not really sure because what I'm doing is just trying to read the semantics of MPI.

18:10.560 --> 18:13.560
I'm trying to implement it at code.

18:13.560 --> 18:17.560
The number of the functions I'm implementing is based on what is the benchmark.

18:17.560 --> 18:20.560
That's all. This is why I'm doing it. No more than that.

18:50.560 --> 19:02.560
Do you have numbers when you increase the number of nodes?

19:02.560 --> 19:07.560
Do you mean if I have numbers when you increment the number of nodes? How that behave?

19:07.560 --> 19:15.560
Yeah.

19:15.560 --> 19:18.560
I'm still doing that number.

19:18.560 --> 19:27.560
The difference is still there between the VM and the Linux implementation.

19:27.560 --> 19:32.560
Still a difference in the sense that it's faster, let's say.

19:32.560 --> 19:35.560
I'm still doing those numbers too.

19:35.560 --> 19:40.560
There is no point in finding the question.

19:40.560 --> 19:45.560
I don't know.

19:45.560 --> 19:51.560
Do you have a question about the big problems that are happening in the end of the time?

19:51.560 --> 19:56.560
The question is if I understand why we have that difference.

19:56.560 --> 20:00.560
I don't know.

20:00.560 --> 20:05.560
There are a lot of ways to tweak Linux to make it more performance.

20:05.560 --> 20:07.560
Maybe I'm lacking that.

20:07.560 --> 20:14.560
If you tweak it, you're going to dramatically drop that difference and the configuration.

20:14.560 --> 20:17.560
I'm not really sure from where it's coming.

20:17.560 --> 20:23.560
But I said before, it's still numbers that I'm working on.

20:23.560 --> 20:26.560
Okay, I think we are running out of time.

20:26.560 --> 20:29.560
So, Api, thanks again for the talk.

20:29.560 --> 20:34.560
Thank you.

20:34.560 --> 20:37.560
We have a short break for five minutes.

20:37.560 --> 20:40.560
And after that, we will have talk.

20:53.560 --> 20:58.560
Thank you.

