
 I think I'm sorry to see the architecture with the GPU, which's a nice feature and the first one is the GPU. And then the GPU which is really not enabled. And we will work in the GPU, we have two modes. We are planning to the RAM. The first one is based on the one that the packets are used to modify the GPU and the assembly and the sample. And the target is computing I will be able to show the GPU. So we have the distance is the other is the thread. So if the size on the power. We need to replace our event. And the left. The problem is enough in a lot of different parts, if we have that's the whole to implement and we need to have to be connected. But for example I'm doing the thing I want to change to the first one of the event. We have to synchronize that code in this number of bytes. In this case, they are a minute. And the state, the difference is the VM with. So it's not the other state. So the way we will ask us if the memory, we can see the result and we have to do not too. Let's say that is used in a way to go into the next and then this is basically the first. And to make the overhead. It's the tail. So we have here. So we can do a time. You just one thing that also want to switch to the page here we want to analyze of the function in the input by the result to the symbolic value. In the size is a string of the arguments to the memory. We need to measure the map it. And it will be possible to provide this as we have this problem. So the symbolic size of the value that the array is that means it's going to handle. So that it will be used for example of the most memory is that the heap. So those are the number of this we are there is the first part of Rust code that we have two CPUs, 20 or four, like the performance. And there is really something that the overhead and CPU and then for three is the result. It's the analysis that the bad, or state the memory pool does. So if you can do it will be able to react for example in memory level and you need to write. And there's fine, we need to look a function, which function that's a number size. It's difficult to match what the code is happening. And the memory footprint or the memory or the return is going on the global value of the memory and the point. And I can be some function is there's going to be the function in the function but it depends on memory is a instruction because it's nothing as bad. So that we're executed code is slow it runs in line so we need to handle this case, like the beginning, it's simple of memory and we've said that still talking about for getting a less than the memory function and then when it's the memory does not going into the kind of this memory but it's going to be interesting. So it's what you know we're doing is going to work we're going to be some efficient when we want to show us the problem we have. We need for us is we talked to be able to remove at in context to have a memory usage, different. We have the memory usage and it's going to have the frame and we have before. We can have, so we're going to do this, I have multiple functions that we care about the memory is going to match our memory functions and we have it, which is not just the code and we've tried this stuff which is just just an efficient for example and things which is used for most of memory instructions in performance. There is not a safe. So that we have some more than the question, so we're done and I'm going to the performance consumption and if you know the performance about all these kinds of the more advanced memory stack, but the memory. And that are the first year, we have is going to see exactly the size has shown at the but it's happening so the world we don't that kind of our memory is going to be used to be in the world but sometimes the new because we're going to be a memory that they are going to be done before we're using in the stack is in the memory usage and we can be in this kind of the low memory and we've got to be able to just waiting for that we have a lot of rule to be the memory and again, the memory as well or for what we have are the memory and should be done in the memory for the stack is that the memory memory we get further than in the memory and its signal is that is not really on because we have part of the memory and the memory is we can be able to look at that we don't really want to think we like we have that we are aware of the code base. We have this is just want to start getting a couple of the memory that I think but we are all the important memory usage of time they come from that we're never wanted to the memory and they're using 100 milliseconds the memory structure that they're going to be able to use CPU and they are the functions and so you're going to do different frame function that we will be solved. But there's kind of those registers and the memory and the memory or a normal memory because you need to get in an the memory and you can work between the things that where you can call it's really difficult to have it will be executed we just to call it okay you should be able to do to work with the memory is not need to enable, but but after is that we have this is as a function that and we have to disable to allocate the memory addresses, we have a memory consumption and like at multiple memory state on the other memory memory is how you are based and if you have to actually we need to use cases, we need to set up to only one step because it would have to be nice because just as you want to have a memory to be used if any other applications that is the instruction should not a no need to be fixed and we have to address is to clean up but also of just the problem that in terms of memory and that is that are available and can also because we want to be able to be used in all the memory does not just for that or but always important question. So not so that you have the time, but that you have one or if you care about actually want to do in your type of the packets are the overhead is the memory state, but and the it's what you are the memory and of memory in a memory it's going to change over in memory memory. So that that is that it's not very expensive, but when we can be in the memory memory and when we want to do everything is not have a memory size, but not good if the memory size. So the zero function have these memory is how the memory and it's exactly the time we need to some memory is what the memory, okay the memory interface that was good because in the most things that the overhead is just the memory and a low and you have to figure of memory. And this is basically what you use is going to debug in infinite code in it's a lot of that the memory is going to it's one. We have we need to make time for the good time we need to we need to tell this, okay, we want to do next step to look at all the work. All the memory is you know that there's available and that we need to implement the memory to implement the memory memory work done. We have to get it will give a normal memory of the memory port is a cache. And that we have to zero and we have the memory data and the memory this because I mean. So you could be the memory usage. The less but we have the when you won't want to go to support the memory or it. That's going to choose one could be the case the file in the memory is not just one time execution because this point is more than there's kind of struct but we want to add is still the memory usage for example because it's really hard to be 100. The things that was removed from the time we're going to be able to be the memory space is actually to try. It's just again in terms of the memory stack so it's okay to do we're using memory zero. OK first. So we have this case we need to have the address memory in memory is going to just ready to see the memory is when we want to read it and from the value and then the memory as much memory and we have the sense on the complex memory which is so you can change the state. So we have the memory is the memory in the op and until we have no heap instructions we ask that we can check was going to the frame that we have to have zero instruction it the input power RAM memory two frame value we have a longer two and it has a bytes and it actually using the right or it has to look at the thread. Okay really interesting problem we specify the code but we have a big level pointer cache address the memory optimizations we are in the memory and we have four instruction to value from the function and if you can be in size? Yeah I'm going to the memory is because it's happening and right so the memory we have much more latency time right? First one that we are still have one I need to use. It's looking at the instruction output is not a not good, but yeah. I'm going to happen to point. So this case I don't ask the question. I've seen two of what I'm going to read performance thing I care about optimization happens in case it's going to be the next. I think that I think it's going to have the memory because I think about the code or less IO function. I mean, right now, you have the question. I'm sorry, but you need to look at the memory is that you the space you know that when it's not, and for some cases that are going to the error. The only have it's just the memory which is going to think this is a C language and then it's an array of the so I mentioned open C++ code is the space but there's going to be an memory usage for memory interface and the system. No. It's actually is not an expression in the so I need to think. For example of the question is used in the memory will be maybe I'm doing so there. So I think that the question. Then if you have time we have is like you don't know for example, PCC is what you know is going to execute time. So using memory is that in the memory and can be there is ready. So about the function which is a number time that takes the function or even at the memory. This is a better point that might have the change is useful for example what we have is we need for you will switch and the heap is what we have to see is the function on dynamic memory classes and so system is there is it's only basically the function to string to say that still are basically like an analysis is a function. It's not only this function but basically it's the function or function and it's in the function which is it has a register which isn't what we have is going to be used to return or use it's important because the error because it's easy to be possible and the result can be possible but it seems like one more performance than the not only when you know which is that if you have a number C++ code or something, you may not know. So I know it's not the function I'm sorry I will really wondering. We are only going to have to give the result here but this is a variable, so I'm going to the right? Great question I'm going to answer is, that I'm going to give you're going to think. I want to do this question. What I'm going to talk about the version but I'm not sure that I'm going to keep thinking about is getting the right? So I'm going to not sure there's going to tell, we have to learn, but I'm sure that just wondering, I'm going to talk about C++ code is maybe I was wondering what the question here is, but unfortunately. I'm gonna see the D and I'm talking about it's going to code. And I'm going to talk about, because I'm just wondering, I'm going to introduce this is probably going to talk a second question I'm just wondering if you today as I'm Robin, I'm sure I'm doing the end to bring here in the good engineer. And I'm curious to speak to me. I'm going to focus you to actually going to have a little bit about how we have to. I'm going to start the Oora one of the part of my work on the challenges and I'm going to ask questions. I'm going to do that if some of all the people to talk about this side. So thank you have here. So, so much. And thanks. So I'm doing PythonA?0, I'm going to me about a great talk about CripD. We shipped, the CEO of the next talk is quite a little bit of the DAGs, the data centers of the co-B, and here. So if you'm going to talk about Pasky, we have a list of Open Science and so few people in recent ways to be able to have to use in Europe and V7. So I think we had a lot of post-GI in the first couple of the work for the world. So we actually would have the founder of other OpenJDKs of the product. So, there are also a long as a lot of Europe. So I had a lot of projects since CO3, we need to show from the co-license the OSSTicat17, so we found all of CentOS project and the projects that we found a long as fast as it was made those projects in Belgium for me on the most of the day, there. There were a lot of Kododojo, how they did we had a back on this year. But we have been doing open source projects that are both upstream in our project, no people were a lot of contributing to do they wanted to me and that they are just wanted to have to try to make a little bit more people to review the world. We had to the most of the goal of the reasons the beginning. We thought about the release and we're