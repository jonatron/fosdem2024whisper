Hello, hey everyone.
Welcome to Making It Easy to Get to Salsa Level 2.
Thanks for sticking around.
It's last day of the conference, send me last talk.
So, yeah, today we're going to be talking about salsa and compliance and hopefully how you
can meet those compliance requirements as a play.
My name is Theophilus and I'm going to be talking about Choc and open source framework.
We developed that crash override.
So I come from a security background and every time I hear the word compliance I get bored
to death.
It's kind of like a book sticking exercise.
But hopefully we can discuss today about this and see how you can do this in your own organization
easily while also get value for your org.
Before jumping into the topic, let me kind of quickly set the scene and talk a little
bit about software supply chain attacks.
So in a software supply chain attack, the attackers compromise the build system or the
package registry and get a foothold there.
And over the past years we've been seeing an increase in these types of attacks.
So there was a report say from Sonatype that said since 2019, year after year, we've been
seeing a sevenfold increase in this type of attacks.
The report came out in 2022 that said supply chain attacks basically surpassed malware
based attacks by 40%.
And last year around two out of three of US businesses were impacted by a supply chain
attack.
So you can take these numbers with a grain of salt, but the fact of the matter is there
is a surge in these types of attacks.
And this popularity on the attack realm drives policy changes.
So in May 2021, there was an executive order by the White House that said software vendors
must be provided and purchased with software of materials and provenance information.
And quick show of hands.
How many are familiar with the term S-bombs or provenance?
Cool.
How many of you have been deploying these in your pipelines or your organizations?
Okay, great.
There's also an S-bomb room.
So today we're going to jump into these topics real quick.
So we're going to discuss some concepts and then talk about the challenges people face
when trying to deploy these things to production.
Then we're going to talk about CHOC and how CHOC can help you solve these problems but
achieve many, many more things and hopefully have a discussion in the end.
So for those of you who are not familiar with software bill of materials or S-bombs, you
can think of it like a list of ingredients for software.
So you go to the supermarket, you see a package, then you read the labels and you get a list
of all the ingredients that are in there.
So an S-bomb is pretty much the same thing but for your software applications.
So you get either an XML or a JSON and from that you can get a list of the packages, their
versions, etc., etc.
When we're talking about provenance, what we're talking about really is how did the
artifact get here?
Like who created it, who packaged it, how was it modified along the way until it actually
reaches the user basically.
So that is all good but if we think about a list of ingredients, what are the guarantees
that what we get is actually what we're promised?
So for instance you could have an NPM package and you can generate an S-bomb for your NPM
package saying that these are the ingredients that are there but then in a package you could
get a foothold somewhere in your build pipeline and inject something that was not originally
there.
So another key component here besides generating the S-bomb and the provenance formation is
really having some attestation around the integrity of the generated artifacts.
So anyone should be able to cryptographically verify that at least what we're promised has
not been tampered with and that the contents of the S-bomb were coming from an original
author, etc., etc.
And what's really important here is we need to have some clear assumptions around the
threat model aka what can an attacker compromise and what are the security guarantees we're
getting depending on that.
So do we require the attacker say to compromise our build pipeline or do we require the attacker
to get a foothold on developers boxes?
What's our threat model?
And that's really important because if we think about DevOps pipelines in practice you
have many components like developers are pushing codes, that code ends up in some provider
like GitHub or GitLab, you have open source packages, you have container images, you have
infrastructure code that modifies this code and pushes it out and then somehow it ends
up in the service or the cloud.
And as we're building out all these graphs of components attackers could get a foothold
at various places.
So this is where Salsa comes in.
Salsa is an open SSF project and essentially gives us some framework to talk about the
security posture of our applications.
And we have different levels for the supply chain security of our artifacts.
At level one essentially all we're doing is we are providing information about how the
package was built and have a report but we don't really have guarantees around the report
whether it has been tampered with or not.
At level two we get signed provenance.
Essentially at this point we say okay once the thing has been generated there has not
been tampering on that artifact but you don't get guarantees around the build platform etc.
And as you move up the layers you get stronger and stronger security guarantees.
So today we're going to be talking about chocking how easy it is to get to Salsa level
two if you deploy chocking to your built pipelines.
So how does one start to do this?
This is good, we all want to improve the security posture of our applications, we want to deploy
these things in our organization, how does one start to do it?
One could think that okay that surely a solved problem there must be tools for this already
and you're right to some extent but the tooling ecosystem is really in its infancy and it's
largely fragmented at this point.
So it's not necessarily obvious to a newcomer which tool or framework they should pick and
even if you say select a space like S-Bombs the outputs of different tools are inconsistent
with each other.
One tool get a certain report, another tool get some different report and there might
be assumptions around how these things should be getting set up, how you should be deploying
all these things so it's not a straightforward way and what's really really hard is thinking
about how can you do this at scale.
If you have a large organization with multiple repositories, different providers, how do you
make it easy for your teams to just set this and let it run and have it be easy to consume
the data and also generate data that are of interest to you.
So yeah it's not an easy problem and hopefully Chalk will help here.
The main idea behind Chalk is really we have some metadata that we care about and then
we want to embed that metadata that we call Chalkmarks into the artifact.
So the artifact could be a binary or it could be a docker image and you want to embed this
metadata into the artifact during the build time or post build time.
So you could have an L file in a box and then you can inject metadata into that L file
and say okay that was indeed here, you can have information that you care about like
the security settings on that box like if a partner is enabled or what are the users
or the network connections, you embed that metadata on it and now that artifact is tagged
and once you have that tagged artifact you basically let it go and it gets deployed somewhere
in production.
So think of Chalk pretty much like air tags for your code so you embed the air tags and
then you're tracking it across the ecosystem of your infrastructure and once the artifact
actually gets executed what's interesting is you can get back reports with metadata
that you configured there.
So essentially you can scan what has been out there in production, you can grab for all
this metadata that has been embedded in the artifacts or you could configure the artifacts
some cases to phone home and give you the report themselves and you could do this once
or you could do it periodically for instance configuring Chalk to send you heartbeat reports.
So let's see this in action.
I have set up here a very very basic git repository and this repository all it does is it deploys
a lambda function.
So we have the main code of the lambda function here and as you can see there's nothing really
special to it, we just sleep and return it to 100k and we're building this lambda function
using a docker file and there's nothing specific to Chalk in this docker file pulling from
a well known image and we're actually building the lambda using a github action.
So during the github action we check out the code, we set up the build environment and
then here we're setting up Chalk.
So we're telling our build ecosystem that Chalk should drop this build of the image
and embed metadata on it and what sort of metadata we choose to embed is completely
up to us.
It comes like Chalk comes with defaults.
So these are the only lines of code we ever need to do for our build pipeline so that
Chalk can embed sbombs and actually use, you know, provide cryptographic guarantees around
the integrity of the generated reports and we're also creating attestation manifests using
SIGS-Tor for those of you who are aware of that framework.
So cool, let's go ahead and trigger this.
I'm going to go here in the action, kind of re-trigger the action once more and what
we're doing here is we're building a docker image and we're telling Chalk to encapsulate
the whole build and inject metadata in here.
And that metadata, we can choose how we want to emit it.
So we can choose to emit a report in there or the CLI or in some destination that we
care like S3 or some server.
So I have here a dummy server that's running and it's waiting for reports.
There's nothing here currently.
And I'm going to go back into one of the previous actions and show you a report that was emitted
by Chalk on the CLI.
So during the build, after we've actually pushed the image, you can see down here we
have a Chalk report and this is basically a JSON file that has metadata that we care
about.
So here we know that some image could build, that was a daytime, that was a docker file
path, the exact contents of the docker file, the commit ID, the author of the committer,
but you also get a cryptographic signature about the integrity of this report essentially.
You get interesting things like the environment variables, arguments.
You can configure this to be however you like it.
And this is generated on the CLI, but we can send the exact report, the exact same report
or variance of that report in other destinations.
So going back here to the action we just triggered, hopefully once this completes, we will be
seeing a report populated to our server.
So not only will we see a report here on the CLI, but we'll also get the metadata in the
endpoint we configured.
What could possibly go wrong?
This is just a live demo here.
So you can make this as fine-grained as you like.
So Chalk supports plugins.
So if you want to run, say, your static analysis tools like SemGrid or CodeQL, you can embed
this metadata into the report as part of your regular other metadata that you're tracking.
So it looks like this got finished.
So we did get a report here.
And if I go here, essentially we see that we got a build operation, so that got sent
over to our server.
And this is essentially just a pre-defined rendering of the JSON, right?
You can send it wherever you see fit and render it however you would like.
But we get some interesting information.
We get some signal that we collected S-Bomb and Signing data.
And indeed, if I scroll down here, I do see that I have the full S-Bomb.
And I can fetch information about the attestation of the artifact.
But I also get a bunch of interesting metadata that might not have been obvious just by seeing
the build.
So I see here CloudProvider is Azure.
And we have information about the actual Azure instance metadata in which the build
happened.
So essentially what happens here is GitHub runs their machines on Azure in this particular
instance.
And so that build triggered in one of the Azure instances.
So that's nice.
We can also see the build command.
And you can see here how the normal build command is now wrapped under Choc.
So Choc is in charge of the build and embeds the metadata into your image.
So that's nice.
What we did do here is we pushed this demo lambda essentially.
You can see this was modified just now.
So I'm going to go ahead and execute the image.
And hopefully, if things work as expected, the lambda will execute.
And I'm going to get a second report here.
And that second report is an exec.
And if I zoom into the exec, you now see that the command that got executed is actually
running within the lambda environment.
So Choc is wrapping the entry point of the execution for that Docker image and tells
you like, hey, this Choc mark that you inserted, the metadata that you've all captured is still
here, but now I'm executing in lambda.
And indeed, if I go here and see the Cloud metadata, you can see the region, the role
they are in, the account ID, et cetera, et cetera.
So with this, we can basically say the metadata that we injected in our build pipeline here
is still present throughout wherever we deploy the image.
And we can keep track of where the thing actually executes.
So if I take into this Choc mark, I'm sorry, let me zoom out here.
I can see that there's two reports essentially associated with this.
One was a build and the other one was an exec for the exact same hash.
So the exact same hash that I build in that machine has been executed in the other machine.
So what did we do here?
First of all, with four lines of YAML in our GitHub action, we generate and distribute
the desktops.
And we also have provenance information because we can track where the build happened and
where the actual image got executed.
And we also get artifact integrity.
So in our case, we're using cosine.
You could use different frameworks to do this.
But essentially, we're meeting the basic requirements here.
So we're checking those boxes.
And that's with minimal effort, in my opinion.
Like all you need to do is you need to configure whatever destinations you want for these
reports to be sent.
So you say, OK, that's cool.
What more can you do?
So let's think about typical scenarios that happen during kind of live production environments.
You might be on call for a given service.
And you get a page in the middle of the night.
And there is some issue.
There's a bug.
There's a vulnerability.
Something is off.
And you want to figure out, OK, what's the component that's responsible for this?
You could have, say, a pretty complex application with multiple teams pushing code.
And for large organizations, usually the pattern for resolving these issues is you cut
the tickets to the team.
You wait for somebody else to be seen and be like, hey, that's the responsibility of
that person.
Potentially, you grab into code.
You say, OK, what was the last commit?
Or you have metrics.
And you track from your metrics what chains.
And you try to correlate it to somebody else.
If you're using Chalk for your build pipelines, it's much, much easier to correlate what exact
version of an image is running where and what the components are.
And potentially, like, who are the code owners, et cetera.
Because if we go back here, you see that we have things like the cometer and the commit
ID.
So we have the commit ID.
You can start building these profiles about ownership incrementally as you go.
So instead of having a process which could potentially take a couple of hours to determine
the root cause of an outage or an issue, you now can have this in a few clicks, hopefully.
Another common use case is application inventory and change management.
So say, for instance, you're part of a large organization.
You want to deprecate the framework.
You want to deprecate, say, AngularJS.
So AngularJS is running production.
And you want to figure out, OK, what is the impact?
How many teams are using it?
Is the code even live?
And what was the last time things got executed?
You can figure out, you can get reports around these things.
More importantly, you can see how applications change over time.
So many of the people we've been talking to have processes where, for instance, they do
a sort of change management meeting.
Like, once a week, they say, OK, what has changed?
What has been deployed?
Do we need to go through a security review?
What's the exact list of changes?
And that process is manual to a large extent.
Using Choc, you can automate this, because you can generate an exact report of the diff
and you can get some integrity guarantees around that report.
But more importantly, besides these things, you can do much, much more rightly.
It's not necessary that you can only Choc containers.
You can run essentially tools of your choosing, or you can submit custom plugins for metadata
surfacing.
And currently, the open source implementation that we have on GitHub only supports the entry
pod wrapping for containers, but we're working to expand Choc functionality with more and
more features.
You can still Choc L files and PYC files and jars, et cetera.
So yeah, the framework is out there.
It's written in NIM.
NIM is a very, very cool statically compiled type safe language.
So any fans of NIM here, feel free to contribute.
And we're welcoming feature requests.
And I think that's my talk.
I'm happy to take questions or discuss this.
Thank you.
Thank you.
Yep.
You talked about large organization.
I'm very open to second.
Yes.
So the question here is I brought up large organizations, but given a concrete example
of what are some use cases that this would apply in, right?
So just to make this clear, this does not only apply to a larger, a small organization.
It applies to everyone.
It's just that if you are having a single application with a single repository, pretty
much you know exactly what version is deployed where.
The complexities of these situations start to be amplified the bigger and bigger you
get, right?
So if you have, say, a web application, and that web application has multiple components
that are live at any given time, or say you have a distributed service and you have microservices
running, you have multiple teams committing different versions of their component at any
given time.
And potentially some of these teams change.
So you could end up with a repository having outdated code, right?
There's a mission now, something has failed, and you go into the code, say, what was the
last commit?
It was six months ago.
The committer of that application has left the team, potentially has left the company.
Who do you contact?
How do you know that's actually that part that has been outdated?
But if you keep track of your builds and your executions, you have the ability now to tap
into all the history of, like, all the provenance of a certain artifact and surface metrics
that you care about.
So if you cared about, say, show me all the components that haven't been updated in the
last month or that haven't been executed the last month, it's way, way easier to do this.
I'm not sure if I answered the question.
Yeah.
Yeah.
So you showed how to do it in a GitHub action, but could you generalize and do this manually
in a one-prime or in a different pipeline environment as well?
Yes, yes.
Chalk, you can actually, if you go now, if you visit the GitHub repo or the website, you
can just download it.
And it's a binary that runs.
You can run locally and embed metadata into any artifact that you care about on your machine.
So you can download on your laptop and scan all the L files in your system or the jar
files or whatever, or even scan a whole directory.
You can specify whatever you want.
And then you can configure metadata that you care about, and these will be embedded there.
And you can then extract it.
So you don't necessarily need to have Chalk report back to you or run it in a GitHub
action.
You can just use it to embed information and then surface it.
So you can both insert and extract if that makes sense.
Yep.
So that's a great question.
I think one of the big benefits of Chalk is that you can embed information even in generated
images or artifacts, right?
So if you're using, say you have some third party software like a library that you're
consuming, perhaps you don't know where it came from, but you know that you saw it in
a certain machine at a certain hash.
And then you can use Chalk to encapsulate that information for your artifact.
And basically, if you run a query across all your applications that say are importing
a given library, you can see all the versions of that library that are running.
So you can start building these application inventories very easily, even if it's a third
party software.
Is it the total of the bottom third party container?
It's still the same premise, right?
Because if you have a container, you have several layers.
So you can start saying, okay, these are the layers I have seen here.
And potentially you don't have the full information, but you can at least ensure that you can attest
that, okay, these are, this is the hash that I have seen.
We are starting to add support to actually wrap entry points of different layers if you'd
like to.
So you should be able to interpose yourself in another layer should you like to, but
that's not currently up yet.
It's not up on the open source limitation.
Yeah?
How does Chalk play together with the useful bits?
Are they to include them in the library?
That's a great question.
No, you don't need to include any compiler.
All you need is the binary.
And then if you have a reducible build for, in your pipeline, you should still be able
to achieve the same guarantees.
For instance, if you have, say, an L file, we'll embed metadata into a section and that
will survive stripping and all that.
So once you have a build, then assuming you know that you're running with Chalk, right,
and you don't modify the thing later on inappropriately, you would at least know that you're running
with Chalk, right?
So that if you're getting a report, that report has not been tampered with.
Yep?
Let's imagine I have a jar which I have Chalk, right?
Then I modify it and zip change it.
So at which point Q and V8 and then I Chalk it again.
At which point how do you pull the code?
Right.
So the question is, suppose you have a jar, you Chalk it, and then you modify it and then
you Chalk it again.
How does the tool help you here?
So Chalk does not allow you to have just a single Chalk mark within a binary.
You can wrap Chalk marks within Chalk marks within Chalk marks essentially.
So if you're making modifications and you'd want it to, you can maintain past information
about past Chalk marks.
Or if you're building a jar, say, out of other jars and those have Chalk marks, you can use
this information and embed them into your final jar, if that makes sense.
So you can wrap and encapsulate all the metadata from all the components.
So I need to focus more on this.
Well it wouldn't be more complex than just saying Chalk insert.
Like Chalk would take care of all the build dependencies and make sure it injects it automatically.
At least that's where we're heading at.
It might not be full feature for all the flavors of what can be choked currently, but that's
where we want to go for sure.
Cool.
Thank you.
