All right, so the next talk is going to be about the Linux kernel key store and why you
should be using it in your next application.
Thank you.
Hello, my name is Ignat.
I work for Cloud for and today we're going to talk about Linux key store.
By the way, how many people here know that Linux has a key store?
Cool, many hands.
Because like James earlier showed us that it has a key store but probably not everyone
knows that Linux actually has a key store.
So, yeah, a little bit about myself.
I do Linux at Cloud for.
I'm passionate about system security and performance.
I'm like Lolo programming, Linux, but loaders, drivers and other stuff written in scary and
safe languages.
And I'm a hard Linux fan.
That's why I'm presenting from a Mac.
And probably like most of you here, I'm a fugitive programmer because NSA banned writing
C and C++ languages and enterprises.
And why is that?
And there are many reasons but one of them is regarding application keys and memory.
And by the way, here is the brand that NSA recommends that organization use memory safe
languages whenever possible.
So what is the problem with application key?
Regarding keys, we're like talking about cryptographic keys, right?
So to dig into that, let's review the Linux address namespace, isolation concept.
So yeah, you have these many processes running on your systems because Linux is a multi-threaded,
multi-process system.
But what these processes have inside, right?
So usually it's kind of like your code, like compiled code, your business logic.
Some libraries, shared libraries, if your application uses shared libraries, some data, like global
data stack.
And yeah, I have the stack box separately.
So it's like data heap and global variable with mStacks, right?
And then you have the kernel, right?
Everything runs in the kernel.
In the kernel also you have the core code.
You have static and dynamic data.
You have the drivers which you load modules.
And also you have stack or stacks if you have different threads, right?
And the idea regarding the address spaces is within the process, each process, and even
within the kernel, everything can access everything, right?
So it's like one global space, whereas you can't access the memory of another process
from one process and you also can't access the memory of the kernel.
Like it's separated.
This is Linux address space isolation.
If we zoom in into the main process, into one of the processes, right?
Like let's actually review what can be here and what can be in your data.
And it can be like some internal state.
So you have global variables, like applications can keep some internal state in the data.
Yeah, your process can have user or customer data if it processes some external inputs
and does stuff.
Right?
And the most important thing is cryptographic keys.
If your application does some sort of level of encryption, it probably has some keys in
the process address space.
And what if like suddenly your application becomes compromised, so either through your
main application logic or through a library, well, it means because it's all in the same
address space, it means all your data section is compromised, right?
But not all data is created equal.
So, well, yeah.
So yeah, well, like if your application internal state is compromised, well, it can be good
or bad, right?
It depends.
Like depends on your logic.
Of course, it can be bad if the attacker has control of some kind of data which can, for
example, change the control flow of your application.
If you're verifying a password, you can flip back like true or false or you can put some
authenticated flag on and yeah, this can be bad, but sometimes it's not as bad depends
on if your application is simple, but it can lead to further compromise.
Well, if your user customer data is compromised, then like it's much, much more now.
And yesterday also mentioned Equifox, my favorite company.
Yeah, if you're a user customer data leak, it's a big problem because kind of it creates
a lot of pressure on the company and you have to pay a lot of fines, but it's very, very
bad but still more or less recoverably.
Equifox is still in business to this day, unfortunately.
But what about cryptographic key compromise?
And this is like a total game over, right?
So like if your identity key is leaked, that's what anyone can be as you.
If you're like the main data encryption key is leaked, everyone knows your data.
So it's a data integrity compromise, full security compromise and total identity take
over.
So what are the, well, 1000 feet view level of methods you can leak your application keys,
right?
Well, first of all, untrusted inputs and out of bound memory access.
So imagine you have stuff in your memory written somewhere, right?
And it may be that like near that stuff, you can have like a cryptographic key also in
the same memory.
And the normal application logic should allow you only to read stuff.
But like what happened, for example, in hard bleed, if you can make the application read
past the buffer boundary, you can also read the cryptographic key, right?
And this is what happened to hard bleed.
Everyone remembers hard bleed.
Well, if your application have arbitrary remote code execution, like what else to discuss
there is game over, right?
So like attacker can control the execution of your binary and they can read, and due
to say everything being in the same process space, so they can read everything and as
to write everything.
Not much to discuss there, but in the example was recent one, lock for shell.
Everyone remembers lock for shell.
Who patched lock for shell?
Should have asked yesterday here, Java, right?
Well, buffer use can be a sort of problem for leaking a key.
So for example, this is a very, of course, this is a simplified program, but specifically
tailored to leak the key, but like it illustrates the example.
So for example, it has to function and crypt and log, right?
And oh no, we forgot to initialize the logging message in the log function.
And if you actually execute it, you will see that it kind of actually leaks the cryptographic
key.
So what happens is you have the process as thread stack, you have your main logic.
For example, you call the decrypt or encrypt data function, which will get the key from
somewhere and may put it on the stack depending on the implementation.
But if you then the function exits, but if it doesn't clean it up the stack with the key,
the next function can take it over and actually has an example, sorry, has an access to that
cryptographic key, right?
This is why all the compliance and security folks will tell you you always need to zero
memory after key use.
Like you have to clean up.
Which is hard to do in many high level programming languages, especially if in garbage collected
languages, right?
Finally, you have the debugging tools.
If you have a logging can accidentally leak your keys like core dumps, like GDB, Ptrace,
everything that can access the memory of the application can leak a secret.
Yeah, well let's make our applications don't crash and fix all the problems, right?
We obviously can't fix all the bugs, so we have to do something about it.
And probably we can't do a completely secure application, but what can we do specifically
for cryptographic keys?
Because they are the highest, most valuable data in our process address space.
What some applications do, well, they try to leverage the operating system address space
isolation, so they basically create another process, right?
It will have a different data section and you can just move the cryptographic keys over
to a different process and you write some very basic, very simple, which is unlikely
to have bugs, a cryptographic logic to handle these keys on behalf of the main process.
And then you create some kind of well-defined, tightened user interface between two processes,
right?
So we call it the key agent model.
So you have two processes, one, the main process and the helper agent.
The main process does not have the cryptographic material in the address space and the main
communicates with the agent through a well-defined interface to perform cryptographic operation
on its behalf.
And agent is usually doesn't process untrusted input, like it's not connected to the network
and is usually, and more scrutiny goes into that review.
And some of the example of these we all use every day.
So who here uses SSH?
Who here doesn't use SSH agent?
You don't?
Yeah.
Yeah, so SSH agent, GP agent, stuff like that.
But there are drawbacks to this approach, right?
So we need to develop and maintain two programs.
We need to design this well-defined interface.
We need to add communication.
Like we need to think about how these processes communicate.
Should we use Unix, talk, shared memory, something else, HTTP.
And probably it's a good to somehow enforce and authenticate the main process from the
agent.
And not if the agent is kind of like this thing that performs cryptographic operations,
we don't want anything in our system talking to it and being able to do signatures with
our keys.
This is where we go to Linux kernel key store.
And the official name is Linux kernel key retention service.
I call it the key store.
Some people say it's a key ring, but actually, like key store has many key rings.
So I think the key store is kind of the most applicable technology.
And what it does is basically it takes this agent model and instead of process two, it
replaces it with a kernel, right?
And the well-defined interface is just system calls.
Easy.
So in a nutshell, Linux kernel key retention service stores cryptographic keys as kernel
object.
And this gives us some flexibility.
So it was initially actually designed to share keys with the kernel services itself.
So like for disk encryption, for example, you pass a key to the kernel and the kernel
uses it.
But eventually it was extended to user space.
And the advantages that keys are now stored outside of the process address space, you
have already have a well-defined system call interface to access and use the keys.
And keys are becoming kernel objects so you can have associated access control lists,
permission checks.
Like you have on files or some other kernel objects itself.
And the nice thing about it is like the key life cycle can be implicitly bound to the
code life cycle.
For example, security deleting a key even if the process terminates abruptly.
And for a kernel feature, it surprisingly has a quite good documentation.
So what does the key store look like?
So it's a collection of key rings and keys.
So a key ring can have links to other key rings and keys can contain other key rings
or contain keys.
So you can get this like a tree like structure.
So keys are just objects that contain actual cryptographic material or a pointer treat.
They can be read and written to and used to perform cryptographic operations.
There are several key types which I go on later.
You have user, logon, asymmetric encrypted and trusted keys.
And they're kind of similar to a file system but unlike the file which can be on the in
one directory, like if you don't take into account the weird bind mounts or some kind
of hard links, keys can be part of many key rings at once.
And key rings, they, it's a collection of links to the keys.
And basically they enforce the life cycle of a key.
If a particular key is not linked to a key ring, like it gets automatically destructed.
And they can be explicitly created key rings or implicit special, a thread process, user
and session.
And they do enforce the key lifetime and they are kind of similar to a directory in the
file system.
So let's see an example.
And by the way, all the examples I'm showing, I copied it from a real terminal.
So it's a demo which doesn't fail.
So in this example, here I'm creating a new key ring and linking it to my implicit user
key ring.
And each key or key ring is designated by a serial number which you can see.
So it's kind of a unique number of the object inside the kernel.
And once I created the key ring, I can add a key there with some secret contents Hunter
2 to my key ring.
Basically I can then show, kind of, KCTL show shows my key ring and key tree.
So we have the session ring, the user ring, my ring and my key there.
Yeah.
And basically you can see that the serial numbers match so what we just created.
And also like because I just created the key, I have access to it so I can read the cryptographic
material back and get the secret.
And I think one of the examples you can use is like secret sharing between two users.
So you have Alice and Bob to users on the system and you may notice they don't have
anything in common.
So they have separate groups, separate IDs, everything is separate.
No common groups or permissions.
For example, and Alice can create a secret with Hunter 2 and put it in their user key
ring.
What Bob can do, for example, it can create a new key ring called from others, a recipient
key ring.
And Bob can actually set permissions on that key ring so it allows everyone to write there.
Write means putting links to other keys.
So then if Bob communicates the serial number to Alice, Alice can just move that key to
the Bob's key ring and then we now see that Alice doesn't have the key anymore in their
possession and Bob can actually now read the cryptographic material because Bob now possesses
that key.
Simple.
There are special key ring types.
And these special key ring times determine the life cycle of a key ring.
So there are session key rings which are available to all the current process and all these children.
So for example, if you are system D and you put a key in the session key ring, it will
be available to every process on the system which is spawned by system D.
The process key ring is private to a particular process.
So like every process has their own implicit key ring which they can use to store process
specific credentials.
And there is also a sweat key ring which is specific to a particular thread.
Then let's say you write a web server which serves several websites and each website has
a different TLS key.
And you can, if you serve a website per thread, for example, so you can kind of securely store
a TLS key for that thread, for that website without other threads even having access to
that key, which is really cool.
There are also user key rings which are bound to the life cycle of a user.
So it's a key ring which is shared between all the processes with the same user ID and
there is a user session key ring which is similar to user but not important in this context.
There is also a type called persistent key rings which the name is a little bit confusing
because they are not actually persisting the keys on the desk.
It has nothing to do with it.
It's just the life cycle of these key rings are different.
They're not bound to a process or a user.
So it's kind of time bound.
So if you basically don't access the key ring for a time out, it gets automatically destroyed.
It's useful, for example, in Chrome jobs where you can't really bind, for example, a key ring
to a user because that user appears and disappears from the system but you can put a time bound
and while your Chrome job is running, your key ring will be available.
If for some reason your Chrome job stops running, the key will be eventually destroyed.
So let's see a session key ring example.
So let me add my favorite Hunter 2 secret to my session key.
And basically, I imagine I'm on a SSH session to this particular machine.
I can see that my key exists, right, and I can see its ID and it's linked to the session key ring.
What I can do now is, for example, in another terminal I can put a BPF probe on a user destroy function
which is responsible for securely destroying keys from the kernel key store.
And if now I just exit my SSH session, I log out, I can see that the probe works
and my key was automatically destroyed because my session ended, so my session key ring got destroyed
and all the keys are linked to it got automatically destroyed as well.
And if I re-log in back, I can see that technically my session key ring changed.
It was destroyed and recreated automatically and I don't have the key anymore.
So what it helps is, like, if you select the appropriate key ring type,
you can ensure that keys will be securely destroyed when not needed.
And you don't have to explicitly clear the memory.
It will happen if you're out.
For example, if you bound to a process key ring, if the process dies, the key will get destroyed.
And regardless how the process dies, if it's successful exit, if it crashed, if it cordoned, whatever,
like the keys will be gone.
Okay, so now let's consider, like, some different key types.
So we check the key ring types, the key types, the simplest one is the user key, which we just saw.
So you have the cryptographic material, you put it inside the kernel,
and then eventually either this process or the other process, which has relevant permissions, can read that secret back.
There is also, like, a special type called logon key, which you can put inside the kernel,
but you can never read back.
And this is where this type is primarily used to share secrets with the kernel for disk encryption or eCryptFS.
So if you're in a relatively recent Linux distribution, if you dump your dmCrypt setup,
you will see that some of your keys are actually coming from the kernel key ring instead of, like, you will see the bytes directly.
There is also an asymmetric key type, which only supports RSA currently.
So you put an RSA key inside the kernel, and technically you don't read it back,
but you can perform some operations with this key, like you can instruct the kernel to sign data or decrypt something with the key.
So for example, this is a simple example, it was open SSL, so we can generate an RSA private key.
Kernel understands only pkcs8 format for unencrypted pkcs8 private keys,
so we have to convert it to pkcs8 format, and then we can actually add it to the kernel,
and then we can ask the kernel to sign something,
and basically we can then verify that the signature is valid with OpenSSL.
Which is very useful, so all the things I'm describing today, and more is describing Cloud for a blog post,
and there we have an example where we completely replace SSL, it's like a proof-of-concept patch,
but we patched OpenSSH and replaced the SSH agent with the kernel key store,
so instead of SSH add, you do SSH add our bash script, which puts your private SSH key into the kernel key store,
and if you run the patched SSH client, it will actually work the same as it would communicate with an agent,
but you don't need any agents running on the assist.
Cool, this is all well and good, this is how you can use it,
but surprisingly key store can be very useful as a big corporate key management building model,
but the question here remains, in all the previous examples you just saw,
that we still need to put the keys into the kernel, so we don't want the secrets to be in the application address space,
but we still need the application to put it inside the kernel,
so even though if the application cleans up after itself, there is a small window of opportunity
where application has the plain text secret in its address space,
so how can we provision application keys without cryptographic material ever being exposed to the user space at all?
So for this we have two other interesting key types, one is called encrypted key,
and in this case the process has not the plain text key material, but encrypted key material with some other key,
and the kernel has a wrapping key, so when the process inserts that key inside the kernel,
the kernel automatically unwraps the key, and if we try to read it back, it gets automatically wrapped by the kernel again.
But here we have the chicken and egg problem like how do you then provision the wrap key, right?
So, still things, so what James showed earlier today in his demo is you can technically replace this with a TPM,
and then you have a thing called a trusted key, so again you have the wrap key, but wrap to a particular TPM,
you can insert in the kernel and TPM will automatically unwrap it, and again if you read it back, it gets wrapped.
But this schema is not really great because as James mentioned TPMs are slow and there is as much as you can do with these operations,
so like if you have thousands of keys you don't want to continuously poke the TPM to unwrap them,
so you can do some kind of a combined approach where basically you have some kind of provision, right?
So, and you have some kind of HSM in the cloud or on-prem, whatever which does your cryptographic keys,
and then you provision a root key first, so you basically wrap the root key to a particular machine to its TPM,
and then you insert it and the TPM unwraps it, but all the other thousand keys are encrypted with this root key,
so the process received the wrap key and then it puts inside the kernel and then you don't go to TPM,
you already have the root key which is a software implementation, can easily unwrap all the other thousand keys.
But there are still problems with this approach, even though the application never sees the cryptographic material in this process address phase,
but applications are still responsible for receiving this wrapped cryptographical material from this centralized KMS HSM service to wrap their keys,
and so basically each application needs, who here uses Vault?
Yeah, some people, right? So like it's, you kind of like know what, need to know what your Vault address endpoint is, right?
You need to speak the Vault protocol or AWS KMS protocol, you need to basically integrate all this crap in your code,
and there is little administrative control if like you're managing fleet of machines of the created kernel key object,
so applications when inserting the key can set invalid permissions, so like anyone can, for example,
if you set improper permissions on your RSA private key, any application, even malicious on your system,
can use it to encrypt or sign data, right?
And ideally like you also want authentication here, so KMS or HSM, that remote service,
needs to somehow authenticate each requesting application if it can provide the wrapped cryptographic material.
So how the kernel tries to solve that problem, it has two set of system calls.
So far we've been using the at key system call with a key CTL utility,
so it adds the key to the specified, key ring with the specified payload.
So basically the application is responsible for the payload itself,
so it's either plain text or in case of trusted or encrypted key, the encrypted payload,
it gets it from somewhere and it sorts it into the kernel.
And the payload is interpreted according to the key type, it's like no interpretation happens for user logon keys,
because those are mostly symmetric keys which are random strings,
it's a private public key for asymmetric cryptos or wrapped for encrypted and trusted.
But there is another interesting API in the kernel called request key,
so instead of applications inserting the payload directly what applications can do,
they can ask the kernel, just give me my key, give me my key and give it an arbitrary string as an identifier.
And it's on the kernel to actually satisfy that request,
and obviously the kernel has no idea of everyone set up, like where should it take the key from,
so it's one of the examples where the kernel can then make a user space callback
and with a special helper program which you can then configure to actually deliver your keys, right?
But it's a more centralized and transparent API to the kernel system, so how it works,
so you have the process instead of adding key, so the process requests the key from the kernel
and provides the identifier, so like give me my cloud app key one,
so the kernel creates a placeholder, then it creates a special process,
a callout process, helper process in user space called request key,
and this one you can configure and you can specify different routes for different key types,
for example if I requested the cloud app key one, it will go to the cloud sub-module
and you can write these sub-modules in any programming language by the way, it doesn't have to be C,
so you can write them in Go, it can be just simple batch scripts as well,
which are basically responsible for if the path is cloud, it can contact your cloud HSM,
get the wrapped cryptographic material, put it back inside the kernel,
the kernel will then instantiate the keys and then the application will get its key back.
So with request key advantages, you have a single centralized operating system API
to request key from the application, so there are no KMS or HSM connection strings,
you arise in your configuration form, just a freeform ID string,
and it kind of fully decouples, your application is fully decoupled from key storage backend,
so it doesn't care where the keys are stored and how they are distributed,
and it's a more secure way to instantiate the keys in the kernel,
so this special call-out process which is created by the kernel is very special in the sense that
it has a special credential enforced by the kernel, so even if you launch the same helper process yourself as root,
it will not be able to instantiate the requested key because it doesn't have a specific token from the kernel to do it.
And this also call-out process is very useful, in fact it can be trustworthy,
so you can perform additional security checks, you can implement arbitrary policies there,
so you can check the requestor, user ID, group ID, executable pass, package name, whatever you suppose,
is this application even allowed to request the key in the first place,
and you can immediately deny that request.
And you can support multiple key storage backends, you have local storage,
you have a TPM backend, cloud HSM backend, whatever, and you can even swap these backends transparently,
like if you, for example, migrated from on-prem HSM to a cloud HSM,
all you have to do is just modify this helper process config file and applications will not notice.
And then you have the nice thing that you need to only authenticate this single helper process on your backend.
And yeah, as I mentioned, the backend connectors can be written in any language, so very easy to extend.
But the nice thing about that with request key, the key management and distribution becomes a core service operating
of the operating system itself as it should be, versus like every application has to deal with it on its own.
That's basically it for today. Here are some links to some kernel documentation, to some key ring man pages,
as well as the last link. Again, everything I told you today and even more is described in the cloud for our blog post,
which is linked at the end.
Thank you and I'm happy to talk to you.
Thank you for the great talk. So I recall there was an API in the producer space to protect memory from kernel space.
So the, like a given page was unmapped from the kernel.
So if you had an out of bounds in the kernel, you couldn't access the memory,
but of course the kernel could remap the page back again.
My question is, are the keys protected in such a way in the kernel?
And do you think it would make sense to do it? I mean, it would potentially minimize the exposure in theory at least.
The default, I don't, I'm not sure about the implement, but I would say no.
I think the keys are not like more protected.
So the guy who wrote it is right there.
And what was the question? If you put a key of the user space process into these areas, they will be more protected than otherwise.
It still doesn't guarantee like 100%
My point is the kernel could also do it so that it would protect those keys from itself as well.
And it would only remap the page back again when it actually, when you do the request key for it.
But what's the point then?
If kernel needs the keys, it has to have access anyway and remapping and mapping is costly.
The other thing is the key store API internally is also extendable.
You can write other modules and this is what I asked for.
James earlier, that you can technically write an asymmetric key implementation backed by the TPM.
So the keys will not be even inside the kernel.
It will be in the TPM, but then each operation will have to touch TPM in the first place.
Or if you like design some kind of crypto chip or you can like design like an arm like a truss zone back here.
So like whatever you want.
There was some effort. I don't remember exactly which areas it touched to do this sort of separation between subsystems.
But I only learned about it once. I don't know what they say this.
No, no. Well in kernel it's still like the old, you mean in the kernel subsystems?
I don't like it's still like a flat address space at this point.
I don't, unless you're again using like arm trance zone or enclaves or whatever.
My question is, so you mentioned that we can do RSA operations.
Not everybody is using RSA.
Are there any efforts to introduce other kinds of asymmetric keys?
In particular, I'd like to see an explicated stuff.
So, yes.
So the kernel currently also supports ECDSA, but only for signature verification.
It was added for kernel modules.
I send like patches to actually support signatures through for the Q-Stone API twice.
I didn't get any traction on them. I'll send it one more time maybe.
Because I also know that the kernel has its own internal crypto API
and has support for all of these operations.
They're just not exposed through the key store.
Well, specifically for RSA, for ECDSA, no.
The kernel crypto API doesn't have crypto for ECDSA signatures for generating the signature.
So my patch set included both the crypto subsystem and the key store subsystem.
The kernel can do ECDSA signatures, but also this code is reachable through the key store API.
Okay, thank you.
Very interesting talk. Thank you.
I have basically the same question.
But also, wouldn't there be an urgency to get some PQ crypto in there?
Maybe, but we have to fix ECDSA first before we have to learn to walk before the run, right?
James, can you pass it to the next?
So if we now add the trouson to the picture, does the kernel have any kind of API to interact?
I mean, the key store itself, would it interact with the trouson to get the key
or we need to still go to the user space to the helper
and then the helper will just go through a normal way of communicating with the trouson
and secure monitor call and get back the result and then the key back to the kernel.
For the trouson, I think there is some code, because I never tested on an ARM system
like similar to what we have, the trusted keys for the TPM back trusted keys.
There is an implementation for trusted keys for the ARM trouson, the open source one.
I saw the code, I never tried it, but it's there.
So there is some reference of the application, right?
Yes.
The GNS and there is internal support for that.
Yes.
OPTE.
Yes, OPTE.
Alright, anything else?
Oh, yeah.
If you shout, I'll just repeat.
It's just wondering which version I need to use this.
Sorry?
Which version is it available from?
The kernel key store.
I mean, it's quite all, I guess.
What we did, I think from 6.1, again, we mentioned the crypto subsystem, the key store subsystem.
It was really handy to insert the RSA key into operation with it, but you didn't have any ability to do the same with the symmetric key.
So what we extended is like the crypto user space socket API to be initialized from the user or logon key.
So now you can do it from 6.1, you can insert a symmetric key and then you can create a crypto socket based on that key to perform like AS encryption with that key without exposing the key to user space.
Back to you, does this not want to...
So if I recall correctly, you said that the persistent keys can expire after some time of being unused.
Does listing the keys also count as using them?
That's my first question.
My second question is like, what's the time out time for it to expire?
I haven't used them like so widely to have those specifics.
I think the time out is configurable, definitely, but listing, I don't know if listing the keys actually reset the timer.
I just want to answer the question from over here.
It looks like the API has been available since 2.6.10, which feels old.
Yeah.
There is one person over there which...
Maybe you shout, I repeat.
As a certified micro-configuration enthusiast, is there a reason why this approach is taking rather than planning APIs for the value of duty and so on, that you need the space and have the same benefits?
The question was why we didn't do it in user space, but...
How do you add extra functionality to the kernel to give you the same benefits?
I kind of don't quite understand the question.
The whole point is not to expose cryptographic material to user space.
You're saying the benefits are, for example, if a process dies, then you can immediately wipe the key from memory and that sort of thing.
You could also add functionality to add consistals to the normal database processes that have that sort of benefits.
Why didn't you do that rather than sticking extra things into the kernel?
Because you can retrace the processing of user space, but you cannot retrace the kernel.
Just saying.
Anyway, we are out of time. Thank you very much.
I'm sure you can get two infocations.
