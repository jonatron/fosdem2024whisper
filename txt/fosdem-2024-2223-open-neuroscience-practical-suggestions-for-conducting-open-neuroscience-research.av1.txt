Cool.
Take it away.
Cool.
Howdy, y'all.
I'm Danielle.
It's nice to see you.
Nice to meet you.
And I'm super excited to talk to you about open neuroscience.
And I'm really glad there's a lot of people here.
I did not expect everybody to come because I know this is a developers conference.
So I'm going to tell you first why you should care about open neuroscience.
First point is that we all have brains, right?
Any time I mention neuroscience, everybody gets really excited because we do have brains
and that is essentially what we are, the integration between our brain and our body.
But the issue is oftentimes our brains don't work the way we'd like them to, right?
Raise your hand if you or somebody you know has ever struggled with mental health,
neurological or psychiatric conditions.
Right.
Everybody's crazy and sad.
And so, and this is not unique, right?
Neurological and neuropsychiatric conditions are one of the greatest contributions to the
global disease burdens, right?
If we think about the fact that 28% of the global disease burden is neurological and
neuropsychiatric, that's including communicable diseases which spread like wildfire.
We all had COVID.
And so we understand the importance of the world.
And so we understand the importance of better neuroscience means better health.
But more than that, why am I presenting this to you?
You may get that implicitly, but I also think there is a long and storied history of
neuroscience and computing.
And so we have been learning from each other and influencing one another since the
inception of our fields.
And to exemplify this, I have two people up there.
Everybody probably knows who John Vaughan Newman is, hooray.
But Rafael Laurent de Neu was a very close collaborator with John Vaughan Newman, and
he was a colleague of Ramoni Kahal.
Out of curiosity, how many of you here do any form of neuro stuff?
More than I thought.
And so you will know Ramoni Kahal is the one who is responsible for any time you've seen
a picture of a neuron, and it's in black and white, probably him.
And so not only were they delving into the structure of neurons to understand how they
functioned, this was seminal to the work of computing for how do we communicate information.
And so you have interactions between Rafael Laurent de Neu, who is understanding how
electricity communicates information through the structure of neurons with John Vaughan
Newman coming together at these conferences on complex systems and biosciences.
This continuing trend of neuroscience and computers have continued to influence them, right?
Fast forward a little bit, you get Frank Rosenblatt and the perceptron, right?
Based on neural networks, literally how neurons communicate with one another.
And so here we are today.
But not only have they continued to learn from each other since the inception of our fields,
now in our kind of open neuroscience focus, we continue to learn from computing science
how we can make neuroscience more applicable.
And so we've all talked about the reproducibility crisis.
I'm not going to spend too much time on it, but we can say that having open source technology,
sharing your code, sharing data, and other techniques that I'll talk to you about today,
are ways that we can improve the quality of neuroscience and therefore hopefully improve
the quality of health for all of us.
But another reason, some of you in this room may be academics.
I hope some of you are academics.
And if there is anything that funders are starting to like, it is the fact that we're
going to be able to do this.
It is the fact that you may have open source technology, or that your work may be reproducible
and shareable, and not just because you have pretty figures, but the fact that funders themselves
are realizing that open neuroscience is more robust, which means it's more often replicated,
which means it's often more generalizable and holds true in ecologically valid and clinically
translational applications.
This means they get what they ask for with their investment back to them.
And so I'm glad personally that funders care about open neuroscience because it then provides
the means for researchers to do the extra time and effort that open practices often take,
and we acknowledge that.
I also think that open neuroscience helps facilitate a synergy between industry and academia.
Oftentimes, industry has a ton of money, but they may be focused on research questions
that are of interest to their stakeholders or profit shareholders,
and maybe not so much time or interest for R&D.
Academia is R&D.
So if there is a little bit more open neuroscience from industry and from academia,
perhaps we can help each other with this.
So when I talk about open research, I'm not just talking about academia,
I'm talking to industry people as well.
And finally, the principles I'll discuss in open neuroscience, a lot of them are transdisciplinary.
There will be some fund neuro-specific examples, which is why I hope you're here,
but there are also many transdisciplinary principles.
So I'm going to move through the different stages of a typical research experiment,
data, preprocessing, analysis, dissemination,
and for each one, I'll just talk about one or more aspects of open neuroscience,
starting with the data we have.
Specifically the fact that I will first talk about the type of data that I mean,
and I mean neuroimaging data.
So we have a beautiful drawing of a brain here.
That was published in 1643, Andreas Vesalius and Dake, what is it?
Dake, Humani Corp. porous day fabrica.
I'm sorry if you're Italian, I just butchered to that.
But he was a visionary in terms of how to visualize the brain.
He was the one who came up with taking this 3D structure that we have and slicing it,
thin sheet by thin sheet and drawing each sheet, and in doing so,
sharing the visualization of how structures connected from top down,
starting to give people a 3D visualization of brain function.
Now that's really cool, but the issue is only the people who could do dissections,
which were not very common,
actually had a chance to interact with these structures themselves
and see how these structures connected in 3D,
and as we know in biology, structure often implicates function.
But worse off is that the structures were dead.
Yes, they can tell you structure, but brains are so complex and filled with electricity
and neurotransmitters and fluids.
A dead brain is a very poor representation of the complex emergent phenomena
of this dynamical pink walnut that we all share.
So this is where neuroimaging comes in, and this is the kind of shit that I do.
This is the kind of stuff that I do.
And so, it's late.
And so these are the ways that I prefer to visualize the brain.
I take the brain, I break it up into a bunch of regions,
like in the top left-hand side,
and then the gif just to the right of that, all those regions,
you see how they connect over time.
The brighter the color means two brain regions, I should have labeled them,
but zero to, in this case, it was zero to 110 brain regions.
I would use a different atlas now, we all improve.
And the lighter the color between the two
means the increased mutual information between them.
And every frame in that is every couple of seconds.
And so this is a person playing a cognitive task.
It's a bit of a memory game.
And we see how the brain evolves its connectivity over time.
That's really cool.
We also have images of how the brain lights up, if you will.
We have better ways of visualizing brain structure.
So this is the neuroimaging data that I'm talking about.
So there's tons of types.
We have EEG, MRI, anachronome, alphabet soup.
The point being is each neuroimaging modality has its own challenges.
In terms of its spatiotemporal resolution, let's take EEG, right?
EEG caps, and I'm going to, this is going to come up later, so.
EEG, raise your hand if you know what EEG is.
Oh, yes!
All right, I'm not going to bore you with a ton of background.
But basically, for those of you who don't, it is a cap pictured here.
It doesn't have to be a cap, but often a cap placed over your head
computes the sum of the cortical electrical activity that we have.
Problem, our brains are not just the outside of our brains, right?
We have tons of nuclei and complex structures deeper within.
That we don't really get with EEG, but EEG is a lot cheaper to use
than my personal favorite, MRI, the superconducting magnetic donut
that we have pictured to the right of the EEG.
And that is a fantastic spatial resolution.
And at the moment, we can get submillimeter resolution.
That's pretty good.
There's still thousands of neurons per voxel or 3D pixel,
but the problem is temporal resolution, right?
I speak quick, the brain moves even quicker.
It's at the speed.
But the issue is with fMRI, we're not measuring electrical activity.
We're measuring the response of blood flow to increase brain activity.
So right now, my language centers are firing, firing, firing,
and it's like using a muscle, right?
The blood flow will come to those brain regions, and that takes time.
Time, that is essentially just a slow down representation of brain function.
Thank goodness the brain is a scale free system,
so we can at least learn some principles from slower temporal resolutions
with EEG's faster temporal rosin and bad spatial resolution with fMRI's.
All this is to say, there are challenges with each.
But if you are going to collect data,
we're going to talk about how you can do it in an open and reproducible manner,
and step one is to think about it from the get-go.
When you are creating your ethics protocol,
when you are designing an experiment,
and you think, okay, I'm just going to have my standard consent form
that my lab or the university typically has,
make sure there's a section about data sharing in your consent forms
and be specific about what types of data you can and will ask participants to share.
So if somebody takes an MRI scan, right,
typically it's very easy to share a group level statistics.
If I take everybody's brain and I do a bunch of processing,
and then at that point it's probably in a standard Atlas space
and you can't backtrack to get to any personal identifiable information.
Problem? That's really boring,
because all of the beauties and the complexity and the individual differences within each of us.
So we have to balance this trade-off of being as open as possible
while being as closed as necessary to protect patient
and participant information.
And so I encourage you to think about that from the outset
and put it in your consent form so that you're not stymied by having all this data,
realizing you can share some cool stuff without harming patient or participant privacy
and realizing you didn't ask them if you could share it.
And nobody likes to get an email or a call six months after you were paid 20 bucks
to participate in a research experiment being like, by the way.
So think about it from the outset.
Another important thing when collecting data
is to consider addressing gender bias.
And so what I mean by this is in many different studies, in most studies,
there's a typical bias to have male participants,
and that is a problem because half the population has female brains.
And so we could think about this with the success, or should I say failure,
of a lot of drugs that go to market, right?
This is not a neuroscience example, but typical medical trials
often have male-dominated participant groups and participant samples.
Then a drug gets approved, ha-zah, we think it's good.
It goes to market, immediately pulled back,
because the other half of the population that now takes that drug
has adverse reactions that we're not accounted for during the clinical trials.
Same stuff goes for doing experiments, get diverse brains.
Which brings me to point three, breaks a weird cycle.
Who knows what weird means as an acronym?
Acronym.
Nice, for those of you, good woke points.
Weird stands for white, educated, industrialized, rich, and democratic.
Most of the time, neuroimaging research is done in western countries,
Australia, the United States, and leaves out a lot of the global south,
often because neuroimaging experiments are expensive and use a lot of resources,
that the global south typically does not have the R&D budget for.
There's some really cool research out there on this.
But point being is the state of neuroscience is not representative of the world's population.
So we need to get better at diverse recruitment.
So for example, I live in London now,
and I looked at the most recent census data to see what's the kind of demography of London.
And I found out only 46% of London is white,
everything else breaks up into different categories.
So I make sure that my study populations are representative of this,
but it's not only cultural or racial ethnic, it's also socio-demographic.
It's very easy for me to go to my university canteen and goes,
who wants 20 pounds to participate in a cool neuroimaging project
that you get a 3D printed brain at the end?
Everybody loves that.
Problem is that everybody there in Imperial College London
tends to probably be very educated and potentially wealthy
and therefore is not subject to the health impacts of the rest,
that literally the rest of the population faces.
So I make a conscious effort to do recruiting in local faith centers,
and I'm talking go to your local Islamic Center,
go to your local synagogue, go to your local Afro-Caribbean church,
get people interested, and I'm not just saying like ask people to do research with you,
show them why it's interesting.
So most of the people I work with have heroin use disorder,
I do addiction neuroscience and psychedelic neuroscience,
and so I go to service users and I say, what would be helpful to you?
What do you want to understand better about yourself?
What would help you?
Maybe not use crack this time.
And so these are the sorts of dynamic conversations you can have with communities
and make sure you have community investment in your research
because the community will give you back that your time and your effort you put in.
And again, better research samples means better generalizability, more robust data.
Huzzah.
Finally, we're going to break various participation.
We talked about EEG earlier for a reason.
If I'm running a neuroimaging experiment, I want to put an EEG cap on somebody's head.
If you have an Afro or just thick and kinky hair,
or you've got box sprays or dreads or banchanauts, whatever,
it means the cap is not going to fit close to your skull,
and I can't get your brain data.
So there's two options.
Participants either say, okay, thank you.
Okay, sorry.
Or they're really patient and kind people who let me move their hair
and put electrodes one by one by one by one in their,
on their scalp so that I can get that data.
The problem is then that we all, I have to make sure I communicate to the participant,
yes, the electrode conducting pace is water soluble,
but maybe ask them, do you want to do this on a hair care day?
And if you do, I want to make sure that I give extra remuneration to participants
who have extra hair care considerations because if I do a study,
my friend washes my hair in the sink.
That's fine.
That works for me.
If somebody else who has to go home, spend a lot more time working on their hair,
they should be reimbursed for that time.
Right?
So think about diversity from the outset of funding your experiments.
I did, that was a long harangue, I'm sorry.
But pros and cons of collecting data is that the pros are that it's customizable
to your research paradigm.
So I'm really interested in the relationship between reward processing,
decision making, and attention, and how it goes wrong in addiction.
Oftentimes it's really hard to get addicts in the scanner, right?
They have a lot of well-founded trust in large structures like universities,
healthcare systems, what have you.
So I often need to go out and collect data, but when I'm developing my computational skill set
and I can just use healthy brains, I'm going to avoid the time and resource expense
of collecting data and utilize what is already out there.
But if you are going to collect data, Danielle's pro tip is to test your analysis pipeline
with a small pilot sample first.
It's not only good for you for your downstream analysis,
but it's great for registered reports, which have we heard of this earlier today at all?
Or in general? Any nods?
Somewhat, okay, not a lot of nods, so we're going to talk about it.
So registered reports are when you say to a journal,
I would like to do this study.
Here's my introduction, here's my methods.
Do you, and it goes through peer review, it's like half the paper goes through peer review.
If they accept it, that means whether or not you have no results, that paper is published.
That's pretty cool.
And that actually gets over the trend where large journals have this,
I don't know if you guys have seen the correlation between the higher impact the journal,
the smaller the p-value a study typically has, and therefore the burying of no results.
So it's really nice that some journals are happy to do registered reports,
which it is more time and effort on early career researchers often or whoever's doing it.
This is why it's nice to say to funders, I'm going to budget extra time to collect this data
in a reproducible and ecologically valid manner.
I'm going to develop my analysis pipeline with some pilot data and test it,
and go to the time and effort of doing a registered report,
then finish recruitment and study sampling.
Open Science takes more time, but for neuroscience example,
if you are going to collect data, data anonymization is important,
because we want to share our data, but if somebody comes into an MRI scan,
and I take an image of your brain, it's not just capturing your brain,
it's capturing your beautiful faces as well.
And so we need to think about how and why we're going to scramble that,
and how we're going to take care of that before we upload this data to whatever open neuroscience data sharing repository.
And I'll cover some of those in a bit.
So I have some examples here of how some people just completely remove the skull,
the other sorts of tissues and what have you, and just go straight up to uploading brains.
You can do defacing algorithms, you can do blurring, masking, whatever.
And so there's pros and cons to each of these, but I just wanted to give this as a highlight
of how we need to think about participant safety before uploading data.
But you could also just use previously available data, and we love this.
My whole PhD was basically the Human Connectome Project.
Pros, it's plug and play, it's well validated, it's easily citable,
but the limitations are what I mentioned before, and it's the pros of collecting your own data.
There's limited study populations, maybe you have the study population you want,
but not the imaging condition you need, etc.
But one thing I really like about open data sets is that even if I collect data,
I can often try to reproduce even some of what I do in my collected data with an open data set,
make sure that my results are replicable with these larger sample sizes
than my lowly grants and funding can afford.
And if you are just going to use open data from the outset,
I encourage you to look from the outset for compatible databases that you can do test-re-test reliability.
So I'm a big fan of using the Human Connectome Project, which is an American project,
in conjunction with the Chinese Human Connectome Project.
So lots of similarities in how the data was acquired,
but you have a really different population from which that data was collected.
Brilliant.
Pre-processing and analysis.
This is what I spend most of my time doing,
and this is what I'm going to spend the least amount of time talking about,
because this gets real technical real quick,
and I don't know how much you know or care about this,
but if you are interested, come find me.
But the thing that I will say is that a lot of pre-processing and analysis
uses a plethora of open-source technology,
and choosing a toolbox can feel like an analysis multiverse.
So when swimming through the sea of analysis techniques that you can use,
one, I'll just leave you with a few tips, one of which is to use bids,
or brain imaging data structure.
It's a way of organizing your data,
where a lot of open-source technology can take your data and shove it through their pipelines,
give you shiny results, but better yet,
if your data is in bid structure,
and when you have properly anonymized it and gotten consent for it,
uploaded it to a data sharing repository,
everybody else can plug and play.
It increases the ability for other researchers to use your data.
We love it.
Now, let's see if this demo will work.
Who's heard of Neurosense?
A few people?
Hazard, but I'm glad most of you haven't,
because that means this is fun and cool.
Actually, I have it pre-loaded.
Neurosense is one of these examples where a ton of data is uploaded,
and we get to see what things look like.
So Neurosense.org, so let's see.
So all these studies that have done language,
they just have language as a part of it, right?
It could be listening, it could be talking, we're keeping it vague,
but you can see how many studies did this say it was?
A thousand one hundred?
That's a lot of studies, and yes, there's some light,
and you can just click through.
You can download these maps.
I won't get too much into why this is really useful
to prevent a circularity of analysis, but it is.
Somebody give me a term.
Dementia.
Dementia, thank you.
Oh, you picked one that you knew was going to be up here, didn't you?
I'm grateful.
Only a hundred and forty-two.
Well, ah, so maybe there's a hundred and forty studies
of frontotemporal lovar dimension?
Who's to say?
Either way, the cool thing about this is not only
can you see the areas of the brain, you can then see all of the studies
that have contributed to those fMRI-based magnitude of the bold signal changes.
You can also do a bunch of FAQs, fun neuroscience and analysis tool.
That'd share it.
Right.
Dissemination.
How are we going to share our stuff?
Who has heard of paywall, the business of scholarship?
If you haven't, you should watch it.
It is a documentary on, and it's free and open source.
If you go to that website, you get to watch the documentary.
There is a terrible, just very boring joke about two minutes in.
If you get past that, the rest is great.
I always say, but the point of this documentary is that it talks about the history
of the for-profit publishing industry and why it's just not great today.
It's a necessary evil, but if you want to learn more about it, check out the documentary.
However, if you're also a part of the academic sphere,
where we need to just fill our CVs with DOI so funders are really happy,
then there are other ways for you to do this other than traditional research outputs,
many of which include things like preprints.
Great, but also protocol papers.
Protocol papers are peer reviewed, and they contribute to this kind of open methodology
and gives you a space to really get into the guts of what you've spent,
probably at least a year, really sweating over.
All of the trials, all of the errors, all of the bugs,
you can put that in a protocol paper.
Otherwise, you just start publishing those.
Registered reports we've talked about.
There's a whole spectrum of open access.
I'm not going to make you sit through it.
These slides will be online, so that's there.
Who's heard of Psyhub?
Good, everybody, moving on.
There are other means of dissemination.
By the way, in the paywall of the documentary, Anna Kay,
I forget her last name, the creator and coder for Psyhub,
she features in it, which is very fun, so she gives cool interviews.
Anyways, how am I doing on time?
You've got like six minutes including questions.
Cool, I'm almost done.
Other means of dissemination.
Y'all have heard of GitHub, but there's a few you haven't,
and if you're a neuro nerd, Nitric is a good one.
There are others.
Open data, I told you to come back.
These are all of the different data sharing repositories for mostly fMRI data,
but there's also EEG data, MEG data.
Have fun.
These are more examples of why we should care about open data,
funding agencies, researchers, the public.
I kind of got over it.
Parting words are going to be short and sweet,
because I actually want to hear your words and questions.
And it's just the simple fact that open neuroscience benefits everyone.
Thank you all for your time and attention.
Thank you.
Thanks.
Thanks.
Questions, my friend?
You in the yellow hoodie.
Thanks a lot for the presentation.
In terms of explainability of these analysis and thanks,
I've read a lot of research papers,
but a lot of them don't really include the code.
And lately maybe it started from 2021.
They had something, so the European Union started publishing some stuff,
but they did not keep up.
And it's not keeping up anymore.
I think there's just only maybe some journals which are accepting and are enforcing that.
So I believe that's going on.
Poorly. I'm also frustrated.
I read a paper. I see the coolest analysis.
I'm like, how can I do this?
And I control F code, control, yeah?
Ah, I told you I was going to do that anyways.
I stink. Okay.
So what do I think about the state of open code sharing?
There was some, you know, progress being made in Europe about it,
but now it's kind of died back.
I'm based in London and I don't see too much of this done in the American sphere as well,
where I'm from. I say, y'all, you can tell.
So I will say that the, to answer the question of the state of data sharing
and neuroscientific papers to increase the interpretability of the analysis
and also the ability for you to just play with it on your own, it's not great.
I wish more journals enforced that.
It's interesting to me that you have funders who ask about open source stuff,
but then the other kind of top gatekeeper of academia publishing journals don't enforce it.
And I think this is where grassroots efforts do so much,
but if you make it policy and regulatory policy as well,
then you'll have a lot more uptake.
And then we can all do it a lot more.
This is probably stuff that you think about yourself,
and I'm sorry I don't have better answers for it.
I also wish it to.
Anyone else? Fun questions?
None? Maybe you're shy. Talk to me after.
Any more questions, my friends?
We do have a minute. We have time for one.
We have time for another as well.
Yes.
You've talked a little bit about scales.
You've talked about the gene in the R.I.
And I have one question.
Immediately pop up when I see such a theory is,
how does all of this relate to the multi-scale problem
in the population of neuroscience?
And...
Yeah.
It's a great question.
It's something that I know the field is trying to...
Oh, thank you for repeating the question.
Yes. When I talked about scale-free systems,
how does this relate to the aspect of multi-scale integration
of neural data in understanding the brain?
Is that a good summary of your question?
Thank you.
Okay. Then, for me, it's trying to harmonize multimodal imaging.
I've not quite bridged the EEG MRI divide,
but I'm starting a bit with PET MRI.
So, in this sense, I am trying to develop a better understanding
of how processes at the neurotransmitter level,
positron emission tomography, to those of you who don't know,
is a way of injecting somebody with a radioactive ligand.
If it's glucose, your brain is an energetically greedy organ.
It takes 20% of the body's cardiovascular output.
If you're using more parts of your brain, you get more blood glucose.
But you can also do it for mitochondrial activity,
for different pathological proteins, regardless.
You can see where cellular-level phenomena
are moving throughout the brain,
and then, because you can do PET and fMRI at the same time,
start to see how those cellular-level processes
relate to these macro-scale processes that we capture with fMRI.
Since those are captured at roughly the same time scale,
we can start to develop an understanding there.
In terms of integrating EEG and fMRI, there's some really cool work
I can maybe share with you a little later if you're interested,
but I have not been able to do it personally yet.
Thank you.
I think it's time to wrap up.
Cool. Thanks.
Thank you.
