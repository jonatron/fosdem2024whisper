Hi everyone. I like being early so we're going to start a little bit early. First of all,
who's enjoying the room? Yes? Yeah? Yeah, make some noise. Come on. There we go. There
we go. It's all Will's work by the way, so thank him after this fact. All right, I have
the pleasure of introducing Will again today. He started our event office this morning and
he's continuing here helping us to do it today. He recently took up bouldering and fell two meters
his first time of doing it and still keeps going on. I have to admit that is impressive. Take it
away Will. Thank you. Yes, so I'm quickly plugging this talk because one of our speakers
dropped out. So if I'm going anywhere nearer over time, just let me know. Just cut me off. It's
fine. And what I want to talk about is a little bit of work I did while I was in neuroscience
researcher. I think we had one of those earlier. Anyone else neuroscience? Nope, not a single one.
Never mind. Well, it doesn't matter. It was there was some interesting work I did while I was a
neuroscientist that looked at how to reverse engineer the causality between different brain
regions. So the idea is we go out, we take FMRI of somebody, we take EEG, we get a signal of how
their brain activity evolves over time. And what we want to understand is how these different
brain regions are interacting with each other to produce this activity, which is a useful thing
to do in research. It's useful in medical applications as well. And what we're actually doing
here at its core is something I think it's really interesting and it's really powerful. We're
simultaneously estimating a causal system that has engineered our behavior and we're
parameterizing it at the same time with the values that made that happen. And that's actually a
really difficult and challenging problem to do. And it's a bit of a shame that the technology
sort of confined to academia at the moment. So this project I did, what I'll talk about today,
is the work I did to make this more free and open source and not that the old code was bad,
but it was research code to make it better and more commercially viable. So let's talk a little
bit. We'll back off a little bit now and talk a little bit about what this technology does in a
bit more detail and we'll talk about then what I did with it. So what we do with this technology,
it's a Bayesian technology for anyone who knows what that means, but that means that we start with
an estimate of everything we do know about the problem or at least an estimate of all the things
that we don't know. We take this, we take our data and then with a dynamic causal modeling framework,
we infer simultaneously a system that describes this behavior and also, as I said, the values of
the parameters that parameterize the system. And we do this because it's Bayesian in an uncertainty
aware way. So every parameter, everything we estimate comes with a, it comes with a probability
distribution. It comes with an error estimate of how wrong we could be about this. So let's walk
through a simple example. So the way this systems inference works is we infer what is called a
dynamical system. That is what physicists use to describe how, I mean, basically everything works.
And this consists of two things. It consists of a state that is in our planet's example, that could
be the position mass of velocity of each planet. And it consists of a rule for how that state evolves
over time, which would in this case be the laws of physics. Things like this, I was going off the
slides a bit, but GM1M2 forces that two bodies with mass are applying to each other. And this is a
dynamical system and it's what we're trying to infer from our data. And some of our viewers may
notice the one I'm describing here, in fact, even on the slides is a differential equation. And for
those guys, I would point out that dynamical systems are known for basically, basically not
having any good solutions, which is partially a neutral framework. And in the dynamical, dynamic
course of modelling world, we would be doing something like taking the position mass and
velocity of planet A and saying, okay, I know there's probably some other planetary bodies
affecting this, but I don't know how many, how many planetary bodies are affecting this planet
that I can observe? And what is the position mass and velocities of each of these? And how
uncertain am I about that? That's an interesting thing to be able to do. A real world application
of this was in the COVID-19 pandemic. Here we have two very, very noisy things, hence the need
for uncertainty that we understand about the pandemic. That is the number of positive COVID tests
and the number of deaths. And we have a broad understanding of how the pandemic works. It's
or at least broad understanding of ways we can model it, something like a CER model, which is
what we opted for here. Well, I didn't originate this work, but I did make it work at the end.
A CER model, which is susceptible, exposed, infected, recovered. And so we can take these two
things. We can take the observed deaths and positive COVID tests and our understanding, and we can
project backwards to a dynamical system that explains this. And there's three reasons this is
a sort of particularly useful thing to be able to do. The first one is because we're understanding
our data from partially, at least, or as much as we want to, we can tip in the things that we
understand about the model beforehand. We can include things like hospital admissions and ventilator
usage. And because we can include these parameters in our model, that means we can estimate them
and it means we can look at them afterwards and have good guesses at them. And then we can do things
like we did here, where we look at the number of deaths from COVID-19 over time. And we can
estimate these parameters and fairly accurately, if you can see these graphs, because we knew they
were there, they've been included, we can estimate them. That's a powerful thing to be able to do.
Similarly, because we've included them out in model, and because of the way these things work,
because it is a dynamical system with different parts, and we now have it all interact with each
other, we can do things like look at counterfactuals. So we can say, what if I only have 200 hospital
beds this week? What happens then? What happens? How bad do things become? And again, that's a
really, really nice thing to be able to do. Finally, because this is a Bayesian method,
because it is uncertainty aware, we don't just get single point estimates out of this method.
We get probability distributions. So we can say things instead of like, I need 200 hospital beds
this week. We can say, the model says, I'm 95% sure that I need between 200 and 400, or I'm 90%
sure I need at least 300. And that's much, much, much more valuable than if you're planning things.
That's what you need to know. You don't need to guess at what's going to happen. You need to know
what might happen and how likely that is. In terms of the project we did about this,
my work about this, it was really about making it more open source. And I say more because the
original code base was open source, but it was written in MATLAB. And MATLAB is not really free
and open source. And I will give credit to the original researchers. They did modify things
so that it could mostly be run in Octave. But the unfortunate fact of the matter is,
Octave is a wonderful thing. It really is. I can't give enough credit to developers, but it is not
a replacement for MATLAB. Complicated MATLAB code, particularly MATLAB code, but dependencies
will just break and then it's annoying to fix. And it's at least 10 times slower. Depending on what
you're doing, it could be much, much, much slower than that. So having your code in MATLAB, even
if it's open sourced, it's not really open sourced. So we rewrote the project in C++,
which I know some people will disagree is an improvement, but it certainly goes a lot quicker.
And yeah, as we did this, we have tried really hard to make this code more generic as well,
because the original code was research code. It was designed for just two problems,
neuroscience stuff and a little bit of COVID stuff. Now the code works generally.
The other thing that we have been trying to do with this is to try and make it more open in other
ways. Again, a problem with this is its research work. And so although there are papers describing
how all of this works, I'm not going to lie, I literally did a PhD in this, they're incomprehensible.
It's really, really, really difficult to get to the bottom of the papers, even if you really
understand the subject material. If you don't understand the subject material, it's just awful.
And the thing is, when you've gone through it, and you do understand all of this, it's not that hard.
It's interesting and useful and creative, but it's difficult, it is not. And it doesn't need to
be, so that's the other part of the work we have been doing with this. To try and make it
free and open source by making it open about exactly what's happening and why.
Anyway, that is the end of my talk. That is my GitHub repo. If anybody wants to look at it,
do we have any questions?
William, you've written it in C++. A lot of AI people expect to use Python. What's your solution
for them? I have been writing a Python front-end for it. Is the solution.
It's a little bit of work in progress, but you can draw from this in Python if you want to.
Any other questions? You're going to make me run? No? All right, everyone give
another round of applause for Will.
