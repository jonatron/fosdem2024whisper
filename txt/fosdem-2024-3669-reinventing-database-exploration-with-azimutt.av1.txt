Welcome everybody, let's get started on the next session.
My name is David and it is my pleasure to introduce Loïc Nuchel, who will be speaking on reinventing database exploration with Azamut.
Thanks a lot.
Hi everyone, thanks a lot for coming to my talk.
Indeed, I will talk about Azamut and how we can explore the database with it.
My name is Loïc Nuchel and I am principal engineer at Dr.Libb.
Basically, the whole talk is a story about how I started at Dr.Libb and now I am here talking to you about Azamut.
Three years ago, I started at Dr.Libb.
I joined the company so if you don't know Dr.Libb, it is a French company in healthcare, allowing patients to book appointments with doctors.
Basically, it is built on big monoliths, on rubric and rails backed by PostgreSQL database.
Basically, it is a huge monorepo and also a huge database with 800 tables inside and several petabytes of data.
As an architect, I joined Dr.Libb to work with the team and help with architecture, improve the code and things like that.
But also, for that, I have to understand what is inside the database, what are the models and what are the relations.
The thing with rubric and rails is you don't define the properties inside the models.
You just define the relations, but often the models are quite long.
They can do like 1,000 lines long and sometimes the relation is as far as 100 lines or something like that.
That is not really convenient and I had to look inside the database a lot to understand what are the things and how it works.
Basically, that is me working at Dr.Libb for the first month and obviously, this is not very friendly.
I had to find a tool.
I looked for a lot of tools.
They are called ERD, and they show tables with relation and nodes.
As you can see, this is not very friendly.
Here is the 10 tables.
Imagine 800 and you will have some trouble.
I tried quite a bunch just for you to have a look at what they look like.
Basically, the NWAS NAP failed.
For a few reasons.
The first one and most of you find is all of the tools I could find will show everything.
When you show 800 tables, you don't understand anything.
The second one is most of them don't have an SQL or database import.
The last one is they are not private.
Basically, I had to upload the schema to the service and I don't want that for Dr.Libb.
Basically, when we are a developer and we are in this situation, we do another tool.
That's what I did with the big one goal to make it easy for large database like 800 tables again.
You may see tables with a lot of columns like 100 or something like that sometimes.
Locally, this is not for us, but this is a possibility to stay local and just have it in your browser.
Not send any data to the service and of course open source.
The first part was the schema exploration.
When you load your schema into azimuth, you don't see anything.
You just see a search bar and an empty screen with some situation.
The goal is to look for tables with the search and just load the table you are entered in.
Mostly, if you are working with a big database, you don't want to see everything.
You just want to see one, ten tables around your scale, your feature or something like that.
You can do some nice diagram like this with choosing the table and the column you want to show.
Also, you can navigate from one table to another following the relation.
Obviously, the foreign key with outgoing relation, but also the incoming relation coming from the primary key from the other relation.
That's pretty nice to expand your diagram and explore what's around.
Of course, you don't see everything. You want many layouts.
One per scope, discovery, team or anything you want, but several layouts of your database to understand it.
The last thing is sometimes in the database, you don't have foreign key for all the relation.
Sometimes for performance reasons, sometimes for reliability.
There are a lot of ideas around there, but sometimes you don't have the relation as foreign key.
So, azimuth can infer and suggest them directly inside the diagram.
The last feature on the stream exploration is a fine pass.
If you want to join data from one table to another and you don't know really all the tables in between, it will be a good one.
Basically, when developing this feature, I was very surprised about how many paths there are.
You will be surprised too.
Basically, that's also a good idea to have a look at that.
The second thing is when people are starting using that, like on read-only on the database schema,
they wanted to draft new features on it.
Basically, doing some more design for the database.
I made a DSL with an explicit goal to be very simple.
Here is a bigger version if you want to read, to just write the table name and the column name with two space before.
Then you can add some attributes like the types and some primariki, unique index, new label and things like that.
The goal of this DSL is to be very simple, very quick to write, to go as fast as you and you can flow and your figure can type.
When you do this kind of exploration, sometimes you have some discovery and sometimes you want to write them somewhere,
maybe for your colleague but also for your future self, again the exploration.
There is a lot of documentation.
Of course, the SQL command from the table, so it's loaded and accessible into azimuth.
Also, the nut into the table, this is the same thing as the SQL command but inside azimuth you can edit and view it easily.
There is some tag also to find type easily and of course there is the same thing for the columns.
So the SQL command, some nut you can add.
The nut are in markdown so you can do the formatting with images if you want, links, lists and things like that.
On the layout, you have one layout for what you want and you can document them with some memo inside.
Same with markdown, you can put image, link, whatever you want to explain the whole schema, some part of the schema, you can have the color behind.
You can also have table groups to show that tables are in the same position or in the same context.
That's how you can do the documentation for azimuth.
The last part I did not long ago is the data exploration.
Basically, before we were only on the structure, on the database model, but sometimes you want to go a bit deeper and understand the data inside the database and how it's working, what you can do.
I think this is quite interesting.
When you open the detailed sidebar for the table, you have all the details but also you have all the columns with the sample of the data inside.
This is random picked data, not just a row with everything but I avoid nulls and things like that.
You have interesting data to show here.
The same for a column, when you open the sidebar for a column, you have the most used value, the count of rows, the cardinalities, the number of nulls and things like that to know a bit.
What is inside this specific row?
That's for the quick access but you can also do some full query from it.
We have a visual editor for very simple query, like a table with some filter, but also you can write any query you want to have the result.
Basically, you have all the results on the right in a list so you can see different results and have some nice features to filter, to sort and things like that.
The most interesting one is this small arrow here.
You can click on it and see the relative row on this part.
Here, I selected all the events, like on the CFP database, we have the event but they are linked to a group here.
You can see in one click that it's the human talkspire group which is the link row on this event.
This also works in a nested way so if you scroll down and see other relations in this sidebar, you can have multiple sidebars that are stacking to navigate from one row to another.
Basically, this was quite interesting but the very nice thing here is you can add this specific row, so one row and data from a table into the diagram.
You can add to the layout and see this row specifically so this is not a table anymore, this is a row of data with of course the table name and the table column, but also with specific data for a specific row.
You can refresh the query again but with all the data.
Same as the layout, you can navigate through the row inside the data.
If you click on the primary queue again, you will have all the linked tables and for the table, all the linked rows, with a maximum of 20, because sometimes it can be very expensive, for example, event or if you have some tracking things, you can have thousands of them.
Basically, you can see easily what are the linked row, what are the incoming links to this specific row and not just the table in the schema.
And then if you click of course on a specific one, you can show it.
And the same is for foreign key, so if you click on an outgoing relation, you can just show the relation with it.
This allows to do some nice diagram with not only the table in the schema but also actual data from your database that sometimes is interesting to show that you have several rows in the same table like here.
And of course you can mix both having on your layout, having your schema, so the table above and the table below.
So this is very small, it's not intended to read, but on the right you can see there is several times the same different row on the same table, on a clear blue.
So I think that's a very interesting way to navigate into the data.
So if you want to try it out, so it's available on azimuth.app, but there is also a nice CLI to load any database almost here, so you can just do NPX azimuth explore and then your database URL.
It can be of course a remote URL but also a local one, you will start to get away on your machine which is just a node server to proxy the query to your database.
So it also works with local database which is like I think the one of the only tools that I can do that.
So thanks a lot, you can try it on azimuth.app, it currently works with several database, so major relational database but also some document database.
And basically for relational database when you have a json field, a json column, it inspects the json column selecting 100 non-empty row and infers the schema from it so you see directly the schema of your json column inside azimuth.
So this project is fully open source, I've been working on it for a bit more than two years and basically I intend to develop it a lot more in 2024, so if you are interested with it, there is a survey with a QR code and I will be happy to have your feedback on what you thought about what I presented but also what are your current problems about the database,
what you expect to see from a tool helping you interact with the database and so on.
Thank you all, there is still two minutes so maybe I can run one or two questions.
Is there any supplementation when you explore a state or really state database?
Yeah, there is several things, so it's made for big database, so basically the table is 100 tables and the biggest schema I think is 1000 tables, 1,500 tables, so there is no issue extracting the schema.
There is more issue and basically that thing I will address soon.
When you explore that, basically if you have a lot of data inside your database, the quick show of the value into the table and the column can be quite hard to get, but after that you just run some queries.
So you will have performance issue if you do queries that take a lot of data but the queries run on your database are not linked to azimuth.
