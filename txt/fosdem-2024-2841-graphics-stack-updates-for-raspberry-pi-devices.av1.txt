So, as I said, thank you to attend this talk about the
acceptance update of the graphics stack in the Raspberry Pi device.
Thanks also to the organizers of the 4 of them and especially to the people
organizing this DAPLOO.
Which is great.
So, let me introduce ourselves.
My name is Juan and with me is my colleague,
Czema Kacenova.
We work in the Alia and the graphics team and we are working on the Raspberry Pi graphics
stack.
So, what is it to come out?
It's basically cover the change that happened in the graphics stack since the release of
Raspberry Pi OS Bullseye Edition was in November 2021.
Up to the latest version, which is Boogworm.
It was released several months ago in October 2023.
So, I mean, this is for people that are not used to with, primarily with MISA.
We have like five devices, Raspberry Pi devices, well, there are more, but are like variations
of those devices.
The Raspberry Pi 1, 2, and 3 use the GPU from Brathcom.
It's called VideoCore 4.
And the name of the MISA driver is called VC4.
And then for the Raspberry Pi 4 and 5, they use the VideoCore 6 and 7.
And the name of the driver changes like V3D for the OpenGLES.
In this case, they are support for the Vulkan driver, which is called V3DV.
So, what things happened?
Well, probably the most exciting one is the release of the Raspberry Pi 5.
This is evolution of the GPU from Raspberry Pi 4.
It's an architecture, but with more benefits, how it really means like.
It has like a higher clock rate, so it's faster.
It supports up to eight render types.
It has better support for subgroups operations, which is interesting for Vulkan.
And that provides a lot of changes at the institutional level, so it allows to have more compact shaders
which run faster.
Drawback is that it has a bit of less register, so it suffers a bit of more pressure.
And this is the support.
It's integrated with V3DV-divis, and it was submitted for review almost the same day the Raspberry Pi 4 was announced.
And now it's released in MSI 23.3, and that's in the current 6.8, which is required.
As I said, this is more or less the evolution of the GPU, so the GPU front has the Raspberry Pi 4.
So nowadays the features are more or less the same in terms of the driver implementation.
So it supports the OpenGL ES 3.1 and Vulkan 1.2, and that supports a non-conformant version of OpenGL 3.1.
We will see that at this moment.
So from the point of view of the drivers in the MSI, the OpenGL driver, well, one of the important things was that
we promote from OpenGL 2.1 to OpenGL 3.1 with some caveats, I'll explain later.
I think this is quite important because at the end the Raspberry Pi is intended to be used as a desktop PC in most cases.
So targeting the OpenGL desktop apps is quite interesting.
So there are some applications that require OpenGL 3.0 something, and now they come on the Raspberry Pi.
The upgrade from Bullside to Google allow us to expose 35 new extensions from OpenGL, OpenGL and OpenGL ES.
And I was saying before, the driver is not fully compliant of 3.1 because there are some missing features in the hardware.
For instance, this version requires 8 radio turrets. This is fixed in Raspberry Pi 5 but not in Raspberry Pi 4.
It doesn't support 4.
And then the hardware itself does seamless QMAP filtering, and the OpenGL spec requires no seamless.
And then some other formats that are not supported.
But all in all, probably these are not the most easy features.
So we support anything else.
So from a practical point of view, probably any application that uses OpenGL 3.1 will work in the Raspberry Pi.
Then in the Vulkan driver, we move from Vulkan 1.0 to 1.2.
So this is Vulkan 1.0, 1.1, and then 1.2, which meant exposing like 80 new extensions.
It will compare both versions of the driver from Bullside to Vulkan.
So there are a lot of new extensions.
Some, I mean, I mentioned like extension dealing with sub-drops, as I said, which is very interesting for Vulkan.
Extension dealing with geometry shaders.
But I think the probably the most important work done was improving the performance.
So when Vulkan 1.0 was released, the target was just having a performance driver.
So we didn't spend any time on making it fast.
And during this lifetime, we were working a lot on making it more performant,
specifically in the shader compiler to reduce the liminal analysis and make strategies to make the shader smaller and faster.
The good part is that the shader compiler for the Vulkan driver is actually shared with the OpenGL.
So both the OpenGL and Vulkan share the same compiler.
So all the improvements in the driver in the shader compiler also affect the OpenGL.
So basically the improvements are both for Vulkan and for OpenGL driver.
Another thing relevant to mention is that now Think, which is the driver that supports OpenGL over Vulkan,
works with the V3D driver.
So it means that you can use the Think to open up the applications.
And then that's how we, well, we know Roman Stratenko was working on that in support for Android.
So now you can run Android in Raspberry Pi 4 with the Vulkan driver.
And now my colleague will continue with the workbook in the kernel.
Okay, Sam.
Well, continuing with our work on Vulkan on the Raspberry Pi,
we need to implement several features that were not available in the hardware.
We need to create what we call CPU jobs.
That is part of the behavior that is not available in the hardware support for the GPU.
So we implemented that in the Vulkan driver in the user space.
But that implied, that was affecting mainly to some queries about performance counters,
time-stun queries, and compute-shaded in this patch.
So this caused issues because when we were submitting the different command buffers to the GPU,
we need to start the driver of the GPU submissions, do the work in the user space,
and then continue after having the result.
So one of the improvements that we have just recently landed upstream in the kernel
was these kernel CPU jobs.
So we moved this operation that are already known to the kernel space.
So when we are creating in the Mesa driver the submission,
we are currently going to handle that so we don't stop the submission of GPU jobs.
That was quite an interesting improvement in terms of performance.
Because before this, there were a lot of stalls in the submission.
Another feature that was quite interesting for the users at the end
was to know if they were just really the GPU when they were running the different applications.
It would happen for a lot of developers.
I don't know if this is really working with the GPU.
So we implemented GPU stats.
We suppose these users' stats per process using the standard way of doing it in DRM.
And we also suppose global stats.
So this way some application just, if you want to know the global status of the GPU,
just check that the value of the percentage of usage.
Because in other case, you need to go to every process,
check each process which amount of GPU has been used, and do the complete sum up.
So because of using the standard interfaces, we can run application like GPU top.
That is really nice because it works for several drivers.
And at the end for the global stats, as we, there is no, no a common defined interface to expose that.
We are currently using a CFS.
So the hardware lacks some features to provide the stats as other drivers are using,
in the case for something in Intel.
So we are, we go to a simple approach.
It is just, we put in the DRM schedule, when we submit a job to the GPU,
we just get the time stop and the job ends, we get the finished time.
As we are only processing one job on each queue, we have the information about how much the GPU was used.
So we can show here, for example, it's on the top right of the, there is a graph with a widget that the users can check
and the GPU users.
And in the task manager, we already have the information about the GPU users.
For example, in this screen, the main user of the GPU is Chromium,
and the second one is the compositor, in our case it's Wayfire,
because it's compositing all the different windows and surface that we already have there available.
So, well, that's the highlights of the modifications from the kernel.
And one of the main important changes that we did from Bullside to Bookrow Raspberry Pi OS was the change from the default desktop.
Previously, in Bullside, we were running for the Raspberry Pi 4 devices,
matter with Xserver, and it was being OK.
And for the previous generation hardware, Raspberry Pi 1, 2 and 3, we were running the previous desktop we had,
that it was an open-boss with Xserver.
Matter was too heavy for the generation of hardware.
And when we have this release of Bookrow,
now all the Raspberry Pi's that we started, the public e-mails,
they get a Wayland desktop using Wayfire.
That was, and for Raspberry Pi 5, it was just a digital, it's the default one.
For previous generation, we still maintained the open-box and Xserver,
but I want to commend on this, now this is the last part of the talk.
So, well, Wayfire is using OpenGL for doing the composition.
It's based on WLroute's backend.
We use the OpenGL, but it's quite tight for OpenGL.
So, all the plugins are implemented there using the OpenGL API.
One of the most important things we did in this transition from Bullside to Bookrow
was that the user's experience don't change a lot.
So, as we can see, Simon Long from the Raspberry Pi has a lot of effort here.
So, it's difficult if you don't see the change of the background
to figure out what are the differences between the previous version and the new one.
That is Bullside and this is Bookrow running.
So, all has been rewritten, the panel, the theme, because there are different compositors.
And, well, now we go to the desktop on the previous generations of hardware.
Well, we are still using the Xserver with Openbox.
It's the file, the file we have.
This has been the same way since Bullside, we didn't try to see it in two matters.
The main cause of still using this is that we need to use sober composition.
We use the CPU to render the desktop because the hardware limitations are supposed to have a memory limit
that is 256 megabytes by default.
The problem is that we don't have control when the GPU memory that is using the CMA, Continuous Memory Allocator, runs out.
So, at the moment, we'll answer a new Chromium Brows tab that uses CMA memory.
If we run out of the memory, next application that can do the following allocation could be the Xserver
and it can crash or the compositor.
So, the solution it has been there during all the time is on these devices, all we are using is CPU sober composition.
So, GLAMOR has been off all the time and there is no hardware support.
You can run a full screen application.
All has been, you can enable it, but it's not the default.
You can enable GLAMOR and you get hardware acceleration.
But you are supposed to crash in your desktop at any moment.
And there are a lot of hungry applications like the browser that can kill you if you open six tabs, you are completely frozen the desktop.
So, during the previous development cycle on both sides, we wanted to make the possibility of enabling the hardware accelerated applications.
So, if you want to launch your GLX-DRS, the GLX-DRS is not using a low beam pipe and it's using the driver for the hardware.
So, we managed to do that.
We enabled the hardware acceleration on the four applications while we were still doing sober composition for the rest of the desktop.
So, in case you run out of memory, what is going to crash is just application.
You are not supposed to the Xserver crashing or matter crashing or whatever application because they are not prepared for when you do a memory location, it fails.
We assume that all the time it has been working.
This was implemented modifying the mod-setting driving index server.
We implemented the support for DRI-3 in this case, but without the need of using Glamour.
How it is currently written is just Glamour enables the DRI-3.
So, on crash-by-devices, we can use DRI-3.
Even we don't have open GL during the composition of the general browser.
There is a request for the server, but there is now too much interest in integrating that.
We understand because Xserver development is stopped at the end.
But we have been using that downstream for almost a year.
It was a huge improvement for the users.
With these changes, we avoid the problem of the GPU memory subsystem.
When we were about to release Book World, the idea is that we are transitioning to Wayfire as the stock compositor.
What can we do for the older generation devices?
We need to rethink again how we solved the previous problems with Xserver, now with Wayfire.
We need to do the software rendering composition using the CPU.
We would like to allow again hardware-obscleted applications.
The problem with using Wayfire to do the software composition is that Wayfire is quite tight to use OpenGL.
It is using WR-ROOT's backend.
As you have seen in parts of the code, mainly in the plugins, doing the different effects,
we are doing calls to OpenGL API.
We don't want to do that.
The first thing is WR-ROOT already has a Pismand backend that is working.
You can just transition and the parts of WR-ROOT that are using Wayfire,
just do small changes to use the Pismand backend and it works.
The next part is we need to reimplement all the parts that were tied to OpenGL in the different plugins
that we are going to use in the distribution.
There are some that are quite complex that we didn't need, so we didn't implement the change,
to use the Pismand rendering logic.
This way we managed to get all the rendering done by Wayfire to be done using CPU rendering.
The problem is that if you do that and you start doing blending operations,
in architecture they become really slow.
Reading from the even buffer when they are doing the blending, assuming that we have synchronous memory,
all the changes are flashing at the moment, it is terrible.
We experimented with enabling for the buffers, we used for doing the run buffers,
to use non-coherent memory.
That makes that if you write on the CPU and then you put it on the display,
maybe there is not coherency.
So you start needing to flash in some places, you need to handle that.
Some things happen funny because in 32 bits, IRM is different to 64 bits.
Things that work in one place, in 32 bits you can just, I'm going to flash the memory before putting it on the display,
and it works. In 62 bits, it doesn't work.
At the end the flash is not doing anything in architecture.
So we need to handle the synchronization but in the compositor to do that work.
The difference of that change is that everything runs fast enough.
The problem is that when you enable non-coherent buffers, you only want to do that for the compositor,
but not the rest of the application.
So that is complex because some applications don't work on the core and buffers
and we are dealing with that, maybe enabling it with a parameter,
creating a new IOCTL for the getting non-coherent buffers or what.
So well, and for the other part, that was quite fast as we already know,
the part about getting hardware-assisted applications because we already have the knowledge of doing this on the X-server,
so at the end we need to handle in WOL routes to pass in the pieceband backend,
to pass modifiers with the memory buffers, and it was already working.
So I'm going to show this is the current working progress we have with this work.
This is our Raspberry Pi 3 running the desktop.
It's using the non-coherent buffers.
In other case, you will see how the programs are moving.
The performance is quite good.
Some of the more complex things that are most expensive is the shadow calculation.
You cannot imagine doing this in the CPU.
Every time you scale a window, it's complex.
We are seeing that these DLX-servers are using the hardware acceleration
and it's not the best thing that we can do because there are possibilities of having another different plane
to show that there is no display, but we are bleeding this by the compositor.
We have enough time, I think.
So we are going to see several plugins working.
So as a conclusion, we are on the point of maybe thinking about putting this for the users,
but it's still not ready.
One of the things that Raspberry Pi devices have is trying to maintain all the generation of hardware
because you can run the last Raspberry Pi OS with the Raspberry Pi 1 and it will work.
We have already tested it with the Raspberry Pi 1 that has slower memory.
Juan was doing that this and was good enough.
It's comparable with the results we are having with the X-server.
We are seeing Chrome running, that is using hardware acceleration.
The good thing is that as we are not spending memory of the CPU, we can run more applications.
But you can crash Chrome in just open, I think it's eight apps.
You will crash Chrome in, but only in some cases, only one window.
This is the Zoom working, this is all software composition.
And I think that's all from us.
We already implemented, this is the switcher that has Wi-Fi by default,
we implemented with Pisman and we tried to do a more simple option,
but this one was already working fine at the end.
So we are maintaining the most complex part is doing the transparency and using the alpha channels in software.
So, question, I think we are on time.
What features do you need the CPU to actually get into the job?
And are they used a lot, the applications need them, will that impact the performance?
Well, our colleague, Mayra Canal, has a lot of positive planning in this and they are really out.
The question is, which features in particular are needed to be done in the CPU and cannot be done in the GPU?
I think I already commented, there are some things related to performance counters,
mainly if you want, when you are running the CPU commands, to reset the counters.
These need to be done in the GPU.
No, you need to write in a resistor in particular.
The other one is related to getting the time stamp, because there is no support to get the time stamp from the GPU.
And the other one is indirect computer shader dispatch.
Is that when you are sending several instances of a computer shader,
in this case you need to send in the CPU one by one, because there is no support in the GPU.
So you just submit the buffer to the kernel and the kernel is going to handle that.
In the other case you were in the user space, you send one, wait, and you are going to send one by one.
So, well, time's up.
Thank you very much for your attendance.
you
