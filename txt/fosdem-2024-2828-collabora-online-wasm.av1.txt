Thank you for joining us for the next talk.
The next talk will be about Collaboration Online Web Assembly and it's going to be with
Kaelan and Thorsten.
Okay, I hope you can hear me.
I can hear myself.
So Collaboration Online, I wasn't myself, Kaelan, Mechmeyer and Thorsten Burns and we'll
just get on with it.
Collaboration Online Typical Overview.
What we have is a...
I can shout louder but again it's meant to be amplified.
Collaboration Online Typical Overview, the idea here is that you have a browser, you
have a JavaScript front-end, the JavaScript front-end communicates back to a server, the
back-end server is a classic C++, compiled to native code, there's a web server daemon
that basically manages a whole set of kit instances.
And obviously, crucially with all these things, if there's no server, then it doesn't work
because the browser talks to the server, if you lose connectivity or connection to the
server then your browser has nothing to communicate with and nothing works at all.
Each kit instance that I mentioned there is basically LibreOffice, it links to LibreOffice
Core, it's big, the combined shared libraries on my local copy of those is 320 megs.
So you've got a very, very large core body of code from LibreOffice that is included
and linked to by each kit instance.
Each instance is one document so when you connect to Collaboration Online, each document
is running separately and each individual document is its own instance.
When you've got multiple users, it's still one document, if you connect to one document,
if you've got one user, three documents, you've got three instances.
And then the server mediates between your browser and powers things to each client.
Client renders images and you send back these pictures back to your JavaScript client.
LibreOffice itself, core part of it is pretty portable.
We've ported it to all these operating systems here, Linux, Windows, Mac, IOS, etc.
On the core side we have the famous bridge which is particularly specific to the ABI
of your architecture.
But we have ported it to all these architectures and all these different ABI's in the past.
So there's plenty of experience and plenty of examples of being ported to very, very,
very diverse sets of things at a particularly low level.
More online itself then, pretty much doesn't have the issue of requiring this low level
bridge so its portability is fundamentally easier on that side even though then it is
going to use Linux-based APIs.
So again, two things that are relatively portable in their own sense.
Which brings web assembly in.
Yeah, that's my cue I guess.
So who in this room has not heard about web assembly?
Okay, so great.
So this slide is for you.
In all brevity.
So web assembly, well the idea behind web assembly is to have something that runs in the same
sandbox as Java but is much closer to the actual machine level abstraction that languages
like C and C++ are having.
The vast, like this massive amount of software out there already in those languages to be
able, which is smart move to run this in the world.
The history of that is the SMJS like started 2011, 2012 or something with SMJS also just
a Google PNACL project.
So that started with a subset of the Java script so that is able then to be run relatively
performant like almost like native performance in the browser.
That passed forward a few years, 2015, web assembly became a standard, started implementation
in the browser like with the W3C.
The M script project, big queue those by the way to M script for enabling that based on
LLVM framework to compile C and increasing the C++ and the more complex features down
to web assembly.
Yeah, so small as to some footnote there, some website security policy is still required
to run that because of the way of actually running in the same sandbox.
It's using the shared array for actually having the memory and also the code down.
If you look at the roadmap and the browser support then you realize this thing has arrived.
It's pretty ubiquitous.
Not all the features are there, some features are beta or just in the process of being standardized.
But regardless of where you are mobile or desktop or anywhere like even this Node.js
and Vazi like on a server has excellent web assembly support right now.
That's the roadmap there.
With any decent browser you have at least a subset of that which is good enough.
Which gets me to what does it have to do with the LibreOffice here.
So in 2015 we had a first look at that because it's kind of obvious to say well LibreOffice
is so portable why not port it natively to the browser.
And we utterly failed back in the day.
It was just the way that the C++ support that was available in MScript was just not enough.
I mean there was essentially no decent support for exceptions.
There was a lot of problems with the threading.
So we tried again in 2021 and we're very grateful to in particular NLNet but also to Collauer
and my company for funding that.
And we started again and long story short we succeeded to port that.
It was quite a ride.
It took more than a year.
But given the fact that LibreOffice was already very portable, the build system was already there.
MScript was already there.
A lot of the building blocks were there.
Qt which we use for the GUI thing that you see there in the screenshot had already been
ported.
So lots of those bits and pieces were falling into place.
Some of them actually while we did the port.
We were actually still quite lucky that in the end we were successful.
So yeah and why did we evaluate that after this initial failure?
Because things like AutoCAD and Unreal Engine and all those projects had already ported
so we were reasonably confident that we were still hitting those nasty roadblocks.
LibreOffice has this habit of breaking everything because it's so large and so did we.
So for example at some stage we wanted to link and it took like almost 100 gigabytes
and took two hours just to link the thing which kind of sucked and then a few months later
MScript and Upstream fixed that and we were happy again.
So that's the story of that port and with that I guess back to Quailin.
Indeed.
So yes so now you have LibreOffice's Wasm port.
So what do we do then for clabber online offline?
Ah so clabber online Wasm so Co-Wasm.
So we took all that we do now in that case in the previous diagram you have your server
running on the distant far away server, physical server and now in this case we bring the clabber
online server side and we run it inside the browser.
So you've got exactly the same javascript front end, the javascript front end communicates
in the server but the server is actually the original stuff converted by inscription
to WebAssembly and running inside the browser.
So your server is inside the browser, you have the same architecture but you're only
running one document in this particular case all inside the browser.
So again the core stuff that Thorsten mentioned and then also port and start out online to
Wasm as well.
When you're sitting in front of your browser and you click this particular offline button
as it is currently at the moment you manually ask to be put into the mode you redirect it
to a page that gives you the Wasm that downloads the Wasm for you and if you get that just
right you can get the Wasm into size to a particular size and location that it's a one
time download.
So the next time you go into it it's a particularly quick process.
You give it a copy of the document and then it executes inside your browser and your javascript
server, javascript client communicates in the server like it normally does.
Thorsten mentioned it and kind of mentioned there is a security policy.
Whether that becomes really, really problematic because you don't tend to just run clabber
online and then of course it's launched from Lex cloud and it integrates back to get its
documents from that or any of the other examples.
So there's an intricate dense of multiple web applications and multiple web servers
and then because of this particular specter flaw the browsers are incredibly paranoid
about letting you run Wasm and it's really difficult to allow you to run Wasm and get
multiple places working together.
So all the links will give some of the documentation on that but it seems to be down to is that
the thing that you're embedding into and the thing being embedded both have to agree that
they're happy with being mixed together so that one isn't being tricked into being embedded
and the other and the other isn't being tricked into embedding something that had no intention
of running in the same browser as it.
So thanks next loud, thanks to Julius Hartel there particularly for helping us get a bootstrapped
up so we can get next clouds which document to provide the appropriate security headers
to at least get the first step started and there's a particular pull request there that
took us ages to get sorted out.
You have to get your initial instigating website to give you the headers then on your side
and the clabber online side you have to get matching headers and say that you're happy
but you've been put inside of that then you have to get it only really will work if you
have clabber online in reverse proxy mode so that all appears from the same server from
the browser perspective.
That works for Firefox just like that but for Chrome it has to be SSL it won't let you
do it if you don't have HPPS.
We found out we experimentally applied it that a lot of our own websites pull our logos
from a third website and again that third website isn't happy to be included within
this process then the logos are broken so in the end then you come up with basically
that if you have Wasm enabled we set up some capabilities saying Wasm is in line and then
we put all this cascade of headers or it becomes conditional on wanting to support.
There's a lot of practicalities as well I mean when it actually runs in your browser
things are pretty good or pretty slick I believe but actually building it in person talks about
the 100 gigs now if it's improved now you only need 25 gigs of memory to link it so
that's pretty challenging when you're unaware of what's going wrong there.
Cross-compiling is always a little bit fraught in my particular case I've used the tool
chain that I've had pushing together your own tool chain is painful so you have to invest
time in that.
Threading is a little bit unclear to me what's going on there we're using in scripting and
then we have the standard C++ API talking about threading and if my particular machine
I inquire how many threads I have it will tell me 20 which is the actual number of hardware
threads I have but then when you actually go and run things with threads inside the
Wasm you find that it seems to have a practical limit of four so you've got a mismatch there
between what two APIs are telling you one of which is telling you 20 threads and another
one is limiting it to four.
It's lying it's four so that's hard to compile.
So you run into problems there you have to watch out for it you have to just limit things
down to your four threads and dismiss or ignore what some of the other APIs are saying.
This particular one is incomplete you manually decide that you want to go into offline mode
and it works beautifully but that's not particularly useful perhaps in the real world because you
can't go back online so once your document is inside the browser it's inside the browser
and it's not going to be migrated back to online when you're connecting with stores
but it does work.
I'll just show a little video and though I actually do have it working locally but trust
me on that one.
So this is your online as usual just about just to just do the two of them and just knock
the network down and then I just hit Firefox's offline as well just to get quickly to the
servers being disconnected you know type type type.
No effort obviously it's going to work because we're not connected to anything.
Back online we go back to reload this I believe and we should flip over to the view file and
go offline as the magic button click click click.
Wappy downloads start instantiating comes back up with a copy of the document.
Drop our connectivity again go back speed up the process here and we should be able to
interact with the document as it runs inside the browser to its jailed for whatever its
slave copy of Clabber Online executing Wappy.
It looks exactly the same even because you know it's non-trivial that it looks exactly
the same but it does it's interactive you can move around with it and it works fine.
Can't save back the abouts as well as it doesn't prove anything but that is the case.
I think I have just got one last slide just to say that is the end of.
Thank you.
Not sure.
I think we're doing good on time so any questions or anything.
Otherwise I think I could.
So I didn't fully understand does it save the document somehow inside the browser but
you cannot get it out from there or can you save it somehow there inside it.
Once it's in the browser you could manually use save as a download as it's not you can
do that but what you can't do is just click another button that says go right right now
you can't do it it's not like there's some fundamental problem it's just not done yet.
Save as and process continue editing with your local copy of the office on the laptop
and then upload it again online or something like this.
Yeah.
Thanks for talk.
I can imagine that the idea on switching from online to offline is that you will be able
to switch freely between online and offline.
What is there the idea or the plan or the challenges you might find to switch easily
back to online for instance when your internet drops out and it comes back.
Well it's just a matter I suppose of some of the practicalities of I don't think there's
anything fundamental I think it's just probably a matter of time to be let investigate the
problem a bit further but if you've taken it offline you're just going to have a little
practicality when you come back online if somebody else has opened up the document in
the meantime you just come back to the classic problems of just file locking it you know do
you go offline you just I mean that's what I would do I just say you know it's locked
you know can't can't write back to it till it comes back online whatever it was just
file locking but there's nothing nothing new or unusual about that.
This is the this is the live version of the Weisman case and we once too I don't know
look under the hood and make sure I'm not doing on that online.
So let's have another question.
I would say there are three people working on the document online and then one is dropping
off continues to add comments and what is your strategy of catching up with the changes
that have been carried out online in the meanwhile.
It's probably the same the same issue again like yeah what are we going to do about that
I mean to be decided I guess is the answer there but I don't think there's anything fundamental
with that I mean it's the same as if you were back in the case where you have your shared
network and you've shared a document and you had your classic clients and they open it
up and it's locked by another user or whatever you just have to decide what strategy you
want to imply there so yeah an open question really.
So first amazing work it's really incredible to see this working I have a question about
memory consumption have you have you measured more in detail the memory consumptions and
are there strategies potentially to to minimize that memory consumption to like reduce it
as much as possible.
Yeah.
The second question is is there a possibility for having multiple documents open in the same
was module.
And the first one was memory consumption.
We're focused initially on this is the size of it getting the size down the physical size
down of the binary which which I guess we've done I'm happy with that memory consumption
of it itself haven't really looked massively at it I mean it's the same as memory consumption
for any of them.
I think this particular computer has just has the four six gigs of memory and there's no
particular problems with that if you have one document if you start to know if you want
to run at the same time you do an eight threaded build of Libre Office then yes you run out
of memory on this machine so it's like one or the other.
So no haven't done any particular about that we did have issues with the threading and
some of the threading of course was causing memory excessive memory usage.
So happy with that.
The other one was second question.
So in terms of memory consumption so the size that's a footprint of the binary like
compared to what you get into some very heavily JavaScript lots of advertising websites it's
not fundamentally different let's not orders of magnitude larger or anything like that so
so while it's relatively large it's not like in the same age for at least desktop browsers
as Quelin said it didn't like it didn't trigger anything but I did not measure like specifically
the so for the let's say document itself is not very very heavy but of course you need
to load the you need to load the binary into the into the sandbox there was clearly a problem
or there will be a problem if you run if you run five or six or seven or eight documents
you've got you that's very little sharing it but there's a cache possibly that chest
but the actual footprint and the browser tab that's not chat from what I can tell so so
valid point.
I think the other question was.
Yes.
To multiple documents and I think the Tarsen cover that today.
Did you answer the second question when I had multiple documents?
My question was in relation to the first to the last response could we have a cache strategy
or something to cache the code that's what I'm thinking to speed up the loading first
loading especially or multiple tabs my idea was a browser extension or something where
we could put the wasm in there and then load it as as you need it.
But I'm not sure if a browser extension allows such use cases.
I think we're happy with the caching as it is.
Yeah.
No I think the download and the caching is seems to be sorted now right the load time
isn't fabulous yet but that's just the nature of the beast.
I think we might be short on time now.
We have one question also.
Just to be clear a document is a file on the server and then it's pulled to the client
so you might as well access it over another file sharing mechanism as well like SMB or
NFS.
When you're in your classic online clabber online case the document tends to be in some
other kind of a wappy server and you get it from there and online can get it and then
it presents it as a file just as a simple file for the browser case so in this wasm
case the wasm doesn't do any direct connection back to the original wappy server so it's
the online is allowed to get the document.
Is the server file is also stored as a file or does it end up somewhere?
Well as far as far as even clabber online is concerned it just is asked to fetch the
document and is given the bytes for that document it doesn't really know where those
bytes come from in that kind of a sense so you know neither of the two really have access
to the underlying location where the files are.
That's why I look at it at least.
Thank you.
This one was a bit hard and the next cloud is pulled and so on with the link.
Yeah.
Where did I put it?
Can you repeat the questions?
He just wants to see the...
There is a long number.
Yeah I'm not entirely sure where that's gone now but the slides will be uploaded to the
place for that must be somewhere here.
Back is up this one or the next one?
This one three, three, two, three, two, six, zero.
That's just where the propagating the headers that need to be passed around the place to
get it up and running.
Thank you.
