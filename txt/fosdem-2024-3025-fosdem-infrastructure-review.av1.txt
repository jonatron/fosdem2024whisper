Okay, so for the end of the Lightning Talk Room, we have Richard Hartman and Sebastian
Schubut with the Fasdame Infrastructure Review.
Thank you and it's great to have you here for the last Lightning Talk of the day for
our traditional infrastructure review that we are giving and trying to tell you how we
are running this conference.
So let's get this started.
We were running on a quite stable platform for the last years.
We have one Cisco AZR 10,000 or 106 that we do for all the magic that happens here.
So you have some Wi-Fi connections and that our customers or our friends that are watching
the live streams right now, I hope they can see us, that it will get the live streams.
That's what we use those infrastructure for.
Most of the traffic we're generating is actually for the live streams that we're doing.
We see that in a bit, but roughly 500 megabits per second are just going out of the building
to our multiplexing service and where then the videos are spread around the globe.
We've had a handful of Cisco switches that we're trying to remove because they're getting
quite old and we replaced them with even the same age Arista ones that are a bit easier
to handle for us.
So we have the first time three new Aristas switches onsite this year, which helped us
a lot with the new setup that we planned.
We had two very old servers.
I think they were last year, they were 13 years.
This year it should be 14 years or so.
We thought about, hey, we should replace them because last year when we powered them up
after the pandemic, the battery packs were depleted and we just saw the K, maybe we should
just replace them.
We found some additional servers that we packed into our rack and then we just spun up a Proxmox
cluster there and started using the first VMs.
And yeah, currently all of the monitoring is done locally here at the infrastructure rack
that we have.
We have a lot of software, Prometheus, Loki and Grafana and it really helps us a lot.
Pain points of the last years, they've all been weeded out in the last year.
So this year it was quite smooth run of the whole network setup.
We were able to dig into problems that have come over the last year quite efficient and
didn't spend a lot of time on working on bigger problems.
We have also data for the public dashboards that we have on the internet that we send
out and just persisted on a machine that's not running here on the campus in case of the
campuses.
Not available anymore to us because we need to get rid of the rack in the room but Richie
will tell you something about the room conditions later.
So first start with the video system that we have here.
I don't know if any one of you has been running into or wanted to get into a room that said
it's full but you can still watch it as a live stream.
We have those beautiful live streaming devices that you can maybe see from the background.
There's a laptop attached and there's a camera over there and there's also a laptop attached.
And we're capturing all the video data with these video boxes that are handmade by the
FOSDOM volunteers or the FOSDOM staff guys.
And we've put that all on GitHub.
You can if you want to see it you can just download everything from GitHub and those
little boxes they sent basically all the streams to our render farm which we'll see
later and then get processed there and sent to the internet.
We have the most of the streams for the live streaming are sent to Hetzner cloud where we
have a lot of storage there where we just send all the raw data and then it's been processed,
cut into pieces and people like me can just go and edit it and say okay there was a blip
that I just want to cut out.
This is all not done here.
It's in Hetzner but for next year this will all be going to the onsite so we don't need
to push data out of the building that never should leave the building because we currently
have some processing here at the ULB some at Hetzner so we're constantly pushing data
in and out which is obviously not really great use of bandwidth.
They were using a semi-autorated review process that some folks of that might be familiar
with it.
It's called S review.
This is the thing that will move into ULB next year once our clusters are production
grade because currently we have some issues with them.
The video boxes I don't know who we have been to foster them before.
They looked like this for years and years and years and they had some minor problems.
I don't know if you can see it.
It's this device.
It's not open source and since we're an open source conference we try to replace everything
with open source components and the other problem was this LCD part.
They're not available anymore.
You can't get them there out of production.
So that's why the decision was made to get rid of them and before we had a new box we
took everything apart to just burn the ships and so we needed to move.
This was the first idea we came up with where you basically, you can see it up here, the
box, just have an HDMI grabber card that is then sent to a small device that puts it
out as a video stream and we have a network switch as well.
We found out that most of the laptops that we use here are not really compatible with
that so we had another version.
It's here which is way, way better from a compatibility view because it just puts out
as a normal, what's it called, video device for the next and we just put a standard, let
me see.
I should have this here.
USB adapter, yeah, just open it up.
That's why I brought it.
Just standard USB adapter like everyone has it in the suitcase.
It's just working and that's how the video boxes are now made.
The data and the firmware for those devices, it's known to us.
It's not yet completely available as I was being told but we should have something that's
not relying on copyrighted, protected things from Blackmagic Design that we used before.
The video setup for those who might be interested in it is quite complicated because we need
to run a lot of wires.
As you can see here, they're running the networking wires and we have all the networking infrastructure
built into those video boxes.
Our volunteers that are building up the whole conference, they get detailed instructions
on how to wire up everything.
It looks a bit messy here but you can look at those up there on GitHub, on our GitHub
repo.
We have a detailed instruction on how everything is set up, how the camera has been set up,
what to turn your switches on and how to turn the knobs because as you might know, FOSDM
is run by volunteers.
We don't do it on a daily basis so we have quite good documentation on that.
This is how video looks like from our video control center.
We have a big overview where we can actually see audio levels from the room.
So hopefully when I'm now speaking, I should be somewhere in the green area.
We see how the slides are, how the speaker is and how the final mix that's going to the
internet.
So we have that in our control room and in every building, there's a per building view
so we can instantly react on problems like the problem and that's why I chose this.
In K1105, you see that it's lighting up in orange.
There seems to be a problem with the audio.
You can see the audio is not constant and spiking and that's what's raising issues
so we can react on the video.
Video rendering, this is how it looked like 2023.
This is how our rack looked like in 2023.
Looked like spaghetti and it was spaghetti but we completely rebuilt it this year.
We emptied the whole rack.
We now have a vacuum cleaner.
A big one to suck in all of this stuff.
For how it's been running in 2024, I like to head over to Riggi Hartman.
Thank you.
So 2024 is cleaner and we forgot to put in the photo of the nice rack but maybe you saw
the mustard on already.
We can also put this into the ones we upload.
Maybe one point on the laptops.
Just on the scale, we have three laptops per room.
One is here in the rendering farm.
One is at the back with one of the video boxes and with the camera.
One is here.
This is basically how we do this.
This says for anyone who wants to copy this and maybe on the copying, part of why we talk
about this and why all of this is in Git and why we try to document it well is we want
you to copy this.
We want you to be able to run your own stuff with tested software so you can focus more
on running things and not reinventing the wheel all the time.
So the great advantage here is you have a built-in UPS.
You have a built-in mouse keyboard and display in all of those machines and there are strong
enough to basically handle all tasks these days.
So highly recommend to just split this out this way.
Yes, Kubernetes containers, whatever is nice but this just works and if it's stupid but
it works, it's not stupid.
Really highly recommend it.
Also, as you can see on the floor, I think I've been staffed for like 15 years or something
now.
We did not clean this room since and no one else did.
So finally tonight we are going to clean this for the first time.
Maybe this gives you also a little bit of an indication of what level of maturity we
reached because we are largely done with the fires.
We can actually do the optional bus night stuff.
We had massive water leakage like this box was halfway full by the time we removed it.
Turns out a lot of you breathe and we kept the doors open because it smells really bad
back there, like really really bad.
I don't know, mold or whatever but anyway the point is we tried to get the bad air out
but we let a lot of moist air in and at the end we literally had this dripping constantly.
It was not fully a stream coming down from the ceiling but it's still dripping.
Like unknown unknowns of running such a thing.
Another thing for the ones who witnessed the power outage in K while trying to debug
this, at first we had this ladder but then I just took a broom and just kept putting
the breaker back in.
While we disconnected bits and pieces, point here is yes, A this is fun but B those are
the things which you just can't plan for and you just have to deal with them and roll with
them.
It doesn't matter, get stuff done, keep the conference going.
So some stats.
As per usual, if you've seen this before, you've seen me talk about those stats repeatedly
over the years and there is some method to this.
I really just want to be honest and transparent about the good and the bad which we encounter
because sometimes it takes us longer.
This time we thought we would be quicker but we weren't.
We are doing ourselves honest in your direction as well but as you can see, we are doing pretty
good.
We were actually done with the network, second quickest ever in the history of FOSSTEM since
at least I took over that part.
So this is, yeah, the point is, I'm making a mess of this, the point is try and build
on your success because previous editions of FOSSTEM were run on throwing away everything
and reinventing the wheel every single time.
It wasted endless amounts of staff hours.
Documenting stuff for yourself and keeping stuff running where you can and actually having
automation, everything really, really will save your own bacon and you get to sleep earlier.
Other numbers, the monitoring was immediate.
We do plan to have even more stuff running under the year and basically take it out of
the box, water it and it's done.
For the 2024 redo, we had big plans when we talked 2020 about what we would do differently
in 2021.
Great.
Last year was mainly about trying to find our footing again and not just like not having
a conference as it were.
So basically all the stuff which we already wanted to do half a decade ago have become
even more pressing.
To some extent some price points shifted and such so it was even cheaper to do it but also
it just was even more work and even more lost muscle memory and everything.
Also full transparency, we thought we would be done with the server migration by now and
we are not.
We still have five servers running, not three.
Also just again like you as the visitors did not notice this and this is how it should
be.
Here if we have one or 20 servers and if 19 of them are on fire, you care about the
product which you are consuming as in the conference.
So for the ones who want to run those things yourself, always think from the user-consumer
customer or whatever perspective first, everything else comes second.
So we will clean this up over the next probably half year because we don't want to touch anything
after this.
Like we have the post-mortem two weeks and then we don't want to see each other for
half a year and then we restart.
Anyway we have massively upgraded our backbone.
As you saw earlier we have a total of three heirs just now.
Two of them are in an MC leg and give us full 10 gig between everything, like multiple
redundant.
So we can actually run a local storage array and don't have to rely on local disks anymore
which obviously means it's quite nice.
If something breaks you can actually just flip over the virtual machine or the container
and we don't need to spin up something from more or less nothing.
Also the new switches which we have, they are literally more than a decade old but it's
nice thing about it.
We don't need much more so we could just get away with buying stuff for 350 euro refurbished.
Yes 350 with SFP cages and 640 for the one with copper ports.
Those used to cost 50k each.
So I implore you if you have old stuff running around in your own lab or whatever look on
eBay or with other refurbished suppliers you can get really nice high-performance hardware
which doesn't even spin up the fence a lot so you can even run this in your own room.
It's really nice and it's just like get on eBay and get the old stuff because the old
enterprise stuff is really really good.
We have the Arista 750.
Out of support forever but it works and it's really really stable.
We got rid of spanning tree and the network is in here.
Know why we hate spanning tree.
Also for the ones who don't know what Arista does, MC leg is basically you pretend you
are a stack on layer 2.
But if you have layer 3 you act as if you had separate devices.
So you do away with all the pain of layer 2 and spanning tree and other and all the
icky stuff and you get all the power of dynamic and of static routing on layer 3 and above
while not having the massive pain of lacking introspection into a stacked halfway magic
layer 3 stack and also not having to deal with a split layer 2.
So anyone who needs some redundancy look at all the rest of us get on with MC leg.
It's going to make your life so much easier and more pleasant you can't even begin to
imagine.
Uplink we have two uplinks now.
Cold gave us a line which is fully protected so they built a ring and gave us a 10 gig
from there but even if we were to cut one of the fibers which run 2D will be premises
we would still have the full 10 gig just running in the other direction and also we have 10
gig through destiny.
There's also talks with others who might be willing to give us even more redundant upstream
so we don't have this thing in the back of our head anymore that maybe something will
break and we are going to be completely offline.
Next year we will also hopefully have a second routing instance so even if the main router
died because at the moment if I pull the plug everything is got down from your perspective.
Hopefully this is also not going to be a single point of failure next year and hopefully
it's going to be on open source and hopefully we will keep running on this new primary we'll
see.
There's plans.
Hopefully the next one the next infrastructure review can go in depth on this because this
again makes it even easier for you to replicate our conference without having to pay I don't
know low five figures for a router.
Clone our stuff.
Main one is here.
You can also find us a matrix you can send email blah blah blah the usual but use our
stuff we don't just do this and put it out for us because we feel vanity we do this so
people can copy this.
We have a few minutes for questions I might need to run at some point to the highlight
thing but I'll leave this one here if I do.
So any questions.
Just shout and I'm going to repeat.
Just shout the question.
The question was how many people are there you mean at foster.
We don't know exactly the last time we had any good guess it was above 12 K but with
privacy extensions we can't really count devices anymore so we did the thing where we counted
rooms and we saw how many people at the laptops out and how many have cell phones blah blah
and did the estimations from there but with privacy extensions we can't do this anymore
unless we started to sell tickets control the entrance whatever and we don't want to
and we can't even so way above 10 K yes yes I have this in the closing talk slides I don't
have the numbers it's it's probably hundreds or it is three figures how many exactly we
don't know how many volunteers was the question.
And on the last year's we had those video boxes that had the small display mainly those
those laptops here for displaying the information so the volunteers that are running the room
they can see like what I can tell you it's the host named the uptime if everything is
working and get a preview and that's what's all built into the old box and to the small
display which is kind of hard to read and in this case the laptop is taking over the
part of the bigger box when it comes to processing the video signal is here processed and sent
as I think is a stream to the rendering farm I don't know what kind of stream they they
chose for for intermediate I think it was mpk now H264 and what we do live streaming
and encoded there will be AV1 and H264 I think for this year's edition.
So the question was what access points do you use we use the access points that are installed
by the ULB by the university here and most of the buildings these are Cisco access points
that are hooked up to a Cisco WLC wireless line controller and some of the newer buildings
or in some buildings they have been replaced with extreme and extreme switches switches
and access points will be the way to go for ULB that's at least that's what we heard and
we use their infrastructure there are two rooms the big one Jean-Saint where we bring
our own Wi-Fi access points that are just connected to the to the backbone of the university
the Wi-Fi controller knows those and adopts them and then just uses them for the additional
amount of people that we bring in because we need more more client or higher density
there.
So the question was that on the main Wi-Fi network we are IPv6 only and how if we document
the experiences with that yes we do that for our post-mortem because there were some glitches
with we mainly we do DNS64 and NAT64 for getting you access to the old internet and we had
some some problems today I think it was packages Mozilla org that we have problems because no
today it was today as well and we're documenting these and everything that's get reported to us
we then dive into that we have one one one of our staff members that's working at Cisco he helps us
with the debugging on this side and we then checking that and also adding that to our post-mortem
to see what's wrong or what has been wrong and try to fix this for the next year like content
constant evolution that but also to be very blunt about this point the reason why we do this and
why we've been doing this for like over half a decade by now is this is an open-source conference a
lot of people who work on the Linux kernel on network management all the components are here
we want to break stuff and we don't want to plaster stuff over we want the others to fix
their stuff because now we have the actual engineers who can drive chains change through the
companies through the projects through the whatever from the ground up and this works really really well
as soon as we don't know but if you send to video at so the question was what the what the lag is
in our in our pipeline how long does it take until we have to stream out at the viewers
send email to video at foster morgue or join or just ask in the in the matrix somewhere we'll pick
it up but it might take two weeks but I think speaking in youtube terms I think we're still
allowed to to call it a live stream if you know if you mean by that it's hundreds of milliseconds
top I think you were first the question was do we have statistics how many people use ipv6 versus
ipv4 before no we don't because we due to privacy extensions we we can't know but we can tell you is
that in the early days most people were in foster do foster dual stack and these days most people
are in foster and I honestly think most of them don't even realize it's ipv6 only
so the question was if we have if we are planning to change the dual stack name to legacy next year
no we had this initially so when I made the whole change and everything I named the I named
I named them foster and foster legacy and I switched this over after like three or four years because
a the technically precise and correct term is dual stack and b there is no huge use in
shaming people for something and also we had some issues with people not using it because they
thought it might be 2.4g and like all kinds of weird stuff but in the end there is no use in
shaming people for this if people use foster as the main thing and most do perfect and they're
going to fix stuff as they go hopefully okay I need to leave to our next thing but I'm going to leave
foster here thank you see you so I'm happy to take any more questions if you just leave leave quietly
yeah please
say so the question is what would I tell folks that are organizing conferences like this but
using proprietary software I would just show them how we run it and what our learnings are from that
and how we engage with the community for example for next year with with the routing thing we've
we've been I don't know who of you has been to the networking dev room they're amazing guys there
and we talked about them how can we replace this routing engine hardware routing engine can we do
something in in in software and yes there is a solution that we found here with the colleagues
and maybe we can show them how they if this is some sort of conference where where it's about
programming or or networking or whatever maybe we can show them yes that can be done all open
source and you get the features that you don't have yet you might get them when you just talk to
the people and and encourage them to work with you yeah yes they're up there
so if I understood it correctly is what's the use for the servers that we have and what is running
there or so I can tell you what's currently running there this is mostly the monitoring
stuff that we do monitoring alerting we have some sort of storage there that we just can have backup
of the the data that that is produced from the laptops here we do the dns 64 things in software
on those machines and these are the main use cases and also hosting our dns infrastructure from here
where we can then just push out our dns the author name service for the conference are in this room
and this is basically the the services that the service need to need to do things like dhcp for
printers yes we have printers and for the payment terminals and things like that this is the the
sort of traffic order what they need to do when they on those machines hope that answers a question
okay
so yes you again
okay
it's a bit it's a bit low on the audio level I can maybe we can just walk here and then I can
understand your your question yeah okay that's fine
yes
or
okay so the question is that we tear down stuff over the year or after the the conference and
what's staying at the ulb and whatnot and everything that's inside the rooms that are not the room
where the server is sitting will be removed from from the from the from the buildings and the service
will be kept there the routers will be kept there one of the switches that you saw earlier on one
of the slides they he will be removed as well but he would just goes to the to the to the the rack
because we have this switch we need to clean up the the the rendering farm and then this
switch will just be moved to the rack where it's sitting without power and but the rest will stay
here over the year currently
the years before we hadn't that that big team that could take care of that stuff over the years and
I've just been taking that over last year and from what I've heard and what I what others told me that
this wreck wasn't there permanently we just had it since six years or so and since then we can
actually host stuff through the year here and the years before they were just piling it up in the
room and and building building a tower of hardware and then just taking it back after the conference
and since we have this wreck and it's also it has locks so we can just lock it and no one can can
to crazy stuff with it since then we are trying to to have it sitting here
running it most of the time most of the stuff will be turned off to to it's not necessary to have
all the servers running and waste energy so the plan is also for the next year is to keep it like
that remove the two servers to save some energy and just have it here and what has been done before
like ripping it out and building it from scratch this is one of the things that we don't want to
do anymore because we have a stable setup now and it's working yeah thanks thanks okay for everyone
who's leaving the room I think we can start you can take the cables with you or can we start tearing
it down or that work excellent okay okay
there will be some more talks in the Jean Saint building like the closing talk if you want to go
just down the hallway and there's a secret passage at the end of the hallway we just turn right on
the last door and then you're in Chanson enjoy foster
