Okay, great thing everyone. Thanks to come to discover linto. linto is your ultimate
open source AI driven media management solution. So I'm Damien Lenn. I'm head of R&D engineering
here for linto at Lina Gora and I'm proud. So what is linto? Essentially linto is a set
of voice technologies that enables you the best on the open source side of voice tech.
You can find in linto all the cognitive APIs that you are craving about like transcription
with a live or batch transcription. We have a set of NLP APIs that enables you to add
punctuation, name entities and topics identification or so on. And also we worked on speech synthesis.
This is the first set of linto technologies. Leveraging those technologies we built a
full-figured surrogate, I mean alternative to Alexa and Dialogflow to build agents, smart agents
which includes chatbots, smart assistants, voicebots with custom full software work walls that work
on the browser that's very neat. And finally we the past two years leveraging further our
technologies we built a business oriented solution which is called linto app which is a media
management platform that enables you to load media and to make to run these cognitive APIs
to edit the transcription in a nutshell to turn routine recording into fully qualified data lake.
So there's a lot of software's closed source that enables you the same kind of features but more or
less all of them uses the APIs from the big players you know them. Okay so the question
here is always the same what happens to my data when I use the services provided by author,
dictation, happy scribe and so on. In a nutshell you just send your data to them.
So linto studio I will present you a quick video to show you the platform but here you
have all the functionalities and note the link which is currently displayed you will find the link
to immediately just use our alpha version which is online free you can just create your account
and try yourself just after the meeting and you will find the link to our github pages to download
and work with the source code. So linto studio enables you to use the APIs I've been talking about
to add automatic stamp with our modified run times for whisper.ai not a whisper by openai.
We are so enabled to speakers and turn identification and all I've been talking about
before just note that the platform is a web platform where you can collaborate in real time using
organization roles and share resources within the platform. It's shipped with companion
Android application that you can use to to recall. The final slide before I move to the quick video
of course as my colleagues presented you a work on the large language models of course we want to
also leverage these technologies within linto studio and add this kind of feature I'm drafting
here on the picture to work with the documents loaded into the platform and ask some things with
large language models. Okay so here I jump to the video. Okay so I recorded this yesterday. Here
on the left I'm currently recording something within the sorry so I'm recording with live
transcription. Okay whenever I'm done I just stop I can navigate local files and listen back what I
recorded but what I want to do is to send this recording directly within the platform which is
of course the big window displayed on the right so I can change I can send it to the platform
I choose the language the model I want to use then the media I uploaded just lands into the
platform and here I can see that the transcription here includes the capitalization and normalization
I can also explore the platform as I tell you media management solution so it's a multi-user
platform we where everyone can create accounts and use roles within organization so here I just
showcase the way you might invite users and assign roles within a given organization here I show the
share mechanisms which is total rip off from notion way of doing things and I'm proud of it it was
flawlessly I can share with external users as well send email automatically when I just share
transcription to a user okay here I jump to the editor where I can you see use AI insight which is our
NLP APIs okay you just click on the one you want to use and start generation forum identifying stuff in
your text like name entities or locations and decisions topics and put highlights you can also
manipulate the text and add manual highlights to annotate the text okay also we have another
editor which is also very neat where it's a place where you can basically just built the SRT or VTT
and you work with the screens you have the center the current screen you can arrange arrange them
the timing you can of course correct the text which enables you to add something that you want to
rip on the video directly some close captions here's the way I want to navigate within the platform
I just can use tags and fetch the document I'm looking for also using full search text and so on
and once again I get back to this recording I can show you here that I can also correct add some
correction corrections to the text change speakers which is a real-time collaboration with a
reconciliation of multi multiple users editing the text and finally as you saw we can export the
document okay that's our platform demonstrated in a nutshell I took 10 minutes for this presentation
hoping for any questions from you so if I am if you thank you for this presentation I have two
questions one of them is technical and the other one is about money I'll start with the money this
specific project how is it sustained that do you have revenue for this specific project and so what's
the business and then the second question was what kind of power of computing power do you need to
run this for a small organization maybe okay so the goal here for our business is very clear we
offer as linear go around services for tuning models okay so this particular platform is also
intended to be a SAS service where the user will be at some point when we have time to develop
a subscription for that users will be able to use our system as a SAS but the source remains
free and it can be austere on premise with the same features like away like like always at
the Nogura we have no premium plan or whatever but we just feel that it's convenient to just host
directly a solution as a SAS offer the other question was about the computing power okay so it
requires quite a lot but we batch the process of the transcriptions and the long models inferences
we just provide the best default way of doing stuff and if you dig in the code you'll see that
our runtime supports kind of everything you can dream of we can run on CPU of course it will be a
little bit clumsy we work on CPU with Intel extensions for transformers and so on and we of
course work on GPU if you want to process a large batch of transcriptions when the hosting on premises
any other questions we got time for one more how do you handle a typically French language
setting which is irony how do you handle because of the keywords and so on the typically French
set which is irony meaning that the speaker means exactly the opposite of what he says
he's asking how do you do with the irony of French language of course using the you know the
irony mark you know this one thank you Damian all right we're gonna start the next talk here in two
minutes
