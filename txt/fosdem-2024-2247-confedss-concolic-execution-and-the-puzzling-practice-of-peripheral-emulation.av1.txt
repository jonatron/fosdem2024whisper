Okay, so this talk will be a little different. That was very impressed by the other talks,
so now I feel like I have the worst one. But it will be a little different because the
problem we have is a little bit different than the problems you have seen in previous
presentations. The talk is called Confed's and Postem asked me to make a nice title,
this is what I came up with. Who am I? I am Jeffrey, Jeffrey Rungen. I work at the NFI
already for 10 years, as you can see by the loss of my hair, I'm getting old. I am the lead
scientist of the exploitation team at the NFI. Oh, sorry, we'll get to what the NFI is. My favorite
area of study is the overlap between hard and software, as we've seen the memory map
profiles and register interfaces is where I'm at. My expertise is in reverse engineering
exploitation, which requires emulation and some non-invasive hardware attacks. This is Luke,
my colleague. Oh, yes, this works. Yeah, so I'm also a member of the exploitation team. Now I did
this research at the NFI before I worked there just during my master thesis. Yeah, and that's
also how I wrote into this subject. The NFI is the Netherlands Forensic Institute, and it's a bit
weird because in other countries, if you get a case and it goes to court, the police do the
forensic investigation. In the Netherlands, that's not the case because in a weird way,
the police are considered not to be independent all of the time. So the defense should also be
able to request evidence and request research and evidence. So what we have is the Netherlands
Forensics Institute, and the police can request cases from us, but also the court itself and the
defense, of course. That makes it also a bit weird in how it's set up because it's not just a digital
lab. We have almost all the forensic principles in one building, which includes biological traces,
chemical and physical. So biological is DNA, pathology, all kinds of stuff. Chemical and
physical traces includes, for example, fiber research for clothing and other stuff, glass research,
but also explosives. And toxicology, which has the drugs, which is, well, digital and biometric
traces. This is where we come in. So we are the digital traces, but the digital and biometrics,
they thought it was handy to put them together. So we're also together in a department with,
for example, fingerprint research and other stuff. One of the weird things that comes out of this is
that we get a lot of cooperation with other departments, mostly on machinery for us, and to
make databases for all kinds of stuff. But for example, we used to use the X-ray scanner that
pathology had to examine bodies, to examine PCBs. But then the resolution was not that great. So we
got our own X-ray scanner. And they had just installed it. I was very excited to see it,
and I come in, and there's a full human head and a jar inside of it. They heard we got a new one.
Yes. And we also, I will not tell too much about this. See me after this presentation,
if you want to know more. So what do we do at the NFI, except the human head thing? We are
team exploitation, which is just a part of the digital team. And most of what we do is extracting
and decrypting evidence from digital devices. And that's a very hard thing to do, and it requires
some legal hard to place things. And that's why the NFI can only do offline methods. So of
course, when you do exploitation, you're actively might be looking for vulnerabilities, for example.
And because of that, we are not allowed to do anything outside of the building. So if we find
your Facebook or off tokens, we're not allowed to look at your vacation pictures, but we can just
give them to the police, and then they can ask permission if we find something. And the evidence
takes many forms, which is what makes this job a lot of fun for me, at least. So of course,
phones is a big one, but also USB sticks, crypto wallets, cars, everything from airplanes as well
to cranes and building sites, we've had them as well. It's a very varying job. And of course,
how do you do decryption of data if you don't have the keys or you don't have a method? You do
reverse engineering, as we've seen the iPhone talk just now. Through reverse engineering, we can
do exploitation. We use fuzzing as well to not have the manual labor. And we use various hardware
based methods, which I will not go into now, because the scale is really large. So let's get
into the technical stuff of things. How did this talk come about? Well, first, you need to know a
little bit about how we do our reverse engineering. And if we just take, for example, as a use case,
an Android boot chain, how does it work? We always start on Android with a primary boot loader,
which is the same as Secure ROM that you saw on the iPhone. It's a piece of ROM that's fused into
the chip, cannot be changed. If you find anything, that's nice for us. But the primary boot loader's
main job is to initialize the storage, for example, EMMC or UFS, and then verify, load the next
boot part from there and verify it and jump into it. The next part is called the secondary boot
loader, which does most of the rest of the hardware initialization to get the system further up and
running. And then we get into the specifics, the A boot, the Android boot loader. And the Android
boot loader just sets everything up for the kernel, in a trim of S. It has some modes, for
example, a lot of you might know fast boot. There's also an A boot that's for rescue type
operations if you destroyed something else. And A boot, again, takes the kernel, verifies it in
the boot image with the inner RD inside of it, verifies it, sets it up, jumps into it. And the
kernel boots the user LAN. In the case of Android, Xigote, doesn't have to be, Graphene doesn't use
it, I think. But from a reverse engineering standpoint, what is interesting about all these
things and is how we can reverse them and how hard that is. For example, user LAN, you have a lot
of library calls, there's a well-defined system, you know, how it works, what it does for most of
the time. So we can quite, we can reverse it quite well, I would say. Linux kernel has the same
thing, it also has a lot of known structures, which is really nice. As you also saw, I will
grab back on the iPhone talk again, you saw a lot of these structs that were already defined. We
can do that in the Linux kernel as well, because all these structs are preset and we know about them,
so we can use them to our advantage. And we have A boot, which is already a bit more proprietary.
There are some strings, some known interfaces, you know, some hardware that lives in there and how
it works. And that gives you some device registers, which gives you some context. The secondary
boot loader is getting a lot harder already, because that is very proprietary, there's not too
many strings. There's some known protocols, but for example, sometimes it will speak a sort of
debug protocol for a few, you can actually destroy the A boot boot loader, because it's on flash. If
you do that, then you're going to talk to the secondary boot loader to repair your phone. And we
know those protocols, so we can check to see what's happening. The primary boot loader, you're not
going to do it for fun, probably. I was really happy, you also said it didn't work out. It's not
nice. So let's look at some examples, because this is all text, I'm already a government employee,
so I'm boring by default. Let's look at some examples. This is a library, I hope it's a bit
visible. But you can see some library calls, for example, a fopen fcfget s. And you can see some
strings in there, and you know what these calls do, because it's post-exdefined behavior, so
that's nice. That gives you a good idea, a good overview of what it does. If you're very lucky,
of course, symbols are still in there, parse proc of s, that kind of gives you a good idea of what
it does. Then we get the kernel, it's a lot smaller, unfortunately. But you can still see some strings
that give you a good idea, because you know what a kernel does. For example, at the bottom there,
it says unexpected syscall invocation. So it might have something to do with syscall handling here.
And you can all annotate that and get further into it. Then we have a boot. It looks a bit better
than you might expect, because there's a lot of strings, for example, signature verification
failed, secure check fail. That gives you some idea, like if there's a branch in there, which there
is, that might be the signature verification. And you can work your way up from that.
Then we get the sbl. And the only thing we see here, and bear in mind that everything that says
r underscore is annotated by me, so that's not originally in there. There's just one string
there, XML packet not formed correctly, run out of room looking for tag. It gives you some idea
that it's probably XML parsing, as you can see on the top row there as well. It's looking for some
new lines, some spaces. But there's a lot less to go on here, also because as we all are not
running against a kernel or anything, there's no syscall interfaces, there's no library calls,
it's a big binary blob talking to device registers basically. And the pbl gives you
constructions like this. It's an absolute pain in the ass. There's no strings, because the way
they make pbls, they're fused onto the sock, but they're rom, so they're generated in the masking
for a chip. And the way it works when you build asics, which socks essentially are, asics go by
square area. And the more square area you use, the more, just one of the parameters, but the more
expensive they get. So they really don't like to use a lot of pbl memory. And that makes it so
that there's very little strings in there usually. And you get constructions like this, which is a
double D reference of an index in an array, which is code, which gets called with some parameters.
It's not nice. You're not going to write this usually in C code. This is probably some struct
indexing. And another thing there is as well. Pbls often from what I can see, but that's more of an
assumption that I made based on the work. They don't use normal compilers. There are some weird
constructions in there. For example, there are some constructions in there so that with one bit you
can get different code paths and patch in new stuff. And I think that is because if they make
masks for chips, once the masks are made for lithography in the factory, it's very, very expensive
to make new masks, but editing one bit in a mask is a little bit less expensive. So there's all kinds
of weird constructions in there. Now, we have normal solutions for debugging. So let's say we want
to get some dynamic stuff going. Kernels, we can emulate them and debug them using QEMU and
debugging with KGDB in QEMU, if you want. Userspace can be debugged with normal GDB. Android supports
it. There's documentation on it. And the reason I say everything before that is signed and hard to
emulate. The kernel, of course, is also signed and some parts of user run. But the kernel, you can
unlock your boot loader and you can use a reference on for that and work your way up from there. You
cannot unlock your boot loader in a way using normal processes so that you can patch a boot. So it
makes it a lot harder. It's not made to be debugged or something like that. And everything before
that. Oh, sorry. And so the state is unknown in a lot of these boot processes. You have no idea what
should be where. A lot of hardware is still being initialized. So, for example, in SBL, the MMU is
initialized. So we don't have it before that, which makes it easier, but also less easy for some
tricks in exploitation. And there's lots of memory map peripherals because, like you saw in the iPhone
talk, it's a von Neumann architecture and peripherals are 99% memory mapped if they're not on a bus. So
let's take a look at how we do some static reversing. Let's take that awful, godawful piece of code and
then PBL and see what it would do normally. So let's visualize it for a bit. So this part, just this
part, the code call, what it would do, if you look, there's a 143680 there. Let's look what should be at
that address given this code. There should be a pointer because it's dereference. So the first dereference
will go to a pointer. Then that pointer will point you to another pointer because it's a double dereference.
That pointer is a pointer, but not the pointer we want because it's an index and an array. So we take the
next one and so on until we get to the right index in the array. And there should be another pointer. And
that pointer is the actual pointer to the function that we're looking for. This is all pretty good and
reasonable. If we have some state, we can say, okay, we'll follow that pointer, we'll go here, blah, blah,
blah, blah. And then we get to the actual function that is referencing. And that function, you can make one
other assumption about it. That function will be inside the memory map and inside the PBL that you have
probably. Otherwise, it's in the SBL, but that's not loaded yet. So it has to be somewhere here because
it's code that gets executed. That is a damn shame because this is very followable. You can do this if
you know what these values are. But in real life, when you do static reversing, this is what that looks
like. You have no idea. Of course, you know that here should be a pointer. And if you're lucky, there's a
direct right to that address. And you know, okay, get set up here by this function. But then still, you
have to follow that array, which is also uninitialized. And somewhere is that actual function, but we have
no idea where at this point. So static reversing gets quite hard. And then if static reversing gets
hard, we usually grab back to dynamic reversing if we can. And there are some nice assumptions we can
make for dynamic reversing. Nothing runs before the primary boot loader. So the memory state is
either zero dot or garbage. It doesn't matter for our setup because we're never going to read anything
uninitialized, maybe. All state is set up inside the emulator. So we don't have to worry about
peripherals having a certain state already and having to account for that. And then structures
and their initialization because what you saw here is, of course, a structure. This is not something
you write by hand. Like, oh, I really want to double the reference. This is just a structure
being set up and used. And then complex logic. You can be single-stamped. And you can see the values
to have a better understanding of what it does in smaller steps. And that's often what you do in
reversing. You break a big problem up in small steps. It makes it a lot easier. So what I did was
I just cobbled together a lot of tools with some glue logic. They make an emulator. This was the
first version of this was done in an afternoon with a lot of anger. But the main thing that we used
was killing. Killing is just a framework on top of Unicorn. But it allows you to write hooks,
which Unicorn also allows you. But it also runs a GDB server, which makes a lot of stuff a lot
easier. So it's built on top of QMU, but not the current version. Long story. So killing runs a GDB
server. And this is the glue logic. So there was no logos for that. This is actually a Dutch tram
company because Redsync also doesn't have a logo. But the killing uses, we attach GDB to killing.
And then you have a tool called Redsync. It's made by Quark's lab. It's really nice. I like it a lot.
And it hooks up GDB to Gidra. And now I know what you're thinking. There's already a GDB
debugger in Gidra. And you can attach it. Yes. But not when we started this. And it was
upcoming for like a year. So we used Redsync. And then we used Gidra Bridge, which is just a
bridge in Python 3 to Gidra because I'm not going to write Python 2. It's 2023.
And the glue logic pulls in all the programming, all the memory mapping, everything from Gidra,
puts it in killing, starts execution. We attach the GDB server to killing and connect that back
to Gidra via Redsync. And then we can single-step logic and set breakpoints and everything we wish to do.
But there is still some problems in the emulation. I'm running this PowerPoint in wine,
just so you know. So I hope the animations will function well. Yes. So the memory map here,
we have DRAM at this point, fully uninitialized. It's not a problem for us at all. It's not
in the way. But it's un-initialized. It's unpowered. You can actually see the powering up of the DRAM
inside the secondary boot loader. And the offset of that DRAM is known from the DDB files. The
kernel has to know it, meaning we know it. Then we have SRAM. And SRAM is a RAM that's on the sock
that's always there. And it's used mainly for boot initialization. There are some weird use cases
for it at runtime. But it's always there and it's initialized. Only the offset is somewhat known.
We don't know all the time where it is. Sometimes it's not in one piece. It's not homogeneous. But
that doesn't matter for our purposes. It's somewhat known by reversing. And the status is known,
because at boot it's all zeros. And SRAM, we know it's all zeroed. So there is no logic in SRAM.
There's no asynchronous state. So emulating SRAM is really, really easy. It's just RAM.
Then we get to the peripherals, which are the actual problems. As we've already seen in the
previous talks, the offset is usually unknown. We know some offsets from the DDB. But there are
things like crypto engines and stuff that get initialized and that the kernel never touches,
because in Android, you have your normal world. You have your secure world with trust zone. And
the problem is that these peripherals, they have to be initialized, but the kernel doesn't know
about them. So DDB doesn't know about them. We don't know about them. So we have to kind of reverse
our way through it sometimes. The status also unknown, because there might be some state set up.
Think about the serials or MAC addresses, some stuff like that. That is a state that is known
at boot time, but not necessarily to us. And the status based on unknown logic. As we've also seen
in the previous talks, it does a read of a memory map peripheral or a write. The things that you
can see is I write one bit and then I wait for another bit to another offset. And we don't know
that logic. And it changes asynchronously from the CPU. So it might have changed at any point
in the execution and we have to deal with that. And the problem here is, and I got a little insight
from the other talks, we can emulate on an peripherals. Of course, a lot of it is stub hooking.
You saw the return 2042. A lot of that is what we did as well. Just write simple hooks. We know
you're going to read from this or return something. It doesn't matter what. And sometimes we can see
it should be a one. It's also good. But the big problem we have is that this is a tool for reverse
engineering and not so much a real fully-flagged emulator. And it needs to work on a lot of things.
So, for example, we'll be reversing a phone one day and then next time it will be a USB stick or
an SSD self-encrypting thing. And then the emulator still needs to work. So we cannot
hard-code peripherals every time. We can. It's a lot of work. And it turned out that I thought
about it too simply when I started this. I thought, how many peripherals can there be needed for a
boot? We just start with some stub hooks and then we implement some simple logic, vertical stacking.
But it turns out there's quite a lot of peripherals needed to boot the phone.
And it was less fun after doing 20 of them or something. So I thought, how can we do peripheral
emulation? It's a really hard problem to do peripheral emulation if you don't know what the
peripheral is. And it turns out that if you have really hard problems, you can just ask for an
intern and they will do their master thesis on it. Okay. Yeah. So as Jeffrey told, we now have to
emulate. Is it on? Hello, everyone. Yes, that works. So we have to emulate the peripherals, but
we don't know what the peripherals are or where they are. So that's quite difficult.
But let's first start with what goals we have. We want the emulation to be automatic. We don't want
to have to do things every time we encounter a new peripheral or a new device. We also want the
peripheral to behave somewhat realistically in the sense that, yeah, it should, the device should
not go into an error state saying, oh, the peripheral was broken or whatever. And we also
want it to be generic. So it works for one thing. It works for the other thing. It's nice.
So of course I did a master thesis. So you have to look at the literature. And there basically
are three different methods that are used to emulate peripherals. There's a hardware in the loop
approach, which basically, well, just you have the hardware and you connect it to your computer
that you're using for emulation. And every time the emulator requests some peripheral
interaction, then you just pass it on through the hardware and then pass the value back.
It works. The values are realistic, but it's not that scalable. Like every time you have a different
device that you're emulating, you have to fetch a new device, buy it. I don't know.
That's not too nice. The other method is to emulate it. And here we mean by emulates,
just write those stops for every peripheral. If you do that well, which also is quite a bit of
effort, if you do it well, the values will be realistic. But it is a lot of effort, especially
if you have all those peripherals that Jeffrey just showed. So it's also not scalable. However,
there is a third method that at least has the, or at least is scalable, symbolic abstractions,
where you use symbolic execution to guess what's the correct value would be. But that might not be
realistic. So this symbolic execution, what is that? Let's talk about that here. We have a simple
function that takes two inputs and returns an output. And if we just execute that classically,
normally, then we might start with a memory state here, a equals 11, b equals 5, and c equals 0.
And in blue, we have the instruction pointer, and it just executes the code. It checks is a equal
to 0, a is 11, so it's not equal to 0. So it goes through the else. It sets a to 4, and then it
calculates c, which is 4 plus 5 equals 9. And then it returns 9 from that function. Pretty simple.
But then symbolic execution, we don't have concrete values for a and b, but we have variables
for us values where I'm using Greek characters for that. So a equals alpha, b equals beta,
and c equals 0. And then we start executing. But then we have a problem. We have to decide is a equal
to 0, but a is equal to alpha, is alpha equal to 0? So, well, for the moment, let's assume it is.
And we'll also draw a nice graph saying, and a note that we assume that alpha is equal to 0.
And we can just continue. We write 9 to b, and then we calculate c, which is 0 plus 9,
which is equal to 9, and then we turn that. So we're done. Not quite. We also have to
take care of the else branch. What happens when alpha is not equal to 0? Well, then a is a to 4,
but b is still beta. So when we calculate c, then c doesn't have a concrete value. It has a symbolic
value 4 plus beta. And then we would just return that. One of the main differences that you can
already see is if we just normally execute a function, we just have one result. We have to
reach result 9. But if we do it symbolically, then we have two results, either 4 plus beta or 9,
depending on the value of alpha. So back to the peripheral emulation. If we use symbolic execution
for the peripheral emulation, then we potentially have some problems. One of the problems is that
there might be multiple states, and that often becomes very many states. So some of those states
lead to successful emulation, and other states lead to bad emulation. They lead to infinite loops.
They lead to the PBL thinking, oh, this peripheral is broken. Let's just sit in this infinite loop
for a while. And another problem is that if you have many peripherals, which we do and many
peripheral interactions, then we also have a lot of states. And we need to somehow remember all those
states, so it quickly takes up a lot of memory. So the solution for these, or at least this last
problem, is to only run symbolic execution just for a bit. Not the entire program, but only a few
steps after the peripheral access, and then we probably will have already seen if the value
that we have returned from the peripheral is actually good or not. So that's what I mean by
concretizing the symbolic values. You run with this potentially symbolic value, for example,
4 plus beta for a while, and then after a while you check and you see, well, this seems like a good
value. You pick a value for beta, say 0, and then you continue with 4 plus 0, namely 4, and then
everything is concrete again, and you can just run the emulator. So that also brings another
question. How do we concretize a value? What value do we pick? For that, I thought it would be nice
to use different heuristics to add more constraints. And each heuristic, I called it a tactic,
and every tactic defines a nice property, something that would indicate sort of success.
For example, a nice property could be return 1 from the function that we're currently in. Maybe
the function is checking if the peripheral is there, and it returns 1 if the peripheral is there,
and 0 if it's not. Then the result of the read from the peripheral, if that leads to a 1 being
returned, then we're probably returning the right value. And how do we know if we want to return 1
or 0 or something else? Well, we can just use first one, and if that doesn't seem to work,
then we try another, and then another, which is to try that. That's also a nice thing that we don't
have to be fast about this. We can just take a little more time. So what are these tactics? I
defined three tactics, or infinitely many, but depends on how you look at it. I defined the
dummy tactic, which is not that clever. It just continues to the next instruction. Many peripheral
interactions are not really that relevant. You just write the value somewhere, or they read some
value and store it in some other memory location. It's not that important. So symbolic execution
is also quite intensive, so we don't have to have all this overhead if it's not necessary. So at first,
we just try to ignore it and just continue to the next instruction. And then there's another
tactic that's a bit more involved, actually uses the symbolic execution return tactic that also
takes a value, value n, and it returns that value from the current function, or at least it tries to
find a peripheral read value that returns n from the function that the peripheral read occurs in.
And the step tactic, it just steps a certain number n states forward in the symbolic execution,
and then it sort of judges the states and sees, well, maybe this state got into an
infinite loop, and the others didn't, so probably don't want to be in the state that
got into the infinite loop. So here is a nice diagram of how this part of the system works.
We have at the top the analysis tool, which is a Ghidra. It provides the binary.
Then on the left, we have the emulator that Jeffrey already talked about,
which is based on killing. And yeah, it uses hooks, and instead of having hooks for different
peripherals, we just hook the, pretty much the entire memory region. And every time there's a
read from there, we say, oh, well, that's probably peripheral read, and we pass it on to a different
component, which I called the read resolver. And there is another hook in there that detects bad
states. The read resolver uses Z3 or anger, uses anger, anger is built on Z3, the symbolic execution
framework, and it passes on the state of the emulator to the symbolic execution and instructs
the symbolic execution what constraints it tried to find a solution for. It also chooses a tactic
that I talked about. And finally, it pushes some things to the history, which is nice if you find
that we chose the wrong tactic, then we can later backtrack, which is why do you have a hook for a
bad state. If we end up in a bad state, we go to the backtracker. The backtracker looks at the history,
and says, oh, well, maybe we should have come back to the previous state. It restores the state, and
then a different tactic is selected. So how does this tactic selection work? It's pretty simple.
We have a hard-coded list of tactics that is as tried. And the first time we come across a read,
we pick the first one in that list. And then if it doesn't work or we go back, we backtrack, or we
have 10 consecutive reads from the same address, then we go to the next item in the list. And if
there are no tactics left, then we're probably in a hopeless state, and we might have made a problem
or made a mistake earlier on, and we have to backtrack even further.
I'll have to be quick about this. So this is a quick example of how this works.
Yeah, so first we try the dummy tactic, which returns zero, which is fine. It just or is in a
flag. Then we go to the second part of the code. First we return zero, but that doesn't work. We
end up in the infinite loop. So we backtrack and we try to return zero. But this function doesn't
return anything. So it gives an error. Return one also feels for the same reason. We step five
things and we five steps forward and we find that, well, maybe if we end the value with two and we
don't have zero, then and it's not equal to zero because we already tried zero. Then we should
probably try that. And the symbolic, symbolic execution finds the value two. So we go to the
next thing where we call a function. We first try zero, zero calls a panic function, which ends up
in the infinite loop. So that's bad. Returning zero also leads to the panic function being called
or well, returning zero doesn't work because we already tried returning zero. So returning one
doesn't work because we end up in the panic function and stepping five actually does work here.
And we return five and we not in the panic function. And then we have this infinite loop
and in every iteration of the loop, it checks the flag checking to see if the peripheral is alive,
probably, or done initialization. And every time we try the dummy tactic because well,
we find this thing, but after 10 times, we find, oh, well, we're reading from the same address
every time 10 times in a row. We probably should try a bit harder and return zero,
which doesn't work because this function doesn't return and step five. And then we see, well,
if we return zero, then we are in this infinite loop. We should try returning one.
And then it works. So then I did the whole thing about evaluation, which combination of tactics
is best. Well, most of them are roughly equally good. And then I did some tests with different
programs to see, well, how fast is this? Not too fast, but it's fast enough. And we also find that
there are, and I compared it to like the real hardware on our Raspberry Pi. And I compared it to
the amount of instruction that were taken, well, fewer because our system exited out of a lot of
loops early because they didn't have to do any initialization. But yeah, it was much, much lower.
But most importantly, the data that is stored and returned, that is pretty much identical.
And so that's nice. Also compared with another framework, which is,
yeah, it was a little slower on these things. Data was nearly identical and the number of
instructions was the same. Also not too important. Not sure what this slide is in your
duplicate slide, I guess. There are some limitations. Sometimes we concretize the wrong value.
And there's a lot of communication overhead, which is also part of future work.
And we also have a summary, and we also have a live demo. So I guess we're going to try the live
demo now. If we can switch the... Yeah. If someone could deliver a cellphone to us today.
Yeah. Thank you.
this.
Yeah.
Yeah, you can all say that's a solution for you.
And then, uh...
I can stand on that side.
I hope I can see it.
So, uh...
Yesterday I noticed that in the description of this talk,
I said there was a live demo.
And then I told Luke, I read the description,
and apparently we're giving a live demo.
So, it's a bit tiny,
but it really shows what this thing does.
And it's definitely not a full-flag simulation.
That is very...
I'm very much a tool for reversing.
It used to be called Firmulator.
Luke didn't like the name.
You maybe make it bigger?
The text.
That'll be it?
That'll be all shit.
I hope we make it in the time.
So, first, we run it without the symbolic execution part.
It loads all the memory mappings from Gidra,
starts the emulation,
and then it crashes, so let's stack them.
Make it one smaller,
then you can see the bottom, probably.
And it says unmapped memory on the bottom.
It's hard to see.
Anyways.
It crashes on an unmapped memory,
because it tries to write, this is a Raspberry Pi,
that's trying to initialize its video driver,
and it tries to write to the video driver
and read something back, and it fails, obviously,
because it's not there.
So, then we can run it again,
using the part with symbolic execution.
No one needs to matter.
Now we run it again, and you can see that it connects to Gidra
using the bridge.
It loads the memory mappings that are there,
loads the code from that, starts executing.
But, unfortunately, now, is what you get.
It's reading from two addresses, one after another.
So, it's hanging, because it thinks it's not in a loop,
but it definitely is in a loop.
And that's the thing you run into here.
Now you can set inside Gidra, you can set a command,
just as I see you're in a loop,
and a lot of what we do is just using this as a reversing tool,
so we just want to be able to set things fast.
And now we tell it in the right part of the loop,
and it just returns here. It's good.
And now you can see that everything went correctly.
It has returned from that loop.
Then it gets to the GPU initialization point.
It should say at some point, yes.
It sees that it has to return,
command parsed, return value none.
Now it returns out of that loop, tries to initialize the GPU,
it maps a memory for that, symbolically executes the function
for initializing the GPU.
More returning.
The demo effect is in full effect.
The fun part about this is that it ends up initializing the GPU,
but it gives you another error.
I couldn't get this weird ass resolution that you wanted,
and for us, that is the thing that differentiates it
from a full blown emulator.
It will not initialize it nicely,
but it will initialize it enough for us to continue on our work
where we are interested.
Thank you, Jeffrey and Luke.
Thank you.
